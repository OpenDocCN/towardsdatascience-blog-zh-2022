<html>
<head>
<title>Node2Vec Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Node2Vec解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/node2vec-explained-db86a319e9ab#2022-01-31">https://towardsdatascience.com/node2vec-explained-db86a319e9ab#2022-01-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="2ad4" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">Node2Vec解释</h1></div><div class=""><h2 id="3cc1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用Python解释和实现Node2Vec白皮书</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2d633b9f27afed914f1d439ac415fff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbtXtKWYD--3-SoeWH-91Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://unsplash.com/@alinnnaaaa" rel="noopener ugc nofollow" target="_blank">阿丽娜·格鲁布尼亚</a>拍摄自<a class="ae ky" href="https://unsplash.com/photos/hdpDLIXZg7Y" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h2 id="4654" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">目录</h2><ul class=""><li id="2cd1" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated">介绍</li><li id="303d" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">什么是图？</li><li id="1622" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">Node2Vec是什么？</li><li id="0670" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">随机漫步生成</li><li id="557f" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">跳过程序体系结构</li><li id="4855" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">它是如何工作的</li><li id="3d7a" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">履行</li><li id="4dd8" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">为什么要用Node2Vec？</li><li id="b406" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">结束语</li><li id="f65f" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">资源</li></ul><h1 id="9182" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">介绍</h1><p id="a530" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">这篇文章将给出由<a class="ae ky" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grover%2C+A" rel="noopener ugc nofollow" target="_blank">阿迪蒂亚·格罗弗</a>和<a class="ae ky" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Leskovec%2C+J" rel="noopener ugc nofollow" target="_blank">朱尔·莱斯科维奇</a>提出的node2vec算法的直观和技术理解。这篇论文可以在这里找到并阅读<a class="ae ky" href="https://arxiv.org/abs/1607.00653" rel="noopener ugc nofollow" target="_blank">，对于那些想更深入了解所介绍的技术概念的人来说。本文作者在python3中制作了一个名为node2vec的开源包，可以通过pip安装，用于网络上的可扩展特征学习。在网上可以找到这篇论文的各种开源实现，作者Aditya创建的知识库可以在这里找到</a><a class="ae ky" href="https://github.com/aditya-grover/node2vec" rel="noopener ugc nofollow" target="_blank"/>。另一个非常流行和常用的实现也可以在<a class="ae ky" href="https://pypi.org/project/node2vec/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。出于本文后面的教程和示例的目的，我将使用后一个包。</p><h1 id="4572" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">什么是图？</h1><p id="ae93" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">图论，致力于研究图形的数学领域。图是模拟节点之间成对关系的数学结构[1]。当节点之间存在关系时，这些节点通过边连接。节点也可以与自己有关系，否则称为自循环。图有多种形式，每种形式都有明显不同的特征，图可以是有向的、无向的、加权的、二分的等等。每个图也可以映射到一个邻接矩阵。邻接矩阵中的元素表示图[1]中的节点对是否彼此相邻。您可以参考图1来直观地了解图表的外观。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/df06172affbae974a0eb831b901434c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2P_Hju-HXu5lLiVPf5NxA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图G的邻接矩阵(图片由作者提供)</p></figure><h1 id="7a43" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">什么是Node2Vec</h1><p id="2ea7" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">使用网络时，一个值得注意的问题是将网络结构转换为数字表示，然后可以传递给传统的机器学习算法。Node2Vec是一种允许用户将图G中的节点映射到嵌入空间的算法。通常，嵌入空间的维数低于原始图g中的节点数。该算法试图保留原始图中的初始结构。本质上，图中相似的节点将在嵌入空间中产生相似的嵌入。这些嵌入空间本质上是对应于网络中每个节点的向量。图嵌入通常用作输入特征，以解决围绕<a class="ae ky" rel="noopener" target="_blank" href="/link-prediction-recommendation-engines-with-node2vec-c97c429351a8">链接预测</a>、社区检测、分类等的机器学习问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/2d252942a042dd015efed32bc446a6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-2esdTqSmJtaic8_4HJ61g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用node2vec从输入图G生成n维节点嵌入(图片由作者提供)</p></figure><p id="4e3e" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">一般来说，当处理非常大的图表时，科学家很难直观地表示他们正在处理的数据。查看图形外观的常见解决方案是生成与该图形相关联的节点嵌入，然后在低维空间中可视化这些嵌入。这使您可以直观地看到在非常大的网络中形成的潜在集群或组。</p><h1 id="7af7" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">随机漫步生成</h1><p id="89d1" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">理解什么是随机漫步以及它们如何工作对于理解node2vec如何工作是至关重要的。我将提供一个高层次的概述，但是如果你想更直观地理解和实现python中的随机漫步，你可以阅读我以前写的关于这个主题的文章。</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/random-walks-with-restart-explained-77c3fe216bca"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">带重启的随机漫步解释</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">理解带重启的随机游走算法及其在Python中的相关实现</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol ks nx"/></div></div></a></div><p id="60f4" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">作为一个高层次的概述，随机漫步的最简单的比较就是漫步。想象你走的每一步都是由概率决定的。这意味着在每一个时间指数上，你已经基于一个概率结果朝着一个确定的方向前进。该算法探索了您将要采取的每一步的关系以及它与初始起点的距离。</p><p id="b560" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">现在你可能想知道这些从一个节点移动到另一个节点的概率是如何计算的。Node2Vec引入了下面的公式，用于确定移动到节点x的概率，假设您先前在节点v。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fa0771bf4376a73889327556d9820a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*m4SlFTQtd3ZSqUpGZ-8Uzg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片取自<a class="ae ky" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank"> Node2Vec论文</a> [4]</p></figure><p id="a7fa" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">其中z是归一化常数，πvx是节点x和v [4]之间的非归一化转移概率。显然，如果没有连接x和v的边，那么概率将是0，但如果有边，我们确定从v到x的归一化概率。</p><p id="947a" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">该论文指出，引入偏差来影响随机游走的最简单方法是，如果每个边都有一个权重。然而，这在未加权的网络中是行不通的。为了解决这个问题，作者引入了由两个参数p和q控制的引导随机行走。p表示随机行走回到前一个节点的概率，而q表示随机行走可以通过图中以前看不见的部分的概率[4]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/16a41c8b0d83b8dba04ae6269bb60d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*Hewv8axfbOWLmjbWdE7KIg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片取自<a class="ae ky" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank"> Node2Vec纸</a> [4]</p></figure><p id="7034" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">其中，dtx表示节点t和x之间的最短路径，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/5dd8fc4536da516dfcaf4502c0a609fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*8I1CypymRZJPATjsTxg5PQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片取自<a class="ae ky" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank"> Node2Vec论文</a> [4]</p></figure><h1 id="eca3" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">跳过程序体系结构</h1><p id="5cba" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">为了理解node2vec中正在做的事情，有必要对word2vec有一个大致的了解。不久前，我写了一篇文章解释word2vec论文的直觉和实现。你可以在这里查看。</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/word2vec-explained-49c52b4ccb71"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">Word2Vec解释道</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">解释Word2Vec的直观性&amp;用Python实现它</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="op l oi oj ok og ol ks nx"/></div></div></a></div><p id="0f9c" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">出于本文的考虑，我将提供跳格模型的高级概述。</p><p id="e101" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">skip-gram模型是一个简单的神经网络，具有一个经过训练的隐藏层，以便在输入单词出现时预测给定单词出现的概率[2]。该过程可以直观地描述如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/6f310cc3ab794079984e7f082091f75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M6UxaLSbNMeoDFWRN_kPeQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为skip-gram模型生成训练数据的示例。窗口大小为3。图片由作者提供</p></figure><p id="14b0" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">如上所述，给定一些文本语料库，在一些滚动窗口上选择目标单词。训练数据由该目标单词和窗口中所有其他单词的成对组合组成。这是神经网络的最终训练数据。一旦训练了模型，我们就可以基本上得出一个单词成为给定目标的上下文单词的概率[2]。下图显示了skip-gram模型的神经网络体系结构。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/afed5871d067d415236163297a524ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYAkOS9JQwdozQjCzttuow.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">跳格模型架构(图片由作者提供)</p></figure><p id="9a31" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">语料库可以表示为大小为N的向量，其中N中的每个元素对应于语料库中的一个单词。在训练过程中，我们有一对目标和上下文单词，输入数组中除目标单词外的所有元素都为0。目标字将等于1。隐藏层将学习每个单词的嵌入表示，产生一个d维嵌入空间[2]。输出层是具有softmax激活功能的密集层。输出层基本上会产生一个与输入大小相同的向量，向量中的每个元素都由一个概率组成。这个概率指示了目标单词和语料库中的关联单词之间的相似性。</p><h1 id="4cde" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">它是如何工作的</h1><p id="349c" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">node2vec的过程相当简单，首先输入一个图，并从输入图中提取一组随机行走。然后，遍历可以被表示为单词的有向序列，其中每个节点表示一个单词。然后将生成的随机游走传递到skip-gram模型中。如上所述，skip-gram模型作用于单词和句子，随机游走中的每个节点可以表示为一个单词，整个游走可以表示为一个句子。skip-gram模型的结果产生了每个节点(或者这个类比中的单词)的嵌入。整个过程见下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/85f52457b65e1b421fa430b29fc2b8c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ok8syTKrUC1_Qo7cFxZUeQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Node2Vec架构(图片由作者提供)</p></figure><h1 id="79f9" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">履行</h1><p id="8d07" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">本文的这一部分将重点关注Python中node2vec的实现。下面是文章中使用的库和版本。对于这个实现，我们将生成一个随机图，将node2vec应用于该图，然后使用PCA在一个低维空间中可视化嵌入。如果你想浏览一下这个例子中用到的笔记本，你可以在这里找到它<a class="ae ky" href="https://github.com/vatsal220/medium_articles/blob/main/n2v/n2v.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="7cd3" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">要求</h2><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="1251" class="kz la it ou b gy oy oz l pa pb">Python=3.8.8<br/>networkx=2.5<br/>pandas=1.2.4<br/>numpy=1.20.1<br/>matplotlib=3.3.4<br/>node2vec=0.4.4<br/>seaborn=0.11.1<br/>sklearn=0.24.1<br/>gensim=4.0.1</span></pre><p id="3c33" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">如果你没有安装node2vec包，这里的<a class="ae ky" href="https://pypi.org/project/node2vec/" rel="noopener ugc nofollow" target="_blank"/>是通过命令行安装它的库文档。</p><h2 id="e2e7" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">生成网络</strong></h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="01db" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">上面的脚本将为我们生成一个随机图，以便在上面使用node2vec。用户将为随机生成的网络指定他们想要的节点数量和度分布。网络将通过配置模型生成。配置模型本质上是通过分配边来匹配度序列来生成随机图。请注意，由于这是随机的，因此每次生成的网络都会不同。此外，这只是一个运行node2vec的示例网络，仅仅因为生成的网络是一个多图并不意味着node2vec只能在其他多图上运行。Node2Vec可以在有向、无向、加权、多重或常规网络上运行。当我为<code class="fe pe pf pg ou b">n = 1000</code>运行上面的函数时，下面是与结果图相关的统计数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/10fa2e01ab0ee65827bf316e7cf069ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*NA0b7FQJzy4jru0mBxmVEQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与生成的网络相关的统计数据(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/625dcf54222e41d84bded086b3766a1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7H1xmJ7M1w2LkmVJ8k7EcQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与生成的网络相关联的度分布(图片由作者提供)</p></figure><p id="8d8d" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">如果你特别想在某个网络上测试这个算法，那么可以随意排除这篇文章的这一部分。在生成的图上应用node2vec。一般来说，在图形生成之后应该有一个数据预处理阶段，通常如果你的图形真的很大，你可能想要修剪掉任何无用的边/离群值，以使算法更有效一点。</p><h2 id="bc9b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">应用节点2Vec </strong></h2><pre class="kj kk kl km gt ot ou ov ow aw ox bi"><span id="ff1e" class="kz la it ou b gy oy oz l pa pb"><strong class="ou iu">Parameter Info</strong> <br/>- graph: a graph g, where all nodes must be integers or strings <br/>- dimensions: embedding dimensions (default: 128) <br/>- walk_length: number of nodes in each walk (default: 80) <br/>- num_walks: number of walks per node (default: 10) <br/>- weight_key: the key for the weight attribute on weighted graphs (default: ‘weight’) <br/>- workers: number of workers for parallel execution (default: 1)<br/>- p: the probability of a random walk getting back to the previous node (default: 1)<br/>- q: probability that a random walk can pass through a previously unseen part of the graph (default: 1)</span></pre><p id="edca" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">Node2Vec.fit方法接受任何可被<code class="fe pe pf pg ou b">gensim.Word2Vec</code>接受的关键字参数。上面提到的参数记录在node2vec库[3]中。出于本文的目的，我将窗口值设置为1，min_count设置为1，batch_words设置为4，dimensions设置为16。其余没有提到的参数设置为word2vec提供的默认值。请根据您自己的问题随意调整这些参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><p id="bc9c" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">因为这个实现在后端使用word2vec，所以您能够识别类似于输入节点的其他节点。请记住，输入节点必须以字符串的形式传入，它将以列表的形式按照相似性降序输出与输入节点最相似的前N个(默认为10个)节点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/e6a8ea514da9e3e413b0164888d76c92.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*D078mTq1c-pGTjdGF8QIrg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">与input_node 1最相似的节点(图片由作者提供)</p></figure><h2 id="d33b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak">转换为数据帧</strong></h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><h2 id="3cf9" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">可视化嵌入</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pc pd l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/18355e6b621f51dc4d0151bc19b7e4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eOTFM7LaeY5nBaBNVRcocQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通过PCA可视化的Node2Vec嵌入。每个点代表原始网络中的一个节点(图片由作者提供)</p></figure><p id="6796" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">请注意，就本文的目的而言，这种可视化没有任何意义。这是因为我们已经随机生成了带边的网络。如果您使用代表某个数据集的实际网络，您可以做出一些有趣的观察。在图中，每个单独的点对应于一个节点，根据论文所述，如果节点彼此相似，则它们会靠得更近。这将是一个简单的方法来查看是否有任何集群/社区与您的数据形成。</p><h1 id="dd9a" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">为什么要用Node2Vec？</h1><ol class=""><li id="f17e" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf pl mh mi mj bi translated">它易于扩展和并行化</li><li id="178e" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf pl mh mi mj bi translated">python和spark中的开源</li><li id="6748" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf pl mh mi mj bi translated">通过节点嵌入学习特征表示的独特方法</li><li id="07a0" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf pl mh mi mj bi translated">原始网络的结构通过嵌入得以保留</li><li id="8058" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf pl mh mi mj bi translated">Node2Vec有许多实际应用，包括但不限于节点分类、社区检测、链路预测等。</li></ol><h1 id="bc85" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated">结束语</h1><p id="66db" class="pw-post-body-paragraph na nb it lx b ly lz ju nc ma mb jx nd li ne nf ng lm nh ni nj lq nk nl nm mf im bi translated">总的来说，我认为本文的主要收获应该是node2vec生成与给定网络中每个节点相关的嵌入。这些嵌入保留了网络的原始结构，因此相似的节点将具有“相似的”嵌入。这是一个开源算法，可以很好地处理更大的网络(只要你有足够的计算能力)。</p><p id="ad8c" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">即使通读了我的文章，我还是鼓励你去阅读原文，并尝试应用它来进行一些分析/解决一些问题。原文可以在这里找到<a class="ae ky" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="650c" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">如果您想了解如何在链接预测和推荐引擎的上下文中使用Node2Vec，可以在这里参考我的文章:</p><div class="nu nv gp gr nw nx"><a href="https://vatsal12-p.medium.com/link-prediction-recommendation-engines-with-node2vec-c97c429351a8" rel="noopener follow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">使用Node2Vec的链接预测推荐引擎</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用节点嵌入进行链路预测</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">vatsal12-p.medium.com</p></div></div><div class="og l"><div class="pm l oi oj ok og ol ks nx"/></div></div></a></div><h1 id="e556" class="mp la it bd lb mq mr ms le mt mu mv lh jz mw ka ll kc mx kd lp kf my kg lt mz bi translated"><strong class="ak">资源</strong></h1><ul class=""><li id="dfd9" class="lv lw it lx b ly lz ma mb li mc lm md lq me mf mg mh mi mj bi translated">【1】<a class="ae ky" href="https://en.wikipedia.org/wiki/Graph_theory" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Graph_theory</a></li><li id="054a" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">[2]图形机器学习:通过应用Aldo Marzullo、Claudio Stamile和Enrico Deusebio的机器学习技术和算法，将图形数据带到下一个级别</li><li id="3c8c" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">[3]<a class="ae ky" href="https://pypi.org/project/node2vec/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/node2vec/</a></li><li id="c7bb" class="lv lw it lx b ly mk ma ml li mm lm mn lq mo mf mg mh mi mj bi translated">[4]https://arxiv.org/pdf/1607.00653.pdf<a class="ae ky" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank"/></li></ul></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="ba6c" class="pw-post-body-paragraph na nb it lx b ly np ju nc ma nq jx nd li nr nf ng lm ns ni nj lq nt nl nm mf im bi translated">我写的一些其他文章，你可能会喜欢读。</p><div class="nu nv gp gr nw nx"><a href="https://pub.towardsai.net/dynamic-time-warping-explained-fbb24c1e079b" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">动态时间扭曲解释</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">动态时间扭曲背后的直觉&amp;股票数据的Python实现</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">pub.towardsai.net</p></div></div><div class="og l"><div class="pu l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a href="https://vatsal12-p.medium.com/salary-analysis-comparison-of-the-us-canadian-markets-b6813839ca55" rel="noopener follow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">美国和加拿大市场的薪资分析和比较</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">分析匿名提交的美国和加拿大经济的工资和人口统计数据</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">vatsal12-p.medium.com</p></div></div><div class="og l"><div class="pv l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/word2vec-explained-49c52b4ccb71"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">Word2Vec解释道</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">解释Word2Vec的直观性&amp;用Python实现它</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="op l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/recommendation-systems-explained-a42fc60591ed"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">推荐系统解释</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">用Python解释和实现基于内容的协同过滤和混合推荐系统</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="pw l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/k-nearest-neighbours-explained-7c49853633b6"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">k最近的邻居解释说</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">在这篇文章中，我将给出一个概述，实现，缺点和相关的K最近…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="px l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/bayesian-a-b-testing-explained-344a6df88c1a"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">贝叶斯A/B测试解释</h2><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="py l oi oj ok og ol ks nx"/></div></div></a></div><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/mining-modelling-character-networks-part-i-e37e4878c467"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd iu gy z fp oc fr fs od fu fw is bi translated">挖掘和模拟字符网络——第一部分</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">图论研究论文讨论</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="pz l oi oj ok og ol ks nx"/></div></div></a></div></div></div>    
</body>
</html>