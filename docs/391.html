<html>
<head>
<title>Increasing model velocity for complex models by leveraging hybrid pipelines, parallelization and GPU acceleration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过利用混合管道、并行化和GPU加速来提高复杂模型的速度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/increasing-model-velocity-for-complex-models-by-leveraging-hybrid-pipelines-parallelization-and-3a0ca5e05049#2022-01-13">https://towardsdatascience.com/increasing-model-velocity-for-complex-models-by-leveraging-hybrid-pipelines-parallelization-and-3a0ca5e05049#2022-01-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="77af" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""><h1 id="5639" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">通过利用混合管道、并行化和GPU加速来提高复杂模型的速度</h1></div><div class=""><h2 id="0a95" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">如何选择正确的工具来处理复杂的模型</h2></div><p id="9edb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据科学正面临着对CPU周期的巨大需求，因为科学家们试图处理复杂性增长速度超过摩尔定律的数据集。考虑到快速迭代和重新训练的需要，几年来，模型复杂性已经超过了可用的计算资源和CPU，并且这个问题正在快速增长。数据科学行业将需要采用并行化和GPU处理来高效利用日益复杂的数据集。</p><p id="ff4d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">鉴于最新模型越来越复杂，任何在大数据集上进行机器学习(ML)的企业最终都将面临这一挑战。像AlexNet这样的模型有61M的参数和超过600M的连接。尝试将其与ImageNet中的120万幅图像进行对比，你会遇到一个巨大的计算挑战。AlexNet是下图中最简单的模型之一——想想今天的SOTA模型需要什么。</p><p id="14da" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">问题是计算需求——这是减缓模型训练的原因。计算需求是基于模型复杂性和数据集大小的函数，用于训练复杂模型的CPU需求的增长速度超过了摩尔定律。如果我们看看从AlexNet到AlphaGo Zero的计算需求，我们会看到一个指数级的增长，三至四个月翻一番。相比之下，摩尔定律有两年的倍增期。自2012年以来，最新模型的计算需求增长了300，000倍以上——摩尔定律只会产生7倍的增长。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/6aa1a40320316152b914a9723ce5504f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*47moRQ2RwzSvqsc8_HycQA.jpeg"/></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">从2013年的AlexNet到今天的AlphaGo Zero，计算需求不断增长的图示；数据点的指数拟合给出了3.43个月的倍增时间，如Kozma，Robert &amp; Noack，Raymond &amp; Siegelmann，Hava。(2019).受大脑能量管理启发的情境智能模型。567–572.10.1109/SMC。18969.868686868617</p></figure><p id="3d42" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">为任务找到合适的框架</strong></p><p id="f021" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当您训练一个预测模型时，您会经历从预处理到模型训练、模型验证和操作化的阶段。传统的方法是端到端地使用Spark，投入更多的计算资源来解决问题，然后等待结果。但是，如果您为管道的不同部分使用不同的框架，您可以划分工作，并为每个工作使用最好的工具来处理每个阶段。</p><p id="bb43" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">混合管道应对现代挑战</strong></p><p id="f942" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您试图围绕一个单一的工具来编排您的整个模型生命周期，您将会受到“这个工具能做什么？”心态。切换到混合管道可以让您自由地为每个阶段选择最佳和最有效的工具。维护集群也非常昂贵。如果您有一个包含50个工作节点的本地Spark集群，您的管理员会希望将尽可能多的工作负载放在该集群上，因为企业需要支付其计算和维护费用。这反过来意味着群集可能会被大量利用并且资源有限。</p><p id="8f04" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一方面，如果您每周或每月都在重新培训您的模型，而不是维护那些在您需要之前会耗尽资金的资产，您可以寻找一些方法来启动集群，然后根据需要取消配置。例如，如果您每天收集数据，每周重新训练模型，您可以设置一个GPU加速的Spark集群，该集群在周日自动供应，执行管道，并在完成后取消供应。这不仅可以节省资金，因为您只需在需要时为集群付费，更重要的是，使用GPU加速可以保证集群在更短的时间内完成流水线，从而节省更多资金。以下是如何设置这一切的方法:<a class="ae lw" href="https://blog.dominodatalab.com/on-demand-spark-clusters-with-gpu-acceleration" rel="noopener ugc nofollow" target="_blank">带有GPU加速的按需Spark集群</a></p><p id="7784" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Spark是加州大学伯克利分校创建的通用计算引擎，是并行大数据处理领域的公认领导者。SparkSQL引擎是其他任何引擎都无法比拟的。但是Spark的ML库不像其他框架那样先进，而且由于其特定的数据处理范例和API，Spark的学习曲线有些陡峭。从这个意义上说，Spark生活在自己的世界里，而像Dask和Ray这样的挑战者一直在稳步增长。</p><p id="6fd3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">与Spark相反，Dask最初的设计原则是“不要发明任何东西”。这个决定背后的想法是，一直使用Python进行数据分析的开发人员应该对使用Dask感到熟悉，并且加速时间应该是最短的。Ray是加州大学伯克利分校的另一个项目，由两个主要组件组成——Ray Core，这是一个分布式计算框架，以及Ray生态系统，广义而言，这是许多与Ray打包在一起的特定于任务的库(例如，Ray Tune——一个超参数优化框架，用于分布式深度学习的RaySGD，用于强化学习的RayRLib等。)</p><p id="2b5a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">Spark仍然非常适合ETL工作负载，但Ray更适合强化学习等特定任务，Dask在对Pandas DataFrames和NumPy数组的开箱即用支持方面处于领先地位。你需要能够挑选最好的。</p><p id="7635" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">关于框架之间的差异，请参见:<a class="ae lw" href="https://blog.dominodatalab.com/spark-dask-ray-choosing-the-right-framework" rel="noopener ugc nofollow" target="_blank"> Spark、Dask和Ray:选择正确的框架</a></p><p id="ece0" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">加速速度</strong></p><p id="da9e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于大多数公司使用的是遗留的基础设施，使用多种工具和框架还不是一种常见的做法。如果您有一个Spark集群需要它来管理，那么您可能不得不使用Spark——获取其他任何资源都是一个IT难题。但是在数据科学中，你需要敏捷，如果到了紧要关头，要有快速失败的自由。</p><p id="b2be" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">数据科学是一个非常动态的领域。如果您想尝试一种新的并行处理框架，您不希望等待6–7周的时间来调配和配置集群。最坏的情况是，如果您的想法在使用IT资源并等待数周后仍未成功，您将失去所有时间，并且您在公司的信誉可能会受到影响。你想让尝试新方法变得容易。</p><p id="d57f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">此外，要解决计算量大的问题，不能只依靠快速CPU和混合流水线。对于像网格搜索和超参数调整这样的任务，您需要成百上千次地重新训练您的模型。你可以并行计算，或者使用GPU加速，或者两者兼而有之。如果不使用并行，您将需要越来越大的计算实例。不是一天重新训练你的模型，而是一个月。这对模型速度不好。</p><p id="42eb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">转向并行和GPU处理</strong></p><p id="9920" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于ML项目，许多问题是基于矩阵的代数计算，有大量简单的数学计算。GPU的一个优势是，它不是有十几个或二十几个核心来计算值，而是有数百个核心，可以非常快速地进行非常基本的计算。这是一个非常适合ML工作负载的解决方案——您可以将矩阵数学卸载到GPU，同时使用CPU进行更多的顺序计算。麻省理工学院的Neil C. Thompson和Kristjan Greenewald在<a class="ae lw" href="https://arxiv.org/pdf/2007.05558.pdf" rel="noopener ugc nofollow" target="_blank">深度学习的计算极限</a>中写了CPU的挑战和GPU的优势。</p><p id="d18d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">人们使用GPU进行模型训练已经有一段时间了。但是，试图建立一个可以协调多台机器和GPU加速的基础设施是非常复杂的——编写代码来分布和管理多台机器上的GPU执行真的很难。这里的创新在于，我们创建了特定的加速器来管理分布式并行化框架。NVIDIA为Apache Spark推出了RAPIDS加速器，为Spark增加了GPU加速。Dask和Ray等框架现在可以处理并行化，并与Tensorflow和PyTorch等GPU框架集成，以提供并行化的GPU执行。我们能够以前所未有的方式将并行化和GPU加速结合起来。驾驭GPU加速的分布式处理的能力对于在合理的时间内打破训练复杂模型的限制变得至关重要。</p><p id="221d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">结论</strong></p><p id="fbf8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">展望未来，模型的规模和复杂性只会增加。整个行业中的公司并不是因为新的和新奇的东西而试图得到模型驱动，他们这样做是因为竞争压力让他们别无选择。</p><p id="e4dc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您想成为一家领先的公司，您应该采取一种方法，通过对您的数据进行分区，使用GPU设置多台机器以闪电般的速度处理代数，并部署一种支持您轻松供应和管理不同框架和工具的能力的基础架构，来充分利用当前和新兴的工具。</p><p id="6f27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当您准备好采取下一步措施来加速您的数据科学计划时，请考虑您将如何实现一个由GPU加速支持的分布式处理混合管道。当您着手下一个项目时，您可以考虑每种方法的不同功能，并考虑在没有太多管理或IT难题的情况下合并多个框架的方法。通过考虑我上面讨论的要点，您将能够使用越来越复杂的模型交付及时的结果。</p></div></div>    
</body>
</html>