# 基于 Flux.jl 的迁移学习和孪生网络图像分类

> 原文：<https://towardsdatascience.com/transfer-learning-and-twin-network-for-image-classification-using-flux-jl-cbe012ced146>

## 利用数据加载器、Metalhead.jl 和双网络设计解决挑战

![](img/0244d4421078afc630a79649c8d7976f.png)

卢卡·布拉沃在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

今年早些时候，我在 PyTorch 从事一个项目，旨在创建一个深度学习模型，可以检测未知物种中的疾病。最近，我决定在 Julia 中重建该项目，并将其作为学习[flux . JL](https://fluxml.ai)【1】的一个练习，这是 Julia 最受欢迎的深度学习包([至少按 GitHub 上的星级数评级](https://juliahub.com/ui/Packages))。但是在这样做的时候，我遇到了一些挑战，这些挑战我在网上或文档中找不到好的例子。因此，我决定写下这篇文章，作为任何想做和我类似事情的人的资源。

# 这是给谁的？

因为 Flux.jl(以下简称“Flux”)是一个深度学习包，所以我写这篇文章主要是为了让熟悉迁移学习等深度学习概念的受众。

虽然我也是带着一个半新手(像我一样)的想法来写这篇文章的，但是其他人可能会觉得这篇文章很有价值。请记住，我写这篇文章并不是为了全面介绍或指导 Julia 或 Flux。为此，我将尊重其他资源，如正式的朱莉娅和通量文件，分别。

最后，我与 PyTorch 做了几次比较。理解我的观点并不需要 PyTorch 的经验，但是有 PyTorch 经验的人可能会觉得特别有趣。

# 为什么是朱莉娅？还有为什么是 Flux.jl？

如果你已经使用了 Julia 和/或 Flux，你可以跳过这一节。此外，许多其他人已经写了很多关于这个问题的帖子，所以我会很简短。

最终是我喜欢朱莉娅。它擅长数值计算，编程是一种真正的乐趣，而且速度很快。本机速度快:不需要 NumPy 或其他封装底层 C++代码的包装器。

至于为什么是 Flux，那是因为它是 Julia 中最流行的深度学习框架，用纯 Julia 编写，可与 Julia 生态系统组合。这个项目看起来和任何最终学习通量的项目一样好。

# 项目本身

好了，现在我已经无耻地说服了朱莉娅，是时候了解一下这个项目本身了。我使用了三个数据集——[plant village](https://data.mendeley.com/datasets/tywbtsjrjv/1)【2】、[plant leaves](https://data.mendeley.com/datasets/hb74ynkjcn/1)【3】和[plant aek](https://data.mendeley.com/datasets/t6j2h22jpx/1)【4】——涵盖了许多不同的物种。我使用 PlantVillage 作为训练集，另外两个组合作为测试集。这意味着模型必须学习一些对未知物种通用的东西，因为测试集将包含未经训练的物种。

了解这一点后，我创建了三个模型:

1.  使用 ResNet 迁移学习的基线
2.  具有定制 CNN 架构的双(又名，[连体](https://en.wikipedia.org/wiki/Siamese_neural_network))神经网络
3.  具有迁移学习双路径的双神经网络

这篇文章的其余部分将详细介绍处理数据以及创建和训练模型的一些挑战和难点。

# 处理数据

第一个挑战是数据集的形式不正确。我不会在这里详述我是如何预处理它们的，但简单来说，我创建了两个图像目录， *train* 和 *test* 。两者都写满了一长串的图片，分别叫做*img0.jpg*、*img1.jpg*、*img2.jpg*等等。我还创建了两个 CSV——一个用于训练集，一个用于测试集——包含一列文件名，一列二进制标签。

上面的结构很关键，因为总的数据集超过 10 GB，肯定不适合我的 PC 的内存，更不用说我的 GPU 的内存了。正因为如此，我们需要使用一个`DataLoader`。(如果你用过 PyTorch，你会很熟悉；这和 PyTorch 中的概念基本相同。)

要在 Flux 中做到这一点，我们需要创建一个自定义结构来包装我们的数据集，以允许它成批地加载数据。为了让我们的自定义结构能够构造一个数据加载器，我们需要做的就是为这个类型定义两个方法:`length`和`getindex`。下面是我们将用于数据集的实现:

本质上，它的工作方式是当 Flux 试图检索一批图像时，它会调用`getindex(dataloader, i:i+batchsize)`，这在 Julia 中相当于`dataloader[i:i+batchsize]`。因此，我们的自定义`getindex`函数获取文件名列表，获取适当的文件名，加载这些图像，然后处理它们并将其重塑为适当的`HEIGHT × WIDTH × COLOR × NUMBER`形状。对标签进行类似的操作。

然后，我们的培训、验证和测试数据加载器可以非常容易地完成:

# 制作一些模型

数据加载器准备就绪后，下一步是创建模型。其中第一个是基于 ResNet 的迁移学习模型。这实际上被证明是相对具有挑战性的工作，虽然希望它会很快得到解决。

在 [Metalhead.jl](https://fluxml.ai/Metalhead.jl/dev/README.html) 包中——包含用于迁移学习的计算机视觉通量模型——创建一个带有预训练权重的 ResNet18 模型应该像`model = ResNet(18; pretrain = true)`一样简单。然而，至少在撰写本文时，创建预训练模型会导致错误。这可能是因为 Metalhead.jl 仍在添加预训练的权重。终于在 HuggingFace 上找到了 *.tar.gz* 文件，里面包含了这里的权重[。提取 tarball 后得到一个普通的*。bson* 文件，我们可以使用以下代码来加载权重，并创建我们自己的自定义通量模型，具有单个二进制输出:](https://huggingface.co/FluxML/resnet18)

(注:如果有比这更优雅的方式来改变 ResNet 的最后一层，请告诉我。)

随着预训练迁移学习模型的建立，只剩下两个孪生网络模型。然而，与迁移学习不同，我们必须学习如何手动创建模型。(如果你习惯了 PyTorch，这就是 Flux 与 PyTorch 大相径庭的地方。)

使用 Flux 文档和其他在线资源创建 CNN 相对容易。然而，Flux 没有内置层来表示具有参数共享的孪生网络。它最接近的是`Parallel`层，这个层*不*使用参数共享。

然而，Flux 确实有文档[在这里](https://fluxml.ai/Flux.jl/stable/models/advanced/#Custom-multiple-input-or-output-layer)关于如何创建定制的多输入或输出层。在我们的例子中，我们可以用来创建自定义`Twin`层的代码如下:

首先注意，它以一个简单的结构`Twin`开始，有两个字段`combine`和`path`。`path` 是我们的两个图像输入将经过的网络，`combine`是最终将来自`path` 的输出组合在一起的功能。

然后，使用`Flux.@functor`告诉 Flux 像对待常规 Flux 层一样对待我们的结构，并且`(m::Twin)(Xs::Tuple) = m.combine(map(X -> m.path(X), Xs)…)`定义向前传递，其中元组 Xs 中的所有输入 X 都通过`path`馈送，然后所有输出都通过`combine`传递。

要创建具有定制 CNN 架构的 Twin 网络，我们可以执行以下操作:

在这种情况下，我们实际上使用`Flux.Bilinear`层作为`combine`，这实质上创建了一个完全连接到两个独立输入的输出层。以上两个输入是`path`的输出，即自定义 CNN 架构。或者，我们可以以某种方式使用`hcat`或`vcat`作为`combine`，然后在最后添加一个`Dense`层，但是这个解决方案对于这个问题来说似乎更优雅。

现在，要使用 ResNet 创建 Twin 网络，我们可以执行以下操作:

请注意我们如何使用与之前相同的技巧，使用一个`Flux.Bilinear`层作为`combine`，并使用一个与之前类似的技巧来使用预训练的 ResNet 作为`path`。

# 训练时间

现在我们已经准备好了数据加载器和模型，剩下的就是训练了。通常在 Flux 中，我们可以使用一个简单的一行程序，`@epochs 2 Flux.train!(loss, ps, dataset, opt)`，用于训练循环，但是我们确实有一些定制的东西想要用我们的来做。

首先，非孪生网络的训练循环:

这里要展开的内容很多，但本质上它做了几件事:

1.  它创建了一个助手结构，用于跟踪我们想要的任何验证指标。在这种情况下，每个历元的损失和精度。
2.  它只选择最后一层参数进行训练。如果我们想的话，我们*可以*训练整个模型，但是那会在计算上更加费力。这是不必要的，因为我们用的是预训练的砝码。
3.  对于每个历元，它遍历训练集的所有批次进行训练。然后，它计算整个验证集(当然是分批的)的准确性和损失。如果历元的验证精度得到提高，则可以省去模型。如果没有，它继续到下一个纪元。

请注意，我们在这里可以做得更多，例如，提前停止，但以上足以获得大致的想法。

接下来，双网络的训练循环非常相似，但略有不同:

首先注意，我们使用了一个同名的函数，`train!`，但是函数签名略有不同。这使得 Julia 能够根据我们训练的网络类型分配正确的功能。

还要注意，Twin ResNet 模型冻结了它的预训练参数，而我们训练所有的 Twin 自定义 CNN 参数。

除此之外，训练循环的其余部分基本相同，只是我们必须使用两个训练数据加载器和两个验证数据加载器。这为我们提供了每批的两个输入和两组标签，我们将其适当地输入到孪生模型中。最后，请注意，孪生模型预测两个输入图像是否具有相同的标签，而常规非孪生网络仅直接预测标签。

这样，为所有三个模型的测试集构建测试循环应该不会太难。因为这篇文章的目的是讨论我在网上找不到例子的主要难点，所以我将测试部分留给读者作为练习。

# 最后的想法

他们所说的 Julia 生态系统的现状有一定的真实性，即它可能不成熟，人们需要愿意处理有限的文档和/或稀缺的例子。

最大的挑战是弥合从相对容易、简单的示例到更高级的技术之间的差距，对于这些技术来说，示例很少。但是这也揭示了 Julia 的一个优势:因为它天生就很快，所以搜索一个包的源代码来找到答案通常非常容易。有几次，我发现自己在浏览 Flux 源代码，寻找一些东西是如何工作的。每次我都能非常轻松快捷地找到答案。我不确定我是否有足够的勇气为 PyTorch 尝试类似的事情。

另一个挑战是 Metalhead.jl 的不成熟状态，这在 Julia 生态系统中肯定不是唯一一个功能不完整的。

我上一个挑战实际上是一个心态挑战。Python 和 Julia 生态系统之间的一个根本区别是许多重要包的规模。例如，PyTorch 因为其内部的 C++需要做所有的事情，而纯 Julia 包可以轻松地互操作和组合。因此，你不会看到 Flux 有 PyTorch 那么多的特性。相反，你会在其他包中看到很多这样的功能，比如 MLUtils.jl、CUDA.jl、BSON.jl、Metalhead.jl 以及其他无数的包。记住这一点，无论何时用 Julia 编程，你都可以节省一些时间和精力。

作为最后一个想法，我发现通量是相当愉快和优雅的…一旦我掌握了它。我以后肯定会用 Flux 做更多的深度学习。

# 参考

[1] M. Innes，Flux:优雅的机器学习与 Julia (2018)，《开源软件杂志》

[2] Arun Pandian J .和 G. Gopal，数据用于:使用 9 层深度卷积神经网络识别植物叶部病害(2019)，Mendeley 数据

[3] S. S. Chouhan、A. Kaul 和 U. P. Singh,《叶片图像数据库:植物病理学植物保护实践》( 2019 年), Mendely Data

[4] V. P. Kour 和 S. Arora，PlantaeK:查谟和克什米尔本地植物叶数据库(2019 年)，Mendeley 数据