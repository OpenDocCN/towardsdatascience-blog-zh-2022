<html>
<head>
<title>How to Visualize Text Embeddings with TensorBoard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用TensorBoard可视化文本嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-visualize-text-embeddings-with-tensorboard-47e07e3a12fb#2022-01-23">https://towardsdatascience.com/how-to-visualize-text-embeddings-with-tensorboard-47e07e3a12fb#2022-01-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="4c0f" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">如何用TensorBoard可视化文本嵌入</h1></div><div class=""><h2 id="7e1c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从文本数据中轻松创建引人注目的图表，并检查嵌入内容的质量</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ee8481d0804298b358dbf655fdedc6c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wm1ZtnqcuLhOAk8gQ_V6Cw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><h1 id="316a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">目录</h1><ol class=""><li id="34d0" class="lq lr it ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated"><a class="ae mi" href="#725a" rel="noopener ugc nofollow">简介</a></li><li id="9c8b" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#e65a" rel="noopener ugc nofollow">数据建模</a> <br/> 2.1 <a class="ae mi" href="#da7a" rel="noopener ugc nofollow">导入数据集</a> <br/> 2.2 <a class="ae mi" href="#39d1" rel="noopener ugc nofollow">拆分训练并验证集合</a> <br/> 2.3 <a class="ae mi" href="#9218" rel="noopener ugc nofollow">标记器</a> <br/> 2.4 <a class="ae mi" href="#6ae3" rel="noopener ugc nofollow">填充</a> <br/> 2.5 <a class="ae mi" href="#a10b" rel="noopener ugc nofollow">创建并拟合模型</a></li><li id="a29d" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#11c7" rel="noopener ugc nofollow">导出并可视化嵌入</a> <br/> 3.1 <a class="ae mi" href="#ee9c" rel="noopener ugc nofollow">配置张量板</a> <br/> 3.2 <a class="ae mi" href="#1294" rel="noopener ugc nofollow">玩嵌入</a></li><li id="3bdb" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#9d2d" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="725a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">1.介绍</h1><p id="d3d4" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated"><strong class="ls iu">单词嵌入</strong>是将单词转换成数字的任何方法，它是任何涉及文本数据的机器学习(ML)工作流的首要任务。</p><p id="b213" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">独立于所面临的问题(分类、聚类等)，利用输入文本的有效数字表示对ML模型的成功至关重要。</p><p id="1742" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">但是什么是文本的有效数字表示呢？基本上，我们希望将一个单词嵌入到一个能够传达单词含义信息的数字或向量中。</p><p id="2ecb" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">直观理解这一概念的一种方式是通过<strong class="ls iu">词语类比</strong>，即以下形式的关系:“<em class="ng"> word₁之于word₂，如同word₃之于word₄ </em>”。这就允许解决诸如“<em class="ng">男人之于国王如同女人之于..？</em>"通过矢量加减法，如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/832be03223e21dde861a0bc5cd0987fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*W2UyE6MujFVoAHogoBh9IQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最接近w(国王)- w(男人)+ w(女人)的嵌入是女王的嵌入。图片来自[1]。</p></figure><p id="a1c5" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">现在，让我们设想有一个通用数据集，其中每个文本样本都与一个类(或标签)相关联。例如，我们可能面临一个情感分析任务(带有诸如:中立、消极、积极等标签)或者一个对话代理的意图检测问题。在这种情况下，我们将训练一个分类模型，并使用准确性、精确度、召回率、F1分数等指标来评估其性能...但是，我们怎样才能容易地观察到嵌入文本的图形表示，如上图所示？</p><p id="32b0" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在本帖中，我们涵盖了从一个文件导入的通用数据集开始，访问文本嵌入的吸引人的动态可视化所需的所有步骤。为了实现这个目标，我们将使用TensorFlow(一个流行的开源ML库)和TensorBoard。</p><h1 id="e65a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">2.数据建模</h1><h2 id="da7a" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">2.1导入数据集</h2><p id="2458" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">在之前的post⁴中，我们描述了一个由罗马图书馆读者的评论组成的数据集的制造，从由“<a class="ae mi" href="https://www.bibliotechediroma.it/" rel="noopener ugc nofollow" target="_blank"><em class="ng">istituzione biblioteche di Roma</em></a>”⁵.公开的公开数据开始</p><p id="397a" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">数据集由<strong class="ls iu">两列</strong>组成，一列为纯文本格式的读者评论(他们的语言是意大利语)，另一列为他们各自的标签。这些标签标识了review⁶.的主题我们希望创建一个多类文本分类器，能够预测输入评论的主题，并观察文本嵌入。</p><p id="d79d" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们从导入所需的库开始:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="42bd" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们从文件中加载数据集。值得注意的是，我们将描述可以<strong class="ls iu">应用于任何数据集</strong>的步骤，该数据集至少包含输入文本样本及其各自的标签，任何语言中的<strong class="ls iu">:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/db49ea700aad95407b1445ff89ef8797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*uAxNjw2iJcSmMD4cMjYZVA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="0a07" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">主题分布如follows⁴:</p><ol class=""><li id="363b" class="lq lr it ls b lt nb lv nc lx nx lz ny mb nz md me mf mg mh bi translated">关于女性在社会中的地位的评论，或者有着强势女性主角的小说(n=205，25.5%)</li><li id="6d1f" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated">专辑和音乐会的评论，或音乐家的传记(n=182，22.64%)</li><li id="f616" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated">关于经济和社会政治状况的书籍和论文的评论(n=161，20.02%)</li><li id="e00d" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated">与日本或日本文化相关的评论(n=134，13.67%)</li><li id="9d11" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated">科技泄密论文综述(122篇，15.17%)</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/19d685426667d8300686455072130c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*khUuX7Dpvy0NkisV7qZo6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="2200" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">出于分类的目的，我们需要数字标签。因此，我们将主题描述映射到整数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="39d1" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">2.2训练和验证集中的分割</h2><p id="f5d8" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">我们将训练集和验证集中的数据拆分如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="9218" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">2.3标记器</h2><p id="a433" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">此时，我们的训练集和验证集仍然是由文本组成的。为了通过将每个评论转化为整数序列来对文本语料库进行矢量化，我们利用了<code class="fe ob oc od oe b">tf.keras.preprocessing.text.Tokenizer</code> ⁷类。</p><p id="2c0d" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们任意选择一个词汇大小，即要保留的最大单词数，然后实例化tokenizer类并使其适合训练集。之后，我们为训练集和验证集生成数字序列:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="84e4" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">标记化的文本序列看起来怎么样？我们可以观察到如下随机处理的序列:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e6df08e5c89cd06f997981175cafd95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*TRcKukqpSzlnhOzlUZgcpA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="f1f8" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">从上图中，我们可以看到输入句子中的每个单词是如何映射到一个不同的整数上，从而创建一个数字序列的。对于出现不止一次的单词，我们注意到它们总是得到相同的数字表示(例如，"<em class="ng"> molto = &gt; 39 </em>")。</p><p id="627d" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们最后创建一个包含单词和整数之间关联的字典:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="6ae3" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">2.4填充</h2><p id="cb58" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">我们有效地将文本转换为向量，但是我们仍然不能将它们用作ML模型的输入，因为任何句子都可能有不同的长度。我们现在必须找到一种方法，使它们一致(即大小相同)，而不产生不需要的噪声。</p><p id="e688" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">获得相同大小的序列的一种方法是通过<strong class="ls iu">填充</strong>它们，即向较短的序列添加相同的便利值(通常为零)，允许它们匹配所需的长度:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/7947548c96cb134943af86540e27a241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0CJgssFgShpKAi5ITSuM5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">填充示例。图片作者。</p></figure><p id="90f5" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在张量流中实现这一点的一种方法是使用<code class="fe ob oc od oe b">tf.keras.preprocessing.sequence.pad_sequences</code> ⁸:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5d6e385fc9d7b803eedb27e493421fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*nDAXWGYs1F4CqR8iXYwQ3w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="f2e1" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">值得注意的是，<code class="fe ob oc od oe b">pad_sequences</code>接受一个输入参数(<code class="fe ob oc od oe b">padding</code>)来指定是否应该在每个序列的(默认行为)之前添加<strong class="ls iu">或者在</strong>之后添加<strong class="ls iu">。我们可以通过提示<code class="fe ob oc od oe b">data_train[0]</code>来打印和检查一个填充序列:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/289e03038a5139fe16f61e1629cdf674.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*A8oY646zBg5KuhuLxjPMgw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">填充序列。图片作者。</p></figure><h2 id="a10b" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">2.5创建并拟合模型</h2><p id="4b40" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">我们定义一个由<code class="fe ob oc od oe b">Dense</code> ⁹和<code class="fe ob oc od oe b">Dropout</code> ⁰层组成的简单模型。用户可以随意修改参数和层，但请务必记住:</p><ol class=""><li id="8a95" class="lq lr it ls b lt nb lv nc lx nx lz ny mb nz md me mf mg mh bi translated">最后一个<code class="fe ob oc od oe b">Dense</code>层的输出空间维度必须等于我们想要预测的类的数量。</li><li id="6000" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated">当我们面临多类分类问题时，我们利用<code class="fe ob oc od oe b">softmax</code>激活函数。它估计目标类的离散概率分布。</li><li id="b55e" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><code class="fe ob oc od oe b">Embedding</code>层应该具有等于词汇表大小的输入维数，即最大整数索引+1:</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c8ec" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们选择训练50个时期的模型，但是我们也使用<code class="fe ob oc od oe b">EarlyStopping</code>回调以便在训练期间监控<code class="fe ob oc od oe b">validation loss</code>:如果度量在至少3个时期(<code class="fe ob oc od oe b">patience = 3</code>)没有改善，则训练被中断，并且来自<code class="fe ob oc od oe b">validation loss</code>显示最佳值(即最低值)的时期的权重被恢复(<code class="fe ob oc od oe b">restore_best_weights = True</code>):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="f2ab" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们可以从由<code class="fe ob oc od oe b">fit</code>方法返回的<code class="fe ob oc od oe b">History</code>对象中观察到分类的准确性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a55999761586c95aeb52d9ef0749358f.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*ucCJqC7H2o0h1ui3PnxD2A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="a674" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">多类文本分类器的创建对于我们的最终目标是必不可少的，即<strong class="ls iu">提供从通用模型中提取文本嵌入的指导，并可视化地探索它们</strong>。因此，我们不会将精力集中在进一步的模型改进和性能评估上。</p><h1 id="11c7" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">3.导出并可视化嵌入</h1><h2 id="ee9c" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">3.1配置张量板</h2><p id="2db6" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">TensorBoard是“<em class="ng"> TensorFlow的可视化工具包</em>”。这是一个工具，提供有用的测量和可视化，以监测ML工作流程。例如，人们可以使用TensorBoard来跟踪损失和准确性等指标，观察模型图，探索权重和偏差，并<strong class="ls iu">将嵌入投影到更低维度的空间</strong>。</p><p id="1982" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">为此，在前面的章节中，我们引入了TensorBoard嵌入式投影仪:</p><pre class="kj kk kl km gt ok oe ol om aw on bi"><span id="7770" class="ni kz it oe b gy oo op l oq or">from tensorboard.plugins import projector</span></pre><p id="b8ee" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们加载TensorBoard笔记本扩展:</p><pre class="kj kk kl km gt ok oe ol om aw on bi"><span id="15fb" class="ni kz it oe b gy oo op l oq or">%load_ext tensorboard</span></pre><p id="07ac" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们创建一个目录来存储所需的信息。然后，我们将单词到整数的字典和来自<code class="fe ob oc od oe b">Embedding</code>层的权重保存在目录中，最后设置<code class="fe ob oc od oe b">projector.ProjectorConfig() </code>配置:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="3d5b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们最后通过<code class="fe ob oc od oe b">logdir</code>参数指定我们刚刚创建的日志目录来启动TensorBoard:</p><pre class="kj kk kl km gt ok oe ol om aw on bi"><span id="ea3e" class="ni kz it oe b gy oo op l oq or">%tensorboard --logdir /logs/fit/</span></pre><h2 id="1294" class="ni kz it bd la nj nk dn le nl nm dp li lx nn no lk lz np nq lm mb nr ns lo nt bi translated">3.2玩嵌入</h2><p id="9e9a" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">为了可视化嵌入，我们从TensorBoard仪表盘右上角的下拉菜单中选择<code class="fe ob oc od oe b">PROJECTOR</code>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/cf2950bdabd529407c6f735861493c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CcugM_qGJgVSfbJ59wTP6Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="0f0b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在左下方，我们注意到该界面提供了多种维度缩减技术<strong class="ls iu">供选择(<strong class="ls iu"> UMAP、t-SNE、PCA、自定义</strong>)，以便直观地检查二维或三维投影维度中的高维向量。</strong></p><p id="fc6f" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们可以使用右上角的菜单来搜索特定的单词，并使用余弦相似度或欧几里德距离来突出显示它们最近的邻居。</p><p id="e9e5" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">例如，“<em class="ng"> pianoforte </em>”(钢琴)这个词更接近于“<em class="ng">巴赫</em>”的名字，这可能是因为这位著名的德国作曲家对钢琴改编曲的评论非常流行:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/936504ddbdca9f51abd99436a64b0b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A5F0oIRAqA-P_V5_mv0rlA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="6d0d" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">如果我们搜索单词"<em class="ng"> Giapponese </em>"(日语)，三个最接近的单词依次是:"<em class="ng">宫崎骏</em>"、"<em class="ng"> urbanistica </em>"(城市规划)和"<em class="ng">香蕉</em>"，表明读者对作者宫崎骏和吉本芭娜娜的可能偏好，以及对日本城市规划概念的兴趣(例如<em class="ng">町村</em>):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/af959fdf82505664403f95cd3c7eb1a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NGoyye_0ID0fjyaNttGcLw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><h1 id="9d2d" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">4.参考</h1><p id="a154" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">[1]卡尔·艾伦(Carl Allen)，蒂莫西·霍斯佩达莱斯(Timothy Hospedales)，《类比解释:走向理解单词嵌入，2019，<a class="ae mi" href="https://arxiv.org/abs/1901.09813" rel="noopener ugc nofollow" target="_blank"> arXiv:1901.09813 </a>。</p><p id="fe47" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><a class="ae mi" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">tensorflow.org/</a></p><p id="ac6b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><a class="ae mi" href="https://www.tensorflow.org/tensorboard" rel="noopener ugc nofollow" target="_blank">tensorflow.org/tensorboard</a></p><p id="5eb6" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[4]<a class="ae mi" rel="noopener" target="_blank" href="/multi-label-text-classification-using-bert-and-tensorflow-d2e88d8f488d">towards data science . com/multi-label-text-class ification-using-Bert-and-tensor flow-D2 e88d 8 f 488d</a></p><p id="e8ac" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">【www.bibliotechediroma.it/it/open-data-commenti-lettori T2】</p><p id="26c9" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[6]<a class="ae mi" rel="noopener" target="_blank" href="/romes-libraries-readers-comments-analysis-with-deep-learning-989d72bb680c">towards data science . com/romes-libraries-readers-comments-analysis-with-deep-learning-989d 72 bb 680 c</a></p><p id="8826" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[7]<a class="ae mi" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer" rel="noopener ugc nofollow" target="_blank">tensor flow . org/API _ docs/python/TF/keras/preprocessing/text/Tokenizer</a></p><p id="4556" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[8]<a class="ae mi" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences" rel="noopener ugc nofollow" target="_blank">tensor flow . org/API _ docs/python/TF/keras/预处理/sequence/pad_sequences </a></p><p id="9cd9" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[9]<a class="ae mi" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank">tensorflow.org/api_docs/python/tf/keras/layers/Dense</a></p><p id="bf7c" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><a class="ae mi" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" rel="noopener ugc nofollow" target="_blank">tensorflow.org/api_docs/python/tf/keras/layers/Dropout</a></p><p id="6c07" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[11]<a class="ae mi" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding" rel="noopener ugc nofollow" target="_blank">tensorflow.org/api_docs/python/tf/keras/layers/Embedding</a></p><p id="ea24" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><a class="ae mi" href="https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin" rel="noopener ugc nofollow" target="_blank">tensorflow.org/tensorboard/tensorboard_projector_plugin</a></p></div></div>    
</body>
</html>