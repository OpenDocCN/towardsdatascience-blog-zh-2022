<html>
<head>
<title>How to Answer Questions with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用机器学习回答问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-answer-questions-with-machine-learning-6c21357a44fc#2022-01-05">https://towardsdatascience.com/how-to-answer-questions-with-machine-learning-6c21357a44fc#2022-01-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="9782" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">如何用机器学习回答问题</h1></div><div class=""><h2 id="ceab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">看看班数据集，它的顶级NLP模型，以及它们是否过度拟合。</h2></div><p id="c7e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你曾经想要建立一个算法来做你的功课吗？虽然技术还没到位，但我们已经接近了。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/5bffb5d697612ee03be8f02ba618b5f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mPgiXQn54QjOyCJeU4fsjw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图1:在SQuAD 2.0数据集上具有最高精确匹配(EM)分数的模型— <a class="ae lr" href="https://paperswithcode.com/sota/question-answering-on-squad20" rel="noopener ugc nofollow" target="_blank"> src </a>。图片作者。</p></figure><p id="2251" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2016年，斯坦福大学的研究人员发布了一个问答数据集来训练NLP模型。从那时起，已经提交了数百个模型，每个模型都经过精心调整，与数据集相匹配。虽然它们拥有令人印象深刻的准确性，但我们预计在多次重用相同的数据集后会有一些过度拟合。</p><p id="abff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们利用加州大学伯克利分校的一个团队的研究来确定这些模型是否A)过度拟合数据集和B)能够概括。我们将保持高水平。</p><p id="9e17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">事不宜迟，我们开始吧。</p><h1 id="d5ce" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">0 —技术TLDR</h1><p id="e276" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">问答(QA)模型是基于自然语言处理的模型，旨在基于文本段落回答问题。斯坦福问答数据集(SQuAD)于2016年推出，以方便QA模型的训练。该库还存储开源NLP模型提交，其中一些已经超过了人类基线。</p><p id="77c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与其他流行的数据集一样，我们预计会观察到自适应过度拟合，因此加州大学伯克利分校的研究人员开发了新的数据集来估计模型的可推广性和自适应过度拟合的影响。令人惊讶的是，模型没有很好地概括，但也没有表现出过度拟合。</p><h1 id="a139" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">1 —但是，实际上发生了什么呢？</h1><p id="aa72" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">好了，让我们稍微慢下来，理解一下SQuAD数据集，一些最好的NLP模型，以及用于估计自适应过拟合的方法。</p><h2 id="730b" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">1.1 —什么是班数据集？</h2><p id="53bc" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">斯坦福问答数据集 (SQuAD)的引入是希望进一步推进问答(QA)建模领域。这是一个阅读理解数据集，由段落、问题和答案组成。这些段落来自维基百科，问题/答案通过亚马逊的机械土耳其人众包。</p><p id="b119" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意有两个版本。班1.1版不包含无法回答的问题，但班2.0版包含。</p><h2 id="9223" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">1.2 —让我们看一个例子</h2><p id="547f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在下面的图2中，我们可以看到一个小队的段落以及来自微软亚洲研究院的算法<em class="nb"> r-net+ </em>的预测。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nc"><img src="../Images/59e0aa79b0547e1d1250c805597802ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6vOYREz75FND0tEzoU_iHg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图2:小队数据源和建模示例— <a class="ae lr" href="https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/Super_Bowl_50.html?model=r-net+%20(ensemble)%20(Microsoft%20Research%20Asia)&amp;version=1.1" rel="noopener ugc nofollow" target="_blank"> src </a>。图片作者。</p></figure><p id="19a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">左边紫色的文字是关于我们主题的信息，在这个例子中是超级碗50，它是从维基百科(合法地)获取的。右边是关于文本的问题，接下来是<em class="nb">可接受的答案</em>和一些模型的预测。</p><p id="bbe7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些算法怎么可能胜过人类？嗯，让我想想…</p><h1 id="678a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">2 —哪种类型的模型表现最好？</h1><p id="b91a" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">大部分功劳归于两个模型:BERT和XLNet。</p><h2 id="8455" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">2.1 —伯特</h2><p id="20d9" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><a class="ae lr" rel="noopener" target="_blank" href="/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">来自变压器的双向编码器表示(BERT) </a>于2018年推出，并在NLP世界掀起风暴。它普及了双向学习的概念，这是一个在我们感兴趣的事物的两边利用信息的概念。</p><p id="b4df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个总体框架内，BERT利用了两种培训策略。</p><p id="06c6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在图3中，我们可以看到这些策略中的第一个，叫做<strong class="kh ir">屏蔽LM (MLM) </strong>。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nd"><img src="../Images/3d020aaeb2157d93d188efda7cf48a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ImrNC42b3l20kqKnRhbQCA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图3:第二个令牌被屏蔽的BERT示意图。图片作者。</p></figure><p id="3a81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在一句话中，MLM屏蔽(删除)了训练数据中的一个已知标记，并试图使用丢失标记周围的上下文来预测其值。这种方法依赖于双向学习，可以产生很好的性能。</p><p id="2a45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二种被称为<strong class="kh ir">下一个序列预测(NSP) </strong>，它只是试图确定两个句子是否顺序相关。训练数据在<em class="nb">真实序列</em>和<em class="nb">随机序列</em>之间平均分配，真实序列是观察到的一个接一个出现的两个句子，随机序列<em class="nb">是两个可能不相关的句子。</em></p><p id="f6f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了这个基线结构，工程师可以添加额外的层，使模型适合他们的任务。一个例子是添加最终分类层来执行情感分析。</p><p id="d5d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简洁起见，我们将继续，但是查看更多资源的评论。</p><h2 id="e3dd" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">2.2 — XLNet</h2><p id="c7ea" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">2020年XLNet发布，解决了BERT的一些缺点。根据该项目的首席研究员Quoc Le的一条推文，XLNet在20多项任务中超过了BERT。</p><p id="c16b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用一个简化的例子来看看XLNet是如何达到这种性能水平的。</p><pre class="lc ld le lf gt ne nf ng nh aw ni bi"><span id="5223" class="mp lt iq nf b gy nj nk l nl nm">import itertools<br/>perms = itertools.permutations(['A','M','C'])</span><span id="4d1f" class="mp lt iq nf b gy nn nk l nl nm">print(list(perms))<br/># Output:<br/>#  [('A', 'M', 'C'), ('A', 'C', 'M'), <br/>#   ('M', 'A', 'C'), ('M', 'C', 'A'), <br/>#   ('C', 'A', 'M'), ('C', 'M', 'A')]</span></pre><p id="0483" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的代码中，我们使用python的itertools库来显示3个令牌的所有排列。<em class="nb"> A </em>和<em class="nb"> C </em>代表单词，<em class="nb"> M </em>代表我们试图预测的未知令牌。</p><p id="af1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">伯特的一个缺点是，它的双向训练缓慢而复杂。另一方面，XLNet是一个严格的自回归模型，它利用排列来收集上下文信息。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi no"><img src="../Images/d0d79547167f07c86d96f18458c05bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jyToCTHks2lABLxVtwlPiQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图XLNet训练结构的例子。在这里，令牌可以根据排列顺序而变化。图片作者。</p></figure><p id="b2f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">XLNet在文本生成任务中经常优于BERT的一个主要原因是<strong class="kh ir"> BERT假设屏蔽记号的独立性，以非屏蔽记号为条件。然而，英语可以表现出大量的顺序依赖性，所以这一假设通常是不成立的。XLNet还实现了一些花哨的技术技巧，比如Transformer-XL的一个段递归机制和相对编码方案。但是(不幸的是)我们不会深入讨论这个问题。</strong></p><h1 id="59b8" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">3-当前模型是否过度拟合数据集？</h1><p id="6b9f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在我们已经了解了数据集和一些顶级建模技术，让我们继续这篇文章的最后一个主题。</p><h2 id="12ae" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">3.1 —评估方法</h2><p id="14ed" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这篇论文的作者试图确定这些模型是否表现出自适应过度拟合，这是一种当许多模型在同一数据集上拟合和调整时发生的现象。</p><p id="aa9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了做到这一点，我们在下面的等式中列出了潜在的偏差…</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi np"><img src="../Images/09fac7504d3445dee67c5d4ff7e19fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W5KBuXb0sRVLmYFrX3E9gw.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图5:损失分解方程— <a class="ae lr" href="https://arxiv.org/pdf/2004.14444.pdf" rel="noopener ugc nofollow" target="_blank"> src </a>。图片作者。</p></figure><p id="04e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在图5中，我们已经定义了每个关键术语，但是让我们简要地讨论一下每个术语的含义…</p><ol class=""><li id="bc1e" class="nq nr iq kh b ki kj kl km ko ns ks nt kw nu la nv nw nx ny bi translated"><strong class="kh ir">适应性缺口</strong>(绿色):训练和样本外(OOS)测试小队数据损失的差异。使用正确的方法选择我们的测试集，这个值应该非常小。</li><li id="f35b" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated"><strong class="kh ir">分布差距</strong>(蓝色):小队与<em class="nb">新</em> (New York Times，Reddit，Amazon)数据训练损失之差。当自然分布发生变化时，例如数据源，我们期望模型表现不同。这个值可能很大。</li><li id="b8f7" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated"><strong class="kh ir">一般化差距</strong>(红色):训练和OOS测试损失小队数据之间的差异。与第一个项目符号一样，我们认为这个值很小。</li></ol><p id="5e08" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有这些加起来就是由于模型的概括能力造成的损失。</p><h2 id="0180" class="mp lt iq bd lu mq mr dn ly ms mt dp mc ko mu mv me ks mw mx mg kw my mz mi na bi translated">3.2 —结果</h2><p id="3019" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">首先，在任何模型中几乎没有适应性过度拟合的证据。在SQuAD数据集上的OOS模型性能与在新数据集上测试的模型的OOS性能线性相关。从数学上来说，这意味着我们的适应性和泛化能力差距有相似的值。</p><p id="57e1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个结果相当令人惊讶，因为像<a class="ae lr" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>和<a class="ae lr" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>这样的著名数据集都表现出自适应过拟合。随着越来越多的研究人员开发针对这些数据集优化的模型，这些模型往往会失去通用性。然而，我们没有看到同样的现象。</p><p id="ea15" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二，在适应新数据集时，性能有了显著下降。换句话说，分配差距很大。更具体地说，NYT、亚马逊和Reddit数据集分别表现出3.8、14.0和17.4 F1点的平均性能下降。</p><p id="2a2f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然我们可能会直觉地认为这种性能下降是由于语法和句子结构的恶化，但作者研究了两组下降，无法找到结论性的解释。</p><h1 id="8a9a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">4—总结和后续步骤</h1><p id="3d15" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">虽然缺乏结论性的解释可能不令人满意，但仍有一些采取下一步措施的机会。但是，在我们开始之前，让我们快速回顾一下…</p><p id="b6b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问答模型基于文本来回答问题。SQuAD是一个QA数据集，它促进了QA应用程序的NLP工作。顶级QA模型包括BERT和XLNet，但是它们仍然不能很好地推广到其他数据集。最后，令人惊讶的是，在SQuAD数据集上几乎没有自适应过度拟合的证据。</p><p id="4527" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们对要点已经非常清楚了，那就让我们来看一些潜在的后续步骤…</p><ol class=""><li id="69d8" class="nq nr iq kh b ki kj kl km ko ns ks nt kw nu la nv nw nx ny bi translated"><strong class="kh ir">构建可解释性能差异的数据集比较指标。</strong>使用一些标准诊断，作者无法确定为什么模型在Reddit和亚马逊文本上的表现相对于维基百科文本如此糟糕。</li><li id="196d" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated"><strong class="kh ir">看看偏倚-方差权衡和训练数据大小之间的关系。</strong>对于高度特定的大型数据集，我们期望看到过度拟合，但数据大小和偏差之间的关系并不为人所知。</li><li id="9473" class="nq nr iq kh b ki nz kl oa ko ob ks oc kw od la nv nw nx ny bi translated"><strong class="kh ir">全面改进QA模式。</strong>尽管一些模型在特定领域非常有效，但要像人类一样进行概括，它们还有很长的路要走。</li></ol></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><p id="0ac2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nb">感谢阅读！我会再写21篇文章，把学术研究带到DS行业。查看我的评论，链接到这篇文章的主要来源和一些有用的资源。</em></p></div></div>    
</body>
</html>