<html>
<head>
<title>TensorFlow Distributed: A Gentle Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流分布:一个温和的介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-distributed-a-gentle-introduction-fafd1e49d1b6#2022-01-20">https://towardsdatascience.com/tensorflow-distributed-a-gentle-introduction-fafd1e49d1b6#2022-01-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="156f" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">张量流分布:一个温和的介绍</h1></div><div class=""><h2 id="441a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当您可以轻松地将训练过程分布到多个GPU时，为什么要将自己限制在一个GPU上呢？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bba315543ab4559feb66ee49d0eac744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EdfUJI_Mc0cw8KbL"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@nanadua11?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">娜娜杜瓦</a>拍摄的照片</p></figure><p id="577d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度学习的最新进展主要是由于我们可以处理的数据量。另一方面，大型模型，如具有1750亿个参数的GPT-3，展示了将该领域推向具有更多层的更深模型的巨大成果。</p><p id="35c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这两种情况下，将训练过程扩展到更多计算资源的需求比以往任何时候都高。训练时间越短，迭代越快。因此，你可以很快尝试新的想法。</p><p id="3e1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow默认情况下只会占用一个GPU进行训练。因此，即使我们的基础设施中有多个GPU设备可用，分发也不是自动的。因此，您需要对代码进行特定的更改，以让TensorFlow知道如何在训练期间协调事情。</p><p id="b9e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分布式培训有两大类:</p><ul class=""><li id="90df" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">数据并行性</li><li id="8aff" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">模型并行性</li></ul><p id="db1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型并行在高级案例中使用，主要是在研究中，这里就不涉及这个话题了。GitHub上的<a class="ae ky" href="https://github.com/tensorflow/mesh" rel="noopener ugc nofollow" target="_blank"> Mesh TensorFlow </a>资源库是深入研究模型并行性的一个很好的资源。</p><blockquote class="mj mk ml"><p id="6ca6" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated"><a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=tf-dist" rel="noopener ugc nofollow" target="_blank"> Learning Rate </a>是一份时事通讯，面向那些对AI和MLOps世界感到好奇的人。你会在每周五收到我关于最新人工智能新闻和文章的更新和想法。订阅<a class="ae ky" href="https://www.dimpo.me/newsletter?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=tf-dist" rel="noopener ugc nofollow" target="_blank">这里</a>！</p></blockquote><h1 id="b59d" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">数据并行性</h1><p id="fe09" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">数据并行适用于任何模型架构。这个事实使得数据并行成为分布式训练的标准方法。需要注意的是，训练模型所需的一切都必须适合GPU内存。</p><p id="ac70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，训练一个深度学习模型需要哪些东西呢？让我们来看一个TensorFlow中训练循环的具体例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="bb81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面代码片段中的注释解释了每一步发生的事情。所以，我们在这里建立一些深度学习词汇。在培训过程中，我们说:</p><ul class=""><li id="6dc3" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">训练过程运行<code class="fe np nq nr ns b">n</code> <strong class="lb iu">个时期</strong>，其中<code class="fe np nq nr ns b">n</code>是用户定义的超参数。</li><li id="649c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">每个历元执行几个步骤，在每个<strong class="lb iu">步骤</strong>，模型看到一批<strong class="lb iu">数据</strong>。</li><li id="f654" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们使用每个<strong class="lb iu">批次</strong>来计算梯度并更新模型的<strong class="lb iu">参数</strong>(或<strong class="lb iu">权重</strong>)。</li><li id="686d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">最后，当模型遍历一次数据集中的每个示例时，训练<strong class="lb iu">时期</strong>完成。因此，上面代码片段中的<code class="fe np nq nr ns b">train_step</code>函数定义了一个训练<strong class="lb iu">步骤</strong>，它将运行<code class="fe np nq nr ns b">n</code> <strong class="lb iu">时期</strong>。</li></ul><p id="afc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们假设我们有一个<code class="fe np nq nr ns b">100</code>图像的数据集。当模型看到每一张图片时，训练时期将结束。但是，我们不会一次将所有的<code class="fe np nq nr ns b">100</code>图像加载到GPU内存中。如果我们将批量大小设置为<code class="fe np nq nr ns b">20</code>，在每一步我们都加载<code class="fe np nq nr ns b">20</code>图像。因此，如果我们有一个由<code class="fe np nq nr ns b">100</code>图像组成的数据集，和一个由<code class="fe np nq nr ns b">20</code>图像组成的<code class="fe np nq nr ns b">batch_size</code>，我们在<code class="fe np nq nr ns b">5</code>步骤(<code class="fe np nq nr ns b">100 / 20 = 5</code>)之后完成一个时期。</p><p id="e47e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些<code class="fe np nq nr ns b">20</code>图像必须适合GPU存储器。此外，我们将模型放在GPU内存中。这意味着模型权重和它们的梯度也必须适合那里。</p><p id="c62c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么数据并行如何加快这个过程呢？利用数据并行性:</p><ul class=""><li id="aa4e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我们又增加了一个GPU设备用于培训。</li><li id="921f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们创建一个模型副本，并将其加载到新的GPU上。</li><li id="513a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们将数据分成两个子集，并为每个GPU提供相应的子集。</li></ul><p id="4a4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是，我们可以将批量加倍，并缩短完成一个时期所需的时间。因此，训练时间减少了。</p><h1 id="8219" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">同步数据并行</h1><p id="ae64" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">数据并行算法可以是<em class="mm">同步</em>或<em class="mm">异步</em>。这些术语指的是如何更新模型参数。在本文中，我们将看到同步方法。我们将在以后的文章中深入探讨异步问题。</p><p id="20ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使事情更具体，让我们采用一个可以使用的运行示例:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="b3c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调用<code class="fe np nq nr ns b">model.fit(…)</code>时，TensorFlow会自动占用并使用一个GPU设备。如果我们可以增加一个GPU设备，我们可以将<code class="fe np nq nr ns b">BATCH_SIZE</code>增加一倍，将每个时期的步骤减少一半。所以，让我们这样做:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="9f9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们定义分销策略。在这个例子中，我们使用最简单的方法<code class="fe np nq nr ns b">MirroredStrategy</code>，它允许我们将训练过程分布在同一台机器上的多个GPU设备上。</p><p id="d8f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们扩大<code class="fe np nq nr ns b">BATCH_SIZE</code>超参数，以充分利用我们添加的新GPU设备。我们称这个新的超参数为<code class="fe np nq nr ns b">GLOBAL_BATCH_SIZE</code>。</p><p id="5eff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们在分销策略的范围内定义和编译我们的模型。这一步告诉<code class="fe np nq nr ns b">MirroredStrategy</code>要在GPU设备间复制(即镜像)哪些变量。当我们调用<code class="fe np nq nr ns b">model.fit(…)</code>时，这个复制就会发生。</p><h2 id="98f7" class="nt mr it bd ms nu nv dn mw nw nx dp na li ny nz nc lm oa ob ne lq oc od ng oe bi translated"><strong class="ak"/><code class="fe np nq nr ns b"><strong class="ak">fit method?</strong></code>里面发生了什么</h2><p id="89ca" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">所以，让我们看看当我们调用' fit()'函数时会发生什么。理解这一点的最佳方式是通过一张图片:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/a834dcb0e7e00896017f138c77215fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*__GxZ_HXWrvu-ePTPh9dKg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">向前传递-作者提供的图像</p></figure><p id="16b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有两个GPU设备:<code class="fe np nq nr ns b">gpu:0</code>和<code class="fe np nq nr ns b">gpu:1</code>。TensorFlow将数据集分成两个子集，并将它们提供给GPU设备。然后，我们运行两个不同的过程，计算两组不同的梯度。这些过程的下一步是使用梯度来更新模型的权重。</p><p id="0e7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们有两个不同的梯度集，我们需要在更新模型的权重之前将它们结合起来。因此，我们将对它们进行平均:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/88133db00392f64d0ebc8f612c0c0b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*p_6txkbxBI_m3eZ5_taDaw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">向后传递-作者提供的图像</p></figure><p id="1d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在通过平均它们的值来减少两个梯度状态之后，我们可以更新模型的权重。</p><p id="4df1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每个训练步骤结束时，将这些梯度集合变成一个集合。然后，优化器执行模型更新，保持所有设备同步，因此得名同步。在所有工人完成上一步培训之前，任何工人都不能进行下一步培训。</p><h2 id="dc36" class="nt mr it bd ms nu nv dn mw nw nx dp na li ny nz nc lm oa ob ne lq oc od ng oe bi translated"><strong class="ak">多工人策略</strong></h2><p id="211f" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">TensorFlow还有另一种策略，在多台机器上执行同步数据并行，每台机器都可能有大量的GPU设备。这个策略的名字叫<code class="fe np nq nr ns b">MultiWorkerMirrorredStrategy</code>。</p><p id="6cc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种分发策略的工作方式类似于<code class="fe np nq nr ns b">MirroredStrategy</code>。此外，如果GPU设备不可用，您可以使用这两种技术在多个CPU核心上分配培训。</p><p id="bb39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，参与培训过程的每台机器被称为<em class="mm">工人</em>。除此之外，还有一个工人承担一些辅助任务。这些任务包括模型检查点和将摘要文件写入TensorBoard。这台机器被称为<code class="fe np nq nr ns b">chief</code>。</p><h1 id="bd20" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">结论</h1><p id="d59d" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">今天我们看到了使用Keras发布的TensorFlow的简介。我们看到了分布式培训的主要类别，并深入研究了数据并行性。</p><p id="7ee7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们研究了同步数据并行方法，以及如何使用TensorFlow实现这一方法。</p><p id="172a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下面的文章中，我们将看到一个具体的例子，并学习如何使用<code class="fe np nq nr ns b">MultiWorkerMirroredStrategy</code>分发策略！</p><h1 id="2d3d" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">关于作者</h1><p id="19c1" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">我叫<a class="ae ky" href="https://www.dimpo.me/?utm_source=medium&amp;utm_medium=article&amp;utm_campaign=tf-dist" rel="noopener ugc nofollow" target="_blank">迪米特里斯·波罗普洛斯</a>，我是一名为<a class="ae ky" href="https://www.arrikto.com/" rel="noopener ugc nofollow" target="_blank">阿里克托</a>工作的机器学习工程师。我曾为欧洲委员会、欧盟统计局、国际货币基金组织、欧洲央行、经合组织和宜家等主要客户设计和实施过人工智能和软件解决方案。</p><p id="62b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣阅读更多关于机器学习、深度学习、数据科学和数据运算的帖子，请关注我的<a class="ae ky" href="https://towardsdatascience.com/medium.com/@dpoulopoulos/follow" rel="noopener" target="_blank"> Medium </a>、<a class="ae ky" href="https://www.linkedin.com/in/dpoulopoulos/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或Twitter上的<a class="ae ky" href="https://twitter.com/james2pl" rel="noopener ugc nofollow" target="_blank"> @james2pl </a>。</p><p id="dcde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所表达的观点仅代表我个人，并不代表我的雇主的观点或意见。</p></div></div>    
</body>
</html>