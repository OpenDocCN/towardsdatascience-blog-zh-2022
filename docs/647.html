<html>
<head>
<title>Understanding DBSCAN and Implementation with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解DBSCAN并使用Python实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-dbscan-and-implementation-with-python-5de75a786f9f#2022-01-23">https://towardsdatascience.com/understanding-dbscan-and-implementation-with-python-5de75a786f9f#2022-01-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="60a2" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">无监督学习</h2><div class=""><h1 id="0734" class="pw-post-title jb jc it bd jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy bi translated">理解DBSCAN并使用Python实现</h1></div><div class=""><h2 id="d9b0" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在这篇文章中，我简要回顾了DBSCAN的思想及其在Python中的实现。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a9f292f0714bec2d4c0bbac0c8dd04df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LMGPEUdWEDAmtjZw"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@umanoide?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乌曼诺德</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2f08" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi me translated"><span class="l mf mg mh bm mi mj mk ml mm di"> D </span> <strong class="lk jd"> BSCAN </strong>代表<strong class="lk jd">基于密度的带噪声应用空间聚类</strong>，是一种<em class="mn">无监督</em>学习算法。DBSCAN是应用最广泛的聚类方法之一，因为DBSCAN发现的聚类可以是任何形状，可以处理一些其他方法不能处理的特殊情况。</p><p id="d408" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">显示<em class="mn"> DBSCAN </em>优于<em class="mn"> K-means </em>聚类算法的一个最常用的例子是下图。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi mo"><img src="../Images/c7b35c999592c0534a9ae9a4e00d4ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rfi9uHjGPdNgXgxe9xWvVw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">DBSCAN vs K-means。点是样本，X轴是特征1，Y轴是特征2。(图片由作者提供)</p></figure><p id="a57d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的例子中，k-means聚类的线性边界肯定不好用。然而，DBSCAN不需要任何形状的聚类，而是跟踪高密度区域，这比k-means更适合这种情况。</p><p id="a094" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本帖中，我将谈谈如何理解这个算法，以及如何用Python实现它。希望文章有帮助。</p><h2 id="5e25" class="mp mq it bd mr ms mt dn mu mv mw dp mx lr my mz na lv nb nc nd lz ne nf ng iz bi translated">了解DBSCAN</h2><p id="0376" class="pw-post-body-paragraph li lj it lk b ll nh kd ln lo ni kg lq lr nj lt lu lv nk lx ly lz nl mb mc md im bi translated">从DBSCAN的名字可以明显看出，最重要的部分就是“<em class="mn">基于密度的</em>这个词。那么，什么是密度呢？直截了当地说，我们可以将密度理解为特定区域内数据点数量的度量。那么，如何描述一个“<em class="mn">指定区域</em>”？我们可以用一个中心点与它的距离的某个值来描述一个特定的区域。因此，DBSCAN中的聚类是大量数据点的那些“指定区域”(密集区域)。</p><p id="6e39" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的描述中，我们发现几个“术语”对于聚类过程非常重要。首先，“<em class="mn">某个距离值</em>”。价值是什么？我们如何衡量距离的价值？第二，“<em class="mn">一个中心点</em>”。定义那些“特定区域”的中心点是什么？第三，“<em class="mn">高数据点</em>”。如何定义「高数」？</p><p id="f949" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其实DBSCAN中的所有参数在上面的问题中已经提到了。</p><p id="9066" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，<strong class="lk jd"> <em class="mn"> eps </em> </strong>，<strong class="lk jd"> <em class="mn">两个样本之间的最大</em> </strong>距离为一个样本被认为与另一个样本相连。并且距离可以由任何类型的距离函数来定义，例如“<em class="mn">欧几里德距离</em>”。</p><p id="b6e7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二，<strong class="lk jd"> <em class="mn">岩心样品</em> </strong>，即处于高密度区域的样品。</p><p id="3104" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第三，<strong class="lk jd"> <em class="mn"> minPts </em> </strong>，<strong class="lk jd"> <em class="mn">最小</em> </strong>数量的样本在一个点的邻域内被认为是核心点。</p><p id="a67b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这些参数共同定义了DBSCAN聚类中数据点的类型。这些点分为<em class="mn">核心点</em>、<em class="mn">可达点、</em>和<em class="mn">离群点。</em>好了，记住这些概念，让我们看一个具体的例子来回顾一下DBSCAN的思想。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nm"><img src="../Images/0b0ff18e4d5c965fb4668d9abcf35cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLkYqpNmEguxDPuhLaTtVA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">DBSCAN中的核心、核心可达点和异常值的示例。(图片由作者提供)</p></figure><p id="4ab3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上面的图中，我们将<strong class="lk jd"> <em class="mn"> minPts </em> </strong>设置为4，这意味着如果至少有4个点(包括其自身)在其距离<em class="mn"> eps </em>之内，则该点称为<strong class="lk jd"> <em class="mn">核心点</em> </strong>。因此，<em class="mn"> A </em>是一个核心点，所有其他棕色点也是核心点，因为它们都在围绕它们的<em class="mn"> eps </em>内至少有4个点。</p><p id="8911" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即使蓝色点，如<em class="mn"> B </em>，由于<em class="mn"> eps </em>内的邻域点少于4个而不是核心点，但它们仍然可以从某些核心点直接到达。因此，它们属于这些核心点的同一群。</p><p id="5922" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，点<em class="mn"> C </em>不能从任何核心点到达，所以它被称为离群点。</p><p id="9a9d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">从上面的例子中，我们可以看到DBSCAN中的集群由核心点和可从核心点到达的非核心点组成。并且每个集群包含至少一个核心点。即使非核心点也可以是聚类的一部分，但它只能位于聚类的边界，因为它们本身不能到达更多的点。</p><h2 id="0270" class="mp mq it bd mr ms mt dn mu mv mw dp mx lr my mz na lv nb nc nd lz ne nf ng iz bi translated">DBSCAN算法</h2><p id="af50" class="pw-post-body-paragraph li lj it lk b ll nh kd ln lo ni kg lq lr nj lt lu lv nk lx ly lz nl mb mc md im bi translated">好了，理解了DBSCAN的思想之后，让我们用下面的步骤来总结一下DBSCAN算法，</p><blockquote class="nn no np"><p id="92ef" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">1.对于每个数据点，在<strong class="lk jd"> eps </strong>距离内的邻域内寻找点，并将<strong class="lk jd">核心点</strong>定义为至少有<strong class="lk jd"> minPts </strong>个邻居的点。</p><p id="f747" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">2.将连接的核心点组定义为集群。</p><p id="e313" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">3.如果每个非核心点可以从相邻的核心点直接到达，则将它分配到附近的簇，否则将其定义为离群点。</p></blockquote><p id="d61e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大的<em class="mn"> eps </em>倾向于在一个聚类中包括更多的点，因此过大的<em class="mn"> eps </em>将包括同一单个聚类中的所有内容，而过小的<em class="mn"> eps </em>将导致根本没有聚类。</p><p id="a9ad" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">太小的<em class="mn"> minPts </em>是没有意义的，因为它会把每一个点都当成一个核心点。相对较大的<em class="mn"> minPts </em>可以更好的处理噪声较多的数据。</p><h2 id="f51f" class="mp mq it bd mr ms mt dn mu mv mw dp mx lr my mz na lv nb nc nd lz ne nf ng iz bi translated">DBSCAN的优势</h2><p id="26c2" class="pw-post-body-paragraph li lj it lk b ll nh kd ln lo ni kg lq lr nj lt lu lv nk lx ly lz nl mb mc md im bi translated">在了解了DBSCAN的思想和算法之后，它的优势就非常明显了。</p><blockquote class="nn no np"><p id="5202" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">首先，DBSCAN不要求用户指定集群的<strong class="lk jd">数量</strong>。</p><p id="7b62" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">第二，DBSCAN对异常值不敏感。</p><p id="91f0" class="li lj mn lk b ll lm kd ln lo lp kg lq nq ls lt lu nr lw lx ly ns ma mb mc md im bi translated">第三，DBSCAN形成的簇可以是任何形状，这使得它对不同类型的数据都是健壮的。</p></blockquote><p id="890b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是没有一个无监督的算法是完美的。DBSCAN确实有其局限性。例如，如果数据在集群之间的密度变化非常大，那么使用DBSCAN将是一个很大的问题，因为在一个数据集上只能使用一对参数，<em class="mn"> eps </em>和<em class="mn"> MinPts </em>。此外，如果没有数据的领域知识，定义<em class="mn">每股收益</em>可能会非常困难。</p><h2 id="513f" class="mp mq it bd mr ms mt dn mu mv mw dp mx lr my mz na lv nb nc nd lz ne nf ng iz bi translated">Python中的实现</h2><p id="da07" class="pw-post-body-paragraph li lj it lk b ll nh kd ln lo ni kg lq lr nj lt lu lv nk lx ly lz nl mb mc md im bi translated">DBSCAN在<em class="mn"> Python </em>中的实现可以通过<em class="mn"> scikit-learn </em>包来实现。对数据X进行聚类的代码如下，</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="c1fe" class="mp mq it nu b gy ny nz l oa ob"><strong class="nu jd">from</strong> <strong class="nu jd">sklearn.cluster</strong> <strong class="nu jd">import</strong> DBSCAN<br/><strong class="nu jd">import</strong> <strong class="nu jd">numpy</strong> <strong class="nu jd">as</strong> <strong class="nu jd">np<br/></strong>DBSCAN_cluster = DBSCAN(eps=10, min_samples=5).fit(X) </span></pre><p id="8eb6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">其中<em class="mn"> min_samples </em>是参数<em class="mn"> MinPts </em>和<em class="mn"> eps </em>是距离参数。</p><p id="2bd2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你想检查数据的聚类结果，你可以使用下面的命令，</p><pre class="ks kt ku kv gt nt nu nv nw aw nx bi"><span id="47ea" class="mp mq it nu b gy ny nz l oa ob">DBSCAN_cluster.labels_</span></pre><p id="4dcd" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就是这样！希望文章有帮助！</p><p id="b7a0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你喜欢阅读我的文章，你可以通过链接订阅我的媒体，<a class="ae lh" href="https://jianan-lin.medium.com/subscribe" rel="noopener">https://jianan-lin.medium.com/subscribe</a>。</p><p id="b2d4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">谢谢大家！</p><h2 id="2701" class="mp mq it bd mr ms mt dn mu mv mw dp mx lr my mz na lv nb nc nd lz ne nf ng iz bi translated">参考</h2><div class="oc od gp gr oe of"><a href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jd gy z fp ok fr fs ol fu fw jc bi translated">DBSCAN -维基百科</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">基于密度的含噪声应用空间聚类(DBSCAN)是由Martin…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">en.wikipedia.org</p></div></div><div class="oo l"><div class="op l oq or os oo ot lb of"/></div></div></a></div><div class="oc od gp gr oe of"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jd gy z fp ok fr fs ol fu fw jc bi translated">sklearn.cluster.DBSCAN</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">从向量数组或距离矩阵执行DBSCAN聚类。基于DBSCAN密度的空间聚类…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">scikit-learn.org</p></div></div><div class="oo l"><div class="ou l oq or os oo ot lb of"/></div></div></a></div><div class="oc od gp gr oe of"><a href="https://scikit-learn.org/stable/modules/clustering.html#dbscan" rel="noopener  ugc nofollow" target="_blank"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jd gy z fp ok fr fs ol fu fw jc bi translated">2.3.使聚集</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">可以使用modulesklearn.cluster对未标记的数据进行聚类。每种聚类算法都有两种…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">scikit-learn.org</p></div></div><div class="oo l"><div class="ov l oq or os oo ot lb of"/></div></div></a></div></div></div>    
</body>
</html>