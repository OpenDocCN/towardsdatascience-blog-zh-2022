# 为什么这么多组织在人工智能和机器学习上犯了错误

> 原文：<https://towardsdatascience.com/why-so-many-organizations-are-getting-ai-and-machine-learning-wrong-6e4e7dc3530e>

## 人工智能的未来:更快地自动化错误决策

![](img/3fe9608ed6acac84ee6f55cf53f4b6ed.png)

照片由作者大卫·E·斯威诺提供

如果您想获得数据科学投资的投资回报，您必须了解它能(或不能)做什么。否则，你就是在浪费时间和金钱。

人工智能(AI)被认为是解决大量商业弊病的灵丹妙药，但它并不总是产生积极的、可操作的结果。这是为什么呢？越来越多的组织目前在运营中使用人工智能、机器学习(ML)或数据分析，但这些实施的商业价值并没有得到实现。

人工智能停滞不前而不是飞速发展有一系列原因。人们很难理解人工智能到底在做什么，以及它的局限性。这些误解通常是由媒体驱动的，带有耸人听闻或过于简化的报道。然而，这些数据科学的神话也被许多声称知道他们在谈论什么的人抛出。

# 关于人工智能的 8 个神话

# 1.人工智能会神奇地解决你所有的问题

AI 承诺大事；增加收入，降低成本，在欺诈发生前识别欺诈，消除您所有重复和单调的工作。但是那些怀着远大梦想进入人工智能和人工智能领域的组织往往会发现现实并不尽如人意。

人工智能应该是一个循序渐进的过程。组织应该从改善流程和提高客户满意度或自动化业务流程这样的项目开始。随着时间的推移，随着对人工智能的能力和理解的增长，它可以用来应对巨大的金融挑战。

也要记住帕累托原则；80%的成果来自 20%的投入。没有必要深究那些不会产生可衡量结果的细节和问题。它们只会让系统——和你的员工——陷入困境。

# 2.机器学习是关于“像人一样思考”

人类是复杂的生物，我们的大脑复杂得令人难以置信。我们一直在使用启发式方法，这是我们从多年的经验中学到的“经验法则”。我们学到的刻板印象让我们做出快速的判断，但不一定是正确的。我们不希望计算机像人类一样思考，因为人类有错误的思维。

事实是，机器学习就是从数据中做出预测。如果数据质量差，结果就不会客观。

垃圾输入=垃圾输出

机器学习只是学习数据中的偏差，以及团队做出的假设。为什么这很重要？算法、数据和团队中的偏差会给企业带来重大损失。

例如，银行使用人工智能来决定借钱给谁。谁是风险？谁更有可能按时还贷？我们知道很多数据是有偏差的，所以基于这些数据的机器学习也会有缺陷。

历史上，男性是抵押贷款的持有者。申请贷款的妇女经常被拒绝，原因与她们的经济能力或偿还银行的能力无关。如果人工智能查看这些数据，它不会说“哦，我发现银行系统在历史上是重男轻女的”，而是说“女性贷款更经常被拒绝，因此女性的抵押贷款申请应该被拒绝”。还记得苹果信用卡惨败给丈夫的信用额度比妻子高 20 倍吗？

从各方面来看，女性的信贷风险实际上都低于男性。女性按时还贷，违约率更低。因此，如果一家银行实施有缺陷的 ML，他们不仅是在借钱给高风险的男性，而且还错过了低风险女性将提供的收入。

另一方面，法律意味着你不能基于性别进行歧视；在确定信用度时考虑性别是违法的。但是无视性别的信用贷款歧视女性。机器学习是从数据中学习，这些数据往往是有缺陷的，有偏见的，而且远非客观的。大多数时候，它不是公开的，而是训练数据集中的细微之处和代理。

# 3.AI 是即插即用的

有了所有的 SaaS 服务和软件公司做出的重大承诺，你认为人工智能很容易是情有可原的。只要把数据放进去，机器就会飞快地浏览信息，吐出你想知道的东西。不需要编码知识！

但是，即使员工了解软件服务，也有很多工作需要先做。

数据清洗:有数据，有好的数据。如果数据错误、不完整、样本太小，或者记录的信息完全错误，那么输入大量数据是没有意义的。

理解任务的结果:当一个企业或客户说他们想要一个钻头时，一个好的数据科学家知道他们实际上想要一个洞。不仅如此，他们还知道数据是否能够提供这些信息。领域知识:数据科学的现实是行业缺乏人才；没有足够的高质量数据分析师和科学家。缺乏训练有素和有经验的员工，这阻碍了人工智能的有效性和在市场上的应用。组织没有(或找不到)具备适当技能的数据科学家作为员工，因此外包给第三方提供商。依赖外部供应商只是一种短期解决方案；领域知识对于产生准确的结果至关重要。

# 4.机器学习预测未来

这是真的，如果未来和过去完全一样的话。ML 训练历史数据，并根据理论预测同样的事情会再次发生。不过，ML 不仅仅是做预测。您可以使用它来创建业务洞察和简化流程，添加新产品或新功能，以及进行预测。如果你不用 ML 来改变你商业决策的行为，那还有什么意义呢？

# 5.随着时间的推移，预测会自动变得更好

ML 使用不同的算法，称为模型，来创建他们的预测。一旦你开始生产一个模型，它就开始退化。这是因为数据会变，环境会变，人也会变。一个模型将是一致的。这就是为什么模型需要从一开始就重新培训，或者如果新模型更合适就使用新模型。

这些退化的模型是由于数据漂移。这是模型试图预测的东西被不可预见的变量改变的时候。例如，如果你预测一家实体店的销售额，其他变量也需要考虑在内，比如天气、即将到来的假期以及你的竞争对手在做什么。

概念漂移的一个例子是当皮肤癌诊断系统由于忽略变量而错过皮肤癌时。该机器知道寻找凸起的边缘、不规则的形状和随时间的变化，这将提醒临床医生怀疑癌症。但如果机器不考虑肤色(由于日晒或人种)，就会出现漏报。

泛化或协变量转移是困扰模型的另一个问题。如果用于训练模型的数据来自一个群体，可能是一个西方的富裕国家，那么它对于该组数据来说是过度拟合的。其他组和看不见的数据意味着预测不会准确，因为它们不能很好地概括。必须采取措施防止模型退化。部署后必须监控 ML 性能。如果模型降级，要么重构模型，要么尝试另一个更适合的模型。它可能需要添加新功能或更改参数。这就是所谓的持续学习，如果预测是准确的，他们需要检查和调整。

# 6.机器学习是为了提供更高的准确性

准确性很好，但这并不能说明性能。一个有 51%准确率的模型可以正确预测彩票号码，你就赢得了一千万美元。当预测导致巨大损失的欺诈性贷款申请时，准确率为 99%的模型可能会给出假阴性。

ML 研究概率，而不是确定性。

就像模型需要不断的重新评估一样，结果需要被检查以保证精确性。多少个假阴性到假阳性？这些错误的商业价值是什么？您损失了多少潜在收入？是系统没有足够的辨别力，你给你的销售团队提供了太多的线索，还是他们因为系统过于繁琐而拒绝了太多的线索而无所事事？

# 7.AI 和 ML 正在取代人

是的，天要塌下来了，小鸡。每当有重大的、有威胁性的变化时，人们都会担心会失去工作。这给人工智能的采用带来了阻力，因为人们试图抵制工作不安全感。一项研究显示，38%的人预计技术将在未来三年内淘汰他们工作场所的工作。据预测，到 2030 年，制造业将有多达 2000 万个工作岗位被机器人夺走。这是一些可怕的数字。

真实情况是 AI 和 ML 在增广人。

他们接受枯燥、重复的任务，并允许人们进行创造性的、不可预测的、更复杂的任务。人工智能应该与人类携手合作，在工作场所做出积极的改变。

我们可以回顾一下工业革命，看看人工智能革命的未来会是什么样子。这一对 18 和 19 世纪几乎所有工作的重大改革并没有造成长期的大范围失业和痛苦。人们总是会找到新工作(通常是在一段痛苦的调整期之后)，对大规模失业的担忧是没有根据的。

虽然人工智能会导致失业，但预计任何损失都将被更强大、更富裕的经济创造的新工作所抵消。自动化和人工智能将改变工作和生活，这是毋庸置疑的。但在大多数情况下，这些变化将是积极的。

# 8.数据越多，对机器学习越有利

GarbageIn:GarbageOut。如果你给机器输入不相关的信息，没有被清理的数据，或者是错误的，结果将会反映出来。数据科学家说，他们大约 50%的职责是清理数据，这是有原因的。即使是最聪明的机器也无法从错误的数据中获得洞察力。

# 数据科学的好处可能是巨大的

这不是一个神话；数据科学的商业成果，如果做得好，可以是所有那些承诺的东西。更快、更好、更强，组织的超人。

但是，要在组织层面上使用人工智能，需要对它能做什么以及它在哪里没用有更广泛的理解。否则，这只是那些 80%左右的数据科学项目中的又一个，永远不会启动。为了获得数据科学投资的投资回报，要对人工智能能做什么持现实态度，并明智地将其应用于具有大量数据的明确定义的项目。虽然这听起来不像即插即用和预测未来那样诱人(也不容易)，但这是一种更成功的战略，可以获得人工智能可以提供的结果。

这篇文章的一个版本首先出现在位于 https://www.alteryx.com/input/blog/8-myths-about-ai[的 Alteryx](https://www.alteryx.com/input/blog/8-myths-about-ai) [#Input](https://www.linkedin.com/feed/hashtag/input) 博客上