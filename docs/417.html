<html>
<head>
<title>Finally, remember what precision and recall is and stop being afraid of these questions in interviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最后，记住什么是精确和回忆，不要在面试中害怕这些问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finally-remember-what-precision-and-recall-is-and-stop-being-afraid-of-these-questions-in-f61981930c67#2022-01-14">https://towardsdatascience.com/finally-remember-what-precision-and-recall-is-and-stop-being-afraid-of-these-questions-in-f61981930c67#2022-01-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="5200" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">最后，记住什么是精确和回忆，不要在面试中害怕这些问题</h1></div><div class=""><h2 id="c4e9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个直观的指南，一步一步地绘制混淆矩阵，并推导出精确度、召回率和F1分数的定义</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5dec01d7645aa4595795e81db6fe9975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vDjGOCx7bF0HHsFRS7ciuw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预览。作者图片</p></figure><p id="0bd6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理解混淆矩阵、精确度和召回率的概念对于评估任何分类算法的质量是最重要的。而且虽然这在现实任务中并不那么重要(首先，你会在90%的情况下使用F1-score，其次，你会花10秒钟谷歌一下来刷新你的记忆)，但是理解这些东西还是很有用的。另外，这个问题在数据科学和机器学习职位面试中极其常见。</p><p id="a3ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我(以及我认识的一些更有经验的人)仍然需要花几秒钟来记住什么是什么。因此，我向你展示我的一步一步的指导，如何记住如何绘制混淆矩阵，并从中推导出精确度、召回率和F1分数的定义。</p><p id="0806" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你已经知道什么是精确或者回忆，但是仍然经常在定义上感到困惑，你应该读读这篇文章。</p><p id="f587" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章并不解释什么是精确或召回。这篇文章解释了如何记住什么是精确或回忆。</p><h1 id="acd9" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated"><strong class="ak">一步一步画困惑矩阵</strong></h1><p id="824b" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">当我们开始画混淆矩阵时，让我们画一个2x2的矩阵。</p><p id="60ec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们记得在某个地方一定有一个实际的类，和一个预测的类。取决于你如何排列它们，你的矩阵可能会相对于主对角线镜像。请记住，你在其他来源看到的矩阵可能与我画的不同。</p><p id="223f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了避免混淆，让我们将<strong class="la iu">预测的类放在</strong>的上面(使用直觉，单词<em class="mr">P</em>redirect中的字母<em class="mr"> P </em>是由一个竖条组成的，上面有一个圆圈<strong class="la iu"/>)。</p><p id="9b5b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后，让第一个元素(实际类的情况下为上，预测类的情况下为左)为负例，第二个元素(实际类的情况下为下，预测类的情况下为右)为正例。这里我用的直觉是，我们是从左到右，从上到下，从一个较小的数向一个较大的数移动(而负类是0，正类是1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/25712d204bf4f3420d473bcfac0ada84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qSjt-LKhI4uX69tUJhKvMw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">画出混淆矩阵。第一步。作者图片</p></figure><p id="7e8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二步也很简单——让我们填充主对角线上的元素。这些是我们的分类器正确识别的元素——真阳性和真阴性(<em class="mr">真</em>在这里意味着我们的分类器是<em class="mr">对</em>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/3ebc5b727716a47e381ece4bea74a2d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEVZ3kXP-SMKWzJJIMXQBg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">画出混淆矩阵。第二步。作者图片</p></figure><ul class=""><li id="fc43" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">真阳性(TP) </strong>是被分类为阳性且实际为阳性的元素——预测<em class="mr">阳性</em>和实际<em class="mr">阳性</em>。</li><li id="b794" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">真阴性(TN) </strong>是已经被归类为阴性的元素，实际为阴性——预测<em class="mr">阴性</em>和实际<em class="mr">阴性</em>。</li></ul><p id="afae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">之后，我们还要在矩阵中放置假阳性和假阴性(<em class="mr">假</em>这里指我们的分类器是<em class="mr">错的</em>)。这就是问题开始出现的地方。</p><p id="efde" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了记住假阳性和假阴性的位置，记住在这些预测中<strong class="la iu">分类器是错误的</strong>。这意味着，尽管它们不正确，但它们是<em class="mr">预测的</em>值，因此它们对应于<em class="mr">预测的</em>类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/37663a787b088306ca25829c5c6673b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lpk9sEAH2Ef2Vw-pPrq7HQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">画出混淆矩阵。第三步。作者图片</p></figure><p id="7763" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们给出正式的定义:</p><ul class=""><li id="2a04" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">假阳性(FP) </strong>(也称为<em class="mr"> I型错误</em>)是一个已经被归类为阳性但实际为阴性的元素——预测<em class="mr">阳性</em>，实际<em class="mr">阴性</em>。</li><li id="1d74" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">假阴性(FN) </strong>(又称<em class="mr"> II型错误</em> ) <em class="mr"> </em>是已经被归类为阴性但实际为阳性的元素——预测<em class="mr">阴性</em>，实际<em class="mr">阳性</em>。</li></ul><p id="1d3f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了快速理解它们之间的区别，不至于混淆，只要记住<strong class="la iu">分类器的预测是包含在题目中的，并且这个预测是错误的</strong>就够了。比如假<em class="mr">正</em>。它是<em class="mr">正的</em>，因为我们的分类器是这样预测的，但它是错误的。所以预测类是<em class="mr">正</em>，而实际类不是正的，所以<em class="mr">负</em>。</p><p id="ffb8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了不混淆TN、TP、FN和FP，问两个问题就足够了:</p><ol class=""><li id="b7cc" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt nj na nb nc bi translated">分类器预测了什么？<em class="mr">负或正</em>。</li><li id="f130" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt nj na nb nc bi translated">分类器正确吗？<em class="mr">真或假</em>。</li></ol><p id="591e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">两个答案都包含在问题中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/a1413520591809f12c98b7ce7628cfa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WQa2K_-vTIgJsNH66W5Fzw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">如何永远不要混淆TN，TP，FN，FP？作者图片</p></figure><p id="ee1c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们有一个现成的混淆矩阵，这已经是一半了！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/64c39b6357fd763827d5c0b38bf5ffcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2x9c_l124a_d7XMo2sYefw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">混乱矩阵。作者图片</p></figure><h1 id="c012" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated"><strong class="ak">如何停止恐惧，开始理解精密和回忆</strong></h1><p id="1a89" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">精确度和召回率公式都很简单。它是真阳性与真阳性加上某个值的比率。分母(真阳性加上某个值)是实际阳性或预测阳性。那有什么意义？让我们弄清楚。</p><h2 id="39ac" class="nm lv it bd lw nn no dn ma np nq dp me lh nr ns mg ll nt nu mi lp nv nw mk nx bi translated"><strong class="ak">精度公式</strong></h2><p id="3e97" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">记住精度公式中的所有项都包含字母<em class="mr"> P </em> ( <em class="mr"> P </em>精度— <em class="mr"> P </em>，很容易记忆)。<br/>所以精度是<em class="mr"> TP </em>与<em class="mr"> (TP + FP) </em>的比值，其中<em class="mr"> (TP + FP) </em>是<em class="mr">预测阳性</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/11d97907ff9f9f906ee705914b5add41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O2BN5Fs08tNrYCtmMK8TMQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">精确公式。作者图片</p></figure><h2 id="a510" class="nm lv it bd lw nn no dn ma np nq dp me lh nr ns mg ll nt nu mi lp nv nw mk nx bi translated"><strong class="ak">回忆公式</strong></h2><p id="adff" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">另一方面，召回是<em class="mr"> TP </em>与<em class="mr"> (TP + FN) </em>的比值，其中<em class="mr"> (TP + FN) </em>是<em class="mr">实际阳性</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/dbd02cdb2ca930b6635eeb463e31481f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0Nu_Ls0zIFWQtTYo9FieA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回忆公式。作者图片</p></figure><h2 id="0883" class="nm lv it bd lw nn no dn ma np nq dp me lh nr ns mg ll nt nu mi lp nv nw mk nx bi translated"><strong class="ak">这些到底有什么意义？</strong></h2><p id="600f" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">我不认为有必要给出奇怪的定义来解释一切，但只会使其复杂化(比如<em class="mr">回忆是一种检测概率</em>)。我不否认它们是有用的，但它们往往弊大于利。最后，你可以很容易地发现他们在阅读其他文章。</p><p id="5f4b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我会尽可能直观地解释一切。我建议你在阅读下面两条语句时，保持精确度，并在眼前回忆公式。</p><ul class=""><li id="b83f" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">如果FP = 0，则精度等于1。<br/>所以<strong class="la iu">精度高</strong>关系到<strong class="la iu"/><strong class="la iu">假阳性率低</strong>或者说<strong class="la iu">I型错误量小</strong>。</li><li id="3fbc" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">如果FN = 0，召回等于1。<br/>所以<strong class="la iu">高召回率</strong>与<strong class="la iu">低假阴性率</strong>或<strong class="la iu">少量II型错误有关。</strong></li></ul><p id="70fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如何记住这些？高精度—很少的假阳性—很少的I型错误。记住精度总是精度-召回对中的第一个(<em class="mr">I类型错误</em>)；我们已经记住的是——精度公式中的所有项都包含字母<em class="mr"> P </em>(很少有误<em class="mr">正</em>)。</p><p id="aa94" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是让您理解何时使用特定指标的基础。</p><ul class=""><li id="5636" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated">如果<strong class="la iu"> FP价格高</strong>，用<strong class="la iu">精度</strong>(预测借款人会还贷，虽然他破产了；“好”的借款人是正类)；</li><li id="90eb" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">而如果<strong class="la iu"> FN价格高</strong>，用<strong class="la iu">召回</strong>(预测病人是健康的，虽然他生病了；病是正类)。</li></ul><p id="ee3b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些定义取决于对类的选择(哪个类是负的，哪个是正的)——所以<strong class="la iu">要时刻注意这个</strong>。例如，交换上面例子中的类，看看会发生什么。</p><h2 id="fc1d" class="nm lv it bd lw nn no dn ma np nq dp me lh nr ns mg ll nt nu mi lp nv nw mk nx bi translated">f1-分数</h2><p id="782c" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">F1-score是一种将精确度和召回率结合成一个指标的方法。我们需要这个，因为只用一个数字评估质量很容易，而不是两个。我们不能使用简单平均值，因为它不考虑极小的值。</p><p id="3c38" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果我们让F1-score是精度和召回率的平均值，则相同的值得到:<br/>精度= 0.5和召回率= 0.5的分类器1和<br/>精度= 1和召回率= 0的分类器2。<br/>两个分类器都将得到F1分数= 0.5，尽管很明显第一个分类器要好得多。当然，这是个玩具例子，但离真相不远。</p><p id="82d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，我们想要这样一个表达式，如果两个元素中至少有一个比一个小得多，那么这个表达式就是小的。这样的表达式称为<em class="mr">加权平均值</em>，或<em class="mr">调和平均值</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/9b129a75e4a6e162e1fc6e1ec197627d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXlzRBMMpvLC2ht86ZrvGw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">f1-得分公式。作者图片</p></figure><p id="6379" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个表达式的分子是乘积，这是合乎逻辑的。如果其中一项比一项小得多，那么它们的乘积也将分别比一项小得多。需要乘以2，以便F1分数像所有常用指标一样从0变为1。</p><p id="6dbc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，还有其他分类指标。比如非常受欢迎的<strong class="la iu">AUC-ROC</strong>—<em class="mr">ROC(受试者工作特性)曲线下的区域</em>(你可以在这里<a class="ae ob" rel="noopener" target="_blank" href="/understanding-auc-roc-curve-68b2303cc9c5">了解一下</a>)或者不太受欢迎的<strong class="la iu"> AUC-PRC </strong> — <em class="mr">精确召回曲线下的区域</em>。</p><h1 id="e98f" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated"><strong class="ak">结论</strong></h1><p id="c87a" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">让我总结一下我们下面列出的所有概念:</p><ul class=""><li id="e860" class="mu mv it la b lb lc le lf lh mw ll mx lp my lt mz na nb nc bi translated"><strong class="la iu">真阳性(TP) </strong>是被分类为阳性且实际为阳性的元素——预测<em class="mr">阳性</em>，实际<em class="mr">阳性</em>；</li><li id="3e6d" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">真阴性(TN) </strong>是已经被归类为阴性的元素，实际上是阴性的——预测<em class="mr">阴性</em>和实际<em class="mr">阴性</em>；</li><li id="755a" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">假阳性(FP) </strong>(也称为<em class="mr"> I型错误</em>)是已经被分类为阳性但实际为阴性的元素——预测<em class="mr">阳性</em>，实际<em class="mr">阴性</em>；</li><li id="c77b" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu">假阴性(FN) </strong>(也称<em class="mr"> II型错误</em> ) <em class="mr"> </em>是已经被归类为阴性但实际为阳性的元素——预测<em class="mr">阴性</em>，实际<em class="mr">阳性</em>；</li><li id="2c44" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">高<strong class="la iu">精度</strong>意味着<strong class="la iu">低FP率</strong>(少数<em class="mr"> I型错误</em>)；</li><li id="9c39" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">高<strong class="la iu">召回</strong>意味着<strong class="la iu">低FN率</strong>(少数<em class="mr"> II型错误</em>)；</li><li id="96e0" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><strong class="la iu"> F1-score </strong>是一个将精度和召回率结合成一个数字的好方法。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/b4e3ae958e23039e06c510687269be86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nIpdlP7zWboF-4omRrwLRg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">总结。作者图片</p></figure><h2 id="5361" class="nm lv it bd lw nn no dn ma np nq dp me lh nr ns mg ll nt nu mi lp nv nw mk nx bi translated">可能对你有用的资源</h2><ul class=""><li id="e219" class="mu mv it la b lb mm le mn lh od ll oe lp of lt mz na nb nc bi translated"><a class="ae ob" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">维基百科关于精度和召回的文章</a></li><li id="b3c6" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><a class="ae ob" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" rel="noopener ugc nofollow" target="_blank">谷歌的机器学习速成班</a></li><li id="c6e6" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated"><a class="ae ob" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html" rel="noopener ugc nofollow" target="_blank"> Scikit学习官方文档</a></li></ul></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="71d0" class="lu lv it bd lw lx on lz ma mb oo md me jz op ka mg kc oq kd mi kf or kg mk ml bi translated">感谢您的阅读！</h1><ul class=""><li id="d8f7" class="mu mv it la b lb mm le mn lh od ll oe lp of lt mz na nb nc bi translated">我希望这些材料对你有用。<a class="ae ob" href="https://medium.com/@andimid" rel="noopener">在Medium上关注我</a>以获得更多类似的文章。</li><li id="ba60" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">如果您有任何问题或意见，我将很高兴得到任何反馈。在评论中问我，或者通过<a class="ae ob" href="https://www.linkedin.com/in/andimid/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ob" href="https://twitter.com/dimid_ml" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系。</li><li id="1601" class="mu mv it la b lb nd le ne lh nf ll ng lp nh lt mz na nb nc bi translated">为了支持我作为一名作家，并获得数以千计的其他媒体文章，使用<a class="ae ob" href="https://medium.com/@andimid/membership" rel="noopener">我的推荐链接</a>获得媒体会员资格(不收取额外费用)。</li></ul></div></div>    
</body>
</html>