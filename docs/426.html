<html>
<head>
<title>Graph Neural Networks: A Learning Journey since 2008 — Python &amp; Graph Convolutional Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图形神经网络:2008年以来的学习之旅——Python和图形卷积网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-neural-networks-a-learning-journey-since-2008-python-graph-convolutional-network-5edfd99f8190#2022-01-14">https://towardsdatascience.com/graph-neural-networks-a-learning-journey-since-2008-python-graph-convolutional-network-5edfd99f8190#2022-01-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="fd14" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">图形神经网络:2008年以来的学习之旅——Python和图形卷积网络</h1></div><p id="9028" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">今天，我们对GCN理论有了清晰而实用的认识。我们会穿过基普夫的火炬🔦GCN的实施👩‍🎓。然后，我们将把我们所学到的应用到可恶的Twitter数据集上🔥</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/33d7eba182e69becdf7148234b8363ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfPEWi9dgG2SdWCKcqHD0A.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片由<a class="ae le" href="https://unsplash.com/@ryunosuke_kikuno" rel="noopener ugc nofollow" target="_blank">龙之介菊野</a>在<a class="ae le" href="https://unsplash.com/photos/n0T2yNKYdwQ" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="3611" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我以前关于图形和ML的帖子:</p><ul class=""><li id="e8eb" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-part-1-7df897834df9?source=your_stories_page----------------------------------------">图形神经网络:2008年以来的学习之旅——第一部分</a></li><li id="f086" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-part-2-22dbf7a3b0d?source=your_stories_page----------------------------------------">图形神经网络:2008年以来的学习之旅——第二部分</a></li><li id="8c03" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-deep-walk-e424e716070a?source=your_stories_page----------------------------------------">图形神经网络:2008年以来的学习之旅——深度行走</a></li><li id="dea7" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-python-deep-walk-29c3e31432f?source=your_stories_page----------------------------------------">图形神经网络:2008年以来的学习之旅——Python&amp;深度行走</a></li><li id="d94a" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated"><a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-graph-convolution-network-aadd77e91606">图神经网络:2008年以来的学习之旅——图卷积网络</a></li></ul><p id="a6c9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="lt">通过我的推荐链接支持我的写作加盟媒介:</em></p><div class="lu lv gp gr lw lx"><a href="https://medium.com/@stefanobosisio1/membership" rel="noopener follow" target="_blank"><div class="ly ab fo"><div class="lz ab ma cl cj mb"><h2 class="bd iu gy z fp mc fr fs md fu fw is bi translated">通过我的推荐链接加入Medium-Stefano Bosisio</h2><div class="me l"><h3 class="bd b gy z fp mc fr fs md fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mf l"><p class="bd b dl z fp mc fr fs md fu fw dk translated">medium.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml ky lx"/></div></div></a></div><p id="8a5e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">欢迎回到我的图形神经网络系列！在之前的文章<a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-graph-convolution-network-aadd77e91606">中，我们研究了图论、卷积神经网络的理论和数学基础</a>。今天我们将讨论Kipf对GCN的PyTorch实现，试图简化实现，并将GCN应用于Twitter仇恨/正常用户数据集。享受:)</p><h1 id="82b9" class="mm mn it bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">将GCN理论翻译成PyTorch</h1><h2 id="6d66" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">传承PyTorch nn。组件</h2><p id="cbf6" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">在PyTorch中常见的做法是制作一个定制模块来创建一个模型，使用<code class="fe ob oc od oe b">torch.nn.Module</code>这就创建了一个Python对象，从而允许创建复杂的模块。定制模块是类，它是包<code class="fe ob oc od oe b">torch.nn.Module</code>的子包，继承了所有的方法和属性:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图1:使用torch.nn定义一个定制模块，新定义的模块继承了所有的nn。模块属性和方法，并可以很容易地适应实现自定义模型。</p></figure><p id="c321" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe ob oc od oe b">class MyNetwork(nn.Module)</code>定义了子类，然后，类似于<code class="fe ob oc od oe b">nn.Module</code>，它希望用输入和输出网络大小(分别是<code class="fe ob oc od oe b">in_size</code>和<code class="fe ob oc od oe b">output_size</code>)来定义构造函数。在构造函数中，调用超级构造函数<code class="fe ob oc od oe b">super()</code>。这允许从对象<code class="fe ob oc od oe b">MyNetwork</code>内的包<code class="fe ob oc od oe b">torch.nn.Module</code>创建对象，而不需要显式初始化它。然后，可以设置网络层和<code class="fe ob oc od oe b">forward</code>步骤，这也是从<code class="fe ob oc od oe b">nn.Module</code>继承而来的。</p><h2 id="04ec" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">应用神经网络。基本GCN操作模块:layers.py</h2><p id="a056" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">同样的方案之后是Kipf在<code class="fe ob oc od oe b">layers.py</code>:<a class="ae le" href="https://github.com/tkipf/pygcn/blob/master/pygcn/layers.py" rel="noopener ugc nofollow" target="_blank">https://github.com/tkipf/pygcn/blob/master/pygcn/layers.py</a>中实现GCN逻辑。图2显示实现了GCN的基本层功能，它是邻接图矩阵与输入图特征数组和第I层权重的乘积:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2:作为torch.nn.Module实现的GCN的基本操作。这里，Kipf定义了GCN步骤，这是一个简单的基于拉普拉斯的矩阵乘法。权重和偏差被均匀采样，前一步执行所需的乘法。</p></figure><p id="3f68" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">权重和偏差参数被定义为<code class="fe ob oc od oe b">torch.nn.parameter</code>对象，通过从均匀分布中随机取样产生。<code class="fe ob oc od oe b">forward</code>步骤更新了前一篇文章的<a class="ae le" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-graph-convolution-network-aadd77e91606#8c18">等式10中的层权重计算。</a></p><h2 id="e8d0" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">堆叠图层:models.py中的GCN模型</h2><p id="8d9e" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">既然我们已经实现了基本的构建模块，我们就可以继续实现GCN模型了。根据Kipf的论文，GCN由两层组成，一个输入层，一个隐藏层，它们通过ReLu激活来组合。此外，我们可以有一个丢弃层，其中输入训练数据的一部分被丢弃，以进一步加强层预测。最终输出为softmax的对数，等式。一</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e6fd93f441c7dcf4394c97747987866e.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*hs0mJH8SewOjeXIQ0A7YGw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式1:对数softmax函数。首先，对第I个输入执行softmax，然后计算log。</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图3:GCN模型的实现。该模型由两层组成，一个输入层，一个隐藏层和一个可能的下降步骤。</p></figure><h2 id="0c19" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">准备输入数据</h2><p id="f420" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">一旦基本模型已经建立，我们可以看看输入数据。Kipf提供了来自Cora数据集(<a class="ae le" href="https://paperswithcode.com/dataset/cora" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/dataset/cora</a>)的数据；<br/> CC0:公共领域)[1，4]。Cora数据集由机器学习论文组成，分为7类:<code class="fe ob oc od oe b">case_based</code>、<code class="fe ob oc od oe b">genetic_algorithms</code>、<code class="fe ob oc od oe b">neural_networks</code>、<code class="fe ob oc od oe b">probabilistic_methods</code>、<code class="fe ob oc od oe b">reinforcement_learning</code>、<code class="fe ob oc od oe b">rule_learning</code>、<code class="fe ob oc od oe b">theory</code>。论文总数为2708，这将是节点数。去除词干和停用词后，最终数据集只有1433个唯一词，这将是要素的数量。因此，该图可以用一个2708 x 1433的矩阵来表示，1和0取决于特定单词的存在。从论文引用文件可以获得边列表，并从那里创建一个2708 x 2708邻接矩阵。<a class="ae le" href="https://github.com/tkipf/pygcn/blob/master/pygcn/utils.py" rel="noopener ugc nofollow" target="_blank">数据通过实用程序脚本</a> <code class="fe ob oc od oe b"><a class="ae le" href="https://github.com/tkipf/pygcn/blob/master/pygcn/utils.py" rel="noopener ugc nofollow" target="_blank">utils.py</a></code>创建。一旦创建了这些元素，就可以继续进行培训步骤。</p><h2 id="fc0b" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">用Cora数据集训练GCN模型</h2><p id="f59b" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">图4总结了所有的GCN步骤。加载数据，以创建特征矩阵<code class="fe ob oc od oe b">X</code>和邻接矩阵<code class="fe ob oc od oe b">adj</code>。这些元素可以被GCN模型摄取，该模型通过拉普拉斯乘法来转换数据，返回每个节点的7个类的概率。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/cdb15a126689a48a4ffc75e230849069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3YfFUu6p8852DvVJ2VUSQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图Kipf代码概述。对初始Cora数据集进行处理，以获得特征矩阵X和邻接矩阵adj。这些元素可在GCN模型中直接用于计算每个结点的输出类。</p></figure><p id="c41d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">图5显示了用于训练GCN模型的Kipf代码的摘录。核心位是火车功能。这里，最初通过<code class="fe ob oc od oe b">optimiser.zero_grad()</code>将梯度设置为零。然后，模型的输出被计算为<code class="fe ob oc od oe b">output = model(features, adj)</code>。最后，运行模型性能检查和损失，计算负对数似然性和准确性，负对数似然性更新网络权重，准确性评估模型相对于评估数据集的良好性。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图5:GCN模型的训练程序。函数串是调用模型的核心位，权重通过负对数似然更新，并通过计算准确度分数来执行评估。</p></figure><h1 id="2e06" class="mm mn it bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">玩GCN，预测推特上可恶的用户</h1><p id="1730" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">现在是时候玩一个奇特的数据集和GCN了。<a class="ae le" href="https://www.kaggle.com/manoelribeiro/hateful-users-on-twitter" rel="noopener ugc nofollow" target="_blank">数据集是Twitter可恶的用户</a>【2】(CC0:公共领域许可证)在其论文中有描述【2】。该数据集拥有100，000名用户。5，000名用户被贴上了仇恨的标签，也就是说，他们在Twitter上发布仇恨帖子。每个用户都有一组定义好的和人工设计的特征<code class="fe ob oc od oe b">users_neightborhood_anon.csv</code>，其中推文已经通过手套嵌入进行编码【3】。其目的是利用网络信息来预测哪些用户也可能是可恨的。这个例子是自由地受这个教程的启发:<a class="ae le" href="https://stellargraph.readthedocs.io/en/v1.0.0rc1/demos/interpretability/gcn/hateful-twitters-interpretability.html" rel="noopener ugc nofollow" target="_blank">https://stellar graph . readthedocs . io/en/v 1 . 0 . 0 rc1/demos/interpretatibility/gcn/evidence-twitters-interpretatibility . html</a></p><h2 id="e682" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">下载数据和预处理</h2><p id="7618" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">首先，我们需要下载数据并解压文件。在本例中，我们将通过Google Colab笔记本使用Kaggle APIs:</p><pre class="kp kq kr ks gt oj oe ok ol aw om bi"><span id="dbf2" class="nk mn it oe b gy on oo l op oq">!pip install kaggle --upgrade<br/># download from your kaggle account the token file kaggle.json<br/>!mkdir /root/.kaggle <br/>!cp kaggle.json /root/.kaggle/. <br/>!mkdir dataset <br/>!kaggle datasets download -d manoelribeiro/hateful-users-on-twitter -p dataset/<br/># unzip the files <br/>!unzip dataset/*.zip</span></pre><p id="aa90" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个例子需要的文件是<code class="fe ob oc od oe b">users_neighborhood_anon.csv</code>和来自<code class="fe ob oc od oe b">users.edges</code>的边缘列表</p><p id="8804" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">节点的特征是人工设计的，然而，图形神经网络的优点在于它们可以去除这些特征，因为它们能够检索网络信息，这对于正确的分类是至关重要的。为此，我们将清理输入数据集，并将要素的大小从1039缩小到206:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图6:读取输入节点的特征并清理它们，以便将维数减少到206。</p></figure><p id="a853" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从这里，我们可以开始准备一个数据集，用于GCN预测。首先，我们选择所有被标记为<code class="fe ob oc od oe b">normal</code>和<code class="fe ob oc od oe b">hate</code>的用户(总共4971个)。然后，可以读取边并选择带有已过滤节点索引的子图，最后，我们可以创建邻接表。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图7:只选择标签不是2的用户，正常用户和讨厌用户，从他们的索引中提取相关的边子图。然后，使用networkx创建邻接矩阵，并使用scipy将其转换为稀疏矩阵</p></figure><p id="7196" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">邻接矩阵是一种稀疏类型，通过<code class="fe ob oc od oe b">scipy.sparse.coo_martrix</code>创建，正如我们在Kipf代码中看到的。</p><p id="0b66" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后一步是为GCN摄取准备邻接和特征矩阵。在这种情况下，我们将对要素的值进行归一化，因为相邻要素已经进行了归一化，我们将为训练(0–1000)、评估(1000–1200)和测试(1200–1400)定义一些样本索引。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图8:归一化节点特征矩阵，定义训练、评估和测试的指标。</p></figure><h2 id="1894" class="nk mn it bd mo nl nm dn ms nn no dp mw kb np nq na kf nr ns ne kj nt nu ni nv bi translated">在推特上训练GCN可恶的数据集</h2><p id="20f6" class="pw-post-body-paragraph jq jr it js b jt nw jv jw jx nx jz ka kb ny kd ke kf nz kh ki kj oa kl km kn im bi translated">最后一步完全遵循Kipf的代码。我们称之为GCN模型和亚当优化器。从那里开始，我们运行一系列的训练程序，然后我们将测量精确度。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="of og l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图9:根据节点的特征形状准备输入尺寸的GCN模型，设置隐藏层尺寸和优化器参数。然后，运行一组定义的时期</p></figure><p id="68b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，我们定义的隐藏层大小为16，但可以随意修改，输出类的数量为2 ( <code class="fe ob oc od oe b">normal</code>或<code class="fe ob oc od oe b">hate</code>)。我们可以收集各个时期的损失和准确度，并看到在50个时期后有一个收敛，而评估集的准确度达到0.89。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi or"><img src="../Images/fdf9cbbce76e85c2fd2f067d94fc3087.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CCEbiL0Oya6Gdr35_gVSlQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图10:训练和评估Twitter数据集的负对数似然损失。两个数据集通过大约0.34(训练)和0.65(评估)的损失收敛。进一步的时代将会加强趋同</p></figure><p id="f965" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这只是GCN美丽的一个小小的例子。你可以带着这些作业进一步练习和探索GCN的力量:</p><ul class=""><li id="15d5" class="lf lg it js b jt ju jx jy kb lh kf li kj lj kn lk ll lm ln bi translated">修改输入数据集大小</li><li id="4d47" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">从输入数据集中提取更多要素</li><li id="1d4d" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn lk ll lm ln bi translated">从第二层提取信息，用分解算法作图，看网络在训练时如何分裂网络。</li></ul><p id="c0c2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">今天它是一切:)请继续关注下一个图表冒险！</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="ac96" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果有任何问题或意见，请随时给我发电子邮件，地址是:stefanobosisio1@gmail.com，或者直接在Medium这里。</p><h1 id="e505" class="mm mn it bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">文献学</h1><ol class=""><li id="dadc" class="lf lg it js b jt nw jx nx kb oz kf pa kj pb kn pc ll lm ln bi translated">网络数据中的集体分类。<em class="lt">艾杂志</em>29.3(2008):93–93。</li><li id="22bd" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn pc ll lm ln bi translated">《推特上仇恨用户的描述和检测》第十二届AAAI国际网络和社交媒体会议。2018.</li><li id="2ec3" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn pc ll lm ln bi translated">彭宁顿、杰弗里、理查德·索彻和克里斯托弗·d·曼宁。"手套:单词表示的全局向量."<em class="lt">2014年自然语言处理经验方法会议论文集</em>。2014.</li><li id="38b9" class="lf lg it js b jt lo jx lp kb lq kf lr kj ls kn pc ll lm ln bi translated">《用机器学习自动化互联网门户的构建》<em class="lt">信息检索</em>3.2(2000):127–163。</li></ol></div></div>    
</body>
</html>