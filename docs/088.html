<html>
<head>
<title>How to Explain Decision Trees’ Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解释决策树的预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-explain-decision-trees-predictions-7a10834fe54d#2022-01-04">https://towardsdatascience.com/how-to-explain-decision-trees-predictions-7a10834fe54d#2022-01-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="52a4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""><h1 id="c920" class="pw-post-title jb jc it bd jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy bi translated">如何解释决策树的预测</h1></div><div class=""><h2 id="6925" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">我们开发了一种方法来解释为什么一个学习过的树模型为一个给定的样本选择一个特定的类，提供了Python中的例子</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/bbfe5d216d5f5f8074eda903e654ede2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HK3JpXnp4PuQ2iM6fL8z6g.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从鸢尾数据集学习的决策树模型，其中花朵被分为三种不同的鸢尾属物种:Setosa、Versicolor和Virginica。下面的“可视化学习模型”中解释了这个情节。</p></figure><p id="4146" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">随着机器学习模型在不同的用例中变得越来越流行，例如信用风险评估系统、诊断系统甚至节能应用；解释模型决策(或预测)的需要变得更加重要。如果拒绝向客户提供信贷，银行需要向客户解释拒绝信贷的原因；如果患者被诊断患有任何疾病，需要提供该诊断的理由；最后，如果节能应用程序关闭了某个房间的供暖，房主可能想知道为什么会发生这种情况。</p><p id="2893" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一些模型的预测自然比其他模型更容易解释。一方面，神经网络可能在自然语言处理和计算机视觉等几项任务中表现出色，但为了做到这一点，必须训练数百万甚至数十亿个参数，这使得解释模型的输出成为一项非常困难的任务。另一方面，线性回归或决策树等简单模型更容易理解，因此它们的预测也更容易解释。正因为如此，在许多现代系统中，这些模型仍在使用。</p><p id="e5fd" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在本文中，我们将关注决策树，以及如何解释用于分类的(经过训练的)决策树模型的输出。在接下来的部分中，我们将快速解释决策树是如何工作的，然后我们将看到如何根据导致给定输出的决策路径来解释决策树模型生成的预测。</p><h2 id="dda1" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">决策树</h2><p id="ab9f" class="pw-post-body-paragraph lh li it lj b lk mv kd lm ln mw kg lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">决策树的目标是通过学习从数据特征(X)推断的简单决策规则来学习预测目标变量的值(我们的Y值或类)的模型。这里的关键是，我们的模型可以被视为一个流程图，其中每个节点代表非叶节点的一个条件或叶节点的一个标签。</p><p id="5cd7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以很容易地使用scikit-learn训练一个决策树，如下所示。在这个例子中，我们将使用<a class="ae na" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a> —一个众所周知的(无聊的)数据集，通常用作ML的玩具示例。我们将把我们的方法应用于这个数据集，但是您可以很容易地修改代码，以应用于您选择的任何其他数据集。下面，我们首先进行必要的导入，然后加载iris数据集，并进行train_test分割，以创建一个训练集和一个测试集。然后，我们使用训练集训练决策树分类器，将叶节点的最大数量设置为3，以提高学习模型的可解释性。这降低了我们模型的准确性，如果我们打印分数，我们会看到模型获得0.964的分数，而如果我们在没有“max_leaf_nodes”参数的情况下训练决策树，学习后的模型将获得1.0的分数(满分)——<em class="nb">哦，我们为提高模型的可解释性所做的牺牲</em>！尽管如此，0.964是一个不错的分数，所以让我们继续下去。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h2 id="b18d" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">可视化学习到的模型</h2><p id="ef2f" class="pw-post-body-paragraph lh li it lj b lk mv kd lm ln mw kg lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">我们现在可以使用scikit-learn中的一种简便方法来绘制我们学习到的模型。我们将首先导入matplotlib，然后从scikit-learn导入名为“plot_tree”的方法。当我们调用该方法时，我们将学习到的模型作为参数发送，然后使用Iris数据集数据设置feature_names和class_names参数。这将把这些数据添加到图中，使它更容易理解。我们可以在下面看到代码和结果。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ne"><img src="../Images/bc17b266fc21d33bda102fc608dda270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qMICbEiIUggCwUTUen6ZA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">为我们学习的决策树模型调用plot_tree()的结果[图片由作者提供]。</p></figure><p id="8d89" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以看到，不同的框按级别组织，箭头显示数据点可以遵循的路径。我们从根开始——最上面的盒子。每个框的第一行显示在该树节点中评估的条件；如果对数据点的条件的评估为真，则遵循左边的路径，否则，我们遵循右边的路径。如果一个框不包含条件，这意味着我们已经到达了一个叶子，该叶子将用框的最后一行中所示的类标签来标记数据点。</p><p id="ba87" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在每个节点中，我们还可以在“样本”中看到到达该节点的数据点的数量，在“值”中，我们可以看到这些样本与其类别标签相关的分布，其中每个第I个元素代表第I个类别标签的数据点的数量。此外，每个方框还显示了<a class="ae na" href="https://medium.com/analytics-steps/understanding-the-gini-index-and-information-gain-in-decision-trees-ab4720518ba8" rel="noopener">基尼指数</a>:节点中“杂质”的一种度量。</p><h2 id="d2e7" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">解释决策树的每个预测</h2><p id="b580" class="pw-post-body-paragraph lh li it lj b lk mv kd lm ln mw kg lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">我们现在可以手动回答问题“为什么这个数据点被标记为X？”通过查看数据点特征，然后沿着该数据点在学习模型中经过的路径。然而，我们可能仍然想要产生一个解释这个路径的自动文本，所以让我们这样做。</p><p id="f995" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我在“<a class="ae na" href="https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html" rel="noopener ugc nofollow" target="_blank">了解决策树结构</a>中采用并修改了Scikit-learn提供的代码，这样我们就可以打印出决策树中给定样本所遵循的路径。我们可以在下面的例子中看到代码及其输出。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="ks kt ku kv gt nf ng nh ni aw nj bi"><span id="d669" class="md me it ng b gy nk nl l nm nn">Rules used to predict sample 0:<br/>node 0, feature: petal width (cm), (actual value) 2.4 &gt; 0.800000011920929 (threshold)<br/>node 2, feature: petal length (cm), (actual value) 5.1 &gt; 4.950000047683716 (threshold)<br/>leaf reached, label: virginica</span></pre><p id="e3e7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">首先，我们声明一些数组，对于给定的样本，我们需要遍历决策树。这些数组中的每一个都有注释，但是如果您仍然不确定其中任何一个的含义，您可以查看scikit-learn文章以获得更详细的解释。其次，我们声明样本id(由它在X_test数组中的位置给出)并获得样本的决策路径。</p><p id="0d92" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们迭代路径中包含的所有节点:对于分裂节点(或非叶节点)，我们打印节点的编号、条件中使用的特征、给定样本的该特征的值以及阈值，显示样本的值是大于“&gt;”还是小于或等于“= </p><p id="8151" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">In the output we see a (somewhat rustic) explanation of why our model has predicted a certain label for the given sample: the petal width is greater than 0.8 and the petal length is greater than 4.95, which our tree model has learned to classify as virginica based on the samples included in the train set. If we check the tree plot, we see that a vast majority of the train samples that meet these conditions are indeed virginica, which explains the label predicted by our model.</p><h2 id="b015" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">Conclusion</h2><p id="7220" class="pw-post-body-paragraph lh li it lj b lk mv kd lm ln mw kg lp lq mx ls lt lu my lw lx ly mz ma mb mc im bi translated">We have managed to provide a rustic explanation to a decision trees’ predictions. With this, we aim to improve the trust in our model because any person can now see why a sample was given a certain label or class by our model. We have to keep in mind that we need to use decision trees for this approach to work, which can condemn the performance of our model. In a future article, we will see how we can use other tools such as Shapley values to explain other models different than decision trees.</p><h2 id="6e79" class="md me it bd mf mg mh dn mi mj mk dp ml lq mm mn mo lu mp mq mr ly ms mt mu iz bi translated">Where to go from here</h2><ul class=""><li id="32e3" class="no np it lj b lk mv ln mw lq nq lu nr ly ns mc nt nu nv nw bi translated"><a class="ae na" href="https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py" rel="noopener ugc nofollow" target="_blank">”。了解决策树结构— Scikit-learn </a>。<br/>如果你想更深入地了解scikit-learn决策树，你可以阅读这篇非常有趣的文章。</li><li id="0502" class="no np it lj b lk nx ln ny lq nz lu oa ly ob mc nt nu nv nw bi translated">如果你对可解释的ML(或可解释的AI)感兴趣，你可能会对这本书感兴趣，这本书以实用的方式解释了如何使用Python实现可解释的模型。</li></ul></div></div>    
</body>
</html>