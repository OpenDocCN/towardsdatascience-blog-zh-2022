# 问题旋转——处理无法完成的人工智能任务

> 原文：<https://towardsdatascience.com/question-pivoting-handling-unachievable-ai-tasks-6e715cb12026>

## 无法训练监督模型时要考虑的 3 个支点

![](img/0877d36039e27d9e8c84cd37320aea5f.png)

照片由[像素](https://www.pexels.com/photo/jumping-cute-playing-animals-4602/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)的[地形](https://www.pexels.com/@gratisography?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels)拍摄

T 他的是一个普通的剧本；数据科学团队被要求生成一个应该非常简单的洞察，但由于缺乏数据等原因，这是不可行的。一个常见的例子是请求预测客户的状态(对产品满意吗？愿意推荐 VS 策划[流失](https://blog.hubspot.com/service/what-is-customer-churn)等..)却发现不存在任何相关的标记数据(如客户反馈记录或客户流失请求)。下一步做什么？最简单的解决方案是推迟请求，直到收集到足够的数据。但是通常我们会建议一个折中的解决方案。这种开箱即用的选项将是采用 [**问题中枢**](https://knowledge.wharton.upenn.edu/article/pivot-entrepreneurship/)**——通过回答不同的问题来处理完全相同的需求。正如我们将看到的，有三个主要可能的支点**可供选择——直接**、**间接**和**手动直接**。每一个都有自己的优点和缺点，这将由你来决定哪一个最适合你的需要。******

# **直接问题支点**

最直观的选择。鉴于标记数据稀缺，尝试在不依赖标记数据的情况下满足需求；使用[非监督](https://en.wikipedia.org/wiki/Unsupervised_learning)方法，而不是我们首先想到的[监督](https://en.wikipedia.org/wiki/Supervised_learning)分类器(需要标记数据进行训练)。一种常见的无监督算法选择是[聚类](https://en.wikipedia.org/wiki/Cluster_analysis)；使用现有的(未标记的)指标生成客户聚类，并根据生成的聚类平面得出结论。唯一的问题是，给定这样的聚类，如何识别其中满意度较低的客户？一种选择是通过使用 [**异常检测**](https://en.wikipedia.org/wiki/Anomaly_detection)；搜索簇外/奇怪的簇，假设它指示值得观察的客户。另一种选择是**部分贴标签**；给定几个已知对产品不满意的客户，查看他们的集群邻居，假设低距离表示类似状态(也不满意)。上述方法的主要问题是假设**生成的集群结构与客户满意度**有关。但是聚类平面上的低距离取决于我们用来生成聚类的指标，因此这可能是由于其他原因，例如类似的使用模式。更普遍的问题是**如何衡量我们的 pivot 成功**？虽然有多种方法可以评估集群的好坏(如[集群内平方和](https://en.wikipedia.org/wiki/K-means_clustering))，但没有人能保证现成的集群会通过将具有相似满意度的客户放在一起而直接满足我们的需求。这是直接枢纽方法的固有问题，即非监督方法不能直接满足监督模型的需求(否则，我们可以省去监督方法对标记数据的需求，而只是通过使用非监督方法来依赖数据)。另一个问题是，在有监督的情况下衡量无监督任务的成功可能会很棘手。一种可能的解决方案是采用其他支点——间接支点；使用监督方法，但将问题重新表述为存在标记数据的问题。

# **间接疑问句枢纽**

假设我们没有标记数据来为我们的问题(客户的状态是什么)训练分类模型，并且假设直接透视(使用非监督方法)效果不好，直观的下一个透视将是相反的方向；继续使用监督方法，但要找到其他有足够标签数据的相关问题来训练它。以我们的例子为例，大多数公司拥有的一个常见的客户数据是操作日志；就像在使用外部任务管理系统时，比如吉拉的 T1 或 T2 的 Zendesk 的 T3，我们可以导出他们的任务执行日志，使我们能够找到我们想要的数据。使用它，我们可以将“我们的客户状态是什么”问题替换为“客户的请求会按时得到解决吗”这样的问题。这样一个问题支点是有意义的，假设客户的哪些请求被及时解决会更满意。现在，我们可以生成一个监督分类模型，并轻松测试它以验证成功。问题是相关性水平；假设我们预测客户请求不会按时解决，并且假设使用我们的帮助，支持团队将设法按时处理它，这与客户状态有什么关系？此外，一个满意的客户可能根本没有任何支持请求。固有的问题是假设可以从一个分类问题到另一个分类问题进行明显的简化(正如我们刚刚看到的，情况并不总是如此)。这就是为什么最终许多案例会以中间支点方法结束——保留目标分类问题(在我们的示例中为“客户状态是什么”),但找到一种中间方法来为其收集标记数据；手动直接旋转。

# **手动直接提问枢纽**

到目前为止，我们一直试图改变我们使用的方法(无人监督而不是有人监督)和我们回答的问题(其他有人监督的任务而不是我们被要求的任务)。两者都缺乏与感兴趣的原始任务的直接联系。直观的最终支点将是尝试回答原始需求，同时找到一种方法来生成中间标记数据以对其进行训练(直到收集到足够多的所需标记数据)。在我们的示例中，我们可以通过查看我们拥有的部分数据，使用启发式方法来估计客户的状态(所需的标签);衡量影响 it 的关键指标，如使用水平、停机次数或整体服务体验。生成定期客户满意度得分。挑战在于使其成为一个可靠的衡量标准。例如，停机时间与客户满意度有什么关系？对于面向应用程序的客户来说，这可能非常重要，但对于监控等后台应用程序来说，停机时间就不那么引人注目了(客户通常只在设置阶段进入应用程序，很可能根本不会意识到停机)。问题是我们试图生成一个固执己见的 KPI(客户满意度得分)来反映一个绝对的 KPI(客户状态)。虽然乍看起来微不足道，但在许多情况下，它最终会变得非常复杂(否则我们可以使用生成的试探法，而不是所需的分类模型)。依赖过于天真的启发式方法的风险可能会很高。那么选择什么支点呢？。

# **没有神奇的答案(除了透明)**

底线结论是，选择正确的支点并不是一个简单的决定。这里没有神奇的解决办法。从我的经验来看，每个支点选项**总是有好有坏**，这取决于我们所拥有的独特条件，以便决定我们应该接受哪一个。同时值得注意的是，这些案例的共同点是需要**的透明度**；尽早向客户清楚地反映我们的状态(有哪些选项、成本和价值)，使我们能够更好地进行规划，然后选择最适合我们的解决方案。在某些情况下，结论是根本不要转向(而是[加速标记过程](/how-to-utilise-a-manual-labelling-workforce-b30db3ab1e8e)，或者[优先处理其他任务](/pivoting-ml-apps-to-success-9bfcb032e0c6)，因为数据丢失)。让相关各方充分理解状态是正确选择如何(中间)调整手头问题所需的秘方。使我们能够专注于我们能回答的问题。