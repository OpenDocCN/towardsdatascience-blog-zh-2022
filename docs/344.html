<html>
<head>
<title>LM!=KM: The Five Reasons Why Language Models Fall Short of Supporting Knowledge Model Requirements of Next-Gen AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LM！=KM:语言模型无法支持下一代人工智能知识模型需求的五个原因</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lm-km-3e81e1e1c3ae#2022-01-12">https://towardsdatascience.com/lm-km-3e81e1e1c3ae#2022-01-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ca61" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/notes-from-industry" rel="noopener" target="_blank">行业笔记</a></h2><div class=""><h1 id="8737" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated"><strong class="ak"> LM！=KM:语言模型无法支持下一代人工智能知识模型需求的五大原因</strong></h1></div><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/4bb54d07bd95d4974beb64dfd5847c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUgoCAvFMatPAKWT5yUcnA.jpeg"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图片来源:<a class="ae kl" href="https://stock.adobe.com/contributor/207461122/coredesign" rel="noopener ugc nofollow" target="_blank"> CoreDESIGN </a>通过Adobe Stock。</p></figure><p id="26d5" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">大型语言模型(LMs)已经证明它们可以作为相对较好的知识模型(KMs)。但是，它们是否擅长执行实现真正智能的认知人工智能系统所需的所有功能？我认为，答案是否定的。这篇文章将讨论构成高级知识管理的五种能力，以及这些领域如何不能被目前形式的LMs轻易解决。这些能力是可扩展性、保真性、适应性、丰富性和可解释性。</strong></p><p id="adc6" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下一波人工智能将转向更高的认知功能，如常识推理、抽象洞察、新技能的获取以及复杂信息的新颖使用。丰富的、结构深刻的、多样的、不断发展的知识将是基础。允许人工智能系统组织其世界观、理解意义并展示对事件和任务的理解的知识结构将可能处于更高水平的机器智能的中心。因此，了解所需的高级知识模型(KM)特征并评估当代完全封装的端到端生成语言模型(LMs)对于满足这些要求的适用性是有价值的。</p><p id="d590" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">像GPT-3和T5这样的LMs作为潜在的知识来源，在研究人员中越来越受欢迎，经常获得相当大的成功。例如，叶筋·崔的团队开创了像<a class="ae kl" href="https://arxiv.org/abs/2110.08387" rel="noopener ugc nofollow" target="_blank">生成知识提示</a>和<a class="ae kl" href="https://arxiv.org/abs/2110.07178" rel="noopener ugc nofollow" target="_blank">象征性知识蒸馏</a>这样的方法，通过查询像GPT-3这样的大型LM成功地提取了高质量的常识关系。显然，这种方法可以带来价值，因为它们允许自动创建数据库，而无需模式工程、预设关系或人工监督。</p><p id="6ea0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">人们很希望LMs能够逐步发展，以提供从<a class="ae kl" href="https://en.wikipedia.org/wiki/Knowledge_base" rel="noopener ugc nofollow" target="_blank">知识库</a>获得的全部能力。然而，尽管它们有许多优点和有价值的用途，LMs有几个结构上的限制，使它们更难成为一个优秀的、功能更多的知识库和知识接口。例如，在开放领域问答这样的基准测试中可以看到，基于检索器的方法<a class="ae kl" href="https://arxiv.org/abs/2007.01282" rel="noopener ugc nofollow" target="_blank">明显优于</a>生成式LMs。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lk"><img src="../Images/b25808e93c663b7ca651302ab70150cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PNoaIzdSteVVzELwkJBLqQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图一。对于开放领域问题回答，基于检索器的方法优于生成式LMs。数据来源:<a class="ae kl" href="https://arxiv.org/abs/2007.01282" rel="noopener ugc nofollow" target="_blank">【3】</a>。图片鸣谢:加迪·辛格。</p></figure><p id="9dab" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">应当注意，LMs被设计成执行下一个单词预测，而不是为了存储知识的特定目的。因此，即使他们在某些情况下可能做得很好，<a class="ae kl" href="https://arxiv.org/abs/2104.10809" rel="noopener ugc nofollow" target="_blank">他们的架构不是表现知识的最佳方式</a>，是<a class="ae kl" href="https://baicsworkshop.github.io/pdf/BAICS_22.pdf" rel="noopener ugc nofollow" target="_blank">不同于人类记忆</a>，并且他们的表现对于知识相关的任务来说不是流线型的。</p><p id="cc2e" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了更好地理解这些缺点，考虑一下一个先进的知识管理能够做些什么。我提出了五种主要能力:可伸缩性、保真性、适应性、丰富性和可解释性。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi lk"><img src="../Images/18d8346b188f4556ce9ad23cd2447028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nafcZPa0BZN-V8A51C_Yw.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图二。先进知识管理的五个特征。图片鸣谢:加迪·辛格。</p></figure><p id="a5d7" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们更详细地看一下它们。</p><h1 id="ad1c" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">可扩展性</strong></h1><p id="a785" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">显然，世界上有大量的信息。大型LMs在其容量允许的情况下在参数存储器中存储尽可能多的相关信息，并以训练效率为代价提供快速访问。这种模型通常需要非常大的数据语料库和大量的时间投资来实现性能改进，因此在部署后它们可以访问的信息范围有限。基于检索的方法(例如图1中引用的方法)扩展了可靠可访问信息的范围，远远超出了LM中编码的内容。2021年12月，作为<a class="ae kl" href="https://arxiv.org/abs/2112.04426" rel="noopener ugc nofollow" target="_blank"> DeepMind的复古</a>的一部分，进一步展示了检索适应规模的基本价值。通过<a class="ae kl" href="http://jalammar.github.io/illustrated-retrieval-transformer/" rel="noopener ugc nofollow" target="_blank">在语言技能(嵌入在模型中)和从具有万亿级表征的数据库中检索的外部知识之间建立分离</a>，他们证明了与280B参数Gopher和178B参数Jurrasic-1相比，其7B参数RETRO的结果有了实质性的改善。</p><p id="b2df" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，检索系统可能缺乏在综合知识的帮助下可以实现的细微差别。一般来说，设计为高速访问相关信息而优化的系统会在规模和便利性之间产生固有的矛盾，未来的系统预计会具有复杂的分层访问架构。正如博客<a class="ae kl" rel="noopener" target="_blank" href="/no-one-rung-to-rule-them-all-208a178df594">“没有人能统治所有人”</a>中所详述的，经济高效的信息访问需要分层的架构，这意味着知识管理必须包括处理每一层的专门模块。</p><p id="9cae" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">例如，我们可能想要区分每十次访问的数据项和每十万亿次只需要访问的数据项。在计算机系统中提供访问层次结构，可以根据数据需要访问的频率来分离数据，并为每个频率层设计不同的硬件架构(想想高速缓存寄存器与计算机中的硬盘驱动器)。</p><p id="2ffd" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">最常使用的知识(或需要最方便的知识)也应该是最容易访问的，这需要更昂贵的体系结构，并限制了该层的最大经济可行容量。例如，随着计算机架构中存储容量的增加，系统必须牺牲一些访问速度(图3)。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi ms"><img src="../Images/83e613a4de38f6c3dd20383cf5c6d4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_UJWQAPABjmHRsPW8ze5dQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图3。规模与速度层级。图片鸣谢:加迪·辛格。</p></figure><p id="3e15" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一个理想的知识管理必须是可扩展的，并且包括人类文明积累的全部智慧(达到人工智能执行和进化可能需要的程度)。该系统还必须能够快速执行最关键和时间敏感的任务，并且可能需要一个如上所述的分层体系结构。虽然LMs可以通过对大型语料库的训练来获取关于世界的知识，但它们没有以优化方式存储知识的特定架构。</p><h1 id="d7be" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">保真度</strong></h1><p id="14c4" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">一个知识管理必须具有高度的保真度，也就是说，它必须允许事实、属性和关系的再现，这些事实、属性和关系是它们的起源所固有的，并且不依赖于它们发生的统计数据。即使两者之间的置信界限不同，单次观测记录的精度也必须等同于经过良好测试的多次观测理论的精度。高保真度的知识管理不太容易出现<a class="ae kl" href="https://www.pnas.org/content/114/13/3521.short" rel="noopener ugc nofollow" target="_blank">灾难性遗忘</a>或其他类型的信息衰减，并允许针对各种类型的基于训练的偏差进行明确的保护。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mt"><img src="../Images/b6c03d64f69ba5df74feb06e9facb2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sZYu__PJ7Prt5iR2gG-6aQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图4。KMs必须保留允许忠实复制的信息。图片鸣谢:加迪·辛格。</p></figure><p id="55f0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">一般来说，LMs和机器学习(ML)模型在这个维度上有些弱。虽然有许多方法可以缓解这个问题，但没有人期望LM能够摆脱这种偏见。相反，LM必须依赖专门的模块和外部进程。</p><h1 id="c7dd" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">适应性</strong></h1><p id="2b34" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">知识管理必须处理许多数据源、类型和更新速率。一个小办公室的牙医需要处理患者信息，随着患者信息的变化随时更新，并将不同的数据类型与同一患者相关联(文本文件中的诊断、x光图像)。每个患者记录在每次就诊的基础上进行更新。另一方面，金融机构处理完全不同类型的信息，更新速度更快，数据量更大。这种类型的系统实际上取决于它处理新信息的速度，以发现欺诈和错误。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mt"><img src="../Images/d3e2729ba6f08151416bd179471acda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vZDG6kOREb43fGCcCtopIA.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图5。知识管理的适应性。图片来源:加迪·辛格和<a class="ae kl" href="https://scedc.caltech.edu/" rel="noopener ugc nofollow" target="_blank"> SCEDC </a>。</p></figure><p id="1fa9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">今天的LMs，即使它们可能已经在最近的数据上被训练，在局部改变网络以反映孤立数据点的增加或改变方面也不那么有效。任何微调都需要完全或至少实质性的更新，这远远超出了所添加或更改的数据点的范围，并且有破坏存储在同一系统中的无关知识的风险。一个先进的知识管理不能有这种限制。它需要处理具有不同数据类型的各种信息源，并且它必须允许与相关知识的变化速度相匹配的经济和及时的更新。</p><h1 id="9208" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">丰富度</strong></h1><p id="4d4d" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">另一种能力是破译知识的丰富性，这是捕捉通过语言和其他形式表达的知识中所有复杂关系的能力。正如在关于<a class="ae kl" rel="noopener" target="_blank" href="/understanding-of-and-by-deep-knowledge-aac5ede75169">知识维度</a>的文章中所讨论的，知识可以分为知识和元知识。直接知识可以是描述性的，如分类学和本体论，或者财产继承。这种类型的知识可以以许多不同的形式存储:语言、3D点云、声音、图像等。它也可以代表世界的<em class="mu">模型，例如因果、程序或物理模型。最后，它可以包括<em class="mu">故事和剧本</em>，如神话、经历描述、日常仪式等。</em></p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mt"><img src="../Images/8cd05afd60616e68c991bd140febc2fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TdYXy118wkJmeKCEXZdJOw.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图6。多模态知识的维度。图片鸣谢:加迪·辛格。</p></figure><p id="4b0f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">元知识维度和结构包括来源属性、价值和优先顺序以及概念。人类可以根据信息来源的可信度来区分它们。例如，人们不能指望黄色媒体上的普通点击诱饵像《自然科学杂志》上的一篇文章一样可信。</p><p id="10f4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">人类还在他们的价值体系和偏好的背景下评估信息，并将其封装到概念结构中，以便长期存储和推理。虽然LMs反映了这些知识维度的一个子集(例如，GPT-3似乎很清楚典型的笑话脚本)，但它们似乎只代表了知识维度的一个部分子集。很可能需要一个不同的架构来捕捉人类知识的全部丰富性。</p><h1 id="0e94" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">交代</strong></h1><p id="77a4" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">当人工智能与人类互动时，特别是在医疗、金融或执法应用等高风险任务上，它解释其选择和沟通的能力自然变得非常重要。这种可解释性和可解释性在明确的、可理解的知识来源的帮助下更容易实现。显性知识允许一个透明的结构，可以检查，编辑和整合到因果推理或反事实推理模块。它为人工智能和人类用户之间的交流提供了一个更好的基础，在这里信息可以被交换、采纳、吸收和反馈。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi mt"><img src="../Images/4a7b3ce1a6a3c5df111a76d2b5b20c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kkL-5GpJqUS9cuJ7p_RgqQ.png"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">图7。知识管理的可解释性。图片鸣谢:加迪·辛格。</p></figure><h1 id="63c5" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">结论</strong></h1><p id="744b" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">一个端到端的LM，无论多大或多贵，都不能完成一个更先进的KM所要求的所有功能来支持下一代的AI能力。但这表明了什么是可以支持下一代人工智能系统的实际架构？在推理和<a class="ae kl" href="https://arxiv.org/abs/2110.07178" rel="noopener ugc nofollow" target="_blank">知识图的自动扩展</a>等领域已经取得了一些初步进展，在描述知识架构蓝图的三个层次时，我已经<a class="ae kl" rel="noopener" target="_blank" href="/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe#e6a1-20df55d5621c">进行了深入的讨论。</a></p><p id="a643" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">无论未来如何，都需要行业努力开发具有涵盖五种能力的知识管理系统的人工智能系统，以便我们可以实现真正智能的认知人工智能。在未来的博客中，我们将讨论一些在未来人工智能系统中开发这些能力的潜在方法。</p><h1 id="779c" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak">参考文献</strong></h1><p id="1182" class="pw-post-body-paragraph km kn iq ko b kp mn kr ks kt mo kv kw kx mp kz la lb mq ld le lf mr lh li lj ij bi translated">1.刘，刘，a，陆，x，韦勒克，s，西，p，布拉斯，R. L，…和Hajishirzi，H. (2021)。常识推理的生成知识提示。<em class="mu"> arXiv预印本arXiv:2110.08387 </em>。</p><p id="4b66" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.韦斯特，p .，巴加瓦图拉，c .，赫塞尔，j .，黄，J. D .，江，l .，布拉斯，R. L .，…，崔永元(2021)。符号知识提炼:从一般语言模型到常识模型。<em class="mu"> arXiv预印本arXiv:2110.07178 </em>。</p><p id="8ccd" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.伊萨卡和格雷夫(2020年)。利用生成模型的段落检索进行开放领域问答。arXiv预印本arXiv:2007.01282 。</p><p id="232c" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">4.Merrill，w .，Goldberg，y .，Schwartz，r .，&amp; Smith，N. A. (2021)。从非基础形式获取意义的可证明的局限性:未来的语言模型将理解什么？。<em class="mu"> arXiv预印本arXiv:2104.10809 </em>。</p><p id="e820" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">5.Nematzadeh，a .，Ruder，s .，和Yogatama，D. (2020年)。人类和人工语言处理系统中的记忆。在<em class="mu">ICLR关于沟通人工智能和认知科学研讨会的会议录</em>。</p><p id="2ba4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">6.歌手g(2021年12月21日)。没有人能统治所有人:解决基于知识的人工智能中的规模和权宜之计。中等。<a class="ae kl" rel="noopener" target="_blank" href="/no-one-rung-to-rule-them-all-208a178df594">https://towards data science . com/no-one-rung-to-rule-them-all-208 a 178 df 594</a></p><p id="14ac" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">7.Kirkpatrick，j .，Pascanu，r .，Rabinowitz，n .，Veness，j .，Desjardins，g .，鲁苏，A. A .，… &amp; Hadsell，R. (2017)。克服神经网络中的灾难性遗忘。<em class="mu">美国国家科学院院刊</em>，<em class="mu"> 114 </em> (13)，3521–3526。</p><p id="3b24" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">8.歌手g(2021 a，12月19日)。<em class="mu">对深度知识的理解和运用——走向数据科学</em>。中等。<a class="ae kl" rel="noopener" target="_blank" href="/understanding-of-and-by-deep-knowledge-aac5ede75169">https://towards data science . com/understanding-of-and-by-deep-knowledge-aac5 ede 75169</a></p><p id="5ec4" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">9.布兰文，G. (2020年6月19日)。<em class="mu"> GPT-3创作小说</em>。<a class="ae kl" href="https://www.gwern.net/GPT-3#humor" rel="noopener ugc nofollow" target="_blank">https://www.gwern.net/GPT-3#humor</a></p><p id="fb28" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">10.歌手g(2021 b，12月20日)。<em class="mu"> Thrill-K:下一代机器智能蓝图</em>。中等。<a class="ae kl" rel="noopener" target="_blank" href="/thrill-k-a-blueprint-for-the-next-generation-of-machine-intelligence-7ddacddfa0fe#e6a1-20df55d5621c">https://towards data science . com/thrill-k-a-blue print-for-the-next-generation-of-machine-intelligence-7 ddacddfa 0 Fe # e6a 1-20df 55d 5621 c</a></p><p id="61e1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">11.Borgeaud，s .，Mensch，a .，Hoffmann，j .，Cai，t .，Rutherford，e .，Millican，k .，… &amp; Sifre，L. (2021)。通过从数万亿个标记中检索来改进语言模型。<em class="mu"> arXiv预印本arXiv:2112.04426 </em>。</p><p id="cf35" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">12.j . alam mar(2022年1月3日)。<em class="mu">图示检索变压器</em>。<a class="ae kl" href="http://jalammar.github.io/illustrated-retrieval-transformer/" rel="noopener ugc nofollow" target="_blank">http://jalammar . github . io/illustrated-retrieval-transformer/</a></p></div></div>    
</body>
</html>