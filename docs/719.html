<html>
<head>
<title>Run your R (SparklyR) workloads at scale with Spark-on-Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助Spark-on-Kubernetes大规模运行您的R (SparklyR)工作负载</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/run-your-r-sparklyr-workloads-at-scale-with-spark-on-kubernetes-3db4f26d3348#2022-01-25">https://towardsdatascience.com/run-your-r-sparklyr-workloads-at-scale-with-spark-on-kubernetes-3db4f26d3348#2022-01-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="c65b" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">借助Spark-on-Kubernetes大规模运行您的R (SparklyR)工作负载</h1></div><div class=""><h2 id="d647" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">教程:如何建立正确的Docker映像，开始您的Spark会话，并大规模运行！</h2></div><p id="b201" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">r是一种用于统计计算的编程语言。它被统计学家和数据科学家广泛使用。长期以来，在单台机器上运行应用程序已经足够了，但是当需要更多数据和高级分析时，这就成了一个限制因素。</p><p id="c7d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是为什么R社区开发了<a class="ae lb" href="https://spark.rstudio.com/" rel="noopener ugc nofollow" target="_blank"> sparklyr </a>来使用Apache Spark扩展数据工程、数据科学和机器学习。它支持Apache Spark用例:Batch、Streaming、ML和Graph、SQL，此外还有众所周知的R包:dplyr、DBI、broom。更多信息可以在<a class="ae lb" href="https://sparklyr.ai" rel="noopener ugc nofollow" target="_blank"> sparklyr.ai </a>上找到。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/874989d1d1c43d78b694bd569a25bde4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yGDg-Kr9X1bsR1BM.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated"><strong class="bd ls">Spark lyr如何建立在Spark之上</strong>(来源:<a class="ae lb" href="https://sparklyr.ai" rel="noopener ugc nofollow" target="_blank"> sparklyr.ai </a>，根据Apache License 2.0授权商业使用转贴)</p></figure><p id="21be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问题是，Sparklyr和Apache Spark之间的集成很脆弱，很难得到库和环境设置的正确组合。我们的一个客户试图让它在EMR上工作，并将其描述为“一场噩梦”。相反，通过构建他们自己的Docker映像并在我们的Spark-on-Kubernetes平台上运行，他能够使他的SparklyR设置可靠地工作。</p><p id="46c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，让我们看看如何使用Spark-on-Kubernetes让您的SparklyR应用程序大规模运行！本教程的所有代码都可以在这个<a class="ae lb" href="https://github.com/datamechanics/examples/tree/main/sparklyr-example" rel="noopener ugc nofollow" target="_blank"> Github库</a>上获得。</p><h1 id="6d84" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">要求</h1><p id="e027" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">您必须配置Docker映像。这是最困难的部分，但我们为你做到了！下面的dockerhub文件使用了我们发布的一张图片作为基础——参见这篇<a class="ae lb" href="https://www.datamechanics.co/blog-post/optimized-spark-docker-images-now-available" rel="noopener ugc nofollow" target="_blank">博客文章</a>和我们的<a class="ae lb" href="https://hub.docker.com/r/datamechanics/spark" rel="noopener ugc nofollow" target="_blank"> dockerhub </a>资源库，了解关于这些图片的更多细节。‍</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者代码。<a class="ae lb" href="https://github.com/datamechanics/examples/tree/main/sparklyr-example" rel="noopener ugc nofollow" target="_blank">全公开回购</a>。</p></figure><p id="a8f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在RUN install2.r部分调优您的包。<a class="ae lb" href="https://www.tidyverse.org/" rel="noopener ugc nofollow" target="_blank"> Tidyverse </a>包含了很多众所周知的包，比如dplyr，ggplot2。一旦您的映像被构建并在注册表中可用，它就包含了您所有的依赖项，在您运行应用程序时需要几秒钟的时间来加载。</p><h1 id="2fd4" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">开发您的SparklyR应用程序</h1><p id="2085" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">首先，我们将向您展示一些代码示例。您可以在<a class="ae lb" href="https://github.com/sparklyr/sparklyr" rel="noopener ugc nofollow" target="_blank"> sparklyr github repo </a>中找到更多示例。有两个关键话题:</p><ul class=""><li id="1eab" class="ms mt iq kh b ki kj kl km ko mu ks mv kw mw la mx my mz na bi translated">创建Spark会话</li><li id="2087" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">理解R对象是Spark数据帧或R数据集的接口。</li></ul><p id="d86f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有经验的Sparklyr开发者可以查看Spark会话的创建，然后直接切换到<em class="ng">大规模运行Spark应用</em>。</p><h2 id="ee4c" class="nh lu iq bd lv ni nj dn lz nk nl dp md ko nm nn mf ks no np mh kw nq nr mj ns bi translated">创建Spark会话</h2><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者代码。<a class="ae lb" href="https://github.com/datamechanics/examples/tree/main/sparklyr-example" rel="noopener ugc nofollow" target="_blank">全公开回购</a>。</p></figure><h2 id="f64d" class="nh lu iq bd lv ni nj dn lz nk nl dp md ko nm nn mf ks no np mh kw nq nr mj ns bi translated">如何操作你的R对象和火花数据帧</h2><p id="4366" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">没有比阅读代码示例更好的学习方法了(见下文)！以下是需要注意的主要事项:</p><ul class=""><li id="26c6" class="ms mt iq kh b ki kj kl km ko mu ks mv kw mw la mx my mz na bi translated">sparklyr <strong class="kh ir"> copy_to </strong>函数返回对生成的Spark数据帧的引用，作为<strong class="kh ir"> tbl_spark </strong>。返回的对象将作为底层Spark表的dplyr兼容接口(<a class="ae lb" href="https://dplyr.tidyverse.org/reference/copy_to.html" rel="noopener ugc nofollow" target="_blank">见文档</a>)。</li><li id="b62c" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">您可以使用<strong class="kh ir"> spark_apply </strong>将R函数应用于Spark数据帧</li><li id="3e86" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">您可以通过调用<strong class="kh ir"> tbl_cache </strong>(或<strong class="kh ir"> tbl_uncache </strong>)显式缓存(或取消缓存)Spark数据帧</li><li id="e077" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">可以用<a class="ae lb" href="https://www.rstudio.com/blog/sparklyr-r-interface-for-apache-spark/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> dbGetQuery </strong> </a>用SQL查询Spark表</li><li id="3905" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">你可以用<strong class="kh ir"> spark_read_parquet </strong>(或<strong class="kh ir"> spark_write_parquet </strong>)读取(或写入)镶木地板表格</li><li id="2d3c" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">您可以使用<a class="ae lb" href="https://datacarpentry.org/R-ecology-lesson/04-visualization-ggplot2.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> ggplot2 </strong> </a>包绘制您的R对象。</li><li id="ed19" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">不要忘记在应用程序代码结束时用<strong class="kh ir"> spark_disconnect </strong>关闭Spark会话。您仍然可以在这一行之后运行R代码，但是不能使用Spark运行任何分布式命令。</li></ul><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">作者代码。<a class="ae lb" href="https://github.com/datamechanics/examples/tree/main/sparklyr-example" rel="noopener ugc nofollow" target="_blank">完全公开回购</a>。</p></figure><h1 id="234c" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">R‍un你的星火大规模应用</h1><p id="da65" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">您必须首先通过<a class="ae lb" href="https://docs.datamechanics.co/docs/first-application" rel="noopener ugc nofollow" target="_blank">模板或configOverride </a>定义一个数据机制配置。对于开源的Spark-on-Kubernetes用户来说，很容易适应这种配置，特别是如果你使用开源项目<a class="ae lb" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator" rel="noopener ugc nofollow" target="_blank"> Spark-on-Kubernetes操作器</a>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nt"><img src="../Images/4253943ec390c4218d7c726ff8da566d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LPPPu7ftbBzVat2E.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">示例数据机制配置(JSON)。来源:作者。</p></figure><p id="ffb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要执行的‍The代码在文件rexamples中。这就是为什么<strong class="kh ir"> mainApplicationFile </strong>指向Docker映像内部的本地路径。</p><p id="9fdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，您可以使用<a class="ae lb" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank"> Delight </a>来监控和优化您的Spark应用程序，这是一个适用于Spark的开源监控UI，可以在任何Spark平台(商业/开源、云/本地等)上运行。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nu"><img src="../Images/84544770eb28f9d9bdfccfa3697965ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bESEkvuw8znOlAbV.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来自<a class="ae lb" href="https://www.datamechanics.co/delight" rel="noopener ugc nofollow" target="_blank"> Delight </a> UI的截图。来源:作者。</p></figure><p id="6e01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">特别感谢在Data Mechanics平台上运行SparklyR工作负载的客户分享他们的技巧和设置。我们希望本教程能帮助你成功使用Spark和R！</p></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="7bc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ng">最初发表于</em><a class="ae lb" href="https://www.datamechanics.co/blog-post/tutorial-run-your-r-sparklyr-workloads-at-scale-with-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"><em class="ng">【https://www.datamechanics.co】</em></a><em class="ng">。</em></p></div></div>    
</body>
</html>