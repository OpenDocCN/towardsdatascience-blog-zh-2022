<html>
<head>
<title>HyperDriveStep in Data Pipelines</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据管道中的超驱动步骤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hyperdrivestep-in-data-pipelines-fe48a69ec7c7#2022-01-23">https://towardsdatascience.com/hyperdrivestep-in-data-pipelines-fe48a69ec7c7#2022-01-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="2fb4" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">数据管道中的超驱动步骤</h1></div><div class=""><h2 id="a87d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用tqdm和Azure机器学习扩展Python流程。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b24965993c8fac5dfea63ac5ff4e3630.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nR0XoUhGMtGCtRTm"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">托马斯·凯利在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3a21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欠开发和过度工程之间的平衡是如此之弱，以至于工程经常在这两个对立面之间摇摆。在本文中，我将解释几种数据管道扩展技术，我们可以应用这些技术来应对业务需求，并帮助您避免越界。</p><h1 id="fc68" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">方案</h1><p id="75cf" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">你是一名数据科学家，在一家制作商店销售预测的新公司工作。在建立机器学习模型的过程中，需要对输入数据进行预处理。这个数据以这样一种方式建模，即有一个国家的集合，每个国家有许多商店，每个商店需要以自己的方式处理。</p><p id="aa58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下代码显示了处理所有商店的简单方法:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="a113" class="mu lt iq mq b gy mv mw l mx my">def etl_preprocess(int shop_id) -&gt; pd.DataFrame:<br/>    # do your work <br/>    pass<br/>​<br/>country_ids = get_countries()<br/>for country_id in country_ids:<br/>    shop_ids = get_country_shops(country_id)<br/>    for shop_id in shop_ids:<br/>        etl_preprocess(shop_id)</span></pre><p id="5d26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开始时一切都很好，但是随着公司因最终的成功而不断发展，这个过程在开始时只需要30分钟就可以为数百家商店执行，现在随着商店数量达到数百万，这个过程在几天内就会停滞不前。</p><p id="d890" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你知道“死于成功”吗？当一个企业无法处理过度增长的需求时，就会出现这种情况，因此它会屈服于这种需求。</p><h1 id="df1f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">如何扩大规模</h1><p id="c76a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们将从简单快速的胜利开始。所以首先要检查的是程序本身。回到理论上来，看看是否可以使用数据类型和/或不同的算法来重构这个过程。想的更聪明，不要更努力。</p><p id="6ca4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦达到算法性能的峰值，我们就可以开始考虑增加更多的<em class="mz">金属</em>(硬件资源)来提高程序的吞吐量。默认情况下，Python阻止多个线程在同一个进程中同时执行。这是使用异步函数获得性能提升的基础，因为当当前线程被阻塞时，大量IO进程可以使用额外的线程。但是对于CPU密集型操作，您的代码可能会在一个强大的多核CPU中执行，然而由于<a class="ae kv" href="https://python.land/python-concurrency/the-python-gil" rel="noopener ugc nofollow" target="_blank"> GIL </a>的原因，Python解释器被限制在一个CPU内核中执行(要更好地理解这个问题，请查看<a class="ae kv" href="https://medium.com/@bfortuner/python-multithreading-vs-multiprocessing-73072ce5600b" rel="noopener">Python中的线程和进程简介</a>)。</p><p id="f938" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你使用云基础设施，你要为每一个CPU支付全价，所以很可能你会送钱。除非你有充分的理由，否则不要向你的经理提及此事。也不要责怪开发人员，因为Python通过设计(通过前面提到的GIL)阻止了多个线程访问同一个进程。但是我们可以通过使用用于多处理的核心python API来创建多个进程，幸运的是还有第三方库提供更好的支持。</p><h1 id="d23c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">挤出所有的核</h1><p id="94b9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我发现(到目前为止)Python中多处理的最佳方法是使用<a class="ae kv" href="https://github.com/tqdm/tqdm" rel="noopener ugc nofollow" target="_blank"> tqdm </a>。在大多数情况下，由于这个库在Python社区中的成功，这个库很有可能已经是项目需求的一部分。</p><p id="b00b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当安装了<code class="fe na nb nc mq b">tqdm</code>之后，您就可以访问这个隐藏在其contrib名称空间中的小东西了:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="c0de" class="mu lt iq mq b gy mv mw l mx my">from tqdm.contrib.concurrent import process_map</span></pre><p id="1010" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从那里，您可以执行:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="6001" class="mu lt iq mq b gy mv mw l mx my">country_ids = get_countries()<br/>for country_id in country_ids:<br/>    shop_ids = get_country_shops(country_id)<br/>    results = process_map(etl_preprocess, shop_ids)</span></pre><p id="7e73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这段代码按照您的设想工作:它将为每个调用创建一个新的进程(每个调用使用不同的参数执行名为<code class="fe na nb nc mq b">etl_preprocess</code>的函数，这些参数取自<code class="fe na nb nc mq b">shop_ids</code>变量)。默认情况下，它会使用所有可用的内核，<code class="fe na nb nc mq b">process_map</code>会一直等到所有进程执行完毕。在这种情况下，对<code class="fe na nb nc mq b">etl_preprocess</code>的每个调用都返回一个单独的<code class="fe na nb nc mq b">pandas</code>数据帧，因此<code class="fe na nb nc mq b">process_map</code>将收集这些函数的返回，并返回一个包含所有熊猫数据帧的列表(返回数据的顺序与调用的执行顺序无关)。</p><p id="9e89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用这种方法的一些缺点:</p><ul class=""><li id="74bf" class="nd ne iq ky b kz la lc ld lf nf lj ng ln nh lr ni nj nk nl bi translated">考虑到如果由<code class="fe na nb nc mq b">process_map</code>调用的函数运行另一个多进程函数，它可能会以死锁场景结束。当使用<code class="fe na nb nc mq b">xgboost</code>或<code class="fe na nb nc mq b">TensorFlow</code>训练一个模型时，我发现自己陷入了这个陷阱(但是你的运气可能会因所用库的版本和特性而异)</li><li id="9e58" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">在发生异常的情况下，这些可以被<code class="fe na nb nc mq b">process_map</code>屏蔽，所以我建议小心处理您的日志记录</li><li id="d973" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">尽量避免依赖父执行(例如，避免使用<em class="mz">共享</em>变量)。<code class="fe na nb nc mq b">process_map</code>执行的方法应该是完全自治的(使用<em class="mz">依赖注入</em>设计模式)，或者公共数据应该被酸洗；否则，您可能会遇到竞态条件和意外的错误</li><li id="27d3" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">有时这种方法对测试库来说并不好用。解决这种情况的一种方法是使用<code class="fe na nb nc mq b">process_map(...,max_workers=1)</code>参数或<a class="ae kv" href="https://docs.python.org/3/library/unittest.mock.html#patch" rel="noopener ugc nofollow" target="_blank">模仿</a> <code class="fe na nb nc mq b">process_map</code>方法</li></ul><h2 id="1e9a" class="mu lt iq bd lu nr ns dn ly nt nu dp mc lf nv nw me lj nx ny mg ln nz oa mi ob bi translated">可供选择的事物</h2><p id="565b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果你的项目中不使用tqdm，可以给<a class="ae kv" href="https://github.com/DanilZherebtsov/verstack" rel="noopener ugc nofollow" target="_blank"> verstack </a>或者<a class="ae kv" href="https://github.com/Slimmer-AI/mpire" rel="noopener ugc nofollow" target="_blank"> mpire </a>一个机会。我没有测试过这些库，但是API是相似的，除此之外，<code class="fe na nb nc mq b">verstack</code>包含了常见机器学习任务的助手。</p><h1 id="582f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">分配你的工作</h1><p id="5ef1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">增强您的过程的另一个选择是将它变成一个完全分布式的作业，并在集群中启动它。在我们深入探讨之前，我先简单定义一些基本概念:<strong class="ky ir">集群</strong>是计算机的集合。在集群世界里，计算机被称为<strong class="ky ir">节点</strong>；大多数时候，存在一个名为<em class="mz">驱动</em>的节点，它管理其余节点(名为<em class="mz">工作节点</em>)的生命周期(节点初始化/关闭/监控)，驱动还负责向每个工作节点发送工作负载。在我们的上下文中，一个<strong class="ky ir">作业</strong>包括整个程序的执行，因此对所有国家/商店执行<code class="fe na nb nc mq b">etl_preprocess</code>。</p><p id="daa3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">综上所述，之前我们使用CPU内核来倍增性能，现在我们将使用集群(反过来可以由<em class="mz"> p </em>节点和<em class="mz"> m </em>内核组成)。我希望你能了解这个规模。</p><p id="2241" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Azure Machine Learning为设置集群提供了一个优秀的API(甚至你可以使用UI来完成)。复杂的部分是你如何访问集群的被管理部分，并让它为你的分布式目的服务。有两种方式:<a class="ae kv" href="https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.parallelrunstep?view=azure-ml-py" rel="noopener ugc nofollow" target="_blank"> ParallelRunStep </a>和<a class="ae kv" href="https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.hyper_drive_step.hyperdrivestep?view=azure-ml-py" rel="noopener ugc nofollow" target="_blank"> HyperDriveStep </a>。在我的例子中，基于<code class="fe na nb nc mq b">HyperDriveStep</code>的流程更容易实现(尽管我建议你自己测试<code class="fe na nb nc mq b">ParallelRunStep</code>并检查，DYOR原则总是适用的)。</p><p id="f4ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe na nb nc mq b">HyperDriveStep</code>通常用于超参数优化，可配置为简单的网格搜索。这是<em class="mz">间接路径</em>到达<em class="mz">管理部分</em>并使其执行我们的工作负载。</p><p id="0f28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最终的代码比之前稍微复杂一点，因为实现需要嵌入到Azure机器学习中。幸运的是，基本实现很容易:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="0c6c" class="mu lt iq mq b gy mv mw l mx my">run_config = ScriptRunConfig(source_directory=source_directory,<br/>                             script="./etl_pre_process.py",<br/>                             arguments=[],<br/>                             compute_target=build_compute_target(ws),<br/>                             environment=build_environment())<br/>​<br/>country_ids = get_countries()<br/>param_sampling = GridParameterSampling({'country_id': choice(*country_ids)})<br/>​<br/>hyperdrive_config = HyperDriveConfig(run_config=run_config,                                                hyperparameter_sampling=param_sampling,<br/>                                     primary_metric_name='count',                                   primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,<br/>                                     max_total_runs=len(ids))<br/>​<br/>step = HyperDriveStep("etl_pre_process", hyperdrive_config, allow_reuse=False)<br/>​</span></pre><p id="57af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，etl_pre_process模块将被执行，传递参数<code class="fe na nb nc mq b">country_id</code>:</p><pre class="kg kh ki kj gt mp mq mr ms aw mt bi"><span id="2bdd" class="mu lt iq mq b gy mv mw l mx my">if __name__ == '__main__':<br/>    parser = argparse.ArgumentParser()<br/>    parser.add_argument('--country_id', type=str, dest='country_id')<br/>    args = parser.parse_args()<br/>​<br/>    shop_ids = get_country_shops(args.country_id)<br/>    results = process_map(etl_preprocess, shop_ids)</span></pre><p id="9d12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，我们需要使用一个可执行的Python模块作为基本的执行功能，Azure机器学习将负责繁重的工作:</p><ul class=""><li id="543a" class="nd ne iq ky b kz la lc ld lf nf lj ng ln nh lr ni nj nk nl bi translated">将代码库签出到工作节点中</li><li id="7e92" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">安装依赖项，并将所需的Python模块复制到工作节点。一旦节点准备就绪，节点将开始执行指定的Python模块</li><li id="b659" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">集群初始化需要一些时间，所以使用不同的集群大小进行一些测试，以减少作业的总执行时间</li><li id="2160" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">集群管理:例如，如果您的集群设置为最多10个节点，但是当前的执行只使用了5个国家，那么它将只启动5个节点。集群本身将<em class="mz">在所有节点之间协调/划分</em>作业，并在作业完成时逐渐关闭节点</li></ul><p id="b524" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种解决方案的缺点是:</p><ul class=""><li id="fafa" class="nd ne iq ky b kz la lc ld lf nf lj ng ln nh lr ni nj nk nl bi translated"><em class="mz">侵入集群</em>(例如，在配置<code class="fe na nb nc mq b">HyperDriveConfig</code>时，我们必须使用<code class="fe na nb nc mq b">primary_metric_name</code>和<code class="fe na nb nc mq b">primary_metric_goal</code>等参数，否则这些参数对于简单的数据争论过程毫无意义)</li><li id="7562" class="nd ne iq ky b kz nm lc nn lf no lj np ln nq lr ni nj nk nl bi translated">从单台机器到集群范例的转换需要额外的工作，这些工作并不总是<em class="mz">直接/琐碎的</em>并且应该提前计划:如何<em class="mz">注入</em>每次执行所需的参数？如何平衡均匀的工作量？或者最终如何收集数据？</li></ul><h1 id="89bd" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">摘要</h1><p id="6ec2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在Python中扩展流程不是一件容易的事情。大多数时候，扩展至少需要对现有代码进行一些重构，甚至从头开始开发代码。有许多选项唾手可得:核心Python多线程/多处理函数，像<a class="ae kv" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> dask </a>或<a class="ae kv" href="https://www.ray.io/" rel="noopener ugc nofollow" target="_blank"> ray </a>这样的库，基于Spark的完全分布式解决方案(如<a class="ae kv" href="https://databricks.com/" rel="noopener ugc nofollow" target="_blank"> Databricks </a>或<a class="ae kv" href="https://www.snowflake.com/" rel="noopener ugc nofollow" target="_blank"> Snowflake </a>)，最后，还有像Azure Machine Learning这样的IaaS解决方案，你可以使用本文中解释的<em class="mz">过程</em>来轻松扩展你的过程。</p></div></div>    
</body>
</html>