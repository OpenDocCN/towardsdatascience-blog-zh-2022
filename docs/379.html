<html>
<head>
<title>A Machine Learning Model Is No Longer a Black Box Thanks to SHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多亏了SHAP，机器学习模型不再是黑匣子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-machine-learning-model-is-no-longer-a-black-box-thanks-to-shap-9f6ae3adaedc#2022-01-13">https://towardsdatascience.com/a-machine-learning-model-is-no-longer-a-black-box-thanks-to-shap-9f6ae3adaedc#2022-01-13</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="71da" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">机器学习</h2><div class=""><h1 id="229c" class="pw-post-title je jf iw bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">多亏了SHAP，机器学习模型不再是黑匣子</h1></div><div class=""><h2 id="ac54" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">Python中的一步一步教程，揭示了机器学习模型的内部工作原理</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/db34f8f410f10b5d8ec04f828acb8faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4oK-XI4JHEzZJRFY"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">萨姆·穆卡达姆在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="6691" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">数据科学家在构建表示数据的模型时可能犯的第一个错误是将算法视为黑盒。在实践中，数据科学家可以更多地关注数据清理，然后尝试一种或多种机器学习算法，而无需了解该算法到底做什么。</p><p id="29ad" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">事实上，在选择这个或那个机器学习模型之前，数据科学家应该问自己的第一个问题是<strong class="ln jg">问是否真的有必要使用机器学习</strong>。</p><p id="ec30" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">因此，我的建议是，机器学习是最后的手段，如果没有替代解决方案，就使用它。</p><p id="b5da" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">一旦你确定机器学习是必要的，重要的是<strong class="ln jg">打开黑盒</strong>了解算法做什么，如何工作。</p><p id="5359" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">有各种各样的技术来解释模型，并使没有机器学习专业知识的人更容易理解为什么模型做出某些预测。</p><p id="c9e6" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在本文中，我将介绍SHAP值，这是最流行的模型解释技术之一。我还将通过一个例子来展示如何使用SHAP价值观来获得洞察力。</p><p id="1df3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">文章组织如下:</p><ul class=""><li id="65f1" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated">SHAP概况</li><li id="e705" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated">Python中的一个实际例子</li></ul><h1 id="daa1" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">1 SHAP概述</h1><p id="7f38" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated"><em class="ns">SHAP代表“沙普利附加解释”。</em>“沙普利值是合作博弈理论中一种广泛使用的方法。</p><p id="ef82" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在机器学习中，<strong class="ln jg">Shapley值分别测量所有输入特征中每个特征对结果的贡献</strong>。实际上，Shapely值有助于理解如何根据输入要素构建预测值。</p><p id="85b5" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">2017年，Lundberg和Lee在一篇题为<a class="ae lk" href="https://arxiv.org/abs/1705.07874" rel="noopener ugc nofollow" target="_blank">解读模型预测的统一方法</a>的文章中首次发表了SHAP算法(鉴于其重要性，该文章有近5500条引用)。</p><p id="9e6f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">关于SHAP价值如何运作的更多细节，你可以阅读萨缪尔·马赞蒂的两篇有趣的文章，标题分别是:SHAP价值准确地解释了你希望别人如何向你解释；黑箱模型实际上比逻辑回归更容易解释。</p><p id="c0dd" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">要在Python中处理SHAP值，可以安装<code class="fe nv nw nx ny b">shap</code>包:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="3486" class="od mw iw ny b gz oe of l og oh">pip3 install shap</span></pre><p id="b161" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">可以为各种Python库计算SHAP值，包括Scikit-learn、XGBoost、LightGBM、CatBoost和Pyspark。<code class="fe nv nw nx ny b">shap</code>包的完整文档可在<a class="ae lk" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">此链接</a>获得。</p><h1 id="8713" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">2 Python中的一个实际例子</h1><p id="3adb" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">作为一个实际的例子，我利用了由<code class="fe nv nw nx ny b">scikit-learn</code>软件包提供的著名的糖尿病数据集。数据集的描述可在<a class="ae lk" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset" rel="noopener ugc nofollow" target="_blank">此链接</a>获得。我测试了以下算法:</p><ul class=""><li id="ccea" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">DummyRegressor</code></li><li id="20c5" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">LinearRegressor</code></li><li id="701d" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">SGDRegressor</code>。</li></ul><p id="bc42" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">对于每个测试过的模型，我创建模型，训练它，并预测由测试集给出的新值。然后，我计算均方差(MSE)来检查它的性能。最后，我计算并绘制SHAP值。</p><h2 id="5103" class="od mw iw bd mx oi oj dn nb ok ol dp nf lu om on nh ly oo op nj mc oq or nl jc bi translated">2.1加载数据集</h2><p id="9583" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">首先，我加载糖尿病数据集:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="3093" class="od mw iw ny b gz oe of l og oh">from sklearn.datasets import load_diabetes</span><span id="7789" class="od mw iw ny b gz os of l og oh">data = <strong class="ny jg">load_diabetes</strong>(as_frame=True)<br/>X = data.data<br/>y = data.target</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ot"><img src="../Images/4d507aea9fbd35ab2e008ffdb8d646ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKrf1_LHBU7y8R8DzFI0wQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="3454" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我把它分成训练集和测试集:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="040a" class="od mw iw ny b gz oe of l og oh">from sklearn.model_selection import train_test_split</span><span id="298d" class="od mw iw ny b gz os of l og oh">X_train, X_test, y_train, y_test = <strong class="ny jg">train_test_split</strong>(X, y, test_size=0.33, random_state=42)</span></pre><p id="7129" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">此场景的目标是根据一些输入特征计算血糖值(y值)，包括体重指数(身体质量指数)、体压(bp)和其他类似参数。输入要素已经被规范化。这是典型的回归问题。</p><h2 id="ce96" class="od mw iw bd mx oi oj dn nb ok ol dp nf lu om on nh ly oo op nj mc oq or nl jc bi translated">2.2虚拟回归量</h2><p id="5d4d" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">在应用真实的机器学习模型之前，我建立了一个基线模型，即虚拟回归器，它将输出值计算为训练集中输出的平均值。</p><p id="096d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">虚拟回归器可用于比较，即检查机器学习模型是否相对于它提高了性能。</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="2b41" class="od mw iw ny b gz oe of l og oh">from sklearn.dummy import DummyRegressor<br/>model = <strong class="ny jg">DummyRegressor</strong>()<br/>model.fit(X_train, y_train)</span></pre><p id="02be" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我计算了模型的MSE:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="1aa4" class="od mw iw ny b gz oe of l og oh">y_pred = model.predict(X_test)<br/>print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))</span></pre><p id="d380" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">输出为5755.47。</p><p id="20e0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我可以计算这个基本模型的SHAP值。我用模型和训练集构建了一个通用的<code class="fe nv nw nx ny b">Explainer</code>，然后计算数据集上的SHAP值，这个数据集可能与训练集不同。在我的例子中，我计算了训练集的SHAP值。</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="9450" class="od mw iw ny b gz oe of l og oh">import shap</span><span id="a425" class="od mw iw ny b gz os of l og oh">explainer = shap.<strong class="ny jg">Explainer</strong>(model.predict, X_train)<br/>shap_values = explainer(X_train)</span></pre><p id="89be" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">注意<code class="fe nv nw nx ny b">Explainer</code>可能接收模型本身或<code class="fe nv nw nx ny b">model.predict</code>函数作为输入，这取决于模型类型。</p><p id="8584" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><code class="fe nv nw nx ny b">shap</code>库提供不同的函数来绘制SHAP值，包括以下几个:</p><ul class=""><li id="1d22" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">summary_plot()</code> —显示每个特征对SHAP值的贡献；</li><li id="b1bf" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">scatter()</code> —显示SHAP值与每个输入特征的散点图；</li><li id="1dd4" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">plots.force() </code> —所有数据集的交互式绘图；</li><li id="bcc6" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><code class="fe nv nw nx ny b">plots.waterfall() </code> —显示如何为单个数据构建SHAP值。</li></ul><p id="a7ec" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在调用前面的函数之前，必须运行以下命令:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="93f7" class="od mw iw ny b gz oe of l og oh">shap.initjs()</span></pre><p id="d7f0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">首先，我画了散点图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="82a6" class="od mw iw ny b gz oe of l og oh">shap.plots.scatter(shap_values, color=shap_values)</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ou"><img src="../Images/59ebf288fa82186e9fde078448f9c73c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KKwIXEanWYbLpSGYrA-_RQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="eec8" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">上图显示了预期的情况:在虚拟模型中，每个特征对SHAP值的贡献是恒定的。</p><p id="4e3a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我画总结图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="c660" class="od mw iw ny b gz oe of l og oh">shap.summary_plot(shap_values, X_train, plot_type='bar')</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ov"><img src="../Images/970c9cdb2078777a8e1301f1284a62ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Yvsj60uzqEjQslRNbNmmQ.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="c8aa" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">有趣的是，在一个虚拟模型中，最有影响的因素是年龄。</p><p id="7157" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">最后，我画出了<code class="fe nv nw nx ny b">force()</code>图。下图是静态的，但如果您在笔记本中绘图，它是交互式的:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ow"><img src="../Images/41e2d243b17d7928bdbb67bc13a33496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qrgXsz2FxLkra2a93fPg8w.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="7f65" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">显然，对于数据集中的每个样本(x轴)，每个特征对预测值(y轴)的贡献是相同的。</p><h2 id="7037" class="od mw iw bd mx oi oj dn nb ok ol dp nf lu om on nh ly oo op nj mc oq or nl jc bi translated">2.3线性回归器</h2><p id="74b3" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">虚拟回归似乎不是最好的模型，因为它达到了MSE = 5755.47。我尝试线性回归，希望它能取得更好的表现。</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="959a" class="od mw iw ny b gz oe of l og oh">from sklearn.linear_model import LinearRegression<br/>model = <strong class="ny jg">LinearRegression</strong>()</span><span id="9a59" class="od mw iw ny b gz os of l og oh">model.fit(X_train, y_train)<br/>y_pred = model.predict(X_test)<br/>print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))</span></pre><p id="42f2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">线性回归器的MSE = 2817.80，优于虚拟模型。</p><p id="1d71" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我构建了<code class="fe nv nw nx ny b">Explainer</code>，它接收模型作为输入:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="021b" class="od mw iw ny b gz oe of l og oh">import shap<br/>explainer = shap.<strong class="ny jg">Explainer</strong>(model, X_train)<br/>shap_values = explainer(X_train)</span></pre><p id="902c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我绘制总结图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="183d" class="od mw iw ny b gz oe of l og oh">shap.summary_plot(shap_values, X_train, plot_type='bar')</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ox"><img src="../Images/3f17df3a24565858125998d9914751bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0VHdO8S1jHfVuLgV-9dqqg.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="81b5" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">在这种情况下，最有影响的特征是s1(在虚拟模型中，最有影响的特征是年龄)。不指定<code class="fe nv nw nx ny b">plot_type</code>参数也可以绘制汇总图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="5d7e" class="od mw iw ny b gz oe of l og oh">shap.summary_plot(shap_values, X_train)</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oy"><img src="../Images/905c10577e431c3d0b558ac344b91eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8nUm8pJ2zyTVbZ18coyucA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="9d50" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">上图显示了每个输入要素对SHAP值的贡献。注意，小于-75的SHAP值仅由s1决定。</p><p id="327f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我为训练集中的样本0绘制了瀑布图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="9572" class="od mw iw ny b gz oe of l og oh">shap.plots.waterfall(shap_values[2])</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oz"><img src="../Images/ac821432db490c8b09b0684e875f6c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*47zRJH6niMMdy0HKokJ9ag.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="6b84" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">上图显示了如何从基线值<code class="fe nv nw nx ny b">E[f(x)]</code>建立最终预测<code class="fe nv nw nx ny b">f(x)</code>。红色条表示正贡献，蓝色条表示负贡献。</p><p id="3ea1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我可以通过<code class="fe nv nw nx ny b">force()</code>图表显示所有样本的先前图表:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj pa"><img src="../Images/80f13046ecc9d0454c65212f7cf44504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHjtjYrgNtGiopNQS82ImA.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="037c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">对于为虚拟回归元(即平面回归元)构建的同一图表，对于线性回归元，每个特征对最终结果的贡献取决于单个样本。</p><p id="89cb" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">最后，我绘制了散点图:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="73b1" class="od mw iw ny b gz oe of l og oh">shap.plots.scatter(shap_values, color=shap_values)</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj pb"><img src="../Images/14c802701fddbec07a5e20733844b789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtqtO-yaXvs4glFISssuqw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><h2 id="524a" class="od mw iw bd mx oi oj dn nb ok ol dp nf lu om on nh ly oo op nj mc oq or nl jc bi translated">2.4新币回归元</h2><p id="98d2" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">最后，我实现了随机梯度下降回归器。我利用交叉验证网格搜索来调整模型:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="c90d" class="od mw iw ny b gz oe of l og oh">from sklearn.model_selection import GridSearchCV<br/>parameters = {<br/>    'penalty' : ('l2', 'l1', 'elasticnet')<br/>}<br/>model = SGDRegressor(max_iter=100000)<br/>clf = GridSearchCV(model, parameters)<br/>clf.fit(X_train, y_train)</span></pre><p id="ed8e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我计算MSE:</p><pre class="kv kw kx ky gu nz ny oa ob aw oc bi"><span id="54a6" class="od mw iw ny b gz oe of l og oh">model = clf.best_estimator_</span><span id="87b5" class="od mw iw ny b gz os of l og oh">y_pred = model.predict(X_test)<br/>print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))</span></pre><p id="41ab" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该模型达到了一个MSE = 2784.27，优于以前的模型。</p><p id="8bb9" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">下图显示了汇总图:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj pc"><img src="../Images/4e739f0c732d80df94c88d818e14c258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwNQIdBljPofiKOH4VNC2w.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="2b15" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">上图显示bmi特征是SGD分类器最有影响力的参数。</p><h1 id="b582" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">摘要</h1><p id="f9d9" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">恭喜你！您刚刚学习了如何通过SHAP值来反转机器学习模型！SHAP值指定了每个要素对最终预测值的影响。</p><p id="8ea5" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你已经走了这么远来阅读，对我来说今天已经很多了。谢谢！你可以在<a class="ae lk" href="https://alod83.medium.com/which-topics-would-you-like-to-read-c68314dc6813" rel="noopener">这篇文章</a>里读到更多关于我的内容。</p><h1 id="4503" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">参考</h1><ul class=""><li id="442a" class="mh mi iw ln b lo nn lr no lu pd ly pe mc pf mg mm mn mo mp bi translated"><a class="ae lk" href="https://coderzcolumn.com/tutorials/machine-learning/shap-explain-machine-learning-model-predictions-using-game-theoretic-approach" rel="noopener ugc nofollow" target="_blank">https://coderzcolumn . com/tutorials/machine-learning/shap-explain-machine-learning-model-predictions-using-game-theory-approach</a></li><li id="301c" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><a class="ae lk" href="https://m.mage.ai/how-to-interpret-and-explain-your-machine-learning-models-using-shap-values-471c2635b78e" rel="noopener ugc nofollow" target="_blank">https://m . mage . ai/how-to-interpret-and-explain-your-machine-learning-models-using-shap-values-471 c 2635 b78e</a></li><li id="dd28" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><a class="ae lk" href="https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/dans Becker/advanced-uses-of-shap-values</a></li><li id="97f9" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><a class="ae lk" href="https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html" rel="noopener ugc nofollow" target="_blank">https://shap . readthedocs . io/en/latest/example _ notebooks/overviews/An % 20 introduction % 20 to % 20 explained % 20 ai % 20 with % 20 Shapley % 20 values . html</a></li></ul><h1 id="5d75" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">相关文章</h1><div class="pg ph gq gs pi pj"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-pycaret-9a13c0fa51d4"><div class="pk ab fp"><div class="pl ab pm cl cj pn"><h2 class="bd jg gz z fq po fs ft pp fv fx jf bi translated">Python PyCaret中的完整数据分析工作流</h2><div class="pq l"><h3 class="bd b gz z fq po fs ft pp fv fx dk translated">这是一个现成的教程，利用了我用过的最好的机器学习库。</h3></div><div class="pr l"><p class="bd b dl z fq po fs ft pp fv fx dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px le pj"/></div></div></a></div><div class="pg ph gq gs pi pj"><a rel="noopener follow" target="_blank" href="/automl-in-python-a-comparison-between-hyperopt-sklearn-and-tpot-8c12aaf7e829"><div class="pk ab fp"><div class="pl ab pm cl cj pn"><h2 class="bd jg gz z fq po fs ft pp fv fx jf bi translated">Python中的AutoML:Hyperopt sk learn和TPOT的比较</h2><div class="pq l"><h3 class="bd b gz z fq po fs ft pp fv fx dk translated">两种流行的Python AutoML库的优缺点</h3></div><div class="pr l"><p class="bd b dl z fq po fs ft pp fv fx dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="py l pu pv pw ps px le pj"/></div></div></a></div><div class="pg ph gq gs pi pj"><a rel="noopener follow" target="_blank" href="/4-different-approaches-for-time-series-analysis-7e2364fadcb9"><div class="pk ab fp"><div class="pl ab pm cl cj pn"><h2 class="bd jg gz z fq po fs ft pp fv fx jf bi translated">4种不同的时间序列分析方法</h2><div class="pr l"><p class="bd b dl z fq po fs ft pp fv fx dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pz l pu pv pw ps px le pj"/></div></div></a></div></div></div>    
</body>
</html>