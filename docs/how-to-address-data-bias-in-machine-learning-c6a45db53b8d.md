# 如何解决机器学习中的数据偏差

> 原文：<https://towardsdatascience.com/how-to-address-data-bias-in-machine-learning-c6a45db53b8d>

## 理解偏差到底是什么并采取正确的措施来防止它在数据科学领域非常有用。

![](img/255a2ddfa92cab39617281fc316dad70.png)

在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上由 [Bodie Pyndus](https://unsplash.com/@bpyndus?utm_source=medium&utm_medium=referral) 拍摄的照片

嗯，**公司**在机器学习的帮助下，花费了大量的收入来帮助发展他们的**业务**。作为一个主要参与数据清理和数据准备以及为公司执行有价值的预测的人，当试图在生产中**部署**ML 模型时，还有一个更重要的因素需要考虑。在这段时间里，我们还应该考虑人工智能的伦理含义以及我们的模型在预测结果时有多大的偏差。因此，最根本的问题应该是机器学习中的偏见到底是什么。现在让我们来处理机器学习的这个领域，这样我们就可以产生一个健壮的模型，它也考虑了伦理因素。

## 什么是数据偏差？

![](img/0b7605b6962e7d3e558a90f2f2d35f22.png)

Alexander Schimmeck 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

每当我们向 ML 模型提供数据时，数据的**质量**以及特征与结果的**关联程度通常决定了预测模型的质量。如果存在与结果不高度相关的特征，那么从最简单的模型到最复杂的模型，成功使用这些模型的可能性极小。因此，作为数据科学家或机器学习工程师，必须考虑的最重要的方面是给予各种模型的数据质量。**

现在我们正在慢慢接近数据偏差的定义。如果你能耐心听我说，你会得到几行字的解释。因为我们已经知道数据形成了模型在**测试数据**(看不见的数据)上实际表现如何的基础，所以假设数据的质量决定了模型在测试数据上表现如何是基本的。如果我们用于 ML 模型的数据包含一组特定类的大量信息，那么它们在这些特定类上的表现可能比在其他类上的表现更好。

为了将它放在上下文中，想象我们正试图根据一系列特征(如地区、性别、种族、社会地位、收入和工作)来预测一个人是否会拖欠贷款。因此，可能会有一些高度适用于模型预测的要素。当我们考虑像**‘性别’**这样的例子，并看到很大一部分被代表的人是男性时，模型将会了解很多关于男性借款人的情况，以及与女性借款人相比，他们是否会偿还贷款。类似的论点也可以用在**种族**身上。通过这种方式，该模型天生就知道，身为“男性”拖欠贷款的几率会更低，反之亦然。当我们考虑诸如**准确度**之类的指标来衡量模型的表现时，我们可能会夸大其表现，尽管它在**少数**类中表现不佳。这就是所谓的数据偏差，即与其他类别的特征相比，某些类别的特征被过度表示。

虽然偏见可能经常是无意的，但它们的存在对受其影响的人群来说却是非常重要的。想想亚马逊的**招聘算法系统地筛选出女性候选人的例子。同样，**微软的** Twitter 机器人因其提供的结果和产生的反馈而被指控为种族主义者。如果结果显示模型结果更偏向于特定的人群，则用户将来更有可能会失去信任并且永远不会使用这些模型。**

在经历了这么长的解释之后，我们可以得出结论，应该采取措施来克服这个问题，这样我们就可以对模型建立更多的信任。

## 如何克服机器学习中的数据偏差

![](img/5ac958a59e7ad9f41e226e1e277d8fef.png)

照片由[新闻社跟随](https://unsplash.com/@olloweb?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 拍摄

借助正确的策略和工具，有许多方法可以减少数据偏差。减少偏差的第一个方法是了解偏差发生的确切位置。如果我们知道应该关注哪些领域可能存在偏差，我们就可以采取正确的措施来确定有助于在很大程度上减少这种偏差的行动。现在让我们回顾一下可以在很大程度上减少偏差的各种方法。

## 确定正确的机器学习模型

当我们使用各种 ML 模型时，无论我们是在进行有监督的机器学习还是无监督的机器学习，偏差都可能是模型学习输入和输出之间的各种表示，这有助于它学习它。如果我们要改变模型中的几个超参数或几组东西，那么我们就会得到最好的模型，所有类别的性能往往会非常一致。

想象一下，你的团队要求你设计一个**机器学习模型**，它可以根据年龄、性别、血压等一系列特征来捕捉一个人是否有更高的患癌几率。有一些模型可以学习诸如性别和年龄等特征的表示。与其他因素相比，这些特征有时可以被使用并被赋予更大的重要性。如果是这种情况，根据模型，特定性别或年龄患**癌症**的可能性更高。因此，在这种情况下，模型可能会有偏差，因为它只是基于性别或年龄作为一个重要因素来预测结果。应对这一挑战的最好方法之一是使用各种工具来构建模型的可解释性。如果我们首先知道为什么模型做出了决定，我们就可以确定模型是否有偏差。有一些工具，如 **LIME** (本地可解释的模型不可知解释)，也可以帮助我们确定为什么模型会给出一个特定的决定，从而帮助医生。还有其他工具，如 **SHAP** (沙普利值)也可以用于可解释性。让你的团队了解为什么模型会给出特定的决策或结果是件好事。

## 为使用的数据提供适当的文件

**记录**数据有两方面的帮助。首先，它有助于我们理解模型中的各种特征及其对结果的影响。第二，它也可能导致这样的情况，我们可以通过观察数据的分布来识别数据中的偏差。拥有适当的数据文档还可以确保使用它的其他人了解对模型预测有影响的各种特征的存在，以及模型中各种组的存在或过度表示。

因此，当我们试图使用数据建立一个具有机器学习的解决方案时，如果有提供的功能的**文档**会很方便。考虑一个预测给定文本是阳性还是阴性的例子。在这种情况下，我们将在**自然语言处理(NLP)** 的帮助下查看各种特性。当我们使用这个解决方案时，如果有一个我们用来预测文本情感的数据和特征的文档，它会非常有用。如果有大量的正面文本，只有少量的负面文本，那么当有负面评论时，模型很难做得很好。此外，查看所使用的各种功能的文档可以帮助我们更好地理解数据以及每个功能在模型预测中的影响程度。如果有适当的数据文档，以便团队成员在使用机器学习模型进行预测之前可以访问并完全理解这些数据，这是可能的。

## 评估各种类别的模型性能

当构建可用于生产的 ML 模型时，它们往往对我们数据中的一组特定类别表现良好。当我们考虑**保护的特征**时，比如年龄、性别和性别，与其他人相比，它们可以在某个群体或类别中表现良好。为了消除偏见，我们必须确保模型在所有类别上都表现良好，而不仅仅是在一个类别上。因此，我们必须考虑每个子组的性能，并了解所有组的性能是否一致。这样，就很有可能减少模型中的偏差。

考虑这样一种情况，您的模型在**测试数据(看不见的数据)**上表现很好，用于预测一封邮件是垃圾邮件还是火腿。我们知道，在现实生活中，我们的大部分邮件都是垃圾邮件，只有少数情况下会有垃圾邮件。因此，可用于训练模型的数据在很大程度上包含类别不平衡，与垃圾邮件相比，垃圾邮件的数量更多。在这种情况下，如果我们评估每个单独类的性能，而不是完全关注数据，这将非常有用。这样，我们很好地评估了每个单独类别的性能，而不是整个数据，从而减少了对特定类别(多数类别)的偏差。

## 传播更多的意识

虽然有许多合格的数据科学家在解决公司中一些最复杂的问题，但也有少数人不太重视人工智能的道德方面。传播对机器学习中存在偏见的认识可能非常有用，特别是当可以采取行动打击偏见时。在在线课程中添加更多关于机器学习伦理方面的内容也可能是有益的。

当看最近的新闻时，我们了解到像**谷歌**和**微软**这样的公司正在采取措施传播更多关于人工智能伦理的意识。类似地，组织可以采取行动，也可以让人们更加意识到数据偏差问题及其对各种受保护类别的影响。当他们采取正确的步骤，对模型预测更加透明时，许多人可以信任这些黑箱模型，并在他们未来的努力中使用它们。

## 结论

总而言之，我们已经看到，在用于预测的机器学习模型中可能存在数据偏差。采取正确的步骤来消除数据中的偏见可能会很方便，特别是当我们承认人工智能的道德方面时。为消除机器学习中的偏差，可以遵循的步骤是确定正确的 ML 模型，评估各种类别的模型性能，并传播更多的偏差意识。感谢您花时间阅读这篇文章。也欢迎分享你的想法。

如果你想获得更多关于我的最新文章的更新，并且每月只需 **5 美元**就可以无限制地访问中型文章，请随时使用下面的**链接**来添加你对我工作的支持。谢了。

[https://suhas-maddali007.medium.com/membership](https://suhas-maddali007.medium.com/membership)

以下是您联系我或查看我作品的方式。

**GitHub:** [苏哈斯马达利(Suhas Maddali)(github.com)](https://github.com/suhasmaddali)

**LinkedIn:** [(1)苏哈斯·马达利，东北大学，数据科学| LinkedIn](https://www.linkedin.com/in/suhas-maddali/)

**中等:**苏哈斯·马达利——中等