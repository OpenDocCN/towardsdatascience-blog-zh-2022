# 人工智能伦理:算法个性化的冲突视角

> 原文：<https://towardsdatascience.com/ai-ethics-conflicting-visions-of-algorithmic-personalization-d04a2e06c0f9>

## 意见

# 人工智能伦理:算法个性化的冲突视角

## 个性化作为最佳控制或人类解放的工具？

![](img/f1bdd85d8c5aaae75704646ec4af35d6.png)

在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上由 [Kalea Jerielle](https://unsplash.com/@kaleajerielle?utm_source=medium&utm_medium=referral) 拍摄的照片

在具有讽刺意味的转变中，*适应性网络*和 *Web 2.0* 技术所承诺的自我表达、自由和互利合作已经被企业一边倒地吸收了。在这个过程中，经济理论中有争议的假设被引入到个性化研究中，很少受到批评性的反对。

从表面上看，个性化是一套技术，旨在过滤无关信息，并提供适合个人品味和需求的建议。但是，脸书、谷歌和亚马逊等商业平台上的个性化越来越多地通过工程优化和控制的镜头来想象(我在这里讨论基于[强化学习](https://en.wikipedia.org/wiki/Reinforcement_learning)的个性化[的控制含义](/corporate-imperatives-and-the-future-of-ai-development-part-i-773f5a1a352b?source=friends_link&sk=9dcf30a0fd0153ddf1e1570693d31b42))。此外，在创新和创造性破坏的技术要求的催化下，大型企业平台通过自私自利的竞争[新自由主义经济逻辑](https://en.wikipedia.org/wiki/Neoliberalism)来实现个性化。

将工程形式主义和经济理论应用于全球范围内数十亿人类用户引发了围绕个人自主和人类自决的伦理问题，其中一些现在正在被转化为正式立法，如欧盟的 [GDPR](https://gdpr.eu/) ，以及最近提出的[人工智能法案](https://www.eipa.eu/publications/briefing/the-artificial-intelligence-act-proposal-and-its-implications-for-member-states/)和[数字服务和市场法案](https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package)。

## 个性化的经济合理性

在经济理论中，平台被视为多边市场，旨在实现用户活动和内容的商品化。感兴趣的第三方，尤其是广告商，受益于该平台的算法标准化和治理结构提供的人类注意力“密集市场”。专业化通过贸易服务于互惠互利。广告商可以将机器学习驱动的市场细分的复杂工作外包给该平台，利用其对顶级数据科学家、计算能力和大量隐性行为数据的访问，让他们更好地将稀缺资源投资于开发个性化信息和通过平台的推荐基础设施提供的服务。

[新古典经济学](https://en.wikipedia.org/wiki/Neoclassical_economics)颂扬市场自然产生商品和服务最优配置的能力，因为所有交易都被认为是自愿和互利的。否则，理性行为者就不会进行交易。因此，个性化通过允许理性消费者访问更大的选择集(即市场)，促进同行、服务和产品提供商之间的信息交换，并降低搜索、交易和决策成本，从而增强了理性消费者(以及广告客户)的能力。

从这个角度来看，个性化是市场驱动的经济自由观的技术实现，在这种经济自由观中，人们可以得到他们个人喜欢的东西——无论这些偏好的谱系或合法性如何。从这个角度来看，个性化促进了自由，因为它是基于自愿的，因此也是公平的交换:理性的用户被认为是自愿地*与平台互动，并留下行为跟踪数据，这些数据随后可以根据用户透露的需求和需要进行处理并与感兴趣的外部方交换。正如诺贝尔奖获得者[米尔顿·弗里德曼](https://en.wikipedia.org/wiki/Milton_Friedman)在他 1980 年的著作*自由选择*中所言，这种基于市场的自愿交易过程促进了经济交换、繁荣，并最终促进了人类自由。*

但是，几十年来获得诺贝尔奖的经济理论所支持的乐观故事忽略了许多重要的细节。正如脸书举报者 Francis Haugen 所描述的，经济激励可以促使企业平台掩盖可能对其底线产生负面影响的个性化研究。这包括发现个性化技术的应用可能对个人产生破坏性的心理影响，并对社会产生不稳定的影响。

## 个性化科学的目标:控制还是自由？

在现代，我们倾向于狭隘地将知识等同于科学。这可能是由强大的技术官僚、经济专家和今天的数据科学家推动的更大的意识形态 [*科学主义*](https://en.wikipedia.org/wiki/Scientism) 利己主义的症状，以证明他们提升的社会地位和决策权？

按照德国哲学家[尤尔根·哈贝马斯](https://en.wikipedia.org/wiki/J%C3%BCrgen_Habermas)的说法，答案可以说是肯定的。在他 1971 年的著作《知识和人类兴趣》中，他声称人类知识分为三大类，每一类都表达了人类的基本兴趣。他进一步主张，特别是在他后来的*交流行为* 的[理论中，忽视除了预测、操纵和控制对象之外的其他兴趣会导致文化、社会和个人发展的病态。除非我们意识到科学与控制和预测并不共延，否则我们仍然无法自由决定自己的未来——在道德上受到我们自己技术的阻碍。](https://en.wikipedia.org/wiki/Communicative_action)

哈贝马斯坚持认为经验分析知识服务于我们对预测、操纵和控制自然的工具性兴趣。我们人类同胞的实践知识和相互理解服务于我们的诠释学兴趣。最后，通过批判性的、自我反思的和深思熟虑的思想解放符合我们的关键利益。对哈贝马斯来说，批判科学通过反思自身及其方法来发现自身的局限性，并在此过程中发展和扩大其认识论范围。批判性科学是人类物种层面的元认知:它不仅告诉我们哪里的科学知识可能是强大的，还告诉我们哪里的科学知识可能是脆弱的，并在不久的将来需要修订。这里我想起了统计推断中置信区间的作用。

借鉴弗洛伊德心理疗法的模式和皮亚杰(T2)和科尔伯格(T4)提出的逻辑和道德发展阶段，解放科学旨在将我们从更低级且经常被压抑的强迫、本能和神经症中解放出来——这是我们早期丑陋的动物本性的一部分，当时身体力量仍然控制着社会关系，T6 可能是正确的。今天，我们已经超越了霍布斯的自然状态，部分原因是我们有能力控制和操纵自然来满足我们的基本物质需求。经验分析知识拯救世界！

但是我们现在还不清楚。哈贝马斯认为，在由自由市场竞争的新自由主义意识形态主导的日益全球化的世界中，金钱越来越多地协调我们的社会互动，并将社会协调降低到以自我为中心的效用计算的博弈论和后果主义逻辑。

## 个性化的人:你在哪里？

个性化，正如这个词本身所暗示的，建立在一个隐含的人的概念上。根据不同的哲学家，这个人可能是下列的一个或全部:

*   政治动物
*   道德代理人
*   理性、自觉的主体
*   特定权利的拥有者
*   具有明确的个性或者特点
*   一种叙事驱动和独特自我诠释的动物
*   一种自我组织的信息系统，能够随着时间的推移以独特的自我决定的方式发展和变化

## 康德:遵守普遍道德法则的自由

启蒙哲学家伊曼纽尔·康德认为人类的状况是内在矛盾的，在某种程度上早于现代双过程心理学。康德的墓碑上写着一句名言:

> 有两样东西，我们越是经常、越是坚定地思考它们，它们就会让我们心中充满新的、越来越多的钦佩和敬畏:我头上的星空和我心中的道德法则。

一方面，我们是物理生物，是受牛顿宇宙运动定律支配的物体。在这方面，我们与构成漂浮在太空中的岩石的一簇簇无意识的原子没有什么不同。然而，我们也拥有理性的能力，一种几乎无限的能力，能够意识到并清楚地表达出支配我们行为的规则。人类存在的这种规范性、自我参照性和“更高”的方面是人类价值和独特道德地位的基础。它赋予我们独特的个性，也是我们通常所说的“自我”的焦点大多数上瘾者都会同意，尽管我们可能会在意志力上有短暂的失误，但我们通常会将“真实的自我”与有意识、理性的自我反思的结果联系起来，而不是与我们的本能、欲望和即时需求联系起来。

康德认为，从严格意义上讲，出于本能和利己动机的行为没有道德价值。作为理性主义者，康德相信道德原则必须先于我们可能有的任何经验、兴趣或欲望而产生。的确，*善意——为了职责而履行职责的*——*——*是唯一的*无条件*或*内在*善意，但它需要自主性(即*自我立法*能力)才能有牙齿。意志必须同时创造它自己的法则，并把自己与这些法则捆绑在一起，这样它才是好的。客观上对所有理性存在有效，康德称这样的普遍法则为*绝对命令。*成为理性意味着有效地使一个人的意志和绝对命令一致。

> 因此，矛盾的是，自由来自于*将一个人的意志与内在的普遍道德法则捆绑在一起，这是一条所有理性生物天生就能遵循的法则。*

康德声称，这种绝对命令是所有道德义务的基础，并作为我们行动动机的决定程序。类似于逻辑一致性的概念，绝对命令认可那些行动规则，当被所有理性主体普遍化时，不会导致矛盾。换句话说，只有可以转化为绝对命令的责任——而不会弄巧成拙或导致矛盾——才算道德责任。例如，我们有义务做出虚假的承诺吗？不，因为如果没有人信守承诺，承诺本身的概念就会瓦解。

与康德对道德的抽象和逻辑方法相反，越来越多地推动算法个性化的正统经济思想遵循哲学家大卫·休谟的经验主义，他的著名观点是*理性是并且应该是激情的奴隶*。关于算法个性化的基础，这种划分被我称为 ***视觉冲突*** 。

![](img/134709e2924796e56f84113e592e8784.png)

照片由 [GR Stocks](https://unsplash.com/@grstocks?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

## **个性化的冲突愿景**

为了更好地理解与个性化相关的人文主义和经济观点之间的紧张关系，我想改编一下托马斯·索威尔在他富有洞察力的书《愿景的冲突》中所做的区分。

索威尔是一名训练有素的经济学家，他区分了西方思想中两种相互冲突的政治和道德观点。这些愿景是无所不包的世界观，不仅偏向一个人的伦理和政治理论，也偏向一个人对科学知识的性质和范围的理解。然而这两种观点是互不相容的。实际上，一个人看到一只鸭子，另一个人看到一只兔子。例如，[消费者主权](https://en.wikipedia.org/wiki/Consumer_sovereignty)概念背后的标准经济思维暗示，因为*我们渴望某样东西，它一定是好的。*然而康德主张相反的观点:*某物是好的，因此我们必须渴望它*(就我们是理性的存在而言)。

我推测人工智能伦理学领域的出现在某种程度上是这种观点冲突的表现。因此，对人工智能伦理的工作和兴趣的快速增长应该被解释为表达对个性化技术迄今为止忽略了无约束愿景的基本元素的不满。我们可以粗略地将这些不受约束的因素与哈贝马斯所说的我们的解释学和解放兴趣联系起来，以实现相互理解和从我们基础的动物性本质中获得自由。

## 受限的视觉

到目前为止，个性化技术在很大程度上是在追求受限视觉的过程中发展起来的。这种受约束的观点遵循了一条最早由苏格兰启蒙运动(T2)的思想家提出的思想路线，比如 T4 的亚当·斯密(T5)和大卫·休谟(T6)。它将相关性置于因果关系之上，将习惯和传统中隐含的直觉和经验知识置于显而易见的原因之上，将可观察到的结果置于不可观察到的意图之上，并将理想与实现理想所需的成本进行权衡。完美不应该是好的敌人。稀缺性和有限性被视为人类生存的基本方面，因此关于分配这种稀缺资源的各种方式的相对效率问题被列为优先事项。受限视野接受权衡是生活中不可避免的事实。

从伦理的角度来看，受约束的观点严重依赖于对正确行为和价值的结果主义、工具主义推理，并采取一种“系统级”的功利主义观点，主张集合体的属性优于个体。受限视觉分享了一种类似于[行为主义](https://en.wikipedia.org/wiki/Behaviorism)和(逻辑)[实证主义](https://en.wikipedia.org/wiki/Positivism)的科学哲学，因为它通过参考环境的可观察、可验证的经验特征来寻找对人类行为的普遍不变的类似法律的解释，避免不可验证、不可观察的内在原因的可疑的形而上学主张。与新古典经济学一样，受约束的视野似乎遭遇了一个明显的物理学嫉妒案例，即物理学的唯物主义科学体现了人类调查研究的方法论和认识论理想。

## 不受约束的视野

我认为，无论是出于实践还是意识形态的原因，个性化技术的发展在很大程度上独立于不受约束的视野。但随着人工智能伦理领域的发展，这种情况可能会慢慢改变。

不受约束的愿景源自法国和德国启蒙时代的思想，由孔多塞和 T2 的伊曼纽尔·康德发展而来，将理性和有意识的深思熟虑提升到直觉、习惯和传统之上，强调抽象的理想而不是实现这些理想所需的实际牺牲，并惊叹于有教养的人类思维达到自我认识和普遍真理的能力。

不受约束的观点认为某些行为和事态本质上是好的，这是因为在理想的公正观察者看来，它们具有客观属性，或者是审议或普遍化的理想化程序的结果。受限视觉的工具主义或结果主义推理通常被认为是低劣的，因为它倾向于不加批判地把结果视为既定的(*但是是谁给的呢？并且可以证明把人当作物品，仅仅是达到他人目的的手段是正当的。*

在其政治、伦理和法律形式中，这种不受约束的观点经常赞同对追求公共利益的个人可以做什么制定严格的规则，经常使用[权利作为“王牌”](https://en.wikipedia.org/wiki/Ronald_Dworkin)的概念来描绘无论效用或后果如何都不能跨越的个人神圣性领域。

就科学哲学而言，不受约束的观点的理性主义超越了可观察的相关性，并通过提及行动的内部原因来解释人类行为，这涉及不可观察的意图，其内容可能只有那些参与共享生活或文化形式的人才能完全理解和理解。不受约束的视野认可了现实主义者，甚至是超验现实主义者的形而上学。

## 人工智能伦理学:一种矛盾修饰法？

一些哲学家称经济伦理的概念为矛盾修饰法。这也适用于人工智能伦理的思想吗？人工智能体现了统计学、计算机科学、数学和工程领域的前沿知识。然而伦理本质上是保守的。哲学学生仍然阅读 2000 年前的文本，而工程师却不读，这是有原因的。

但个性化核心的视觉冲突并不是放弃对个性化未来希望的理由。不受约束的理想主义宣称技术和道德进步不是也不应该是相互排斥的。扩大对数据科学家和工程师的教育，让他们接触哲学和社会科学的关键思想，是重要的第一步。包括来自各种文化和跨学科视角的人工智能研究人员也是如此。如果个性化被(重新)想象为一种解放技术，而不仅仅是一种工具控制和优化人类对象的工程工具，这些变化将是必要的。

我们必须确保，在开发和部署个性化技术的过程中，我们不会为了效率、便利或利润这种纯粹的工具性商品而牺牲我们内在良好的认知“内在道德法则”的能力。批判性科学和人工智能伦理在指导我们应用技术方面发挥了作用，这些技术促进了我们的诠释学和批判性兴趣，并进一步——而不是阻碍——人类道德发展。