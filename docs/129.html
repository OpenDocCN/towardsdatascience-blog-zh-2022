<html>
<head>
<title>Complete Guideline to Implementation of Basic NLP Techniques with spaCy (Part-4)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用spaCy实现基本NLP技术的完整指南(第4部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-implementation-of-basic-nlp-techniques-nltk-or-spacy-687099e02816#2022-01-05">https://towardsdatascience.com/hands-on-implementation-of-basic-nlp-techniques-nltk-or-spacy-687099e02816#2022-01-05</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""><h1 id="abe7" class="pw-post-title is it iu bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">用spaCy实现基本NLP技术的完整指南(第4部分)</h1></div><div class=""><h2 id="7e96" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">了解如何使用Python库实现基本的NLP技术</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/69e887d44fe80483230033e96bd7e925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ooA9CgChsl1hWv2d"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kz" href="https://unsplash.com/@theshubhamdhage?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Shubham Dhage </a>拍摄的照片</p></figure><h2 id="2982" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">动机</h2><p id="3f92" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">自然语言处理(NLP)是一项非常有趣的技术，因为通过这项技术，计算机可以识别我们的自然语言，并像智能人一样做出反应。起初，当我开始了解NLP的魔力时，我感到非常惊讶。</p><p id="032f" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">【如果你想了解我的自然语言处理之旅以及自然语言处理的基础知识，我强烈推荐你阅读这篇文章——</em><a class="ae kz" rel="noopener" target="_blank" href="/a-complete-guide-to-natural-language-processing-nlp-c91f1cfd3b0c"><em class="mu"/></a><em class="mu">。] </em></p><p id="8cc6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">我相信实践经验是学习一项技术的最好方法，只有理论知识是没有帮助的。苹果的Siri，微软的Cortana，谷歌的语音助手，亚马逊的Alexa等。，都在用NLP。他们的作品多有趣啊！希望我们也能创造一些有趣的项目。</p><p id="b829" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">所以，是时候动手实践实现标记化、词汇化、词干化、停用词、词性标注等了。我们还将了解哪个python库最适合实际应用，以及原因。</p><p id="85c7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv"> <em class="mu">让我们开始吧…… </em> </strong></p><blockquote class="mv mw mx"><p id="0c52" class="lw lx mu ly b lz mp jv mb mc mq jy me my mr mg mh mz ms mj mk na mt mm mn mo in bi translated"><strong class="ly iv">自然语言处理</strong> ( <strong class="ly iv"> NLP </strong>)是语言学、计算机科学和人工智能的一个分支，涉及计算机和人类语言之间的交互，特别是如何编写计算机程序来处理和分析大量自然语言数据[1]。</p></blockquote><h2 id="980e" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">空间和NLTK概述</h2><p id="c706" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">spaCy和NLTK都是开源的自然语言处理库。</p><p id="57b6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">空间</strong></p><p id="96e7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">spaCy在2015年作为开源的NLP库首次进入聚光灯下。它可以有效地执行大多数NLP任务。spaCy主要实现最常见的高效NLP技术来执行任务。没有选择特定算法来执行任务的选项。例如，有多种词干提取技术，您希望选择其中一种。不幸的是，空间没有给我们提供灵活性；相反，它会自动选择最常用的算法来执行任务。</p><p id="c475" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">想了解更多spaCy的信息，请登陆</em><a class="ae kz" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"><em class="mu">spaCy【2】官网。</em> </a></p><p id="016e" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv"> NLTK </strong></p><p id="4509" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">NLTK代表自然语言工具包，是最古老和最流行的自然语言处理库之一。它于2001年首次发布，这意味着它比spaCy早得多。它促进了许多NLP功能，但是效率较低。您可以在NLTK中选择不同的算法。</p><p id="364e" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">你可以从</em> <a class="ae kz" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> <em class="mu">这里</em></a><em class="mu">【3】获得NLTK的官方文档。</em></p><p id="d4be" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">➤<strong class="ly iv">nltk和spaCy的对比分析</strong></p><p id="55a8" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">NLTK和spaCy都是NLP的重要库。有些任务在spaCy中是高效的，有些在NLTK中是高效的。我们需要在不同的环境中使用这两个库，让我们来看一些比较。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nb"><img src="../Images/3d396424a566be019664def2112fa8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuYSQBT43W7qCcW5_a5GtQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">spaCy与其他NLP库的比较(图片由作者提供)</p></figure><p id="7f33" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">上图清楚地表明，在<strong class="ly iv"> <em class="mu">标记化</em> </strong>和<strong class="ly iv"> <em class="mu">标记</em> </strong>的情况下，spaCy分别比NLTK快20倍和443倍。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nc"><img src="../Images/bb81f31083f13d903cde08aedfecf2cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*IA9GCW2_9Z6CtedoBBI4QA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">SpaCy，NLTK提供的功能比较[4]</p></figure><p id="70ad" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">我们不能根据优势对图书馆进行分类；相反，在不同的情况下两者都需要。一般来说，在速度和实现方面，spaCy比NLTK工作得更好，但是NLTK也是必需的。</p><p id="5841" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">在整篇文章中，我将向您展示NLP任务的基本实现，如标记化、词干化、词汇化、词性标注、文本匹配等。让我们用一些代码来弄脏我们的手。首先，我将展示如何为空间创造环境。</p><h2 id="de7a" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">空间库的安装和设置</h2><p id="4328" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">如果您使用Anaconda，您必须将以下命令写入Anaconda命令提示符。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="c40e" class="la lb iu ne b gz ni nj l nk nl">conda install -c conda-forge spacy<br/>or <br/>pip install -U spacy</span></pre><p id="2316" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">如果您在本地使用除Anaconda之外的库，您可以使用下面的命令。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="dcbe" class="la lb iu ne b gz ni nj l nk nl">pip install -U spacy</span></pre><p id="e764" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">因为我们使用英语进行演示，所以我们需要下载英语的必要元素。在命令提示符下运行命令。</p><p id="22e2" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">注意——您必须以管理员身份运行该命令或使用</em> <code class="fe nm nn no ne b"><em class="mu">sudo</em></code> <em class="mu">。</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="c49c" class="la lb iu ne b gz ni nj l nk nl">python -m spacy download en</span></pre><p id="b308" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">与空间合作</strong></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="132b" class="la lb iu ne b gz ni nj l nk nl">import spacy<br/>nlp = spacy.load('en_core_web_sm')</span></pre><p id="bf72" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">当我们运行下面这段代码时，它将导入空间库并将模型加载到<code class="fe nm nn no ne b">nlp</code>。如果我们在文本上调用对象<code class="fe nm nn no ne b">nlp</code>，spaCy将标记文本并保存到一个<code class="fe nm nn no ne b">Doc</code>对象。之后，<code class="fe nm nn no ne b">Doc</code>对象再次通过不同的步骤，这个过程被称为流水线。通常，管道包含标记器、语法分析器、解析器和命名实体识别器。下图清晰地描述了管道流程[5]。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj np"><img src="../Images/4af50e01d6ccaa61e992a12537a19dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*5RZ1Saa-R7LKN30UoTL5ZA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">空间管道的图形表示[5]</p></figure><p id="70e6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">通过运行代码<code class="fe nm nn no ne b">nlp.pipepline</code>，我们可以找出管道的组件。有一些用于查找原始标记文本、词汇化、词性标注等的标记属性。在下表中，还有一些其他属性。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nq nr l"/></div></figure><h2 id="392c" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用空间的标记化:</h2><p id="511a" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">标记化技术将文本分割成小单元。我们来举个例子[6]。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="238a" class="la lb iu ne b gz ni nj l nk nl">doc = nlp('"Let\'s go to N.Y.!"')<br/>for token in doc:<br/>    print(token.text)</span></pre><p id="46c4" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">如果我们运行代码，我们会发现输出如下。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="c9ba" class="la lb iu ne b gz ni nj l nk nl">"<br/>Let<br/>'s<br/>go<br/>to<br/>N.Y.<br/>!<br/>"</span></pre><p id="f7fa" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><code class="fe nm nn no ne b">doc</code>对象包含文本的标记，属性<code class="fe nm nn no ne b">.text</code>保存原始文本。spaCy非常聪明，因为它没有把<code class="fe nm nn no ne b">N.Y.</code>分开，也没有把<code class="fe nm nn no ne b">‘s</code>当作一个令牌。下图清楚地描述了标记化的过程。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ns"><img src="../Images/f2c587fc441d07111e43fb1e64044967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*bRm9QJGFxeoCf9sFpjSQrA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">来源:https://spacy.io/usage/linguistic-features<a class="ae kz" href="https://spacy.io/usage/linguistic-features" rel="noopener ugc nofollow" target="_blank"/></p></figure><h2 id="bf13" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">具有空间的命名实体</h2><p id="61dd" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在一个句子中，一个单词或一组单词表示名称(例如，地名、人名、地区名、国家名、州名、货币值等)。命名实体的主要目的是识别它。命名实体可以通过<code class="fe nm nn no ne b">Doc</code>对象的<code class="fe nm nn no ne b">ents</code>属性访问。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nq nr l"/></div></figure><p id="11cb" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">代码的输出</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="2c29" class="la lb iu ne b gz ni nj l nk nl">Google | 's | monthly | revenue | is | $ | 6 | million | <br/>______________________________________________________<br/>Google - ORG - Companies, agencies, institutions, etc.<br/>monthly - DATE - Absolute or relative dates or periods<br/>$6 million - MONEY - Monetary values, including unit</span></pre><p id="83a6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">输出的第一行显示了句子的标记，其余的行显示了命名的实体以及适当的文档。通过使用<code class="fe nm nn no ne b">.noun_chunks</code>属性，我们将得到<strong class="ly iv"> <em class="mu">基本名词短语</em> </strong>。</p><h2 id="e260" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">可视化命名实体</h2><p id="7aed" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">spaCy有一个内置的可视化工具来可视化命名实体。为此，我们必须从<code class="fe nm nn no ne b">spaCy</code>库中导入<code class="fe nm nn no ne b">displacy</code>模块。以下代码显示了如下输出。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="37dc" class="la lb iu ne b gz ni nj l nk nl">from spacy import displacy<br/>doc = nlp(u'Over last few years USA generates $6 million revenue.')<br/>displacy.render(doc, style='ent', jupyter=True)</span></pre><p id="65dd" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">输出</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nt"><img src="../Images/6220307aa862c4ac321c90022c7780cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*X3jkiLSeK37akb5zPeQsDQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><h2 id="a3de" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">可视化依赖关系</h2><p id="8bc3" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">使用<strong class="ly iv"> spaCy </strong>，我们还可以可视化一个句子的标记的依赖关系。出于演示目的，请遵循以下代码片段。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="8159" class="la lb iu ne b gz ni nj l nk nl">from spacy import displacy</span><span id="9a15" class="la lb iu ne b gz nu nj l nk nl">document = nlp(u'Bangladesh is a beautiful country')<br/>displacy.render(document, style='dep', jupyter=True, options={'distance': 110})</span></pre><p id="c34b" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">输出</em></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nv"><img src="../Images/7341804c11319ab28c5e20e6fd3c77cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*Lr8ZAGAPb77jQ_fJKDbtZA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">标记的依赖性(作者的图像)</p></figure><h2 id="055f" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">用NLTK做词干</h2><p id="ce2b" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">词干化意味着切分单词/记号以找出它们的词根。但是它并不总是提供有意义的字符串。空间库没有词干分析器；相反，它完全依赖于词汇化。</p><p id="2f0c" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">波特梗器</strong></p><p id="2a09" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">波特词干分析器有自己的映射规则，根据这些规则，单词在不同阶段被切分。该算法使用五个阶段来缩减单词。首先，使用一些预定义的规则来删除后缀，这些规则在下面给出。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nw"><img src="../Images/0a6da48ff30889c5ed84bf8210e53966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PkwAKax7Li2BHB0NWzZgCg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">波特词干分析器的一般规则(图片由作者提供)</p></figure><p id="b51d" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">这里，S1表示较长文本的后缀，S2表示单词缩减后的缩减形式。一次只能应用一个规则。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nw"><img src="../Images/e7c09ae0b37aa834ff7d4f1d03cb7629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C6mSl3YleAfnhfRotgwpDg.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">波特词干分析器的复杂规则(图片由作者提供)</p></figure><p id="a552" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">上述规则比第一个规则更复杂。<code class="fe nm nn no ne b">m</code>表示长度的度量。如果你想了解更多波特词干分析器算法，请访问<a class="ae kz" href="https://tartarus.org/martin/PorterStemmer/" rel="noopener ugc nofollow" target="_blank"> <em class="mu">链接</em></a>【7】。我们来举个编码的例子。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="55fb" class="la lb iu ne b gz ni nj l nk nl">import nltk<br/>from nltk.stem.porter import *<br/>p_stemmer = PorterStemmer()<br/>words = ['run','runner','running','ran','runs','easily','fairly']<br/>for word in words:<br/>    print(word+' --&gt; '+p_stemmer.stem(word))</span></pre><p id="bf75" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">输出</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="57a9" class="la lb iu ne b gz ni nj l nk nl">run --&gt; run<br/>runner --&gt; runner<br/>running --&gt; run<br/>ran --&gt; ran<br/>runs --&gt; run<br/>easily --&gt; easili<br/>fairly --&gt; fairli</span></pre><p id="59a0" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">雪球阻止器</strong></p><p id="b3c2" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">词干分析器是porter词干分析器的改进版本，它在逻辑和速度方面比以前的词干算法提供了更好的结果。让我们用<strong class="ly iv"> NLTK来实现。</strong></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="5308" class="la lb iu ne b gz ni nj l nk nl">from nltk.stem.snowball import SnowballStemmer</span><span id="adfb" class="la lb iu ne b gz nu nj l nk nl">s_stemmer = SnowballStemmer(language='english')<br/>words = ['run','runner','running','ran','runs','easily','fairly']</span><span id="851a" class="la lb iu ne b gz nu nj l nk nl">for word in words:<br/>    print(word+' --&gt; '+s_stemmer.stem(word))</span></pre><p id="2d0d" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">输出</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="c19c" class="la lb iu ne b gz ni nj l nk nl">run --&gt; run<br/>runner --&gt; runner<br/>running --&gt; run<br/>ran --&gt; ran<br/>runs --&gt; run<br/>easily --&gt; easili<br/>fairly --&gt; fair</span></pre><p id="b70f" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">结果似乎略有改善。</p><h2 id="d9cf" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">词汇化和词性标注</h2><p id="7b7b" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">词汇化不仅仅是像词干化一样减少或删减单词。词汇化的主要思想是找出主要的词根。请从<a class="ae kz" rel="noopener" target="_blank" href="/a-complete-guide-to-natural-language-processing-nlp-c91f1cfd3b0c"> <em class="mu">这里</em> </a>把我之前的文章读出来，了解更多关于词汇化的知识。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="nx nr l"/></div></figure><p id="3463" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">上面的代码产生以下输出</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="969c" class="la lb iu ne b gz ni nj l nk nl">He           PRON   561228191312463089     -PRON-<br/>is           VERB   10382539506755952630   be<br/>a            DET    11901859001352538922   a<br/>runner       NOUN   12640964157389618806   runner<br/>running      VERB   12767647472892411841   run<br/>in           ADP    3002984154512732771    in<br/>a            DET    11901859001352538922   a<br/>competition  NOUN   4661638505416061516    competition<br/>because      ADP    16950148841647037698   because<br/>he           PRON   561228191312463089     -PRON-<br/>loves        VERB   3702023516439754181    love<br/>to           PART   3791531372978436496    to<br/>run          VERB   12767647472892411841   run<br/>since        ADP    10066841407251338481   since<br/>he           PRON   561228191312463089     -PRON-<br/>ran          VERB   12767647472892411841   run<br/>today        NOUN   11042482332948150395   today</span></pre><p id="8c7c" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><code class="fe nm nn no ne b">.pos_</code>属性返回单词的词性，<code class="fe nm nn no ne b">.lemma</code>提供特定单词的哈希值，<code class="fe nm nn no ne b">.lemma_</code>给出单词的引理。如果我们观察令牌<code class="fe nm nn no ne b">running, run, ran,</code>，我们会发现它来自同一个引理<code class="fe nm nn no ne b">run</code>。这真是一份有趣又神奇的工作。</p><h2 id="d48f" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">用空格停止单词</h2><p id="1d0c" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">停用词在句子中出现得如此频繁，但对改变句子的意思并不重要。像spaCy库中的<code class="fe nm nn no ne b">a, an, the, then, etc.</code>，默认有<strong class="ly iv"> <em class="mu"> 305 </em> </strong>停用词。我们可以根据需要修改停用词列表。让我们举一个成文的例子。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="00eb" class="la lb iu ne b gz ni nj l nk nl">import spacy<br/>nlp = spacy.load('en_core_web_sm')</span><span id="dd93" class="la lb iu ne b gz nu nj l nk nl">print(nlp.Defaults.stop_words)</span></pre><p id="b6b9" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">输出</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="046c" class="la lb iu ne b gz ni nj l nk nl">{'hers', 'show', 'though', 'various', 'sixty', 'say', 'quite', 'ten', 'anything', 'although', 'hereby', 'in', 'ours', 'herself', 'among', 'unless', 'and', 'whole', 'anywhere', 'latter', 'therein', 'whereafter', 'that', 'one', 'whose', 'either', 'within', 'eight', 'three', 'latterly', 'anyone', 'a', 'less', 'former', 'been', 'same', 'anyway', 'else', 'cannot', 'five', 'i', 'until', 'last', 'thus', 'give', 'move', 'thereafter', 'via', 'than', 'empty', 'off', 'neither', 'too', 'please', 'over', 'just', 'otherwise', 'has', 'her', 'put', 'its', 'whether', 'herein', 'myself', 'me', 'nevertheless', 'whatever', 'someone', 'towards', 'whereby', 'onto', 'sometimes', 'thence', 'them', 'done', 'at', 'back', 'nor', 'another', 'behind', 'together', 'take', 'amongst', 'being', 'seemed', 'seeming', 'fifteen', 'do', 'further', 'something', 'again', 'this', 'were', 'wherein', 'how', 'up', 'must', 'get', 'whereas', 'much', 'upon', 'yet', 'both', 'many', 'very', 'may', 'after', 'regarding', 'full', 'through', 'below', 'his', 'well', 'everything', 'so', 'our', 'should', 'seem', 'while', 'for', 'might', 'mine', 'when', 'with', 'you', 'few', 'never', 'because', 'own', 'also', 'due', 'hence', 'it', 'more', 'their', 'such', 'becomes', 'first', 'hereupon', 'since', 'third', 'twenty', 'who', 'she', 'nobody', 'name', 'really', 'enough', 'least', 'two', 'whoever', 'which', 'yours', 'moreover', 'seems', 'before', 'therefore', 'then', 'used', 'even', 'nowhere', 'without', 'other', 'around', 'made', 'hundred', 'no', 'twelve', 'several', 'your', 'meanwhile', 'per', 'except', 'yourselves', 'why', 'some', 'not', 'yourself', 'sometime', 'somehow', 'become', 'beyond', 'almost', 'will', 'somewhere', 'the', 'everyone', 'about', 'everywhere', 'anyhow', 'side', 'next', 'fifty', 'they', 'most', 'perhaps', 'across', 'themselves', 'besides', 'against', 'can', 'him', 'there', 'noone', 'under', 'formerly', 'already', 'all', 'if', 'my', 'or', 'serious', 'four', 'thereupon', 'whence', 'here', 'whither', 'beside', 'wherever', 'to', 'himself', 'between', 'ourselves', 'none', 'on', 'became', 'an', 'have', 'part', 'did', 'had', 'each', 'six', 'those', 'from', 'whenever', 'any', 'am', 'would', 'make', 'could', 'does', 'go', 'call', 'indeed', 'these', 'often', 'above', 'during', 'by', 'nine', 'thereby', 'others', 'afterwards', 'throughout', 'whom', 'amount', 'as', 'hereafter', 'top', 'mostly', 'us', 'whereupon', 'once', 'only', 'still', 'namely', 'forty', 'ca', 'along', 'be', 'itself', 'where', 'see', 'into', 'toward', 'but', 'is', 'keep', 'bottom', 'ever', 'becoming', 'every', 'always', 'front', 'nothing', 'we', 'of', 'out', 'eleven', 'alone', 'he', 'however', 'rather', 'down', 'thru', 'now', 'using', 'are', 'doing', 'what', 'beforehand', 're', 'was', 'elsewhere'}</span></pre><p id="1461" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">检查一个特定的令牌是否是一个停用词。</strong></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="31ce" class="la lb iu ne b gz ni nj l nk nl">nlp.vocab['myself'].is_stop</span></pre><p id="220e" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">它返回<code class="fe nm nn no ne b"><strong class="ly iv">True</strong></code> <strong class="ly iv"> </strong>，因为默认的停用词列表包含单词<code class="fe nm nn no ne b">‘myself’</code>。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="2b37" class="la lb iu ne b gz ni nj l nk nl">nlp.vocab['mystery'].is_stop</span></pre><p id="c0b5" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">代码返回<code class="fe nm nn no ne b">False</code>，因为默认的停用词列表不包含单词<code class="fe nm nn no ne b">‘mystery’</code>。</p><p id="74ca" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">在默认空间停用词表中添加和删除停用词</strong></p><p id="6506" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">代码<code class="fe nm nn no ne b">nlp.Defaults.stop_words.add(‘btw’)</code>将字符串<code class="fe nm nn no ne b">btw </code>添加到默认列表中，而<code class="fe nm nn no ne b">nlp.Defaults.stop_words.remove(‘hers’)</code>将单词<code class="fe nm nn no ne b">hers</code>从默认停用单词列表中移除。</p><h2 id="46c3" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">使用空间创建匹配器</h2><p id="cc51" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">spaCy提供了名为<code class="fe nm nn no ne b">Matcher</code>的基于规则的匹配工具，它允许我们设置规则或正则表达式来匹配一个Doc对象，并返回一个包含找到的匹配的列表。要了解更多信息，请访问<a class="ae kz" href="https://spacy.io/usage/rule-based-matching" rel="noopener ugc nofollow" target="_blank"> <em class="mu">链接</em></a>【7】<em class="mu">。</em></p><p id="dde6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">基于规则的匹配器</strong></p><p id="584a" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">➤ <em class="mu">导入</em> <code class="fe nm nn no ne b"><em class="mu">Matcher </em></code> <em class="mu">库并创建一个匹配器对象。</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="46c7" class="la lb iu ne b gz ni nj l nk nl">from spacy.matcher import Matcher<br/>matcher = Matcher(nlp.vocab)</span></pre><p id="1352" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">➤ <em class="mu">创建图案并将其添加到匹配器</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="1e33" class="la lb iu ne b gz ni nj l nk nl">pattern_1 = [{'LOWER': 'solarpower'}]<br/>pattern_2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]<br/>pattern_3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]</span><span id="c9e5" class="la lb iu ne b gz nu nj l nk nl">matcher.add('SolarPower', None, pattern1, pattern2, pattern3)</span></pre><p id="e573" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">上面这段代码包含三种模式。</p><ul class=""><li id="071c" class="ny nz iu ly b lz mp mc mq lj oa ln ob lr oc mo od oe of og bi translated"><code class="fe nm nn no ne b">pattern_1</code>用小写<code class="fe nm nn no ne b">solarpower</code>表示任何匹配。</li><li id="e331" class="ny nz iu ly b lz oh mc oi lj oj ln ok lr ol mo od oe of og bi translated"><code class="fe nm nn no ne b">pattern_2 </code>表示与相邻小写<code class="fe nm nn no ne b">solar </code>和<code class="fe nm nn no ne b">power</code>的任何匹配。</li><li id="56ae" class="ny nz iu ly b lz oh mc oi lj oj ln ok lr ol mo od oe of og bi translated"><code class="fe nm nn no ne b">pattern_3 </code>表示带有小写<code class="fe nm nn no ne b">solar </code>和<code class="fe nm nn no ne b">power </code>以及它们之间的任何标点符号的任何匹配。</li></ul><p id="4f00" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">➤ <em class="mu">将匹配器应用于一个文档对象。</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="af52" class="la lb iu ne b gz ni nj l nk nl">document = nlp(u'The Solar Power industry continues to grow as demand \<br/>for solarpower increases. Solar-power cars are gaining popularity.')</span><span id="24ec" class="la lb iu ne b gz nu nj l nk nl">found_matches = matcher(document)<br/>print(found_matches)</span></pre><p id="87ca" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><code class="fe nm nn no ne b">matcher</code>返回元组列表。每个元组包含一个匹配的ID，start &amp; end标记映射到span <code class="fe nm nn no ne b">doc[start:end].</code></p><p id="392b" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">➤为比赛找出课文。</p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="bad2" class="la lb iu ne b gz ni nj l nk nl">for match_id, start, end in found_matches:<br/>    # get string representation<br/>    string_id = nlp.vocab.strings[match_id]<br/>    # get the matched span<br/>    span = doc[start:end]       <br/>    print(match_id, string_id, start, end, span.text)</span></pre><p id="d352" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><em class="mu">输出</em></p><pre class="kk kl km kn gu nd ne nf ng aw nh bi"><span id="8210" class="la lb iu ne b gz ni nj l nk nl">8656102463236116519 SolarPower 1 3 Solar Power<br/>8656102463236116519 SolarPower 10 11 solarpower<br/>8656102463236116519 SolarPower 13 16 Solar-power</span></pre><p id="ab68" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><code class="fe nm nn no ne b">match_id</code>就是<code class="fe nm nn no ne b">string_ID</code>‘太阳能’的哈希值。</p><p id="60d5" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">◉ <strong class="ly iv">短语匹配器</strong></p><p id="b3f8" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">如果你想了解PhraseMatcher，请访问<strong class="ly iv"><em class="mu"/></strong><a class="ae kz" href="https://spacy.io/usage/rule-based-matching#phrasematcher" rel="noopener ugc nofollow" target="_blank"><strong class="ly iv"><em class="mu">链接</em></strong></a><strong class="ly iv"><em class="mu"/></strong>。</p><h2 id="86cb" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">结论</h2><p id="a29d" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">NLP是现代计算中令人惊叹的技术之一，通过它，计算机可以识别我们的自然语言。有一些计算机处理自然语言的技术，因为人类和机器的学习过程是不同的。spaCy、NLTK等不同的库使这个过程变得简单。不可能在一篇文章中包含所有必要的技术。因此，请关注即将发布的文章，了解更多令人惊叹的NLP实现技术和项目。你也可以读一下我写的关于NLP的文章。</p><div class="om on gq gs oo op"><a rel="noopener follow" target="_blank" href="/a-complete-guide-to-natural-language-processing-nlp-c91f1cfd3b0c"><div class="oq ab fp"><div class="or ab os cl cj ot"><h2 class="bd iv gz z fq ou fs ft ov fv fx it bi translated">自然语言处理(NLP)完全指南</h2><div class="ow l"><h3 class="bd b gz z fq ou fs ft ov fv fx dk translated">机器如何识别人类语言并据此行动</h3></div><div class="ox l"><p class="bd b dl z fq ou fs ft ov fv fx dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd kt op"/></div></div></a></div><div class="om on gq gs oo op"><a rel="noopener follow" target="_blank" href="/tips-and-tricks-to-work-with-text-files-in-python-89f14a755315"><div class="oq ab fp"><div class="or ab os cl cj ot"><h2 class="bd iv gz z fq ou fs ft ov fv fx it bi translated">使用Python处理文本文件的技巧和诀窍</h2><div class="ow l"><h3 class="bd b gz z fq ou fs ft ov fv fx dk translated">使用文本文件并熟悉Python中令人惊叹的技术</h3></div><div class="ox l"><p class="bd b dl z fq ou fs ft ov fv fx dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="pe l pa pb pc oy pd kt op"/></div></div></a></div><div class="om on gq gs oo op"><a rel="noopener follow" target="_blank" href="/manipulate-pdf-files-extract-information-with-pypdf2-and-regular-expression-39ff697db0ca"><div class="oq ab fp"><div class="or ab os cl cj ot"><h2 class="bd iv gz z fq ou fs ft ov fv fx it bi translated">操作PDF文件，用PyPDF2和正则表达式提取信息</h2><div class="ow l"><h3 class="bd b gz z fq ou fs ft ov fv fx dk translated">使用PyPDF2和正则表达式简化PDF操作任务</h3></div><div class="ox l"><p class="bd b dl z fq ou fs ft ov fv fx dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="pf l pa pb pc oy pd kt op"/></div></div></a></div><h2 id="f738" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">参考</h2><p id="3bde" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">[1].<a class="ae kz" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Natural_language_processing</a></p><p id="3ece" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[2].Python中的spaCy工业级自然语言处理</p><p id="dffd" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[3].<a class="ae kz" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK::自然语言工具包</a></p><p id="e8dd" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[4].【https://spacy.io/usage/facts-figures T4】</p><p id="94d7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[5].<a class="ae kz" href="https://spacy.io/usage/spacy-101#pipelines" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/spacy-101#pipelines</a></p><p id="cb56" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[6].<a class="ae kz" href="https://spacy.io/usage/linguistic-features" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/linguistic-features</a></p><p id="b4ad" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[7].<a class="ae kz" href="https://spacy.io/usage/rule-based-matching" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/rule-based-matching</a></p><p id="a3d6" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">[8].<a class="ae kz" href="https://spacy.io/usage/rule-based-matching#phrasematcher" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/rule-based-matching#phrasematcher</a></p></div></div>    
</body>
</html>