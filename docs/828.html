<html>
<head>
<title>Interpreting ROC Curve and ROC AUC for Classification Evaluation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释ROC曲线和ROC AUC进行分类评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interpreting-roc-curve-and-roc-auc-for-classification-evaluation-28ec3983f077#2022-01-31">https://towardsdatascience.com/interpreting-roc-curve-and-roc-auc-for-classification-evaluation-28ec3983f077#2022-01-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="ed3d" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><em class="jn">解释ROC曲线和ROC AUC进行分类评价</em></h1></div><div class=""><h2 id="a8fd" class="pw-subtitle-paragraph jo ip iq bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">我多么希望我第一次学ROC曲线的时候就有人教我</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/0688ec23a9ba920743e594c2c265307d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EBT81VPT_cS4U_pXTqWCYw.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">原文来自<a class="ae kw" href="https://unsplash.com/@willfrancis" rel="noopener ugc nofollow" target="_blank">威尔·弗朗西斯</a>上<a class="ae kw" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank">的Unsplash </a></p></figure><p id="090b" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">评估分类器预测能力的一个非常有效的方法是绘制ROC(接收器操作特性)曲线。</p><p id="39b3" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是众所周知的，但你知道如何解读ROC曲线吗？</p><h1 id="7419" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">ROC曲线直觉</h1><p id="ff69" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">这条曲线通过绘制两个变量向我们展示了每个阈值的分类器行为:真阳性率(TPR)和假阳性率(FPR)。</p><p id="246e" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">真实阳性率通常被称为回忆/敏感度，定义为:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/3d5a24ef239ca2cf163d6b70924d95f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*YLlOAZ-dbCDR9Wra0gKirQ.png"/></div></figure><p id="6002" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">而假阳性率定义为:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/edcd83e81b59fdaeacbe2a325ffef905.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*bkHUfAhLrW_dHuFwR1s48w.png"/></div></figure><p id="9696" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在下图中，我们展示了给定数据集的逻辑回归模型的输出。当我们将阈值定义在<strong class="kz ir"> 50% </strong>时，没有实际的正观测值会被归类为负，所以FN = 0，TP = 11，但是4个负例会被归类为正，所以FP = 4，15个负观测值被归类为负，所以TN = 15。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ms"><img src="../Images/5d30bbb1ad29b2f0be5e0e7294cebe92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cexvd0XLM2238tXp-RWYDw.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">改编自<a class="ae kw" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc" rel="noopener ugc nofollow" target="_blank">谷歌开发者</a></p></figure><p id="4ca0" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当我们将阈值移动到<strong class="kz ir"> 75% </strong>时，只有阳性观测值会被归类为阳性，所以TP = 7，FP = 0，而所有阴性观测值都会被归类为阴性，TN = 19。我们仍有4个阳性观察结果被归类为阴性，因此FN = 4。</p><p id="774c" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们可以计算每个阈值的TPR和FPR，并对它们进行比较:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/b13e6ecb3c3e09ae2da6384e9d2dc983.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*8E8lCk_Ka-pmoKNW9-Si3g.png"/></div></figure><p id="a697" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最佳阈值取决于模型的目标。如果更重要的是将所有的正面分类为正面，即使这意味着将一些负面分类为正面，50%的阈值更好(见下面的例子)。</p><blockquote class="mu mv mw"><p id="91b2" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated"><strong class="kz ir"> 1)汽车故障预测——高召回，低精度</strong></p><p id="49bd" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">假设您为一家从汽车中收集数据的汽车制造商工作，您的模型试图预测汽车何时会发生故障，以便提醒客户前往修理厂进行检查。</p><p id="58c4" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">在这种情况下，你可能想要一个<strong class="kz ir">高召回</strong>，这意味着所有有潜在缺陷的车主将被警告进行检查。然而，通过最大化召回，我们也可能向不太可能很快损坏的汽车发送警告(误报)，从而降低精确度。假阳性汽车的车主将面临一个小小的不便，即去修理店却发现他的汽车很好，但另一方面，大多数可能损坏(甚至可能导致事故)的汽车情况都包括在内。</p><p id="e949" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">我们减少了FN(提高了召回率)，但增加了FP(降低了准确率)。</p></blockquote></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><p id="cf99" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在，如果我们希望有一个对每个被分类为正面的观察都有高置信度的模型，即使这意味着将一些正面的观察错误分类为负面的，75%的阈值是最佳选择(参见下面的选股示例)。</p><blockquote class="mu mv mw"><p id="1bfe" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated"><strong class="kz ir"> 2)选股预测——低召回、高精度</strong></p><p id="755f" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">这里你是一个股票交易者，希望建立一个模型来帮助你挑选股票。这个模型将把高收益概率的股票归类为正数。</p><p id="1c0b" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">在这种情况下，你希望只买最好的股票，因为你的钱有限，你不想承担太大的风险。这种情况下，你要提高精确度，只挑选最有可能产生回报的股票，即使这意味着一些好的股票可能会被遗漏(假阴性)。</p><p id="0849" class="kx ky mx kz b la lb js lc ld le jv lf my lh li lj mz ll lm ln na lp lq lr ls ij bi translated">通过只挑选最好的，我们减少了假阳性(并提高了精确度)，同时接受增加假阴性(并减少召回)。</p></blockquote><h1 id="39be" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">解读ROC曲线</h1><p id="f9a2" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">ROC曲线的目的是显示该模型对于每个可能的阈值的效果，作为TPR与FPR的关系。所以基本上，为了绘制曲线，我们需要计算每个阈值的变量，并绘制在一个平面上。</p><p id="5678" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在下图中，绿线代表TPR = FPR，而蓝线代表分类器的ROC曲线。如果ROC曲线正好在绿线上，说明分类器的预测能力和抛硬币一样。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ni"><img src="../Images/36efce9d11c93b6a327f0596a47757ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SKn7aehckf2J8FVz9xnraQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="9480" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在左图中，蓝线相对靠近绿线，这意味着分类器是坏的。最右边的图显示了一个好的分类器，ROC曲线靠近轴，而“肘”靠近坐标(0，1)。中间的一个是足够好的分类器，更接近于从真实世界数据中可能得到的结果。</p><p id="670d" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">解释ROC曲线的另一种方式是考虑类别的分离，我们可以用直方图来说明，如下所示。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nj"><img src="../Images/e92bd98e375a3ee2e5d6718efe6073f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQe_g5Rs_VzaU5CUV_dzSA.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">作者图片</p></figure><p id="9628" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">坏的分类器(左)有太多的类别重叠，因此无法做出好的预测，并且没有阈值能够分离类别。正如预期的那样，好的分类器(右)几乎没有重叠，因此我们可以很容易地找到一个好的阈值来分离正确类别中的预测。最后，中间的一个处于中间位置:有一些重叠，但通过相应地设置阈值可以获得良好的结果。</p><h1 id="7829" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">ROC AUC</h1><p id="8be6" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">现在你知道ROC曲线有多有用了，但是怎么评价呢？答案是:曲线下面积(AUC)。</p><p id="7453" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">AUROC曲线(ROC曲线下的面积)或简称为ROC AUC得分，是一种允许我们比较不同ROC曲线的指标。</p><p id="27c1" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">绿线是下限，该线下的面积是0.5，完美的ROC曲线的面积应该是1。我们模型的ROC AUC越接近1，就越有利于分类和做出更好的预测。</p><p id="e588" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们可以使用sklearn轻松计算ROC AUC:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="4c29" class="np lu iq nl b gy nq nr l ns nt">from sklearn.metrics import roc_auc_score<br/>score = roc_auc_score(y_real, y_pred)<br/>print(f"ROC AUC: {score:.4f}")</span></pre><p id="b8b0" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">输出是:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="2110" class="np lu iq nl b gy nq nr l ns nt">ROC AUC: 0.8720</span></pre><p id="bcab" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当使用<code class="fe nu nv nw nl b">y_pred</code>时，ROC曲线将只有“1”和“0”来计算变量，因此ROC曲线将是一个近似值。为了避免这种影响并获得更准确的结果，在计算ROC AUC时，建议使用<code class="fe nu nv nw nl b">y_proba</code>并获得类别“1”的概率:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="db76" class="np lu iq nl b gy nq nr l ns nt">score = roc_auc_score(y_real, y_proba[:, 1)<br/>print(f"ROC AUC: {score:.4f}")</span></pre><p id="a011" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">输出是:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="fb8e" class="np lu iq nl b gy nq nr l ns nt">ROC AUC: 0.9271</span></pre><h1 id="2708" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">从头开始绘制ROC曲线</h1><p id="eb21" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">我认为理解一个概念的最好方法是通过实验，所以让我们从头开始学习如何绘制ROC曲线。稍后，我将展示如何使用sklearn库轻松做到这一点。</p><p id="f298" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">您可以在我的github存储库中找到可用的代码，所以可以跳过这一部分。</p><div class="nx ny gp gr nz oa"><a href="https://github.com/vinyluis/Articles/tree/main/ROC%20Curve%20and%20ROC%20AUC" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">主要乙烯基/物品的物品/ROC曲线和ROC AUC</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">第一篇:解读ROC曲线和ROC AUC用于分类评价(TBD) [EN]什么是ROC曲线，如何…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">github.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo kq oa"/></div></div></a></div><p id="f754" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">首先，我们需要在数据集中训练一个分类器模型:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="39e2" class="np lu iq nl b gy nq nr l ns nt">from sklearn.model_selection import train_test_split<br/>from sklearn.naive_bayes import GaussianNB</span><span id="c572" class="np lu iq nl b gy op nr l ns nt"># Split train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)<br/># Create the model object<br/>model = GaussianNB()<br/># Fit the model to the training data<br/>model.fit(X_train, y_train)<br/># Predict the classes on the test data<br/>y_pred = model.predict(X_test)<br/># Predict the classes on the test data, and return the probabilities for each class<br/>y_proba = model.predict_proba(X_test)</span></pre><p id="9365" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然后，我们定义一个函数，根据前面给出的公式计算每个实例的TPR和FPR。</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="dea4" class="np lu iq nl b gy nq nr l ns nt">from sklearn.metrics import confusion_matrix</span><span id="2b76" class="np lu iq nl b gy op nr l ns nt">def calculate_tpr_fpr(y_real, y_pred):<br/>    # Calculates the confusion matrix and recover each element<br/>    cm = confusion_matrix(y_real, y_pred)<br/>    TN = cm[0, 0]<br/>    FP = cm[0, 1]<br/>    FN = cm[1, 0]<br/>    TP = cm[1, 1]<br/>    # Calculates tpr and fpr<br/>    tpr =  TP/(TP + FN) # sensitivity - true positive rate<br/>    fpr = 1 - TN/(TN+FP) # 1-specificity - false positive rate<br/>    <br/>    return tpr, fpr</span></pre><p id="95d9" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们希望评估每个阈值的TPR和FPR，因此我们定义了一个函数，该函数将创建“n”个阈值，并在这些阈值上迭代，计算变量并将它们存储在一个列表中。这些将是ROC曲线点的坐标。</p><p id="6205" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在二元分类器中，预测可以是“0”或“1”，并且移动阈值不会有任何影响。为了确保我们能够得到正确的曲线，我们需要使用将每个观察分类为“1”类的概率，我们通过<code class="fe nu nv nw nl b">model.predict_proba(X_test)</code>方法得到这些概率。</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="a1e0" class="np lu iq nl b gy nq nr l ns nt">def get_n_roc_coordinates(y_real, y_proba, n = 50):<br/>    tpr_list = [0]<br/>    fpr_list = [0]<br/>    for i in range(n):<br/>        threshold = i/n<br/>        y_pred = y_proba[:, 1] &gt; threshold<br/>        tpr, fpr = calculate_tpr_fpr(y_real, y_pred)<br/>        tpr_list.append(tpr)<br/>        fpr_list.append(fpr)<br/>    return tpr_list, fpr_list</span></pre><p id="2e51" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最后，我们可以使用seaborn绘制点和曲线，方法是将tpr和fpr列表传递给下面的函数:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="d128" class="np lu iq nl b gy nq nr l ns nt">import seaborn as sns<br/>import matplotlib.pyplot as plt</span><span id="1f85" class="np lu iq nl b gy op nr l ns nt">def plot_roc_curve(tpr, fpr, scatter = True):<br/>    plt.figure(figsize = (5, 5))<br/>    if scatter:<br/>        sns.scatterplot(x = fpr, y = tpr)<br/>    sns.lineplot(x = fpr, y = tpr)<br/>    sns.lineplot(x = [0, 1], y = [0, 1], color = 'green')<br/>    plt.xlim(-0.05, 1.05)<br/>    plt.ylim(-0.05, 1.05)<br/>    plt.xlabel("False Positive Rate")<br/>    plt.ylabel("True Positive Rate")</span></pre><p id="1583" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">结果是一个相当好的ROC曲线，使用直线作为没有计算坐标的线段的近似值。</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="b97c" class="np lu iq nl b gy nq nr l ns nt"># Calculates 10 coordinates of the ROC Curve<br/>tpr, fpr = get_n_roc_coordinates(y_test, y_proba, resolution = 10)<br/># Plots the ROC curve<br/>plot_roc_curve(tpr, fpr)</span></pre><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/a52923556009c04fe1f721a81dcc982c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Gv9U54fCkeM2WAT7nXZndA.png"/></div></figure><h1 id="fbed" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">用Scikit-Learn绘制ROC曲线</h1><p id="75b1" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">当然，您不会每次需要时都从头构建ROC曲线，所以我将展示如何用scikit-learn绘制它。</p><p id="45d1" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">看看有多简单:</p><pre class="kh ki kj kk gt nk nl nm nn aw no bi"><span id="50b0" class="np lu iq nl b gy nq nr l ns nt">from sklearn.metrics import roc_curve<br/>from sklearn.metrics import RocCurveDisplay</span><span id="bbdb" class="np lu iq nl b gy op nr l ns nt">def plot_sklearn_roc_curve(y_real, y_pred):<br/>    fpr, tpr, _ = roc_curve(y_real, y_pred)<br/>    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()<br/>    roc_display.figure_.set_size_inches(5,5)<br/>    plt.plot([0, 1], [0, 1], color = 'g')</span><span id="9860" class="np lu iq nl b gy op nr l ns nt"># Plots the ROC curve using the sklearn methods - Good plot<br/>plot_sklearn_roc_curve(y_test, y_proba[:, 1])</span><span id="9155" class="np lu iq nl b gy op nr l ns nt"># Plots the ROC curve using the sklearn methods - Bad plot<br/>plot_sklearn_roc_curve(y_test, y_pred)</span></pre><p id="0724" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><code class="fe nu nv nw nl b">roc_curve</code>函数计算所有FPR和TPR坐标，而<code class="fe nu nv nw nl b">RocCurveDisplay</code>将它们用作绘制曲线的参数。线条<code class="fe nu nv nw nl b">plt.plot([0, 1], [0, 1], color = 'g')</code>绘制绿色线条，可选。</p><p id="dac4" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果用<code class="fe nu nv nw nl b">model.predict_proba(X_test)[:, 1]</code>的输出作为参数y_pred，结果就是一条漂亮的ROC曲线:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/6bc59641f673973671bcf63296191a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8GgyAkAmfj0hTiTdQzpY0w.png"/></div></figure><p id="46bd" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">但是，如果直接使用<code class="fe nu nv nw nl b">model.predict(X_test)</code>的输出，该方法将没有构建所有点的所有必要信息，并且绘图将是两条线段的近似:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/d490364c6a4ebc74d372d4f46483a82f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7aL1-foi718_u1zC1BuN5w.png"/></div></figure></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="d948" class="lt lu iq bd lv lw oq ly lz ma or mc md jx os jy mf ka ot kb mh kd ou ke mj mk bi translated">结论</h1><p id="6d77" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">本文的结论是:ROC AUC最终是二元分类器中类之间分离的度量。我希望在我开始作为一名数据科学家的旅程时，这是如何向我解释的，我希望这将对本文的所有读者产生影响。</p><h1 id="c96d" class="lt lu iq bd lv lw lx ly lz ma mb mc md jx me jy mf ka mg kb mh kd mi ke mj mk bi translated">如果你喜欢这个帖子…</h1><p id="823e" class="pw-post-body-paragraph kx ky iq kz b la ml js lc ld mm jv lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">支持我一杯咖啡！</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><a href="https://www.buymeacoffee.com/vinitrevisan"><div class="gh gi ov"><img src="../Images/acf4154cfebdc13859934db49fd502cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*h_y4o6IwDDFFWIyKQE7Rww.png"/></div></a><p class="ks kt gj gh gi ku kv bd b be z dk translated">给我买杯咖啡！</p></figure><p id="2e5a" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果你喜欢这个主题，可以看看我解释ROC曲线用于多类分类的文章:</p><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/multiclass-classification-evaluation-with-roc-curves-and-roc-auc-294fd4617e3a"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">用ROC曲线和ROC AUC进行多类分类评价</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">将最常用的分类评估度量用于具有OvR和OvO的多类分类问题…</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="ow l ol om on oj oo kq oa"/></div></div></a></div></div></div>    
</body>
</html>