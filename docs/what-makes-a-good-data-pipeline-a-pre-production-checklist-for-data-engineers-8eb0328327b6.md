# 什么是好的数据管道——数据工程师的生产前清单

> 原文：<https://towardsdatascience.com/what-makes-a-good-data-pipeline-a-pre-production-checklist-for-data-engineers-8eb0328327b6>

## 成为数据工程师最重要的部分是构建高度可伸缩和可靠的数据管道

在我以前的一篇关于这个主题的文章中，即[学习数据工程的核心——构建数据管道](https://medium.com/@weiyunna91/learn-the-core-of-data-engineering-building-data-pipelines-21a4be265cc0?source=friends_link&sk=a15ca2e70b29b46a33adc695a341349e),我谈到了构建数据管道(也称为提取、转换和加载(ETL)管道)的 8 个关键组成部分

在今天的文章中，我将更详细地解释是什么使得数据管道适合在生产环境中部署。希望这也能在您将业务关键数据管道部署到生产环境之前，为您提供一种“清单”。

我将首先解释在生产环境中数据管道可能出错的地方，然后解释需要做些什么来(尽可能)防止管道出错，并确保在管道出现错误和故障时安全快速地恢复。除非你非常幸运，否则你的管道很有可能在某个阶段出问题。

让我们来看看在生产中运行数据管道时，您可以做些什么来保持平和的心态。

![](img/d17f31ade4773f88befe0718d544d613.png)

由[昆滕·德格拉夫](https://unsplash.com/@quinten149?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

## 数据量波动

在真实的生产环境中，数据量并不总是保持稳定。由于各种原因，如业务扩展、更多的客户获取、营销推广等，数据量可能会上升或下降。事实上，在大多数情况下，数据量都会波动。因此，数据管道需要能够自动伸缩，以应对数据量的波动。因此,“清单”上的第一项是了解您的数据量是否波动，如果波动，您需要利用提供自动扩展功能的数据基础架构来实时响应数据量的变化。您希望避免以下情况:

*   基础设施过度配置，这将导致不必要的浪费。
*   基础设施供应不足，这可能会导致管道故障，或者管道完成，但完成的级别低于服务级别协议(SLA)。

因此，了解数据量的变化模式是如何发生的，并在底层基础架构中拥有弹性以立即响应变化是至关重要的。

## 数据延迟变化

数据延迟是指从数据源获取数据并交付给最终用户使用的速度。当业务需求发生变化时，用户的数据延迟需求也会发生变化。需要以足够灵活的方式定义数据管道，以便在不对源代码进行重大更改的情况下适应这种变化。如果是批处理管道，您可以利用工作流编排来调整调度频率。如果是流式管道，您可以修改管道的触发频率。

让我们以 [Apache Spark 结构化流](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)为例，你可以调整流管道触发间隔如下:

*   默认-如果没有明确指定触发器设置，则默认情况下，流式管道将以微批处理模式执行，在这种模式下，只要前一个微批处理完成处理，就会生成微批处理。
*   固定间隔微批处理—流式管道将以微批处理模式执行，微批处理将在用户指定的间隔启动。
*   一次性微批处理—流式管道将只执行一个微批处理来处理所有可用数据，然后自行停止。
*   Available-now 微批处理—类似于一次性微批处理触发器，流式管道将处理所有可用数据，然后自行停止。不同之处在于，它将根据源选项(例如，文件源的 maxFilesPerTrigger)在(可能的)多个微批处理中处理数据。
*   具有固定检查点间隔的连续——流式管道将以新的低延迟连续处理模式执行。

如果您预见到数据延迟要求在未来可能会发生变化，您需要选择一个能够轻松促进数据延迟变化的计算引擎和框架。Apache Spark 结构化流加上 [delta lake](https://delta.io/) 作为数据存储格式是很好的组合，它提供了统一批处理和流数据管道的能力。

## 数据质量检查和管理

验证数据质量规则并保证端到端数据管道中的可靠数据是非常必要的，因为质量差的数据会导致糟糕的决策和/或糟糕的机器学习(ML)模型。当数据工程师开发和部署数据管道时，他们需要:

*   一是大力开展数据质量检查。这些数据检查包括技术验证，包括统计检查、缺失值检查、数据类型检查、数据重复检查以及业务检查，这些通常由数据资产的业务所有者或用户定义。
*   第二，报告违反关键数据质量规则的情况并发出警报。当您调试由数据质量恶化引起的管道问题时，这些报告将非常有用。
*   第三，了解数据质量差的根本原因，并根据根本原因提供相应的修复方法。

有一些开源库是专门为数据质量管理设计的，例如:

*   [great_expectations](https://greatexpectations.io/) —共享、开放的数据质量标准。它帮助数据团队通过数据测试、文档和分析消除管道债务。
*   [Deequ](https://github.com/awslabs/deequ) —基于 Apache Spark 构建的库，用于定义“数据的单元测试”，测量大型数据集中的数据质量。Python 用户可能也会对 [PyDeequ](https://github.com/awslabs/python-deequ) 感兴趣，这是 Deequ 的一个 Python 接口。

一些商业 ETL 框架如 [Databricks Delta Live Table](https://www.databricks.com/product/delta-live-tables) 也提供数据质量管理功能。增量实时表通过验证和完整性检查防止坏数据流入表中，并通过预定义的错误策略(失败、丢弃、警报或隔离数据)避免数据质量错误。此外，您还可以监视数据质量随时间的变化趋势，以深入了解数据的发展情况以及哪些地方需要进行更改。

在数据管道中包含数据质量检查和验证步骤始终是最佳实践，以交付高度可靠的数据。我将写另一篇文章，专门讨论在数据管道中嵌入数据质量检查。如果您想在文章发表时得到通知，请随时关注我。

## 数据模式演变

随着业务环境和需求的快速变化，数据模式(定义数据形状的蓝图，如数据类型、列和元数据)也相对快速地变化。好的数据管道应该能够灵活地处理数据模式的变化，同时保持数据质量。

*   数据质量的模式实施-为了维护和确保数据质量，模式实施是必要的，这意味着当数据工程师将数据(与预定义表的模式不匹配)写入和持久存储到目标表中时，写入将被拒绝，管道将失败。
*   针对管道灵活性的模式演变——正如刚才所解释的，期望数据模式一直保持不变是不现实的。您的数据管道应该足够灵活，允许用户轻松地更改表的当前模式，以适应随时间变化的数据。在执行追加或覆盖操作时，通常会使用模式进化来自动调整模式以包含一个或多个新列。

根据数据管道的性质及其支持的业务用例，数据工程师在创作数据管道时需要考虑模式如何变化。使用模式实施来维护数据的最高标准，并确保最高级别的数据完整性。模式演化通过使预期的模式改变容易自动发生来补充实施。

## 管道监控和可观察性

了解并记录管道的工作方式(包括审核日志、作业指标、数据质量检查、管道进度和数据沿袭)对于您找出错误的根本原因并快速恢复管道非常必要。良好的可见性和可观察性使您有信心将数据管道部署到生产环境中。

数据工程师可以利用工作流编排工具进行管道日志记录。大多数工作流编制器工具支持标准的 Python 日志记录级别——关键、错误、警告、信息和调试。它们通常还允许您通过配置自定义日志记录消息，使您能够更好地了解工作流的任务和作业。

此外，数据工程师还可以将工作流编排器与实时监控解决方案相集成，例如用于实时指标、关键警报和通知的 [Prometheus](https://prometheus.io/) 或 [Grafana](https://graphiteapp.org/) 。

如果您的数据管道是业务关键型的，并且具有极高的 SLA，那么实现健壮的日志记录和监控机制绝对是值得的。

## 错误处理和管道恢复

管道恢复不仅仅是修复错误和重新运行工作流。更重要的是，在修复错误时，您必须确保底层数据不会因为错误而损坏。例如，如果将数据写入目标位置的任务中途失败，根据存储位置和数据格式，这可能会非常棘手。如果您正在将数据写入一种提供原子性、一致性、隔离性和持久性(ACID)事务保证、数据快照隔离以及并发支持的数据格式，那么在写入数据阶段失败应该不会太麻烦，并且您可以安全地重新运行该任务，而不必太担心数据质量和可靠性。

[Delta Lake](https://delta.io/) 就是这样一种格式，它提供了 ACID 事务、可扩展的元数据处理，并在现有数据湖(如 S3、ADLS、GCS 和 HDFS)的基础上统一了流和批量数据处理。但是，如果您正在将数据写入没有这种数据可靠性保证的数据格式，则必须手动清理，然后才能重新运行失败的作业。

一旦确信数据质量不会因管道故障而受到影响，就可以利用以下方法进行错误处理和管道恢复。

*   首先是得到通知。为管道设置有意义的通知，以便在出现严重错误和失败时通知您。
*   第二，让管道在失败时自动重试。数据工程师可以定义重试次数，以及每次重试之间的时间间隔。
*   第三，当自动重试不起作用时，手动修复故障。为了能够快速修复错误，拥有足够详细的日志是非常必要的。

## 摘要

我希望这篇博客能为您提供一些有用的技巧，帮助您的数据管道更少出错，并以高度可伸缩和可靠的方式运行。下面是一个快速总结，作为一个清单:

*   检查您的管道是否能够自动扩展以处理数据量波动；
*   检查是否可以调整调度/触发频率来处理数据延迟方面的需求变化；
*   了解数据质量预期，确保在管道中验证这些预期，并报告关键的数据质量违规情况；
*   了解数据模式将如何发展，并在管道中为模式实施和模式发展建立机制；
*   我建议至少要有一些监控和可观察性。当然，取决于你的数据管道的 SLA，SLA 越高，应该安排更有力的监控和可观察性；
*   当出现管道故障时，首先检查并了解原因是否是底层数据损坏，以及是否存在任何数据质量问题。如果是，在重新运行管道之前清除损坏的数据是非常重要的；
*   最后，了解管道的根本原因，并内置一些自动管道恢复，如重试；

如果你想在有新博客发表时得到通知，请随时关注我。我一般每周都会发表 1-2 篇关于数据和 AI 的文章。

如果你想看到更多围绕现代高效数据+AI 栈的指南、深度潜水、见解，请订阅我的免费简讯— [***高效数据+AI 栈***](https://yunnawei.substack.com/) ，谢谢！

注:以防万一你还没有成为媒体会员，并希望获得无限制的媒体访问权限，你可以使用我的[推荐链接](https://medium.com/@weiyunna91/membership)注册！我可以免费给你一点佣金。非常感谢你的支持！