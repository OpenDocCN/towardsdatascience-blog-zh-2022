# 因果推理完全指南

> 原文：<https://towardsdatascience.com/a-complete-guide-to-causal-inference-8d5aaca68a47>

## 你一直忽略的问题汇编，以及如何正确处理

![](img/741baccc59ccc6770115fc5b82b20e5c.png)

达维德·利伯拉德斯基在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

**我们为什么需要因果推理？**

将测量转化为行动是任何智能系统的核心。数据科学的核心是使用大量的定量测量来采取行动。在私人技术领域，这些*测量*是用户的活动，我们可以采取的*行动*是商业行动。我们的业务活动范围广泛，从一般战略方法的内部决策，到直接影响客户的决策，如新产品或改进产品、功能、建议或定价。

数据科学的艺术和科学在于如何正确使用我们的测量来推断正确的行动。如果你曾经这样做过，你就会看到我们必须采取的信念的飞跃。它通常看起来像这样，“嗯，我们知道这一组客户有这个结果，所以让我们把更多的客户放在类似的情况下，以实现类似的结果。”这种信念的飞跃何时实现？数据科学家推荐的行动何时会真正产生预期的结果？

为了对信念的飞跃充满信心，我们必须承认，我们将数据分析转化为商业建议的旧方法有点幼稚。我们听说相关性不是因果关系，但我们实际上忽略了这一区别。充其量，我们承认我们不确定，多挖一点，或者将我们的结果与直觉进行比较，以建立对我们结论的信心。但是这种得出结论的无组织的狂野西部容易受到偏见的影响，尤其是如果我们不确切知道我们在做什么的时候。

**什么是因果推断？**

幸运的是，人们一直在研究这个基本问题:什么是因果关系，我们如何知道 A 何时引起 B？

这个领域的关键人物之一，Judea Pearl 经常重申理解因果关系是做出好决策的关键。他开发了一个 3 级系统来理解简单观察之间的关系，并真正理解因果关系:

**第一层，关联**，是关于统计可以衡量的所有关联。这第一个层次包括条件概率、相关性，甚至所有的机器学习，包括神经网络，允许我们从其他数据中“预测”一些数据。

历史上，每个领域的人都使用这些模型来做决策。据说，在第一周完成入职的客户“更有可能”避免第一年的流失，当时衡量的只是相关性或条件概率，而不是因果关系。大多数人还在这样做。

**朱迪亚·珀尔的第二层，干预**，掌握着我们想要回答的问题。如果我们采取 X 商业行动，那么会发生什么？如果我们给顾客打折，他们会呆多久？如果我们增加这项新功能，客户 LTV 会有多大变化？

如果我们知道所有的 2 级答案，我们就可以做出所有的最优决策(在我们认为要考虑的选择范围内！)

最后，**第三级问题是对一个系统的因果关系**的全面理解。即使我知道 LTV 会发生多大的变化，我能理解**为什么**吗？等级 2 是关于任何原因的*结果，等级 3 是关于任何结果*的*原因。如果我们能看到发生的任何事情，并完全理解它发生的每一个原因，那么我们就能很容易地回答任何第二级问题，而不仅仅是我们试图估计的答案。*

事实上，回答 2 级问题通常是我们在技术领域进行因果推理的直接目标。那么应该怎么做呢？

**因果推理的一般方法**

每个项目都暗中近似一个因果推理问题。数据科学家所做的一切都是某种形式的决定，即应该对系统进行什么样的改变，以获得用户/客户的最佳结果。

在第 1 级方法中，我们通过一些量化来查看行动和结果指标之间的关联，而不考虑其他因素。有人称之为粗略估计，或方向正确。当然，正如幽灵般的辛普森悖论向我们展示的那样，这可能是完全错误的。

因果推断的关键事实是:**对于系统中可能影响测量结果(直接或间接)的任何协变量，您必须确保您的治疗+对照组具有相同数量的这些协变量。**

例如，如果你想知道一种药物对一种疾病的效果，你当然需要一组服用该药物的人，而另一组不服用。无论这是通过随机试验还是仅仅观察人群的当前行为，当你比较这两组人时，你需要他们在各方面尽可能相同，除了他们是否服用药物这一事实。

在随机试验中，你会给另一组服用安慰剂，这样两组人都同样地认为他们服用了药物，因为他们的信念会影响他们的结果(无论是直接还是通过他们的行为)。无论是否是随机试验，你都必须确保两组都有相同的性别比例(如果性别以某种方式影响可测量的结果)、遗传倾向等等。

正如朱迪亚·珀尔提醒我们的那样，为了正确地做到这一点，我们真的需要一个我们整个系统的模型。我们想知道影响谁接受治疗的所有因素，结果是什么，以及所有相关的事情。该模型的结构是 DAG(有向无环图),它可以向我们显示相关的变量，以及与它们相关的边的方向。(例如，咖啡机的压力会影响气压计，但气压计不会影响咖啡机的压力)。

我们至少要注意哪些变量是混杂变量(直接或通过其他关系导致治疗和结果)、介体变量(治疗导致结果的途径)以及由治疗或结果导致的变量。

我们需要这个信息，因为我们 ***确实想要控制*** 的直接和间接混杂因素，因为不控制它自然会使我们的结果产生偏差，就像在辛普森悖论中一样。然而我们 ***不想控制*** 作为中介或效果，因为那样控制会使我们的结果产生偏差。

这些在 Dag 中正确控制变量的规则称为 d-分离，当数据生成过程的真实因果模型包含相互影响的变量(双向箭头)、本身是原因但也充当其他原因的中介的变量以及其他复杂结构时，就会产生问题。

例如，一个帐户拥有的联系人数量可能会直接影响留存率，因为没有联系人的帐户在社交平台上提供的价值更低(例如，新闻订阅源中有趣的帖子更少，可以获得的关于受众的信息更少)。此外，联系人的数量也可能影响用户在平台上采取行动的数量，因为每个联系人都给他们采取行动的机会，而平台上的行动数量也可能直接影响留存率(因为积极使用平台的用户不太可能流失)。

因此，接触的数量可能直接影响保持，也可能通过每种行为的数量的中介影响保持，因为这些行为直接影响保持。那么，我们应该把这两个变量作为混杂变量来处理吗？如果我们这样做，我们将测量什么？通常，我们必须根据我们对哪些因果路径更重要的猜测来做出选择，并且我们必须记住，我们的测量是对一组特定的因果路径的测量，这些路径可能比我们想要测量的路径更多，或者比我们想要测量的路径更少(如果我们想要增加更多成员的效果，我们需要允许它影响所有路径，因此我们不应该控制动作的数量)。

确定 DAG 的另一个棘手的方面是，具有不同因果关系 的个体的任何 ***子集都算作一个因果变量。例如，如果性别导致某些身体特征改变了不同治疗/结果的可能性(如乳腺癌)，那么它就被视为该治疗/结果的原因。同样，如果性别导致了一些影响其在治疗/结果组中出现频率的社会心理环境(例如，女性比男性更多地注册了女性杂志)，那么它就是该治疗/结果的原因。***

此外，我们可以用代理变量来表示因果系统中的任何变量。有争议的是，我们总是使用代理变量。我们不知道 ***用户的年龄或性别，但是我们会问他们，用他们的回答来代表真相。同样，我们不知道他们对产品的感受和动机，但我们可以用他们的调查答案来代表事实。我们可以用他们的参与度来代表他们与产品的关系。这样的例子不胜枚举。在因果 DAG 中，使用变量的直接影响作为它的噪声测量总是没问题的。你可以想象一个箭头从每个变量指向它的可测量的代理，但是没有必要把我们的图片复杂化——我们总是使用代理测量。***

**推断因果关系的框架**

一旦我们建立了系统中可测量变量之间非零因果关系的试验性模型，并确定了作为混杂变量的试验性变量集，我们就可以进行因果推理了！

**我提出了这个因果推理过程的框架。**

**包括 4 个步骤:**

1.  **随机实验**
2.  **观察修剪**
3.  **协变量建模**
4.  **成果衡量**

随机实验是 A/B 检验(或随机对照试验)，我们知道它在估计治疗变量的因果效应时非常有用。删减是指删除我们不想包含在测量中的数据的过程。建模就是描述每个协变量对结果的影响。最后，测量是关于观察治疗组和对照组之间的差异，并确定其范围、可靠性和显著性。

前三步中的每一步都可以跳过。我们可以进行因果推断，不需要随机分配，不需要删除最差的数据，也不需要对协变量的影响进行建模。然而，我们几乎肯定应该至少完成这三个步骤中的一个。理想情况下，利用所有的步骤将会得到最好的结果。

因果推断通常指的是准实验，这是一种在没有步骤 1 的随机分配的情况下推断因果关系的艺术，因为 A/B 测试的研究包括使用步骤 1 的项目。但是我在这里要强调的是，这个框架适用于**所有有或没有 A/B 测试**的因果推理项目。

(是的，即使做 A/B 测试也要考虑剪枝建模！我们将深入了解原因和方法。)

![](img/9351848eb328f87907eeff666af8bd82.png)

[engin akyurt](https://unsplash.com/@enginakyurt?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

# **第一步:随机实验(A/B 测试)**

**A/B 测试并不完美**

回到随机对照试验(RCTs)的话题，或者在技术领域被称为 A/B 测试，我们可以开始理解为什么它们在因果关系领域几乎是神奇的。通过随机试验，我们可以确保治疗组和对照组不会因为任何可能影响结果的协变量而以有偏见的方式分配。

平均而言，*治疗组和对照组具有相同数量的每种性别、每种素质..每一个混杂因素。*我们没有错误地控制任何影响，因为治疗和控制分配发生在治疗发生之前，所以我们不将其影响包括在治疗分配中。**

**但是，随机对照试验并不完美。平均而言，治疗组和对照组的每个混杂因素 ***数量相等，这意味着什么？*** 这真是 RCTs 的肮脏秘密。这意味着，如果你重复这个实验无数次，每组中混杂因素的平均数将是相等的。但是它 ***并不意味着在你的实验中混杂因素是相等的。平均而言，*** 相等，这种方式使得它成为一个**无偏的度量。****

**但是，成为一个公正的衡量标准并不意味着你就是一个最优的衡量标准。**

****封堵更好****

**如果性别影响我们的结果，并且你随机分配的治疗组比你的对照组有更大比例的女性，那会影响你测量的结果吗？当然是了！您测量的治疗组和对照组的结果差异部分是由于这两个组的女性比例不同！因此，实验中治疗的因果效应会被实验的不平衡协变量(如性别)所扭曲。如果你重复这个实验很多次，你测量的平均因果效应将确实是正确的(不像如果你没有 RCT，平均值将是不正确的)，但是你的实验的测量是倾斜的。**

**因此，尽管 RCT 给了我们一个无偏的度量，在某种意义上说，许多假设的实验都趋向于真实，但我们在实验中有一个**可修复的**误差源，即我们的协变量不平衡。一种方法是将其固定为分层/分组随机试验。这里，我们确保治疗组和对照组有相同数量的协变量。我们不是把所有人平均分配到每个治疗组，而是把所有女性平均分配，然后把所有男性平均分配，等等。**

**那么两组之间有相等的协变量！由于要考虑许多混杂的变量，我们需要从变量的组合中进行分层。如果我们关注性别和他们的年龄是否超过 40 岁，那么我们有 40 岁以上的男性和 40 岁以下的男性，40 岁以上的女性和 40 岁以下的女性，等等。这些层中的每一层必须在每个治疗组之间平均分配。**

**从统计学的角度来说，这会产生什么？治疗变量的偶然效应的测量已经是无偏的，但现在它将更加准确:它将有一个更小的方差。也就是说，如果我们多次做这个实验，我们的治疗效果的测量将仍然是无偏的，并且那些测量将具有比简单 RCT 更低的方差。**

**如果可以的话，做一个封锁的 RCT 吧！**

****Bin 连续变量启用阻塞****

**这是我们第一次提到每列数据的类型。想一想你的 DAG 中的节点，你已经选择将它们包含在你的因果推断中，你知道这些变量会影响结果。每一个都可以是连续的、有序的或分类的。有序变量和分类变量在分层方面可以被同样对待，但是连续变量呢？**

**如果我们想对我们的试验进行分组随机化，我们需要将连续变量绑定到范围中，这样我们就可以将每个范围转化为在治疗组之间平均分配的分组。**

**宁滨一个连续的范围可以用许多方法来完成。这里我们选择一个混杂变量的表示，所以我们想要捕获一个分类表示，其中连续变量的值在每个类别内不会有太大的变化。当然，箱的数量越大，箱内连续值的范围就越大，不会对结果产生太大影响。但是太多的箱子意味着太多的层。**

**Scikit-learn 的 KBinsDiscretizer 有一些方法，比如将数据均匀地分类到 k 个箱中(按分位数拆分)，均匀地分开设置 k 个边界，或者对数据使用一维 k 均值聚类。实际上，结合查看连续数据样本的直方图和思考领域知识，可能是选择如何对其进行分组以进行块随机试验的最佳选择:**

**如果直方图有明显的峰，这些可能是好的面元。如果它是一个非常偏斜的分布，您可能希望以几何或对数的方式分割，如宁滨每个数量级(因子为 10)。**

**稍后，我们仍然可以对连续变量进行建模，因此我们不一定需要对其进行装箱，但在连续变量的装箱版本上阻止随机化我们的试验可能是一个好主意。**

****功率和样本大小计算的强制位****

**如果我不多说一点关于进行适当的随机实验的事情，那就是我的失职。**

**首先，只有当你有足够大的样本时，你的结果才具有统计学意义。嗯，这是概率性的，所以真实的情况是，样本量越大，你就越有可能发现某种影响，如果它确实存在的话。对于一个特定的效应大小，你可以计算出你需要多大的样本量，以确保你能检测到一个效应，如果有效应的话。我们称这些元素为功效、效应大小和样本大小。**

**让我们用两个独立样本的 t 检验来讨论这一现象，因为它可能需要对更复杂的模型和测量进行一些修改。从频率主义者的角度来看，我们考虑一个零假设，即治疗组之间的差异为零。如果这个零假设为真，并且我们以无偏的方式重复测量组间的差异(做了很多无偏的实验)，那么我们将得到的测量值将平均为零，并形成具有一些方差的正态分布(即中心极限定理)。测量方差将与样本大小成反比。我们将基于该分布绘制 alpha 阈值(例如，对于假阳性率为 5%的双尾 alpha，我们可以寻找正常 CDF 为 0.975 的位置，这是 1.96 个标准差)。**

**然后，我们还考虑了处理组之间存在差异的世界，这样，在许多实验中差异的测量将是相同的正态分布，但具有非零均值。这个非零均值，即这两个高斯函数的均值之差，就是效应大小。在这个世界中，只有当我们的度量超过第一个分布的 1.96 个标准偏差时，我们才会拒绝零假设，所以我们需要第二个分布上的点的位置距离第二个分布的中心有一段距离，这样，如果第二个分布为真，我们将有 P 个机会正确拒绝零假设。这里的 p 称为幂，它是第二个分布下的面积，位于第一个分布的 1.96 个标准差的右侧(假设双尾 5% alpha)。典型的幂数是 80%，在正常的 CDF 上，它与中心有 0.84 个标准偏差。因此，两个正态分布的平均值必须相差 1.96+0.84 个标准差。使用将 z 得分与效应大小、方差和样本大小(的调和平均值)相关联的双样本 t 检验方程，我们发现这种 5%α、80%功效标准情景所需的样本大小约为:**

**N = 16 *方差/效应 _ 大小**

**TL；对于具有 80%功效和双尾 5%α的双样本 t 检验，上述公式给出了作为组内个体观察值方差函数的样本大小，以及组间效应大小。我们倾向于称之为最小效应大小——我们将有 80%的能力来检测最小效应，甚至更多的能力来检测任何更大的效应。**

**根据标准偏差与最小可检测效应的比率，该公式的一些经验法则如下:**

*   **10 倍比率->每组需要 1600 个样本**
*   **100 倍比率->每组需要 16 万个样本**
*   **1000 倍比率->每组需要 16M 样品。**

**作为一个合理的例子，如果我们有一个标准偏差为 50%的度量，例如平均购买价值为 80 美元，标准偏差为 40 美元，我们关心的是检测治疗组之间 0.5% (40 美分)的影响，那么我们的比率是 100 倍，因此我们需要每组 160，000 个样本。**

****样本量修改****

**我们说过，当我们进行一个随机分组试验时，我们得到的测量结果的方差较小。我们将最终合并每个阶层的测量值，最终确实会得到一个较小的方差，这可以让我们用相同数量的样本检测到较小的影响，或者说，我们可以用较少数量的样本检测到真实的影响。为了更好地衡量每个阶层，我们需要足够的样本。**

**最起码，我们需要在每个治疗组的每个阶层中至少有一个测量值。这个原则叫做积极——如果没有例子，我们就无法衡量效果。实际上，我们需要大量的测量，以便我们可以合理地估计观察总体的方差，并使总体实验结果的不确定性小到足以使我们的效果显著。这意味着我们需要足够的样本来分析每一层。每个阶层的“足够”是基于该阶层内的人口方差。**

**因此，我们需要每一层的许多样本，每一层需要不同数量的样本。如果我们做一个简单的随机对照试验，那么每一个阶层只会出现在整个样本组中。如果试验中只有 1%的人超过 60 岁，那么我们可能不得不扩大整个样本的规模，以获得足够多的 60 岁以上的人来很好地衡量这一部分。然而，在一个区块实验中，我们将明确地选择我们想要的任何数量的 60 岁以上的人，并且我们将分别选择我们想要的任何数量的人。因此，我们可以扩大一个阶层而不扩大另一个阶层，保持我们的总样本量下降。这对于一些实验是有帮助的(尽管对于其他实验可能没有帮助，在其他实验中，我们只是简单地运行几个星期的试验，然后等待每个阶层都有足够多的人)。**

**一般来说，我们可以将估计的必要样本量乘以各种因素，通常称为**设计效应**，以考虑任何因素。如果我们想从单尾测试到双尾测试，多找 20%的人。如果我们有一些缺失的数据，那就找更多的人。我们还需要更大的样本量来检测相互作用效应，主要是一个阶层的治疗效应。**

**我们还需要更大的样本量来进行最后一种随机试验，即整群随机试验。**

****网络效应****

**我们说过这是一个全面的指南，不是吗？所以我们来谈谈网络效应。**

**本质上，随机试验应该满足稳定单位治疗值假设(SUTVA ),即治疗不影响对照组个体。然而，在我们这个相互联系的世界里，这个假设可能会被违背。**

**对照组的人可以认识治疗组的人，这可以让他们接触到治疗组的知识、经验、信念、行为、资源等。这降低了实验中对照和治疗结果之间的差异，因此相对于真正单独的对照，测量的效果低估了治疗的真实效果。**

**另一个违反 SUTVA 的情况正好相反——资源是有限的，所以如果治疗组使用不同数量的资源，那么这会影响对照组可用的资源数量。这将增加实验中处理和对照之间的测量差异，从而使实验高估了处理效果。**

**我们试图通过将治疗组和对照组分开来解决这个问题。根据不同的情况，我们可以在地理上(治疗组在一个城市，对照组在另一个城市)，时间上(治疗组在一个日期/时间，对照组在另一个日期/时间)，或者通过朋友组(切割到一个社交网络图，留下彼此联系最少的组)。**

**根据我们如何分析实验结果，我们可能需要更多的样本量来补偿实验结构。传统的方法让我们将每个集群视为一个单元，因此集群将被计算在样本大小 N 中——N 个集群而不是 N 个人是一个更大的样本大小！**

**较新的方法将保留单个观察值，并在建模阶段包括它们的聚类，以将聚类的效果与治疗的效果分开。因为观察值是通过它们的聚类相关的，所以在这个意义上它们不是独立的样本，我们需要更大的样本量来补偿。**类内相关性(ICC)** 是衡量类内与类间样本相似程度的指标，将决定我们需要多少额外样本。我们将样本大小乘以的设计效应因子是 1+ ICC*(N-1)，其中 ICC 的范围是从 0 到 1。**

**让我们进入下一阶段。**

**![](img/11e94c0e8ef757ea4d27569bfc95423f.png)**

**由 [Georgie Cobbs](https://unsplash.com/@georgie_cobbs?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄**

# ****第二步:修剪****

****修剪的问题****

**修剪数据是指我们在进行分析之前删除数据点。这是一个有争议的话题，而且理由很充分。剪枝标准的灵活性意味着研究人员可以尝试许多剪枝启发式方法，直到他们得到他们想要的结果(这种在科学中作弊的方式有时被称为 **p-hacking)** 。为了解决这个问题，让我们首先指出两点:**

1.  **你的分析应该在做之前就计划好了。研究人员最近在 arxiv 上发布了他们的分析计划，这样他们就可以公开负责执行一项没有经过调整以获得预期结果的分析。**
2.  **如果你确实考虑了几种不同的策略，那么你必须在结果的方差中考虑它。p 值阈值需要被校正，以保持真实的假阳性率与您声称的阈值一致，因为您实际上正在运行不止一个实验。我们稍后将深入探讨 p 值校正。**

**接下来，让我们通过讨论选择正确的数据来更深入地理解修剪。**

****当我们修剪时，我们在做什么？****

**修剪离群值是常见的做法，但是我们为什么要这样做呢？当我们看到一个异常值时，我们知道它会打乱我们的测量，尽管它是一个均值或模型。但是为什么保留离群值是不对的呢？**

**从根本上说，我们是在说，我们不想对产生这种离群值的现象进行建模。如果离群值是针对坏数据收集的，那么我们说我们不希望我们的模型包含坏数据收集。或者，如果离群值是一个真实但很大的数字，就像房价数据集中的巨型房屋，那么我们是说我们不希望我们的模型包括巨型房屋。**

**如果我们的目标是因果推断，那么我们必须清楚我们在推断什么。如果数据是由我们不想建模的原因产生的，那么我们应该删除它。数据不需要成为离群值来符合这个定义。任何来自我们不想建模的不同来源的数据，或者关于我们不想建模的人群子集的数据，都应该被排除在外！**

**这个概念与我们混淆变量的概念完全一致。事实上，统计模型中“概括”到测试人群的“概括”概念通常是对与我们的测试人群相同的原因进行建模。如果我们的数据集/训练数据在某些关键方面不同于我们的测试数据/一般人群，如不同的时间、不同的地点或不同的人口分布，这些都是我们在模型中没有正确捕捉到的混杂原因。模型不能概括很大程度上是一个混淆变量的问题。为了回答我们想要回答的问题，我们必须使用正确的数据来模拟正确的原因。**

****让我们修剪吧！****

**首先，欢迎你参加你的常规修剪练习。坏数据当然应该被修复或删除，不客气地说，“我不想对这些极端情况建模。”如果你去掉了前 10%的数据，那么就明确地说你在为后 90%的人建模。如果你剔除 500 万美元以上的房子，那么就说你的模型不适用于这些房子。有时，为每一种制度制定不同的模式是一个很好的解决方案。(例如分段回归)。**

**现在让我们用这些因果推理概念来扩展你的修剪练习。在随机试验中，我们希望治疗组和对照组具有相同数量的影响结果的每个协变量。在一个简单的随机试验中，我们接近了，但不完全是。如果没有随机试验，情况会变得更糟。如果我们只是从人群中获取数据，一个准实验，那么协变量在每个治疗组之间可能是极不平衡的。**

**所以，我们可以通过忽略一些测量来模拟一个更加可控的实验。我们可以只保留测量的子集，这样我们选择的数据在得到治疗变量的每个值的人群子集之间有相等的协变量。**

**例如，如果我们想看看父母的收入对孩子收入的直接影响，我们可能需要控制变量，如他们居住的州。我们不能在这里做任何类型的随机试验，因为我们不能设定父母的收入。**

**要了解这为什么会是一个问题，考虑不同州的一般人群不成比例地有不同的收入，所以如果州独立居住影响孩子的收入，那么在一般人群中，父母收入高的家庭通常会生活在高收入的州，这将使孩子的收入有偏差(将父母收入和州的影响结合到我们的测量中，当我们只想测量父母收入的直接影响时)**

**因此，我们可以选择数据，使父母的收入组在每个州平均分配。在我们删减的数据中，每个州的高收入父母与低收入父母的比例应该是相同的。这样，我们就不会把父母收入的影响和居住状态的影响混为一谈。**

**让我们深入了解如何做到这一点的细节**

****匹配****

**无论我们有一个还是多个重要的混杂因素，都有一些好的方法来删减数据。许多修剪技术依赖于某种形式的**匹配**——我们将每个治疗观察与具有非常相似混杂因素的对照观察进行匹配。**

**只要有一个混杂因素，我们就可以将治疗观察结果与具有最相似混杂因素值的对照观察结果进行匹配。如果我们有多个混杂因素，那么在选择最佳匹配时，我们必须同时考虑混杂因素的多个维度。**

**由于我们的混杂因素可以是连续的，也可以是分类的，我们必须对这两种情况都有解决方案。**

**如果我们的混杂因素是连续的，我们可以将治疗观察值与混杂因素之间的“距离”最小的对照组相匹配。这叫做**马氏距离匹配。**您可能应该重新调整混杂因素，使混杂因素在单位距离内同等重要，这样我们就能匹配到最接近的值。实际上，我们应该根据每个混杂因素对结果测量的影响程度来衡量。**

**如果我们有明确的混杂因素，或者把连续的混杂因素分成不同的类别，我们可以再次进行分层(混杂因素的每一种可能的组合)。我们可以删减数据，直到我们从每个层的每个治疗组中得到相同数量的数据点。我们也可以只移除不存在任何治疗组的层中的所有数据点(在该层中有 0 个数据点)，并允许在每个层中存在不平衡的治疗与对照——然后我们可以对我们的数据点进行加权，以在层中有效地平衡。这叫做**粗化精确匹配**。**

**我将简要说明因果推断中的另一种常用方法是**倾向匹配**。我们将在后面讨论倾向得分，因为在这里我只说基于倾向的修剪是不推荐的。倾向本质上涉及将多维协变量投影到单个维度上，结果是基于更少的信息，因此严格来说比基于阶层的修剪更差。它有时被推荐为解决维数灾难和对阳性的需求(如果有许多混杂因素，很难从每个层次的每个治疗组获得数据)。例如，如果存在例如 n 个混杂因素，每个混杂因素具有 k 个水平，则存在 k^n 层)。参见 https://www.youtube.com/watch?v=rBv39pK1iEs Gary King 关于为什么不值得的讨论:**

****用于修剪的分类数据表示****

**让我们再来看看数据类型的问题。我们只能对分类变量进行粗化的精确匹配，所以这可能是我们绑定一些连续变量的时候了。对于给定的变量使用更多的箱将意味着更好的分辨率，但也可能迫使我们删除大量的数据，因为我们需要在该变量的每个箱和所有其他变量的每个箱的每个组合内，来自每个处理组的至少一个样本。一般来说，宁滨变量在 5 倍左右是正常的，但这取决于你的样本大小。看看你被迫删除了多少数据，这是数据仓数量的函数。**

**此外，如果你的混杂因素更复杂，宁滨分类最终将是一个必要的步骤。例如，你的一个混淆对象可能是文本、音频或图像数据！我们可能正在查看一个社交平台，并希望了解社交沟通的某些方面的治疗效果，但我们需要控制沟通本身的内容，即控制帖子/消息的语言，或其图像或视频！在这种情况下，我们将需要一个有意义的，简单的高维数据表示，以便进行因果推理。**

**为了将它包含在粗化的精确匹配中，我们需要一个相对低维的表示，以保持合理的块数，这样我们就不会删除太多数据。基于情绪/情感和语义主题，自然语言数据可以被分成少数类别。**

**接下来，让我们进入第 3 步，在这里我们显式地对每个变量的影响进行建模。**

**![](img/17c1bb6c6ad2ee8d68a2cab01930d6d2.png)**

**照片由 [STIL](https://unsplash.com/@stilclassics?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄**

# ****第三步:模拟混杂因素****

**重复我们关于修剪的讨论，我们实际上不需要数据集/训练数据具有与测试数据完全相同的协变量平衡。我们只需要 ***知道*** 所有影响结果的混杂因素，并以某种方式“控制”它们。**

**即使我们的训练数据是 10%的孩子，而我们的测试数据是 90%的孩子，如果我们已经完全模拟了作为一个孩子的影响，我们可能会做出完美的预测。**

**建模可以通过多种方式完成。我们可能会认为我们应该关心模型的可解释性。毕竟，关于模型可解释性的讨论本质上是关于因果关系的——我们想知道为什么我们的模型预测了结果 y。哪些特征在预测中发挥了最大的作用？**

**一般来说，我会说这些关于可解释性的讨论取决于不知道我们应该把哪个变量作为我们的治疗变量。如果我们想考虑每个变量的因果关系，同时使用所有其他变量作为对照，那么是的，可解释性是极好的。我们可以使用简单的线性回归，将所有系数解释为每个变量的因果效应(我们将更严格地讨论这一点)。然而，我们知道多重共线性会增加复杂性，考虑到我们的因果系统的 DAG 模型，我们应该关注“将所有其他变量视为混杂因素”是否合适。**

**但是，如果我们确实知道我们想要分析哪个变量作为治疗方法(当然，如果我们进行随机实验，这已经设置好了)，那么是时候进行适当的因果推理建模了。**

**关于随机实验，我们可能仍然希望包括建模。在一个简单的随机实验中，我们的协变量并不完全平衡。如果我们不通过修剪和加权来处理这个问题，那么我们可以在建模中处理它。**

**对于一个随机区组试验，我们可以潜在地测量每一层而不需要任何建模，因为协变量是完全匹配的。然而，我们可能只屏蔽了一些协变量以降低维度，因此我们可以在单个模型或每个阶层的模型中对其余的协变量进行建模。或者，如果我们的分块是基于一个真正的连续变量的宁滨，那么我们可能希望用一个模型为每个阶层的连续变量建模。**

**最后，对于整群随机试验，如果我们想使用个体观察，我们需要使用建模，因为整群是一个额外的混杂因素。**

****元学习者****

**元学习者框架允许我们以同样简单的方式使用任何任意复杂的 ML 模型来衡量治疗效果。s，T 和 X 学习器允许我们将任何机器学习模型翻译成因果推理机。**

**最简单的框架是 S-learner。首先，我们根据我们的数据训练任何模型，使用治疗和协变量来预测结果。可能是回归，随机森林，kNN，助推机，神经网络，随便你说。**

**然后使用我们的模型，我们获取数据，用一个治疗组的值替换所有的治疗变量测量，并使用该模型预测结果。这些作为我们对治疗组的观察。然后，我们对每个治疗组重复上述步骤。Viola 就像一个实验，人工生成的数据在每个治疗组中都有相同的协变量——几乎每个观察都在每个治疗组中重复，只有治疗发生了变化。每组的平均值之间的差异是我们的 ATE(平均治疗效果)的量度。**

**我们还可以通过简单地只查看给定条件下的观察值来获得 CATE(条件平均治疗效果)。如果我们想要男性的治疗效果，我们可以在进行 S-learner 过程时只查看男性的观察结果。**

**t 和 X 的学习者用一些更强大的控制方式重复这个问题——比如为每个治疗组训练一个模型，并根据模型预测的测量值之间的误差训练额外的模型。这些元学习者都基于这样一种理解，即我们正试图测量**反事实**，这是如果给定的观察结果只*改变了*他们的治疗组会发生的事情。**

**有了这些知识，我们可以跳回解释线性回归为因果关系。事实上，如果我们在 S-learner 框架中使用线性回归，那么治疗组之间的平均差异就是治疗变量前面的系数，因为其他所有变量都减为 0。**

**因此，如果回归中的其他一切确实是适当的混杂因素，并且我们已经测量了所有混杂因素，并且线性模型捕获了所有变量之间的完整关系，那么这个 S-learner 是因果效应的良好测量。**

**但是现实并不美好。**

****异源治疗效果和相互作用****

**好的建模意味着尽可能准确地评估我们的系统。如果每个变量与结果线性相关，并且每个变量对结果的影响完全独立于其他变量，那么简单的线性模型才是好的模型。你的系统是这样吗？**

**就因果推断而言，**现实往往具有异质的治疗效果**——这种治疗是其他变量的函数。也就是说，接受治疗的人决定了治疗的效果。例如，根据人口统计、健康状况、地理位置、知识水平或目标，治疗可能对人产生不同的影响。**

****现实也有混杂因素之间的相互作用。**性别等混杂因素对结果的影响可能是年龄的函数——也许年轻女性比任何其他年龄和性别的女性更倾向于更好的结果，但老年女性实际上更倾向于任何年龄和性别的最差结果。在这种情况下，线性相加年龄和性别的贡献不会捕捉到这一现象**

**概括地说，每个变量对结果的影响可以是任意非线性的，也可以是任何其他变量的任意函数。**

**我们可以使用复杂的模型进行因果推断，这是一件好事。**

**这里我要说明的是，我们也可以使用许多模型。没有必要用一个单一的训练过的模型来代表一切。为不同范围的输入值训练不同的模型通常是个好主意。如果我们有一些阶层，每个阶层的不同模型可能会很有帮助。**

**对每个层使用不同的模型有很多好处:我们可以允许每个层的模型的一般形状，甚至类型完全不同。此外，每个模型本质上都捕捉了定义该层的类别和被建模的变量之间的异质和交互术语。**

**例如，如果我们有一个 40 岁以下女性的阶层，在这个阶层中，我们有一个包含年龄(作为连续变量)、治疗以及她们是否是新使用者的模型，那么我们将捕捉治疗仅对 40 岁以下女性的影响，这是一个异质效应，我们还将捕捉连续年龄和新使用者对 40 岁以下女性的影响，这是一个交互效应。**

**选择使用多种模型也有不利的一面。首先，每个模型的数据会更少。如果我们有一个包含所有这些相互作用项的单一模型，情况可能会更糟，因为训练模型所需的数据与项的数量呈超线性关系。但是，如果我们有一个单一的模型，有一组更有限的相互作用项，我们可能有更多的每项数据比每层模型的方法。**

**此外，如果我们有一个单一的模型，它通常建议包括主要影响(非相互作用的条款)，每个阶层将有助于该项目的平均估计。但是在每层模型方法中，这一方面是缺失的。**

****照常提取特征****

**好的机器学习规则仍然适用。如果我们保持我们的一些数据连续，那么我们需要尝试建模它与结果变量的关系，就像任何 ML 一样。虽然基于决策树的模型(forests，GBMs)将为我们处理连续数据，并且神经网络可以学习任意函数，但一些更简单的模型需要我们的帮助。我们可以从我们的数据中提取新的特征，方法是对连续变量进行多项式拟合，计算它们的比值，或者使用其他特征提取/降维技术来创建新的特征(PCA、ICA、RBF 核等)。).**

**像在 ML 中一样，如果必要的话，我们应该考虑缩放特性。任何使用距离度量(kNNs、RBF 核函数)的方法都应该具有重定比例的要素，以便距离对每个要素的价值是相等的(或者在您认为合适的时候随意重定比例)。如果我们使用正则化，我们也可能会重新缩放，这将在后面讨论。**

**将连续变量宁滨成分类变量，或者更确切地说是顺序变量可以有助于正确地对域建模。**

**在连续变量的线性模型中，我们需要使用多项式和比率来捕捉任何非线性关系。然而，如果我们绑定一个连续变量，我们的一个热编码将迫使我们至少学习每个绑定和结果变量之间的恒定关系。如果我们把它映射回我们最初的连续变量，这就像学习一个分段常数函数。对于足够多的片段，这可以让我们找到比显式建模的连续变量更复杂的关系。**

**例如，如果我们将用户的社交联系人数量分成几个部分，那么我们可能能够测量出连续体中有多个波峰和波谷——也许 0 个联系人会导致最高的保留率，因为人们会忘记他们的帐户，而 1-5 个联系人则不好。然后，也许 6-25 个联系人也是好的，因为他们使用该平台与同学交流，但 25-200 个联系人是不好的，因为他们所有的薄弱联系都会在 feed 中产生噪音，而拥有 200 个以上的联系人是好的，因为这些用户正在使用该平台开展业务。**

**宁滨连续变量同样可以帮助我们建模异质和相互作用的关系。如果我们将变量 X 分成 5 个箱[X1…X5]，那么我们可以用 X1 和处理 X1*T 的乘积、X2 和处理等来创建项。或者 X 和另一个混杂因素之间的区别。这再次启用了这些交互的分段模型，这提供了很好的灵活性。对于连续变量，我们需要考虑 X 上的比率和多项式与其他项的乘积，这在指定错误的结构时会更加复杂。但是要看你的域！**

****我们如何选择合适的模型？****

**我们说过，有了元学习者框架，我们可以使用任何类型的 ML 模型，我们现在也在考虑一些交互/异质术语，以及为不同的体制训练不同模型的选择。**

**那么，我们如何找出正确的建模方法呢？**

**好吧，考虑一下，我们只是想要一个能准确捕捉我们系统的模型。这似乎与典型的偏差-方差权衡没有本质区别。这并不奇怪，因为我们说过模型泛化与正确建模我们系统的因果关系有很大关系。**

**如果我们可以找到一个具有高泛化精度的模型，那么我们可能已经相当好地模拟了我们的因果系统——如果任何可测量的变化都导致可预测的结果，那么我们就理解了我们系统中的力量，至少在测试数据探索的范围内。**

**所以，我们感兴趣的是通常的——一个测试分数很高的 ML 模型。和通常的最佳实践一样，如果测试分数不可区分，我们应该选择更简单的模型。我们还应该更喜欢重复拟合导致相同模型的模型——线性模型中相似的系数，森林中的重要性分数，以及在使用这些模型进行因果推断时，每次我们再次拟合和测量时相同的估计治疗效果。**

**与我们所有的建模方法一样，我们应该尝试许多对我们的系统有意义的方法，并比较结果。在结果相同的情况下，我们可以确信我们的模型/数据对假设/框架的微小变化是稳健的。当结果不同时，我们从数据中学到了一些重要的东西——也许某个特定的关系很重要。**

**让我们考虑一下我们的选择。**

****正规化****

**我们已经讨论了一个简单的线性回归。复杂性的下一步，或者更确切地说，降低模型复杂性的更复杂的损失函数，是正则化我们的线性模型。如果正则化提高了我们的测试分数，同时降低了模型的复杂性，那么我们很可能更好地捕捉到了因果关系。**

**事实上，当用不同程度的正则化拟合回归时，论文已经探索了真实治疗效果和估计效果之间的关系。研究结果通常表明，强正则化倾向于导致更精确的治疗效果。你可以网格搜索，对半搜索，随机搜索，或使用贝叶斯优化来找到一个弹性网的最佳正则化参数，看看什么工作。**

**亚马逊 2019 年的一篇论文在一些假设下，分析性地确定了正则化的正确量，以便最佳地估计治疗效果。一般来说，它与更严格的正规化相一致。**

****逆概率加权****

**正如我们已经讨论过的，因果推理的核心是平衡混杂因素。如果您的治疗组具有相同的混杂值，那么结果的差异将集中在治疗效果上。**

**我们已经讨论了建模，所以我们在控制混杂因素的任何剩余差异方面做得很好。但是我们可以通过计算我们拥有的数据量来做得更好。**

**考虑我们的模型正在最小化一个损失函数，该函数对数据集中每个点的误差进行求和。如果我们的数据集在治疗 1 中有许多妇女，但在治疗 2 中没有许多妇女，那么与治疗 2 中的妇女相比，模型将更关心优化治疗 1 中的妇女的预测。我们希望模型平等地关注所有阶层，以及所有异质性/治疗效果，但我们的数据并不代表这一点。**

**所以我们对数据进行加权。**

**我们将对数据进行加权，以便在任何混杂因素组合中，每个治疗组都有相同数量的数据点。这种方法已经以多种方式实施，并且在估计治疗效果方面持续显示出改进。**

**在粗化精确匹配中，我们提到，如果治疗组之间的地层不平衡，我们可以对数据进行加权。在建模之前对数据进行加权甚至比最后简单地对测量结果进行加权更好。**

**在数学上，对于分类变量，我们可以通过其治疗组频率的倒数来对数据进行加权。例如，如果我们有 3 个处理 1 的例子和 5 个处理 2 的例子，那么我们可以分别将数据点加权 1/3 和 1/5。那么每个处理组具有相同的总重量 1。我们也可以通过点在每个处理组中的概率的倒数来加权。概率分别是 3/8 和 5/8，所以逆概率是 8/3 和 8/5。用这些值对这些点进行加权也将导致每个治疗组的总重量相同。我们称之为**逆概率加权**。**

**但是如何对模型中的连续变量进行加权呢？**

****倾向****

**好吧，这是一个讨论倾向分数的好时机。我们之前拒绝了倾向的概念，因为基于混杂因素的完整信息进行修剪比投射到一个维度更好。但是在这里，我们需要每个治疗组的频率/概率的单个连续权重，因此投影到一维正是我们想要的。**

**倾向模型可以是任何 ML 模型。我们的“主”ML 模型使用治疗+混杂因素来预测结果，而倾向模型使用混杂因素 ***来预测治疗。*** 可以是线性模型，也可以是像森林、kNN、神经网络这样的非线性的东西。我们只需要知道，对于一组给定的混杂因素，在每个治疗组中观察到的可能性是多少。**

**我们真正想做的是创建一个代理，代表每个治疗组在每个混杂值下有多少观察值。**

**例如，如果我们的数据集中有很多大约 39 岁的男性(T4)，但很少有大约 39 岁的女性，那么这些观察在这个范围内是有偏差的。我们可以在我们的主模型中纠正这种偏差，方法是使用一个倾向模型来估计在这个年龄范围内男性观察值比女性多的程度，并使用我们观察数据的权重来更好地训练我们的主模型。**

**添加倾向得分作为模型权重使我们的模型更加稳健。由于我们在尝试评估治疗效果时关注如此多的移动部分，这种稳健性是受欢迎的。**

**此外，由于我们使用倾向模型作为概率，我们希望它得到很好的校准，并避免值过于接近边缘。让我们深入讨论一下:**

**考虑这样的情况，我们有一个二元处理，如 1 个处理对 1 个对照，用 0 或 1 表示。倾向得分是观察接受治疗的概率。当我们训练一个输出从 0 到 1 的“概率”的二进制分类器时(就像用 predict_proba()方法)，我们非常希望这个概率尽可能准确。对于分类，我们通常不关心*确切的*概率——我们只关心两个类从任何决策边界(在某个概率值)的分离——我们通常只关心单调缩放。但是在这里，我们希望倾向评分的*精确*概率能够正常工作。**

**因此，我们应该对我们的倾向分数分类器进行*校准。*校准只是一种使用一些验证数据来获得完全正确的概率的方法。我们可以通过简单的 sigmoid 曲线来校准我们的预测，或者通过一个非参数的、任意的“等张”函数，如果我们有足够的数据来学习它而不过度拟合的话。Scikit-learn 具有校准功能。**

**让我们更深入地探讨一下如何选择合适的型号。**

****输出和广义线性模型的误差结构****

**虽然我们可以盲目地使用 AutoML 类型的方法来进行机器学习，但领域和数学可以提出一些好的解决方案。**

**检查结果变量的误差结构总是很重要的。不对称残差让我们知道，如果我们的模型有偏差，也应该检查独立变量不同值的方差。**

**当结果变量等于模型输出加上简单的正态分布误差ε时，最小二乘成本函数实际上是最大似然估计量:**

**y =线性模型+ε，**

**其中ε～N(0，方差)**

**这意味着一个同方差的事实，即线性模型之外的噪声不是独立变量的函数(y 的方差沿 x 轴都是相同的)**

**当然，事实未必如此。**

**当然，分类结果变量不是这种情况，在分类结果变量中，分布是某种二项式/多项式，取 n 个值，独立变量 x 的每个值都有一定的概率。**

**缩小，广义线性模型方法允许我们指定其他误差结构。我们可以从指数离差族中选择任何分布，指数离差族包括大多数你听说过的分布。**

**如果我们不喜欢我们的误差结构，或者不想预测一个非常倾斜的结果变量(因为误差的平方在右尾将是巨大的)，我们可以考虑转换我们的输出变量。我们只需要为转换后的输出变量指定正确的误差分布。**

**虽然这本身是有用的，但我认为这将是考虑我们所学参数的 ***分布的一个好的介绍。*****

****混合/分层模型和广义估计方程****

**分类变量的标准做法是将其转换为一个热变量。也就是说，对于具有 N 个可能值的类别，我们将每个观察值映射到长度为 N-1 的向量上(以避免完美的多重共线性)，方法是在 N-1 个向量元素的每个元素中用指示符变量表示 N-1 个类别，并让所有元素中的 0 状态引用被丢弃的“参考”类别。**

**当我们进行这种热编码时，我们允许我们的模型学习每个类别的独立参数。让我们考虑一个线性模型。一个类别的参数值几乎不会影响其他类别的参数值(除非它们都可以移动一定的量，如果该量被分解到模型中的其他术语中)。**

**但是对于一些问题，最好是详细说明这些参数的分布，这些参数代表了分类混杂因素的影响。事实证明，我们需要这一点，以便在群集随机试验中对个体观察进行建模。至少，这是推荐的最佳实践。**

**混合/分层模型就是这样做的。应用于一个聚类试验的建模，我们指定了聚类效果的系数分布。这样，一个观测值所属的分类就成为了一个额外的误差源，每个分类都有自己的项，这些项的集合形成了一个均值为 0 且有一定方差的正态分布。**

**任何“相关的”数据都可以用这种方式建模。任何时候，当我们从每个人那里得到多个观察结果时，这种方法可能是合适的，因为个人表现为具有正态分布参数的分组“随机效应”。当我们查看用户对影响者或活动的响应时，我也使用了这种方法，因为我们希望在模型中包括个人响应，但他们通过他们响应的活动或影响者进行关联。**

**另一种解决同类问题的方法是使用**广义估计方程(GEEs)。**建议将差异结构指定为可交换的，但您也可以尝试所有的结构。**

**像混合模型、广义线性模型和广义估计方程这样的复杂模型可以在 Python 中使用 Statsmodels 库来完成。**

****高级因果推理模型****

**最后，我们可以谈谈其他几个专门为因果推理设计的模型。**

****双稳健**模型是对我们在模型中使用倾向分数的讨论的一个小小的扩展。双稳健模型很像元学习者，因为我们使用我们的主模型来进行预测并查看结果。不同的是，我们也使用倾向，并结合他们的预测，为每个观察。用于估计 ATE(平均治疗效果)的最终等式使用因果模型和倾向模型，如果正确指定任一模型，结果将是正确的！因此，模型中的小误差和其中一个模型中的大误差不会过多地干扰我们对治疗效果的估计。**

****双机器学习(DML)** 和**因果森林**是另外两种流行的方法。DML 可以使用因果森林或其他任意复杂的 ML 来处理非线性、相互作用和异质效应。DML 采用了一种稳健的方法，包括交替模型拟合，有趣的是，它将结果建模为混杂因素单独的函数，以及一个倾向样模型。**

**让我们继续第 4 步。**

**![](img/793be22bef12c667f166364b407044a3.png)**

**照片由 [krakenimages](https://unsplash.com/@krakenimages?utm_source=medium&utm_medium=referral) 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄**

# **第四步:测量**

****再次分层****

**如果我们不符合任何模型，测量值就是通常的统计检验。也就是说，我们可以对每个治疗组的结果取平均值，并确定这些平均值是否不同。**

**然而，当我们这样做时，最好进行分层。获取每个阶层的治疗效果，然后将这些测量值汇集在一起(基于它们在我们试图建模的人群中的流行程度),得到我们的平均治疗效果，同时强烈控制那些混杂因素。**

**因此，如果我们有一个稍微不平衡混杂的随机试验，我们可以使用这种技术。**

**当然，如果我们只有观察数据，我们应该使用这种技术，特别是如果我们不能很好地修剪。**

**这里分层的效果可以非常类似于建模，尤其是对一个热变量的交互项进行建模。线性模型可以包含 k 个不同的热混杂变量的 k 维相互作用项，并且这些项将基本上测量相同的东西，就像将数据分层到那些 k 维层中并取数据的平均值。战略性地结合这些技术是有益的。**

**那么我们用的是哪种统计检验呢？**

****统计测试****

**对于连续变量，我们可以利用双样本 t 检验，或多样本扩展。对于分类结果，我们可以使用卡方。**

**对于连续变量，我们应该考虑拥有不同的均值是否足以回答我们的问题。t 检验通常真正的目的是询问对照组和治疗组的整体分布是否相同——两组是否真正相同。如果是这样，那么您可能希望确保方差也是相同的，并对相同的方差进行统计测试。**

**您可能还想验证这些分布是正态分布，或者对它们进行修剪/Winsorize，直到它们是正态分布——如果两个分布具有完全不同的形状，则具有相同的平均值并不表示它们相等！使用 QQ 图和夏皮罗-维尔克测试来确保你的分布是正态的，或者修剪 x%的数据，并声明你正在测试每个分布的中间(100-x)%是否相同，如果这是使它们正态的必要条件。**

**否则，您可以使用非参数统计检验。一般来说，这是对所有数据点的排序，以确定分布是否可能相同。**

**如果我们匹配数据，那么我们可以考虑配对测试。通常情况下，当一个个体在纵向研究中被测试不止一次时，会使用配对测试，但它也可以应用于此。配对检验有更大的功效，因为个体间差异的方差比整个个体集的方差小得多。是使用成对检验还是更保守的独立检验在数学上与潜在成对观察值之间的相关性相关，即协方差中的真实方差因子，因此它的范围从没有协方差时的独立检验到差异方差为零且您已经知道成对检验拒绝空值的完美协方差。**

**如果我们做许多统计测试，那么我们也需要控制家庭明智的错误率。如果我们希望我们整个分析的总假阳性率是α，那么我们不能用同一个α做几个测试。Bonferonni 修正是处理这个问题的一种非常保守的方法，因为它假设所有的测试都是独立的，并强制它们都超过最严格的标准(alpha 除以测试次数)。Holm-Bonferonni 修正仍然假设独立测试，但至少允许几个假设被拒绝，只要一个通过最严格的标准。在这种方法和其他相关统计检验方法中，p 值被排序，非常类似于非参数检验中观察值的排序。**

**此外，Tukey 的诚实测试正确处理了许多双样本 t 测试的家族错误率问题。本质上，相同的 t 分数与相似学生的 t 分布进行比较，涉及分数之间的**范围**。**

**如果我们符合模型，那么我们就可以像我们讨论的那样进行测量。Metalearner 框架或 Doubly Robust 框架提供了衡量我们平均治疗效果的方法。然而，我们仍然需要这些治疗效果的误差。为此，一个通用的解决方案是自举。**

****自举获取误差测量值****

**自举是另一种神奇的技术。我认为它令人惊讶和有用的性质使它与中心极限定理相提并论。在 Bootstrapping 中，我们从样本数据的一些任意复杂的过程中寻找我们的测量中的误差——我们想知道我们对样本数据的测量与对整个人口的测量实际上有多大的差异。与根据样本数据的方差来估计 t 检验中的总体误差的逻辑类似，我们将仅使用样本数据来估计度量中的误差。**

**Bootstrapping 可用于估计任何测量的*误差。我们习惯于得到平均值的误差，但是如果你的测量值是中间值呢？如果是线性回归的系数呢？也许有基于样本数据方差的误差公式，但如果我们的测量是关于随机森林或神经网络的，那会怎样呢——这看起来很棘手！***

**引导的技术很简单。如果我们有 N 个数据点用于获得我们的度量(通过将一些任意复杂的模型拟合到这 N 个数据点)，我们只需从我们的 N 个数据点 ***中重复采样 N 个数据点，替换*** 。因此，如果我们的数据点是数字[1，2，3，4，5]，一个 bootstrap 采样是[2，2，4，5，5] —它仍然是 5 个数据点，但它是一组不同的数据。我们将使用这个新的“引导数据”再次得到我们的测量。我们重复这样做，也许 50 或 100 次，以得到结果的分布。**

**神奇之处就在于此:来自自举数据集的测量值的方差是我们原始测量值和真实总体测量值之间误差的一个很好的估计。**

**难以置信。**

**还有许多其他的自举方式。一项有趣的技术是获取模型的残差，在数据点之间进行置换，并在拟合新模型之前将其应用于结果。如果你要依赖这种误差测量，最好深入研究不同引导技术的优缺点！**

**我们也对测量异质因果效应及其误差感兴趣。**

****异源效应的大小和显著性****

**同样，异质效应是指治疗的效果依赖于其他协变量，如接受治疗的人群子集。正如我们提到的，如果选择样本量只是为了测量某一特定大小的主要效应，我们的样本量可能无法测量所有这些异质性效应，但我们可以看到是否有统计学意义。**

**我们可以观察每一层的统计测试，以了解治疗对该层的影响大小和意义。我们还可以对我们的模型采取 CATE 方法，看看个体子集(由一些协变量的范围定义)的治疗效果是否显著，并获得其效果大小。在需要获取错误度量的地方使用引导。**

**和往常一样，即使真的有效果，我们的结果也可能不是统计信号。如果自举方差大于我们关心的效应大小，那么我们需要更多的数据。**

**![](img/43b1f08b1f58e270d1634a43a016dd5a.png)**

**[切瑞迪克](https://unsplash.com/@cherrydeck?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片**

****接下来要学的东西****

**作为最后一节，让我们快速提一下在因果推理中可能出现的其他几个概念。**

**首先，我们没有过多地讨论有序数据。事实上，我们归类的所有连续变量都可以保持它们的顺序结构。有序建模方法可以使用不同的阈值来建立单个决策边界，或者在 n 个有序值之间的决策边界上训练 n-1 个不同的模型，并且组合这些模型。这如何与因果推理相联系是另一天的话题。**

**最近，Judea Pearl 一直在与 Elias Bareinboim 合作进行数据融合，这是我们如何使用多个非常不同的数据源来做出单一的因果推断。例如，我们可能有一个随机对照试验和一个单独的观察数据集，每个数据集测量不同的变量子集。这些怎么结合？**

**另一项工作是个性化。如果我们只能对所有个体应用相同的治疗方法，那么也许平均的治疗效果就足够了。但是，如果我们能够对不同的个体给予不同的治疗，那么我们需要找出哪一种对每个人来说是最好的。个人层面的因果关系需要一些额外的理论。**

**我们也可以根据个人的结果来分析不同的制度。除了因果推断之外，分位数回归可以让我们为不同百分位数的结果创建一个模型。如果电力用户提供了我们的大部分收入，我们可能会对模拟最佳结果非常感兴趣，如果避免不利影响是最高优先级，我们可能会对模拟最坏结果非常感兴趣。根据领域的不同，我们应该始终自上而下地考虑什么是有价值的预测，并将其纳入我们正在寻找的因果度量中。然而，我们应该始终小心基于结果的分析——简单地通过干预后变量划分用户会导致有偏见的治疗效果测量。**

**此外，我们没有特别注意时间序列类型的数据。差异 DiD 方法的差异是检查治疗效果的基线方法，但它们假设每个治疗组的趋势相同(不是每个组的治疗前值的函数)。本质上，DiD 方法只是一个配对测试。我们也可以像处理其他协变量一样，沿时间轴应用分段回归，以允许水平和斜率在每个时间段发生变化。然而，这些方法遗漏了更复杂时间现象模型，如自相关和季节性。考虑这些元素的模型对于正确地对系统建模并获得标准误差的精确估计是必要的。Google 的 CausalImpact 使用状态空间方法来建模时间序列，即贝叶斯结构时间序列(BSTS)，这是一种非常灵活的方法，可以捕捉大多数时间现象。**

**当一个协变量超过某个阈值时，对所有个体进行治疗时，可以使用回归不连续设计。因为在这个协变量中，控制和处理是完全(或模糊)分开的，所以分析通常通过使用边界附近的个体来关注局部平均处理效果。**

**最后，最近有一项工作将因果关系与深度学习相结合。我期待着朱迪亚·珀尔即将于 2022 年 2 月 25 日举办的研讨会，主题是:
[https://www.cs.uci.edu/events/seminar-series/?研讨会 _id=1094](https://www.cs.uci.edu/events/seminar-series/?seminar_id=1094)**

****再见****

**我已经尽了最大努力让这个指南变得全面——这是我在一个周末内组织我的一般因果推理知识的最好机会。我会在未来发表一些关于更具体主题的文章，或者有任何问题随时联系我。希望对你有帮助！**

**关于简短的相关讨论，请查看我的文章:因果推理中的方差减少:**

**[](https://medium.com/@skylar.kerzner/variance-reduction-in-causal-inference-8145dd9d5f2) [## 因果推理中的方差缩减

### 数学技巧可以让我们的测量更加精确

medium.com](https://medium.com/@skylar.kerzner/variance-reduction-in-causal-inference-8145dd9d5f2)**