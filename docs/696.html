<html>
<head>
<title>Modern Data Stack: Which Place for Spark ?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">现代数据栈:Spark何去何从？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modern-data-stack-which-place-for-spark-8e10365a8772#2022-01-25">https://towardsdatascience.com/modern-data-stack-which-place-for-spark-8e10365a8772#2022-01-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="db51" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">现代数据栈:Spark何去何从？</h1></div><p id="1dcc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一年前，<a class="ae kl" href="https://medium.com/datamindedbe/why-dbt-will-one-day-be-bigger-than-spark-2225cadbdad0" rel="noopener">一些人已经预测dbt有一天会超过Spark </a>，2021年证明他们是对的:dbt已经变得非常受欢迎，有传言称<a class="ae kl" href="https://www.forbes.com/sites/kenrickcai/2021/12/15/dbt-labs-in-talks-to-raise-at-6-billion-valuation-six-months-after-becoming-a-unicorn/" rel="noopener ugc nofollow" target="_blank"> dbt-labs可能会以60亿美元的估值再次融资</a>。按照这种速度，他们将很快赶上2021年9月估值达到380亿美元的<a class="ae kl" href="https://www.futuriom.com/articles/news/databricks-heaps-on-1-6-billion-for-38-billion-valuation/2021/09" rel="noopener ugc nofollow" target="_blank"> Databricks。</a></p><p id="76b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管如此，今年Spark给我留下最深刻印象的是，几乎所有关于现代数据堆栈的博客帖子中都没有Spark，现代数据堆栈是围绕两个关键组件构建的:</p><ul class=""><li id="86bd" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">一个大规模并行SQL引擎(大查询、红移、雪花)</li><li id="1628" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">还有… dbt</li></ul><p id="9b06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上游:无代码提取/加载工具(Fivetran、Stitch、Airbyte、Hevo)。下游:BI工具(Tableau、Looker、Power BI、Metabase)和反向ETL工具，用于将数据导出到专门的数据库(客户数据平台等)。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/b32dc687e70a5bacda66781d6154d350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O6xNCRAYaiEa8Th_.jpg"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">Dataiku的现代数据堆栈:<a class="ae kl" href="https://blog.dataiku.com/challenges-to-the-modern-data-stack" rel="noopener ugc nofollow" target="_blank">https://blog . Data iku . com/challenges-to-the-Modern-Data-Stack</a></p></figure><p id="962b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我只需在Google Images中键入“Modern Data Stack ”,就会注意到数据市场中的所有公司都在提出自己的技术列表，因为他们通常会试图将自己包括在列表中。</p><p id="f61d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但我也注意到，这种现代数据堆栈通常完全没有Spark，Databricks生态系统通常被视为它的完整替代方案。当然，Databricks完全意识到了这一点，并且像许多其他人一样，尝试加入可以放在堆栈中心的SQL引擎小圈子:他们在12月发布了与dbt Core和Databricks SQL的完全集成。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi lq"><img src="../Images/095c8734869fe4f765be438684299586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8BsSCt8N6qIqOzQl.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">来源:<a class="ae kl" href="https://lakefs.io/thoughts-on-the-future-of-the-databricks-ecosystem/" rel="noopener ugc nofollow" target="_blank">https://lakefs . io/thinks-on-the-future-of-the-data bricks-ecosystem/</a></p></figure><p id="c077" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，我回复了另一家公司的一个人，他询问将Spark添加到他们的现代数据堆栈中是否值得。由于我的团队目前同时使用pySpark、BigQuery和(一点点)dbt，我自己对这个问题想了很多。所以我用一长串支持和反对的理由来回答他们，这些理由激发了我现在的思考，我在这里分享一下:</p><p id="67db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">基础设施:</strong> BigQuery完全由Google管理，你什么都不用做。相比之下，掌握Spark要复杂得多，即使这往往会变得更容易(Spark-serverless在GCP的预览版中可用，即将在Databricks和Databricks SQL中推出)。</p><p id="63b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">学习曲线:</strong>同样，在BigQuery(只有SQL)上比Spark更容易找到或形成有技能的人。我的建议是:在Scala、Java或. Net中，更喜欢pySpark而不是Spark。Python更容易理解，例如，已经被Airflow使用。我认为在Spark中使用Python之外的另一种语言的唯一有效理由是:“用RDD做<strong class="jp ir">非常</strong>高级的事情”和“重用一些公司已经用Java编写的代码，而不必重新实现它”。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/f77800d85b576204793d7b38dd5088e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*B5DbBkBhII-jDl_Z_Ub1Rg.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">非常感谢XKCD网络漫画公司明确允许我在本文中使用他们的漫画:【https://xkcd.com/1409/ T4】</p></figure><p id="4a87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">代码组织:</strong> dbt展示了组织SQL转换管道的正确方式(我知道这一点:从2014年到2017年，我开发了一个<a class="ae kl" href="https://flamy.readthedocs.io/en/latest/Demo.html" rel="noopener ugc nofollow" target="_blank">工具，它做了与dbt相同的事情，但针对Apache Hive </a>)。据我所知，目前还没有工具能为pySpark做同样的事情(dbt确实支持spark-sql，但没有完整的pySpark)。这就是为什么我们开发了一个内部工具，我希望有一天可以开源。如果没有这样的工具，很容易回到dbt帮助我们停止的那些糟糕的做法。</p><p id="365b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">表现力</strong>:我热爱SQL，甚至超过BigQuery，但是我只是不能只用SQL做我需要的一切。此外，我认为使用Jinja模板不是正确的解决方案:正如Maxime Beauchemin在他的博客文章中所说，这将导致大量的模板化SQL和YAML。就我个人而言，我认为这与第一批调度器中的错误是一样的:<em class="ls"> config-as-code </em>有许多限制，而Airflow通过证明<em class="ls"> code-as-config </em>(感谢Python)工作得更好而扭转了局面。是的，JINJA确实解决了一些<em class="ls"> config-as-code、</em>的刚性问题，但是我仍然觉得JINJA相当沉重和冗长，可读性不强，而且对JINJA代码进行单元测试似乎相当乏味。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/420138fb41474524d8ce76f077873647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*YDsBxtoK_5j6ICUIQqT0-A.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">得到xkcd的明确许可:<a class="ae kl" href="https://xkcd.com/1409/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1409/</a></p></figure><p id="a979" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">SQL的限制:</strong>和Maxime Beauchemin一样，我相信(至少，我希望)当BigQuery、Snowflake或Redshift提供类似于pySpark提供的DataFrame API时，事情会变得更好。雪花实际上已经这么做了:他们最近发布了Snowpark，其<a class="ae kl" href="https://docs.snowflake.com/en/developer-guide/snowpark/reference/scala/com/snowflake/snowpark/DataFrame.html" rel="noopener ugc nofollow" target="_blank">数据帧API </a>显然是借鉴了<a class="ae kl" href="https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html" rel="noopener ugc nofollow" target="_blank"> Spark的one </a>。我最近开始为big queryPOC一个<a class="ae kl" href="https://medium.com/r?url=https%3A%2F%2Fgithub.com%2FFurcyPin%2Fbigquery-frame" rel="noopener"> DataFrame API，以展示使用这样的东西可以做更多的事情(我承认，其中一些已经可以用JINJA宏来完成，但我觉得这种方式不够优雅，也更难维护)。我将在下一篇文章中更多地讨论这个POC。</a></p><p id="3554" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">UDF:</strong>SQL的另一个重要限制:有些逻辑用UDF实现要比用SQL代码容易得多。在BigQuery中，UDF必须用SQL或Javascript(！！！).Idem <a class="ae kl" href="https://docs.snowflake.com/en/sql-reference/user-defined-functions.html" rel="noopener ugc nofollow" target="_blank">带雪花</a>，也支持Java。去告诉一个只懂Python的数据工程师/分析师/科学家写一个Javascript UDF吧……PySpark允许我们用Python写UDF，我等不及BigQuery也允许了。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi lr"><img src="../Images/d1cf0f511eaa4104cd75526c576948fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*tLU41zC6pb0GXlKSW2IguA.png"/></div></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">经xkcd明确许可:<a class="ae kl" href="https://xkcd.com/1409/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1409/</a></p></figure><p id="7975" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Extract-Load (E/L) </strong>:我对大量的人似乎使用定制气流操作器来执行E/L任务感到非常惊讶，而不是Spark。我认为这是Spark最大的优势之一:它有<a class="ae kl" href="https://spark-packages.org/?q=tags%3A%22Data%20Sources%22" rel="noopener ugc nofollow" target="_blank">大量的连接器</a>来读取/写入任何东西。它还可以毫不费力地对json和xml执行自动模式检测。并且，<a class="ae kl" href="https://airbyte.io/blog/airflow-etl-pipelines" rel="noopener ugc nofollow" target="_blank">正如Ari Bajo </a>所指出的，最好通过一个中央状态(Spark)并拥有<em class="ls"> O(n) </em>连接器，而不是为每个源-目的地对编写<em class="ls"> O(n ) </em>连接器。Spark可以做到所有这些，我认为它的运行成本比Fivetran要低得多(尽管我必须说开源工具Airbyte可能是一个很好的选择)。Spark的设置成本可能会更高，但是一旦支付了费用，复制和添加新的源/目的地并不需要很长时间。另一个优势是:Spark可以同时完成<em class="ls"> ETL </em>和<em class="ls">反向ETL。诚然，它确实需要开发人员，而非开发人员可以使用图形界面。但是我也有一种感觉，一个没有GUI的开发人员不太能够调查和解决潜在的问题(但是我可能错了)。</em></p><p id="f200" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">实时:</strong>在我的团队中，我们开始将pySpark用于简单的实时案例(将原始数据摄取到BigQuery中)，但我对这个主题还不够了解，无法将其与其他替代方案(如lambda函数)进行比较。我们会注意到，由于它的<em class="ls">微批量</em>模式，Spark允许我们非常容易地拥有恰好一次的保证。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/4fe8577cbcbb92537412482a3759b3da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*W1vhoZB3ThmTS4A2S6L68Q.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">得到xkcd的明确许可:<a class="ae kl" href="https://xkcd.com/1409/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1409/</a></p></figure><h2 id="f571" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">结论</h2><p id="1813" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">用几句话总结一下，我认为这些考虑大多围绕一个中心点，这是SQL最大的优点，也是它最大的缺点:简单。正是由于SQL的简单性，像BigQuery和Snowflake这样的平台才如此易于使用，并被广泛采用，同时降低了被供应商锁定的风险。相反，这种简单性也是它最大的缺点，因为SQL很快就达到了极限，开发最佳实践更难应用，也更不普及。多亏了dbt和JINJA，这些缺点中的一些可以得到缓解，但我相信行业将不得不走得更远，用DataFrames或其他类似的API来帮助数据技术人员编写更通用和高级的转换，并更好地满足不断增长的数据需求。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/f3e24de3282f2f75d2041b6ffe3f46c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*V5tKh3cd4YkWIXsXzG06uA.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">得到xkcd的明确许可:<a class="ae kl" href="https://xkcd.com/1409/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1409/</a></p></figure><p id="af14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的团队中，一个主要的挑战是我们倾向于在pySpark和BigQuery之间交替使用，以从每种工具的优势中获益。这使得<em class="ls">数据血统</em>更加困难，因为dbt只让我们可视化BigQuery部分，而我们的内部“<em class="ls">用于pySpark的dbt</em>”工具只让我们看到pySpark部分。从长远来看，我希望BigQuery能够添加与pySpark (DataFrame API和Python UDFs)相比所缺少的特性，这将允许我们有一天将当前的pySpark转换迁移到BigQuery。唯一留在pySpark这边的是E/L和实时数据处理。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/f5ccc3efbfd73250d98b768eb6e19cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*YlypLRaGpNkBCcjhAVZIMg.png"/></div><p class="lm ln gj gh gi lo lp bd b be z dk translated">得到xkcd的明确许可:<a class="ae kl" href="https://xkcd.com/1409/" rel="noopener ugc nofollow" target="_blank">https://xkcd.com/1409/</a></p></figure><p id="1726" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ls">(此贴有法文版</em> <a class="ae kl" href="https://medium.com/@pin.furcy/modern-data-stack-quelle-place-pour-spark-43bb06fa586a" rel="noopener"> <em class="ls">此处</em> </a> <em class="ls"> ) </em></p></div></div>    
</body>
</html>