# 人工智能驱动的虚假信息，现在和未来

> 原文：<https://towardsdatascience.com/ai-powered-disinformation-present-and-future-555cc56144e9>

## [播客](https://towardsdatascience.com/tagged/tds-podcast)

## 卡佳·塞多娃论语言模型的恶意应用

[苹果](https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2) | [谷歌](https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz) | [SPOTIFY](https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU) | [其他](https://anchor.fm/towardsdatascience)

*编者按:TDS 播客由杰雷米·哈里斯主持，他是人工智能安全初创公司墨丘利的联合创始人。每周，Jeremie 都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。*

直到最近，很少有人关注人工智能的潜在恶意应用。这有一定的道理:在一个人工智能范围狭窄、必须为每个应用程序专门构建的时代，你需要一个完整的研究团队来开发针对恶意应用程序的人工智能工具。由于这种人才在合法经济中工作更有利可图(也更安全)，艾没有给恶意演员提供多少唾手可得的果实。

但是今天，这一切都改变了。随着人工智能变得更加灵活和通用，人工智能的建造目的与其潜在的下游应用之间的联系几乎消失了。大型语言模型可以被训练来执行有价值的任务，比如支持作者、在语言之间进行翻译或者编写更好的代码。但是，一个可以写文章的系统也可以写假新闻，或者为一大批类似人类的文本生成机器人提供动力。

与人工智能历史上的任何其他时刻相比，向规模化、通用基础模型的转移已经表明人工智能如何成为一把双刃剑。现在，这些模型已经存在，我们必须与它们达成协议，并找出如何建立社会，在面对引人注目的人工智能生成的内容和越来越容易获得的具有恶意使用潜力的人工智能工具时保持稳定。

这就是为什么我想与前国会议员和微软校友 Katya Sedova 交谈，她现在在乔治敦大学安全和新兴技术中心工作，她最近与人合著了一些有趣的作品，探索人工智能目前和未来可能的恶意使用。如果你喜欢这个对话，我真的建议看看她的团队的最新报告——它被称为“ [AI 和虚假信息运动的未来](https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns-2/)”。

在这一集的 TDS 播客中，Katya 和我一起谈论了恶意的人工智能聊天机器人、假新闻的产生以及人工智能增强影响力活动的未来。

以下是我在对话中最喜欢的一些观点:

*   当谈到人工智能增强的信息操作时，许多人正确地认为自动内容生成是一个主要的风险来源。但 Katya 指出，人工智能工具在虚假信息运动的早期阶段也很有用，当时一个恶意的演员试图了解其目标观众，以期找到可能获得牵引力的叙事或策略。情感分析、概念图和该分析阶段可能需要的其他任务——这些任务可以通过现有工具进行增强或自动化。
*   许多虚假信息活动都有一个共同阶段，那就是建立基础设施，恶意参与者可以利用这些基础设施来推广他们的信息。例如，这种基础设施可以包括 Twitter 上的虚拟机器人账户，或者虚假的智库网站。人工智能可以以改变游戏规则的方式增强或自动化这一过程。例如，通过大幅降低类似人类的文本生成成本，语言模型可以允许社交媒体机器人定期发布与它们最初被创建来推动的叙事没有直接联系的主题。这将产生更多有机的、看起来合法的机器人，它们可以被用来积累追随者，并且更难被识别为不真实的。
*   人工智能驱动的虚假信息战役变得非常复杂，并对人工智能的新发展做出快速反应。例如，在 thispersondoesnotexist.com(基于 StyleGAN2)公开发布的几周内，Katya 知道至少有一个国家支持的操作开始使用该工具为虚假的社交媒体机器人生成头像。她预计，一个复杂的恶意人工智能工具生态系统将越来越多地由专门的灰色市场“影响力即服务”公司开发和集成。
*   类人文本生成的自动化(以及其他)引发了关于允许在线匿名的风险回报情况的问题。虽然匿名对于确保压制言论的国家的活动分子的安全至关重要，但它也使国内外的影响行动有可能大规模展开。
*   Katya 认为，人工智能行业和学术界应该投资于关于制定出版规范的热烈讨论，这些规范反映了开源算法可能产生的潜在影响，特别是当它们被用于虚假信息活动时。这些对话正在开始，但正如许多与人工智能相关的问题一样，这是一个必须在最后期限内完成的哲学问题。

你可以[在推特上关注卡佳](https://twitter.com/LUMKatrusya)，或者[我在这里](https://twitter.com/jeremiecharris)。

![](img/8263a38d8512843e1dd58b21f244e908.png)

## 章节:

*   0:00 介绍
*   2:40 恶意使用人工智能
*   4:30 过去十年在这个领域
*   7:50 自动化的低手水果
*   14:30 其他分析功能
*   25:30 真实的机器人
*   30:00 服务业的影响
*   36:00 比赛到底
*   42:30 系统自动化
*   50:00 制造规范
*   52:30 跨学科对话
*   54:00 总结