# 从沙普利到 Shapley 理解数学

> 原文：<https://towardsdatascience.com/from-shapley-to-shap-understanding-the-math-e7155414213b>

## 如何计算 SHAP 要素贡献的概述

![](img/19c4fba1a8090ace64fdbc6532761207.png)

克拉拉·库利科娃在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

假设你(玩家 1)和一个朋友(玩家 2)参加了一场猜拳比赛。你最终赢得了**一等奖，10，000 美元**。现在，你想公平地分配这笔钱。你的朋友建议你平分它。但是，你的超参数调优技术更胜一筹。你认为你应该得到更大的份额，因为你对团队的贡献更大。考虑到这一点，你怎么能公平地分配这笔钱呢？

很方便，你的朋友有一台时光机。你们各自回到过去，独自重新进行卡格尔竞赛。你最终获得第二名，并赢得 **$7，500** 。你的朋友仅获得第三名，赚了 **$5，000** 。如果你们都不玩，就不会赢得任何奖金( **$0** )。我们将这 4 个玩家联盟的价值记录如下。很明显，你应该得到更多的奖金，但是如何分配还不清楚。

![](img/cae96bfc357a404dc90ac9c0777a3933.png)

联盟价值观(来源:作者)

一种方法是通过计算每个玩家的**预期边际贡献**。这是玩家对其可以加入的所有联盟贡献的加权平均值。

例如，参与人 1 (P1)可以加入只有参与人 2 (P2)的联盟。P2 从第三名升至第一名，奖金增加了 **$5000** 。P1 也可以加入一个没有玩家的联盟，增加 7500 美元的奖金。这些是 P1 的边际贡献。这些因素的平均值为我们提供了预期边际贡献 **$6，250** 。

![](img/0b5a08389f7fb3c76df355133978142c.png)

参与人 1 的预期边际贡献(来源:作者)

我们可以按照类似的过程来计算 P2 的预期边际贡献。这次的价值是 3750 美元。最终，P1 将获得 6250 美元，P2 将获得 3750 美元。这两个值也被称为**沙普利值**。请注意，这些值加起来的总奖金为 10，000 美元。

![](img/087595730237dad87238ca1df54d4571.png)

参与人 2 的预期边际贡献(来源:作者)

沙普利价值观被认为是一种公平的奖金分配方式。这是一个来自博弈论的概念。我们只计算了两个人的团队。我们能够使用它们来计算任何规模的团队的公平分配。我们将花时间来理解这个**的广义沙普利值公式**。这个公式可能看起来很可怕。然而，当我们得到引擎盖下你会看到它有一个直观的解释。

> 沙普利值=预期边际贡献
> 
> 这是玩家对其可以加入的所有联盟贡献的加权平均值。

从划分奖金到解释机器学习模型，这似乎是一个很大的飞跃。然而，Shapley 值可以用来理解每个模型特征(玩家)如何对预测(奖金)做出贡献。我们将解释 Shapley 值如何**扩展到解释模型预测**。我们将以探索</introduction-to-shap-with-python-d27edc23c454>**对这一领域研究的**贡献来结束。也就是说，它们极大地提高了我们逼近 Shapley 值的速度。****

# **3 人游戏的 Shapley 值**

**在我们继续之前，让我们再看一个例子。这将使一般方程更容易理解。这次我们有一个由三名球员组成的队伍。计算很复杂，我们还得再回溯几次。**

**现在将有 8 个可能的联盟，如下所示。你们一起赢得一等奖( **$10，000** )。现在有 3 个 2 人联盟。例如，P1 和 P3 的联盟将获得第二名(**$ 7500**)。也会有一个玩家的联盟。例如，如果 P3 独自比赛，他们将不会获得任何奖金( **$0** )。也许他们应该投资一个更好的 GPU。**

**![](img/27a46c8003747092b477e38fc437d293.png)**

**联盟价值观(来源:作者)**

**我们可以用这些联盟值来计算 P1 的沙普利值。现在 P1 可以加入 4 个联盟。P1 可以加入 P2 和 P3 的联合政府，或者只有 P2 或 P3 的联合政府，或者没有成员的联合政府。像以前一样，我们计算 P1 对每个联盟的边际贡献。最后，我们取加权平均值。这给了我们一个沙普利值**$ 5000**。**

**![](img/f1fdbeb13208184d40e624cd3decf964.png)**

**参与人 1 的预期边际贡献(来源:作者)**

**你可能会问，我们从哪里得到这些重量？这就是为什么我们把第一个边际贡献的权重定为 1/3，第二个边际贡献的权重定为 1/6，以此类推……这些就是 P1 做出这些特定贡献的概率。通过概率加权给我们一个 ***预期*** 边际贡献。**

**这些概率从何而来并不明显。首先，我们需要找出三个人组成联盟的方法。这是因为只有所有 3 名成员齐心协力才能赢得全部奖金(10，000 美元)。**

**为了做到这一点，我们假设每个成员都有平等的机会依次加入团队。例如，P1 加入，然后 P3，然后 P2。这样我们总共有 3 个！=形成联盟的 6 种方式。你可以在下面看到所有这些。一般来说，有 n 个！组建 n 人团队的方法。**

**![](img/5a31fd21409a0726724668b3891a25ba.png)**

**形成 3 人联盟的 6 种方式(来源:作者)**

**上面我们看到，如果 P1 加入 P2 和 P3 的联盟，他们将贡献 5000 美元的边际贡献。这可能以两种方式发生。要么 P2 加入，然后是 P3，然后是 P1，要么 P3 加入，然后是 P2，然后是 P1。换句话说，P1 将为团队组建的 6 种方式中的 2 种做出边际贡献。这给了我们 2/6 = 1/3 的概率，P1 做出了这一贡献。**

**只有一种方法可以让 P1 做出第二笔捐款(【2,500 美元】)。也就是说，如果 P2 加入，然后是 P1，然后是 P3。这给了我们 1/6 的概率。同样，第三次贡献(**$ 7500**)的概率是 1/6。第四次贡献( **$5000** )有 1/3 的概率。就像第一次捐款一样，P1 有两种方式。先是 P1 加入，然后是 P2，然后是 P3，或者是 P3，然后是 P2。**

**我们可以对 P2 和 P3 采取同样的做法。对于这些玩家，Shapley 值分别为 **$3，750** 和 **$1，250** 。同样，所有 Shapley 值加起来就是总奖金。Shapley values 将始终公平地分配所有奖金。现在让我们看看如何推广 Shapley 值。**

# **广义 Shapley 值**

****等式 1** 给出了 **p** 玩家游戏中**玩家 i** 的 Shapley 值的公式。从求和符号开始，我们对所有联盟 S 求和。其中 S 是不包括参与人 I 的联盟的子集。换句话说，S 包含参与人 I 能够做出边际贡献的所有联盟。回到三人组的例子，有 4 个联盟不包括 P1。**

**![](img/bafcf677e4d749410479a6d25a635406.png)**

**等式 1:p 玩家游戏中玩家 I 的 shapley 值(来源:作者)**

**在方括号中，我们有参与人 I 对联盟 S 的边际贡献。具体来说，我们有联盟 S 的价值(val ),包括参与人 I 减去联盟 S 的价值。价值函数取决于正在进行的特定游戏。在我们三个玩家的例子中，我们使用了不同的符号。我们谈到了联盟的价值观，并使用了字母 C 和玩家下标。这些联盟值给出了 Kaggle 游戏的价值函数。**

**最后，我们对边际贡献进行加权。下面，你可以看到重量的每个组成部分代表什么。这里 **|S|** 是联盟 S 中玩家的数量，这意味着 **p-|S|-1** 是在玩家 I 之后需要加入联盟的玩家数量**

**![](img/f8efbba9960a0766d03888223e872724.png)**

**在权重分子中，我们有联盟可以形成的方式的数量。分母是整个团队可以形成的方式的数量。因此，当博弈中有 p 个参与者时，权重给出了参与者 I 对规模为|S|的联盟做出贡献的概率。如果你代入我们 3 人游戏的值，你会得到和以前一样的权重。**

**把 Shapley 值分解一下，可以看到它有一个直观的解释。我们用参与人 I 做出贡献的概率来衡量他们的边际贡献。然后我们将参与人 I 可以加入的所有联盟的加权贡献相加。这给了我们一个**预期边际贡献**。使用这些值，我们可以在所有玩家之间分配游戏的总价值。**

**凭直觉，看起来**预期边际贡献**是一种公平的方式。我们考虑对所有联盟的贡献。这意味着我们考虑了玩家的个人贡献和玩家之间的互动。也就是说，一些玩家可以很好地合作，增加他们的共同价值。问题是可能有其他看起来公平的价值分配方式。我们需要证明 Shapley 值是公平的。**

## **匀称的公理**

**Shapley 值实际上来源于 3 个公理。我们只对它们进行总结，但它们也可以用数学[来定义](https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pcbi.0010064/1/pcbi.0010064.sd003.pdf?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=wombat-sa%40plos-prod.iam.gserviceaccount.com%2F20220706%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220706T120331Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=bcfb885603db7bd53010f3a85bd65602fc3b50eaf09b3630d7bcb47cad669f74c986803e9ca9848d97e8a1a04d3d7f3e5a15ebfcb64ad7e33da9d95c0df07668231b62fde12d431bee105b56ad6f2ded61df3effbc0dcf9977d317f0d2511053be0f04f61801f64657322cf58acbe8ea6990166f45384e341d4e66558bf2b08c198bc5a204d0f953b006c944c8d2e4173d21a55d0fcec6a35d73f6b0defd20d58da756fed230908ec22125d679cd4dc6e6382423304a7857e2c5f1dddeba4679ec16c376654b14c73018ce70633ca4a5fbeac975128fbe1cedcb148e6bfb7802ecb22ba55964ff58ff69bbff347191212760204d01f7e9969bf0500141d2f2be)。这些公理可以被认为是公平的定义。因此，满足这一定义的价值分割方法可以被认为是公平的。**

**如果两个玩家对所有联盟做出相同的贡献，他们就被认为是可以互换的。如果两个玩家可以互换，那么他们必须得到游戏总价值的同等份额。**

****无效玩家财产**如果一个玩家对所有联盟的边际贡献为零，那么他们将一无所获。**

****可加性**如果我们合并两个游戏，那么一个玩家的总贡献是两个单独游戏贡献的总和。这个公理假设任何游戏都是独立的。**

**我们可以从数学上证明 Shapley 值是满足这 3 个公理的唯一有效值。所谓高效，我们的意思是游戏的价值没有剩余。最终，在这个定义下，沙普利值是唯一公平的价值分配方式。令人惊讶的是，这样一个直观的公式可以从 3 个简单的公理推导出来。**

# **机器学习的 Shapley 值**

**我们可以使用 Shapley 值来理解模型是如何做出预测的。现在，游戏的价值就是模型**预测**。**特征值**是玩家。要明确的是，玩游戏的不是特征，而是用于特定观察的特征的 ***值*** 。但是，我们将这些称为特性。我们使用 Shapley 值来计算每个特征对预测的贡献。**

**例如，在[之前的一篇文章](/introduction-to-shap-with-python-d27edc23c454)中，我们训练了一个模型来预测鲍鱼的年龄。您可以在图 1 的**中看到特定观察的 Shapley 值。这些给出了平均预测年龄 E[f(x)]和观测值预测值 f(x)之间的差值。例如，**去壳重量**的值使预测年龄增加了 1.81。我们称之为特性的贡献。****

**![](img/947579dc4be69e258af4cf759847d309.png)**

**图 1:SHAP 价值观的例子(来源:作者)**

**为了计算这些，我们可以使用与前面相同的 Shapley 值公式。我们需要做的就是改变价值函数。**等式 2** 给出了我们用于特定观察的函数 **x** 。这里 S 是特征值的联合， **f** 给出模型预测，模型具有 **p** 个特征。 **S** 的值是不在 S 中的所有特征的模型预测值。我们使用 S 中的实际值。**

**![](img/3b9bd39b409eb54b5278484cb9022224.png)**

**等式 2:机器学习的价值函数 Shapley 值(来源:作者)**

**我们实际上是在上式中做多重积分。为了忽略某个特征，我们将预测函数与特征值的概率相结合。我们对 s 中的所有特征都这样做，为此我们需要知道特征分布或使用经验分布。**

**上面的公式里有很多运动的部分。在本节的下一部分，我们将通过一个 ML 示例来更好地理解它。然后我们将继续讨论如何**近似 ML 的 Shapley 值**。为了结束这一节，我们将讨论 Shapley 值的**性质。这些来自公理，我们将讨论它们在机器学习环境中的含义。****

## **ML 示例**

**假设我们想预测某人的收入。我们有两个特征——年龄(特征 1)和学位(特征 2)。我们以下面的模型 **f** 结束。对于年龄，我们假设特征在 18 到 60 岁之间均匀分布。类似地，对于学位，我们假设某人拥有学位(1)或没有学位(0)的机会是均等的。在我们的观察中，我们有一个 20 岁有学位的人。该模型将预测此人的收入为 5000 美元。**

**![](img/d42eeb21011110731a5d260ddc8a2ba3.png)**

**(来源:作者)**

**我们可以计算功能 2 {2}对功能 1 的联合的边际贡献，S = {1}。这可用于帮助计算特征 2 的 Shapley 值。换句话说，计算特征 2(度=1)对预测的贡献。**

**我们首先计算两个特征的联合的值，S = {1，2}。这相对简单。s 包含这两个特性，所以我们不必忽略任何特性。我们可以使用特性的实际值。如下所示，这与该观察的预测相同。**

**![](img/6ca1089c99c4a3c5fb77b87065244b29.png)**

**(来源:作者)**

**然后我们需要计算联盟的价值，S = {1}。在这种情况下，S 不包含{2}。我们忽略功能 2，使用功能 1 的实际值。记住，特征 2 不是连续的。为了忽略特性的价值，我们不需要使用集成。我们只是将每个值的预测值乘以该值的概率(即 50%)相加。**

**![](img/505f0a4fe1d89b33834cf449cf23fc61.png)**

**(来源:作者)**

**我们现在可以计算特征 2 对 S={1}的边际贡献。该贡献的权重以与标准 Shapley 值相同的方式计算。为了清楚起见，我们使用联合中特征的数量和特征值的总数。我们有|S| = |{1}| = 1 和 p = 2。这给了我们一个权重(1！)(0!)/2!= 1/2.**

**![](img/49c5bdb824aea78a7644efdcbd37e3b0.png)**

**(来源:作者)**

**这仅给出了特征 2 的 Shapley 值所需的部分计算。我们还需要计算特征 2 对 S={}的边际贡献。为此，我们需要计算 S = {}的价值函数。这将要求我们忽略这两个特性的分布。**

## **Shapely 值的近似值**

**计算精确的 Shapley 值在计算上是昂贵的。在上面的例子中，我们只有两个特征。随着我们添加更多的功能，可能的联盟数量呈指数增长。在实践中，只有接近 Shapley 值才是可行的。**

**一种方法是使用蒙特卡罗抽样。对于特征 I，我们先用特征值(+i)计算预测。我们在没有值(-i)的情况下做同样的事情。也就是说，我们为特征 I 取一个随机值。其余的特征值也将全部被随机采样。我们取这两个预测的差值。如下所示，我们这样做 M 次，并找出所有这些差异的平均值。通过随机采样和平均，我们隐含地根据特征的分布进行加权。**

**![](img/161acf69f5fa61585ac3e2f0aaaf3ded.png)**

**(来源:作者)**

**上述过程仍然不切实际。我们可能需要许多样本来获得一个合理的 Shapley 值的近似值。这就是 SHAP 的用武之地。正如我们在上一节中讨论的，这是一种更快的近似 Shapley 值的方法。在我们继续之前，我们将在机器学习的背景下讨论 Shapley 值的属性。**

## **Shapley 值的性质**

**沙普利是解释预测的一种方法。它因其令人满意的特性而广受欢迎。这些大部分是从 Shapley 值的公理中得出的。**

****效率**如前所述，沙普利值是有效率的。以前，这意味着游戏的全部价值在玩家之间分配。对于最大似然，这意味着预测在特征之间划分。具体地，Shapley 值满足下面的等式。所有 Shapley 值和平均预测值之和等于观测值的预测值。我们在前面的**图 1** 中看到了这一点。**

**![](img/3e82b24e658846bd0ec67f8c511ca087.png)**

**(来源:作者)**

**另一种流行的当地解释方法是石灰。相比较而言，石灰不一定有效。计算出的权重将不会与原始预测相加。对 Shapley 来说，我们知道每个特征对预测的贡献有多大。对于 LIME，我们只知道哪个特征对预测最重要。**

****对称性**如果两个特征对所有联盟做出相同的贡献，那么它们将具有相同的 Shapley 值。**

****Dummy** 如果一个特征从未改变预测，则其 Shapley 值为 0。换句话说，模型中不使用的特征将不具有 Shapley 值。**

****可加性**机器学习的 Shapley 值也是可加的。这仅与集合模型相关。在这种情况下，可以通过对集合中每个模型的 Shapley 值进行加权平均来计算总 Shapley 值。其中权重将与给予每个模型的预测的权重相同。例如，在随机森林中，来自每个决策树的预测被赋予相等的权重。**

****一致性**这个属性来源于前面的 3 个属性。假设我们把一个模型从 M1 换成 M2。如果一个特征现在比以前增加了更多的预测，那么它的 Shapley 值将增加。这意味着我们可以可靠地比较不同模型的特性贡献。**

# **SHAP 价值观**

**[SHAP python 包](https://github.com/slundberg/shap)已经成为使用 Shapley 价值观的代名词。这个包广泛实现的关键是它可以进行近似的**速度**。我们在下面讨论一些方法。速度的提高意味着我们也能够计算许多 Shapley 值。这允许对值进行不同的聚合，从而为我们提供模型的全局视图。**

## **KernelSHAP**

**内核 SHAP 将 Shapley 值重新定义为线性模型中的参数。简单地说，近似方法通过首先置换特征值来工作。在足够的排列之后，使用线性回归联合估计 Shapley 值。与其他采样方法相比，一起估计这些值需要更少的计算。例如蒙特卡罗采样，其中单独计算每个特征的 Shapley 值。**

**KernelSHAP 也是一种[模型不可知的](/what-are-model-agnostic-methods-387b0e8441ef#:~:text=Model%20agnostic%20evaluation%20methods%20provide,want%20to%20compare%20model%20performance.)近似 Shapley 值的方法。这意味着它可以用于任何型号。前提是 SHAP 已经为你的建模包实现。**

## **树形**

**与模型无关的近似方法是 TreeSHAP。它利用了集合模型中个体树的结构。因此，它只能用于基于树的算法，如随机森林和 XGBoost。TreeSHAP 的优点是明显比 KernelSHAP 快。**

**使用 KernelSHAP，我们可以在指数时间内估计 Shapley 值与特征数量的关系。而 TreeSHAP 可以在线性时间内估计它们。我们将在下面的文章中详细讨论这种差异。我们还探讨了模型的其他方面如何影响近似时间。这包括集合中的树的数量、最大深度和叶子的数量。**

**</kernelshap-vs-treeshap-e00f3b3a27db>  

如前所述，这些方法可以近似计算大量的 Shapley 值。我们可以用不同的方式将它们结合起来，以了解模型作为一个整体是如何工作的。一个例子是**图 2** 中给出的蜂群图。

在这里，我们对每个特性的值进行分组(例如壳重)。我们可以看到倾向于具有大的正负 Shapley 值的特征。这些是倾向于对预测做出重要贡献的特征。我们还根据特征的值给点着色。这样我们就可以开始理解特征和目标变量之间的关系。

![](img/130e6fd7a5a5042f98e498274acf8e6b.png)

图 2:蜂群图的例子(来源:作者)

这些类型的地块易于实施是 SHAP 一揽子计划被广泛采用的另一个原因。我们将在下面的文章中探索如何使用这个包。我们讨论 Python 代码，并探索该包提供的一些其他聚合。

</introduction-to-shap-with-python-d27edc23c454>  

我希望这篇文章对你有帮助！如果你想看更多，你可以成为我的 [**推荐会员**](https://conorosullyds.medium.com/membership) **来支持我。你可以访问 medium 上的所有文章，我可以得到你的部分费用。**

<https://conorosullyds.medium.com/membership>  

你可以在|[Twitter](https://twitter.com/conorosullyDS)|[YouTube](https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w)|[时事通讯](https://mailchi.mp/aa82a5ce1dc0/signup)上找到我——注册免费参加 [Python SHAP 课程](https://adataodyssey.com/courses/shap-with-python/)

## 图像来源

所有图片都是我自己的或从[www.flaticon.com](http://www.flaticon.com/)获得的。在后者的情况下，我拥有他们的[保费计划](https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-)中定义的“完全许可”。

## 参考

南伦德伯格， **SHAP 蟒包** (2021) *，*[https://github.com/slundberg/shap](https://github.com/slundberg/shap)

南 Lundberg & S. Lee，**解释模型预测的统一方法** (2017)，[https://arxiv.org/pdf/1705.07874.pdf](https://arxiv.org/pdf/1705.07874.pdf)

C.Molnar，**可解释机器学习***(2021)[https://christophm . github . io/Interpretable-ml-book/shap . html](https://christophm.github.io/interpretable-ml-book/shap.html)*

*南 Masís，**用 Python 进行可解释的机器学习** (2021)*

*L.S. Shapley，**对博弈论的贡献，第一章为 n 人对策的价值。(** 1953)*

*[**了解沙普利值**](https://www.youtube.com/watch?v=9OFMRiAVH-w&ab_channel=MachineLearningTV)*

*[**正文 S1:沙普利值的公理化基础**](https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pcbi.0010064/1/pcbi.0010064.sd003.pdf?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=wombat-sa%40plos-prod.iam.gserviceaccount.com%2F20220905%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20220905T203831Z&X-Goog-Expires=86400&X-Goog-SignedHeaders=host&X-Goog-Signature=026abd2505b5387d0faf1edfd158981b1a191c12c5d3ea7d8fbcf5f3bc938dff5951fa17a22693671da9743ec33edebe0ed3d23a39968a50f8987916f23b69b104abcd3b40133e84e8ab75eb6c7da85cfdd411d910f4d32212cfaa7d8dbf1fbd9c213cef80bd2b89818960c26ae0cc950c9a9cef1e75deecef41264dc311d39eeb873b586c2f67e2d15d1a665a751204fb0bb292e3a4204d4d990cad82a0ce7b27057160f6a9ba28e27d7b2b3b4a4e6177f17ad45a4536fc8584d26503f82904dba00da91dcb8a29c6726dabd4914172b44f08a33602fc58aa24ee07b5e5fc1828dd4cd51c0df2fec828e2b9504fb5a47ec0dd871838f3d304190de31e5282af#:~:text=The%20Shapley%20value%20is%20the,the%20players'%20%E2%80%9Cnames%E2%80%9D.)***