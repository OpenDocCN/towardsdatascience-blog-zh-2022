# 计数流中的不同事件

> 原文：<https://towardsdatascience.com/counting-distinct-events-in-streams-c80ea7d48a46>

## 分布式环境中的大数据统计

![](img/cec2022713638123e192067d7f44cbfc.png)

阿克顿·克劳福德在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

想象一个无限的输入符号流。我们想知道到目前为止在任何时间点收到的不同值的数量。

这个问题有许多用途。其中之一是跟踪某个时间段内，比如说上个月，某个访问量很大的网站的不同访问者的数量。

解决这个问题最简单的方法是维护到目前为止看到的所有(不同的)值的集合。当有许多不同的值时，这会消耗大量内存。

如果我们的记忆能力有限，我们能做什么？或者，如果我们处于分布式设置中，需要以分布式方式合并数据结构的许多实例，这涉及到四处传送数据结构？

寻求精确的计数变得不可行。然而，我们仍然可以在不牺牲速度的情况下获得一个近似的计数，并获得很大的压缩。

幸运的是，在许多用例中，一个(足够好的)近似计数就足够了。例如，一个网站在一个月内收到的不同访问者的数量的近似计数可能足够好，只要该近似足够好。

从这一点开始，我们将这个问题称为*基数估计*。

首先，我们想给读者一个如何思考和处理这类问题的具体感受。为了这个目的，这个问题的简化版本将会更有效。接下来，我们将回到最初的问题，因为它有更广泛的用途。

**计数事件**

我们只想计算到目前为止到达流中的符号的数量。不明显的。如果实际计数为 *n* ，我们可以在 log n 位数量级的数据结构中捕获它。嗯，这看起来已经很节省内存了，不是吗？假设我们想要做得更好。如果没有别的原因，这将迫使我们思考一个更困难问题的可行解决方案——带有*独特的*约束。

首先，我们将放弃得到确切答案的目标。也就是说，我们会对一个大概的答案感到满意。只要近似“足够好”

首先，让我们从这里开始。对于预先设定的固定概率 *p* ，当事件到来时，以概率 *p，*让我们的计数器加 1。(概率为 1- *p* ，我们忽略这个事件。)在任何时候，我们对计数的估计都将是计数器的值乘以 1/ *p* 。

与当 *p* 等于 1 时相比，通过选择 *p* 足够小，我们可以在计数器中使用更少的内存。例如，假设实际数量约为 43 亿。这将需要 32 位来精确存储。通过选择*p*为 1/2 ⁶，我们期望以 16 位通过。当然，最终的计数只是一个近似值。

更重要的是，如果我们在精确计数小得多的情况下使用相同的 *p* ，我们的近似值可能会相差很远。我们估计的计数总是以 1/ *p* 为单位，即 0，1/ *p* ，2/ *p* ，…。对于 p = 1/2 ⁶，这将是 0，2⁶，2*2 ⁶，…

假设实际数是 1000。最接近 1000 的估计数 0 和 2 ⁶都相差甚远。

如果我们可以用大的 *p* 来表示低的实际计数，用小的 *p* 来表示高的计数，那就太好了。莫里斯柜台体现了这种思想。

假设近似计数器的当前值是 *X* 。假设看到了下一个事件。准确的计数器会在 *X* 上加 1。莫里斯计数器以 1/2^ *X* 的概率给 *X* 加 1。

这样做的效果是，流中较早发生的事件比流中较晚发生的事件更有可能被计数。这很直观。

这么想吧。想象一下 50 个事件的切片。假设这些是流中的前 50 个事件。我们希望使用一个非常大的 p 值，这样，如果流在那里结束，我们的估计计数就足够好了。例如，如果 *p* 为 0，那么我们的估计计数将为 0，而实际计数为 50。

另一方面，如果这 50 个事件发生在已经看过一百万个事件之后，我们可以使用更低的 *p* ，实际上甚至是 0。一百万是“一百万加 50”的一个很好的近似值。

**计数*不同的*事件**

现在让我们回到激发这篇文章的问题:估计在一个流中遇到的*不同*项的数量。

下面我们来说明一下这个问题。假设我们生成 *n* 个数字 1/ *n* ，2/ *n* ，…，3/ *n* 。请注意，它们平均分布在 0 和 1 之间。接下来，我们将它们复制任意多次。最后，我们任意排列这个集合。我们能从最终数据推断出 *n* 吗？

这里有一个 *n* = 4 的例子。

```
0.25 0.5 0.75 1               // **4 numbers uniformly spread in (0,1]**
0.25 0.25 0.25 0.5 0.5 0.75 1 1 // **Some replicates added**
0.5 0.25 0.25 0.25 1 0.75 0.5 1 // **Permuted**
```

我们的第一个想法是，我们找到这些数字的最小值，并输出一除以这个最小值作为我们的估计。在我们的例子中，最小值是 0.25，1/0.25 是 4，这确实是不同项目的数量。

这个想法的吸引力在于流中的最小值可以以流的方式更新。速度非常快，而且内存容量不变。

有意思。在我们的例子中，数字平均分布在 0 和 1 之间。我们如何解除这一限制？这将我们引向…

**使用最小散列的概率计数**

我们先适当散列。不管使用什么情况，一个有效的散列函数都将数据*均匀地*映射到固定数量 *m* 个桶上。这正是我们想要的。除了 0，1，…， *m* -1 到(0，1)的重新缩放只涉及除以 *m* 和加 1。

当然，你可以说我们已经把问题从原来的问题转移到寻找一个均匀分布数据的散列函数。幸运的是，在过去的几十年里，已经有了很多关于哈希函数对哪种类型的数据做这种事情的研究和经验。

使用这种方法的基数估计如下。我们选择一个散列函数，我们认为它将在 0 和 1 之间平均分布这些值。在做这个选择时，我们可能需要了解到达数据流的数据的性质。

(还要注意，我们不允许对数据进行多次传递，例如第一次学习哈希函数，下一次使用它。也就是说，我们想要一个纯粹的流式解决方案。)

现在，当数据以流的形式到达时，我们保持我们看到的散列值的最小值。一除以这个最小值就是我们对原始集合的基数的估计。

**Min+Invert 放大哈希函数中的噪声**

合理的预期是，我们选择的哈希函数对于我们正在建模的数据来说并不完美。特别是，数据集中的最小哈希值可能与它应有的值相差甚远。例如，如果它是应有数量的一半，估计的数量将是应有数量的两倍。

取最小值会放大哈希函数中的噪声。直觉类似于为什么 iid 随机变量的最小值具有比它们的和更高的方差的直觉。非正式地说，当取总和时，变量的可变性倾向于抵消，而当取最小值时则不会。

反转噪声最小值会进一步放大噪声。

所以让我们寻求一种噪音更小的方法。

**最大前导位哈希概率计数**

和前面的方法一样，首先，我们散列。这一次，我们将哈希值视为一个二进制数(固定位数)。接下来，我们计算 *k* ，这个哈希值中 0 值位的最长前缀的长度。因此， *k* 对于 **0** 110 将是 1，对于 **00** 10 将是 2。最后，我们跟踪 *k* _max，这是流中计算的哈希值在所有这些 *k* 中的最大值。我们返回 2^( *k* _max)作为流中不同事件的估计数量。

直觉是什么？想象一下，我们的散列函数将任何固定事件 *x* 映射到从散列函数的范围中随机均匀选择的一个数。(注意，相同的 *x* 应该总是映射到相同的哈希值。)

对于任何固定的 *x* ，其哈希值以 *k* 连续 0 开始的概率为 1/(2^ *k* 。这是因为在 *k* 位上有 2^ *k* 个二进制数，其中正好有一个是“全 0”。

因此，如果我们在流中遇到 2^*k*不同的事件，我们会期望它们的哈希值之一以*k*连续的 0 开始。将这个推理反过来，如果 *k* _max 是找到的任何散列值开始的 0 值比特的最大数量，则 2^( *k* _max)是从其导出这样一组散列值的流中的不同事件的数量的合理估计。

这种方法非常节省内存。假设散列函数的范围是一个 *m* 位数。也就是说，散列函数在其范围内有 *n* =2^ *m* 个不同的值。在处理流的时候，我们只需要跟踪和更新 *k* _max。 *k* _max 的值可以存储在 log *m* 位的二进制数中。用 *n* 表示——我们可以区分的不同事件的最大值——这只是 log(log *n* ))位。

与前面的方法一样，这种方法也放大了哈希函数的噪声，尽管可能没有那么大。说实际产生的 *k* _max 才是真正的一加二。从前者得到的估计计数将是从真实的 *k* _max 得到的 4 倍。

**通过使用多个哈希函数来改进估计**

我们可以使用多个独立的散列函数，并取它们产生的估计值的平均值。得到的估计值通常具有较低的方差，因此会更准确。这适用于我们到目前为止看到的两种方法。

我们使用的散列函数越多，我们的估计就越准确。也就是说，我们将需要为我们看到的任何一个事件 *x* 计算许多哈希值。当我们使用的散列函数的数量达到 1000 个时，这可能会变得非常耗时。

一个叫做*随机平均*的巧妙程序使用一个散列函数来模拟多个散列函数的效果。假设我们的哈希函数将一个 x 映射到一个 *m* 位的随机二进制数。我们将把由第一个 *q* 位形成的二进制数解释为散列函数标识符，将由剩余的 *m 个* - *q* 位形成的二进制数解释为所识别的散列函数的值。

请注意，对于事件的任何一次发生，该方法在 *m* - *q* 位上只给出一个散列函数的值。尽管如此，我们得到了方差减少的好处，因为现在就好像我们已经从 2^ *q* 选择中为这个实例随机选择了散列函数。

我们确实需要跟踪和更新 2^的值，因为我们现在已经有了那么多的散列函数。在估算的时候，我们将需要使用所有这些 2^值。

**最大前导位哈希的估计计数**

这是:

常数**p**2^(mean(*r*1、…、 *Rp* )、 *p* = 2^ *q*

这里 *R* 1、…、 *Rp* 是 *p* 哈希函数传递的最大前导 0 位数，mean( *R* 1、…、 *Rp* )是它们的算术平均值。前两个因素，常数和 *p* ，修正了单独使用 2^(mean( *R* 1、…、*RP*)**会引入的偏差。这些因素我们就不多说了。如果仅使用一个散列函数，则 *R* 1，…， *Rp* 的平均值将是 R1。使用多个哈希函数时，单个值会被平均值替换。正是这一点减少了方差。**

****用调和平均值代替算术平均值****

**根据[2]，在[4]中观察到，R1 到 Rp 的最大值不成比例地对平均值中的噪声产生影响( *R* 1，…， *Rp* )。这可能是如下的直觉。**

**假设流中有 *N* 个事件。每个哈希函数 *i* 看到其中的 *N* / *p* 。因此，对于比 1 大得多的 *p* ，与当 *p* 为 1 时相比，从更小的样本 *N* / *p* 中估计 *R* i。这导致了估计的误差。因为在估算 R 时我们使用了最大值运算，所以更是如此。最后，取 2^(mean( *R* 1，…， *Rp* ))进一步放大噪声。**

**当然，使用一个远大于 1 的 *p* 仍然比使用 *p* = 1 要好。问题是，我们是否可以通过用其他东西替换 *R* 1、…、 *Rp* 的算术平均值来进一步提高估计值？**

**事实证明，是的。从取算术平均值切换到*谐波*平均值。众所周知，算术平均值受到异常值的过度影响(在我们的例子中，Ri 过大)。相比之下，调和平均值更倾向于较小的 Ri，因此对右尾异常值更稳健。**

**这个增强序列的最终数据结构被称为*超对数对数* (HLL)。**

****可制造性****

**现在假设事件以两个流的形式到达，由两个不同的服务器独立处理，这两个服务器可能相距很远。你在想象一个分布式的环境。(实际上可能有数千个服务器，而不仅仅是两个。)**

**我们希望每个服务器都能处理它的数据流。然而，我们还希望跨两个流的事件计数不同。为了做到这一点，我们需要我们的数据结构是可合并的。**

**向数据结构中添加可合并性支持可以加速其在分布式设置中的使用。我们可以高效简洁地独立处理大量的流，然后在需要连接流中的点时合并数据结构。**

**好了，数据结构应该支持合并操作，从两个实例构建数据结构的新实例。这个新实例是两者的“联合”。如果您将两个流合并，并直接从它构建一个实例，那么您将会得到它。这可以描述如下。**

**构建(s1) +构建(s2) =构建(s1+s2)**

**其中左手边的+表示*数据结构*合并操作，右手边的+表示*流*合并操作。**

**只要两个实例使用相同的“优步”散列函数、相同的 *q* 和相同的 *n* ，HLL 就是可合并的。对于每个 *i* ，合并实例的 Ri 就是输入实例的 *R* i 的最大值。**

**只要实例使用相同的散列函数，最小散列数据结构也是可合并的。**

****总结****

**这篇文章研究了计算到达一个潜在无限流中的不同事件的数量的问题。这个问题有很多用途，例如，计算网站的不同访问者的数量。**

**将问题简化为获得计数的估计值，而不一定是其精确值，这为概率数据结构打开了大门，当数据到达时，概率数据结构可以有效而简洁地捕获有关数据的某些信息。估计需求数量所需的信息，即何时需要。这种数据结构还支持可合并性，这允许它们在任意复杂的分布式设置中使用。也就是说，可能在地理上分散的大量流中的每一个可以在本地被处理，并且数据结构根据需要被合并以估计计数，就好像它来自单个合并的流一样。**

****延伸阅读****

1.  **[计数问题——维基百科](https://en.wikipedia.org/wiki/Count-distinct_problem)**
2.  **[HyperLogLog in Presto:更快的基数估计 Meta 工程](https://engineering.fb.com/2018/12/13/data-infrastructure/hyperloglog/)**
3.  **[概率计数和莫里斯计数器](https://courses.engr.illinois.edu/cs498abd/fa2020/slides/04-lec.pdf)**
4.  **[数据库应用的概率计数算法](https://hal.inria.fr/inria-00076244/file/RR-0313.pdf)**
5.  **[超级日志—维基百科](https://en.wikipedia.org/wiki/HyperLogLog)**