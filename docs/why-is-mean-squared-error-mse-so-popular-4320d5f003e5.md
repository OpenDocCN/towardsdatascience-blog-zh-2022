# 为什么均方差(MSE)这么受欢迎？

> 原文：<https://towardsdatascience.com/why-is-mean-squared-error-mse-so-popular-4320d5f003e5>

## 快速浏览一下大家最喜欢的损失函数

![](img/8d24e13f390877357967d11b3776bd90.png)

作者创造的形象。

# 太有创意了，很痛

作为一名正在康复的统计学家，我会第一个告诉你，我的人民是一群痛苦的墨守成规的人。人工智能爱好者喜欢更多的[科幻味道的名字](http://bit.ly/mfml_096)，统计爱好者喜欢完全按照罐头上说的去做……这种态度没有比流行的[指标](https://bit.ly/quaesita_metricdesign) MSE 和 RMSE 更令人讨厌的了。

这些名字是——等等——字面意思是计算它们的方法。就像召唤一个非常温顺的小恶魔。

如何计算均方误差(MSE):

1.  *你发现了* [*错误*](http://bit.ly/quaesita_babymse) *。*
2.  你纠正了那些错误。
3.  *取误差平方的平均值。*

哒哒，那是 MSE。

如果你在寻找均方根误差(RMSE)，你只需要在最后取一个平方根。

*4。你拿根。*

是的，这些公制名称是如此有创意，它伤害。它们真的只是反向的配方。

如果你从这个快速的解释中发现了 MSE 是什么，请继续阅读！如果你不确定什么是“错误”和/或你感到有点困惑，请快速浏览我的介绍 MSE 演练[这里](http://bit.ly/quaesita_babymse)。

观看我的课程中计算和优化的 MSE:[bit.ly/mfml_006](http://bit.ly/mfml_006)

# 婴儿的第一损失函数

均方差(MSE)是众多*指标*[](http://bit.ly/quaesita_opera)**中的一个，你可以用它来衡量你的 [**型号**](http://bit.ly/quaesita_emperorm)**的性能。如果你上了一堂 [**机器学习**](http://bit.ly/quaesita_simplest) 课，你很可能会在教学大纲中很早就遇到它——它通常是婴儿的第一个 [**损失函数**](http://bit.ly/quaesita_emperorm)*[**连续**](http://bit.ly/quaesita_datatypes) 数据。****

*****(如果你对任何一个加粗的***单词的意思不清楚，你可能会想通过链接对每个概念做一个温和的介绍。)******

*****你已经知道 MSE *是什么了，但是为什么它如此受欢迎呢？为什么好像是大家最喜欢的评分功能？*****

*****有几个原因，有些甚至是很好的原因。*****

*****为什么我们可能希望计算 MSE？*****

1.  *******绩效评估**:我们的模型表现如何？*****
2.  *******型号** [**优化**](https://bit.ly/mfml_045) :这是最合适的吗？我们能让模型更接近我们的数据点吗？*****

*****性能评估和优化是两个不同的目标…没有宇宙法则说你必须对两者使用相同的函数。如果你继续呆在[应用人工智能/人工智能](http://bit.ly/quaesita_fail)的话，理解这种微妙之处将会减轻很多未来的困惑。*****

*****对于这个讨论，我假设你理解如何以及为什么一个函数被用于评估和优化，所以如果你对此模糊不清，现在可能是一个绕一个小弯路的好时机。*****

*****说到 ***型号*** ***评测*** ，MSE 就是垃圾。说真的。它作为一个[度量](https://bit.ly/quaesita_metricdesign)有很多问题，首先是它的规模不对(这个问题通常通过用平方根代替 RMSE 来解决)，但并没有就此结束。它还加重了离群值的权重，使得 MSE 和 RMSE 都难以解释。没有一个能准确地反映出 ***的含义*** ，这对于一个想知道他们的[模型](https://bit.ly/quaesita_emperorm)平均有多错误的人来说是最感兴趣的。为此，理想的度量标准是所谓的 [MAD](https://bit.ly/quaesita_msemad) 。没有理由不使用 MAD 进行评估——它很容易计算。*****

*****那么，为什么每个人都对 MSE 如此着迷呢？为什么是你学习的第一个模型评分函数？因为它真的有不同的用途:优化，而不是评估。*****

*****如果你想使用优化算法(或微积分)快速找到给你最好的理想参数设置— [最优！](http://bit.ly/mfml_046) —性能，有一个 ***方便的*** 功能配合工作真好。这一点很难超越 MSE。你学过的一阶导数是 x，这是有充分理由的——在微积分中，正方形让事情变得超级简单。微积分 101 的下一课是如何处理常数和求和，因为这些也非常简单。你猜怎么着？平方、总和以及常数(1/n)就是 MSE 的全部公式！*****

*****朋友们，这就是 MSE 如此受欢迎的真正原因。务实懒惰。这是最容易优化的模糊合理的误差函数。这就是为什么它是勒让德和高斯在 19 世纪之交使用的第一个回归模型……也是为什么我们今天仍然喜欢它。*****

*****但是它能满足你所有的需求吗？它是否在所有条件下都优于其他损失函数？当然不会，尤其是当你的数据中有大量异常值时。*****

*****实际上，你经常会用到两个函数:一个损失函数和一个 ***独立的*** 绩效评估指标。点击此处了解更多信息。*****

*****现在您已经知道了喜欢 MSE 的原因，您还可以自由选择其他可用的损失函数，尤其是当您拥有大量计算资源和/或较小数据集时。*****

# *****感谢阅读！YouTube 课程怎么样？*****

*****如果你在这里很开心，并且你正在寻找一个为初学者和专家设计的有趣的完整的应用人工智能课程，这里有一个我为你制作的娱乐课程:*****

# *****寻找动手 ML/AI 教程？*****

*****以下是我最喜欢的 10 分钟演练:*****

*   *****[AutoML](https://console.cloud.google.com/?walkthrough_id=automl_quickstart)*****
*   *****[顶点艾](https://bit.ly/kozvertex)*****
*   *****[人工智能笔记本](https://bit.ly/kozvertexnotebooks)*****
*   *****[ML 为表格数据](https://bit.ly/kozvertextables)*****
*   *****[文本分类](https://bit.ly/kozvertextext)*****
*   *****[图像分类](https://bit.ly/kozverteximage)*****
*   *****[视频分类](https://bit.ly/kozvertexvideo)*****

## *****脚注*****

******“损失函数”是“*目标函数*”的[机器学习](http://bit.ly/quaesita_emperorm)词——它们是一回事。*****