<html>
<head>
<title>The Challenge Of Interpreting Language in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中口译语言的挑战</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-challenge-of-interpreting-language-in-nlp-edf732775870#2022-01-31">https://towardsdatascience.com/the-challenge-of-interpreting-language-in-nlp-edf732775870#2022-01-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="27ea" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">自然语言处理中口译语言的挑战</h1></div><div class=""><h2 id="550b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么教机器理解语言如此困难</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/653951135ad17329a786f7f13b3cd993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RCecJSieJ8pLKpx3"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@rey_7?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Rey Seven </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="503e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们的机器理解文本是一项艰巨的任务。尽管在这方面已经取得了很多进展，但我们距离创造一种将语言无缝转换成机器可读数据的方法还有很长的路要走。</p><p id="7535" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们面对它；我们的语言很复杂。</p><p id="9cf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与整齐地由行和列组成的表格以及由RBG值在固定范围内的像素组成的图像不同，我们说的和写的单词不遵循严格的结构化系统。</p><p id="ae3e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">鉴于我们的灵活性，在过去200万年的人类文明中，我们一直能够做到这一点(这是一次不错的尝试)。不幸的是，当我们试图教计算机理解我们复杂的系统时，我们语言中的谬误开始困扰我们。</p><p id="4b42" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了更好地理解NLP从业者面临的挑战，从语言学家的角度来审视我们的语言是理想的。</p><p id="2c2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看让我们的语言变得晦涩甚至有时无意义的一些因素。</p><p id="221c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注:本文主要以英语为主。讨论的一些特性可能不适用于其他语言。</p><h2 id="4a9f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">单词序列</h2><p id="9224" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在口语和书面语中，单词的顺序很重要。一篇文章的语义价值不仅在于单词本身，还在于单词的顺序。</p><p id="3f7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑下面几对句子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a20f" class="lv lw it mu b gy my mz l na nb">Case 1:<br/>"The cat ate the mouse."<br/>"The mouse ate the cat."</span><span id="2fa7" class="lv lw it mu b gy nc mz l na nb">Case 2:<br/>"I had fixed my laptop."<br/>"I had my laptop fixed."</span></pre><p id="9375" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这两种情况下，即使句子有相同的单词，它们的语义是不同的。</p><h2 id="9b16" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">同义词</h2><p id="d456" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">同义词指的是彼此意思相同或相似的词。您很可能对它们很熟悉，但这里有几个例子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="59af" class="lv lw it mu b gy my mz l na nb">1: {great, amazing, fantastic}<br/>2: {big, huge, enormous}<br/>3: {costly, expensive, pricey}</span></pre><p id="8f37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用多种方式表达相同的信息会增加复杂性，这是NLP模型必须考虑的。</p><h2 id="693f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">同音异义词</h2><p id="a6cf" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">同音异义词是指拼写和发音相同，但有多种含义的词。</p><p id="1f20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在对话中，根据上下文，很容易确定所指的是什么意思。这里有一个例子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5e62" class="lv lw it mu b gy my mz l na nb">"The fishes are swimming in a tank."<br/>"The military unit was supplied with a tank."</span></pre><p id="fa6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据所提供的上下文，我们可以很容易地说出每个场景中“tank”的定义。然而，让计算机做同样的事情是一个挑战。</p><h2 id="e682" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">讽刺</h2><p id="701d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">讽刺，通俗地说，就是说一些与你想说的意思相反的话(通常是一种嘲弄或嘲笑的形式)。它早已融入我们的日常对话。它也存在于文本中，常见于个人聊天等交流形式中。</p><p id="af95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我相信我们都见过类似以下的在线评论:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="11f9" class="lv lw it mu b gy my mz l na nb">"What a book! After 50 pages in, I only dozed off twice!"</span></pre><p id="a248" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，这种现象对人类来说很容易察觉，但对计算机来说就不那么容易了。不幸的是，未能检测讽刺会妨碍需要检测情感(例如，情感分析)的NLP应用的性能。</p><h2 id="8f5a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">未知单词</h2><p id="40d1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">NLP模型也有可能遇到不认识的单词。这些词不包括在用于训练模型的数据中。这类单词的例子包括新词汇、拼写错误的单词、俚语和缩写。</p><h1 id="351f" class="nd lw it bd lx ne nf ng ma nh ni nj md jz nk ka mg kc nl kd mj kf nm kg mm nn bi translated">NLP中的当前模型</h1><p id="d1c8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">研究人员进行了无数的研究，以开发算法和模型，使计算机能够向量化文本，尽管我们的语言错综复杂。</p><p id="2aeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看其中的几个。</p><h2 id="c1df" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">基于计数的模型</h2><p id="79d1" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">像单词袋或TF-IDF这样的模型经常被介绍给从自然语言处理开始的新手。他们对文本进行矢量化的方法很简单，主要基于单词的频率来评估文本。</p><p id="b5d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模型易于大规模部署，可用于许多应用。然而，他们的矢量化方法忽略了单词的顺序以及单个单词的语义值。</p><p id="621a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，这里有两个非常简单的句子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="bcdd" class="lv lw it mu b gy my mz l na nb">"Pigeons fly."<br/>"Eagles soar.</span></pre><p id="ea5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很相似，对吧？</p><p id="6d88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，对于单词袋或TF-IDF模型，这些句子的余弦相似度为0。</p><p id="339a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用基于计数的模型，同义词如“飞”和“翱翔”以及来自同一类别的词如“鸽子”和“鹰”将被视为完全不同的实体。</p><h2 id="2257" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">深度学习模型</h2><p id="836a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了解决基于计数的模型的局限性，一些研究转向深度学习模型作为向量化文本的手段。</p><p id="6c70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，word2vec模型使用浅层神经网络根据每个单词周围的单词来评估每个单词。这解决了基于计数的模型无法保留给定文本的语义值的问题。</p><p id="b95d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，word2vec模型有其自身的局限性。</p><p id="1431" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，它不能正确识别同音异义词的不同含义。该模型不能识别在正文中找到的单词的版本。</p><p id="31e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其次，它无法容纳未用于训练模型的未知单词。</p><p id="2e4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，作为深度学习模型，它需要大量的数据。深度学习模型的性能只有在用高质量和高数量的数据训练时才能达到令人满意的水平。</p><p id="dc1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了演示，让我们使用从Kaggle(无版权)获得的几篇BBC文章来创建word2vec模型。此演示的数据可在<a class="ae ky" href="https://www.kaggle.com/pariza/bbc-news-summary" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="ebdf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们加载。txt文件，并将业务类别中的所有文本合并成一个语料库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="a729" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在用NLTK库对语料进行预处理之后，让我们用它来训练一个word2vec模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="76c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于模型，我们来看5个与“金融”最相似的词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/d5647f8cd7954575de6d46b1ba2b809e.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*WZpZbvf9H0PZGpN723qg5w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="c16e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如你所见，被认为与金融最相似的5个词在商业环境中并没有那么紧密地联系在一起。然而，这样的结果是可以预期的，因为模型的输出受到用于训练它的语料库的限制。不能期望这样的模型充分执行。</p><h2 id="366e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">基于变压器的模型</h2><p id="4fdc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">广泛的研究导致了基于变压器的模型的出现。这些模型的编码器-解码器架构允许计算机理解更复杂的文本。他们能够处理同音异义词，甚至是不认识的单词。</p><p id="ee30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种模型可用于执行高级任务，如文本摘要和机器翻译。</p><p id="941f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于变压器的模型的例子包括谷歌的变压器双向编码器表示(BERT)模型和OpenAI的GPT-2。</p><p id="35dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这些模型非常复杂，但它们的性能代价很高。字面上。</p><p id="a416" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些模型具有复杂的体系结构，并用数十亿个单词进行训练。因此，培训和部署他们会产生很高的成本。</p><p id="4a4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自然，它们是为更高级的应用程序保留的。</p><p id="1fd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用变压器完成简单的NLP任务就像租一辆豪华轿车去杂货店一样。</p><h2 id="673d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9bdf01f3fa58ad68a2b478d441ff0c98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EoSJtK4fu5yJpsDF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@prateekkatyal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普拉蒂克·卡蒂亚尔</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="e550" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你现在对我们语言的构成是如何让计算机理解我们的语言变得如此困难有了一些了解。</p><p id="52aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在NLP中显然还有其他困难的障碍需要面对(例如，缺乏对数据的可访问性)，但是认识到有多少障碍源于我们语言的无组织本质是很重要的。</p><p id="458d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着我们继续尝试实现更复杂的NLP技术，让我们的计算机理解我们的语言，尽管它们是谬误的，仍将是一个持续的挑战。</p><p id="4f6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我祝你在NLP的努力中好运！</p><h2 id="8c22" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参考</h2><ol class=""><li id="0d37" class="nr ns it lb b lc mo lf mp li nt lm nu lq nv lu nw nx ny nz bi translated">谢里夫，P. (2018)。BBC新闻摘要，第2版。于2022年1月30日从https://www.kaggle.com/pariza/bbc-news-summary.取回</li></ol></div></div>    
</body>
</html>