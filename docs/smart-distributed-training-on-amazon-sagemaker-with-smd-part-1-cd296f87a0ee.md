# 带 SMD 的 Amazon SageMaker 上的智能分布式培训:第 1 部分

> 原文：<https://towardsdatascience.com/smart-distributed-training-on-amazon-sagemaker-with-smd-part-1-cd296f87a0ee>

## 如何选择与您的训练实例的功能相一致的分发算法来增加吞吐量和降低成本

![](img/85d4b7462f5f8b42eb1a7fb80ce14346.png)

雅尼克·菲舍尔在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

优化训练作业运行时性能的一个关键步骤是调整算法，以便最大限度地利用训练环境中的资源。这需要彻底了解你的资源，(计算设备的数量和类型，可用内存，通信带宽等。)以及分析其利用情况的适当工具。调整您的训练算法以充分利用您的资源可以提高您的训练速度并降低您的训练成本。这尤其适用于您的**分布式训练算法**，它严重依赖于运行在多个处理器(例如，GPU)上的多个进程之间的高速通信。未能考虑培训环境的具体情况会导致沟通瓶颈、高延迟、培训速度降低和成本增加。

这是关于优化分布式培训主题的三篇文章的第一部分。在第一部分中，我们将简要回顾执行分布式培训的不同方法，同时强调它们对底层培训环境的依赖性。在第二和第三部分中，我们将展示两个例子，说明分布式训练方法和算法的选择如何影响训练速度。运行分布式培训有许多不同的流行框架。在本帖中，我们将使用 [Amazon SageMaker 的分布式培训库](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html) (SMD)进行演示。虽然我们的重点是 Amazon SageMaker 环境，但是这篇文章的内容同样适用于任何其他培训环境和分发算法。这篇文章中的框架选择不应该被看作是一种认可。对你来说，正确的选择将高度依赖于你的项目的细节，并应考虑到最新的技术和实用工具。

# 分布式培训概述

有关分布式培训的更详细概述，请参见[此处](https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/distributed-training.html)和[此处](https://huggingface.co/docs/transformers/v4.15.0/parallelism)。

在分布式培训作业中，对多名员工进行培训。在这篇文章中，我们将假设工人是 GPU。分配培训工作有两个主要原因:

1.  **训练加速**:通过结合多个 GPU 的力量，我们可以加快训练过程。
2.  **大模型尺寸**:当一个模型太大而不适合单个 GPU 的内存时，我们需要多个 GPU 来训练。

分布式训练有两种，**数据并行**训练(又名**数据分发**)和**模型并行**训练(又名**模型分发**)。

在**数据并行**分布式训练中，每个 GPU 维护其自己的完整模型副本，并对训练数据的不同子集(本地批次)执行每个训练步骤。在每个训练步骤之后，它发布其结果梯度，并考虑所有 GPU 学习的组合知识来更新其自己的模型。用 *k* 表示 GPU 的数量，用 *b* 表示**局部批量**，对*k*GPU 进行分布式训练的结果是，在每一个训练步骤中，模型都在 *k*b* 样本的**全局批量**上进行训练。理想情况下，在 *k* 个 GPU 上执行数据分布式训练会将训练速度提高数倍 *k* 。然而，由于*梯度共享*的额外开销，这种线性比例加速不应被视为理所当然。实际的训练加速将取决于许多因素，包括 GPU 间的通信带宽、用于共享梯度的算法以及模型架构。查看[这篇博文](/a-guide-to-highly-distributed-dnn-training-9e4814fb8bd3)了解更多关于数据分布式培训的信息。

在**模型并行**分布式训练中，模型分布在几个 GPU 上。有几种方法可以分布模型，包括:垂直(管道并行)、水平(张量并行)和通过模型分片。

在**流水线并行**解决方案中，模型的单个副本将被分成 *N* 个部分，每个部分将包含一个或多个层。每个部分都将存储在其中一个 GPU 上。训练数据将被输入到托管输入层的 GPU 中，并将向前流经模型的 *N* 部分，然后向后用于梯度计算。在向前和向后传递期间，模型部分之间的数据流在宿主 GPU 之间传递。流水线并行化的主要挑战之一是试图减少 GPU 空闲时间。在一个简单的实现中，您会发现在训练步骤中的任何给定点只有一个 GPU 是活动的。在实践中，现代流水线算法将输入样本分成微批，并使用复杂的调度算法来减少空闲时间。

在**张量并行**解决方案中，有时被称为**张量切片**，模型张量的子集将跨 GPU 划分，并且将添加适当的通信操作以跨 GPU 传输输入和输出数据。请注意，虽然被归类为模型并行技术，但张量并行与数据并行有一些共同的属性，即每个 GPU 都有自己独特的小批量数据，并且没有并行化的张量是重复的。参见[此处](https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/model-parallel-extended-features-pytorch-tensor-parallelism-how-it-works.html)了解张量并行性如何工作的更多细节。

在**分片数据并行**中，有时也称为**零功耗数据并行**，模型参数在所有 GPU 之间进行分片。每个参数将驻留在单个 GPU 上，由单个 GPU 拥有和更新。与标准数据并行性一样，完整的训练步骤将在每个独立的小批量 GPU 上执行。当 GPU 达到存储在 *gpu_j* 上的*参数 _i* 时，它将需要从 *gpu_j* 中提取其权重来执行所需的计算，但它随后会立即删除权重，以便它不会占用任何本地内存。这在向前和向后传球中都发生。一旦计算出梯度更新，GPU 需要将它们传达给它们各自参数的所有者。注意，这种方法有时(例如，这里的[是](https://www.deepspeed.ai/tutorials/large-models-w-deepspeed/))被归类为数据并行方法，而不是模型并行方法。

**3D 并行**是在[这篇论文](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)中引入的一个术语，指的是上面讨论的数据并行和模型并行策略的任意组合。3D 并行技术的目标是结合各种技术的优势。

**所有方法的共同点是数据在 GPU 之间传递。然而，GPU 之间的通信路径的数量和细节、每个训练步骤的数据跳数以及传递的数据量可能会有很大差异。**

现在你可能会对自己说，“哇，这么多进行分布式培训的方法，多么好的概述啊，但是我怎么知道该用哪一种呢？”。我想让你知道我能感受到你，我的朋友。事实是，弄清楚这一点并不简单。(我想说这是 NP 难的，但我手头没有资料支持这一点。)最佳选择将取决于您的模型的细节以及您的基础培训环境的细节。如果你的模型足够小，可以放入单个 GPU 的内存中，那么你可能会选择**数据并行分布式**算法。如果您的模型太大，不适合单个 GPU，但 GPU 之间的通信带宽特别小，那么您可能会发现管道并行化是最佳选择。

有许多资源(例如这里的[和这里的](https://www.deepspeed.ai/tutorials/large-models-w-deepspeed/#deciding-which-technology-to-use)[试图根据模型和环境的细节来提供决策指南。一旦选择了高级策略，包括 SMD 在内的一些库将自动执行一些特定的配置。在撰写本文时，还没有 API(据我们所知)能够自动完成寻找和构建最佳分布式训练拓扑的整个过程。我们只能希望在某个地方，有人正在研究这样的解决方案。](https://medium.com/pytorch/pytorch-data-parallel-best-practices-on-google-cloud-6c8da2be180d)

在下一节中，我们将深入研究在选择分布式训练方法和算法时应该考虑的基础训练环境的一个特定方面。

# 一些 GPU 到 GPU 的链接与其他链接不同

如上所述，所有分布式训练算法都依赖于 GPU 之间的数据通信。该数据可以是参数权重、梯度和/或激活。该通信可以是直接的或者经由某种形式的中介(例如，参数服务器)。它可以通过几种不同的介质，如以太网、pci 或 [NVLink](https://en.wikipedia.org/wiki/NVLink) 。在大多数现代训练系统中，NVLink 支持同一实例中 GPU 之间的最高数据传输速率。因此，许多分布式训练算法将选择直接的 GPU 到 GPU 数据传输。在许多情况下——当然，如果所有的 GPU 都在一个实例上——这确实可能是最佳选择。然而，当在多个实例上训练时，每个实例都有多个 GPU，**重要的是要意识到这样一个事实，即两个不同实例上的两个 GPU 之间的数据传输速度和延迟可能会与同一实例上的两个 GPU 有很大不同**。这有几个原因，包括:

1.  计算实例之间的网络带宽往往比单个实例上直接 GPU 到 GPU 链接的带宽低得多。
2.  网络带宽由与分布式训练算法无关的其他类型的数据通信共享，例如训练样本加载、检查点保存等。
3.  实例之间的距离会导致一定量的延迟，这会对分布式训练算法的速度产生负面影响。(注意，在撰写本文时，SageMaker APIs 不允许您为所有实例强制使用一个单一的[集群放置组](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html#placement-groups-cluster)。)

在某些情况下，您可能有一个专用的网络接口来促进节点间的通信，比如 [Amazon EFA](https://aws.amazon.com/hpc/efa/) 。然而，它仍然不是单实例直接 GPU 到 GPU 链接的对手。

理想情况下，我们希望我们的分布式训练算法能够考虑到不同类型的 GPU 到 GPU 连接之间的差异。我们希望这种方法优于一种简单的方法，在这种方法中，所有 GPU 到 GPU 的连接都以相同的方式处理。在接下来的部分中，我们将用两种方式对此进行测试，首先使用 [SageMaker 分布式数据并行](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html) (SDP)，然后使用 [SageMaker 分布式模型并行](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html) (SMP)。

# 后续步骤

请务必查看帖子的第二部分，我们将在其中演示[亚马逊 SageMaker 的分布式数据并行库](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)如何以区分节点内和节点间 GPU 对的方式支持数据分发。