# 初学者的 9 个最佳机器学习模型

> 原文：<https://towardsdatascience.com/9-best-machine-learning-models-for-beginners-2bcd8386774d>

## 你应该学习的模型有线性回归、支持向量机的逻辑回归和主成分分析

![](img/f939cfa6fc7743edb58625d21a683d35.png)

照片来自 Pexels，由 [Kindel Media](https://www.pexels.com/photo/dawn-woman-coffee-industry-9028877/)

机器学习是计算机科学中最令人着迷的领域之一。

它在许多行业都有应用，任何人都可以了解它。

在这篇博客文章中，我将为初学者回顾一些 9 大机器学习模型，这样你就可以开始学习 ML 了！

# 1.线性回归

线性回归是你应该了解的第一批机器学习模型之一。这是一种简单的方法来衡量变量之间的关系，这使得它非常容易理解。

如果你想根据平方英尺或卧室数量来预测房价，这将是一种方法！训练后，线性回归会为最符合数据的直线生成一个方程。

## 为什么要用线性回归？

线性回归的主要好处是它非常容易解释。在训练一个模型后，你可以很容易地理解两个变量之间的关系，这在某些情况下，当你需要解释你的机器学习模型如何做出像欺诈检测或流失预测这样的决策时，效果很好。

线性回归方程是总结两个变量之间关系的好方法。它可用于根据一个变量的已知值预测另一个变量的值。

## 应用程序

可以使用线性回归的实际应用包括:

*   根据平方英尺或卧室数量预测房价
*   根据库存水平和其他因素预测销售
*   确定哪些变量对客户的购买决策很重要

# 2.逻辑回归

逻辑回归是另一个你应该尽早学习的模型。当因变量是分类变量(即只有有限数量的可能值)时，使用逻辑回归。

它可用于预测某件事是否会发生(例如，某人是否会购买某件产品)或确定哪些因素对确定感兴趣的结果最重要。

## 为什么使用逻辑回归？

逻辑回归的主要好处是解释结果相对容易。这是因为系数(即参数的估计值)对应于每个变量对结果预测的贡献程度。

简单来说，逻辑回归的工作原理是试图找到将数据分成两组的最佳直线。一组由因变量等于 1 的所有情况组成(即预测他们会购买该产品)，另一组由因变量等于 0 的所有情况组成(即预测他们不会购买该产品)。

## 应用程序

您可以使用逻辑回归的实际应用包括:

*   确定决定学生成功的最重要因素
*   在给定库存水平和其他因素的情况下，预测客户是否会购买产品
*   根据个人喜好和其他个人信息来确定某人是否愿意成为捐献者。

# 3.决策树

决策树是另一种类型的机器学习模型，通常用于分类任务。

它们的工作方式是将数据集分成越来越小的子集，直到每个子集只包含具有相似属性的实例，这意味着您可以通过查看新示例在树结构中所处位置的相关特征来轻松对其进行分类。

## 为什么要使用决策树？

决策树的主要好处是它们相对容易理解和解释。这是因为树结构使得很容易看到每个特征如何对新示例的分类做出贡献。

决策树的另一个好处是，它们对过度拟合相对健壮，这意味着即使你有很多数据，它们仍然会做出很好的预测。这是因为树结构有助于减少数据中的噪声，并区分不同类型的示例。

## 应用

随机森林可能有用的实际应用包括:

*   识别植物或动物的种类
*   预测房价
*   根据消费习惯对顾客进行分类

# 4.随机森林

随机森林是一种集成机器学习模型，这意味着它是通过组合多个模型来创建的。众所周知，集合方法在减少过度拟合方面特别好

在随机森林的情况下，这涉及到创建许多决策树，然后使用它们来投票决定每个实例中的最佳预测。

## 为什么使用随机森林？

使用随机森林的好处之一是它对过度拟合相对健壮，这意味着即使你有很多数据，它仍然会做出好的预测。这是因为森林中的单个决策树能够抵消数据中的一些噪声。

使用随机森林的另一个好处是相对容易解释。这是因为每个决策树都可以单独查看，它们之间的交互可以使用一个称为“森林图”的图形来可视化。

## 应用

随机森林可能有用的实际应用包括:

*   预测葡萄酒的质量
*   星系分类
*   确定某人将来是否可能患糖尿病

# 5.k-最近邻

k-最近邻算法(kNN)是一个简单的机器学习模型，它存储所有可用的案例，并通过与这些已知案例的相似性对新案例进行分类。

他们的工作方式是通过查看一组训练示例的属性，然后使用这些信息来预测新示例是否具有与这些已知案例相似或不同的属性。

这使得他们可以做出很好的预测，即使你只有少量的数据。

## 为什么要用 K 近邻呢？

k-NN 的主要优点是运行速度非常快，效率非常高，适合在大型数据集上使用。

## 应用

k-NN 可能有用的实际应用包括:

*   根据过去的交易预测客户行为
*   出于营销目的将客户分成不同的群体
*   使用医学图像确定肿瘤是良性的还是恶性的

# 6.朴素贝叶斯

朴素贝叶斯算法是一种简单的分类算法，常用于文本分类。它基于贝叶斯定理，可用于分类和回归任务。

他们的工作方式是通过使用统计方法来预测一个新的例子是否属于一个类别或另一个类别，基于它被赋予的特征。

## 为什么要用朴素贝叶斯？

朴素贝叶斯模型的一个优点是，您不需要像其他模型那样多的数据来获得良好的预测。

这是因为他们能够从不同示例之间的相似性中学习，而不会被数据集中不相关的细节所迷惑。

## 应用

朴素贝叶斯可能有用的实际应用包括:

*   根据内容识别垃圾邮件
*   预测某人将要说的下一个词
*   给动物图片分类

# 7.k 均值聚类

K-Means 聚类是一种用于聚类分析的技术，聚类分析是将数据点分组为聚类的过程。它可以用于识别数据中的模式，并提高机器学习模型的性能。

## 为什么要使用 K-Means 聚类？

k-means 聚类的一个优点是速度非常快，计算效率高。这使得它成为一种迭代细化集群的好技术，并且经常用于交互式数据挖掘。

k-means 聚类的准确性取决于您选择查看的聚类数以及这些聚类是如何定义的。但是，通过在算法初始化阶段选择适当的聚类中心，可以提高其预测能力

## 应用

k 均值聚类通常用于:

*   识别客户群
*   根据联系人或联系对社交网络进行细分
*   将大型数据集划分为预定数量的簇

# 8.支持向量机

支持向量机(SVM)是一种监督学习算法，可用于分类和回归任务。

它创建了一个超平面来分隔数据集中的不同数据类，最大化它们之间的距离，同时尽量减少错误分类示例带来的错误。

支持向量机已被证明在处理高维数据时表现良好，并经常用于文本分类或图像识别任务。

## 为什么要用支持向量机？

支持向量机的一个优点是，它们能够很好地从训练数据推广到新的例子。这使得他们不太可能过度适应你训练他们的数据，从而在实践中获得更好的表现。

与其他机器学习算法相比，它们的训练速度也相对较快。

## 应用

支持向量机的实际应用包括:

*   在句子中识别单词是名词还是动词
*   将图像分类为汽车或卡车
*   识别一个人的语音

# 9.主成分分析

主成分分析(PCA)是一种用于减少数据集中维数的技术。

它通过识别主成分来做到这一点，主成分是解释数据中最大差异的方向。PCA 可用于简化数据可视化并提高机器学习模型的性能。

## 为什么使用主成分分析

使用 PCA 的主要好处是减少了数据集中的维数。这使得数据更容易可视化，同时防止过度拟合并提高模型性能。

其他优势包括:

*   与线性模型一起使用时，提高了预测准确性
*   计算强度低于 k-均值聚类
*   有助于识别数据中的重要特征

# 选择一个并开始练习

这个列表中的模型从简单到复杂，它们使用不同类型的方法。在大多数情况下，这些模型可以用于任何类型的可用数据集。

你练习使用它们的次数越多，你就越能理解每一种方法何时最有效。然而，当它来临时，没有什么可以代替直接投入到一个项目中去尝试！

[**与 5k 以上的人一起加入我的电子邮件列表，免费获得“完整的 Python 数据科学备忘手册”**](https://dogged-trader-1732.ck.page/python_cheat_sheet)