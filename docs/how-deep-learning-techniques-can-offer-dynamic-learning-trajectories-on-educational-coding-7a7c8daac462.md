# 深度学习技术如何在教育编码平台上提供动态轨迹——问题陈述

> 原文：<https://towardsdatascience.com/how-deep-learning-techniques-can-offer-dynamic-learning-trajectories-on-educational-coding-7a7c8daac462>

在这个系列中，我将介绍我在鲁汶大学计算机科学系所做的论文的主要发现。这篇博文详细阐述了问题陈述，让你更好地理解为什么适应性学习轨迹是重要的，并给出了一些如何实现它的线索。

![](img/b5edd502e505ecfc9346f335a6847b4d.png)

[Unsplash](https://unsplash.com/s/photos/learn-coding?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上 [AltumCode](https://unsplash.com/@altumcode?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 拍摄的照片

学习编程语言的教育平台通常以一种相当静态的方式提供服务，学习者一旦注册了一门课程，他们的轨迹就固定了。然而，这应该被理想地调整，以确保更熟练的学习者不会因为材料太简单而失去动力。对于速度较慢的学习者来说也是如此，他们应该遵循一个有更多重复的轨迹。

因此，本系列的主要目标是开发一个系统，该系统将根据学习者的表现动态地调整他们的轨迹。为了创建这样一个系统，以及评估其性能，需要一个在线学习平台。在这里，E-Systant 前来救援。

# 电子系统

E-Systant 是一个在线学习平台，由鲁汶大学开发。它被用在计算机科学项目的“声明性语言”课程中，用来教授逻辑编程语言(Prolog)和函数式编程语言(Haskell)。该平台自 2015 年投入使用，已有超过 1500 名学生使用。通过这种方式，它积累了大量有价值的数据，这些数据将被证明对自适应系统的开发是有用的。但是，需要注意的是，只有当学生提交代码进行评估时，才会创建新的数据提交条目。因此，无法获得学生在短时间内的详细进步信息。

# 适应性学习

## 1.推荐下一个编程任务

实现自适应学习的方法之一是对下一个应该承担的编程任务提出建议。为了给出这些建议，将使用神经网络模型，根据 E-Systant 的历史数据进行训练。除此之外，我们将调查深度强化学习技术是否可以提高推荐的整体性能。

## 1.1 基于经典神经网络的模型

在第一阶段，模型将仅使用可用的提交数据作为输入特征进行训练。这里，每次提交都包含时间戳、提交的代码、已经获得的分数以及服务器执行代码所花费的时间..在第二阶段，这些模型将被扩展以附加特征，在一些特征工程之后被创建。这种额外功能的一个例子将是一个创建的技能组合，它捕捉学生对课程的某些概念的掌握程度。

大多数关于电子学习环境中自适应学习的文献要么使用协同过滤，要么使用基于内容的推荐，如[1]中所总结的。然而，自适应学习的深度学习方法目前还不是很常见。在[2]中，提出了基于深度学习的推荐框架，但没有给出具体的实现或实际结果。尽管如此，深度学习推荐模型正在应用于许多其他领域，如文献调查[3]所示。因此，本系列研究如何将这些深度学习模型应用于电子学习环境中。

## 技能组合

从概念上讲，技能组合最初应该是一个空间中的向量，其维度与课程中的概念一样多。向量在某一维上的长度应该表明学生对这个概念的理解程度。然而，由于概念不会彼此正交，进一步的优化将是使用嵌入空间，其中概念可以彼此相关。之后，嵌入空间应该被投影到更低维度的空间，以便学生的技能组合可以被学生和教师可视化。

我们不希望技能组合的概念是数据驱动的，因为技能组合本身将被用作神经网络中的额外输入特征。相反，我们将用作业中教授的概念来注释编程作业。示例概念可以是相当低级的，如“模式匹配”和“高阶函数”，也可以是更高级的，如“学生能够构建不同的概念”。

[4]和[5]已经完成了建立学习者档案的工作，但是他们更多地关注学习者的态度，而不是他们获得的技能。据我们所知，还没有其他工作基于学生在编程作业中的表现为他们创建技能组合。创建这样一个对已获得技能的概述，以及对用户和教师的可视化，在我们看来是对 E-Systant 平台的一个有价值的补充。

## 1.2 深度强化学习

除了经典的机器学习技术，还会尝试深度强化学习来给出建议。其思想是，状态应该代表已完成的任务，而动作应该代表下一步应该尝试的任务。奖励是学生在作业中获得的分数。

在[6]中，阐述了如何在电子学习环境中使用强化学习。此外，在[7]和[8]中，正在使用经典的 Q-learning，而\ cite { deep _ reinforcement _ learning _ e _ learning }实际上使用的是深度强化学习。因此，本文将研究他们的结果在我们的环境中复制得如何，以及深度强化学习的结果与经典的深度学习技术相比如何。

# 审查阶段的建议

学习者可以获得适应性反馈的另一种方式是向学习者提供他们最难理解的概念的见解。此外，在复习阶段(例如，当他们准备考试时)，可以向学习者推荐特定的编程作业，以便他们尽可能高效地填补知识空白。这一特点将在很大程度上依赖于前面提到的技能组合，从中可以确定学习者的优势和劣势。

# 文献学

[1] Shristi Shakya Khanal、P. W.C. Prasad、Abeer Alsadoon 和 Angelika Maag。基于机器学习的电子学习推荐系统。教育和信息技术，25(4):2635–2664，2020。
[2]小王，，，于，刘锡伟，袁勇，费。基于深度学习的网络学习推荐框架。2017 IEEE 系统、人和控制论国际会议，SMC 2017，2017-Janua:455–460，2017。
[3]，，，，孙，和易泰。基于深度学习的推荐系统:综述与展望。ACM 计算调查，52(1):1–35，2019。
[4] Alaa El-Halees。挖掘学生数据分析学习行为:教育系统案例研究。工作，(10 月)，2008 年。
【5】张怡颖，何，周依林，，
李。基于在线行为分析的智能电子学习学生模型。电气与计算机工程学报，2017，2017。
[6]Hamid r . Tizhoosh、Maryam Shokri 和 Mohamed Kamel。电子学习应用的强化代理。《高级信息和知识处理》, 289 页。2007.
[7]Youness Madani、Hanane Ezzikouri、Mohammed Erritali 和 Badr Hssina。使用新的推荐方法和强化学习在自适应电子学习平台中寻找最佳教学内容。环境智能和人性化计算杂志，11(10):3921–3936，2020。
[8]穆罕默德·布萨克苏、巴德尔·赫西纳和穆罕默德·厄立特里亚塔利。基于 Q 学习算法的自适应网络学习系统。Procedia 计算机科学，170:1198–1203，2020。