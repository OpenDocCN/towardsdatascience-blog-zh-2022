# 生成人工智能的归因问题

> 原文：<https://towardsdatascience.com/attribution-425f7ade46b0>

## 生成模型和人类一样依赖于它们的来源吗？

![](img/e2f38f7fcdb3048d628a995ef62d4d37.png)

当关于大型预训练生成模型的讨论触及“艺术家、程序员和作家的所有这些作品在他们不知情或未同意的情况下被用于商业产品/模型中怎么办？”，为什么这是可以的一个论点是这种模型与潜在搜索引擎的比较。事情是这样的:

> 作为一个人，你可以也确实在其他人的作品、代码片段和艺术作品中寻找灵感。生成模型与之类似，它只是为你在大量数据中进行搜索提供了一个方便的界面。

附注:这是关于生成模型在其常规生成过程中执行的训练数据的“潜在搜索”或“合成”。关于使用模型替代基于索引的搜索引擎，有一个相关但独立的讨论。例如，Metzler，Tay，Bahri 和 Najork (2021)提出了模型作为“领域专家”的愿景，为用户可能有的任何问题提供权威答案。Shah & Bender (2022 年)通过讨论搜索用户需要采取的多种行为来挑战这一愿景，这些行为根本不会得到试图产生一个明确答案的“领域专家”模型的支持(例如，在提炼他们的问题之前了解更多，考虑选项列表，不同来源背后的动机等)。

那么，生成模型的“潜在搜索引擎”观点有什么问题呢？

显然，自回归语言模型确实会根据提示搜索最有可能的完成。同样真实的是，人类的写作和艺术取决于所述人类在其生活中遇到的输入，以及为应对特定挑战而故意寻找的相关输入。在文学研究和艺术中有互文性的概念(巴赫金，1981；克里斯特瓦，1980；Barthes，1977)，涵盖了各种不同的文本/艺术作品相关的方式(或被读者认为相关)，如典故，引用，戏仿等。

但这种类比有一些重要的局限性，包括生成模型和人类灵感背后的机制的根本差异，商业模型的潜在社会影响规模，以及非常不同的利益相关者和资助者。这篇文章关注的是搜索引擎类比失败的一个特殊点:归属问题。

## 归因问题

当你使用搜索引擎时，你会找到一个特定的想法、作品或代码片段，你可以清楚地看到其来源。有参考(即使来源只知道 stackoverflow user02348)。重要的是，不存在任何想法/艺术作品/代码就在那里，可以作为你自己的作品自由使用的错觉。如果你的搜索空间不是网络，而是你自己的记忆或生活经历，你通常仍然知道值得引用的东西的来源(或者你在 Twitter 上问人们“有/没有 X 的电影/书籍/项目/论文是什么？”)

如果你是一名研究人员，你可能会有像 [Zotero](https://www.zotero.org/) 这样的东西来跟踪你的参考资料，以及一个巨大的书籍和论文数据库。即使你的消息来源本身来自其他地方，即使有人在你不知情的情况下说了同样的话，你在读者(和你自己)面前的可信度要求你披露你确实知道的参考文献。在这样做的过程中，你必须确保你真的相信消息来源是可靠的，并且你意识到它在你自己的推理中的作用。

注意，归属问题是双向的:当且仅当你知道并引用了你的资料来源时，为你的工作成果要求完全的荣誉才是可能的。这和原创程度是完全正交的。假设我发表了这篇博文，然后我发现别人已经发表了完全相同的文本:我仍然会知道我*发表的是我自己的作品。另一方面，如果我没有写这篇博客，而是让 GPT-3 生成它，甚至得到了完全相同的结果——我根本不能声称有任何贡献。在作为我自己的文本发表时，我的角色只是说“我将这解释为连贯的文本，并同意其内容”(我认为杰克·克拉克在国会作证时使用合成文本时就是这么做的)。如果我用 GPT-3 获得下一步写什么的“想法”——即生成连贯的文本部分，然后我会编辑——我会说什么呢？不确定。但是想法、风格、背景知识的数量等等。只会有一部分是我的。*

最近在 Reddit 上有一个关于 GPT-3 如何开始受学生欢迎的讨论，目的是避免写论文。除了学生们完全误解了练习的目的，以及浪费了老师的时间，这场讨论还强调了一个想法，即人工智能辅助写作者实际上不是因为写作而获得荣誉，而是因为“街头智慧”:他们能够利用系统并获得高分，即使他们的语言技能并不太好。有些人可能会说，这就像使用拼写检查器或类似 Grammarly 的服务来提高自己的写作水平，但很明显，生成完整或部分草稿在性质上是不同的:你不仅可以获得语言形式的帮助，还可以获得内容的帮助。

## 但是人们不也在做同样的事情吗？

是的，人们当然总是在别人的工作基础上发展。如果你想使用某些东西，你可以这样做——但社会已经制定了相当多的规范，关于你自己的工作有多少必须进入结果。因为这些规范随着时间的推移而演变，我们通常很清楚我们的来源。也许不是全部，但肯定是重要的。

任何音乐家都听过影响他们的其他音乐。艺术生去画廊，创意写作生看别人的书。他们和/或他们的老师甚至可能故意策划他们所接触的内容，以达到特定的结果。他们都可以接受采访，讲述他们的成长经历。这种解释将是不完整的，与批评家的想法不一致，但这不是重点:只是人们通常会保留至少一些对他们来说非常重要的事情的记忆。

另一个关键的区别是，如果他们的目标是成为一名原创艺术家/音乐家/作家，当他们建立在以前的工作基础上时，重点总是要加入足够多的他们自己的想法，下一代也可以从*他们*(而不仅仅是他们的“来源”)那里学到一些东西。我们是否能从生成模型中获得同样程度的创造力还远未可知。

特别是关于人工智能艺术:我根本不是艺术家，但它似乎实际上是风格(形状、配色方案等)，而不仅仅是艺术家花费一生开发的特定图像/艺术品，这也给他们带来了专业的认可。他们似乎非常不同意，这是可以的，只是挪用(Heikkil，2022)。[产卵人工智能](https://spawning.ai/)已经为艺术家建立了一个[工具](https://haveibeentrained.com/)来检测他们的作品何时成为流行训练数据集的一部分。

总之:不，生成模型不像人类在创作文本或艺术时一样，对他们可能“说”的事情进行同样的潜在搜索。一个关键的区别是，对人类来说，这不仅是一种由内容考虑驱动的认知活动，也是一种社会活动。我们敏锐地意识到何时需要归因，我们提供归因，并期望归因作为回报。当然，不同的人可能对何时归因是恰当的有不同的理解(基于他们的个人经验、对一个主题的熟悉程度、他们环境中的社会规范等)。)——但这并没有降低基本原则的真实性。

# 反论点

本着讨论的精神，这里是我看到的一些反对意见，以及我对它们的回应。

## 生成模型具有足够的创造性

要声称一个生成模型有足够的创造力而不用担心归因，我们首先需要定义“创造力”。有人举出了 DALL-E 的[鳄梨椅](https://openai.com/blog/dall-e/)这样的例子。对我来说，这里的创造力是由制定疯狂提示的人展示的，而模型展示了能够重组它所学习的视觉“概念”的组合性(在这种情况下，它学习了“椅子”、“木头”和“鳄梨”，以及视觉图式“椅子+材料”)。我们大多数人都画得不好，所以几乎任何处决都会让人印象深刻。但是，考虑一下这种作曲技能在语言领域会是什么样子，我们都足够精通:模型学习了“约翰喝了咖啡”和“玛丽喝了茶”，然后它能够产生“约翰喝了茶”。这看起来像鳄梨椅一样令人印象深刻的创意吗？

我也不会将创造力解释为随机性(例如，由 GPT-3 的温度设置控制)。如果我遇到写作瓶颈，不得不求助于随机的写作提示来摆脱困境，那倒不如说是一种缺乏创造力的*的症状，不是吗？此外，随着当前模型增加生成的随机性，可能会牺牲生成数据的事实正确性，因为它必然会进一步远离训练分布，并且没有概念一致性的机制。在生成的文本锚定于现实世界或一些长篇叙事的大多数场景中，创造性/无意义不是可接受的权衡。*

最后，在关于人工智能艺术或人工智能-人类合作的出版物中，“创造力”可能被讨论为生成的文本/艺术作品的一些外部特征，由评论家在一些美学维度上评分，如(Hitsuwari，，Yun，& Nomura，2022)。我认为这也不是这次讨论的创意的相关概念。由于我们正在谈论一个机器学习系统，对其输出的任何美学属性的评估都有与任何其他基准相同的问题:除非我们知道系统在训练中看到了什么，否则我们无法判断它是否实际获得了某种能力，或者只是鹦鹉学舌。到目前为止，我还没有看到给定所有训练数据的非常大的模型的研究(考虑到这些数据通常不会以可查询的形式完全公开)。因为从根本上说，当前的模型被优化以产生当前提示的统计上可能的完成，所以举证的责任在声称有创造性的一方。

我们从较小模型的研究中所知道的是，它们能够并且确实逐字重现训练数据的段落(Carlini 等人，2021；Carlini 等人，2022 年等)。记忆和抄袭的能力会随着规模的增加而增加(Lee，Le，Chen 和 Lee，2022)。有鉴于此，我认为，即使我们有一些一般性的证据证明生成模型有能力合成有意义的原创内容，这也是不够的:毕竟，人类也可以有创造力，但是老师们仍然怀疑学生的剽窃行为。对于一个统计学习者来说，一个给定的一代人有多有创造力(或可信)可能取决于它有多少证据，以及不同的数据点有多相似。因此，除非出售该模型的公司在特定情况下提供一些原创性保证，否则它只是将潜在抄袭的责任转嫁给不知情的客户。

## 我们可以只添加参考吗？

当介绍他们的“领域专家”端到端信息检索的愿景时，Metzler，Tay，Bahri 和 Najork (2021)主张一个添加一些参考的模型，此外还努力介绍有争议主题的“双方”。也许这是解决归因问题的一个简单方法——如果我们只是添加指向与生成的输出最相似的训练数据示例的指针？

假设你正在写一篇关于《变形金刚》中自我关注的深度学习博文。假设您的“书写辅助”模型将为您提供以下句子组合:

> 变形金刚中的自我注意机制能够全局计算面片之间的成对关系，从而实现大范围的特征交互。它被认为是查询和键/值对到输出的映射，每一个都由一个向量表示。一个众所周知的关于自我关注的问题是二次时间和记忆的复杂性，这在许多情况下会阻碍模型的可扩展性。

所有这些句子实际上都来自不同的研究论文。如果加上这些论文的链接，同一段落应该是这样的:

> 变形金刚中的自我注意机制能够全局计算面片之间的成对关系，从而实现大范围的特征交互。[[https://arxiv.org/pdf/2201.00462v2.pdf](https://arxiv.org/pdf/2201.00462v2.pdf)]它……被认为是查询和键/值对到输出的映射，每一个都由一个向量[[https://arxiv.org/pdf/1807.03052.pdf](https://arxiv.org/pdf/1807.03052.pdf)]表示。一个众所周知的关于自我关注的问题是二次时间和记忆的复杂性，这在许多情况下会阻碍模型的可扩展性。https://arxiv.org/pdf/2009.06732.pdf[。](https://arxiv.org/pdf/2009.06732.pdf)

关键的区别在于第一段*看起来*像是模型实际“完成”的东西，你可能真的想使用它。参考文献破坏了无归属文本的幻想，于是“写作辅助”看起来就不那么吸引人了。如果你选择依靠 GPT-3 来进行高层次的思考，它可能是一个有用的研究工具。但是，除非你习惯于简单地从别人的作品中抄袭短语，否则“写作辅助工具”的幻想就会破灭。

不可否认，这个例子被夸大了:也许只有生成文本的某个部分会如此明显地抄袭。也许这只会偶尔发生。但是，如果没有这些参考，科学界的归因规范仍然会被打破。有了它们，就意味着你要依靠 GPT 三号来获得你研究背后的高层次思考。这是否有意义取决于(a)你在多大程度上相信它有这样的思考能力，(b)如果是这样的话——你在多大程度上愿意接受别人的想法。

Shah & Bender (2022 年)认为，即使对于 Metzler，Tay，Bahri 和 Najork (2021 年)设想的“领域专家”QA 模型，参考文献方法也是不够的:该模型可能最终成为远未解决的案件真相的仲裁者，可能在扁平地球理论等主题上呈现“双方”,并可能掩盖引用背后的真实信息来源(例如，所谓的“XYZ 诊所”实际上可能是一个没有医学证书的顺势疗法提供商)。当然，在有些情况下，答案足够简单，可以信任当前的模型——但不幸的是，我们无法轻易说出哪些情况是“安全的”。

## 如果你足够深入，一切都有参考。

> 如果你足够深入，一切都有参考。没有人期待基础代数或英语字母表的归属。没有人对使用语法或拼写检查器写作有道德上的疑虑。为什么要求抽象的想法或艺术风格的归属？

的确，当我们现在写学术文章时，没有人期望你提供一路追溯到亚里士多德的参考文献。但很少有人会说，拿走某人最近的 NeurIPS 论文并重新发表就可以了。是的，它是一个连续体，但它仍然是真实的。

究竟什么是常识，什么在给定时间点值得参考，因人而异，取决于他们的领域知识和原则。尽管如此，每个人都相当清楚自己的界限是什么。您个人是否愿意在 StackOverflow 代码片段中更改一些变量名，并将其作为您自己的工作来传递？你会告诉你的孩子从公共领域复制粘贴文章是可以的吗——毕竟，这并不违法。如果你在某人的主题演讲中听到一个你在其他地方没有听到过的贴切比喻——你会说它“只是英语”并将其作为你自己的吗？不管你对这些问题的答案是什么——你有这些答案，这意味着你有自己的归因规范。他们对你很重要。你拥有这套特定规范的部分原因是，你知道这是你周围的人所期望的。

## “合理使用”

> 这只是卢德主义。印刷机让书法家失业，这样世界会更好。版权和知识产权的概念已经过时，将很快在“合理使用”中消失。如果这让艺术家/作家/程序员失业——那又怎样，社会只需要适应。

印刷机并不是真的由世界上所有书法家的作品驱动，在他们不知情或未同意的情况下被用于商业用途——尤其是在同时代的法律中至少已经存在一些保护措施的时候。对于学术研究或制作人工智能辅助内容的个人创作者来说，“合理使用”听起来可能是一种合理的方法(有适当的来源归属)，但这不是讨论的内容——人工智能公司有权使用他们可以获得的任何数据来训练商业模型，而不与原始创作者分享任何收益，甚至不让他们知道他们的作品被使用。这场斗争远未结束，为数不多的法院判决(如正在进行的 [LinkedIn 案](https://www.socialmediatoday.com/news/linkedin-loses-latest-appeal-in-ongoing-data-scraping-case/622333/))是基于个案的，而不是公司已经可以用来作为一揽子许可的东西。关于 GitHub CoPilot 的实际诉讼调查正在进行中(Joseph Saveri 律师事务所& Butterick，2022)。

我不知道社会方面正在设想什么样的适应。让我们想象一个可能的场景:你是一个程序员，生活在一个被未来的类似副驾驶的系统所主宰的世界里，这个系统每个人都在使用，并接受所有公共代码的训练。你的任何新的公共代码都被输入到这个系统中，其他人可以立即使用它。由于没有归属，你的公共工作不再能帮助你建立声誉、社区和专业形象，而这些在你目前的公司之外是众所周知的，这将使你更难在出现任何问题时更换工作。你的雇主知道这一点，并调整了一些人力资源政策。

也许未来的 CoPilot 所有者制定了一些许可计划，当你的代码片段被使用时会给你一些版税？这就是平台力量的用武之地，我们希望我们没有如此热衷于商业上的“合理使用”。有趣的事实:2020 年，Spotify 上 700 万艺术家中只有 0.96%的人赚到了 5K 美元(Smith，2021)。700 万艺术家中只有 0.19% (13，400 名艺术家)受欢迎程度足以年薪 5 万美元。

非常感谢来自 HuggingFace 的了不起的人们的反馈和建议！特别是 Christopher Akiki、Gérard Dupont、Sasha Luccioni 和 Aleksandra Piktus(按字母顺序排列)。由于这个 [Twitter 帖子](https://twitter.com/annargrs/status/1587765010763108353)的反馈，这篇帖子也被更新了。

# 参考

*   巴赫金，硕士(1981)。小说中的话语。在 M. Holquist(编辑。)，*对话想象:四篇散文*。德克萨斯大学出版社。
*   巴特，河(1977 年)。作者之死。在 S. Heath (Tran。)、*形象、音乐、文字:随笔*(第十三篇，第 142–148 页)。伦敦:丰塔纳。
*   n .卡里尼，d .伊波利托，m .贾吉尔斯基，Lee，k .，Tramer，f .，，张，C. (2022)。跨神经语言模型量化记忆。https://doi.org/10.48550/arXiv.2202.07646
*   Carlini，Tramèr，f .，Wallace，e .，Jagielski，m .，Herbert-Voss，a .，Lee，k .，Raffel，C. (2021)。从大型语言模型中提取训练数据。第 30 届 USENIX 安全研讨会(USENIX 安全 21)，2633-2650。[https://www . usenix . org/conference/usenixsecurity 21/presentation/Carlini-extracting](https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting)
*   约瑟夫·萨维里律师事务所&巴特里克，硕士(2022)。 *GitHub 副驾驶调查*。[https://www . saverilawfirst . com/our-cases/github-copilot-知识产权-诉讼](https://www.saverilawfirm.com/our-cases/github-copilot-intellectual-property-litigation)
*   黑基勒，M. (2022)。这位艺术家正在主宰人工智能生成的艺术。他对此并不高兴。[https://www . technology review . com/2022/09/16/1059598/this-artist-is-dominating-ai-generated-art-and-hes-not-happy-about-it/](https://www.technologyreview.com/2022/09/16/1059598/this-artist-is-dominating-ai-generated-art-and-hes-not-happy-about-it/)
*   Hitsuwari，j .，，y .，Yun w .，& Nomura，M. (2022)。人类与人工智能的合作会带来更多创造性的艺术吗？人工俳句和人工俳句的审美评价。*人类行为中的计算机*，107502。[https://doi.org/10.1016/j.chb.2022.107502](https://doi.org/10.1016/j.chb.2022.107502)
*   克里斯特瓦，J. (1980 年)。*语言中的欲望:文学艺术的符号学研究*。哥伦比亚大学出版社。
*   李，李，陈，陈(2022)。*语言模型抄袭吗？*[https://doi.org/10.48550/arXiv.2203.07618](https://doi.org/10.48550/arXiv.2203.07618)
*   梅茨勒博士、泰伊、巴里博士和纳约克博士(2021 年)。重新思考搜索:让领域专家走出困境。 *ACM SIGIR 论坛*， *55* (1)，13:1–13:27。[https://doi.org/10.1145/3476415.3476428](https://doi.org/10.1145/3476415.3476428)
*   Shah，c .，& Bender，E. M. (2022)。定位搜索。ACM SIGIR 人类信息交互和检索会议，221–232。https://doi.org/10.1145/3498366.3505816
*   史密斯博士(2021)。13，400 名艺术家(700 万人中)每年从 Spotify 获得 5 万美元或以上的收入。[https://www . digital music news . com/2021/03/18/Spotify-artist-earnings-figures/](https://www.digitalmusicnews.com/2021/03/18/spotify-artist-earnings-figures/)