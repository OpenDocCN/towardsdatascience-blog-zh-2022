# AI 可以从这三个领域学到一两件事

> 原文：<https://towardsdatascience.com/ai-could-learn-a-thing-or-two-from-these-three-fields-9aaf90f21f4c>

![](img/5912b5f1dad7086b1f7de82124e56997.png)

随着人工智能系统不断从周围世界产生的数据中学习，它们的创造者也必须如此。照片由 [Unsplash](http://unsplash.com) 的 Aideal Hwa 拍摄。

众所周知，人工智能(AI)领域充满了丑闻、偏见和限制。也不乏解决这些问题的尝试，无论是来自技术、数学、伦理，甚至是设计。越来越清楚的是，这些问题永远不会有一个放之四海而皆准的解决方案，与其试图重新发明轮子，该领域可以从利用现有的走向以人为本和包容性的运动和趋势中受益匪浅。

## 数据女权主义——参与

从广义上说，参与意味着参加某事。利益主体参与人工智能领域的一个重要好处是更均匀地分配决策权，并在受技术或干预影响的各方中拥有有影响力的声音，特别是那些经历[“结构性压迫”或“系统性劣势”的各方](https://mitpress.mit.edu/9780262044004/data-feminism/)。“参与”是指任何人在任何时候出于任何目的参与某项活动；作为一个术语，它是非特定的。虽然该术语经常用于人机交互和设计领域，但它用于描述[广泛变化的参与度](https://dl.acm.org/doi/10.1145/2470654.2470716)，对于利益相关者和设计/开发团队来说，甚至在不同的用户组之间，这种参与度通常是不平等或不对称的，形成了[不对称的协作模型](https://www.proquest.com/openview/ae18ccb05ef6bd863675c4aa02869c57/1?pq-origsite=gscholar&cbl=5045567)。

![](img/ba26dd6b547f71f64f1890070f147a23.png)

数据女权主义超越了性别不平等，专注于公平和有意义地参与整个技术生命周期。照片由[拍摄，那是她的事](https://unsplash.com/@thatsherbusiness)来自 [Unsplash](http://unsplash.com) 。

在记录和分析参与性活动发生时研究人员和参与者之间互动的[实际效果](https://www.researchgate.net/publication/221631349_The_unit_of_analysis_in_understanding_the_politics_of_participatory_practice)方面也做得很少。另一方面，通过使用包容性和多样性的框架，目标变得面向建设一个环境，在这个环境中，具有不同背景和经历的人感到舒适，并被赋予足够的权能，能够有意义和有效地参与。参与还可以实现价值敏感性，因为让利益相关者参与进来是理解他们的价值并允许他们做出反映这些价值的决策的唯一途径。它避免了同质的创作者群体做出假设和决定，他们可能会成为[特权风险和隧道视野](https://mitpress.mit.edu/9780262044004/data-feminism/)的牺牲品。

## *跨学科研究——跨学科合作*

尽管在全球范围内有许多跨学科的呼吁，但让跨学科工作成为热门话题已经有很长时间了。虽然“跨学科研究”一词最早出现在 20 世纪，但有证据表明，与古埃及和古希腊一样古老的文明参与了跨学科的工作和研究。任何活动都可以被描述为跨学科的，只要它使用的工具、知识或框架跨越了两个或更多的学科；其中，一个学科是一个学术领域，它有自己生成知识、提出问题和寻求答案的既定方式(即，它自己的工具、框架、模型、术语等等)。通过利用不同且通常不相似的学科的知识、技能、工具和框架，跨学科团队能够更好地解决和回答跨学科的问题，而单科专家不具备独自解决问题所需的知识。创建基于人工智能的系统是一个高度跨学科的过程，涉及几个科学领域，如数据科学，数学，计算机科学，物理学。然而，不可忽视的是，需要与社会科学家、领域专家、用户和设计专家进行跨学科合作，以获得这些系统的维度和影响的真正整体视图。

![](img/c57b999cb88ff9df338049bf5649e389.png)

跨学科合作是一个强大的工具，可以帮助弥合学科工具和理解之间的差距，并建立一个更强大、更团结的整体。来自 [Unsplash](http://unsplash.com) 的 [Vardan Papikyan](https://unsplash.com/@varpap) 摄影。

无数人呼吁为基于人工智能的系统引入跨学科、参与式的设计过程，特别是在[帮助解释和透明](https://link.springer.com/article/10.1007/s00766-020-00333-1)、[将价值观](https://www.nature.com/articles/538311a)嵌入这些系统、提供问责制以及减轻由几个级联偏差和限制引起的下游伤害方面。也有人呼吁在整个人工智能管道中进行[协作，包括数据创建和选择，而不是让设计师在前端或过程的开始，工程师在后端。事实上，有人说，打击现有的结构和数据偏见蔓延到人工智能系统的唯一方法是远离定制的、纯技术的解决方案，并使用开放的建设性对话、合作和集体反思来弥合利益相关者愿景和实际实施之间的鸿沟，并检查人工智能系统正在使用的更广泛的社会文化背景的更广泛框架，并让所需的声音以有意义、有影响的方式提供他们的输入。](https://www.designbetter.co/podcast/brad-frost-dan-mall)

**这些呼吁和建议强调了以人为中心、对价值敏感的人工智能系统是通过多元化参与和跨学科合作构建的。**

## **软件工程——非功能需求和文档**

展望软件工程领域，出现了几个重要的教训。

**利用非功能需求**

需求规格说明是抽象的、更高层次的概念(在软件工程中以非功能性需求的形式出现)和工程师可以实际实现的具体需求之间的重要桥梁。这些非功能性需求可以被认为是用户价值和优先级以及其他社会技术元素和约束的同义词；技术领域中通常被忽视的因素。

![](img/6474c98199151912036f1b2e5d2ce3c3.png)

将非功能性和基于价值的需求与功能性需求一起操作的实用方法，对于创建更加以人为中心的人工智能系统大有帮助。照片由来自 [Unsplash](http://unsplash.com) 的 [Joan Gamell](https://unsplash.com/@gamell) 拍摄。

从利益相关者收集的高级非功能性需求开始，这些需求通常被重新组织为“质量目标”，然后以“质量因素”的形式提取潜在的价值，这些价值被量化为“质量标准”，最终使用“质量度量”进行测量。例如，用户可能表示他们希望系统在任何需要的时候都保持在线。这种非功能性需求将转化为质量目标，即系统应该对用户始终在线。潜在的质量因素将是“可靠性”，质量标准可能是让系统在 99%的时间内在线，所使用的指标可能是服务器在一年内离线的时间(这应该是<1\%). By following this series of translations and conversions, ambiguous stakeholder statements can be transformed into quantifiable metrics and well-defined desired outcomes across managerial, design, and implementation levels.

This specification process can help address calls for operationalizing abstract chosen qualities and values into measurable, actionable steps and metrics, and “[从原则到实践](https://link.springer.com/article/10.1007/s11948-019-00165-5))当涉及到基于人工智能的系统时，以及该领域内发布的道德准则和建议因过于理论化和难以实施而受到的批评。关键是将度量标准转化为具体的目标和结果，否则这些度量标准就是理论上的构造，无法量化，甚至无法观察到。

**气密文件**

人工智能系统构建方式的巨大局限性之一是缺乏透明度。这部分是由于对所产生的学习和知识以及贯穿其中的设计决策的过度技术性和/或有限的文档化和反思。文档的缺乏会导致数据丢失，以及对团队角色、预期结果和正在发生的过程的混淆——尤其是在跨学科的环境中。另一方面，文档提供了团队理解的共享表示，以及一个参考点，并且可以增量地和协作地创建，这使它成为一个非常有用的工具。因此，关注文档阶段，或者在整个过程中作为文档本身的工件的生产，是非常重要的。在基于人工智能的系统的背景下，文档[被发现](https://partnershiponai.org/about-ml-2021/)增加了透明度和可解释性，帮助创作者理解所涉及的各种利益相关者的不同需求，反映和证明所做的不同决定，弥合人工智能伦理和实践之间的差距，并将整个人工智能生命周期包含和统一在一个工件中——将文档变成有形的工件和过程本身。

![](img/6ee4df3c48634572e9d138ecf16402c0.png)

让人工智能系统更加以人为本和对价值更加敏感是一项具有挑战性但至关重要的工作。来自 [Unsplash](http://unsplash.com) 的 [Alexander Sinns](https://unsplash.com/@swimstaralex) 摄影。

## 将这一切结合在一起

人工智能领域及其设计过程可以从其他领域和当前趋势中学到一两件事。通过关注:

1.  有意义和公平的参与(数据女权主义)，
2.  支持并优先考虑跨学科合作(跨学科研究)，
3.  捕捉和操作人们的价值观和优先事项(软件工程)，以及
4.  维护文档透明度(软件工程)

该领域可以通过使用来自隔壁的屡试不爽的方法来解决其当前的几个缺点。

# 我适合的地方

当前的现实是，人工智能系统悬而未决，有可能变得更加孤立、排外和复杂；或者开放，变得更容易接近和包容，这是我博士项目的灵感来源。我正致力于创建一个参与性的过程，以及一个支持它的工具包，在人工智能的整个生命周期中系统地让人们参与进来——重点是价值敏感性。

你可以在伦敦帝国理工学院网站上查看我的项目的官方页面。你也可以看看我写的另一篇解释我博士项目的[细节的文章。](https://medium.com/@malaksadekIC/introducing-my-phd-project-to-make-ai-design-more-inclusive-80d0edf70378)

我建立了这个媒体账户来发布我在博士项目中的有趣发现，希望以一种任何人都可以理解的方式传播关于人工智能系统的新闻和信息。如果你喜欢这篇文章，那么请考虑跟随我发布新的东西，并请喜欢和分享！