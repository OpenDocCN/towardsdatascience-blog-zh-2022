<html>
<head>
<title>Hands-On Reinforcement Learning Course: Part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实践强化学习课程:第4部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-4-55da5eae851f#2022-01-17">https://towardsdatascience.com/hands-on-reinforcement-learning-course-part-4-55da5eae851f#2022-01-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="9b67" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">实践强化学习课程:第4部分</h1></div><div class=""><h2 id="bd9e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">线性Q学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a48eb11c58b38b64e48c5b6cd2191414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdXTNQi893Fjz-76O_ZtBA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们跳舞好吗？ <a class="ae kz" href="https://www.pexels.com/@yogendras31?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">约根德拉·辛格</a> ❤️</p></figure><h1 id="7ade" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">欢迎来到我的强化学习课程❤️</h1><p id="62c3" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这是强化学习实践课程的第4部分，带你从零到英雄🦸‍♂️.</p><p id="da05" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/hands-on-reinforcement-learning-course-part-1-269b50e39d08">第一部分:强化学习简介</a> <br/> <a class="ae kz" rel="noopener" target="_blank" href="/hands-on-reinforcement-learning-course-part-2-1b0828a1046b">第二部分:表格Q-learning </a> <br/> <a class="ae kz" rel="noopener" target="_blank" href="/hands-on-reinforcement-learning-course-part-3-5db40e7938d4">第三部分:表格SARSA </a> <br/>👉🏻第四部分:线性Q学习(今天)</p><p id="eba6" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">很抱歉让你等了这么久，我想和你分享整个学习过程，这样你就知道好的结果来之不易。但是一旦他们这么做了，他们就值trouble️.奖了</p><p id="c63a" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">今天，我们进入了新的领域…</p><p id="c0f3" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">强化学习遇到了现代机器学习中必不可少的优化技术的领域<strong class="lu iu">。</strong>解决大量不同问题和环境的杀手锏🚀。</p><p id="14fc" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们要解决的问题是著名的<strong class="lu iu">推车杆</strong>平衡，目标是通过左右移动推车来平衡连接在推车上的杆。</p><p id="ad55" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这是我们将在本次冒险结束时实现的Deep Q-Agent的外观:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="8a2d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们将在这一部分探讨的技术是过去5到10年中强化学习领域令人印象深刻的成就背后的支柱。</p><p id="6474" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">有很多东西需要消化，所以我们将工作负载分成3部分:</p><ul class=""><li id="d6b0" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated">在第4部分(这个！)我们实现了一个线性Q代理来获得一个不错的解决方案。</li><li id="d268" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">在第5部分中，我们增加了深度并实现了一个Deep Q代理来获得一个好的解决方案。</li><li id="a847" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">在第6部分，我们将看到如何微调所有的超参数，以最大限度地提高性能。在这里，我们终于得到了你在上面看到的可怕的深Q代理！</li></ul><p id="e7e7" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在每一部分中，我们都会加入新的想法、技巧和你需要掌握的实现细节。更重要的是，我希望你在构建RL解决方案时习惯于<strong class="lu iu">失败</strong>。因为大多数时候都是这样。</p><p id="b45e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">高级RL技术，如我们将在这三部分中看到的技术，非常强大，但需要仔细实施和超参数调整。</p><p id="b2be" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">调试RL算法不是一件容易的事情，而变得更好的唯一方法就是犯错。当我开始学习强化学习时，我最大的挫折之一是算法表面上的简单，以及试图复制已发表的结果时的极端困难。</p><p id="0ea5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">强化学习本身就很难，所以我们尽量不要让它变得更加复杂。一步一步来！</p><p id="11dc" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这节课的所有代码都在<a class="ae kz" href="https://github.com/Paulescu/hands-on-rl" rel="noopener ugc nofollow" target="_blank"> <strong class="lu iu">这个Github repo </strong> </a> <strong class="lu iu">里。</strong> Git克隆它来跟进今天的问题</p><p id="0582" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">还有别忘了给它一个⭐<a class="ae kz" href="https://github.com/Paulescu/hands-on-rl" rel="noopener ugc nofollow" target="_blank"/>！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://github.com/Paulescu/hands-on-rl"><div class="gh gi nj"><img src="../Images/0cadaab276f185fc976218cacdb1c945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O6oOqGDYocMlmwWB.jpeg"/></div></a></figure><h1 id="c513" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">第四部分</h1><h1 id="4a6b" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">内容</h1><ol class=""><li id="b3cb" class="mv mw it lu b lv lw ly lz mb nk mf nl mj nm mn nn nb nc nd bi translated"><a class="ae kz" href="#8a1d" rel="noopener ugc nofollow">大车杆子问题🕹️ </a></li><li id="70ee" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">环境、行动、状态、奖励</li><li id="a3fb" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">随机代理基线🤖 🍸</li><li id="b45d" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">参数Q学习</li><li id="14a0" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">你好PyTorch！👋</li><li id="e93a" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">线性Q代理🤖</li><li id="47f3" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">重述✨</li><li id="1888" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">家庭作业📚</li><li id="957e" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">下一步是什么？❤️</li></ol><h1 id="8a1d" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">1.推车杆子问题🕹️</h1><p id="40b0" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">一根杆子用一个未启动的接头连接到一辆手推车上。你的目标是移动推车的位置，左右移动，防止杆子掉下来。</p><p id="81e8" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们将使用<code class="fe no np nq nr b">CartPole-v1</code>的实现，你可以在<a class="ae kz" href="https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>中找到。</p><h2 id="1920" class="ns lb it bd lc nt nu dn lg nv nw dp lk mb nx ny lm mf nz oa lo mj ob oc lq od bi translated">为什么会有这个问题？</h2><p id="0d82" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">到目前为止，我们已经在离散/表格环境中使用了经典的强化学习算法、Q-learning(第2部分)和SARSA(第3部分)。</p><p id="7cf5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">今天的问题稍微复杂一点，因为它的状态空间太大，无法离散化。相反，我们需要升级我们的游戏，并使用更强大的RL算法。</p><p id="a054" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们将使用参数Q-learning，这是一种将我们在第2部分看到的经典Q-learning与参数近似相结合的技术，参数近似可以是线性的(在第4部分)，也可以是更复杂的，如神经网络(在第5部分)。</p><p id="4912" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">使用神经网络的参数Q学习(又名深度Q学习)是强化学习中许多最新突破的背后，如DeepMind 的著名<a class="ae kz" href="https://arxiv.org/pdf/1312.5602v1.pdf" rel="noopener ugc nofollow" target="_blank"> Atari游戏播放器。</a></p><p id="35bf" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">让我们熟悉一下这个环境的具体情况！</p><h1 id="68ae" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">2.环境、行动、状态、奖励</h1><p id="72f8" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/00_environment.ipynb" rel="noopener ugc nofollow" target="_blank">👉🏽notebooks/00 _ environment . ipynb</a></p><p id="fc49" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">状态由4个数字表示:</p><ul class=""><li id="3645" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated">大车位置<strong class="lu iu"> <em class="oe"> x </em> </strong> <em class="oe"> </em>从-2.4到2.5。</li><li id="c8b2" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><strong class="lu iu">大车速度<em class="oe">v</em>T26】</strong></li><li id="cbd6" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">相对于垂直线的极角<strong class="lu iu"> <em class="oe"> θ </em> </strong>从-12到12度(从-0.21到0.21弧度)</li><li id="e127" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">极点角速度<strong class="lu iu"> <em class="oe"> ω。</em> </strong>这是<strong class="lu iu"> θ的变化率。</strong></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/0705d20a5a653e9b45a7a96abef862b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*VZcW5MKAkp2P2uqZ_-o53w.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">大车极点状态向量(图片由作者提供)</p></figure><p id="be80" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">当出现以下任一情况时，一集终止:</p><ul class=""><li id="c6e7" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated">大车越限:<strong class="lu iu"> <em class="oe"> x &gt; 2.4 </em> </strong>或<strong class="lu iu"> <em class="oe"> x &lt; -2.4 </em> </strong></li><li id="399b" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">电杆离垂线太远:<strong class="lu iu"> <em class="oe"> θ &gt; 12度</em> </strong>或<strong class="lu iu"> <em class="oe"> θ &lt; -12度。</em> </strong></li><li id="a482" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">或者我们达到了最大集数500步。在这种情况下，代理人完美地解决了插曲。</li></ul><p id="42d5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">起始状态是从每个状态的区间[-0.05，0.05]中随机抽样的。有时候，开始的位置如此接近平衡，以至于这一集很容易。其他时候，开始的位置是如此不平衡，以至于插曲很难解决，有时甚至是不可能的。</p><p id="354f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">大车速度<strong class="lu iu"> <em class="oe"> v </em> </strong>和杆子角速度<strong class="lu iu"> <em class="oe"> ω呢。</em> </strong>这些值也有界吗？</p><p id="d241" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">首先，让我们加载<code class="fe no np nq nr b">CartPole-v1</code>环境。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/09aa2ab65c4608c8256565b6ed7456de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N40nbBWslYNb_gwwrZ1OhA.png"/></div></div></figure><p id="790b" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">如果你看看OpenAI健身房的区间变量<code class="fe no np nq nr b">env.observation_space.low</code>和<code class="fe no np nq nr b">env.observation_space.high</code>，你会发现这两个数字似乎是任意大或小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/dd7c5ad95f6d45a9c02d783f8985b4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mko5KnPIlIGGQ6Xh0Oy1_g.png"/></div></div></figure><p id="396a" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">实际上，这是不正确的。无论是<strong class="lu iu"> <em class="oe"> v </em> </strong>还是<strong class="lu iu"> <em class="oe"> ω </em> </strong>都有更窄的间隔，但这是你无法直接从<code class="fe no np nq nr b">env</code>对象中读出的东西。您只能在您的代理探索环境时观察它们的真实范围。</p><p id="7a84" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这一点很重要，因为我们今天和第5部分将使用的模型，与<strong class="lu iu">标准化输入</strong>配合使用效果最佳。在这种情况下，归一化状态。要归一化一个数，你首先需要知道它的最大值和最小值。<strong class="lu iu"> <em class="oe"> v </em> </strong>和<strong class="lu iu"> <em class="oe"> ω </em> </strong>这两个值不能从<code class="fe no np nq nr b">env.observation_space</code>中读取。你需要通过一点探索来估计它们。</p><p id="fe2d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这张纸条的重点是:</p><blockquote class="oi"><p id="8ffa" class="oj ok it bd ol om on oo op oq or mn dk translated">⚠️不会盲目地把`<code class="fe no np nq nr b">env.observaton_space</code>中的数值作为每个状态的真实范围。</p></blockquote><p id="08b9" class="pw-post-body-paragraph ls lt it lu b lv os ju lx ly ot jx ma mb ou md me mf ov mh mi mj ow ml mm mn im bi translated">我们的代理可以执行的<strong class="lu iu">操作</strong>是什么？</p><ul class=""><li id="7286" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated"><code class="fe no np nq nr b">0</code>:向左推推车。</li><li id="15dd" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><code class="fe no np nq nr b">1</code>:向右推推车。</li></ul><p id="edcc" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">每走一步<strong class="lu iu">奖励</strong>为+1。这意味着代理人保持杆子站立的时间越长，累积奖励越高。</p><h1 id="d363" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">3.随机代理基线</h1><p id="7ee6" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/01_random_agent_baseline.ipynb" rel="noopener ugc nofollow" target="_blank">👉🏽notebooks/01 _ random _ agent _ baseline . ipynb</a></p><p id="3081" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">像往常一样，我们使用一个<code class="fe no np nq nr b">RandomAgent</code>来建立一个基准性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/f08f89e2e246f6ed91eaea1a0a68aa6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DiNnq-wrOSE6tVvrNag_kQ.png"/></div></div></figure><p id="8b7e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们用1000集来评估这个代理</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/23c3a731945a36a483b517900afd7122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MvlQEz5YucVENgrJJM_B6g.png"/></div></div></figure><p id="62d7" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">计算平均回报及其标准差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/99989eba355f9850fb806cac7a81592c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AbrCvJJB0kxH9u7pvbtkWw.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/3f427010c2e9b22f98449c717a646754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdpN-gAFc6dQ76MVLw3YrQ.png"/></div></div></figure><p id="a3c8" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">让我们看看参数Q学习如何帮助我们构建一个更智能的代理！🧠</p><h1 id="07f4" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">4.参数Q学习</h1><p id="e765" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">到目前为止，我们已经在离散/表格环境中工作过(在第2部分),或者将原始环境转换为离散环境(第3部分)。</p><p id="222f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">然而，大多数有趣的环境不是离散的，而是连续的，并且太大而无法离散和求解。</p><p id="3de3" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">幸运的是，有直接在连续状态空间上工作的RL算法。</p><p id="da42" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">今天我们将使用<strong class="lu iu">参数Q学习。</strong>该算法类似于我们在第2部分中看到的原始Q学习，但适用于连续设置。</p><p id="d202" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><code class="fe no np nq nr b">CartPole</code>的状态空间由4个连续数字组成</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/81cd1cead9671bb1f3a6cac50ad1ddab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XkVnBMcCt18j2kdP0q-m_Q.png"/></div></div></figure><p id="778f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在哪里</p><ul class=""><li id="ff25" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated"><strong class="lu iu"> <em class="oe"> x </em> </strong>是大车位置</li><li id="c863" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><strong class="lu iu"> <em class="oe"> v </em> </strong>是大车运行速度</li><li id="f29a" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><strong class="lu iu"> <em class="oe"> θ </em> </strong>是磁极角度</li><li id="6467" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><strong class="lu iu"> <em class="oe"> ω </em> </strong>是极点角速度</li></ul><p id="3bcb" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在这样的连续状态空间中，最佳Q值函数</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/f03dbbff7f8165eb68f8bf48385b54b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QE4rVylz9FoIr0Z9uSb1rA.png"/></div></div></figure><p id="bd11" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">不能用表来表示(因为它会有无限多个维度)。</p><p id="1768" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">相反，我们用一个<strong class="lu iu">参数形式</strong>来表示它</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/a60a3e74825115b6332814a99efbe10e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KjS5N4_KnYjeCtR1jYUD4Q.png"/></div></div></figure><p id="bb6f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在哪里</p><ul class=""><li id="b6eb" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated"><code class="fe no np nq nr b">Q*</code>是模型架构，像线性模型，或者非常深度的前馈神经网络。</li><li id="06a8" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">这取决于我们将使用代理在训练期间收集的经验<em class="oe"> (s，a，r，s’)</em>来估计的一组参数。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/840118c1ed9e1055954e44e592c48420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-AqRPT790zRxijIuzp7sg.png"/></div></div></figure><p id="d21c" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">为Q*选择<strong class="lu iu">模型架构对于学习好的策略和解决问题至关重要</strong>。</p><p id="e15d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">模型的参数越多，就越灵活。它更有可能是这个问题的一个好模型。事实上，线性模型只是神经网络的特例，没有中间层。</p><p id="6b8a" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">为了简单起见，今天我们将使用线性模型，在下一讲中，我们将引入一个更深(即更多层)的神经网络模型来提高性能。</p><p id="8289" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">一旦您为<strong class="lu iu"> Q* </strong>选择了模型架构，您就需要找到最佳参数<strong class="lu iu"> P. </strong></p><p id="4329" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><em class="oe">好的，但是如何学习参数</em> <strong class="lu iu"> <em class="oe"> P </em> </strong> <em class="oe">的向量呢？</em></p><p id="955f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们需要一种方法来迭代地找到这些参数<strong class="lu iu"> P </strong>的更好估计，因为代理在训练期间收集了更多的经验，并且收敛到最优参数<strong class="lu iu"> P* </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/c4fc4d59da24aff0d926c0b6e8dd7ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9oywy_9MJIVotZrjscQljg.png"/></div></div></figure><p id="3182" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">现在，函数<strong class="lu iu"> Q*(s，a，P) </strong>满足贝尔曼最优方程，这是强化学习中的一个关键方程</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/afcbe78ae1f53b0f38927f3f4a525d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgptxy7-CoKGKEFRC1bK5A.png"/></div></div></figure><p id="f81d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这告诉我们，最大未来报酬<strong class="lu iu"> Q*(s，a，P) </strong>是代理人进入当前状态<strong class="lu iu"><em class="oe"/></strong>所收到的报酬<strong class="lu iu"> <em class="oe"> r </em> </strong>加上下一个状态<strong class="lu iu"><em class="oe">s’的最大未来报酬。</em> </strong></p><p id="8b1e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">最佳参数<strong class="lu iu"> P* </strong>是那些使该等式的左侧尽可能接近右侧的参数。</p><p id="6d3e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这是一个优化问题，你可以用现代机器学习技术来解决。更准确地说，监督机器学习技术。</p><p id="b1c7" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">有监督的ML问题有3个组成部分:</p><ol class=""><li id="362f" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn nn nb nc nd bi translated">输入<code class="fe no np nq nr b">features</code>和相应的<code class="fe no np nq nr b">targets</code></li><li id="7389" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">我们需要确定一组<code class="fe no np nq nr b">parameters</code></li><li id="ae64" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">依赖于这些<code class="fe no np nq nr b">parameters</code>并将<code class="fe no np nq nr b">features</code>映射到<code class="fe no np nq nr b">model outputs</code>的模型架构</li></ol><p id="1458" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">目标是找到使<code class="fe no np nq nr b">model outputs</code>与<code class="fe no np nq nr b">target</code>值匹配的<code class="fe no np nq nr b">parameters</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/db9006f3515cfb5ab6f5ef18da139b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lHGuetwYQXj5Ub6thAlYOQ.png"/></div></div></figure><p id="3cc3" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">换句话说，我们要找到使距离最小化的参数<strong class="lu iu"> P* </strong>，也就是ML行话<strong class="lu iu">中的<strong class="lu iu">损耗</strong>。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/2eaa9e870b54b4b8fdf0a17ceeeb217b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dIeH_LcVAuqzijM4EaeXDA.png"/></div></div></figure><p id="005d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">机器学习界解决这个优化问题的一个经典算法是<strong class="lu iu">随机梯度下降</strong> <strong class="lu iu"> (SGD) </strong>方法。更准确地说，<strong class="lu iu">小批量</strong>随机梯度下降。</p><p id="e331" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">给定你当前的估计<strong class="lu iu"> P⁰，</strong>一个小批量的经验(s，a，r，s’)和一个合适的<strong class="lu iu">学习率</strong>，你可以用<strong class="lu iu"> SGD </strong>更新公式来改进你的估计<strong class="lu iu"> P⁰ </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/a03898a21090e6862e063a3b98935d4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ry6mqD7cSSjfIbVY41on-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SGD更新公式</p></figure><p id="798d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">损失相对于参数的梯度，∇ L是一个向量，其分量是损失相对于参数向量中每个分量的灵敏度。</p><p id="ce7f" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">实际上，你永远不需要自己计算梯度。PyTorch或TensorFlow等Python库使用一种叫做<strong class="lu iu">反向传播、</strong>的算法为您完成了这项工作，这只是您可能多年前在高中就已经学习过的微积分中链式法则的一个花哨名称。</p><p id="f909" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">让我们回顾一下:</p><ul class=""><li id="4b6a" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated">当我们的代理探索环境时，您收集成批的经验，并使用这些经验通过SGD更新公式来更新参数。</li><li id="285f" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">如果你重复这个足够长的时间，你会(希望🤞)得到最佳参数<strong class="lu iu"> P*，</strong>并因此得到最佳<strong class="lu iu"> Q* </strong>值函数。</li><li id="bfe3" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">从最优Q*函数中，你可以推导出最优策略</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/32e2efab7869cbff880a40c064c7bc14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFTKotcr2aF4Cp49pwrVcQ.png"/></div></div></figure><p id="1a10" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">瞧啊。这就是参数Q学习的工作原理！</p><p id="5a8b" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">但是等一下…</p><p id="d2e5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">为什么在<strong class="lu iu">上面说<em class="oe">有希望收敛到最优</em>👆</strong>？</p><p id="47b0" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">与表格设置相反，在表格设置中，Q-learning的工作有很强的保证，在参数化版本中，事情更加<em class="oe">脆弱</em>。</p><p id="ef12" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">本质上，导致事情失败的是我们优化问题的目标值</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/d0a3b2b24c0ad191c3ab2be5b9dbd484.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDKHHuJmbAKru3xsj98xjA.png"/></div></div></figure><p id="1c2a" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">随着我们更新参数估计而改变。目标在训练过程中会发生变化。他们移动🏃</p><p id="29cc" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这个看似微不足道的细节让问题变得更加难以解决。</p><p id="5769" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">希望研究人员发挥创意，介绍了一些提示和技巧✨来解决这个问题。</p><h2 id="49eb" class="ns lb it bd lc nt nu dn lg nv nw dp lk mb nx ny lm mf nz oa lo mj ob oc lq od bi translated">技巧1:目标✨更新较慢</h2><p id="2cbe" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">如果移动目标是个问题，我们能不能尽量少移动它们？</p><p id="2a06" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">答案是肯定的。我们可以通过使用两个不同的参数向量来实现:</p><ul class=""><li id="c5cd" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated"><strong class="lu iu"> P: </strong>主模型的参数(左侧)。这些在每次SGD更新后进行调整。不出所料。</li><li id="4ffd" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated"><strong class="lu iu"> Pᵀ: </strong>目标模型的参数(右侧)。这些参数在SGD更新期间保持固定，我们只在第N次<em class="oe">迭代中重置它们以匹配P中的参数。</em></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/dbfdf5d88ff526d496423447eb39f2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJ3X7PlQ9-75d5io1j7wCQ.png"/></div></div></figure><p id="3796" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><strong class="lu iu"> Pᵀ </strong>的更新频率是我们需要调整的一个超参数。</p><h2 id="5f17" class="ns lb it bd lc nt nu dn lg nv nw dp lk mb nx ny lm mf nz oa lo mj ob oc lq od bi translated">招数二:重放记忆✨</h2><p id="119f" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">Q-learning是一个<strong class="lu iu">离线</strong>算法。这意味着贝尔曼方程适用于任何代理体验<strong class="lu iu"> <em class="oe"> (s，a，r，s’)，无论代理遵循哪种策略。</em>T19】</strong></p><p id="d08b" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">因此，过去的经验可以成批分组，并用于通过SGD更新来更新参数。</p><p id="0317" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">创建像这样的批量数据<strong class="lu iu">消除了经验之间的相关性</strong>，这对于更快地训练神经网络模型特别有用。</p><p id="6530" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这段记忆里要储存多少经历？</p><p id="4ff6" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这个数字(也称为内存大小)是一个我们需要调整的超级参数。</p></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="9031" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">今天，你需要相信我，我们将使用超参数，并等待第6部分，看看我们如何得到它们。</p><blockquote class="oi"><p id="5764" class="oj ok it bd ol om on oo op oq or mn dk translated">调整超参数不是一门艺术，而是一门科学。我们将在第6部分中看到如何使用非常流行的Python库来实现</p></blockquote><p id="c334" class="pw-post-body-paragraph ls lt it lu b lv os ju lx ly ot jx ma mb ou md me mf ov mh mi mj ow ml mm mn im bi translated">最后，如果你已经用PyTorch库建立了神经网络模型，你可以跳过下一节。否则，让我把你介绍给你的下一个好朋友🤓</p><h1 id="94b8" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">5.你好PyTorch！👋</h1><p id="c58b" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">PyTorch是一个Python库，允许您训练可区分的模型，包括线性模型和神经网络。</p><p id="cde6" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">PyTorch将会是<strong class="lu iu">这个</strong>库，我们将会在剩下的课程中使用它来解决我们在参数强化学习算法中需要解决的那种有监督的ML问题，比如参数Q学习。</p><p id="03ea" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">PyTorch有一个非常Python化的接口(与Tensorflow相反),我相信你会很快学会它。</p><p id="6ef9" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">PyTorch背后的关键特性是它的<strong class="lu iu">自动微分引擎</strong>，它为我们计算更新模型参数所需的梯度。</p><p id="69cf" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">PyTorch中培训脚本的主要构件包括:</p><p id="8c3c" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉一批输入<strong class="lu iu">数据</strong>，包含特征和目标。</p><p id="fa2e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉<strong class="lu iu">模型定义</strong>封装成Python对象<code class="fe no np nq nr b">torch.nn.Module</code>你只需要实现正向传递，即从输入到输出的映射。举个例子，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/c9daf38a71ca003441d2092b90c0a0ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jsjy5tem-AackJj3QWnBdQ.png"/></div></div></figure><p id="39a4" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉一个<strong class="lu iu">损失函数</strong>，例如<code class="fe no np nq nr b">torch.nn.functional.mse</code>(均方误差)，它计算给定模型输出和目标的损失。</p><p id="d90e" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉一个<strong class="lu iu">优化器</strong>，像<code class="fe no np nq nr b">torch.optim.Adam</code>(SGD的一个复杂版本)，它调整模型参数以减少批量输入数据的损失函数。</p><p id="e3ed" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这4个要素被组合成一个循环，也就是监督机器学习问题的训练循环。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/85fe6df65fb7f5827411a927b6328c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjE82ha_cJi3CGZvkb1mIQ.png"/></div></div></figure><p id="dbc2" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在这个脚本的最后，如果您的<code class="fe no np nq nr b">model</code>架构适合数据，您的<code class="fe no np nq nr b">model</code>参数将会使<code class="fe no np nq nr b">model_output</code>非常非常接近<code class="fe no np nq nr b">target</code>值</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/ef16b94690b722b358a40c507f857b9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88eIz7gh14MmI40NqRSJAA.png"/></div></div></figure><p id="58d5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这就是用PyTorch求解参数函数近似值的方法。</p><p id="e740" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">说够了。让我们来看看代码，实现一个线性Q代理！</p><h1 id="6ecc" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">6.线性Q代理</h1><p id="b0d3" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">我们使用以下模型将输入状态映射到q值函数(也称为我们的q函数):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi px"><img src="../Images/41cbf7dd6d5a8db84b22ba0206df9f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*g6KgxrSVAYlGZO7AK1q7Gg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">self.q_net</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/40221489d5249dde91ab1ddab0c2a87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FeLGvuDA65IaAPTJvqIqhw.png"/></div></div></figure><p id="1f8a" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">参数的数量等于输入和输出像元之间的连接数(即4 x 2 = 8)加上我们通常添加到这些线性层以增强其表现力的2个偏置项。这总共给出了10个参数。</p><blockquote class="pz qa qb"><p id="7ab0" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated">这不是一个非常灵活的模型，但是对于今天来说已经足够了。在接下来的讲座中，我们将使用更强大的神经网络模型。🤑</p></blockquote><p id="afa7" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">现在，让我们来看看超参数…</p><p id="6aef" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我创建了2个笔记本。一个具有<strong class="lu iu">坏的</strong>超参数，另一个具有<strong class="lu iu">好的</strong>超参数。</p><blockquote class="oi"><p id="a9a5" class="oj ok it bd ol om on oo op oq or mn dk translated">在两节课中，我们将看到如何通过实验找到这些值。目前，相信我，它们是我能找到的最好的(也是最差的)🙂</p></blockquote><h2 id="7229" class="ns lb it bd lc nt qg dn lg nv qh dp lk mb qi ny lm mf qj oa lo mj qk oc lq od bi translated">错误的超参数</h2><p id="7ced" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/02_linear_q_agent_bad_hyperparameters.ipynb" rel="noopener ugc nofollow" target="_blank">👉🏽notebooks/02 _ linear _ q _ agent _ bad _ hyperparameters . ipynb</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/475d30286377656098282f60414e4e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_31Se56MvH-iCS6Cxy3TQ.png"/></div></div></figure><p id="c6d9" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们固定所有随机种子，以确保可重复性</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qm"><img src="../Images/c9520be8321fe1146751b5951ed21923.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AE3WkvRx5H_SD6IbF7Ty_g.png"/></div></div></figure><p id="fee3" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">然后我们创建<code class="fe no np nq nr b">QAgent</code>对象</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/fd6acdd68b9eff0ee88db884aca70e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOgeAmqpOJaQM-nyaLvFTg.png"/></div></div></figure><p id="71ac" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们训练它2000集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qn"><img src="../Images/cb10511be0650a4d03639ff7ec0631f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iOUfxSsc7o__LbX42_WpLQ.png"/></div></div></figure><p id="1280" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们在1000次随机运行中评估了它的性能</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/a9b699d794d5877c8f877c276eaeaf34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjr7087E3MG4sjSEhDN4tQ.png"/></div></div></figure><p id="6629" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">结果看起来…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qo"><img src="../Images/768dcf6cf6815df6e0a8d0fe4c9b4219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hk3L6EF84dNgHXkW3W9FAA.png"/></div></div></figure><p id="66ac" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">相当糟糕！</p><p id="41cb" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">它们比基线更差<code class="fe no np nq nr b">RandomAgent</code>😵！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qp"><img src="../Images/133944d79e6e43e1382ecea10ab880f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jCz6sowLT2-JZffHMYWONA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">战胜</p></figure><p id="43cc" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">让我们看看当你使用好的超参数时会发生什么。</p><h2 id="8ae2" class="ns lb it bd lc nt nu dn lg nv nw dp lk mb nx ny lm mf nz oa lo mj ob oc lq od bi translated">良好的超参数</h2><p id="e61a" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/03_linear_q_agent_good_hyperparameters.ipynb" rel="noopener ugc nofollow" target="_blank">👉🏽notebooks/03 _ linear _ q _ agent _ good _ hyperparameters . ipynb</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qq"><img src="../Images/10bd42111e9d41e74d26a90af1e2e9ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NQQtLGdbvJbJ-Y78kxevqg.png"/></div></div></figure><p id="d921" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们重复相同的步骤来训练代理，然后评估它的性能:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qr"><img src="../Images/c0251f55043ab943046662848cdb19c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pKKZjKRmk-yJLoaYMK2Zbg.png"/></div></div></figure><p id="7e91" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">惊人的结果！</p><p id="d7ff" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">您可以绘制整个分布图，以查看代理始终得分高于100！🎉🎉🎉</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qs"><img src="../Images/1aa7360302aee4a74aaa4a484d542560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pSUZzYG7Lqn7Qdn7jpx20A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">胜利！</p></figure><p id="d1ce" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">哇！超参数对训练结果有多么巨大的影响。</p><blockquote class="pz qa qb"><p id="7c20" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated"><strong class="lu iu"> <em class="it">超参数灵敏度</em> </strong></p><p id="b55e" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated"><em class="it">使用参数近似的强化学习代理对超参数非常敏感。通常，他们对你在训练中用来控制所有随机性来源的随机种子也很敏感。</em></p><p id="e2c3" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated"><em class="it">除非提供所有超参数，否则很难复制发表在论文和期刊上的结果。</em></p><p id="c2d3" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated"><em class="it">我强烈推荐你阅读一篇关于现代/深度强化学习中再现性的优秀论文</em></p><p id="d3be" class="ls lt oe lu b lv mo ju lx ly mp jx ma qc mq md me qd mr mh mi qe ms ml mm mn im bi translated"><a class="ae kz" href="https://arxiv.org/abs/1709.06560" rel="noopener ugc nofollow" target="_blank"> <em class="it">📝重要的深度强化学习</em> </a></p></blockquote><p id="d6a2" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">我们今天取得了足够的进展，建立了我们的第一个参数Q代理。</p><p id="3980" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">是时候停下来回顾一下了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qt"><img src="../Images/403f5b55345c69c0918dd88c2904e200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X9LMzH7kMysHXFM2DpLbKQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">贝尔格莱德的凯(图片由作者提供)</p></figure><h1 id="278b" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">7.重述✨</h1><p id="fc51" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">这是3个关键要点:</p><ul class=""><li id="b9c6" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn na nb nc nd bi translated">参数Q学习是一种结合经典RL (Q学习)和函数逼近(监督ML)的强大算法。</li><li id="047a" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">您使用的参数化是确保算法收敛到最优解的关键。今天我们使用了一个线性模型，但是在下一部分，我们将使用一个更灵活的模型:神经网络。</li><li id="4a13" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn na nb nc nd bi translated">超参数是至关重要的，可以成为交易的破坏者。</li></ul><h1 id="91c2" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">8.家庭作业📚</h1><p id="b470" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/blob/main/03_cart_pole/notebooks/04_homework.ipynb" rel="noopener ugc nofollow" target="_blank">👉🏽笔记本/04 _作业. ipynb </a></p><p id="9847" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">这是我要你做的:</p><ol class=""><li id="67c2" class="mv mw it lu b lv mo ly mp mb mx mf my mj mz mn nn nb nc nd bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl" rel="noopener ugc nofollow" target="_blank"> <strong class="lu iu"> Git克隆</strong> </a>把回购到你的本地机器上。</li><li id="d2c6" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated"><a class="ae kz" href="https://github.com/Paulescu/hands-on-rl/tree/main/02_mountain_car#quick-setup" rel="noopener ugc nofollow" target="_blank"> <strong class="lu iu">设置</strong> </a>本课的环境<code class="fe no np nq nr b">03_cart_pole</code></li><li id="f2f9" class="mv mw it lu b lv ne ly nf mb ng mf nh mj ni mn nn nb nc nd bi translated">打开<code class="fe no np nq nr b"><a class="ae kz" href="http://02_mountain_car/notebooks/04_homework.ipynb" rel="noopener ugc nofollow" target="_blank">03_cart_pole/notebooks/04_homework.ipynb</a></code>，尝试完成两个挑战。</li></ol><p id="b340" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在第一个挑战中，我希望你尝试不同的<code class="fe no np nq nr b">SEED</code>值，并使用我向你展示的良好超参数重新训练代理。还能得到好的表现吗？还是结果很大程度上取决于你用的<code class="fe no np nq nr b">SEED</code>？</p><p id="f45c" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">在第二个挑战中，我要求你用今天的方法和代码解决<a class="ae kz" rel="noopener" target="_blank" href="/hands-on-reinforcement-learning-course-part-3-5db40e7938d4">第三部</a>中的<code class="fe no np nq nr b">MountainCar-v0</code>环境。你能用线性Q-learning得到99%的分数吗？</p><h1 id="1d27" class="la lb it bd lc ld le lf lg lh li lj lk jz ll ka lm kc ln kd lo kf lp kg lq lr bi translated">9.下一步是什么？❤️</h1><p id="6e68" class="pw-post-body-paragraph ls lt it lu b lv lw ju lx ly lz jx ma mb mc md me mf mg mh mi mj mk ml mm mn im bi translated">在下一课中，我们将加入我们的第一个深度神经网络，并创建我们的第一个<strong class="lu iu">深度Q代理。</strong></p><p id="2f1d" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">令人兴奋，不是吗？</p><p id="7644" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">让我们一起继续学习吧！</p></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="c4f5" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated"><em class="oe">你想成为(甚至)更好的数据科学家，接触关于机器学习和数据科学的顶级课程吗？</em></p><p id="6be9" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉🏽订阅<a class="ae kz" href="https://datamachines.xyz/subscribe/" rel="noopener ugc nofollow" target="_blank"> <strong class="lu iu"> <em class="oe"> datamachines </em>简讯</strong> </a> <strong class="lu iu">。</strong></p><p id="8333" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉🏽<a class="ae kz" href="https://pau-labarta-bajo.medium.com/" rel="noopener"> <strong class="lu iu">跟着我</strong> </a>上媒。</p><p id="6042" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">👉🏽给课程一个⭐<a class="ae kz" href="https://github.com/Paulescu/hands-on-rl" rel="noopener ugc nofollow" target="_blank">github回购</a></p><p id="7ed8" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">祝你愉快，🧡❤️💙</p><p id="c445" class="pw-post-body-paragraph ls lt it lu b lv mo ju lx ly mp jx ma mb mq md me mf mr mh mi mj ms ml mm mn im bi translated">避寒胜地</p></div></div>    
</body>
</html>