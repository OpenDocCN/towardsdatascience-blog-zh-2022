<html>
<head>
<title>Using SHAP Values to Explain How Your Machine Learning Model Works</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用SHAP值来解释你的机器学习模型是如何工作的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137#2022-01-17">https://towardsdatascience.com/using-shap-values-to-explain-how-your-machine-learning-model-works-732b3f40e137#2022-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="1cd8" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">用SHAP值来解释你的机器学习模型是如何工作的</h1></div><div class=""><h2 id="d5e7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">学习使用工具来显示每个特征如何影响模型的每个预测</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7bd7208e0e4291bb86fedf2268beb655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHByax1pMse82whguXgFcw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">改编自<a class="ae kv" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@cakirchoff" rel="noopener ugc nofollow" target="_blank"> Chad Kirchoff </a></p></figure><p id="9090" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习模型通常是黑盒，这使得它们的解释很困难。为了理解影响模型输出的主要特征是什么，我们需要可解释的机器学习技术来揭示其中的一些方面。</p><p id="f572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中一种技术是SHAP方法，用于解释每个特征如何影响模型，并允许对数据集和手头的问题进行局部和全局分析。</p><h1 id="9426" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">SHAP价值观</h1><p id="db52" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">SHAP值(<strong class="ky ir">SH</strong>apley<strong class="ky ir">A</strong>additive ex<strong class="ky ir">P</strong>lanations)是一种基于合作博弈论的方法，用于增加机器学习模型的透明度和可解释性。</p><p id="e769" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，线性模型可以使用它们的系数作为每个特征的整体重要性的度量，但是它们随变量本身的比例而缩放，这可能会导致扭曲和误解。此外，该系数不能说明特征的<em class="mp">局部</em>重要性，以及它如何随着更低或更高的值而变化。基于树的模型的特征重要性也是如此，这就是为什么SHAP对于模型的可解释性是有用的。</p><blockquote class="mq mr ms"><p id="bf02" class="kw kx mp ky b kz la jr lb lc ld ju le mt lg lh li mu lk ll lm mv lo lp lq lr ij bi translated">重要提示:虽然SHAP显示了每个特征对模型预测的贡献或重要性，但它并不评估预测本身的质量。</p></blockquote><p id="8ef3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑一个合作游戏，玩家数量与游戏特征的名称相同。对于每个例子或观察，SHAP将披露每个参与者(或特征)对模型输出的贡献。</p><p id="c047" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定加州住房数据集[1，2](可从<a class="ae kv" href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset" rel="noopener ugc nofollow" target="_blank"> scikit-learn库</a>获得)，我们可以分离出一个单独的观察值，并计算该单独数据点的SHAP值:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="10a3" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.waterfall(shap_values[x])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/d5f978b49ea94d8f188de64e36b9c231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ef_-kN3Cs1CfmtQdN3WiqA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ac94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的瀑布中，x轴表示目标(因变量)变量的值，即房价。x是选择的观测值，f(x)是模型的预测值，给定输入x，E[f(x)]是目标变量的期望值，或者换句话说，所有预测的平均值(<code class="fe nh ni nj mx b">mean(model.predict(X))</code>)。</p><p id="7269" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该观测中每个特征的SHAP值由条形的长度给出。在上面的示例中，经度的SHAP值为-0.48，纬度的SHAP值为+0.25，依此类推。所有SHAP值的总和将等于E[f(x)]-f(x)。</p><p id="9a77" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">绝对SHAP值向我们展示了单个要素对预测的影响程度，因此经度的影响最大，其次是中纬度，平均值占第三位，人口是对预测影响最小的要素。</p><p id="ff72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，这些SHAP值仅对<strong class="ky ir"> <em class="mp">有效，本次观察仅</em> </strong>。随着其他数据点的SHAP值<strong class="ky ir"> <em class="mp">将</em> </strong>改变。为了理解特征对于整个数据集的重要性或贡献，可以使用另一个图，蜂群图:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="f06a" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.beeswarm(shap_values)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/28c2c8d787f7bb87bd5d73d7ead928be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QhlpEdTCEtjmPfCNbGW0TQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bac0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，纬度变量的高值对预测有很大的负面影响，而低值则有很大的正面影响。</p><p id="864b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MedInc变量在其值较高时具有非常高的正贡献，而在低值时具有低的负贡献。无论其值是高还是低，特征总体对预测几乎没有贡献。</p><p id="7eef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有变量按照全局特征重要性的顺序显示，第一个最重要，最后一个最不重要。</p><p id="9212" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实际上，SHAP可以通过使用特征重要性向我们展示全局贡献，以及通过蜂群图的散布展示问题的每个实例的局部特征贡献。</p><h1 id="a3a1" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">在Python中使用SHAP值</h1><p id="44fb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我在github上提供了这一部分的代码。看看这个:</p><div class="nl nm gp gr nn no"><a href="https://github.com/vinyluis/Articles/tree/main/Boruta%20SHAP" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">文章/博鲁塔SHAP在主要乙烯/文章</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">第1篇:用SHAP价值观解释你的机器学习模型是如何工作的(TBD) [EN]什么是SHAP价值观，如何…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc kp no"/></div></div></a></div><p id="cd0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要在Python中使用SHAP，我们需要安装SHAP模块:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="c1c3" class="nb lt iq mx b gy nc nd l ne nf">pip install shap</span></pre><p id="90f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们需要训练我们的模型。在示例中，我们可以直接从sklearn库中导入California Housing数据集，并训练任何模型，例如随机森林回归量</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="be63" class="nb lt iq mx b gy nc nd l ne nf">import shap<br/>import pandas as pd<br/>from sklearn.datasets import fetch_california_housing<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestRegressor</span><span id="c5e1" class="nb lt iq mx b gy od nd l ne nf"># California Housing Prices<br/>dataset = fetch_california_housing(as_frame = True)<br/>X = dataset['data']<br/>y = dataset['target']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)</span><span id="cf39" class="nb lt iq mx b gy od nd l ne nf"># Prepares a default instance of the random forest regressor<br/>model = RandomForestRegressor()</span><span id="828d" class="nb lt iq mx b gy od nd l ne nf"># Fits the model on the data<br/>model.fit(X_train, y_train)</span></pre><p id="55c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了计算模型的SHAP值，我们需要创建一个Explainer对象，并使用它来评估样本或整个数据集:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="a7da" class="nb lt iq mx b gy nc nd l ne nf"># Fits the explainer<br/>explainer = shap.Explainer(model.predict, X_test)<br/># Calculates the SHAP values - It takes some time<br/>shap_values = explainer(X_test)</span></pre><p id="1694" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">shap_values变量将有三个属性:<code class="fe nh ni nj mx b">.values</code>、<code class="fe nh ni nj mx b">.base_values</code>和<code class="fe nh ni nj mx b">.data</code>。</p><p id="e52a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj mx b">.data</code>属性只是输入数据的副本，<code class="fe nh ni nj mx b">.base_values</code>是目标的期望值，或者所有训练数据的平均目标值，<code class="fe nh ni nj mx b">.values</code>是每个例子的SHAP值。</p><p id="2cc5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们只对SHAP值感兴趣，我们可以使用<code class="fe nh ni nj mx b">explainer.shap_values()</code>方法:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="c5cb" class="nb lt iq mx b gy nc nd l ne nf"># Evaluate SHAP values<br/>shap_values = explainer.shap_values(X)</span></pre><p id="7307" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们只是想要SHAP算法确定的特征重要性，我们需要取每个特征的平均值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oe of l"/></div></figure><h1 id="584e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">SHAP图书馆的一些情节</h1><p id="8818" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">也可以使用SHAP库来绘制瀑布图或蜂群图，或者部分依赖图。</p></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="04a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了分析这些特征的整体效果，我们可以使用下面的图。</p><p id="3543" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">柱状图</strong></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="10e5" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.bar(shap_values)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/092f3a2ad36b12b4a1952413825fb493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyhevHqUKIRUIHM56UnexQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="fac5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，特征从对预测的影响最高到最低排序。它考虑了绝对SHAP值，因此要素对预测的影响是积极的还是消极的并不重要。</p><p id="dd23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">概要剧情:蜂群</strong></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="36a8" class="nb lt iq mx b gy nc nd l ne nf">shap.summary_plot(shap_values)<br/># or <br/>shap.plots.beeswarm(shap_values)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/e9110b6cc09b9086997acd92c0d0c666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LYsCWl85zu8Frmba8e2x_g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bccb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在beeswarm上，特征也根据它们对预测的影响进行排序，但是我们也可以看到特征的较高和较低值将如何影响结果。</p><p id="8460" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图上所有的小点代表一次观察。水平轴代表SHAP值，而点的颜色向我们显示该观察值与其他观察值相比是高还是低。</p><p id="bb60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本例中，较高的纬度和经度对预测有负面影响，而较低的值则有正面影响。</p><p id="5c04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">概要剧情:小提琴</strong></p><p id="9ae3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看蜂群信息的另一种方法是使用小提琴图:</p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="3f03" class="nb lt iq mx b gy nc nd l ne nf">shap.summary_plot(shap_values, plot_type='violin')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/ee0a39ff41543f2279d6f8f526898566.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ti_CtRiO2GjomaYQPf2xZw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="cc1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了分析局部的、实例式的影响，我们可以在单个观察值上使用下面的图(在下面的例子中，我使用了<code class="fe nh ni nj mx b">shap_values[0]</code>)。</p><p id="9fae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">本地条形图</strong></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="0f83" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.bar(shap_values[0])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/c8d3aaf121433554281299d23472a8f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yorFxtKBnfjuIoKwR7-KUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="407b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该图向我们展示了影响单次观测预测的主要特征，以及每个特征的SHAP值的大小。</p><p id="3e20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">瀑布图</strong></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="9741" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.waterfall(shap_values[0])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/d5f978b49ea94d8f188de64e36b9c231.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ef_-kN3Cs1CfmtQdN3WiqA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f127" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">瀑布图具有相同的信息，但以不同的方式表示。这里我们可以看到所有SHAP值之和等于预测值f(x)和期望值E[f(x)]之差。</p><p id="3ded" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">力图</strong></p><pre class="kg kh ki kj gt mw mx my mz aw na bi"><span id="c7d3" class="nb lt iq mx b gy nc nd l ne nf">shap.plots.force(shap_test[0])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi gj"><img src="../Images/b8836db14f3de84f8ffc851ca1311066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPuVoRiRmplHsJpWfxyJaQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e457" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于给定的观察，力图是查看每个特征对预测的影响的另一种方式。在该图中，正的SHAP值显示在左侧，负的显示在右侧，就像相互竞争一样。突出显示的值是该观察的预测值。</p></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="83cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这篇文章能帮助你更好地理解如何使用SHAP价值观来解释你的模型是如何工作的。这是每个数据科学家都应该拥有的工具，我们应该将它用于每个模型。</p><p id="d4ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">记得查看这篇文章的笔记本:</p><div class="nl nm gp gr nn no"><a href="https://github.com/vinyluis/Articles/tree/main/Boruta%20SHAP" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">文章/博鲁塔SHAP在主要乙烯/文章</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">第一篇:用SHAP价值观解释你的机器学习模型是如何工作的(TBD) [EN]什么是SHAP价值观，如何…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc kp no"/></div></div></a></div></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><h1 id="d073" class="ls lt iq bd lu lv op lx ly lz oq mb mc jw or jx me jz os ka mg kc ot kd mi mj bi translated">如果你喜欢这个帖子…</h1><p id="823e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">支持我一杯咖啡！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><a href="https://www.buymeacoffee.com/vinitrevisan"><div class="gh gi ou"><img src="../Images/acf4154cfebdc13859934db49fd502cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*h_y4o6IwDDFFWIyKQE7Rww.png"/></div></a><p class="kr ks gj gh gi kt ku bd b be z dk translated">给我买杯咖啡！</p></figure><p id="cf7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看看这个很棒的帖子</p><div class="nl nm gp gr nn no"><a rel="noopener follow" target="_blank" href="/boruta-shap-an-amazing-tool-for-feature-selection-every-data-scientist-should-know-33a5f01285c0"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">博鲁塔·SHAP:每个数据科学家都应该知道的惊人的特征选择工具</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">我们如何使用博鲁塔和SHAP构建一个惊人的特征选择过程——以python为例</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">towardsdatascience.com</p></div></div><div class="nx l"><div class="ov l nz oa ob nx oc kp no"/></div></div></a></div><h1 id="d03c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考资料:</h1><p id="b92c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1] Pace，R. Kelley和Ronald Barry,《稀疏空间自回归，统计和概率快报》, 33(1997)291–297</p><p id="6076" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]sci kit-学习开发者。<a class="ae kv" href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset" rel="noopener ugc nofollow" target="_blank">真实世界数据集:加州住房数据集</a>。最后一次访问是在2022年1月。(BSD许可证)</p></div></div>    
</body>
</html>