# 机器学习的特征工程(2/3)

> 原文：<https://towardsdatascience.com/feature-engineering-for-machine-learning-434c9b4912c6>

## 第 2 部分:特征生成

![](img/0bc1b4d1e8f90936da9c722ca5a0a4fe.png)

图片来自 [Pixabay](https://pixabay.com/) 的[皮特·林福思](https://pixabay.com/users/thedigitalartist-202249/)

在关于特征工程的三部分系列的第二部分([第一部分:数据预处理](https://medium.com/@wpoon/feature-engineering-for-machine-learning-a80d3cdfede6)，我们将看到有几乎无限多的方法从现有的构建新的特征，所以一旦你意识到下面描述的基本技术，特征生成中的*艺术*实际上是获得一种*直觉*对于给定的问题域尝试什么。

> “好的特性可以让简单的模型战胜复杂的模型”
> 
> —彼得·诺维格

# 2.特征生成

对于本文，我们将共同描述*特征提取*，它通常指特定领域的降维方法，以及*特征生成*，通常通过 *i.* 将现有特征映射到新空间， *ii .来完成。*把多种特征结合成一个复合体， *iii。*汇总数据以发现模式或 *iv。*合并辅助数据。我们将根据方法对底层数据类型的适用性对它们进行分组。

## 2.1 日期和时间

事件通常表现出周期性或季节性。周期性可能表现在多个时间尺度上，因此，根据您的数据，您可能希望将一个时间戳列分解为多个列，例如:分钟、小时、星期几、工作日或周末、月中的某一天、月、季或年。这样做还可以让您使用`[pd.DataFrame.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby)`来执行聚合，这本身就是生成新特性的最强大的方法之一。分解时间戳的一个简单方法是使用 Pandas 的字符串方法，例如`[pd.Series.str.split()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html?highlight=str)`:

```
# ‘date’ column in transactions is encoded as “01.04.2022”
transactions_date = transactions[‘date’].str.split(‘.’)# add three new columns to the dataframe
transactions[[‘day’, ‘month’, ‘year’]] = pd.DataFrame(transactions_date.tolist())
```

一旦创建了这些`groupby()`列，例如，为了预测产品的未来销售，您可以计算以下新特性并将其添加到您的模型中:I .上周*同一天销售的商品数量*，ii .从*到上月*的日均销售额，以及 iii。去年同月*销售额。*

可以生成的另一个非常有用的特征是**时间增量**，比如两个特征日期之间的差异。例如，在预测客户流失时，自服务/订购开始、合同到期或最后一次致电客户支持以来的月数。在欺诈检测中，该客户的最后一次信用卡交易可能已经过去了几天。在消费者支出中，指自上一个双周支付期(根据美国劳工统计局的数据，这是最常见的支付期)以来的天数。在医学诊断中，减去出生日期以获得年龄，然后再减去第 20 百分位目标阳性年龄以获得超过发病年龄。

当事件跨多个时区发生时，如果已知每个样本的对应位置，则对每个样本的本地时间进行编码可能是有益的。例如，一家美国在线零售商为 4 个时区(太平洋、山地、中部和东部)的客户提供服务，当预测点击率时，无论是晚上 8 点还是晚上 11 点，客户对推荐或广告的反应都会有所不同。

## 2.2 地理定位

对于地理定位，比如预测房价，增加新功能的一种方式是补充辅助数据。你可以将**距离**添加到相关地标:市中心、宗教场所、好学校等。如果地理位置数据已被匿名化(即非绝对坐标)，您仍然可以执行聚类，然后计算到聚类质心的距离。

局部最小值/最大值也是用于计算距离的有用参考点，充当期望的或不期望的地理实体的代理。另一个特征是周围的建筑密度，高密度表示受欢迎程度、交通选择的融合等。

## 2.3 定价

![](img/b44be47917383968a32ef8039f23f158.png)

图片由[200 度](https://pixabay.com/users/200degrees-2051452/)距[像素点](https://pixabay.com/)

对于一个算法来说，一件商品标价 5.00 美元和 4.99 美元几乎没有什么区别，但我们知道人类并不理性。因此，例如，如果预测销售额，您可以为以$0.49 或$0.99 结尾的价格添加一个标志(或者为价格的小数部分添加一列，让决策树自己找出模式)。同样，众所周知，某些价格点具有心理共鸣，并充当阻力位，例如 19 美元、49 美元、199 美元，因此添加一个(模 x)功能来帮助您的算法检测它们。

## 2.4 数值

线性回归不仅限于线性关系，它只需要对独立变量(即特征)呈线性。因此，添加**多项式特征**将使 LinR 更具表现力，并减少拟合偏差。使添加它们变得轻而易举，甚至支持交互功能，如下所述。

数字特征是添加**交互特征**(也称为交互**术语**)的良好候选。这些是通过在两个或多个特征之间执行加法/减法/除法/乘法而形成的。它们对于基于树的模型尤其有益，因为基于树的模型很难提取这种依赖性。

当然，对我们来说，困难在于创造这种互动的方式有无数种，只有一些是有用的。例如，在给定价格和建筑面积的情况下计算价格/平方英尺，在给定人口普查区块组规模和家庭数量的情况下计算平均家庭规模，将压力乘以温度以预测化学反应的速率。

t 型 SNE 通常用作可视化辅助工具，但你也可以使用它的投影[作为特征](https://zelros.medium.com/anomaly-detection-with-t-sne-211857b1cd00)。但是要注意，t-SNE 对超参数(困惑)值非常敏感，所以你需要实验来找到最好的方法。如果您确实使用 t-SNE 作为一个特性，不要使用 scikit-learn 的实现(sklearn.manifold.TSNE ),因为它没有. transform()方法。取而代之的是使用`[openTSNE.TSNE.transform()](https://opentsne.readthedocs.io/en/latest/api/index.html)`，它不仅更快，更重要的是支持新点的嵌入。如果只投影到二维对你的数据来说太有限，你可以试试 [**UMAP**](https://umap-learn.readthedocs.io/en/latest/index.html) 。

**如果特征直方图中有多个不同的峰值，连续变量的分桶**可能会有用。经度与房价的关系图没有显示可辨别的关系，但是绘制直方图显示了多个峰值，对应于位于纵向“带”内的城市-这些带可用作宁滨连续要素分类的阈值。

## 2.5 分类

分类交互特征对线性和 k-NN 模型有用，但对基于树的模型无效。它们是通过字符串连接两个分类特征以形成新的组合而形成的，例如连接“性别”∈ {M，F}和“教育水平”∈ {1，2，3，4}以给出“性别-EDC”∈{ M1，F1，M2，…}。好的候选特征是在相邻的决策树节点上频繁引用的特征。

分类**目标编码**(也称为似然或均值编码)在 Kaggle 竞赛上非常流行。它是每个分类类的编码，作为目标类值的某个函数。常见的功能包括:

*   均值:P(Y=1 | X_i)
*   证据权重(WOE): log( P(Y=1 | X_i) / P(Y=0 | X_i))
*   计数:#(Y=1 | X_i)
*   差值:#(Y = 1 | X _ I)#(Y = 0 | X _ I)

例如，可以使用`pd.df.groupby('feature')['y'].mean()`计算平均值

由于最大深度限制(在每个节点上只能走两条路中的一条)，决策树在处理高分类基数(许多唯一值)时有困难——对于相同的树深度，目标编码会导致更低的损失。

目标编码的主要问题是严重的*过拟合*或*数据泄漏*的风险。发生这种情况的一种方式是当训练集和验证/测试集之间的数据分布发生变化时(例如，目标平均值发生变化)。k 倍交叉验证和加法平滑是减轻这种风险的两种方法。

## 2.6 统计汇总

这是从现有要素创建新要素的最有效方法之一。必须做出三个选择:I .根据什么分组，ii .如何聚合各组，最后，iii。在哪个键上连接聚合统计信息。以下是一些例子:

*   计算在同一页面(分组)上显示给用户(加入)的所有广告的最小/最大/标准偏差(聚合)成本。可用于通过提供上下文来预测特定广告的点击率，即，该页面上更昂贵的广告将被更突出地展示，因此将对放置在同一页面上的更便宜的广告产生负面影响
*   用户在会话期间已经查看的页面数量，即推荐/广告疲劳。患者的症状数量，即任何一种症状可能不明显，但多种症状可能明显
*   对于去年的每个客户，两次连续交易之间的中间时间、每月交易的平均次数、每个消费类别费用的平均值和标准差，所有这些都有助于预测欺诈，方法是告知卡通常的使用频率、使用内容、金额和使用模式(临时与定期自动支付)

熊猫的“T1”对于计算这些统计数据是必不可少的，但群体可能还需要根据数字特征即时合成，例如在设定半径内房屋的平均价格/平方英尺。

有时数据分散在多个表中，在这种情况下，用从其他表收集的信息补充主(如交易)表，例如，如果商家与最近有争议的交易高峰有关，则在交易表中添加一个标志。

## 2.7 文本

在第一部分中，我们对原始文本进行预处理，并将其标记成小块文本。现在我们需要将这些组块序列转换成数字，这是矢量器的工作。

一个词袋(BOW，也称为计数)**矢量器**统计每个唯一标记在文档中出现的次数。通常可以选择忽略出现频率太低或太频繁的单词。术语频率(TF)矢量器对原始计数进行归一化，以显示每个术语构成的文档比例(即矢量元素总和为 1)。TF-IDF 矢量器进一步将 TF 乘以每个术语在文档语料库中出现频率的倒数的对数。

单词和句子**嵌入**(例如 Word2vec、GloVe、fastText)在文本特征生成方面提供了更高层次的复杂性。注意，由于这些被训练的方式，即无监督训练，所得到的单词嵌入的数学“接近度”反映的不是语义相似性，而是单词的共现，例如“爱”和“恨”在一个句子中频繁地一起出现，因此将在嵌入空间中紧密地映射在一起，即使它们是反义词。

还要注意，这些简单的嵌入是静态的，对于每个单词，只有一个对应的嵌入。因此，它们不能进行语义消歧，即`black bear`、`bear market`和`bear arms`中的“熊”将被分配相同的矢量嵌入。

当涉及到嵌入时(比如使用 Word2vec)，您可以选择是使用[预训练嵌入](https://code.google.com/archive/p/word2vec/)，还是让模型使用反向传播在您的数据上学习它自己的嵌入。如果您希望创建一个总结句子的单一特征，句子也可以有嵌入，通过将单个单词向量平均在一起，使用`[CLS]`标记的嵌入，或者使用类似 [Doc2vec](https://radimrehurek.com/gensim/models/doc2vec.html) 的东西。对于短语(如“煎锅”)，尝试 [sense2vec](https://github.com/explosion/sense2vec) 。

创建附加文本特征的最后一个技巧是对每段文本执行双重翻译(例如英语→西班牙语→英语)，然后使用集成对两个语料库进行预测。

## 2.8 图像

![](img/d42f7c3d4b9a642f02bbd84de22cf320.png)

图片由 [Jan Tik](https://www.flickr.com/photos/15363357@N00/271992932) 标注 [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/?ref=openverse) 。

在大型数据集上训练的预训练模型(通常是 CNN)学习将整个图像表示为其最终层中的潜在表示。通过截断“头部”，但保留“身体”，这些模型可以用作**特征提取器**。馈入和馈出图像是图像嵌入，常见的输出尺寸为 768 或 2048。

您不仅可以从不同的模型架构(例如 VGG16、ResNet50、MobileNet)中选择，还可以根据在图像的*域特定子集*上训练模型来选择权重。为什么这行得通是因为没有免费的午餐定理:没有放之四海而皆准的最佳解决方案。TensorFlow Hub 提供了一系列 ResNet50 模型，这些模型具有相同的架构，但针对 ImageNet 类别的不同子集进行了培训。使用在[花子树](https://tfhub.dev/google/experts/bit/r50x1/in21k/flower/1)上训练的权重，我发现我能够在 *Oxford102* 数据集上获得比使用在整个 *ImageNet-1K* 上训练的权重显著更高的准确性(即相关性胜过丰度)*。*

对于最先进的技术，正如变形金刚通过注意力的应用彻底改变了自然语言处理，人们也可以使用预训练的视觉变形金刚( [ViT](https://tfhub.dev/sayakpaul/collections/vision_transformer/1) )来提取(768 到 1024 维)图像的矢量表示。

## 2.9 时间序列

对于时间序列数据，除了那些已经在【第 2.1 节】中提到的，人们可以通过添加一个或多个**滞后特征**来生成新的特征。简单地将数据延迟或移位(例如`[pd.DataFrame.shift()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift)`)一段设定的时间。使用自相关，例如`[statsmodels.tsa.stattools.acf()](https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.acf.html)`，确定最具预测性的滞后期。

另一种技术也有消除时间序列趋势的额外好处，就是将时间序列编码为与某个时期的**差**或增量。对于具有强烈趋势的时间序列，例如长期的股票价格，最好使用**比率指标**或百分比变化，而不是绝对变化，因为这能更好地反映价格的变化。这两种转换(差异或比率)也可以应用于目标变量(让模型预测第二天的变化，而不是绝对值)。

**移动窗口聚合**(也称为跟踪指示器)也可以添加上下文。例如，价格的移动平均线可以用来检测市场趋势。同样，使用不同的汇总时间跨度是有帮助的，例如交易者经常使用 50 天和 100 天的 SMAs。也可以使用扩展窗口，但不太常见。

然后是特定于领域的特征，例如添加一个特征来指示与前一天的收盘相比有多大的涨跌差距。MACD 指标是用两个指数移动平均线(EMA)的差值计算出来的，用来检测趋势何时加速。对于与天气相关的时间序列，计算露点(温度和压力的函数)。

时域数据可以转换到**频域**。单独执行傅立叶变换更属于特征提取的范畴，而不是特征生成的范畴，因为变换后的数据不再在时间上锚定，因此不能与时域特征一起使用，如上所述。然而，时间可以被结合回来，例如在光谱图的情况下，我们可以跟踪功率谱密度作为时间的函数的变化。

## 2.10 表征学习

表征学习(RL)是指使用非参数(即非统计)方法学习潜在表征，以*提取特征*。已经描述了一些例子，例如单词嵌入和基于 CNN/ViT 的图像特征提取器。

强化学习已经非常成功地应用于计算机视觉。[例如，SimCLR](https://github.com/google-research/simclr) 可用于使用无监督学习从无标签数据中学习视觉表示。然后，通过引入一小部分标签，可以利用学习到的表示以惊人的准确度对数据集的其余部分进行分类。

特征提取器对于执行相似性搜索特别有用。这是因为一旦被训练(或者如果使用预训练的特征向量)，提取的特征向量对于一组输入是不变的。在相似性搜索中，您是根据相似性度量(如余弦相似性)将一个样本与整个数据库进行比较。通过*预先计算*所有对应于原始输入的特征向量一次，你可以非常有效地存储并随后使用一个特殊的数据库如 [FAISS](https://faiss.ai/) 执行最近邻相似性搜索。

本系列关于特征工程的第二部分到此结束。我们现在已经积累了大量的特性，所以在第三部分，我们将把注意力转向*特性选择*，在这里我们看看如何将小麦从谷壳中分离出来，以确保我们不会过度拟合我们的数据。