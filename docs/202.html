<html>
<head>
<title>Scaling PyCaret with Spark (or Dask) through Fugue</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过赋格用火花(或Dask)缩放PyCaret</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scaling-pycaret-with-spark-or-dask-through-fugue-60bdc3ce133f#2022-01-07">https://towardsdatascience.com/scaling-pycaret-with-spark-or-dask-through-fugue-60bdc3ce133f#2022-01-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="ed7e" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">通过赋格用火花(或Dask)缩放PyCaret</h1></div><div class=""><h2 id="614f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">分布式地在每个数据分区上运行PyCaret函数</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6a4a43e9500369aae47a0f5c17b3e73c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V5I9QQwMv8A8RRkr"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">汉尼斯·艾格勒在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="72bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">PyCaret 是一个低代码机器学习框架，它自动化了机器学习管道的许多部分。只需几行代码，就可以在一个数据集上训练多个模型。在本文中，我们将探讨如何通过在Spark或Dask上以分布式方式运行几个PyCaret训练任务来扩展这种能力。</p><h1 id="588a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">PyCaret模型分数网格示例</h1><p id="b912" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">首先，我们看一个简单的PyCaret分类示例。大部分代码摘自PyCaret文档中的<a class="ae kv" href="https://www.pycaret.org/tutorials/html/CLF101.html" rel="noopener ugc nofollow" target="_blank">本教程</a>。重点是展示我们如何用几行代码生成模型排行榜。</p><p id="937e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们通过使用<code class="fe mp mq mr ms b">get_data</code>函数加载Titanic数据集。这是一个众所周知的分类数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从PyCaret获取泰坦尼克号数据集</p></figure><p id="e64b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将为我们提供以下数据。在这个例子中，我们关心的是创建一个模型来预测一个乘客是否幸存。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/9e7b534f9561649fe00e522af88307e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rH1yw7rucf_TTWCoP-UuoQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自Titanic数据集的样本数据</p></figure><p id="d214" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以使用PyCaret进行模型训练。下一个代码块中有三个函数调用来训练模型并为我们的数据集检索它们的指标。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PyCaret比较模型</p></figure><p id="98f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个函数调用的简要说明:</p><ul class=""><li id="1eaa" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><code class="fe mp mq mr ms b">setup</code>初始化环境并创建要运行的转换管道。</li><li id="0d89" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe mp mq mr ms b">compare_models</code>运行几个模型训练运行，并用分层交叉验证对它们进行评分。这将返回基于<code class="fe mp mq mr ms b">n_select</code>的顶级型号。值为5将返回前5个训练模型。</li><li id="3232" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><code class="fe mp mq mr ms b">pull</code>将为我们获取分数网格数据框架。下面是一个示例(前5行按准确度排序)。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/e214342d442cf257c7a0ccd24064f077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*zRASDvqg0S1vPL1Qq22gCg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">泰坦尼克号数据集的评分网格</p></figure><p id="dc0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">稍后，我们将看看如何使用Spark或Dask分布式并行运行多个<code class="fe mp mq mr ms b">compare_models</code>调用。在此之前，我们将了解如何为Spark或Dask带来单独的功能。</p><h1 id="d4f7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">包装PyCaret代码</h1><p id="ac19" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/fugue-project/fugue" rel="noopener ugc nofollow" target="_blank"> Fugue </a>是一个开源框架，将Python、Pandas或SQL代码移植到Spark或Dask。在这篇博客中，我们将看看<code class="fe mp mq mr ms b">transform</code>函数。这采用单个函数，并在数据的每个分区<strong class="ky ir">的Spark或Dask上执行它。</strong></p><p id="3cfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先将PyCaret代码封装在一个名为<code class="fe mp mq mr ms b">wrapper</code>的函数中。这个<code class="fe mp mq mr ms b">wrapper</code>函数将用于Spark中的每个数据分区。在<code class="fe mp mq mr ms b">wrapper</code>里面基本上是我们之前所有的代码。唯一的新东西是重置索引和重命名列。这是因为Fugue需要列名不包含空格和句点，以便与所有后端兼容。</p><p id="329d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，函数的类型注释(pd。DataFrame)是神游所需要的，以便知道如何将函数带到Spark或Dask。这是因为赋格可以处理更多的注释，比如<code class="fe mp mq mr ms b">List[Dict[str, Any]]</code>或<code class="fe mp mq mr ms b">Iterable[List[Any]]</code>。在<code class="fe mp mq mr ms b">transform</code>函数中也需要模式，因为Spark和Dask需要显式模式(或从中受益匪浅)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用赋格包装PyCaret</p></figure><p id="ec7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有了一个基本功能，可以用在原生熊猫身上。调用<code class="fe mp mq mr ms b">transform</code>函数将会得到与之前的分数网格相同的结果。通过在Pandas上测试它，我们知道当我们把它移植到Spark执行引擎上时，这个代码将会工作。但是在将它引入Spark之前，我们将在下一节中首先对数据进行分区。</p><h1 id="a402" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Spark和Dask上的机器学习</h1><p id="3501" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">大数据集上的机器学习有两种形式。Dask-ML <a class="ae kv" href="https://ml.dask.org/" rel="noopener ugc nofollow" target="_blank">文档</a>对此提供了很好的解释。第一个是内存限制问题，即数据集不适合单台机器。在这种情况下，一个大型模型正在整个集群中接受训练。第二个是与计算相关的问题，在这种情况下，多个模型根据适合单台机器的数据进行训练。群集用于并行化多个较小的模型训练作业。</p><p id="1484" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当数据太大而不适合单台机器时，通常意味着可以使用数据的逻辑分组将问题分成几个更小的机器学习问题。在这个巨大的例子中，我们将按性别(男性或女性)分割数据，然后为每组数据运行PyCaret <code class="fe mp mq mr ms b">compare_models</code>。</p><h1 id="9ac9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">将PyCaret代码移植到Spark和Dask</h1><p id="0c0e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">下面的代码会把数据拆分成男性和女性，然后对每一组运行<code class="fe mp mq mr ms b">compare_models</code>。这两个<code class="fe mp mq mr ms b">compare_models</code>函数调用将在Spark上分布式运行。首先，我们将首先显示代码和输出，然后我们将进行修改以使我们的<code class="fe mp mq mr ms b">wrapper</code>产生火花。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mt mu l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在Spark上分布式运行PyCaret</p></figure><p id="f05e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这为我们提供了前5名模型和两组(男性和女性)的指标。对于这个特定的问题，我们看到性能略有提高。由于数据量的原因，这可能是有限的。然而，对于大数据集，与在整个数据集上训练一个大模型相比，这种方法通常可以产生显著的改进。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/e4d8eb2569e409c06913d5b1545164ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*pBCLFXGryIjzo3mO9xCMgg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Spark上的分布式培训结果</p></figure><p id="59cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了将PyCaret引入Spark，我们必须对我们的<code class="fe mp mq mr ms b">wrapper</code>函数进行如下修改:</p><ul class=""><li id="b546" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">将性添加到模式中。分布式计算框架对模式有严格的要求。</li><li id="ad54" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">在结果中添加一个名为Sex的列。这是为了在我们收集所有结果时进行跟踪。因为数据是因为调用了<code class="fe mp mq mr ms b">wrapper</code>函数而被预先分区的，所以我们保证在性别列中有一个统一的值(男性或女性)。</li></ul><p id="f7f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们对<code class="fe mp mq mr ms b">transform</code>呼叫做了以下更改:</p><ul class=""><li id="f7ff" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">将原始数据帧中的np.nan替换为None。Spark很难解释同时具有np.nan和string值的列。</li><li id="f32c" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">添加了一个按性别划分的分区，将数据分成两组</li><li id="e2f5" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">导入了fugue_spark，并为fugue使用了“spark”执行引擎。</li></ul><h1 id="d558" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="dd32" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在本文中，我们展示了如何利用Spark同时对多个数据分区执行PyCaret模型训练。自撰写本文以来，PyCaret团队和Fugue团队正在致力于一个更加原生的集成，以便在Spark或Dask上分发<code class="fe mp mq mr ms b">compare_models</code>功能。可以在Github上跟踪<a class="ae kv" href="https://github.com/pycaret/pycaret/issues/2015" rel="noopener ugc nofollow" target="_blank">的进展。</a></p><h1 id="8eae" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">数据许可证</h1><p id="01c1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">Titanic数据集由PyCaret在MIT许可下托管。</p></div></div>    
</body>
</html>