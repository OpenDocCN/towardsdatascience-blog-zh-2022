<html>
<head>
<title>Garbage Route Optimization Using Computer Vision Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用计算机视觉目标检测的垃圾路线优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d#2022-01-04">https://towardsdatascience.com/garbage-route-optimization-using-computer-vision-object-detection-17a217d5582d#2022-01-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="32c8" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/data-for-change" rel="noopener" target="_blank">变更数据</a></h2><div class=""><h1 id="53e7" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">使用计算机视觉目标检测的垃圾路线优化</h1></div><div class=""><h2 id="1767" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">由我10岁的女儿Isabella合著，她的科学展项目变成了她的第一个动手机器学习项目</h2></div><p id="9d6c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是我女儿五年级科学展期末报告的编辑版本。我们在一起工作了两个月，每次几个周末。就我个人而言，这是一个<em class="lk">非常</em>有益的机会来教她(我所知甚少)计算机视觉和Python编码。</p><p id="b232" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从她执行第一个Colab cell <code class="fe ll lm ln lo b">2+2</code>的那一刻起，她就被迷住了——只看到它演变成一个完全成熟的系统，可以检测图像中的垃圾:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/4fe6e8da7bc659596d1e9d2cccb47cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuUo8RRUmwzSvjnT6RhLBA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">我女儿对我们第一个经过训练的模型在验证集图像中识别垃圾的最初反应。【图片由作者提供。]</p></figure><p id="3380" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我期待着与下一代人工智能工程师合作更多的项目！</p></div><div class="ab cl mf mg hu mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="ij ik il im in"><h2 id="5dae" class="mm mn iq bd mo mp mq dn mr ms mt dp mu kx mv mw mx lb my mz na lf nb nc nd iw bi translated">问题动机</h2><p id="f2cf" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">我对我在我的城市里看到的垃圾数量感到困扰。保持街道清洁很重要，因为垃圾会渗入我们的土壤和水源。这种环境影响对我们的健康是可怕的——更不用说动植物了。似乎这还不够，我们自然景观的美丽被垃圾大大削弱了。</p><p id="aa57" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了提高对这一问题的认识，我假设市议会需要良好的数据来(1)确认问题存在于他们的地区，以及(2)确定哪些地区最需要垃圾收集资源。为了解决这个问题，我设想了一种安装在城市车辆(警车、垃圾车等)上的摄像机。)在车辆执行其日常公民职责时被动地收集视频数据。然后，摄像头数据由计算机视觉系统处理，该系统可以自动检测摄像头视野中的垃圾。最后，我设想向市议会提供一个数据产品(比如热图)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nk"><img src="../Images/28843ea12f310848cf610952803aa895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e6SBN_cN3y_oAbQMlhdEIw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">德克萨斯州埃尔帕索垃圾检测热图。【图片由作者提供。]</p></figure><p id="3776" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">有了这样一个系统，我相信城市会对最需要帮助的地区采取有针对性的行动。</p><h2 id="08d8" class="mm mn iq bd mo mp mq dn mr ms mt dp mu kx mv mw mx lb my mz na lf nb nc nd iw bi translated">蓝图</h2><p id="85f3" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">我开始我的项目时，头脑风暴了这个问题的多种解决方案。在一个解决方案中，我设想了一个简单的、非技术性的实现:</p><div class="lq lr ls lt gt ab cb"><figure class="nl lu nm nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/a5dd38aaf48d767446e48145ca465999.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/format:webp/1*81HtCyyH1VbEoiFv3wQsGA.jpeg"/></div></figure><figure class="nl lu nr nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/0e912ddab3b72ae140c35dda0a2123c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*pGFywm3_4R1egAeltN6P5w.jpeg"/></div></figure><figure class="nl lu nr nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/7ef8261dc59c5a5d948bba4b91f1224e.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*zFuIdWNr_SyvrYBupTyigA.jpeg"/></div><p class="mb mc gj gh gi md me bd b be z dk ns di nt nu translated">提议系统的蓝图。【图片由作者提供。]</p></figure></div><p id="72ea" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">解决方案1有许多限制。也就是说，它不可扩展。没有一个城市会让它的工人每天都盯着每条街上的垃圾。因此，我考虑了“解决方案2”，它利用机器学习来对来自相机馈送的图像进行分类。这种解决方案很有吸引力，因为它是可行的，并且具有商业现成组件的成本效益。解决方案2有两个重要的局限性:它不能识别多个垃圾项目，也不能识别不同种类的垃圾。因此，我考虑了“解决方案3”，一个被训练来识别每张图像的多种垃圾类型的物体检测系统。</p><p id="ed9d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是我如何准备和使用我的机器学习模型的蓝图:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nv"><img src="../Images/480eade4a5eb5beb3953a808ecbf4960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxdCYw6PBlZtvWn0HWd2wg.jpeg"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">机器学习工作流的系统图。【图片由作者提供。]</p></figure><h2 id="9aae" class="mm mn iq bd mo mp mq dn mr ms mt dp mu kx mv mw mx lb my mz na lf nb nc nd iw bi translated">建筑物</h2><p id="7b34" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">以下摘录来自我的<a class="ae nj" href="https://colab.research.google.com/drive/1PU3rJeuUgWYHnpZ-uyFwaCfxoU6rArYA#scrollTo=zwgMTbrjereU" rel="noopener ugc nofollow" target="_blank"> Google Colab笔记本</a>。</p><p id="e382" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，我在Colab中安装了Tensorflow对象检测库。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nw"><img src="../Images/a5cd652f20f945c7eec21f19a7e22466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sibjof-3t_6KDrQX2FEJ_Q.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="4a31" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后我下载了<a class="ae nj" href="https://github.com/pedropro/TACO" rel="noopener ugc nofollow" target="_blank"> TACO数据集</a>，它包含了数以千计的COCO格式的标签垃圾图片。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nx"><img src="../Images/0b5e339f90169ae7260b1ddc88e63f5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrP3JB81sTUeLXNq836qaQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">[图片由作者提供，<a class="ae nj" href="https://github.com/pedropro/TACO/" rel="noopener ugc nofollow" target="_blank"> TACO Github库</a>在<a class="ae nj" href="https://github.com/pedropro/TACO/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可</a>下的截图。]</p></figure><p id="d086" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">接下来，我将COCO数据格式从XML转换为适合Tensorflow对象检测器的CSV格式。然后我创建了一个数据框，其中包含文件名、类(“Trash”)和边界框坐标。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ny"><img src="../Images/7e645efd53f4ddf60aa53314d9510cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsTl9wbo3BAdZcsLa3DxPA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="645a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我创建了一个数据混洗和分割，将图像随机分配到训练、测试和验证组。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nz"><img src="../Images/804586a4baf183c3e948b90b1b6eede6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWwx73sAW2rS11x-N3cJAw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="9c11" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我从TensorFlow库中配置了一个具有预训练权重的<a class="ae nj" href="https://tfhub.dev/tensorflow/efficientdet/d0/1" rel="noopener ugc nofollow" target="_blank"> efficientDet_d0_512x512 </a>对象检测器。这有助于减少训练时间，因为模型已经配置了一些基本层来检测各种对象。这里的任务是用垃圾的例子“微调”基础模型，以便它也能学会检测我的例子。</p><p id="d4b4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我对模型进行了训练，并观察了它的total_loss函数，以确定它的训练是否正确。请注意，随着模型在训练迭代中不断运行，损失函数会逐渐减小。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oa"><img src="../Images/607dca6946f349f039c38638a5a2075b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KANvQhpCHsfqkPLPXMURxw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="28e1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我导出了模型权重，以便以后可以根据需要重新加载它们。这很重要，因为否则每次我想运行对象检测推理时，我都必须重新训练该模型，这并不好，因为花了1.5小时来完成训练该模型。</p><p id="2b81" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我还确认了我可以可靠地重新加载我导出的模型，如下所示:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ob"><img src="../Images/2cea6cf404d2d48d8d43d0677ae1e5ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HoQ2NYg06hrses2ApOFJkg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="01ac" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">急于看到我的结果，我使用了一个脚本，该脚本将拍摄模型从未见过的新照片，以可视化其性能:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oc"><img src="../Images/2dee6356b4b8d8e1a7eb26d711e23d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yNK983mlPz2orHWmJ4WQfA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="33c4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">以下是该步骤的一些输出示例:</p><div class="lq lr ls lt gt ab cb"><figure class="nl lu od nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/5118f3fc44b0f8ea41d932fa08bc215c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*oZ4KfUSMD6aCspYcolfw_Q.png"/></div></figure><figure class="nl lu od nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/f4eb8c79ea8cd48dccdf663bd15bd58a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*AdsGMSIoGtrlucvMusET7w.png"/></div></figure><figure class="nl lu od nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/968a0cd48457d9027abae88d0fea5fc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*bYyfbQUiSpRYUaLajPPtPA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk oe di of nu translated">【图片由作者提供；底层图片是<a class="ae nj" href="https://github.com/pedropro/TACO/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可的</a>来自<a class="ae nj" href="https://github.com/pedropro/TACO/" rel="noopener ugc nofollow" target="_blank"> TACO开源库</a>的数据。]</p></figure></div><p id="1417" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">模型完成后，我将注意力转向从图片的EXIF元数据中提取纬度和经度。我用这个脚本成功地完成了这个任务:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi og"><img src="../Images/286c9f3b2e5db265b11b2569b24509f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EjAXB9EtSLL1x86wF7R9qQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="df0b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">另一天，我坐在父亲汽车的后座上，他开着车在德克萨斯州埃尔帕索的各个街区转悠，而我则用iPad拍照。这些图片包括地理位置数据，我可以使用上面的脚本提取。</p><p id="7e6e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">拍完所有的照片后，我们将iPad连接到电脑上，下载照片。后来，我们将这些图像上传到Colab环境的“custom_data”文件夹中。</p><p id="f554" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于custom_data文件夹中的每个图像，以下脚本(1)执行对象检测推理，(2)提取纬度/经度，(3)将数据一起存储在dataframe(表)中。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oh"><img src="../Images/56c40fbd471528fb30d8687ac24e0539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6XineEQ_chPxvoGzfrL-wg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="d7fd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下面是一个输出示例:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oi"><img src="../Images/ecbc8f43cf72c12d477cbd0c116bfd57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ODhvpXAzKjYivGBRcDK3Q.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="2275" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">接下来，我为GeoPandas安装了一个lyum插件，它提供了一个热图功能:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oj"><img src="../Images/488152b1b9fdc6a1d5acc0d9a8eb82f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3VHX9u900FyMNbLtZznRfA.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供。]</p></figure><p id="75c7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">从上面的脚本中输入数据帧创建了一个交互式热图，显示垃圾或多或少的区域。以下是德克萨斯州埃尔帕索不同地区的一些热图截图:</p><div class="lq lr ls lt gt ab cb"><figure class="nl lu ok nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/4cf79495e57b1cbdf654557bc557aedf.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*wkV6TsoPPdDUXKPLJuS4uA.png"/></div></figure><figure class="nl lu ol nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/cac4169fed50d481ef26d0048df2b222.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*6xWjEWhTTYmQllKlFcTShQ.png"/></div></figure><figure class="nl lu om nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/ff573f8938c8798b09e867371f0719bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*e6SBN_cN3y_oAbQMlhdEIw.png"/></div></figure></div><div class="ab cb"><figure class="nl lu on nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/5d000770db43928f76a7e6ec09462a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*W9YNOg-NwTlImdUUiodJ_A.png"/></div></figure><figure class="nl lu oo nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/9a81ec8b318675d0e03dc0512020b2dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*m0vZz27Kj6gBicRJy2bc1g.png"/></div></figure><figure class="nl lu op nn no np nq paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/6aaea03f092da4b03a85f9b9d293d37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*YxLGa-V45av9_gQCexaUdg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk oq di or nu translated">【每张图片由作者提供。]</p></figure></div><p id="2f1a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">回顾这些数据，我做了一些重要的观察。首先，沃尔玛的停车场出奇的干净。我曾假设那里会非常脏，因为人和车太多了。然而，经过思考，我认为这是一个干净的区域，因为企业有兴趣创造一个友好的购物环境，因此定期清洁停车场。第二，我假设10号州际公路附近的区域会因为交通流量而变脏。我的数据支持这一结论，埃尔帕索市应该分配更多的资源清理该地区。第三，农业区(又名“上谷”)脏得惊人。我推测更少的房屋和人会导致更少的垃圾。恰恰相反。</p><h2 id="a13b" class="mm mn iq bd mo mp mq dn mr ms mt dp mu kx mv mw mx lb my mz na lf nb nc nd iw bi translated">结论</h2><p id="49bd" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">总之，这是一个学习更多关于Python、机器学习和对象检测的伟大项目——所有这些都是在为城市做好事的背景下进行的！对于最初的问题，这是一个很好的解决方案，因为如果没有自动化，人们执行这样的分析将会非常耗时。我提出的解决方案是一种经济高效的方法，可以快速识别城市中有大量垃圾的区域。我可以想象在城市车辆上配置我的系统，以便他们在执行其他日常任务时定期收集这些数据。</p><p id="1f74" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">下一次，我会做一些不同的事情。例如，我会尝试为拍摄城市照片创造一种更平衡的采样方法。我担心我是如此渴望找到垃圾的照片，在这样做的时候，我可能在我的数据中过度采样了垃圾(偏见)。我记得在一个公园里，我可以看到许多垃圾，我特意跑过去给它们拍照。</p><p id="c432" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">至于改进我的设计，我会做两个重要的改变。首先，当同一块垃圾出现在多张照片中时，我会找到一种方法来处理垃圾计数过多的问题。这发生在汽车缓慢移动时，我快速拍摄了一系列照片，从而在一张照片的前半部分和第二张照片的后半部分包含了垃圾。在这种情况下，同一个垃圾在一个特定的区域被计数两次。改进这种设计的一种方法是创建一个地理过滤器，在每个地理半径内只取一个样本。例如，即使10张照片是在同一纬度/经度拍摄的，那么其中一张照片应该仅用于分析。</p><p id="3d33" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第二，该模型有时会将<em class="lk">相同的垃圾项目</em>识别为预测数组中的多个推断。这里有一个例子:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi os"><img src="../Images/997e678cbea61d451e6a1d844bd65b7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9O7rwsrDpiSChOzunZBMfw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供；底层图片是来自<a class="ae nj" href="https://github.com/pedropro/TACO/" rel="noopener ugc nofollow" target="_blank"> TACO开源库</a>的<a class="ae nj" href="https://github.com/pedropro/TACO/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> MIT许可的</a>数据。]</p></figure><p id="2e0c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">未来的改进包括处理推理以确定一个边界框是否实质上在另一个推理边界框内，这样我只从许多相似的预测中的一个得到结果。在这里，为了使项目在我分配的时间内易于处理，我采用了一系列预测中最有可能的对象检测推断。举例来说，我的系统在热图中只识别和绘制一个项目，即使物体检测器可以发现两个项目(见下图)。这导致了在特别脏的地区对垃圾的统计不足。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/30602bbfb7f1eb7648a042e1f5e0735a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*--Tnsc_7qiLf4Ggpj5IEmg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">【图片由作者提供；底层图片是<a class="ae nj" href="https://github.com/pedropro/TACO/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可的</a>来自<a class="ae nj" href="https://github.com/pedropro/TACO/" rel="noopener ugc nofollow" target="_blank"> TACO开源库</a>的数据。]</p></figure><p id="69c5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">第三，我的第一个训练模型使用了60+类的TACO数据集(铝箔，气溶胶罐，包装纸等。).但是我假设我没有足够的训练数据来准确地捕获这么多不同的类，在这种情况下，我正在微调一个现有的模型。相反，我使用了一个脚本，将所有垃圾类转换成一个名为“trash”的超类这样，我可以用大约2400个不同的垃圾样本来训练物体检测器。这一改变提高了我的模型持续检测上传图像中垃圾的能力。</p><p id="bc78" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我的想法在这个项目中不断发展。起初，我想建立一个对象检测器模型，因为它可以计算每张图像中的多块垃圾，并报告不同类型的垃圾(铝、纸、玻璃等)。).但是我遇到了一些挑战，例如(1)意识到当相同的垃圾出现在不同的图像中时，该模型会对其进行多次计数，以及(2)以不同的准确度对相同的项目进行多次分类。为了解决这些问题，我的设计必须改变。首先，我创建了一个只有一个类(“trash”)的对象检测器，并对每张图像只计数一个Trash实例。回想起来，我应该使用图像分类器。我怀疑这样训练会更快。</p><p id="17da" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这个项目应该帮助其他人谁想要扩展我的工作。我希望有一天世界各地的城市都能实施这个项目。这样，他们可以识别最脏的区域并优化垃圾收集工作。我真心喜欢帮助地球和编码。这个项目是我结合这些激情的完美方式。</p><p id="168a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi">—</p><p id="ae22" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">非常感谢<a class="ou ov ep" href="https://medium.com/u/a6b447eb702d?source=post_page-----17a217d5582d--------------------------------" rel="noopener" target="_blank">佩德罗·普罗恩萨</a>和<a class="ou ov ep" href="https://medium.com/u/c391c9b3d21f?source=post_page-----17a217d5582d--------------------------------" rel="noopener" target="_blank">佩德罗·西莫斯</a>开源他们的项目，<a class="ae nj" href="https://arxiv.org/abs/2003.06975" rel="noopener ugc nofollow" target="_blank"> TACO:垃圾检测上下文中的垃圾注释</a>，这使得这项工作成为可能。</p><p id="4df8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里使用的训练、测试和验证数据集是在<a class="ae nj" href="https://github.com/pedropro/TACO/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可</a>下的，可以在位于【https://github.com/pedropro/TACO】T2的GitHub上获得。用于创建热图可视化的数据是作者拍摄的图像。</p></div></div>    
</body>
</html>