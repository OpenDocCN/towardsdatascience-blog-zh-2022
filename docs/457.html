<html>
<head>
<title>Principal Component Analysis (PCA): A Physically Intuitive Mathematical Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析:物理直观的数学介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/principal-component-analysis-pca-8133b02f11bd#2022-01-16">https://towardsdatascience.com/principal-component-analysis-pca-8133b02f11bd#2022-01-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="0021" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">主成分分析:物理直观的数学介绍</h1></div><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/8a9678bac793827a6397dad964d2113d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*60u4gOXkDzBLRnDj5rWgtQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">亨特·哈里特在<a class="ae kc" href="https://unsplash.com/@hharritt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="67b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主成分分析(PCA)涉及旋转欧几里德空间中的数据点云，使得方差沿着第一轴最大，即所谓的第一主成分。主轴定理确保数据可以以这种方式旋转。在数学术语中，PCA涉及寻找正交线性坐标变换，或者更一般地，寻找新的基。</p><p id="55f7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PCA背后的数学在刚体转动的描述中再次被发现。这种物理解释对于理解PCA是有指导意义的。</p><p id="d942" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博客文章可以在<a class="ae kc" href="https://github.com/lnemec/Intro2PCA" rel="noopener ugc nofollow" target="_blank"> github </a>的<a class="ae kc" href="https://julialang.org" rel="noopener ugc nofollow" target="_blank"> julia </a>笔记本上找到。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="2bb8" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">定义参数以生成样本数据</h1><p id="4071" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">首先，我们将生成一个由欧几里德空间中的<em class="ml"> N </em>个随机分布的数据点组成的云<em class="ml"> ℝⁿ </em>，坐标为<em class="ml"> { x⃗⁽ ⁾，x⃗⁽ ⁾,…，x⃗⁽ᴺ⁾ } = X </em>。我们将基于<em class="ml"> 3 </em>维度数据来演示这个概念，其中<em class="ml"> n=3 </em>和<em class="ml"> X </em> ⊂ ℝ，基向量<em class="ml"> e⃗₁ </em>、<em class="ml"> e⃗₂ </em>和<em class="ml"> e⃗₃ </em>以原点<em class="ml"> (0，0，0) </em>为中心。为简单起见，我们将沿基向量<em class="ml"> e⃗₃ </em>的所有坐标设置为零。它将允许我们在<em class="ml"> e⃗₁ </em>和<em class="ml"> e⃗₂ </em>平面上可视化数据。</p><p id="c07d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的例子中，我们用<em class="ml"> N=820 </em>个数据点创建了一个数据集。数据中的方差设置为<em class="ml"> R1=4.0 </em>和<em class="ml"> R2=8.5 </em>，数据在空间中旋转<em class="ml">角度=35.0 </em>。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/92eeb3955e6761bfffcab26f7c1a9342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*WaikVuNLDKbx3Gfe20dRIg.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图一。a)沿e⃗₂.分布的随机点的直方图b)欧几里得空间ℝ中随机分布的数据点的云，具有坐标<em class="mr"> { x⃗⁽ ⁾，x⃗⁽ ⁾,…，x⃗⁽ᴺ⁾ } = X </em>，具有基本向量(图b中的轴)<em class="mr"> e⃗₁ </em>和<em class="mr"> e⃗₂ </em>。b)图中的灰线表示u⃗₁和u⃗₂.的主轴线c)沿<em class="mr"> e⃗₁ </em>分布的随机点的直方图。沿e⃗₃的所有值都等于零。</p></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="532b" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">转动惯量</h1><p id="7464" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">刚体的转动惯量<strong class="kf ir"> <em class="ml"> J </em> </strong>也称为转动惯量，决定了围绕旋转轴的期望角加速度所需的扭矩。这取决于物体的质量分布和选定的旋转轴。转动惯量<strong class="kf ir"> <em class="ml"> J </em> </strong>较大的物体需要更大的扭矩来改变物体的转速。对于同一个刚体，不同的旋转轴会有不同的惯性矩。换句话说，它取决于身体的质量分布和选择的轴，更大的力矩需要更大的扭矩来改变身体的转速。</p><p id="14c3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">刚体的所有转动惯量都可以用一个矩阵来概括。一般来说，它可以相对于空间中的任何一点来确定。为了简单起见，我们将计算相对于质心的转动惯量。</p><p id="69c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">物体的主轴(也称为图形轴)和主惯性矩可以通过旋转点质量云来找到。在数学术语中，PCA涉及寻找正交线性坐标变换，或者更一般地，寻找新的基。</p><p id="8e0f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最大主惯性矩对应的图形轴是质点分布最大的平面的面积矢量。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/38209e000d4f0a6a57fa62404a944d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/1*Q5eINhZ7re-LHTESfJAB7A.gif"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图二。六个气缸质量相同，但转动惯量不同<strong class="bd mt"> J </strong>。当它们滚下斜坡时，转动惯量越小的圆柱体加速越快。(<a class="ae kc" href="https://en.wikipedia.org/wiki/File:RollingVsInertia.gif" rel="noopener ugc nofollow" target="_blank">图片取自维基百科</a> <a class="ae kc" href="https://en.wikipedia.org/wiki/File:RollingVsInertia.gif))*" rel="noopener ugc nofollow" target="_blank"> ) </a></p></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="8fee" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">PCA中主轴和惯性矩的视觉比较</h1><p id="e078" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在下面，我们将以两种方式解释上面的随机数据点集合。首先，我们用协方差矩阵<strong class="kf ir"> <em class="ml"> C </em> </strong>将数据点<em class="ml"> X </em>解释为统计分布的数据。二、<em class="ml"> X </em>用惯性矩矩阵<strong class="kf ir"> <em class="ml"> J </em> </strong>表示一个刚体的一组点质量。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/de7ca6c9ab860a942b40653c9d30d86c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*LY_x269DDjqxkY8fudTgSw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图3。a) PCA:第一主分量u⃗₁是沿着方差最大的轴，由红色箭头指示b)惯性矩:图轴u⃗₂对应于由绿色箭头指示的(实际上第二)最大的主惯性矩。</p></figure><p id="e193" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">借助<em class="ml">图1 </em>和<em class="ml"> 3 </em>的视觉支持，我们预计PCA的主轴和惯性矩是相同的。然而，最大主成分和主惯性矩的值对于大多数数据集来说是不同的。</p><blockquote class="mu mv mw"><p id="6ce0" class="kd ke ml kf b kg kh ki kj kk kl km kn mx kp kq kr my kt ku kv mz kx ky kz la ij bi translated"><strong class="kf ir">注:</strong>在物理学中，惯性矩是针对三维刚体定义的。为简单起见，我们将数据投影到e⃗₁和e⃗₂.之间的平面上在我们的例子中，质点分布最大的平面是由e⃗₁和e⃗₂.展开的对应于最大力矩的主轴指向沿e⃗₃的平面外，并与e⃗₁和e⃗₂.正交</p></blockquote><p id="b789" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">沿着u⃗₁的线相当于方差最大的方向。在下文中，我们将通过数学上探索PCA和惯性矩来支持我们的视觉理解。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="d800" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">刚体转动惯量的定义</h1><p id="67c9" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">对于一个质量为mᵢ的刚性物体<em class="ml"> N </em>点在ℝⁿ，转动惯量<strong class="kf ir">jt23】由下式给出</strong></p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5a18bf230caab164d9c0259731383353.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*bvCAX0U38k_CcM0iRxIQVQ.png"/></div></figure><p id="9e0d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它的组成部分由等式定义。(1)作为</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/bf2245f2589aeb75ec8cd471907b933b.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*hL0C2q4bG9IUgpk5dVkcGw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">方程式(1)</p></figure><p id="8689" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="ml"> δⱼ,ⱼ' </em>是克罗内克δ，而<em class="ml"> M = ∑ᵢᴺ mᵢ </em>是总质量。</p><blockquote class="mu mv mw"><p id="b254" class="kd ke ml kf b kg kh ki kj kk kl km kn mx kp kq kr my kt ku kv mz kx ky kz la ij bi translated"><strong class="kf ir">注:</strong>这里，我们用总质量来归一化转动惯量。在物理学中，惯性矩通常不会这样归一化。</p></blockquote><p id="a72c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">走近一看，我们看到<strong class="kf ir"> <em class="ml"> J </em> </strong>与<em class="ml"> Jⱼ,ⱼ' = Jⱼ',ⱼ </em>对称。谱定理告诉我们<strong class="kf ir"> <em class="ml"> J </em> </strong>有实特征值λ，并且可由一个正交矩阵对角化(正交可对角化)。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="ce74" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">协方差矩阵的定义</h1><p id="10ed" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">欧几里德空间中以平均值为中心的点云的协方差矩阵<strong class="kf ir"> <em class="ml"> C </em> </strong>由下式给出</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/e0f706e0d439ec7b96991ef552b85339.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*kSgUqkhuzjq7X7Et1i3msA.png"/></div></figure><p id="5e7b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它的组成部分由等式定义。(2)作为</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/7b8de72241e80acb576f8473e9ec86a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*tJ2KK_KdgH6CzgKmAiLVFw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">方程式(2)</p></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="503e" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">求解特征值问题</h1><p id="aae1" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">PCA的主轴和惯性矩可以通过旋转空间中的数据点来确定。更准确地说，通过求解特征值问题来计算主分量和轴。</p><p id="c5b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个实对称矩阵(如<strong class="kf ir"> <em class="ml"> C </em> </strong>和<strong class="kf ir"> <em class="ml"> J </em> </strong>)的特征分解为一个旋转矩阵<strong class="kf ir"> <em class="ml"> R </em> </strong>和一个对角矩阵<strong class="kf ir"><em class="ml">λ</em></strong>的乘积</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/b508e0a31422c50848535a34294be48b.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*BciXoLmpyX0wqrff3mclDg.png"/></div></figure><p id="108d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由<strong class="kf ir"><em class="ml">j</em></strong><em class="ml">=</em><strong class="kf ir"><em class="ml">rλr</em></strong><em class="ml">ᵀ给出。</em>旋转矩阵<strong class="kf ir"> <em class="ml"> R </em> </strong>的列定义主轴的方向，常数λ₁、…、λₙ是矩阵<strong class="kf ir"><em class="ml">λ</em></strong><br/>的对角元素，称为主矩。</p><p id="9339" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">矩阵<strong class="kf ir"> <em class="ml"> J </em> </strong>和<strong class="kf ir"> <em class="ml"> C </em> </strong>的结构是相同的，除了非对角元素的符号。我们将在下面看到，对于<strong class="kf ir"> <em class="ml"> C </em> </strong>和<strong class="kf ir"> <em class="ml"> J </em> </strong>，特征向量将是相同的。另外我们会看到<strong class="kf ir"> <em class="ml"> C </em> </strong>的特征值<strong class="kf ir"><em class="ml">λ</em></strong>与<strong class="kf ir"> <em class="ml"> J </em> </strong>的特征值是如何关联的。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="26a6" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">显示<strong class="ak"> <em class="mr"> C </em> </strong>和<strong class="ak"> <em class="mr"> J </em> </strong>的特征向量相等</h1><p id="1267" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">让我们改写一下由Eq定义的转动惯量矩阵<strong class="kf ir"> <em class="ml"> J </em> </strong>。(1)就等式中的协方差矩阵<strong class="kf ir"> <em class="ml"> C </em> </strong>而言。(2).</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/f2a5ccb8da803adfa5ffe508cc911874.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*_v8ToYyHxQaTLd2TVKmnWQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">等式3</p></figure><p id="c46d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kf ir"> <em class="ml"> I </em> </strong>为单位矩阵。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/319a2b5e6ffe511359d6a872a3813ebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*-ymm51psSUGzL8nNUkFP9g.png"/></div></figure><p id="3b0b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了获得<strong class="kf ir"> <em class="ml"> C </em> </strong>的特征向量和特征值，我们通过将<strong class="kf ir"> <em class="ml"> C </em> </strong>分解为一个旋转矩阵<strong class="kf ir"> <em class="ml"> R </em> </strong>和一个对角矩阵<strong class="kf ir"><em class="ml">λ</em></strong>ₒᵥ的乘积来解决特征值问题</p><p id="c34e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"><em class="ml">c</em></strong>=<strong class="kf ir">r</strong><strong class="kf ir"><em class="ml">λ</em></strong>ₒᵥ<strong class="kf ir"><em class="ml">r</em></strong>t115】ᵀ</p><p id="156d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kf ir"> R </strong>由特征向量v⃗ʲ.组成在<em class="ml"> 3 </em>的情况下——维空间<strong class="kf ir">r</strong>=【v⃗v⃗v⃗】</p><p id="7882" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/c398378253a220bfd32788db0f67d05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*-ubiYRpfxMoI21gi9QVZmg.png"/></div></figure><p id="203a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">协方差矩阵<strong class="kf ir"> <em class="ml"> C </em> </strong>的jᵗʰ特征向量v⃗ʲ和jᵗʰ特征值λʲₒᵥ由下式给出</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/53feb85e60b7c1d2b254af63a4b0eae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*CysiUuCPSTAdnnrZ72ICRw.png"/></div></figure><p id="1036" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面，我们将删除索引$j$并将上面的公式重写为<strong class="kf ir"> <em class="ml"> C </em> </strong> λₒᵥ = λₒᵥv⃗.乘法等式Eq。(3)通过右侧的特征向量v⃗，我们找到等式。(4).</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/111c37204732090445771fe61b2ce1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*9yDKARSzO-YlK9mV9B4IHg.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">等式4</p></figure><p id="1f83" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">情商。(4)暗示<strong class="kf ir"> <em class="ml"> C </em> </strong>和<strong class="kf ir"> <em class="ml"> J </em> </strong>具有相同的特征向量v⃗.</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="a372" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">计算转动惯量矩阵的特征值</h1><p id="b20a" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated"><strong class="kf ir"> <em class="ml"> C </em> </strong>和<strong class="kf ir"> <em class="ml"> J </em> </strong>的特征向量相同，但特征值不相同。为了将它们联系起来，我们需要注意到</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/4ef1358d1d38cc8b0b3b29fa89f3c1fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*lPbU7Ra2xv85iL1O2xs4Tg.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">等式5</p></figure><p id="2ea2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中我们使用了矩阵的迹在循环置换下是不变的，所以</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f73fff3884fd803d04fcde35c8665c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*ou6VjZgqETtgzt9ZH9IkWw.png"/></div></figure><p id="40fa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Eq。(4)和情商。(5)我们可以写出特征值<strong class="kf ir"><em class="ml">λ</em></strong><em class="ml">J</em>的转动惯量<strong class="kf ir"> <em class="ml"> J </em> </strong> (Eq。(1))作为</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/eb434e08d431fee53f1789a20df36a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*_uBtejWqwyJxcTyXnMj4Nw.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">等式6</p></figure><p id="1969" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到，kᵗʰ特征值λᵏ<em class="ml">j</em>可以用特征值λₒᵥ.来表示</p><p id="2b91" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">物理上，我们可以通过考虑沿着例如轴v⃗的协方差特征值由数据点在<em class="ml"> (1) </em>方向上的分量确定，而围绕轴<em class="ml"> (1) </em>旋转的转动惯量由数据点离该轴的欧几里德距离确定，来获得对这两组特征值之间关系的直观理解。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="8253" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">使用上述数据集X计算特征值和特征向量</h1><p id="d28c" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">接下来，我们计算协方差矩阵元素、特征值和特征向量。数据集<em class="ml"> X </em>的协方差矩阵<strong class="kf ir">CT39】为</strong></p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/d9189529c14ed68041269ed1788fc11a.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*wyO00Tcszp8TZBsTdJa6Rg.png"/></div></figure><p id="091d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于变异矩阵<strong class="kf ir"> <em class="ml"> C </em> </strong>，我们求出特征值</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d212f675ae2f631d359ab57437778863.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*M02A3tsxeZt98xHvhswFgg.png"/></div></figure><p id="eef6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和特征向量</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/59120f240dd5f7c44f207306acd85e8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*YkEgHCtXc3HL6ZyzbNmV4Q.png"/></div></div></figure><p id="495d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Eq。(6)我们可以计算出<strong class="kf ir">J<em class="ml">J</em>T51】的特征值λ <em class="ml"> J </em></strong></p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/e2becf04117f7eff3bb14d607d222dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*qmB-SvjfE0-4rLt97kKBPA.png"/></div></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="6ab4" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">计算J的特征值和特征向量</h1><p id="2314" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">现在，我们计算转动惯量的矩阵元素、特征值和特征向量。数据集<em class="ml"> X </em>的惯性矩矩阵<strong class="kf ir">JT55】为</strong></p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/b00d523dcb06f2615e38f38c33d84d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*dZsEch1FGt3OCFXj9047cA.png"/></div></figure><p id="c3c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于转动惯量矩阵<strong class="kf ir"> <em class="ml"> J </em> </strong>，我们求出特征值</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/c0e99e2d799f08267a2d4520f5c57e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*nVI9pKDD7OeZaLV8nEhaqg.png"/></div></figure><p id="7ef3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和特征向量</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/654261535b7a268c975d3f7836a7b8de.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*FR7PbXl0MQ5QsCqEuRIQXQ.png"/></div></figure><p id="9afa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在数据点云的两种解释中——第一种是以平均值为中心的点云，第二种是围绕质心旋转的刚体——我们获得了相同的特征向量。</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/a3a6a818c27b68c76272db87e728f342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Ru70FsXX-v7lQOElrdVFbQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图4。随机分布的数据点云<strong class="bd mt"> X </strong>。覆盖的是缩放的特征向量(显示为红色和绿色箭头)。</p></figure><p id="c30f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们使用特征向量和特征值来旋转数据，并在新的基中表示它</p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/1e03391749b40f588ac54f0e3f25b447.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*V_liE6uVQfmzzdDqq85KPQ.png"/></div></figure><p id="d258" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们旋转数据集<em class="ml"> X </em></p><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/fbd3fa07696c7a9880892a9eb51bf3b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*sM1FmdSgyqlHwkDPFTEwQg.png"/></div></figure><figure class="mn mo mp mq gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/fde4d3ddd6b18dda343d8924194916a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*gnuiVmmJzawn3XtfnYF52Q.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><em class="mr">图5。随机分布的数据点云</em> <strong class="bd mt"> <em class="mr"> X </em> </strong> <em class="mr">由矢量</em>【u⃗₁u⃗₂u⃗₃】<em class="mr">所表示的基跨度。灰色箭头表示旧的基矢</em> e⃗₁和e⃗₂ <em class="mr">在这个新的基中。</em></p></figure></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="41c5" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">最后的想法</h1><p id="d0e4" class="pw-post-body-paragraph kd ke iq kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在机器学习和数据科学中，使用PCA有两个原因。<br/>首先，一些机器学习算法的准确性和数值稳定性对相关的输入数据很敏感。特别是，执行协方差矩阵反演的机器学习算法可能会遇到奇点问题——高斯混合模型浮现在脑海中。另一个不同的例子是应用随机森林算法来检测不同特征之间的相互作用，其中大的相关性可以掩盖这些相互作用。首先执行PCA允许我们梳理相关性的影响，这可以改进特征重要性分析。</p><p id="4160" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二，PCA用于降低数据集的维数，例如用于数据压缩。在我们的例子中，我们使用了一个三维数据集<strong class="kf ir"> <em class="ml"> X </em> </strong>，但是e⃗₃组件没有携带任何信息(通过构造)。我们可以使用主成分分析来证明删除第三维是正确的，因为主成分分析会显示在e⃗₃方向上的方差是最小的。像这样使用高维数据集到低维空间的投影是处理高维数据和处理[ <a class="ae kc" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a> ]的有力工具。</p><p id="1e8d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对PCA的两种应用都进行了广泛的讨论。参见下面的进一步阅读建议。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="0aee" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">进一步阅读</h1><ol class=""><li id="decf" class="nv nw iq kf b kg mg kk mh ko nx ks ny kw nz la oa ob oc od bi translated">鲍克哈格、克里斯蒂安&amp;董、天丝；<a class="ae kc" href="https://www.researchgate.net/publication/326541038_A_Tutorial_on_Principal_Component_Analysis_Part_1_Motivation" rel="noopener ugc nofollow" target="_blank">主成分分析教程第一部分:动机</a> (2018)</li><li id="fbee" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated">鲍克哈格、克里斯蒂安&amp;董、天丝；<a class="ae kc" href="https://www.researchgate.net/publication/326546791_A_Tutorial_on_Principal_Component_Analysis_Part_2_Principal_Axis_via_Moment_of_Inertia" rel="noopener ugc nofollow" target="_blank">主成分分析教程第二部分:通过惯性矩的主轴</a> (2018)</li><li id="a7f0" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated">洪、梁；<a class="ae kc" href="https://www.scientific.net/AMR.945-949.2071" rel="noopener ugc nofollow" target="_blank">LOS检测中“基于转动惯量的方法”和“基于PCA的方法”等价性的证明</a>；先进材料研究。945–949.2071–2074 (2014)</li><li id="0e5b" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated">凯文·墨菲；<a class="ae kc" href="https://isbnsearch.org/isbn/9780262018029" rel="noopener ugc nofollow" target="_blank">机器学习的概率视角</a>，麻省理工学院出版社，第12.2章(2012年)</li><li id="2ff2" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated">斯蒂芬·马斯兰德；<a class="ae kc" href="https://isbnsearch.org/isbn/9781466583283" rel="noopener ugc nofollow" target="_blank">从算法角度看机器学习</a>，第二版，Chapman and Hall/CRC (2014)</li><li id="c20c" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated"><a class="oj ok ep" href="https://medium.com/u/551ba3f6b67d?source=post_page-----8133b02f11bd--------------------------------" rel="noopener" target="_blank"> Will Badr </a> <a class="ae kc" rel="noopener" target="_blank" href="/why-feature-correlation-matters-a-lot-847e8ba439c4">为什么特征相关性很重要…很多！</a>博客走向数据科学(2019)</li></ol></div></div>    
</body>
</html>