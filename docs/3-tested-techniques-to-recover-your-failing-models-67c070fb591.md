# 3 种经过测试的技术来恢复失败的模型

> 原文：<https://towardsdatascience.com/3-tested-techniques-to-recover-your-failing-models-67c070fb591>

## 曾经表现良好的模型可能会开始恶化。这就是你能坚持下去的方法。

![](img/3eef1276e8ccb4cec0e774930b41d4c1.png)

照片由来自 [Pexels](https://www.pexels.com/photo/photo-of-person-riding-kayak-3413686/) 的 [Thilo Lehnert](https://www.pexels.com/photo/photo-of-person-riding-kayak-3413686/) 拍摄。

宇宙中只有一个常数——变化！

你所看到和感觉到的一切都是一个版本——你用来拟合模型的数据也不例外。

随着时间的推移，一个完美的模型无法像过去那样预测。这不是一个错误；这就是 ML 模型的工作方式。期待它是 ML 工程师的工作。

生产中的 ML 模型与白水漂流非常相似。更糟糕的是，这是一条没有人走过的河流。你必须对当前的形势有所了解，才能预见未来。忽视危险可能会把你的木筏引向悬崖。

将其转化为 MLOps，您必须在您的模型开始跌落悬崖之前主动跟踪底层数据的变化——在它们做出不准确的预测之前。

这种现象被俗称为“**概念漂移**”

由于**并非所有的变化都是独特的**，处理它们需要不同的策略。例如，社会行为，如离婚率，显示出缓慢的变化。另一方面，股票市场经常受到冲击，一夜之间创造和毁灭百万富翁。

而且还有**周期性变化**。你现在经历的变化可能会在未来几年逆转。

您的域可能会显示这些类型的变化之一。你应该在它们发生之前做好准备。

<https://levelup.gitconnected.com/concept-drift-in-machine-learning-1fc7a4396b10>  

这里有三种 ML 工程师经常用来对抗概念漂移的技术。

# 为你的模特制定一个再培训计划。

再培训是一个简单易懂的概念。在每个周期中，你都会得到一组新的数据。您可以使用它们从头开始再次训练模型。

鉴于其简单性，您可能会经常使用它。但是，再培训是一项昂贵的工作。只有当你的模型训练起来既便宜又快速时，你才能从再训练中获益。

你可以采取三种方法中的一种来优化成本和培训时间。您可以用…重新训练模型

*   仅限您的新数据；
*   你过去的所有数据，或者；
*   最新数据点权重更大的完整数据集。

## 仅用最近的数据重新训练模型。

虽然放弃旧数据并完全根据新数据进行重新训练听起来可能违反直觉，但它们在许多情况下是有帮助的，尤其是如果您确定旧数据已经过时，并且只会在模型中产生噪声。

短期金融市场预测就是一个很好的例子。因为有大量的机器人交易账户，如果有一种模式，很快所有的机器人都会学习它们。结果，这种模式很快就过时了。您的模型可能必须忘记过时的模式，并在新的数据集中找到新的模式。

这种再培训方式成本较低，因为它涉及的数据很少。但是这个模型失去了先前学习的背景。

只有当你的旧数据毫无疑问是不相关的时候，才使用它。

使用较小的数据集时，您应该注意模型**过度拟合**。虽然只有最近的数据集可能看起来是一种廉价而快速的重新训练方法，但如果您的模型有很多参数，它可能会过度学习数据点。

## 重新训练你所有过去的数据集

当你需要在知识中坚持的时候，你不能丢弃你已经拥有的。因此，您可能需要使用所有过去的数据来重新训练模型。

例如，天气预报肯定会发生变化。出于这个原因，我们更严肃地谈论气候变化。但是这种转变是渐进的。您的模型可以从过去的数据中受益，同时从新数据中学习不断变化的模式。

这种培训方式的缺点是成本高。数据点越多，存储和培训成本就越高，这不足为奇。

但是如果你的模型有很多参数，这可能是不可避免的。为了避免过度拟合，数据集必须足够大。

## 在最近的数据点上重新训练更多的权重

当数据集必须足够大，但又想考虑老化数据集时，可以使用这种方法。

当您需要在整个数据集上重新训练模型，但又希望赋予最新的模型更多的重要性时，您可以使用权重。您可以为较新的数据点分配较大的权重，而为较旧的数据点分配较小的权重。

但是要做到这一点，您的算法应该支持数据点选择。如果没有，你可以**对数据集**进行采样，使其更接近最新的。

# 定期用新数据更新旧模型。

这听起来可能与前面的策略相似。但是有一个微妙的区别。这里我们不像以前那样从头开始重新训练模型。我们用新的数据集更新已经训练好的模型。

你的算法应该支持初始权重和批量训练。如果你使用的是深度神经网络，这是一个很好的选择。

更新模型可能比从头再培训更划算。但这也取决于模型的大小和输入数据的大小。如果每次更新都有大量的数据点，并且您的模型有数百万个参数，那么这可能不是一个很好的选择。

另一方面，如果你必须坚持过去的知识并适应新的变化，这种方法是合适的。

# 使用新组件扩展您的模型。

基于前面的两个策略，只重新训练模型的可变组件可能是有益的。

更先进的技术，如迁移学习和模型集成，使这成为可能。

在**迁移学习**中，你拿一个预先训练好的神经网络进行再训练。不是重新训练整个模型，而是只解开网络的最后一层。这通常被称为解冻。现在，您使用新数据训练前一层。这个模型不会忘记它以前学过的所有东西。然而，最新数据在最终决策中发挥着关键作用。

</transfer-learning-in-deep-learning-641089950f5d>  

你也可以使用一个新的模型来改进你的预测。我们称这样的团体为“T2 模特组合”。虽然您的初始模型保持不变，但中间会有一个新的模型。新模型从新数据中学习，并改变原始模型的行为。

# 有时候，什么都不做也没关系！

你没看错。

什么都不做意味着你训练一个模型，并长时间使用它。它也被称为**静态模型**。

静态模型之所以吸引人，有几个原因。

你需要一些标准来衡量任何事情。静态模型允许我们在它们发生时识别和漂移。对于数据漂移，这个**静态模型就是你的标尺**。

此外，当您对现有模型进行更改时，您需要一个基准来评估。静态模型也是一个完美的目标。

然而，您必须小心静态模型。如果您在生产中使用，您应该确保数据和模型漂移不会对模型产生太大影响。

# 最后的想法

如果你认为数据科学家或 ML 工程师的工作在模型部署后就结束了，那你就是在冒险。

这只是开始。

生产中的模型性能下降。这被称为概念漂移，是机器学习中一个被广泛研究的挑战。

根据具体情况，您可以使用各种技术来确保您的模型持续保持最佳性能。

在这篇文章中，我们讨论了 ML 工程师经常使用的五种策略来对抗概念漂移。

您可以重新培训、更新或扩展模型！每一种都有其优点和缺点。

当你的模型无法准确预测时，你会怎么做？

> 感谢阅读，朋友！在[**LinkedIn**](https://www.linkedin.com/in/thuwarakesh/)[**Twitter**](https://twitter.com/Thuwarakesh)[**Medium**](https://thuwarakesh.medium.com/)上跟我打招呼。
> 
> 还不是中等会员？请使用此链接 [**成为会员**](https://thuwarakesh.medium.com/membership) 因为，在没有额外费用给你的情况下，我赚了一点佣金。