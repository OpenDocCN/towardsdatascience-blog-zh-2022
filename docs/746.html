<html>
<head>
<title>Understanding Machine Learning Interpretability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解机器学习的可解释性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-machine-learning-interpretability-168fd7562a1a#2022-01-26">https://towardsdatascience.com/understanding-machine-learning-interpretability-168fd7562a1a#2022-01-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="7858" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">理解机器学习的可解释性</h1></div><div class=""><h2 id="f759" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">机器学习可解释性介绍，</strong>可解释性评估的驱动力、分类、示例和注释。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4a09028ecfee973ce3cf69136a06020c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VtVnP6tedRVFXXWk"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">丹妮拉·奎瓦斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6dff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> T </span>如今，机器学习无处不在，尽管机器学习模型已经显示出很好的预测性能，并在不同的应用中取得了显著的突破，但这些机器学习模型正变得越来越复杂，反过来，它们的内部工作结构以及它们如何达到特定的结果变得不清楚，甚至对专家来说也是隐藏的，这提出了一个严重的问题:我们如何信任这些模型？</p><p id="f3df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，机器学习在高度监管和关键领域(如刑事司法、金融服务和医疗保健)的应用要求测量机器学习模型，不仅要基于其准确性，还要基于其可解释性和透明度。</p><p id="a9d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文概述了机器学习的可解释性、驱动力、分类、可解释性方法的示例以及评估可解释性方法质量的重要性。</p><p id="bcda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章结构如下:</p><p id="e7f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 1。驱动力</strong></p><p id="9c45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.1人工智能事件</p><p id="88a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.2公众意识和法规</p><p id="84ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2。术语</strong></p><p id="fe3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 3。示例</strong></p><p id="4895" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 4。评估可解释性</strong></p><p id="c473" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 5。总结和结论</strong></p><p id="1843" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 6。参考文献</strong></p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="1e85" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated"><strong class="ak"> 1。驱动力</strong></h2><p id="50dd" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated"><strong class="ky ir"> 1.1 AI事件</strong></p><p id="83f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">许多事件都是因为不完善的人工智能和机器学习而记录的，这引起了人们对我们如何信任这些自动算法的关注，早期的严重事件之一是在2016年5月7日，当时一名特斯拉司机在自动驾驶仪激活时被杀[1]</p><p id="cd03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2018年，优步自动驾驶汽车在车辆处于自动驾驶模式时撞死了一名行人(女性)，“优步发现其自动驾驶软件在汽车的传感器检测到行人后决定不采取任何行动”[2]</p><p id="5810" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2019年11月，纽约州金融服务局(State Department of Financial Services)在显示出对女性客户的歧视后，对高盛(Goldman Sachs)的信用卡算法进行了调查，此前丹麦企业家兼开发商大卫·海涅迈尔·汉森(David Heinemeier Hansson)在推特上说:“我和我的妻子提交了联合纳税申报单，住在一个共有财产的州，已经结婚很长时间了。然而，苹果的黑盒算法认为我应该得到她20倍的信用额度”[3]，同样的事件迫使亚马逊关闭了其人工智能招聘工具，该工具被发现歧视女性申请人[4]。</p><p id="368f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在刑事司法中，<a class="ae kv" href="https://www.propublica.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> ProPublica </strong> </a>的一份报告显示，<strong class="ky ir"/>COMPAS是美国法院用来评估被告成为累犯的可能性的案件管理和决策支持工具[15]，该报告显示该软件对黑人有偏见，预测他们的风险是白人的两倍[5]。</p><p id="870d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">医疗保健也不是人工智能故障的例外，许多事件的发生引起了人们对人工智能在医疗保健领域可信度的关注。</p><p id="8373" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，新的研究表明，美国一家大医院指导数千万人护理的软件系统地给予白人患者优先于黑人患者的权利[6]</p><p id="278b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还有很多事件需要提及，你可以在这里找到更多报道:<a class="ae kv" href="https://incidentdatabase.ai/" rel="noopener ugc nofollow" target="_blank">https://incidentdatabase.ai/</a></p><p id="36bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 1.2公众意识和法规</strong></p><p id="4113" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工智能事件以及人工智能和机器学习在安全关键和受监管领域的使用日益增加，促使人们关注机器学习可解释性的重要性，将其作为信任机器学习模型及其结果的不可否认的要求。</p><p id="ef95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在欧洲，一个重要的项目是DARPA的XAI计划，正如该计划官方网站所述，该计划旨在创建一套机器学习技术:</p><ul class=""><li id="5de6" class="ng nh iq ky b kz la lc ld lf ni lj nj ln nk lr nl nm nn no bi translated">产生更多可解释的模型，同时保持高水平的学习性能(预测精度)；和</li><li id="8d8d" class="ng nh iq ky b kz np lc nq lf nr lj ns ln nt lr nl nm nn no bi translated">使人类用户能够理解、适当信任和有效管理新一代人工智能伙伴[7]。</li></ul><p id="35a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于美国，2016年10月，国家科学技术委员会技术委员会发表了一份题为“为人工智能的未来做准备”的报告，其中一项建议是，“向州政府和地方政府提供拨款以支持使用基于人工智能的系统对个人做出相应决定的联邦机构应审查拨款条款，以确保用联邦拨款购买的基于人工智能的产品或服务以足够透明的方式产生结果，并得到有效性和公平性证据的支持”[16]。</p><p id="0946" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最近的法规包括欧盟于2021年4月发布的一项提案[9]，题为“制定关于人工智能的协调规则(人工智能法案)并修改某些欧盟立法法案”，其中强调并强制执行不同级别的透明度，作为在欧盟市场使用和部署人工智能系统的要求。</p><p id="4775" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，许多国家已经公布了他们自己的人工智能战略提案，包括法国[10]，德国[11]，葡萄牙[12]，英国[13]，美国[14]以及许多其他国家，人工智能系统的透明度和可解释性是人工智能未来的强制性要求。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="6c03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2。术语</strong></p><p id="4218" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2.1可解释性:</strong></p><p id="3378" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对可解释性没有一致的定义，在定义可解释性时，有必要考虑上下文和领域，但粗略地说，可解释性是用户或专家理解模型决策和结果背后的基本原理的手段。</p><p id="305f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一般来说，有两种方法可以实现可解释性[8]:</p><p id="47ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.1.1开发本质上可解释的模型，或者通过使用本质上可解释的模型，例如线性回归、决策树，或者通过对模型施加其他约束。</p><p id="1090" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.1.2开发适用于已开发模型的解释方法。</p><p id="0234" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2.2模型前对比模型中对比模型后</strong></p><p id="8b8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">前模型是指我们在选择和开发模型之前使用的可解释性方法，为此，它与探索性数据分析密切相关。</p><p id="68f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型内可解释性是关于本质上可解释的模型。</p><p id="5c9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">后模型(Post-Hoc)指的是在模型被开发之后，试图增强模型可解释性的可解释性技术。</p><p id="3896" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2.3特定型号与不特定型号的对比</strong></p><p id="f7ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特定于模型的可解释性技术仅限于特定类型的模型，而模型不可知技术可以应用于任何模型(事后)。</p><p id="b703" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 2.4本地与全球</strong></p><p id="f2d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">局部可解释性方法是指解释单个预测的方法，而全局方法是指解释整体模型的方法</p><p id="1405" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了总结机器学习可解释性相关分类的图表:</p><p id="3ae0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【道歉:在<a class="ae kv" href="https://drive.google.com/file/d/1oGgVSxDE9OP7TopEXKju8AvUnod6ezHl/view?usp=sharing" rel="noopener ugc nofollow" target="_blank"> google drive </a>上有思维导图的高分辨率图像，因为该图像可能不可读(质量会自动降低)】</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/a905319a30e01ecfab131366ee9089d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kmvey4tku1ur-FpsoYnpVw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f95b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 3。可解释性方法示例</strong></p><p id="7267" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好地理解机器学习的可解释性及其重要性，让我们以一个非常简单、基本的例子来说明著名的可解释性技术之一:沙普利附加解释或简称SHAP。</p><p id="dc4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前，只需要理解“SHAP的目标是通过计算每个特征对预测的贡献来解释实例x的预测”[17]就足够了，所以一般来说，SHAP为每个特征输出一个值，解释其重要性和对实例预测输出的影响。</p><p id="59ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，让我们导入必要的库(这个例子是使用Google Colab实现的)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="9159" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们安装并导入SHAP库</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="b844" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个例子，我已经创建了一个非常简单的工资数据集，这足以满足说明的目的，您可以在这里下载它<a class="ae kv" href="https://drive.google.com/file/d/1yZOle-CJY1AuM0Y10L6KgcJwdSJ3T5Kg/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">，然后使用下一个代码单元格上传它:</a></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="f4e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来的几行将读取数据集文件，并向数据集添加一个性别列(这是为了创建更多的特性，以便我们可以更好地理解这个示例)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="f5e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">拟合模型</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="782b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们建立了模型之后，让我们使用Shapley值来理解和解释我们的模型</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/47bf3864e3dd0c1dc5e2e93bb02432a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*KXV4tkF98BARfW3wScbC3A.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">电池输出</p></figure><p id="f925" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上图我们可以看到，对于例10，对预测工资最有贡献的特征是工作经验的年限，这似乎是合理的，性别不应该影响个人的工资。</p><p id="972b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一个代码单元将输出数据集特征的总体摘要，我们可以注意到，这里的影响特征是年经验。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/552144395b8aa89eb9c3f2304e423189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*v4z55s-9s-oqwpYI4gAllw.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">电池输出</p></figure><h2 id="bd7f" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated"><strong class="ak">建模有偏数据集</strong></h2><p id="fd01" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">为了理解SHAP如何帮助我们检测模型的偏差，我用一个有偏差的假数据集创建了一个简单的例子，该数据集代表简单的贷款批准数据，由两列组成:收入和性别。</p><p id="04e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在该数据集中，贷款批准完全取决于性别，这意味着如果申请人是男性，则贷款获得批准，否则，贷款被拒绝。如果我们拟合模型并仅基于其准确性来衡量它，我们可以认为模型非常好，但如果我们试图解释模型，我们会发现模型对女性申请人有偏见，这个简单的例子是现实世界中实际发生的情况，有许多类似的记录事件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="7c8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">拟合模型</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="93a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解释模型</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/d1cf91f0f95b8ba84cc6dcc12dc02dc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cNxQOs9Ra_3SO0agnAKmjg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">电池输出</p></figure><p id="900e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从上图中我们可以看到，对于10号申请人(女性)，性别特征对贷款审批的影响最大，在这种情况下，负面影响(蓝条)导致贷款未被批准。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/42d66c2e0610ddddccc3ef9b6630a295.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rhsUygC3SEJH4qQtgWSoqA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">电池输出</p></figure><p id="21d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与上述数字形成对比的是，这一数字表明，性别特征对11号申请人(男性)的贷款审批产生了积极影响</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/dab6dd1a72bc026226194e0d304fef6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*i9jUWUxc41ZwhjnL-gETiw.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">电池输出</p></figure><p id="5744" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该图总结了贷款审批数据集的整体特征重要性，从中我们可以得出结论，即使我们的模型在准确性方面表现良好，但在公平性方面却非常糟糕，对女性申请人有严重的偏见，而收入特征对贷款审批流程的最终决策没有影响，正如所述，这是现实世界中发生的问题。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="2540" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated"><strong class="ak"> 4。评估可解释性技术的方法</strong></h2><p id="f000" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">已经发表了许多关于构建解释和解释黑盒机器学习模型的方法的研究文章，其他关于开发内在可解释模型的研究文章，但是已经完成了一些评估和评价可解释性方法质量的研究。</p><p id="6a9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">出于本文的需要，我们将坚持指出，对我们如何评价和评估可解释性方法的质量进行处理和研究是很重要的，迪奥戈·v·卡瓦略等人在他们的文献综述论文[8]中提出了评价可解释性方法的一些框架和公理。(<strong class="ky ir">我强烈推荐阅读这篇论文</strong>)。</p><h2 id="081c" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated"><strong class="ak"> 5。总结和结论</strong></h2><p id="833a" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">本文介绍了机器学习的可解释性、驱动力、公共工作以及关于机器学习的使用和发展的法规的介绍性概述，可解释性分类的总结，使用Shapley值的示例，该示例展示了可解释性方法的重要性，最后是关于评估和评价可解释性技术的重要性的说明。</p><p id="c9e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里要总结的一点是:机器学习的可解释性是机器学习的未来所必须的，它与开发高性能的机器学习模型一样重要，这需要数据科学家、机器学习研究人员和其他在机器学习领域工作的人注意-在开发他们的模型时考虑可解释性和透明性问题。</p><p id="843e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接下来的文章中，我们将进一步理解最近的可解释性方法，这将有助于在开发您的模型时加以考虑。</p><p id="cfeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的阅读，如果您有任何问题、建议和其他疑问，请随时通过<a class="ae kv" href="https://www.linkedin.com/in/salih-eihab/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或电子邮件:salih.eihab1@gmail.com联系我们。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><h2 id="64f0" class="mi mj iq bd mk ml mm dn mn mo mp dp mq lf mr ms mt lj mu mv mw ln mx my mz na bi translated"><strong class="ak"> 6。参考文献:</strong></h2><p id="ed51" class="pw-post-body-paragraph kw kx iq ky b kz nb jr lb lc nc ju le lf nd lh li lj ne ll lm ln nf lp lq lr ij bi translated">[1]《卫报》，特斯拉司机在使用自动驾驶模式时发生首次致命车祸死亡(2016年)，<a class="ae kv" href="https://www.theguardian.com/technology/2016/jun/30/tesla-autopilot-death-self-driving-car-elon-musk" rel="noopener ugc nofollow" target="_blank">https://www . The Guardian . com/technology/2016/jun/30/特斯拉-自动驾驶-死亡-自动驾驶-汽车-埃隆-马斯克</a></p><p id="dbec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]景岛乐·若林，自动驾驶优步汽车在机器人漫游的亚利桑那州撞死行人(2018)，<a class="ae kv" href="https://www.nytimes.com/2018/03/19/technology/uber-driverless-fatality.html" rel="noopener ugc nofollow" target="_blank">https://www . nytimes . com/2018/03/19/technology/Uber-drivers-deadlines . html</a></p><p id="9408" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]泰勒·特尔福德(Taylor Telford)，Apple Card算法引发针对高盛的性别偏见指控(2019)，<a class="ae kv" href="https://www.washingtonpost.com/business/2019/11/11/apple-card-algorithm-sparks-gender-bias-allegations-against-goldman-sachs/" rel="noopener ugc nofollow" target="_blank">https://www . Washington post . com/business/2019/11/11/Apple-Card-algorithm-sparks-gender-bias-consensations-against-Goldman-Sachs/</a></p><p id="38bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4]匿名。(2016)事件编号37。在麦格雷戈，s .(编辑。)人工智能事件数据库。人工智能伙伴关系。2022年1月25日从incidentdatabase.ai/cite/37.取回</p><p id="4dbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5]匿名。(2016)事件编号40。在麦格雷戈，s .(编辑。)人工智能事件数据库。人工智能伙伴关系。2022年1月25日从incidentdatabase.ai/cite/40.取回</p><p id="ae7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6]鲁茨曼。(2019)事件编号124。在麦格雷戈，s .(编辑。)人工智能事件数据库。人工智能伙伴关系。2022年1月25日从incidentdatabase.ai/cite/124.取回</p><p id="4fb8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[7]马特·图雷克博士，可解释的人工智能(XAI)，<a class="ae kv" href="https://www.darpa.mil/program/explainable-artificial-intelligence" rel="noopener ugc nofollow" target="_blank">https://www . DARPA . mil/program/可解释的人工智能</a></p><p id="fa8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[8]卡瓦略、迪奥戈、爱德华多·佩雷拉和海梅·卡多佐。《机器学习可解释性:关于方法和度量的调查》Electronics 8(2019)第8期:832。https://doi.org/10.3390/electronics8080832<a class="ae kv" href="https://doi.org/10.3390/electronics8080832" rel="noopener ugc nofollow" target="_blank"/></p><p id="3020" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[9]欧洲委员会，欧洲议会和理事会关于制定人工智能统一规则(人工智能法)和修正某些联盟法案的条例(2021年)，【https://eur-lex.europa.eu/legal-content/EN/TXT/? T4】qid = 1623335154975&amp;uri = CELEX % 3a 52021 PC 0206</p><p id="dc2f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[10]法国AI战略报告(2018)，<a class="ae kv" href="https://knowledge4policy.ec.europa.eu/ai-watch/france-ai-strategy-report_en" rel="noopener ugc nofollow" target="_blank">https://knowledge 4 policy . EC . Europa . eu/AI-watch/France-AI-Strategy-Report _ en</a></p><p id="3cc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[11]德国AI战略报告(2018)，<a class="ae kv" href="https://knowledge4policy.ec.europa.eu/ai-watch/germany-ai-strategy-report_en" rel="noopener ugc nofollow" target="_blank">https://knowledge 4 policy . EC . Europa . eu/AI-watch/Germany-AI-Strategy-Report _ en</a></p><p id="2198" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[12]葡萄牙AI战略报告(2019)，<a class="ae kv" href="https://knowledge4policy.ec.europa.eu/ai-watch/portugal-ai-strategy-report_en" rel="noopener ugc nofollow" target="_blank">https://knowledge 4 policy . EC . Europa . eu/AI-watch/Portugal-AI-Strategy-Report _ en</a></p><p id="cedc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[13]英国AI战略报告(2018)，<a class="ae kv" href="https://knowledge4policy.ec.europa.eu/ai-watch/united-kingdom-ai-strategy-report_en" rel="noopener ugc nofollow" target="_blank">https://knowledge 4 policy . EC . Europa . eu/AI-watch/United-Kingdom-AI-Strategy-Report _ en</a></p><p id="87eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[14]国家安全委员会人工智能(2021年)，<a class="ae kv" href="https://www.nscai.gov/wp-content/uploads/2021/03/Full-Report-Digital-1.pdf" rel="noopener ugc nofollow" target="_blank">https://www . nscai . gov/WP-content/uploads/2021/03/Full-Report-Digital-1 . pdf</a></p><p id="e775" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[15] COMPAS(软件)，<a class="ae kv" href="https://en.wikipedia.org/wiki/COMPAS_(software)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/COMPAS _(软件)</a></p><p id="0123" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[16]美国国家科学技术委员会技术委员会，为人工智能的未来做准备(2016)，<a class="ae kv" href="https://obamawhitehouse.archives.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf" rel="noopener ugc nofollow" target="_blank">https://obamawhitehouse . archives . gov/sites/default/files/white house _ files/microsites/ostp/NSTC/preparating _ FOR _ THE _ FUTURE _ OF _ ai . pdf</a></p><p id="7fa4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[17] Christoph Molnar，可解释的机器学习，使黑盒模型可解释的指南(2022年)，<a class="ae kv" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/</a></p></div></div>    
</body>
</html>