<html>
<head>
<title>10 AI Models that Have Defined 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">定义2021年的10个人工智能模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-ai-models-that-have-defined-2021-7d804b87b10#2022-01-27">https://towardsdatascience.com/10-ai-models-that-have-defined-2021-7d804b87b10#2022-01-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="dafe" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">定义2021年的10个人工智能模型</h1></div><div class=""><h2 id="7616" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">未来将建立在这些基础上</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/80b40575cad14e271b08d244fee38d60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d43sz3DnKsjxWVlQMhS9Aw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.shutterstock.com/es/g/Kirichay+D" rel="noopener ugc nofollow" target="_blank"> Kirichay D </a>在<a class="ae ky" href="https://www.shutterstock.com/es/image-photo/beautiful-woman-purple-hair-futuristic-costume-1747573019" rel="noopener ugc nofollow" target="_blank"> Shutterstock </a>上拍照</p></figure><p id="cb68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人工智能不断加速。每年我们都会读到大量的新闻，谈论新的人工智能模型，这些模型将彻底改变X行业或将人工智能推向新的高度。但是，信噪比很低。只有一堆令人印象深刻的突破值得铭记。</p><p id="4157" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2021年没有什么不同，这就是为什么我按时间顺序列出了今年最相关和最有影响力的车型。尽管研究和开发的路线多种多样，但有几个明显的趋势:大型语言模型变得更大，未来的顶级模型很可能是多模态的，对效率的追求正在得到有趣的结果。我用一小段描述了每个模型对该领域的主要影响。尽情享受吧！</p><h1 id="03a4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">开关变压器:第一个+1T参数模型</h1><p id="1df8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">影响:</strong>稀疏性支持将模型扩展到巨大的规模，这对于密集架构是不可行的，同时保持计算负担不变。</p><p id="d149" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2021年1月，谷歌发表了论文“<a class="ae ky" href="https://arxiv.org/abs/2101.03961" rel="noopener ugc nofollow" target="_blank">开关变压器:通过简单有效的稀疏性扩展到万亿参数模型</a>他们提出了一种新的语言模型架构，以证明模型可以增长到超过1T参数(开关变压器具有1.7T参数)，同时保持计算成本稳定。</p><p id="72e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了保持较低的计算要求，switch transformer使用了由深度学习先驱Geoffrey Hinton共同发明的<a class="ae ky" href="https://en.wikipedia.org/wiki/Mixture_of_experts" rel="noopener ugc nofollow" target="_blank">专家混合</a>范式的变体。模型的参数被分成2048个专家，使得输入仅由一个专家处理。在任何给定时间，只有一小部分参数是活动的，即稀疏模型。</p><p id="3eb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT-3和大多数其他语言模型是密集的——它们使用整个模型来处理每个输入。通过利用稀疏性，开关变压器降低了计算成本，同时提高了精度和功耗。</p><h1 id="5274" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">一张图片胜过千言万语</h1><p id="f081" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">影响: DALL E利用丰富的自然语言创造出各种各样的图像。这是最早流行的多模式人工智能之一。</p><p id="bf2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OpenAI于2021年2月建造了<a class="ae ky" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> DALL E </a>。该模型以西班牙著名画家萨瓦尔多·达利和可爱的皮克斯机器人瓦力命名，是GPT 3(120亿参数)的小型版本，并在文本-图像对上接受训练，以“通过语言操纵视觉概念”</p><p id="71d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DALL E采用自然语言书写的句子，并使用预期的含义生成图像。它的力量依赖于它的零射击能力；它可以执行没有经过训练的生成任务，而不需要例子。DALL E创造性地利用了语言和图像相结合的可能性——例如，将高层次的概念融合到一幅图像中。用“竖琴做的蜗牛”或“鳄梨形状的扶手椅”来提示它，会给出你所期待的确切的<a class="ae ky" href="https://openai.com/blog/dall-e/#:~:text=navigatedownwide-,Combining%20Unrelated%20Concepts,-The%20compositional%20nature" rel="noopener ugc nofollow" target="_blank">，尽管世界上不存在任何类似的东西。</a></p><p id="6077" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DALL E加入了人工智能画家的行列——谷歌的<a class="ae ky" href="https://deepdreamgenerator.com/" rel="noopener ugc nofollow" target="_blank"> DeepDream </a>、<a class="ae ky" href="https://www.ai-darobot.com/" rel="noopener ugc nofollow" target="_blank"> Ai-Da </a>、<a class="ae ky" href="https://obvious-art.com/" rel="noopener ugc nofollow" target="_blank">显见</a>等等。创造力曾经是我们的专利，但现在不再是了。DALL E已经证明，人工智能更接近于赋予“一张图胜过千言万语”这句话新的含义。</p><h1 id="accb" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">谷歌输入/输出大会:妈妈和LaMDA</h1><p id="6ac3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">影响:类似妈妈的模特会简化在互联网上搜索的过程。LaMDA是创造类似人类的对话式人工智能的最新一步。</p><p id="7ff4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谷歌一年一度的输入输出事件发生在2021年5月。技术高管展示了最新的产品和研究，其中<a class="ae ky" href="https://blog.google/products/search/introducing-mum/" rel="noopener ugc nofollow" target="_blank"> MUM </a>(多任务统一模型)和<a class="ae ky" href="https://blog.google/technology/ai/lamda/" rel="noopener ugc nofollow" target="_blank"> LaMDA </a>被描绘成明星。两种语言模型，没有什么好羡慕流行的GPT-3的。MUM是搜索引擎的未来，而LaMDA是一个能够进行有趣对话的聊天机器人。</p><p id="6ae5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于Transformer架构和以前的系统，如BERT和Meena，谷歌建立了MUM和LaMDA其技术规格仍未披露。但是我们知道一些关于他们的事情。MUM的使命是进一步增强谷歌的搜索引擎——可能会让SEO过时，正如我在之前的一篇文章中所说的。MUM比BERT(谷歌目前支持搜索引擎的力量)强大1000倍，可以处理跨语言、跨任务、最重要的是跨模式的自然语言复杂查询——它理解文本和图像。</p><p id="63a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LaMDA以与人交流为导向。作为一个明智、具体、有趣和实事求是的聊天机器人，LaMDA可以管理开放式对话——正如首席执行官<a class="ae ky" href="https://www.dailymotion.com/video/x81d4rm" rel="noopener ugc nofollow" target="_blank">桑德尔·皮帅在演示中通过让LaMDA扮演冥王星和纸飞机的角色向</a>展示的那样。人类可以从一个句子中创造出一千条独特的路径。我们只需要做出选择，整个世界就会从那里出现。LaMDA更接近于能够做同样的事情。</p><h1 id="1a41" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">中国的语言人工智能市场:悟道2.0，M6</h1><p id="cf9c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">影响力:</strong>这些模型为中国在人工智能研究、开发和效率方面达到第一做出了巨大贡献。</p><p id="dd6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">中国一直在努力在技术开发和研究方面赶上美国，人工智能是一个特别热门的领域。去年有两款车型引起了分析师的关注:<a class="ae ky" rel="noopener" target="_blank" href="/gpt-3-scared-you-meet-wu-dao-2-0-a-monster-of-1-75-trillion-parameters-832cd83db484">武道2.0</a>(1.75吨)和<a class="ae ky" rel="noopener" target="_blank" href="/meet-m6-10-trillion-parameters-at-1-gpt-3s-energy-cost-997092cbe5e8">M6</a>(10吨)。它们基于在性能、计算成本降低和污染减少方面利用稀疏性的承诺。</p><p id="c011" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2021年6月，Wu Dao 2.0害羞地亮相，声称它是有史以来最大的神经网络，规模是GPT-3的10倍。两者的主要区别是吴导的多模态性；作为一个通用的语言模型，它是第一个像DALL E或MUM那样利用多模态的语言。然而，性能方面没有太多的信息，因为北京人工智能研究院(BAAI)没有给出任何结果。(我的猜测是，该模型并没有被训练成收敛，而是作为一个实验来分析专家混合范式的力量)。</p><p id="4434" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由阿里巴巴DAMO学院建设的M6经历了一个阶段性的发展过程。它于6月首次以1T参数作为多模式和多任务模型推出。然后，在2021年底，研究人员发表了一篇文章，概述了一个惊人的结果:在10万亿个参数下，新版本的M6在训练期间消耗的计算成本只有GPT-3的1%——在效率和减少碳足迹方面达到了一个新的里程碑。</p><h1 id="2561" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">微软和英伟达联手:MT-NLG</h1><p id="c3c5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">影响:这是最大的密集语言模型，也是Nvidia和微软合作的第一个潜在的其他发展。</p><p id="400c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">10月，Nvidia <a class="ae ky" href="https://developer.nvidia.com/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/" rel="noopener ugc nofollow" target="_blank">在其博客</a>中发布消息称，他们已经与微软联手打造了(至今)最大的密集语言模型。MT-NLG在530B参数上大于GPT-3、J1-Jumbo和Gopher(尽管明显小于稀疏模型)。在大多数基准测试中，MT-NLG比GPT-3具有更好的性能，直到最近，它仍然是我们拥有数据的顶级语言模型。</p><p id="30b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我把它列入这个名单的另一个原因是Nvidia和微软的联盟。两家大型科技公司都是人工智能领域的佼佼者。英伟达是图形处理器的头号制造商和提供商，微软在云服务和人工智能软件方面有着非常强大的影响力。这种伙伴关系的未来努力将值得关注。</p><h1 id="e00c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">GitHub Copilot:你的互惠生程序员</h1><p id="adf2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><strong class="lb iu">影响:</strong> GitHub Copilot是程序员迈向自动化最枯燥重复任务的第一步。它最终也会成为一种威胁。</p><p id="f5fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GitHub的母公司微软和OpenAI联手创造了<a class="ae ky" rel="noopener" target="_blank" href="/github-copilot-a-new-generation-of-ai-programmers-327e3c7ef3ae"> GitHub Copilot </a>，许多开发者已经在日常工作中使用它。copilot——扩展了GPT-3强大的语言技能，并作为OpenAI编码模型Codex的基础——擅长编程。它可以跨语言工作，可以完成代码行，编写完整的函数，或者将注释转换成代码，还有其他功能。</p><p id="bfe5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一些用户指出由于版权和许可的潜在法律问题。副驾驶从哪里学的？使用它所有的完成是否安全？如果最终触犯了法律，该怪谁？但是不管它的大图限制，它是编码未来的一个重要里程碑。它很可能成为开发人员工具箱中的必备工具。</p><h1 id="a9c7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">DeepMind进入语言AI的入口:地鼠，复古</h1><p id="23f8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">影响: Gopher是目前排名第一的语言模型。复古证明，新技术可以提高效率(降低成本和碳足迹)数量级超过以前的模式。</p><p id="bd4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DeepMind这些年一直保持沉默，而全球的公司都参与了人工智能语言的爆炸。自从谷歌发明了Transformer架构以来，语言人工智能已经成为研究的主要焦点，超过了视觉、游戏和其他领域。作为主要的人工智能公司之一，DeepMind的缺席令人惊讶。</p><p id="2700" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2021年12月，情况发生了变化。DeepMind发表了三篇关于语言AI的论文。首先，他们提出了<a class="ae ky" rel="noopener" target="_blank" href="/deepmind-is-now-the-undisputed-leader-in-language-ai-with-gopher-280b-79363106011f"> Gopher </a>，一个280B参数密集模型，在124个任务中的100个任务中抹杀了能力——包括GPT-3、MT-NLG和J1-Jumbo。一夜之间，DeepMind不仅成为了强化学习的领导者，也成为了语言人工智能的领导者。Gopher现在是有史以来无可争议的最好的语言模型。</p><p id="8446" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第三篇论文更令人印象深刻。在7B参数下，<a class="ae ky" href="https://deepmind.com/research/publications/2021/improving-language-models-by-retrieving-from-trillions-of-tokens" rel="noopener ugc nofollow" target="_blank"> RETRO </a>(检索增强的Transformer)是一个小一点的语言模型。然而，尽管它比GPT-3小25倍，但在各项基准测试中，它的性能不相上下。与GPT-3相比，DeepMind通过该模型实现了10倍的计算成本降低。RETRO使用一种检索机制，允许它实时访问大型数据库，避免模型必须记住所有的训练集。</p><p id="94df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这具有重要的后果。首先，它证明了新技术可以显著提高语言模型的效率。随着成本变得更可承受，这也有利于较小的公司参与进来。最后，它有助于减少人工智能对环境的影响。</p></div><div class="ab cl ms mt hx mu" role="separator"><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx my"/><span class="mv bw bk mw mx"/></div><div class="im in io ip iq"><p id="645d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mz">如果你喜欢这篇文章，可以考虑订阅我的免费周报</em><a class="ae ky" href="https://mindsoftomorrow.ck.page/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="mz"/></strong></a><em class="mz">！每周都有关于人工智能和技术的新闻、研究和见解！</em></p><p id="4bfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mz">您也可以使用我的推荐链接</em> <a class="ae ky" href="https://albertoromgar.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="mz">这里</em> </strong> </a> <em class="mz">直接支持我的工作，成为中级会员，获得无限权限！:)</em></p></div></div>    
</body>
</html>