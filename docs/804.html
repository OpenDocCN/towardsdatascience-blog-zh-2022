<html>
<head>
<title>Neural Network From Scratch In Excel</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Excel中从头开始的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-network-from-scratch-in-excel-4774f6131cdb#2022-01-29">https://towardsdatascience.com/neural-network-from-scratch-in-excel-4774f6131cdb#2022-01-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="5dff" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">Excel中从头开始的神经网络</h1></div><div class=""><h2 id="79b3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为了更好地理解反向传播的工作原理</h2></div><p id="b057" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然使用Excel/Google Sheets来解决机器学习算法的实际问题肯定是一个坏主意，但使用简单的公式和简单的数据集从零开始实现算法对理解算法的工作方式非常有帮助。</p><p id="a506" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我写这些文章是为了解释梯度下降如何用于线性回归和逻辑回归:</p><ul class=""><li id="ff09" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/linear-regression-from-scratch-in-excel-3d8192214752">Excel中带梯度下降的线性回归</a> /Google Sheet</li><li id="5797" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/logistic-regression-with-gradient-descent-in-excel-52a46c46f704">Excel中带梯度下降的逻辑回归</a> /Google Sheet</li></ul><p id="e86d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将分享我如何在Excel中实现一个带有<strong class="kk iu">梯度下降(或反向传播)的<strong class="kk iu">简单</strong> <strong class="kk iu">神经网络</strong>。</strong></p><p id="177d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你不熟悉神经网络的原理，我写了<a class="ae ln" rel="noopener" target="_blank" href="/intuitively-how-do-neural-networks-work-d7710b602e51">这篇文章</a>用非常直观的方式来解释。而如果想从头开始用python实现，我也写了<a class="ae ln" rel="noopener" target="_blank" href="/visualize-how-a-neural-network-works-from-scratch-3c04918a278">这篇文章</a>。</p><p id="4d95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以在这篇文章中，你不需要了解python或者其他编程语言，所以你没有借口！您可以使用此链接查看所有不同的计算。</p><p id="7d50" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们把手弄脏吧！</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi lt"><img src="../Images/62d886842f8671de4b00591b9cd7e5b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hbCXxicafAe3b5wb"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">杰里米·毕晓普在<a class="ae ln" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="06c4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">从零开始为ML的谷歌表</h1><p id="3940" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">如果你想得到谷歌表，请在Ko-fi上支持我。</p><p id="7415" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以得到我创建的所有谷歌表单(梯度下降的线性回归，逻辑回归，神经网络，KNN，k-means，等等)。)和下面的链接。</p><p id="2726" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae ln" href="https://ko-fi.com/s/4ddca6dff1" rel="noopener ugc nofollow" target="_blank">https://ko-fi.com/s/4ddca6dff1</a></p><h1 id="2c2c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">一个简单的神经网络</h1><h2 id="2865" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">数据集</h2><p id="c003" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">首先，我使用一个非常简单的数据集，只有一个特征x，目标变量y是二进制的。你可以看到下图。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ns"><img src="../Images/124c6be2f11d402db6b7b11f6e6bc639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aq1LBslhSjztUEA4yJRKfg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">数据集(作者提供的图片)</p></figure><h2 id="e1ee" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">神经网络</h2><p id="6ecb" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">数据是<strong class="kk iu">不可线性分离的</strong>。所以逻辑回归是不够的。如果你看过我这篇关于<a class="ae ln" rel="noopener" target="_blank" href="/neural-network-why-deeper-isnt-always-better-2f862f40e2c4">构建神经网络应该选择多少层</a>的文章，你应该知道，对于这个数据集来说，<strong class="kk iu">一个隐层两个神经元</strong>就够了。这里我们将使用sigmoid函数作为激活函数。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nt"><img src="../Images/00a6cf3e7e3fc2078999dae3efb61084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4TIdEwwYLj4DoFw4Xt3A1g.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">神经网络(图片作者提供)</p></figure><p id="d1ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，神经网络是一个数学函数，这里是与上图相关的函数。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nu"><img src="../Images/f3cbb8ef6392b2af7d5b3d6773b62048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pGUc_lCtn3RpSng6cYDWbw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">神经网络数学函数(图片由作者提供)</p></figure><p id="db33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如你所见，带有圆圈和链接的神经网络图更清晰地显示了所有系数。</p><h2 id="db8c" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">功能的实现</h2><p id="9eae" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated"><strong class="kk iu">在Excel/Google工作表的工作表m </strong>(针对模型)中，我使用以下系数值实现了该函数。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nv"><img src="../Images/78548b18bf2842d08bbe1a481ded3289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D4JAIhmkStA5GYvwj0uWYA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">为神经网络选择的系数(图片由作者提供)</p></figure><p id="0bac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如你所知，如果你读了<a class="ae ln" rel="noopener" target="_blank" href="/visualize-how-a-neural-network-works-from-scratch-3c04918a278">这篇关于成本函数的文章</a>，就会发现有多个全局最小值。这些只是这些系数的一组令人满意的值。</p><p id="1670" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了简化公式，我显示了中间结果(隐藏层)A1和A2。那么输出的最终结果就是这两者的组合。你可以看到这个神经网络可以完美地将数据集分成两类。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nw"><img src="../Images/75750f007577f385d6ac6d628d8c957f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7hkgVhhrscKpaFFqCWAEQg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">神经网络图(图片作者提供)</p></figure><p id="5431" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，您可以更改系数值，看看不同函数的图形会如何变化。</p><p id="ab6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是容易的部分。现在的问题是:如何找到这些系数的值？我们来做反向传播部分。</p><h1 id="6cce" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">梯度下降</h1><p id="48d8" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated"><strong class="kk iu">在工作表gd </strong>(针对梯度下降)，你可以找到所有的计算细节。</p><h2 id="d808" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">输入</h2><p id="79ba" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">首先，我们有输入数据:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nx"><img src="../Images/14e053de3bb1a3d452aa1776b263ec4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2e0Zc0QSYydZPXZLcEfPA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">输入数据(图片由作者提供)</p></figure><p id="fb24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">和系数的初始值。所以你可以改变这些值来玩梯度下降。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ny"><img src="../Images/b6de934397844e0d89081f3b3d3d1a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zJaK02EjkKJlF8zOvhYlEg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">系数的初始值(图片由作者提供)</p></figure><h2 id="9372" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">正向传播</h2><p id="530e" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于从AG到BP的列，我们有正向传播阶段。我们首先计算A1和A2，然后是输出。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nz"><img src="../Images/cb6949007bfcf0696aff5e7bcf472977.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0DgRqe8LvSxId_c7OGiYMg.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">正向传播(图片由作者提供)</p></figure><h2 id="f5d6" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">价值函数</h2><p id="e7d5" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于从BQ到CN的列，我们计算误差和成本函数。我们尽量详细地做所有的计算，这样我们可以避免错误。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oa"><img src="../Images/7dc4223e0c5e2b45eafe4268fa5ae496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV96kzXZbsKbkvJMmPZI6Q.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">误差和成本函数(图片由作者提供)</p></figure><p id="d773" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回想一下，有一个成本函数:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ob"><img src="../Images/0c7f118115e35285c1cc5188adb98048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LcQpK3SUj3fedwW8.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">成本函数(图片由作者提供)</p></figure><h2 id="efd8" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">反向传播</h2><p id="26ee" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">在<a class="ae ln" rel="noopener" target="_blank" href="/visualize-how-a-neural-network-works-from-scratch-3c04918a278">这篇文章</a>里，我写了所有的公式。如果不知道结果从何而来就能拥有很多。</p><p id="e5ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于从c0到D1的列，有a11和a12的偏导数:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oc"><img src="../Images/8df21ca4cfd046a0ae91fa734f45b11b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rN3BrkZuQS8MubNF5QQz2Q.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="ea30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在从DM到EJ的列中，有b11和b12的偏导数:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi od"><img src="../Images/8f0af88737e3d1dac686062ac72636cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9xPkuXEuVVsvlIwYyyQNBA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="2aee" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在从EK到FH的列中，有a21和a22的偏导数:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oe"><img src="../Images/badea36895b66c8f3541cb097e404262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rznRbSODuhj8QYN_FrdXcA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="8fc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在从f1到FT的列中，有b2的偏导数:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi of"><img src="../Images/25f488f304825a1bfef957ed75306e3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OIl4LTF-8bjy_NSjnlsmTA.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="488d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们对所有12个观测值的偏导数求和，列从Z到FI。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi og"><img src="../Images/9d2b0190847de285e7390ecc02765fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twbJIpkqvQfg3nbn4jn9og.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><h2 id="df5b" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">梯度下降</h2><p id="84df" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">这些偏导数将允许我们对从R到x的列中的每个系数进行梯度下降。您可以通过上图直观地看到下降阶段的值是如何变化的。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oh"><img src="../Images/e03d35178095d0694a79cd076efdb978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f-fdYCenvLMkeVvVhHpWfw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="8688" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下降过程中，成本函数下降，所以我们也可以将其可视化。我在y列计算。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/08de0429c02790714e269dad1c1be21e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*UyrLSg44DYQTK8lTBJNiKQ.png"/></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="7940" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每组系数值，我们可以将神经网络的输出可视化。我使用表mh(模型隐藏)来创建下图:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oj"><img src="../Images/4e787af7da00f9dc450385343a39526b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t1zftipj9W7W0fcaBM8yjw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><p id="bc90" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当然，我们可以通过连续组合不同系数值的图表来创建一个漂亮的gif。但是手工用Excel输出会很繁琐。这是我用r创建的gif。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ok"><img src="../Images/d083bd48c0dd47964e32439dfa78c0a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a7KCF87E1C_B2qIg.gif"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">作者图片</p></figure><h2 id="d409" class="ng mk it bd ml nh ni dn mp nj nk dp mt kr nl nm mv kv nn no mx kz np nq mz nr bi translated">结论</h2><p id="96ff" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">如您所见，对于12个观测值的数据集，我们可以在Excel中实现梯度下降。通过300次迭代，步长为0.1，以及一些精心选择的初始值，我们可以创建一些很好的梯度下降可视化，以及一组令人满意的待确定的7个系数的值。</p><h1 id="9e10" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">玩Google Sheet！</h1><p id="76d3" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">您可以更改一些值并可视化所有中间结果:</p><ul class=""><li id="7191" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">数据集</li><li id="52a9" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">初始值</li><li id="e731" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">梯度下降的步骤</li></ul><p id="0190" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当测试系数的初始值时，您可以看到，神经网络有时会陷入局部最小值</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ol"><img src="../Images/076aae39882f2b63afc05775864b94b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-3mOcke9HWYAwzgugVSrlw.png"/></div></div><p class="mf mg gj gh gi mh mi bd b be z dk translated">局部最小神经网络(图片由作者提供)</p></figure></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="6a5d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">神经网络是一种有监督的机器学习算法。你想有一个<strong class="kk iu">监督机器学习算法</strong>的完整概述吗？那么你应该看看这篇文章:</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/overview-of-supervised-machine-learning-algorithms-a5107d036296"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">监督机器学习算法综述</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">大图如何通过连接点给我们洞察力和对ML的更好理解</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk md ow"/></div></div></a></div></div></div>    
</body>
</html>