<html>
<head>
<title>Speed up EfficientNet training on AWS with SageMaker Distributed Data Parallel Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SageMaker分布式数据并行库加快AWS的高效网络培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speed-up-efficientnet-training-on-aws-by-up-to-30-with-sagemaker-distributed-data-parallel-library-2dbf6d1e18e8#2022-01-12">https://towardsdatascience.com/speed-up-efficientnet-training-on-aws-by-up-to-30-with-sagemaker-distributed-data-parallel-library-2dbf6d1e18e8#2022-01-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2b52" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""><h1 id="c0a6" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">使用SageMaker分布式数据并行库加快AWS的高效网络培训</h1></div><div class=""><h2 id="05b1" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">深入探讨SageMaker分布式数据并行如何帮助将最先进的EfficientNet模型的训练速度提高30%</h2></div><p id="4eec" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">卷积神经网络(CNN)现在广泛用于执行计算机视觉任务。自动驾驶汽车、安全系统和医疗保健等领域正朝着在应用工作流中采用CNN的方向发展。这些用例通常需要高精度模型，根据部署位置的不同，计算要求也有所不同，例如，基于边缘的安全系统可用的计算基础设施与基于云的医疗成像系统非常不同。</p><p id="3831" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，训练机器学习模型并将其集成到应用程序中可能会很麻烦，这就是为什么我们在AWS开发了<a class="ae lk" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker </a>，这是一个完全管理的端到端机器学习(ML)平台。SageMaker提供工具并管理基础设施；因此，ML科学家和开发人员可以专注于模型开发。你可以仔细阅读<a class="ae lk" href="https://github.com/aws/amazon-sagemaker-examples" rel="noopener ugc nofollow" target="_blank"> SageMaker示例GitHub知识库</a>，深入了解SageMaker如何简化你的机器学习管道。</p><p id="6c98" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">SageMaker还允许您通过在多个GPU上分配训练来更快地训练模型。为了帮助您更快更便宜地训练您的模型，我们在AWS的团队开发了<a class="ae lk" href="https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja"> SageMaker分布式数据并行(SMDDP) </strong> </a>库，以实现<em class="ll">接近线性的缩放效率</em>和<em class="ll">最少的代码更改</em>。SMDDP通过利用AWS的专业网络基础设施和Amazon EC2拓扑信息来执行优化的节点间通信，以加快您的分布式培训工作量。我们已经发表了<a class="ae lk" href="https://www.amazon.science/publications/herring-rethinking-the-parameter-server-at-scale-for-the-cloud" rel="noopener ugc nofollow" target="_blank">一篇论文</a>来描述SMDDP的内部设计和背后的科学原理，供您参考。</p><p id="9bbf" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这篇文章中，你将看到与<a class="ae lk" href="https://horovod.ai/" rel="noopener ugc nofollow" target="_blank"> Horovod </a>相比，SMDDP如何帮助你在EfficientNet的训练中获得高达30%的速度，efficient net是一种用于计算机视觉任务的最先进的模型。我们将首先对EfficientNet和SMDDP进行概述，然后我们将一步一步地指导您如何修改现有的EfficientNet代码，这些代码使用带有TensorFlow 的<a class="ae lk" rel="noopener" target="_blank" href="/distributed-deep-learning-with-horovod-2d1eea004cb2"> Horovod来替代使用SMDDP。最后，我们将通过查看一些性能测量来帮助您了解SMDDP的优势。到本帖结束，你应该能使用SMDDP加快自己模型的训练速度了！</a></p><h1 id="bb12" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">EfficientNet概述</h1><p id="4876" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">卷积神经网络的一个关键挑战是扩展网络，即增加模型参数的数量以获得更高的精度。扩展CNN的常用策略是开发具有更高层数的更深模型。事实上，多年来，<a class="ae lk" href="https://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet大规模视觉识别挑战赛(ILSVRC) </a>的获奖作品毫不奇怪地采用了更深层次的CNN，AlexNet在2012年使用了8层，ResNet在2015年使用了152层。</p><p id="b70a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，以这种方式放大CNN是乏味的，需要大量的微调和实验来达到具有所需精度和资源要求的网络。谷歌的研究人员在他们的<a class="ae lk" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> ICML的论文</a>中解决了这个问题，他们开发了一种放大CNN的原则性方法，他们称之为<em class="ll">复合缩放</em>。复合扩展的关键在于神经网络可以在三个维度上扩展</p><ol class=""><li id="81ce" class="mj mk iq kq b kr ks ku kv kx ml lb mm lf mn lj mo mp mq mr bi translated">深度:增加网络的层数，这是ResNets中使用的主要缩放方法。</li><li id="4f0f" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">宽度:增加单层中神经元的数量，或者更具体地说，增加卷积层中使用的滤波器的数量。</li><li id="cfca" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">分辨率:增加输入图像的宽度和高度。</li></ol><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi mx"><img src="../Images/dd48772d9f55658b36f09bab21f3b85c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olsH8Z_pURIJRKhos2838A.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">EfficientNet模型中使用的复合缩放。图片来自<a class="ae lk" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNet:反思卷积神经网络的模型缩放，ICML 2019</a></p></figure><p id="439e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">复合缩放本质上是以一个恒定的比率沿着上述三个维度均匀地缩放网络，作者称之为<em class="ll">复合系数ɸ.</em>通过使用更大的复合系数，可以生成更精确且计算成本更高的模型。</p><p id="c161" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">虽然作者表明复合扩展可以普遍应用于任何基线网络架构，但复合扩展的效率受到基线网络架构选择的严重影响。为此，作者利用<a class="ae lk" rel="noopener" target="_blank" href="/neural-architecture-search-nas-the-future-of-deep-learning-c99356351136">神经架构搜索</a>构建了一个最优网络架构<em class="ll"> EfficientNet-B0 </em>。该基线网络的主要构建模块是MobileNetv2 中使用的<a class="ae lk" rel="noopener" target="_blank" href="/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c">移动反向瓶颈模块。EfficientNet-B0在只有530万个参数的ImageNet上实现了77.1%的准确率。相比之下，ResNet-50提供了76%的准确性，但使用了5倍数量的参数。这使得EfficientNet成为自动驾驶汽车和安全系统等需要较低计算开销和高精度的系统的首选。此外，可以使用复合缩放来缩放EfficientNet以获得更高的精度，从而产生EfficientNet-B1至EfficientNet-B7，该整数位于名称的末尾，表示复合系数ɸ <em class="ll">。</em>你可以在这篇</a><a class="ae lk" rel="noopener" target="_blank" href="/efficientnet-scaling-of-convolutional-neural-networks-done-right-3fde32aef8ff">详细博客</a>中读到更多关于EfficientNet的技术细节。</p><h1 id="91a7" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">分布式数据并行训练和SMDDP</h1><p id="ea47" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">这些年来，可用于训练模型的训练数据量一直在增长，并且将来还会继续增长。例如，在这篇文章中，我们使用ImageNet数据集训练EfficientNet，该数据集有超过一百万个训练图像。根据我们与AWS客户合作的经验，训练数据的大小可能会大得多，因为训练作业通常会使用超过1000万到1500万张训练图像！有了如此大的训练数据，在单个GPU上运行单个时期(整个训练数据集的一个完整周期)的训练的时间增加了，使得训练非常长，并且不符合业务需求。</p><p id="338d" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">人们可以通过使用多个GPU并利用一种称为<em class="ll">数据并行</em>的技术来减少训练时间。数据并行工作流程如下-</p><ol class=""><li id="6f85" class="mj mk iq kq b kr ks ku kv kx ml lb mm lf mn lj mo mp mq mr bi translated">驻留在每个GPU上的工作者进程具有其自己的模型副本，并且训练数据在工作者之间被分割。</li><li id="6b82" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">对于每个工人，我们在相应的训练数据片段上运行一次迭代训练，并使用<a class="ae lk" rel="noopener" target="_blank" href="/understanding-backpropagation-algorithm-7bb3aa2f95fd">反向传播算法</a>计算梯度。</li><li id="5644" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">在每次迭代结束时，所有工人使用<a class="ae lk" rel="noopener" target="_blank" href="/visual-intuition-on-ring-allreduce-for-distributed-deep-learning-d1f34b4911da"> AllReduce算法</a>交换本地计算的梯度，并计算全局平均梯度，然后用于更新模型的本地副本。</li></ol><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nn"><img src="../Images/6917a765178f8ad337579913303cc233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1N3FSeS8tTsGzN9f1Db7qw.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">AWS上的数据并行分布式深度学习。照片摘自AWS文档<a class="ae lk" href="https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-intro.html" rel="noopener ugc nofollow" target="_blank">sage maker分布式数据并行库介绍</a></p></figure><p id="109a" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在分布式培训中，我们上面看到的所有减少步骤都涉及到通过网络在工人之间进行梯度交流。对于像EfficientNet这样拥有超过一百万个参数的先进模型，通过网络交换梯度会导致大量的通信开销，因为大型模型梯度会在实例之间争夺有限的网络带宽。除了降低训练速度之外，通信开销还限制了分布式数据并行训练的可扩展性。</p><p id="1fd6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">理想情况下，难道我们不都喜欢线性<em class="ll">缩放效率，</em>其中训练速度与用于训练的GPU数量成比例地提高！通信开销成为实现线性扩展效率的障碍，并导致昂贵的GPU资源未得到充分利用。</p><p id="92c8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们在AWS的团队已经认识到这个关键问题，并开发了SageMaker分布式数据并行库(SMDDP)来提供接近线性的扩展效率，以最少的代码更改实现更快的训练速度。该库利用AWS基础设施，如<a class="ae lk" href="https://aws.amazon.com/hpc/efa/" rel="noopener ugc nofollow" target="_blank">弹性纤维适配器</a> (EFA)和亚马逊EC2拓扑信息来实现定制的优化AllReduce算法。SMDDP还使用CPU而不是GPU(其他通信库，如<a class="ae lk" href="https://developer.nvidia.com/nccl" rel="noopener ugc nofollow" target="_blank"> NCCL </a>只使用GPU)来执行AllReduce，提供更多的GPU周期来计算梯度。这允许反向传递和梯度传递之间有更大程度的重叠，从而减少训练时间。要深入了解定制AllReduce算法，请参考我们关于SageMaker分布式数据并行性的<a class="ae lk" href="https://www.amazon.science/publications/herring-rethinking-the-parameter-server-at-scale-for-the-cloud" rel="noopener ugc nofollow" target="_blank">出版物</a>。</p><h1 id="3ed2" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">使用SMDDP培训效率网络</h1><p id="61b5" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">在这篇博文中，我们将派生出NVIDIA 提供的EfficientNet的<a class="ae lk" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow2/Classification/ConvNets/efficientnet" rel="noopener ugc nofollow" target="_blank">多GPU实现，该实现使用Horovod和TensorFlow。在此基础上，我们将需要对</a><a class="ae lk" href="https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel-modify-sdp-tf2.html" rel="noopener ugc nofollow" target="_blank">进行微小的代码更改，利用AWS SMDDP库</a>而不是Horovod。SMDDP有一个类似于Horovod的API规范。这使得熟悉<a class="ae lk" href="https://horovod.readthedocs.io/en/stable/summary_include.html" rel="noopener ugc nofollow" target="_blank">Horovod API</a>的用户可以直接采用horo VOD培训脚本来使用SMDDP。为了您的方便，我们已经在我们的<a class="ae lk" href="https://github.com/HerringForks/SMDDP-Examples/tree/main/tensorflow/efficientnet" rel="noopener ugc nofollow" target="_blank"> SMDDP-Examples GitHub资源库</a>中发布了完整的培训脚本。下面，我们将带您大致了解所需的主要变化。</p><ol class=""><li id="b8a1" class="mj mk iq kq b kr ks ku kv kx ml lb mm lf mn lj mo mp mq mr bi translated">导入SMDDP的TensorFlow客户端而不是Horovod的TensorFlow客户端并初始化。</li></ol><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="ce47" class="nt ln iq np b gy nu nv l nw nx"># Import SMDDP client instead of Horovod's TensorFlow client<br/># import horovod.tensorflow as hvd<br/>import smdistributed.dataparallel.tensorflow as sdp</span><span id="cd20" class="nt ln iq np b gy ny nv l nw nx"># Initialize the SMDDP client instead of Horovod client<br/># hvd.init()<br/>sdp.init()</span></pre><p id="369f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">2.EfficientNet培训脚本使用Horovod提供的<code class="fe nz oa ob np b">rank()</code> API来获取worker的全局等级(逻辑全局进程号)。对数据集进行分片、对模型进行检查点操作以及记录性能指标的一些操作都需要这样做。下面是一个例子。</p><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="fb3e" class="nt ln iq np b gy nu nv l nw nx"># Checkpoint only on rank 0<br/># Replace hvd.rank() calls with sdp.rank() as illustrated below<br/># if model_checkpoint and hvd.rank() == 0:<br/>if model_checkpoint and sdp.rank() == 0:<br/>  ckpt_full_path = os.path.join(model_dir, 'model.ckpt-{epoch:04d}')<br/>  callbacks.append(tf.keras.callbacks.ModelCheckpoint(<br/>      ckpt_full_path, save_weights_only=True, verbose=1,<br/>      save_freq=save_checkpoint_freq))</span></pre><p id="da12" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">3.将优化器包装在SMDDP <code class="fe nz oa ob np b">DistributedOptimizer</code>类中，而不是Horovod <code class="fe nz oa ob np b">DistributedOptimizer</code>类中。</p><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="2244" class="nt ln iq np b gy nu nv l nw nx"># Replace Horovod's DistributedOptimizer class with SMDDP's DistributedOptimizer<br/># optimizer = hvd.DistributedOptimizer(optimizer,<br/>                  compression=hvd.Compression.fp16)<br/>optimizer = sdp.keras.DistributedOptimizer(optimizer,<br/>                compression=sdp.Compression.fp16)</span></pre><p id="a3a8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">4.训练脚本使用<a class="ae lk" href="https://keras.io/api/callbacks/" rel="noopener ugc nofollow" target="_blank"> Keras回调</a>将来自领导者等级(等级<code class="fe nz oa ob np b">0</code>)的初始模型变量传播给所有其他工作人员。用SMDDP的回调API替换Horovod的回调API。</p><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="9e24" class="nt ln iq np b gy nu nv l nw nx"># Replace Horovod's BroadcastGlobalVariablesCallback callback with<br/># SMDDP provided BroadcastGlobalVariablesCallback callback<br/># callbacks=[hvd.callbacks.BroadcastGlobalVariablesCallback(0)]<br/>callbacks=[sdp.keras.callbacks.BroadcastGlobalVariablesCallback(0)]</span></pre><p id="c03f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">5.训练脚本使用<code class="fe nz oa ob np b">allreduce()</code>调用，特别是在验证阶段，来分发训练好的模型评估，并收集统计数据，如准确性。用SMDDP的<code class="fe nz oa ob np b">oob_allreduce()</code>(带外AllReduce)调用替换Horovod的<code class="fe nz oa ob np b">allreduce()</code>调用。注意，SMDDP同时提供了<code class="fe nz oa ob np b">allreduce()</code>和<code class="fe nz oa ob np b">oob_allreduce()</code>API。<code class="fe nz oa ob np b">allreduce()</code> API必须仅用于梯度张量。对于统计等非梯度张量，使用<code class="fe nz oa ob np b">oob_allreduce()</code> API。</p><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="e650" class="nt ln iq np b gy nu nv l nw nx"># Replace Horovod's allreduce() call with SMDDP's oob_allreduce() call.<br/># SMDDP's oob_allreduce() does an average reduce operation by default.<br/># stats['training_accuracy_top_1'] = float(hvd.allreduce(tf.constant(<br/># train_hist['categorical_accuracy'][-1], dtype=tf.float32),<br/>    average=True))<br/>stats['training_accuracy_top_1'] = float(sdp.oob_allreduce(tf.constant(<br/>  train_hist['categorical_accuracy'][-1], dtype=tf.float32))</span></pre><h1 id="29ed" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">在SageMaker上使用SMDDP训练EfficientNet</h1><p id="5fa0" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">现在我们已经修改了EfficientNet培训脚本以使用SMDDP，接下来我们继续在Amazon SageMaker上培训EfficientNet。为了您的方便，我们开发了一个详细的<a class="ae lk" href="https://github.com/aws/amazon-sagemaker-examples/tree/master/training/distributed_training/tensorflow/data_parallel/efficientnet" rel="noopener ugc nofollow" target="_blank">示例笔记本</a>,带您完成SageMaker上培训EfficientNet的整个过程。我们建议启动一个<a class="ae lk" href="https://docs.aws.amazon.com/sagemaker/latest/dg/nbi.html" rel="noopener ugc nofollow" target="_blank"> SageMaker笔记本实例</a>来运行示例笔记本，而无需做任何设置。以下是一些最重要步骤的概述。</p><ol class=""><li id="ea43" class="mj mk iq kq b kr ks ku kv kx ml lb mm lf mn lj mo mp mq mr bi translated">准备ImageNet数据集作为<a class="ae lk" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecords </a>的集合。TFRecords是包含定型数据的二进制记录序列。它使用Google的<a class="ae lk" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank">协议缓冲区</a>格式进行序列化。您可以按照<a class="ae lk" href="https://github.com/kmonachopoulos/ImageNet-to-TFrecord" rel="noopener ugc nofollow" target="_blank">步骤下载ImageNet数据集并将其转换为TFRecords格式</a>，然后将其上传到<a class="ae lk" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊S3 </a>桶。对于像ImageNet这样的大型数据集，我们建议使用<a class="ae lk" href="https://aws.amazon.com/fsx/" rel="noopener ugc nofollow" target="_blank"> Amazon FSx </a>作为您的文件系统。FSx文件系统大大减少了SageMaker上的培训启动时间，因为它避免了每次启动培训作业时下载培训数据(就像SageMaker培训作业的S3输入一样)。FSx还提供了更好的数据I/O吞吐量。示例笔记本包含创建FSx的步骤，该FSx与保存ImageNet TFRecords的S3存储桶相关联。</li><li id="95dd" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">默认情况下，SageMaker使用最新的<a class="ae lk" href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md" rel="noopener ugc nofollow" target="_blank">亚马逊深度学习容器(DLC) </a>图像进行训练。示例笔记本有一个<a class="ae lk" href="https://github.com/aws/amazon-sagemaker-examples/blob/master/training/distributed_training/tensorflow/data_parallel/efficientnet/build_and_push.sh" rel="noopener ugc nofollow" target="_blank">脚本</a>，它使用TensorFlow 2.6的DLC作为基础映像，安装基于<a class="ae lk" href="https://developer.nvidia.com/ai-hpc-containers" rel="noopener ugc nofollow" target="_blank">英伟达NGC容器</a>训练EfficientNet模型所需的<a class="ae lk" href="https://github.com/NVIDIA/DeepLearningExamples/blob/master/TensorFlow2/Classification/ConvNets/efficientnet/requirements.txt" rel="noopener ugc nofollow" target="_blank">附加依赖项</a>，并将定制的Docker容器推送到<a class="ae lk" href="https://aws.amazon.com/ecr/" rel="noopener ugc nofollow" target="_blank">亚马逊ECR </a>。使用自定义Docker容器的图像URI，您可以在下一步中构造一个SageMaker估计器。</li><li id="20ba" class="mj mk iq kq b kr ms ku mt kx mu lb mv lf mw lj mo mp mq mr bi translated">使用<a class="ae lk" href="https://sagemaker.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> SageMaker Python SDK </a>提供的SageMaker估计器类来启动一个训练任务。estimator类允许您配置参数来指定要使用的Docker映像、实例的数量和类型以及超参数。参见以下设置SageMaker TensorFlow估算器的示例。</li></ol><pre class="my mz na nb gt no np nq nr aw ns bi"><span id="d143" class="nt ln iq np b gy nu nv l nw nx">import sagemaker<br/>from sagemaker import get_execution_role<br/>from sagemaker.estimator import Estimator<br/>import boto3</span><span id="fd45" class="nt ln iq np b gy ny nv l nw nx">sagemaker_session = sagemaker.Session()</span><span id="fdcb" class="nt ln iq np b gy ny nv l nw nx"># Configure the hyper-parameters<br/>hyperparameters = {<br/>    "mode": "train",<br/>    "arch": "efficientnet-b4",<br/>    "use_amp": "",<br/>    "use_xla": "",<br/>    "max_epochs": 5,<br/>    "train_batch_size": 64,<br/>    "lr_init": 0.005,<br/>    "batch_norm": "syncbn",<br/>    "mixup_alpha": 0.2,<br/>    "weight_decay": 5e-6<br/>}<br/>    <br/>estimator = TensorFlow(<br/>    entry_point="main.py",<br/>    role=role,<br/>    image_uri=docker_image, # name of docker image uploaded to ECR<br/>    source_dir="./tensorflow/efficientnet",<br/>    instance_count=2, # number of instances<br/>    instance_type="ml.p4d.24xlarge", <br/>    # Other supported instance types: ml.p3.16xlarge, ml.p3dn.24xlarge<br/>    framework_version="2.6", # TensorFlow 2.6<br/>    py_version="py38",<br/>    sagemaker_session=sagemaker_session,<br/>    hyperparameters=hyperparameters,<br/>    subnets=["&lt;SUBNET_ID&gt;"],<br/>    # Should be same as Subnet used for FSx. Example: subnet-0f9XXXX<br/>    security_group_ids=["&lt;SECURITY_GROUP_ID&gt;"],<br/>    # Should be same as Security group used for FSx. sg-03ZZZZZZ<br/>    debugger_hook_config=False,<br/>    # Training using SMDataParallel Distributed Training Framework<br/>    distribution={"smdistributed": {"dataparallel": {"enabled": True}}},<br/>)</span><span id="e91c" class="nt ln iq np b gy ny nv l nw nx"># Submit SageMaker training job<br/># data_channels is the FSx input<br/>estimator.fit(inputs=data_channels, job_name=job_name)</span></pre><h1 id="895f" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">性能比较</h1><p id="cc39" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">我们比较了SMDDP和Horovod在SageMaker上训练效率网的性能。我们使用多个<a class="ae lk" href="https://aws.amazon.com/ec2/instance-types/p4/" rel="noopener ugc nofollow" target="_blank"> ml.p4d.24xlarge实例</a>进行训练。每个ml.p4d.24xlarge实例配有8个NVIDIA A100 GPUs，并具有400 Gbps实例网络，支持EFA和<a class="ae lk" href="https://docs.nvidia.com/cuda/gpudirect-rdma/index.html" rel="noopener ugc nofollow" target="_blank"> GPUDirect RDMA </a>(远程直接内存访问)。我们根据NVIDIA DeepLearningExamples存储库中提供的<a class="ae lk" href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow2/Classification/ConvNets/efficientnet/scripts" rel="noopener ugc nofollow" target="_blank">脚本选择训练超参数，如批量大小和时期数。注意，使用Horovod和SMDDP对相同数量的历元进行训练将产生相同的参数集，因为库仅编排梯度的通信。我们展示了以下两种EfficientNet变体的性能结果:具有530万个参数的efficent net-B0和具有1900万个参数的efficent net-B4。</a></p><p id="7a49" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">NVIDIA A100 GPUs支持用<a class="ae lk" href="https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html" rel="noopener ugc nofollow" target="_blank">自动混合精度</a> (AMP)训练。SMDDP支持开箱即用的放大器，当FP16中产生梯度时，SMDDP会在FP16模式下自动降低梯度。当使用AMP训练EfficientNet-B0时，我们可以观察到，与Horovod相比，SMDDP提供了高达25%的性能提升。当使用8 ml.p4d.24xlarge实例时，Horovod的缩放效率下降到94%，而SMDDP能够保持97%以上的缩放效率。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oc"><img src="../Images/91375dd04875832252efb9a296bafb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G9C8QS_75tnhIKBNnYkjbw.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">SMDDP与Horovod for EfficientNet-B0的性能比较。图片作者。</p></figure><p id="860c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">当<a class="ae lk" href="https://www.tensorflow.org/xla" rel="noopener ugc nofollow" target="_blank"> XLA(加速线性代数)</a>用于训练EfficientNet-B0时，我们注意到SMDDP相对于Horovod的性能收益下降到7%左右。Horovod和SMDDP等数据并行库使用的一个关键设计方面是使用反向传播将生成梯度的通信与梯度的计算重叠。实际上，这隐藏了高通信开销并提高了性能。由于XLA融合了GPU内核来优化性能，数据并行训练的一个意想不到的后果是，它减少了重叠计算和通信的机会。我们建议ML科学家和开发人员在使用和不使用XLA编译的情况下评估训练性能，以确定特定模型的最佳选择。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi od"><img src="../Images/eb082b9020a98e0e440de67390f8fdbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*Y9AH7f2j6kwOyAIE4acCKg.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">SMDDP与Horovod for EfficientNet-B0的性能比较与XLA一起训练。图片作者。</p></figure><p id="1a99" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们观察到使用含SMDDP的EfficientNet-B4的类似结果，其性能比Horovod高约16%,并且具有更好的扩展效率。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oc"><img src="../Images/371befc2c2daebd1ad185c5677fcc7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9VY8uDb8c9mTZft_3tvRA.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">SMDDP与Horovod for EfficientNet-B4的性能比较。图片作者。</p></figure><p id="dcd8" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然而，当XLA用于训练EfficientNet-B4时，SMDDP的性能收益比Horovod提高了近30%。</p><figure class="my mz na nb gt nc gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi oe"><img src="../Images/952154ac25b644e957eb903ddbd5766f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kXcluscM_7TCeRZqVVy3xQ.png"/></div></div><p class="nj nk gj gh gi nl nm bd b be z dk translated">SMDDP与Horovod for EfficientNet-B4的性能比较与XLA一起训练。图片作者。</p></figure><p id="66c7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">结果表明，与Horovod相比，SMDDP可以实现高达30%的训练吞吐量改进。这意味着您可以训练您的模型更快地收敛，并减少使用如此昂贵的GPU资源的计费时间。最重要的是，只要对我们前面提到的培训脚本进行简单的修改，所有这些都是可能的。</p><h1 id="5871" class="lm ln iq bd lo lp lq lr ls lt lu lv lw kf lx kg ly ki lz kj ma kl mb km mc md bi translated">结论</h1><p id="8eed" class="pw-post-body-paragraph ko kp iq kq b kr me ka kt ku mf kd kw kx mg kz la lb mh ld le lf mi lh li lj ij bi translated">在这篇博客文章中，您了解了如何使用SageMaker的分布式数据并行(SMDDP)库来加速和扩展EfficientNet的训练，这是一种用于计算机视觉任务的最先进的神经网络架构。SageMaker和SMDDP简化并加快了模型的训练，使ML科学家和开发人员能够更快地创新。我们介绍了如何修改现有的EfficientNet培训脚本，以采用SMDDP，只需修改几行代码，就可以实现高达30%的性能提升。</p><p id="9e2c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们还有其他几个<a class="ae lk" href="https://github.com/aws/amazon-sagemaker-examples/tree/master/training/distributed_training/pytorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae lk" href="https://github.com/aws/amazon-sagemaker-examples/tree/master/training/distributed_training/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>的例子，供你进一步使用SMDDP。我们也鼓励您利用您在这里学到的知识，使用SMDDP来加速我们自己模型的训练。如有任何问题或反馈，请联系我们，您可以在<a class="ae lk" href="https://github.com/HerringForks/SMDDP-Examples" rel="noopener ugc nofollow" target="_blank"> SMDDP-Examples GitHub资源库</a>中提出问题。</p></div></div>    
</body>
</html>