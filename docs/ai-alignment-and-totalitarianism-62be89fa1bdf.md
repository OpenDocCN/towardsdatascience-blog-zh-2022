# 人工智能联盟和极权主义

> 原文：<https://towardsdatascience.com/ai-alignment-and-totalitarianism-62be89fa1bdf>

## 意见

## 汉娜·阿伦特会对人工智能对齐说些什么？

![](img/a5a0e6ec0a3d845ff92f1f946c7eb05f.png)

图片来源: [Unsplash](https://unsplash.com/photos/S2oy0RCkORY)

## 介绍

这篇文章通过极权主义的框架来看待人工智能的错位，如汉娜·阿伦特的*极权主义的起源*中所述。我不想在 20 世纪非常真实的、单一的极权主义恐怖和仍然是假设的人工智能错位问题之间做任何油嘴滑舌的道德比较；但我认为这种相似之处仍然值得探究。

在她的巨著中，阿伦特描述了一个历史和政治背景，它孕育了一场与人类繁荣根本不一致的政治运动，这是一场与以往政府形式的反常决裂，构成了一台毁灭人类的机器。尼克·博斯特罗姆[著名的纸张思维实验](https://www.lesswrong.com/tag/paperclip-maximizer)想象了一个 AGI，他被授权制造尽可能多的回形针；由一个全能的代理人来执行，这个平庸但不受约束(读极权主义)的奖励函数导致了天启。两者都是强大的机器，在没有自然的人类直觉的指导下，朝着与人类繁荣根本不一致的目标逻辑地、无情地前进。

## 是什么让政府成为极权政府？

极权政府区别于其他形式的独裁政府(甚至像墨索里尼的意大利这样的法西斯独裁政府)，在于它不断地走向统治生活的每一个方面。它的终极目标是让人类机器人，可以预测地、顺从地对政权的命令做出反应，消灭自由意志的所有残余。任何形式的人类自发性都是对秩序的威胁:极权主义可以被认为是一个试图进一步消灭它的系统。

在阿伦特的思想中，当一个运动达到一个逃逸速度并退出“正常”政府的领域时，它就变成了极权主义，而“正常”政府，无论是哪种类型，都在某种程度上受到功利主义的约束:这是为其人民的福利服务的某种需要。(允许这种逃避的历史和政治条件超出了我的能力范围，也是本书大部分的主题。)

但是一旦它逃脱了，它就变成了一台毁灭人类的机器。它原子化、恐吓和谋杀自己的人民。它用运动的逻辑代替了常识，运动需要无限的扩张和与外部正常世界的战争。合乎逻辑的结论是，这场运动要么在外部被击败，要么耗尽人的生命来摧毁:没有可能的平衡。

## 生成人工智能和创造性破坏

博斯特罗姆的毁灭人类的回形针似乎是一个不可信的例子，但它强调了在一个只关心逻辑目标实现的无限过程中规模的危险。

生成式人工智能模型(如 OpenAI 的 GTP-3 和 DALLE-2)在创造能力方面取得了令人难以置信的加速飞跃，颠覆了关于人工智能有能力破坏何种工作的传统预期。它们通过拜占庭神经网络架构输入大量数据(基本上是整个互联网)来产生捕捉令人震惊的细微差别的信息模型。而且，由于他们所训练的群体的普遍性(出色地展示了一篇[这种规模的博客文章](https://scale.com/blog/text-universal-interface))，他们在执行任务时表现出惊人的灵活性。允许这种进步的基本创新是网络和训练集的规模；事实证明，蛮力，而不是更聪明的信息结构，可能是广义智能的关键。

从某种意义上说，人工智能在这里的错位与政治经济有关:它以零边际成本即时完成智力工作(如新闻、医疗诊断、标志设计)的能力，可能会把人们完全挤出特定领域，留下不满的大众。

但从另一个角度来看，威胁在于扼杀以人为中心的创造力。如果你不相信这个人工智能具有真正的自发性(我不相信)，即使你相信，如果你相信它的自发性与人类的自发性有根本的不同(如果我不相信，我会相信)，那么人工智能已经消灭了人类在其领域的自发性。不是字面上的机器学习奖励功能摧毁了人类，就像博斯特罗姆的回形针算法一样，人工智能的运行颠覆了人类以特定方式创造的*动机*。机器的规模和效率，加上资本主义的基本原理，扼杀了人性的核心原则。

我个人不相信一个 LLM 会粉碎一个领域中所有人类的创造力，LLM 可能会成为在新的方向上投射创造力的强大工具。但是，随着人工智能生成能力的相互复合(值得强调的是，人工智能已经开始编写代码)，人类适应的速度有多快？

## 风险和回报

20 世纪的极权主义罪行是由带有不人道目的的人类领导的运动延续下来的。人工智能安全研究人员的担忧集中在算法奖励函数的非人性本质上，这些函数寻求最小化数学定义的误差。

我相信机器学习承诺的物质丰富和知识是追求它的足够好的理由。但任何不受人类需求约束的权力系统(如大公司手中的人工智能)——甚至或特别是创造和智力满足的需求——都会打开一扇门，无论多么小，通向生活和意义的空虚。