<html>
<head>
<title>Serverless NLP Inference via HTTP API on AWS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过AWS上的HTTP API进行无服务器NLP推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serverless-nlp-inference-via-http-api-on-aws-e27ea41d122b#2022-01-18">https://towardsdatascience.com/serverless-nlp-inference-via-http-api-on-aws-e27ea41d122b#2022-01-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="5afb" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">通过AWS上的HTTP API进行无服务器NLP推理</h1></div><div class=""><h2 id="6e54" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用Boto3为您的无服务器端点设置API</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b8dfd2e94e80fe68044b4f876c8d8048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cKI5qwYnoItga5oy"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@tianshu?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">天舒刘</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h1 id="c1f3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">这是怎么回事？</h1><p id="7a10" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在之前的一篇博文中，我描述了我们如何在Amazon SageMaker上部署NLP模型进行无服务器推理。下一步，我们将测量这个无服务器端点的性能。为此，我们需要用一些测试数据调用端点。这可以使用Boto3 <em class="mk"> sagemaker-runtime </em>客户端轻松完成:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="c79a" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">但是这通常不是应用程序和服务与我们的模型交互的方式。实际上，我们希望有一个API来路由我们的请求，这样我们就可以监视和控制对模型的访问。</p><p id="71ab" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">在本教程中，我们将做到这一点:我们将设置一个允许我们访问无服务器端点的API，这样，作为下一步，我们可以测量端点在现实条件下的性能。和往常一样，本教程的代码在这个<a class="ae kv" href="https://github.com/marshmellow77/nlp-serverless" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中公开。repo由两个笔记本组成:第一个用来创建无服务器端点，第二个用来创建API的基础设施。</p><h1 id="16df" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">为什么这很重要？</h1><p id="44f2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如上所述，建议公开使用API来服务NLP模型。这种方法确保了对模型的请求可以被监控和检查。API还决定哪个模型用于哪个请求，并确保在无效请求的情况下进行适当的异常处理。智能扬声器是这种设置的一个很好的例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/92df844a04778ebf4d22d59b67355094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Z-EmB_1nun5r8o2nPomKw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0bcc" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">在这个场景中，API根据请求的类型决定应该使用哪个模型，并相应地路由请求。</p><p id="cd91" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">在本教程中，我们将学习如何通过创建API和Lambda函数来建立这样一个路由，该函数将处理我们的请求并将其发送到无服务器端点上的NLP模型。我将假设已经存在一个SageMaker端点来开始本教程。如果你还没有设置，你可以用这个<a class="ae kv" href="https://github.com/marshmellow77/nlp-serverless/blob/main/1_model_train_deploy.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中的代码轻松设置。</p><h1 id="c966" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">创建Lambda函数</h1><p id="35e8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">完成上述架构设置的最佳方式是从右到左，即从创建Lambda函数开始。</p><p id="7747" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">第一步是编写函数应该执行的代码。Lambda函数需要提取将通过API发送的文本，调用端点，并在将结果发送回API之前解析结果。下面是如何做到这一点的示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><blockquote class="mt mu mv"><p id="2da6" class="lo lp mk lq b lr mn jr lt lu mo ju lw mw mp lz ma mx mq md me my mr mh mi mj ij bi translated">我们如何知道来自API的请求的结构，即我们如何知道我们可以通过<em class="iq">事件[‘body’]</em>提取模型的文本？我们可以在HTTP API 的<a class="ae kv" href="https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-lambda.html" rel="noopener ugc nofollow" target="_blank">文档中找到有效载荷格式，我们将在下面设置API时进一步研究它。</a></p></blockquote><p id="608c" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">我们可以将Lambda函数的代码存储在本地的一个文本文件中。要创建函数，我们需要压缩这个文件，然后通过Boto3创建Lambda函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="39f6" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">记住，要选择一个IAM执行角色，该角色包含一个策略，该策略允许您函数调用SageMaker端点！</p><h1 id="6b40" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">创建HTTP API</h1><blockquote class="mt mu mv"><p id="5a42" class="lo lp mk lq b lr mn jr lt lu mo ju lw mw mp lz ma mx mq md me my mr mh mi mj ij bi translated"><strong class="lq ir"> HTTP API vs REST API:选哪个？</strong></p><p id="7f0a" class="lo lp mk lq b lr mn jr lt lu mo ju lw mw mp lz ma mx mq md me my mr mh mi mj ij bi translated">AWS在2019年推出了HTTP APIs，试图为使用API Gateway构建的客户提供增强的功能、改进的性能和更轻松的开发人员体验。HTTP APIs的缺点是它们不像REST APIs那样功能齐全。然而，对于我们相对简单的用例来说，HTTP APIs工作得很好，设置起来也很容易:)</p><p id="53b8" class="lo lp mk lq b lr mn jr lt lu mo ju lw mw mp lz ma mx mq md me my mr mh mi mj ij bi translated">要了解更多信息，我建议查看官方的AWS文档和博客文章。</p></blockquote><p id="f4e0" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">使用Boto3创建HTTP API非常简单。我们只需要一行代码来创建API，其中我们提供Lambda函数作为目标:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="3ac1" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">在测试我们的设置之前，我们需要做的最后一件事是允许API调用Lambda函数。这是在Lambda函数的配置中完成的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><h1 id="e56f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">测试</h1><p id="4079" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们终于有了所有的东西，现在可以测试我们的设置。为此，我们可以使用标准Python库<em class="mk">请求:</em>向API发送一个常规的POST请求</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ml mm l"/></div></figure><h1 id="aef0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论和后续步骤</h1><p id="5116" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们已经建立了一个架构，允许我们通过API访问无服务器NLP端点。这类似于真实场景，现在我们可以开始测试端点的性能，并调查端点的延迟和冷启动。</p><p id="872a" class="pw-post-body-paragraph lo lp iq lq b lr mn jr lt lu mo ju lw lx mp lz ma mb mq md me mf mr mh mi mj ij bi translated">我希望这是有帮助的，请随时提出问题和意见！</p></div></div>    
</body>
</html>