# 回答用自然语言提出的问题

> 原文：<https://towardsdatascience.com/answering-questions-posed-in-natural-language-a50a0043a033>

## **涉及信息检索、自然语言处理和机器学习的问题**

![](img/4b0de4a7e3a1622ccc48b4d8a310c0f3.png)

由[马塞尔·斯特劳](https://unsplash.com/@martzzl?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在 [Unsplash](https://unsplash.com/s/photos/question-mark?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

想象一个软件系统能够有效地回答用自然语言提出的问题。这样的系统非常有用。从引擎盖下发生的事情来看，这也非常有趣。

让我们从列举这样一个系统的一些实际用例开始。

*   **网上购物**:回答关于网上购物网站上特定商品的问题。我们在 Amazon.com 看到了这一点。
*   **技术/呼叫中心支持**:将询问故障排除问题的人发送到可能有答案的知识文章，甚至发送到答案本身。
*   **改进的搜索**:通常一个搜索查询是一个精确的问题，一个直接的答案是用户所寻求的。Google 通常可以发现这种情况，并返回一个简洁的答案。

在本帖中，我们将用真实的、深刻的例子来说明这个问题。接下来，我们将讨论这个问题在不同环境下的例子，并将这些例子与解决问题的想法配对。也就是说，解决方法在某种程度上取决于设置。

我们从

**示例问题、意图、背景**

考虑下面的问题

```
Unable to connect to my wifi at Starbucks
```

提问者真正想要的是一个解决方案。揭示可能的根本原因将是一个额外的收获。

接下来，考虑这个

```
How much mpg does a Honda accord give?
```

从字面上看，一个足够精确的数字估计就足够了。比如~ 25 mpg。一个更微妙的，返回两个估计，一个城市英里数和一个公路英里数会更好。

接下来，考虑这两个问题

```
Who won the 2022 Nobel prize in Physics?

What is a yellowtail?
```

正确答案是事实。

下一个，这个

```
Is there an online chatbot web service?
```

从字面上看，答案是一个布尔值:是或否。也就是说，如果答案是*是*，提问者也会喜欢这些服务的链接。

最后这个

```
How durable is the Kong dog toy?
```

答案可能来自以下各项的组合

*   产品的网站，如果有相关的耐久性信息。
*   Amazon.com 等在线购物网站上该产品各种版本的页面
*   来自关于这个话题的博客
*   根据该产品的实际购买者在购物网站或评论网站或两者的报告经验。

也就是说，

1.  可能有多个答案。(毕竟问题有点主观。)
2.  提问者会很感激各种答案按来源分类。提问者可能更喜欢某些来源的答案。例如来自购买者的实际经历。

认为

```
From reported experiences of actual purchasers of **this product** at a 
shopping site or a reviews site or both.
```

粗体字是上下文的一个例子。这种背景会很有帮助。只有与此产品的*相关的问答或评论是相关的。*

**Q & A 作为关键词搜索**

我们指的是*关键词*搜索，而不是谷歌。虽然谷歌最出名的是前者，但它也试图在可能的情况下直接回答问题。通常它做得很好。我们很快就会看到例子。

现在，我们只想说，关键字搜索通过分析查询中的术语与各种文档中的术语的匹配，返回一组被认为与查询相关的文档。虽然这在搜索环境中通常是有效的，但在问答环境中却不够有效(我们前面已经看到了这样的例子)。关键词搜索并不试图理解问题。也不知道提问者的意图。它也无法从一系列相关文件中找到答案。

**一些实际 Q & A 系统的例子**

**不太好的答案示例**

这是来自一个真实的未命名的在线问答系统。我们不能说我们选择了一个伟大的系统来尝试。尽管如此，这些答案揭示了他们在哪些方面是错误的，或者至少是可以改进的。

```
who won the 2022 nobel prize in physics
**Max Born won The Nobel Prize in Physics in 1954.**
```

该系统的许多部分都是正确的。年份错误抵消了所有这些。

```
How much mpg does a Honda Accord give
**My 1999 Honda Accord 4 cylinder gives me 21 mpg around town.**
```

还不错。不过，只有一个人的经历给出了一个答案。多个答案会更好。加上提供公路 mpg(如前所述)也将不胜感激。

**好答案示例**

这个来自前面提到的未命名系统。

```
What is a yellowtail?
**A yellowtail is another name for the yellowtail amberjack, Latin name 
Seriola lalandi, a species of edible fish.**
```

下面的是从谷歌搜索。

```
How much mpg does a Honda Accord give
**In the Honda Accord, miles per gallon fuel economy differs by trim level. 
The EPA-estimated 30 city and 38 highway MPG figures above can be found in 
the base LX trim, as well as the EX and EX-L trims.**

**Accord Gas Miles Per Gallon.
City 23 Highway 34**
```

我在谷歌搜索的顶部结果页面找到了两个答案，所以我把它们都列出来了。

**朝一问&朝一制**

**来自文章知识库**

我们有一个文章知识库，最好是实际答案。我们寻求检索所提问题的最佳文章。相关性问题类似于搜索中的问题。语料库的全面性、检索到的文章的相关性等。

在下文中，我们在两种意义上使用“答案”这个词。

*   当知识库由答案组成时，一个真实的答案。
*   当知识库由文章组成时，问答系统响应查询而返回的文章。

在特定情况下使用的意义将由上下文揭示。

**示例**

在线购物网站上的产品目录。它比整个网络更受限制。然而，它可以像 Amazon.com 一样拥有数百万种产品。

**方法:机器学习视角**

通过“机器学习的观点”,我们真正的意思是将特征工程作为一个明确的步骤，并在有意义的时候倾向于监督学习。这个视角中的成分将根据需要使用来自信息检索(IR)、统计和机器学习(ML)的方法。

下面的讨论方式是“头脑风暴”。它应该是吸引人的，而不是全面的。

**问题特征**

显然，这些应该围绕单词和可能的短语。问题是，哪些？

在一个极端，我们可以将任何问题中可能出现的每个单词定义为特征空间中的一个维度。这个空间可能有几十万个维度，每个维度代表词典中的一个单词。然后把问题表示成这个空间中的一个合适的向量。例如单词袋，一个使用术语频率，或者一个使用 TF×IDF。

词典可能很大，许多单词不能预测特定的答案。例如*、的*、*与*、……捕捉这些词在问题中的存在可能会产生噪声。另一方面，这种方法仅限于使用文字。取决于 Q & A 领域，某些短语可能比相关文章中的独立单词更好地预测相关文章。**

*如果其中任何一个是一个问题，我们可以考虑下面的。*

*最简单的方法是从常用词词典中过滤掉停用词。正如搜索引擎通常所做的那样。*

*更详细一点的是统计 NLP 的以下方法。使用词性标注器来标注问题中每个单词的词性。然后过滤掉那些词类预计不能预测答案的词。如*条* ( *条*、*条、一条*、…)。或者相反，只保留那些被认为是答案的预测词。如*名词*。*

*我们可以进一步提炼出突出的短语。如果我们简单地提取二元模型或三元模型，即仅基于频率的两个词或第三个词的短语，我们会得到许多假阳性，即不显著的短语。“of the”就是一个例子。在问题的特征向量中使用这样的假阳性只会增加噪声。*

*事实证明，一个短语中各种单词的词性非常能预示其显著性。例如，名词短语往往是突出的。*

***监督细化***

*考虑我们选择以无监督的方式提取的特征——单词和短语。我们可以尽可能使用监督学习来改进我们的选择。*

*考虑我们的产品目录示例。假设目录中的每个产品都有(除了其他属性之外)文本描述、作为标签的关键字以及它所属的产品分类。我们可以从产品的分类中得到一个合适的标签。比如顶级产品类别:*电子产品*、*服装*、……我们可以从产品的描述和标签中提取合适的词语。然后，我们可以使用监督学习来找到我们的世界中的哪些单词和短语(已经以无监督的方式进行了修剪)是产品顶级类别的预测。*

***寻找好答案***

*我们已经讨论完了从问题中提取合适的特征。让我们把注意力转向从我们的知识库中寻找好的答案。*

*我们可以采取信息检索的方法。从我们的知识库中的所有文章中提取相同的特征，并将问题的特征向量与文章的特征向量进行比较。*

*在这里，我们将进一步探讨。使用机器学习来提高我们找到好答案的能力。为此，我们显然需要反馈。例如哪些答案是好的，哪些不是个人用户所认为的。*

*在搜索的设定中，这种方式叫做*学习排名*。涵盖这个广泛的主题超出了本文的范围。好奇就看【3】。*

*也就是说，我们将深入研究这一点。公式化监督学习问题的一种方式是将输入作为问题-文章对。(问题和答案都由它们的特征向量表示。)将该输入标记为*相关*或*不相关。**

*现在，这是一个二元分类问题，可以使用合适的机器学习分类器来解决。值得注意的是，分类器应该旨在为问题-文章对分配相关性分数。也就是说，即使训练集中的标签是二元的，我们真正寻求的是量化相关程度的预测。例如文章与问题相关的概率。然后，这种预测可用于对回答问题的答案进行排序。事实上，这就是为什么我们称这种学习为*排序*而不仅仅是二进制分类。*

***来自问答配对知识库***

*在某些情况下，我们的知识库可以采取问答配对的形式。注意“Answers”是复数形式。这是因为一个问题可能有多个相关的答案。*

*这种设置的两个值得注意的例子是*

*   *与特定产品相关联并由在线购物网站维护的问答配对。比如 Amazon.com。*
*   *专门维护问答配对的网站。比如 quora.com*

*当知识库是这种形式时，优先将查询问题与数据库中的问题进行匹配比答案更有意义。这是因为*

*   *问题往往比答案更简洁。*
*   *同一个问题的两个表达通常比问题的一个表达与链接到不同表达的答案更相似。*

*让我们用一个例子来说明这两点。*

*假设下面的问答配对在我们的知识库中。*

```
*where is quora located?
**It's headquarters are in Mountain View, CA.***
```

*现在考虑这个问题*

```
*where are the headquarters of quora?*
```

*将这个问题与知识库中的答案进行匹配可能不会有任何结果。正确答案甚至没有明确提到 **quora** 。*

*另一方面，这个问题的两种表达方式很匹配。*

```
***where** are the headquarters of **quora**?
**where** is **quora** located?*
```

*有了更先进的模型来解释单词的语义相关性，我们对这种匹配的信心原则上可以进一步加强。具体涉及*总部*和*所在地。**

*这个例子还揭示了使用来自链接到匹配问题的答案的信息可以增加匹配的强度。如下图所示。*

```
***where** are the **headquarters** of **quora**?

**where** is **quora** located?
It's **headquarters** are in Mountain View, VA*
```

*第一行包含查询。接下来的两行包含知识库中匹配的问答对。*

*这个例子还表明，使用高级的 NLP 方法，如单词嵌入，可能会提高匹配的质量。特别是比较、*所在*和*总部*的词向量，可以揭示三者之间的语义关联。它们都与地点有关。*

***从知识库中选择答案***

*现在我们把注意力转向一个更难的问题。像以前一样，我们有一个来自某个领域的用户的自由形式的问题和一个知识库，一旦人工智能系统理解了这个问题，它就可以进行咨询。这次我们假设知识库中的实体是文章，而不是具体问题的具体答案。*

*所以，当收到一个问题时，人工智能系统必须首先找到相关的文章，然后从中构造一个或多个合适的答案。*

*首先，我们为什么对这个问题感兴趣？除此之外就更难了。*

*在公共领域或商业实体中有许多可用的知识库。只有极小一部分包含特定问题的现成答案。因此，算法答案的构建为极大地扩展可回答问题的范围提供了可能性。*

*综上所述，回答一个问题，首先，AI 系统需要找到相关的知识文章，然后从中推导出合适的答案。*

*第一步，我们可以使用本节之前讨论过的思想。(也就是说，稍后当我们看到具体的示例时，我们将细化其中的一些内容。)*

*所以这里让我们来关注一下*

***构造答案***

*我们得到问题和一组人工智能系统认为与问题相关的文本文档。任务是构建一个或多个好的答案。*

*这个问题不好解决。我们不会试图给出一个完整的解决方案。相反，讨论什么样的 NLP 可以作为构建最终配方的有用成分。为此，我们将研究一些现实的例子，并集思广益，从中找出正确的答案。*

***一个例子***

*考虑以下问题:*

```
*who won the 2022 Nobel prize for Physics?*
```

*我在谷歌上输入了这个。谷歌给出了正确答案。*

*出于说明的目的，我将忽略谷歌的回答，而是检查谷歌显示的前几个搜索结果的片段。我会想象我们的构造函数试图从这些片段中得到正确的答案。*

```
*Oct 4, 2022 — Alain Aspect, John Clauser and Anton Zeilinger have won the 
2022 Nobel Prize in Physics for groundbreaking experiments with entangled …

Oct 4, 2022 - The 2022 Nobel Prize in Physics has been awarded jointly to 
Alain Aspect, John F Clauser and Anton Zeilinger "for experiments with 
entangled …

Oct 10, 2022 - On Oct. 4, the prize for physics was shared by three men, 
Alain Aspect, John F. Clauser and Anton Zeilinger, for their work in 
quantum …

**Oct 4, 2022 - The prize was awarded to Syukuro Manabe, Klaus Hasselmann and
Giorgio Parisi for their work detailing humanity's role in climate change. 
Who …**

Oct 4, 2022 - The 2022 Nobel Prize in Physics has been awarded to three 
scientists for their contributions to understanding quantum entanglement 
and …

Oct 10, 2022 - Nobel Prize in Physics - Scientists Alain Aspect, John 
Clauser and Anton Zeilinger won the 2022 Nobel Prize in Physics for 
experiments in …*
```

*正确的答案隐藏在所有这些片段中。除了用粗体字标出的错误答案。*

***进一步过滤片段列表:局部对齐***

*问题中的单词序列“获得 2022 年诺贝尔物理学奖**”**几乎与前面提到的一些片段完全匹配，如下所示。*

```
*Oct 4, 2022 — Alain Aspect, John Clauser and Anton Zeilinger have **won the 
2022 Nobel Prize in Physics** for groundbreaking experiments with entangled …

Oct 10, 2022 - Nobel Prize in Physics - Scientists Alain Aspect, John 
Clauser and Anton Zeilinger **won the 2022 Nobel Prize in Physics** for
experiments in …*
```

*提出这一点的目的是，问题中的一长串单词与一个片段几乎完全匹配，这表明该片段可能包含正确的答案。*

*检查两个标记序列是否有一个共同的长子序列(直到某种变化)的问题已经得到了很好的研究。在生物信息学中，它被称为局部比对问题。Smith-Waterman 算法是解决这一问题的有效方法[1]。*

*在这个例子中，我们看到这个问题的一个增强版本，称为多重局部对齐，可能也有价值。在多重局部比对中，我们发现许多序列共有的长序列，而不仅仅是两个。在我们上面的例子中，所有三个问题和两个片段都有一个以粗体突出显示的子序列。*

*将问题与片段进行局部对齐可以显示似乎与问题匹配的附加片段，尽管匹配的片段稍短。下面是突出显示的对齐区域。*

```
*who won **the** **2022 nobel prize for physics**?

Oct 4, 2022 - **The 2022 Nobel Prize in Physics** has been awarded jointly to 
Alain Aspect, John F Clauser and Anton Zeilinger "for experiments with 
entangled …

Oct 4, 2022 - **The 2022 Nobel Prize in Physics** has been awarded to three 
scientists for their contributions to understanding quantum entanglement 
and …

Oct 10, 2022 - Nobel Prize in Physics - Scientists Alain Aspect, John 
Clauser and Anton Zeilinger won **the 2022 Nobel Prize in Physics** for 
experiments in …*
```

*注意，在进行局部比对之前，我们不希望丢弃停用词。在本地对准中包含字**和**携带信号。*

***命名实体识别可以帮助***

*在问题和片段中，我们注意到有命名的实体:*年* (2022)，*人名* (Alain Aspect，John Clauser，Anton Zeilinger)，以及*学科*(物理)。清楚地识别这些命名实体有助于找到更相关的片段，即问题-片段匹配和提取最终答案。*

*命名实体的概念似乎也有助于推断问题在寻找什么。在这种特殊情况下，问题以 **who** 开始，这是一个强有力的线索，表明问题正在寻找*人名*的实体。*

*参见[2]中关于文本中命名实体识别的文章。*

***例 2，多模态，产品 Q & A***

*考虑购物网站上的产品页面。假设有一个区域，用户可以就产品提出一个问题。假设产品的页面有它的描述，一些来自贡献者的问答配对，以及文本评论。最后两个最好来自实际购买者。*

*理想情况下，人们希望只使用问答配对的数据集。然而，这是假设数据集有足够的覆盖面。事实往往并非如此。尤其是小众产品。因此，我们希望使用产品描述和评论中的信息。*

*在这种情况下，我们使用术语“多模态”,因为回答一个问题需要对具有不同模态的数据源进行不同种类的处理。然后以某种方式组合结果。*

*这里，以提纲的形式，是我们回答一个具体问题的一种方法。*

1.  *使用本文前面讨论的方法，我们可能会从问答配对的数据集中找到合适的答案(如果有的话)。简而言之，在数据集中找到与新问题匹配的问题(如果有的话)，并使用与匹配问题链接的答案中的信息作为支持或反对新问题的额外证据。*
2.  *发现产品的描述是否对隐藏在其中的问题有一个合适的答案可能会有不同的工作方式，因为我们只有一个描述。也就是说，这个问题似乎是挖掘描述，而不是匹配、评分和排列多个命中的问题。*
3.  *发现评论是否有这个问题的答案类似于从这样的知识库中找到相关的文章。随后可能是一个合并或巩固阶段，试图将多个答案中的点连接起来。*

*最后，我们可能需要考虑是否需要整合/巩固/合并步骤 1 到 3 分别返回的答案。*

***总结***

*在这篇文章中，我们讨论了试图回答自然语言问题的人工智能引擎的问题。我们首先列出了一些实际的用例。然后，我们讨论了一些现实的说明性例子的问题和问题的意图和背景。从这些例子中，很明显，关键字搜索不足以解决这个问题。*

*然后，我们在几个在线问答系统上尝试了几个问题，包括在谷歌上。一些答案是好的，另一些揭示了系统出错的方式，还有一些在揭示答案可以改进的具体方式时是好的。*

*接下来，我们深入探讨了如何构建一个问答引擎来回答这些问题。我们把它分解为*

*   *从答案知识库中寻找好的答案。*
*   *从问答配对知识库中寻找好的答案。*

*然后，我们讨论了添加一个后处理步骤，以尝试合并系统可能返回给特定问题的多个答案。如果知识库包含文章，而不是特定的答案，这一步尤其重要。即使知识库包含特定的答案或一组问答对，它也是有用的。*

*在前一种情况下，可能会发现与问题相关的多个答案。也许对这些答案进行后处理会得到一个更好的答案。在后一种情况下，该查询可以匹配知识库中具有多个链接到它的答案的问题。同样，对这些答案进行后处理可能会得到更好的答案。*

*最后，我们讨论了一个设置，其中的问题是在一个背景和知识库是多模态的。我们讨论的设定是网上购物。一个特定的产品。特定产品的知识库被假定为包括其描述、一组评论和一组问答对。*

***附录:较新的材料***

*我选择把更新的想法放在这里，而不是把它们留在外面，因为我不想花时间把它们整合到帖子的正确位置。*

*认为*

```
*Are floss picks better than regular floss?*
```

*这没有一个非黑即白的答案。提问者可能对反映牙医一致意见的答案感兴趣。*

*假设我们的知识库由问题-答案对组成，这个问题碰巧出现在其中，也许有许多答案。假设用户给出反馈，说明哪些答案有用，哪些没用。假设知识库中链接到特定问题的答案包含一些关于提交答案的人的元数据。在我们的情况下，她是一名牙医。原则上，系统然后可以学习回答贡献者是牙医和回答质量之间的关联(或缺乏关联)。*

*考虑这个问题*

```
*how to reset a wifi modem*
```

*一个好的答案应该简洁地给出步骤。诸如*

```
*1\. Unplug the cable.
2\. Wait 30 seconds.
3\. Plug the cable back.
4\. Check if the Internet light on the modem is white.*
```

*理想情况下，如果问题有多种不同的解决方案，那么也要列出可供选择的步骤。在我们的例子中，也许*

```
*1\. Locate the reset button on the back of your modem.
2\. Using a pointed object such as the back of a paper clip, 
   press the reset button and hold for 30 seconds.*
```

*谷歌通常在这类问题上做得很好。并不总是清楚列出的步骤是正确的，因为它们是从查询的顶级网页点击中提取的。然而，它们简洁、易于理解、易于测试。*

***参考文献***

1.  *[斯密–沃特曼算法——维基百科](https://en.wikipedia.org/wiki/Smith%E2%80%93Waterman_algorithm)*
2.  *自然语言处理中的命名实体识别。真实世界的用例、模型、方法…*
3.  *[学习排名—维基百科](https://en.wikipedia.org/wiki/Learning_to_rank)*