<html>
<head>
<title>Powering Semantic Similarity Search in Computer Vision with State of the Art Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用最先进的嵌入技术支持计算机视觉中的语义相似性搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/powering-semantic-similarity-search-in-computer-vision-with-state-of-the-art-embeddings-f6c183fff134#2022-01-26">https://towardsdatascience.com/powering-semantic-similarity-search-in-computer-vision-with-state-of-the-art-embeddings-f6c183fff134#2022-01-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="cee6" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">用最先进的嵌入技术支持计算机视觉中的语义相似性搜索</h1></div><div class=""><h2 id="db66" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">执行图像到图像和文本到图像相似性搜索的最简单方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/31d54f88c1e22a08b07bc3b83fd5e9f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A7zD9kukeXtXB1VD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">厉害的力量！由<a class="ae ky" href="https://unsplash.com/@laviperchik?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">狮式战斗机·珀奇克</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="2907" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自从人类文明诞生以来，多达90%的数据是在过去两年中产生的！随着社交媒体和物联网(IoT)等数字技术的激增，以及5G等速度更快的无线通信技术的发展，数据创建率不断提高。然而，大多数新创建的数据都是“<a class="ae ky" href="https://www.researchgate.net/publication/322058724_Unified_concept-based_multimedia_information_retrieval_technique" rel="noopener ugc nofollow" target="_blank">非结构化的</a>，如文本、图像、音频和视频<a class="ae ky" href="https://www.researchgate.net/figure/The-Massive-Growth-in-Unstructured-Data-Source-IDC-The-Digital-Universe-Dec-2012_fig12_322058724" rel="noopener ugc nofollow" target="_blank">来源</a>。</p><p id="de33" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非结构化数据之所以得名，是因为它没有固有的结构，不像表格那样由行和列组成。相反，非结构化数据包含几种可能格式之一的信息。例如，电子商务图像、客户评论、社交媒体帖子、监控视频、语音命令等。，是丰富的信息源，不遵循传统的表格数据格式。</p><p id="3da1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">人工智能(AI)和机器学习(ML)技术的最新进展创造了一种通过使用“嵌入”以可扩展的方式从非结构化数据源中提取有用信息的方法。将非结构化数据转换为嵌入数据，并将其存储在向量数据库中，如<a class="ae ky" href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank"> Milvus </a>已经实现了几个优秀的应用程序，这在几年前是不可想象的。一些示例应用是<a class="ae ky" href="https://arxiv.org/abs/2102.04674" rel="noopener ugc nofollow" target="_blank">视觉图像搜索</a>、<a class="ae ky" href="https://arxiv.org/abs/1908.10084" rel="noopener ugc nofollow" target="_blank">语义文本搜索</a>、<a class="ae ky" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank">推荐引擎</a>、<a class="ae ky" href="https://ai.facebook.com/blog/using-ai-to-detect-covid-19-misinformation-and-exploitative-content/" rel="noopener ugc nofollow" target="_blank">对抗错误信息</a>、<a class="ae ky" href="https://blog.milvus.io/milvus-in-action-chemical-structure-similarity-search-33130767162a" rel="noopener ugc nofollow" target="_blank">药物发现</a>等。！</p><p id="c1e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们将讨论以下内容。点击链接，跳转到以下部分:</p><ol class=""><li id="c8c6" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#2b04" rel="noopener">什么是嵌入</a></li><li id="2bfe" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#06bc" rel="noopener">用Kaggle API加载一些数据</a></li><li id="7e0c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#df1d" rel="noopener">拉平原始像素值</a></li><li id="36db" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#7a4b" rel="noopener">针对分类目标</a>预训练的卷积神经网络:Towhee by Zilliz</li><li id="bca7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#ed6c" rel="noopener">用度量学习目标</a>预训练的卷积神经网络:谷歌的SimCLR</li><li id="0dc2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#f3c6" rel="noopener">用度量学习目标</a>预训练的图像-文本多模态神经网络:由OpenAI剪辑</li><li id="2cbc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#79aa" rel="noopener">结论</a></li></ol><p id="08eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将使用Kaggle提供的Digikala产品颜色分类数据集<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank">在这里</a>构建一个简单的基于图像的电子商务相似产品搜索服务。数据集是在GPL 2许可下授权的。</p><h1 id="2b04" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是嵌入</h1><p id="18d4" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们的计算机不能像人类那样直接理解图像或文本。但是，计算机擅长理解数字！因此，为了帮助我们的计算机理解图像或文本的内容，我们需要将它们转换成数字表示。例如，如果我们考虑图像用例，我们本质上是将图像的上下文和场景“编码”或“嵌入”到一系列矢量形式的数字中。</p><blockquote class="ng"><p id="27ad" class="nh ni it bd nj nk nl nm nn no np lu dk translated"><em class="nq">“嵌入”向量是我们图像数据的数字表示，以便我们的计算机可以理解我们图像的上下文和场景。</em></p></blockquote><figure class="ns nt nu nv nw kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/d87e8d4f33b7d145530bc0e79f185b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k7zaxRvRM7J7sgPawGk2kQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算机不能直接理解图像，但是它们可以很好地理解数字！作者图片</p></figure><p id="c41c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">几个Python库允许我们从图像中生成嵌入。一般来说，我们可以将这些库分为两大类。</p><ol class=""><li id="d9a1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">提供具有预训练模型的现成API的库:</strong>对于许多涉及日常物品图像的现实世界问题，我们可能不需要训练任何模型。相反，我们可以依赖全球研究人员开源的许多高质量的预训练模型。研究人员已经训练这些模型从<a class="ae ky" href="https://paperswithcode.com/dataset/imagenet" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集中识别和聚类几个日常物体。</li><li id="bacc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">允许我们训练和微调我们的模型的库:</strong>顾名思义，对于这些模型，我们可以从零开始带来我们的数据和训练模型，或者专门针对我们的用例微调预训练的模型。如果预先训练的模型没有为我们的问题领域提供良好的嵌入，我们只需要沿着这条路走下去。</li></ol><p id="c1f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们在这篇文章中看看其中的几个库。但是首先，让我们加载一些图像数据来定性地评估我们在相似性搜索应用程序中的嵌入。</p><h1 id="06bc" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">加载一些数据</h1><p id="2d3b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们首先需要加载一些图像数据来测试各种嵌入策略。在这篇文章中，让我们使用来自Kaggle的Digikala产品颜色分类数据集<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank">这里</a>。该数据集包含超过6K个电子商务产品的图像，非常适合测试基于电子商务图像的类似产品搜索服务。</p><h2 id="072e" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">步骤1:设置Kaggle环境</h2><ol class=""><li id="4214" class="lv lw it lb b lc nb lf nc li oj lm ok lq ol lu ma mb mc md bi translated">在<a class="ae ky" href="http://kaggle.com" rel="noopener ugc nofollow" target="_blank">kaggle.com</a>上创建账户</li><li id="ea9e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">单击您的个人资料图片，然后从下拉菜单中单击“帐户”。</li><li id="b6f0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">向下滚动到“API”部分。</li><li id="6ec1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">单击下图所示的“创建新的API令牌”按钮，下载一个新的令牌，作为一个JSON文件，其中包含用户名和API密钥。</li><li id="fcce" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果您使用的是macOS或Linux，将JSON文件复制到<code class="fe om on oo op b">~/.kaggle/</code>目录。在Windows系统上，转到您的根目录，然后转到<code class="fe om on oo op b">.kaggle</code>文件夹，并将下载的文件复制到该文件夹。如果<code class="fe om on oo op b">.kaggle</code>目录不存在，请创建它并将JSON文件复制到其中。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/bd716fa8ab52735de9c040ab6f2c965e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V3uclwD6W2KDXaey.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">创建一个新的Kaggle API令牌。图片作者。</p></figure><h2 id="7577" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">步骤2:从Kaggle下载数据</h2><p id="5bf4" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们将使用Anaconda来管理这个项目的虚拟环境。你可以从<a class="ae ky" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank">这里</a>安装Anaconda。一旦您下载并安装了Anaconda，我们就可以设置一个名为<code class="fe om on oo op b">semantic_similarity</code>的新环境，安装必要的库，如<code class="fe om on oo op b">kaggle</code>和<code class="fe om on oo op b">pandas</code>，并通过在终端窗口中运行以下命令从<a class="ae ky" href="http://kaggle.com" rel="noopener ugc nofollow" target="_blank">kaggle.com</a>下载整个数据集。如果不想使用Anaconda，也可以使用python的<code class="fe om on oo op b">venv</code>为这个项目创建和管理一个虚拟环境。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="36cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据包含各种电子商务产品的6K多张图片。在下图中，我们可以看到数据集中的一些样本图像。正如您所注意到的，数据集包含各种时尚产品，如男装、女装、包、珠宝、手表等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/9f47939a99f6a75905ed9ee25e3ead8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIfAzpymIWdtzhlWCb7E1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集中可用的示例产品。作者使用来自拥有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>的图像合成图像。</p></figure><h2 id="ce53" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">步骤3:将所有图像从每个文件夹移动到父文件夹</h2><p id="36ef" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">让我们在<code class="fe om on oo op b">semantic_similarity/notebooks</code>目录中创建一个新的jupyter笔记本来测试各种嵌入策略。首先，让我们导入必要的库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="0277" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下载的图像位于几个子文件夹中。让我们将它们全部移动到主父目录中，这样我们就可以很容易地获得它们的所有路径。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://stackoverflow.com/questions/8428954/move-child-folder-contents-to-parent-folder-in-python" rel="noopener ugc nofollow" target="_blank">堆栈溢出</a>的代码，由作者修改</p></figure><h2 id="66db" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">步骤4:将图像路径加载到熊猫数据帧中</h2><p id="f03f" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">接下来，让我们将所有图像文件路径的列表加载到pandas数据帧中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/90923f49447b4a1863a3474a9f868ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*wkCgSOpPyKowpJDgEZPEkw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧中的前5行。作者图片</p></figure><h1 id="a268" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">生成嵌入的策略</h1><p id="4886" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">计算机视觉技术的最新进展开辟了许多将图像转换成数字嵌入的方法。让我们来看看其中的几个。点击链接跳转到相关部分。</p><ol class=""><li id="edb1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#df1d" rel="noopener">拉平原始像素值</a></li><li id="125d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#7a4b" rel="noopener">根据分类目标预先训练的卷积神经网络</a></li><li id="4c5c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#ed6c" rel="noopener">用度量学习目标预训练的卷积神经网络</a></li><li id="a706" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/p/f6c183fff134#f3c6" rel="noopener">用度量学习目标预训练的图文多模态神经网络</a></li></ol><h1 id="df1d" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">拉平原始像素值</h1><p id="20db" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">彩色图像由三维像素阵列组成。第一维是图像的高度，第二维是图像的宽度，最后第三维是颜色通道，统称为RGB，包含红色、绿色和蓝色，如下图所示。每个像素的值是0到255之间的整数，255是可能的最高亮度。</p><p id="1df6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此,( 0，0，0)的RGB值是全黑或纯黑像素，而(255，255，255)是全饱和纯白像素。我们图像中可见的所有其他颜色都是由RGB这三个基本值的各种组合构成的。在<a class="ae ky" href="https://www.rapidtables.com/web/color/RGB_Color.html" rel="noopener ugc nofollow" target="_blank"> RapidTables网站</a>上的RGB颜色代码表允许你选择任何颜色来查看它的RGB值，一定要试试！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/bfe215dbba6f3e6d20e5b59133d4f79c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rftM7Zn4odNLO5_H_q5L4A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">彩色图像由3个通道组成，一个用于红色，一个用于绿色，一个用于蓝色。作者图片</p></figure><p id="d5e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设图像是3D数组格式的一系列数字，使用<code class="fe om on oo op b">reshape</code>操作将它们转换成1D向量是很简单的，如下图所示。我们也可以通过将每个像素的值除以255来归一化0到1之间的像素。我们将在代码中这样做。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/5b6fa55700352f6c7a386a2a9e40bb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wyBY7vM14mzOSVCeAJRdxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拼合会将3D数组转换为1D矢量。作者图片</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><h2 id="8b89" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">这种方法的问题</h2><p id="1b98" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">尽管这种方法易于理解并且易于实现，但是这种将图像“嵌入”到矢量中的方法有一些严重的缺点。</p><ol class=""><li id="0f0f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">巨大的矢量:</strong>我们从Kaggle下载的图像尺寸非常小[224 x 224 x 3]，对应于[高x宽x通道]，将这个3D数组转换为1D矢量的结果是一个大小为150，528的矢量！对于如此小的图像来说，这是一个巨大的矢量！在我们整个数据集上生成这个向量时，我的计算机崩溃了好几次。我最后只在一个较小的子集(1K行)上运行它来说明这种方法。</li><li id="24d5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">带有大量空白(白色)空间的稀疏向量:</strong>视觉检查我们时尚数据集中的图像，我们注意到图片中有大片白色区域。因此，这个150，528元素向量的许多元素只是值255(对于白色),并没有添加任何与图像中的对象相关的信息。换句话说，这种“嵌入”方案不能有效地编码图像的对象，而是包括许多无用的空白。</li><li id="5b02" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">缺乏局部结构:</strong>最后，直接展平一幅图像，失去了画面的所有局部结构。例如，我们通过眼睛、耳朵、鼻子和嘴巴的相对位置来识别人脸的图像。这些是各种“特征”级别的信息，如果我们一次只看一行像素，我们会完全忽略这些信息。这种损失的影响是颠倒的脸将具有与正面朝上的脸非常不同的平坦嵌入，即使两者都是同一张人脸的照片！</li></ol><p id="158e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着基于卷积神经网络<a class="ae ky" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank"> CNN </a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="noopener ugc nofollow" target="_blank">变换器</a>架构的新型神经网络架构的出现，我们已经基本克服了这些问题。这篇文章的其余部分深入探讨了使用这些神经网络将我们的图像转换成嵌入图像的方法。</p><h1 id="7a4b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">基于分类目标预训练的卷积神经网络</h1><p id="e7e2" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">也许最著名的计算机视觉任务之一是将图像分类成不同的类别。通常，对于这项任务，我们将使用CNN模型，如<a class="ae ky" href="https://arxiv.org/abs/1512.03385v1" rel="noopener ugc nofollow" target="_blank"> ResNet </a>作为编码器，将图像转换为向量，然后将该向量通过多层感知器(MLP)模型来确定图像的类别，如下图所示。研究人员将使用交叉熵损失来训练这种CNN + MLP模型，以准确地对图像类别进行分类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/1c9c76a20e93ca1cc0b39736b63b06bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d5C15wQMh1bvu25P9P5bgw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像分类管道。CNN将图像转换为嵌入向量。MLP用这个向量来预测图片的类别。图片作者。</p></figure><p id="5b90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法提供了最先进的精确度，甚至超过了大多数人的能力。在训练了这样的模型之后，我们可以省去MLP层，直接将CNN编码器的输出作为每个输入图像的嵌入向量。</p><p id="fa76" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在现实中，我们不需要为许多现实世界的问题从头训练我们自己的CNN模型。相反，我们直接下载并使用已经训练好的模型来识别日常对象，如<a class="ae ky" href="https://paperswithcode.com/dataset/imagenet" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集中的那些类别。<code class="fe om on oo op b">Towhee</code>是一个python库，使用这些预先训练好的模型快速生成嵌入。让我们来看看如何做到这一点。</p><h2 id="7517" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">Towhee管道</h2><p id="8593" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><a class="ae ky" href="https://hub.towhee.io/" rel="noopener ugc nofollow" target="_blank"> Towhee </a>是一个python库，提供了极其易用的嵌入生成管道。我们可以使用towhee将一个图像转换成一个嵌入，只需要不到五行的代码！首先，让我们在终端窗口中使用<code class="fe om on oo op b">pip</code>安装<code class="fe om on oo op b">towhee</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="1ae7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，在Jupyter笔记本单元格中，让我们导入库并实例化一个管道对象。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="83ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们在一行代码中使用管道将图像转换为嵌入内容！嵌入管道的输出有几个额外的维度，我们可以用<code class="fe om on oo op b">np.squeeze</code>去掉。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a7e02310497bd1215dbdfa6f784e3d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*cVRK8H9Kit8f7O7IoS2UrA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧的前5行用于嵌入创建。作者图片</p></figure><p id="1bcc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们继续之前，让我们创建一个助手函数，它接受嵌入列的名称、用作查询图像的数据框的索引以及要搜索的相似图像的<code class="fe om on oo op b">k</code>数量。该函数计算查询图像的嵌入和数据帧中所有其他图像的嵌入之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>，以找到顶部<code class="fe om on oo op b">k</code>最相似的图像并显示它们。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="e25c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以通过从数据帧中查询随机图像，并使用上面的辅助函数显示<code class="fe om on oo op b">k</code>最相似的图像，来测试towhee的嵌入质量。如下所示，对于我们运行的每个查询，towhee嵌入都非常准确，以便从包含几个不同产品(如服装、手表、包和配饰)的整个图像集中找到相似的图片！考虑到我们只用三行代码就生成了这些嵌入，这就更令人印象深刻了！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/57325b94e6003f2c7d530022c92f6e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OcPMXZ1eG4QyY5I1XPX6rw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机查询图片和来自towhee嵌入的前5个最相似的图片。作者使用具有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>中的图像制作图片。</p></figure><p id="fb3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从结果中，我们可以得出结论，towhee是快速生成相似性搜索应用程序的嵌入的一个很好的起点。然而，我们没有明确地训练这些模型来确保相似的图像具有彼此相同的嵌入。因此，在相似性搜索的上下文中，来自这种模型的嵌入可能不是对所有用例都是最准确的。你现在可能会问的自然问题是，<em class="pa">“有没有一种方法可以训练模型，使得相似的图像具有彼此相似的嵌入？”</em>谢天谢地，有！</p><h1 id="ed6c" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">用度量学习目标预训练的卷积神经网络</h1><p id="4323" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">进入<a class="ae ky" href="https://paperswithcode.com/task/metric-learning?page=6" rel="noopener ugc nofollow" target="_blank">度量学习</a>，这是生成嵌入的最有前途的方法之一，尤其是对于相似性搜索应用。在最基本的层面上，在度量学习中，</p><ol class=""><li id="cb97" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我们使用诸如CNN或Transformer网络之类的神经网络来将图像转换成嵌入。</li><li id="0b9a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们构建这些嵌入，使得语义相似的图像彼此聚集得更近，而不相似的图像则相距更远。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/a778d6784100586511a32ba9d2aae7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Rtsf0K6vQco305k7.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">向量空间中的手写数字图像示例。图片来源:<a class="ae ky" rel="noopener" target="_blank" href="/contrastive-loss-explaned-159f2d4a87ec">媒体博文</a>作者<a class="ae ky" href="https://medium.com/@rantlab?source=post_page-----159f2d4a87ec-----------------------------------" rel="noopener">布莱恩·威廉斯</a>。经允许重新发布。</p></figure><p id="2912" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练度量学习模型需要数据处理方式和模型训练方式的创新。</p><ol class=""><li id="33b1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">数据:</strong>在度量学习中，对于每个称为“锚”图像的源图像，我们需要至少一个称为“正”的相似图像我们也可以合并一个不同的第三个图像，称为“负”，以改善嵌入表示。在最近针对每个源图像的<a class="ae ky" href="http://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank">度量学习</a>方法中，我们使用各种数据扩充综合生成一个“锚”和一个“正面”图像，如下图所示。由于两个图像都是同一源图像的变体，因此将它们标记为锚定阳性对是合乎逻辑的。另一方面，我们通过拍摄同一批图像中除“锚”以外的所有图像，合成生成“底片”。</li><li id="8052" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">模型:</strong>度量学习模型大多有一个<a class="ae ky" href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" rel="noopener ugc nofollow" target="_blank">连体网络架构</a>。锚定图像、正图像和负图像依次通过相同的模型来生成嵌入，然后我们使用特殊的损失函数来比较这些嵌入。这样的损失函数之一被称为<a class="ae ky" href="http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf" rel="noopener ugc nofollow" target="_blank">对比损失</a>，其中模型的目标是将锚图像和正图像的嵌入移动得更近，使得它们之间的距离接近0。相反，该模型旨在将锚和负嵌入彼此远离，使得它们之间的距离很大。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/275a27195acc6bfc07d194743833ac54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*2hwgIxqey6jE980YKtN9pA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">锚点和正片都是同一源图像的增强版本。图片由作者使用具有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>中的图片制作。受谷歌人工智能博客的启发</p></figure><p id="215e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在用这种方法训练模型之后，我们可以通过使用诸如余弦距离之类的度量以数学方式计算它们的嵌入向量之间的距离来找到任意两个图像之间的相似性。如这篇<a class="ae ky" rel="noopener" target="_blank" href="/9-distance-measures-in-data-science-918109d069fa">中型博客文章</a>所示，存在几种距离度量，余弦距离常用于比较嵌入。</p><h2 id="c1d7" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">SimCLR:简单对比学习</h2><p id="433d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><a class="ae ky" href="http://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>代表视觉表征对比学习的简单框架。这是使用一种称为对比学习的度量学习来生成图像嵌入的流行方法之一。在对比学习中，对比损失函数比较两个嵌入是相似的(0)还是不相似的(1)。</p><p id="aac9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SimCLR的伟大之处在于它是一个简单的自我监督算法(我们不需要图像类的任何标签！)实现了与一些监督方法相当的性能，如下图所示！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/a2a0892787d688f7e20706ff9178701c.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/0*yN7Y53toygk25aYl.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">自监督SimCLR 4X实现了与完全监督ResNet50相似的精度！图片来源:<a class="ae ky" href="http://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank">arxiv.org的SimCLR论文</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/341ac25706ce2e13ffbc42a09e5a5ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GiauvdwsIPWa0ZDc.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">可能的图像数据增强的例子。图片来源:<a class="ae ky" href="http://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank">arxiv.org的SimCLR论文</a></p></figure><p id="8b8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SimCLR的基本思想如下。</p><ol class=""><li id="ed1c" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">给定一幅图像，创建同一幅图像的两个增强版本。这些增强可以是裁剪和调整大小、颜色失真、旋转、添加噪声等。上图展示了一些增强的例子。</li><li id="d689" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">一批中所有图像的增强版本通过CNN编码器，将图像转换为嵌入内容。这些CNN嵌入然后通过一个简单的只有一个隐藏层的多层感知器(MLP)将它们转换到另一个空间。</li><li id="7b3f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">最后，使用余弦距离对MLP输出端的嵌入进行相互比较。该模型期望来自同一图像的增强的余弦距离为0，而来自不同图像的增强的余弦距离为1。损失函数然后更新CNN和MLP的参数，使得嵌入更接近我们的期望。</li><li id="5c3e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">一旦训练完成，我们不再需要MLP，直接使用CNN编码器的输出作为我们的嵌入。</li></ol><p id="4612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图从概念上解释了整个过程。更多细节，请看这篇谷歌<a class="ae ky" href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html" rel="noopener ugc nofollow" target="_blank">博客文章</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/f41224a202f85691a8946cfdc4d74abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KBq9SpUBRiRzPgDIjkGkAg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SimCLR概念性解释。图片由作者使用来自<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>的图片，拥有GPL 2许可证。受<a class="ae ky" href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html" rel="noopener ugc nofollow" target="_blank">谷歌人工智能博客</a>的启发</p></figure><p id="50fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作者进行了几次实验，并确定随机裁剪和颜色失真是增强的最佳组合，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/fe0b9de8ce1afeae1d6021eadb1d627e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ypos3Ua_UF9KYB6C.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同数据集扩充的下游模型精度。图片来源:<a class="ae ky" href="http://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank">arxiv.org的SimCLR论文</a></p></figure><p id="feae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像towhee一样，我们使用其他研究人员在ImageNet上预先训练的模型来直接提取SimCLR嵌入。然而，在撰写本文时，为了获得SimCLR预训练嵌入，我们需要使用Pytorch <a class="ae ky" href="https://github.com/PyTorchLightning/lightning-bolts" rel="noopener ugc nofollow" target="_blank"> Lightning Bolts </a>库编写几行代码。我改编了官方闪电文件<a class="ae ky" href="https://pytorch-lightning-bolts.readthedocs.io/en/latest/self_supervised_models.html" rel="noopener ugc nofollow" target="_blank">中的以下内容。首先，在终端窗口中使用<code class="fe om on oo op b">pip</code>安装必要的库。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="3316" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，在Jupyter笔记本单元中，让我们导入必要的库，并根据您的计算机是否有GPU将设备设置为<code class="fe om on oo op b">cuda</code>或<code class="fe om on oo op b">cpu</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="98f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们加载预先在ImageNet上训练的SimCLR模型，并将其设置为eval模式，因为我们只想从模型中获得嵌入，而不想再训练它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="9bf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下两个步骤是Pytorch特有的；用于实现模型的基础库。我们首先创建一个数据集，它可以将我们的dataframe作为输入，从<code class="fe om on oo op b">img_path</code>列中读取图像，应用一些转换，最后创建我们可以输入到模型中的批量图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="fb95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们可以迭代dataloader中的批处理，为所有图像生成嵌入，并将它们作为一列存储回我们的dataframe。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/b2957b444050c324a26b353841dd340b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuYRZwouFyD8kwHcWcM-Yw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SimCLR嵌入生成后数据帧的前5行。作者图片</p></figure><p id="86c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在有趣的部分来了！我们可以用相同的帮助函数测试SimCLR嵌入的质量。我们从数据框中查询随机图像并显示<code class="fe om on oo op b">k</code>最相似的图像。如下所示，SimCLR嵌入也能准确地为我们运行的每个查询找到相似的图像！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/84a03438eae926225823f06ef379aa20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMamVLfKI_kuJ0Z9yV6kIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机查询图像和来自SimCLR嵌入的前5个最相似的图像。作者使用具有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>中的图像制作图片。</p></figure><h1 id="f3c6" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">用度量学习目标预训练的图文多模态神经网络</h1><p id="3034" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">最后，将图像和文本嵌入到统一嵌入空间的模型有了巨大的改进[ <a class="ae ky" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank"> Open AI的回形针</a>，<a class="ae ky" href="http://arxiv.org/abs/2102.05918" rel="noopener ugc nofollow" target="_blank"> Google的ALIGN Paper </a>，<a class="ae ky" href="http://arxiv.org/abs/2004.00849" rel="noopener ugc nofollow" target="_blank">微软的PixelBERT Paper </a> ]，这开启了图像到文本和文本到图像相似性搜索的几个优秀应用。这种范式中最流行的模型之一是<a class="ae ky" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank"> CLIP(对比语言-图像预训练)</a>。</p><p id="45f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CLIP是建立在度量学习框架上的神经网络。CLIP使用图像作为锚点，相应的文本描述作为正面来构建图像-文本对，而不是在纯粹的图像锚点-正面对上进行训练。我们可以在多种应用中使用CLIP，包括文本到图像、图像到文本、图像到图像和文本到文本的相似性搜索。</p><p id="cb9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像通过ResNet或<a class="ae ky" href="http://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> ViT </a>编码器生成图像嵌入。文本描述通过基于转换器的编码器来生成文本嵌入。CLIP联合训练图像和文本编码器，以便在一批<em class="pa"> N个</em>图像-文本对中，嵌入第<em class="pa">个</em>图像与嵌入第<em class="pa">个</em>个文本的点积最高，如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/d3a1d0479678cc845ebeb892c27c88ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K5WjVFfmTYVMR6jY.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CLIP的对比预训练。图片来源:<a class="ae ky" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank">回形针</a>arxiv.org</p></figure><p id="f37f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练完成后，我们可以找到与查询图像最相似的文本行，只需将两者转换为各自的嵌入，然后使用点积或余弦距离进行比较，如下图所示。相反，我们也可以用同样的方式搜索给定查询文本的最相似的图像。让我们看看如何在我们的示例问题上实现这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/d81c6287ca1d3eed56e9e05b5e82c399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pjbox2REj14IhARW.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预测期间剪辑。图片来源:<a class="ae ky" href="https://arxiv.org/abs/2103.00020" rel="noopener ugc nofollow" target="_blank">回形针</a>arxiv.org</p></figure><h2 id="4f56" class="nx mk it bd ml ny nz dn mp oa ob dp mt li oc od mv lm oe of mx lq og oh mz oi bi translated">句子变形金刚</h2><p id="d1e5" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">使用优秀的<a class="ae ky" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子-变形库</a>，在我们的数据上生成剪辑嵌入非常简单。然而，由于操作系统对我们一次可以打开的文件数量的限制，当处理成千上万的图像时，我们需要编写几行样板代码。首先，在终端窗口中使用<code class="fe om on oo op b">pip</code>安装必要的库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="5fae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，在Jupyter笔记本单元格中，让我们导入库并实例化一个剪辑模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="c71b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们需要迭代10K映像，以绕过操作系统对一次可以打开的文件数量的限制。我们在每次迭代中加载所有图像，并生成剪辑嵌入。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/a90f1d7a8c8d4686f4ba762ba73e98c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DDvlPzwvbzSbjO7gyzOK5g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧后剪辑图像嵌入生成的前5行。作者图片</p></figure><p id="ed84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了所有图像的剪辑嵌入，我们可以使用相同的辅助函数来测试嵌入的质量。我们从数据帧中查询随机图像，并显示<code class="fe om on oo op b">k</code>个最相似的图像。如下所示，剪辑嵌入也非常准确，可以为我们运行的每个查询找到相似的图像！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/8515f902f9938f9b3603643d3be793cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIn67nV_wQd7bnz4Y3eHOA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机查询图像和来自剪辑图像嵌入的前5个最相似的图像。图片由作者使用具有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>中的图片制作。</p></figure><p id="8142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们不得不编写一些额外的代码来生成剪辑嵌入，但它提供的一个显著优势是文本到图像的搜索。换句话说，我们可以搜索匹配给定文本描述的所有图像。下面我们来看看这个。</p><p id="25c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们已经将图像转换为剪辑嵌入，现在我们只需要将文本查询转换为剪辑嵌入。然后，我们可以通过使用文本嵌入和数据帧中所有图像嵌入之间的余弦相似性来搜索相似产品。我们将编写一个简单的助手函数来为我们完成所有这些工作，如下所示。最后，我们将绘制所有相似的<code class="fe om on oo op b">k</code>产品图片。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><p id="8ed7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用助手函数来测试示例文本查询。如下图所示，如果我们的测试查询是“一件女装的照片”，那么最相似的产品都是女装！即使每个产品的标题没有明确指定单词“连衣裙”，剪辑模型也能够仅从文本和图像嵌入中推断出这些图像与查询“一件女装的照片”最相关。继续用其他查询进行尝试吧！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者代码</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/e2932fa6444c7a644205f7fa94ab318d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6F3b0JGzR_nsIX-KKL8C_A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机查询图像和来自剪辑文本嵌入的前5个最相似的图像。图片由作者使用具有GPL 2许可证的<a class="ae ky" href="https://www.kaggle.com/masouduut94/digikala-color-classification" rel="noopener ugc nofollow" target="_blank"> Digikala产品颜色分类数据集</a>中的图片制作。</p></figure><h1 id="79aa" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="dcc9" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">深度学习研究和开源代码库的当前技术水平已经开辟了许多从图像和文本数据生成高质量嵌入的简单方法。这些现成的嵌入是为许多现实世界的问题构建原型的极好起点！下面的流程图可以帮助选择要使用的初始嵌入。然而，在将任何一个单一的查询部署到生产环境之前，要不断地评估嵌入模型在一些复杂的样本查询上的准确性！</p><p id="7e12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谈到生产，我们在这里使用的数据集是一个只有6K图像的玩具数据集。在现实世界的应用程序中，例如电子商务商店，您需要在几分之一秒内嵌入、存储和执行最近邻搜索数亿张产品图像！这个问题的规模需要使用强大的矢量搜索数据库，如<a class="ae ky" href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank"> Milvus </a>！你可以在这里了解更多关于矢量数据库<a class="ae ky" href="https://zilliz.com/learn/what-is-vector-database" rel="noopener ugc nofollow" target="_blank">的信息。</a></p><p id="94bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请访问Zilliz的<a class="ae ky" href="https://zilliz.com/learn" rel="noopener ugc nofollow" target="_blank">“学习”频道</a>以获得更多关于嵌入和向量相似性数据库的各种酷应用的灵感！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/1a2b35b2467e763fbc779d55402edb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*eewWICsIKJMaH6jlg9b0vA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">选择嵌入方法。作者图片</p></figure></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="09ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="pa">原载于2022年1月24日https://zilliz.com</em><em class="pa"/><a class="ae ky" href="https://zilliz.com/learn/embedding-generation" rel="noopener ugc nofollow" target="_blank"><em class="pa">。</em></a></p></div></div>    
</body>
</html>