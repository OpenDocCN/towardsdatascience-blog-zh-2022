<html>
<head>
<title>Learning how GPT-3 instruct models were (most likely) trained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解GPT-3教学模型(很可能)是如何训练的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-how-gpt-3-instruct-models-were-most-likely-trained-3eb61e0f4169#2022-01-17">https://towardsdatascience.com/learning-how-gpt-3-instruct-models-were-most-likely-trained-3eb61e0f4169#2022-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="dc13" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">了解GPT-3教学模型(很可能)是如何训练的</h1></div><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/8125d0cfdabcb03a5c32ad707f156262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lSqEL9JQXPVdqoyELHzViQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">斯文·布兰德斯马在<a class="ae kc" href="https://unsplash.com/s/photos/word?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="fa3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">【更新</strong>:2022年1月27日，Open AI发表了一篇名为<em class="lb">排列语言模型以遵循指令</em>的论文，其中他们解释了他们真正用来训练InstructGPT的方法。你可以在这里找到论文<a class="ae kc" href="https://openai.com/blog/instruction-following/" rel="noopener ugc nofollow" target="_blank"/>。]</p><p id="4bb2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几个月前，OpenAI发布了他们位于GPT的指令模型的测试版。Open AI声称，指令模型可以像人类一样理解你的指令，并且它们仍然拥有与其他GPT-3基础模型相同的能力。</p><p id="1baa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一进步为设计和工程师带来了更多创新提示的可能性。你可以告诉模型你的任务是什么，你想得到的结果是什么，模型会尽力理解你的指令并完成它们。</p><p id="fd95" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<a class="ae kc" href="https://www.flowrite.com/" rel="noopener ugc nofollow" target="_blank"> Flowrite </a>，我们每天都在使用GPT-3模型，所以我们没有等待一秒钟，就开始广泛测试这些指令模型。</p><div class="lc ld gp gr le lf"><a href="https://www.flowrite.com/" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab fo"><div class="lh ab li cl cj lj"><h2 class="bd ir gy z fp lk fr fs ll fu fw ip bi translated">Flowrite -增强您的日常沟通</h2><div class="lm l"><h3 class="bd b gy z fp lk fr fs ll fu fw dk translated">Flowrite将简短的指令转化为可随时发送的电子邮件和信息，供您在浏览器中浏览。谢谢大家！你的…</h3></div><div class="ln l"><p class="bd b dl z fp lk fr fs ll fu fw dk translated">www.flowrite.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt jw lf"/></div></div></a></div><p id="76ec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们对这些指导模型是如何工作的有了一个坚实的直觉，但是Open AI从未发表过关于指导模型如何被训练的论文或文章，所以这个问题仍然是未知的。幸运的是，谷歌研究团队在2021年12月就同一主题发表了一篇<a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，该论文揭示了基于transformer的模型如何被微调以理解指令。</p><p id="b24c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看这篇文章中最重要的方面，这将帮助我们理解如何微调大型语言模型，以便它们能够处理指令提示。</p><h1 id="e166" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">微调模型是零射击学习者</h1><p id="51f0" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">正如您可能已经发现的那样，本文围绕大型语言模型执行零触发任务的能力以及指令调优如何提高这些模型的零触发能力展开。</p><blockquote class="mx my mz"><p id="f953" class="kd ke lb kf b kg kh ki kj kk kl km kn na kp kq kr nb kt ku kv nc kx ky kz la ij bi translated">零射击学习(ZSL)是机器学习中的一个问题设置，在测试时，学习者观察训练中没有观察到的来自班级的样本，并需要预测它们所属的班级。— <a class="ae kc" href="https://en.wikipedia.org/wiki/Zero-shot_learning" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></blockquote><p id="3d49" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大规模的语言模型，如GPT-3，具有巨大的少量学习能力，但在零次学习中表现较差。在几项任务(阅读理解、质量保证和NGI)中，GPT-3零发成绩比少发成绩差得多。在零镜头设置中，提示没有少量镜头/上下文中的示例，模型可能很难表现良好，这可能是因为它们无法找到与预训练数据的相似性。</p><p id="6669" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">指令调优</strong>被描述为微调预训练语言模型(LM)的任务，以提高其响应自然语言指令的能力。这个想法是，通过使用监督来教LM执行通过指令描述的任务，它将学会遵循指令，甚至对看不见的任务也这样做。</p><p id="3a94" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者的指令在通过自然语言指令模板表达的60个NLP数据集上微调了137B参数预训练语言模型。由此产生的微调模型被称为FLAN，正如我们将要看到的，它是在看不见的任务类型上进行评估的，这些任务类型显示了在其他机器学习设置中(例如，少量学习)相对于其他语言模型在许多任务中的性能改善。</p><h2 id="9f5f" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">数据集</h2><p id="a60c" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">对于教学微调，谷歌研究团队必须将超过60个NLP数据集的混合物转换为教学格式。这些数据集在<a class="ae kc" href="https://www.tensorflow.org/datasets?hl=es-419" rel="noopener ugc nofollow" target="_blank"> TensorFlow数据集</a>中公开。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/3c673e198d82c633f0083f312c1b2b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulfmLMFc6nj8Sp5jvUAdRw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">用于指令微调的公开可用数据集。数据集被转换成教学格式，并按任务聚集成簇。——图来自<a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">微调过的模特是零起点的学习者</a>由<a class="ae kc" href="https://research.google/research-areas/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">谷歌研究团队</a></p></figure><p id="a5d7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者根据任务将数据集聚集成簇:常识、自然语言推理(NLI)、情感等。然后，对于每个数据集，他们创建了10个描述任务的独特的指令提示模板。为了增加数据的多样性，10个模板中有3个指示模型改变任务。例如情感分类→生成一条情感正面的影评。</p><p id="d5c8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，通过随机选择特定于每个数据集的指令提示模板，对每个数据集进行格式化。</p><p id="b1c8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下图中，作者说明了如何创建指令提示来构建用于指令微调的数据集:</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/733b9540e51301d031dacadd12e0712f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3AlBQexVofo_O8M3DCCgQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">描述自然语言推理任务的多个指令模板——图来自<a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">微调模型是零射击学习者</a>由<a class="ae kc" href="https://research.google/research-areas/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">谷歌研究团队</a></p></figure><h2 id="f41b" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">估价</h2><p id="06fb" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">作者感兴趣的是评估FLAN如何执行在指令调优期间没有看到的任务，因此有必要清楚地定义什么算作看不见的任务。</p><p id="9745" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果在指令调优期间没有看到来自<em class="lb"> D </em>所属的任何任务集群的数据集，他们在评估时定义了一个看不见的数据集<em class="lb"> D </em>。例如，让我们假设<em class="lb"> D </em>是一个包含任务，那么该包含集群被忽略用于指令调整，并且只使用所有其他集群。</p><p id="4cb4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者将数据集分组到任务簇中，并支持评估簇，同时指示对所有剩余簇进行调优。通过这种方式，他们确保果馅饼是在看不见的任务上被评估的。</p><h2 id="dae9" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">带选项的分类</h2><p id="8c7f" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">FLAN是一种专用于解码器的语言模型(如GPT ),针对不同的任务进行指令调整，因此，它会将完成的内容返回给输入文本。</p><p id="9426" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分类任务的输出空间是特定于当前问题的几个唯一类之一。例如，如果我们使用仅解码器语言模型执行二元分类(“是”或“否”)，我们需要记住，该模型仍在生成文本，并且大量不同的回答“是”的方式可能会降低分配给标记“是”的概率质量。</p><p id="6667" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如作者所述，在表达相同答案的备选方案中具有不期望分布的答案的概率质量使得一些方法如<em class="lb">等级分类</em>(考虑2个输出，并且2个输出之间最可能的是预测)<em class="lb"> </em>不完美。</p><p id="4afe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解决分类任务中的这个潜在问题，作者提出了<strong class="kf ir">选项后缀</strong>。Options后缀是一个附加到分类任务末尾的标记，附带一个唯一输出类的列表，因此模型被限制为仅响应其中一个类。</p><h2 id="f881" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">培养</h2><p id="f698" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">模型架构是一个密集的从左到右，只有137B参数的解码器转换器语言模型。该模型在网络文档、对话数据等方面被预先训练。使用<a class="ae kc" href="https://github.com/google/sentencepiece" rel="noopener ugc nofollow" target="_blank"> SentencePiece </a>库，该文本被标记为2.49T的32k词汇量的BPE标记。此外，作者在预训练数据集中包括了大约10%的非英语文本。</p><p id="a8a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">得到的预训练模型被称为基本LM，因此FLAN是基本LM的指令调整版本。</p><p id="abe3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于指令微调，作者建立了管道来混合所有数据集，并从其中随机采样。</p><h2 id="f2bf" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">结果</h2><p id="0017" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">在自然语言推理、阅读理解、闭卷问答、翻译、常识推理、共指消解和结构转文本方面对FLAN进行了评估。</p><p id="8621" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是结果的简要总结。更多细节可以在<a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>中找到。</p><ul class=""><li id="7f6e" class="nv nw iq kf b kg kh kk kl ko nx ks ny kw nz la oa ob oc od bi translated">在25个任务中，零发子弹的FLAN在20个任务中超过了零发子弹的GPT-3，甚至在10个任务中超过了GPT-3的少发子弹性能</li><li id="6de1" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la oa ob oc od bi translated">指令调优显著提高了大多数任务的基本LM。</li></ul><p id="9df2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者表示，总的来说，指令调优对于由人类自然表述为指令的任务(NLI、QA、翻译、结构到文本)更有效，而对于可以直接表述为语言建模的任务(常识推理和指代消解任务，格式为完成不完整的句子或段落)，该模型则不太有效。这背后的直觉是，在后一种情况下，指令可能被认为是多余的，因此，它们不会添加太多信息。</p><h2 id="0741" class="nd lv iq bd lw ne nf dn ma ng nh dp me ko ni nj mi ks nk nl mm kw nm nn mq no bi translated">消融研究——包含少量实例的说明</h2><p id="c5ae" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">该论文的作者介绍了一些消融研究。其中最有趣的一个研究了指令调优的能力，在提示中的推断时间提供了一些例子。</p><p id="07f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">他们在零投提示的基础上建立了一个少投学习提示，如下所示:</p><p id="c53a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于输入<em class="lb"> x </em>和输出<em class="lb"> y，</em>让<em class="lb">指令(x) </em>表示零炮指令。给定<em class="lb"> k </em>少量拍摄的例子:</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/8d1b724e383e2dcd11f3e73e5a47c41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*JmO3q2-t_AVi6LHlZ0irpQ.png"/></div></figure><p id="6e75" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和一个新的输入<em class="lb"> x </em>，少拍提示的指令格式定义为</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ok"><img src="../Images/9deb4eb62f9280c13922a4369079a819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uFfdQQ_Abq6pRDP17ELumw.png"/></div></div></figure><p id="16f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中指令由输入填充，并通过中间的分隔符标记与输出连接。</p><p id="c7d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提示中提供的示例的最大数量限制为16个，这些示例是从训练集中随机抽取的。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ol"><img src="../Images/91dbd4332e0c818e8bb013fedc37ec32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7UmtKk1SDQZ8CgEEkXQPA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">零注果馅饼对少注果馅饼。橙色条表示模板之间的标准偏差，是每个聚类在数据集级别的平均值——来自<a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">微调模型的数字是零射击学习者</a>来自<a class="ae kc" href="https://research.google/research-areas/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">谷歌研究团队</a></p></figure><p id="71c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以看出，与零镜头设置相比，在提示中添加少量镜头的例子提高了FLAN在所有任务中的性能。在复杂的任务中，如结构到文本或QA，这些改进更大。这实际上是有意义的，因为这些任务的输出空间更大，上下文中的示例有助于模型更好地理解输出格式，因此在零触发设置中比FLAN执行得更好。</p><h1 id="63e4" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">摘要</h1><p id="7192" class="pw-post-body-paragraph kd ke iq kf b kg ms ki kj kk mt km kn ko mu kq kr ks mv ku kv kw mw ky kz la ij bi translated">在这篇文章中，我试图总结谷歌研究团队<a class="ae kc" href="https://research.google/research-areas/natural-language-processing/" rel="noopener ugc nofollow" target="_blank">的论文</a><a class="ae kc" href="https://arxiv.org/pdf/2109.01652.pdf" rel="noopener ugc nofollow" target="_blank">中最重要的概念。</a></p><p id="f91c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您听说过GPT-3指令模型，但不知道这些模型是如何训练的，我希望这篇摘要和本文能让您对指令调整及其好处有一个良好的直觉。</p><p id="19cf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于开放人工智能没有发表关于指令模型的论文，我们不能完全肯定GPT-3指令模型是按照这里介绍的完全相同的程序训练的，但很可能他们采用了非常相似的技术。</p><p id="e367" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.linkedin.com/in/bernardo-garc%C3%ADa-del-r%C3%ADo-b4a98873/" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">如果你想在LinkedIn上和我联系，就给我发个纸条！:)</strong>T17】</a></p><h1 id="e0c6" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">参考</h1><ol class=""><li id="14de" class="nv nw iq kf b kg ms kk mt ko om ks on kw oo la op ob oc od bi translated">微调过的语言模型都是零命中率的学习者——<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+J" rel="noopener ugc nofollow" target="_blank">贾森·魏</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosma%2C+M" rel="noopener ugc nofollow" target="_blank">马腾·博斯马</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+V+Y" rel="noopener ugc nofollow" target="_blank">文森特·y·赵</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Guu%2C+K" rel="noopener ugc nofollow" target="_blank">凯尔文·古</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu%2C+A+W" rel="noopener ugc nofollow" target="_blank">亚当斯·禹卫</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lester%2C+B" rel="noopener ugc nofollow" target="_blank">布莱恩·莱斯特</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Du%2C+N" rel="noopener ugc nofollow" target="_blank">杜南</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+A+M" rel="noopener ugc nofollow" target="_blank">安德鲁·m·戴</a>、<a class="ae kc" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+Q+V" rel="noopener ugc nofollow" target="_blank">郭诉勒</a></li><li id="f140" class="nv nw iq kf b kg oe kk of ko og ks oh kw oi la op ob oc od bi translated">开放AI API文档—<a class="ae kc" href="https://beta.openai.com/docs/engines/instruct-series-beta" rel="noopener ugc nofollow" target="_blank">https://beta.openai.com/docs/engines/instruct-series-beta</a></li></ol></div></div>    
</body>
</html>