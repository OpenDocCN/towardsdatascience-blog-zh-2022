<html>
<head>
<title>AI Got Your Back Segmented (PyTorch)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能让你的背部分段(PyTorch)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-got-your-back-segmented-pytorch-72ef14856db6#2022-01-06">https://towardsdatascience.com/ai-got-your-back-segmented-pytorch-72ef14856db6#2022-01-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="4ddc" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">人工智能让你的背部分段(PyTorch)</h1></div><div class=""><h2 id="d11a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于脊柱的UNet分割</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/95b5d6d2347b87b5391576ccc59e66d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*BAdOcsdaRUSmvmHdXVC9Mg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片部分由<a class="ae ky" href="http://grand-challenge.org" rel="noopener ugc nofollow" target="_blank">本来源</a>部分由作者提供</p></figure><p id="ad6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着我们每天收集更多的数据，人工智能(AI)将越来越多地用于医疗保健领域。医疗保健中人工智能应用的一个关键类别是诊断。医疗诊断中的人工智能有助于决策、管理、自动化等。</p><p id="2d68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">脊柱是肌肉骨骼系统的重要组成部分，支撑着身体及其器官结构，同时在我们的流动性和负荷转移方面发挥着重要作用。它还能保护脊髓免受冲击造成的损伤和机械冲击。</p><p id="dd26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在自动脊椎处理流水线中，脊椎标记和分割是两个基本任务。脊柱图像的可靠和精确处理有望有益于临床决策支持系统，用于脊柱和骨骼健康的诊断、手术计划和基于群体的分析。设计用于脊柱处理的自动算法是具有挑战性的，这主要是由于解剖和采集协议中的相当大的变化以及公开可用数据的严重缺乏。</p><p id="62b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇博客中，我将只关注给定CT扫描数据集中的脊柱分割。标记每个椎骨和进一步诊断的任务没有包括在这个博客中，可以作为这个任务的继续。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="11d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">脊柱或椎骨分割在所有关于脊柱形态学和病理学的自动量化的应用中是至关重要的步骤。随着深度学习的出现，对于计算机断层扫描(CT)扫描这样的任务，大量不同的数据是主要的受欢迎资源。但是，目前还没有大规模的公共数据集。<a class="ae ky" href="https://github.com/anjany/verse" rel="noopener ugc nofollow" target="_blank">VerSe I</a>是一个大规模、多探测器、多站点的CT脊柱数据集，由来自355名患者的374次扫描组成。2019年和2020年的数据集都有。在这篇博客中，我将两个数据集合并成一个数据集，以便从更多的数据中获益。</p><div class="mc md gp gr me mf"><a href="https://github.com/anjany/verse#download" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">GitHub - anjany/verse:关于“大规模椎骨分割挑战”的一切</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">仔细观察脊柱，寻找疾病的原因--希波克拉底诗句的例子。观察数据的可变性…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">github.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt ks mf"/></div></div></a></div><p id="d0d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mu mv mw mx b"><em class="my">The data is provided under the CC BY-SA 4.0 License, making it fully open-sourced.</em></code></p><p id="5750" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NIfTI(神经成像信息学技术倡议)是一种用于神经成像的文件格式。NIfTI文件在神经科学甚至神经放射学研究的成像信息学中非常常用。每个NIfTI文件包含多达7维的元数据和体素，并支持各种数据类型。前三个维度被保留来定义三个空间维度<em class="my"> x </em>、<em class="my"> y、</em>和<em class="my"> z </em>，而第四维被保留来定义时间点<em class="my"> t </em>。剩下的维度，从第五到第七，则是其他用途。然而，第五维度仍然可以有一些预定义的用途，例如存储体素特定的分布参数或保存基于向量的数据。VerSe数据集包含NIfTI文件的zip文件。</p><p id="2136" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="http://www.itksnap.org" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> ITK快照</strong> </a>是一款用于分割3D医学图像中结构的软件应用。它是可以安装在不同平台上的开源软件。我已经使用它能够在3D视图中可视化NifTi文件，并在原始图像上加载和覆盖3D蒙版。我强烈推荐在这个任务中使用它。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/084123ffb286ba587dd9ba43e0640d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*VuwW4M6GA_orc7mgIjWaGA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CT扫描机— <a class="ae ky" href="https://www.mayoclinic.org/" rel="noopener ugc nofollow" target="_blank">图像来源</a></p></figure><p id="3ce8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">计算机断层扫描</strong> (CT)是一种x射线成像程序，在该程序中，一束狭窄的x射线在围绕身体快速旋转的同时瞄准患者。机器收集的信号将被存储在计算机中，以生成身体的横截面图像，也称为“切片”。这些切片被称为断层图像，包含比传统x射线更详细的信息。一系列切片可以数字地“堆叠”在一起，以形成患者的3D图像，该图像允许更容易地识别和定位基本结构以及可能的肿瘤或异常。</p><p id="ce7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">动作步骤如下。我开始下载2019年和2020年的数据集。然后，我将两个数据集合并到它们的训练、验证和测试文件夹中。下一步是读取CT扫描图像，并将CT扫描图像的每个切片转换为一系列PNG原始图像和蒙版。后来我使用了这个<a class="ae ky" href="https://github.com/milesial/Pytorch-UNet" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中的UNet模型，并训练了一个细分模型。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="b479" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据理解:</strong>在开始数据处理和训练之前，我想加载几个NIfTI文件，以便更熟悉它们的3D数据结构，并能够可视化它们和从图像中提取元数据。</p><p id="6c25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下载完VerSe数据集后，我能够使用NiBabel库打开一个<em class="my"> .nii.gz </em>文件(解释如下)。通过读取一个文件并查看CT扫描图像的一个特定切片，我能够运行Numpy transpose函数来查看轴向、矢状和冠状三个不同视图中的一个切片。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/51a8fb1769d752215558149dbed4d4e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAA2E135GUp5CcZHlKsPMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三个不同角度的CT扫描切片——图片由作者提供</p></figure><p id="3712" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我更加熟悉原始图像并且能够从原始3D图像中取出一个切片后，现在是时候查看同一切片的蒙版文件了。正如你在下图中看到的，我能够在原始图像切片上叠加蒙版切片。我们在这里看到渐变颜色的原因是，遮罩文件不仅定义了存在的每个椎骨的区域，而且它们还具有不同的标签(用不同的颜色显示),即每个椎骨的编号或标签。为了更好地理解脊柱标签，你可以参考<a class="ae ky" href="https://en.wikipedia.org/wiki/Vertebral_column#Vertebrae" rel="noopener ugc nofollow" target="_blank">这一页</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/fa4523e0d5e994a2b7465642ca40fa5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*IFxQO_hCcHxtjHZJXvdQhg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将蒙版数据叠加在原始图像的一个切片上—按作者分类的图像</p></figure><p id="5d0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据准备:</strong>数据准备的任务是从原始图像和掩模文件中生成每个3D CT扫描文件的图像切片。它从在<em class="my">中读取原始和掩模图像开始。zip" </em>格式，并将它们转换成Numpy数组。然后浏览每幅3D图像，检查每幅图像的视角，并尝试将大多数图像转换为矢状视图。接下来，我从每个切片生成了<strong class="lb iu"> PNG </strong>文件，并将它们存储为灰度值“L”格式。在这种情况下，我们不需要生成RGB图像，因为每个CT扫描切片都只有1D值。</p><p id="e5b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这项任务中，我使用了<strong class="lb iu"> UNet </strong>架构来对数据集应用<strong class="lb iu">语义分段</strong>。为了更好地了解UNet和语义分割，我推荐查看这个博客。</p><p id="f14f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还使用了<strong class="lb iu"> Pytorch </strong>和<strong class="lb iu"> Pytorchvision </strong>来完成这个任务。正如我提到的<a class="ae ky" href="https://github.com/milesial/Pytorch-UNet" rel="noopener ugc nofollow" target="_blank">这个回购</a>使用PyTorch很好地实现了UNet，我一直在使用其中的一些代码。</p><p id="2b5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我正在处理NIfTI文件，并且能够用python阅读这些文件，我将使用<a class="ae ky" href="https://nipy.org/nibabel/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">ni Abel</strong></a><strong class="lb iu"/>库。NiBabel是一个python库，用于读写一些常见的医学和神经成像文件格式，如NIfTI文件。</p><p id="cd0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Dice Score: </strong>为了评估我们的模型在语义分割任务中的表现，我们可以使用Dice Score。Dice系数是2 *重叠面积(在预测遮蔽面积和真实遮蔽面积之间)除以两幅图像中的像素总数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/906253077a96d7c097590859a03c410e.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*0TToB9WnuSuTbX_ACP6TuA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">骰子点数— <a class="ae ky" href="https://www.kaggle.com/yerramvarun/understanding-dice-coefficient" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><p id="4360" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">训练:</strong>首先我定义了UNet类，然后定义了PyTorch数据集类，它包括读取和预处理图像。预处理任务包括加载PNG文件，将它们的大小调整为一个大小(在本例中为250x250)，然后将它们全部转换为NumPy数组和PyTorch张量。通过调用dataset类(VerSeDataset ),我们可以在我定义的批处理中准备我们的数据。为了确保raw图像和mask图像之间的映射是正确的，我曾经调用过<code class="fe mu mv mw mx b">next(iter(valid_dataloader))</code>来获取一批中的下一个项目并将其可视化。</p><p id="dc69" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">后来我把模型定义为<code class="fe mu mv mw mx b">model = UNet(n_channels=1, n_classes=1)</code>。通道数是1，因为我有一个灰度图像，而不是RGB，如果你的图像是RGB图像，你可以将通道数改为3。类的数量是1，因为我只有一个类来判断一个像素是不是椎骨的一部分。如果你的问题是多类分割，你可以设置你有多少个类就有多少个类。后来我训练了一些时期的模型。对于每一批，我首先计算损失值，通过反向传播更新参数。后来，我再次检查了所有批次，只计算了验证数据集的损失，并存储了损失值。接下来，我直观地查看了训练和验证的损失值，并跟踪了我们模型的性能。</p><p id="dda2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我保存了模型之后，我能够抓取其中一个图像，并将其传递给训练好的模型，并接收到一个预测的掩模图像。通过绘制原始、真实遮罩和预测遮罩的所有三幅图像，我能够直观地评估结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/1d579cbeb25aac0a5ae6c69dae797f5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaITjV7MdaMJLYhSkUrwbw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始图像(左)、真实蒙版(中)和预测蒙版(右)-按作者分类的图像</p></figure><p id="7172" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你从上面的图像中看到的，这个模型在矢状面和轴向上都做得很好，因为预测的遮罩与真实的遮罩区域非常相似。</p><p id="f646" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在这里找到完整的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ne nf l"/></div></figure><p id="fef8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">未来工作:</strong>这项任务也可以用3D UNet来完成，这可能是学习脊椎结构的更好方法。因为我们有每个椎骨的每个掩模区域的标签，那么我们可以进一步做多类掩模分割。此外，当图像视图为矢状时，模型性能最佳，因此可能将所有切片转换为矢状会具有最佳模型。</p><p id="e601" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p></div></div>    
</body>
</html>