<html>
<head>
<title>The Ultimate Guide: Challenges of Machine Learning Model Deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">终极指南:机器学习模型部署的挑战</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ultimate-guide-challenges-of-machine-learning-model-deployment-e81b2f6bd83b#2022-01-11">https://towardsdatascience.com/the-ultimate-guide-challenges-of-machine-learning-model-deployment-e81b2f6bd83b#2022-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="d031" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">终极指南:机器学习模型部署的挑战</h1></div><h1 id="4b82" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">动机</h1><blockquote class="kl km kn"><p id="4d1e" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">“机器学习模型部署很容易”</p></blockquote><p id="4e91" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">这是一个我听过很多次的神话。作为一个有工程背景的数据科学家，我也有这个观点，直到实际开发了一个机器学习部署(或<a class="ae lq" href="https://aipaca.ai/" rel="noopener ugc nofollow" target="_blank"> MLOps </a>)项目。从技术上讲，部署机器学习(ML)模型可能非常简单:启动一台服务器，创建一个ML <a class="ae lq" href="https://hazelcast.com/glossary/machine-learning-inference/#:~:text=Machine%20learning%20(ML)%20inference%20is,as%20a%20single%20numerical%20score.&amp;text=ML%20inference%20is%20the%20second,data%20to%20produce%20actionable%20output." rel="noopener ugc nofollow" target="_blank">推理</a> API，并将该API应用于一个现有的应用程序。不幸的是，这个工作流程太容易出现了，以至于人们往往低估了它的复杂性。事实上，我的一些ML工程师朋友抱怨说，他们的工作不被这么多人理解，例如来自不同团队的工程师、产品经理、执行团队，甚至客户。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/12506b63d5d8097c87eaeb0c31e0fc3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UXmgJWJkYtcyqhpe"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">不要根据提示来判断MLOps项目的复杂性。西蒙·李在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f557" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">通过这个故事，我希望更多的人能够理解MLOps背后的困难。我想穿上工程师裤，与你分享ML模型部署挑战的终极指南。</p><p id="ce9f" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated"><em class="kq">背景:ML工程师与数据科学家紧密合作。例如，数据科学家构建ML模型，ML工程师实现模型。</em></p><h1 id="f6cc" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">第一阶段:当一个模型刚刚交给ML工程师时</h1><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/c951040ff9cfc29e70e0592b67300016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JxFxIBao0xj58ayu"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">照片由<a class="ae lq" href="https://unsplash.com/@etaplus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> ETA+ </a>在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><blockquote class="kl km kn"><p id="330e" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kr ir">“该模型实际上无法在生产服务器上运行”</strong></p></blockquote><p id="8e3f" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">当数据科学家将他们的模型传递给ML工程师时，该模型可能无法在不同的机器上工作。这个问题通常是由<strong class="kr ir">软件</strong> <strong class="kr ir">环境变化</strong>或者<strong class="kr ir">代码质量差</strong>造成的。</p><p id="c095" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">像<a class="ae lq" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>和<a class="ae lq" href="https://kubernetes.io/" rel="noopener ugc nofollow" target="_blank"> K8s </a>这样的容器能够通过跨机器调整软件环境来解决大部分的复制问题。然而，模型容器化并不是每个数据科学家(DS)都具备的技能。如果这种情况发生，DS和ML工程师将需要额外的时间来交流知识。</p><p id="f7a7" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">另一方面，服务器和ML框架之间的编译也会导致系统错误。例如，尽管Flask + Tensorflow是许多教程中使用的组合，但有一段时间我们发现，随着环境变得越来越复杂，Flask服务器环境对Tensorflow 2并不友好。我们花了一段时间才找到解决办法。</p><p id="4428" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">数据科学家不是程序员。写代码时遵循<a class="ae lq" href="https://www.python.org/dev/peps/pep-0008/" rel="noopener ugc nofollow" target="_blank"> PEP 8指南</a>对于数据科学来说并不是必须的。一个ML工程师声称的“糟糕的代码质量”可能来自于科学家和工程师之间不同的编码习惯。Jupyter Notebook取代了VS Code等传统IDE，是一款更受数据科学家欢迎的代码编辑工具。笔记本中的编程逻辑与普通的软件开发非常不同。因此，当代码模型从Jupyter Notebook迁移出来时，它可能会出错。</p><p id="5204" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">如果生产服务器使用与开发服务器不同规格(例如，操作系统、CPU类型、GPU)的机器，那么MLOps项目将会上升到更高的复杂性水平。</p><h1 id="8aa7" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段2:当团队开始合作时</h1><p id="02bb" class="pw-post-body-paragraph ko kp iq kr b ks mh ku kv kw mi ky kz ln mj lc ld lo mk lg lh lp ml lk ll lm ij bi translated">假设来自数据科学团队的ML模型现在可以在生产环境中成功运行，那么是时候将它迁移到现有的应用程序中了。然而，在哪里以及如何在应用中使用模型来解决实际的业务问题是一个新的课题，需要跨团队的协作。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mm"><img src="../Images/55cc760c45c89a9135b8bc7b44e69ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RbP9wNRyiwr55CQU"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated"><a class="ae lq" href="https://unsplash.com/@jasongoodman_youxventures?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">杰森·古德曼</a>在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="kl km kn"><p id="3cc4" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kr ir">“我们为什么要关心……”</strong></p></blockquote><p id="e27c" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">由于分散的责任和优先权，跨团队的沟通面临许多挑战。<strong class="kr ir">工程师们关心软件的效率、系统的稳定性和易维护性</strong>。然而，大多数决策支持系统更关心ML模型的性能和严密性。为了最大化模型性能，他们总是利用各种数据科学工具。我见过DS的同事用SQL预处理数据，用R启动模型管道，然后是Sklearn，最后是Pytorch。当然，这种结构是不会被工程师欣赏的。</p><p id="3f52" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">当DS和ML工程师争论什么应该更优先时，产品经理(pm)进入舞台并要求两个团队关注路线图，因为<strong class="kr ir">pm的责任是确保产品交付按时发布</strong>。</p><p id="ff08" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated"><strong class="kr ir"> <em class="kq">“有意思，部署ML车型的门票正在引发团队辩论……”</em></strong></p><p id="da53" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">没有固定的解决方案来避免这种纠结。软件效率，ML模型性能，路线图，哪个更有意义？答案是企业与企业之间的转移，而且永远不会完美。</p><h1 id="cd54" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段3:当模型即将发布时</h1><p id="d443" class="pw-post-body-paragraph ko kp iq kr b ks mh ku kv kw mi ky kz ln mj lc ld lo mk lg lh lp ml lk ll lm ij bi translated">团队最终为了彼此的需要而妥协。工程团队还成功地将模型推理功能添加到应用程序中。一切看起来都很好，不是吗？</p><blockquote class="kl km kn"><p id="f48b" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kr ir">“等一下，模型托管服务器应该支持多少流量？”</strong></p></blockquote><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mn"><img src="../Images/2150881a82ee661ef6a06355771bd705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p_lwmstJ7_BTxkX7"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">压倒性的系统日志。由<a class="ae lq" href="https://unsplash.com/@markusspiske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Markus Spiske </a>在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4116" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">当涉及到用户吞吐量问题时，如果一家公司资源丰富，最值得推荐的解决方案是购买一组功能强大的服务器，即使在高峰时也足以处理所有流量负载。然而，用于容纳ML模型的机器是稀缺和昂贵的。8个V100核心的按需p 3.16 x大型AWS服务器的定价为每小时24.48美元，每月17625.6美元。</p><p id="0154" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">可悲的是，上述解决方案只有少数公司负担得起。对于其他公司来说，根据需要扩展计算能力更实际，但即使对于高级ML工程师来说也很有挑战性。数据搜索、并发、一致性和速度是伸缩系统中的四个常见问题。更糟糕的是，由于服务器容量的不足，ML的可扩展性更加困难:假设你的项目中最常用的云服务器叫做服务器A，在传统的扩展系统中，你只需要考虑你应该扩展到的服务器A的数量。但是在机器学习中，即使在AWS这样的大型云平台中，服务器A也并不总是具备容量，因为它是稀缺的。您的扩展策略还应该包括具有更高容量的其他类型的服务器。<a class="ae lq" href="https://en.wikipedia.org/wiki/Load_testing" rel="noopener ugc nofollow" target="_blank">负载测试</a>需要对所有种类的组合进行。还可以添加新的云平台，这样，如果服务器A在一个平台上不可用，您仍然有机会通过查找其他平台来获得一个。因此，很少有ML项目最终开发出成熟的缩放系统。</p><h1 id="fe16" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段4:当模型被部署时</h1><p id="63d9" class="pw-post-body-paragraph ko kp iq kr b ks mh ku kv kw mi ky kz ln mj lc ld lo mk lg lh lp ml lk ll lm ij bi translated">恭喜你！您最终部署了模型，但现在还不是离开的时候。</p><blockquote class="kl km kn"><p id="2576" class="ko kp kq kr b ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kr ir">“什么？挑战还没结束？”</strong></p></blockquote><p id="73de" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">即使你是一个在这个行业工作了10年的有经验的ML工程师，你的ML基础设施也不会一直在运转。其实如果你是有经验的，你应该比我更担心ML系统变质。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mo"><img src="../Images/1c87f4fdd89d74e2f220cbdecc2ed7f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mex_e9sCfjpwatEm"/></div></div><p class="md me gj gh gi mf mg bd b be z dk translated">不稳定堆积的石头。照片由<a class="ae lq" href="https://unsplash.com/@coltonsturgeon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">科尔顿鲟鱼</a>在<a class="ae lq" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3742" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">恶化来自两个方面:工程方面和数据科学方面。</p><p id="34b5" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">在工程方面，内部软件迭代可能是关闭机器的主要原因，特别是当模型部署模块与应用程序的其余部分高度集成时。当一个软件更新时，它可能会破坏其他的连接部分。隔离模块可能是一个解决方案，但是缺点是开发速度变慢，因为重用的工作减少了。同样，引入和升级外部软件包也会对系统稳定性产生负面影响。例如，当版本升级时，R包以破坏模型脚本而闻名。</p><p id="1dd0" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">在最坏的情况下，工程师可能会犯错误。曾经有一段时间<a class="ae lq" href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai" rel="noopener ugc nofollow" target="_blank"> Google Photo工程师不小心部署了一个性能很差的模型</a>，它把黑人朋友认成了“大猩猩”。</p><p id="3b28" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">在数据科学方面，随着时间的推移，<a class="ae lq" href="https://www.section.io/engineering-education/correcting-data-shift/" rel="noopener ugc nofollow" target="_blank">数据转移</a>是模型性能的一大杀手。数据偏移被定义为来自ML模型的输入和输出数据之间的潜在关系的改变。如果发生数据转移，数据科学家将需要重新训练旧模型。<a class="ae lq" href="https://www.clarifai.com/blog/closing-the-loop-how-feedback-loops-help-to-maintain-quality-long-term-ai-results" rel="noopener ugc nofollow" target="_blank">反馈回路</a>是克服数据偏移的解决方案之一。它检测性能变化，并通过新收集的数据重新训练部署的模型。是的，你是对的。这种解决方案也有不利的一面。模型可能存在严重偏差，偏差问题难以识别。</p><p id="4638" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated"><em class="kq">“假设一家杂货店使用ML模型来预测下个月的库存变化。该模型预测瓶装水是下个月最受欢迎的商品，因此店主采纳了它的建议，储备了更多的瓶装水。因为有更多的瓶装水，下个月最畅销的商品确实是瓶装水，这个数据作为新收集的数据被再次输入到ML模型中。结果，反馈回路使模型非常偏向瓶装水，总是要求所有者获得更多的瓶装水……当然，这种预测是不恰当的。”</em></p><p id="c414" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated">为了检测退化，监控系统在模型部署中是必不可少的，这也是最后一个挑战点。监视器需要是实时的，检测异常事件，发送警报，收集ML度量，跟踪模型性能，等等。</p><h1 id="6552" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结束了</h1><p id="f388" class="pw-post-body-paragraph ko kp iq kr b ks mh ku kv kw mi ky kz ln mj lc ld lo mk lg lh lp ml lk ll lm ij bi translated">这篇博客描述了工程团队在部署ML模型时可能面临的挑战。我描述了时间序列中的挑战。总结一下:</p><ol class=""><li id="26f0" class="mp mq iq kr b ks kt kw kx ln mr lo ms lp mt lm mu mv mw mx bi translated">阶段1中的挑战:当从开发环境迁移到生产环境时，模型可能会有不同的行为。</li><li id="a21f" class="mp mq iq kr b ks my kw mz ln na lo nb lp nc lm mu mv mw mx bi translated">阶段2中的挑战:当在生产中将ML模型添加到现有的应用程序中时，很难满足所有团队的需求。</li><li id="420e" class="mp mq iq kr b ks my kw mz ln na lo nb lp nc lm mu mv mw mx bi translated">第3阶段的挑战:构建可扩展的计算能力来服务模型是必要的，但也是艰难的。</li><li id="5538" class="mp mq iq kr b ks my kw mz ln na lo nb lp nc lm mu mv mw mx bi translated">第四阶段的挑战:ML系统总是随着时间而恶化；应该建立一个监测系统。</li></ol><p id="3d0f" class="pw-post-body-paragraph ko kp iq kr b ks kt ku kv kw kx ky kz ln lb lc ld lo lf lg lh lp lj lk ll lm ij bi translated"><a class="ae lq" href="https://www.oreilly.com/radar/data-engineers-vs-data-scientists/" rel="noopener ugc nofollow" target="_blank">一个常见的团队配置是每个数据科学家有2-3名数据工程师</a>，在一些具有更复杂数据工程任务的组织中，这个数字可能会超过5名。这种说法与我的经验相关，即ML模型部署总是比模型开发花费更长的时间(除了由学术界领导的旨在给整个ML世界带来翻天覆地变化的研究)。为了保持故事的简洁，我在解释一些挑战时仍然保持高水平。如果你有兴趣了解更多的细节，请加入我的不和谐社区来DM我:【https://discord.gg/vUzAUj7V<a class="ae lq" href="https://discord.gg/vUzAUj7V" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="44b2" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">关于我们</h1><p id="f56e" class="pw-post-body-paragraph ko kp iq kr b ks mh ku kv kw mi ky kz ln mj lc ld lo mk lg lh lp ml lk ll lm ij bi translated">我们来自<a class="ae lq" href="https://aipaca.ai" rel="noopener ugc nofollow" target="_blank"> Aipaca </a>团队，构建一个无服务器的MLOps工具Aibro，帮助数据科学家训练&amp;在2分钟内在云平台上部署AI模型。与此同时，Aibro采用了专为机器学习打造的成本节约战略，将云成本降低了85%。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8b0a2de8c2a76d6caa6e735f9d83f9ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*5LLWYNyR3BsEhXkJ-twU8A.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">AIpaca Inc .图片作者</p></figure></div></div>    
</body>
</html>