<html>
<head>
<title>Pipeline and Custom Transformer with a Hands-On Case Study in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">管道和定制转换器，并附有Python实践案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pipeline-and-custom-transformer-with-a-hands-on-case-study-in-python-c416731e6158#2022-01-14">https://towardsdatascience.com/pipeline-and-custom-transformer-with-a-hands-on-case-study-in-python-c416731e6158#2022-01-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="c484" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">管道和定制转换器，并附有Python实践案例研究</h1></div><div class=""><h2 id="3b6c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用定制和scikit-learn管道</h2></div><p id="6e1c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">机器学习中的管道涉及将端到端的工作流转换为一组代码，以自动化整个数据处理和模型开发过程。我们可以使用管道依次应用一系列转换来准备数据，并在最后安装一个估计器。管道有助于简化将一系列操作组合在一起的过程。仅当转换和模型及其超参数被预先识别时，才使用管道。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/104d0bb0aaf7762dbe61b548d017268d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0mmiL7zmPPgGGo03sdeAmg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图一。说明了转换器和估算器如何为管道工作的流程图。作者使用PowerPoint制作的图片</p></figure><h1 id="b71c" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">管道是如何工作的？</h1><p id="047f" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">管道由一系列拟合和转换操作组成，这些操作因训练数据和测试数据而异。通常，在训练集上使用拟合和变换或者拟合函数；在测试集上只使用变换。拟合和转换操作首先识别关于数据分布的重要信息，然后根据这些信息转换数据。fit()通过研究数据分布来获取相应属性的中值，而transform()则用从数据中获取的中值替换缺失值。举例来说，我们使用一个SimpleImputer()，一个用于缺失值处理的python包，用中间值替换缺失值。</p><p id="58eb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，测试数据只使用转换操作。这主要是为了避免在构建模型时出现任何数据泄漏。其思想是基于从训练集中学习到的信息对测试数据执行预处理，而不是将整个数据作为一个整体进行清理。传入数据流中任何缺失的信息都需要在输入预测模型之前进行处理。这一点很重要，尤其是当您将模型投入生产时。</p><h1 id="7e62" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">工作示例</h1><p id="d34b" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">我们的想法是建立一个客户流失模型，使我们能够预测对预测客户流失有影响的驱动因素。我们不会专注于数据探索或建立一个高精度的模型；相反，我们将检查数据组件，并确定如何使用管道开发整个过程。用于此分析的数据集取自<a class="ae mr" href="https://www.kaggle.com/blastchar/telco-customer-churn" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>，并对任何人开放(公开)使用(Kaggle，2018)。数据字典和业务上下文可以在上面的链接中找到。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="3bdf" class="mx lv it mt b gy my mz l na nb"># To help with reading and manipulating data<br/>import pandas as pd<br/>import numpy as np</span><span id="c4fd" class="mx lv it mt b gy nc mz l na nb"># To help with data visualization<br/>%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="eaee" class="mx lv it mt b gy nc mz l na nb"># To be used for missing value imputation<br/>from sklearn.impute import SimpleImputer</span><span id="3651" class="mx lv it mt b gy nc mz l na nb"># To help with model building<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import (<br/> AdaBoostClassifier,<br/> GradientBoostingClassifier,<br/> RandomForestClassifier,<br/> BaggingClassifier,<br/>)<br/>from xgboost import XGBClassifier</span><span id="bf01" class="mx lv it mt b gy nc mz l na nb"># To get different metric scores, and split data<br/>from sklearn import metrics<br/>from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score<br/>from sklearn.metrics import (<br/> f1_score,<br/> accuracy_score,<br/> recall_score,<br/> precision_score,<br/> confusion_matrix,<br/> roc_auc_score,<br/> plot_confusion_matrix,<br/>)</span><span id="f506" class="mx lv it mt b gy nc mz l na nb"># To be used for data scaling and one hot encoding<br/># from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder</span><span id="50c4" class="mx lv it mt b gy nc mz l na nb"># To be used for tuning the model<br/>from sklearn.model_selection import GridSearchCV, RandomizedSearchCV</span><span id="d381" class="mx lv it mt b gy nc mz l na nb"># To be used for creating pipelines and personalizing them<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.compose import ColumnTransformer</span><span id="58f0" class="mx lv it mt b gy nc mz l na nb"># To define maximum number of columns to be displayed in a dataframe<br/>pd.set_option(“display.max_columns”, None)</span><span id="5cd8" class="mx lv it mt b gy nc mz l na nb"># To supress warnings<br/>import warnings</span><span id="021c" class="mx lv it mt b gy nc mz l na nb">warnings.filterwarnings(“ignore”)</span></pre><p id="07be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们来读数据。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="d17d" class="mx lv it mt b gy my mz l na nb">data=pd.read_csv(“WA_Fn-UseC_-Telco-Customer-Churn.csv”)<br/>data.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nd"><img src="../Images/f27f4a8ca25eab454a763211099ae38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqxB8d5S0aFHNBcjUW01iw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图二。展示了数据的前五行。快照取自Jupyter笔记本。</p></figure><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="6eda" class="mx lv it mt b gy my mz l na nb">data[‘MultipleLines’].value_counts()</span></pre><p id="3408" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们期望属性“MultipleLines”是二进制的；然而，这里有三个不同的值。</p><ol class=""><li id="3d7a" class="ne nf it kk b kl km ko kp kr ng kv nh kz ni ld nj nk nl nm bi translated">是~3.5K记录</li><li id="d066" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">不~ 3K唱片</li><li id="1e39" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">没有电话服务~0.5K记录</li></ol><p id="ccae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当使用Jupyter Notebook时，我们总是可以将“无电话服务”转换为“无”，然而，当建立管道时，这些转换需要在管道本身内发生。因此，我们需要定义一个自定义转换器，可以将“无电话服务”转换为“无”。下面是一个自定义转换器的示例。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="50ac" class="mx lv it mt b gy my mz l na nb">#Custom Transformer that extracts columns passed as argument to its constructor</span><span id="89cb" class="mx lv it mt b gy nc mz l na nb">class NPSTF():<br/>    <br/>    #Class Constructor <br/>    <br/>    def __init__( self, feature_names):<br/>        self._feature_names = feature_names <br/>    <br/>    #Return self nothing else to do here    <br/>    <br/>    def fit( self, X, y = None ):<br/>        return self<br/>    <br/>    #Method that describes what we need this transformer to do<br/>    <br/>    def transform(self, X, y = None ):<br/>        <br/>        def map_values(val):<br/>        <br/>            if val in ["No phone service"]:</span><span id="0b8d" class="mx lv it mt b gy nc mz l na nb">return 'No'<br/>            else:<br/>                return val<br/>        <br/>        X_=X.copy()<br/>        <br/>        X_[self._feature_names] = X_[self._feature_names].apply(map_values)<br/>        <br/>        return  X_</span></pre><p id="652f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们试着验证一下定制转换器是否能处理虚拟数据。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="b7b0" class="mx lv it mt b gy my mz l na nb">data1=[(0, “No”),(0, “Yes”), (1, “No”), (1,”No phone service”)]</span><span id="b330" class="mx lv it mt b gy nc mz l na nb">df = pd.DataFrame(data1, columns=[‘Label’, ‘MultipleLines’])</span><span id="d7fd" class="mx lv it mt b gy nc mz l na nb">df.head()</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/cd86853c90aa3400991c64e913f24805.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*JMCc8pJIi3vaWsuLZD8ZUQ.png"/></div></figure><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="c6bb" class="mx lv it mt b gy my mz l na nb">pipeline=Pipeline(steps=[(“CT”, NPSTF(“MultipleLines”))])</span><span id="d2c0" class="mx lv it mt b gy nc mz l na nb">pipeline.fit_transform(df)</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/774fe11efc9181a0150f083a39c23401.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*F0D2Td2JzOecgMUbXPvDJQ.png"/></div></figure><p id="d180" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将开发一个端到端的流程来使用管道。请注意，我们对数据做了以下假设。</p><ol class=""><li id="c44c" class="ne nf it kk b kl km ko kp kr ng kv nh kz ni ld nj nk nl nm bi translated">因为我们正在构建非参数模型，所以我们不会检查数据分布。</li><li id="0ff5" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">所有分类列都需要进行一次性编码，数字列中缺失的条目需要进行估算。</li><li id="0aa1" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">我们将实现一个XGBoost()模型和管道。理想情况下，我们需要找出最佳模型，然后才能沿着管道实现它。</li></ol><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="f74c" class="mx lv it mt b gy my mz l na nb">cat_columns=list(data.select_dtypes(include=["object"]).columns)<br/>print(cat_columns)</span><span id="99ea" class="mx lv it mt b gy nc mz l na nb">numeric_columns=list(data.select_dtypes(include=["int64", "float64"]).columns)<br/>print(numeric_columns)</span></pre><p id="9911" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">建立管道。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="9f83" class="mx lv it mt b gy my mz l na nb">from imblearn.pipeline import Pipeline</span><span id="e5c8" class="mx lv it mt b gy nc mz l na nb">from sklearn.preprocessing import OneHotEncoder</span><span id="9afe" class="mx lv it mt b gy nc mz l na nb"># To oversample and undersample data<br/>from imblearn.under_sampling import NearMiss<br/>from imblearn.under_sampling import RandomUnderSampler</span><span id="b8c7" class="mx lv it mt b gy nc mz l na nb"># creating a list of numerical variables<br/>numerical_features = numeric_columns</span><span id="113e" class="mx lv it mt b gy nc mz l na nb"># creating a transformer for numerical variables, which will apply simple imputer on the numerical variables<br/>numeric_transformer = Pipeline(steps=[("imputer", SimpleImputer(strategy="median"))])</span><span id="f321" class="mx lv it mt b gy nc mz l na nb"># creating a list of categorical variables<br/>categorical_features = cat_columns.remove('Churn')</span><span id="b19c" class="mx lv it mt b gy nc mz l na nb"># creating a transformer for categorical variables, which will first apply simple imputer and <br/>#then do one hot encoding for categorical variables<br/>categorical_transformer = Pipeline(<br/>    steps=[<br/>        ("imputer", SimpleImputer(strategy="most_frequent")),<br/>        ("onehot", OneHotEncoder(handle_unknown="ignore")),<br/>    ]<br/>)</span><span id="6560" class="mx lv it mt b gy nc mz l na nb"># handle_unknown = "ignore", allows model to handle any unknown category in the test data</span><span id="0a49" class="mx lv it mt b gy nc mz l na nb"># combining categorical transformer and numerical transformer using a column transformer</span><span id="4cc2" class="mx lv it mt b gy nc mz l na nb">preprocessor = ColumnTransformer(<br/>    transformers=[<br/>        ("num", numeric_transformer, numerical_features),<br/>        ("cat", categorical_transformer, categorical_features),<br/>    ],<br/>    remainder="passthrough",<br/>)</span><span id="666d" class="mx lv it mt b gy nc mz l na nb"># remainder = "passthrough" has been used, it will allow variables that are present in original data <br/># but not in "numerical_columns" and "categorical_columns" to pass through the column transformer without any changes</span><span id="6545" class="mx lv it mt b gy nc mz l na nb">model = Pipeline(<br/>    steps=[<br/>        ("CT", NPSTF("MultipleLines")),<br/>        ("pre", preprocessor),<br/>        ("class balance", NearMiss(version=1)),<br/>        (<br/>            "XGB",<br/>            XGBClassifier(random_state=1,subsample= 0.9, reg_lambda= 5, n_estimators= 50, \<br/>                          learning_rate= 0.1, gamma= 1, eval_metric='logloss'),<br/>        )<br/>    ]<br/>)</span></pre><p id="1315" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们正在实施数据管道。</p><pre class="lf lg lh li gt ms mt mu mv aw mw bi"><span id="1c02" class="mx lv it mt b gy my mz l na nb"># Separating target variable and other variables</span><span id="b9ca" class="mx lv it mt b gy nc mz l na nb">## Encoding Existing and Attrited customers to 0 and 1 respectively, for analysis.<br/>data["Churn"].replace("No", 0, inplace=True)<br/>data["Churn"].replace("Yes", 1, inplace=True)</span><span id="635a" class="mx lv it mt b gy nc mz l na nb">X = data.drop(columns="Churn")<br/>Y = data["Churn"]</span><span id="fc46" class="mx lv it mt b gy nc mz l na nb"># Splitting the data into train and test sets<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>    X, Y, test_size=0.20, random_state=1, stratify=Y<br/>)<br/>print(X_train.shape, X_test.shape)</span><span id="9dc7" class="mx lv it mt b gy nc mz l na nb"># Fit the model on training data<br/>model.fit(X_train, y_train)</span></pre><p id="4790" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们在训练数据上拟合了管道，我们就可以在验证数据上测试它。这个想法是，一旦数据清理过程得到处理，并且确定了最适合的模型，就实现管道。管道应该处理原始数据本身；因此，上面的示例是在考虑部署场景的情况下构建的。</p><h1 id="0743" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">参考</h1><ol class=""><li id="cac1" class="ne nf it kk b kl mm ko mn kr nu kv nv kz nw ld nj nk nl nm bi translated">Github。(2021年11月29日)。使用Cloud Pak上的Watson机器学习和Jupyter笔记本预测客户流失数据。检索于2022年1月14日，来自GitHub网站:<a class="ae mr" href="https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/data/Telco-Customer-Churn.csv" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/IBM/Telco-Customer-churn-on-ICP 4d/blob/master/data/Telco-Customer-churn . CSV</a></li><li id="c62f" class="ne nf it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">卡格尔。(2018).电信客户流失。从kaggle.com网站检索到:【https://www.kaggle.com/blastchar/telco-customer-churn T2】</li></ol></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="3436" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="oe">关于作者:高级分析专家和管理顾问，帮助公司通过商业、技术和组织数据的数学组合找到各种问题的解决方案。一个数据科学爱好者，在这里分享、学习、贡献；可以和我在</em> <a class="ae mr" href="https://www.linkedin.com/in/angel-das-9532bb12a/" rel="noopener ugc nofollow" target="_blank"> <em class="oe">上联系</em> </a> <em class="oe">和</em> <a class="ae mr" href="https://twitter.com/dasangel07_andy" rel="noopener ugc nofollow" target="_blank"> <em class="oe">推特</em></a><em class="oe">；</em></p></div></div>    
</body>
</html>