<html>
<head>
<title>Everything You Need to Know to Build an Amazing Binary Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建惊人的二进制分类器所需的一切</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/everything-you-need-to-know-to-build-an-amazing-binary-classifier-590de3482aad#2022-01-30">https://towardsdatascience.com/everything-you-need-to-know-to-build-an-amazing-binary-classifier-590de3482aad#2022-01-30</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""><h1 id="3b7f" class="pw-post-title is it iu bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">构建惊人的二进制分类器所需的一切</h1></div><div class=""><h2 id="5632" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">利用机器学习将产品评论自动分类为正面或负面</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/33c74c2dda3c5c5c0a58612d1f730ae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tXw4QWdnGjRNtk1p"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">安妮·斯普拉特在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="07cf" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">机器学习中的分类是什么？</h1><p id="4189" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">有两种最简单形式的<strong class="lu iv">监督机器学习</strong>方法。首先，你可能会遇到一个<strong class="lu iv">回归问题</strong>，你试图预测一个连续变量，比如温度或股票价格。第二个是<strong class="lu iv">分类</strong>问题，您希望预测一个分类变量，如<em class="mo">通过/失败</em>或<em class="mo">垃圾邮件/火腿</em>。此外，我们可能会遇到<strong class="lu iv">二元分类</strong>问题，我们将在此仅讨论两个结果，以及<strong class="lu iv">多类分类</strong>两个以上的结果。</p><h1 id="7a19" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">准备数据</h1><p id="c81b" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们想采取几个步骤来为机器学习准备数据。对于文本，我们希望<em class="mo">清除</em>它移除不需要的字符或数字，我们希望移除<em class="mo">停用词</em>，或出现频率太高的词，我们还应该<em class="mo">词干</em>或<em class="mo">对</em>词进行去词法分析，这将把诸如<em class="mo">运行</em>和<em class="mo">运行</em>这样的词带到它们的根形式【T28运行。我们可能想要创建<em class="mo">新列</em>或功能来帮助您的机器学习分类过程。</p><p id="35c4" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">对于这个例子，我们将使用Kaggle 上<a class="ae kz" href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank">女装电子商务服装评论的数据集，该数据集可以在</a><a class="ae kz" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CC0:公共领域</a>下供您使用。</p><p id="d9d2" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">像往常一样，让我们加载执行该分析所需的所有库:</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="5ada" class="mz lb iu mv b be na nb l nc nd"># Gereral Imports<br/>import numpy as np<br/>import pandas as pd<br/>import re<br/>import string<br/>from timeit import timeit<br/><br/># Machine Learning Imports<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import ConfusionMatrixDisplay<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn import metrics <br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import RepeatedStratifiedKFold<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.pipeline import Pipeline<br/><br/># Model Persistence Imports<br/>from joblib import dump, load<br/><br/># Test Processing Imports<br/>import nltk<br/>from nltk.stem import PorterStemmer<br/><br/># Plotting Imports<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span></pre><h1 id="02f6" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">特征工程</h1><p id="6055" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">该数据集包含评论、评级、部门名称和撰写评论的人的年龄。评级系统是经典的<em class="mo">1–5星</em>系统。在清理之前，让我们导入数据并创建一些我们将在模型中使用的关键列，也称为<strong class="lu iv">特征工程</strong>。我们将使用<code class="fe ne nf ng mv b">read_csv</code>函数读取数据并创建一个名为<code class="fe ne nf ng mv b">df</code>的数据帧。</p><ol class=""><li id="5aff" class="nh ni iu lu b lv mp ly mq mb nj mf nk mj nl mn nm nn no np bi translated">由于我们正在执行<em class="mo">二进制分类</em>，我们的<strong class="lu iv">目标</strong>变量需要是<code class="fe ne nf ng mv b">1</code>或<code class="fe ne nf ng mv b">0</code>。在五星评论系统中，我们可以将<code class="fe ne nf ng mv b">4</code>和<code class="fe ne nf ng mv b">5</code>评论设为<strong class="lu iv">正级</strong>，然后将剩余的<code class="fe ne nf ng mv b">1</code>、<code class="fe ne nf ng mv b">2</code>和<code class="fe ne nf ng mv b">3</code>评论设为<strong class="lu iv">负级</strong>。</li><li id="62bc" class="nh ni iu lu b lv nq ly nr mb ns mf nt mj nu mn nm nn no np bi translated">这组特殊的评论既有标题<strong class="lu iv">又有<strong class="lu iv">评论文本</strong>字段。我们可以将这两列合并成一个名为<strong class="lu iv"> Text </strong>的新列，以简化我们的处理。</strong></li><li id="17a7" class="nh ni iu lu b lv nq ly nr mb ns mf nt mj nu mn nm nn no np bi translated">作为模型中的另一个特性，我们可以创建一个新的列来表示评论文本的总长度。</li></ol><p id="56fb" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated"><strong class="lu iv">注意</strong> : <em class="mo">这里我没有展示的一个步骤是EDA或者探索性数据分析。我建议你总是在建立模型之前这样做。你可以在我的帖子</em> <a class="ae kz" rel="noopener" target="_blank" href="/exploratory-data-analysis-with-python-1b8ae98a61c5"> <em class="mo">探索性数据分析</em> </a> <em class="mo">中找到我的过程。</em></p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="f542" class="mz lb iu mv b be na nb l nc nd"># Import the data<br/>df = pd.read_csv("ClothingReviews.csv")<br/><br/># add a column for positive or negative based on the 5 star review<br/>df['Target'] = df['Rating'].apply(lambda c: 0 if c &lt; 4 else 1)<br/><br/># Combine the title and text into a single column<br/>df['Text'] = df['Title'] + ' ' + df['Review Text']<br/><br/># Create a new column that is the length of the text field<br/>df['text_len'] = df.apply(lambda row: len(row['Text']), axis = 1)</span></pre><h1 id="d902" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">清理文本</h1><p id="50a1" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">接下来，我们需要<strong class="lu iv">清理</strong>文本。我已经创建了一个适用于几乎所有NLP清理情况的函数。我们先来看看正文前的正文:</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="6299" class="mz lb iu mv b be na nb l nc nd">' Love this dress!  it\'s sooo pretty.  i happened to find it in a store, <br/>and i\'m glad i did bc i never would have ordered it online bc it\'s <br/>petite.  i bought a petite and am 5\'8".  i love the length on me- <br/>hits just a little below the knee.  would definitely be a true <br/>midi on someone who is truly petite.'</span></pre><p id="2386" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">接下来是一个用于处理字符串的函数:</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="f170" class="mz lb iu mv b be na nb l nc nd"># Cleaning Function<br/>def process_string(text):<br/><br/>    final_string = ""<br/><br/>    # Convert the text to lowercase<br/>    text = text.lower()<br/><br/>    # Remove punctuation<br/>    translator = str.maketrans('', '', string.punctuation)<br/>    text = text.translate(translator)<br/><br/>    # Remove stop words and useless words<br/>    text = text.split()<br/>    useless_words = nltk.corpus.stopwords.words("english")<br/>    text_filtered = [word for word in text if not word in useless_words]<br/><br/>    # Remove numbers<br/>    text_filtered = [re.sub('\w*\d\w*', '', w) for w in text_filtered]<br/><br/>    # Stem the text with NLTK PorterStemmer<br/>    stemmer = PorterStemmer() <br/>    text_stemmed = [stemmer.stem(y) for y in text_filtered]<br/><br/>    # Join the words back into a string<br/>    final_string = ' '.join(text_stemmed)<br/><br/>    return final_string</span></pre><p id="38b9" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">我们使用<strong class="lu iv"> Pandas </strong> <code class="fe ne nf ng mv b">apply</code>方法在我们的数据帧上运行这个。应用这个函数后，让我们来看看结果字符串。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="a851" class="mz lb iu mv b be na nb l nc nd">df['Text_Processed'] = df['Text'].apply(lambda x: process_string(x))</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="f269" class="mz lb iu mv b be na nb l nc nd">'love dress sooo pretti happen find store im glad bc never would <br/>order onlin bc petit bought petit  love length hit littl knee would <br/>definit true midi someon truli petit'</span></pre><p id="ebc1" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">我们可以看到字符串非常干净，没有<em class="mo">数字</em>、<em class="mo">标点符号</em>、<em class="mo">停用词</em>，单词被<em class="mo">词干化</em>成它们最简单的形式。我们已经<em class="mo">差不多</em>准备好开始建造我们的模型了！</p><h1 id="3a37" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">不平衡数据测试</h1><p id="d65e" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们必须了解我们的数据集是否在目标中的两个类之间<strong class="lu iv">不平衡</strong>。我们可以用熊猫的一行代码很快做到这一点。不平衡数据是指一个类比另一个类有更多的观察值。当我们训练我们的模型时，结果将是模型将<em class="mo">偏向</em>具有最多观察值的类。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="f3bf" class="mz lb iu mv b be na nb l nc nd">df['Target'].value_counts()</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="0008" class="mz lb iu mv b be na nb l nc nd">1    17433<br/>0     5193<br/>Name: Target, dtype: int64</span></pre><p id="83c7" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">计数让我们知道<strong class="lu iv">数据不平衡</strong>。正面类别<code class="fe ne nf ng mv b">1</code>的观察数量是负面类别<code class="fe ne nf ng mv b">0</code>的三倍。我们必须确保在我们的模型中恰当地处理不平衡。在本文中，我将介绍几种不同的方法。</p><h1 id="ce13" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">管道建设</h1><p id="9934" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><strong class="lu iv">流水线</strong>是<em class="mo">正确</em>构建机器学习模型的必备条件。它们帮助您组织转换数据和重复使用模型所需的所有步骤。您可以单独执行这些步骤，但是在将您的模型应用到新数据时，如果您不这样做，就不容易。稍后，我将向您展示这在新数据上的实际工作方式，但现在让我们先构建管道。</p><p id="aaaa" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">我们有一个创建<a class="ae kz" rel="noopener" target="_blank" href="/using-pipelines-in-sci-kit-learn-516aa431dcc5">管道</a>的函数。管道被包装在一个函数中，以便在我们评估我们的选项时利用多个模型。</p><p id="cd17" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">该功能中的第一个是<strong class="lu iv">列变压器</strong>。列转换器允许我们以任何适合我们模型的方式预处理数据。有许多不同的方法来转换你的数据，我不会在这里一一介绍，但是让我解释一下我们使用的两种方法。</p><ul class=""><li id="568e" class="nh ni iu lu b lv mp ly mq mb nj mf nk mj nl mn nw nn no np bi translated"><strong class="lu iv">tfidf矢量器</strong>:TF-IDF矢量器将文本转换成数值。关于这方面的详细描述，请查看我在<a class="ae kz" rel="noopener" target="_blank" href="/a-quick-introduction-to-bag-of-words-and-tf-idf-fbd3ab84ecbf"> BoW和TF-IDF </a>上的帖子。在这里，我们正在转换我们的<code class="fe ne nf ng mv b">Text_Processed</code>列。</li><li id="55e2" class="nh ni iu lu b lv nq ly nr mb ns mf nt mj nu mn nw nn no np bi translated"><strong class="lu iv">最小最大缩放器</strong>:将所有数值转换成一个介于<code class="fe ne nf ng mv b">0</code>和<code class="fe ne nf ng mv b">1</code>之间的范围。大多数ML算法不处理具有大范围值的数据；扩展数据始终是一种最佳做法。你可以在Scikit-Learn的<a class="ae kz" href="https://scikit-learn.org/stable/modules/preprocessing.html" rel="noopener ugc nofollow" target="_blank">文档</a>上阅读更多相关内容。这里我们正在扩展我们的<code class="fe ne nf ng mv b">text_len</code>列。</li></ul><p id="45d4" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">第二个是<strong class="lu iv">管道</strong>本身的创建。管道列出了我们想要对数据运行的步骤。我们这里有一个相当简单的管道，但是您可以添加任意多的步骤。我们有以下内容。</p><ol class=""><li id="1626" class="nh ni iu lu b lv mp ly mq mb nj mf nk mj nl mn nm nn no np bi translated"><strong class="lu iv">准备</strong>:这是从上面看的柱形变压器。它将矢量化我们的文本，并缩放我们的文本长度。</li><li id="41df" class="nh ni iu lu b lv nq ly nr mb ns mf nt mj nu mn nm nn no np bi translated">clf :这是我们选择分类器实例的地方。你可以看到这被传入我们的函数，我们把它传入函数，用相同的数据测试不同的分类器。</li></ol><p id="a144" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated"><strong class="lu iv">注意</strong> : <em class="mo">分类器的实例就是类本身。比如</em> <code class="fe ne nf ng mv b"><em class="mo">LogisticRegression()</em></code> <em class="mo">就是</em> <code class="fe ne nf ng mv b"><em class="mo">LogisticRegression</em></code> <em class="mo">的一个实例。</em></p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="8a0e" class="mz lb iu mv b be na nb l nc nd">def create_pipe(clf):<br/><br/>    column_trans = ColumnTransformer(<br/>            [('Text', TfidfVectorizer(), 'Text_Processed'),<br/>             ('Text Length', MinMaxScaler(), ['text_len'])],<br/>            remainder='drop') <br/><br/>    pipeline = Pipeline([('prep',column_trans),<br/>                         ('clf', clf)])<br/><br/>    return pipeline</span></pre><h1 id="d8d4" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">通过交叉验证选择模型</h1><p id="fe4c" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">当构建机器学习模型时，最佳实践是执行<strong class="lu iv">模型选择</strong>。模型选择允许您对数据测试不同的算法，并确定哪种算法的性能最好。首先，我们将把数据集分成<code class="fe ne nf ng mv b">X</code>和<code class="fe ne nf ng mv b">y</code>数据集。<code class="fe ne nf ng mv b">X</code>代表我们模型的所有特征，<code class="fe ne nf ng mv b">y</code>将代表目标变量。目标是我们试图预测的变量。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="f766" class="mz lb iu mv b be na nb l nc nd">X = df[['Text_Processed', 'text_len']]<br/>y = df['Target']</span></pre><p id="5746" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">现在是<strong class="lu iv">交叉验证</strong>两个分类器的时候了。交叉验证是将数据划分为<em class="mo"> n </em>个不同部分的过程，然后您使用这些部分来验证您的模型。交叉验证很重要，因为在某些情况下，它从<em class="mo">训练</em>集中学习的观察值可能不代表<em class="mo">测试</em>集中的观察值。因此，您可以通过运行不同的数据片来避免这种情况。在<a class="ae kz" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn的文档</a>上阅读更多相关信息。</p><p id="2c5c" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated"><strong class="lu iv">重要</strong> : <em class="mo">下面有一点我要特别注意的是</em><a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html" rel="noopener ugc nofollow" target="_blank"><strong class="lu iv"><em class="mo">RepeatedStratifiedKFold</em></strong></a><em class="mo">进行交叉验证。</em>分层的<em class="mo">交叉验证器将确保在</em>不平衡的<em class="mo">数据的情况下，分区</em>在分割中保持相对的类频率<em class="mo">。</em></p><p id="ad71" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">最后，我们将使用一个支持<code class="fe ne nf ng mv b">class_weight</code>参数的分类器来处理不平衡数据。Scikit-Learn的一些模型支持这一点，只需将值设置为<code class="fe ne nf ng mv b">balanced</code>，我们就可以解决不平衡的数据。其他方法包括<a class="ae kz" href="https://www.jair.org/index.php/jair/article/view/10302" rel="noopener ugc nofollow" target="_blank"> SMOTE </a>(合成生成少数类观察值以平衡数据，但这是一个很好的起点。你可以从我的另一篇文章中读到更多关于处理不平衡数据的信息。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="0496" class="mz lb iu mv b be na nb l nc nd">models = {'LogReg' : LogisticRegression(random_state=42, <br/>                                        class_weight='balanced', <br/>                                        max_iter=500),<br/>          'RandomForest' : RandomForestClassifier(<br/>                                        class_weight='balanced', <br/>                                        random_state=42)}<br/><br/>for name, model, in models.items():<br/>    clf = model<br/>    pipeline = create_pipe(clf)<br/>    cv = RepeatedStratifiedKFold(n_splits=10, <br/>                                 n_repeats=3, <br/>                                 random_state=1)<br/>    %time scores = cross_val_score(pipeline, X, y, <br/>                             scoring='f1_weighted', cv=cv, <br/>                             n_jobs=-1, error_score='raise')<br/>    print(name, ': Mean f1 Weighted: %.3f and StdDev: (%.3f)' % \<br/>        (np.mean(scores), np.std(scores)))</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="e11b" class="mz lb iu mv b be na nb l nc nd">CPU times: user 23.2 s, sys: 10.7 s, total: 33.9 s<br/>Wall time: 15.5 s<br/>LogReg : Mean f1 Weighted: 0.878 and StdDev: (0.005)<br/>CPU times: user 3min, sys: 2.35 s, total: 3min 2s<br/>Wall time: 3min 2s<br/>RandomForest : Mean f1 Weighted: 0.824 and StdDev: (0.008)</span></pre><p id="f8fb" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">在上面的函数中，你可以看到评分是用<code class="fe ne nf ng mv b">f1_weighted</code>完成的。选择正确的指标是一个完整的讨论，理解它至关重要。我写过如何选择正确的<a class="ae kz" rel="noopener" target="_blank" href="/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd">评估指标</a>。</p><p id="f88e" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">下面简单解释一下我为什么选择这个指标。首先，我们有不平衡的数据，而且我们<strong class="lu iv">从未</strong>想要使用<code class="fe ne nf ng mv b">accuracy</code>作为我们的衡量标准。不平衡数据的准确性会给你一种虚假的成功感，但准确性会使更多的观察偏向这个类。还有<code class="fe ne nf ng mv b">precision</code>和<code class="fe ne nf ng mv b">recall</code>可以帮助你最小化误报(精确度)或者最小化漏报(召回)。根据您想要优化的结果，您可以选择其中之一。</p><p id="a15f" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">由于我们不喜欢预测正面评价和负面评价，在这种情况下，我选择了<code class="fe ne nf ng mv b">F1</code>分数。<code class="fe ne nf ng mv b">F1</code>顾名思义就是将精确度和回忆的调和平均值结合成一个单一的度量。然而，也有一种方法可以告诉这个指标用<code class="fe ne nf ng mv b">weighted</code>标志对不平衡的数据进行评分。正如<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank"> Sciki-learn </a>文档所述:</p><blockquote class="nx ny nz"><p id="eeee" class="ls lt mo lu b lv mp jv lx ly mq jy ma oa mr md me ob ms mh mi oc mt ml mm mn in bi translated">计算每个标签的指标，并根据支持度(每个标签的真实实例数)计算其平均值。这改变了“宏”以解决标签不平衡；它会导致精确度和召回率之间的F值。</p></blockquote><p id="c0e7" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">基于这些结果，我们可以看到<code class="fe ne nf ng mv b">LogisticRegression</code>分类器表现稍好，速度更快，<strong class="lu iv"> 15秒</strong>对<strong class="lu iv"> 3分钟</strong>。因此，我们可以继续前进，用它来训练我们的模型。</p><p id="95f5" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">同样，请阅读我对<a class="ae kz" rel="noopener" target="_blank" href="/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd">模型评估</a>的完整解释，让您更好地了解使用哪一个以及何时使用。</p><h1 id="b59e" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">模型训练和验证</h1><p id="cb87" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们终于到了！是时候训练我们的最终模型并验证它了。我们将把我们的数据分成<strong class="lu iv">训练</strong>和<strong class="lu iv">测试</strong>分区，因为我们在上面执行<em class="mo">交叉验证</em>时没有这样做。你永远不会想用你所有的数据来训练你的模型，而是留一部分出来测试。每当模型在训练期间看到所有数据，它就会知道这些数据并导致<em class="mo">过拟合</em>。过度拟合是指模型过于擅长预测它所看到的数据，而不能推广到新数据。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="df23" class="mz lb iu mv b be na nb l nc nd"># Make training and test sets <br/>X_train, X_test, y_train, y_test = train_test_split(X, <br/>                                                    y, <br/>                                                    test_size=0.33, <br/>                                                    random_state=53)</span></pre><p id="bb90" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">接下来，一个快速函数将适合我们的模型，并用一个<code class="fe ne nf ng mv b">classification_report</code>和一个<em class="mo">混淆矩阵</em> (CM)对其进行评估。我认为与CM一起运行分类报告是至关重要的，它将向您展示您的每个关键评估指标，并告诉您模型的表现如何。CM是可视化结果的好方法。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="f183" class="mz lb iu mv b be na nb l nc nd">def fit_and_print(pipeline, name):<br/><br/>    pipeline.fit(X_train, y_train)<br/>    y_pred = pipeline.predict(X_test)<br/><br/>    print(metrics.classification_report(y_test, y_pred, digits=3))<br/><br/>    ConfusionMatrixDisplay.from_predictions(y_test, <br/>                                            y_pred, <br/>                                            cmap=plt.cm.YlOrBr)<br/><br/>    plt.tight_layout()<br/>    plt.ylabel('True label')<br/>    plt.xlabel('predicted label')<br/>    plt.tight_layout()<br/>    plt.savefig('classification_1.png', dpi=300)</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="f2a6" class="mz lb iu mv b be na nb l nc nd">clf = LogisticRegression(random_state=42, <br/>                         class_weight='balanced', <br/>                         max_iter=500)<br/>pipeline = create_pipe(clf)<br/>fit_and_print(pipeline, 'Logistic Regression')</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="591b" class="mz lb iu mv b be na nb l nc nd">              precision    recall  f1-score   support<br/><br/>           0      0.681     0.855     0.758      1715<br/>           1      0.953     0.881     0.915      5752<br/><br/>    accuracy                          0.875      7467<br/>   macro avg      0.817     0.868     0.837      7467<br/>weighted avg      0.891     0.875     0.879      7467</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj od"><img src="../Images/a26cdfc38736ac60b65e6129a2bbad5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YvBFaPfxQCsRogze.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="9736" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">结果出来了！分类报告显示了我们需要的一切。因为我们说过不一定要针对正类或负类进行优化，所以我们将使用<code class="fe ne nf ng mv b">f1-score</code>列。我们可以在<code class="fe ne nf ng mv b">0.758</code>看到<code class="fe ne nf ng mv b">0</code>班，在<code class="fe ne nf ng mv b">0.915</code>看到<code class="fe ne nf ng mv b">1</code>班。每当您有不平衡的数据时，您可以期望较大的类执行得更好，但是您可以使用上面的一些步骤来提高模型的性能。</p><p id="cfdb" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated"><strong class="lu iv"> 92% </strong>的时候，该模型会正确地将评论分类为正面类，而<strong class="lu iv"> 76% </strong>的时候会正确地将评论分类为负面类。仅仅通过查看用户提交的评论文本，就能给人留下深刻的印象！</p><h1 id="c29f" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">坚持模型</h1><p id="3e1d" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们可以很容易地将我们的模型持久化以备后用。因为我们使用了一个<strong class="lu iv">管道</strong>来构建模型，所以我们执行了所有必要的步骤来预处理我们的数据并运行模型。持久化模型使得在生产服务器上运行它或者稍后加载它变得容易，并且不需要再次训练它。保存到磁盘后，这个模型在磁盘上还不到<code class="fe ne nf ng mv b">500KB</code>简直不可思议！</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="0635" class="mz lb iu mv b be na nb l nc nd"># Save the model to disk<br/>dump(pipeline, 'binary.joblib') <br/><br/># Load the model from disk when you're ready to continue<br/>pipeline = load('binary.joblib')</span></pre><h1 id="7942" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">测试新数据</h1><p id="97a4" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">现在来演示真正重要的部分。你的模型对以前从未见过的新观测的预测有多好？这个过程在生产中会有很大的不同，但是我们可以通过创建一些新的评论来模拟它。我还创建了一个函数，它将字符串列表转换成带有干净文本和<code class="fe ne nf ng mv b">text_len</code>列的格式正确的数据帧。</p><pre class="kk kl km kn gu mu mv mw bn mx my bi"><span id="1b8d" class="mz lb iu mv b be na nb l nc nd">def create_test_data(x):<br/><br/>    x = process_string(x)<br/>    length = len(x)<br/><br/>    d = {'Text_Processed' : x,<br/>        'text_len' : length}<br/><br/>    df = pd.DataFrame(d, index=[0])<br/><br/>    return df</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="a414" class="mz lb iu mv b be na nb l nc nd"># Manually Generated Reviews<br/>revs = ['This dress is gorgeous and I love it and would gladly recommend it to all of my friends.',<br/>        'This skirt has really horrible quality and I hate it!',<br/>        'A super cute top with the perfect fit.',<br/>        'The most gorgeous pair of jeans I have seen.',<br/>        'This item is too little and tight.']</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="4a87" class="mz lb iu mv b be na nb l nc nd"># Print the predictions on new data<br/>print('Returns 1 for Positive reviews and 0 for Negative reviews:','\n')<br/>for rev in revs:<br/>    c_res = pipeline.predict(create_test_data(rev))<br/>    print(rev, '=', c_res)</span></pre><pre class="nv mu mv mw bn mx my bi"><span id="b444" class="mz lb iu mv b be na nb l nc nd">Returns 1 for Positive reviews and 0 for Negative reviews: <br/><br/>This dress is gorgeous and I love it and would gladly recommend it to all of my friends. = [1]<br/>This skirt has really horrible quality and I hate it! = [0]<br/>A super cute top with the perfect fit. = [1]<br/>The most gorgeous pair of jeans I have seen. = [1]<br/>This item is too little and tight. = [0]</span></pre><h1 id="6008" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">结论</h1><p id="1caa" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">你有它！构建二元分类器的端到端示例。用几个步骤构建一个可能很简单，但是这篇文章概述了你应该用来正确地<em class="mo">构建你的分类器的优选步骤。我们从清理数据和一些轻量级的<em class="mo">特征工程</em>、<em class="mo">管道</em>建筑、<em class="mo">模型选择</em>、<em class="mo">模型训练和评估</em>开始，最后<em class="mo">持久化模型</em>。最后，我们还在新数据上进行了测试。这个工作流程应该适用于几乎任何二元或多类分类问题。享受和快乐的模型建设！</em></p><p id="907b" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">这里我还遗漏了另外两个步骤，稍后我会讲到。<strong class="lu iv">特征选择</strong>和<strong class="lu iv">超参数调整</strong>。根据数据的复杂性，您可能希望深入研究特征选择，并充分发挥模型的性能，请查看超参数调整。</p><p id="44dd" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">这篇文章的所有代码都可以在<a class="ae kz" href="https://github.com/broepke/Classification" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到</p><p id="365e" class="pw-post-body-paragraph ls lt iu lu b lv mp jv lx ly mq jy ma mb mr md me mf ms mh mi mj mt ml mm mn in bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，可以考虑报名成为一名媒体成员。一个月5美元，让你可以无限制地访问成千上万篇文章。如果你使用<a class="ae kz" href="https://medium.com/@broepke/membership" rel="noopener">我的链接</a>注册，我会赚一小笔佣金，不需要你额外付费。</p></div></div>    
</body>
</html>