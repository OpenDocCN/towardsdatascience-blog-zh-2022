# 人工智能时刻

> 原文：<https://towardsdatascience.com/the-ai-moment-12761189b87d>

## 为什么人工智能的进步比以往任何时候都更让我们兴奋。

![](img/837284a580389041c28f66f828b6aaf1.png)

米拉德·法库里安在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

随着我在斯坦福大学与各种令人印象深刻的人工智能研究人员相处的时间越来越长，我注意到这些人对自己领域的突破做出反应的方式有些奇怪。他们的脑海中似乎总有一个声音告诉他们永远不要太兴奋。机器学习模型可以做[竞技编码](https://www.deepmind.com/blog/article/Competitive-programming-with-AlphaCode)？好的。他们能[写校样](https://mathscholar.org/2019/04/google-ai-system-proves-over-1200-mathematical-theorems/)？那很有趣。当我在高中的时候，我经常听说这些里程碑，并对未来充满希望。但当我成为一名圈内人士时，我注意到研究人工智能的人并不真的那么喜欢它。

我想你不能指望任何人对他们花费一生探索和思考的模型的微小改进或修改感到如此兴奋，但我私下怀疑还有别的事情在发生。

自 20 世纪 50 年代以来，人类一直在远离人工智能(AGI)5 年和远离 AGI 100 年之间摇摆不定。引用海明威的话，人工智能的进步是“逐渐地，然后突然地”发生的。有一些新技术改变了我们对待人工智能的方式，我们将它应用于我们能想到的一切，然后我们会被困 10-20 年。冲洗并重复。这已经让位于 20 世纪下半叶的两个历史性的“人工智能冬天”，在这段时间里，很少资源或注意力进入人工智能。

研究人员悄悄地担心，尽管我们近年来取得了巨大的进步，但我们最终会发现自己处于另一个冬天。根据正在取得的进展类型，有理由这样认为。今天，大多数导致强大新模型的新想法实际上都是基于深度学习成为主流之前所做的工作。例如，强化学习和卷积神经网络，这两个当今非常热门的话题，分别是在 20 世纪 60 年代和 80 年代发展起来的。这些方法只有在 1986 年发明的现代硬件、数据和[反向传播](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)下才变得可用。因此，从研究的角度来看，很容易看出，与过去 15 年相比，用新资源复兴旧思想将更难产生新的创新。

但我有不同的观点，因为我真的还是那个高中生，一想到能像人类一样思考的计算机，我的心就开始狂跳。我并不认为我们需要进一步创新。我们将被同样的宏观趋势所推动，这些趋势已经将我们带到了现在:更多的数据，更便宜、更快的计算。

在未标记的数据上预先训练模型使模型能够访问指数级的更多信息。随着研究的成熟，预训练方法将让我们更多地利用这些信息。随着互联网扩展到世界上最遥远的角落，数据将不断积累，这种趋势将继续并加速。为了从所有这些数据中保留信息，我们需要大量的参数。要在大量数据上训练大量参数，需要做大量的矩阵乘法。幸运的是，摩尔定律可以说是近代史上最强劲的趋势之一。计算将继续变得更便宜、更容易获得、更快。更多的数据，更多的计算，更好的模型。

我的意思不是说我们明天或在未来 x 年内会有 AGI，或者类似的事情。我只想说，有理由对机器学习模型的成就感到真正兴奋:我们不再需要依赖科学家和爱好者的智慧来期待机器学习的进步，我们所需要依赖的只是使用互联网的人和正在生产的计算机。我们已经进入了一个不可战胜的人工智能的夏天，被类人的一般智能所包围。

*神经网络中注意力的想法是这种趋势的一个非常重要的例外。

*如果你喜欢这篇文章，请考虑给* [和*一个跟随*](https://medium.com/@drfein) *！*