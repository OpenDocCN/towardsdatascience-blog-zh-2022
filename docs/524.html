<html>
<head>
<title>“MAPIE” Explained Exactly How You Wished Someone Explained to You</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“MAPIE”准确地解释了你希望别人如何向你解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mapie-explained-exactly-how-you-wished-someone-explained-to-you-78fb8ce81ff3#2022-01-18">https://towardsdatascience.com/mapie-explained-exactly-how-you-wished-someone-explained-to-you-78fb8ce81ff3#2022-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="3aa8" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">“MAPIE”准确地解释了你希望别人如何向你解释</h1></div><div class=""><h2 id="cc7e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个Python库，可以将任何模型的预测转化为置信区间</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bc05e9e0684da88948cb0e9d56236635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cMGoYOEfgK_efmeuuUpx8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[图片由作者提供]</p></figure><p id="20ea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当您为数值目标变量构建预测模型时，Scikit-learn、XGBoost、LightGBM、CatBoost、Keras等经典Python库会生成<strong class="la iu">点预测</strong>。不幸的是，</p><blockquote class="lu"><p id="e847" class="lv lw it bd lx ly lz ma mb mc md lt dk translated">点预测总是错的。</p></blockquote><p id="8f48" class="pw-post-body-paragraph ky kz it la b lb me ju ld le mf jx lg lh mg lj lk ll mh ln lo lp mi lr ls lt im bi translated">事实上，假设您有一个预测旧金山房屋销售价格的模型。该模型已经预测出一栋房子将以746，632.15美元的价格出售。这是实际价格的可能性有多大，精确到每一分钱？实际上，零。</p><p id="bce5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">知道房子将以70万美元到80万美元之间的价格出售，有95%的把握，这要有用得多(也安全得多)。其中95%的置信度大致意味着——如果我们可以观察所有可能的宇宙——在95%的情况下，售价实际上在70万美元到80万美元之间。这被称为<strong class="la iu">区间预测</strong>。</p><p id="8bef" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，<strong class="la iu">我们如何在Python </strong>中从点预测得到区间预测呢？这就是MAPIE发挥作用的地方。</p><h1 id="8625" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是MAPIE，如何使用它</h1><p id="6450" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated"><a class="ae ng" href="https://github.com/scikit-learn-contrib/MAPIE" rel="noopener ugc nofollow" target="_blank"> MAPIE </a>是一个用于获取区间预测的Python库。名字代表“<strong class="la iu">模型不可知预测区间估计器</strong>”，其中重要的部分是“模型不可知”。事实上，与分位数回归或贝叶斯推断等更传统的方法相反，<strong class="la iu"> MAPIE允许您保留您最喜欢的高度精确的模型</strong>。</p><p id="bc00" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，我们来看看怎么用。为了在一些真实数据上测试MAPIE，我将使用来自<a class="ae ng" href="http://lib.stat.cmu.edu/datasets/" rel="noopener ugc nofollow" target="_blank"> StatLib </a>的加州住房数据集，该数据集可以在Scikit-learn中直接获得(在<a class="ae ng" href="https://github.com/scikit-learn/scikit-learn/blob/main/COPYING" rel="noopener ugc nofollow" target="_blank"> BSD许可</a>下)。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="754e" class="nm mk it ni b gy nn no l np nq">from sklearn.datasets import fetch_california_housing<br/>from sklearn.model_selection import train_test_split</span><span id="a730" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># Get California housing dataset, and split it in 3 sets<br/></strong>X, y = fetch_california_housing(return_X_y=True, as_frame=True)</span><span id="3b1c" class="nm mk it ni b gy nr no l np nq">X_train_and_cal, X_test, y_train_and_cal, y_test =<br/>  train_test_split(X, y, test_size=1/3)</span><span id="cb40" class="nm mk it ni b gy nr no l np nq">X_train, X_cal, y_train, y_cal = train_test_split(<br/>  X_train_and_cal, y_train_and_cal, test_size=1/2)</span></pre><p id="c3d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">重要的是，我们有三组数据:</p><ul class=""><li id="9518" class="ns nt it la b lb lc le lf lh nu ll nv lp nw lt nx ny nz oa bi translated"><strong class="la iu">训练数据</strong>:预测模型学习的数据。</li><li id="722e" class="ns nt it la b lb ob le oc lh od ll oe lp of lt nx ny nz oa bi translated"><strong class="la iu">校准数据</strong>:MAPIE校准间隔的数据。</li><li id="abd8" class="ns nt it la b lb ob le oc lh od ll oe lp of lt nx ny nz oa bi translated"><strong class="la iu">测试数据</strong>:我们用来评估区间好坏的数据。</li></ul><p id="9dec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们的例子中，每个集合由6，880个观察值和8个特征组成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/28d4192b396789d50ecfbd0400719cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZaW24DTKrUCO3E1oEII7KA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧的形状。[图片由作者提供]</p></figure><p id="e4a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目标变量是加州各区的房价中值，以几十万美元表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/2cae6c179660d53e5ca29b2df600d9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x-gpZ1EwyIRyu1QKPjw2Bg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试集的前5个房屋的值。[图片由作者提供]</p></figure><p id="13c6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以第一栋房子值35.5万美元，第二栋房子值7.07万美元，以此类推。</p><p id="0756" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们已经准备好了数据，让我们对训练数据拟合预测模型(我将使用Scikit-learn的随机森林回归器),对校准数据拟合MAPIE回归器。</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="5eb2" class="nm mk it ni b gy nn no l np nq">from sklearn.ensemble import RandomForestRegressor<br/>from mapie.regression import MapieRegressor</span><span id="329c" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># Fit model on training data<br/></strong>model = RandomForestRegressor().fit(X_train, y_train)</span><span id="ab96" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># Fit MAPIE on calibration data<br/># Important: calibration data must be different from training data!</strong><br/>mapie = MapieRegressor(estimator=model, cv="prefit"<br/>  ).fit(X_cal, y_cal)</span></pre><p id="00ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一点上，我们可以最终使用MAPIE回归器的“预测”方法，它为观察值产生预测间隔(为了方便起见，我将它们存储到Pandas数据帧中):</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="b6f4" class="nm mk it ni b gy nn no l np nq">import pandas as pd</span><span id="a5fe" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># Get interval predictions on test data, with alpha=5%<br/></strong>y_test_pred_interval = pd.DataFrame(mapie.predict(X_test, alpha=.05)[1].reshape(-1,2), index=X_test.index, columns=["left", "right"])</span></pre><p id="152f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个区间由区间的左端和右端定义。例如，这些是测试集的前5个观察值的预测间隔:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/035589cf81fb4f8b5794a3a589104582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHdqr6VGolXOUh8SKaah-A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试集的前5次观察的预测间隔。[图片由作者提供]</p></figure><h1 id="75e1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">“阿尔法”的含义</h1><p id="284c" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">如果您查看最后一段代码，您会注意到一个名为<code class="fe oj ok ol ni b">alpha</code>的参数。如何解读这个参数？<code class="fe oj ok ol ni b">alpha</code>是<strong class="la iu">公差</strong>。它回答了这个问题:</p><blockquote class="lu"><p id="5b78" class="lv lw it bd lx ly lz ma mb mc md lt dk translated">“我们愿意接受多少‘错误’？”</p></blockquote><p id="8120" class="pw-post-body-paragraph ky kz it la b lb me ju ld le mf jx lg lh mg lj lk ll mh ln lo lp mi lr ls lt im bi translated">我所说的“错误”是指超出预测区间的观察结果。例如，如果<code class="fe oj ok ol ni b">alpha</code>设置为10%，这意味着我们预计不会有超过10%的观测值超出MAPIE预测的区间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/0f1c7c78d47fc2ec5448a131f2f06174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j8tmbQtG_ocPJoFyH59Nkw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">alpha = 10%时的输出示例:10次观察中有1次超出其预测区间。[图片由作者提供]</p></figure><p id="1e03" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们如何确保MAPIE预测的区间实际上与容差相匹配？这就是测试集存在的目的。统计<code class="fe oj ok ol ni b">y_test</code>的观测值落在预测区间之外的次数并与<code class="fe oj ok ol ni b">alpha</code>进行比较就足够了；</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="f1e1" class="nm mk it ni b gy nn no l np nq">out_of_interval = ((y_test &lt; y_test_pred_interval["left"]) | <br/> (y_test &gt; y_test_pred_interval["right"])<br/>).sum() / len(y_test)</span></pre><p id="4347" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们对不同的<code class="fe oj ok ol ni b">alpha</code>值重复此过程。这是结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/63007ab3df0310bbcbcaea5d8c6a5759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2RZJ_LFa_RTeZqumcm70iQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将alpha与超出预测区间的观察值百分比进行比较。[图片由作者提供]</p></figure><p id="6b35" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">区间外观察值的百分比实际上非常接近<code class="fe oj ok ol ni b">alpha</code>的相应值。这可能感觉像是魔术，但却出奇的简单！在下一段中，我将向您展示这是如何工作的。</p><h1 id="9267" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">引擎盖下的MAPIE</h1><p id="df47" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">MAPIE背后的想法是从模型对一组数据(称为校准数据)产生的错误中学习。一旦我们知道我们应该期望什么样的误差(对于给定的容差)，将它加在点预测的两侧就足够了，以获得一个区间预测。</p><p id="fb7a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">MAPIE基本算法包括6个步骤:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/5aa8ae02f040933a57f5f0dcb68c6e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlb9bSwkqldq2zFcp3wnqQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MAPIE算法。[图片由作者提供]</p></figure><p id="2bc5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些步骤是:</p><ol class=""><li id="f22e" class="ns nt it la b lb lc le lf lh nu ll nv lp nw lt op ny nz oa bi translated">根据训练数据拟合模型。</li><li id="2765" class="ns nt it la b lb ob le oc lh od ll oe lp of lt op ny nz oa bi translated">对校准数据进行预测。</li><li id="1637" class="ns nt it la b lb ob le oc lh od ll oe lp of lt op ny nz oa bi translated">计算模型对校准数据产生的绝对误差。</li><li id="4bd6" class="ns nt it la b lb ob le oc lh od ll oe lp of lt op ny nz oa bi translated">从前一点得到的绝对误差分布中得到1- <code class="fe oj ok ol ni b">alpha</code>分位数。</li><li id="3177" class="ns nt it la b lb ob le oc lh od ll oe lp of lt op ny nz oa bi translated">对测试数据进行预测。</li><li id="6cfb" class="ns nt it la b lb ob le oc lh od ll oe lp of lt op ny nz oa bi translated">通过将点4获得的分位数与点5获得的预测值相减(相加)来计算区间的左(右)端。</li></ol><p id="ab61" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以用几行Python代码轻松再现该算法:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="5a7f" class="nm mk it ni b gy nn no l np nq"><strong class="ni iu"># 1. Fit model on training data<br/></strong>model = RandomForestRegressor().fit(X_train, y_train)</span><span id="77a7" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># 2. Make prediction on calibration data<br/></strong>y_cal_pred = model.predict(X_cal)</span><span id="1783" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># 3. Compute absolute errors made by the model on calibration data<br/></strong>y_cal_error = np.abs(y_cal - y_cal_pred)</span><span id="5974" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># 4. Get 1-alpha quantile from the distribution of absolute errors<br/>#    Note: this is a single number<br/></strong>quantile = y_cal_error.quantile(q=.95, interpolation='higher')</span><span id="b093" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># 5. Make prediction on test data<br/></strong>y_test_pred = model.predict(X_test)</span><span id="2ed9" class="nm mk it ni b gy nr no l np nq"><strong class="ni iu"># 6. Compute left (right) end of the interval by<br/>#    subtracting (adding) the quantile to the predictions<br/></strong>y_test_interval_pred_left = y_test_pred - quantile<br/>y_test_interval_pred_right = y_test_pred + quantile</span></pre><p id="f6da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是<code class="fe oj ok ol ni b">y_cal_error</code>的直方图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/9ce42a1087af812c9632cb8bed8e7f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8U6XIqLPN_NTaC2dWpCipg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">校准误差直方图和α= 5%的分位数。[图片由作者提供]</p></figure><p id="e4b5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当<code class="fe oj ok ol ni b">alpha</code>为5%时，<code class="fe oj ok ol ni b">quantile</code>等于1.18。这意味着随机森林回归器产生的误差在5%的情况下高于1.18亿美元(在95%的情况下低于1.18亿美元)。此时，通过简单地将随机森林所做的预测加上和减去118k $,就可以获得区间预测:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/37d85da8fcaecafea0a6a43fd9419d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3pgGfyK5zdkggmroDPsjlA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">MAPIE中点预测与区间预测的关系。[图片由作者提供]</p></figure><p id="de87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就是这样。如果你已经理解了这段代码，那么<strong class="la iu">恭喜你:你已经掌握了MAPIE </strong>背后的逻辑！</p><p id="f772" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个库还包含了这个基本算法的一些细微变化，我们将在下一段中看到。</p><h1 id="3c9b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">其他模式</h1><p id="e456" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">到目前为止，我们一直在“prefit”模式(<code class="fe oj ok ol ni b">cv="prefit"</code>)下使用MAPIE。“Prefit”意味着模型(在我们的例子中是一个随机森林)是预先拟合的。但是，根据我们选择的参数，还有其他的可能性。这是<code class="fe oj ok ol ni b">MapieRegressor</code>的大致结构:</p><p id="59a2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe oj ok ol ni b">MapieRegressor(estimator=model, cv=cv, method=method)</code></p><p id="fb9b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，决定MAPIE行为的参数是<code class="fe oj ok ol ni b">cv</code>和<code class="fe oj ok ol ni b">method</code>。让我们分别来看:</p><ul class=""><li id="e2b0" class="ns nt it la b lb lc le lf lh nu ll nv lp nw lt nx ny nz oa bi translated"><code class="fe oj ok ol ni b">cv</code>:交叉验证的折叠次数(除非等于“prefit”，此时不进行交叉验证)；</li><li id="2e76" class="ns nt it la b lb ob le oc lh od ll oe lp of lt nx ny nz oa bi translated"><code class="fe oj ok ol ni b">method</code>:“幼稚”、“贱”、“加”、“最大化”之一。该参数仅在<code class="fe oj ok ol ni b">cv</code>不同于“前缀”时使用。“naive”类似于“prefit”，但校准数据与训练数据相吻合。“base”类似于“prefit”，但是预测误差是从交叉验证过程中获得的。“plus”类似于base，但每个区间都是测试预测的分位数加上验证残差。“最小最大值”类似于“加号”，但是使用了来自交叉验证模型的最小和最大预测值。</li></ul><p id="8481" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里就不深究各种方法的细节了。我们将在一些真实数据集上尝试它们，看看它们的表现如何。</p><p id="c0ba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">我们用来评估MAPIE输出质量的标准是与</strong> <code class="fe oj ok ol ni b"><strong class="la iu">alpha</strong></code>的正距离。的确，既然<code class="fe oj ok ol ni b">alpha</code>被定义为我们愿意接受的错误百分比，那么问题就出在<code class="fe oj ok ol ni b">% out of interval</code>大于<code class="fe oj ok ol ni b">alpha</code>的时候。</p><p id="db30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们感兴趣的量是:</p><pre class="kj kk kl km gt nh ni nj nk aw nl bi"><span id="2316" class="nm mk it ni b gy nn no l np nq">df["breach"] = (df["% out of interval"] — df["alpha"]).clip(lower=0)</span></pre><p id="e4b4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的示例中，这将是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/78e4e719aec5fcbdcb1bec86381e25ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RwaXZ_Z9yRsuqLk1WQg08g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将alpha与超出区间的观察值百分比进行比较。[图片由作者提供]</p></figure><p id="4e6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，<strong class="la iu">列</strong> <code class="fe oj ok ol ni b"><strong class="la iu">breach</strong></code> <strong class="la iu">的简单平均值是MAPIE </strong>预测的间隔有多差的指标:该数字越高，MAPIE性能越差。</p><p id="ea0b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们看看这种方法在不同的数据集上是如何变化的。除了上面引用的加州住房数据集，我还使用了来自<a class="ae ng" href="https://github.com/pycaret/pycaret" rel="noopener ugc nofollow" target="_blank"> Pycaret </a>的“帕金森”、“钻石”和“交通”数据集，这是在<a class="ae ng" href="https://github.com/pycaret/pycaret/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank">麻省理工学院许可</a>下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/904bb80ac74f7fc2b3242f1002a4c19a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mMebUP8WgR_IJobyyXfx5g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">各种数据集的MAPIE与alpha的平均正偏差(越低越好)。左上:帕金森数据集(Pycaret)。右上:加州数据集(Scikit-learn)。左下角:钻石数据集(Pycaret)。右下角:交通数据集(Pycaret)[图片由作者提供]</p></figure><p id="1669" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，当你使用<code class="fe oj ok ol ni b">cv="prefit"</code>时，不使用<code class="fe oj ok ol ni b">method</code>，这就是为什么列<code class="fe oj ok ol ni b">prefit</code>总是不变的原因。</p><p id="85e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">简而言之，<strong class="la iu">你要一直避开</strong> <code class="fe oj ok ol ni b"><strong class="la iu">method="naive"</strong></code> <strong class="la iu">，因为它的表现一直不好</strong>。关于剩下的选项，<code class="fe oj ok ol ni b">method="base"</code>、<code class="fe oj ok ol ni b">method="plus"</code>和<code class="fe oj ok ol ni b">method="minmax"</code>工作得很好，但是你应该考虑到它们是基于交叉验证的，所以如果你处理真正的大数据，它们需要更多的时间。</p><p id="85ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">总的来说，<code class="fe oj ok ol ni b">cv="prefit"</code>的性能几乎和其他选项一样好，而且速度更快。此外，它在现实生活中更方便，在现实生活中，您已经有一个拟合的模型，并希望从中“提取”区间预测。</p><h1 id="a53b" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">MAPIE的弱点</h1><p id="988b" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们都知道，直觉上，有些预测比其他的更难。这应该反映在间隔的宽度上。<strong class="la iu">有理由预期，预测越不确定，区间越大</strong>。</p><p id="10e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是MAPIE，至少是它的基础版本，并不满足这个属性。事实上，为了获得区间，我们在预测中加入和减去了校准误差的分位数。但是分位数是一个数字，因此所有观测值的区间宽度是相同的。</p><p id="c1ea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，基本上，<strong class="la iu">这就像你只是估计一个与预测模型相关的区间，然后将它复制粘贴到所有的观察值上</strong>。</p><p id="5388" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，使用<code class="fe oj ok ol ni b">method="plus"</code>或<code class="fe oj ok ol ni b">method="minmax"</code>，输出间隔将不会有相同的确切宽度。但这只是一种“扰动”，最终的区间不会有实质性的不同。事实上，让我们来看看加州住房数据集的预测区间宽度的分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/9bc2550b4cdca198ff7bb6322f37a9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3uZNbyZ8LsyJerrhJ23Bng.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加州住房数据集上method="plus "(左)和method="minmax "(右)时预测区间宽度的分布。[图片由作者提供]</p></figure><p id="ea30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，间隔的宽度没有太大的变化。采取“加”的方法(左):至少75%的区间在220k $和223k $宽之间:它们的宽度几乎相同。</p><h1 id="c671" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">外卖食品</h1><p id="dbc3" class="pw-post-body-paragraph ky kz it la b lb nb ju ld le nc jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">MAPIE是一个Python库，用于将模型做出的点预测转化为区间预测。它是模型不可知的，因此您可以保留您最喜欢的ML模型，并且仍然具有强大的统计保证，即预测区间符合您设置的容差。</p><p id="8a8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，你必须意识到，从根本上来说，间隔的宽度都是一样的。因此，与其为每个观察值估计一个时间间隔，不如只估计一个时间间隔，然后将该时间间隔应用于所有观察值。</p><p id="27f2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想知道如何预测与每次观察相关的风险的“定制”区间，你可以阅读我下面的文章“共形分位数回归”:</p><div class="ov ow gp gr ox oy"><a rel="noopener follow" target="_blank" href="/how-to-predict-risk-proportional-intervals-with-conformal-quantile-regression-175775840dc4"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">如何用“共形分位数回归”预测风险比例区间</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">这种算法-由斯坦福大学学者于2019年发表-结合了分位数回归和保形预测。这里…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">towardsdatascience.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm ks oy"/></div></div></a></div></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><blockquote class="pu pv pw"><p id="abd5" class="ky kz px la b lb lc ju ld le lf jx lg py li lj lk pz lm ln lo qa lq lr ls lt im bi translated"><em class="it">感谢您的阅读！我希望你喜欢这篇文章。如果你愿意，</em> <a class="ae ng" href="https://www.linkedin.com/in/samuelemazzanti/" rel="noopener ugc nofollow" target="_blank"> <em class="it">在Linkedin上加我</em> </a> <em class="it">！</em></p></blockquote></div></div>    
</body>
</html>