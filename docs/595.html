<html>
<head>
<title>Improve Apache Spark performance with the S3 magic committer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用S3魔术提交器提高Apache Spark性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improve-apache-spark-performance-with-the-s3-magic-committer-257a34e367af#2022-01-20">https://towardsdatascience.com/improve-apache-spark-performance-with-the-s3-magic-committer-257a34e367af#2022-01-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="7394" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">使用S3魔术提交器提高Apache Spark性能</h1></div><div class=""><h2 id="0c2c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Spark 3.2和Hadoop 3.3的最新S3 magic committer实现高达65%的性能提升！</h2></div><p id="7619" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大多数Apache Spark 用户忽略了S3提交器的选择(Spark在将输出结果写入S3时使用的一种协议)，因为它相当复杂，并且关于它的文档很少。每当Spark向S3写入数据时，这种选择都会对性能产生重大影响。由于对于AWS用户来说，Spark工作的很大一部分都花在了给S3写信上，所以选择合适的S3提交者非常重要。</p><p id="0423" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着<a class="ae lb" href="https://www.datamechanics.co/blog-post/apache-spark-3-2-release-main-features-whats-new-for-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank"> Apache Spark 3.2于2021年10月</a>发布，一种特殊类型的S3提交器<strong class="kh ir">魔法提交器</strong>得到了显著改进，使其性能更高、更稳定、更易于使用。</p><p id="01b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在我们客户的一些管道上测试了S3提交器，并意识到对于像<a class="ae lb" href="https://www.datamechanics.co/blog-post/cost-effective-weather-analytics-at-scale-with-cloud-native-apache-spark" rel="noopener ugc nofollow" target="_blank"> Weather20/20 </a>这样的客户，它将Spark作业的速度提高了65%。<strong class="kh ir">我们现在向所有AWS Spark用户推荐使用该提交器。</strong> ‍</p><p id="b235" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是我们将在这篇博文中涉及的内容:</p><ul class=""><li id="eb43" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">什么是S3委员？为什么我应该使用魔法提交器？</li><li id="79d0" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">它能带来哪些性能优势？</li><li id="7d0c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">我怎样才能打开魔法提交器？</li><li id="b9a7" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">Spark 3.2发生了什么？对未来的Spark版本有什么期待？</li></ul><h1 id="221a" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">什么是S3委员？为什么我应该使用魔法提交器？</h1><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mi"><img src="../Images/b6b72018b4059baab4c5e0fce67b8ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZadgqXRgkLDa3m2E4INLw.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">下面是默认提交器(FileOutputCommiter)的工作方式。图片作者。</p></figure><p id="7325" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Apache Spark和之前的Hadoop MapReduce一样，将工作的输出写在文件系统中。更准确地说，许多Spark任务并行运行，每个Spark任务将其输出作为文件写入。系统必须产生一致的输出，即使:</p><ul class=""><li id="a647" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">一些任务可以在进行中被中断(例如，定点清除、执行器内存不足错误)并在另一个执行器上重试</li><li id="f17e" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">同一任务的多个副本可以在不同的执行器上并行执行(一种称为推测的机制，有助于提高性能)</li></ul><p id="64bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解决这个问题，Hadoop MapReduce使用了一种称为提交协议的技术，它列出了中间输出目录，并将文件重命名到它们的最终位置。这在Hadoop分布式文件系统(HDFS)上运行良好，因为列出目录会产生一致的结果，重命名文件是一个快速的“O(1)”操作。</p><p id="3bd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然对HDFS来说是这样，但对S3来说却不是这样。在S3上重命名文件*不是*原子操作，它是作为一个<strong class="kh ir">复制</strong>和一个<strong class="kh ir">删除</strong>操作来实现的，运行起来大约需要6MB/秒。</p><p id="a29d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，Spark的默认作业提交器(称为<strong class="kh ir">fileoutputcommitter</strong>)与S3一起使用是不安全的。例如，如果在重命名操作进行过程中出现故障，数据输出可能会损坏。除了不安全之外，它还可能非常慢。</p><p id="f8d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解决这个问题，社区为S3开发了特殊的提交器，称为S3A提交器:</p><ul class=""><li id="74ae" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">网飞开发的staging committer。它工作得很好，但是它需要像HDFS或NFS这样的集群级共享存储来存储中间输出文件，这不太方便设置，特别是对于Spark-on-Kubernetes用户来说。</li><li id="5b5e" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">magic committer，由社区领导，是新的Hadoop默认值。</li></ul><p id="918e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最初，magic committer有一个很大的缺点:它需要安装一个Dynamodb数据库来启用一个名为S3Guard的S3客户端机制(“保护”您避免不一致的结果)。</p><p id="e0fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自2020年12月以来，<a class="ae lb" href="https://aws.amazon.com/about-aws/whats-new/2020/12/amazon-s3-now-delivers-strong-read-after-write-consistency-automatically-for-all-applications/" rel="noopener ugc nofollow" target="_blank"> S3在全球范围内提供了强大的写后读一致性</a>，这意味着在写入文件后，当您列出目录时，您一定会看到文件(就像在笔记本电脑的硬盘上一样)。因此，没有必要再安装S3Guard，这使得magic committer更易于使用。</p><blockquote class="my mz na"><p id="9ff3" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">要深入了解这个主题，请参阅官方Hadoop文档<a class="ae lb" href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/committers.html" rel="noopener ugc nofollow" target="_blank">和这篇由Steve Loughran和其他Apache贡献者撰写的关于“零重命名提交者”的研究论文</a><a class="ae lb" href="https://github.com/steveloughran/zero-rename-committer/releases/tag/tag_release_2021-05-17" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="b511" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">重要提示:</strong>如果您使用纯清单表格式，如Delta.io、Apache Iceberg或Apache胡迪，S3提交器与您无关，因为这些表格式处理提交过程的方式不同。</p><h1 id="b6a5" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">S3提交者可以实现哪些性能优势？</h1><p id="b684" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">确切的性能收益取决于工作负载，但是根据经验，如果您的Spark工作的很大一部分用于向S3写入数据(这是一种非常常见的情况)，收益将会非常显著。除了性能优势之外，使用magic committer代替默认的FileOutputCommitter还可以保护您在边缘情况下免受讨厌的数据损坏错误(执行器丢失、推测等)。</p><p id="7ab1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们评估一下我们的一个客户<a class="ae lb" href="https://www.datamechanics.co/blog-post/cost-effective-weather-analytics-at-scale-with-cloud-native-apache-spark" rel="noopener ugc nofollow" target="_blank"> Weather20/20 </a>在真实世界Spark管道上的性能优势，这是一个天气分析平台。在使用magic committer之前，他们的管道将运行许多Spark作业和任务一个小时，然后“休息”近一个小时，在此期间，Spark似乎是空闲的，因为没有执行任何任务，然后最终退出。</p><p id="00e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过查看我们的免费Spark监控工具<a class="ae lb" href="https://github.com/datamechanics/delight" rel="noopener ugc nofollow" target="_blank"> Delight </a>，这个问题非常明显:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nk"><img src="../Images/07af34c3b5f7e00164eff78515172837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vq8Po9PvoH-r1pH3.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">右边的灰色区域表示所有Spark执行器都空闲了将近一个小时——然而Spark作业并没有退出。图片作者。</p></figure><p id="7feb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark应用结束时的48分钟中断在Spark driver日志中也清晰可见:</p><blockquote class="my mz na"><p id="9910" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">21/11/08 20:52:11 INFO Dag scheduler:作业7已完成:在nativemethodaccessorimpl . Java:0处插入，耗时3495.605049秒</p><p id="e9dd" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">21/11/08 21:40:13信息文件格式写入程序:写入作业13 ca 8 CB 6–5fc 0–4fe 9–9fd 0-bb a5 cf 9 e 2f 7 f已提交。</p></blockquote><p id="18bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后一行提示在20:52到21:40之间，Spark正在运行FileOutputCommitter协议的<a class="ae lb" href="https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/FileFormatWriter.scala#L264" rel="noopener ugc nofollow" target="_blank">作业提交</a>步骤。如前所述，S3重命名操作非常慢(对于大型数据集)。除了缓慢的S3调用之外，提交者正在进行成千上万的S3调用，在某些情况下，这些调用可以被S3抑制(您可以通过启用S3日志并查找503 API响应来确认这一点)。</p><p id="3da4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过切换到magic committer，下面是应用程序愉悦图的样子:</p><figure class="mj mk ml mm gt mn gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nk"><img src="../Images/53517fdaf02e6986427962893f6ca75e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4s5ntlr1aGgZyXv-.png"/></div></div><p class="mu mv gj gh gi mw mx bd b be z dk translated">Spark应用结束的空闲时间几乎完全消失了。图片作者。</p></figure><p id="8cb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这条管道现在只需40分钟，而以前需要1小时48分钟。这是一个<strong class="kh ir"> 63% </strong>的提升！这条管道可能是一个特别极端的改进例子，但我们经常看到向S3写入大量数据的管道有15–50%的改进。所以你绝对应该亲自尝试一下。</p><h1 id="d4ed" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">我怎样才能打开魔法提交器？</h1><p id="1185" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">您可以通过在sparkConf中插入一个配置标志来打开它:<strong class="kh ir">" spark . Hadoop . fs . s3a . bucket . all . committer . magic . enabled ":" true "</strong></p><blockquote class="my mz na"><p id="fcba" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kh ir">注意:</strong>以前需要在您的spark配置键<strong class="kh ir"><em class="iq">spark . Hadoop . fs . s3a . bucket .&lt;bucket&gt;. committer . magic . enabled .</em></strong>中提供bucket名称，这是因为最初您必须在每个bucket的基础上安装S3Guard。现在S3已经非常稳定了，这已经没有必要了。如果传递标志<strong class="kh ir"><em class="iq">spark . Hadoop . fs . s3a . bucket . all . committer . magic . enabled，</em></strong>magic committer将在所有bucket上使用。</p></blockquote><p id="9a1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您还需要将<a class="ae lb" href="https://mvnrepository.com/artifact/org.apache.spark/spark-hadoop-cloud" rel="noopener ugc nofollow" target="_blank"> spark-hadoop-cloud </a>库包含在docker映像中或作为一个依赖项，因为它提供了S3A提交者使用的类。如果您缺少这个依赖项，您将会得到一个类似这样的错误:<strong class="kh ir"><em class="nb">Java . lang . classnotfoundexception:org . Apache . spark . internal . io . cloud . pathoutputcommitprotocol</em></strong></p><p id="3f43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要验证是否使用了神奇的提交器，最简单的方法是在Spark驱动程序日志中查找单词“committer”。</p><p id="97c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您看到这样的日志:</p><blockquote class="my mz na"><p id="fc0f" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">21/11/08 19:53:54 WARN abstracts 3a Committer factory:21/11/08 19:53:54 INFO FileOutputCommitter:文件输出提交器算法版本为1 <strong class="kh ir">使用标准File Output Committer提交工作。这既慢又有潜在的不安全。</strong></p></blockquote><p id="ea6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么就有一个问题了——使用了标准的FileOutputCommitter。正如警告所说，它速度慢，而且有潜在的不安全因素。但是，如果您看到下面的日志，那么您就知道magic committer被正确地使用了:</p><blockquote class="my mz na"><p id="267c" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">21/11/14 00:05:11信息摘要3ACommitterFactory: <strong class="kh ir">使用committer magic </strong>将数据输出到s3a://…</p></blockquote><h1 id="db66" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">Spark 3.2发生了什么？对未来的Spark版本有什么期待？</h1><p id="efdf" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">Spark 3.2使得魔术提交器更容易使用(<a class="ae lb" href="https://issues.apache.org/jira/browse/SPARK-35383" rel="noopener ugc nofollow" target="_blank"> SPARK-35383 </a>)，因为你可以通过插入一个配置标志来打开它(以前你必须传递4个不同的标志)。Spark 3.2也建立在Hadoop 3.3.1的基础上，Hadoop 3 . 3 . 1包含了针对magic committer的错误修复和性能改进。<a class="ae lb" href="https://www.datamechanics.co/blog-post/apache-spark-3-2-release-main-features-whats-new-for-spark-on-kubernetes" rel="noopener ugc nofollow" target="_blank">阅读我们关于Spark 3.2的文章</a>，了解更多关于这个版本的主要特性和改进。</p><blockquote class="my mz na"><p id="59e1" class="kf kg nb kh b ki kj jr kk kl km ju kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kh ir"> <em class="iq">注:</em> </strong>另一个无关的Hadoop 3.3改进。如果通过配置标志<strong class="kh ir"><em class="iq">" spark . Hadoop . fs . s3a . directory . marker . retention ":" keep "</em></strong>Hadoop会停止不必要的删除<a class="ae lb" href="https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/directory_markers.html" rel="noopener ugc nofollow" target="_blank">目录标记</a>。您需要选择加入这种行为(您需要传递标志)，因为它不是向后兼容的。只有当所有Spark应用程序都使用Hadoop 3.3+时，才应该传递这个标志。</p></blockquote><p id="f469" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Steve Loughran(自2000年以来一直是Apache软件基金会的成员)正在为Azure和GCP的对象存储(<a class="ae lb" href="https://issues.apache.org/jira/browse/MAPREDUCE-7341" rel="noopener ugc nofollow" target="_blank"> MAPREDUCE-7341 </a>)构建类似的任务清单提交算法，并提高magic committer(<a class="ae lb" href="https://issues.apache.org/jira/browse/HADOOP-17833" rel="noopener ugc nofollow" target="_blank">HADOOP-17833</a>)的性能。这是一个巨大的工作量(谢谢史蒂夫！)首先需要贡献给Hadoop，然后由一个新的Spark版本来完成。</p><h1 id="b6d3" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">结论</h1><p id="5231" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">从Spark 3.2开始，我们向通过管道向S3写入数据的AWS Spark用户强烈推荐magic committer(除非他们已经在使用像Delta、胡迪或Iceberg这样的表格式)。通过切换单个配置标志，您可以在管道上实现高达65%的性能提升，并避免由默认的FileOutputCommitter导致的严重的数据损坏错误。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><p id="ff4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nb">原NetApp博客现场发布:</em><a class="ae lb" href="https://spot.io/blog/improve-apache-spark-performance-with-the-s3-magic-committer/" rel="noopener ugc nofollow" target="_blank"><em class="nb">https://spot.io/blog/</em></a></p></div></div>    
</body>
</html>