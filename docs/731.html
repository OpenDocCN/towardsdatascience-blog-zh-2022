<html>
<head>
<title>The Intuition Behind Graph Convolutions and Message Passing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图形卷积和消息传递背后的直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-intuition-behind-graph-convolutions-and-message-passing-6dcd0ebf0063#2022-01-26">https://towardsdatascience.com/the-intuition-behind-graph-convolutions-and-message-passing-6dcd0ebf0063#2022-01-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="6010" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">图形卷积和消息传递背后的直觉</h1></div><div class=""><h2 id="bb65" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">图神经网络中图卷积和消息传递之间的关系及图分类实例。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/5e8d1787cdb82920403f547ea9cb0f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*UWmKxuehjpDk-cXY5pBUCA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">【图片由作者提供】。</p></figure><h2 id="40fa" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">内容</h2><p id="badb" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在接下来的文章中，我们将介绍图形卷积背后的基本思想和建立一些直觉，研究如何基于消息传递机制建立图形卷积神经网络，并创建一个模型来用嵌入可视化对分子进行分类。</p><h2 id="50a1" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">问题陈述的示例</h2><p id="dbe7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">让我们想象我们设计药物来治疗某种疾病。让我们假设我们有一个数据集，其中包含成功治疗该疾病的药物和无效的药物。我们现在正在设计一种新药，想知道它是否能治疗这种疾病。如果我们可以创建一个有意义的药物表示，我们就可以训练一个分类器来预测它对疾病治疗是否有用。我们的药物是分子，可以用图表来表示。这个图的节点是原子。也可以用特征向量<strong class="ls iu"> <em class="mj"> x </em> </strong>来描述原子(它可以由原子属性组成，如质量、电子数或其他)。为了对分子进行分类，我们希望利用关于其空间结构和原子特征的知识来获得一些有意义的表示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/78b548814cd6fed140a1d46b5edce78b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-oNw_plmVP0oGduEKfIgzQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">用图形表示的分子的例子。原子有它们的特征向量x，特征向量中的索引代表节点索引[图片由作者提供]。</p></figure><h2 id="a0f3" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">那么我们能做什么呢？</h2><p id="fae4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">最直接的方法是聚集特征向量，例如，简单地取它们的平均值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/79bd9ef66bf008c6943c1f9504171b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*3aGTxH5xkM88CJ1fVxI4Xg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">节点特征向量的平均。</p></figure><p id="ff94" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">这是一个有效的解决方案，但是它忽略了分子的空间结构，而空间结构是很重要的。</p><p id="4a31" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">人们可以提出另一个想法:用<a class="ae mv" href="https://en.wikipedia.org/wiki/Adjacency_matrix" rel="noopener ugc nofollow" target="_blank">邻接矩阵</a>表示分子图，并用特征向量“扩展”其深度。结果，我们获得伪图像[8，8，N]，其中N是节点特征向量<strong class="ls iu"> <em class="mj"> x </em> </strong>的维数。现在有可能使用常规卷积神经网络并提取嵌入的分子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mw"><img src="../Images/7fcd4649c859b3d6d998b9f60581819c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HnTqBST3pa8-u5v5CXIvBw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图结构可以表示为邻接矩阵。节点特征可以表示为图像中的通道(括号代表串联)[Image by author]。</p></figure><p id="c5af" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">这种方法利用了图形结构，但有一个巨大的缺点:如果我们改变节点的顺序，我们会得到不同的表示。所以这种表示不是置换不变量。然而，相反的情况是可取的:邻接矩阵中的节点顺序是任意的。例如，我们可以将列顺序从[0，1，2，3，4，5，6，7]更改为[0，2，1，3，5，4，7，6]，它仍然是图的有效邻接矩阵。我们可以创建所有可能的排列并将它们堆叠在一起，这将导致1625702400个可能的邻接矩阵(8！* 8!).那似乎是过分的，所以我们应该找到更好的。</p><p id="d80a" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">问题是，我们如何整合空间信息，并有效地做到这一点？上面的例子可以让我们想到卷积的概念，但它应该在图形上进行。</p><h2 id="1db1" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图形卷积背后的直觉</h2><p id="6998" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">当我们对图像应用正则卷积时会发生什么？相邻像素的值乘以滤波器权重并求和。我们能在图上做类似的事情吗？是的，我们可以将节点特征向量堆叠在一个矩阵<strong class="ls iu"> <em class="mj"> X </em> </strong>中，并将它们乘以邻接矩阵<strong class="ls iu"> <em class="mj"> A </em> </strong>，然后我们获得更新的特征<strong class="ls iu"> <em class="mj"> X` </em> </strong>，其结合了关于节点最近邻居的信息。为简单起见，让我们考虑一个具有标量节点特征的示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mx"><img src="../Images/207b0ff875f28dd9f5a80e3aafe1928c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUDCBe6dEUDYMYXZXnlslQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">标量值结点要素的示例。仅针对节点0说明了1跳距离，但所有其他节点都适用[图片由作者提供]。</p></figure><p id="053f" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">因此，每个节点都会获得关于其最近邻居的信息(也称为1跳距离)。邻接矩阵上的乘法将特征从节点传播到节点。</p><p id="c852" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">在图像域中，我们可以通过增加滤波器尺寸来扩展感受野。在图中，我们也可以考虑更远的邻居。如果将<strong class="ls iu"><em class="mj"/></strong>乘以<strong class="ls iu"><em class="mj">X</em></strong>——关于两跳距离的节点的信息传播到这些节点:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mx"><img src="../Images/cd66f056104cd7edae37d4fc004aef15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KjpnlwFuXC4saN5L61ujug.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">注意，节点0现在有了关于在2跳距离内的节点2的信息。仅说明了节点0的跳数，但所有其他节点都是如此[图片由作者提供]。</p></figure><p id="5f28" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">矩阵的高次幂<strong class="ls iu"><em class="mj"/></strong>以相同的方式工作:乘以<strong class="ls iu"> <em class="mj"> A^n </em> </strong>导致从n跳距离节点传播特征。<strong class="ls iu"> <em class="mj"> </em> </strong>所以我们可以通过对邻接矩阵的高次幂增加乘法来扩展“感受野”。为了概括这个操作，可以将节点更新的函数定义为这样的乘法的和，这些乘法具有一些权重<strong class="ls iu"> <em class="mj"> w </em> </strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/d406254d6800c7e7967fab1e8393122d.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*6RmFwhFIHxnY_j2YxwLKgQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">多项式图形卷积滤波器。a-图邻接矩阵，w-标量权重，x-初始节点特征，x '-更新的节点特征。</p></figure><p id="5511" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">所以新特性<strong class="ls iu"><em class="mj">【x’</em></strong>看起来是一些来自n-hop距离中节点的混合物的影响，相应的距离由权重<strong class="ls iu"> <em class="mj"> w </em> </strong>控制。这样的操作可以被认为是与由权重<strong class="ls iu"><em class="mj">【w】</em></strong>参数化的滤波器<strong class="ls iu"> <em class="mj"> P </em> </strong>的图形卷积。与图像上的卷积类似，图卷积滤波器也可以具有不同的感受域，并且聚集关于节点邻居的信息，但是邻居的结构不应该像图像中的卷积核那样规则。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mz"><img src="../Images/276b11d6b1505c3c825783733fd4a8bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAgLl5Z4p1YTyySuJTj1Hg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图形卷积和图像卷积的相似性【图片由作者提供】。</p></figure><p id="1341" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">这种多项式满足一般卷积的置换等变。可以使用图拉普拉斯算子而不是邻接矩阵来在节点之间传递特征差异而不是特征值。也可以使用邻接矩阵或图拉普拉斯的规范化形式。</p><blockquote class="na nb nc"><p id="48d7" class="lq lr mj ls b lt mq ju lv lw mr jx ly nd ms ma mb ne mt md me nf mu mg mh mi im bi translated">将图卷积表示为多项式的能力可以从一般的谱图卷积中得到。例如，利用具有图拉普拉斯算子的切比雪夫多项式的滤波器提供了直接谱图卷积的近似[ <a class="ae mv" href="https://arxiv.org/pdf/1606.09375.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]。</p></blockquote><p id="a135" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">请注意，我们可以很容易地将其推广到任何维度的节点特征，并保持相同的方程。唯一不同的是，在更高维的情况下，我们处理的是节点特征矩阵<strong class="ls iu"> <em class="mj"> X </em> </strong>而不是节点特征向量。例如对于N个<strong class="ls iu"><em class="mj"/></strong>节点和1个<strong class="ls iu"> <em class="mj">或M个</em> </strong>节点我们得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/7f27d61d39902f4efabdd753a56e2b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*VVNUceo_GuOZCQsmN2iprA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">X-节点特征向量，X-堆叠节点特征，M-节点特征向量的维度，N-节点数量。</p></figure><p id="134f" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">请注意，我们可以将特征向量的“深度”维度视为图像卷积中的“通道”。</p><h2 id="27d3" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">信息传递</h2><p id="abf5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">现在让我们以稍微不同的方式来考虑同样的话题。让我们采用上面讨论的仅具有前两项的简单多项式卷积，并让<strong class="ls iu"> <em class="mj"> w </em> </strong>等于1:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/5b8a42b53dea8da6876f429edb74ac2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*o-rV27-gQ6bNAtWj2y6Vsw.png"/></div></figure><p id="a3fb" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">所以现在如果我们将图形特征矩阵<strong class="ls iu"> <em class="mj"> X </em> </strong>乘以(<strong class="ls iu"> <em class="mj"> I + A </em> </strong>)我们得到如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ni"><img src="../Images/1e8d0ae7be06b69214216b87ec5736a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TfqalL4w3CzjBMFoj0jEFA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">【图片由作者提供】。</p></figure><p id="e26a" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">可以看到所有特征发生了什么，对于每个节点，添加了相邻节点的总和。因此操作可以表示如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ac1c59cef773e8edcc5d313ec71fdcc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*SlCxzJ5x_PvKKWzsYrVlPA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">N(i)表示节点I的一跳距离邻居</p></figure><p id="dc18" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">在我们的例子中,“更新”和“聚集”只是简单的求和函数。</p><p id="330b" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">这种对节点特性更新的观点被称为消息传递机制。考虑这种消息传递的单次迭代相当于与过滤器<strong class="ls iu"> <em class="mj"> P= I + A </em> </strong>的图卷积。现在，如果我们想要从更远的节点传播信息，我们可以再次重复这样的操作几次，从而用更多的多项式项来近似图形卷积。</p><blockquote class="na nb nc"><p id="45aa" class="lq lr mj ls b lt mq ju lv lw mr jx ly nd ms ma mb ne mt md me nf mu mg mh mi im bi translated">如果重复几次图形卷积，会导致图形过度平滑，其中每个节点嵌入对于所有连接的节点都变成相同的平均向量。</p></blockquote><p id="6d44" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">现在，怎样才能增加表达信息传递的能力呢？您可以尝试聚合和更新功能，还可以转换节点功能:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/46af758dac65088c6e8ec2fe46ced766.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*vmniaJQSrL8UqsU7Z3wq4g.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">w1-更新结点要素的权重矩阵，W2-更新相邻结点要素的权重矩阵。</p></figure><blockquote class="na nb nc"><p id="856f" class="lq lr mj ls b lt mq ju lv lw mr jx ly nd ms ma mb ne mt md me nf mu mg mh mi im bi translated">请注意，可以使用任何排列不变函数进行聚合，如sum、max、mean或更复杂的函数，如<a class="ae mv" href="https://arxiv.org/pdf/1703.06114.pdf" rel="noopener ugc nofollow" target="_blank"> DeepSets </a>。</p></blockquote><p id="bf54" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">例如，评估消息传递的基本方法之一是<a class="ae mv" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank"> GCN </a>层:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/4666387352509225a00005142046b73e.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*vTlxRFkEvOEkZaCCmAnaog.png"/></div></figure><p id="4cd5" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">乍一看可能不太熟悉，但是让我们使用“更新”和“聚合”函数来看看它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/eb776765d2526f69486e8bc71933f54d.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*kvG-KqxC4ZllaoPgWvpogw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用单个矩阵W代替两个加权矩阵W1和W2。更新函数是总和，聚合函数是包括结点特征I在内的归一化结点特征的总和。d-表示<a class="ae mv" href="https://en.wikipedia.org/wiki/Degree_(graph_theory)" rel="noopener ugc nofollow" target="_blank">结点度</a>。</p></figure><p id="f128" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">我们有单个权重矩阵<strong class="ls iu"> <em class="mj"> W </em> </strong>而不是两个，用<a class="ae mv" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank"> Kipf和Welling归一化</a>求和作为聚合，再加一个求和作为更新函数。注意，聚合会评估邻居和节点<strong class="ls iu"> <em class="mj"> i </em> </strong>本身，这相当于将自循环添加到一个图中。</p><p id="b8d8" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">因此，具有消息传递机制的GNN可以表示为重复多次的聚集和更新功能。消息传递的每次迭代可以被认为是一个新的GNN层。节点更新的所有操作都是可微分的，并且用可以学习的权重矩阵来参数化。现在，我们可以构建一个图形卷积网络，并研究它的性能。</p><h1 id="f522" class="nn kv it bd kw no np nq kz nr ns nt lc jz nu ka lg kc nv kd lk kf nw kg lo nx bi translated">实际例子</h1><p id="ca5c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">现在让我们使用上面提到的GCN层来构建和训练图形神经网络。对于这个例子，我将使用已经实现了许多层的<a class="ae mv" href="https://pytorch-geometric.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> PyG </a>库，包括一个GCN层。为了举例，我将使用<a class="ae mv" href="https://wiki.nci.nih.gov/display/NCIDTPdata/AIDS+Antiviral+Screen+Data" rel="noopener ugc nofollow" target="_blank">辅助</a>图形数据集【2，3】。它由2000个代表分子化合物的图表组成:其中1600个被认为对艾滋病毒无活性，400个对艾滋病毒有活性。每个节点都有一个包含38个特征的特征向量。以下是来自数据集的分子图表示示例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ny"><img src="../Images/30ae26b48e88e67aa63c0a50b807c356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPCN5mHS9uostXcVkVCl2g.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">使用<a class="ae mv" href="https://networkx.org/" rel="noopener ugc nofollow" target="_blank">网络x </a>库对来自艾滋病数据集的样本进行可视化【图片由作者提供】。</p></figure><p id="7fdf" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">为了简单起见，我们将建立一个只有3个GCN层的模型。对于嵌入空间可视化，最终嵌入维度将是2-d。为了得到图形嵌入，我们将使用平均聚合。为了对分子进行分类，将在图形嵌入的顶部使用简单的线性分类器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nz"><img src="../Images/25743345ca19476ec71bb82db117256c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ynamnEAIVFZzTVRdkzW7Vg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">具有三个GCN层、平均池和线性分类器的图形神经网络。</p></figure><p id="9723" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">对于第一次消息传递迭代(第1层)，初始特征向量被投影到256维空间。在第二次消息传递(第2层)期间，在相同维度上更新特征向量。在第三次消息传递(第3层)期间，特征被投影到2-d空间上，然后应用所有节点特征的平均来获得最终的图形嵌入。最后，这些嵌入被馈送到线性分类器。请注意，选择最终的2-d维度只是为了可视化，维度越高效果越好。这种模型可以使用PyG库来实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="ee8f" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">那么它可以被训练成通常的具有二进制交叉熵损失的Pytorch模型。在训练过程中，我们可以可视化图形嵌入和分类器决策边界。通过这样做，我们可以看到消息传递操作如何仅用3个图卷积层就产生有意义的图嵌入。注意，随机初始化的模型嵌入没有线性可分的分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/0d15531f30cc4c44b5cd61b5984b8cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*QLKTND5zheiicQUSTmg2Pw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">分子嵌入是通过正向传递随机初始化的模型获得的[图片由作者提供]。</p></figure><p id="6f0f" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">但是在训练期间，分子嵌入很快变得线性可分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e7ea12a042c2ab63f612670ca308c4bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/0*Y84CE_OytXluGURd"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">验证集和分类器决策边界的分子嵌入。</p></figure><p id="11c3" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated">因此，即使3个图形卷积层也可以评估有意义的2-d分子嵌入，这些嵌入可以用线性模型分类，在验证集上具有大约82%的准确性。</p><h2 id="da20" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h2><p id="761c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们看到了如何将图卷积表示为多项式，以及如何使用消息传递机制来逼近它。这种具有附加特征变换的方法具有强大的代表性，可以用于实际应用。我们几乎没有触及图形卷积和图形神经网络的表面。有几十种不同的图形卷积层和聚合函数架构。我们也不包括可以在图上完成的其他任务，比如节点分类、边重构等等。如果你想深入了解，PyG教程可能是一个很好的起点。</p></div><div class="ab cl oe of hx og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="im in io ip iq"><p id="dd93" class="pw-post-body-paragraph lq lr it ls b lt mq ju lv lw mr jx ly ld ms ma mb lh mt md me ll mu mg mh mi im bi translated"><strong class="ls iu">T3】参考文献:T5】</strong></p><ol class=""><li id="82af" class="ol om it ls b lt mq lw mr ld on lh oo ll op mi oq or os ot bi translated"><a class="ae mv" href="https://arxiv.org/pdf/1606.09375.pdf" rel="noopener ugc nofollow" target="_blank">具有快速局部谱滤波的图上卷积神经网络。Michal Defferrard，Xavier Bresson，Pierre Vandergheynst，EPFL，瑞士洛桑，2017年</a></li><li id="3c4e" class="ol om it ls b lt ou lw ov ld ow lh ox ll oy mi oq or os ot bi translated"><a class="ae mv" href="https://arxiv.org/pdf/2007.08663.pdf" rel="noopener ugc nofollow" target="_blank">图数据集:用图学习的基准数据集集合，克里斯多夫·莫利斯、尼尔斯·m·克里格、弗兰卡·鲍斯、克里斯蒂安·克斯汀、佩特拉·穆策尔、马里恩·诺依曼，2020年</a></li><li id="f242" class="ol om it ls b lt ou lw ov ld ow lh ox ll oy mi oq or os ot bi translated"><a class="ae mv" href="http://www.graphlearning.io/" rel="noopener ugc nofollow" target="_blank"> graphlearning.io </a></li></ol></div></div>    
</body>
</html>