# TensorFlow 中的音频增强

> 原文：<https://towardsdatascience.com/audio-augmentations-in-tensorflow-48483260b169>

## 直接加强和向前传球

对于基于图像的任务，研究人员和从业人员通常都依赖于增强。这些是(人工)数据转换，如旋转、模糊或调整大小。与其他数据类型的修改相比，图像增强可以很快被理解。通常，一瞥向我们展示了一个特定的图像是如何转变的。虽然增强在图像领域很常见，但它们对其他数据类型也很有用，如音频。

![](img/71dac1776bd913c03ba011cd7da5f2aa.png)

理查德·霍瓦特在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

在[早先的一篇博文](/visualizing-audio-pipelines-with-streamlit-96525781b5d9)中，我描述了一个简单的 GUI 来在浏览器中可视化这种增强。它还在运行，你可以在这里现场试用。在这篇文章中，我继续我早期的工作，并描述了如何在 TensorFlow 中将增强应用到数据集的两种方法。第一种方式直接修改数据；第二种方式是在网络的正向传递过程中实现的。

# 直接音频增强

在第一个场景中，我们从生成人工音频数据集开始。这个过程是直截了当的，并尽可能保持简单，所以你可以很容易地跟随。我们不加载预先存在的数据集，而是根据需要多次重复 librosa 库中的一个样本:

您可能已经注意到，在这个过程中，我们已经创建了一个 Dataset 对象。为了方便，我选择这样做；但是我们也可以使用纯 NumPy 数组。无论如何，音频数据现在与其采样率一起存储。如果您正在寻找其他方法来创建这样的数据集对象，您可以使用本[实践指南](/a-practical-guide-to-tfrecords-584536bc786c)中给出的方法之一。

既然我们的小数据集已经可以使用了，我们可以开始应用扩充了。对于这一步，我们使用了[一个*GUI 转换*库](https://github.com/iver56/audiomentations)(顺便说一下，这是为提到的 GUI 生成转换的库)。

为了简单起见，我们只导入三个修改，特别是 PitchShift、Shift 和 ApplyGaussianNoise。前两个移位音高(Pitchshift)和数据(Shift，可以认为是滚动数据；例如，狗的叫声将偏移+ 5 秒)。最后的变换使信号更加嘈杂，增加了神经网络以后的挑战。接下来，我们将所有三个扩展合并到一个管道中:

在通过管道输入数据之前，我们必须编写一些额外的代码。我们需要这样做，因为我们正在使用一个 Dataset 对象，简单地说，它在应用占位符之前通过一个函数输入占位符(这仅在实际数据加载期间完成！).

在我们的例子中，这个额外的代码告诉 TensorFlow 将张量临时转换为 NumPy 数组，这被管道接受:

有了这些辅助函数，我们现在可以扩充数据集了。此外，我们扩展了数据的维度，在末尾添加了一个人工轴。这将单个音频样本从(num_data_point，)变为(num_data_points，1)，表示我们有单声道音频。这是必要的，在这里我们通过网络来馈送数据:

这一节到此为止。应用增强后，任何后续操作，无论是网络还是其他，都将看到增强的数据。

# 向前传球时的音频增强

与第一种技术相比，增加网络内的音频数据会增加前向传递的计算负荷。

为此，我们将使用 kapre 库，它提供了自定义的 TensorFlow 图层。这些层中有 MelSpectrogram 层，它接受原始(即未修改的)音频数据，并在 GPU 上计算 Mel 缩放的频谱图*。*

虽然与数据扩充没有直接关系，但这有两个好处:

首先，我们可以在例如超参数搜索期间优化用于频谱图生成的参数，使得重复的音频-频谱图生成变得不必要。第二，转换直接在 GPU 上进行，因此速度更快，无论是在原始转换速度还是在设备上的存储器布局方面。

考虑到这些好处，我们可以在计算出光谱图后再进行扩充。尽管在撰写本文时可用转换的数量有限，但我们可以在概念上欺骗这个过程。

首先，我们从加载音频特定层开始，这些层是由 kapre 库提供的。如上所述，这些层获取原始音频数据并计算声谱图表示:

之后，我们从 [*规范增强*包](https://pypi.org/project/spec-augment/)中添加一个增强层。这个软件包实现了研究人员 Park 等人[1]的 SpecAugment 论文，它屏蔽了部分谱图。屏蔽模糊了神经网络所需的信息，从而增加了挑战。反过来，这种修改迫使网络关注其他功能，扩展其能力以概括看不见的数据:

最后，我们可以在上面添加更多的层。对于我们的例子，我添加了一个未经训练的残差网络，用任意 10 个类将数据分类成:

这部分到此为止。我们现在有一个深度神经网络，在向前传递的过程中增强音频数据。

# 摘要

在这篇博文中，我们讨论了两种增加音频数据的方法:第一种方法直接修改音频数据，第二种方法作为神经网络正向传递的一部分。这两个方法应该给你如何在你的用例中继续的好主意。为了让你快速入门，你可以在 [GitHub](https://github.com/phrasenmaeher/tf-audio-augmentations) 上找到完整的笔记本。

[1] Park 等， [Specaugment:一种用于自动语音识别的简单数据增强方法](https://arxiv.org/abs/1904.08779)，2019，Proc。Interspeech 2019