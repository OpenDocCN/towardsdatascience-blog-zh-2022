<html>
<head>
<title>Linear Regression Visualized and Better Understood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归直观且更容易理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-visualized-and-better-understood-c8f7b9c69810#2022-01-22">https://towardsdatascience.com/linear-regression-visualized-and-better-understood-c8f7b9c69810#2022-01-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="d1d8" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">线性回归直观且更容易理解</h1></div><div class=""><h2 id="d6c1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">可以检查一下自己是否真的懂多元线性回归</h2></div><p id="14ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">线性回归是最简单的算法之一。特别是当只有一个连续的特征变量:y=ax+b，并且用一条<strong class="kk iu">直线</strong>表示的时候。这种可视化表示对于理解模型是什么非常有用。</p><p id="95f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，你想知道在多变量的情况下，模型的可视化表示是什么吗？如果有多个<strong class="kk iu">连续</strong>变量，加上<strong class="kk iu">分类</strong>变量是什么？</p><p id="f138" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在本文中，我将通过不同的案例，用具体的R代码来绘制图表。在看答案之前，你可以试着想象以下几种情况:</p><p id="f8d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">连续变量</strong></p><ul class=""><li id="a215" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">两个连续变量</li><li id="ec20" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">三个连续变量</li></ul><p id="2d59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">分类变量</strong></p><ul class=""><li id="25b3" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">只有一个二元变量</li><li id="a61f" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个变量有三个类别</li><li id="8911" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个变量有n个类别</li><li id="b522" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">两个二元变量</li></ul><p id="9c6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">混合变量</strong></p><ul class=""><li id="6d52" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">一个连续变量和一个二元变量</li><li id="32e4" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">两个连续变量和一个二元变量</li><li id="f885" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个连续变量和一个n类离散变量</li></ul><p id="a51e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意隐患</strong></p><p id="1101" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当想象视觉表象时，请记住它总是线性的，笔直的，平坦的…不是弯曲的，不是非线性的…</p><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ls"><img src="../Images/19c29ca0813d8f9a8d912d6c520fb42b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sliNSsmCx9P8IUfE"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">由<a class="ae mi" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae mi" href="https://unsplash.com/@karsten_wuerth?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">卡斯滕·沃思</a>拍摄的照片</p></figure><h1 id="0b8e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">连续变量</h1><p id="acd2" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于一个连续的变量，众所周知，线性回归是一条直线。然而，开始对其进行具体的编程和可视化是一个很好且容易的起点。</p><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="8df4" class="nl mk it nh b gy nm nn l no np">x=runif(100,1,10)<br/>y=2*x+rnorm(100,0,1)</span><span id="50ce" class="nl mk it nh b gy nq nn l no np">data=data.frame(x=x,y=y)</span><span id="2e9a" class="nl mk it nh b gy nq nn l no np">fit_lm=lm(y ~ .,data = data)</span><span id="7d21" class="nl mk it nh b gy nq nn l no np">ggplot(data,aes(x, y))+geom_point()+<br/> geom_abline(slope=fit_lm$coefficients[2],<br/> intercept = fit_lm$coefficients[1],<br/> color=”red”)</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nr"><img src="../Images/2d7b15264187db0b9c3b258b39b60920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SXjNmhprVElKQ3YAXSlBPg.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">一个连续变量的线性回归(图片由作者提供)</p></figure><p id="baf1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于<strong class="kk iu">两个连续变量</strong>，让我们称它们为x1和x2，分别为系数a1和a2，那么等式为:y = a1x1 + a2x2 + b。由于总共有3个连续变量(x1、x2和y)，我们必须想象一个三维空间:x1和x2轴可以代表地面，y轴代表高度。对于地面上的每一点，我们可以为y确定一个高度。所以最后，我们得到一个<strong class="kk iu">平面</strong>。</p><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="d96f" class="nl mk it nh b gy nm nn l no np">x1=runif(100,1,10)<br/>x2=runif(100,1,10)</span><span id="120a" class="nl mk it nh b gy nq nn l no np">y=2*x1+3*x2+rnorm(100,0,2)</span><span id="36f9" class="nl mk it nh b gy nq nn l no np">data=data.frame(x1=x1,x2=x2,y=y)</span><span id="f589" class="nl mk it nh b gy nq nn l no np">fit_lm=lm(y ~ x1 + x2,data = data)</span><span id="4a96" class="nl mk it nh b gy nq nn l no np">plot3d(x=data$x1,y=data$x2,z=data$y, type = 'p')</span><span id="4a89" class="nl mk it nh b gy nq nn l no np">planes3d(fit_lm$coefficients["x1"], fit_lm$coefficients["x2"], <br/>         -1, -fit_lm$coefficients["(Intercept)"],<br/>         col = 'red', alpha = 0.6)</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ns"><img src="../Images/d29a49dc3458998921c146a254076748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_K341wyobBYvd2QhG2DTQ.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">两个连续变量的可视化线性回归(图片由作者提供)</p></figure><p id="144e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于<strong class="kk iu">三个连续变量</strong>，我们无法具体地将其形象化，但我们可以想象它:它将是一个四维超空间中的一个空间。</p><h1 id="724f" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">分类变量</h1><p id="f396" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于一个二元变量，我们回到我们的简单方程:y = ax + b。在现实世界中，它可以代表性别，对不同的特征是或否。实际上，我们必须对它进行一次性编码，它可以取值为0或1。然后我们就可以计算y的值了，如果x = 0，那么y = b，如果x = 1，那么y = a + b .所以直观的表示就是<strong class="kk iu">两点</strong>。我们可以很容易地证明，对于x的每个值，它们都是y的平均值。</p><p id="de3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了形象化，我们仍然可以用直线来表示，但实际上在具体使用模型时，x只等于0或1。</p><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="ea4c" class="nl mk it nh b gy nm nn l no np">x=c(rep(1,50),rep(0,50))<br/>y=2*x+rnorm(100,0,1)</span><span id="9b13" class="nl mk it nh b gy nq nn l no np">data=data.frame(x=x,y=y)</span><span id="f44d" class="nl mk it nh b gy nq nn l no np">fit_lm=lm(y ~ .,data = data)</span><span id="a720" class="nl mk it nh b gy nq nn l no np">ggplot(data,aes(x, y))+geom_point()+<br/>   geom_abline(slope=fit_lm$coefficients[2],<br/>               intercept = fit_lm$coefficients[1],<br/>               color="red")</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi nt"><img src="../Images/7b2d3edde2d6f6ef5ac33a6d1e453f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_Fs76qdRt3ZVEhaPdm3oA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">一个二元分类变量的线性回归(图片由作者提供)</p></figure><p id="b2b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，对于具有三个类别的分类变量，我们还可以创建虚拟变量，在实践中，我们将有两个特征。所以我们必须使用3D绘图。</p><p id="a5a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与前一种情况一样，虚拟变量的组合会有几个点。我们可以创建一个平面来更好地可视化。我们知道可能的点在一个平面上，因为对于两个连续变量，方程是相同的:</p><p id="101b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">y = a1x1 + a2x2 + b</p><p id="6e9d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在前一节连续变量中，x1和x2是连续的，在这里，它们是二元的。</p><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="00d1" class="nl mk it nh b gy nm nn l no np">x=as.factor(sample(c(0,1,2), replace=TRUE, size=100))</span><span id="bf72" class="nl mk it nh b gy nq nn l no np">data=data.frame(model.matrix(~x))</span><span id="e342" class="nl mk it nh b gy nq nn l no np">data$y=2*data[["x1"]]+3*data[["x2"]]+rnorm(100,0,2)</span><span id="984b" class="nl mk it nh b gy nq nn l no np">fit_lm=lm(y ~ x1 + x2,data = data)</span><span id="e9e2" class="nl mk it nh b gy nq nn l no np">plot3d(x=data$x1,y=data$x2,z=data$y, type = 'p')</span><span id="bdf9" class="nl mk it nh b gy nq nn l no np">planes3d(fit_lm$coefficients["x1"], fit_lm$coefficients["x2"], <br/>         -1, -fit_lm$coefficients["(Intercept)"],<br/>         col = 'red', alpha = 0.6)</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/1a9a48917a9efc316f6cdbdb19cbdff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*GCXkn0K5Ol0qE4QWeDzhdQ.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated">具有3个类别的分类变量的线性回归(图片由作者提供)</p></figure><p id="8fa7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">值得注意的是，没有x1=1和x2 =1的观测值，因为x1和x2来自一个唯一的分类变量，不可能同时为真。</p><p id="2a26" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以线性回归的表示是空间中的三个点。很容易证明它们是x1和x2可能组合的平均值。</p><p id="04b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，如果有<strong class="kk iu">两个二元变量</strong>呢？除了x1=1和x2 =1的观测值之外，情况非常相似。该表示仍然是一个平面，包含二进制变量的<strong class="kk iu"> 4种可能组合</strong>中每一种的点。值得问的问题是:</p><blockquote class="nv"><p id="0078" class="nw nx it bd ny nz oa ob oc od oe ld dk translated">平面是否用平均值切割4组观测值？</p></blockquote><p id="6a9c" class="pw-post-body-paragraph ki kj it kk b kl of ju kn ko og jx kq kr oh kt ku kv oi kx ky kz oj lb lc ld im bi translated">答案是否定的，我们用收缩来证明。</p><ul class=""><li id="3cec" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">条件1:如果它们是平均值，则空间中将有4个点</li><li id="395d" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">条件2:所有点都应该在一个平面上因为我们有等式:y = a1x1 + a2x2 + b</li></ul><p id="48d1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上述两个条件不可能同时成立，空间中的4个点不一定在一个平面上。因为我们知道条件2总是真的，所以条件1不总是真的。</p><h1 id="2809" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">混合变量</strong></h1><p id="ad9a" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">对于<strong class="kk iu">一个连续变量和一个二元变量</strong>，我们可以用两种不同的方式想象。设模型为y = a1x1 + a2x2 + b，x1连续，x2分类。</p><ul class=""><li id="1d0a" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">由于我们有两个连续变量的平面，如果其中一个特征变量是二元变量，那么对于空间中的一维，我们只有0和1，而不是可能的值，那么我们有<strong class="kk iu">两条直线在3D空间</strong>中。而且你认为他们一定是<strong class="kk iu">并联</strong>？答案是肯定的，因为它们肯定来自一架飞机。</li></ul><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="342f" class="nl mk it nh b gy nm nn l no np">x1=runif(100,1,10)<br/>x2=sample(c(0,1), replace=TRUE, size=100)</span><span id="fa5f" class="nl mk it nh b gy nq nn l no np">y=2*x1+3*x2+rnorm(100,0,2)<br/>data=data.frame(x1=x1,x2=x2,y=y)</span><span id="7814" class="nl mk it nh b gy nq nn l no np">fit_lm=lm(y ~ x1 + x2,data = data)</span><span id="203e" class="nl mk it nh b gy nq nn l no np">plot3d(x=data$x1,y=data$x2,z=data$y, type = 'p') <br/>planes3d(fit_lm$coefficients["x1"], fit_lm$coefficients["x2"], <br/>         -1, -fit_lm$coefficients["(Intercept)"],<br/>         col = 'red', alpha = 0.6)</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ok"><img src="../Images/5077787ffc6ac857026c20d7c2bf0988.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1n6NNAKoIwDZvd_jyNcTtA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">一个连续变量和一个二元变量的线性回归(图片由作者提供)</p></figure><ul class=""><li id="96f8" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">由于有两条直线，我们可以把它们投影到连续特征变量x1和y形成的平面上，这样就得到两条平行的直线。一条直线代表x2=0时的模型，斜率为a1，截距为b；另一个会代表x2=1时的模型，斜率永远是a1，截距是a2+b。</li></ul><pre class="lt lu lv lw gt ng nh ni nj aw nk bi"><span id="d865" class="nl mk it nh b gy nm nn l no np">ggplot(data,aes(x1, y,color=as.factor(x2)))+<br/>   geom_point()+<br/>   geom_abline(slope=fit_lm$coefficients["x1"],<br/>               intercept = fit_lm$coefficients[1],<br/>               color="red")+<br/>   geom_abline(slope=fit_lm$coefficients["x1"],<br/>               intercept = fit_lm$coefficients[2]+<br/>                  fit_lm$coefficients[3],<br/>               color="#06D1D5")+<br/>   labs(color="x2")</span></pre><figure class="lt lu lv lw gt lx gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi ol"><img src="../Images/add6c2168ab7471fc6e564cc0b5728ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sq1v5liBUiRiX-Rz2nPBSA.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated">一个连续变量和一个二元变量的线性回归(图片由作者提供)</p></figure><p id="f6e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于一个连续变量加<strong class="kk iu">一个分类变量</strong>带<strong class="kk iu"> 3个分类</strong>或者<strong class="kk iu"> n个分类</strong>，我们将无法表示整个空间，我们可以表示连续变量和y形成的平面上的投影，平行的直线会有n条。</p><h1 id="0f7e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="9bd9" class="pw-post-body-paragraph ki kj it kk b kl nb ju kn ko nc jx kq kr nd kt ku kv ne kx ky kz nf lb lc ld im bi translated">现在，我们可以对所有问题给出答案，以此作为结束:</p><p id="4447" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">连续变量</strong></p><ul class=""><li id="4645" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">一个连续变量:直线</li><li id="f1ca" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">两个连续变量:计划</li><li id="a52c" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">三个连续变量:空间</li></ul><p id="9121" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">分类变量</strong></p><ul class=""><li id="136e" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">只有一个二元变量:两点(类别平均值)</li><li id="3e88" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个变量有三个类别:三个点(类别平均值),它们在一个平面上，因为否则不可能</li><li id="a601" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个变量有n个类别:n个点(类别平均值)</li><li id="3f49" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">两个二元变量:4个点(不是平均值),它们不在一个平面上</li></ul><p id="1979" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">混合变量</strong></p><ul class=""><li id="742d" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">一个连续变量和一个二元变量:两条平行的直线(每个类别一条线)</li><li id="ce52" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">两个连续变量和一个二元变量:两个平行平面</li><li id="96e3" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">一个连续变量和一个n类离散变量:n条平行直线</li></ul></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="e9ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想在Excel中从头实现线性回归，可以阅读这篇文章:</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/linear-regression-from-scratch-in-excel-3d8192214752"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">在Excel中从头开始线性回归</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">这样你就能更好地理解线性回归是如何工作的</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk mc ow"/></div></div></a></div><p id="9724" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您对其他算法的同类可视化感兴趣，请发表评论。</p><p id="e68f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">线性回归是一个非常基本的算法，正如你可以看到的所有可视化，如果数据不是线性的，它不会执行得很好。为了更好地模拟非线性数据，我们可以用几种方法来增强线性回归。你可以通过这篇文章了解更多关于<strong class="kk iu">无监督机器学习算法</strong>。</p><div class="ot ou gp gr ov ow"><a rel="noopener follow" target="_blank" href="/overview-of-supervised-machine-learning-algorithms-a5107d036296"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">监督机器学习算法综述</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">大图如何通过连接点给我们洞察力和对ML的更好理解</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">towardsdatascience.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk mc ow"/></div></div></a></div></div></div>    
</body>
</html>