# 为什么数据质量比代码质量难

> 原文：<https://towardsdatascience.com/why-data-quality-is-harder-than-code-quality-a7ab78c9d9e>

## 如何检测、理解、修复和减少数据质量问题。

![](img/41bee88bdeff11cb11ea5d46c5cfb1f5.png)

照片由[帕特里克·福尔](https://unsplash.com/photos/JBghIzjbuLs)在 [Unsplash](https://unsplash.com) 拍摄

作为一名数据工程师，我总是对自己处理的数据质量不如自己编写的代码质量有信心。代码，至少，我可以交互地运行它，并在部署到产品之前编写测试。数据，我经常不得不等待它在系统中流动，并被用来处理数据质量问题。而且不仅仅是出现了错误。也是这种感觉，比代码 bug 更多的未知数据质量问题等着被发现。但是，数据质量比代码质量更难解决吗？

代码质量是确保代码符合预期的过程。同样，**数据质量是确保数据满足期望的过程**。在本文中，我想抽象出期望值(在谈论数据时称为[数据质量维度](https://www.metaplane.dev/blog/data-quality-metrics-for-data-warehouses)),因为它们可能会根据您的使用情况而有所不同。相反，我讨论处理数据质量问题的不同步骤:**检测、理解、修复和减少质量问题**。然后，我解释了为什么我发现这些步骤中的每一步在应用于数据时都比应用于代码时更难实现。

# 为什么检测数据质量问题很难？

一个公认的原则是，您遇到的数据质量问题的数量将与您的代码库和数据的大小成比例。大多数数据存储库将比任何代码存储库大几个数量级。最重要的是，**您可以每天部署几次代码，但是数据可以在几毫秒内更新**。随着数据更改越来越多，您遇到数据质量问题的可能性也越来越大。

检测数据质量问题有三种主要方法:

*   一位业务用户报告了一个问题。
*   数据测试失败。
*   数据监控会发出警报。

首先，您的数据需要一个通信渠道，以便用户报告数据问题。不要低估这一点，否则您最终会得到越来越多的修补数据问题的 SQL 代码，而这些问题应该从源头上解决。然后，您可以开始添加测试来捕捉已知的数据问题，并添加数据监控来提前发现未知的数据问题。

# 测试数据与测试代码

数据测试是将数据资产与一组预期进行比较的过程。**数据预期被硬编码为规则，并在生产数据上运行**。一方面，在更新生产代码之前，代码测试作为 CI 管道的一部分运行。在软件工程团队中，在发布到产品之前，对代码进行阶段化、测试和验证是很常见的。另一方面，如今大多数数据团队都致力于定期对数据库和仓库中的静态数据进行[测试](https://validio.io/blog/whats-next-in-data-quality)。为了在代码库中拥有良好的测试覆盖率，软件工程团队可能会尝试拥有一个执行所有代码行的测试套件，这就是 100%测试代码覆盖率的[神话](https://www.functionize.com/blog/the-myth-of-100-code-coverage)。对数据进行良好的测试覆盖意味着什么？

您可以编写的数据测试的数量与列的数量成正比。您不需要为每一行编写测试，而是为每一列编写一些测试。例如，测试可以检查缺少的值、值是否在某个范围内，或者一个表中的列值是否与另一个表中的列值相匹配。你可以使用像[远大前程](https://docs.greatexpectations.io/docs/terms/expectation)、 [Soda](https://docs.soda.io/soda-sql/tests.html) 或者 [dbt tests](https://docs.getdbt.com/docs/building-a-dbt-project/tests) 这样的开源测试库来测试数据。

开始您的数据质量之旅的一个方法是识别在下游更常用的数据模型。当然，核心模型可能会对用户对数据质量的看法产生更大的影响。然而，数据集变化的比率使得为每一列编写多个测试不切实际，许多团队转而求助于数据监控。

# 监控数据与监控代码

数据监控，也称为数据可观察性，是持续收集数据指标的过程。例如，对于每个数据集，您可以收集有关每个数据集的行数、列数和值的数据。您还可以收集关于数据集的元数据，例如上次更新的时间。

**指标可用于根据过去的数据自动创建期望值**并帮助您发现未知的数据质量问题。例如，如果一个表在历史上每天添加 5 到 10，000 个新行，而突然有一天它只获得了 100 个新行，那么监控就会发出警报。

许多团队在监控中面临的最大问题是警报疲劳，因为误报会越积越多。这个问题在软件工程团队使用的云监控工具中是共有的。一方面，像 Datadog 这样的云监控工具大多求助于收集低维的时间序列数据，如 CPU 消耗和 API 响应时间。另一方面，数据质量监控工具收集列和表之间的多元数据。因此，**通过对多个变量进行统计分析发出警报比通过观察时间序列中的一个指标发出警报更难**。

# 为什么理解数据质量问题很难？

当您收到数据问题的警报时，您的数据可能已经更改。您可能需要签出数据的以前版本来调试错误。任何严肃的软件开发团队版本都控制着它的代码库。不幸的是，我们不能对数据仓库说同样的话。**版本控制数据资产仍然是一件好事，但很难做到**。像雪花这样的数据仓库和像数据块这样的数据湖提供了[时间旅行](https://glossary.airbyte.com/term/time-travel)能力。检出单个数据集的先前版本很容易；更难的部分仍然是一致地恢复所有受影响的数据和代码。使用其他提供原子回滚的数据版本控制工具，如 [lakeFS](https://lakefs.io/) ，您只能对数据湖进行版本控制。

一旦找到了引起错误的数据，就需要找到错误的来源。不幸的是，**浏览数据依赖关系绝非易事。** [OpenLineage](https://openlineage.io/) 提供了数据沿袭收集的标准，但需要为数据堆栈的每个组件配置一个客户端，如果它们提供集成的话。

找到错误来源后，您可能希望了解错误是何时引入的，并将数据与以前的版本进行比较。**为了计算数据集之间的差异，你需要求助于一个数据协调工具**，比如 [data-diff](https://github.com/datafold/data-diff) (最近由 Datafold 开源)，它集成了十几个数据存储系统。

将所有这些与版本控制代码进行比较，探索代码依赖性，并直接通过 git 的代码编辑器可视化代码差异。对我来说，这方面的数据质量将受益于整合。

# 为什么解决数据质量问题很难？

调试完数据质量问题后，您会做什么？如果错误是由中间模型造成的，那么您可以修复代码。否则，数据质量问题可能源自外部系统。这带来了另一个挑战，**数据质量问题并不总是能立即得到解决，在某些情况下，你甚至无法了解真相**。然而，即使您的代码依赖于其他库，大多数情况下您也可以访问源代码来修补它并提交一个 pull 请求。

当您发现代码错误时，您可以暂停程序并向用户发送一个错误代码。您可以收集堆栈跟踪并将其存储在某个地方，但大多数情况下，**您不需要重新执行失败的代码**。例如，如果有人访问您的电子商务网站并试图订购一件商品，但付款失败，您会向该用户发送一条错误消息。当您解决问题时，您最多可以向用户发送电子邮件，但您不必重新处理所有失败的支付。

当检测到数据质量错误时，您可以隔离这些数据。然后，您可以尝试手动修复数据，使用数据插补技术或修改产生数据错误的代码。然后，您必须重新处理来自源的数据，以更新所有下游依赖项。能够使用[数据编排](https://airbyte.com/blog/data-orchestration-trends)(称为回填)重新处理旧数据而没有副作用，这在很大程度上取决于您作为数据工程师是否能够让您的数据处理代码[起作用](https://glossary.airbyte.com/term/functional-data-engineering)和幂等。

> *“回填是一个真正显示数据工程师和优秀数据工程师之间差异的话题。大概是因为回填需要经验和耐心。运行管道很容易，但当您的管道需要重新计算或重新吸收过去 4 年的数据时，它将给您的系统带来沉重的压力。”— Christophe Blefari 在他的* [*数据简讯上。*](https://www.blef.fr/data-news-week-22-33/)

# 减少数据质量问题

在经历了几次检测、理解和修复循环之后，您可能会问自己如何改进您的数据架构以避免如此频繁地经历这个过程。您可以尝试在外部来源的数据质量问题被接收后立即检测出来。然而，大多数问题可能是由系统故障和错误的逻辑引起的。

为了提高代码质量，您可以重构代码以减少代码库中重复逻辑的数量。通常，更少的代码也意味着编写更少的测试和导航代码库的开销更少。我们同样可以说**数据质量问题的数量与数据的大小成正比**。但是数据越多不总是越好吗？

您可能不想减少您正在摄取的总体数据，但是您可以**减少您创建的中间数据模型的数量**。当前的一个趋势是，[数据网格](https://glossary.airbyte.com/term/data-mesh)组织提倡在组织内分散数据所有权和民主化数据使用。这说起来容易做起来难，与其说是技术变革，不如说是组织变革。像 [Castor](https://www.castordoc.com/) 这样的数据目录有助于在整个组织中发现数据，以避免创建另一个具有相同信息的数据集。

减少中间模型数量的另外两个趋势是从 ETL 到 ELT 的转换和度量层。一方面， **ELT 管道将转换移到右边，在您存储原始数据之后，在您的数据仓库或 lake** 中发生。在过去，有时会创建一个 [ETL 脚本](https://airbyte.com/blog/etl-framework-vs-etl-script)来服务于一个单一的仪表板(完全相反)。另一方面，**[**指标层**](https://glossary.airbyte.com/term/metrics-layer) **将转换从 BI 工具向左移动到数据仓库**。但是度量层只是抽象转换逻辑的一种方式。语义层(一个更广泛的概念)仍然充满了未解决的问题。**

> ***“语义层的核心动机是提供一个定义概念的地方，包括(但不限于)指标，这种方式不需要你在定义中重复自己。语义建模包括定义正确的构建模块，允许您基于它们定义更高级别的概念。”—从* [*往下语义兔子洞*](https://jpmonteiro.substack.com/p/down-the-semantic-rabbit-hole) *作者 JP 蒙泰罗。***

**这里有最后一个不受欢迎的建议来减少中间模型的数量:**减少接收和转换数据的频率**。你可能认为更多的数据、更多的仪表板和更新鲜的数据总是更好，但要知道所有这些都带来了它们自己的问题，例如在运行更多的[数据集成](https://airbyte.com/blog/data-integration)和处理作业时增加警报疲劳。**

**如果每天只消耗数据，是否需要每分钟摄取数据？最近，Benn Stancil 创造了术语[反向编排](https://benn.substack.com/p/down-with-the-dag)，其中 ETL/ELT 作业的频率是从数据和 SLA 的消耗中推断出来的。**

> ***“例如，一个频繁更新的数据摄取任务可能会定期失败并自我纠正，所有这些都在延迟 SLA 的范围内。提醒人们任务失败会教会我们忽略这些警告，并将系统问题和内部故障与影响数据是否可信的实际问题区分开来。”—从* [*向下，通过本模板*使用 DAG](https://benn.substack.com/p/down-with-the-dag?utm_source=substack&utm_medium=email)**

# ***使数据质量成为一个更容易解决的问题***

***正如我们所看到的，数据比代码变化更快，包含更多的依赖关系，这使得引入新的质量问题更加容易。您可以采取一些措施来减少数据质量问题的影响，例如添加数据测试和监控。有时，这是处理来自外部来源的数据质量问题所能做的全部工作。***

***但是你能做些什么来减少来自你的逻辑的质量问题的数量呢？首先，您可以教育数据生产者减少中间数据模型的数量，从将原始数据加载到中央存储库并在那里进行大部分转换开始。虽然这将减少模型的数量，但它不是一个灵丹妙药，因为它还会增加管道之间的依赖性，并且需要一组最佳实践。***

***数据质量生态系统没有代码质量成熟。例如，调试数据质量问题仍然是数据工程师花费最多时间的步骤。数据工程师需要在不同的工具之间周旋，以控制数据版本、导航数据依赖关系和比较数据集，而您可以在调试代码时通过代码编辑器完成所有这些工作。***

***最后，数据组织在不同的系统(应用程序、数据库、数据湖、数据仓库)上存储数据，而大多数代码存储在同一个代码托管系统(Github)上。这使得数据质量工具(测试、监控、沿袭、目录)更难支持所有系统的集成。为了简化数据堆栈所有层的集成，我们需要为所有三个核心数据领域制定更多的数据标准:数据存储、数据移动和数据转换。***

***在 Airbyte，我们正致力于通过提供用于移动数据的开源连接器来解决集成的长尾问题。说到数据存储系统，[开放式数据湖表格式](https://airbyte.com/blog/data-lake-lakehouse-guide-powered-by-table-formats-delta-lake-iceberg-hudi)(胡迪的 Delta Lake，Iceberg)有可能简化数据堆栈不同层之间的集成，但仍需要更广泛的采用。我们仍然缺少数据转换的标准。***

****原载于* [*Airbyte 博客*](https://airbyte.com/blog/data-quality-issues) *。****