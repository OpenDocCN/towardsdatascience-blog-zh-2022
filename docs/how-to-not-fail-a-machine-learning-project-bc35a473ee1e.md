# 如何(不)让一个机器学习项目失败

> 原文：<https://towardsdatascience.com/how-to-not-fail-a-machine-learning-project-bc35a473ee1e>

## 在一万次实验后得到的教训

四个月是很长的时间。但是，十个月也是如此。一般来说，四周以后的事情都是将来的事情。这种情况对于机器学习项目来说可能是福也可能是祸。幸事，因为我们有充足的时间来完成这个项目。这是一个诅咒，因为我们还没有开始(或继续工作)。

编辑#1 (Mai 2022):在为单个项目运行了一万多个实验之后，我已经包含了更多的经验教训。适应它们，享受更快的进步。

编辑# 2(2022 年 6 月):我更新了这篇文章，思考清洁的标签管道如何让生活变得更容易。

![](img/ac5c9b41b6fd545f5a3226956010edfe.png)

[斯科特·格雷厄姆](https://unsplash.com/@homajob?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

因此，长期追求项目本身就是一门艺术。谢天谢地，我们很少需要从头开始；在我们之前的人经常已经走了这条路。通过从他们的错误中学习，并改进他们认为有用的东西，我们可以很好地处理令人生畏的项目。因此，第一步是找到需要改进的地方。在这里，芭芭拉·奥克利的*数字头脑*帮助我养成了列出当天所学课程的习惯。

担心这听起来很老套，通常只有通过我们犯的错误(或只是避免的错误)，我们才能在下一次做得更好。但是，带着这种心态，我们不可避免地会发现我们可以改进的地方。在从事机器学习项目半年后，我发现有很多东西需要学习。

为了帮助其他读者和从业者避免我的事故，我现在将介绍我学到的最重要的经验。当然，这并不是说如果你犯了同样的错误，你就会不可避免地失败。此外，如果你设法避开它们，也不会自动成功。相反，通过尽可能多的学习，看看什么能与你的经历产生共鸣，你会大大增加成功的机会。

其余的分为两类。第一个，机器学习，列出了与实践实际的 ML 任务相关的经验教训。第二个是 general，列出了适用于任何大型项目的要点。

# 机器学习

## 不要过度优化

好代码是好的，更快的好代码更好。但仅限于某一点。在这一点上，花费在优化代码上的额外时间并没有转化为同等增加的回报。很明显，没有硬门槛；这取决于项目。然而，我相信许多从业者都熟悉类似的情况。

## 使用专用的实验跟踪软件

如果您有几个实验，通过记录具体的配置来手动跟踪它们是可行的。然而，这种方法不能很好地扩展。手动跟踪所有实验的结果，除了几十个实验外，没有什么效果。在这里，我推荐使用专用的追踪软件。就我个人而言，我已经使用[权重&偏差](https://wandb.ai/site)很长时间了，并开始称赞这个奇妙的用户界面。除了记录结果之外，这样的系统可以被设置来跟踪特定实验的输入。反过来，这些特性使得复制结果变得更加容易。

## 开始时使用较少的数据集

在《T2:一个没有电子邮件的世界》一书中，卡尔·纽波特介绍了“做得更少但更好”的理念(参见第 215 页和第 227 页)。我们可以将相同的概念用于机器学习项目。当涉及到测试新想法(用于研究)时，我们通常希望尽可能全面地评估它们。虽然这是合理的，但它并不适用于每个阶段。一开始，最好处理好几个核心数据集，而不是勉强支持几十个。在项目持续期间，您可以决定添加额外的数据集。

## 明确地做 EDA

这是我几年前采用的一个有缺陷的方法。我训练了一个神经网络来分类音频数据。然而，不是检查数据——也就是说，查看标签分布、频率、持续时间等。—我使用了一种更不结构化、更容易出错的方法。我手动实验了不同的超参数，希望能偶然找到一个好的集合。显然，这种试错过程只在极少数情况下有效。相比之下，通过进行探索性数据分析，我们可以在早期获得对数据集的更多见解，并从长期来看节省时间和成本。

## 考虑将数据复制到 pod

这一点适用于 a)使用 Docker(或任何其他容器管理软件)和 b)有一个缓慢的文件系统的情况。如果这些需求适用于您的情况，您可以考虑在实验之前将数据复制到容器中。但是，您必须平衡复制的额外开销和由此减少的训练时间。中间路线是从文件系统中读取第一个数据迭代，然后将其缓存到临时磁盘(查看由 SSD 或 RAM 支持的 EmptyDir)。

## 自动化图像构建

这个场景很熟悉:在本地，您已经更改了您的设置，但是这反映在您的容器中了吗？在训练过程中意识到缺少依赖是很烦人的。因此，每次您在本地更新一些包时，让它触发一个映像构建过程。或者，您可以手动启动一个脚本，在没有您监督的情况下在后台执行。

## 提前确定要跟踪的指标

只有当您事先决定了要根据什么标准来评定特定配置的成功程度时，才可能进行评定。一旦实验开始，就没有太多的选择来改变指标。因此，如果您在开始时花时间仔细评估度量标准并在每次运行时收集它们，这是值得的。为了以后的想法更加安全:存储每个实验的基础事实和预测。有了这些数据，您可以在以后计算其他数据。

## 保存预测和实际数据

即使在您决定了要跟踪的度量标准之后，您可能仍然会到达这样一个点，这时您会想:拥有这个额外的度量标准会有所帮助。最愚蠢的选择是添加后重启所有实验；这可能会花费您数月的计算时间和数千美元。更好的方法是做好准备，至少将测试数据集上的预测与真实数据保存在一起。然后，一旦您需要进一步了解您的模型的性能，您可以计算它们。您甚至可以更进一步，在训练期间保存预测-背景-事实对(这可能会导致额外的磁盘空间和暂停训练)，以更详细地分析训练进度。通过仅捕获子集或以某一频率对数据进行下采样是一个很好的解决方案。

## 为超参数优化做准备

KerasTuner、Optuna、Weights & Biases、Ray-Tune:为你的问题集寻找最优超参数的工具数量很多。如果你计划在(遥远的)晚些时候做它们，你可以早点做。通常，优化框架通过字典或类似的结构提供下一组参数。因此，如果您将代码设计为从字典中加载超参数，那么更改参数就像传递不同的配置一样简单。尽早考虑这一点可以减少准备框架时的开销。

## 检查你的训练

2022 年 3 月 11 日，来自世界各地的 900 多名研究人员开始训练世界上最大的开源语言模型。运行在 384 A100 Nvidia GPUs 上，训练估计需要三个月甚至更长时间(你可以[在这里](https://huggingface.co/bigscience/tr11-176B-ml-logs/tensorboard)跟踪进度)。在如此高的风险下，如果培训因为任何原因失败，那么*将会付出异常高昂的代价*。因此，定期检查训练状态以避免失去进展是很重要的。这就是相关工程师所做的，即使经常进行检查点检查，也总是有硬件故障的可能性。当然，[失去七个小时的进度](https://github.com/bigscience-workshop/bigscience/blob/master/train/tr11-176B-ml/chronicles.md)会很痛苦，但这比重新开始要好得多。

## 有一小部分

杰瑞米·霍华德和瑞秋·托马斯(Rachel Thomas)创立了机器学习研究公司 fast.ai，让每个人都可以使用神经网络。与此相关的是，Howard 还提供了 ImageNet 数据集，这是极其庞大的 ImageNet 数据集的一个可管理的子集。这个数据集，ImageNet，在过去的几年里可能受到了最多的关注。原因有二。第一个原因是它作为一个具有挑战性的基准的地位，由每年的比赛推动。第二个原因是庞大的规模。这个数据集在磁盘上占用超过 250 GB，通常需要快速加速器来在合理的时间内处理数据集。这就是上面提到的 Imagenette 发挥作用的地方。拥有一个小的子集可以让你更快地评估新的想法。

## 简化并行化

如果幸运的话，您可以使用不止一个加速器，那么提前为并行化准备好代码就成为了一种潜在的方法。在 TensorFlow 中，通过将所有创建变量的例程包装到一个*策略*对象中来实现这一点。这在目前会稍微多花些精力，但是从长远来看，会使你的代码分发更加容易。换句话说，如果您提前知道将会有更多的加速器可用，那么为并行化做准备是值得的。

## 使用显著性测试

我们假设以下情况。您已经试验了两种配置，现在比较结果。第一次运行达到了 75%的准确率，而第二次运行达到了 79%。查看此指标只能表明第二种配置更好。然而，问题是，它真的更好吗，还是只是运气好？我们可以通过运行显著性测试来研究这个案例。在这里，你比较两个想法。想法一是没有区别，想法二说有区别(为了我们的目的:不指明方向)。我们现在可以使用各种测试来详细检查这些*假设*，并最终得出结论，我们的实验之间的差异在统计上是相关的。我推荐 [Statology](https://www.statology.org) 网站，那里有大量与数据分析相关的动手教程。

## 检查回归

2 月 23 日，我在 UrbanSound8K 数据集上训练了一个 ResNet152。该数据集被分成 10 个折叠，一个折叠花费了 100 个训练时期的大约 30 分钟。总的来说，对完整数据集的训练花费了 300 分钟或 5 个小时。两个月后，一个纪元花了 15 分钟。

发生了什么事？事实证明，这种情况是一种倒退。观察二月份的实验，我注意到验证分数大大低于训练分数。为了减少这种差异，当时，我决定添加[音频增强](/audio-augmentations-in-tensorflow-48483260b169)。因为我之前曾经使用过*音频库*库(甚至[构建了一个 GUI 来可视化转换](/visualizing-audio-pipelines-with-streamlit-96525781b5d9))，所以我再次依赖于它的特性。这个库提供了几种与音频相关的变换，如音高移位或时移。添加这个功能后，我检查了验证分数是否增加了。看到情况确实如此，我把注意力放在了其他任务上。

然而，正如我在两个月后发现的那样，并且正如文档中清楚描述的那样，转换在 CPU 上运行，并且当时只在单个样本上运行。这个细节被证明是一个巨大的瓶颈，特别是考虑到相当大的 UrbanSound8K 数据集。因此，长话短说，我决定在 pure TensorFlow 中重新实现关键的增强，并让它们处理批量数据。这些修改将单个历元减少到大约 30 秒。所以这次旅行的寓意是:a)检查整个数据管道，b)不要盲目地添加很酷的东西。

## 监控您的数据管道

去年，我有机会读了凯瑟琳·尼尔森和汉尼斯·哈普克的《构建机器学习管道》。在他们高度实用(且相关)的书中，他们涵盖了建立自动化模型部署管道的过程。尽管他们使用 TensorFlow 扩展库作为核心管道工具，但他们的想法和技巧并不局限于这个框架。该信息是与机器学习项目相关的点，也适用于任何 ML 数据管道。例如，一个小的形状误差或标准化操作可能会造成严重后果。此外，正如前一点所言，任何进一步的转变都会影响管道的速度。因此，定期检查管道的吞吐量是有好处的，至少在添加了关键操作(如扩充)之后。

## 有一个干净和批准的标签过程

数据是我们训练模型的核心。如果我们幸运的话，我们的数据集可能是高质量的，并且对于分类或类似的任务特别重要，已经被标记了。如果不是这样，那么我们经常不得不从头开始设计一个标签管道或者修改现有的代码。在这两种情况下，有一个干净的和批准的管道是很重要的。我说的*干净*和*认可*是什么意思？首先，对我们来说，干净是复杂、混乱的反义词。我们必须避免编写分散在多个文件中并且难以理解的代码。理想情况下，管道是完全自动化的，只需要很少的人工干预。这就引出了第二点，*认可*。管道可以非常快速地创建，但是它的质量才是最重要的。如果我们的标签过程有问题，我们使用的数据可能会造成伤害。我们可以通过与同事和主题专家讨论我们的管道来防止这种情况并提高质量。与他们交流有助于我们纠正错误，并导致一个更全面的、可接受的管道。

# 一般

## 不要陷入完美主义

通常，我们会沉浸在当下。另一个改进的想法突然出现在我们的脑海中，在我们注意到之前，我们已经花了一个小时深入代码库。尽管这听起来很好，但请将这些适时的步骤保持到最后。尤其是在开始的时候，专注于构建核心。

## 首先实现核心功能

在一个项目的开始，你有这个*真的*长的(假想的)待办事项清单。这种情况可能会让人不知所措，导致我们不按特定的顺序实现特性。这种方法当然是不可持续的；结果往往取决于几个核心特性。所以还是先把重点放在这些上，以后再进一步补充比较好。

## 记录你的经验教训

很可能，这个项目不会是你的最后一个。这很好！不太好的是重蹈覆辙。为了下次做得更好一点，记下学到的教训会有所帮助。为每个项目准备一张纸，当你意识到有些事情本可以变得更容易时，添加一个条目。你浓缩了你的经验，下次就有了一个定制的、倒排的入门清单。

## 更多的时间不一定有帮助

番茄工作法的发明强调了一个事实:如果时间有限，我们可以像放松约束时一样高效。机器学习领域不是离群值。只允许固定的时间去创造价值会让你自己承受交付的压力。令人惊讶的是，在短短 25 分钟内完成项目，然后休息 5 分钟，可以提高工作效率。尝试这种方法，这是我从*对数字的头脑*中得到的，看看你能在哪里应用它。

## 实践不收尾的艺术

让我们考虑以下情况:你训练一个神经网络来分类花的图像。仔细观察准确度分数，您会发现有改进的空间，因此您开始选择另一个优化器并增加批量大小。与此同时，你的同事发现，对植物进行分类可以完全跳过；你决定使用预先训练好的网络。但是完美主义现在控制了你。在您放弃(现在已经过时的)任务之前，您想要证明您可以达到出色的测试结果。最后，你可能会对一个不再存在的问题有一个很好的解决方案。对于参与的每一方来说，这都不是一个令人满意的局面。所以，坚持完成过时的任务。

## 坚持今天的任务清单

这个是短的。一般来说，避免迷失在一个单独的子任务中，而是努力一个接一个地处理待办事项。推荐阅读 Cal Newport 的*深度作品*(尤其是第 223 页 ff。)了解更多信息。

## 订购每日任务列表

这是一个简单的技巧。根据任务的重要性排序，你会进步得更快。通过最后处理最不重要的，你将会在主要特性上花费大部分的时间和认知资源。

## 不要让每天的任务清单超负荷

这需要实验和自我反省来预先粗略评估你在一次工作会议中能处理多少。我经常添加另一个东西，它堆积成很长的列表。在开始的时候，坚持先列出较短的清单，然后随着你的学习不断扩展。从心理学上来说，看到一个明确的待办事项列表的效果是非常令人满意的。相比之下，一天结束时还没有完成的任务会让人失去动力。

## 定期与共创者交流

*爱因斯坦效应*(参见*数字思维*，第 17 页)指出，一旦你达成了一个解决问题的方法，你就会非常倾向于坚持下去，并减少对替代解决方案的关注。我们在日常生活中经历过这种现象，例如当我们寻找钥匙时，疯狂地在我们认为最有可能最快的地方搜索。然而，我们更容易接受其他想法，因为我们不会一时冲动，这有助于推断出钥匙可能就在我们的口袋里。类似的情况也可能出现在你以自我为中心相信你的方法的项目中。虽然停止自己的解决方案需要自信，但获得同行的智慧输入会让你更快地前进。

## 接受建设性的批评

你很少单独做一个项目，几乎每次你都会受到外界的影响。这种影响不能来自同事，也可以来自视频讲座或博客条目(如本文)。不管是哪种情况，建设性的意见可以推动我们前进，指出我们错过的东西。诚然，让自己的想法受到批评需要自信，但如果这种反馈来自那些已经有过这种经历的人，那么这种反馈的力量将是指数级的。你们都尊重提出想法的人，通过考虑他们的意见并根据自己的问题进行调整，你们会进步得更快。

## 下班后保护你

作家兼计算机科学教授 Cal Newport 在他的书*数字极简主义*中建议用高质量的活动来培养一个人的闲暇时间(第 165 页及以下)。这个想法也与机器学习项目有关。在这里，不一定是你投入的原始小时数，而是在加州新港所花费的时间，这种时间被称为深度工作状态。然而，很明显，认知资源是有限的；我们需要时间充电。这种充电最好用手来完成，而不是用大脑。

与其花更多的时间粘在屏幕上，我们应该争取更多的手动操作。这种方法的美妙之处在于，它利用了芭芭拉·奥克利在《数字思维》中描述的分散注意力。当我们不在的时候，似乎没有做任何与项目相关的事情，我们的思想可以漫游并发展创造性的想法。

## 不要一次追求太多的项目

做这个；那样做；在那里工作:我们(不得不)从同一个领域并行运行的项目越多(也就是说，不是一个来自象棋，另一个来自机器学习)，我们就越容易被对我们注意力的持续需求所淹没。在一定程度上，这样的情况可以刺激我们的大脑；我们从不同的角度受益。然而，杂交利润有一个门槛，即当我们开始从一项活动跳到另一项活动时。这种情况干扰了我们和工作之间的距离，因为我们已经在同一领域做下一件事了。为了让我们的大脑有喘息的空间，我们应该限制同时进行的项目数量。

## 从多个角度解决问题

你被一个具有挑战性的问题困住了吗？尝试在集中思考和分散思考之间交替进行。我从芭芭拉·奥克利的《数字思维》中了解到这一点，该书详细解释了这些模式。要点是，默认情况下，我们只使用(并且通常知道)聚焦的那个。当你全神贯注于一个问题并尝试多种方法时，这种模式是活跃的。然而，我们可能会因为卡住而卡住；它是一个圆。通过进一步集中，我们只是增加了另一个无限循环的迭代。对我们有帮助的是发散思维。在投入大量的密集(精神)工作后，你让学到的见解在你的大脑中来回跳动。这就像打弹球一样(这个类比是芭芭拉·奥克利做的):你付出足够的努力让球滚动起来，让你的大脑缓冲器完成剩下的工作。例如，我们可以通过散步和让我们的思维漫游来激活这种模式。

## 富有成效，而不是忙碌

生产率正在取得显著进步；忙碌是发明方法来隐藏你的不进步。

## 使用项目管理工具

在较大的组织中，通常已经有一个规定如何组织项目的过程。如果不是这样，或者你是唯一的成员，考虑使用专用的项目管理软件。起初，学习另一种工具听起来需要更多的工作。然而，那只是暂时的。巧妙组织你的工作可以释放你的认知资源，原因有三:

1.  您可以在一个地方收集所有与项目相关的数据，无需再疯狂地搜索信息。
2.  所有(即将到来的)步骤在任何时候都是清晰的，给你方向。
3.  通过更新整个工具，您可以直观地看到进度。

如果你不喜欢数字工具，你可以使用白板或黑板来复制一般的想法，并手动跟踪你的进度。如果这个话题听起来很有趣，看看吉姆·本森&的*个人看板*和加州纽波特的*一个没有电子邮件的世界*(尤其是第五章以后)。