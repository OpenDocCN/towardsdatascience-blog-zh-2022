<html>
<head>
<title>GANfolk: Using AI to Create Portraits of Fictional People to Sell as NFTs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GANfolk:使用人工智能创建虚构人物的肖像，作为非功能性物品出售</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ganfolk-using-ai-to-create-portraits-of-fictional-people-to-sell-as-nfts-6e24f5214ed1#2022-01-10">https://towardsdatascience.com/ganfolk-using-ai-to-create-portraits-of-fictional-people-to-sell-as-nfts-6e24f5214ed1#2022-01-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="4d11" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">GANfolk:使用人工智能创建虚构人物的肖像，作为非功能性物品出售</h1></div><div class=""><h2 id="c250" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用StyleGAN2、VQGAN和GPT-3从开源图像中合成不同的字符</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b7a44679e2174b5603eae7ea2a4e0788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3ABmGD4v1uRLsUQ8hTpLg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> GANfolk样本</strong>，图片作者</p></figure><p id="319a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我之前在Medium上写过关于使用人工智能创造视觉艺术的文章，比如<a class="ae lv" rel="noopener" target="_blank" href="/ganshare-creating-and-curating-art-with-ai-for-fun-and-profit-1b3b4dcd7376">抽象画</a>和<a class="ae lv" rel="noopener" target="_blank" href="/ganscapes-using-ai-to-create-new-impressionist-paintings-d6af1cf94c56">风景画</a>。在我的研究中，我注意到生成敌对网络(GANs)似乎很难创建人的形象。我决定正面迎接这个挑战，所以我用画和人的照片训练了两只甘。然后我把这些图片作为NFT放在OpenSea上一个名为<a class="ae lv" href="https://opensea.io/collection/ganfolk" rel="noopener ugc nofollow" target="_blank"> GANfolk </a>的收藏中出售。</p><p id="3f4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，我是在知识共享署名共享许可下发布训练图像数据集、源代码和训练模型的。这意味着你可以使用我的代码来创建你自己的数字人画并出售它们，只要你给我署名。有关详细信息，请参见下面的源代码部分。</p><h1 id="a1f8" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">系统概况</h1><p id="0745" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这里是GANfolk系统的概述。您可以在下面的章节中找到组件和流程的详细信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/c726c6cfc93cfcc5c4495719a21b0b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5IczX1WXxkAee5Hp47JWNA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">赣方言成分</strong>，作者配图</p></figure><p id="d1f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我首先写了一个脚本来收集在<a class="ae lv" href="https://www.wikiart.org/" rel="noopener ugc nofollow" target="_blank"> WikiArt </a>上公开的人们的画作，以及来自谷歌<a class="ae lv" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank"> Open Images </a>数据集的开源图像。我通过对齐面部特征和使用LaMa修复系统填充任何空白点来预处理图像[1]。然后我用5400张图片的GANfolk训练集训练了两个GANs，StyleGAN 2 ADA [2]和VQGAN [3]。我收集了2700幅旧的人物绘画和2700幅新的人物照片。</p><p id="2383" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于创建过程的第一步，经过训练的StyleGAN 2系统生成了1000幅图像作为基线集。我使用OpenAI [4]的GPT-3为图片生成文本提示，比如“一个体贴的巴西女孩的画像”然后，我使用同样来自OpenAI的CLIP系统[5]，找到与提示匹配的最佳图像。我选择了最好的图片，并将其输入经过训练的VQGAN系统进行进一步修改，以使图像与文本提示更加匹配。</p><p id="b256" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我回到GPT 3号，让它为每张照片写一个名字和一个简短的背景故事。作为后期处理步骤，我添加了一个晕影效果，并将图像尺寸放大了四倍(从512x512到2048x2048)。经过温和的编辑，我上传了照片和背景故事到OpenSea作为<a class="ae lv" href="https://opensea.io/collection/ganfolk" rel="noopener ugc nofollow" target="_blank"> GANfolk </a> NFTs出售。</p><h1 id="955b" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">先前的工作</h1><p id="508f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在我进入GANfolk的细节之前，这里有一个简短的部分，关于其他人在生成人物肖像方面所做的工作。</p><h2 id="0e99" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">Flickr-Faces-HQ数据集</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/5aba4f218b224f7dec3b492f3c0a73e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qV5HIJfNwJbnd2bg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">来自Flickr-Faces-HQ数据集</strong>的样本，图片来源:<a class="ae lv" href="https://github.com/NVlabs/ffhq-dataset" rel="noopener ugc nofollow" target="_blank"> NVidia </a></p></figure><p id="04a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在开发他们的StyleGAN系列生成网络的同时，NVidia发布了一个名为Flickr-Faces-HQ Dataset (FFHQ)的人物照片数据集。据英伟达称…</p><blockquote class="nh ni nj"><p id="6a66" class="kz la nk lb b lc ld ju le lf lg jx lh nl lj lk ll nm ln lo lp nn lr ls lt lu im bi translated">…[该]数据集由70，000张分辨率为1024×1024的高质量PNG图像组成，并且在年龄、种族和图像背景方面存在相当大的差异。</p></blockquote><p id="269f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管FFHQ图像的质量和种类都非常好，但NVidia还是以<a class="ae lv" href="https://raw.githubusercontent.com/NVlabs/ffhq-dataset/master/LICENSE.txt" rel="noopener ugc nofollow" target="_blank">非商业条款</a>发布了数据集。此外，我发现这些脸似乎剪得太紧了，不适合拍出好的肖像。</p><h2 id="6052" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">MetFaces数据集</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/3d06d39ec56cf4b02a67020cd4cf376d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*swm1471J32juzkjd.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">来自MetFaces数据集的样本，</strong>图像来源:<a class="ae lv" href="https://github.com/NVlabs/metfaces-dataset" rel="noopener ugc nofollow" target="_blank"> NVidia </a></p></figure><p id="0997" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NVidia还发布了MetFaces数据集，这些人脸来自大都会艺术博物馆的画作</p><blockquote class="nh ni nj"><p id="717f" class="kz la nk lb b lc ld ju le lf lg jx lh nl lj lk ll nm ln lo lp nn lr ls lt lu im bi translated">数据集由1，336张分辨率为1024×1024的高质量PNG图像组成。这些图像通过<a class="ae lv" href="https://metmuseum.github.io/" rel="noopener ugc nofollow" target="_blank">大都会艺术博物馆收藏API </a>下载，并使用<a class="ae lv" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> dlib </a>自动对齐和裁剪。各种自动过滤器被用来修剪集合。</p></blockquote><p id="d3b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，NVidia根据非商业条款发布了数据集，他们对人脸使用了类似的紧密裁剪。</p><p id="fb63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是使用StyleGAN 2 ADA在FFHQ数据集上训练并使用MetFaces数据集微调后新生成的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/fc5ed86371956c05d3a846a3a7586651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CCtOgX7pZlOYT9cdfYi6Jw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">StyleGAN 2 ADA</strong>输出，图像来源:<a class="ae lv" href="https://arxiv.org/pdf/2006.06676.pdf" rel="noopener ugc nofollow" target="_blank"> NVidia </a></p></figure><p id="c507" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然结果令人印象深刻，但毫不奇怪，结果似乎裁剪得太紧了。除了数据集，NVidia还根据<a class="ae lv" href="https://github.com/NVlabs/stylegan2-ada/blob/main/LICENSE.txt" rel="noopener ugc nofollow" target="_blank">非商业条款</a>发布了官方源代码，因此这些人脸不能作为NFT出售。此外，在生成的面孔中似乎明显缺乏文化多样性。</p><h1 id="e3bf" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">GANfolk系统组件</h1><p id="7045" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我将在接下来的小节中讨论GANfolk系统中使用的组件和过程的细节。</p><h2 id="58dc" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">采集和预处理训练图像</h2><p id="7cd2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我写了两个脚本来为GANfolk收集源图像。第一个收集了19世纪和20世纪早期WikiArt上的公共领域绘画。第二个从谷歌的开放图像数据集中收集肖像。该数据集由Flickr上根据CC-BY-SA许可发布的照片组成，该许可允许商业使用。</p><p id="8fdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了找到并定位图像中的人脸，我使用了一个名为<a class="ae lv" href="https://github.com/davisking/dlib" rel="noopener ugc nofollow" target="_blank"> DLIB </a>的包中的人脸识别算法。我修改了<a class="ae lv" href="https://gist.github.com/robgon-art/ba854bc3c986297e57b71bfab541cf86" rel="noopener ugc nofollow" target="_blank">面部识别</a>代码来更宽松地裁剪面部。这是一些来自WikiArt的画作的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/f330c62ad08520d531efff1a5365d31e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Nlw3ezxVUi1r5NpvYvcag.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">排列整齐的WikiArt.com肖像</strong>，图片由作者提供</p></figure><p id="e9a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然肖像周围有更多的负空间，但它确实在大多数图像周围拾取了许多空白的黑色区域。这是因为原始图片没有足够的背景区域来考虑脸部方向的旋转和缩放。</p><p id="3986" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了弥补这一点，我使用了罗曼·苏沃罗夫等人开发的修复人工智能系统，名为“大遮罩(LaMa)修复”。该系统将自动“填充”由第二个遮罩图像指定的图像部分。这是我写的和喇嘛一起修补的<a class="ae lv" href="https://gist.github.com/robgon-art/f5a283e437e9029b7a6442bdbf2eeb81" rel="noopener ugc nofollow" target="_blank">代码</a>。下面是从WikiArt修复样本肖像的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/4956489a4b5177a1e61d79cb27b25b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQPUZSPe9ebdk1hkwOhDQw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">来自WikiArt.com的修复肖像</strong>，作者图片</p></figure><p id="bd3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一张经过相同预处理步骤后的图片样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/8a10935da22854371b1f64195e836455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5vm9zCjb2aPPQz3203d3Vw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">修复公开图像中的肖像</strong>，作者图片</p></figure><p id="3b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">照片中似乎有各种各样的风格、年龄和种族。并且，在大多数情况下，修复的效果是不可见的。</p><h2 id="7228" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">两个甘的故事</h2><p id="f488" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我在这个项目中使用了两个GAN，一个是由Kim Seonghyeon(又名rosinality)独立实现的StyleGAN2，另一个是由Patrick Esser等人实现的VQGAN。</p><p id="4a29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我之前的研究中，我发现StyleGAN2在生成的图像中创建一个与训练数据中的类型大致相似的全局结构方面做得非常好。然而，图像细节经常模糊或缺失。但是VQGAN是完全互补的。它不知道如何创建一个全局结构，但它在填充现实的图像细节方面做得很好。使用两种gan是两全其美的。</p><h2 id="49bc" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">使用GPT-3生成图像提示</h2><p id="67dc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了开始创建过程，我使用GPT-3来提示制作图像。我真的要求GPT-3达芬奇指令模型这样做:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="5fdf" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">"Create prompts to render fictional people at different ages and nationalities."</strong></span></pre><p id="fe48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">源代码这里是<a class="ae lv" href="https://gist.github.com/robgon-art/e4dcdba846e7f57875496cb95fb2ca03" rel="noopener ugc nofollow" target="_blank">这里是</a>。典型结果如下。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="6ca1" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">drawing of a thoughtful Brazilian girl<br/>acrylic painting of a sassy Mexican girl<br/>charcoal sketch of an inquisitive Turkish boy<br/>pencil drawing of a determined Indian woman<br/>ink drawing of a playful Japanese girl<br/>acrylic painting of an optimistic Spanish boy</strong></span></pre><p id="d9c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用这些提示有两个目的:(1)作为CLIP的输入，指导GANs生成相应的图像；(2)作为NFT的标题。</p><h2 id="f77c" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">使用StyleGAN2和CLIP生成基线图像</h2><p id="c115" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">生成提示后，我运行StyleGAN2来生成1000幅随机的人物画像。然后，我使用OpenAI的CLIP系统找到与提示最匹配的图像。正如我在<a class="ae lv" rel="noopener" target="_blank" href="/using-openais-clip-to-search-for-design-patents-7fcc63d91033">早期文章</a>中描述的，CLIP系统有一个文本编码器和一个图像编码器，用于确定短语和图像之间的相似性。</p><p id="ff3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是StyleGAN 2生成的最符合提示的前14幅图像，“绘制一个有思想的巴西女孩。”</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/1155334e7a39a93d9ecd2c63b364c729.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v7GGQlD_2T5mvkP5BELcQA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">结果来自GANfolk StyleGAN2生成的图片</strong>，图片作者</p></figure><p id="426e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在结果中看到各种各样的风格。有些看起来像图画；有些看起来像照片。虽然有些人看起来很体贴，但很难说她们看起来像来自巴西的女孩。所以我选择了系列中的第一个来看看VQGAN可以用它做什么。</p><h2 id="ddc4" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">使用VQGAN细化细节</h2><p id="6c74" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为了找到与提示匹配的图像，我从StyleGAN2中提取了一个结果图像，并使用VQGAN对其进行了迭代优化。感谢<a class="ae lv" href="https://github.com/crowsonkb" rel="noopener ugc nofollow" target="_blank">凯瑟琳·克劳森</a>所做的工作以及<a class="ae lv" href="https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP_%28z%2Bquantize_method_with_augmentations%2C_user_friendly_interface%29.ipynb#scrollTo=c3d7a8be-73ce-4cee-be70-e21c1210a7a6" rel="noopener ugc nofollow" target="_blank">贾斯汀·约翰</a>的进一步修改，我再次使用CLIP来分析图像的每次迭代，并引导VQGAN修改图像以更好地匹配提示。这是结果。</p><div class="kj kk kl km gt ab cb"><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f265ba31dda0b4cef8b573531fc22c05.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*r9wQgib1waD5qMaFv7fq_A.png"/></div></figure><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0789323efdcc5b03532300a9756d93ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*KfP6K-yghS_bYnZ9ArCKOg.png"/></div></figure><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/fcc2c57b0465565751fbf7094a15a6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8palrbwZP73OJGEe4nvCTQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk oh di oi oj translated"><strong class="bd ky">来自GANfolk VQGAN的结果提炼出一张图片</strong>，图片作者</p></figure></div><p id="634a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的图像是使用VQGAN和CLIP来匹配提示“绘制一个有思想的巴西女孩”的迭代次数0、25和50你可以看到照片中的女人变得更年轻，或许“更巴西化”此外，肖像风格变得更像素描而不是油画。</p><h2 id="5b6d" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">图像后处理</h2><p id="d412" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我对每张图片进行了几个后期处理步骤，使它们看起来完美统一:</p><ol class=""><li id="3553" class="ok ol it lb b lc ld lf lg li om lm on lq oo lu op oq or os bi translated">添加了一个晕影来淡化图像的角落；</li><li id="c42d" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">使用模糊蒙版使细节更加清晰(可选)；</li><li id="1612" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">执行超分辨率调整，将图像尺寸从512x512增加到2048x2048</li></ol><div class="kj kk kl km gt ab cb"><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/fcc2c57b0465565751fbf7094a15a6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*8palrbwZP73OJGEe4nvCTQ.png"/></div></figure><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/de2590104e65b63e3eba52dc189d12ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*2EpyaX9DRYzzaWV41qwwDQ.png"/></div></figure><figure class="ob kn oc od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/0c243facd3315e5656eac0e30fe149ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*rK-5MKfvV3rNY4-4QSIA1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk oh di oi oj translated"><strong class="bd ky">从左到右，原始图像、渐晕效果后的图像和模糊蒙版效果后的图像</strong>，作者的图像</p></figure></div><p id="45c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这有点微妙，但你可以看到晕影效果如何强调了中心的主题，模糊蒙版效果锐化了细节。这里是<a class="ae lv" href="https://gist.github.com/robgon-art/781be13086e9d4202a3fe8f3041e4747" rel="noopener ugc nofollow" target="_blank">晕影</a>和<a class="ae lv" href="https://gist.github.com/robgon-art/d39731f69a355a93536e856dc2f82e01" rel="noopener ugc nofollow" target="_blank">反锐化掩模效果</a>的源代码。</p><p id="28d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">StyleGAN2和VQGAN生成的图像分辨率为512x512像素。我使用了德国Idealo公司的超分辨率调整系统来提高分辨率。在调整尺寸之前，我给图像添加了一点随机噪声来创造一种绘画效果。这里的源代码是<a class="ae lv" href="https://gist.github.com/robgon-art/a027bb77831b16d31c6c49d6a740535c" rel="noopener ugc nofollow" target="_blank"/>。下面是调整到2048x2048的样图。你可以点击图片放大，查看细节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/fa9bff6a48a7afc1afd2cd2d965ffcba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VCF53fom6gTdDgo3FbBKvg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个深思熟虑的巴西女孩的画像，作者图片</p></figure><h2 id="ca15" class="mu lx it bd ly mv mw dn mc mx my dp mg li mz na mi lm nb nc mk lq nd ne mm nf bi translated">使用GPT-3创建虚构人物的名字和背景故事</h2><p id="c7c6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在将图片发布到OpenSea marketplace之前，我决定通过使用GPT-3达芬奇指令系统为虚构的人创建名字和背景故事来“增加人们对NFTs的兴趣”。</p><p id="44c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用来创建名字的提示如下。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="e9a5" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">Create a name for a thoughtful Brazilian girl.</strong></span><span id="b705" class="mu lx it ns b gy oz nx l ny nz"><strong class="ns iu">First name:</strong></span></pre><p id="ffb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT-3系统的回应是:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="176a" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">Sophia  Last name:  Santos</strong></span></pre><p id="fd05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我注意到系统有时会出现一个名人的名字，所以我写了一些代码来检查这个人是否有维基百科页面。然后我创建了一个循环来不断生成名字，直到它在维基百科上创建了一个<em class="nk">而不是</em>。这里的代码是<a class="ae lv" href="https://gist.github.com/robgon-art/2ac0974c5d143c5b3d43c0ffa5497812" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><p id="c9c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我使用类似的技术为每个虚构的人创建一个背景故事。我使用的提示如下。</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="51ac" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">Create a brief backstory for Sophia Santos, a thoughtful Brazilian girl.</strong></span></pre><p id="9569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT三号写道:</p><pre class="kj kk kl km gt nr ns nt nu aw nv bi"><span id="33ab" class="mu lx it ns b gy nw nx l ny nz"><strong class="ns iu">Sofia Santos was born in the heart of Brazil to a Brazilian father and an American mother. Sofia grew up in a bilingual household and learned to appreciate both of her cultures. Sofia is a thoughtful and intelligent young woman who always looks for ways to help others.</strong></span></pre><p id="1479" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果相当不错！我的合作者兼评论家珍妮弗花时间阅读了GANfolk的全部100篇背景故事，其中只有几篇需要编辑。</p><p id="c4bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在NFT露天市场上铸造GANfolk</strong></p><p id="564d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于我早期的NFT项目，<a class="ae lv" rel="noopener" target="_blank" href="/ganshare-creating-and-curating-art-with-ai-for-fun-and-profit-1b3b4dcd7376"> GANshare </a>，我选择使用多边形区块链，因为它比Etherium更环保。出于同样的原因，我决定将GANfolk系列放在多边形链上。一旦我创建了所有100张带有名字和背景故事的图片，上传并把它们做成NFT就非常简单了。你现在可以在OpenSea上看到整个GANfolk系列。</p><h1 id="dca5" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结果</h1><p id="d622" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这里是前5个GANfolk，显示了经过后处理的StyleGAN2和VQGAN的输出图像。</p><div class="kj kk kl km gt ab cb"><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/11806ae4d3a66de6de4dac5d004c5e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sJR3OOiqI0K51Yf8Ml-rFQ.png"/></div></figure><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/6bd5228d1651c2c2376c0b6334cd80fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qy9gzLI2-VoFwp-AlAnpyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pb di pc oj translated"><strong class="bd ky"> GANfolk #1，</strong>图片作者</p></figure></div><p id="951c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一幅神秘的法国女人的画，玛蒂尔德·杜布瓦<br/> 玛蒂尔德·杜布瓦出生在法国南部的小镇圣·让·德·鲁兹。她是一位富有的航运巨头和一位歌剧演员的独生女。从年轻时起，玛蒂尔德就表现出对艺术的热爱。<br/>上市<a class="ae lv" href="https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743845102298595329" rel="noopener ugc nofollow" target="_blank">T5】OpenSeaT7】</a></p><div class="kj kk kl km gt ab cb"><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/4e81e8c99bff2b7ea2824fddd6f9bc44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lN7qItSLt3c0kur1TJfRNA.png"/></div></figure><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/6d94894ff85ad0d3ec6d55646356de04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*eLiRMDPWiQu9IdIKgLe8Yg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pb di pc oj translated"><strong class="bd ky"> GANfolk #2，</strong>图片作者</p></figure></div><p id="7259" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">GANfolk # 2——专注的葡萄牙男子joo Silva<br/></strong>joo Silva于1984年出生于葡萄牙里斯本。他从小就对了解周围的世界和不同的文化感兴趣。16岁时，他和家人搬到了美国，他在加州完成了高中学业。<br/>在<a class="ae lv" href="https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743846201810223105" rel="noopener ugc nofollow" target="_blank">上挂牌<strong class="lb iu"> OpenSea </strong>上挂牌</a></p><div class="kj kk kl km gt ab cb"><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/9cae9c48d446cdfab6987510433933f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Fbr4ZNX-d8mDOdFj7PWPzg.png"/></div></figure><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/563a319e81609fbd75efccec6837d1ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mR9Am0A_IRRVA1XFSZvyUQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pb di pc oj translated"><strong class="bd ky"> GANfolk #3，</strong>图片作者</p></figure></div><p id="75c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一张淘气的英国少年奈杰尔·拉克斯珀的照片奈杰尔·拉克斯珀出生于富裕的英国父母，他们把他宠坏了。他很快成为一个麻烦的少年，总是在学校和法律上惹麻烦。他的父母想尽一切办法让他守规矩，但都没用。奈杰尔喜欢制造麻烦，喜欢看到父母脸上失望的表情。<br/>在<a class="ae lv" href="https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743847301321850881" rel="noopener ugc nofollow" target="_blank">上市<strong class="lb iu"> OpenSea </strong>上市</a></p><div class="kj kk kl km gt ab cb"><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/57ed8bc8ab4437840f50a6f4015ce360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5TavwLAKFbdpc64tCFxFSQ.png"/></div></figure><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/b20750a3fdf82569b63f0fc54ab4d7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*KgbJTt3zlhPN5vpaOnlavg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pb di pc oj translated"><strong class="bd ky"> GANfolk #4，</strong>图片作者</p></figure></div><p id="c255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">斯特凡·斯托伊切科夫是一名坚忍的保加利亚少年，斯特凡·斯托伊切科夫出生在保加利亚中心的一个小镇上。他的父母是勤劳的农民，他们教会了他诚实、正直和自力更生的重要性。斯特凡一直是一个安静、自省的孩子，他喜欢花时间阅读、学习和探索周围的自然世界。<br/>上市<a class="ae lv" href="https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743848400833478657" rel="noopener ugc nofollow" target="_blank">上市<strong class="lb iu"> OpenSea </strong>上市</a></p><div class="kj kk kl km gt ab cb"><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/35d03fe5cd48840bdad721965273dead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*CMZkURt0ULRDtj69GkAlPA.png"/></div></figure><figure class="ob kn pa od oe of og paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/6e3dad94dc768f32d0a1dbe75f1f5368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jRpBEzhUf14F3cGeiZDYRw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk pb di pc oj translated"><strong class="bd ky"> GANfolk #5，</strong>图片作者</p></figure></div><p id="e2e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">GANfolk # 5——一位忧心忡忡的韩国妇女的画像，金春熙<br/> </strong>金春熙在首尔郊区长大。从小，她就被教导家庭和传统价值观的重要性。她的父母向她灌输了强烈的职业道德，她很快就树立了勤奋工作的名声。<br/>上市<a class="ae lv" href="https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/95949048702184002022994543019454797960309252011183799747181743849500345106433" rel="noopener ugc nofollow" target="_blank">T5】OpenSeaT7】</a></p><p id="1f5c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在这里看到所有的100个GANfolk，<a class="ae lv" href="https://opensea.io/collection/ganfolk" rel="noopener ugc nofollow" target="_blank">https://opensea.io/collection/ganfolk</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/a731c3b5c73fe9c7b24e9ed40ee79e8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*bZeP8Zwjkq3aO2Tpmbr9pg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lv" href="https://opensea.io/collection/ganfolk" rel="noopener ugc nofollow" target="_blank"><strong class="bd ky"/></a>，图片作者</p></figure><h1 id="76ba" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="175c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在这个项目中，我学到了很多关于GANs的优点和缺点。正如我上面提到的，StyleGAN2生成了整体形式良好的体面图像，尽管它们通常缺乏精细的细节。VQGAN是互补的，因为它不知道如何创建具有全局形式的图像，但如果它从一张具有体面形式的图片开始，它在添加细节方面做得很好，主要是在使用剪辑系统时。</p><p id="22de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个项目中，我也注意到了对欧洲人的偏见。《StyleGAN2》在塑造不同国籍的人物形象时似乎有些吃力。这可能是由于训练图像缺乏多样性，尤其是来自WikiArt的绘画。但CLIP似乎知道世界各地的人长什么样，VQGAN负责适当修改图像。</p><h1 id="c5ce" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">源代码</h1><p id="00b8" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我收集的5400张图片可以在<a class="ae lv" href="https://www.kaggle.com/robgonsalves/ganfolk" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到。这个项目的<a class="ae lv" href="https://github.com/robgon-art/GANfolk" rel="noopener ugc nofollow" target="_blank">源代码</a>可以在GitHub上获得。我在<a class="ae lv" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA许可</a>下发布训练图像、源代码和训练模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/4d51d328f3611d9a6c47c603f7109b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/0*pXqarzRqx5Y02iQK.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">知识共享署名共享</p></figure><p id="27ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用这些资源来创建新的图像，请给出这样的归属:此图像是由<a class="ae lv" href="https://robgon.medium.com/" rel="noopener"> Robert A. Gonsalves </a>与<a class="ae lv" href="https://opensea.io/collection/ganfolk" rel="noopener ugc nofollow" target="_blank"> GANfolk </a>一起创建的。</p><h1 id="8a43" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感谢</h1><p id="6713" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我要感谢詹尼弗·林和奥利弗·斯特瑞普对本文的帮助。</p><h1 id="cbad" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考</h1><p id="a6dc" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">[1]R .苏沃罗夫等人的LaMa，<a class="ae lv" href="https://arxiv.org/pdf/2109.07161.pdf" rel="noopener ugc nofollow" target="_blank">分辨率稳健的大型蒙版修复与傅里叶卷积</a> (2021)</p><p id="bc01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]t . Karras等人的StyleGAN2 ADA，<a class="ae lv" href="https://arxiv.org/pdf/2006.06676.pdf" rel="noopener ugc nofollow" target="_blank">用有限的数据训练生成式对抗网络</a> (2020)</p><p id="35bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3]p . Esser、R. Rombach和B. Ommer的VQGAN，<a class="ae lv" href="https://arxiv.org/pdf/2012.09841.pdf" rel="noopener ugc nofollow" target="_blank">驯服高分辨率图像合成的变形金刚</a> (2020年)</p><p id="f3d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4]汤姆·布朗等著的《GPT-3》，<a class="ae lv" href="https://arxiv.org/pdf/2005.14165.pdf" rel="noopener ugc nofollow" target="_blank">语言模型是一次性学习者</a> (2020)</p><p id="03b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5]a .拉德福德等人的剪辑，<a class="ae lv" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf" rel="noopener ugc nofollow" target="_blank">从自然语言监督中学习可转移的视觉模型</a> (2021)</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="f4ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae lv" href="https://robgon.medium.com/membership" rel="noopener">成为</a>的会员，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>