<html>
<head>
<title>Machine Learning Cats and Dogs Breeds Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习猫狗品种分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000#2022-01-11">https://towardsdatascience.com/machine-learning-cats-and-dogs-breeds-classifier-b26a9df45000#2022-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="2839" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""><h1 id="d976" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">机器学习猫狗品种分类器</h1></div><div class=""><h2 id="a266" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">了解如何使用Python中的机器学习模型来创建猫狗品种分类器，以预测您宠物的品种</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/26b5dc7496ad3b08e8a84b46ecbd720f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SkluBJG8tGwU6RsCC0sOIw.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">遇见卡罗莱娜(没错，是一个人的名字；不，不是我选的)——图片作者</p></figure><p id="62bb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">谁不喜欢动物呢，对吧？就我个人而言，如果我能把它们放在我所有的项目中，我就能享受生活了。如果你有点像我，想探索机器学习技术，那么这个教程可能就是你正在寻找的。</p><h1 id="0b0f" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">我们要做什么？</h1><p id="d91a" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">在本教程中，我将向您展示如何获取一个充满可爱动物图像的数据集，使用一些黑魔法，最终得到一个甚至可以对您的个人宠物图片进行分类的模型。这个模型可以用在你的个人应用程序中，这样你就可以向你的朋友和家人展示你学到的很酷的东西。</p><p id="ade6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这篇教程是基于我和同事<a class="ae mx" href="https://www.linkedin.com/in/pedro-silva-3b41a3221/" rel="noopener ugc nofollow" target="_blank"> Pedro Silva </a>一起为大学课程做的一个项目。我们一起设法在测试集上创建了一个准确率为92%的模型。也就是说，它正确地分类了未用于训练的数据集部分中92%的图像。这不是一个糟糕的分数，但它可以被改进——我也将告诉你如何改进！</p><p id="3e3a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们开始之前，你应该知道这些技术在计算上非常昂贵，并且很可能需要很长时间来执行。但是不要因此而气馁！在等待的时候，你可以做很多事情，比如遛狗……或者喝杯咖啡，或者小睡一会儿。事实上，如果你想拖延，这是一个很好的借口；)</p><h1 id="b567" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">数据集</h1><p id="0065" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">为了实现我们的目标，我们将使用Kaggle上的<a class="ae mx" href="https://www.kaggle.com/zippyz/cats-and-dogs-breeds-classification-oxford-dataset" rel="noopener ugc nofollow" target="_blank">猫狗品种分类牛津数据集</a>(可以根据知识共享署名-共享4.0国际许可证下载用于商业/研究目的)。这个数据集总共有7384张宠物的图片，可以分为37个品种(或者，在这个上下文中，<strong class="lg ja">类</strong>)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi my"><img src="../Images/2b4cd47f3cb7ccc60d838acbb302c202.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ww0tZvugQqtgNz4JdgVkow.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">数据集中的图像示例—数据集中的图像</p></figure><p id="f256" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些图片都是非正式的宠物图片，就像我们通常在手机上看到的一样，这很重要，因为这意味着我们的模型将更加通用。否则，只有当照片具有某种特征或以特定方式拍摄时，它才能理解宠物品种。</p><p id="b300" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们需要验证的另一件事是每个类的图像分布。我们需要知道这一点，因为如果类别中的图像数量不完全相同，那么该模型就不太擅长预测某些品种。为了了解这种情况，让我们绘制一个图表，并开始分析数据集！</p><h2 id="f90e" class="na mb iq bd mc nb nc dn mg nd ne dp mk ln nf ng mm lr nh ni mo lv nj nk mq iw bi translated">绘制数据集中每个类别的图片数量</h2><p id="6a95" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">首先，我们需要导入一些依赖项，并将所有图像文件名加载到一个列表中。我们发现有些图像打不开，所以我们把它们的文件名放在一个集合中，从一开始就把它们排除在外。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">加载所有图像的名称</p></figure><p id="0b02" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">数据集包括一个文本文件，其中包含一些关于信息组织方式的信息。我们可以使用这些信息来填充2个字典:<code class="fe nn no np nq b">info_by_name</code>和<code class="fe nn no np nq b">info_by_id</code>。尽管该文件也给了我们关于图像数量的信息，但我决定不信任它，并在代码中对其进行计数。我知道这是可选的，我只是展示我是如何做的。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">将相关数据保存到字典中，以便于访问</p></figure><p id="89b2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们已经有了字典中提到的所有信息，我们可以继续绘制条形图。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用每个品种的图片分布绘制图表</p></figure><p id="d86f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">并且输出应该如下！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nr"><img src="../Images/95bb5972018427b28d4a330a502a0e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zKVjqLby3Sy-BU3Qo72WA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">每个品种图片分布的条形图—按作者分类的图片</p></figure><p id="6d71" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如我们所见，每个品种的图像数量变化不大，这很好！尽管猫和狗的图片数量差异很大，但这应该不是问题，因为分类器并不专注于确定图片是猫还是狗。</p><h1 id="b0a3" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">基本原则</h1><p id="2ec7" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">现在我们已经看了数据，是时候考虑我们将要构建的基础了。因为这个问题被认为是细粒度图像分类的一个问题——它旨在区分具有非常相似特征的类别——经典的机器学习方法不会成功。</p><p id="8c36" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一般来说，在解决这类问题时，一个好的做法是从查看以前的类似作品开始。在研究这个问题时，我们发现一些作品特别有趣和有用:<a class="ae mx" href="https://ieeexplore.ieee.org/document/8524715" rel="noopener ugc nofollow" target="_blank">“使用深度学习识别狗的品种”(z . rádully，C. Sulyok，Z. Vadászi和a . zlde)</a>，<a class="ae mx" href="https://link.springer.com/article/10.1007/s11633-020-1261-0" rel="noopener ugc nofollow" target="_blank">“了解你的狗品种:用深度学习识别狗的品种”(P. Borwarnginn，W. Kusakunniran，S. Karnjanapreechakorn，和<br/> K. Thongkanchorn) </a>和<a class="ae mx" href="http://noiselab.ucsd.edu/ECE228_2019/Reports/Report10.pdf" rel="noopener ugc nofollow" target="_blank">“狗分类成12</a></p><p id="341f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">普遍的看法是，卷积神经网络(CNN)对于涉及大量复杂数据的问题是最可行的，从这些数据中必须获得抽象特征，如形状和颜色，以获得准确的结果。我不会详细介绍什么是CNN在Medium上有很多关于它的文章——但我会在必要时给出一个概述。</p><h2 id="d9b3" class="na mb iq bd mc nb nc dn mg nd ne dp mk ln nf ng mm lr nh ni mo lv nj nk mq iw bi translated">迁移学习</h2><p id="4065" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">许多被分析的文献提到<strong class="lg ja">迁移学习</strong>是一种好的方法，不仅可以提高模型的性能，还可以降低其训练的计算复杂度。</p><p id="aeb9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该技术包括:使用预先训练的模型作为起点；<em class="mz">冻结</em>这些图层，以避免在拟合阶段破坏它们已经拥有的信息；给它添加一些新的图层。</p><p id="b70a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">基本模型被用作理解图像分类任务中的共同特征的框架，例如形状和颜色。前提是这些特征对于每幅图像都是相似的，因此我们可以节省一些时间来重新使用它们之前计算的权重。另一方面，新层的目的是使模型适应新的更具体的特征，从而允许模型对我们新的和具体的数据集进行预测。</p><p id="591e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这甚至可以通过<em class="mz">解冻</em>先前训练好的模型的最后几层来改善，这个过程叫做<strong class="lg ja">微调</strong>。我们一会儿就来看看这个。</p><h1 id="d96c" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">模型架构</h1><p id="cab1" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">由于在<strong class="lg ja"> imagenet </strong>数据集上预训练的<strong class="lg ja"> InceptionV3 </strong>架构在文献中多次被提及，被认为是解决类似问题的迁移学习基础模型的良好架构，我们将使用它。</p><p id="41fd" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该架构由不同层的多种组合组成，包括<strong class="lg ja">卷积层</strong>、<strong class="lg ja">批量归一化层、</strong>和<strong class="lg ja">池层</strong>。这是一个非常深刻和复杂的网络，我不打算详述。</p><p id="97ef" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在基本模型的末尾，我们将添加5层:</p><ul class=""><li id="ecdc" class="ns nt iq lg b lh li lk ll ln nu lr nv lv nw lz nx ny nz oa bi translated"><strong class="lg ja">池层</strong>:该层将直接与InceptionV3层的输出交互。通过应用将形成像素组的过滤器并对其应用操作，池化图层用于对输入进行缩减采样。在我们的例子中，使用了<strong class="lg ja">平均池</strong>，它计算那些像素组的平均值。</li><li id="26c6" class="ns nt iq lg b lh ob lk oc ln od lr oe lv of lz nx ny nz oa bi translated"><strong class="lg ja">密集层</strong>:具有特定数量神经元的单一连接层——在我们的例子中是256个。选择的激活函数是<strong class="lg ja"> ReLU </strong>，它简单地将任何负输入映射到0，将任何正输入映射到自身。它被广泛使用，因为它是实际输入的线性函数，没有任何饱和风险。</li><li id="d88b" class="ns nt iq lg b lh ob lk oc ln od lr oe lv of lz nx ny nz oa bi translated"><strong class="lg ja">丢弃层</strong>:其目的是根据正则化参数随机忽略前一层输出的一定百分比。这一层的目标是防止数据过度拟合。</li><li id="f434" class="ns nt iq lg b lh ob lk oc ln od lr oe lv of lz nx ny nz oa bi translated"><strong class="lg ja">批量标准化层</strong>:用于按顺序缩放输出，使其平均值为0，标准差为1。</li><li id="d38b" class="ns nt iq lg b lh ob lk oc ln od lr oe lv of lz nx ny nz oa bi translated"><strong class="lg ja">密集层</strong>:这是输出层，全连接的一层，有37个神经元，每个对应我们的一个分类类。这里使用了<strong class="lg ja"> SoftMax </strong>激活功能。与逻辑函数(如<strong class="lg ja"> sigmoid </strong>)相比，对于多分类问题，这是一个更好的激活函数。这是因为SoftMax输出一个概率向量，每个类对应一个值，使我们能够轻松理解哪些类具有更高的值，以及更大的概率是正确的。</li></ul><p id="9971" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们还需要向我们的模型添加一个新的输入层，以正确的格式准备要传递给InceptionV3模型的图像。该图层直接与输入数据交互，并将接收到的每个值重新调整为-1和1之间的值。</p><p id="435c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">优化器选择为<strong class="lg ja"> Adam </strong>，并实现随机梯度下降，其默认学习率为0.001，我们将在稍后更改。<strong class="lg ja">准确性</strong>是我们将在培训期间用来评估模型性能的指标。</p><p id="b22d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">使用<strong class="lg ja"> Keras </strong>库，很容易使用这个架构组装模型。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">函数创建具有指定配置的模型</p></figure><h1 id="675d" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">准备图像</h1><p id="1a79" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">为了让这些图像可以在模型中使用，我们必须对它们进行预处理。这包括将它们重新整形为(299，299，3)张量，因为这是InceptionV3模型输入的推荐形状。</p><p id="5ffa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一个常见的预处理任务是将图像的彩色图变为黑白。我们不打算这样做，因为颜色实际上是这个问题所必需的，因为它们对区分品种有特殊的重要性。此外，我们的模型需要一个三维输入。</p><p id="9565" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这里我们将使用之前填充的<code class="fe nn no np nq b">info_by_breed</code>字典来获取每张图片的品种标识符，这样我们就可以将图片数据保存在其ID中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">创建两个数组:一个包含正确格式的图像，另一个包含各自的ID</p></figure><p id="935d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们有了数据，我们需要把它分成两大部分:训练和测试数据。为此，我们要做一个叫做<strong class="lg ja"> <em class="mz">的分层拆分</em> </strong>。这意味着每一类中图像数量之间的比例在测试集中保持相等。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用分层分离来分离训练和测试数据</p></figure><h1 id="46ab" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">超参数优化</h1><p id="00d3" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">尽管我们已经有了一个(希望)可行的模型，但是它的开发过程还没有结束！为了改进当前的设置，我们可以改变很多变量，以了解哪些变量可以产生最好的结果。我们将迅速探索改变<strong class="lg ja">学习率</strong>和<strong class="lg ja">下降值</strong>如何影响模型的能力。</p><p id="feba" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果您想立即测试这个模型，您可以向下滚动以了解如何。我建议您继续阅读本节，了解超参数优化的工作原理及其重要性，从我们如何发现某个配置是否适合我们的问题开始。</p><h2 id="83c0" class="na mb iq bd mc nb nc dn mg nd ne dp mk ln nf ng mm lr nh ni mo lv nj nk mq iw bi translated">k倍交叉验证</h2><p id="755a" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">K-Fold交叉验证是一种众所周知的优化超参数的技术。这是一种将训练数据分为K部分(或<strong class="lg ja">倍</strong>)的技术。然后，该模型将在K-1个零件上进行训练，并在其余零件上进行验证。这要做K次，因为每个折叠都有机会扮演验证的角色。然后对结果进行平均。这试图解决所使用的验证数据不能很好地代表模型性能的问题。因为所有数据都间接用于验证，所以这种情况不会发生。</p><p id="3a86" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管最常见的折叠次数似乎是5次或10次，但我们决定只用3次，因为这个过程需要时间。由于时间限制，我们使用了32和15个时期的批量大小。我鼓励你尝试其他的价值观！</p><p id="38a9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以下函数返回一个字典，其中包含一些指标随时间的变化:训练数据准确性和丢失，以及验证准确性和丢失。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="061b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这里，您可能注意到了代码中的一些奇怪之处——函数<code class="fe nn no np nq b">onehotencode_func</code>！其定义如下:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="e47b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">它有一个非常重要的目标，将我们在<code class="fe nn no np nq b">y_train</code>数组中使用的品种id的十进制表示转换为另一种表示——只使用1和0。每个值都将被转换成一个包含37个元素的数组，这些元素是我们的数据集中的类的数量，除了在与被转换的值相等的位置之外，都用0填充。例如，数字0将被转换为<code class="fe nn no np nq b">[1,0,0,0,0,0,...]</code>，数字3将被转换为<code class="fe nn no np nq b">[0,0,0,1,0,0,...]</code>。</p><p id="6262" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">还记得我们的<strong class="lg ja">密集层</strong>有37个神经元，每个神经元输出一个概率值吗？我们可以把每一个看作是数组中的一个元素。如果我们将最大值设置为1，并将所有其他值设置为0，我们将最终得到一个数字<strong class="lg ja">一个</strong> - <strong class="lg ja">热编码</strong>。该数字是模型对该输入的预测！</p><p id="bb03" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">学习率</strong></p><p id="f73a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下一个要点中的代码对学习率的不同值执行这个过程，并将提到的度量保存在一个名为<code class="fe nn no np nq b">lr</code>的字典中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="795f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们可以使用存储在这本字典中的数据来可视化信息。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="a9c0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">输出应该是两个图表——每个学习率值一个图表，每个图表都有一条针对每个指标的曲线。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/f595d53ca13b31b92ff9919b06999f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*71A3D0pywciAFba5r8xvNw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同学习率指标的演变—图片由作者提供</p></figure><p id="ac90" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">可以清楚地看到较低的学习率如何有益于该模型。训练和验证的准确性显示出相似的曲线和值，甚至训练损失也是相似的，尽管随着学习率的降低，训练损失会有所降低。最大的区别在于验证损失。随着更大的学习速率，该曲线没有收敛到一个值，可能是因为由于更大的步长，它“跳跃”通过局部最小值。在这次经历中，我们得出结论，0.001是所有比较中最好的学习。</p><p id="478d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">下降值</strong></p><p id="3d70" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">改变其他变量的过程非常相似。下一个代码片段重复了相同的过程，但是更改了dropout值。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="22ea" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">显示图表的代码与之前的非常相似！如果一切顺利，结果应该如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/5687bda0587aeb9faa31a357ae82be2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1r0sobCHhVPiXyPcW-TWoQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">指标的演变改变了差值—按作者分类的图片</p></figure><p id="bc71" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这种情况下，差异似乎更不明显。在最后一个时期中，具有0.25的下降的训练精度仅好于0.007，并且还具有大约0.037的较低训练损失。当参考验证数据时，精度比0.35的压降低0.003，验证损失大0.025。这里没有明确的“赢家”，但是我们将假设0.35是一个更好的值，因为在验证数据中结果稍微好一些。</p><h1 id="d021" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">模型评估</h1><p id="c770" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">正如我们所划分的，训练集构成了总数据集的30%,其对应于2216幅图像。既然我们已经发现了最佳超参数，我们终于可以用它来检查我们模型的准确性了。</p><p id="0b1b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">首先，我们创建一个模型，并根据训练数据对其进行训练。我使用了32和15个时期的批量大小。然后，我们让它根据我们的测试数据进行预测，并将值从一次性编码转换为十进制值——预测品种的ID，以便更好地可视化正在发生的事情。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="df36" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在有一些有趣的方法来直观显示模型预测图像的好坏。其中之一是混淆矩阵，这是理解模型预测错误的情况的一种非常好的方式。我们可以用下面的代码展示这个矩阵的热图表示。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="b3bf" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这段代码应该会向我们展示一个如下图所示的图形。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/cff05dcdc1888d0c6501c13c4ccf27fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vo0X6E0QAcgOOA1VPHZ-aw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">混淆矩阵-作者图片</p></figure><p id="1ffa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有趣的是，这个模型在预测埃及猫品种时遇到了一些麻烦。它经常预测品种孟加拉而不是它。当看这些图片时，就有可能明白为什么会发生这种情况，因为它们彼此相当接近，尽管有时它们有不同的皮毛颜色。然而，在绝大多数情况下，分类器能够预测正确的品种。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi my"><img src="../Images/53f35fe5e45d49171a679ff16c6406ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cuwIQ1EkYwIjcaYf_mi8Zg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">孟加拉猫和埃及猫图片示例-来自数据集的图片</p></figure><h1 id="2761" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">微调基本模型</h1><p id="15f3" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">正如我之前所说的，在许多事情中，有一件事我们可以做，以提高模型性能，我想在这里探讨一下，这就是<em class="mz">解冻</em>预训练的InceptionV3模型的最后一些层。</p><p id="03d9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">有了一个已经根据我们的数据训练好的模型，我们现在可以<em class="mz">解冻</em>基础模型的一些层。在这种情况下，我们选择解冻基础模型层的最后三分之一。然后，该模型使用0.0001的非常低的学习率再训练10个时期。程序如下。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="0fde" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在我们可以像以前一样重复同样的技术来评估我们新改进的模型。如果我们给出混淆矩阵的一个表示，我们应该得到一个这样的表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/1be192e14f6cad349a66c67d06b0f45d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U4vGPMi3HrEWk2KWShbShg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">混淆矩阵-作者图片</p></figure><p id="1cb0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">很明显，这一次模型在区分孟加拉猫和埃及猫时没有那么多麻烦。我们甚至成功地将精确度、召回率、f1分数和准确度提高到了92%。</p><h1 id="34c4" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">结论</h1><p id="7b81" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">这当然不是一篇短文，但是我真诚地希望你在这个过程中学到了一些东西。我们仍然可以做很多事情来改进这个模型，使它更加稳健。我把它作为家庭作业留给你:)你也可以在GitHub上点击查看Jupyter笔记本上的所有代码(以及更多)<a class="ae mx" href="https://github.com/immarianaas/cat-dog-breeds-classifier" rel="noopener ugc nofollow" target="_blank">！</a></p><p id="bcdb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">非常感谢您的阅读！请留下您的任何反馈意见。</p></div></div>    
</body>
</html>