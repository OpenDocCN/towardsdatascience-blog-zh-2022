<html>
<head>
<title>Evaluation metrics: leave your comfort zone and try MCC and Brier Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评估指标:离开你的舒适区，尝试MCC和Brier评分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/evaluation-metrics-leave-your-comfort-zone-and-try-mcc-and-brier-score-86307fb1236a#2022-01-08">https://towardsdatascience.com/evaluation-metrics-leave-your-comfort-zone-and-try-mcc-and-brier-score-86307fb1236a#2022-01-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="8a30" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">评估指标:离开你的舒适区，尝试MCC和Brier评分</h1></div><div class=""><h2 id="c9ea" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Matthews相关系数和Brier评分简介</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f4d3a37e05069290056c5b2ec8710462.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UA91CqDtGXSGIwFW"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Eran Menashri 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d1e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Data_science" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">数据科学</strong> </a>是一个跨学科的领域，它使用科学的方法、流程、算法和系统从嘈杂、结构化和非结构化的数据中提取知识和见解，并将来自数据的知识和可操作的见解应用于广泛的应用领域。</p><p id="b1c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Machine_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">机器学习</strong> </a>取而代之的是对计算机算法的研究，这些算法可以通过经验和数据的使用来自动改进。它被视为人工智能的一部分。</p><p id="9a94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">世界各地的数据科学家应用机器学习来建立能够预测未来事件的模型，将人/物体聚类到相似的组中，并识别意外的异常。</p><blockquote class="ls lt lu"><p id="a8e2" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">每个热情的数据科学家都知道，机器学习最令人兴奋的部分是选择能够解决感兴趣的问题(有监督或无监督)的最酷的算法。然而，机器学习中的一个关键部分是模型评估，有时被危险地低估了。</p></blockquote><p id="08a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管如此，我知道大多数数据科学家知道如何正确评估一个模型，他们总是倾向于使用相同的(众所周知的)评估指标。本文的目的是给大家介绍两个不常用的分类评价指标:<em class="lv">马修斯相关系数</em> (MCC)和<em class="lv">布赖尔评分</em> (BS)。此外，我还将尝试强调将它们纳入数据科学管道的原因。</p><h2 id="b85d" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">模型评估</h2><p id="7cf8" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">模型评估是评估机器学习模型执行特定任务(如预测某种疾病的存在与否)的能力的过程。每当你在建立一个机器学习模型的时候，在某些时候，你必须对它进行评估，以确保得到好的结果。</p><p id="b252" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从技术上讲，模型评估包括将您的数据集分为训练集和测试集，使用训练集训练您的模型(<em class="lv">即</em>估计模型参数)，然后使用测试集应用一些评估指标。</p><p id="a47c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，模型度量在无监督和有监督学习的情况下是不同的，对于有监督学习，在回归和分类问题的情况下也是不同的。然而，想法是一样的，非常简单:</p><blockquote class="mx"><p id="4a3a" class="my mz iq bd na nb nc nd ne nf ng lr dk translated">不管你将使用什么类型的评估标准，当预测的结果尽可能接近真实的观察结果时，模型将表现良好。</p></blockquote><p id="dddf" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">由于本文的目标是向您介绍分类问题中使用的<strong class="ky ir"> <em class="lv"> MCC </em> </strong>和<strong class="ky ir"> <em class="lv"> Brier Score </em> </strong>，在下一节中，我将总结这一领域中一些最常用的评估指标。然后，我会向你解释为什么你真的应该尝试这两种方法来代替传统的方法。</p><h2 id="adc6" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">通用评估指标</h2><p id="377c" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">比方说，我们在训练集上训练了我们的awesome分类模型，我们希望评估它在给定新观察值(测试集)的情况下表现如何。在一个典型的二进制问题中，对于测试集的每个元素，你都有一个标签来说明该元素是正还是负(通常是1或0)。你的机器学习模型为测试集中的每个元素提供了一个预测，表示它是<em class="lv">正</em>还是<em class="lv">负</em>。它会将每个元素分配到以下类别之一:<strong class="ky ir">真阴性(TN) </strong>，<strong class="ky ir">真阳性(TP) </strong>，<strong class="ky ir">假阳性(FP) </strong>，<strong class="ky ir">假阴性(FN) </strong>。理想情况下，模型应该最大化TP和TN的数量。在这种情况下，您的模型能够正确地将测试集中为阳性的元素分类为阳性，而不会产生假阴性，并且将测试集中实际为阴性的样本预测为阴性，而不会产生假阳性。</p><p id="9d87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为数据科学家，您知道要证明您的模型表现如何，您可以利用通用评估指标来综合您的模型在TP、TN、FP、FN方面的性能。当需要决定必须选择哪些指标时，大多数人会选择:</p><p id="06b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">准确率:</strong>是正确预测(TP + TN)占被检验案例总数的比例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/05002222f529d5bbff02ae056d0bc0f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*4UjP9wU4RqZ1A0D6dkF4xg.png"/></div></figure><p id="fdce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精度范围在区间[0；+1]，有+1个最佳值和0个最差值。</p><p id="94bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精度:</strong>是模型做出的正面预测总数(TP + FP)中正确正面预测(TP)的比例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/cc886fb921bb168f5a35d65aa748bc52.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*a3vwiBeCiSAXz6XcxuTrEQ.png"/></div></figure><p id="bb47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">区间[0；+1]，有+1个最佳值和0个最差值。</p><p id="2b0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">召回:</strong>是正确的正面预测(TP)占测试集(TP + FN)中正面样本总数的比例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/c998bd1588174904ddeaf29fed4df0cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:406/format:webp/1*8VDnPVHM8WtWIaie5N8r3g.png"/></div></figure><p id="b809" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">召回区间[0；+1]，有+1个最佳值和0个最差值。</p><p id="91c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> F1评分:</strong>是精度和召回率的调和平均值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/be86194903ed503972a1e9b048a4f4e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*KH66PfxIUBO5zHJWP74jBg.png"/></div></figure><p id="5748" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">F1的范围在区间[0；+1]，有+1个最佳值和0个最差值。</p><p id="c74f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这四个指标通常一起使用，以获取模型正确预测实例的能力。<strong class="ky ir"> <em class="lv">准确性</em> </strong>是最简单的选择，当数据集很平衡时(正面和负面的比例倾向于50:50或60:40的比例)，获得关于模型性能的第一印象很有用。<strong class="ky ir"> <em class="lv">精度</em> </strong>当我们想要非常确定我们的预测时，是评估度量的有效选择。<strong class="ky ir"> <em class="lv">回忆</em> </strong>当我们想要捕捉尽可能多的正面时，是一个有效的选择。<strong class="ky ir"> <em class="lv"> F1评分</em> </strong>试图将精度和召回率合成为一个单一的度量，常用于不平衡问题。</p><p id="4832" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，这些并不是唯一的衡量标准。其中最著名的还有:</p><ul class=""><li id="b375" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated"><strong class="ky ir">平衡精度:</strong>一种可用于不平衡数据集的精度。</li><li id="8521" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><strong class="ky ir">加权F1评分:</strong>经典F1评分的演变，克服了F1评分的主要问题:对准确率和召回率给予同等权重。</li><li id="41f5" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><strong class="ky ir">对数损失:</strong>通常用于衡量模型的置信度，因为它是基于预测的概率。</li></ul><p id="12db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而且，数据科学家倾向于使用大量的<strong class="ky ir"> ROC曲线</strong>及其相应的度量<strong class="ky ir"> AUC。</strong> <a class="ae kv" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc" rel="noopener ugc nofollow" target="_blank"> ROC </a>曲线是显示分类模型在所有分类阈值下的性能的图形。<a class="ae kv" href="https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc" rel="noopener ugc nofollow" target="_blank"> AUC </a>代表“ROC曲线下的面积”,它测量整个ROC曲线下的整个二维面积(想想积分)。然而，给出ROC和AUC的完整介绍超出了本文的范围。</p><h2 id="2bee" class="lz ma iq bd mb mc md dn me mf mg dp mh lf mi mj mk lj ml mm mn ln mo mp mq mr bi translated">离开你的舒适区，尝试这些评估指标</h2><p id="927e" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">做了这个初步的，但必要的介绍，让我们深入到本文的主要目标，<em class="lv">即</em>，介绍两个很少使用的评价指标:<em class="lv"> Matthews相关系数</em>和<em class="lv"> Brier评分。</em></p><p id="8754" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">Matthews Correlation Coefficient:</strong>它是Pearson Correlation Coefficient的一种特殊情况，测量真实类别与预测标签的相关性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/5d976e353aafd49e94274df50667b3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*Rq0EzY2CeUh4PjhRu_gHXQ.png"/></div></figure><p id="5142" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它的范围在区间[1，+1]内，其中–1表示完全错误分类，+1表示完全分类，而MCC=0基本上表示随机猜测。我真正邀请您在您的数据科学项目中考虑这一评估指标的主要原因是，只有当预测在所有混淆矩阵类别(TP、FP、TN、FN)中获得良好结果时，MCC才会产生高分，与数据集中的正元素大小和负元素大小成比例。这个结果已经被Davide Chicco和Giuseppe Jurman在他们的论文中证明了。</p><p id="2734" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，让我们考虑一个由100个元素组成的测试集，其中90%的实例是阳性的(不平衡数据集)。现在，考虑这两种情况:</p><p id="387b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lv">场景A </em> →你不知道不平衡类的概念，你建立了一个奇特的模型，它意外地预测所有元素为正。你得出了以下值:TP=90，FP=10，TN=0，FN=0。使用这些数字，准确度和精确度将等于90%，F1分数将为94.74%，召回率甚至将等于1，这些都是非常好的结果。假设TN和FN的数目等于0，MCC的分母也将是0，因此其分数将是未定义的。这将是一个明确的信号，表明您的模型正朝着错误的方向发展，这个信号没有被其他指标捕捉到。</p><p id="a054" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="lv">场景B </em> →你决定建立另一个模型，因为第一个模型总是预测积极的实例。现在，模型也预测负元素，你面临这样的情况:TP=80，FP=10，TN=2，FN=8。在这种情况下，准确率=82%，精度=88.88%，F1=89.89%，召回率=90.9%，MCC=0.08。即使在这种情况下，MCC也是唯一能够捕获模型无法正确预测实例的指标。</p><blockquote class="ls lt lu"><p id="25fb" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">要点1:将MCC纳入您的评估流程！它将帮助您捕捉模型正确预测实例的真实能力。</p></blockquote><p id="bc63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Brier Score: </strong>这是一个评估指标，用于确定预测概率得分的准确性。BS是应用于预测概率的均方误差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e260c6cbd4ac21c53dd55317581b6284.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*X0DzWoidBFzz43ven8DmZA.png"/></div></figure><p id="8ad4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，<em class="lv"> N </em>是实例总数，<em class="lv"> fᵢ </em>是预测的概率，<em class="lv"> oᵢ </em>是事件在实例<em class="lv"> i. </em>的实际结果</p><p id="301a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html" rel="noopener ugc nofollow" target="_blank"> Brier得分</a>总是取0(最佳值)和1(最差值)之间的值，因为这是预测概率(必须在0和1之间)和实际结果(只能取0和1的值)之间的最大可能差异。Brier Score类似于Log Loss，因为它使用概率来衡量模型的可信度。然而，我个人认为Brier评分比Log Loss更能提供信息，因为它的公式更容易解释，其值的范围在0到1之间，而Log Loss没有上限。</p><p id="dd28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一名数据科学家，我在医疗保健和制药行业工作，部署<em class="lv">准确</em>、<em class="lv">可解释</em>并且<em class="lv">自信</em>的模型至关重要。Brier Score是帮助我了解模型是否自信的指标。如果我们考虑两个模型，它们给出相同的精度值，甚至更好，相同的MCC值，我应该最依赖哪一个？一个可能的解决方案是使用Brier Score来查看两个模型的置信度。让我们假设在你的测试集中你只有3个实例(请不要这样做)，2个正的和1个负的[1，1，0]。第一个模型预测关于正类的以下概率[0.6，0.55，0.4]，而第二个模型预测[0.8，0.7，0.1]。第一个模型的BS等于0.34，而第二个模型的BS等于0.14。即使这两个模型具有相同的准确性或MCC值，通过评估Brier评分，我们可以得出结论，第二个模型应该是首选的，因为它更有信心。简而言之，如果你知道自己在做什么，Brier Score会奖励你(即给真实结果一个高概率)，惩罚你不知道自己在做什么(即给错误结果一个高概率)。</p><blockquote class="ls lt lu"><p id="473f" class="kw kx lv ky b kz la jr lb lc ld ju le lw lg lh li lx lk ll lm ly lo lp lq lr ij bi translated">方法2:在你的评估过程中包括Brier评分！它会帮助你了解模特有多自信。</p></blockquote><p id="e1c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后但同样重要的是，<a class="ae kv" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>将MCC和Brier评分作为评估指标，而<a class="ae kv" href="https://pycaret.org/compare-models/" rel="noopener ugc nofollow" target="_blank"> PyCaret </a>仅支持MCC，尚不支持Brier评分。</p><p id="32f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论</strong></p><p id="36aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Matthews相关系数和Brier分数是数据科学家并不总是考虑的两个重要指标。MCC可用作众所周知的指标(准确度、F1分数、精确度和召回率)的替代，因为(a)它在不平衡数据的情况下更可靠，以及(b)只有当预测在所有混淆矩阵类别(TP、FP、TN、FN)中获得良好结果时，它才给出高分。相反，如果您想衡量模型对您的预测有多有信心，BS应该是一个选项。由于BS的取值范围和公式，它比更著名的测井曲线损失更容易解释。</p><p id="b6fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我真的希望你喜欢这篇文章，这是我的第一篇。让我们乐观地说，这是一个长系列的第一个。欢迎发表任何评论，甚至在<a class="ae kv" href="https://www.linkedin.com/in/federicocomotto/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上加我。另外，如果你想看我的下一篇文章，别忘了关注我。</p></div></div>    
</body>
</html>