# 你的电脑最喜欢的度量标准是什么？

> 原文：<https://towardsdatascience.com/whats-your-computer-s-favorite-metric-98c132b0488a>

## 优化不同的函数:MSE vs RMSE vs MAD

均方差(MSE)是模型的[损失函数](http://bit.ly/quaesita_emperor) *最受欢迎的(也是最普通的)选择，它往往是您在数据科学初学者课程中学习的第一个选择。在[以前的帖子](https://bit.ly/quaesita_mseeg)中，我们研究了如何将它用于两个目的:

1.  **绩效评估**:一目了然，我们的模型做得怎么样？换句话说，我们能快速阅读我们正在处理的内容吗？
2.  **模型** [**优化**](https://bit.ly/mfml_045) :这是可能的最佳拟合还是我们可以改进？换句话说，哪个模型最接近我们的数据点？

结果是 MSE 对于模型评估来说是垃圾，但是对于优化来说却是极好的。绩效评估的目标是让一个*人*(你、我、任何人)阅读一个分数，并了解我们模型的一些情况。模型优化的目标是让机器确定模型的最佳设置，使其适合您的数据。

总结这一切的一种更诗意的方式是，MSE 对人类有害，但对机器有益。

对于人类的需求，均方根误差(RMSE)比 MSE 更方便，平均绝对偏差(MAD)是最好的。为了计算 MAD，您只需在所有的[错误](http://bit.ly/quaesita_babymse)上去掉符号，然后取平均值。换句话说，MAD 实际上给出了模型误差的平均大小，使其成为最直观的评估指标。

*(缩写真多！如果你是第一次接触这些字母汤，在阅读之前，请快速浏览一下上一篇文章*[](https://bit.ly/quaesita_mseeg)**。)**

> *MSE 对人类不好，对机器好。*

*在这篇文章中，我将解释为什么 MSE 是你的机器最喜欢的指标(而不是你最喜欢的指标),为什么它比 RMSE 和 MAD 更适合优化。我还将向您展示 MSE 输掉比赛的情况。让我们开始吧！*

*![](img/cd09fbed2380612db0e9dfed834a3e65.png)*

*作者创造的形象。*

# *为什么你的机器喜欢 MSE*

*咳咳，机器[不爱](http://bit.ly/quaesita_ethics)任何人任何事。然而，也有*人*热爱 MSE，而这台机器的编程反映了他们的热爱。这些人就是构建优化算法的工程师。*

> *你学过的一阶导数是 x，这是有充分理由的——在微积分中，平方非常简单。*

*出于对机器的热爱和尊重，专业人士以实现尽可能高效的计算优化算法为荣。开玩笑的。更像是出于对环境和钱包的爱和尊重。低效的算法代价高昂，所以我们避免使用。*

*如果你想使用优化算法(或微积分)快速找到给你最好的理想参数设置— [最优！](http://bit.ly/mfml_046) —性能，有一个方便使用的功能真好。在优化便利性方面，很难超越 MSE。你学过的一阶导数是 x，这是有充分理由的——在微积分中，平方非常简单。微积分 101 的下一课是如何处理常数和求和，因为这些也非常简单。你猜怎么着？平方、总和、常数(1/n)是 MSE 的[整体公式](https://en.wikipedia.org/wiki/Mean_squared_error#Predictor)！*

*MSE 通常是最有效的。*

# *优化 MSE 与 RMSE*

*如果你用 RMSE 作为损失函数呢？(毕竟，这是更有意义的指标。)*

*你会得到同样的结果…无论你优化 RMSE 还是 MSE，获胜的模型都是一样的，但是你不太可能有选择。损失函数永远不会是 RMSE，除非你有太多的空闲时间。为什么？*

> *声称使用 RMSE 的算法实际上只是在引擎盖下优化 MSE，但为了你的观看乐趣，在最后一步用平方根写下答案。*

*即使获胜的 MSE 解决方案与获胜的 RMSE 解决方案相同，但效率要求任何有自尊的工程师都不会在优化算法中使用 RMSE 而不是 MSE。相反，机器将使用 MSE 来寻找解决方案，也许它会在最后弹出一个平方根来满足你怪异的审美缺陷。*

*为什么效率爱好者对 RMSE 如此反感？微积分，就是这个原因。对平方的东西求导很容易。(还记得 d/d *x x* 吗？2x。简单。)和与常数的导数也很容易。所有这些的导数加上一个平方根是不必要的麻烦，特别是如果结果是相同的。*

*直接使用 RMSE 而不是 MSE 增加了一层麻烦(和额外的失败)——这样实现效率很低。*

# *优化 MSE 与 MAD*

*疯子怎么办？难道我们不希望它发生在前的[时刻吗？](http://bit.ly/quaesita_lemur)*

*当然可以，但是 MAD ( [公式这里](https://en.wikipedia.org/wiki/Median_absolute_deviation))里面有个绝对值函数，有个尖角。尖的东西在微积分中不是你的朋友，所以优化 MAD 比优化 MSE 更昂贵。*

*但无论如何，都有很好的理由去做。*

*最重要的一点是，它比 MSE 更好地处理了[异常值](http://bit.ly/quaesita_ytoutliers)。MSE 对异常值过于敏感，使大误差对解决方案产生太大影响。*

> *MSE 处理异常值很糟糕。疯子更擅长对付他们。*

*为什么 MSE 在异常值出现时会反常？离群值有很大的误差…现在我们把这个大数字平方？这是一个巨大的数字！如果一个巨大的数字增加了损失，而你试图让损失尽可能小，最快的方法就是减少那个令人讨厌的错误的大小。你会怎么做？简单。只要把线拉向异常值。*

*有了 MSE，异常值几乎接管了你的解决方案。对于 MAD，没有过度反应。那我们为什么不到处都用 MAD 呢？实施问题。MSE 使用起来更方便，而且它更有可能作为内置在您要借用的任何代码中的东西提供给您。*

*有意义吗？这是你想要的吗？这是你的问题吗？不一定。这是一个容易优化的损失函数。这就是为什么它无处不在。**但是，对于您的建模问题，还有其他损失函数有时会是更好的选择，现在您可以找到它们。*

# *感谢阅读！YouTube 课程怎么样？*

*如果你在这里很开心，并且你正在寻找一个为初学者和专家设计的有趣的完整的应用人工智能课程，这里有一个我为你制作的娱乐课程:*

**“损失函数”是“*目标函数*”的[机器学习](http://bit.ly/quaesita_emperorm)词——它们是一回事。
* * MSE 也超级方便统计推断。*