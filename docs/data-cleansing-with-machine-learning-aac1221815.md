# 利用机器学习进行数据清洗

> 原文：<https://towardsdatascience.com/data-cleansing-with-machine-learning-aac1221815>

## 手动输入数据的概念证明

![](img/175fa275b197c2e8178a3c63fbb457f7.png)

达米安·扎莱斯基在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

手动输入数据可能是世界上最混乱的数据之一。粗手指打字错误、昵称和缩写只是困扰手动输入数据的一些常见问题。甚至像日期字段这样简单的东西也可能以各种格式和分隔符结束。然而，在处理了来自各种机构和保险公司的医生数据后，我开始厌恶手工输入姓名。

清理工作尝试了多次，但最终很明显，这个问题是普遍存在的，任何一个人或团队都无法独自解决。为了做出凹痕(自动凹痕)，我开始尝试各种模糊逻辑匹配的方法。总的想法是定义两个名字之间的某种形式的度量/距离，并确定适当的截断来表示“匹配”或“不匹配”。每种方法在特定情况下都有效，但是各种系统因素，如姓名长度或原产国，将不可避免地迫使匹配结果超出截止范围。有趣的是，与不匹配的名字相比，匹配名字之间的编辑距离仍然相对较小。这是因为扩大两个匹配之间的距离的相同特征成比例地扩大不匹配之间的距离。

这激发了一个想法，使用机器学习来识别*差距*，而不是依赖于一个截止。以下想法为机器学习方法清理手动输入数据奠定了基础。

![](img/879fca51e8cb20fcac6af815f4200601.png)

[布雷特·乔丹](https://unsplash.com/@brett_jordan?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

# 该过程

## 第一步:标准化

将任何“姓氏”或“姓氏，名字”条目转换为相同的格式。或者，更好的是，把它们分成不同的领域。做你想做的事。只要确保所有的名字都是相同的格式。这是一小步，但影响重大。机器正在为我们做一些重大决定。让我们至少在力所能及的地方帮忙。

> 分开的字段产生更多的数据，并允许更细微的测量。并非所有数据都是平等的。与姓名相比，地址可能需要不同的测量方法。中间的首字母可能需要更多的重量。

## 步骤 2:播种数据

假设我们的数据库中有了一个新名字，“威利·旺卡”。我们有一个 10k 已知条目的列表，但是“威利·旺卡”不在其中。当我们将这个新条目与“William Wonka”进行匹配时，我们需要用我们的新数据点播种已知条目。从字面上看，只需在数据中添加“威利·旺卡”即可。

这给了我们一个极端的异常值，当我们测量我们的编辑距离时，他代表了一个完美的匹配。这个种子条目也作为我们的集群的基础，相近的匹配将加入其中。所有其他不匹配的名称将被集中到不包括我们的种子条目的集群中。

![](img/52a270da0be4a477b79d3b5467226dde.png)

杰里米·毕晓普在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

## 步骤 3:测量编辑距离

这是魔法开始的地方。编辑距离帮助我们确定两个名字之间的距离。有各种不同的方法来测量名字之间的距离。下面是一个简短的列表:

1.  [Levenshtein 距离](https://en.wikipedia.org/wiki/Levenshtein_distance):使用删除、插入和替换
2.  [最长公共子序列](https://en.wikipedia.org/wiki/Longest_common_subsequence) (LCS):使用插入和删除
3.  [汉明距离](https://en.wikipedia.org/wiki/Hamming_distance):仅使用替换，要求字符串长度相同
4.  [damer au–Levenshtein 距离](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance):使用插入、删除、替换和相邻字符的换位。
5.  [Jaro 距离](https://en.wikipedia.org/wiki/Jaro_distance):仅使用换位

另一种测量编辑距离的方法是使用 [soundex](https://en.wikipedia.org/wiki/Soundex) 算法，该算法使用语音字符而不是字母表。虽然它本身不是距离的度量，但它增加了一个额外的标准化层。想象一下，输入你在电话中听到的名字。你听到“比利”这个名字，但它是拼写为“比利”还是“比利”。正常的编辑距离会将这些视为不同。soundex 算法之上的编辑距离会说它们是相同的。

## 第四步:让机器来决定！

![](img/639fbf24cceb96a6a78cd3c79e13b4d3.png)

[亚历山大·奈特](https://unsplash.com/@agk42?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍照

最后，聚类算法开始为我们做决定。然而，并不是任何聚类算法都适用于此。重要的是使用凝聚聚类算法，该算法从 *n* 个聚类开始(其中 *n* 是数据点的数量)，然后合并最近的 2 个聚类，直到只剩下 *k* 个聚类(其中 *k* 是聚类停止的聚类数量)。我们最终得到的聚类数量取决于数据点的数量和距离。一个好的起点是十个最终的集群。九个虚拟聚类来消耗不匹配的聚类，一个聚类包含我们可能的匹配。

凝聚聚类还确保我们的种子条目获得它们自己的聚类，并且只有比任何非匹配聚类更接近种子条目的数据点被包括在内。这是计算机为我们做决定的地方。还记得截止点如何移动，但间隙不会移动吗？聚类算法使用该间隙作为边界，它根据所有其他数据点来确定该边界。那些不匹配项越远，近似匹配项相对于我们的种子条目就越接近。因此，当该算法对那些相近的匹配进行聚类时，它会根据唯一的一组距离做出决定。

## 考虑

这里的普通方法并不是数据清理的灵丹妙药。任何实施都面临一些挑战:

1.  这个过程一次只能处理一个名字。当清理大型数据集时，这是一个真正的考虑因素。然而，每个决定都可以在真空中发生，这使得它非常适合多线程设置。你不必有一个完全干净的数据集来匹配。
2.  原产国和语言与 soundex 算法有关。这使得他们不是一个一刀切。理想情况下，您可以根据目标名称的来源交换算法。不过，任何 soundex 通常都比没有 soundex 好。
3.  普通的凝聚聚类算法需要大量资源，即使是中等大小的数据集也需要考虑。
4.  并非所有的距离都是一样的。编辑距离的适当平衡是很重要的，并且会随着姓名、地址、首字母等的变化而变化。此外，标准化分数可以大大提高性能。

## 结论

谢谢你能走到这一步！这篇文章在使用机器学习进行数据清理的表述上有点抽象。对于我们这些更注重实践的人来说，我制作了一个在线互动演示。尝试一下，感受一下算法是如何工作的，以及什么样的变化会改变算法。首先在数据集中取一个名字，稍微拼错一点。

如果你喜欢这个概念证明，并希望联系或关注，请在 [LinkedIn](https://www.linkedin.com/in/hersheleason/) 上查看我，并关注 [Medium](https://medium.com/@hersheleason/) 上的更多文章！