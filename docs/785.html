<html>
<head>
<title>Parsing the UrbanSound8K Dataset with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用TensorFlow解析UrbanSound8K数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/parsing-the-urbansound8k-dataset-with-tensorflow-43192a5206e7#2022-01-27">https://towardsdatascience.com/parsing-the-urbansound8k-dataset-with-tensorflow-43192a5206e7#2022-01-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="699c" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">用TensorFlow解析UrbanSound8K数据集</h1></div><div class=""><h2 id="b68c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从原始音频到TFRecord再到填充批次</h2></div><p id="84e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有多种方法可以将数据输入神经网络。最常用的是Numpy数组和CSV/Pandas文件。此外，TensorFlow还提供自定义存储格式TFRecord。它很方便，但对初学者不太友好。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/4bea86c240e185c2fff8c9f5cb6ee332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C94R0OpmwnjkS83b"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">理查德·霍瓦特在<a class="ae lr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="de9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管许多数据集都是现成的，比如MNIST或CIFAR，但有时您必须自己实现定制的数据集。令人欣慰的是，一旦你做了几次，把其他数据集转换成TFRecord格式并不困难。在这里，我们将分析UrbanSound8K数据集，以TFRecord格式存储它，最后，迭代它的样本。如果你对这种格式完全陌生，你可以在这里得到一个实际操作的回顾<a class="ae lr" rel="noopener" target="_blank" href="/a-practical-guide-to-tfrecords-584536bc786c">，它也涵盖了我们如何解析文本和图像数据。</a></p><h2 id="7caa" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">数据集描述</h2><p id="c407" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><a class="ae lr" href="https://urbansounddataset.weebly.com/urbansound8k.html" rel="noopener ugc nofollow" target="_blank"> UrbanSound8K数据集</a> [1】(可在<a class="ae lr" href="https://urbansounddataset.weebly.com" rel="noopener ugc nofollow" target="_blank">免费获得，仅用于非商业用途</a>；CC BY-NC 3.0)包含8732个不同时长的音频文件。每个样本最多4秒钟，属于10个类别中的一个。这些文件被预先安排在十个文件夹中，并以WAVE格式存储。每个文件可能有不同的采样率、位深度和通道数。大约7 GB，是一个中等大小的数据集。因此，如果你正在寻找一个更小，更容易访问的音频数据集，那么看看ESC50。</p><h2 id="99ab" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">下载和提取</h2><p id="a103" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">转到<a class="ae lr" href="https://urbansounddataset.weebly.com/urbansound8k.html" rel="noopener ugc nofollow" target="_blank">数据集的网页</a>，点击底部的下载链接下载数据集。如前所述，您可以免费使用这些数据，但只能用于非商业项目——对于这篇展示数据解析和相关概念的解释性博文来说，一切都很好。</p><p id="a439" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据您的连接，下载可能需要几分钟。下载完成后，解压归档文件。你现在有两个文件夹，<em class="mq">音频</em>和<em class="mq">元数据</em>。我们只需要第一个。</p><p id="3446" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个文件夹中，文件被预先安排在十个文件夹中，<em class="mq">文件夹1 </em>到<em class="mq">文件夹10 </em>。所有文件都根据以下方案命名:</p><p id="e985" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">{源ID }-{标签}-{拍摄}-{切片}。声音资源文件</p><p id="ddc7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一部分用来标识源文件的ID，<em class="mq">标签</em>是类标签，<em class="mq">取</em>和<em class="mq">片</em>用来区分取自同一个原始文件的多个样本。</p><h2 id="3216" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">将音频数据解析为TFRecords</h2><p id="9414" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">事先说句话，如果这是你第一次使用TFRecords，TensorFlow高效数据存储的原生格式，或者你需要复习一下，看看<a class="ae lr" href="https://colab.research.google.com/drive/1xU_MJ3R8oj8YYYi-VI_WJTU3hD1OpAB7" rel="noopener ugc nofollow" target="_blank">这款Google Colab笔记本</a>和这里的配套描述<a class="ae lr" rel="noopener" target="_blank" href="/a-practical-guide-to-tfrecords-584536bc786c"/>。</p><p id="de87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们不需要元数据文件，因为一个音频样本的标签就写在它的文件名中。因此，我们可以直接开始将数据写入TFRecord文件。为了做到这一点，我们首先导入一些包和几个助手函数:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="792c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们定义一个从磁盘加载音频的函数。为此，我们使用了<em class="mq">图书馆</em>图书馆。虽然有其他选择，比如<em class="mq"> scipy </em>，但我发现它最方便。此外，我们可以通过首先在“/”上拆分文件名，然后在“-”上拆分文件名来快速提取标签。最后，我们返回音频数据、其采样率、标签和文件名:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="a09e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们定义一个函数，这个函数使得提取的数据准备好被存储。这里，我们将使用前面实现的助手函数。正如我在TFRecord 格式的介绍性实践指南中所描述的，这些函数用于将整数、浮点、字符串和字节数据准备好写入磁盘。给特性起一个合适的名字有助于我们以后提取它们。最后，我们将它们包装成一个<em class="mq">示例</em>对象，就像一个包含一些内容和属性的盒子。下图形象地展示了这一概念:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mt"><img src="../Images/bbcdd535a0e848b01ba0fb0390a3b006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xN2KGlvEQhCsSvkIZib0Q.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">TFRecord格式将数据存储为<em class="mu">示例对象，可以这么想。图片由作者提供。</em></p></figure><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="3c05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在已经定义了两个核心功能:从磁盘加载音频数据，并将其解析为TFRecord兼容的格式。因此，我们可以实现两者相结合的方法。为此，我们创建一个<em class="mq"> TFRecordWriter </em>对象，负责将数据写入磁盘，并遍历我们找到的所有音频文件。然后，解析每个音频文件，打包成一个<em class="mq">示例</em>对象，并写入一个TFRecord文件。</p><p id="eb7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">即使数据集相对较大，存储一个完整文件夹的单个TFRecord文件也有合适的大小，大约为550 MB。对于较大的数据集，您希望使用更多的文件。对于这种情况，<a class="ae lr" href="https://www.tensorflow.org/tutorials/load_data/tfrecord?hl=en" rel="noopener ugc nofollow" target="_blank">文档中有一些提示</a>。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="8b94" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们实现下面的<em class="mq"> main </em>函数来迭代所有的折叠:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="f794" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了完善我们的小脚本，我们定义了一个参数解析器。它采用开头提到的<em class="mq">音频</em>目录和输出目录的路径。如果该目录尚不存在，将创建它:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="be05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过调用<em class="mq"> python /path/to/script.py </em>来运行脚本</p><p id="f088" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在定义了创建TFRecord文件的脚本之后，我们可能希望稍后读回这些文件。这就是我们现在要实现的。</p><h2 id="e59c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">从TFRecords读取音频数据</h2><p id="87fa" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">一旦做了几次，从TFRecord文件中获取数据实际上非常简单。我们只需颠倒存储过程。之前，我们将名为<em class="mq"> sr </em>、<em class="mq"> len </em>、<em class="mq"> y </em>、<em class="mq">、</em>等特征放入盒子中。因此，我们使用相同的名称来获取数据。</p><p id="a9d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">唯一需要注意的是音频数据。因为它是一个数组，所以我们要对它进行整形。这就是我们存储<em class="mq"> len </em>属性的原因。类似地，<em class="mq">文件名</em>必须被解析成一个字符串:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="f330" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用下面的函数来读取一个或多个TFRecord文件的内容。它返回一个<em class="mq">数据集</em>对象:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="1434" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用for循环迭代前几个元素，检查它们是否有错误。每个样本由四部分组成:实际音频数据、标签、采样速率和原始文件名称:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="a453" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个警告是不均衡的文件持续时间。常规批处理操作将会失败。所以，我们要垫批。我们可以通过以下方式做到这一点:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="e7fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意:我们将样本填充到178017个条目，因为最长的音频文件略超过4秒，我们不想截断这些数据。所有其他文件的最大输出时间为4秒* 44100 Hz = 176400个样本。</p><p id="af0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！现在就看你的了。</p><h1 id="1963" class="mv lt iq bd lu mw mx my lx mz na nb ma jw nc jx md jz nd ka mg kc ne kd mj nf bi translated">摘要</h1><p id="dac6" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在这篇文章中，我们将UrbanSound8K数据集解析为TFRecord。为此，我们使用了<em class="mq"> librosa </em> python库和几个助手函数。然后，我们迭代预定义的折叠，并分别解析每个折叠。</p><p id="467e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们提取了数据并填充了一批数据。这给了我们一个可以迭代的数据集。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h2 id="ff30" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">文学</h2><p id="7631" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">[1] J. Salamon、C. Jacoby和J. P. Bello，“城市声音研究的数据集和分类法<a class="ae lr" href="http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir"/></a>”，第22届ACM多媒体国际会议，美国奥兰多，2014年11月。</p></div></div>    
</body>
</html>