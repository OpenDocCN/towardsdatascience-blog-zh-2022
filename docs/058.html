<html>
<head>
<title>TensorFlow for Computer Vision — Transfer Learning Made Easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面向计算机视觉的TensorFlow轻松实现迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-for-computer-vision-transfer-learning-made-easy-e3d1418b110f#2022-01-03">https://towardsdatascience.com/tensorflow-for-computer-vision-transfer-learning-made-easy-e3d1418b110f#2022-01-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="5fe1" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">面向计算机视觉的TensorFlow轻松实现迁移学习</h1></div><div class=""><h2 id="01d1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">90+%的准确率？迁移学习使之成为可能。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/85efd3377c0b9a3bb43cd5d623da5346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6mDHQy_SmCU2JALG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@ratushny?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Dmitry Ratushny </a>拍摄</p></figure><p id="7006" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://betterdatascience.com/tensorflow-for-computer-vision-how-to-increase-model-accuracy-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank">上周</a>，您已经看到了数据增强如何从TensorFlow模型中获得额外的百分之几的准确性。与你今天看到的相比，我们只是触及了表面。通过一种非常简单的方法，我们最终将在验证集上获得90%以上的准确率。</p><p id="c362" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您还将看到，如果我们将训练数据量缩减20倍，验证准确性会发生什么变化。剧透警告——它将保持不变。</p><p id="b4b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不想看书？请观看我的视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="9d03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在<a class="ae ky" href="https://github.com/better-data-science/TensorFlow" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上下载源代码。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="ff5c" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">TensorFlow中的迁移学习是什么？</h1><p id="b09c" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">从头开始编写神经网络模型架构涉及大量猜测。多少层？每层有多少个节点？使用什么激活功能？正规化？你不会很快就没有问题了。</p><p id="f064" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">迁移学习采用不同的方法。不是从零开始，你需要一个现有的神经网络模型，这个模型已经被一个非常聪明的人在一个巨大的数据集上训练过，这个数据集的硬件比你家里的要高级得多。这些网络可以有数百层，不像我们几周前实施的<a class="ae ky" href="https://betterdatascience.com/train-image-classifier-with-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank"> 2块CNN </a>。</p><p id="c5a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">长话短说——你进入网络越深，你就能提取出越复杂的特征。</p><p id="3b9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整个迁移学习过程可归结为3个步骤:</p><ol class=""><li id="c371" class="nb nc it lb b lc ld lf lg li nd lm ne lq nf lu ng nh ni nj bi translated"><strong class="lb iu">以一个预先训练好的网络</strong> —例如，以一个VGG、ResNet或EfficientNet架构为例，该架构已经在数百万张图像上进行了训练，可以检测1000个类别。</li><li id="203e" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><strong class="lb iu">切掉模型的头部</strong>——去掉预训练模型的最后几层，用你自己的替换掉。例如，我们的<a class="ae ky" href="https://betterdatascience.com/top-3-prerequisites-for-deep-learning-projects/" rel="noopener ugc nofollow" target="_blank">狗与猫数据集</a>有两个类，最终的分类层需要类似于此。</li><li id="fcaf" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu ng nh ni nj bi translated"><strong class="lb iu">微调最终图层</strong> —在数据集上训练网络以调整分类器。预训练模型的权重是冻结的，这意味着它们不会在您训练模型时更新。</li></ol><p id="ccc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些归结起来就是迁移学习允许你用更少的数据获得更好的结果。我们定制的2块架构在验证集上只给出了76%的准确率。迁移学习将使其飙升至90%以上。</p><h1 id="8908" class="me mf it bd mg mh np mj mk ml nq mn mo jz nr ka mq kc ns kd ms kf nt kg mu mv bi translated">入门-库和数据集导入</h1><p id="18a0" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们将使用来自Kaggle的<a class="ae ky" href="https://www.kaggle.com/pybear/cats-vs-dogs?select=PetImages" rel="noopener ugc nofollow" target="_blank">狗和猫的数据集</a>。它根据知识共享许可协议获得许可，这意味着您可以免费使用它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/5e6220aff16a4e8ef1494e652ffd5364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4z0dNuYpLhbEPwco09HBhQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片1-狗和猫的数据集(图片由作者提供)</p></figure><p id="78e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集相当大-25，000张图像均匀分布在各个类别之间(12，500张狗图像和12，500张猫图像)。它应该足够大，可以训练一个像样的图像分类器。唯一的问题是——它不是为开箱即用的深度学习而构建的。您可以按照我以前的文章创建一个合适的目录结构，并将其分为训练集、测试集和验证集:</p><div class="nv nw gp gr nx ny"><a href="https://betterdatascience.com/top-3-prerequisites-for-deep-learning-projects" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">用于图像分类的TensorFlow深度学习项目的三大先决条件|更好的数据…</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">想训练一个用于图像分类的神经网络？确保做到这一点首先识别图像中的对象是一个…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">betterdatascience.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om ks ny"/></div></div></a></div><p id="d697" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您还应该删除<em class="on"> train/cat/666.jpg </em>和<em class="on"> train/dog/11702.jpg </em>图像，因为它们已损坏，您的模型将无法使用它们进行训练。</p><p id="b911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完成后，您可以继续导入库。我们今天只需要Numpy和TensorFlow。其他导入是为了消除不必要的警告消息:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="762a" class="ot mf it op b gy ou ov l ow ox">import os<br/>os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' </span><span id="a1e9" class="ot mf it op b gy oy ov l ow ox">import warnings<br/>warnings.filterwarnings('ignore')</span><span id="b5ca" class="ot mf it op b gy oy ov l ow ox">import numpy as np<br/>import tensorflow as tf</span></pre><p id="9b3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在整篇文章中，我们必须从不同的目录中加载训练和验证数据。最佳实践是声明一个加载图像和<a class="ae ky" href="https://betterdatascience.com/tensorflow-for-computer-vision-how-to-increase-model-accuracy-with-data-augmentation/" rel="noopener ugc nofollow" target="_blank">数据扩充</a>的函数:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="eecd" class="ot mf it op b gy ou ov l ow ox">def init_data(train_dir: str, valid_dir: str) -&gt; tuple:<br/>    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>        rescale=1/255.0,<br/>        rotation_range=20,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest'<br/>    )<br/>    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>        rescale=1/255.0<br/>    )<br/>    <br/>    train_data = train_datagen.flow_from_directory(<br/>        directory=train_dir,<br/>        target_size=(224, 224),<br/>        class_mode='categorical',<br/>        batch_size=64,<br/>        seed=42<br/>    )<br/>    valid_data = valid_datagen.flow_from_directory(<br/>        directory=valid_dir,<br/>        target_size=(224, 224),<br/>        class_mode='categorical',<br/>        batch_size=64,<br/>        seed=42<br/>    )<br/>    <br/>    return train_data, valid_data</span></pre><p id="33fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们加载我们的猫狗数据集:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="916c" class="ot mf it op b gy ou ov l ow ox">train_data, valid_data = init_data(<br/>    train_dir='data/train/', <br/>    valid_dir='data/validation/'<br/>)</span></pre><p id="6a5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是您应该看到的输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/5d5f70ec1e0ca70fe183e49f6f2ea217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SWDcWWqNcPK7h7J8FObBBQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图像2 —训练和验证图像的数量(按作者分类的图像)</p></figure><p id="671d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">20K训练图像对于迁移学习来说是不是大材小用？可能吧，但是让我们看看我们能得到多精确的模型。</p><h1 id="716d" class="me mf it bd mg mh np mj mk ml nq mn mo jz nr ka mq kc ns kd ms kf nt kg mu mv bi translated">张量流在迁移学习中的应用</h1><p id="19b7" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">对于迁移学习，我们基本上是加载一个巨大的预训练模型，而没有顶级分类层。这样，我们可以冻结学习到的权重，只添加输出图层来匹配我们的数据集。</p><p id="e541" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，大多数预训练模型都是在具有1000个类的<em class="on"> ImageNet </em>数据集上训练的。我们只有两只(猫和狗)，所以我们需要具体说明。</p><p id="5a48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是<code class="fe pa pb pc op b">build_transfer_learning_model()</code>函数发挥作用的地方。它只有一个参数<code class="fe pa pb pc op b">base_model</code>，代表预训练的架构。首先，我们将冻结该模型中的所有层，然后通过添加几个自定义层来构建一个<code class="fe pa pb pc op b">Sequential</code>模型。最后，我们将使用通常的假设来编译模型:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="ca23" class="ot mf it op b gy ou ov l ow ox">def build_transfer_learning_model(base_model):<br/>    # `base_model` stands for the pretrained model<br/>    # We want to use the learned weights, and to do so we must freeze them<br/>    for layer in base_model.layers:<br/>        layer.trainable = False<br/>        <br/>    # Declare a sequential model that combines the base model with custom layers<br/>    model = tf.keras.Sequential([<br/>        base_model,<br/>        tf.keras.layers.GlobalAveragePooling2D(),<br/>        tf.keras.layers.BatchNormalization(),<br/>        tf.keras.layers.Dropout(rate=0.2),<br/>        tf.keras.layers.Dense(units=2, activation='softmax')<br/>    ])<br/>    <br/>    # Compile the model<br/>    model.compile(<br/>        loss='categorical_crossentropy',<br/>        optimizer=tf.keras.optimizers.Adam(),<br/>        metrics=['accuracy']<br/>    )<br/>    <br/>    return model</span></pre><p id="4921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在有趣的部分开始了。从TensorFlow导入<code class="fe pa pb pc op b">VGG16</code>架构，并将其指定为我们的<code class="fe pa pb pc op b">build_transfer_learning_model()</code>函数的基础模型。<code class="fe pa pb pc op b">include_top=False</code>参数意味着我们不想要顶级分类层，因为我们已经声明了我们自己的。另外，请注意<code class="fe pa pb pc op b">input_shape</code>是如何被设置成类似我们的图像形状的:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="6433" class="ot mf it op b gy ou ov l ow ox"># Let's use a simple and well-known architecture - VGG16<br/>from tensorflow.keras.applications.vgg16 import VGG16</span><span id="ec07" class="ot mf it op b gy oy ov l ow ox"># We'll specify it as a base model<br/># `include_top=False` means we don't want the top classification layer<br/># Specify the `input_shape` to match our image size<br/># Specify the `weights` accordingly<br/>vgg_model = build_transfer_learning_model(<br/>    base_model=VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')<br/>)</span><span id="99df" class="ot mf it op b gy oy ov l ow ox"># Train the model for 10 epochs<br/>vgg_hist = vgg_model.fit(<br/>    train_data,<br/>    validation_data=valid_data,<br/>    epochs=10<br/>)</span></pre><p id="c000" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是模型训练10个时期后的输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/2bebbc78eeb1fa16ab1fc010f0e22373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-LWcm5_uFMFVCvMB_cjQ5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3—10个时期后20K训练图像上的VGG16模型(图片由作者提供)</p></figure><p id="926c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是值得大书特书的— 93%的验证准确率，甚至不用考虑模式架构。迁移学习的真正魅力在于训练精确模型所需的数据量，这比定制架构少得多。</p><p id="0067" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">少多少？</strong>让我们将数据集缩小20倍，看看会发生什么。</p><h1 id="4eb1" class="me mf it bd mg mh np mj mk ml nq mn mo jz nr ka mq kc ns kd ms kf nt kg mu mv bi translated">在20倍的较小子集上进行迁移学习</h1><p id="74ec" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">我们想看看减少数据集大小是否会对预测能力产生负面影响。为训练和验证映像创建新的目录结构。图像将被保存在<code class="fe pa pb pc op b">data_small</code>文件夹中，但是你可以随意将其重命名为其他名称:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="d2eb" class="ot mf it op b gy ou ov l ow ox">import random<br/>import pathlib<br/>import shutil</span><span id="3caf" class="ot mf it op b gy oy ov l ow ox">random.seed(42)<br/></span><span id="1cf4" class="ot mf it op b gy oy ov l ow ox">dir_data = pathlib.Path.cwd().joinpath('data_small')<br/>dir_train = dir_data.joinpath('train')<br/>dir_valid = dir_data.joinpath('validation')</span><span id="ff65" class="ot mf it op b gy oy ov l ow ox">if not dir_data.exists(): dir_data.mkdir()<br/>if not dir_train.exists(): dir_train.mkdir()<br/>if not dir_valid.exists(): dir_valid.mkdir()</span><span id="8945" class="ot mf it op b gy oy ov l ow ox">for cls in ['cat', 'dog']:<br/>    if not dir_train.joinpath(cls).exists(): dir_train.joinpath(cls).mkdir()<br/>    if not dir_valid.joinpath(cls).exists(): dir_valid.joinpath(cls).mkdir()</span></pre><p id="4b5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是可以用来打印目录结构的命令:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="3987" class="ot mf it op b gy ou ov l ow ox">!ls -R data_small | grep ":$" | sed -e 's/:$//' -e 's/[^-][^\/]*\//--/g' -e 's/^/   /' -e 's/-/|/'</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/9e0437e22c8955c9f0f2474beaf6a665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0UQHT3Ek1Idu8sqe0cwEIg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4 —目录结构(作者图片)</p></figure><p id="c623" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将图像样本复制到新文件夹中。<code class="fe pa pb pc op b">copy_sample()</code>功能从<code class="fe pa pb pc op b">src_folder</code>获取<code class="fe pa pb pc op b">n</code>图像并将其复制到<code class="fe pa pb pc op b">tgt_folder</code>。默认情况下，我们将把<code class="fe pa pb pc op b">n</code>设置为500:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="fde7" class="ot mf it op b gy ou ov l ow ox">def copy_sample(src_folder: pathlib.PosixPath, tgt_folder: pathlib.PosixPath, n: int = 500):<br/>    imgs = random.sample(list(src_folder.iterdir()), n)</span><span id="45a4" class="ot mf it op b gy oy ov l ow ox">    for img in imgs:<br/>        img_name = str(img).split('/')[-1]<br/>        <br/>        shutil.copy(<br/>            src=img,<br/>            dst=f'{tgt_folder}/{img_name}'<br/>        )</span></pre><p id="493f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们复制训练和验证图像。对于验证集，我们将每个类只复制100个图像:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="b642" class="ot mf it op b gy ou ov l ow ox"># Train - cat<br/>copy_sample(<br/>    src_folder=pathlib.Path.cwd().joinpath('data/train/cat/'), <br/>    tgt_folder=pathlib.Path.cwd().joinpath('data_small/train/cat/'), <br/>)</span><span id="9408" class="ot mf it op b gy oy ov l ow ox"># Train - dog<br/>copy_sample(<br/>    src_folder=pathlib.Path.cwd().joinpath('data/train/dog/'), <br/>    tgt_folder=pathlib.Path.cwd().joinpath('data_small/train/dog/'), <br/>)</span><span id="67ec" class="ot mf it op b gy oy ov l ow ox"># Valid - cat<br/>copy_sample(<br/>    src_folder=pathlib.Path.cwd().joinpath('data/validation/cat/'), <br/>    tgt_folder=pathlib.Path.cwd().joinpath('data_small/validation/cat/'),<br/>    n=100<br/>)</span><span id="fab4" class="ot mf it op b gy oy ov l ow ox"># Valid - dog<br/>copy_sample(<br/>    src_folder=pathlib.Path.cwd().joinpath('data/validation/dog/'), <br/>    tgt_folder=pathlib.Path.cwd().joinpath('data_small/validation/dog/'),<br/>    n=100<br/>)</span></pre><p id="7077" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用以下命令打印每个文件夹中的图像数量:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/375057089506942e2bfd8022e5ba6a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*3xrgbQhbcaUP507fmxFAmw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片5 —每类培训和验证图片的数量(图片由作者提供)</p></figure><p id="7301" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，调用<code class="fe pa pb pc op b">init_data()</code>函数从新源加载图像:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="9cb1" class="ot mf it op b gy ou ov l ow ox">train_data, valid_data = init_data(<br/>    train_dir='data_small/train/', <br/>    valid_dir='data_small/validation/'<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/cb34cf03e72c3fbbd747a1f6df72f4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*88sKM0PVy2N8nPeAdLrXSg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片6-较小子集中的训练和验证图片的数量(图片由作者提供)</p></figure><p id="c17f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总共有1000个训练图像。看看我们是否能从这么小的数据集里得到一个像样的模型，这将会很有趣。我们将保持模型架构不变，但是因为数据集更小，所以要为更多的时期进行训练。此外，由于每个历元的训练时间减少，我们可以进行更长时间的训练:</p><pre class="kj kk kl km gt oo op oq or aw os bi"><span id="56b8" class="ot mf it op b gy ou ov l ow ox">vgg_model = build_transfer_learning_model(<br/>    base_model=VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')<br/>)</span><span id="dba6" class="ot mf it op b gy oy ov l ow ox">vgg_hist = vgg_model.fit(<br/>    train_data,<br/>    validation_data=valid_data,<br/>    epochs=20<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/7aff4a425e771e50127744ae13fda097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6LsMgd607LWnoFFJwxde9Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7 —最近10个时期的训练结果(作者提供的图片)</p></figure><p id="2193" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你看看这个——我们得到了与在20K图像上训练的模型大致相同的验证准确性，这太令人惊讶了。</p><p id="a98d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是迁移学习的真正力量所在。你并不总是能接触到巨大的数据集，所以看到我们能用如此有限的数据建立如此精确的东西是令人惊讶的。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="7b33" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="e7e3" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">总而言之，在构建图像分类模型时，迁移学习应该是您的首选方法。你不需要考虑架构，因为已经有人为你做了。你不需要有一个巨大的数据集，因为有人已经在数百万张图像上训练了一个通用模型。最后，除非数据集高度专门化，否则大多数时候不需要担心性能差。</p><p id="ade8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你唯一需要做的就是选择一个预先训练好的架构。我们今天选择了VGG16，但是我鼓励您尝试ResNet、MobileNet、EfficientNet和其他工具。</p><p id="e87b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是你可以做的另一个<strong class="lb iu">家庭作业</strong>——使用今天训练的两个模型来预测整个测试集。精确度如何比较？请让我知道。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="36c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="on">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="on">中等会员</em> </a> <em class="on">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="nv nw gp gr nx ny"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">通过我的推荐链接加入Medium-Dario rade ci</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="pi l oj ok ol oh om ks ny"/></div></div></a></div></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="0723" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">保持联系</h1><ul class=""><li id="4110" class="nb nc it lb b lc mw lf mx li pj lm pk lq pl lu pm nh ni nj bi translated">注册我的<a class="ae ky" href="https://mailchi.mp/46a3d2989d9b/bdssubscribe" rel="noopener ugc nofollow" target="_blank">简讯</a></li><li id="559a" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu pm nh ni nj bi translated">订阅<a class="ae ky" href="https://www.youtube.com/c/BetterDataScience" rel="noopener ugc nofollow" target="_blank"> YouTube </a></li><li id="5d52" class="nb nc it lb b lc nk lf nl li nm lm nn lq no lu pm nh ni nj bi translated">在<a class="ae ky" href="https://www.linkedin.com/in/darioradecic/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上连接</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="1b62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="on">原载于2022年1月3日</em><a class="ae ky" href="https://betterdatascience.com/tensorflow-transfer-learning/" rel="noopener ugc nofollow" target="_blank"><em class="on">https://betterdatascience.com</em></a><em class="on">。</em></p></div></div>    
</body>
</html>