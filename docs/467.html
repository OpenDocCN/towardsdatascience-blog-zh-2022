<html>
<head>
<title>5 Fundamental Concepts to Understand Big Data Processing with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解Spark大数据处理的5个基本概念</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-fundamental-concepts-to-understand-big-data-processing-with-spark-f2a6aadb1093#2022-01-16">https://towardsdatascience.com/5-fundamental-concepts-to-understand-big-data-processing-with-spark-f2a6aadb1093#2022-01-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="ea76" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">理解Spark大数据处理的5个基本概念</h1></div><div class=""><h2 id="21c3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">#5.懒惰评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7a045b0d9a1e3c0a53d72f5c5005d69e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ptMVo9mZOUAnKpFyoLv3w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SpaceX 在<a class="ae ky" href="https://unsplash.com/s/photos/spark?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的<a class="ae ky" href="https://unsplash.com/@spacex?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="9a2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你们中的许多人可能都经历过计算机在某些任务上表现不佳。它要么不能完成任务，要么永远无法完成。</p><p id="b839" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据处理，尤其是处理大型数据集时，就是这些任务之一。您的计算机可能没有足够的能力或资源来进行大规模数据处理。</p><p id="e365" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种解决方案是通过形成集群(即一组计算机)来组合来自许多计算机的资源。即使您有许多计算机，您也需要一种有组织的方式将任务分成小部分，并在计算机之间分配。这就是Spark所做的。</p><p id="7d55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark是一个框架，它管理和协调跨计算机集群的任务执行。它让您可以分散数据和计算，从而实现显著的性能提升。</p><p id="e6e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark的默认语言是Scala，但是我们可以通过数据科学生态系统中流行的编程语言来使用Spark。</p><p id="7e56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，PySpark是一个Python库，允许使用Python语法运行Spark代码。Spark还通过SparkR和sparklyr库支持R。</p><p id="7831" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将回顾5个概念，它们是理解Spark大数据处理的基础。当您开始使用Spark进行大规模数据处理时，它们也会很有帮助。</p><blockquote class="lv lw lx"><p id="483a" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">如果你想在我发表新文章时收到电子邮件，别忘了订阅。</p></blockquote></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="6c6a" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">1.火花应用</h1><p id="2ab0" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">Spark应用程序由一个驱动程序进程和一组执行器进程组成。这些进程由集群管理器管理。</p><p id="97a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用户通过驱动程序进程与Spark应用程序进行交互。它接受用户输入，并在执行者之间分配工作。假设我们编写一个程序来计算超市产品的平均周销售额。我们不把任务分成块，分别分配给执行者。驱动程序处理在执行器之间分配和调度任务。</p><p id="7156" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">驱动程序进程还通过维护相关信息来跟踪Spark应用程序。</p><p id="95d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">执行者完成司机交给他们的任务。它们还通知驱动程序计算的状态。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="fd54" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">2.火花会议</h1><p id="7397" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">火花应用通过一个叫做<em class="ly"> SparkSession </em>的驱动程序来控制。因此，编写Spark代码的第一步是实例化一个<em class="ly"> SparkSession </em>。</p><p id="9f82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，下面的PySpark代码创建一个<em class="ly"> SparkSession </em>，然后通过这个会话读取一个parquet文件。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="1f0c" class="nl mk it nh b gy nm nn l no np">from pyspark.sql import SparkSession</span><span id="1663" class="nl mk it nh b gy nq nn l no np">spark = SparkSession.builder.getOrCreate()</span><span id="d748" class="nl mk it nh b gy nq nn l no np">df = spark.<!-- -->read.parquet("myfile.parquet")</span></pre></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="3b70" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">3.数据帧和分区</h1><p id="51b3" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated"><em class="ly"> DataFrame </em>基本上就是一个有行有列的表格。定义列及其数据类型的列表称为<em class="ly">模式</em>。</p><p id="2e6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark <em class="ly">数据帧</em>与熊猫或R数据帧非常相似，但有一个显著区别。在Pandas和R中，数据帧存储在一台机器或计算机上(有一些例外)，而Spark数据帧分布在许多计算机上。</p><p id="b9de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark将数据分成更小的块，称为<em class="ly">分区</em>。分区允许每个执行器并行工作，从而极大地提高了性能。</p><p id="cfa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个<em class="ly">分区</em>包含原始<em class="ly">数据帧中的一组行。</em>将数据划分为分区的原因是数据太大，无法在单台机器上运行，或者在单个分区上进行计算需要太多时间。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="618e" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">4.转换和操作</h1><p id="119c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">火花操作可分为两大类，即<em class="ly">转换</em>和<em class="ly">动作</em>。</p><p id="79b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">修改数据帧的指令称为<em class="ly">转换</em>。例如，根据列中的值过滤数据帧就是一种转换。另一个例子是根据列中的不同值对行进行分组。</p><p id="b8ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两种类型的变换是<em class="ly">窄变换</em>和<em class="ly">宽变换</em>。在窄转换中，每个输入分区只贡献给一个输出分区。过滤是窄变换的一个例子。一个分区中的值对其他分区没有任何影响。</p><p id="18c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">宽转换包含宽依赖关系，这意味着一个输入分区可能对几个输出分区有贡献。对行进行分组(即groupBy操作)是广泛转换的一个例子。一个组可能包括来自许多不同输入分区的数据点(即行)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/92bdfe34af00483051f04556d3031a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C0eP5txdAJqRewUSILVV1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="3ed2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们向Spark发出转换指令时，它不会立即转换数据。即使我们给出了一系列转换指令，它们也成为了转换计划的一部分。</p><p id="ed72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们运行一个动作时，转换被执行或计算。动作告诉Spark通过执行转换来计算结果。<code class="fe ns nt nu nh b">Count</code>、<code class="fe ns nt nu nh b">collect</code>和<code class="fe ns nt nu nh b">aggregate</code>是火花动作的一些例子。在控制台中显示数据也是一个操作。</p><p id="14e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看一个例子来更清楚地解释这些术语。假设我们有一个数据框架，其中包含一家连锁超市的产品日销售量。我们需要找到蔬菜类产品的平均月销售额。</p><ul class=""><li id="43dd" class="nv nw it lb b lc ld lf lg li nx lm ny lq nz lu oa ob oc od bi translated">过滤属于蔬菜类别的产品(窄转换)</li><li id="af2d" class="nv nw it lb b lc oe lf of li og lm oh lq oi lu oa ob oc od bi translated">按月列对行进行分组(宽转换)</li><li id="4ae0" class="nv nw it lb b lc oe lf of li og lm oh lq oi lu oa ob oc od bi translated">计算平均值(动作)</li></ul></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><h1 id="22f1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">5.懒惰评估</h1><p id="eb44" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们刚刚提到，Spark跟踪转换，直到一个动作被执行。Spark不是立即修改或转换数据，而是根据给定的转换指令制定转换计划。这个过程叫做<em class="ly">懒评</em>。</p><p id="d713" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我第一次开始使用Spark时，我不知道懒惰评估。我被Spark执行数据转换的速度震惊了。然而，它实际上并没有进行转换，而是将它们保存起来以备后用。当我调用一个action操作时，所有的转换都被执行了，这需要相当长的时间。</p><p id="638f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">惰性评估允许Spark优化整个操作集，这是一个很大的好处。考虑这样一种情况，我们进行了一系列转换，作为最后过滤操作的结果，只有一小部分数据受到影响。</p><p id="441c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于惰性评估，Spark可以通过只转换受影响的行来完成工作。否则，将完成所有转换，然后过滤受影响的行。</p></div><div class="ab cl mc md hx me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="im in io ip iq"><p id="25e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据技术的进步使得收集、传输和存储数据比以往任何时候都更容易。面向数据的应用程序和产品是用非常大量的数据创建的。因此，Spark等用于大规模数据处理的工具开始成为数据科学中的必要工具。</p><p id="e071" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经介绍了5个基本概念，可以帮助您开始学习Spark。如果你是或者想成为一名数据科学家，我强烈建议你熟悉一下Spark。</p><p id="ae9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">别忘了</em> <a class="ae ky" href="https://sonery.medium.com/subscribe" rel="noopener"> <em class="ly">订阅</em> </a> <em class="ly">如果你想在我发表新文章时收到电子邮件。</em></p><p id="e158" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ly">你可以成为</em> <a class="ae ky" href="https://sonery.medium.com/membership" rel="noopener"> <em class="ly">媒介会员</em> </a> <em class="ly">解锁我的全部写作权限，外加其余媒介。如果您使用以下链接，我将收取您的一部分会员费，无需您支付额外费用。</em></p><div class="oj ok gp gr ol om"><a href="https://sonery.medium.com/membership" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">通过我的推荐链接加入Medium-Soner yl DRM</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">sonery.medium.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div><p id="2c15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>