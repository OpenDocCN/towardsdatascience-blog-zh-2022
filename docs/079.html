<html>
<head>
<title>Image Classification with Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于卷积神经网络的图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-classification-with-convolutional-neural-networks-12a7b4fb4c91#2022-01-04">https://towardsdatascience.com/image-classification-with-convolutional-neural-networks-12a7b4fb4c91#2022-01-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="3832" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">基于卷积神经网络的图像分类</h1></div><div class=""><h2 id="6001" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于图像分类的卷积和卷积神经网络综合指南，从Python和TensorFlow的实现到优化和转移学习技术</h2></div><p id="d20e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我之前的文章中，我们学习了神经网络的基础知识</p><div class="le lf gp gr lg lh"><a rel="noopener follow" target="_blank" href="/neural-networks-fundamentals-80aa045504bd"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">神经网络基础</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">神经网络的快速介绍，无监督和监督学习，回归和…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">towardsdatascience.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv lw lh"/></div></div></a></div><p id="2fb9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是时候了解卷积神经网络及其在图像分类中的用途了。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/ea66548b3513a0ccba2275e0c9183696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*whYTToTcXSvV2ZgSkfSAMw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="aa6e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">什么是卷积？</strong></p><p id="7669" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">卷积运算是用具有恒定大小的“窗口”移动图像，并将图像像素与卷积窗口相乘以获得输出图像的过程。让我们看看下面的例子:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mm"><img src="../Images/0ed2730d7de047525a5c411ed33f2284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3VxXXK-jVDZ63M0WJbuQg.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="b26e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到一个9×9的图像和一个3×3的卷积滤波器，其恒定权重为3 0 3 2 0 2 1 0 1，以及卷积运算的计算。尝试使用如下图所示的滤镜浏览图像，并更好地理解如何通过卷积计算输出图像的这些像素。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mn"><img src="../Images/066622eef96745b6db8fe51a7f365a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*urcJp1_GiFItKnPlrtePCQ.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><ul class=""><li id="6d08" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated"><strong class="kk iu"/>、<strong class="kk iu">滤镜</strong>、<strong class="kk iu">内核</strong>、<strong class="kk iu">遮罩</strong>是提及“卷积滤镜”的不同方式，我们也将在整篇文章中使用这些术语。</li></ul><p id="e339" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">填充</strong></p><p id="513d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">填充是在我们的输入图像边界上添加额外像素的过程，主要是为了保持输出图像的大小与输入图像相同。最常见的填充技术是加零(称为<strong class="kk iu"> <em class="mx">零填充</em> </strong>)。</p><p id="06d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">跨步</strong></p><p id="88b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">步幅是我们用卷积窗遍历图像时每次迭代的步长。在下面的例子中，我们实际上看到步长是1，所以我们将窗口移动了1。现在让我们看另一个例子，以便更好地理解水平步幅= 1，垂直步幅= 2:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi my"><img src="../Images/264b2f806c7075ad03db836a9637dd9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8CxI8Lz9FbOQ-cX6MFWftw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><ul class=""><li id="ec55" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">因此，填充尺寸、步幅尺寸、滤波器尺寸和输入尺寸影响输出图像尺寸，并且根据这些不同参数的输出图像尺寸的公式如下:</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mz"><img src="../Images/e1e64246ffb6b3db3e63ae1511f3c5b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMWR-MBFEWCf73u8Dr-cYA.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="ae54" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">到目前为止，我们只研究了应用于输入图像的1个卷积运算，现在让我们来看看什么是卷积神经网络以及我们如何训练它们。</p><p id="168b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">卷积神经网络(CNN) </strong></p><p id="d14a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们将层作为卷积窗口，<strong class="kk iu">其中窗口中的每个像素实际上是一个权重</strong>(而不是我们在之前的<a class="ae na" rel="noopener" target="_blank" href="/neural-networks-fundamentals-80aa045504bd"><strong class="kk iu"/></a>文章中学习的完全连接的神经网络)，它是一个卷积神经网络，我们的目标是训练模型以在最后以最小的成本更新这些权重。因此，与前面的例子相反，我们的卷积滤波器中没有任何常量值，但是<strong class="kk iu">这些是我们的权重，我们应该让模型为它们找到最佳值</strong>。</p><p id="2909" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">换句话说，与<a class="ae na" rel="noopener" target="_blank" href="/image-processing-part-2-1fb84931364a"> <strong class="kk iu">图像处理</strong> </a> <strong class="kk iu"> </strong>相反，在<a class="ae na" rel="noopener" target="_blank" href="/image-processing-part-2-1fb84931364a"><strong class="kk iu">图像处理中，我们将这些卷积运算用于特定的滤波器(在卷积滤波器中具有特殊的和已知的权重)，在卷积神经网络的卷积层中，我们的窗口具有一些随机的、不重要的权重，并且我们在模型训练步骤中更新它们，以获得使我们的损失最小化的最佳权重。(因此它们不是图像处理术语中的常数<strong class="kk iu"/></strong></a></p><p id="3365" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以一个简单的CNN无非是如下一些卷积运算的序列:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/96ce8eb1c382290d1a35c307504a251d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DQQ5YZcd0WenleIz-KR3g.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="6abc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">用CNN进行图像分类</strong></p><p id="2c16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是如何利用CNN实现图像分类呢？</p><p id="52bd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们在之前的<a class="ae na" rel="noopener" target="_blank" href="/neural-networks-fundamentals-80aa045504bd"><strong class="kk iu"/></a>中看到了训练过程如何更新回归或分类模型权重。图像分类的唯一区别是，现在我们处理的是图像，而不是结构化数据，如房价、房间号等。</p><p id="d9ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每个卷积运算都参与<strong class="kk iu">提取图像特征</strong>，如耳朵、脚、狗嘴等。这个特征提取步骤随着更深的卷积层而变得更深，而在第一层，我们只获得图像的一些边缘。</p><p id="2024" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要了解更多关于应用<strong class="kk iu">边缘检测</strong>的不同卷积滤波器的信息，请参考本文<strong class="kk iu"> : </strong></p><div class="le lf gp gr lg lh"><a rel="noopener follow" target="_blank" href="/image-processing-part-2-1fb84931364a"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">图像处理第二部分</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">2.1:非线性空间滤波、最小值、最大值和中值滤波器，从头开始用Python实现2.2:线性…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">towardsdatascience.com</p></div></div><div class="lq l"><div class="nb l ls lt lu lq lv lw lh"/></div></div></a></div><p id="dae8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以卷积层承担了提取重要特征的责任，最后要有一个完整的图像分类模型，我们只需要一些<strong class="kk iu">全连通的输出节点</strong>就可以根据它们的权重决定图像的正确类别！</p><p id="af06" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们假设我们有一个狗和猫类的图像分类问题。在这种情况下，在训练结束时，一些输出节点将表示狗类要素和一些猫类要素。如果通过这些卷积层的输入图像在我们的激活函数结束时给予代表节点的狗类更高的输入，则这些节点的总和将给予狗类输出节点更高的结果。否则，它就是一个cat类输出节点。让我们想象一下这个过程:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nc"><img src="../Images/ee13cd441f3f2d359ee7fd9c28e5a8f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6cLsUVd0LsCFDhZ_0irIuw.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="ab5b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到拼图的所有碎片都聚集在一起<strong class="kk iu"> CNN +全连接神经网络创建了一个图像分类模型</strong>！</p><p id="6fc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在介绍用于图像分类的常见CNN架构之前，让我们先来看一些更复杂、更真实的CNN示例:</p><ul class=""><li id="6c0c" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">当我们谈到CNN层的时候，我们不是说1层只有1个卷积核；实际上，<strong class="kk iu">多个卷积核创建一个卷积层</strong>。因此，我们将所有这些卷积滤波器一个接一个地应用于输入图像，然后进入下一个卷积层。<strong class="kk iu">1卷积层中卷积核的个数决定了3。我们图层的尺寸</strong>就像一个图像的“通道尺寸”。</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nd"><img src="../Images/c43210c688f8fb4de627abb88e6f47f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*415XVWSXWikvHHx23hO-ag.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><ul class=""><li id="031d" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">我们学习了如何在应用卷积运算后计算输出图像大小，现在您应该知道卷积层的<strong class="kk iu">通道大小直接是输出通道大小</strong>，因为我们应用1个卷积运算来获得1个输出图像。<strong class="kk iu">因此，如果CNN层内部有5个卷积核，我们在这一层的末尾获得5个输出核。</strong></li><li id="ee2f" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">如果我们处理RGB图像，我们有3个通道，而灰度图像只有1个通道。在这种情况下，我们将1个卷积核应用3次，每个通道1乘1，以获得输出通道。因此，输出图像的通道大小不会改变，但卷积层的参数总数会改变。1个CNN层的参数总数计算如下:</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/d70a53601a2f42fc1b11c04aa6174caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*WUfee9T1_rEV0q2NavcJ2w.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="2939" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，对于前面的例子，我们可以说n=64 m=64 l=1 k=32。</p><p id="99ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">联营</strong></p><p id="39a9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是在图像分类CNN架构中使用的另一个重要术语。这是一种用来减少CNN模型参数的方法。我相信你已经发现(使用上面提到的公式),我们讨论的大量参数是如何与具有超过5-10个卷积滤波器的几个CNN层相关的。因此，一次一次地减少参数的数量，并从特征图中仅选择<strong class="kk iu">最重要的特征(输出图来自每个卷积层)。正如我们之前所说，更深的卷积层具有更具体的特征)是重要的。共有两种常见的池类型:</strong></p><ul class=""><li id="3137" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">最大池化</li></ul><p id="4a8f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">基本思想是再次使用一个窗口，此时没有任何权重，并且在遍历要素地图时，选择最大像素值作为输出。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/3c34417d42552c82addf13aa11de85d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*-1KacQ_rElMyZa4PExOyhw.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="6307" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用相同的公式来计算我前面提到的卷积运算的最大池的输出映射大小。<strong class="kk iu">重要的一点是，因为目标是减少参数大小，所以给定填充大小= 0，步长大小=池内核的大小是一个合理的</strong>和常见的方法，就像我们在本例中所做的那样。</p><ul class=""><li id="52a6" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated"><strong class="kk iu">平均统筹</strong></li></ul><p id="2d33" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们不是从最大像素计算输出，而是从停留在池内核中的像素的平均值计算输出。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/af57a41272ec610aff1ca89763500575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*xMgL8Onm2Q2RcLemYZTZHg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="bdc4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">常见的卷积神经网络架构</strong></p><p id="8877" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ImageNet大规模视觉识别挑战赛(<strong class="kk iu"> ILSVRC </strong>)多年来一直是一项非常受欢迎的比赛。我们将考察不同年份的一些获胜者。这些是用于图像分类任务的最常见的架构，因为它们在竞赛年与其他模型相比具有更高的性能。</p><p id="b678" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ImageNet是一个数据集，具有针对<strong class="kk iu"> 1000个类别</strong>的<strong class="kk iu"> 1，281，167幅训练图像</strong>、<strong class="kk iu"> 50，000幅验证图像</strong>和<strong class="kk iu"> 100，000幅测试图像</strong>。</p><p id="6038" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mx">验证数据集</em>:除了用于任何模型的训练步骤的训练数据集和在训练步骤完成后用于测试模型以计算模型精度-性能的测试图像之外，它是模型以前没有见过的数据，即在训练阶段不参与反向传播-权重更新阶段，而是用于测试以便真实地跟踪训练阶段的进展。</p><ul class=""><li id="52b7" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">AlexNet (2012年)</li></ul><p id="0c7b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型由8层组成，具有<strong class="kk iu">5-卷积</strong>和<strong class="kk iu"> 3全连接</strong>。</p><p id="4d93" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">针对RGB输入图像实施(3通道)</p><p id="b360" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">包含6000万个参数</p><p id="f18d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ImageNet测试数据集的最终误差为15.3%</p><p id="1625" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> ReLU激活</strong>功能首次用于该型号。除了最后一个全连接层具有<strong class="kk iu"> Softmax激活</strong>功能外，ReLu用作整个模型的激活功能</p><p id="c5fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用比率为0.5的<strong class="kk iu">脱扣</strong>机构。</p><p id="ced6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">动量随机梯度下降</strong>用于动量= 0.9，批量= 128</p><p id="00d2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用标准偏差= 0.01，用<strong class="kk iu">零均值高斯分布</strong>初始化权重</p><p id="b9d9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">偏差初始化为常数值1。</p><p id="50cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">学习率被初始化为0.01，并且“<strong class="kk iu">权重衰减正则化</strong>被应用为0.0005</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nl"><img src="../Images/d4766fd5c6e34320052349b0fe80a520.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ZGSN8CRC-f-qUl3HIZwug.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="9fdf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上图中，我们看到了AlexNet架构，输出特征映射了每一步的大小，当然，我们有1000个完全连接的层节点，因为ImageNet数据集有1000个类。</p><p id="998a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于这种架构，我们还会遇到一些我之前没有提到的术语:</p><p id="d550" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mx">带动量的梯度下降:</em>这是对梯度下降计算的优化，我们将之前梯度下降的导数添加到我们的梯度下降计算中。对于这种架构，我们将这一额外部分乘以动量超参数0.9。</p><p id="7d4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mx">高斯分布的权重初始化:</em>在开始训练模型之前，有不同的方法来初始化我们的权重。例如，将所有权重设为0是一种方法，但却是一种糟糕的方法！取而代之的是，根据高斯分布初始化所有权重是一种常用的方法。我们只需要选择分布的平均值和标准偏差，<strong class="kk iu">我们的权重将在这个分布范围内</strong>。</p><p id="dc80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mx">权重衰减优化</em>:在本文中使用SGD(随机梯度下降)的情况下，这与L2正则化是一样的！</p><ul class=""><li id="21e3" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">VGG16 (2014年)</li></ul><p id="d208" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">VGG架构是一个16层模型，具有13个卷积和3个全连接。</p><p id="ad62" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它有1.38亿个参数</p><p id="6454" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在测试数据集上有7.5%的误差</p><p id="3aa5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">与AlexNet </strong>相反，每个卷积层中的所有内核使用相同的大小。那是3x3内核，步幅= 1，填充= 1。对于跨度= 2的2x2内核的最大池</p><p id="c830" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">类似于AlexNet </strong>，ReLu用于隐藏层，Softmax用于输出层。动量为0.9的SGD，衰减参数为0.00005的权重衰减正则化，初始学习率为0.01，使用高斯分布的权重初始化。</p><p id="5c52" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为AlexNet 的一个<strong class="kk iu">小区别，VGG16架构使用batch size = 256，初始化bias，不是1而是0，输入图像大小为224x224x3。</strong></p><p id="8c38" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有一个更新的版本叫做VGG19，总共有19层。</p><ul class=""><li id="3c3b" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">ResNet (2015年)</li></ul><p id="ced7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该架构的名称来自<strong class="kk iu">残差块</strong>，其中残差块是“<strong class="kk iu">相同输入</strong>”和“<strong class="kk iu">卷积和激活函数</strong>后的输出”的组合。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nm"><img src="../Images/2d13d1a110cdfcd16c38a979ed697cd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ykZ3hzKbixWbEFNaYY3tg.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="8dab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ResNet的不同版本具有不同的层数，如Resnet18、Resnet34、Resnet50、Resnet101和Resnet152。在下图中，我们看到左侧是一个“正常”的18层架构，右侧是残余块版本。红线表示相同的块和主块具有相同的尺寸，因此它们可以直接组合，蓝线表示尺寸不同，因此相同的层应该添加零填充，或者在使用兼容的填充(步长大小)用1x1卷积内核调整大小之后添加。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/122c698bd67f54bfefb6eefe67769f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*I6Fom21eEyNbannFE_Ds9g.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="8c14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ResNet152对于测试数据集实现了%3.57的误差，并且它具有58M的参数。当我们将参数大小和小误差与以前的架构进行比较时，这已经很不错了，对吗？</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="0fc0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了可训练参数的数量，每秒FLOPS ( <strong class="kk iu">浮点运算</strong><strong class="kk iu"/>)是一个重要因素。让我们比较一下到目前为止我们检查过的模型:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/528f23e9f2fb2aa5e7f67b610c941d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*iWOjpqSk5roP29V1N5OJ5A.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="2fc3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想考察更多类型的卷积神经网络，我建议你搜索<strong class="kk iu"> Inception </strong>、<strong class="kk iu"> SeNet </strong> (2017年ILSVRC获奖者)、以及<strong class="kk iu"> MobileNet </strong>。</p><p id="178b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在该是我们用VGG16配合Python和Tensorflow应用图像分类的时候了！</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><h2 id="7dec" class="nw nx it bd ny nz oa dn ob oc od dp oe kr of og oh kv oi oj ok kz ol om on oo bi translated">VGG建筑从无到有</h2><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="e071" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是用Python和Tensorflow实现的VGG16。让我们稍微检查一下代码</p><ul class=""><li id="4079" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">首先，我们检查我们的TensorFlow-Cuda-Cudnn安装是否正常，以及TensorFlow是否能找到我们的<strong class="kk iu"> GPU </strong>。因为如果不是这样，这意味着有一个<strong class="kk iu">包冲突</strong>或一个我们应该解决的错误<strong class="kk iu">，因为用CPU进行模型训练太慢了，几乎不可能</strong>。</li><li id="a4ed" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">然后，我们使用用于卷积层的<strong class="kk iu"> Conv2D </strong>函数、用于最大池层的<strong class="kk iu"> MaxPool2D </strong>函数、<strong class="kk iu"> Flatten </strong>函数来创建VGG16模型，以使CNN输出能够传递到全连接层的平坦输入、<strong class="kk iu"> Dense </strong>函数用于全连接层、<strong class="kk iu"> Dropout </strong>函数用于在最后的全连接层之间添加Dropout优化。你可以看到，我们应该添加<strong class="kk iu">权重初始化，偏差初始化，l2正则化</strong> 1乘1到层，同时使用相关的层函数。注意，正态分布是高斯分布的同义词，所以当看到weight _ initializer = TF . keras . initializer . randomnormal(mean = 0.0，stddev=0.01，seed=None)时，不要让您的思维混乱</li><li id="00b9" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">我将用2个类来测试这个模型，而不是用1000个类来处理非常庞大的ImageNet数据集，因此我将输出层从1000个节点更改为<strong class="kk iu"> 2个节点</strong></li><li id="d628" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">使用<strong class="kk iu"> ImageGenerator </strong>函数和<strong class="kk iu"> flow_from_directory() </strong>，我们将数据集准备为能够与TensorFlow模型一起工作的向量。我们在这里也给出了批量大小。(由于我的计算机内存不足，我可以给出批量大小16，而不是论文中提到的256。)<strong class="kk iu"> shuffle </strong>参数意味着数据集将在每个历元之前被打乱，以使批次不那么恒定</li><li id="4709" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated"><strong class="kk iu"> model.compile() </strong>函数是训练我们的模型之前的最后一部分。我们确定使用哪个优化器(带动量的SGD)，哪个损失函数(二进制交叉熵，因为在我们的例子中我们有2个类)，以及使用哪个度量来计算训练期间的性能(二进制准确度)。</li><li id="d9f0" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">我使用<strong class="kk iu"> model.fit() </strong>函数来训练我们的模型。我添加了一些选项，比如“<strong class="kk iu">提前停止</strong>”和“<strong class="kk iu">模型检查点</strong>”回调。如果验证损失在10个时期内没有增加，则第一个停止训练，并且如果验证损失比前一个时期好，则模型检查点不仅在结束时而且在训练期间保存我们的模型。</li><li id="3711" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated"><strong class="kk iu">CustomLearningRateScheduler</strong>是我手动实现的学习率调度器，用于应用“如果验证精度停止提高，我们通过除以10来更新学习率”</li><li id="1f49" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">在培训结束时，我将验证和培训数据集的准确性和损失图表可视化。</li><li id="fd7e" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">最后一部分是用测试数据集测试模型。我们检查是否有名为“trained_model.h5”的已训练模型，如果没有，我们训练一个模型，如果有，我们使用这个模型来测试性能</li></ul><p id="355b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想解释一下我在解释我的代码时使用的一些附加术语:</p><ul class=""><li id="f952" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated"><em class="mx">验证—训练准确性</em>:验证准确性是一个衡量我们的模型在验证数据集上表现如何的指标。它只是检查在验证数据集中有多少图像预测为真。我们也对训练数据集进行同样的检查。但这只是针对我们的监控模型，只有列车损失用于梯度下降计算</li><li id="9d2e" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated"><em class="mx">迭代—历元</em> : 1次迭代是对一批中的所有图像进行建模的过程。历元是指为我们训练数据集中的所有图像提供模型的过程。例如，如果我们有100个图像，并且我们的批量大小= 10，则1个时期将有10次迭代。</li><li id="d96e" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated"><em class="mx">拉平:</em>这只不过是重塑我们的CNN输出，使其具有1D输入，这是从卷积层传递到全连接层的唯一方式。</li></ul><p id="b0e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们检查结果</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi or"><img src="../Images/302b3e0b7b118449c1be6689b7a516bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mn5Vsk7Xrhz476J9JHfkGg.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="fadc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">即使我们通过监控验证精度来改变学习率，结果也不好，验证精度也没有提高。但是为什么它不像VGG16论文中那样直接工作呢？</p><ol class=""><li id="1c69" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld os mu mv mw bi translated">在原始论文中，我们讨论了374个时期的1000个输出类和1500000个图像。不幸的是，我使用这个数据集并为1000个类训练一个模型需要几天时间，所以正如我之前所说，我为2个类使用了一个数据集，并将输出层更改为具有2个输出节点。</li><li id="3560" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld os mu mv mw bi translated">模型架构和数据集都需要不同的优化，因此一个运行良好的模型可能不适用于另一个数据集。</li><li id="198e" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld os mu mv mw bi translated"><strong class="kk iu">微调</strong>超参数以改进您的模型与了解如何首先构建模型一样重要。您可能已经注意到我们需要微调的超参数数量</li></ol><ul class=""><li id="f68d" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">权重和偏差初始化</li><li id="ed50" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">损失函数选择</li><li id="98ce" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">初始学习率选择</li><li id="5297" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">优化器选择(梯度下降法)</li><li id="579b" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">是否使用辍学</li><li id="d4d4" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">数据扩充(如果您没有足够的图像，或者图像过于相似，您希望获得相同图像的不同版本)</li></ul><p id="9389" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">诸如此类…</p><p id="a47f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是在你对如何优化如此多的变量感到悲观之前，我想提两个要点。</p><ol class=""><li id="085f" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld os mu mv mw bi translated"><strong class="kk iu">转移学习</strong></li></ol><p id="2187" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个非常重要的方法，我们使用一个<strong class="kk iu">预训练模型</strong>用我们自己的数据集来训练它。在我们的例子中，我们不会只使用VGG16架构，而是使用已经用VGG16架构和ImageNet数据集训练过的模型，我们将使用比ImageNet小得多的数据集重新训练它。这种方法为我们提供了并非未知的开始——一些随机的权重但是一些已经意味着一些特征。我们的数据集可能包含不同的对象，但不同对象之间有基本的共同特征，如边缘、圆形，为什么不使用它们而不是从头开始呢？我们将看到这种方法如何减少耗时并提高我们的精度性能。</p><p id="630f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.当我查看我们的输出时，我看到问题是<strong class="kk iu">不是因为模型停止学习，而是因为它没有开始学习</strong>！精度从0.5开始，永远不变！那个特定的结果给了我们一个非常明确的信息:我们应该<strong class="kk iu">降低学习率</strong>让模型开始学习。请记住，学习率是学习的步长，我们的权重会受到每次迭代的梯度下降计算的影响。如果这个比率太大，步长太大，以至于我们不能控制权重更新，所以模型不能学习任何东西，它只会变得混乱。</p><p id="21e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下代码仅包括迁移学习的更改，其中我采用了具有预训练权重Tensorflow内置模型和较低学习率(0.001)的模型</p><figure class="ly lz ma mb gt mc"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="9329" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看结果:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi or"><img src="../Images/0d636183407cb7df6a4f1145dd225a32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gDyo-5xvaxbFxHzFVKi4gQ.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi ot"><img src="../Images/ba9ade726db45ec530ec523bb760565d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dIyltncBA1eCzmQ1W4NXlQ.png"/></div></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="e800" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">性能有了很大的提高，对吗？！我们看到，验证精度不再停滞不前，并增加到0.97，而训练精度达到1.00。测试准确度的最终检查:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/984fba53e95bc7f60dfb7d90a5df9afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*9CeHZ9PCRXabEW6rrulRcg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="115b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一切似乎都很好！</p><p id="c538" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我想和你们分享我做的一些实验和它们的结果:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/197990effd060cf8ec51f1a07e8b0948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*v-9YfmwqD8firHu9q624tg.png"/></div><p class="mi mj gj gh gi mk ml bd b be z dk translated">作者图片</p></figure><p id="12de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以做如下分析:</p><ul class=""><li id="0b1a" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated">如果我们的学习速度不一致，迁移学习本身仍然是不够的。</li><li id="6850" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">如果我们将base _ model _ trainable变量设置为False，这意味着我们不训练我们采用的模型，我们只训练我们添加的最后一个完全连接的层。(VGG有1000个输出，所以我使用include_top = False上传了没有最后密集层的模型，我在这个预训练模型的末尾添加了一个密集层，如代码中所示)如果我们不更新这些权重，我们会得到比base _ model _ trainable = True选项稍差的结果。从4点停止训练开始就更快了。虽然是时代。</li><li id="6027" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">只是为了看看，我改变了vgg_from_scratch实现的学习速率，但是验证acc仍然停留在0.5，所以仅仅学习速率优化本身也是不够的。(至少如果你没有几天的时间在微调之后从头训练一个模型。)</li></ul><p id="ef60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以通过这个<a class="ae na" href="https://drive.google.com/drive/folders/1vt8HiybDroEMCvpdGQJx2T50Co4nZNYe?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">链接</strong> </a>到达我使用的数据集，请不要忘记把它和你的代码放在同一个文件夹里，如下所示。当然，h和日志文件将在培训完成后提供！🌼):</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="2ae7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我用Python=3.7，Tensorflow=2.2.0，Cuda=10.1，Cudnn=7.6.5的Anaconda，用GPU来训练和测试我的模型。如果您不熟悉这些术语，这里有一个快速教程:</p><ul class=""><li id="6ed4" class="mo mp it kk b kl km ko kp kr mq kv mr kz ms ld mt mu mv mw bi translated"><strong class="kk iu">从<a class="ae na" href="https://www.anaconda.com/products/individual" rel="noopener ugc nofollow" target="_blank">https://www.anaconda.com/products/individual</a>下载Anaconda </strong>(请为您的电脑选择合适的操作系统)</li><li id="db12" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">打开Anaconda终端，使用<strong class="kk iu">conda create-n im _ class python = 3.7 Anaconda</strong>命令创建一个环境。环境术语可能是Anaconda最重要的属性，它允许您为不同的项目单独工作。您可以将任何包添加到您的环境中，如果您需要另一个包的另一个版本，您可以简单地创建另一个环境以避免您的另一个项目崩溃，等等。</li><li id="372b" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">使用<strong class="kk iu"> conda activate im_class </strong>命令进入到您的环境中添加更多的包(如果您忘记了这一步，您基本上不会在您的环境中而是在所有的anaconda空间中进行更改)</li><li id="0897" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">使用<strong class="kk iu"> pip安装具有GPU能力的tensorflow-gpu==2.2.0 </strong></li><li id="ab64" class="mo mp it kk b kl ne ko nf kr ng kv nh kz ni ld mt mu mv mw bi translated">使用<strong class="kk iu">conda install CUDA toolkit = 10.1</strong>命令安装CUDA和Cudnn</li></ul><p id="a83b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在您已经准备好测试上面的代码了！</p><p id="07e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，包版本之间的<strong class="kk iu">冲突是一个很大的问题</strong>，请只使用这些命令和上面提到的版本。这将帮助您在构建环境时花费更少的时间。</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="af72" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">恭喜你。您已经完成了卷积神经网络图像分类教程。您可以尝试从头开始构建任何模型(甚至可能是您自己的模型👀)，对其进行微调，针对不同架构应用迁移学习等等。现在轮到你自己动手做一些实验了！</p><p id="dd58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一篇文章再见，我们将讨论✋ ✋物体识别的神经网络架构</p><div class="le lf gp gr lg lh"><a rel="noopener follow" target="_blank" href="/object-detection-with-convolutional-neural-networks-c9d729eedc18"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd iu gy z fp lm fr fs ln fu fw is bi translated">基于卷积神经网络的目标检测</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">多级(RCNN，快速RCNN，更快RCNN)和单级(SSD，YOLO)结构的对象检测和他们的…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">towardsdatascience.com</p></div></div><div class="lq l"><div class="ow l ls lt lu lq lv lw lh"/></div></div></a></div></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="e6f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">AlexNet论文:<a class="ae na" href="https://arxiv.org/ftp/arxiv/papers/1803/1803.01164.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/ftp/arxiv/papers/1803/1803.01164.pdf</a></p><p id="17bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">VGG16论文:【https://arxiv.org/pdf/1409.1556.pdf T2】</p><p id="73e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ResNet论文:【https://arxiv.org/pdf/1512.03385.pdf T4】</p><p id="6c14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ImageNet官网，数据集和挑战:<a class="ae na" href="https://www.image-net.org/download.php" rel="noopener ugc nofollow" target="_blank">https://www.image-net.org/download.php</a></p></div></div>    
</body>
</html>