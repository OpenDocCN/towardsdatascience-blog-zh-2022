# SourceCodeAI 固有的训练-推理不匹配

> 原文：<https://towardsdatascience.com/sourcecodeai-how-to-handle-train-inference-mismatch-2914be981a04>

![](img/762b94271fef89b921e0da821d82f417.png)

来自 [Pexels](https://www.pexels.com/photo/blue-toy-car-near-a-blue-car-7877759/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) 的 [Alex Dumitru](https://www.pexels.com/@alex-dumitru-3480544?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels) 的照片

S 源代码 AI 有许多独特的特性，使其区别于更一般的 NLP 应用程序(比如在将输入馈送给模型之前[大量处理输入的常见做法)。它的一个主要挑战是，虽然生成源代码训练数据集似乎很容易(](/sourcecodeai-deep-learning-for-source-code-why-and-how-50eba7ff0329)[“只需抓取 Github”](/how-to-generate-code-dataset-for-machine-learning-applications-fbc1b888cc84))，但现实中包括许多要避免的隐藏陷阱，其中一个事实是，这些高度可用的源(如 [Github](https://github.com/) 、 [Bitbucket](https://bitbucket.org/) 或 [Stackoverflow](https://stackoverflow.com/) )通常不同于推断数据(生产阶段)，这可能会影响预计的模型性能。更多关于这种现象以及如何避免的信息在前面。

# **所见并非所得**

机器学习应用的第一个要素是工作数据集。对于源代码应用程序，这样的数据集可以使用公共源代码托管服务(如 Github)轻松构建。让我们假设，例如，我们想开发一个应用程序，它将找到无意中留在源代码片段上的 [PII](https://en.wikipedia.org/wiki/Personal_data) 。为了生成一个训练数据集，我们抓取 Github，主动搜索相关的术语(如“信用卡号= .”，以确保我们会有足够多的正面例子)。最后，我们使用该数据集训练了一个模型，结果发现我们的内部存储库的性能显著下降。哪里出了问题？更深入的观察会发现，我们用于训练-测试-验证的存储库与我们内部的存储库有很大的不同。例如，Github 存储库可以由一个组织或一个用户拥有，并且可以有公共或私有范围(只对帐户成员可见)。从这些人口特征来看，私人回购和公共回购之间存在着内在的紧张关系；虽然公共代码是容易获得的资源，但我们训练的人工智能应用程序的真正目标通常是内部代码，可以合理地假设这些代码看起来会有所不同；以您的组织内部代码片段为例，将其与 Github 随机代码片段进行比较。例如，考虑像文档级别和最佳实践比率这样的特性。遇到一个[整体](https://en.wikipedia.org/wiki/Monolithic_application)、[环境变量](https://en.wikipedia.org/wiki/Environment_variable)或者一个好的 API [封装](https://en.wikipedia.org/wiki/Encapsulation_(computer_programming)#:~:text=In%20object%2Doriented%20programming%20(OOP,some%20of%20an%20object's%20components.)结构的可能性有多大？。在随机的 Github 存储库中，在数据库相关的片段中面临 AWS 集成的可能性有多大？。考虑到 Github 的[许多可能的子群体](/source-code-datasets-deep-dive-into-github-characteristics-a26c622e0794)，事情变得更加复杂——尽管我们假设一个公共的、公司所有的库是 SDK、开源的或者一个通用的例子(否则，为什么要公开它？)和一个公共的、私有的、POC 或一般项目的存储库(否则，为什么不把它放在公司的存储库上)，**事实是 Github 拥有这一切**，因为快速的 Github 搜索可以显示私有的存储库，这些存储库看起来是公司所有的，反之亦然。这种现象的主要问题是分布差异；在公共 Github 仓库中找到 PII(以我们的例子为例)的可能性有多大，在公司内部仓库中又有多大呢？为了更好地理解这种差异如何影响生成的模型的性能，让我们来看一个系统化的分析，该分析是为另一个源代码 AI 用例[代码自动完成](https://code.visualstudio.com/docs/editor/intellisense)评估这种差异的重要性而做的。

# **训练推理群体不匹配如何影响自动完成应用**

代码自动完成是源代码人工智能世界中的一个时髦话题。虽然传统上它几乎是每个 [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment) 的重要组成部分，但最近像 [Github Copilot](https://copilot.github.com/) 和 [Tabnine](https://www.tabnine.com/) 这样的解决方案开始提出一种基于人工智能的竞争解决方案。 [Hellendoorn 等人](https://ieeexplore.ieee.org/abstract/document/8812116) (2019)强调了这种开发的一个固有问题——自动完成模型通常在合成的数据集上训练，被要求填充随机移除的标记。这种方法的两个主要问题是:第一，提交的代码通常与编写代码时的样子不同(比如有部分的，甚至可能没有工作的上下文与准备提交的上下文)，第二，在现实中，不是所有的令牌都有相同的可能性被应用程序用户要求自动完成。从模型的角度来看，一些重复的、短的、容易预测的记号比那些更长的、更罕见的记号更有利于学习。但实际上，我们可以假设较长且罕见的标记与自动完成更相关。不足为奇的是，该研究发现，与相关论文中提到的情况相比，现实中的性能有显著下降。有趣的是，许多推理时间完成都在项目 API 中，根据定义，对于在一般群体上训练的模型来说是不可见的(这可以使用每个给定群体的“调整”步骤来解决，类似于迁移学习的 [ULMFit](https://arxiv.org/pdf/1801.06146.pdf) 实践)。这些发现让我们怀疑离线数据在现实世界中预测这些模型准确性的可靠性，这将我们带到了一个我们无法真正信任离线指标的场景。

# **更多相似的训练群体如何提高自动完成应用程序的推断能力**

既然我们知道了训练推理不匹配可能会影响自动完成应用程序的性能，那么对于这样的用例，是否有可能获得好的推理结果呢？。根据海伦多恩的发现，脸书( [Gareth at el](https://arxiv.org/pdf/2011.04542.pdf) ，2020)研究了这个问题，发现在真实的自动完成示例上训练这样的模型显著改善了它们的结果。有趣的是，他们不仅发现了性能下降(对于合成与真实示例模型)，还发现了使用下降；一项内部 A-B 测试实验显示，根据真实数据训练的模型最终获得了更高的使用率。此外，值得注意的是，这种下降甚至出现在 GPT-2 等最先进的模型上(有趣的是，BPE 标记化的性能下降最小，可能是因为具有最低水平的词汇外标记，他们提到这显然符合 [Karampatsis el al](https://arxiv.org/pdf/1903.05734.pdf) 的发现，即*的“当开发人员活动数据集不可用于模型训练时，子标记编码可能特别有用”*)。不足为奇的是，分析显示，被接受的自动完成标记平均比普通的提交标记更长(更难记住)。总结这些论文结果，我们应该找到一种方法来确保我们的训练数据集与推理数据集高度相似(或者至少足够接近推理数据通过模型视角看起来的样子)。

# **使训练数据集更类似于推理**

虽然我们希望我们的训练数据集尽可能与推理阶段相似，但对许多人来说，这并不是一个可行的要求。以我们开始的用例为例；我们应该从哪里获得包含 PII 的真实公司库呢？(假设这些片段非常关键)。虽然大公司理论上可以利用他们的内部代码库来满足这种需求(有过度适应他们的内部代码实践和样式的风险)，但中小型公司没有这样的奢侈。一个更现实的评估将揭示出大多数公司**必须**依赖像 Github 这样的公共资源来生成他们的数据集。但是由于许多 Github 子群体可能是不相关的(例如，私有 POC 可能看起来与大公司的内部代码不同)，我们应该找到一种方法来定位其中更相关的子群体。它需要对问题域进行更好的分析——我们试图解决什么？一个模型会关注哪些数据关键因素？我们如何预测这些因素来看待内部存储库？。一旦回答了这些问题，我们就可以开始验证我们对内部存储库和一般 Github 存储库的假设，以更好地确定我们需要的群体类型。然后，我们可以以更直接的方式接近 Github，积极地瞄准我们需要的子人群。

# **巧妙地瞄准 Github**

现在我们对推断阶段的数据特征有了更好的了解，我们可以开始在 Github 中搜索相关的片段。重要的是要记住，一个现实的数据集将包括具有不同程度的标签相关性的不同子群体；一些可能具有高的[假阳性率](https://en.wikipedia.org/wiki/False_positive_rate)，而另一些可能完全是真阳性。对于我们的例子(寻找 PII ),将世界分成三个主要部分是有意义的

*   **高标准；包含 PII 的可能性几乎为零的回购协议。相关的例子可以是文档或大公司(如 S & P top 50)的存储库。作为例子，查看[脸书(公共)存储库](https://github.com/orgs/facebook/repositories)，我们可以假设找到 PII 的可能性极低。**
*   **Med 标准；**可能包含 PII 的回购协议。相关的例子可以是小规模的开放源码或小规模的组织库(在那里更容易出错)。两者都可以通过查看 Github accounts 元字段来定位，比如提交者数量或一般存储库数量。
*   **标准低；**很可能包含 PII 的回购协议。相关的例子可以是私人用户的(公共)存储库，其中包括相关的术语(如“信用卡=”。可以假设找到 PII 的可能性更高)。

好消息是，所有提到的例子都可以使用 [Github 搜索 API](https://github.com/search/advanced?q=pii&type=Repositories)作为目标，使我们能够积极地(综合地)生成一个与我们的目标(推断，私人)群体更相似的群体。在推理阶段获得更好的性能。

# **了解你的数据特征**

既然我们设法生成了一个像人口这样的推论，那么验证它是否真正符合我们的需要就很重要了。主要的挑战将是如何决定我们合成的数据集中每个亚群的比率。通常，可能需要几次迭代来生成一个数据集，其特征与计划推理阶段的特征足够相似。同时，解决方案是持续监控每个子群体的性能(每个生成的数据集子群体和我们的内部存储库中)。确保预测的行为确实成立(就像在我们的例子中，高标准亚人群不应该包括几乎任何 PII，否则目标机制就有问题)。这就是为什么从你的用户那里收集反馈也很重要，以验证重要的子群体没有被遗漏。不断用新的假阳性例子重新训练。致力于生成一个完全优化的数据集，能够击败任何基于数据的模型。