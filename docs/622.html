<html>
<head>
<title>Building Custom Image Datasets in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中构建自定义影像数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-custom-image-datasets-in-pytorch-15ba855b47cb#2022-01-21">https://towardsdatascience.com/building-custom-image-datasets-in-pytorch-15ba855b47cb#2022-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="0c49" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">在PyTorch中构建自定义影像数据集</h1></div><div class=""><h2 id="0132" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">带代码的教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aeaf47a4abbffa07245082619f95ba17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vf8-rFETpCv6EBiHVruHcw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。包括来自维基百科(知识共享许可)的<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Two-layer_feedforward_artificial_neural_network.png" rel="noopener ugc nofollow" target="_blank">神经网络可视化。</a></p></figure><p id="7963" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，您将学习如何使用PyTorch的内置图像数据集，以及如何使用您想要的任何图像构建您自己的自定义图像数据集。虽然本教程的重点是图像数据，但PyTorch中可定制数据集的关键概念适用于任何类型的数据，包括文本和结构化表格数据。</p><p id="02c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程基于我的公开资源库<a class="ae ky" href="https://github.com/rachellea/pytorch-computer-vision" rel="noopener ugc nofollow" target="_blank">https://github.com/rachellea/pytorch-computer-vision</a>，其中包含了使用定制PyTorch数据集的代码。它还包括训练和评估定制神经网络的代码，在<a class="ae ky" href="https://glassboxmedicine.com/2021/02/06/designing-custom-2d-and-3d-cnns-in-pytorch-tutorial-with-code/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>中有概述。</p><p id="0afd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">学完本教程后，您应该能够:</p><ul class=""><li id="0c39" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">下载并使用torchvision.datasets (MNIST、CIFAR、ImageNet等)的公共计算机视觉数据集。);</li><li id="7f20" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用图像数据标准化和数据扩充；</li><li id="bc0c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">通过子类化torch.utils.data.Dataset，从任意图像集合(或非图像训练示例)中创建您自己的数据集；</li><li id="4ec9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用num_workers并行加载数据。</li></ul><h1 id="b7b6" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">什么是数据集？</strong></h1><p id="51a5" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">数据集由带标签的示例组成。对于影像数据集，这意味着每个影像都与一个标签相关联。标签可以是:</p><ul class=""><li id="569e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">定义类的向量，如“cat”=[0，1，0]代表[dog，cat，bus]</li><li id="80a5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">定义多个类别的向量，如“猫和狗”= [1，1，0]表示[狗，猫，公共汽车]</li><li id="5fcd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">定义分割图的矩阵，其中矩阵的每个元素对应于图像的单个像素，并指定该像素属于哪一类，例如，“0”代表狗的一部分，“1”代表猫，“2”代表公共汽车，“3”代表椅子，等等。</li></ul><p id="1e8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于分类任务的更多信息，请看<a class="ae ky" href="https://glassboxmedicine.com/2019/05/26/classification-sigmoid-vs-softmax/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。有关分段任务的更多信息，请参见<a class="ae ky" href="https://glassboxmedicine.com/2020/01/21/segmentation-u-net-mask-r-cnn-and-medical-applications/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="0284" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">下载内置PyTorch图像数据集</strong></h1><p id="b2ed" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在构建自定义数据集之前，了解内置PyTorch图像数据集是很有用的。PyTorch通过torchvision提供了许多内置/预先准备/预先烘焙的图像数据集，包括:</p><ul class=""><li id="b528" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">MNIST，时尚MNIST，KMNIST，EMNIST，QMNIST</li><li id="ff73" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">COCO字幕，COCO检测；</li><li id="0536" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">LSUN、ImageNet、CIFAR、STL10、SVHN、PhotoTour、SBU、Flickr、VOC、Cityscapes、SBD、USPS、Kinetics-400、HMDB51、UCF101和CelebA。</li></ul><p id="cf36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导入torchvision后，只需一行代码就可以下载所提供的数据集。下面是一个下载MNIST数据集的例子，该数据集由60，000个训练和10，000个手写数字测试图像组成。每个图像都是灰度和28 x 28像素:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="2efa" class="nl mk it nh b gy nm nn l no np">import torchvision <br/>mnist = torchvision.datasets.MNIST('path/to/mnist_root/',download=True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/f7dec0393f9eb2890107035f81968398.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/0*OTPYHR-i8xoEGSfM"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从MNIST数据集采样的图像蒙太奇。图片来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank">维基百科</a>，CC by SA 4.0</p></figure><p id="e516" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的代码片段中，您可以将“path/to/mnist_root/”替换为保存mnist图像的目录的绝对路径。</p><p id="f743" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何下载CIFAR-10数据集的示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bd95" class="nl mk it nh b gy nm nn l no np">cifar10 = torchvision.datasets.CIFAR10('path/to/cifar10_root/',download=True)</span></pre><p id="1397" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CIFAR-10包括50，000个训练图像和10，000个测试图像。它们都是自然的彩色图像，大小为32 x 32像素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/18a6a3ff1593a45276e5a0542ffbfa41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*R2U1FNeOK1DaoZvfcPoiQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CIFAR-10示例图像。图片来源:<a class="ae ky" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR网站</a></p></figure><p id="693b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以指定下载数据集的特定子集(例如，训练、val或测试)。语法很简单，并且根据您使用的数据集的不同而略有不同。在torchvision datasets页面上，为每个数据集分别记录了指定下载数据集特定子集的所有必要参数<a class="ae ky" href="https://pytorch.org/vision/stable/datasets.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="3f51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个例子，为了指定MNIST的训练或测试集，提供了一个称为“train”的自变量，它可以被设置为真或假:</p><p id="2e59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">若要指定MNIST的训练集，请设置train=True。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="767b" class="nl mk it nh b gy nm nn l no np">mnist_train = torchvision.datasets.MNIST('path/to/mnist_root/', train=True)</span></pre><p id="81df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要指定MNIST的测试集，请设置train=False。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="be29" class="nl mk it nh b gy nm nn l no np">mnist_test = torchvision.datasets.MNIST('path/to/mnist_root/', train=False)</span></pre><p id="f65d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了指定VOC 2012分割数据集的训练集或val集，提供了一个名为“image_set”的参数，它可以设置为“train”或“val”:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8718" class="nl mk it nh b gy nm nn l no np">vocseg_train = torchvision.datasets.VOCSegmentation('path/to/voc_root/', year='2012',image_set='train') </span><span id="14cd" class="nl mk it nh b gy ns nn l no np">vocseg_val = torchvision.datasets.VOCSegmentation('path/to/voc_root/',year='2012',image_set='val')</span></pre><h2 id="1820" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">避免过度下载</strong></h2><p id="529d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">对于一些内置的PyTorch数据集，初始下载可能需要很长时间，这取决于数据集的大小和您的互联网速度。幸运的是，如果您已经下载了一次数据集，那么只要您指定了最初下载数据集的目录，就不需要在该计算机上再次下载它。例如，如果您已经将MNIST下载到“path/to/mnist_root/”目录，那么只要您提供的路径是“path/to/mnist_root/”，您就可以访问数据集，而无需再次下载。您还可以通过设置download=False来明确指定不要再次下载数据集，这意味着如果由于某种原因您提供的路径不正确，您将会得到一个错误。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ad86" class="nl mk it nh b gy nm nn l no np">#The first time we use this training set, we download it to a particular location <br/>mnist_train = torchvision.datasets.MNIST('path/to/mnist_root/', train=True) </span><span id="7a77" class="nl mk it nh b gy ns nn l no np">#The second time we use this training set, we don't need to download it and we can just load it from the location we specified before: <br/>mnist_train = torchvision.datasets.MNIST('path/to/mnist_root/', train=True, download=False)</span></pre><h1 id="3e51" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">通过DataLoader类</strong>使用内置PyTorch图像数据集 <strong class="ak"/></h1><p id="bfb5" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了实际使用一个数据集，我们需要能够从该数据集中挑选出示例，并创建它们的批处理以提供给我们的模型。PyTorch数据加载器接收数据集并对其进行批处理。DataLoader负责批处理，这很好，因为这意味着我们不需要编写任何繁琐的代码来选择数据集的随机子集。</p><p id="c3ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何使用提供的data loader类为MNIST创建训练数据加载器的示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8a8c" class="nl mk it nh b gy nm nn l no np">import torch <br/>import torchvision </span><span id="1948" class="nl mk it nh b gy ns nn l no np">mnist_train = torchvision.datasets.MNIST('path/to/mnist_root/',train=True) </span><span id="2ee3" class="nl mk it nh b gy ns nn l no np">train_data_loader = torch.utils.data.DataLoader(mnist_train, batch_size=32, shuffle=True, num_workers=16) </span><span id="cf53" class="nl mk it nh b gy ns nn l no np">for batch_idx, batch in enumerate(train_data_loader): <br/>    #inside this loop we can do stuff with a batch, <br/>     like use it to train a model</span></pre><p id="baa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何为MNIST创建测试数据加载器的示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7db3" class="nl mk it nh b gy nm nn l no np">mnist_test = torchvision.datasets.MNIST('path/to/mnist_root/',train=False) </span><span id="3142" class="nl mk it nh b gy ns nn l no np">test_data_loader = torch.utils.data.DataLoader(mnist_test, <br/>                                               batch_size=32, <br/>                                               shuffle=False, <br/>                                               num_workers=16) </span><span id="7aff" class="nl mk it nh b gy ns nn l no np">for batch_idx, batch in enumerate(test_data_loader): <br/>    #do stuff</span></pre><h1 id="e528" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">为神经网络模型归一化数据</strong></h1><p id="2855" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在向神经网络提供图像数据之前，必须对图像进行归一化，以使输入数据在数值上大致在[0，1]或[-1，1]的范围内。当训练神经网络的数据量大约在这个范围内时，神经网络具有更稳定的训练。对于原始RGB像素值在0到255范围内的图像，成功训练神经网络模型的可能性极小。</p><p id="58f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch为规范化数据提供了多种选择。一个选项是torch vision . transforms . normalize:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi gj"><img src="../Images/1d9c39fbd77c59b4fd2600367e3a568d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gd6AuyRyjzKeb4M0oRG3LA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"> torchvision.transforms文档</a></p></figure><p id="cc7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以看到，上面的Normalize函数需要一个“均值”输入和一个“标准差”输入。“平均值”应该是训练集中每个颜色通道的原始像素的平均值。“std”应该是训练集中每个颜色通道的原始像素的标准偏差。如果您有一个大的数据集，您会希望计算这些值一次，然后存储它们，而不是每次都重新计算它们。请注意，您必须仅使用训练集来计算平均值和标准偏差，因为如果您使用整个数据集，您会将测试集的相关信息泄漏到训练过程中，因为它包含在平均值/标准偏差计算中。</p><h2 id="8630" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">为ImageNet上预训练的模型预处理数据</strong></h2><p id="00e7" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">PyTorch提供在ImageNet 上预先训练的<a class="ae ky" href="https://glassboxmedicine.com/2020/12/08/using-predefined-and-pretrained-cnns-in-pytorch-tutorial-with-code/" rel="noopener ugc nofollow" target="_blank">模型。在为这些模型准备数据时，我们必须考虑到所有这些模型都希望它们的输入图像以特定的方式进行预处理。这些图像必须是3通道和RGB，形状(3 x高x宽)，其中高和宽预计至少为224。此外，像素值必须在范围[0，1]内，并且应该使用mean = [0.485，0.456，0.406]和std = [0.229，0.224，0.225]进行归一化。这些平均值和标准值是使用上一节描述的过程在ImageNet上计算的。以下转换将使用这些ImageNet规范进行规范化:</a></p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="c7ba" class="nl mk it nh b gy nm nn l no np">normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], <br/>                                 std=[0.229, 0.224, 0.225])</span></pre><h1 id="ab17" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">数据增强</strong></h1><p id="99e5" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">数据扩充允许您鼓励模型的预测对某些类型的变化保持不变，例如图像的翻转或旋转。PyTorch在<a class="ae ky" href="https://pytorch.org/docs/stable/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank"> torchvision.transforms </a>中为图像数据增强提供了许多变换，包括颜色抖动、灰度、随机仿射变换、随机裁剪、随机翻转、随机旋转和随机擦除。可以用torch vision . transforms . compose(<em class="oe">transforms</em>)聚合多个转换。</p><p id="dd4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，如果您正在执行对象检测或分割任务，其中地面实况与输入图像“类似图像”且形状相同，则需要对地面实况和输入图像应用等效的数据变换。例如，如果您对输入图像应用水平翻转，您还需要水平翻转该图像的分割基础事实。</p><p id="5ff1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是一些数据扩充的数据转换的例子，使用的是来自维基百科的公共领域狗图片<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:BeachDog2.jpg" rel="noopener ugc nofollow" target="_blank">:</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b8fe9d4e57677d0b8fee51dc8282d429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/0*EINJX78Tk6tmcqLp"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，来自公共领域狗的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/4ba9769f4f4057b01e5c43eb7bf50544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/0*8d8cZcE-qcKt1utk"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，来自公共领域狗的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/42cfa8facff195ba38a91651153084b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/0*htM3VGN8gv8pU6H5"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，来自公共领域狗的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/bc521845f55ef3eba941b5a7e2e2ae97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z2xG8cHMIHks3AlD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，来自公共领域狗的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/6d21fcf6213ac475685897b388fee277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EPgC4CxaQjGW30dB"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，来自公共领域狗的照片</p></figure><h1 id="ba97" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">制作自己的数据集:概述</strong></h1><p id="09c3" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">您可以为您想要的任何图像集合创建PyTorch数据集，例如医疗数据、从互联网上下载的随机图像或您拍摄的照片。各种机器学习数据集的例子可以在<a class="ae ky" href="https://howtolearnmachinelearning.com/datasets/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="aa94" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch中自定义数据集实现的要求如下:</p><ul class=""><li id="6b97" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">必须是torch.utils.data.Dataset的子类</li><li id="607e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">必须实现__getitem__方法</li><li id="4ab2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">必须实现__len__方法</li></ul><p id="1b57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现之后，可以将自定义数据集传递给torch.utils.data.DataLoader，然后它可以并行加载多个批处理。这真的很好——这意味着您所要做的就是定义在哪里找到您的图像数据以及如何准备它(即定义一个数据集),然后PyTorch会处理所有的批处理和并行数据加载，这样您就不必这么做了！</p><h1 id="1540" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">制作自己的数据集:TinyData示例</strong></h1><p id="834e" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">本教程的<a class="ae ky" href="https://github.com/rachellea/pytorch-computer-vision" rel="noopener ugc nofollow" target="_blank">库包括TinyData，这是一个自定义PyTorch数据集的例子，它是由我在Microsoft Paint中绘制的一堆微小的多色图像组成的。这张图片展示了数据集中的图像:</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/a83db1b6aba01d58e5082eefa8e11834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*x57wpT_oe0g7CgVR"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3de9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是CSV(显示在Excel中)的屏幕截图，它定义了每个图像的标签:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/5d3397e17f77ea7b087689a55536bdb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/0*aSa1sZjgvUoWJm-H"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0513" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，TinyData是一个用于多标签分类任务的数据集，其中每个影像都与一个或多个标签类别相关联，即红色、蓝色或黄色，以确定该特定颜色是否出现在影像中。</p><h2 id="b862" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">tiny data py torch数据集的代码</strong></h2><p id="2f90" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在让我们看一下定义TinyData PyTorch数据集的代码。</p><p id="117c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这段代码可以在<a class="ae ky" href="https://github.com/rachellea/pytorch-computer-vision" rel="noopener ugc nofollow" target="_blank">库</a>的load_dataset目录中找到。它分为两个模块，custom_tiny.py定义TinyData数据集，utils.py定义图像预处理函数。</p><p id="af2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括地说，如果我们在custom_tiny.py中查看TinyData类，我们可以看到TinyData满足上面列出的在PyTorch中实现自定义数据集的3个要求:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/9047e3d797385dd8bffbedf2bf6a1559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Ye6wbp0q45fKU8O"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们来考虑这些必需的部分:</p><p id="19be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">torch.utils.data.Dataset的子类:为了使我们的数据集成为PyTorch数据集的子类，我们需要做的就是将torch.utils.data.Dataset放在我们的类名后面的括号中，比如如果我们只导入了torch，就放入my class name(torch . utils . data . Dataset)，或者如果我们使用了更具体的导入，就放入my class name(Dataset)“from torch . utils . data import Dataset”使我们的数据集成为PyTorch数据集的子类意味着我们的自定义数据集继承了PyTorch数据集的所有功能，包括进行批处理和并行数据加载的能力。</p><p id="c2ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">__len__方法:该方法只返回数据集中图像的总数。您可以在TinyDataset的代码中看到，我们将self.all_filenames定义为包含数据目录中所有图像文件的名称，这样我们就可以简单地将__len__方法实现为len(self.all_filenames)。对数据集中的图像数量进行硬编码不是一个好主意；最好根据存储图像的目录的内容来计算图像的数量。</p><p id="8a19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">__getitem__ method:该方法必须接受一个整数值“idx”。该方法然后使用该整数值从数据集中选择单个例子，例如通过索引到文件名列表中。最后，该方法返回示例，以便将其提供给模型。该示例至少需要包含一个图像及其相应的标签。图像应该已经过完全处理，以便可以直接输入到模型中-在此方法返回图像之前，应该对图像应用所有规范化和数据扩充步骤。</p><p id="700c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在TinyData的示例代码中可以看到，它的__getitem__方法包括几个步骤:<br/> (1)通过selected _ filename = self . all _ filenames[idx]选择位于索引“idx”的文件；<br/> (2)使用PIL库加载存储在该位置的图像；<br/> (3)应用数据处理步骤，在这种情况下由函数to_tensor_and_normalize()实现，该函数在utils模块中定义；<br/> (4)加载该图像的标签；<br/> (5)通过定义包含图像数据、标签以及整数索引的Python字典来创建示例(称为“样本”)。从技术上讲，您不需要提供整数索引，但是它对学习有帮助，所以这里包含了它。</p><h2 id="fda2" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">保持数据处理代码</strong> <strong class="ak">分开</strong></h2><p id="1fa6" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">最好将执行数据处理步骤的代码放在与数据集定义不同的模块中。为什么？</p><p id="cf13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原因1:如果您要运行许多不同种类的实验，那么您的图像处理代码很可能会随着时间的推移而增长，并且您不希望用一堆数据处理函数来混淆定义数据集的模块。本教程中的数据处理代码非常简单——只有几行代码——但是原则上我已经将它放入了自己的模块utils.py中(实际上，有一个比“utils”更具体的模块名称是个好主意，但是对于本教程来说已经足够了。)</p><p id="d854" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原因2:您可能希望多个不同的数据集使用相同的数据处理步骤。如果所有的数据处理函数都在某个“处理模块”中定义，那么每个数据集模块都可以从这个“处理模块”导入，并且代码保持有序。作为一个例子，utils.py被custom_tiny.py(定义我们的微型自定义数据集)和custom_pascal.py(定义基于PASCAL VOC 2012的数据集，在本文后面讨论)导入和使用。</p><p id="45bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们正在做大量的定制数据扩充，那么做这些的函数也将在utils.py中定义。</p><h2 id="f7ae" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">定义训练vs验证vs测试</strong> <strong class="ak">数据</strong></h2><p id="3024" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">您不需要为训练、验证和测试数据定义单独的数据集类。事实上，这样做是不可取的，因为这需要您的代码库包含大量冗余代码。相反，要使单个数据集类能够用于定型、验证或测试数据，可以使用参数来确定数据集将在何处查找图像。在TinyData示例中，该参数称为“setname ”,它确定TinyData类将从哪个目录加载图像。</p><h2 id="d435" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">tiny data上的训练模型</strong></h2><p id="801b" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">要在TinyData上训练神经网络，可以运行以下命令:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="672c" class="nl mk it nh b gy nm nn l no np">python Demo-1-TinyConvWithoutSequential-TinyData.py <br/>python Demo-2-TinyConv-TinyData.py</span></pre><p id="ca3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你不需要GPU来运行上述命令，因为数据集非常小。</p><h1 id="c728" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">PASCAL VOC 2012的自定义数据集</strong></h1><p id="0c6c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">正如我们从TinyData示例中看到的，当您想要使用自己的图像时，PyTorch数据集肯定会派上用场。事实证明，如果您想以不同于默认的方式使用现有的PyTorch数据集，PyTorch数据集也很方便。让我们看一下load_dataset/custom_pascal.py(也在<a class="ae ky" href="https://github.com/rachellea/pytorch-computer-vision" rel="noopener ugc nofollow" target="_blank">教程库</a>中)来理解为什么以及如何做到这一点。</p><p id="8f7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">custom_pascal.py为PASCAL VOC 2012数据集定义了一个数据集。PASCAL是一个自然图像数据集，标有以下类别的分割图:“飞机”、“自行车”、“鸟”、“船”、“瓶子”、“公共汽车”、“汽车”、“猫”、“椅子”、“奶牛”、“餐桌”、“狗”、“马”、“摩托车”、“人”、“盆栽植物”、“羊”、“沙发”、“火车”和“电视监视器”。每个图像可能有多个类别。</p><p id="d00a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原来PyTorch已经提供了一个加载PASCAL的类。下面是一个使用内置PyTorch类加载PASCAL VOC 2012训练集的示例:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e580" class="nl mk it nh b gy nm nn l no np">pascal_train = torchvision.datasets.VOCSegmentation(voc_dataset_dir, year='2012',image_set='train',download=False)</span></pre><p id="73cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果PyTorch已经有了一个PASCAL的内置类，叫做VOCSegmentation，那我们为什么还要费心在custom_pascal.py中定义一个PASCAL的自定义类呢？有两个主要原因:</p><p id="59f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(1)因此我们可以将帕斯卡数据集与SBD相结合，并创建更大的整体数据集；</p><p id="ff6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(2)所以我们可以用分类标签代替分段标签。</p><h2 id="10ec" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">合并两个数据集:帕斯卡+ SBD </strong></h2><p id="00aa" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">研究论文中的PASCAL数据集经常与SBD数据集结合在一起。为了在帕斯卡和SBD数据集上训练单个模型，我们需要以某种方式“混合”这些数据集。最简单的方法是在一个自定义数据集类中同时加载帕斯卡和SBD，我们在自定义类中这样做:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f766" class="nl mk it nh b gy nm nn l no np">#Define dataset <br/>if setname == 'train': <br/>    #In the training set, combine PASCAL VOC 2012 with SBD <br/>    self.dataset =    <br/>        [torchvision.datasets.VOCSegmentation(voc_dataset_dir,<br/>                                              year='2012',<br/>                                              image_set='train',<br/>                                              download=False), <br/>        #SBD image set train_noval excludes VOC 2012 val images    <br/>        torchvision.datasets.SBDataset(sbd_dataset_dir, <br/>                                       image_set='train_noval', <br/>                                       mode='segmentation',<br/>                                       download=False)] </span><span id="037c" class="nl mk it nh b gy ns nn l no np">elif setname == 'val': <br/>    self.dataset = <br/>        [torchvision.datasets.VOCSegmentation(voc_dataset_dir, <br/>                                              year='2012',     <br/>                                              image_set='val', <br/>                                              download=False)]</span></pre><p id="60ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后在__getitem__方法的开始，我们简单地检查是否需要从PASCAL数据集或SBD数据集中选择我们的图像，这取决于整数idx有多大:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="bf97" class="nl mk it nh b gy nm nn l no np">if idx &lt; len(self.dataset[0]): <br/>    chosen_dataset = self.dataset[0] <br/>else: <br/>    chosen_dataset = self.dataset[1] <br/>    idx = idx - len(self.dataset[0])</span></pre><p id="b671" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后要考虑的是适当地定义我们的__len__方法，以便我们考虑两个数据集的大小:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="ca5e" class="nl mk it nh b gy nm nn l no np">def __len__(self): <br/>    if self.setname == 'train': <br/>        return len(self.dataset[0])+len(self.dataset[1]) </span><span id="50c0" class="nl mk it nh b gy ns nn l no np">    elif self.setname == 'val': <br/>        return len(self.dataset[0])</span></pre><p id="083c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为__len__方法正确地反映了帕斯卡和SBD的组合大小，PyTorch从我们的数据集中采样时产生的随机整数idx有时会导致__getitem__函数返回帕斯卡图像，而其他时候会导致__getitem__返回SBD图像。</p><h2 id="859a" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">改变数据集的标签:分段- &gt;分类</strong></h2><p id="9ff9" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我们为PASCAL定义自定义数据集的第二个原因是使用不同的标签。PyTorch定义的PASCAL数据集用于训练分割模型。因此，每个图像的基本事实是分割图。</p><p id="98bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，如果不是训练完全监督的分割模型，而是训练分类模型，或者仅依赖于分类标签的弱监督分割模型，会怎么样？在这种情况下，我们需要不同格式的标签，即指示每个类存在或不存在的多热点向量。</p><p id="c31b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在自定义数据集类中定义这种新的标签。这是在custom_pascal.py函数get_label_vector()中完成的，该函数接受默认分段图标签，并将其转换为多热点存在/不存在向量。然后，__getitem__利用get_label_vector()将分割图标签转换成我们想要使用的分类标签。</p><p id="a9dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模块custom_pascal.py还包含其他有用的代码，包括可视化数据集中的图像和可视化地面真实分割图的函数。它还包括从整数类标签到它们相应的描述性名称(如“cat”或“bus ”)的映射。</p><h2 id="1f71" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">定制PASCAL VOC 2012数据集上的训练模型</strong></h2><p id="e02d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">要在自定义PASCAL VOC 2012数据集(包括SBD)上训练神经网络，您可以运行以下命令，最好是在具有GPU的机器上:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="54d0" class="nl mk it nh b gy nm nn l no np">python Demo-3-VGG16-PASCAL.py <br/>python Demo-4-VGG16Customizable-PASCAL.py</span></pre><h2 id="df2a" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">单元测试</strong></h2><p id="798d" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为数据处理编写单元测试总是一个好的策略。如果您错误地处理数据，那么您在其上训练的任何模型都将是错误的。</p><p id="564c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在src/unit_tests.py中可以看到一个单元测试的例子。要运行单元测试，您可以使用以下命令:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="8f93" class="nl mk it nh b gy nm nn l no np">python Demo-0-Unit-Tests-and-Visualization.py</span></pre><p id="1ddb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述命令还将运行PASCAL VOC 2012数据集可视化。</p><p id="0545" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(关于代码组织的附带说明:如果您正在编写大量的单元测试，那么它们实际上都应该放在它们自己的测试目录中，该目录与src处于同一级别。那么src中的每个模块在测试中可以有一个相应的单元测试模块。)</p><h1 id="8158" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">定制医疗数据集</strong></h1><p id="ad22" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">公共GitHub存储库<a class="ae ky" href="https://github.com/rachellea/ct-net-models" rel="noopener ugc nofollow" target="_blank">rachella/ct-net-models</a>包含为CT体积数据定义PyTorch数据集的代码，包括大量的数据预处理步骤和数据扩充。</p><h1 id="31c0" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">用num_workers并行数据加载</strong></h1><p id="e104" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我提到过PyTorch负责并行加载多个批次。您可以通过在数据加载器中定义num_workers来控制并行加载的批处理数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/ae1f15eeabfc2e39821ff701e4e58a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-KYou0spmZgo--hv"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4e9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">num_workers确定将用于加载数据的进程数。每个过程将加载一个批次。</p><p id="a7c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想进行单进程数据加载，并且一次只加载一个批处理，那么您可以将num_workers设置为0。因为这将导致PyTorch只启动一个数据加载过程，所以总体上可能会比较慢，并且您的GPU可能会有很多空闲时间，因为它在等待CPU完成下一个批处理。设置num_workers = 0的一个很好的原因是，如果您使用的是Windows机器，并且希望使用Python调试器。因为Windows是如何处理多处理的，所以您需要将num_workers = 0，以便在Windows上使用带有PyTorch的Python调试器。但是，一旦调试了程序，就可以增加num_workers并在没有调试器的情况下运行代码。</p><p id="d7f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果要进行多进程数据加载，则需要将num_workers设置为正整数，指定加载器工作进程的数量。在此设置中，当GPU对一个批次进行计算时，会加载其他批次。例如，如果您选择num_workers=16，那么将有16个进程加载您的批次，这意味着大致上您将同时加载16个批次。如果您很好地选择了num_workers，那么GPU将根本不必在批处理之间等待——一旦使用一个批处理完成，下一个批处理就已经准备好了。</p><p id="9c4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您需要仔细选择num_workers，否则您可能会因为试图同时加载太多的批处理而使您的机器过载。如果您正在处理像<a class="ae ky" href="https://glassboxmedicine.com/2021/02/16/downloading-and-preprocessing-medical-images-in-bulk-dicom-to-numpy-with-python/" rel="noopener ugc nofollow" target="_blank"> CT volumes </a>这样的海量图像，或者如果您正在进行大量的数据预处理，这一点尤其重要。</p><p id="50e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于如何选择num_workers，没有严格的规定。以下是一些可能有用的一般提示:</p><ul class=""><li id="6eb0" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">请记住，越高并不总是越好。如果你把num_workers设置得太高，会使你的机器窒息，导致速度变慢或者内存出错。</li><li id="9421" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">一个不错的经验法则是使用与可用CPU内核数量相等的num_workers。</li><li id="c69a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果您需要最大限度地优化性能，只需用不同的num_workers值做实验，记录一个epoch需要多长时间，然后选择导致最快时间的值。这不是一个非常“精神上令人满意”的方法(因为感觉上你应该能够<em class="oe">很容易地计算出</em>最佳工人数量)，但是这个实验性的测量是计算出一个好的工人数量的最快和最可靠的方法。</li><li id="6d0e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">请记住，如果您突然从一次训练一个模型切换到一次训练多个模型，您可能希望降低num_workers。</li></ul><p id="7fd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您使用的是NVIDIA GPU，您可以使用nvidia-smi检查内存使用情况:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/d6cc436e14077629deefc97be14e6b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BD3ok7cGTZgRcoY2"/></div></div></figure><h2 id="a82b" class="nl mk it bd ml nt nu dn mp nv nw dp mt li nx ny mv lm nz oa mx lq ob oc mz od bi translated"><strong class="ak">杂项提示</strong></h2><ul class=""><li id="f320" class="lv lw it lb b lc nb lf nc li op lm oq lq or lu ma mb mc md bi translated">如果有一个遍历历元的训练循环，请确保将数据加载器放在历元循环之外。否则，您将在每个时期初始化一次数据加载器，这(a)是不必要的，(b)会耗尽您的内存使用。</li><li id="70f7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果您使用Git进行版本控制，请将图像数据集存储在Git存储库之外。“微小数据”出现在教程回购中的唯一原因是因为这是一个教程，数据小得不切实际。</li><li id="cce9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">与前面的要点相似，将结果文件存储在您的Git存储库之外也是一个好主意，因为图像模型的结果通常包含大文件(例如可视化)。</li></ul><h1 id="7d46" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated"><strong class="ak">总结</strong></h1><ul class=""><li id="87a9" class="lv lw it lb b lc nb lf nc li op lm oq lq or lu ma mb mc md bi translated">PyTorch的torchvision库包括许多内置数据集，包括MNIST和ImageNet。</li><li id="db54" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PyTorch的数据加载器接收数据集并对其进行批处理。</li><li id="a10d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">torchvision.transforms可用于规范化数据和/或执行数据扩充。</li><li id="0092" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PyTorch中的自定义数据集必须是torch.utils.data.Dataset的子类，并且必须实现_ _ getitem _ _和__len__方法。除此之外，细节由你决定！</li><li id="95f2" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PyTorch中的自定义数据集也可以利用内置数据集，将它们合并成一个更大的数据集和/或为每个图像计算不同的标签。</li><li id="8dd4" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将num_workers DataLoader参数设置为某个正整数值<em class="oe"> n </em>意味着<em class="oe"> n </em>进程将并行加载批处理。</li></ul><p id="c137" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集创建愉快！</p><p id="0c14" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oe">原载于2022年1月21日</em><a class="ae ky" href="https://glassboxmedicine.com/2022/01/21/building-custom-image-data-sets-in-pytorch-tutorial-with-code/" rel="noopener ugc nofollow" target="_blank"><em class="oe">【http://glassboxmedicine.com】</em></a><em class="oe">。</em></p></div></div>    
</body>
</html>