<html>
<head>
<title>Training RegNets for tf.keras.applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">tf.keras .应用程序的培训规则</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-regnets-for-tf-keras-applications-c9bcdc70755#2022-01-15">https://towardsdatascience.com/training-regnets-for-tf-keras-applications-c9bcdc70755#2022-01-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="aa73" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">tf.keras .应用程序的培训规则</h1></div><div class=""><h2 id="29bd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这篇博文是关于分享我为<code class="fe kf kg kh ki b">tf.keras.applications</code>训练24个RegNet模型的经验。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/4612b00bb70395321b54f3f810fc6798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6Xnup26P7Kz-tHQ6WdN3A.jpeg"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">Paola blaskovi在<a class="ae kz" href="https://unsplash.com/photos/5Md4QPSQVhE" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="5af5" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">序言</h1><p id="2a8a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated"><code class="fe kf kg kh ki b">tf.keras.applications</code>是TensorFlow-Keras中的一组内置模型。它们在ImageNet-1k上进行了预训练，只需一次函数调用。这使得大联盟成员的生活更加轻松，因为他们有现成的模型可供使用。<a class="ae kz" href="https://arxiv.org/abs/2003.13678" rel="noopener ugc nofollow" target="_blank">regnet</a>是脸书人工智能研究所(FAIR)提出的高效可扩展模型。它们被用在像<a class="ae kz" href="https://arxiv.org/abs/2103.01988" rel="noopener ugc nofollow" target="_blank"> SEER </a>这样的工程中，这些工程需要可以扩展到亿万个参数的模型。在向Keras 提交<a class="ae kz" href="https://github.com/keras-team/keras/pull/15702" rel="noopener ugc nofollow" target="_blank"> PR的过程中，我实现并训练了24个不同复杂程度的RegNet模型给<code class="fe kf kg kh ki b">tf.keras.applications</code>。</a></p><p id="48e0" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">尽管我负责PR的主要开发工作以及培训模型，但我从社区获得了很大的帮助，这使它真正具有协作性。</p><p id="1018" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">我用这些模型进行了几个实验，因为使用本文提供的超参数无法重现报告的精度。这篇博文记录了我尝试的这些实验以及它们的结果。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="84bd" class="la lb iq bd lc ld na lf lg lh nb lj lk jw nc jx lm jz nd ka lo kc ne kd lq lr bi translated">致谢:</h1><p id="fc05" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">我真诚地感谢Keras团队允许我添加这些模型。非常感谢<a class="ae kz" href="https://sites.research.google/trc/about/" rel="noopener ugc nofollow" target="_blank"> TPU研究小组(TRC) </a>在整个项目期间提供TPU，没有他们，这一切都是不可能的。非常感谢<a class="ae kz" href="https://github.com/fchollet" rel="noopener ugc nofollow" target="_blank">Fran ois Chollet</a>允许这一点并在整个过程中指导我。感谢<a class="ae kz" href="https://github.com/qlzh727" rel="noopener ugc nofollow" target="_blank">Scott Zhu</a>在虚拟机上从源代码构建Keras的指导。感谢Matt Watson对分组卷积的支持。特别感谢Lukas Geiger对代码的贡献。最后但同样重要的是，非常感谢Sayak Paul不断的指导和鼓励。</p><h1 id="7080" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">基础知识</h1><h2 id="0d07" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">关于报纸</h2><p id="ef13" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">论文<a class="ae kz" href="https://arxiv.org/abs/2003.13678" rel="noopener ugc nofollow" target="_blank">“设计网络设计空间”</a>旨在从一个没有约束的模型空间出发，系统地推导出最佳模型群体。该文件还旨在找到一个最佳模型群体，而不是像在<a class="ae kz" href="https://arxiv.org/abs/1707.07012" rel="noopener ugc nofollow" target="_blank"> NASNet </a>这样的作品中找到一个单一的最佳模型。</p><p id="86b8" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">该实验的结果是一系列网络，其包括具有各种计算成本的模型。用户可以根据需要选择特定的架构。</p><h2 id="7ebb" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">关于模型</h2><p id="50fc" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">RegNet系列的每个模型都包含四个阶段。每个阶段由许多块组成。该模块的架构是固定的，并且该模块有三种主要变体:X模块、Y模块、Z模块。在论文中可以看到其他变体，并且作者声明模型推导方法是稳健的，并且RegNets很好地推广到这些块类型。</p><p id="7a96" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">每一级的块数及其通道宽度由文中提出的简单量化规则决定。更多信息请见<a class="ae kz" href="https://medium.com/visionwizard/simple-powerful-and-fast-regnet-architecture-from-facebook-ai-research-6bbc8818fb44" rel="noopener">博客</a>。由于其卓越的扩展能力，正则网络已经成为SEER等自监督方法的首选网络。</p><h1 id="6864" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">拉取请求:</h1><p id="2eed" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">在打开需要大量工作的“拉”请求之前，建议先咨询团队，这样就不会有利益冲突。在得到Keras团队的可靠确认后，我开始编写代码。你可以点击查看我们的讨论<a class="ae kz" href="https://github.com/keras-team/keras/issues/15240" rel="noopener ugc nofollow" target="_blank">。以下是我们对话中的一小段:</a></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nr"><img src="../Images/06f6f5c1fd1bffff42cdbe2a09041c4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*utyjugszQlS07ekB"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">问题#15240的摘录</p></figure><p id="7cee" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">Franç ois Chollet和Keras团队给予了极大的支持，使合并PR成为一个顺利的过程。我对团队的帮助表示衷心的感谢。</p><p id="393a" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">尽管我要实现24个模型，但基本代码相当简单。因此，我能够用代码创建一个PR，并很快得到团队的评论。点击查看公关<a class="ae kz" href="https://github.com/keras-team/keras/pull/15702" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="4920" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">训练模型:</h1><h2 id="f9f9" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">一般设置</h2><p id="d656" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">我主要用TPU v3–8节点进行训练。它有一个96核虚拟机，大约335 GB内存，可以轻松处理繁重的预处理。经过预处理后，原始图像被调整到224x224的大小，如文中所述。我同时使用多个TPU节点，以便并行运行多个实验。这大大减少了实验时间。</p><p id="24b7" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">我用来训练的代码可以在<a class="ae kz" href="https://github.com/AdityaKane2001/regnets_trainer" rel="noopener ugc nofollow" target="_blank">这里</a>得到。</p><p id="db7f" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在这一部分，我简单地记下了我实现这一表现的要点和方法。</p><h2 id="8c4f" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">1.输入管道</h2><p id="2b65" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">我在强大的TPU-v3上训练这些模型(感谢TRC)。这意味着我不得不使用一个快如闪电的输入管道。此外，输入管道必须是静态的，这意味着我不能在运行时突然改变预处理图(因为预处理函数是使用AutoGraph优化的)。根据TPUs的要求，我将ImageNet-1k TFRecords存储在一个GCS存储桶中，并采用了一种交叉读取数据集的方法。</p><p id="684a" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><em class="ns">学习要点:重要的是以最有效和最稳定的方式实施扩增，并在此过程中尽量减少缓慢和冗余的操作。</em></p><p id="77fb" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">这里有一个例子，说明如何避免执行图中的动态变化。我已经为盗梦风格的裁剪创建了几个函数，最初的盗梦文件推广了这个函数。有趣的是，在图形执行中不允许使用<code class="fe kf kg kh ki b">break</code>语句，因为它们会动态地改变图形。</p><p id="7bb7" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">一些代码块是重复的，但是这保证了函数保持纯净。这里的纯粹仅仅意味着没有<code class="fe kf kg kh ki b">break</code>语句，否则会导致图形任意变化。例如，我们还可以看到，在整个函数调用中，变量<code class="fe kf kg kh ki b">w_crop</code>恰好被转换为<code class="fe kf kg kh ki b">tf.int32</code>一次。进行这样的优化很重要，因为我们一次处理一个图像，而不是一批图像。你可以在这里查看代码<a class="ae kz" href="https://github.com/AdityaKane2001/regnets_trainer/blob/63bf8fb00e83fe92ae8a6f2ce2307bc9274d43e0/dataset.py#L384-L536" rel="noopener ugc nofollow" target="_blank"/>。为了简洁起见，实际的代码没有包含在这个博客中。</p><p id="64ac" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">除了初始风格的裁剪，其余输入管道的实现相当简单。总之，我使用了初始裁剪、通道式PCA抖动、水平翻转和<a class="ae kz" href="https://arxiv.org/abs/1710.09412v2" rel="noopener ugc nofollow" target="_blank">混音</a>。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">PCA抖动增强代码</p></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">混合增强代码</p></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">水平翻转增强代码</p></figure><p id="ffda" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">论文中提出了PCA抖动和随机水平翻转，而添加mixup则受到了论文<a class="ae kz" href="https://arxiv.org/abs/2103.07579" rel="noopener ugc nofollow" target="_blank"> Revisited ResNets </a>的启发。</p><h2 id="38c4" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">2.体重衰减对训练的影响</h2><p id="f1ed" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">权重衰减是一种正则化技术，我们对过大的权重进行惩罚。权重衰减是一种久经考验的方法，经常在训练深度神经网络时使用。一个小注意，我使用解耦权重衰减，而不是权重衰减的传统实现。</p><p id="881b" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">我看到增加过多的权重衰减会使模型难以收敛。然而，小的重量衰减导致模型在最后的时期具有接近恒定的精度。这些观察表明，重量衰减是一个强正则化，特别是对于较小的模型。受论文<a class="ae kz" href="https://arxiv.org/abs/2103.07579" rel="noopener ugc nofollow" target="_blank">“重温结果:改进的训练和缩放策略”</a>的启发，我保持大模型的权重衰减不变，因为混合同时增加。</p><p id="5ffe" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><em class="ns">学习点:权重衰减是强正则化。对于大型模型，建议减少权重衰减或保持其不变，同时使用其他增强或正则化。</em></p><p id="a42f" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">最后，我对所有模型使用了5e-5的恒定重量衰减，这是原始论文中建议的。</p><h2 id="10f7" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">3.作为模型大小函数的正则化</h2><p id="77d6" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">根据经验，增加正则化的增强会导致更好的性能。与此一致，随着模型尺寸的增加，我逐渐增加了混合增强的强度。我看到使用这个简单的技术效果很好。</p><p id="9768" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><em class="ns">学习点:增加模型规模时，增加扩充和正则化。</em></p><h2 id="6cdd" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">4.较小的模型很难训练</h2><p id="e263" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">我必须训练RegNetX和RegNetY的12个变种。这包括小模型，它们没有大模型那么多参数。据推测，这些模型根本没有足够的容量来保存给定的信息。它们往往会出现不足，解决方案很少像增加功能那样简单。在大多数情况下，最好的起点是低正则化和中等增强。我可以从那里调整其余的超参数。这些模型需要花费大量时间进行微调和训练，而较大的模型具有更大的灵活性。较小的模型对正则化或增强中的微小变化很敏感。</p><p id="e0c3" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><em class="ns">学习点:做一个小模型的超参数搜索。随着模型尺寸的增加，重复搜索。</em></p><h2 id="c554" class="nf lb iq bd lc ng nh dn lg ni nj dp lk mb nk nl lm mf nm nn lo mj no np lq nq bi translated">5.值得注意的学习:</h2><p id="0ff4" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated"><strong class="lu ir">答:如有可能，使用数据的多个副本</strong></p><p id="e6dd" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">据观察，训练会突然停止，并在一个时期结束时停滞不前。我使用了<code class="fe kf kg kh ki b">tf.data.Dataset.interleave</code>方法，它同时从多个TFRecords中读取数据。在此读取操作期间，TFRecords对其他进程不可用。我曾经并行训练多个模型，因此它们经常需要从同一个桶中读取数据。因此，为了解决这个问题，我创建了TFRecords的多个副本，并将它们保存在不同的桶中。这减少了碰撞，问题也大大减少了。</p><p id="eac2" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><strong class="lu ir"> b .在单一位置转储日志</strong></p><p id="f672" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在训练多个模型时，维护日志可能会失控。在我看来，最好的办法是把所有的原木都倒在一个地方。在我们的例子中，我使用训练的时间和日期来组织模型的日志和检查点。这使得在需要的地方定位和使用检查点变得更加容易。以下是相同的快照:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/edad1fc4a613e3400da3b9f4f27b62db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*xj8WUkFVHT7tHvHY"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">我的圆木桶。虽然有点乱，但确实管用:)</p></figure><p id="d762" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><strong class="lu ir"> c .使用自动化来减少认知负荷</strong></p><p id="29e9" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">同时快速管理多个实验成为一项艰巨的任务。从一开始就将你需要重复做的事情自动化是一件非常有用的事情。例如，可以使用权重和偏差(W&amp;B)来自动跟踪所有实验。将超参数与运行一起记录在W&amp;B中是有用的，而不是手动输入它们。这些看起来很小的事情减少了大量的认知负荷，所以你可以专注于重要的事情——进行实验。以下是我们运行的快照:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nw"><img src="../Images/35ca944a93a9231f2c4456e6cf65bd11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3lmMykCJ8aD7y-xJ"/></div></div></figure><p id="8511" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><strong class="lu ir"> d .获得模型如何对超参数的某些变化做出反应的直觉</strong></p><p id="6724" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">在一个架构上工作了几天或几个月之后，您可能会注意到模型性能的模式。这有助于建立模型如何对超参数的不同变化做出反应的直觉。利用这种新发现的直觉，你可能会想出有助于提高性能的主意。例如，对RegNetY004使用稍高的权重衰减会导致运行结束时准确度突然增加，然后降低，但使用较低的权重衰减会使这种情况变平。这意味着，在这种情况下，使用更积极的增加策略和更低的体重下降可能有助于训练。以类似的方式，人们可以发现导致显著改善的超参数的变化。</p><p id="9831" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated">最后，这里是结果。在下面的表格中，我将我们的结果与论文进行了比较。最后一列具有不同于原始实现的超参数。</p><p id="a815" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><strong class="lu ir"> X变种</strong></p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="nx nu l"/></div></figure><p id="fa4a" class="pw-post-body-paragraph ls lt iq lu b lv mo jr lx ly mp ju ma mb mq md me mf mr mh mi mj ms ml mm mn ij bi translated"><strong class="lu ir"> Y变体</strong></p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="nx nu l"/></div></figure><h1 id="14b8" class="la lb iq bd lc ld le lf lg lh li lj lk jw ll jx lm jz ln ka lo kc lp kd lq lr bi translated">结论</h1><p id="8929" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma mb mc md me mf mg mh mi mj mk ml mm mn ij bi translated">为了这次公关，我一共训练了24个模特。这是一次丰富的经历，我希望这些模型将被许多开发人员使用。通过这次经历，我学到了很多东西，我希望在不久的将来继续为TensorFlow &amp; Keras做出贡献。</p></div></div>    
</body>
</html>