<html>
<head>
<title>Introduction to Logistic Regression: Predicting Diabetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归简介:预测糖尿病</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-logistic-regression-predicting-diabetes-bc3a88f1e60e#2022-01-18">https://towardsdatascience.com/introduction-to-logistic-regression-predicting-diabetes-bc3a88f1e60e#2022-01-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="e482" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">逻辑回归简介:预测糖尿病</h1></div><div class=""><h2 id="00e2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">UCL数据科学学会研讨会11:什么是逻辑回归、数据探索、实施和评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2890e8ebd891404f6ffc3bb7919129d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aERBJlFZwapDO21T"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="8010" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今年，作为UCL数据科学协会的科学负责人，该协会的目标是在整个学年举办一系列20场研讨会，涵盖的主题包括Python、数据科学家工具包和机器学习方法的介绍。每一篇文章的目标都是创建一系列的小博客，这些小博客将概述要点，并为任何希望跟进的人提供完整研讨会的链接。所有这些都可以在我们的<a class="ae ky" href="https://github.com/UCL-DSS" rel="noopener ugc nofollow" target="_blank"> GitHub </a>资源库中找到，该资源库将在全年更新新的研讨会和挑战。</p><p id="baf9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本系列的第11个研讨会是Seda Radoykova撰写的Python中的逻辑回归介绍。本课程涵盖了什么是逻辑回归，什么时候可以使用它，探索数据，实施模型和评估结果。虽然亮点将会在这篇博文中呈现，但是完整的研讨会可以在我们的GitHub账户<a class="ae ky" href="https://github.com/UCL-DSS/logistic_regression_DSS" rel="noopener ugc nofollow" target="_blank">这里找到。</a></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="91c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您错过了我们之前的任何研讨会，可以在这里找到:</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/linear-regression-in-python-for-data-scientists-16caef003012"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">面向数据科学家的Python线性回归</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL数据科学学会研讨会10:什么是线性回归，数据探索，Scikit学习实施和…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/an-introduction-to-sql-for-data-scientists-e3bb539decdf"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">数据科学家的SQL介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL数据科学学会工作坊9:什么是SQL，选择数据，查询数据，汇总统计，分组数据和…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/an-introduction-to-plotting-with-matplotlib-in-python-6d983b9ba081"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">Python中Matplotlib绘图简介</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL数据科学学会研讨会7:创建一个基本的图表，在同一图表上绘制不同的信息…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mv l mq mr ms mo mt ks mf"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="358d" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">什么是逻辑回归？</h2><p id="b422" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">数据可以大致分为连续数据和分类/离散数据，前者可以在给定范围(如距离或时间)内获取无限数量的点，后者在给定数据组(如支付方式或客户投诉)内包含有限数量的点或类别。我们已经看到了以<a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-in-python-for-data-scientists-16caef003012">线性回归</a>的形式将回归应用于连续预测问题的例子，其中我们预测了销售额，但是为了预测分类输出，我们可以使用逻辑回归。</p><p id="2fc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们仍然使用回归来预测结果，但逻辑回归的主要目的是能够预测哪个类别和观察值属于哪个类别，而不是一个确切的值。该方法可用于的问题示例包括:“给定一个人的年龄、性别、吸烟状况、<em class="nu">等、</em> ( <strong class="lb iu">变量/特征</strong>)，该人患疾病的可能性有多大？”“这封电子邮件是垃圾邮件的可能性有多大？”"给学生一些成绩预测指标，他们会通过考试吗？"。</p><p id="70f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑回归的实现是基于“sigmoid函数”，也称为“逻辑函数”，而不是线性回归中使用的线性函数。对于二元分类任务，其基础是结果值只能取0或1，因此我们必须将我们的预测限制在这个范围内。该功能采取以下形式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/678d0f2113d3005b5c73ffd4ede958ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*iHjkUO9jEvLlGGeZBZ_EXg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="150d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用于将预测值映射到0和1之间的概率。这可以直观地表示为:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2b59" class="mw mx it nx b gy ob oc l od oe"># implement a sigmoid function by hand<br/>def sigmoid(x):<br/>    a = []<br/>    for item in x:<br/>        a.append(1/(1+math.exp(-item)))<br/>    return a</span><span id="85d8" class="mw mx it nx b gy of oc l od oe"># evaluate the sigmoid at some x values<br/>sigm = np.arange(-22, 22, 0.5)</span><span id="4479" class="mw mx it nx b gy of oc l od oe"># plot the sigmoid<br/>plt.plot(sigm*0.2+4.57, np.array(sigmoid(sigm)), color = "red") # manually implemented sigmoid<br/>plt.plot([0,10], [0.5, 0.5], linestyle = "dotted", color = "black") <br/>plt.title("Sigmoid function")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/094b8c65892ebe75c7d270be7068f660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nUlj5g4bE5bsJSmpdBIv3Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2d83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到大多数值非常接近0或1。在此范围内，如果预测的概率大于0.5，那么它将被指定为1，或者如果它小于0.5，那么它将被指定为0。</p><p id="f9ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中，传统的线性回归模型表现为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/3bcaa49a46a71ab8abc97601bb6c0d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*vAA2HCxIa5Sv9_lbMUA45w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="ce9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当B值代表校准模型的参数时，逻辑回归函数变为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f0b864e8c31ef0de3888353f08ff416c.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*6Xt5HwLTfP8ljtgEHy_PCQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c831" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中P(x)可被视为给定输入的输出等于1的概率(给定输入的输出等于0的概率由1- p(x)给出)。然后，模型拟合具有相同的目的，即确定系数(B)的最佳值，使得曲线和每个y的数据点之间的距离尽可能接近。</p><h2 id="b0de" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">探索数据</h2><p id="3465" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们使用的数据集来自<a class="ae ky" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>，专注于能够基于几个变量预测一个人是否患有糖尿病。在此范围内，我们有八个预测值和一个结果:</p><ul class=""><li id="79a6" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">怀孕次数=既往怀孕次数</li><li id="20a1" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">葡萄糖=葡萄糖耐量试验中的血糖水平</li><li id="66ab" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">bp =舒张压值(毫米汞柱)</li><li id="5019" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">skin_thickness =三头肌皮褶厚度(mm)</li><li id="25a9" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">胰岛素=胰岛素水平</li><li id="0484" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">bmi =身体质量指数(bmi)，𝑤𝑒𝑖𝑔ℎ𝑡ℎ𝑒𝑖𝑔ℎ𝑡2=𝑘𝑔𝑚2weightheight2=kgm2</li><li id="a690" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">谱系=糖尿病谱系功能</li><li id="9c8d" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">年龄=年龄(岁)</li><li id="008b" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">结果=健康结果(1 =糖尿病，0 =健康)</li></ul><p id="4372" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们不一定需要理解这些与糖尿病有什么关系(如果有的话),因为有人在数据收集中已经为我们想到了这一点。然而，我们的任务是创建探索这些关系的模型，并对它们进行评估。</p><h2 id="dd2e" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">模型拟合</h2><p id="b5bc" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">创建一个模型的主要目的之一是确保它可以推广到看不见的数据，这样它就不会过度拟合它训练的数据(<a class="ae ky" rel="noopener" target="_blank" href="/bias-and-variance-for-machine-learning-in-3-minutes-4e5770e4bf1b">偏差与方差权衡</a>)。这意味着，我们在建模之前要做的第一件事是拆分训练和测试数据集中的数据，以便我们可以保存一些数据，从而能够准确地评估模型的性能。我们可以这样做:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="64ef" class="mw mx it nx b gy ob oc l od oe"># split data into features/inputs and targets/outputs<br/>feature_cols = ['pregnancies', 'insulin', 'bmi',<br/>                'age', 'glucose', 'bp', 'pedigree']<br/>X = diabetes[feature_cols] # features<br/>y = diabetes.outcome # target variable</span><span id="ea1b" class="mw mx it nx b gy of oc l od oe"># split data into training and validation datasets <br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)</span></pre><p id="5316" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们已经将数据放入了训练和测试数据集，我们就可以创建将要使用的模型了。为此，我们导入必要的库和模型，然后将模型实例化为:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="e91c" class="mw mx it nx b gy ob oc l od oe">from sklearn.linear_model import LogisticRegression</span><span id="a44e" class="mw mx it nx b gy of oc l od oe"># instantiate the model<br/>model = LogisticRegression()</span></pre><p id="7403" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此时，我们已经创建了一个<code class="fe ox oy oz nx b">LogisticRegression</code>对象的实例。然而，在此过程中，我们使用了默认的参数设置，这将有助于确定哪些参数可能是我们感兴趣的，以及它们的含义:</p><ul class=""><li id="c8d5" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated"><code class="fe ox oy oz nx b">fit_intercept</code> -布尔值，决定是否计算截距𝛽0β0(为真时，默认)或将其视为等于零(为假时)。</li><li id="f71f" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><code class="fe ox oy oz nx b">intercept_scaling</code> -浮点数，定义了截距𝛽0β0的缩放比例，(默认为1.0)。</li><li id="0688" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><code class="fe ox oy oz nx b">class_weight</code> -字典，“平衡”或<code class="fe ox oy oz nx b">None</code>(默认)，定义与每个类别相关的权重。当<code class="fe ox oy oz nx b">None</code>时，所有类的权重都为1。</li><li id="d094" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><code class="fe ox oy oz nx b">solver</code> -字符串，用于拟合模型的解算器。默认为“liblinear ”;其他选项包括“牛顿-cg”、“lbfgs”、“sag”和“saga”。</li><li id="77d6" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><code class="fe ox oy oz nx b">tol</code> -浮点数，定义停止程序的公差(默认为0.0001)。</li><li id="ee93" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated"><code class="fe ox oy oz nx b">n_jobs</code> -整数或<code class="fe ox oy oz nx b">None</code>(默认)，定义要使用的并行进程的数量。<code class="fe ox oy oz nx b">None</code>通常表示使用一个内核，而-1表示使用所有可用的内核。</li></ul><p id="ed05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在更复杂的应用程序中还可以探索更多。</p><p id="7aaf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到这一点，我们可以使用默认值，并将其与我们现有的训练数据进行拟合，如下所示:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2afa" class="mw mx it nx b gy ob oc l od oe"># fitting the model<br/>model.fit(X_train, y_train)</span></pre><p id="d7af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过从模型中提取截距和斜率，我们可以看到它的表现:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="7f69" class="mw mx it nx b gy ob oc l od oe">coefficents = {"Features": ["Intercept"] + feature_cols,<br/>              "Coefficients":np.concatenate((model.intercept_ ,model.coef_[0]))}</span><span id="9dde" class="mw mx it nx b gy of oc l od oe">coefficents = pd.DataFrame(coefficents)</span><span id="89bb" class="mw mx it nx b gy of oc l od oe">coefficents</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/34b137ebd290cb45c32dc37db5cc11e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*urvvLNE5om8mgmew16i7XQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="32b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将这些解释为积极的迹象，即在其他条件相同的情况下，人数越多，他们患糖尿病的可能性越大，人数越少，他们患糖尿病的可能性越小。尽管这些影响的实际大小可能难以解释，并且取决于所涉及的变量的范围和大小。理解这一点的一个很好的来源是this <a class="ae ky" href="https://www.displayr.com/how-to-interpret-logistic-regression-coefficients/" rel="noopener ugc nofollow" target="_blank">链接。</a></p><h2 id="a5cb" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">评估绩效</h2><p id="6024" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">一旦我们拟合了模型并检查了参数，我们就可以看到它的表现以及在看不见的数据上的表现。虽然在一个好的模型中，许多预测都是准确的，但不可避免地会有误差。</p><p id="f276" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的应用中，有时模型会将健康个体误分类为糖尿病个体(假阳性)，将糖尿病个体误分类为健康个体(假阴性)。然而，为了全面评估性能，我们可以使用各种不同的方法来理解和评估模型的性能。其中包括:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/addd0746fe62355baa9b15f03d438cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-cRRFbAWnBWvJtADYykSKA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="db41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择使用哪种指标将取决于您的目标，因为不同的模型实现可能会以牺牲一种指标的性能为代价来提高另一种指标的性能。</p><p id="74b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以做的第一件事是对我们设置的测试数据集的看不见的数据做一些预测。为此，我们可以使用模型中的<code class="fe ox oy oz nx b">.predict()</code>方法来检查我们的测试数据集，如下所示:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="8dfc" class="mw mx it nx b gy ob oc l od oe">y_pred = model.predict(X_test)<br/>y_pred[0:5]</span><span id="448a" class="mw mx it nx b gy of oc l od oe">#out:<br/>array([1, 0, 0, 1, 0], dtype=int64)</span></pre><p id="1af2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，模型将个人分为1类或0类(是否患有糖尿病)。因为我们知道这些个体实际上是否患有糖尿病，所以我们可以使用这些知识来评估模型性能。</p><p id="11c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以从分别检查准确度分数、精确度分数和召回分数开始:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="e164" class="mw mx it nx b gy ob oc l od oe"># metrics<br/>print("Accuracy for test set is {}.".format(round(metrics.accuracy_score(y_test, y_pred), 4)))<br/>print("Precision for test set is {}.".format(round(metrics.precision_score(y_test, y_pred), 4)))<br/>print("Recall for test set is {}.".format(round(metrics.recall_score(y_test, y_pred), 4)))</span><span id="4b9f" class="mw mx it nx b gy of oc l od oe">#out:<br/>Accuracy for test set is 0.8073.<br/>Precision for test set is 0.766.<br/>Recall for test set is 0.5806.</span></pre><p id="c457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，我们也可以使用scikit learn的内置功能获得分类报告，例如:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="b2ce" class="mw mx it nx b gy ob oc l od oe">print(metrics.classification_report(y_test, y_pred))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/c12c824b6e0036fc9aa5915a8c9b8335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmVNNQwjIqXbqvnWaIGArw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="a702" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从中我们可以看出，虽然我们在模型中有很好的整体准确性和精确度，但在召回率方面表现很差。这告诉我们，虽然该模型在真阳性方面表现良好，但在假阴性方面有点困难。</p><p id="4027" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过一个混淆矩阵来实现这一点，该矩阵可以在一行代码中提取，然后绘制如下:</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="14ef" class="mw mx it nx b gy ob oc l od oe">#confusion matrix<br/>conf_mat = metrics.confusion_matrix(y_test, y_pred)</span><span id="81a4" class="mw mx it nx b gy of oc l od oe"># plotting the confusion matrix<br/>plt.figure(figsize=(12,6))<br/>plt.title("Confusion Matrix")<br/>sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')<br/>plt.ylabel("Actual Values")<br/>plt.xlabel("Predicted Values")<br/>plt.savefig('confusion_matrix.png')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/01c605cb1d57e810a08c7c68b092760e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BvwjiBx9djlF3NB86Zyyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="dd6f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以直观地看到分类报告如何转化为实际结果。</p><p id="db36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以为此使用的另一种评估技术是接收器操作特性(ROC)曲线，这在许多机器学习上下文中都可以看到。这用于绘制真阳性率与假阳性率，显示灵敏度和特异性之间的权衡。在该图中，理想曲线是紫线，而完全随机模型的结果是红线，目标是尽可能接近紫线。</p><pre class="kj kk kl km gt nw nx ny nz aw oa bi"><span id="2d42" class="mw mx it nx b gy ob oc l od oe"># ROC curve<br/>y_pred_proba = model.predict_proba(X_test)[::,1]<br/>fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)<br/>auc = metrics.roc_auc_score(y_test, y_pred_proba)<br/>plt.plot(fpr, tpr, label="auc = " + str(round(auc,2)))<br/>plt.plot(x, y, color = "violet", label = "Ideal")<br/>plt.plot([0,1], [0,1], color = "red", linestyle = "--",<br/>          label = "random")<br/>plt.legend(loc=4)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/ba7524100915fdad1b21bf9f8b17a971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M0neIynAXvwwidcPjUbQg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8167" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种性能通过曲线下面积(AUC)来量化，曲线下面积显示模型与理想性能的接近程度。理想模型的“最佳”AUC分数应该是1，而我们的随机模型的AUC是0.5。因此，我们可以看到我们的模型虽然不完美，但表现相对较好。</p><h2 id="3302" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">结束语</h2><p id="63e8" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们已经学习了如何实现一个简单的逻辑回归方法。这是一种相对直观、有效和优雅的分类技术，它为我们提供了给定一些观察结果的给定结果的概率。这使得它成为一种非常流行的分类方法。</p><p id="c3ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的好处包括:</p><ul class=""><li id="ebea" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">不需要很高的计算能力</li><li id="4b4d" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">易于实施(甚至从头开始)</li><li id="ed25" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">易于解释和评估</li></ul><p id="3cf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这样做的负面影响是:</p><ul class=""><li id="b784" class="oj ok it lb b lc ld lf lg li ol lm om lq on lu oo op oq or bi translated">它不能处理具有许多预测变量的高度复杂的模型</li><li id="a898" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">需要在大样本上训练</li><li id="ed89" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">倾向于过度拟合</li><li id="4d44" class="oj ok it lb b lc os lf ot li ou lm ov lq ow lu oo op oq or bi translated">无法处理非线性问题</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="dba6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想了解我们协会的更多信息，请随时关注我们的社交网站:</p><p id="b37c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">https://www.facebook.com/ucldata</p><p id="4e7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">insta gram:【https://www.instagram.com/ucl.datasci/ T2】</p><p id="588d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">领英:【https://www.linkedin.com/company/ucldata/ T4】</p><p id="898e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解UCL数据科学协会和其他优秀作者的最新信息，请使用我下面的推荐代码注册medium。</p><div class="mc md gp gr me mf"><a href="https://philip-wilkinson.medium.com/membership" rel="noopener follow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">通过我的推荐链接加入媒体-菲利普·威尔金森</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">philip-wilkinson.medium.com</p></div></div><div class="mo l"><div class="pf l mq mr ms mo mt ks mf"/></div></div></a></div><p id="e964" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者看看我写的其他故事:</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/bias-and-variance-for-machine-learning-in-3-minutes-4e5770e4bf1b"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">3分钟机器学习的偏差和方差</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">什么是偏差和方差，这对你的机器学习模型意味着什么？</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="pg l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/an-introduction-to-object-oriented-programming-for-data-scientists-879106d90d89"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">面向数据科学家的面向对象编程介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">面向对象的基础知识，适合那些以前可能没有接触过这个概念或者想知道更多的人</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="ph l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/git-and-github-basics-for-data-scientists-b9fd96f8a02a"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">面向数据科学家的Git和GitHub基础知识</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL数据科学研讨会8:什么是Git，创建本地存储库，提交第一批文件，链接到远程…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="pi l mq mr ms mo mt ks mf"/></div></div></a></div></div></div>    
</body>
</html>