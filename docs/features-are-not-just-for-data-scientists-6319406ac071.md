# 特性不仅仅是数据科学家的专利

> 原文：<https://towardsdatascience.com/features-are-not-just-for-data-scientists-6319406ac071>

## 特色商店起源故事

![](img/75d62969019458a24d6a0e412b4a560d.png)

照片由 Mikael Blomkvist 拍摄:[https://www . pexels . com/photo/simple-workspace-at-home-6476588/](https://www.pexels.com/photo/simple-workspace-at-home-6476588/)

# 起初

很久以前，在一个很远很远的地方，我是一家财富 50 强公司的数百名数据分析师之一。幸运的是，我在 2014 年被提升为该公司首批数据科学家之一，旁边还有一些拥有博士学位和多年预测建模经验的新员工。我以为我完全超出了我的能力范围。

没过多久，我就发现我的 SQL 知识和业务专长比我意识到的要有价值得多。如果您不知道数据中的所有细微差别，或者不知道如何编写 SQL 来正确避免客户时数据设置的泄漏，那么流失模型是没有用的。因此，我成了团队中一名有价值的成员。其他数据科学家和我有一种共生关系:他们教我预测建模，我为他们编写他们的 SQL。

## 辉煌的日子

因此，我的 SQL 片段变成了一个脚本，然后我的脚本变成了一个团队项目。作为一个团队，我们开始构建一个主 SQL 脚本，将 20 多个表连接在一起，并计算每个客户在任何给定时间点的信息指标:

*   自客户更换包装后的天数
*   在过去 365 天内，客户账单上涨超过 5 美元的次数
*   客户收入与同一 ZIP 平均收入的比率 3
*   在过去 5 年里，同一栋房子里不同顾客的数量
*   产品变化是否算作升级、降级、降级的标志

如果你是一个开始一个新模型的数据科学家，你只需要带来 3 列:客户、日期和目标。主脚本会立刻给你 150 个特性。这大大节省了时间。它允许数据科学家花更多的时间想出*新的和* *有创意的*功能，然后可以添加到主脚本中。作为这个主剧本事实上的“主人”，所有的工作都落到了我的身上。然而，生活是伟大的。每位数据科学家在 6 周内准时部署模型。

## 成功的痛苦

然后它打电话来了。随着我们的团队发展到 10 名数据科学家，我们对数据库基础设施的影响花费了大量资金。我们积累的主脚本运行起来非常昂贵，每个数据科学家必须为每个模型运行 3 次(训练、OOT1、OOT2)。按照传统的 IT 方式，他们没有帮助我们解决问题。他们只是通过将我们放在一个单独的资源队列中来限制我们的处理能力，在那里我们不得不象征性地在史诗般的笼子里战斗，争夺谁有权首先运行他们的查询。要么这样，要么给他们 300 万美元来扩展系统。那是不会发生的。

## 替代方案

因此，我们在一个房间里集思广益，我们意识到每月运行相同的查询 70 次是多么多余(这是 10 x 3，加上 40 个用于评分的部署模型)。如果我们每月运行一次这个查询会怎么样？我们不能继续将结果追加到一个大表中，准备好按 CustomerID 和快照日期连接吗？于是，我们的第一家特色店诞生了。然而，那个术语还不存在。

# 回到辉煌的日子

一切又变得美好了。我们的模型变得越来越好。我们从 150 个功能增加到 400 个。我们甚至将 20%的产能用于重新开发我们已经生产的旧型号——并通过新功能获得更好的结果。一帆风顺……至少我们是这么认为的。

## 如果你建造了它，他们就会来

有一天，就像其他任何一天一样，我们意识到，如果我们把税收从支付指标中剔除，它会更有预测性。所以我们把税收分成不同的部分继续。

然后，我老板的老板接到市场部 SVP 的电话。谁敢毫无征兆地更改数据？显然，通过口口相传，来自*另一个团队*的一些分析师已经发现了我们的客户特征宝库。他们用这些数据建立了 Tableau 仪表盘，并定期制作报告。

不知不觉中，我们宝贵的内部表受到了很多限制。营销部门希望为新功能制定一个 3 个月的路线图，以便它们能够产生影响。他们还想要一个健壮的具有血统的数据字典。我们甚至发现运营部门已经开始将我们的表复制到他们自己的数据库中，并基于*我们的*特性构建他们的特性。依赖性变得令人困惑。仅仅几个月后，我们的灵活建模特性库就陷入了依赖和官僚主义的泥沼。

我当时并没有意识到，但一些重要的事情正在发生。

## 我是数据科学家，别烦我

我在网上读到，如果你想激怒一个数据科学家，告诉他们记录一切。作为一个数据科学团队，我们的反应没有什么不同。我们的第一反应是占有欲:“这是我们的数据集。让他们自己做吧！这将影响我们建立模型的能力和速度。难道他们没有意识到公司可能会损失数百万美元吗？”此时，我已经被提升为经理，我注意到在功能工程方面完全缺乏创造力。如果添加功能会成为一种负担，那么没有人会添加更多的功能。

## 不同的视角

我非常感激的另一位经理，我永远不会忘记他，他把我拉到一边，用一种我从未考虑过的新观点启发了我。他向我展示了良好数据的巨大价值。公司内数百名分析师快速获得洞察力的能力远远超过我们模型的影响力。分析师们蜂拥至我们的数据，因为有真正的需求。我们没有与之抗争，而是有机会以一种*的方式*帮助公司，改变了公司的数据文化。

因此，作为一个跨职能团队，我们联手实施了我在公司中见过的最成功的数据计划。营销部门想出了一个好主意，给这个特色商店起了一个朗朗上口的名字“罗塞塔”它看到了效率和标准化以及专用计算和监控工具的优势。高管们也看到了好处，并自上而下地鼓励他们的分析师使用它。

一年后，我们拥有了两个世界的精华。真正擅长数据处理的分析工程师拥有 ETL 和基础设施。数据科学家拥有逻辑和需求，并最终拥有 16，000 个预先计算好的现成功能。业务单元选择了 400 个特性的子集，并仔细地将它们放在分析师的分析特性存储库中(也称为 Rosetta)。

事实上，数据可以在一个标准化的地方获得，这使该公司进入了一个分析的黄金时代。呼叫中心分析师发现了营销活动在实现他们的 KPI 中发挥巨大作用的细微差别。营销分析师发现了对客户产品使用的大量洞察。金融发现，光纤升级可以针对特定的社区，以减少流失。如果没有功能库，这些团队都不会有专业知识或时间将这些数据集汇集在一起进行分析。

# 经验教训

后来我离开了那家公司，去了更好的地方，但我一直记得那些教训。在接下来的几年里，我从事咨询工作，在那里我意识到我有这样的经历是多么幸运。最近，我加入了 Rasgo 的一个伟大团队，我们正在积极开发一个免费产品，帮助人们跟随我经历的相同旅程。当我与其他公司的领导会面时，我最常被问到的问题是，你在这一过程中学到了什么？

## **这是团队的努力**

大型组织以各自为政而闻名。他们也因重大的集中化努力以悲惨的失败而闻名。成功的关键是不要完全摇摆不定。我坚信技术、计算资源和“卓越中心”的集中化，但与此同时，我们也必须接受分散分析团队的力量，他们是各自领域的专家。从构建功能商店的角度来看，您需要弄清楚如何让集中式数据工程和分散式分析以协同的方式一起工作。

## **定义一次**

下面是冷酷无情的事实:*特性和度量的逻辑需要集中化*。如果你点头同意，你可能已经经历了分散分析师不得不重新发明轮子的灾难。如果您不同意，那么您可能经历过同样灾难性的情况，即定义和创建新的度量标准受到集中式工程过程的限制。定义的集中化是关键——但是您必须使用技术和业务流程来创建一个有效的反馈循环，以允许分散的分析师为指标创建过程做出贡献。我所说的“有效的反馈循环”并不是指:(1)投入一张 JIRA 门票，(2)为一项新功能等待 6 个月。如果你今天这样做，你需要重新评估。

## **高效计算**

尽可能在现代数据堆栈中处理。根据我的经验，我们有太多可用的工具，这实际上伤害了我们。数据不断地从仓库转移到 Alteryx、Tableau、SAS、Databricks、hdfs、S3 等等。这大大增加了 IT 成本、基础架构要求和管理复杂性。在扩展之前，将所有主要处理集中到一个地方。只有在特殊情况下，您才需要将数据卸载到不同的基础架构进行处理(例如，流和 IOT 数据)。

## **随处使用**

起初，你可能会注意到一个功能商店出售自己。如果您创建了正确的指标和特性，那么分析师自然会开始使用它们。然而，长期成功的秘诀是避免创建这些指标的孤岛和变体的诱惑。同样，关键是使用技术和业务流程来创建一个高效的反馈回路。您希望分析师能够进行试验，但是您必须提供一种快速而简单的方法来将新的指标推入商店。

# 入门的战术建议

## 巩固

你应该先挑一个仓库技术。当您做出此决定时，有许多与 IT 和最终用户相关的问题需要考虑。在大公司中，您可能有合理的理由保留多个数据存储解决方案。尽管如此，我们的目标应该是将尽可能多的数据整合到一个单一的数据仓库中，作为分析的唯一数据源。

过去几年的流行选择是像雪花这样的云解决方案。有时，公司仍然需要辅助系统来使用 spark 进行专门的数据处理，但最终结果是将最终结果存储在云仓库中。这方面的一个很好的例子是 IOT 传感器数据:分布式存储和 spark 是将数据解析成有意义的表格表示所必需的，这些表格表示随后被加载到仓库中。

## 雇佣优秀的工程师

整个计划背后的驱动力将是您的工程团队。如果我可以从头开始，我会推荐知道骨骼埋藏在哪里的内部雇员，以及可以带来经验和思想多样性的外部专家。

整合计算负载的工作对工程师的影响最大。在分散工作中，我最常看到的一件事是工程师制作一些简单的东西，如“虚拟变量”，并建立一个管道，将数据从雪花通过网络传输到 hdfs，然后通过 spark 加载到内存中。从那里，它运行几行 scala，将数据帧写回 hdfs，然后通过网络将结果加载回 Snowflake。这既昂贵又过于复杂。

如果你组建一个工程英雄团队，他们都会理解将数据处理整合到适当的基础设施上的好处，并一起工作。最后，当你的工程师推荐有助于协调他们疯狂复杂的世界的技术时，一定要听他们的。我注意到最近很流行。那时候它还不存在，但是不管工程师们说什么，相信他们。我们不得不使用一种叫做 UC4 的管道自动化技术，我可以有把握地说没有一个工程师喜欢使用这种技术。

## 不要煮沸海洋

您应该采用帕累托原则，关注代表您业务核心的关键数据元素。当然，整体的成功取决于用户的采用，所以你可能需要选择能为你赢得一些支持者的数据元素。

在我的例子中，我们的业务主要由订阅收入驱动。因此，与客户相关的订阅数据位于列表的顶部，因为“客户流失”是每个人都关注的指标。然而，营销部门(及其数百名分析师)需要成为测试和采用这一新概念的盟友。因此，我们与他们合作，找出哪些数据源和指标是*他们*所必需的。事实证明，第三方细分和受众分数至关重要，因此我们将它们作为第一阶段的必备要素。

另一件要记住的事情是，你可以选择从简单开始。例如，当我们构建第一个客户功能商店时，我们添加的一个元素是一个 source，它让我们知道客户在之前的 30 天、60 天和 90 天打了多少电话。还有一些更复杂的元素需要更多的工程设计——比如它们排在哪个队列中？通话持续了多长时间？他们等待了多长时间？我们知道我们最终需要这些数据元素，但是我们从简单的东西开始。

## 建造所有的管道

根据您的公司和现有的基础设施，这可能从相对简单到极其复杂。在我的例子中，工程师需要从大约 25 个不同的来源构建许多提取-加载管道，这样就可以从数据仓库中访问它们。

这也是一个关键的技术决策，应该与选择仓库的决策齐头并进。Airbyte、Fivetran、Integrate 和 Segment 是一些现代的例子，它们是 Pentaho、SSIS 或 Talend 等更传统解决方案的云原生替代方案。

## 定义一次

成功的关键之一是为您的度量和特性找到合适的定义。这比看起来更难。例如，流失率可能听起来很简单，但是那些不支付账单并因此自动断开连接的客户怎么办？你应该把这些算作客户流失吗？那些因为死亡而断开连接的客户呢？或者搬到你公司不服务的区域？也许你真正需要的是一个自愿流失指标和一个非自愿流失指标合并成一个总流失指标。

这里的要点是企业需要参与进来。显然，工程师拥有幕后的管道和处理代码，但是您需要一种方法让分析师来指导这个过程。

## 使民主化

最后一步是在任何地方使用这些数据。有时候，用户会自己涌向数据，因为数据本身就说明了一切。其他时候，你将不得不付出巨大的努力去追踪那些需要转变的报告、系统和遗留的“习惯”。此外，追踪和迁移遗留流程的工作无疑会发现您不知道的额外需求。所以，用一些问题来挑战自己，比如，为什么提交给董事会的季度总结不能建立在新数据的基础上？

像这样的项目最终失败的最大原因是因为公司输掉了民主化的战斗。我见过几次，由于之前所有步骤的沉没成本，它总是一场灾难。有时是因为对计算缺乏信任(见上文定义一次)。有时是由于糟糕的技术决策导致了技能差距(参见上文的整合)。

失败的另一个重要原因是缺乏反馈回路。不幸的是，这需要一段时间才能显现出来，所以最初成功的项目可能会在几个月后失败。事实是，业务总是在移动和变化，因此需要一个灵活的流程来控制未来的增强和发展。

例如，当我们推出我们的第一个功能商店时，该公司只销售了 3 条业务线。拥有所有 3 种功能的客户被确定为“三网合一”客户。不久，我们推出了第四个业务系列。于是，“四合一”的客户就诞生了。然而，度量定义需要仔细考虑是否需要更新，并且必须创建新的度量。如果你没有一个有效的反馈回路，新产品团队中的分析师将会出于必要开始报告他们自己的流失率。其他业务线可能希望开始排除和例外，因此他们将开始构建新指标的孤岛。这就是技术和业务流程需要让分析师更容易参与度量定义过程的地方。

## 结论

作为一名年轻的数据科学家，在这个术语普及之前开发一个功能商店是令人兴奋的。然而，我目光短浅，不知道这个概念对于企业级转变为数据驱动的文化有多重要。我非常感谢那些有远见的人，让我能够和他们一起工作，参与这样的旅程。我希望分享我的故事对那些正在经历类似旅程的人有所帮助和鼓励。想聊天随时伸手；你通常可以在空闲时找到我。我在[本地乐观](https://locallyoptimistic.com/community/)和[数据会谈中特别活跃。俱乐部](https://datatalks.club/)，你可以随时在[拉斯戈](http://rasgousergroup.slack.com)直接 ping 我。