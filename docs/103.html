<html>
<head>
<title>Good practices for neural network training: Identify, save, and document best models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络训练的良好实践:识别、保存和记录最佳模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identify-version-control-and-document-the-best-performing-model-during-training-62d7408eceef#2022-01-04">https://towardsdatascience.com/identify-version-control-and-document-the-best-performing-model-during-training-62d7408eceef#2022-01-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="5476" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tips-and-tricks" rel="noopener" target="_blank">提示和技巧</a></h2><div class=""><h1 id="3d3d" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">神经网络训练的良好实践:识别、保存和记录最佳模型</h1></div><div class=""><h2 id="bd94" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">介绍训练神经网络时<em class="ko">最佳模型</em>保存的良好实践，以及使用fastai和权重&amp;偏差的实际实现</h2></div><p id="4c00" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated"><strong class="kr ja"> <em class="ll">本文原载于我的</em> </strong> <a class="ae lm" href="https://nicjac.dev/posts/identify-best-model/" rel="noopener ugc nofollow" target="_blank"> <strong class="kr ja"> <em class="ll">个人博客</em> </strong> </a></p><p id="95a9" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在这篇文章中，我们将:</p><ul class=""><li id="f994" class="ln lo iq kr b ks kt kv kw ky lp lc lq lg lr lk ls lt lu lv bi translated">介绍<em class="ll">最佳模式</em>的概念</li><li id="d1a5" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated">讨论如何在培训期间识别、保存和记录<em class="ll">最佳模型</em></li><li id="e629" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated">探索如何利用fastai和Weights &amp; Biases(几乎)自动且毫不费力地完成所有这些工作</li></ul><h2 id="871c" class="mb mc iq bd md me mf dn mg mh mi dp mj ky mk ml mm lc mn mo mp lg mq mr ms iw bi translated">什么是“最佳模式”,我为什么要关心？</h2><p id="e16b" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">模型训练可以被看作是模型的后续版本的生成——在每一批之后，模型权重被调整，并且作为结果，模型的新版本被创建。每个新版本都将具有不同的性能水平(根据验证集进行评估)。</p><p id="3bd8" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如果一切顺利，训练和验证损失将随着训练时期的数量而减少。然而，模型的最佳执行版本(这里缩写为<em class="ll">最佳模型</em>)很少是在训练过程结束时获得的版本。</p><figure class="mz na nb nc gt nd gh gi paragraph-image"><div class="gh gi my"><img src="../Images/0a0f8fa936655d9785896431a03c9c3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*fos8X14BRDfIPXM1A6mSCg.png"/></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">过度拟合训练曲线的一个典型例子(图片由作者提供)</p></figure><p id="85c7" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">举一个典型的过度拟合案例——首先，随着训练的进行，训练和验证损失都在减少。在某一点上，验证损失可能开始增加，即使训练损失继续减少；从这一点开始，在训练过程中产生的后续模型版本会过度拟合训练数据。这些模型版本不太可能很好地推广到看不见的数据。在这种情况下，<em class="ll">最佳模型</em>将是在验证损失开始偏离时获得的模型。</p><p id="ef1f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">过度拟合是一个方便的例子，但是类似的观察也适用于模型训练的其他动态，例如局部最大值或最小值的存在。</p><h2 id="08aa" class="mb mc iq bd md me mf dn mg mh mi dp mj ky mk ml mm lc mn mo mp lg mq mr ms iw bi translated">在训练期间识别并保存<em class="ko">最佳模型</em></h2><p id="64ef" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">解决该问题的简单方法是在训练期间的每个时期之后保存我们的模型，并基于训练曲线回顾性地选择最佳版本。这种方法有几个明显的缺点:</p><ul class=""><li id="f1c4" class="ln lo iq kr b ks kt kv kw ky lp lc lq lg lr lk ls lt lu lv bi translated"><strong class="kr ja">存储空间</strong>:大型模型在保存时往往会占用大量的存储空间，文件大小会达到数百MB到GBs。用这个乘以历元数，你最终会得到一个相当大的存储空间，专门用来保存一个模型的所有版本。这很快就会成为问题，尤其是在远程训练模型时。</li><li id="d194" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated"><strong class="kr ja">计算影响</strong>:在每个历元之后保存一个模型将会影响整个训练时间——一些模型的序列化/导出可能计算量大且速度慢。</li></ul><figure class="mz na nb nc gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/39fa78aa1a60d92bf0d525a1e091a617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7SckyT4DM08PowyPIbAr9Q.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">天真的方法是持久化所有模型版本，而最好的方法是只持久化最近表现最好的模型(图片由作者提供)</p></figure><p id="a9a7" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">作为这种在训练期间保存所有模型版本的强力方法的替代，可以更有选择性。从上面我们知道，我们的<em class="ll">最佳模型</em>很可能与低验证损失相关联。因此，我们可以为选择我们的<em class="ll">最佳模型</em>制定一个标准:它必须比前一个候选模型具有更低的验证损失。作为伪代码:</p><pre class="mz na nb nc gt np nq nr ns aw nt bi"><span id="9cf1" class="mb mc iq nq b gy nu nv l nw nx">if current validation loss lower than candidate validation loss:</span><span id="6258" class="mb mc iq nq b gy ny nv l nw nx">    save model to disk overwriting previous candidate<br/>    set candidate validation loss to current validation loss</span></pre><p id="43ca" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这种方法的主要优点是:a)只有当验证损失比之前的最佳候选模型有所改善时，才导出新的模型；b)在任何给定时间，我们只有一个模型版本保存到存储中。因此，我们成功地解决了简单方法的两个缺点。</p><p id="eb6a" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">也许更重要的是，仅保存<em class="ll">最佳模型</em>还通过要求在培训开始之前决定性能评估方法来鼓励良好的实践，并且它消除了在单独的测试数据集上追溯评估模型的其他版本的诱惑。</p><h1 id="ad86" class="nz mc iq bd md oa ob oc mg od oe of mj kf og kg mm ki oh kj mp kl oi km ms oj bi translated">关于验证损失、替代指标和模型文档的注释</h1><p id="1be5" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">到目前为止，我们使用验证损失作为我们的目标度量，以在训练期间识别最佳模型<em class="ll">。你可能会问，为什么会有验证损失？事实上，它几乎总是在训练期间计算，这使得它成为一个方便的例子来说明本文中讨论的概念。</em></p><p id="6e8f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">然而，验证损失可能与您的特定用例或领域不相关，可以使用任何其他度量来代替。对于分类任务，准确性可能是一个不错的选择。同样，您可以选择目标指标，以确保<em class="ll">最佳模型</em>也能很好地推广到看不见的数据，例如在处理严重不平衡的数据集时使用<a class="ae lm" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html" rel="noopener ugc nofollow" target="_blank"> Matthews相关系数</a>。</p><p id="5316" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">无论您决定使用什么样的目标度量，记录模型的这个特定版本的其他方面也是很重要的。通常，这将包括培训期间跟踪的所有绩效指标。将这些信息与实际的模型工件保存在一起在以后会非常有用，例如，对从超参数搜索中获得的模型进行排序，或者在产品中部署时执行集成测试(在以后的文章中会有更多关于这方面的内容！).</p><h1 id="7b21" class="nz mc iq bd md oa ob oc mg od oe of mj kf og kg mm ki oh kj mp kl oi km ms oj bi translated">使用fastai轻松保存训练期间的最佳模型</h1><p id="aa4c" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">最佳模型保存的实现需要改变训练循环，以便监控目标度量并在检测到改进时触发模型保存。许多现代框架都内置了这种能力。这里，我们将重点关注fastai实现，但是类似的功能也可能适用于您选择的库。您仍然可以了解如何在实践中实现这一点。</p><p id="d0f3" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">如果你不知道<em class="ll"> fastai是什么，</em>它的<a class="ae lm" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank">官方描述</a>是<em class="ll"> : </em></p><blockquote class="ok ol om"><p id="c961" class="kp kq ll kr b ks kt ka ku kv kw kd kx on kz la lb oo ld le lf op lh li lj lk ij bi translated">fastai使用现代最佳实践简化了快速准确神经网络的训练</p></blockquote><p id="26d2" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">可以使用在训练的特定阶段调用的<a class="ae lm" href="https://docs.fast.ai/callback.core.html" rel="noopener ugc nofollow" target="_blank">回调方法</a>来修改和扩展fastai训练循环，例如在一个时期完成之后，或者在训练结束时。方便的是，<a class="ae lm" href="https://docs.fast.ai/callback.tracker.html#SaveModelCallback" rel="noopener ugc nofollow" target="_blank"> SaveModelCallback </a>恰好(几乎)做了我们需要的事情。</p><p id="5cfd" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">使用回调再简单不过了:python</p><pre class="mz na nb nc gt np nq nr ns aw nt bi"><span id="fa5d" class="mb mc iq nq b gy nu nv l nw nx">learner.fit_one_cycle(... ,cbs=[..., SaveModelCallback(monitor='valid_loss')])</span></pre><p id="0e1c" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">其中<code class="fe oq or os nq b">learner</code>是标准fastai <a class="ae lm" href="https://docs.fast.ai/learner.html#Learner" rel="noopener ugc nofollow" target="_blank">学习对象</a>。默认情况下，回调将跟踪验证损失，以确定何时保存新的<em class="ll">最佳模型</em>。使用<code class="fe oq or os nq b">monitor</code>参数将其设置为由您的<code class="fe oq or os nq b">learner</code>对象跟踪的任何其他指标。在训练期间的每个时期之后，将目标度量的当前值与先前的最佳值进行比较——如果是改进，则将模型保存在<code class="fe oq or os nq b">models</code>目录中(并覆盖先前的最佳候选，如果存在的话)。</p><p id="cadc" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">在幕后，回调试图判断改进是较小的值(如果目标度量包含<code class="fe oq or os nq b">loss</code>或<code class="fe oq or os nq b">error</code>)还是较大的值(其他的)。使用<code class="fe oq or os nq b">comp</code>参数可以覆盖这种行为。该模型使用fastai的<code class="fe oq or os nq b"><a class="ae lm" href="https://docs.fast.ai/learner.html#Learner.save" rel="noopener ugc nofollow" target="_blank">save_model</a></code>函数持久化，该函数是Pytorch本机<code class="fe oq or os nq b"><a class="ae lm" href="https://pytorch.org/docs/stable/generated/torch.save.html" rel="noopener ugc nofollow" target="_blank">torch.save</a></code>的包装器。</p><p id="55b7" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">内置回调不是我们所需要的<em class="ll">的原因是，它只会记录用于识别<em class="ll">最佳模型</em>的目标度量，而不会记录其他任何东西。它不会记录其他指标(例如准确性，如果<em class="ll">最佳模型</em>是基于验证损失确定的)。这可能没问题，但是考虑到我们的<em class="ll">最佳模型</em>可能会在某个地方被用作产品的一部分，尽可能多地描述它的特征是一个好主意。我组装了一个定制版本的<code class="fe oq or os nq b">SaveModelCallback</code>，它将记录fastai在培训期间跟踪的所有指标。的代码可以在这里找到<a class="ae lm" href="https://gist.github.com/nicjac/b363d2454ea253570a54e5e178e7666a" rel="noopener ugc nofollow" target="_blank">。</a></em></p><p id="2873" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这种定制版本的回调可以作为替代。它真正做的只是在内部跟踪与<em class="ll">最佳模型</em>相关联的度量字典(<code class="fe oq or os nq b">last_saved_metadata</code>)。如何利用这一点？一切将在下一节揭晓！</p><h1 id="fac3" class="nz mc iq bd md oa ob oc mg od oe of mj kf og kg mm ki oh kj mp kl oi km ms oj bi translated">自动记录带有权重和偏差的最佳模型</h1><p id="1790" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">在本地保存最佳模型是一个好的开始，但是如果你远程工作，或者进行大量的实验，它会很快变得难以操作。那么如何跟踪所创建的模型，以及它们相关的度量标准呢？这就是<a class="ae lm" href="https://wandb.ai/site" rel="noopener ugc nofollow" target="_blank">权重&amp;偏差</a>的来源。B是其中一种工具，它让你想知道没有它们你怎么能正常工作。虽然官方将其描述为“开发者至上的MLOps平台”，但我更愿意称之为MLOps的瑞士军刀。</p><p id="ec56" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">W&amp;B对于跟踪和比较实验非常有用。然而，出于本文的目的，我们主要对它几乎通用的版本控制能力感兴趣。在W&amp;B生态系统中，<a class="ae lm" href="https://wandb.ai/site/artifacts" rel="noopener ugc nofollow" target="_blank">工件</a>是可以被版本化的组件，可能连同它们的血统一起。模型可以被版本化为工件。</p><p id="6e1f" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">方便的是，fastai有一个内置的回调函数来与W&amp;B集成，它被恰当地命名为<code class="fe oq or os nq b"><a class="ae lm" href="https://docs.fast.ai/callback.wandb.html#WandbCallback" rel="noopener ugc nofollow" target="_blank">WandbCallback</a></code>。要使用它，需要初始化一个W &amp; B运行，并向学习者对象添加回调，如下所示:</p><pre class="mz na nb nc gt np nq nr ns aw nt bi"><span id="41ad" class="mb mc iq nq b gy nu nv l nw nx"># Import W&amp;B package</span><span id="3e8c" class="mb mc iq nq b gy ny nv l nw nx">import wandb</span><span id="849b" class="mb mc iq nq b gy ny nv l nw nx"># Initialize W&amp;B run (can potentially set project name, run name, etc...)</span><span id="3d5e" class="mb mc iq nq b gy ny nv l nw nx">wandb.init()</span><span id="024a" class="mb mc iq nq b gy ny nv l nw nx"># Add Callback to learner to track training metrics and log best models</span><span id="0106" class="mb mc iq nq b gy ny nv l nw nx">learn = learner(..., cbs=WandbCallback())</span></pre><p id="6967" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">回电的主要目的是将有关培训过程的有用遥测记录到您的W&amp;B帐户，包括环境信息和指标。当它与<code class="fe oq or os nq b">SaveModelCallback</code>结合使用时，神奇的事情发生了——在训练过程结束时，表现最好的模型将自动记录为W &amp; B运行的工件。</p><p id="e06e" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">默认的<code class="fe oq or os nq b">WandbCallback</code>有一个主要问题:与模型相关的元数据是在运行结束时记录的，而不是在保存<em class="ll">最佳模型</em>的时候。换句话说，元数据<strong class="kr ja">与保存的模型</strong>根本不对应，并且可能是误导性的(例如，当跟踪的度量由于过度拟合而在训练接近结束时偏离)。</p><p id="83f8" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这就是上一节讨论的定制<code class="fe oq or os nq b">SaveModelCallback</code>的用武之地。它将保存将模型与其<em class="ll">实际</em>元数据相关联所需的所有信息。为了利用这一点，还需要使用一个定制版本的<code class="fe oq or os nq b">WandbCallback</code>，可以在这里找到<a class="ae lm" href="https://gist.github.com/nicjac/9efb56cccd57f9c84910f02ccabf6fac" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="cf4e" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">这里突出显示了在自定义回调中所做的更改:</p><pre class="mz na nb nc gt np nq nr ns aw nt bi"><span id="30b1" class="mb mc iq nq b gy nu nv l nw nx">def after_fit(self):</span><span id="e1d8" class="mb mc iq nq b gy ny nv l nw nx">    if self.log_model:</span><span id="af5d" class="mb mc iq nq b gy ny nv l nw nx">        if self.save_model.last_saved_path is None:</span><span id="2b21" class="mb mc iq nq b gy ny nv l nw nx">        print('WandbCallback could not retrieve a model to upload')</span><span id="15f0" class="mb mc iq nq b gy ny nv l nw nx">    else:</span><span id="d2a9" class="mb mc iq nq b gy ny nv l nw nx">        log_model(self.save_model.last_saved_path, metadata=self.save_model.last_saved_metadata)</span><span id="3a0f" class="mb mc iq nq b gy ny nv l nw nx">        for metadata_key in self.save_model.last_saved_metadata:</span><span id="44f6" class="mb mc iq nq b gy ny nv l nw nx">            wandb.run.summary[f'best_{metadata_key}'] = self.save_model.last_saved_metadata[metadata_key]</span></pre><p id="daa6" class="pw-post-body-paragraph kp kq iq kr b ks kt ka ku kv kw kd kx ky kz la lb lc ld le lf lg lh li lj lk ij bi translated">因此，将自动发生以下情况:</p><ul class=""><li id="7dc6" class="ln lo iq kr b ks kt kv kw ky lp lc lq lg lr lk ls lt lu lv bi translated">记录到W&amp;B运行中的模型与包含正确度量值的元数据相关联</li><li id="6e7b" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated">将<em class="ll">最佳模型</em>的所有指标值添加到运行总结中，前缀为<code class="fe oq or os nq b">best_</code>。这允许根据各自<em class="ll">最佳模型</em>的性能对运行进行分类和比较</li></ul><figure class="mz na nb nc gt nd gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi ot"><img src="../Images/45fb2004b36b12f5ff810dea85872f98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LLoA7EWzrgSOifA0dnicfg.png"/></div></div><p class="ng nh gj gh gi ni nj bd b be z dk translated">记录权重和偏差的最佳模型。(左)包括关键指标的模型元数据；(右)W&amp;B项目中的模型按与其各自的<em class="ko">最佳模型</em>相关的<code class="fe oq or os nq b"><strong class="bd ou"><em class="ko">best_matthews_corrcoef</em></strong></code>元数据排序(图片由作者提供)</p></figure><h1 id="712a" class="nz mc iq bd md oa ob oc mg od oe of mj kf og kg mm ki oh kj mp kl oi km ms oj bi translated">包扎</h1><p id="ccdc" class="pw-post-body-paragraph kp kq iq kr b ks mt ka ku kv mu kd kx ky mv la lb lc mw le lf lg mx li lj lk ij bi translated">那么，我们从这篇文章中学到了什么？</p><ul class=""><li id="573f" class="ln lo iq kr b ks kt kv kw ky lp lc lq lg lr lk ls lt lu lv bi translated">只有在培训期间保存<em class="ll">最佳模式</em>才是有效的，并鼓励良好的实践</li><li id="2a42" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated">元数据，包括与<em class="ll">最佳模型</em>相关的关键指标，几乎与模型工件本身一样重要</li><li id="8ada" class="ln lo iq kr b ks lw kv lx ky ly lc lz lg ma lk ls lt lu lv bi translated">使用fastai和Weights &amp; Biases，可以自动保存和记录<em class="ll">最佳模型</em>。描述了两个定制回调函数来使这个过程更好(<a class="ae lm" href="https://gist.github.com/nicjac/b363d2454ea253570a54e5e178e7666a" rel="noopener ugc nofollow" target="_blank"> SaveModelCallback </a>和<a class="ae lm" href="https://gist.github.com/nicjac/9efb56cccd57f9c84910f02ccabf6fac" rel="noopener ugc nofollow" target="_blank"> WandbCallback </a>)。</li></ul></div></div>    
</body>
</html>