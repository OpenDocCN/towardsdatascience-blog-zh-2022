<html>
<head>
<title>Understanding MapReduce with the Help of Harry Potter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助《哈利·波特》理解MapReduce</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-mapreduce-with-the-help-of-harry-potter-5b0ae89cc88#2022-01-30">https://towardsdatascience.com/understanding-mapreduce-with-the-help-of-harry-potter-5b0ae89cc88#2022-01-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="715b" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">借助《哈利·波特》理解MapReduce</h1></div><div class=""><h2 id="aa69" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过一个简单的例子从头开始学习MapReduce</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/400805015b449387de434be9cc67d717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1DjoUXAjo5K02bD7ava8g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伊恩·杜利在<a class="ae ky" href="https://unsplash.com/s/photos/map-reduce?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="9934" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MapReduce是一种允许并行处理大型数据集的算法，即同时在多台计算机上处理。这大大加快了大型数据集的查询速度。</p><h1 id="ac59" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">我们用MapReduce做什么？</h1><p id="496f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">MapReduce最初是由Google推出的，用于高效地查询大量的搜索结果。然而，该算法真正出名是因为它在Hadoop框架中的使用。它在Hadoop分布式文件系统(HDFS)中存储大量数据，并使用MapReduce来查询或聚合TB或Pb范围内的信息。</p><p id="1ce2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们已经将《哈利·波特》小说的所有部分以PDF格式存储在<a class="ae ky" href="https://databasecamp.de/en/data/hadoop-explained" rel="noopener ugc nofollow" target="_blank"> Hadoop </a>中，现在想要统计书中出现的单个单词。这是一个经典的任务，分解成一个映射函数和一个归约函数可以帮助我们。</p><h1 id="8fdd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">以前是怎么做的？</h1><p id="49b2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在有可能将如此复杂的查询拆分到整个计算机集群中并并行计算它们之前，人们被迫一个接一个地运行完整的数据集。当然，数据集越大，查询时间越长。</p><p id="9f7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们已经在Python列表中逐字记录了哈利波特文本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="50d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过使用For循环遍历这个列表，并将每个单词从Python“Collections”模块加载到“Counter”中，来计算出现的单词数。然后，这个函数为我们进行单词计数，并输出十个最常用的单词。使用Python模块“Time”，我们可以显示我们的计算机执行这个函数花了多长时间。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mt l"/></div></figure><p id="073b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">据网站<a class="ae ky" href="https://wordcounter.io/blog/how-many-words-are-in-harry-potter/" rel="noopener ugc nofollow" target="_blank"> wordcounter.io </a>统计，哈利波特第一部共有76944个单词。由于我们的例句只有20个单词(包括句号)，这意味着我们必须重复例句大约3850次(76944/20 ~ 3847)才能得到一个和哈利波特第一本书一样多的单词列表:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv mt l"/></div></figure><p id="cd71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的函数需要64毫秒来遍历第一部分的所有单词，并计算它们出现的频率。如果我们对所有总共3397170个单词的哈利波特书籍进行同样的查询(来源:<a class="ae ky" href="https://wordcounter.io/blog/how-many-words-are-in-harry-potter/" rel="noopener ugc nofollow" target="_blank"> wordcounter.io </a>)，总共需要2.4秒。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mv mt l"/></div></figure><p id="5d7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个查询需要相对较长的时间，对于较大的数据集，自然会变得越来越长。加快功能执行的唯一方法是为计算机配备更强大的处理器(CPU)，即改进其硬件。当一个人试图通过改进设备的硬件来加速算法的执行时，这被称为<strong class="lb iu">垂直缩放</strong>。</p><h1 id="e0d4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MapReduce算法是如何工作的？</h1><p id="300f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在MapReduce的帮助下，通过将任务拆分成更小的子任务，可以显著加快这样的查询。这反过来又有一个优点，即子任务可以在许多不同的计算机之间划分和执行。这意味着我们不必改进单个设备的硬件，而是可以使用许多功能相对较弱的计算机，并且仍然可以减少查询时间。这种方法被称为<strong class="lb iu">水平缩放</strong>。</p><p id="982f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们回到我们的例子:到目前为止，我们已经形象地以这样一种方式进行，我们阅读了所有的哈利波特书籍，并简单地在我们阅读的每个单词后将单个单词的计数表扩展一个计数。这样做的问题是我们不能并行化这种方法。假设有第二个人想要帮助我们，她不能这样做，因为她需要我们正在处理的计数表来继续。只要她没有，就支持不了。</p><p id="a3a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，她可以支持我们，从哈利波特系列的第二部分开始，为第二本书创建一个单独的清单。最后，我们可以合并所有单独的计数表，例如，将单词“Harry”在所有计数表上的出现频率相加。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/8d63e533358e61b760c1d322fcae8f4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w3bGQ4wpU7OMsWMfXxfGjw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="93ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这也使得让一个人在每本哈利波特书上工作相对容易横向扩展任务。如果我们想工作得更快，我们也可以让更多的人参与进来，让每个人都做一章。最后，我们只需要把每个人的所有结果结合起来，就可以得出一个整体的结果。</p><h1 id="45f6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Python中的MapReduce示例</h1><p id="ebbd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">总之，我们需要两个函数一个映射器和一个缩减器来用Python编码这种方法。我们以这样一种方式定义映射器，它为接收到的每个单词返回一个字典，以单词为关键字，值为1:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx mt l"/></div></figure><p id="c204" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与我们的示例类似，映射器返回一个计数列表，上面写着:“传递给我的单词恰好出现一次”。在第二步中，reducer将所有单独的计数表合并成一个大的总计数表。它区分了两种情况:如果传递给它的单词已经出现在它的大计数列表中，那么它只是在相应的行中添加一个破折号。如果新单词还没有出现在列表中，reducer只需在大计数列表中添加一个新行。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mu mt l"/></div></figure><p id="0f7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们合并这两个子任务，与之前相同的查询只需要1.4秒:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="my mt l"/></div></figure><p id="898e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，使用MapReduce算法，我们能够在不进行任何水平或垂直缩放的情况下，将所有哈利波特书籍的查询时间减少一半以上。但是，如果1.4秒的查询时间对于我们的应用程序来说仍然太长，我们可以简单地任意拆分单词列表，并在不同的计算机上并行运行映射器，以进一步加快这个过程。没有MapReduce算法，这是不可能的。</p><h1 id="1e76" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MapReduce的缺点</h1><p id="07dd" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们的例子令人印象深刻地表明，我们可以使用MapReduce更快地查询大量数据，同时为水平缩放准备算法。然而，MapReduce并不总是可以使用，或者根据使用情况的不同也会带来一些缺点:</p><ul class=""><li id="8ac8" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">某些查询无法引入MapReduce架构。</li><li id="dc5c" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">地图功能彼此独立运行。因此，这些进程不可能相互通信。</li><li id="c9cf" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">分布式系统比单台计算机更难管理和控制。因此，应该仔细考虑是否真的需要计算集群。Kubernetes软件工具可用于控制计算机集群。</li></ul><h1 id="ada0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">这是你应该带走的东西</h1><ul class=""><li id="36b1" class="mz na it lb b lc mn lf mo li nn lm no lq np lu ne nf ng nh bi translated">MapReduce是一种允许并行快速处理大型数据集的算法。</li><li id="f4b7" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">MapReduce算法将一个大的查询拆分成几个小的子任务，然后可以在不同的计算机上分发和处理这些子任务。</li><li id="b9d2" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">不是每个应用程序都可以转换成MapReduce方案，所以有时甚至不可能使用这种算法。</li></ul></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="fce4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nx">如果你喜欢我的作品，请在这里订阅</em><a class="ae ky" href="https://medium.com/subscribe/@niklas_lang" rel="noopener"><em class="nx"/></a><em class="nx">或者查看我的网站</em> <a class="ae ky" href="http://www.databasecamp.de/en/homepage" rel="noopener ugc nofollow" target="_blank"> <em class="nx">数据大本营</em> </a> <em class="nx">！还有，medium允许你每月免费阅读</em> <strong class="lb iu"> <em class="nx"> 3篇</em> </strong> <em class="nx">。如果你想让</em><strong class="lb iu"><em class="nx"/></strong><em class="nx">无限制地访问我的文章和数以千计的精彩文章，请不要犹豫，通过点击我的推荐链接:</em><a class="ae ky" href="https://medium.com/@niklas_lang/membership" rel="noopener">【https://medium.com/@niklas_lang/membership】</a>每月花$<strong class="lb iu"><em class="nx">5</em></strong><em class="nx">获得会员资格</em></p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ny"><a href="https://medium.com/@niklas_lang/what-are-deepfakes-and-how-do-you-recognize-them-f9ab1a143456" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">什么是deepfakes，怎么识别？</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">Deepfakes是使用深度学习模型人工创建的视频、图像或音频文件。比如说…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om ks ny"/></div></div></a></div><div class="on oo gp gr op ny"><a href="https://medium.com/@niklas_lang/what-are-convolutional-neural-networks-cnn-faf948b5a98a" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">理解卷积神经网络</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">卷积神经网络(CNN或ConvNet)是神经网络的一个子类型，主要用于神经网络的分类</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="oq l oj ok ol oh om ks ny"/></div></div></a></div><div class="on oo gp gr op ny"><a href="https://medium.com/@niklas_lang/intuitive-guide-to-artificial-neural-networks-5a2925ea3fa2" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd iu gy z fp od fr fs oe fu fw is bi translated">人工神经网络直观指南</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">人工神经网络(ANN)是人工智能和人工智能领域最常用的术语</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="or l oj ok ol oh om ks ny"/></div></div></a></div></div></div>    
</body>
</html>