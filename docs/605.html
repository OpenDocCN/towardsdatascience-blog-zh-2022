<html>
<head>
<title>What Actually Makes a Good Category?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么才是好的类别？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-actually-makes-a-good-category-b30069305633#2022-01-20">https://towardsdatascience.com/what-actually-makes-a-good-category-b30069305633#2022-01-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="890d" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">什么才是好的类别？</h1></div><div class=""><h2 id="8678" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak"> <em class="kf">做出有意义类别的5个初始步骤</em> </strong></h2></div><p id="7e4b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">简单的事情看起来很容易。不是吗？以条形图为例，它包含引人入胜的类别和引人注目的数字。一个好的图表可以在7秒钟内讲述一个故事，使企业领导人能够自信地领导。但是在这个过程中，很多事情都是理所当然的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/ffa21a117ba5e8fd64645ae69b553c53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*0wwHeuYS3gMWT3HOC91cug.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">随机公司战略(图片由作者提供)</p></figure><p id="a61c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于数据科学家来说，在这个敏感的地方获取分类数据并不容易。类别可能跨越不切实际的类别数量，范围不相等，或者严重不平衡。这些数据可能根本就不是类别！为了有意义，类别必须经历大量的解释、争论、重要性测试和最终分组(或重组)。</p><p id="d969" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">下面我将描述以下<strong class="ki ir"> 5个步骤来选择好的分类变量</strong>，最终用于二元分类模型(预测医院索赔是否会被拒绝):</p><ol class=""><li id="5e89" class="ls lt iq ki b kj kk km kn kp lu kt lv kx lw lb lx ly lz ma bi translated">频率和目视检查(以特征工程为例)</li><li id="34b2" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">独立性测试(卡方检验)</li><li id="710b" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">相关强度(克莱姆氏V)</li><li id="07e0" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">功能选择(选择最佳)</li><li id="b2a5" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">特征重要性(使用随机森林分类器)</li></ol><p id="b1a6" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们还将触及分类数据的一些常见困境:</p><ol class=""><li id="549e" class="ls lt iq ki b kj kk km kn kp lu kt lv kx lw lb lx ly lz ma bi translated">高基数</li><li id="251f" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">阶级不平衡</li><li id="1d59" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">联想vs实力</li><li id="5870" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb lx ly lz ma bi translated">真正的相关性</li></ol><p id="9663" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="mg">注意:以下所有数据都是出于HIPAA目的由随机生成器生成的。</em></p><h2 id="c82c" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">1.频率和目视检查</h2><p id="cfd3" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">理解类别的第一步是看它们的频率。我们将使用分类CPT代码作为例子。CPT是5位数的字母数字代码，代表临床诊疗过程中执行的任何程序。大多数就诊有1-2个CPT代码，有些没有，有些很多。</p><p id="1dfb" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">以下是7次虚构患者就诊的CPT代码。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/dfbe7206a4106c8d21dc60ba3f209419.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*jGCDYvv-a_vSXk1YPNtFOg.png"/></div></figure><p id="e24d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在一个非常大的数据集中，CPT代码的变化太多，无法以有意义的方式显示(这里实际上有137，376个<strong class="ki ir">唯一的</strong> <strong class="ki ir">类别</strong>)。</p><p id="7c36" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们看看它们的频率。以下是十大最常见的CPT组合。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="9d3a" class="mh mi iq nh b gy nl nm l nn no">dataset.cpt_code.value_counts().head(10)/dataset.account.count()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi np"><img src="../Images/381c0c1f7890ad0e0153055d42f2f046.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*8JwhvH3epOhtr5mkbgQy_Q.png"/></div></figure><p id="e8a9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">猜猜Q3014对应什么？远程保健。最近很常见。最常见的服务类型是[无]——没有服务(24%)。那很有趣。其余CPT组合出现的频率为4%或更低。这揭示了医学的一些特殊之处:<strong class="ki ir">患者就诊非常独特。</strong></p><p id="d667" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在数据方面，这些CPT组合具有<strong class="ki ir">高基数</strong>，这将使预测建模具有挑战性。太多的类别会使可视化变得混乱，阻碍训练速度，并且会使数据溢出。<strong class="ki ir">像CPT代码这样的类别的维数减少</strong>是一项广泛但有价值的工作。</p><p id="b888" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为类别提供更广泛、更有意义的标签不仅支持降维，还能突出关键特征。我们可以将许多CPT代码归为一类“临床经验”例如，代码Q3014、99441、99442、99443都与远程医疗访问有关(将其标记为“远程医疗”)。CPT代码80053、85025、86359、86360都对应于实验室测试(标记为“其他实验室”)。</p><p id="b086" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这样做，我们有效地将近138，000个类别缩减为大约30个“临床体验”这首先是商业意义，其次是数据科学意义。我们现在可以看到哪些CPT类别正在影响拒绝(我们的结果变量)以及影响的程度。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="6774" class="mh mi iq nh b gy nl nm l nn no">pd.DataFrame({‘count’:dataset.cpt_min_categories.value_counts(),‘denied’:dataset.cpt_min_categories[dataset.claim==1].value_counts(),\<br/> ‘frequency’:(dataset.cpt_min_categories[dataset.claim==1].value_counts()/dataset.cpt_min_categories.value_counts())*100}).sort_values(by=’frequency’,ascending=False)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/5f7518cbf7b1aa1b43ceb6785eb2b1c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*ygeEEAle5CJ6sf70vDDZbw.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">五大CPT类别</p></figure><p id="330f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在这个虚构的数据集中，麻醉声称创造了最多的否认。为什么会这样？这些案件更复杂吗？这些程序的编码规则最近有变化吗？我们必须进一步探索。</p><h2 id="6dbb" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">保持简单:数数就好</h2><p id="400f" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">或者，我们可以对CPT代码进行计数，而不是对它们进行分组。例如，有多少次访问生成了1个CPT代码、2个CPT代码等。？这很简单，但它有助于深入了解每个患者体验的相对强度，也潜在地了解其临床复杂性。</p><p id="fb32" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以创建两个新的类别:<strong class="ki ir"> cpt_count </strong>用于每次患者就诊的cpt代码计数，和<strong class="ki ir"> cpt_count_10 </strong>相同，但是将超过10个CPT代码的就诊分组在最后的第10个类别中。我这样分组是因为<strong class="ki ir"> cpt_count </strong>一直延伸到91次(即一名患者在一次就诊中进行了91次手术)。将他纳入最多只有10个CPT代码的患者中会有错吗？让我们检查分布。</p><p id="e926" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了创建上面的两列，我们可以实现以下代码:</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="c4e6" class="mh mi iq nh b gy nl nm l nn no">def cpt_count(x):<br/>    """Creates the cpt_count and cpt_count_10 variables<br/>    Input: Entire dataframe (dataset)<br/>    Output (integers): <br/>    1. cpt_count: counts of all CPT codes<br/>    2. cpt_count_10: counts of all CPT codes where &gt;9 codes is bucketed as 10 <br/>    """<br/>    x['cpt_count'] = x['cpt_code'].where(x['cpt_code'].astype(str)!="['None']",'0')<br/>    x['cpt_count'] = x['cpt_count'].where(x['cpt_count']=='0',[len(i) for i in x['cpt_count']])<br/>    x['cpt_count'] = x['cpt_count'].astype(int)<br/>    x['cpt_count_10'] = [10 if i&gt;9 else i for i in x['cpt_count']]<br/>    x['cpt_count_10'] = x['cpt_count_10'].astype(int)<br/>    return x</span><span id="c4b2" class="mh mi iq nh b gy nr nm l nn no">dataset = cpt_count(dataset)<br/>dataset[['cpt_code','cpt_count','cpt_count_10']].head(10)</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/b86f48367b1784ce84f2fee7a11eb635.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*c1pjA3Pnr7nrLXsgU0TnOw.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">CPT代码计数，以及最大计数为10的CPT代码计数</p></figure><p id="601e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在让我们用下面的代码将<strong class="ki ir"> cpt_code_10 </strong>和我们的拒绝结果变量可视化在一个条形图中:</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="be5f" class="mh mi iq nh b gy nl nm l nn no">table = pd.pivot_table(dataset[['cpt_count_10','claim']].groupby(['cpt_count_10','claim'])['claim'].count().reset_index(name='count'),index=['cpt_count_10'],columns='claim')<br/>ax = table.plot(kind='bar', figsize=(10,6),fontsize=15)</span><span id="addc" class="mh mi iq nh b gy nr nm l nn no">ax.set_title('Number of Claims by CPT Buckets',fontsize= 20) # title of plot<br/>ax.set_ylabel('Number of Claims', fontsize=16)<br/>ax.set_xlabel('CPT Buckets (0 - 10+ codes)',fontsize=16)</span><span id="c97d" class="mh mi iq nh b gy nr nm l nn no">L=ax.legend(fontsize=12)<br/>L.set_title('Type of Claim',prop={'size':12})<br/>L.get_texts()[0].set_text('Clean Claim')<br/>L.get_texts()[1].set_text('Denied Claim')</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/352ad02129b556b68ec27890537af904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*lD1XfxTLvp89Q1PSCP27rg.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">干净/被拒绝索赔的CPT类别分布</p></figure><p id="9f78" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以看到大多数访问只生成0-2个CPT代码。这远远超过了扩展到91个CPT码的“10个或更多”桶。两个索赔结果显示大致相同的分布。但也许最有趣的是，这张图表揭示了索赔之间的阶级不平衡。下面我们将评估这种常见分布背景下的分类相关性。</p><h2 id="1fa1" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">2.卡方检验</h2><p id="015c" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">卡方检验评估两个标称变量之间的独立性，每个变量都有两个或更多可能的值。对于分类变量来说，这是一个很好的初始测试，因为它测试了一个变量中的比例是否不同于另一个变量(结果变量)。</p><p id="1a3b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">比如评价是否喜欢披萨(是/否)取决于是不是某个性别(男/女)。这个测试不能告诉你男性比女性更喜欢比萨饼的程度(影响大小)，只能告诉你男性和女性喜欢比萨饼的程度不同。</p><p id="a7dc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">卡方的一个很好的特点是类别不平衡不会影响结果。在轻微不平衡(1:2)或甚至严重类别不平衡(1:1000)的情况下，两个结果都可能使卡方统计接近于零(无关联)。然而，影响卡方结果的是样本大小。在大样本中，即使组间最小的差异也会产生显著的卡方结果，p值远低于0.001。这是p值的一个固有特征，因为它表明<em class="mg">您偶然获得卡方统计的可能性有多大。</em></p><p id="2304" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">例如，让我们首先创建一个列联表来执行卡方检验，以比较入院类型(急诊、住院、门诊)的数量与我们的二元拒绝状态结果(0 =索赔未被拒绝，1 =索赔被拒绝)。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="1dd7" class="mh mi iq nh b gy nl nm l nn no">patient_type = pd.crosstab(dataset[‘patient_type’], dataset[‘claim’])/100<br/>patient_type</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/39af00dee7d7a5a68f3793b97f2ced87.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*-LIUKVz2PQYgcFU7Xf_4Rw.png"/></div></figure><p id="3751" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">再一次，我们看到主张(拒绝结果)是不平衡的，但是没关系。让我们通过评估检验统计量和p值来评估这些组之间的独立性。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="b3a1" class="mh mi iq nh b gy nl nm l nn no">stat, p, dof, expected = chi2_contingency(patient_type)<br/>  <br/># interpret p-value<br/>alpha = 0.05<br/>print("The p-value is: " + str(p))<br/>print('The test statistic is: '+ str(stat))<br/>print('The degrees of freedom are: '+str(dof))<br/>print(' ')<br/>if p &lt;= alpha:<br/>    print('Samples are dependent (reject H0); proportions of patient types are different between clean and denied claims')<br/>else:<br/>    print('Samples are independent (H0 holds true); proportions of patient types are the same between clean and denied claims')</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/f37cd54d1768908c1528c82c8335c3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*4CQiabbYi7xz97Qo-kCddQ.png"/></div></figure><p id="8bfa" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">结果表明，患者类型和我们的拒绝结果之间存在一定的相关性。仅从列联表中，我们可以看到住院病人和急诊病人的频率相似，但门诊病人的频率不同。当值的总数超过1000，样本是独立的，并且交叉表中没有单元格少于5个时，适合使用卡方检验(改为应用Fisher精确检验)。</p><h2 id="c7d1" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">3.克莱姆氏V</h2><p id="2322" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">群体之间的独立性可能会告诉我们什么是有意义的不同，但如果你真的在追求差异的<em class="mg">强度</em>呢？对于分类变量和结果，我们可以求助于克莱姆V或比值比(or)。</p><p id="e37e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">OR通常用于2x2表，而Cramer的V可以评估跨多个级别的类别，因此可以评估更大的表。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/f00cc271695b15db41bdd0bbdf56a015.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/1*vyuy98hzg4usdugxE0XwXQ.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">优势比的好表格</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/79b1368a9126f9e114309248414abab2.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*Z90isLi8-froM2KJl_WC6w.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">克莱姆的V的一个好表</p></figure><p id="be0c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">OR不是“赔率”的度量，而是2赔率的比值；例如，暴露组与非暴露组发生事件的几率。但是OR和Cramer的V都用来报告暴露和事件之间的关联强度。两者都报告为大于1的值，值越高，关联越大。</p><p id="ecd7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">Cramer的V还结合了卡方统计，因此这是一个很好的后续测试。它采用公式:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/03246a73ef69c51cbd16d14a3eb761d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*U0lUIVPScsjWj3WDW5LvLA.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">克莱姆氏V</p></figure><p id="94da" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">其中<em class="mg"> k </em>代表行数或列数(取最大值)，<em class="mg"> N </em>是整个样本大小，<em class="mg"> X </em>是卡方统计量。</p><p id="4bd3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以用python实现Cramer的V函数:</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="38cf" class="mh mi iq nh b gy nl nm l nn no">def cramers(x, y):<br/>    """This is the Cramer's V statistic<br/>        Input: X feature variable, y target variable<br/>        Output: Provides association strength from the chi-square statistic<br/>        """<br/>    x_length = len(x.value_counts().index)<br/>    y_length = len(y.value_counts().index)<br/>    <br/>    # getting highest row/column total - 1<br/>    if x_length &lt; y_length:<br/>        rc = x_length - 1<br/>    else: rc = y_length - 1<br/>    <br/>    chi_data = pd.crosstab(x, y)<br/>    stat, p, dof, expected = chi2_contingency(chi_data)<br/>    <br/>    # total sample size<br/>    n = chi_data.sum().sum()<br/>    <br/>    cramers =  np.sqrt((stat)/(n * rc))<br/>    return print("The Cramer's V correlation strength is:", round(cramers, 4))</span></pre><p id="af2d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于我们之前的患者类型变量，我们可以看到:</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="7788" class="mh mi iq nh b gy nl nm l nn no">cramers(dataset['patient_type'], dataset['claim'])</span></pre><p id="5b79" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">退货:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/1f152c6b036f421b89d431dd920416d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*Nw0Y1aeUCqNqyplH3wpd6w.png"/></div></figure><p id="7400" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这表明，尽管患者类型与我们的结果变量之间存在有意义的差异(如卡方检验所示)，但没有很强的相关性。</p><p id="cf29" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于克莱姆的V:</p><ul class=""><li id="6438" class="ls lt iq ki b kj kk km kn kp lu kt lv kx lw lb oa ly lz ma bi translated">&gt; . 1表示小的影响</li><li id="f011" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb oa ly lz ma bi translated">&gt; . 3代表中等效果</li><li id="ee1c" class="ls lt iq ki b kj mb km mc kp md kt me kx mf lb oa ly lz ma bi translated">&gt; . 5代表大效果</li></ul><p id="3b6c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">有兴趣查看所有变量的克莱姆V结果吗？创建一个循环，评估所有Cramer的V分数，并将它们(及其变量名)分配到一个列表中作为一个图。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="ea88" class="mh mi iq nh b gy nl nm l nn no">column_list = ['pat_sex', 'patient_type',<br/>       'department_name', 'adm_type', 'specialty', 'attending_prov',<br/>       'financial_class_name', 'primary_payor', 'current_financial_class',<br/>       'current_payor', 'collection_agency','cpt_count_10', 'cpt_categories', 'cpt_min_categories',<br/>       'rev_categories', 'rev_min_categories', 'rev_count_10',<br/>       'icd_10_min_categories', 'icd_10_count', 'icd_10_count_10',<br/>       'pharm_categories', 'pharm_count', 'pharm_count_10',  'los_cat',<br/>               <br/>               'pat_dob_decade']</span><span id="61df" class="mh mi iq nh b gy nr nm l nn no">cramer_list = []<br/>for i in column_list:<br/>    result = cramers(dataset[i], dataset['claim'])<br/>    cramer_list.append(result)</span><span id="df44" class="mh mi iq nh b gy nr nm l nn no">cramers_list = pd.DataFrame({'column': column_list, 'cramer_value':cramer_list})</span><span id="c129" class="mh mi iq nh b gy nr nm l nn no">cramers_list.sort_values(by='cramer_value',ascending=True).plot(y='cramer_value',x='column',kind='barh', \<br/>                                                                title='Strongest Correlation with Denial Rate')</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cf9cdaeb2e2911540021be7217eab4f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*7s_4lX05qV6Z3zcU0H5LTw.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">所有分类特征的Cramer V评分汇总</p></figure><p id="69df" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在这里，变量<strong class="ki ir"> rev_categories </strong>(收入代码)<strong class="ki ir"> cpt_categories </strong> (cpt代码)和<strong class="ki ir">attenting _ prov</strong>(护理提供者)在确定索赔是否会被拒绝方面最有希望。从商业角度来看，这也是有意义的；收入代码告诉付款人提供了什么服务以及多少钱，CPT代码告诉提供了什么服务，并且主治医生经常在所有患者就诊时签字。</p><h2 id="33c5" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">4.功能选择(选择最佳)</h2><p id="4e25" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">如果您的数据集包含许多分类变量，您可能会好奇哪一个对您的结果变量影响最大。这种特征选择剔除了非解释性变量，以提高模型性能。其次，它还提供了对功能工程工作可能提供高ROI的洞察。正如我们将会看到的，在精选测试中排名靠前的分类表现者可以被拆开、重新分类或重新加权，以进一步增强他们的影响力。</p><p id="feb5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">SelectKBest <strong class="ki ir"> </strong>函数可以接受卡方作为评分函数。它计算<em class="mg"> X </em>和<em class="mg"> y </em>的每个特征之间的<em class="mg"> X </em>统计量(您的类标签)。大值意味着该特征与<em class="mg"> y </em>非随机相关，因此可能提供重要信息。您可以强制模型只选择<em class="mg"> k </em>个最相关的特征来保留。</p><p id="d032" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">实际上，您需要为分类变量中的所有类别获取单独的特征名称。在这里，我创建了一个ColumnTransformer，它将OneHotEncoder应用于我的所有分类变量。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="e75f" class="mh mi iq nh b gy nl nm l nn no">col_transformer = ColumnTransformer(transformers=[('ohe', OneHotEncoder(handle_unknown='ignore'), <br/>                  ['pat_sex','patient_type','department_name','adm_type','financial_class_name','primary_payor',<br/>                       'collection_agency','cpt_count_10','cpt_min_categories','rev_count_10','rev_min_categories',<br/>                       'icd_10_count_10','icd_10_min_categories','pharm_categories','pharm_count_10','los_cat'])],<br/>                                   remainder='passthrough')</span></pre><p id="6730" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然后，我可以通过将我的变量转换成一个数组，然后调用get_feature_names()来创建这些特性名</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="4928" class="mh mi iq nh b gy nl nm l nn no">test = dataset[['pat_sex','patient_type','department_name','adm_type','financial_class_name','primary_payor',<br/>                       'collection_agency','cpt_count_10','cpt_min_categories','rev_count_10','rev_min_categories',<br/>                       'icd_10_count_10','icd_10_min_categories','pharm_categories','pharm_count_10','los_cat']].astype(str)</span><span id="4ff4" class="mh mi iq nh b gy nr nm l nn no">codes = col_transformer.transform(test).toarray()<br/>feature_names = col_transformer.get_feature_names()</span><span id="4595" class="mh mi iq nh b gy nr nm l nn no">feature_names</span></pre><p id="c8ed" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这里有许多单独的特性名称:16个变量乘以它们包含的类别数=特性名称的数量。很多。</p><p id="b2db" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在我们实现SelectKBest函数。我们将下载这些包，将卡方作为我们的评分函数，并查看所有变量的排名分数(您可以让k=5只查看前5个变量)。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="dba4" class="mh mi iq nh b gy nl nm l nn no">from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif</span><span id="90c6" class="mh mi iq nh b gy nr nm l nn no">select = SelectKBest(score_func=chi2, k='all')<br/>z = select.fit_transform(X_transformed, test_y)</span></pre><p id="1c8d" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">现在，模型已经拟合好了，让我们找出所有特性名称的范围以及每个特性的得分。我们可以通过把它们组合成熊猫的数据框架来更好地形象化它们。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="2382" class="mh mi iq nh b gy nl nm l nn no">feature_num = []<br/>feature_name = []<br/>feature_score = []<br/>for i in range(len(select.scores_)) and range(len(feature_names)):<br/>    feature_num.append(i)<br/>    feature_name.append(feature_names[i])<br/>    feature_score.append(select.scores_[i])</span><span id="8463" class="mh mi iq nh b gy nr nm l nn no">kbest = pd.DataFrame({'num':feature_num, 'name': feature_name, 'score':feature_score})</span><span id="6cd0" class="mh mi iq nh b gy nr nm l nn no">kbest.sort_values(by='score', ascending=False)</span></pre><p id="3fd9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">最后，我们可以利用<a class="ae oc" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"> re包</a>来更新字符和字符串。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="8575" class="mh mi iq nh b gy nl nm l nn no">import re<br/>import matplotlib.pyplot as plt</span><span id="16af" class="mh mi iq nh b gy nr nm l nn no">types = []<br/>for i in kbest.name:<br/>    result = re.search('__x(.*)_', i)<br/>    types.append(result.group(1))</span><span id="8c64" class="mh mi iq nh b gy nr nm l nn no">kbest = pd.concat([kbest,pd.DataFrame({'types':types})], axis=1)</span><span id="c732" class="mh mi iq nh b gy nr nm l nn no">counts = []<br/>desc = []<br/>for count, i in enumerate(test.columns):<br/>    counts.append(count)<br/>    desc.append(i)<br/>lookups = pd.DataFrame({'types':counts, 'variable':desc})<br/>lookups['types'] = lookups['types'].astype(str)</span><span id="d04f" class="mh mi iq nh b gy nr nm l nn no">kbest = kbest.merge(lookups, on='types')</span><span id="a6a2" class="mh mi iq nh b gy nr nm l nn no">kbest.groupby('variable').score.sum().sort_values(ascending=True).plot(kind='barh',  title='Chi-Square statistic: Higher means related to denial rate')</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi od"><img src="../Images/74d26a464def66838071a149f5d3a55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*7x_cbDq-oE29uXwSbqLHCA.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">所有变量的卡方统计</p></figure><p id="1f5a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这些卡方统计值相当高，会影响我们的结果变量。这也被我们的Cramer的V结果和我们早期的可视化所证实。画面在这里变得更加清晰:准确的税收代码和CPT代码是预测被拒绝索赔的核心。</p><h2 id="79a3" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">5.特征重要性(使用随机森林分类器)</h2><p id="a10c" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">在像随机森林这样的基于树的模型中，决策分割是从每个特征(在其他特征的随机子集之间)中做出的，这最大程度地减少了杂质(基本上是不确定性)。所有预测的树集合在一起形成随机森林。尽管有些树是不相关的，但它们一起保护彼此免受个别错误的影响，并优于它们各自的组成树。</p><p id="57ca" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">特征重要性将最能减少杂质的特征排列为最高。尽管有用且实现简单，但对于基数高的变量，重要性往往会增加。如果您的变量具有高基数，那么可以利用<a class="ae oc" href="https://explained.ai/rf-importance/" rel="noopener ugc nofollow" target="_blank">排列重要性</a>。</p><p id="f539" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了评估特征的重要性，我们简单地从随机森林分类器模型中调用feature_importances_ right。</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="19bc" class="mh mi iq nh b gy nl nm l nn no"># instantiate RFC, assign coefficients to coefs, and zip together with column names<br/>rfc = RandomForestClassifier(random_state=0)<br/>coefs = rfc.feature_importances_<br/>zipped = zip(clean_columns.iloc[:,0], coefs)</span><span id="4bb0" class="mh mi iq nh b gy nr nm l nn no"># create a dataframe of just the top 20 most important features<br/>feature_imp = pd.DataFrame(zipped, columns=['feature','importance']).sort_values(by='importance',ascending=False).head(20)</span></pre><p id="6c81" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">然后我们可以想象这些结果</p><pre class="ld le lf lg gt ng nh ni nj aw nk bi"><span id="519c" class="mh mi iq nh b gy nl nm l nn no">fig, ax = plt.subplots(figsize=(10,4))<br/>ind = range(0,10)<br/>ax.barh(ind, feature_imp['importance'].values[0:10],<br/>       align='center',alpha=0.8)<br/>ax.set_yticks(ind)<br/>ax.set_yticklabels(feature_imp.iloc[0:10,0].tolist())<br/>ax.tick_params(left=False, top=False, right=False)<br/>ax.set_title("10 Most Important Features in Denials Prediction Model")<br/>ax.set_xlabel('Feature Importance Coefficient \n(RandomForestClassifier)')<br/>plt.gca().invert_yaxis()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oe"><img src="../Images/598b9ea246ff3e47044990c22b419f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G70Pn_SxOvtz80cXX_gzQQ.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">随机森林分类器中最重要的10个特征</p></figure><p id="1989" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">上面的结果来自其他虚构的数据，包括<strong class="ki ir"> bill_status </strong>(发送给保险公司的账单类型)，但是同样，您可以看到收入代码占据了特性重要性的首位。</p><h2 id="7958" class="mh mi iq bd mj mk ml dn mm mn mo dp mp kp mq mr ms kt mt mu mv kx mw mx my mz bi translated">结论</h2><p id="44e1" class="pw-post-body-paragraph kg kh iq ki b kj na jr kl km nb ju ko kp nc kr ks kt nd kv kw kx ne kz la lb ij bi translated">这些只是评估分类变量的相关性和重要性的5种初始方法。像数据科学中的所有事情一样，我们一直处于证据收集模式，让统计数据和可视化告诉我们真实的故事。</p><p id="6762" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">感谢您的阅读，请随时通过<a class="ae oc" href="https://www.linkedin.com/in/gabe-verzino-71401137/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或电子邮件与我联系！</p></div></div>    
</body>
</html>