<html>
<head>
<title>How to Automatically Generate VGG Image Annotation Files</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何自动生成VGG图像标注文件</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-automatically-generate-vgg-image-annotation-files-41d226e6d85#2022-01-11">https://towardsdatascience.com/how-to-automatically-generate-vgg-image-annotation-files-41d226e6d85#2022-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="a962" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">如何自动生成VGG图像标注文件</h1></div><div class=""><h2 id="21b8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用语义数据集更快地训练实例分割</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8c462d18ba70d68a749458fa29e86698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WxT_Wr5DMI7Q_mPB"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克里斯蒂安·威迪格在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="dec1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算机视觉领域，实例分割是目前最热门的话题之一。它包括图像中对象的检测/分割，即特定对象的定位及其所属像素的关联。像任何一种机器学习系统一样，需要大量的图像来训练主干架构。更具体地说，需要大量的注释来训练神经网络的定位功能。注释是一项耗时的活动，并且可以决定项目是否会成功。因此，必须小心处理它以提高生产率。</p><p id="115e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在卫星图像领域，可以利用免费数据集来利用研究人员或注释人员以前所做的工作。这些数据集通常由研究人员在从开源图像中构建它们，对它们进行前后处理，并使用它们来训练和测试他们自己的人工智能研究系统之后发布。语义分段和实例分段略有不同，但是在建筑物的情况下，一个分段可以帮助另一个分段。事实上，建筑往往是独特的，可以在任何图像上进行视觉分离。利用这种考虑，可以从二进制标签图像为每个建筑物生成单独的掩模，然后用于更快地训练实例分割算法，如掩模RCNN。注释不必手动执行，这是该技术的主要优点。这里有一些如何做的提示！</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="709a" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">JSON文件格式</h1><p id="4d9b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">Mask RCNN <a class="ae kv" href="https://github.com/matterport/Mask_RCNN/blob/3deaec5d902d16e1daf56b62d5971d428dc920bc/samples/balloon/balloon.py#L97" rel="noopener ugc nofollow" target="_blank"> Matterport </a>实现以及<a class="ae kv" href="https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=PIbAM2pv-urF&amp;line=4&amp;uniqifier=1" rel="noopener ugc nofollow" target="_blank">FAIR detector 2</a>平台正在使用JSON文件为训练图像数据集加载注释。这种文件格式在许多计算机科学应用程序中使用，因为它允许以一对属性-值格式轻松存储和共享字母数字信息。它是为JavaScript语言构建的，但现在，它被用于许多其他编程语言，如Python。已经构建了专用库，能够在Python代码中生成和解析JSON格式的数据作为文本文件。在<a class="ae kv" href="https://annotate.officialstatistics.org/" rel="noopener ugc nofollow" target="_blank"> VGG注释工具</a>格式中，Mask RCNN使用的典型JSON文件将具有以下形状:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="9256" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于子集，一个JSON注释文件收集所有的注释数据。每个图像注释都堆积在一个大的JSON文件中。</p><ul class=""><li id="c952" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">一个图像由它的名称和它在磁盘上的大小来标识。这个标识符由四个属性描述:图像的名称(<em class="nh">文件名</em>)、它在磁盘上的大小(<em class="nh">大小</em>)、带注释的形状(<em class="nh">区域</em>)以及图像上的一些元数据(<em class="nh">文件属性</em>)。这个<em class="nh">区域</em>属性本身由一个元素列表描述，该列表表示可以在图像上绘制的不同注释。</li><li id="1a89" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">每个注释可以由一对两个元素描述:形状描述(<em class="nh"> shapes_attributes </em>)和注释数据(<em class="nh"> region_attributes </em>)。<em class="nh"> shapes_attributes </em>描述由注释的形状(<em class="nh"> name </em>)和两个整数有序列表(<em class="nh"> all_points_x </em>和<em class="nh"> all_points_y </em>)组成，它们代表形成掩膜注释的点的x和y坐标。注释数据<em class="nh"> region_attributes </em>可以被调整，并且注释类可以被保存用于多类分割目的。</li><li id="b228" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">第四个标识符属性被命名为<em class="nh"> file_attributes </em>，可以用来存储关于带注释图像的任何信息。</li></ul><p id="f260" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在语法方面，让我们注意花括号{}通常用于分隔相同类型的元素，以及引用描述一个元素的属性。方括号[]也用于表示参数列表。关于对，属性通常由包含其名称的字符串描述，并由:字符分隔值/数组。</p><p id="aa32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">幸运的是，Python有一个库供我们读写JSON文件。使用<em class="nh"> import json </em>代码片段可以很容易地加载它，用通用语法读写一个文本文件。让我们在下一章推导如何将二进制标签图像转换成VGG注释，特别是如何用JSON语法编写注释文件。</p><h1 id="e700" class="lz ma iq bd mb mc nn me mf mg no mi mj jw np jx ml jz nq ka mn kc nr kd mp mq bi translated">正在生成注释JSON文件</h1><p id="edb3" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">本文提出的主要思想是将二进制标签图像转换成VGG注释格式的mask JSON文件。二进制标签图像的每个形状被个性化，以将它变成用于例如分割的掩模元素。转换主要通过Python中易于使用的著名OpenCV图形库来执行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><ul class=""><li id="4f16" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第一行是构建正确的文件夹路径到地面真相标签和光学图像文件夹，并创建将被写入注释的JSON文件。</li><li id="ae1c" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">首先，使用cv2.findContours函数将二值蒙版裁剪成轮廓。大多数转换(阈值、灰度转换)实际上并不需要，因为数据已经是二进制图像。cv2.findContours函数提供了一个轮廓列表，作为点的列表，这些点的坐标以图像的参考表示。</li><li id="9259" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">在我的<a class="ae kv" rel="noopener" target="_blank" href="/my-rooftop-project-a-satellite-imagery-computer-vision-example-e45a296129a0?gi=b58691812f1c">屋顶项目</a>的背景下，我只对大型建筑屋顶感兴趣，因此可以使用自定义OpenCV函数来导出屋顶的表面，然后将它们转换为平方米，并只选择有足够面积的屋顶。在这种情况下，可以使用Ramer–Douglas–peu cker(RDP)算法来简化和近似检测到的轮廓，以便更紧凑地存储注释数据。此时，您应该有一个表示在二进制图像上检测到的轮廓的点列表。</li><li id="05fd" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">现在，你需要将整个轮廓点列表转换成一个大的<em class="nh"> via_region_data.json </em>文件，用于掩膜RCNN算法。对于JSON注释，数据需要具有第一段中指定的格式。在将数据推送到JSON文件之前，将主要使用字典。</li><li id="e63e" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">根据轮廓周围[]的数量，您将需要特定数量的[:，0]来获取适当的数据。描述轮廓的整数数组必须用。tolist()参数，然后将其放入JSON属性。制作VGG注释JSON文件非常类似于俄罗斯娃娃。您可以创建一个空字典，指定它的一个(或多个)属性的值，然后将其作为更高级别的属性的值进行传递，以将其封装到更大的字典中。让我们注意，对于多类分割或对象检测，<em class="nh"> region_attributes </em>可以包含一个属性类，其中对象的实际类在<em class="nh"> shape_attributes </em>参数中指定。</li><li id="b255" class="my mz iq ky b kz ni lc nj lf nk lj nl ln nm lr nd ne nf ng bi translated">最后，每个图像数据都存储在一个大的“jsonf”元素中，用它的名称+大小字符串作为标识符，然后将所有数据放入一个JSON文件中。这样做非常重要，因为如果每次运行新图像时都在JSON文件中写入，JSON文件的Mask RCNN导入将会失败。这是由于<em class="nh"> json.load() </em>只读取第一组花括号{}的内容，将无法解释下一组。</li></ul><p id="5967" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就是这样！让我们看看这个过程的结果是什么！</p><h1 id="b4f4" class="lz ma iq bd mb mc nn me mf mg no mi mj jw np jx ml jz nq ka mn kc nr kd mp mq bi translated">检查注释显示</h1><p id="7817" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">这个小章节将展示上述过程的图形使用。我主要使用美国地质调查局通过国家地图服务公开发布的美国城市图片(芝加哥、奥斯汀、旧金山)。美国地质调查局、国家地理空间计划提供的地图服务和数据。这项服务是<a class="ae kv" href="https://www.usgs.gov/faqs/what-are-terms-uselicensing-map-services-and-data-national-map?qt-news_science_products=0#qt-news_science_products" rel="noopener ugc nofollow" target="_blank">开源的</a>，所以你可以对数据做任何你想做的事情！在本文中，我处理了德克萨斯州奥斯汀附近的非常高分辨率的影像(空间分辨率= 0.3米/像素)。</p><ul class=""><li id="c753" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第一幅图像是视觉彩色图像，通常以GeoTiff格式与<em class="nh">一起提供。tif </em>扩展也包含嵌入的地理空间数据。它以美国城市环境的城市场景为特色。渲染是用三个光谱视觉图像构建的:常见的蓝色、绿色和红色。但是在更复杂的影像背景下，影像供应商可以提供近红外影像，以便能够生成CNIR(彩色+近红外影像)来分析光谱影像的不同方面。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/8b86b70f2d75d715f9f4f462c21bffe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1GlEQynJoqoxmpUE9H-56w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">德克萨斯州奥斯丁的卫星图像来自<a class="ae kv" href="https://www.usgs.gov/programs/national-geospatial-program/national-map" rel="noopener ugc nofollow" target="_blank">美国地质调查局国家地图项目</a></p></figure><ul class=""><li id="6326" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第二个图像显示二进制标签图像。可以看出，地面真实包含了与建筑物相关联的每一个像素，甚至是具有弯曲形状的最小像素。每个建筑都可以单独识别，因为建筑不能重叠，这证明了这一点。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/1b3aa6ef2e41d9683fb0d431662edd62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Re0j1X-A1t-cQsE8dPEqQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://www.usgs.gov/programs/national-geospatial-program/national-map" rel="noopener ugc nofollow" target="_blank"> USGS国家地图计划</a>的德克萨斯州奥斯汀的建筑地面真相</p></figure><ul class=""><li id="874d" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第三个图像由二进制标签one和cv2.findContours()函数检测到的轮廓组成，在它上面用红色突出显示。显示的轮廓是来自OpenCV函数的原始数据，并且没有被过滤掉，因此即使最小的建筑物也被表示出来。需要注意的是，cv2.findContours函数是逐像素的变换:由一个像素连接的两个建筑物将被分割在一起，而仅一行暗像素就足以将两个靠近的建筑物分开。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/02a3a7fdd953e8a1ae28b999e42a20b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6pGPq7G_UX-MgCmRw2_XQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供，基于<a class="ae kv" href="https://www.usgs.gov/programs/national-geospatial-program/national-map" rel="noopener ugc nofollow" target="_blank">美国地质调查局国家地图</a>数据</p></figure><ul class=""><li id="e7d9" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第四幅图像显示了带有过滤后的近似轮廓的二进制标签图像。正如第二章所说，在我的屋顶项目中，我对面积小于一百平方米的建筑不感兴趣。还执行轮廓近似以减小注释文件的大小。因此，仅在大型建筑物周围绘制轮廓，并且在某些情况下，轮廓与建筑物形状不完全匹配，从而影响轮廓近似。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/e9499669d8e8ee22e229ce8261fc4d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XC8f2H1CkpNNZx0IeQqLyQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者根据<a class="ae kv" href="https://www.usgs.gov/programs/national-geospatial-program/national-map" rel="noopener ugc nofollow" target="_blank">美国地质调查局国家地图</a>数据制作</p></figure><ul class=""><li id="dfd9" class="my mz iq ky b kz la lc ld lf na lj nb ln nc lr nd ne nf ng bi translated">第五个也是最后一个图像显示了通常的实例分割可视化，可以使用<a class="ae kv" href="https://github.com/matterport/Mask_RCNN/blob/master/samples/balloon/inspect_balloon_data.ipynb" rel="noopener ugc nofollow" target="_blank"> inspect_roof_data.ipynb </a>等工具绘制。大型建筑的屋顶被单独分割，属于这些屋顶的像素被单独关联。此处使用的笔记本将从via_region_data.json文件加载注记，因此，如果您可以像这样显示带注记的卫星影像，您的数据集就可以训练实例分割掩膜RCNN算法了！</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b5e5a823f2726e7272a5dccad31d6a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*LhvfgmJf77JWwyuhxTEAMA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供，基于<a class="ae kv" href="https://www.usgs.gov/programs/national-geospatial-program/national-map" rel="noopener ugc nofollow" target="_blank">美国地质调查局国家地图</a>数据</p></figure><h1 id="a14c" class="lz ma iq bd mb mc nn me mf mg no mi mj jw np jx ml jz nq ka mn kc nr kd mp mq bi translated">结论</h1><p id="5a96" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">本文展示的过程展示了如何将语义数据集转化为实例分割训练数据集。然后，它可以用来有效地训练掩模RCNN算法。该流程还可以重复使用和修改，以适应具有不同输入标签形状的数据集，如ka ggle<a class="ae kv" href="https://www.kaggle.com/c/sartorius-cell-instance-segmentation" rel="noopener ugc nofollow" target="_blank">Sartorius Cell Instance Segmentation</a>competition等</p><p id="bf27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望你觉得这几行有趣且有用😀如果你喜欢我的内容，你可以关注我的帐户来获得更多的deeptech主题！C u😉🚀</p></div></div>    
</body>
</html>