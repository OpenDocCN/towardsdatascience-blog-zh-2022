# 为什么我们在深度学习中使用交叉熵——第 1 部分

> 原文：<https://towardsdatascience.com/why-do-we-use-cross-entropy-in-deep-learning-part-1-e787f885c1c>

## 解释人工神经网络中最广泛使用的损失函数之一

**第二部分可用** [**这里用**](https://medium.com/towards-data-science/why-do-we-use-cross-entropy-in-deep-learning-part-2-943c915db115) **！**

</why-do-we-use-cross-entropy-in-deep-learning-part-2-943c915db115>  

如果你在深度学习领域刚刚起步，看过一些专业文章，我很确定你遇到过以下任何一个术语:*熵*、*交叉熵*、*二元交叉熵、*或*分类交叉熵*。

都来源于同一个概念:**熵**，这个概念你可能从物理和化学上比较熟悉。但是，物理和人工智能有什么关系呢？公式从何而来？我们如何解读它们？我们将它们应用在哪些问题上？

熵、交叉熵和范畴交叉熵是人工智能领域中的重要概念。然而，没有多少课程或文章深入解释这些术语，因为正确地解释它们需要一些时间和数学知识。在这两个系列的文章中，我将尝试使用我在寻找类似本文的文章时收集的资源和直觉给出一个清晰的解释。此外，我将提供公式的正式数学描述以及它们的来源。

> **注**。在我的书目研究过程中，我发现了克里斯托弗·奥拉的 [**这篇**](https://colah.github.io/posts/2015-09-Visual-Information/) 不可思议的文章，启发了我写这篇文章。如果你有时间，我强烈推荐你阅读它，并查看克里斯托弗的网站。

![](img/c34e897b9c817914f4f2e29da25dfd3d.png)

照片由 [mahdis mousavi](https://unsplash.com/@dissii?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/s/photos/deep-learning?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄

# 熵定义

在基础物理和化学的热力学课上，你可能对熵这个术语很熟悉，但它还有两个来自数学和计算机科学不同分支的概念:

## 物理学中的熵

根据经典热力学，****熵是一个系统中无序程度的度量****。**

**一个物理系统可以被看作是一组粒子，每个粒子都有一个相关的能量。无序是指系统可以采用的可能组态的数量(也叫*微观态*，一个系统的组态越多，无序度越大，熵也就越大。**

**![](img/49c399fce0e2f3cb5f66739889f0662e.png)**

**总能量为 5E 的三粒子系统所有可能的微观态。这些条代表与每个粒子相关的能量，例如对于微观状态 1:粒子 1 有 2E，粒子 2 有 2E，粒子 3 1E。因此，总的系统能量是 2E + 2E + 1E = 5E。图片由作者提供。**

> ****注 1** 。如果你想了解更多关于物理学中熵的知识，请观看这个视频**

## **统计学中的熵**

**从熵的热力学定义推导出，我们也可以把熵想成: ***“熵是随机变量不确定性的度量”*** 。**

**这么说吧:我们的随机变量是一个系统的微观状态(可能的能量配置)，其中每个配置是我们的随机变量可以取的一个值。然后，假设每个微观状态发生的概率相同，我们的系统可以采用的配置越多，我们对系统实际所处的微观状态的不确定性就越大。**

**![](img/93e34b3c960ce40780429a4cb5c7b146.png)**

**两个系统的概率分布:系统 1 有两个微观状态(m 1，M2)，系统 2 有六个微观状态(M1，…，M6)。图片由作者提供。**

**统计学中对熵的另一种可能的理解可能是: ***【熵是一个随机变量的信息量】*** 。因为我们对一个变量的结果越不确定，这个变量提供给我们的信息就越多。如果我们确定或几乎确定一个变量的结果，那么测量它就没有价值，因为它不会给我们提供相关的信息。**

**![](img/730651847f6768e1cb2cd53eeee63d3f.png)**

**与系统 2 相似但熵较低的第三个系统。回想一下，所有的概率必须等于 1。图片由作者提供。**

**所以不确定性越高，信息量越高，熵也就越高。**

## **信息论中的熵**

**信息论使用熵的概念来解释一个与物理学非常不同的概念， ***“熵是编码消息的最佳平均长度”*。****

**继续以微软为例，假设我们想将位于马德里(西班牙)的实验室的实验结果发送到世界各地的悉尼(澳大利亚)的阳光海滩。首先，我们必须决定我们将使用哪种编码系统来编写我们的消息(二进制、十六进制、ASCII 等等)。假设我们选择二进制编码来简化示例。
接下来，我们应该定义如何表示每个实验结果。由于我们有 6 个微状态，我们可以将它们表示为:**

**![](img/63524457c3212d862de5364800237faf.png)**

**6 种微观状态的二进制表示。作者图片**

**另一种可能的编码是*一键编码*:**

**![](img/f3eeed1dbd4e13c2acefe2e4bdcd7611.png)**

**另一种可能的编码。图片由作者提供。**

**还有许多其他可能的解决方案……**但是哪一个是最佳的呢？现在想象一下，信息的每一位都有一个价格，比如说每一位 10€，现在我们的第一次编码的平均价格是每实验 30€，而一键编码是每实验 60€。因此，我们自然希望优化我们的信息，使整体价格尽可能低。****

> ****注 2** 。注意，我用的是“价格”这个词，而不是“成本”。这是因为我稍后将使用术语“成本”来指代另一个概念，这样，我可以避免产生歧义。**

**从我们的实验中得到的代表每个微观状态的最佳长度就是熵所代表的长度。在熵障碍下，我们无法获得更短的信息编码。**

# **熵公式**

**如果你在互联网上查找熵公式，你可能会得到不同的结果，这取决于你正在搜索的领域，原因是存在许多熵公式(看这个)。**

**但是，在深度学习中我们感兴趣的是**香农熵**，它来自信息论领域(香农熵也用于熵的统计理解)
***我们为什么要用它？*** 原因将在下一篇文章[深度学习中的交叉熵](http://a)一节中给出，但首先，让我们看看这个公式是从哪里来的。**

> ****注 3** 。得到熵公式的推理是基于我在本文开头提到的 Christopher Olah 的文章[【1】](https://colah.github.io/posts/2015-09-Visual-Information/)。为了更深入地了解，我建议你访问他的网站。**

## **码字的空间**

**码字空间指的是你可以用 n 位信息创建的所有可能的编码信息的集合。**

**所以对于仅仅 1 位，你只能代表两个不同的 ***字*** (我们例子中的实验结果): *0* 和 *1* 。用 2 位可以表示四个字: *00* 、 *01* 、 *10* 和 *11* 。以此类推(见表)。**

**然后，对于二进制代码，我们可以表明，用 n 个表示位的**我们可以表示*个 2^n* 个字**(演示很简单，只需将位数想象为要填充的间隙，对于第一个间隙，您有两个选项( *0* 或 *1* )，对于第二个选项，又有两个选项( *0* 或 *1* )，以此类推现在，为了计算你拥有的所有选项，你将 *2 2 2 … 2 = 2^n* 选项(二进制字符串)乘以 *n* 位)+**

**![](img/e4056db1bda43856bedd7c2d3291b99b.png)**

**3 比特的码字空间。最后一列显示了可能的组合数(8)，从顶部开始:000，001，…作者图片。**

**如果我们操作并清除 n(位数)，我们可以看到，要用二进制表示 5 个字，我们需要使用 3 位。**

**![](img/34ab4542ad753ddb2d0369f1ae37c196.png)**

**清除 n 并计算表达 6 个实验所需的最小位数(我们不能有 2.585 位，所以我们必须向上取整)。图片由作者提供。**

**但是，这只有在我们使用相同数量的比特来表示每个单词时才成立。如果我们使用一个**变长码**会发生什么？**

**回想我们的编码实验结果，我们仍然必须找出最便宜的方式来传送讯息。于是代替拥有: *000* ， *001* ， *010* ， *011* ， *100，101；*我们可以尝试用 *00* 、 *01* 、 *100* 、 *101* 、 *110、111* 来表示。**

**现在新编码系统的平均价格已经降到了 26.67€/实验，而不是 30€。**

**更重要的是，如果实验 100、101、110 和 111 中的每一个只发生了 5%的时间呢？那么平均消息价格会更低，因为我们的消息通常由 2 位字组成。**

**![](img/45cf91cb2ce4a040240d1ce402c19ed7.png)**

**可变长度编码系统的平均价格。80%的时间我们会使用 20 个€单词，而只有 20%的时间会使用 30 个€单词。图片由作者提供。**

## **成本函数**

**为了获得最优解，**我们需要一个目标函数来最小化**。**

**(还记得我说过我使用价格这个词而不是成本，因为我想引入另一个不同的术语，而不是产生歧义吗？现在是时候了)我们将 ***成本*** 定义为当用 n 比特编码一个字时我们牺牲的码字空间的部分。当我说使用 2 比特来表示一个字的成本是 1/4 时，这意味着我损失了 1/4 的码字空间。**

**![](img/39afaaf5921ac68b5dcffba6ffc8b81a.png)**

**使用 00 代表一个单词可以防止使用所有以 00 开头的字符串(灰色单元格)。这相当于 1/4 的成本。作者图片**

**目标函数(从现在起，我将称之为***成本函数*** )必须表示使用长度为 X 比特的代码来表示结果的成本(即，该函数以比特为单位获取代码的长度，并根据码字的空间输出使用该代码的成本)**

**再次查看表示码字空间和使用可变长度码的成本的表格，您可能能够得到以下成本函数:**

**![](img/003dc2d9bd0cf62b95ba901ceba8361f.png)**

**使用 x 比特编码一个字的成本函数。结果被表示为码字空间的一部分。作者图片**

**分析成本函数的性质 *C(l):***

**![](img/882ab7554529131ea4b61de40bc7cbf9.png)**

**成本函数被限制在 0 和 1 之间。长度为 0 的代码牺牲了整个代码字空间，因为我们发送的是一个只能代表一个结果的空消息。作者图片**

## **达到最低限度**

**最后，我们必须根据成本来决定表示单词的最佳长度。我们有整个码字空间为我们工作，因此我们的预算是 1，并且我们必须找到最短的可能代码，使得:**

**![](img/b5671850ab55de25fdadbaf70cd2529a.png)**

**定义我们问题的函数。作者图片**

**回想之前，我们对根据每个结果发生的概率使用**可变长度代码感兴趣**(因此将 l *1，…，l6* 表示为不同的变量，而不仅仅是 l)**

**直观地说，我们希望将一个更短的**码(因此在码字空间中成本更高)分配给最频繁出现的单词，而将一个更长的**码(成本更低)分配给不太可能出现的单词。**但是我们如何量化*变短*和*变长*？**是短 3 位还是长 3 位？******

> **答案是概率**

**可以这样想:我们有一个成本函数，它的总和必须是 1(否则我们就是在浪费码字的空间)，我们想给每一项分配一个与它们的概率成比例的成本，**总和为 1！**与成本函数相同，实验的概率之和为 1。**

**![](img/3a2bed482d3b7284986200c7b9036c0e.png)**

**长度为 L 的单词的最低成本是作者的单词本身 P(x)图像出现的概率**

> ****注 4** 。虽然我刚刚做出的声明需要数学证明，但我不想超载这个帖子。如果你有兴趣阅读，这里的是一个非常直观形象的解释链接。**

**最后，我们只需运算这些项，并将长度 *l* 写成概率 *P(x)* 的函数。**

**![](img/05789201f72373556c43823249f9968d.png)**

**作为概率函数的码字长度。图片由作者提供。**

> ****注 5** 。当您将概率值(在[0，1]中连续)代入上面的公式时，您会看到长度“l”的结果是一个小数值。但那不可能是对的！怎样才能构造出 1.6145 比特的代码？嗯，我会把这个解释留给克里斯托弗，但简单的回答是，我们不能，我们必须围捕，尽管有一种方法可以做得更好…**

## **熵呢**

**我们能够使用二进制编码字出现的概率来计算它的最佳(最短)长度。然而，计算熵还有最后一步，因为*“熵是编码消息的平均***最佳长度”，*这一步是计算我们消息的所有单词长度的平均值:***

**![](img/e8a36e31683731d64990567cc5f94f42.png)**

**离散随机变量的熵公式。**

**开发日志术语:**

**![](img/f765ea7003829233e5cf5f39b6c014ac.png)**

**熵公式最常见的表示。作者图片**

> ****注 6** 。通常，你会看到以对数为底 10 的熵公式。在大多数情况下，这无关紧要，因为 log_10(x) = log_2(x) / log_2(10)，本质上是乘以一个常数 1/log_2(10)。这种基数的变化只适用于忽略常数的优化或比较方法，但使用基数 2(每一位信息只取 2 个可能的值)计算消息的最佳平均长度与使用基数 10 是不同的。阅读[本](https://www.khanacademy.org/math/algebra2/x2ec2f6f830c9fb89:logs/x2ec2f6f830c9fb89:change-of-base/a/logarithm-change-of-base-rule-intro)了解更多信息。**

# **最后的结果**

**到目前为止，我已经提出了三种不同的(但相关的)熵概念，并使用数学和视觉表示法从头推导出了它的表达式。**

**然而，还有一项任务。我们必须为我们的实验室解决对实验结果进行最佳编码的问题！**

**因此，我们只需将实验的概率分布代入熵公式，并计算各项:**

> ****注 7** 。我将使用标题为系统 3 的图像中绘制的最后一个概率分布，但请记住，这对任何离散随机变量都是一样的。**

**![](img/8324493b16bf8cd793bd48ed85c61e94.png)**

**计算系统 3 的编码系统的最佳平均长度。**

**记住这是一个平均值；因此，一些实验可能用 1 位来表示，其他的用 2 位或 3 位来表示…熵只是告诉我们平均最小值，但它并不反映每个消息应该如何编码。**请注意，我使用以 2 为底的对数来计算熵，因为我们使用的是二进制编码**(使用以 10 为底的对数会产生一个不同的结果，它由常数 1/log_2(10)加权，并不反映真实的结果)**

**我希望这篇文章能帮助你更好地理解熵。在下一篇文章中，我将谈论交叉熵以及为什么我们在人工智能模型中使用它。最后，我将解释我们在哪些问题中应用它，以及如何解释它。**

# **参考**

****【1】**视觉信息理论。克里斯托弗·奥拉。2015.[https://colah.github.io/posts/2015-09-Visual-Information/](https://colah.github.io/posts/2015-09-Visual-Information/)**

****【2】**熵真的是“无序度”的度量吗？熵的物理学解释和变得容易。Parth G. 2020。[https://www.youtube.com/watch?v=mg0hueOyoAw](https://www.youtube.com/watch?v=mg0hueOyoAw)**

****【3】**对熵的更好描述。史蒂夫·莫德。2016.[https://youtu.be/w2iTCm0xpDc](https://youtu.be/w2iTCm0xpDc)**