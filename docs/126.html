<html>
<head>
<title>SageMaker Multi-Model vs Multi-Container Endpoints</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SageMaker多模型与多容器端点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sagemaker-multi-model-vs-multi-container-endpoints-304f4c151540#2022-01-05">https://towardsdatascience.com/sagemaker-multi-model-vs-multi-container-endpoints-304f4c151540#2022-01-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="8b3b" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">SageMaker多模型与多容器端点</h1></div><div class=""><h2 id="f022" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用哪个实时推理选项</h2></div><p id="caeb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Amazon SageMaker为模型托管和部署提供了过多的推理选项。在推论内具体有四个主要选项:</p><ol class=""><li id="6408" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated"><a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html" rel="noopener ugc nofollow" target="_blank">实时推断</a></li><li id="f852" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated"><a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html" rel="noopener ugc nofollow" target="_blank">无服务器推断</a></li><li id="1137" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated"><a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html" rel="noopener ugc nofollow" target="_blank">批量转换</a></li><li id="74bf" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated"><a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html" rel="noopener ugc nofollow" target="_blank">异步推理</a></li></ol><p id="fcfe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">出于本文的目的，我们将关注<strong class="kk iu">实时推理</strong>。当您需要一个具有严格延迟需求(亚毫秒级)的<strong class="kk iu">持久端点</strong>时，实时推理是理想的。在实时推理中，你也可以使用不同的选项。最简单的形式是，您可以拥有一个端点，其中包含一个由一个实例支持的模型。让我们来看看这个基本架构是什么样子的。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/4308dafa8c0ea5aff61477c2012ddfa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*LTAVE55R9XhK8PpKOeLg-A.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">作者截图</p></figure><p id="4194" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以为TensorFlow、PyTorch、Sklearn等流行框架创建一个模型并<a class="ae ln" href="https://aws.plainenglish.io/how-to-retrieve-amazon-sagemaker-deep-learning-images-ff4a5866299e" rel="noopener ugc nofollow" target="_blank">检索</a>一个<a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-available-images.html" rel="noopener ugc nofollow" target="_blank"> SageMaker支持的图像</a>。如果你正在为你的模型使用一个定制的框架，那么你也可以<a class="ae ln" rel="noopener" target="_blank" href="/bring-your-own-container-with-amazon-sagemaker-37211d8412f4">使用你自己的容器</a>来安装你的依赖项。</p><p id="a110" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着你的ML平台变得越来越复杂，有更多的高级选项，如<a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html" rel="noopener ugc nofollow" target="_blank">多模型端点</a>和<a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-container-endpoints.html" rel="noopener ugc nofollow" target="_blank">多容器端点</a>。让我们看一下每种产品的架构，以了解它们的使用情形。</p><h1 id="d8b7" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">多模型端点(MME)</h1><p id="dc92" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">多模型端点帮助您将数千个模型扩展到一个端点。通过使用共享的服务容器，您可以在同一个端点中以经济高效的可伸缩方式托管多个模型。该体系结构将不同于下图所示的单个模型端点。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d78f2c9a6a47e4f57b65d11f93920c35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*ORFugTinW6nQ4OOmJaFExA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">MME架构(作者截图)</p></figure><p id="88d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">底层基础设施(容器+实例)保持不变，但是主要的区别在于可以装载到这个容器上的模型。类似于单个模型端点的部署，您需要指向<strong class="kk iu">模型数据</strong>。这里的关键区别是，您将拥有多个模型数据/工件，而不是一个，您需要为您拥有的每个模型加载它们。像单模型端点这样的工件存储在S3，但是为了让SageMaker意识到您正在处理一个多模型端点，您将把所有的模型数据放在一个公共的S3位置。模型数据也需要压缩成modelname.tar.gz格式，以便SageMaker理解。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/69ca94005554090cbebd44512934f0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*-eyLf4Q-Me1DHq3lu7LnCA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">模型数据结构(作者截图)</p></figure><p id="7c87" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用MME需要理解的最重要的特性是<strong class="kk iu">所有的模型都必须在同一个框架</strong>中构建。例如，MME中的所有模型应该是纯粹的PyTorch，或者纯粹的TensorFlow，或者纯粹的您正在处理的自定义框架。<strong class="kk iu">您不能混合和匹配具有多模型端点</strong>的模型框架。</p><p id="9aa3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在可能会有一个问题，为什么不只是有一堆单一模型端点，而不是在一个多模型端点上加载所有的模型。简而言之，将所有模型加载到一个端点上更具成本效益。例如，假设您有10个想要部署的模型。如果我们为每个端点部署一个<strong class="kk iu"> ml.c5.large </strong>实例，我们就有10个持久端点在运行。如果我们看一下这个实例的<a class="ae ln" href="https://aws.amazon.com/sagemaker/pricing/" rel="noopener ugc nofollow" target="_blank">定价</a>，它是每小时0.102美元。</p><p id="0838" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 10个单一模型端点:10 * $ 0.102 =每小时$ 1.02</strong></p><p id="76ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，如果我们用一个ml.c5.large实例将所有10个模型加载到一个多模型端点上，我们可以节省10倍。</p><p id="a6f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> 1个多型号终点(10个型号):1个&amp; $.102 = $.102每小时</strong></p><h2 id="3e44" class="ne mg it bd mh nf ng dn ml nh ni dp mp kr nj nk mr kv nl nm mt kz nn no mv np bi translated">多模型端点资源</h2><p id="b07c" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/deploy-multiple-tensorflow-models-to-one-endpoint-65bea81c3f2f">多模型端点张量流示例</a></p><p id="52fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html" rel="noopener ugc nofollow" target="_blank">多模型终点文件</a></p><h1 id="fe82" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">多容器端点(MCE)</h1><p id="499d" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">我们讨论多模型端点的一个警告是，我们不能混合和匹配框架。多容器端点解决了这个问题，您可以为您将要使用的不同框架提供容器。例如，您可以在同一个端点上加载PyTorch和TensorFlow容器。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/303827fcf429cb55f9c2718729817091.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*FJGTD9xwKMHQ-hgRY6G6Wg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">多容器结构(作者截图)</p></figure><p id="4554" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">多容器端点还提供了强大的功能，您可以在一个<a class="ae ln" href="https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html" rel="noopener ugc nofollow" target="_blank">串行推理管道</a>中将容器缝合在一起，或者调用您选择的容器。串行推理管道允许你将2-15个容器连接在一起，一个容器的输出成为下一个容器的输入。这是一个理想的用例，例如，如果您有Sklearn预处理容器- &gt; TensorFlow模型。</p><h2 id="2b91" class="ne mg it bd mh nf ng dn ml nh ni dp mp kr nj nk mr kv nl nm mt kz nn no mv np bi translated">多容器端点资源</h2><p id="aeb8" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated"><a class="ae ln" href="https://github.com/RamVegiraju/SageMaker-Deployment/tree/master/RealTime/Multi-Container" rel="noopener ugc nofollow" target="_blank">多容器示例</a></p><p id="5d92" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae ln" href="https://github.com/aws/amazon-sagemaker-examples/blob/master/contrib/inference_pipeline_custom_containers/inference-pipeline.ipynb" rel="noopener ugc nofollow" target="_blank">串行推理流水线示例</a></p><h1 id="17f1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">代码差异</h1><p id="d387" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">使用SageMaker的许多步骤都可以通过Boto3 Python SDK来完成，您可以在其中创建一个SageMaker客户端。任何SageMaker端点的三个主要部署步骤如下。</p><ol class=""><li id="0984" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">SageMaker模型创建(提供模型数据+图像)</li><li id="8d0a" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">SageMaker端点配置创建(获取模型名称，在创建端点之前添加实例详细信息/配置)</li><li id="56ec" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">端点创建(需要3-4分钟实施端点配置的详细信息)</li><li id="a9ee" class="le lf it kk b kl lo ko lp kr lq kv lr kz ls ld lj lk ll lm bi translated">端点调用</li></ol><p id="daa2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">像任何其他实时端点一样，多模型和多容器端点遵循相同的方法。对于区分这两者的几个步骤，需要添加一些微小的差异。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nr ns l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">模型设定</p></figure><p id="3e80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于多模型，我们想要指定包含模型工件的模型前缀(S3位置)。对于多容器，我们需要指定我们在这个用例中处理的不同图像/容器。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nr ns l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">MCE模型创建</p></figure><p id="b6a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里，我们在<a class="ae ln" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#SageMaker.Client.create_model" rel="noopener ugc nofollow" target="_blank"> create_model </a>调用中用containers参数指定了两个不同的容器。</p><p id="dec0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下一个需要注意的主要区别是端点是如何被调用的，通过下面的代码示例，这一点是显而易见的。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nr ns l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">MME调用</p></figure><p id="09f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于MME，您在调用中指定一个名为TargetModel的参数，并指定您想要调用的模型。</p><figure class="lu lv lw lx gt ly"><div class="bz fp l di"><div class="nr ns l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">MCE调用</p></figure><p id="8209" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">类似地，对于MCE，有一个名为TargetContainerHostname的参数，您可以在其中指定要调用的容器。</p><h1 id="6af4" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">结论和附加资源</h1><p id="8afd" class="pw-post-body-paragraph ki kj it kk b kl mx ju kn ko my jx kq kr mz kt ku kv na kx ky kz nb lb lc ld im bi translated">Amazon SageMaker有一个不断扩大的推理选项列表。使用对您的用例最有效的选项是很重要的，我希望这篇文章已经阐明了使用这两个选项中的哪一个。我在下面附上更多关于推论和SageMaker的资源。</p><p id="0e6e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae ln" href="https://github.com/RamVegiraju/SageMaker-Deployment" rel="noopener ugc nofollow" target="_blank"> SageMaker推理范例库</a></p><p id="8ca5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae ln" href="https://aws.amazon.com/about-aws/whats-new/2021/12/amazon-sagemaker-inference-recommender/" rel="noopener ugc nofollow" target="_blank"> SageMaker推理推荐器选择正确的实例</a></p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="edeb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="oa">如果你喜欢这篇文章，请在</em><a class="ae ln" href="https://www.linkedin.com/in/ram-vegiraju-81272b162/" rel="noopener ugc nofollow" target="_blank"><em class="oa">LinkedIn</em></a><em class="oa">上联系我，订阅我的媒体</em> <a class="ae ln" href="https://ram-vegiraju.medium.com/subscribe" rel="noopener"> <em class="oa">简讯</em> </a> <em class="oa">。如果你是新手，使用我的</em> <a class="ae ln" href="https://ram-vegiraju.medium.com/membership" rel="noopener"> <em class="oa">会员推荐</em> </a> <em class="oa">报名。</em></p></div></div>    
</body>
</html>