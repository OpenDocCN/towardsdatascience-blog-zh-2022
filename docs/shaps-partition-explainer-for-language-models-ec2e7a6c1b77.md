# 语言模型的 Shap 划分解释器

> 原文：<https://towardsdatascience.com/shaps-partition-explainer-for-language-models-ec2e7a6c1b77>

## Shapley 值，Owen 值和 shap 中的分割解释器:它们是如何联系在一起的

![](img/b094b868dcedac4d4bd393a9e843dfdc.png)

照片由[雷德查理](https://unsplash.com/@redcharlie?utm_source=medium&utm_medium=referral)在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄

理解模型预测的能力通常对铺平生产道路至关重要。虽然简单、可解释的模型在某些应用中取得了足够好的结果，但在其他应用中，使用复杂建模技术的好处超过了对易处理性的追求，如自然语言处理或计算机视觉。然而，我们希望了解哪些特征对模型的预测最重要。

Shapley 值是一个理论上合理且广泛用于解释黑盒机器学习模型的概念。作为一种与模型无关的方法，它可以用于任何预测模型。它的吸引力在于其直白的解释:Shapley 值是一个特征对实际预测的贡献，所有特征的 Shapley 值加起来就是预测。不幸的是，它有一个不可忽视的缺点:在其纯形式中，它很快变得难以计算。因此，我们必须求助于替代的、近似的方法。T4 图书馆提供了一套不同的方法。对于自然语言处理和图像分类任务，它默认使用*分区解释器*计算 *Owen 值*。本文的目的是演示它是如何工作的。

我在一个文本模型设置中演示了什么是欧文价值观，它们如何与 Shapley 价值观相关，它们有多好，以及它们如何在 shap 中实现。在描述欧文价值观之前，我先快速回顾一下沙普利价值观。

## 文本语境中的 Shapley 值述评

关于 Shapley 值、它的内部工作方式、优点和缺点已经写了很多，我不打算在这里赘述。感兴趣的读者可以在网上找到大量容易获取的资料(例如这里的[或者这里的](https://christophm.github.io/interpretable-ml-book/shapley.html)或者[和](/the-shapley-value-for-ml-models-f1100bff78d1))。相反，我限制自己在一个特定的环境中回顾它的本质，即基于文本的模型。

在较高层次上，Shapley 值是特征值或文本设置中的标记对模型结果的贡献。代币被解释为合作游戏中的玩家，他们合作产生收益或损失，即结果减去参考值。每个玩家贡献了多少？Shapley 值试图将公平份额分配给每个参与者。单个玩家也可能对群体的得失做出相反的贡献。

为了说明，让我们看一些随机的句子:“令人惊讶的曲折”，在一些监督学习文本模型中，它产生 0.9886 的预测。对于作为引用的空字符串，模型输出 0.6431。每个单词对这 0.3455 的差异贡献了多少？

在这里，我们把句子想象成一组玩家 **F** ，令牌。对于参与人 **i** ，我们计算 I 在 **F** 中排除 I 的所有子集 **S** 上的加权边际贡献，边际贡献指的是 I 的存在引起的结果函数 **v** 的变化。接近初始联盟或空集的子集被赋予更大的权重。在正式符号中，令牌 I 的 Shapley 值是:

![](img/b3f3bfed8414dedf2ea8a6966f4097aa.png)

参与人 I 的 Shapley 值的正式定义。

所有子集 **S** ，也称为联合，都尊重原句子的顺序。下表展示了在示例文本中，对于某些假设模型，如何计算“令人惊讶”的 Shapley 值:

将加权差值相加得到沙普利值 0.1218。这就是“令人惊讶的”对 0.3455 的预测增长的贡献。为了计算这个小句子中一个单词的 Shapley 值，我们需要计算 16 个预测，8 个子集各两个。总的来说，这个数字相当于

![](img/743aae09f1451ae5872b64231eba2827.png)

计算。

## 欧文值:Shapley 值的一个易于计算的近似值

欧文值是沙普利值的联合版本。最初，欧文的意图是考虑到球员可能属于群体。在 ML 设置中，这转化为相关的特征值。尽管这是一个很好的副作用，但据我理解，shap 的分区解释器使用 Owen 值的主要原因是为了让计算更容易处理。

欧文值通过减少需要计算边际贡献的子集数量来逼近沙普利值。选择基于初始划分，即联合结构，它指定如何将令牌分组到联合中。从玩家的角度来看，联盟既可以在联盟内部形成，也可以在联盟层面形成。外部联合保持完整，不会分裂。在这两个层次上组合联盟的初始次序是选择联盟。

让我们回到我们的例子，使这一点更清楚。句子“令人惊讶的曲折”可以被分割成联合结构 B={{0，1}，{2，3}}。因此，形成的联合是{0，1}和{2，3}。对于索引 0 处的令牌“令人惊讶”，要组合的联盟是:

*   内部级别的{}和{1}
*   {}和{2，3}在联合级别。

组合后的联合是{}、{2，3}、{1}、{1，2，3}。

就像之前一样，我们然后计算 I 在排除 I 的所有已识别联盟上的加权边际贡献。正式定义是:

![](img/2824667080794ac6293c5e8a5318b51b.png)

参与人 I 的欧文值的正式定义。

诚然，这看起来有点复杂，但实际上与 Shapley 方程没有太大区别。 **R** 都是 **M\{k}** 的子集，其中 **M={1，2，…，m}** ，其中 **k** 是指其中有 I 的并集。 **Q** 是 r 中的并的对应并(就集合论而言)即 Q 是并层次上的并。 **T** 则是内部级别的联合，不包含 I，小写字母 **r** 和 **t** 代表各自集合的大小。

在我们的例子中，下面是如何计算“令人惊讶”的欧文值，略有滥用符号:

对于 Shapley 值，我们需要计算 8*2=16 次预测，而对于 Owen 值，我们只需要 4*2=8 次！根据分区，所需的计算量可以大大减少。

下面是一个更长的例子:一个有七个标记的句子被分割成 B={{0，1，2}，{3}，{4，5，6}}。对于索引为 0 的令牌，要考虑的联盟有

*   在内部级别:{}、{1}、{2}、{1，2}
*   在外层:{}、{3}、{4，5，6}、{3，4，5，6}

在这个例子中，计算了 4*4*2 = 32 个预测。不可忽略，但比最初的 128 个预测要少得多。更一般地，单个令牌所需的计算次数总计为

![](img/35b1daf07b90e8809a852a97f4a6ee65.png)

欧文值方法潜在地节省了大量的计算资源。注意，如果形成个体联盟(每个集合一个令牌，b_k = 1)或大联盟(一个集合中的所有令牌，m = 1)，欧文值与沙普利值完全相同。

计算 Shapley 值的计算成本极高。因此，采用更便宜的选择不仅是可取的，而且往往是必要的。不利的一面是，欧文值不是沙普利值，而沙普利值长期以来被认为是满足许多理想性质的唯一值。在 ML 环境中，它们是:

*   *对称性*:如果两个令牌对所有可能的联盟贡献相等，那么它们的贡献值是相同的。
*   *效率*:所有 Shapley 值之和充分说明了得失。
*   *虚拟*:其值不影响模型结果的特征贡献值为零。
*   *可加性*:当一个模型的输出是两个中间输出的相加结果时，新的 Shapley 值是两个中间 Shapley 值之和。

不出所料，对称性被放弃了，或者至少放松了，因为它仍然适用于同一联盟中的令牌。贡献值取决于初始分区，因此现在是不明确的。

欧文值和沙普利值有多接近？在我们上面举例说明的例子中，欧文对“惊奇”的贡献是 0.1175，所以只比沙普利值 0.1218 小一点点。更一般地说，[本文在这里](https://www.researchgate.net/publication/46510645_The_shapley_value_the_owen_value_and_the_veil_of_ignorance)论证了 Shapley 值是所有可能分区上所有对称分布的期望 Owen 值，但它没有对方差作出陈述。

## 在 shap 中实施

在 shap 中，Owen 值由 partition explainer 实现，缺省情况下文本模型会调用它。

在下面的代码片段中，我给出了一个例子。解释器需要一些模型函数来从给定的字符串列表中产生输出。在这里，我使用了一个经过微调的 distilbert 情绪分析模型，它碰巧输出了上面示例中列出的预测。掩码很可能不同于原始模型的记号赋予器，它定义了计算 Owen 值的基础。我想获得“不可否认”的贡献值，而不是计算“un”、“deni”、“able”的贡献值。我发现 transformers 库中的 BasicTokenizer 通常是处理标点使用不当的好选择，但是空格标记化可能就足够了。

在上面的例子中，我使用空字符串作为引用字符串。如果标记化器没有属性 mask_token，shap.maskers.Text()则使用“…”。对 Shapley 值的一个常见批评是引用不可信的特征值组合，这些组合不太可能甚至不可能在野外找到。虽然简单地丢弃标记肯定是有问题的，但在我看来，用一些随机的字符串替换它们更有问题，并且会创建特别奇怪的句子。我不知道作者为什么选择这样做。

为了计算样本文本的 Owen 值，我们简单地调用 explainer，`explainer(['surprising twists and turns']).`这样就实现了上面给出的划分，B = { { ' surprising '，' twists'}，{'and '，' turns'}}。

要查看不同样本字符串上实现的分区，我们可以绘制一个树状图，如下所示:

![](img/7b3229a13355b225f5ef606c27b5c915.png)

sample_text 的树形图

显然，划分树有多个层次，B={{{0，1}，{2，3}}，{{4，5}，{6}}}。在我的理解中，绿色分支内的所有令牌都将红色分支视为一个整体，反之亦然。除此之外，程序没有改变。在所描绘的树中，使用分区 B={{0，1}、{2，3}、{4，5，6}}来计算前四个令牌的 Owen 值，而红色分支令牌考虑 B={{0，1，2，3}、{4，5}、{6}}。此外，权重不是根据上面描述的公式计算的，而是被均匀地分割。

## Owen values:一种计算效率更高的近似值，易于在 shap 中实现

Shapley 值是一个强大的 ML 解释工具，具有吸引人的解释:它对应于一个特征对模型预测的贡献。接近 Shapley 值的 Owen 值继承了这种直接的可解释性。此外，Shapley 值长期以来被认为是满足许多期望属性的唯一概念，这些属性被认为共同定义了公平分享回报的含义。幸运的是，欧文价值观分享了其中的大部分。

欧文最初的动机是扩展 Shapley 值，以考虑到球员可能属于群体。因此，同一个组的成员在彼此之间分享其收益之前形成一个协商子联盟。在 ML 上下文中，如果划分被相应地定义，这可能会重新平衡相关特性的问题。据我所知，这并不是 shap 库计算 Owen 值作为自然语言处理模型默认值的主要原因。相反，它利用了欧文值的计算更容易处理的事实，这是由于减少了所考虑的联盟的数量。

当我试图在一个文本分类模型上计算 Shapley 值时，我无意中发现了 shap 的分区解释器。我花了一些时间来弄清楚它的内部工作原理，由于很难找到对欧文价值观的通俗易懂的解释，我决定撰写这篇文章。我所写的是我所能理解的，希望对某人有所帮助！

**参考资料/进一步阅读**

[1] *J. M. Giménez，M. A .普恩特:* [*欧文和欧文-班扎夫价值观应用于立法机构 2015–2019*](https://upcommons.upc.edu/bitstream/handle/2117/131879/ICORES_2019_9_CR.pdf;jsessionid=1265EA4B2DB8C82F48ECBAA87BA249B7?sequence=1)*马德里议会和安达卢西亚议会的研究。ICORES 2019:45–52*

[2] *C. Molnar:可解释的机器学习:使黑盒模型可解释的指南(第二版。).*[*christophm.github.io/interpretable-ml-book/*](http://christophm.github.io/interpretable-ml-book/)