<html>
<head>
<title>How to Build Powerful Airflow DAGs for Big Data Workflows in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Python中为大数据工作流构建强大的气流Dag</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-powerful-airflow-dags-for-big-data-workflows-in-python-14eb2b66f280#2022-01-07">https://towardsdatascience.com/how-to-build-powerful-airflow-dags-for-big-data-workflows-in-python-14eb2b66f280#2022-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="e5ea" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">如何在Python中为大数据工作流构建强大的气流Dag</h1></div><div class=""><h2 id="da02" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将您的气流管道扩展到云</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d0dd05c3dbdac623d152eac2406d52de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MsE29S_Zo2fWhQzaucZLoA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由Solen Feyissa通过<a class="ae ky" href="http://unsplash.com" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="d117" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">气流DAGs for(真的！)大数据</h1><p id="257e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Apache Airflow是用于编排数据工程、机器学习和DevOps工作流的最流行的工具之一。但是它有一个重要的缺点。开箱即用，Airflow将在本地运行您的计算<em class="mn">，</em>这意味着您只能处理适合您的机器资源的数据集。</p><p id="5feb" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">要在大于内存的数据集上使用Airflow进行计算，您可以将包含繁重工作负载的特定Airflow任务扩展到Dask集群。这篇博客将向您展示如何为大于内存的数据集构建气流Dag，而只需对您现有的Python代码进行最小的更改。</p><p id="d334" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们将详细介绍一个例子。你可以在<a class="ae ky" href="https://github.com/coiled/coiled-resources/tree/main/airflow-with-coiled" rel="noopener ugc nofollow" target="_blank">这个专门的库</a>中找到其他气流DAG的例子。</p><h1 id="58a0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">如何使用Dask扩展气流ETL任务</h1><p id="03e4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">气流工作流程由<code class="fe mt mu mv mw b">Tasks</code>和<code class="fe mt mu mv mw b">DAGs</code>定义，并由<code class="fe mt mu mv mw b">Executors</code>协调。为了将繁重的工作流委托给Dask，我们将在一个包含繁重计算的<code class="fe mt mu mv mw b">Task </code>中旋转一个盘绕的集群，并返回结果，在本例中是一个<strong class="lt iu">。</strong> <code class="fe mt mu mv mw b">value_counts()</code>掠过一列兴趣。因为这个结果很容易被存储到内存中，所以我们可以立即关闭集群以限制成本，并在本地的下一个任务中继续使用这个结果。</p><p id="92b1" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="mn">免责声明:我在Coiled工作，是一名数据科学传播者。</em><a class="ae ky" href="http://coiled.io/" rel="noopener ugc nofollow" target="_blank"><em class="mn">Coiled</em></a><em class="mn">由</em><a class="ae ky" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"><em class="mn">Dask</em></a><em class="mn">的最初作者马修·洛克林(Matthew Rocklin)创立，是一个面向分布式计算的开源Python库。</em></p><h1 id="38d4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">定义您的气流ETL DAG</h1><p id="7329" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><code class="fe mt mu mv mw b">DAG</code>将包含以下3个<code class="fe mt mu mv mw b">Tasks</code>:</p><ol class=""><li id="2caf" class="mx my it lt b lu mo lx mp ma mz me na mi nb mm nc nd ne nf bi translated">旋转盘绕的集群，对整个数据集执行繁重的计算，然后关闭集群；</li><li id="2071" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">使用结果计算汇总统计数据，并将这些数据保存到CSV文件中；</li><li id="2a45" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">使用result查找前100名最活跃的Github用户，并将它们保存到一个CSV文件中。</li></ol><p id="ad18" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">让我们从使用<code class="fe mt mu mv mw b">@dag</code>装饰器定义一个气流<code class="fe mt mu mv mw b">DAG</code>开始，向它传递脚本中前面定义的<code class="fe mt mu mv mw b">default_args</code>以及一些您可以调整的其他参数。</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="e9a1" class="np la it mw b gy nq nr l ns nt"># define DAG as a function with the @dag decorator <br/>@dag( <br/>    default_args=default_args, <br/>    schedule_interval=None, <br/>    start_date=datetime(2021, 1, 1), <br/>    catchup=False, <br/>    tags=['coiled-demo'], <br/>) <br/>def airflow_on_coiled():</span></pre><h1 id="b03c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">启动你的Dask集群</h1><p id="d0d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">先来定义一下我们的第一个<code class="fe mt mu mv mw b"> Task</code>。</p><p id="f7c8" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这就形成了一个名为“气流-任务”的盘绕式集群，由20个Dask工人组成，每个工人运行一个指定的<a class="ae ky" href="https://docs.coiled.io/user_guide/software_environment.html" rel="noopener ugc nofollow" target="_blank">盘绕式软件环境</a>，以确保他们拥有所有正确的依赖关系。</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="74ac" class="np la it mw b gy nq nr l ns nt"># define Airflow task that runs a computation on a Coiled cluster </span><span id="293d" class="np la it mw b gy nu nr l ns nt">@task() <br/>def transform(): </span><span id="3a38" class="np la it mw b gy nu nr l ns nt">    # Create and connect to Coiled cluster<br/>    cluster = coiled.Cluster( <br/>        name="airflow-task", <br/>        n_workers=20, <br/>        software="rrpelgrim/airflow", <br/>    ) </span><span id="14e2" class="np la it mw b gy nu nr l ns nt">    client = Client(cluster)</span></pre><p id="0bac" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">然后，我们可以将存储在S3上的数据集读入Dask数据帧，并计算出我们感兴趣的结果。在这里，我们加载2015年的Github存档数据(子集仅包括PushEvents ),并通过调用<code class="fe mt mu mv mw b">.value_counts()</code>计算全年每个用户的PushEvents数量。</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="63ae" class="np la it mw b gy nq nr l ns nt"># Read CSV data from S3 <br/>ddf = dd.read_parquet( <br/>    's3://coiled-datasets/github-archive/github-archive-2015.parq/',    <br/>    storage_options={"anon": True, 'use_ssl': True}, <br/>    blocksize="16 MiB", <br/>) </span><span id="c68c" class="np la it mw b gy nu nr l ns nt"># Compute result number of entries (PushEvents) per user <br/>result = ddf.user.value_counts().compute()</span></pre><p id="8977" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">因为我们现在在本地得到了结果，所以我们可以关闭集群来限制我们的成本。请注意，这实际上只是一种形式，因为Coiled会在20分钟不活动后自动关闭您的集群。</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="525c" class="np la it mw b gy nq nr l ns nt"># Shutdown Coiled cluster <br/>cluster.close() <br/>return result</span></pre><p id="21b4" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">转到卷云仪表板，我们可以看到这个计算花费了我们5美分。不，这不是打印错误😉这意味着您可以使用<a class="ae ky" href="https://cloud.coiled.io/" rel="noopener ugc nofollow" target="_blank">盘绕自由层</a>每月免费运行这个气流DAG示例多达200次。</p><h1 id="2ba6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">本地使用结果</h1><p id="9c89" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们已经利用云资源获得了我们感兴趣的结果，现在我们可以在本地继续执行以下任务。因为Coiled在您自己的机器上本地运行，所以读写本地磁盘很简单。</p><p id="63fc" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们将生成<code class="fe mt mu mv mw b">result</code>熊猫系列的汇总统计数据，并将其保存到一个CSV文件中:</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="99b3" class="np la it mw b gy nq nr l ns nt">@task() <br/>def summarize(series): <br/>    # Get summary statistics <br/>    sum_stats = series.describe() </span><span id="63cf" class="np la it mw b gy nu nr l ns nt">    # Save to CSV   <br/>    sum_stats.to_csv(<br/>         f'{storage_directory}usercounts_summary_statistics.csv'<br/>    ) <br/>    <br/>    return sum_stats</span></pre><p id="5fb4" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">并获取前100名最活跃用户的用户名和推送事件数量:</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="16e9" class="np la it mw b gy nq nr l ns nt">@task() <br/>def get_top_users(series): <br/>    # Get top 100 most active users <br/>    top_100 = series.head(100) </span><span id="72c4" class="np la it mw b gy nu nr l ns nt">    # Store user + number of events to CSV <br/>    top_100.to_csv(f'{storage_directory}top_100_users.csv') </span><span id="acbc" class="np la it mw b gy nu nr l ns nt">    return top_100</span></pre><p id="10be" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">最后但同样重要的是，我们将指定我们希望气流<code class="fe mt mu mv mw b">Tasks</code>运行的顺序，并实际调用<code class="fe mt mu mv mw b">DAG</code>函数来触发工作流。</p><pre class="kj kk kl km gt nl mw nm nn aw no bi"><span id="6f97" class="np la it mw b gy nq nr l ns nt"># Call task functions in order <br/>series = transform() <br/>sum_stats = summarize(series) <br/>top_100 = get_top_users(series) </span><span id="1b55" class="np la it mw b gy nu nr l ns nt"># Call taskflow <br/>airflow_on_coiled()</span></pre><p id="d054" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">干得好，都准备好了！现在，您可以将Airflow DAG Python脚本添加到您的<code class="fe mt mu mv mw b">dags</code>文件夹(默认为:<code class="fe mt mu mv mw b">~/airflow/dags</code>)中，并根据需要运行或调度它。</p><p id="1f80" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="mn">重要提示:默认情况下，气流禁用</em> <code class="fe mt mu mv mw b"><em class="mn">pickling</em></code> <em class="mn">。您必须启用它才能运行Dask任务。你可以通过编辑你的</em> <code class="fe mt mu mv mw b"><em class="mn">airflow.cfg</em></code> <em class="mn">文件或者通过使用</em> <code class="fe mt mu mv mw b"><em class="mn">export AIRFLOW__CORE__ENABLE_XCOM_PICKLING = True</em></code> <em class="mn">设置相应的环境变量来实现。在启动Airflow服务器之前，请执行此操作。</em> <em class="mn">如果你在苹果M1机器上工作，你可能想看看这篇关于使用conda </em>  <em class="mn">安装PyData库的博客。具体来说，确保在您的本地和集群软件环境中既没有安装</em> <code class="fe mt mu mv mw b"><em class="mn">blosc</em></code> <em class="mn">也没有安装</em> <code class="fe mt mu mv mw b"><em class="mn">python-blosc</em></code> <em class="mn">库。</em></p><h1 id="82bb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">更多气流DAG示例</h1><p id="08b9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在专用的<a class="ae ky" href="https://github.com/coiled/coiled-resources/tree/main/airflow-with-coiled" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">带盘管的气流</strong>库</a>中，您将找到另外两个使用Dask的气流DAG示例。示例包括常见的气流ETL操作。</p><p id="f7e1" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">请注意:</p><ul class=""><li id="255c" class="mx my it lt b lu mo lx mp ma mz me na mi nb mm nv nd ne nf bi translated">JSON-to-Parquet转换DAG 示例要求您将Airflow连接到亚马逊S3。您可以在气流文件<a class="ae ky" href="https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/connections/aws.html" rel="noopener ugc nofollow" target="_blank">中找到操作说明，点击</a>。您还需要使用<code class="fe mt mu mv mw b">storage_options</code>关键字参数将您的AWS秘密传递给<code class="fe mt mu mv mw b">to_parquet()</code>调用。</li><li id="b654" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nv nd ne nf bi translated">XGBoost DAG示例仅适用于&gt; 20GB ARCOS数据集的约250MB子集。要在整个数据集上运行它，请查看本教程。</li></ul><div class="nw nx gp gr ny nz"><a href="https://coiled.io/blog/common-dask-mistakes/" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">使用Dask时要避免的常见错误</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">第一次使用Dask可能是一个陡峭的学习曲线。经过多年的建设Dask和引导人们通过…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">coiled.io</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ks nz"/></div></div></a></div><h1 id="592b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">使用DaskExecutor运行所有气流ETL任务</h1><p id="173d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">上面报告中的气流DAG示例从气流任务的中的<em class="mn">启动盘绕簇。您还可以选择不同的架构，并在盘绕式集群上的Airflow DAG中运行所有任务。然后，您可以使用Coiled的<a class="ae ky" href="https://docs.coiled.io/user_guide/cluster_scaling.html#using-the-adapt-method" rel="noopener ugc nofollow" target="_blank">自适应伸缩</a>功能，根据工作负载来增减工作人员的数量。</em></p><p id="d723" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">为此，从使用气流的默认<code class="fe mt mu mv mw b">SequentialExecutor</code>切换到<code class="fe mt mu mv mw b">DaskExecutor</code>。使用除默认SequentialExecutor之外的任何Airflow executor还需要<a class="ae ky" href="https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html" rel="noopener ugc nofollow" target="_blank">设置一个专用的数据库后端</a>，Airflow可以在那里存储与您的工作流相关的元数据。一旦完成，将<code class="fe mt mu mv mw b">DaskExecutor</code>指向一个已经运行的盘绕星团。</p><p id="1142" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">您可以通过在您的<code class="fe mt mu mv mw b">airflow.cfg</code>文件中进行以下更改来做到这一点，该文件默认存储在~/airflow/中。</p><ol class=""><li id="4574" class="mx my it lt b lu mo lx mp ma mz me na mi nb mm nc nd ne nf bi translated">设定<code class="fe mt mu mv mw b">executor = DaskExecutor</code></li><li id="e7a2" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">设置<code class="fe mt mu mv mw b">cluster_address = &lt;cluster_IP_address/cluster_port&gt;</code>。您可以使用<code class="fe mt mu mv mw b">cluster.scheduler_address</code>访问该地址</li><li id="d2c2" class="mx my it lt b lu ng lx nh ma ni me nj mi nk mm nc nd ne nf bi translated">设置集群的TLS设置:<code class="fe mt mu mv mw b">tls_cert</code>、<code class="fe mt mu mv mw b">tls_key</code>和<code class="fe mt mu mv mw b">tls_ca</code>。您可以使用<code class="fe mt mu mv mw b">client.security.tls_key</code>和<code class="fe mt mu mv mw b">client.security.tls_cert</code>来访问它们。注意<code class="fe mt mu mv mw b">tls_ca</code>的值与<code class="fe mt mu mv mw b">tls_cert</code>相同。</li></ol><p id="220e" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">然后，您可以在Coiled上运行整个气流DAG。</p><p id="bf1f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在启动盘绕式集群的脚本中包含一个<code class="fe mt mu mv mw b">cluster.adapt(minimum=1, maximum=20)</code>将确保集群根据工作负载在设定的最小和最大工作数量(在本例中为1到20)之间自适应地伸缩。</p><h1 id="ddd2" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">取得联系</h1><p id="dd2b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这里关注我，在Twitter 关注<a class="ae ky" href="https://twitter.com/richardpelgrim" rel="noopener ugc nofollow" target="_blank">了解更多类似的内容。</a></p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="a751" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><em class="mn">原载于2022年1月7日</em><a class="ae ky" href="https://coiled.io/blog/3-airflow-dag-examples-with-dask/" rel="noopener ugc nofollow" target="_blank"><em class="mn">https://coiled . io</em></a><em class="mn">。</em></p></div></div>    
</body>
</html>