<html>
<head>
<title>Exploring the LSTM Neural Network Model for Time Series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索时间序列的LSTM神经网络模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf#2022-01-13">https://towardsdatascience.com/exploring-the-lstm-neural-network-model-for-time-series-8b7685aa8cf#2022-01-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="1ee2" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">探索时间序列的LSTM神经网络模型</h1></div><div class=""><h2 id="9dd5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">scalecast库的实用、简单实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1d3af001ec4f65d725bc79ba7b4ec33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hifrjc8ugQfhZByYOVRdTw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5038" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">预测时间序列的最先进的模型之一是长短期记忆(LSTM)神经网络。根据Korstanje在他的书<em class="lr">中所说，使用Python进行高级预测</em>:</p><blockquote class="ls"><p id="0505" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated"><em class="mc">“LSTM细胞以一种更有效的方式增加了长期记忆，因为它允许学习更多的参数。这使得它成为最强大的(递归神经网络)来做预测，特别是当你的数据中有一个长期趋势时。LSTMs是目前最先进的预测模型之一，“</em> (2021)。</p></blockquote><p id="7e43" class="pw-post-body-paragraph kv kw iq kx b ky md jr la lb me ju ld le mf lg lh li mg lk ll lm mh lo lp lq ij bi translated">这是好消息。坏消息是，如果你在TensorFlow中使用过这个概念，你就会知道，设计和实现一个有用的LSTM模型并不总是简单的。网上有很多优秀的教程，但大多数都没有把你从A点(读取数据)带到Z点(从完成的模型中提取有用的、适当缩放的、未来预测的点)。我见过的很多教程在显示了训练过程中的损失图后就停止了，证明了模型的准确性。这是有用的，我感谢任何在这个问题上提供他们智慧的人，但这还不完全<em class="lr">。</em></p><p id="548e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">还有一个办法。</p><div class="mi mj gp gr mk ml"><a href="https://github.com/mikekeith52/scalecast" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd ir gy z fp mq fr fs mr fu fw ip bi translated">GitHub - mikekeith52/scalecast:使用这个独特的软件包进行大规模动态预测。pip安装…</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">该软件包使用Python中的可扩展预测方法，具有公共scikit-learn和statsmodels，以及…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">github.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz kp ml"/></div></div></a></div><p id="bf21" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae na" href="https://scalecast.readthedocs.io/en/latest/Forecaster/_forecast.html#module-src.scalecast.Forecaster.Forecaster._forecast_lstm" rel="noopener ugc nofollow" target="_blank"> scalecast </a>库托管TensorFlow LSTM，可轻松用于时间序列预测任务。该软件包旨在消除实施时间序列预测的许多麻烦。它在引擎盖下使用TensorFlow。以下是你应该尝试一下的一些理由:</p><ul class=""><li id="8a91" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq ng nh ni nj bi translated">易于实施和查看结果，大多数数据预处理和后处理在后台执行，包括缩放、取消缩放和评估置信区间</li><li id="73fa" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">测试模型是自动进行的——模型一次适合训练数据，然后再次适合完整的时间序列数据集(这有助于防止过度拟合，并为比较许多方法提供了一个公平的基准)</li><li id="e6c2" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">类似于TensforFlow，在验证数据的每个训练时期验证和观察损失是可能的和容易的</li><li id="4b58" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">针对其他建模概念的基准测试，包括脸书预言家和Scikit-learn模型，是可能且容易的</li></ul><p id="294a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">还有一些你可能会远离的原因:</p><ul class=""><li id="af87" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq ng nh ni nj bi translated">因为所有的模型都适合两次，训练一个已经很复杂的模型会慢两倍</li><li id="c078" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">您无法使用直接与TensorFlow合作所能提供的所有工具来干预模型</li><li id="7703" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq ng nh ni nj bi translated">对于一个鲜为人知的包，您永远不知道会出现什么不可预见的错误和问题</li></ul><p id="4fce" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">希望这能给你足够的时间来决定继续读下去是否值得。好了，让我们进入教程，你可以在这里找到笔记本形式的<a class="ae na" href="https://github.com/mikekeith52/scalecast-examples/blob/main/lstm/lstm.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="1d0a" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">数据预处理</h1><p id="14e7" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">首先，我们安装库:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="0f81" class="or nq iq on b be os ot l ou ov">pip install scalecast --upgrade</span></pre><p id="b605" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您还需要tensor flow(Windows版)或tensor flow-MAC OS(MAC版)。</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="fc3e" class="or nq iq on b be os ot l ou ov">pip install tensorflow</span></pre><p id="14ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">或者</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="9e5a" class="or nq iq on b be os ot l ou ov">pip install tensorflow-macos</span></pre><p id="267f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，让我们导入库并读入数据(可以在<a class="ae na" href="https://www.kaggle.com/rakannimer/air-passengers" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上通过开放数据库许可获得):</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="9b8d" class="or nq iq on b be os ot l ow ov">import pandas as pd<br/>import numpy as np<br/>import pickle<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from scalecast.Forecaster import Forecaster<br/><br/>df = pd.read_csv('AirPassengers.csv',parse_dates=['Month'])</span></pre><p id="a4c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该集合捕获了一家航空公司12年的月度航空乘客数据。它始于1949年1月，止于1960年12月。这是一个很好的预测数据集示例，因为它具有清晰的趋势和季节模式。我们来直观的看一下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/9263e75837aaa65bc55fb1d3922345be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4nWCbcoambKF0fhQ4xropQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="63ab" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">探索性数据分析</h1><p id="fffc" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">要开始使用scalecast进行预测，我们必须首先调用指定了<code class="fe oy oz pa on b">y</code>和<code class="fe oy oz pa on b">current_dates</code>参数的<code class="fe oy oz pa on b">Forecaster</code>对象，如下所示:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="6742" class="or nq iq on b be os ot l ow ov">&gt;&gt;&gt; f = Forecaster(<br/>&gt;&gt;&gt;    y=data['#Passengers'],<br/>&gt;&gt;&gt;    current_dates=data['Month']<br/>&gt;&gt;&gt; )<br/>&gt;&gt;&gt; f<br/><br/>Forecaster(<br/>    DateStartActuals=1949-02-01T00:00:00.000000000<br/>    DateEndActuals=1960-12-01T00:00:00.000000000<br/>    Freq=MS<br/>    ForecastLength=0<br/>    Xvars=[]<br/>    Differenced=0<br/>    TestLength=1<br/>    ValidationLength=1<br/>    ValidationMetric=rmse<br/>    CILevel=0.95<br/>    BootstrapSamples=100<br/>)</span></pre><p id="cc49" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们通过查看PACF(部分自相关函数)图来分解这个时间序列，该图测量y变量(在我们的情况下，航空乘客)与它本身的过去值的相关程度，以及统计上显著的相关性存在多远。PACF图与ACF图的不同之处在于，PACF控制了过去各项之间的相关性。很高兴看到这两个，这两个都在我为这篇文章创建的笔记本中，但只有PACF将在这里显示。</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="d632" class="or nq iq on b be os ot l ow ov">f.plot_pacf(lags=26)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/d40c252cef3fdb5e98d56593365ab218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nM89PREjuwDBTpDuBE5phA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ea9b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从这个图中，看起来在数据中可能存在长达两年的统计上显著的相关性。这将是建模时使用的好信息。让我们进一步将该系列分解为趋势、季节和剩余部分:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="f6fd" class="or nq iq on b be os ot l ow ov">f.seasonal_decompose().plot()<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/b600b664fcb35f58bf9555f895682c4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zZjxwvBGtRPkjFC9rl8i7Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a40f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们在这个数据中看到了明显的线性趋势和很强的季节性。残差似乎也遵循一种模式，尽管不清楚是哪种模式(因此，为什么它们是残差)。</p><p id="d3f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，让我们测试序列的平稳性。</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="3efa" class="or nq iq on b be os ot l ow ov">&gt;&gt;&gt; stat, pval, _, _, _, _ = f.adf_test(full_res=True)<br/>&gt;&gt;&gt; stat<br/>0.8153688792060569<br/>&gt;&gt;&gt; pval<br/>0.9918802434376411</span></pre><p id="4068" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">检查序列的平稳性很重要，因为大多数时间序列方法不能有效地模拟非平稳数据。“非平稳”是一个术语，表示数据的趋势不是均值回复，而是在整个系列的时间跨度内持续稳定地向上或向下。在我们的例子中，趋势显然不是平稳的，因为它逐年上升，但扩展的Dickey-Fuller测试的结果为我们的肉眼所见提供了统计上的证明。由于p值不小于0.05，我们必须假设序列是非平稳的。</p><p id="5cfc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有这些序言有时看起来都是多余的，但是在尝试建模之前彻底研究数据是一个很好的练习。在这篇文章中，我将探索阶段减少到了最低限度，但是如果我不做至少这么多，我会觉得自己疏忽了。</p><h1 id="fccc" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">LSTM预测</h1><p id="434f" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">要在scalecast中建模，我们需要完成以下三个基本步骤:</p><ol class=""><li id="ed49" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq pd nh ni nj bi translated"><strong class="kx ir">指定检验长度— </strong>检验长度是完整时间序列中最后一次观测值的离散数。您可以将百分比或离散数字传递给<code class="fe oy oz pa on b">set_test_length</code>函数。在较新的scalecast版本中，可以通过将测试长度设置为0来跳过测试。</li><li id="e71a" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq pd nh ni nj bi translated"><strong class="kx ir">生成未来日期— </strong>您在此步骤中生成的日期数将决定所有模型的预测时间。</li><li id="1c2a" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq pd nh ni nj bi translated"><strong class="kx ir">选择估计量</strong> —我们将使用“lstm”估计量，但也有其他几种估计量。</li></ol><p id="dc5f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要完成这些步骤，请参见下面的代码:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="eb80" class="or nq iq on b be os ot l ow ov">f.set_test_length(12)       # 1. 12 observations to test the results<br/>f.generate_future_dates(12) # 2. 12 future points to forecast<br/>f.set_estimator('lstm')     # 3. LSTM neural network</span></pre><p id="04e4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，打电话给LSTM天气预报。默认情况下，该模型将使用8大小的单个输入层、Adam优化器、tanh激活、用于训练的单个滞后因变量值、0.001的学习率和无辍学来运行。所有数据都通过最小-最大缩放器进行缩放，然后输出未缩放的数据。任何可以传递给<a class="ae na" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#Fit" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>中的<code class="fe oy oz pa on b">fit()</code>方法的东西，也可以传递给scalecast <code class="fe oy oz pa on b">manual_forecast()</code>方法。</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="9503" class="or nq iq on b be os ot l ow ov">f.manual_forecast(call_me='lstm_default')<br/>f.plot_test_set(ci=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/608a2cb1ee2d62834418f24e60031364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zUnMDCGAoDOhGBAL1N4W0w.png"/></div></div></figure><p id="1f01" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以预见的是，这种模式表现不佳。但事实上，我们能够轻松获得结果是一个巨大的开端。对其进行微调以产生有用的东西应该不会太难。</p><p id="bdf7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们从简单的开始，给它更多的滞后来预测。我们在PACF看到了24个月的显著自相关，所以让我们使用它:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="a941" class="or nq iq on b be os ot l ow ov">f.manual_forecast(call_me='lstm_24lags',lags=24)<br/>f.plot_test_set(ci=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/d741de9dbc54011d6beda00882855c24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g3hosP7gFi_DTu9gWXWjjw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="2844" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经看到了一些明显的改进，但这还远远没有准备好。一个明显的下一步可能是给它更多的时间来训练。在这个宇宙中，更多的时间意味着更多的纪元。让我们看看五个时代会带给我们什么。我们还在模型训练时通过指定下面的<code class="fe oy oz pa on b">validation_split=.2</code>来验证模型:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="597a" class="or nq iq on b be os ot l ow ov">f.manual_forecast(<br/>    call_me='lstm_24lags_5epochs',<br/>    lags=24,<br/>    epochs=5,<br/>    validation_split=.2,<br/>    shuffle=True,<br/>)<br/>f.plot_test_set(ci=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/ddb89f30bc3ae0e256b8901facead37b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*2xfJoqJl6P3zmxenVWsY-g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/31800b8e3d34ab2141ac09f61010dc6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9gHF5IRB-IMtJTpBj2o-0w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="439d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">再近一点。这次有几个值甚至落在95%的置信区间内。接下来，让我们尝试将网络中的层数增加到3，将历元增加到25，但监控验证损失值，并在超过5次迭代后告诉模型退出，如果没有改善。这就是所谓的提前停止。</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="f00c" class="or nq iq on b be os ot l ow ov">from tensorflow.keras.callbacks import EarlyStopping<br/><br/>f.manual_forecast(<br/>    call_me='lstm_24lags_earlystop_3layers',<br/>    lags=24,<br/>    epochs=25,<br/>    validation_split=.2,<br/>    shuffle=True,<br/>    callbacks=EarlyStopping(<br/>        monitor='val_loss',               <br/>        patience=5,<br/>    ),<br/>    lstm_layer_sizes=(16,16,16),<br/>    dropout=(0,0,0),<br/>)<br/><br/>f.plot_test_set(ci=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/4a0387f4b7fe58e4b3a91d361bd24d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*945HGmwdOt6vOJ-FqOGCig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d0c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">再次，缓慢改善。到目前为止，您可能已经厌倦了看到像这样的建模过程。给我找个能用的型号就行了！因此，我将直接跳到使用这种方法找到的最佳模型。参见代码:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="f342" class="or nq iq on b be os ot l ow ov">f.manual_forecast(<br/>    call_me='lstm_best',<br/>    lags=36,<br/>    batch_size=32,<br/>    epochs=15,<br/>    validation_split=.2,<br/>    shuffle=True,<br/>    activation='tanh',<br/>    optimizer='Adam',<br/>    learning_rate=0.001,<br/>    lstm_layer_sizes=(72,)*4,<br/>    dropout=(0,)*4,<br/>    plot_loss=True<br/>)<br/>f.plot_test_set(order_by='LevelTestSetMAPE',models='top_2',ci=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pg"><img src="../Images/440be2a6fd85f5f16ff4f93dd4c86d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aitWrskr1yjYnzPeAKoOHQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/c77417184cb0e4172186d310c2318f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y53vZSHxliUBmqAzxOu9XQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="20de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这花了很长时间，比我愿意承认的时间还要长，但最终我们有了一些像样的东西。除了两个点之外，所有的实际点都在模型的95%置信区间内。它唯一的问题是预测季节性高峰的最高点。这是一个我们可以考虑在现实世界中使用的模型。</p><h1 id="82aa" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">MLR预测和模型基准测试</h1><p id="7b24" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">现在我们终于找到了一个可接受的LSTM模型，让我们将其与一个简单的模型，最简单的模型，多元线性回归(MLR)进行比较，看看我们浪费了多少时间。</p><p id="32ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要在scalecast中从LSTM模式切换到MLR模式，我们需要遵循以下步骤:</p><ol class=""><li id="d847" class="nb nc iq kx b ky kz lb lc le nd li ne lm nf lq pd nh ni nj bi translated"><strong class="kx ir">选择MLR估计量</strong> —就像我们之前选择LSTM估计量一样。</li><li id="41eb" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq pd nh ni nj bi translated"><strong class="kx ir">向模型添加回归变量</strong>—在LSTM，我们只使用了系列自身的历史，并让模型自己参数化。使用MLR，我们仍然可以使用序列自身的历史，但我们也可以添加关于任何给定观测值属于哪个月、季度或年份的信息，以捕捉季节性和时间趋势(以及其他选项)。我们甚至可以摄取我们自己的回归变量的数据框架(这里没有显示)。</li><li id="149e" class="nb nc iq kx b ky nk lb nl le nm li nn lm no lq pd nh ni nj bi translated"><strong class="kx ir">差异非平稳数据</strong> —这是我们如何减轻显示我们有非平稳数据的增强Dickey-Fuller测试的结果。我们也可以在LSTM身上做到这一点，但我们希望它足够复杂，不需要这一步。</li></ol><p id="71a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这都是在下面的代码中完成的:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="1768" class="or nq iq on b be os ot l ow ov">from scalecast.SeriesTransformer import SeriesTransformer<br/><br/>transformer = SeriesTransformer(f)<br/>f = transformer.DiffTransform()<br/><br/>f.add_ar_terms(24)<br/>f.add_seasonal_regressors('month','quarter',dummy=True)<br/>f.add_seasonal_regressors('year')<br/>f.add_time_trend()</span></pre><p id="adbd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们运行预测，并对照最佳LSTM模型查看MLR的测试集性能:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="d649" class="or nq iq on b be os ot l ow ov">f.set_estimator('mlr')<br/>f.manual_forecast()<br/><br/>f = transformer.DiffRevert(<br/>    exclude_models = [m for m in f.history if m != 'mlr']<br/>) # exclude all lstm models from the revert<br/><br/>f.plot_test_set(order_by='TestSetMAPE',models=['lstm_best','mlr'])<br/>plt.title('Top-2 Models Test-set Performance - Level Data',size=16)<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/6bf5b61344be84c968d0c457d54c6a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YBsMtVLS3WWtqEDSLsIF2Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1a68" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">绝对难以置信。用最简单的模型，我们很快就造出了比最先进的模型更好的东西。这可能是由于用户错误造成的。也许你可以用LSTM模型找到比我发现的更好的东西——如果是这样，请留下评论并分享你的代码。但我预测了足够多的时间序列，知道在这种情况下很难超越简单的线性模型。也许，由于数据集的规模很小，LSTM模型从一开始就不合适。</p><p id="202c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后我们可以看到我们的模型对未来数据的预测:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="e46d" class="or nq iq on b be os ot l ow ov">f.plot(<br/>    models=['mlr','lstm_best'],<br/>    order_by='LevelTestSetMAPE',<br/>    level=True,<br/>)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/0b573c3210de9e7aa3f4f2c50fb12cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZlmGx9nejCOKL8WRnm4ZIw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e769" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还可以在样本外测试数据上看到所有模型的误差和准确性指标:</p><pre class="kg kh ki kj gt om on oo bn op oq bi"><span id="7c20" class="or nq iq on b be os ot l ow ov">f.export('model_summaries',determine_best_by='LevelTestSetMAPE')[<br/>    ['ModelNickname',<br/>     'LevelTestSetMAPE',<br/>     'LevelTestSetRMSE',<br/>     'LevelTestSetR2',<br/>     'best_model']<br/>]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/eb14736f0d77dbd12991fb845cf35562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*YxnyLn1Umu0HJal_JXhYfg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="81af" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">scalecast软件包使用动态预测和测试方法，通过自己的预测传播AR/lagged值，因此不存在数据泄漏。MLR模型没有过度拟合。</p><h1 id="62b0" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">结论</h1><p id="9620" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">我希望你喜欢这个关于如何在scalecast中与LSTM一起建模的快速概述。希望你学到了一些东西。我的观点是，对于任何给定的问题，立即采用最先进的方法并不总是明智的。更简单的模型通常更好、更快、更容易理解。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/926d4f4a4c6621a08d0c8b6fad7c2211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PN9ZV1otYBXsM2Kw"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">布雷特·乔丹在<a class="ae na" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="65f7" class="np nq iq bd nr ns nt nu nv nw nx ny nz jw oa jx ob jz oc ka od kc oe kd of og bi translated">引用的作品</h1><p id="fb8a" class="pw-post-body-paragraph kv kw iq kx b ky oh jr la lb oi ju ld le oj lg lh li ok lk ll lm ol lo lp lq ij bi translated">Korstanje，J. (2021)。LSTM RNNs。在J. Korstanje的文章中，<em class="lr">使用Pyton </em>进行高级预测(第243–251页)。加州伯克利:新闻。</p></div></div>    
</body>
</html>