<html>
<head>
<title>Training On AWS with Habana Gaudi</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Habana Gaudi的AWS培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-on-aws-with-habana-gaudi-3126e183048#2022-01-17">https://towardsdatascience.com/training-on-aws-with-habana-gaudi-3126e183048#2022-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="0cfc" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">Habana Gaudi的AWS培训</h1></div><div class=""><h2 id="7241" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用专用DNN训练芯片的力量—第2部分</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d26a25c7e658fd1fccc7c1bb870f5abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lGZqPqFRhe6ThGod"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://en.wikipedia.org/wiki/Antoni_Gaud%C3%AD" rel="noopener ugc nofollow" target="_blank">安东尼·高迪</a>设计的圣家族大教堂的中殿，由<a class="ae kv" href="https://unsplash.com/@wiwid?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维德·昆乔罗</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="ac4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今年十月，AWS <a class="ae kv" href="https://aws.amazon.com/blogs/aws/new-ec2-instances-powered-by-gaudi-accelerators-for-training-deep-learning-models/" rel="noopener ugc nofollow" target="_blank">宣布</a>亚马逊<a class="ae kv" href="https://aws.amazon.com/ec2/instance-types/dl1/" rel="noopener ugc nofollow" target="_blank">EC2 DL1实例类型</a>的到来。DL1由8个Habana Gaudi加速器驱动，是第一个包含专用AI加速器的AWS实例类型，这些加速器是<strong class="ky ir">而不是</strong>GPU。Habana Gaudi以著名的加泰罗尼亚建筑师<a class="ae kv" href="https://en.wikipedia.org/wiki/Antoni_Gaud%C3%AD" rel="noopener ugc nofollow" target="_blank">Antoni Gaudi</a>的名字命名，是一款全新的人工智能ASIC，专门为深度学习工作负载而从头设计。这提供了提高资源利用率和降低培训成本的潜力。事实上，DL1实例已经向全世界发布，并承诺“比当前一代基于GPU的实例的性价比高40%”。</p><p id="4536" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文中，我们将评估DL1实例，并展示它的一些独特属性。这是上一篇<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">文章</a>的续篇，在那篇文章中，我们讨论了使用专用人工智能芯片的潜力以及采用它们的一些潜在挑战。在那里，我们建议将您的训练应用程序迁移到新的人工智能芯片的任务分解为四个步骤:</p><ol class=""><li id="165a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">高级兼容性分析</strong>:尽早评估您的工作负载特性是否符合芯片规格和支持软件堆栈。</li><li id="4971" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">调整您的模型以在新芯片上运行</strong>:您可能需要对您的模型进行一些调整，例如替换专用人工智能芯片不支持的操作。</li><li id="facc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">优化新芯片的运行时性能</strong>:为了充分利用芯片，您需要分析并最大化其利用率。</li><li id="2527" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">调整模型以在新芯片上收敛</strong>:可能需要对模型超参数进行一些修改，以确保及时收敛。</li></ol><p id="3f40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些步骤在我们之前的<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">帖子</a>中有详细描述。在本帖中，我们将按照这些步骤评估DL1实例。</p><p id="cfbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博文和我们包含的代码片段是基于撰写本文时可用的最新软件栈，<a class="ae kv" href="https://docs.habana.ai/en/latest/Installation_Guide/GAUDI_Installation_Guide.html#release-versions" rel="noopener ugc nofollow" target="_blank">版本1.2.0 </a>。鉴于Habana Gaudi产品的相对新颖性，新版本可能会包括重要的增强和优化。您必须使用最新的可用软件堆栈，并确保相应地重新评估我们的一些陈述。<br/>虽然我们将专注于<a class="ae kv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">tensor flow</a>2.7版本，但我们写的大部分内容也同样适用于Habana Gaudi支持的其他机器学习框架。</p><h1 id="4768" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">1.高级兼容性评估</h1><p id="9be2" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">此步骤的目的是收集尽可能多的公开信息，以便评估DL1产品是否满足了您的培训需求。这包括以下在线资源:</p><ul class=""><li id="8459" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nd ly lz ma bi translated"><strong class="ky ir">系统架构规格</strong>:<a class="ae kv" href="https://aws.amazon.com/ec2/instance-types/dl1/" rel="noopener ugc nofollow" target="_blank">DL1硬件细节</a>以及<a class="ae kv" href="https://docs.habana.ai/en/latest/Gaudi_Overview/Gaudi_Overview.html#gaudi-architecture" rel="noopener ugc nofollow" target="_blank"> Habana Gaudi架构指南</a>应该能让你对机器的训练能力有一个大致的了解。特别是，您可以验证内存、计算和其他硬件资源是否符合您的需求。</li><li id="21e1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">软件文档</strong> : Habana Gaudi附带了一个名为<a class="ae kv" href="https://docs.habana.ai/en/latest/Gaudi_Overview/Gaudi_Overview.html#synapseai-software-suite" rel="noopener ugc nofollow" target="_blank"> SynapseAI软件套件</a>的综合软件堆栈。<a class="ae kv" href="https://docs.habana.ai/en/latest/#getting-started" rel="noopener ugc nofollow" target="_blank">开发者文档</a>包括支持的<a class="ae kv" href="https://docs.habana.ai/en/latest/#getting-started" rel="noopener ugc nofollow" target="_blank">框架和版本</a>、<a class="ae kv" href="https://docs.habana.ai/en/latest/Release_Notes/GAUDI_Release_Notes.html#known-issues-and-limitations-1-2-0" rel="noopener ugc nofollow" target="_blank"> API限制</a>等细节。有几个<a class="ae kv" href="https://docs.habana.ai/en/latest/#synapseai-user-guides" rel="noopener ugc nofollow" target="_blank">用户指南</a>演示了如何使用API套件的许多特性。<br/>使用软件文档来验证支持的框架、版本和操作是否满足您的机器学习项目的需求。</li><li id="b559" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">基准测试报告</strong>:哈伯纳在各种流行的模型架构上分享了性能<a class="ae kv" href="https://developer.habana.ai/resources/habana-training-models/" rel="noopener ugc nofollow" target="_blank">基准测试结果</a>。你可以将这些与其他人工智能加速器厂商的<a class="ae kv" href="https://developer.nvidia.com/deep-learning-performance-training-inference" rel="noopener ugc nofollow" target="_blank">性能结果进行比较。您还可以查看</a><a class="ae kv" href="https://mlcommons.org/en/" rel="noopener ugc nofollow" target="_blank"> MLPerf </a>，这是一个流行的人工智能培训基准套件，可以比较多个人工智能加速器(包括Habana Gaudi)在各种工作负载上的性能。最新的MLPerf报告摘要(在撰写本文时)可在<a class="ae kv" href="https://habana.ai/mlperf-ai-training-benchmark-habana-gaudi-performance-and-scale-results/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。<br/>基准测试结果可以让你了解高迪擅长的车型类型。然而，正如我们在<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">之前的帖子</a>中所警告的，除非您正在训练的模型与基准报告中包含的模型之一相同，否则根据报告的基准来预测您自己的模型的性能可能不那么容易。这是因为模型中的小变化会对其运行时性能产生有意义的影响。</li></ul><p id="7e80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与任何其他新颖的硬件产品一样，要真正感受DL1的功能，除了开始使用它之外，没有其他更好的方法了。是的，您确实面临着投资进入潜在死胡同的风险，但我们相信，即使您最终没有在DL1上培训您当前的模型，您在此过程中积累的知识和技能也会很好地为您服务。</p><p id="5ddc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的项目中，我们总结了与其他人工智能加速器和训练实例相比，基于高迪的DL1产品的一些主要亮点。接下来是一些潜在的担忧。这些都是基于我们自己的个人印象。我们的列表并不全面，也不应该被视为官方文件的替代品。</p><ul class=""><li id="ad3c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nd ly lz ma bi translated"><strong class="ky ir">异构架构</strong>:单个Gaudi内核，有时被称为HPU (Habana处理单元)，由一群张量处理内核(TPC)和可配置矩阵数学引擎(GEMM)组成。GEMM擅长矩阵乘法，而非线性和元素运算在TPC上运行。这种异构性使Gaudi能够在各种各样的工作负载上实现高效率。通过有效地平衡资源之间的负载，可以实现最大的利用率。</li><li id="62ec" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">高规模训练</strong>:架构设计特别注重高迪处理器之间的数据吞吐速度。这使得高迪能够<a class="ae kv" href="https://habana.ai/mlperf-ai-training-benchmark-habana-gaudi-performance-and-scale-results/" rel="noopener ugc nofollow" target="_blank">展示</a>当将训练扩展到多核时，出色的、接近线性的结果。</li><li id="b510" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">框架支持</strong>:SynapseAI API包括对<a class="ae kv" href="https://docs.habana.ai/en/latest/Tensorflow_User_Guide/Tensorflow_User_Guide.html" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和<a class="ae kv" href="https://docs.habana.ai/en/latest/PyTorch_User_Guide/PyTorch_User_Guide.html" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的支持，这是目前使用的最流行的两个机器学习框架。它还支持<a class="ae kv" href="https://horovod.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> Horovod </a>，这是一个流行的分布式培训框架。这些产品使得现代机器学习开发人员非常容易为Gaudi创建模型。</li><li id="3bb2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">丰富的模型花园</strong>:Habana SW产品包括各种各样的<a class="ae kv" href="https://github.com/HabanaAI/Model-References" rel="noopener ugc nofollow" target="_blank">参考模型</a>——已经移植并优化用于在Gaudi上运行的流行模型的实现。</li><li id="515f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">定制内核创建</strong>:与其他一些专用AI ASICs相反，SynapseAI SW套件包括用于<a class="ae kv" href="https://docs.habana.ai/en/latest/TPC_User_Guide/TPC_User_Guide.html#tpc-user-guide" rel="noopener ugc nofollow" target="_blank">实现定制Gaudi (TPC)内核的工具</a>。与用于GPU内核开发的<a class="ae kv" href="https://developer.nvidia.com/cuda-toolkit" rel="noopener ugc nofollow" target="_blank"> CUDA工具包</a>类似，这一功能使用户能够设计、开发和优化专门针对其工作负载需求的低级操作。</li><li id="f941" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">运行并行试验</strong>:SW套件支持在DL1实例上的八个底层Gaudi加速器的不相交子集上运行并行工作负载。一种方法是使用训练管弦乐队，比如kubernetes。我们将演示如何利用这种能力来并行化超参数调优试验。</li><li id="4524" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir"> CPU与Gaudi计算比率</strong>:在一个标准的机器学习项目中，计算将在CPU资源和AI加速器之间分配。通常，输入数据预处理管道将在CPU上运行，模型计算图(向前向后传递)将在AI加速器上运行。在理想情况下<em class="ne">所有的</em>培训资源都将被充分利用。但是最大化利用率对于AI加速器资源是最重要的，这些资源通常是系统中最强大和最昂贵的资源。在某些情况下，你可能会发现CPU跟不上人工智能加速器的速度，导致CPU瓶颈和人工智能加速器的利用不足。CPU瓶颈的可能性由整体CPU计算能力和整体加速器计算能力之间的比率决定。DL1实例具有相对较高的CPU与Gaudi计算比率，从而降低了CPU瓶颈和加速器利用不足的可能性。事实上，DL1实例包含与<a class="ae kv" href="https://aws.amazon.com/ec2/instance-types/p4/" rel="noopener ugc nofollow" target="_blank"> p4d.24xlarge </a> EC2实例相同的CPU计算能力(96个第二代英特尔至强可扩展CPU内核)，尽管其AI加速器A100被认为比Habana Gaudi更强大。</li><li id="bb27" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">批量灵活性</strong>:与其他人工智能加速器相反，Habana Gaudi能够在很大的批量范围内实现高利用率，而其他人工智能加速器可能需要特别高的批量培训，以便充分利用硬件的价格优势。这使得高迪成为可能无法适应大批量生产的模型的可行选择。</li></ul><p id="2a99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是您应该考虑的几点:</p><ul class=""><li id="d08d" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nd ly lz ma bi translated"><strong class="ky ir"> API限制</strong>:确保仔细阅读SynapseAI软件套件的限制。正如在撰写本文时在<a class="ae kv" href="https://habana.ai/mlperf-ai-training-benchmark-habana-gaudi-performance-and-scale-results/" rel="noopener ugc nofollow" target="_blank">文档</a>中明确指出的那样，“并非所有的模型在Gaudi上都得到支持”。如果您不能在DL1上编译您的模型，您可以尝试调整您的模型以符合API支持，或者探索<a class="ae kv" href="https://docs.habana.ai/en/latest/TensorFlow_CustomOp_API/page_index.html#" rel="noopener ugc nofollow" target="_blank">创建定制操作</a>的选项。或者，您可以简单地报告您的发现并跟踪<a class="ae kv" href="https://github.com/HabanaAI/synapseai-roadmap" rel="noopener ugc nofollow" target="_blank">synapse ai版本的未来版本</a>。</li><li id="eaf0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">每个DL1实例八个加速器</strong>:在撰写本文时，唯一基于Gaudi的AWS实例产品包括八个加速器。这意味着，为了充分利用这个系统，你需要或者运行并行实验，或者将你的训练分布在所有的加速器上。如果这两个选项都不适合您，那么DL1实例可能不是您的最佳选择。</li><li id="889b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nd ly lz ma bi translated"><strong class="ky ir">性价比</strong>:你可能会发现你的型号<em class="ne">是</em>支持的，但是你最初的试用并没有达到你预期的性价比。在这种情况下，您可以使用Habana <a class="ae kv" href="https://docs.habana.ai/en/latest/Model_Performance_Optimization/Model_Performance_Optimization_in_Habana_Gaudi.html" rel="noopener ugc nofollow" target="_blank">优化指南</a>、<a class="ae kv" href="https://docs.habana.ai/en/latest/Profiler_Guide/Profiler_User_Guide.html" rel="noopener ugc nofollow" target="_blank">性能分析指南</a>、<a class="ae kv" href="https://docs.habana.ai/en/latest/TensorFlow_CustomOp_API/page_index.html#" rel="noopener ugc nofollow" target="_blank">自定义op创建指南</a>和其他资源来提高性能。如果尽管你尽了一切努力，你还是不能达到足够的性价比，你最好的选择可能是报告你的发现，并等待SynapseAI套件的更新版本。</li></ul><h1 id="ad8b" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">2.调整您的模型以在DL1上运行</h1><p id="d247" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本节中，我们将讨论在DL1实例上启动和运行模型所需的一些步骤。这些都基于Habana官方文档，尤其是<a class="ae kv" href="https://docs.habana.ai/en/latest/Migration_Guide/Migration_Guide.html#porting-a-simple-tensorflow-model-to-gaudi" rel="noopener ugc nofollow" target="_blank"> TensorFlow迁移指南</a>。更多详情请见此处。</p><h2 id="a295" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">系统设置</h2><p id="87ed" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">有多种方法可以启动一个<a class="ae kv" href="https://aws.amazon.com/ec2/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2 </a>实例和<a class="ae kv" href="https://aws.amazon.com/ec2/" rel="noopener ugc nofollow" target="_blank">建立一个DL1运行时环境</a>。最适合您的选择将取决于您/您组织的整体云架构。</p><h2 id="5125" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">加载Habana模块</h2><p id="0669" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">调整TensorFlow模型以在Habana Gaudi上运行只需要两行代码，如下面摘自<a class="ae kv" href="https://github.com/HabanaAI/Model-References/blob/1.2.0/TensorFlow/examples/hello_world/example.py" rel="noopener ugc nofollow" target="_blank"> Habana TensorFlow Hello World示例</a>的代码片段所示。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="e803" class="nf mh iq ns b gy nw nx l ny nz">import tensorflow as tf<br/><strong class="ns ir">from habana_frameworks.tensorflow import load_habana_module<br/>load_habana_module()</strong></span><span id="3b1a" class="nf mh iq ns b gy oa nx l ny nz">(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()<br/>x_train, x_test = x_train / 255.0, x_test / 255.0</span><span id="4809" class="nf mh iq ns b gy oa nx l ny nz">model = tf.keras.models.Sequential([<br/>            tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>            tf.keras.layers.Dense(10),<br/>])<br/>loss = tf.keras.losses.SparseCategoricalCrossentropy(<br/>                                           from_logits=True)<br/>optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)</span><span id="22ee" class="nf mh iq ns b gy oa nx l ny nz">model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])</span><span id="404c" class="nf mh iq ns b gy oa nx l ny nz">model.fit(x_train, y_train, epochs=5, batch_size=128)</span></pre><p id="e651" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行脚本时，确保使用适当的python可执行文件。这取决于您选择的设置，如这里的<a class="ae kv" href="https://github.com/HabanaAI/Setup_and_Install#setup-python" rel="noopener ugc nofollow" target="_blank"/>所示。</p><h2 id="bfcf" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">检查设备放置</h2><p id="bd57" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">当运行你的脚本时，你要做的第一件事就是验证你的模型确实运行在Gaudi加速器上。高迪运行时环境包括<a class="ae kv" href="https://docs.habana.ai/en/latest/System_Management_Tools_Guide/System_Management_Tools.html" rel="noopener ugc nofollow" target="_blank"> <em class="ne"> hl-smi </em>工具</a>，它报告八个高迪内核的资源利用情况。它的外观和感觉类似于用于GPU的<a class="ae kv" href="https://developer.nvidia.com/nvidia-system-management-interface" rel="noopener ugc nofollow" target="_blank"> <em class="ne"> nvidia-smi </em>工具</a>。您可以使用该工具来验证运行您的训练脚本是否增加了第一个Gaudi内核的内存和计算资源。<br/>除了断言正在使用Gaudi内核之外，您还会希望确保您的训练计算图的所有操作都在Gaudi上运行，而不是在CPU上运行。Gaudi不支持的操作被卸载到CPU上，这可能会导致很高的事务开销，并大大降低您的培训速度。<br/>检查器件布局的一种方法是使用<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/debugging/set_log_device_placement" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . debugging . set _ log _ device _ placement</em></a>函数。当设置为<em class="ne"> True </em>时，该例程将生成一个日志，记录程序中所有TensorFlow操作的设备位置。高迪核心在TensorFlow中注册为“HPU”设备。如果你所有的训练任务都分配给“HPU ”,你的情况就很好。如果你的任何训练运算被分配给“CPU ”,你可能需要调整你的计算图，我们将在下一小节讨论。<br/>此处记录了分析op布局的另一种方法<a class="ae kv" href="https://docs.habana.ai/en/latest/Model_Performance_Optimization/Model_Performance_Optimization_in_Habana_Gaudi.html#place-ops-in-hpu" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a781" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">示例—使用不支持的数据类型</strong>:在下面的代码片段中，我们添加了对<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/math/argmax" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . math . arg max</em></a><em class="ne"/>的调用，后跟<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/math/equal" rel="noopener ugc nofollow" target="_blank"> <em class="ne"> tf.equal </em> </a>。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="6b61" class="nf mh iq ns b gy nw nx l ny nz">import tensorflow as tf<br/>from habana_frameworks.tensorflow import load_habana_module<br/>load_habana_module()<br/><strong class="ns ir">tf.debugging.set_log_device_placement(True)<br/></strong>(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()</span><span id="45b1" class="nf mh iq ns b gy oa nx l ny nz">x_train, x_test = x_train / 255.0, x_test / 255.0</span><span id="cb3f" class="nf mh iq ns b gy oa nx l ny nz">model = tf.keras.models.Sequential([<br/>            tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>            tf.keras.layers.Dense(10),<br/>            tf.keras.layers.Lambda(lambda x: <br/>               tf.where(tf.expand_dims(<strong class="ns ir">tf.equal</strong>(<br/>                  <strong class="ns ir">tf.math.argmax</strong>(x,axis=-1),2),-1),<br/>                  x,<br/>                  tf.math.square(x)))])<br/>loss =  tf.keras.losses.SparseCategoricalCrossentropy(<br/>                                          from_logits=True)<br/>optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)<br/>model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])<br/>model.fit(x_train, y_train, epochs=5, batch_size=128)</span></pre><p id="e86d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/math/argmax" rel="noopener ugc nofollow" target="_blank"> <em class="ne"> tf.math.argmax </em> </a>的默认输出为tf.int64类型，然而，截至本文撰写之时，int64并不在HPU 支持的<a class="ae kv" href="https://www.google.com/search?q=%D7%94%D7%A8%D7%98%D7%95%D7%9D+13+%D7%94%D7%A8+%D7%97%D7%95%D7%A6%D7%91%D7%99%D7%9D&amp;rlz=1C1GCEB_enIL904IL904&amp;oq=%D7%94%D7%A8%D7%98%D7%95%D7%9D+13&amp;aqs=chrome.2.69i57j0i19j0i19i22i30l3.8084j0j7&amp;sourceid=chrome&amp;ie=UTF-8" rel="noopener ugc nofollow" target="_blank">数据类型列表中。结果是</a><a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/math/equal" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . equal</em></a><em class="ne"/>操作将在CPU上运行。器件放置调试日志将包括以下几行:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="3e8f" class="nf mh iq ns b gy nw nx l ny nz">sequential/lambda/ArgMax: (ArgMax): /job:localhost/replica:0/task:0/device:HPU:0<br/>sequential/lambda/Equal: (Equal): /job:localhost/replica:0/task:0/<strong class="ns ir">device:CPU</strong>:0</span></pre><p id="59a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个玩具示例中，修复方法是简单地将<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/math/argmax" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . math . arg max</em></a><em class="ne"/>的<em class="ne"> output_type </em>设置为tf.int32。</p><h2 id="32d8" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">模型调整</h2><p id="f035" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在HPU上训练模型可能需要对模型进行一些更改。所需的模型调整在复杂程度上会有所不同。在某些情况下，它们就像指定底层数据类型一样简单，如上例所示。在其他情况下，您可能需要修改数据流或替换操作序列。例如，SynapseAI 1.2.0版本的<a class="ae kv" href="https://docs.habana.ai/en/latest/Release_Notes/GAUDI_Release_Notes.html#tensorflow-known-issues" rel="noopener ugc nofollow" target="_blank">发行说明</a>中包含了“Gaudi目前不支持<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/cond" rel="noopener ugc nofollow" target="_blank"> tf.cond </a>和<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/while_loop" rel="noopener ugc nofollow" target="_blank"> tf.while_loop </a>等控制流操作”的限制。在撰写本文时，Gaudi不支持的另一个操作示例是<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/numpy_function" rel="noopener ugc nofollow" target="_blank"> tf.numpy_function </a>，这是一个允许在计算图中包含任意python代码(例如用于度量计算)的例程，有时用于绕过本机TensorFlow API施加的限制。如果您的模型包含这样的操作，您将需要设计一个替代流程，或者接受让它们在CPU上运行的性能损失。</p><p id="cca1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您需要为高迪进行模型调整的三个重要资源是HPU支持的TensorFlow操作的<a class="ae kv" href="https://docs.habana.ai/en/latest/TensorFlow_Operators/TF_Operators.html#tensorflow-operators" rel="noopener ugc nofollow" target="_blank">列表、</a><a class="ae kv" href="https://github.com/HabanaAI/Model-References" rel="noopener ugc nofollow" target="_blank">模型参考目录</a>和<a class="ae kv" href="https://docs.habana.ai/en/latest/TPC_User_Guide/TPC_User_Guide.html#tpc-user-guide" rel="noopener ugc nofollow" target="_blank">定制内核创建指南</a>。</p><p id="5795" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/TensorFlow_Operators/TF_Operators.html#tensorflow-operators" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">支持的TensorFlow操作</strong> </a>:使用本文档在图形中查找高迪对操作的支持。</p><p id="8874" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/HabanaAI/Model-References" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">模型参考目录</strong> </a>:哈瓦那高迪产品包括各种常见机器学习模型架构的参考实现。这些实现已经过修改和调整，可以在高迪上运行。如果您正在使用其中一种实现的架构，您应该认为自己很幸运。但是，即使您使用的是不同的模型架构，模型参考目录中也可能包含您认为有用的计算层或计算块。例如，如果您正在研究变压器架构，最好查看一下变压器块<a class="ae kv" href="https://github.com/HabanaAI/Model-References/blob/master/TensorFlow/nlp/transformer/layers/transformer_layers.py" rel="noopener ugc nofollow" target="_blank">和</a>的高迪特定实现，要么照原样使用，要么深入了解如何对您自己的变压器块进行适当的调整。</p><p id="e6d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/TPC_User_Guide/TPC_User_Guide.html#tpc-user-guide" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">自定义内核创建</strong></a>:Habana Gaudi区别于市场上其他一些专用AI ASICs的特性之一是其可由最终用户编程。Habana提供了关于<a class="ae kv" href="https://docs.habana.ai/en/latest/TPC_User_Guide/TPC_User_Guide.html#tpc-user-guide" rel="noopener ugc nofollow" target="_blank">创建定制HPU内核</a>和<a class="ae kv" href="https://docs.habana.ai/en/latest/TensorFlow_CustomOp_API/page_index.html" rel="noopener ugc nofollow" target="_blank">用TensorFlow操作符包装它们</a>的全面指南。也可以看看<a class="ae kv" href="https://github.com/HabanaAI/Model-References/tree/master/TensorFlow/examples/custom_op" rel="noopener ugc nofollow" target="_blank">这个详细的例子</a>和这个<a class="ae kv" href="https://vimeo.com/543215096" rel="noopener ugc nofollow" target="_blank">视频教程</a>。</p><p id="1276" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">预处理流水线</strong>:需要注意的是，虽然将你的模型移植到Gaudi可能需要改变运行在加速器上的训练计算图，但是<em class="ne">不</em>需要调整运行在CPU内核上的预处理流水线。这与其他一些人工智能加速器相反，正如我们在过去看到的<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138"/>。</p><h2 id="ed5d" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated">关于DL1的分布式培训</h2><p id="280f" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">当然，要充分利用DL1资源，仅将其移植到单个HPU上运行是不够的；您将希望利用所有八个hpu。一种方法是使用<a class="ae kv" href="https://docs.habana.ai/en/latest/Tensorflow_Scaling_Guide/TensorFlow_Gaudi_Scaling_Guide.html" rel="noopener ugc nofollow" target="_blank">数据分布式训练</a>在所有八个hpu上并行训练。Habana Gaudi软件堆栈提供了两种实施分布式培训的机制。第一个使用了Habana Gaudi流行的<a class="ae kv" href="https://horovod.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"> Horovod </a>框架的具体实现。第二个使用了一个定制的<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy" rel="noopener ugc nofollow" target="_blank">TF . distribute . strategy</a>API实现。<a class="ae kv" href="https://docs.habana.ai/en/latest/Tensorflow_Scaling_Guide/TensorFlow_Gaudi_Scaling_Guide.html" rel="noopener ugc nofollow" target="_blank">分布式培训指南</a>包括两个选项的详细信息。<br/>选择Horovod选项的优势在于，如果您已经使用Horovod for GPUs实施了分布式培训，则无需更改代码即可在hpu上运行。您需要做的只是验证<a class="ae kv" href="https://github.com/HabanaAI/Setup_and_Install#check-tfhorovod-habana-packages" rel="noopener ugc nofollow" target="_blank"> habana-horovod套件</a>的正确安装。事实上，与其他定制AI ASIC产品相比，Horovod支持是Habana产品的优势之一。</p><p id="eacd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，在撰写本文时，遵守导入命令的特定顺序很重要，如摘自<a class="ae kv" href="https://docs.habana.ai/en/latest/Tensorflow_Scaling_Guide/TensorFlow_Gaudi_Scaling_Guide.html#example-scale-up-within-a-server" rel="noopener ugc nofollow" target="_blank"> Habana Gaudi文档</a>的这段代码所示。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="7ba2" class="nf mh iq ns b gy nw nx l ny nz">import tensorflow as tf<br/>from habana_frameworks.tensorflow import load_habana_module<br/><strong class="ns ir"><em class="ne"># ensure that load_habana_module() needs to be called before<br/># import horovod</em></strong><br/>load_habana_module()<br/>import horovod.tensorflow.keras as hvd<br/><em class="ne">#Initialization of Horovod. </em><br/>hvd.init()</span></pre><p id="ba1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Horovod框架也可用于在<a class="ae kv" href="https://docs.habana.ai/en/latest/AWS_Distributed_Training_Multiple_DL1/AWS_Distributed_Training_Multiple_DL1.html" rel="noopener ugc nofollow" target="_blank">多个DL1实例上并行训练</a>。</p><h1 id="4b44" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">3.在DL1上优化您的模型性能</h1><p id="e814" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">此时，您应该能够在DL1上成功运行一个培训周期。接下来是性能分析和优化的关键步骤。正如我们在<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">上一篇文章</a>中强调的，人工智能加速器的好坏取决于它为性能分析和优化提供的工具。如果你不能分析和优化性能，你就不能充分利用人工智能芯片。</p><p id="95c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Habana为性能分析和优化提供了三个重要的资源:最佳实践列表(T0)、T2性能优化指南(T3)和T4性能分析器(T5)。应该详细研究这些指南并经常参考。我们将对每一个提供一些简短的评论。</p><h2 id="f24f" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/Best_Practices_for_Model_Training/Best_Practices_for_Model_Training_on_Gaudi.html" rel="noopener ugc nofollow" target="_blank">高迪培训的最佳实践</a></h2><p id="eab4" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">这个页面包括关于高迪培训的一般(框架不可知)指南。虽然这个列表很紧凑(在撰写本文时只有7点)，但是每一项都可以对模型性能产生有意义的影响。有两点值得一提:</p><ol class=""><li id="93c1" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">动态形状</strong>:不鼓励使用返回未确定大小的形状的操作符。参见我们之前的<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">帖子</a>，在其中我们演示了如何替换使用一个这样的函数，<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/boolean_mask" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . boolean _ mask</em></a>。</li><li id="9906" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">张量形状</strong>:有些项目建议张量形状的选择(如批量大小和特征/通道数量)遵循一定的公式。这对于一个专门的人工智能加速器(或者任何芯片，就此而言)来说并不罕见。正如我们在第1节中提到的，其他AI芯片需要使用大批量来最大化利用率。在这方面，高迪为用户提供了更大的自由/灵活性。</li></ol><h2 id="13e1" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/Model_Performance_Optimization/Model_Performance_Optimization_in_Habana_Gaudi.html" rel="noopener ugc nofollow" target="_blank">性能优化指南</a></h2><p id="9577" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">本页主要关注TensorFlow框架的优化指南。其中一个建议是利用高迪内置的对<a class="ae kv" href="https://docs.habana.ai/en/latest/Tensorflow_User_Guide/Tensorflow_User_Guide.html#tf-mixed-precision-training" rel="noopener ugc nofollow" target="_blank"> bfloat16 </a>的支持，使用<a class="ae kv" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> TensorFlow的混合精度API</a>。在训练期间使用低精度浮点(16位)可以潜在地减少存储器使用和训练步骤时间。有两种低精度浮点格式，float16和<a class="ae kv" href="https://cloud.google.com/tpu/docs/bfloat16" rel="noopener ugc nofollow" target="_blank"> bfloat16 </a>，bfloat16具有许多属性，使其成为机器学习的首选格式。<br/>需要注意的是，虽然使用混合精度时内存利用率的降低几乎是可以保证的，但步长时间的降低以及模型的收敛能力仍需验证。</p><h2 id="bc4b" class="nf mh iq bd mi ng nh dn mm ni nj dp mq lf nk nl ms lj nm nn mu ln no np mw nq bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/Profiler_Guide/Profiler_User_Guide.html" rel="noopener ugc nofollow" target="_blank">性能分析器</a></h2><p id="e877" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated"><a class="ae kv" href="https://docs.habana.ai/en/latest/Profiler_Guide/Profiler_User_Guide.html" rel="noopener ugc nofollow" target="_blank"> Profiler用户指南</a>包含关于SynapseAI Profiler的大量文档，包括其设置、执行和分析工具。还有这个有用的<a class="ae kv" href="https://vimeo.com/532336520" rel="noopener ugc nofollow" target="_blank">视频教程</a>。<br/>正如我们在之前的帖子中详细讨论的那样(例如这里的<a class="ae kv" rel="noopener" target="_blank" href="/tensorflow-performance-analysis-314b56dceb59">和这里的</a>和<a class="ae kv" rel="noopener" target="_blank" href="/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851">和</a>)，描述您的培训绩效对于最大限度地利用您的培训资源、加速您的培训和降低培训成本至关重要。</p><p id="d69b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Habana性能分析器的主要工件是<a class="ae kv" href="https://docs.habana.ai/en/latest/Profiler_Guide/Profiler_User_Guide.html#viewing-instructions" rel="noopener ugc nofollow" target="_blank">分析图</a>。与<a class="ae kv" href="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#debug_performance_bottlenecks" rel="noopener ugc nofollow" target="_blank"> TensorBoard跟踪查看器</a>类似，该图显示了不同系统资源上发生的不同事件的时间线，特别是DMA、MME和TPC。下面是一些您可能遇到的资源使用模式的例子，以及从中可以学到什么:</p><ol class=""><li id="493d" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">数据输入管道上的瓶颈</strong>:HPU上训练步骤之间的大间隔可能表示HPU在等待CPU传递训练数据时处于空闲状态。在这种情况下，您应该致力于优化您的数据输入管道。(此处见<a class="ae kv" rel="noopener" target="_blank" href="/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851">。)</a></li><li id="cc3a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">将操作卸载到CPU上</strong>:在训练步骤中间的HPU空闲与增加的DMA活动相结合，可能表明一些图形操作正在被卸载到CPU上。在这种情况下，您应该重新检查图形操作的设备位置。</li><li id="a447" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">MME利用率和HPC利用率之间的不平衡</strong>:您可能会在训练步骤中发现MME空闲而HPU非常繁忙的时段，反之亦然。在这种情况下，您可以通过改善资源之间的负载平衡来减少步骤时间。这可以通过编程/设计等效的设备特定内核来实现，如这里建议的<a class="ae kv" href="https://docs.habana.ai/en/latest/Model_Performance_Optimization/Model_Performance_Optimization_in_Habana_Gaudi.html#advanced-replace-some-tpc-operations-with-their-mme-equivalents" rel="noopener ugc nofollow" target="_blank"/>。</li></ol><p id="0ce4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在撰写本文时，Habana Gaudi性能分析器的使用需要Gaudi特定的配置步骤和工具。我们的预期是，即将发布的版本将包括对分析器使用的改进，包括将其完全集成到TensorFlow分析API和TensorBoard中。</p><h1 id="5244" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">4.调整您的模型以收敛于DL1</h1><p id="19a9" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">此时，您的模型已经被调整到您满意的程度，您可以开始训练了。您可能需要对模型进行一些更改，这需要重新调整超参数以确保模型收敛。此类更改可能包括替换某些操作、更改控制流或更改底层数据类型。即使你没有对你的模型做任何改变，你也应该确保你的训练收敛在新的AI ASIC上。这是因为不同的硬件加速器以不同的方式实现，并且可能在它们的行为中表现出微小的数值差异。在一个ASIC上的收敛并不保证在另一个上的收敛。</p><h1 id="5789" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">示例DL1上的超参数调谐</h1><p id="ecd6" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本例中，我们展示了如何利用八个HPU内核在超参数调整环境下运行八个并行实验。超参数调整指的是为您的模型搜索最佳<a class="ae kv" href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)" rel="noopener ugc nofollow" target="_blank">超参数</a>的任务。<a class="ae kv" href="https://docs.ray.io/en/latest/tune/index.html" rel="noopener ugc nofollow" target="_blank"> Ray Tune </a>是一个流行的python库，用于自动化超参数调整，支持各种最先进的优化算法。虽然默认版本只将CPU和GPU视为可能的“培训资源”，但它也可以扩展为使用HPU。在下面的代码块中，我们通过将hpu注册为GPU来演示一种相当简单的方法。在下面的代码片段中，它基于Ray Tune记录的<a class="ae kv" href="https://docs.ray.io/en/latest/tune/examples/tune_mnist_keras.html" rel="noopener ugc nofollow" target="_blank"> mnist示例</a>，我们突出显示了两个必需的更改:</p><ol class=""><li id="374d" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">通过<a class="ae kv" href="https://docs.ray.io/en/latest/package-ref.html#ray-init" rel="noopener ugc nofollow" target="_blank">光线初始化</a>命令显式注册八个GPU。这是必需的，因为当前版本的Ray不能识别HPU加速器。</li><li id="efd7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">进入列车功能后，根据<em class="ne"> CUDA_VISIBLE_DEVICES </em>环境变量的值设置<em class="ne"> HABANA_VISIBLE_DEVICES </em>环境变量。这将确保每个进程在单独的HPU上运行。</li></ol><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="4e1c" class="nf mh iq ns b gy nw nx l ny nz">import os<br/>import ray<br/>from ray import tune<br/>from ray.tune.schedulers import AsyncHyperBandScheduler<br/>from ray.tune.integration.keras import TuneReportCallback</span><span id="cdda" class="nf mh iq ns b gy oa nx l ny nz">def train_mnist(config):<br/><strong class="ns ir">    os.environ['HABANA_VISIBLE_DEVICES'] = \<br/>        os.environ['CUDA_VISIBLE_DEVICES']<br/></strong>    import tensorflow as tf<br/>    from habana_frameworks.tensorflow import load_habana_module<br/>    from tensorflow.keras.datasets import mnist<br/>    from filelock import FileLock<br/>    load_habana_module()</span><span id="da42" class="nf mh iq ns b gy oa nx l ny nz">    with FileLock(os.path.expanduser("~/.data.lock")):<br/>        (x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>    x_train, x_test = x_train / 255.0, x_test / 255.0</span><span id="a658" class="nf mh iq ns b gy oa nx l ny nz">    model = tf.keras.models.Sequential([<br/>            tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>            tf.keras.layers.Dense(10)])<br/>    loss = tf.keras.losses.SparseCategoricalCrossentropy(<br/>                          from_logits=True)<br/>    optimizer = tf.keras.optimizers.SGD(learning_rate=config['lr'])<br/>    model.compile(optimizer=optimizer,<br/>                  loss=loss, <br/>                  metrics=['accuracy'])<br/>    model.fit(x_train, y_train, epochs=5, batch_size=128,<br/>              verbose=0, validation_data=(x_test, y_test),<br/>              callbacks=[TuneReportCallback({<br/>                 "mean_accuracy": "accuracy"})])</span><span id="698b" class="nf mh iq ns b gy oa nx l ny nz">def tune_mnist(num_training_iterations):<br/>    sched = AsyncHyperBandScheduler(<br/>        time_attr="training_iteration", max_t=400, grace_period=20)<br/><strong class="ns ir">    # explicitly init ray with number of accelerators set to 8</strong> <br/><strong class="ns ir">    ray.init(num_gpus=8)<br/></strong>    analysis = tune.run(<br/>        train_mnist,<br/>        name="exp",<br/>        scheduler=sched,<br/>        metric="mean_accuracy",<br/>        mode="max",<br/>        stop={<br/>            "mean_accuracy": 0.9,<br/>            "training_iteration": num_training_iterations<br/>        },<br/>        num_samples=8,<br/>        resources_per_trial={<br/>            "cpu": 12,<br/>            "gpu": 1<br/>        },<br/>        config={<br/>            "lr": tune.uniform(0.001, 0.1),<br/>        })<br/>    print("Best hyperparameters found were: ", analysis.best_config)</span><span id="a282" class="nf mh iq ns b gy oa nx l ny nz">if __name__ == "__main__":<br/>    tune_mnist(num_training_iterations=1000)</span></pre><h1 id="9d7f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">摘要</h1><p id="b4ad" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">新的训练实例选项的可用性总是令人兴奋的消息，尤其是当它基于专用的AI ASIC时。为DL1实例提供动力的Habana Gaudi产品似乎具备了当今市场上其他人工智能加速器的所有有价值的替代物。特别是，其附带的软件堆栈在设计和优化机器学习工作负载方面为用户提供了极大的灵活性。与此同时，重要的是要记住，Habana Gaudi相对较新，因此应该以适当的心态来对待。达到你的最佳结果可能需要耐心和韧性。但是它值得潜在的回报。在我们自己的车型上，性价比的增长达到甚至超过了公布的40%大关。</p><p id="64cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章仅仅介绍了DL1实例培训的几个方面。请务必参考丰富的在线文档以了解更多详细信息。</p><p id="8c4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文的研究过程中，我发现“高迪”在德语中是“有趣”的意思。我想不出更好的方式来描述我迄今为止在DL1上的经历。我所能希望的是，你也有“高迪”和你的高迪。</p></div></div>    
</body>
</html>