# 如何通过创建跑步管理器来组织和跟踪您的 PyTorch 培训

> 原文：<https://towardsdatascience.com/how-to-organize-and-track-your-pytorch-training-by-creating-a-run-manager-878cc830ea90>

## 如果您正在寻找一种方法来组织、管理和记录培训过程中的步骤和操作，并且不想使用 PyTorch Lightning，请不要再找了

![](img/5b54f702a04e0e466cd24f0471f5501a.png)

Marcel strau 在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上拍摄的照片

我们将按照培训设置的经典层次结构，将培训经理的逻辑分为几个阶段:

*   最高级的阶段是**训练运行**，它涵盖了一组超参数(时期数、模型配置、学习率、优化器等)的整个训练。)
*   接下来，我们有**时期**，这个阶段代表整个数据集通过我们的模型的一次通过
*   对于每个时期，我们有两个步骤:训练步骤**和验证步骤**。在训练步骤中，我们通过前向和后向传递执行实际学习，在验证中，我们计算保留样本的选择指标。

作为**的额外收获**，我还将向您展示一种从可用值列表中生成每个运行参数集的方法(*提示:笛卡尔乘积*)。

## 培训过程

首先，让我们定义一个已经使用管理器的培训流程，这样我们就有了一个应该如何使用它的示例，这将有助于我们稍后定义实际功能。

## 运行管理器

接下来，让我们考虑我们希望我们的管理器收集和记录什么信息，以便我们对运行管理器的样子有一个概念:

*   我们想知道当前的纪元和运行
*   每个时期的平均损失
*   每个时期的精确度(我们可以使用其他指标:F1、精确度、召回率、MSE、MAE 等。)
*   纪元和运行花了多长时间
*   把所有事情都记录到 tensorboard 上也不错

对于损失和精度，我们想把它们分开成训练和验证，这样可以更好的了解模型的真实表现。

## 运行和新纪元的开始

正如我在本文开始时提到的，我们有两个主要循环，外部循环通过创建定义特定运行的集合来遍历所有超参数的组合(我们将立即看到如何生成它们)，内部循环遍历多个时期(也是一个潜在的超参数)，这是学习发生的部分。

因此，我们需要在新的运行和新的时期开始时通知运行管理器，以便相应地对数据进行分组，并重置基于状态的变量。

## *奖金*

在机器学习模型的训练过程中，一些参数是不可微的，并且在更高的水平上定义学习过程。我们称之为*超参数。*

通常，没有办法确定它们的最佳价值，所以我们只能全部尝试(**免责声明**:有一些方法可以改进搜索，但这超出了本文的范围)。

简而言之，我们的任务是从我们为超参数提出的值中生成所有可能的组合，这些组合定义了每次运行。为此，我们将使用 python 的内置 **itertools** 包中的**产品**函数:

```
from **itertools** import **product**h_params = {
    "**lr**": [0.001, 0.0001],
    "**num_epochs**": [10, 50]
}**runs** = []
for **run** in **product**(*h_params.values()):
    **runs**.append(**run**)
```

## 纪元和运行结束

接下来，我们将在一个步骤中涵盖几个阶段，所有阶段都是相互关联的，这样会更有意义。

前面我们已经看到了表示一个运行和一个时期开始的方法。在每个时期，我们必须迭代整个数据集，由于与计算和收敛优化相关的各种原因，我们分批进行(**小批量随机梯度下降**)。因此，我们必须将与此步骤相关的一些信息记录到我们的运行管理器中，这将帮助我们计算整个时期的总损失和准确性。

一旦纪元结束，我们必须计算上述指标，将它们保存到本地集合并记录到 Tensorboard。我们将有两个子步骤，分别用于培训和验证:

## 最后

一旦一切完成，您将有很好的 tensorboard 图来分析模型的性能和每个时期的记录历史，您可以将它们打包到 pandas 数据帧中或作为 CSV 或 JSON 保存到磁盘。

## 结论

这里给出的训练过程是非常普通的，但是，它表明通过使用 RunManager 类型的模块，您可以有一个更清晰和更容易理解的代码。

正如我在文章开头提到的，你应该检查 Pytorch 闪电。

感谢您的阅读，我希望您会发现这篇文章很有帮助，如果您想了解最新的编程和机器学习新闻以及一些优质的模因:)，您可以在 Twitter [这里](https://twitter.com/SurdoiuT)关注我，或者在 LinkedIn [这里](https://www.linkedin.com/in/tudor-marian-surdoiu/)联系我。

## 参考

*   [https://www.youtube.com/c/deeplizard](https://www.youtube.com/c/deeplizard)
*   [https://pytorch.org/docs/stable/tensorboard.html](https://pytorch.org/docs/stable/tensorboard.html)