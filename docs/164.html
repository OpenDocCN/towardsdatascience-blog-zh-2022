<html>
<head>
<title>Intro to Image Retrieval with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch图像检索简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-hands-on-introduction-to-image-retrieval-in-deep-learning-with-pytorch-651cd6dba61e#2022-01-06">https://towardsdatascience.com/a-hands-on-introduction-to-image-retrieval-in-deep-learning-with-pytorch-651cd6dba61e#2022-01-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""><h1 id="3a8b" class="pw-post-title io ip iq bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">【PyTorch图像检索简介</h1></div><div class=""><h2 id="9178" class="pw-subtitle-paragraph jo ip iq bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated"><em class="jn">用PyTorch的完整代码简单而彻底地介绍了图像检索的世界</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/8df3f331d0a4bf62d3b94d63ab0df4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qVqzOw-DHsK_6XM9"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">马库斯·温克勒在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8e7d" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi lt translated"><span class="l lu lv lw bm lx ly lz ma mb di">随着电子商务和在线网站的出现，图像检索应用一直在我们的日常生活中不断增加。亚马逊、阿里巴巴、Myntra等。一直在大量利用图像检索，根据我们刚才看到的内容，提出他们认为最合适的产品。当然，只有当通常的信息检索技术失效时，图像检索才会被调用。例如，尽管基于元数据的方法会失败，但我们的人眼会很容易地将右边的所有衬衫聚集在一起作为相似的。</span></p><blockquote class="mc md me"><p id="d5aa" class="kx ky mf kz b la lb js lc ld le jv lf mg lh li lj mh ll lm ln mi lp lq lr ls ij bi translated">文章底部列出了不同的资源。</p></blockquote><h1 id="ce12" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated">一点背景</h1><p id="fd9f" class="pw-post-body-paragraph kx ky iq kz b la nb js lc ld nc jv lf lg nd li lj lk ne lm ln lo nf lq lr ls ij bi translated">图像检索的基本本质是根据查询图像的特征从集合或数据库中找出一幅图像的问题。大多数时候，这种特征是图像之间简单的视觉相似性。在一个复杂的问题中，特征可以是两个图像的风格相似性，甚至是互补的性质。由于原始形式的图像在其基于像素的数据中不反映这些特征，我们需要将该像素数据转换到潜在空间中，在该空间中图像的表示将反映这些特征。</p><p id="1e84" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一般来说，任何两个相似的图像在潜在空间中会彼此靠得更近，而不同的图像会离得更远。这是我们用来训练模型的基本管理规则。一旦我们这样做了，检索部分简单地搜索潜在空间，以在给定查询图像的表示的潜在空间中挑选最接近的图像。大多数时候，它是在<a class="ae kw" href="https://scikit-learn.org/stable/modules/neighbors.html" rel="noopener ugc nofollow" target="_blank">最近邻搜索</a>的帮助下完成的。</p><p id="e9f7" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">因此，我们可以将我们的方法分为两部分:</p><ol class=""><li id="fe09" class="ng nh iq kz b la lb ld le lg ni lk nj lo nk ls nl nm nn no bi translated"><strong class="kz ir"> <em class="mf">图像表示</em> </strong></li><li id="515a" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated"><strong class="kz ir"> <em class="mf">搜索</em> </strong></li></ol><blockquote class="mc md me"><p id="cdd0" class="kx ky mf kz b la lb js lc ld le jv lf mg lh li lj mh ll lm ln mi lp lq lr ls ij bi translated">我们将在<strong class="kz ir">牛津102朵花</strong>数据集上整体解决这两个部分。你可以在这里下载并阅读数据集<a class="ae kw" href="https://www.tensorflow.org/datasets/catalog/oxford_flowers102" rel="noopener ugc nofollow" target="_blank"/>。</p></blockquote><h1 id="5956" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated"><strong class="ak">形象再现</strong></h1><p id="b002" class="pw-post-body-paragraph kx ky iq kz b la nb js lc ld nc jv lf lg nd li lj lk ne lm ln lo nf lq lr ls ij bi translated">我们将使用一种叫做连体模型(来自连体双胞胎)的东西，它本身并不是一个全新的模型，而是一种训练我们模型的新技术。大多数情况下，这与所谓的三重态损失一起使用。这个想法的基本组成部分是三胞胎。</p><p id="c41c" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在，三胞胎到底是什么？三元组是3个独立的数据样本，假设A(锚)、B(正)和C(负)；其中A和B相似或具有相似的特征(可能是同一个类),而C与A和B都不相似。这3个样本一起形成训练数据的一个单元——三元组。</p><blockquote class="mc md me"><p id="a2da" class="kx ky mf kz b la lb js lc ld le jv lf mg lh li lj mh ll lm ln mi lp lq lr ls ij bi translated"><strong class="kz ir">注</strong>:任何图像检索任务的90%都体现在连体网络、三元组丢失和生成真三元组上。如果你成功地完成了这些，整个努力的成功或多或少是有保证的。</p></blockquote><p id="9dae" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">首先，我们将创建管道的这个组件——数据。下面我们将在PyTorch中创建一个自定义数据集和数据加载器，它从数据集生成三个一组的图像。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="e256" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">现在我们有了数据，让我们继续到暹罗网络。暹罗网络本身是一个单一模型，我们将其应用于一对或三个输入。它给人一种2或3个模型的明显印象，但中心思想是所有这些模型必须共享权重，即只有一个模型。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/f9e3214007dc50b849d22cabb35fe06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rSPmpfsZpl0ypwKv"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">暹罗网络。这里的ConvNet实际上是一个单一的模型。</p></figure><p id="9a3b" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如前所述，维系整个架构的关键是三重态损耗。三重损失创建了一个目标函数，该目标函数强制相似输入对(锚定&amp;正)之间的距离比相异输入对(锚定&amp;负)之间的距离小某个定义的余量。下面我们将看看三重损失以及培训管道。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="6bea" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">到目前为止，我们的模型已经被训练成将图像转换到嵌入空间，该嵌入空间反映了我们想要实现的相似感。接下来，我们进入搜索部分。</p><h1 id="bb3a" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated"><strong class="ak">搜索</strong></h1><p id="e754" class="pw-post-body-paragraph kx ky iq kz b la nb js lc ld nc jv lf lg nd li lj lk ne lm ln lo nf lq lr ls ij bi translated">我们可以很容易地使用Scikit-Learn提供的最近邻搜索。我们将探索新的更好的东西，而不是走那条简单的路线。</p><p id="d309" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们将使用脸书研究公司的Faiss。这比最近邻法要快得多，如果我们有大量的图像，这种速度上的差异会变得更加突出。</p><p id="c161" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下面我们将演示如何在给定一个查询图像的情况下，在存储的图像表示中搜索最接近的图像。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="db5d" class="pw-post-body-paragraph kx ky iq kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这涵盖了基于现代深度学习的图像检索，而不会使它变得太复杂。大多数检索问题都可以用这个基本管道来解决。根据问题陈述的创新主要在于根据需要修改的基础模型。</p><h1 id="4738" class="mj mk iq bd ml mm mn mo mp mq mr ms mt jx mu jy mv ka mw kb mx kd my ke mz na bi translated">资源</h1><ol class=""><li id="1a18" class="ng nh iq kz b la nb ld nc lg nx lk ny lo nz ls nl nm nn no bi translated">包含本文所有代码的样板笔记本可以在这里找到:<a class="ae kw" href="https://www.kaggle.com/mayukh18/oxford-flowers-image-retrieval-pytorch" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/mayukh 18/Oxford-flowers-image-retrieval-py torch</a></li><li id="f68d" class="ng nh iq kz b la np ld nq lg nr lk ns lo nt ls nl nm nn no bi translated">这里列出了图像检索界流行的基准数据集:<a class="ae kw" href="https://paperswithcode.com/task/image-retrieval" rel="noopener ugc nofollow" target="_blank">https://paperswithcode.com/task/image-retrieval</a></li></ol></div></div>    
</body>
</html>