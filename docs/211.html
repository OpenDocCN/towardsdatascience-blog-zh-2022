<html>
<head>
<title>Exploring Large Collections of Documents with Unsupervised Topic Modelling — Part 1/4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用无监督主题建模探索大型文档集—第1/4部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-large-collections-of-documents-with-unsupervised-topic-modelling-part-1-4-404f4931dab7#2022-01-07">https://towardsdatascience.com/exploring-large-collections-of-documents-with-unsupervised-topic-modelling-part-1-4-404f4931dab7#2022-01-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""><h1 id="91f9" class="pw-post-title ir is it bd iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp bi translated">利用无监督主题建模探索大型文档集—第1/4部分</h1></div><div class=""><h2 id="6ac1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">借助话题模块性解读提取的话题</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9adf31568b4f19b17bbba85b4252a4a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Un0oaKJyummD-WoywtEFw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="43ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一系列的文章中，我们将重点探索基于主题建模的大量未标记文档。我们假设除了语料库的上下文之外，我们对语料库的内容一无所知。我们的目标是用一些新的、量化的知识来完成对语料库中所讨论内容的探索。</p><p id="b317" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是4部分系列的第一部分。让我们开始吧。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="31f6" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">介绍</h1><h2 id="9c8d" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">主题建模101</h2><p id="d277" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">在整个系列中，主题建模是我们分析的基础。对于给定的语料库，主题模型估计其每个文档的主题分布(即，一组主题上的权重分布)，其中主题本身是语料库的词汇上的权重分布。在给定文档集合的情况下，每个主题的权重最大的单词在句法和/或语义上是相关的。这意味着两个不同的主题共享完全相同的词汇，但具有不同的权重分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/d91eca7f01d7bb2bb8fd10852026cfed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W4d6AVjKDtWa-YEGerIUXQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左边是一个大集合中给定文档的主题分布示例，考虑了10个主题(范围从0到9)。右边是主题5在语料库词汇中的权重分布的提示性描述。图片作者。</p></figure><h2 id="3a58" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">问题是</h2><p id="0d57" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">从上图可以看出，尽管主题建模的想法听起来很吸引人，但通常很难对这种模型的结果做出一致的解释——记住，我们对语料库的内容一无所知！</p><p id="11a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这一系列的文章将呈现实验性的设置设计，引导我们走向理性的解释，并以他们的结果为依据。</p><h2 id="5e01" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">拟议解决方案</h2><p id="8200" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">在第一部分中，我们将利用两个工具在解释主题模型的结果方面向前迈进了一步:(1)主题解释，和(2)主题模块化。</p><h1 id="3a54" class="mb mc it bd md me nl mg mh mi nm mk ml jz nn ka mn kc no kd mp kf np kg mr ms bi translated">履行</h1><h2 id="23a9" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">文集</h2><p id="199a" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我们收集的文档由1904个短篇恐怖故事组成，摘自<a class="ae nq" href="https://www.reddit.com/r/shortscarystories/" rel="noopener ugc nofollow" target="_blank">r/shortcarystorys subreddit</a>。如果你想学习如何自己提取这些和其他的，请阅读<a class="ae nq" rel="noopener" target="_blank" href="/how-to-collect-a-reddit-dataset-c369de539114">我的帖子，详细介绍了整个过程</a>。根据Reddit的<a class="ae nq" href="https://www.reddit.com/wiki/api-terms" rel="noopener ugc nofollow" target="_blank">使用条款</a>，这些数据是使用Reddit的API ( <a class="ae nq" href="https://praw.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> PRAW </a>和<a class="ae nq" href="https://pypi.org/project/psaw/" rel="noopener ugc nofollow" target="_blank"> PSAW </a>收集的。</p><p id="2ee2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们假设文本已经过充分的预处理，文档中的单词由一个空格分隔。</p><h2 id="9f94" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">估计分布</h2><p id="14c5" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">我们分析的基础将是LDA主题建模的结果，在这个具体的例子中，有10个主题(目前是任意确定的)。我们将使用<a class="ae nq" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html" rel="noopener ugc nofollow" target="_blank"> Sci-Kit学习实现</a>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="4bd3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的代码中，变量<strong class="la iu"> tf </strong>(代表词频)<strong class="la iu"> </strong>是一个shape (D，V)的numpy矩阵，其中D是语料库中文档的数量，V是词汇量的大小。每个条目<strong class="la iu"> tf{d，v} </strong>是文档<strong class="la iu"> d </strong>中术语<strong class="la iu"> v </strong>的频率。这必须是LDA模型的输入。</p><p id="59a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出变量<strong class="la iu"> doc_topic </strong>的形状为(D，K)，其中K是主题的数量。根据LDA，<strong class="la iu"> doc_topic </strong>的每一行加起来都是1。</p><p id="59c9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">属性<strong class="la iu"> model.components_ </strong>的形状为(K，V)，表示词汇上的主题权重分布。同样，每一行的总和为1。</p><h2 id="bbd5" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">话题解读</h2><p id="a2b4" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">这些是前一节中估计的10个主题中每个主题的前10个最重要的词:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/63cc7c4d9e55e9cb95176f6275978454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z69udkQz7cKQZNBZvETRfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">10个主题中的前10个最重要的单词。运行上述代码的结果。图片作者。</p></figure><p id="bbac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如前所述，主题只是相同词汇的权重分布，因此，将我们自己限制在每个主题的前10个权重最大的单词将允许我们专注于核心概念。然而，在这个描述中，我们不能掌握词与词之间的相对权重，这可能是所传达的概念的指示。</p><p id="39c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些是主题0、2和7的词汇云:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/28093c63b43dce4586b857b960b0b255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eiDNjoar1YLhVN15Uk46Yw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">主题0、2和7的文字云。在wordcloud中，单词越大，它在主题中的权重就越大。图片作者。</p></figure><p id="9a03" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">花几分钟时间阅读10个主题中的每一个，并尝试解释它们可能代表的概念。解释所有这些容易吗？还是有些人比其他人更难？</p><p id="d861" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你觉得哪一个最容易诠释？没有错误的答案(或正确的答案，就此而言)，但我敢打赌它是主题0，概念将是与“圣诞节”有关的东西。我个人也将话题2标注为“可疑观察”，话题7标注为“感兴趣的物体/位置”，话题8标注为“家庭成员”，话题9标注为“可疑对象”。剩下的话题让我很难解释它们。</p><p id="58a3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很明显，话题口译是一项非常艰巨的任务。如果现在我要写一份报告，这个和那个主题很容易解释，上面的标签可以分配，而这些和那些主题不能，这听起来就不太科学了。我需要用一些可以量化的东西来支持这些说法。这就是主题模块化发挥作用的地方。</p><h2 id="6bfd" class="mt mc it bd md mu mv dn mh mw mx dp ml lh my mz mn ll na nb mp lp nc nd mr ne bi translated">主题模块化</h2><p id="a71d" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">一个话题可能传达某种概念。但是，在观察那个题目的前N个单词时，潜在的概念可能并不具体，也不全面。然而，一个不与其余主题共享一个单词(从前N个开始)的主题可以定义一个具体的、模块化的概念。达成这一概念，反过来，允许在这一方面对计划的文件进行独立评估。</p><p id="7f0b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，因为主题0很容易解释为“圣诞节”，所以可以假设它具体代表一年中的那个时间。这允许我们进一步假设，所有在主题0上有很大权重的文档必须与圣诞节有一些关联。更重要的是，因为我们知道语料库的上下文，我们可以声明这些文档是以圣诞节为背景的恐怖故事。</p><p id="dad8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里有一个例子支持我们的假设:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/5bd831bdaf49a07185a3766bbbed2413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CNbvragtPDHCAgUF0p9TKw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在左边，文档的主题分布在右边。该文档是从<a class="ae nq" href="https://www.reddit.com/r/shortscarystories/" rel="noopener ugc nofollow" target="_blank">r/shortcarystorys子编辑</a>中自动提取的，并非作者所写。该文档可在引用的网站上公开获得。</p></figure><p id="a431" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这似乎是朝着更好地理解我们的语料库的正确方向迈出的有希望的一步！我们只需要将相同的技术应用于每个“具体”的主题。抛开主观性，主题模块化允许我们陈述哪些主题比其他主题更具体。</p><p id="de9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们通过确定由一个模型提取的所有主题之间共享的字数来评估主题模块性(给定每个主题的前N个最有权重的单词)。因此，我们对具有最多独特单词的主题最感兴趣，然而考虑到从词汇表中选择K组N个独特单词的概率不是零。因此，围绕这些结果的讨论不能独立于每个主题的实际热门词。</p><p id="3393" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代码如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="88d8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/8b045738cf28abae02303d719753ab05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kcI9XRW3FioQz_OySYA5BQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个主题前10个单词中独特单词的数量。图片作者。</p></figure><p id="13e1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不那么巧合的是，话题0在话题模块化上得分最高。这一指标证实了它确实是最容易解释的(或最容易给它贴上标签的)。</p><p id="8887" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看看第二高的分数，题目4。尽管它有很高的主题模块化分数，但仍然很难(至少对我来说)理解它。我不能给它一个具体的标签。这表明，就其本身而言，主题模块性还不足以作为一种评价——它必须总是伴随着主题的实际用词。</p><p id="55e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来是主题7和8，我分别给它们分配了标签“感兴趣的对象/位置”和“家庭成员”。让我们来看几个关于这些主题的重要文档来支持这些陈述:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/cbc1f4d923a31956964d1dc4386a2f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgDDKk-Bu_EkLlCedxZDYg.png"/></div></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/b5807517c20dfacb58a29577160f4095.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6W1DnA_046nJS5MC7OvDzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在左边，文档的主题分布在右边。该文档是从<a class="ae nq" href="https://www.reddit.com/r/shortscarystories/" rel="noopener ugc nofollow" target="_blank">r/shortcarystorys subreddit</a>中自动提取的，并非作者所写。该文档可在引用的网站上公开获得。</p></figure><p id="c04c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，主题模块化给了我们信心和正确的直觉。事实上，在主题7和8上具有高权重的两个示例文档都提到了“感兴趣的对象/位置”和“家庭成员”。更进一步，他们都没有提到圣诞节，这是令人放心的，因为他们在主题0中都没有权重。</p><h1 id="05ac" class="mb mc it bd md me nl mg mh mi nm mk ml jz nn ka mn kc no kd mp kf np kg mr ms bi translated">结论</h1><p id="3a26" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">在第一部分中，我们利用两个工具在解释未标记语料库上的主题模型的结果方面向前迈进了一步:(1)主题解释，和(2)主题模块化。</p><p id="db92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们看到，在我们的例子中，解读LDA的主题是非常主观的。在非常初始的步骤中，借助于主题模块性的度量，我们能够客观地陈述哪些主题更具体，并给它们分配一个标签。</p><p id="c496" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从一个完全未知的短篇恐怖小说集开始，我们现在可以得出以下结论:</p><ol class=""><li id="0167" class="ny nz it la b lb lc le lf lh oa ll ob lp oc lt od oe of og bi translated">一些恐怖故事发生在圣诞节期间，或者以某种方式与一年中的那个时候有关。</li><li id="b5f9" class="ny nz it la b lb oh le oi lh oj ll ok lp ol lt od oe of og bi translated">一些恐怖故事涉及家庭成员。</li><li id="5016" class="ny nz it la b lb oh le oi lh oj ll ok lp ol lt od oe of og bi translated">一些恐怖故事涉及有趣的物体或地点。</li><li id="4fe0" class="ny nz it la b lb oh le oi lh oj ll ok lp ol lt od oe of og bi translated">我们知道哪些恐怖故事有这些特征，并精确量化它们有多少这些特征:<br/> → 0.5%的所有故事在话题0 —圣诞节中的权重超过0.5；<br/> → 2.3%的所有故事在主题7—感兴趣的物体/位置中的权重超过0.5；<br/> → 4.7%的故事在话题8——家庭成员中的权重超过0.5。</li><li id="921f" class="ny nz it la b lb oh le oi lh oj ll ok lp ol lt od oe of og bi translated">通过同样的量化，我们可以确定一个给定的故事是否比任何其他故事与这些特征更相关。</li></ol><p id="e39b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是理解我们语料库的第一步。尽管我们已经获得了很多信息，但还需要更多的步骤来达到一些明显的东西。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="116c" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">下一部分</h1><p id="8ebc" class="pw-post-body-paragraph ky kz it la b lb nf ju ld le ng jx lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">在本系列的下一部分中，我们将通过了解文档在主题空间中是如何聚集的来更深入地研究文档的主题分布。这将允许我们陈述有多少组不同的恐怖故事，以及它们在谈论什么。</p></div></div>    
</body>
</html>