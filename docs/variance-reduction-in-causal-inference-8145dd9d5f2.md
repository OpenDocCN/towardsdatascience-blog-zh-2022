# 因果推理中的方差缩减

> 原文：<https://towardsdatascience.com/variance-reduction-in-causal-inference-8145dd9d5f2>

## 数学技巧可以让我们的测量更加精确

![](img/df5327fb0254ae2307b3caf87484d70c.png)

丹尼尔·勒曼在 [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) 上的照片

**我们谈论的是哪个方差？**

方差是任何度量估计中的一个问题。每次我们进行测量时，都有两个共同的事实:

1.  我们正在从有限的样本量中估计测量值，并且
2.  我们希望尽可能准确。

现在，只要我们的测量是*无偏的*，平均来说，来自样本的测量将是来自真实总体的真实测量的适当估计。无偏测量意味着，如果我们对来自同一分布的不同数据样本进行无限次相同的实验，或者对无限个数据进行单次实验，我们的结果将平均为总体的真实测量值。

然而，*偏差*并不是单一实验中唯一可能的误差来源。每个样本与真实人口略有不同。

例如，如果我们想要美国人的平均年龄，而我们只对 100 人进行了抽样，那么我们这 100 人的平均年龄不会完全符合所有美国人的平均年龄。

一般来说，一个样本的平均值并不完全是总体的平均值(确实通过中心极限定理，很多样本的平均值会在真实总体的平均值周围形成一个高斯)。

当我们使用数据点的样本来获得我们的测量值时，它试图估计全部人口的测量值，由于随机性，我们会有一些误差。想想样本均值的高斯方差。这是我们试图减少的方差，本质上是样本测量值和真实总体测量值之间的典型差异。

方差减少技术是关于使用有限的样本大小来尽可能精确地估计。换句话说，方差减少技术使您能够用尽可能少的样本以给定的准确度进行测量。

顺便提一下，我们应该记住,*平均值*并不是唯一有趣的指标。我们可能对任何任意的计算感兴趣，比如我们度量的中值，或者我们度量的倒数加一的平均值！

U = 1/(1+x)

**衡量标准包含哪些内容？**

我们可以测量的任何事物都可能与我们也可以测量的其他事物相关。如果我们对 x 的每个值都考虑 1/(1+x)，那么它与每个 x 的(1+x)相关。

在这个世界上，度量不仅是相关的，而且通常是由其他我们也可以度量的事情引起的。在因果推理中，我们通常将一个结果建模为由多个其他实体引起的*。这些其他协变量合在一起产生结果。*

对于有许多输入的可测量的结果，我们可能会对其中一个输入的贡献感兴趣，这就是因果推理的情况。我们对“治疗”输入的效果感兴趣，而其他输入也对结果有影响。

例如，如果可衡量的结果是平台的参与度，则影响该结果的变量包括治疗、用户的年龄、他们的地理位置以及治疗前用户的活动水平。

如果我们做一个简单的 t 检验，测量治疗组和对照组的平均结果，并比较它们的差异，那么我们就有了整个人群的方差，这不仅是因为有限样本的噪声，还直接归因于可测量的协变量，如年龄、位置和治疗前活动。

**我们已经知道方差缩减！**

事实上，我们在第一堂统计课中介绍的一种方差缩减技术是配对 t 检验。如果在治疗前后都测量了同一组个体，那么我们可以使用配对 t 检验作为测量治疗效果的方差减少技术。

如果没有这种方差减少技术，我们将简单地取治疗前个体结果的平均值，并将其与治疗后个体结果的平均值进行比较。但是通过配对 t 检验，我们基本上控制了每个人的治疗前措施。我们通过采取差异的治疗前措施来校正他们的治疗后结果。

我们在这里做了什么？除了治疗，我们知道另一个影响最终结果的协变量:个体。因此，从因果关系来看，我们可以对结果的两个输入进行建模，即治疗和个体。如果我们想要治疗的因果效应，那么我们可以通过控制个体来减少方差。我们通过测量每个人的治疗前措施，并将其包括在计算中来做到这一点。利用每个个体的治疗前和治疗后测量之间的协方差来减少我们对治疗效果的估计的方差。

另一种最先进的、常见的方差减少技术 CUPED 没有太大的不同。如果我们计划测量一个治疗组和对照组的一些结果，那么一个非常有效的控制是在对任何人进行治疗之前的相同测量。这减少了我们对治疗效果估计的方差，因为我们去除了由于人口的内在差异而产生的方差。这就像一个配对的 t 检验——我们从治疗前的水平来看变化，而不是只比较结果而不控制个体差异。CUPED 只是去掉了治疗措施，乘以一个常数，得到治疗效果的最小方差预测。

希望这能打开你的思维，让你看到一般的可能性。我们可以控制与结果相关的任何协变量，以尽可能减少我们测量的方差。

**方差总体减少**

在维基百科页面之外，方差缩减技术包括普通随机数、[对偶变量](https://en.wikipedia.org/wiki/Antithetic_variates)、[控制变量](https://en.wikipedia.org/wiki/Control_variate)、[重要性抽样](https://en.wikipedia.org/wiki/Importance_sampling)、[分层抽样](https://en.wikipedia.org/wiki/Stratified_sampling)、矩匹配、条件蒙特卡罗和准随机变量。

通常，这些技术利用两个测量值之间的协方差将这两个测量值都包含在最终计算中，以尝试减少感兴趣的测量值的方差。他们通过使用另一个方差相关的度量来解释我们的度量中的一些方差，并在某种意义上控制它，以减少他们的组合方差。

对偶变量使用协方差负相关的测量值，CUPED 使用协方差正相关的变量，而控制协变量使用另一个测量值与其每个测量值的平均值之间的差值。我们很快会谈到分层抽样(块随机实验)。

**因果推断中的协变量**

有不同种类的协变量会对结果产生影响，因此在某种意义上应该加以控制，以减少方差。

当我们想要在没有随机实验的情况下推断因果关系时，因果推断最迫切地与**混杂因素**有关。混杂因素是治疗和结果的原因。因此，如果你有混杂因素，那么这些相关变量与治疗相关。没有随机实验，混杂因素不仅会增加方差，**它们还会使结果产生偏差**！因此，我们绝对*必须*控制混杂因素，以消除这种偏差，然后我们才有机会简单地担心减少方差。

*作为一个题外话，这似乎是我们的 ML 偏差-方差权衡所熟悉的，但通常在统计测量中，我们强烈偏好无偏测量，因此我们的统计假设成立，并且任何非常大的样本大小都将是对真相的良好估计。不知道偏差的大小真的会削弱我们对结果的信心，因为我们总是可以估计置信区间，但不知道偏离真相的程度是很糟糕的。*

在随机实验中，我们不需要考虑偏见。同样，偏差是指许多实验的平均值与真实值不同)。有了随机实验，我们只需要担心方差的减少。但是仍然有一种感觉，单个实验是有偏见的。

当我们进行随机分配时，虽然协变量被随机分配到治疗组，因此与治疗没有因果关系，但随机分配仍然导致治疗组之间协变量的不完全平衡。

例如，如果我们随机分配一个治疗组或对照组，那么平均而言，两个治疗组中的儿童和成人比例相同，但我们单个实验的现实情况可能是，对照组中的儿童比例略高于治疗组。假设作为一个孩子和作为一个成年人会影响结果，这是我们实验中治疗效果的差异来源。

因此，我们的样本在儿童/成人协变量和治疗之间将具有非零相关性，尽管它在统计上不显著(达到相关性显著性检验的预期假阳性率)。

一般来说，由于随机分配不会产生完全平衡的协变量，因此在样本中，协变量和处理之间会有一些小的相关性。协变量和治疗之间的这些小的相关性来自于随机机会，因为它们在设计上是平均不相关的，但是仍然影响我们的结果，并且是可以控制的。

**通过机器学习减少方差**

我们可以用机器学习来解释混杂因素以及任何其他协变量。为了简单起见，让我们考虑一个线性回归。可以训练回归来预测治疗的结果，以及影响结果的任何其他变量。这些其他协变量可以包括与结果相同或相似的治疗前测量，或影响结果的任何其他治疗前协变量，如人口统计学和地理因素。

如果我们有一个适当的随机实验，或者没有被这些其他协变量真正混淆，那么我们的测量在没有回归的情况下将是无偏的。利用回归，我们通过考虑每个协变量对方差的贡献来减少方差。从本质上讲，对于每个人的结果，我们正在控制结果的其他原因，因此我们严格衡量我们的治疗的贡献，在我们不同的人群中，这将比结果本身有更少的差异。

在没有随机实验的情况下，这样的线性回归可以消除简单的线性混杂，这意味着它可以消除由这些混杂产生的测量偏差。因此，这种方差减少技术甚至可以消除偏差！

另外，原来常见的 CUPED 技术相当于一个简单的最小二乘线性回归，以预处理测度为变量！

**用倾向得分说明协变量不平衡**

即使是随机实验，尤其是没有真正混杂因素的实验，因果推断的典型做法是使用倾向模型来帮助校正治疗可以从协变量中预测的事实。

倾向得分是给定其他协变量的治疗概率。常见的技术包括将倾向得分添加到回归中，通过倾向的倒数对样本进行加权，以及在回归的解释中使用倾向(双重稳健)。

**因果推理的 ML 模型中的正则化**

ML 模型中的正则化(想想回归中的 L2 或 L1 正则化)也是有帮助的。有研究探讨正则化程度与模型对潜在因果结构的正确结论。ML 泛化与正确建模因果结构密切相关。训练数据的特性可以由表征训练数据的附加(可能未知)协变量来表示。过度适应来自与测试数据不同的人群的训练数据是一个没有对这个使训练数据不同的缺失协变量建模的问题。因此，实现泛化需要避免过度适应来自不同人群的训练数据。在这种常见情况下，正确建模因果结构受益于显著的正则化。Amazon 有一篇论文将最优正则化计算为某个可测量协方差的函数。

这些方法将有助于减少因果测量的方差，因为我们正确地表征了因果系统。

现在，如果我们分析来自 A/B 检验的数据，那么在设计上就没有真正的混杂因素——治疗和协变量之间的任何相关性只是随机分配的统计方差。

在这种情况下，回归仍然优于 t 检验，因为它有助于控制影响结果的协变量，减少治疗效果测量的方差，还因为它有助于处理来自随机性的治疗组之间的小协变量不平衡。

**处理治疗组协变量差异**

虽然在个体水平上解释协变量差异是最有力的，但我们也了解到，我们的因果推断中的一些差异是由于治疗组之间的协变量不平衡，即使在随机实验中也会出现这种情况。

为了更好地控制各治疗组之间的协变量不平衡，我们可以进行一个块随机实验，使用(协变量类别或协变量距离)匹配进行一些修剪(有或没有随机实验)，并根据样本的逆频率或概率对样本进行加权，以校正不平衡(有或没有随机实验)。

**自举**

我已经说过，我们可以测量任何测度的置信区间。事实上，我们总是可以用 bootstrapping 来估计测量中的误差。在 bootstrapping 中，我们进行测量和建模过程，以获得我们最终感兴趣的测量值，然后我们使用略有不同的数据集再次进行测量——略有不同的数据集来自我们相同的样本数据，通过对其进行采样*进行替换。*如果我们有 N 个数据点，那么我们用替换法从这 N 个数据点中采样另外 N 个数据点。例如，对于数据集[1，2，3，4，5]，我们可以用替换法采样 5 个数据点，我们可能得到[1，2，2，5，5]。用不同的 bootstrap 样本重复我们的分析 50-100 次将会产生结果分布。

神奇的是:我们结果的方差是我们初始结果和真实总体结果之间方差的一个很好的估计。因此，如果我们的初始度量是 15，我们的 50–100 bootstrap 结果的标准偏差是 1，那么我们可以说**真实总体的度量**是 15 +/- 1。

**再见**

今天到此为止。我希望对方差缩减的介绍有助于解释它的重要性，以及它与其他概念的关系。查看我的相关文章，因果推理完全指南:

[](/a-complete-guide-to-causal-inference-8d5aaca68a47) [## 因果推理完全指南

### 你一直忽略的问题汇编，以及如何正确处理

towardsdatascience.com](/a-complete-guide-to-causal-inference-8d5aaca68a47)