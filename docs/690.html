<html>
<head>
<title>The Many Ways To Re-skin An Intercept</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为拦截换肤的多种方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-many-ways-to-re-skin-an-intercept-cbfd59c8728c#2022-01-24">https://towardsdatascience.com/the-many-ways-to-re-skin-an-intercept-cbfd59c8728c#2022-01-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="fc39" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">数据争论/机器学习/ Python</h2><div class=""><h1 id="1f0d" class="pw-post-title iy iz iq bd ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv bi translated">为拦截换肤的多种方式</h1></div><div class=""><h2 id="f275" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">向数据集添加截取列的方法</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/74cecfaf454b8df887b761a286212113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LRiLxhI6OgMTPV-R-Lr5iA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片作者:Karsten Cao</p></figure><p id="58b9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果你和我一样，你无疑在你的数据科学之旅中遇到过线性回归。也许为了理解这个模型，你决定从头开始编写一个，或者至少用一些公共库，比如Pandas或NumPy。不知何故，我总是忘记在我的截距数据集上添加一个恒定的1列的步骤，最终不得不查找这个过程，却发现一个与以前不同的方法。为了让您和我永远不会走得太远，这里有几种方法可以将截取列添加到现有数据集。</p><p id="c777" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">对于那些好奇的人来说，这些方法后面是额外的时间和记忆评估部分。pd.concat被认为是内存效率最高的，它产生了一个Pandas数据帧，而np.concatenate在速度方面是最好的，它产生了一个NumPy数组。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="2361" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">1.创建数据</h1><p id="c26d" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">我从一个Pandas数据框架开始，因为它与提供的所有方法一起工作。也可以使用NumPy数组，但它仅限于NumPy进程。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ne nf l"/></div></figure><div class="kp kq kr ks gt ab cb"><figure class="ng kt nh ni nj nk nl paragraph-image"><img src="../Images/62c4e413fed600c2fe9e6609c6cbad62.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*sSNrY2E8gkArE9ypQmIjLQ.png"/></figure><figure class="ng kt nh ni nj nk nl paragraph-image"><img src="../Images/d6bd8945c196e3e556a6936d0e13574e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*pqjh1EnsFvfRPZ4FVCgOhg.png"/><p class="la lb gj gh gi lc ld bd b be z dk nm di nn no translated">这里，我们用[2]熊猫数据帧和[3]2D数组表示数据。Karsten Cao的图片</p></figure></div></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="5d52" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">2.对截取进行“重新换肤”</h1><p id="2de0" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">下面我列出了我在向现有数据集添加截取列时遇到的7种方法。它们似乎可以分为三类:分配优先、连接和插入。结果在熊猫数据帧或NumPy 2D阵列中，截距在最左列，为一些线性代数和机器学习做好准备。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="ne nf l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi np"><img src="../Images/272f123e3af9d27f13a860bbcb6dc4ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*SgX-R5EyFFDxbhKiVj706A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">任一方法的一般输出。熊猫数据帧在上面，NumPy数组在下面。图片作者:Karsten Cao</p></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="548d" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">3.一般讨论</h1><p id="d0d3" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">在这一节中，我将探究每一种方法，并对每一个过程进行高层次的描述。</p><p id="644b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第一种方法是按照原始数据集的形状分配一个多一列的矩阵。然后，非截距位置被替换为来自x的数据。这可能会感觉很慢，因为在被覆盖之前会生成许多1并且未使用。输出是一个np.array。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="556e" class="nv mi iq nr b gy nw nx l ny nz">tempX = np.ones((X.shape[0], X.shape[1] + 1))<br/>tempX[:,1:] = X</span></pre><p id="6864" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第二种方法使用串联。它生成一个截取列，将其转换为DataFrame对象，然后将该列与原始数据集连接起来。这种方法的内存使用量非常惊人，因为它几乎没有使用比原始数据集更多的内存。输出是pd.DataFrame。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="cb7e" class="nv mi iq nr b gy nw nx l ny nz">pd.concat([pd.DataFrame(np.ones(X.shape[0])), X], axis=1)</span></pre><p id="347e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第三、第四和第五种方法是使用NumPy的串联方法。除了所需参数的不同，这只是将截距追加到数据集的三种不同方法。在组合新输出的结果之前，每个都创建一个新的截距列。输出是np.arrays。虽然有所不同，但是本文并不探讨这些不同之处。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="6055" class="nv mi iq nr b gy nw nx l ny nz">np.c_[np.ones(X.shape[0]), X]</span><span id="22d3" class="nv mi iq nr b gy oa nx l ny nz">np.hstack([np.ones((X.shape[0], 1)), X])</span><span id="b4dd" class="nv mi iq nr b gy oa nx l ny nz">np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)</span></pre><p id="aab8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第六种方法是插入。它通过提供索引和轴方向来指定列，选择要插入的值，然后继续。它使用np.array(X)将DataFrame转换为NumPy数组。这类似于Python list内置函数，但它确实会带来一些混乱，因为您可以添加一个值来传播数组中的一列。同样，您可以在第三个参数中传递[1]来获得完全相同的输出。输出是一个np.array。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="ae9a" class="nv mi iq nr b gy nw nx l ny nz">np.insert(np.array(X), 0, 1, axis=1)</span></pre><p id="8cd6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">第七种方法是插入和交换。它会制作一份拷贝，这样原始数据帧就不会受到影响。使用类似于第六种方法的特殊Pandas过程添加一个截距，在第六种方法中，我们将一个列设置为标量，创建一个用所提供的标量填充的列。DataFrame的列被取出、重新排序，然后传递给reindex方法。输出是pd.DataFrame。</p><pre class="kp kq kr ks gt nq nr ns nt aw nu bi"><span id="76b9" class="nv mi iq nr b gy nw nx l ny nz">tempX = X.copy()<br/>tempX['intercept'] = 1<br/>columns = list(tempX.columns)<br/>columns[0], columns[1:] = columns[-1], columns[0:-1]<br/>tempX.reindex(columns=columns)</span></pre><p id="bac9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些是我发现的几种使用Pandas或NumPy向现有数据集添加截距的方法。由于这个过程对每个数据集只进行一次，并且只是为线性回归等模型准备数据，因此这些选项中的任何一个都非常适合刚刚进入机器学习和数据科学的人。</p><p id="4953" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但是如果毫秒和兆字节很重要呢？继续读。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="2cc5" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">4.事实真相</h1><p id="7d8e" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">在被告知“这些选项中的任何一个都非常合适”后，有些人可能会不满意。在这一节中，我将探讨每个模型的时间和空间效率，并比较它们的性能。</p><h2 id="6d24" class="nv mi iq bd mj ob oc dn mn od oe dp mr ln of og mt lr oh oi mv lv oj ok mx iw bi translated"><strong class="ak">方法论</strong></h2><p id="f614" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">我使用了一个Pandas数据帧和一个带有(100_000，100)个随机初始化变量的NumPy数组。<br/>为了避免Python缓存数组和矩阵，我单独运行并计时了每个方法。创建了一个base()函数来初始化和计算数据集和截距列的常量内存使用。此外，基本内存使用量用于验证哪些变量正在被缓存。<br/>所有的拦截方法都放在一个函数中，这个函数被封装在一个<a class="ae ol" href="https://pypi.org/project/memory-profiler/" rel="noopener ugc nofollow" target="_blank">内存分析器</a>中，用来测量增量数据的使用情况。下面的内存使用是使用profiler decorator计算的。为了给每个函数计时，我创建了一个时间装饰器，循环遍历每个截取方法，计算运行时间，并记录结果。</p><h2 id="e0c8" class="nv mi iq bd mj ob oc dn mn od oe dp mr ln of og mt lr oh oi mv lv oj ok mx iw bi translated"><strong class="ak">结果</strong></h2><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f9836afeb705fbe29411502861831bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*CUcW9g1BztQm9VjNxqgzeQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">用于循环计算和建立基线的恒定内存使用量。图片作者:Karsten Cao</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/fee3f67811f8b1436943fb4656420a63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*hC-W6luZ4vCcGgn6C_1grw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">每种方法的内存使用和时间评估。图片作者:Karsten Cao</p></figure><h2 id="ab52" class="nv mi iq bd mj ob oc dn mn od oe dp mr ln of og mt lr oh oi mv lv oj ok mx iw bi translated">以下是我注意到的一些事情:</h2><ul class=""><li id="bec6" class="oo op iq lg b lh mz lk na ln oq lr or lv os lz ot ou ov ow bi translated">Pandas和NumPy之间最初的数据使用差异可以忽略不计。</li><li id="d590" class="oo op iq lg b lh ox lk oy ln oz lr pa lv pb lz ot ou ov ow bi translated">除了np.concatenate有10次迭代之外，np.array的初始开销更小，运行速度更快。</li><li id="9d71" class="oo op iq lg b lh ox lk oy ln oz lr pa lv pb lz ot ou ov ow bi translated">令人惊讶的是，使用pd.concat的第二种方法是<strong class="lg ja">最有效的内存方法</strong>,它只使用了323.9MB的ram。似乎是将指针合并到返回的数据帧中，而不是为副本分配新的空间。不幸的是，它花费的时间最长，是np.concatenate的2-5倍。</li><li id="d0e2" class="oo op iq lg b lh ox lk oy ln oz lr pa lv pb lz ot ou ov ow bi translated">最快的方法<strong class="lg ja"> </strong>因迭代而异。经过10次迭代，np.concatenate、np.hstack和np.insert以0.097秒打平。经过100次迭代，NumPy串联方法(3，4，5)的次数达到了1%。</li><li id="0ffd" class="oo op iq lg b lh ox lk oy ln oz lr pa lv pb lz ot ou ov ow bi translated">如果您希望输出是数据帧，那么第七种带有插入和重新索引的方法非常快，100次迭代0.801秒，10次迭代0.130秒。否则，np.concatenate在两种数据集类型上的速度都是一致的。</li></ul><h1 id="a92c" class="mh mi iq bd mj mk pc mm mn mo pd mq mr kf pe kg mt ki pf kj mv kl pg km mx my bi translated">结论</h1><p id="29c0" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">总而言之，我建议坚持使用您开始使用的数据对象或适合您的用例的数据对象。毕竟，如果你正在用Python编码，那么对你来说最重要的可能是你编码和思考的时间，而不是你将向数据集添加截距的过程从毫秒缩短到最小的能力。</p><p id="5857" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我知道我只会用我记得的那个。</p><p id="f51d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">感谢您的阅读！随意查看代码<a class="ae ol" href="https://github.com/karagain/Intercept-Profiler/blob/main/profiler.py" rel="noopener ugc nofollow" target="_blank">这里</a>！</p></div></div>    
</body>
</html>