<html>
<head>
<title>Linear Regression with OLS: Heteroskedasticity and Autocorrelation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OLS线性回归:异方差性和自相关性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-with-ols-heteroskedasticity-and-autocorrelation-c12f1f65c13#2022-06-01">https://towardsdatascience.com/linear-regression-with-ols-heteroskedasticity-and-autocorrelation-c12f1f65c13#2022-06-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="91eb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用一点数学知识理解OLS线性回归</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/b18b2336485a09955af4f25622e320c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/0*RbdOnvD8GbdL64wI.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="3594" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">异方差</strong>和<strong class="kw iu">自相关</strong>是我们在建立线性回归时需要解决的不可避免的问题。在本文中，让我们更深入地了解什么是异方差和自相关，什么是后果，以及处理问题的补救措施。</p><p id="a410" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">典型的线性回归采用如下形式。响应变量(即Y)被解释为解释变量(如截距、X1、X2、X3……)的线性组合，而<strong class="kw iu"> ε </strong>是误差项(即一个<strong class="kw iu">随机变量</strong>)，代表拟合响应值和实际响应值之间的差异。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/8a39960bf9ac5a9437776b42d8b83913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0KEHRGpV1D6mKgt5.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图1(作者图片)</p></figure><h2 id="cfd0" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated"><strong class="ak">什么是同方差？</strong></h2><p id="e17a" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">在<strong class="kw iu">同方差</strong>的假设下，误差项应该有常数方差和iid。换句话说，误差项的方差-协方差矩阵中的对角线值应该是常数，非对角线值应该都是0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mt"><img src="../Images/64c2813278a40a137a8dc073391d6635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hkog64FtGPHZHTSYiVShbw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图2(作者图片)</p></figure><h2 id="669d" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated">什么是异方差？</h2><p id="c82f" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">在现实世界中，同质性假设可能<em class="mu">不合理</em>。误差项的方差可能不会保持不变。有时误差项的方差取决于模型中的解释变量。</p><p id="21b4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">例如，卧室的数量通常用于预测房价，我们看到6+卧室的房子比2-卧室的房子预测误差更大，因为6+卧室的房子通常比2-卧室的房子价值高得多，因此，有更大的<strong class="kw iu">未解释的</strong>和有时<strong class="kw iu">不可约的</strong>价格方差，这漏入了误差项。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mv"><img src="../Images/f24de58e7301d1b3de8f6f6f60bb8ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xchyOMhXfzdY4z4SQQ_m_Q.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图3(作者图片)</p></figure><p id="9936" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们称其方差在观测值间不恒定的误差项为异方差误差。这个特性被称为<strong class="kw iu">异方差</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mw"><img src="../Images/04bc8a6489258e8f5bcaaf5e09e7603c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NlTExUJ_eYr1oehAQ4tChw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图4(作者图片)</p></figure><h2 id="57e1" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated">什么是自相关？</h2><p id="6f13" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">当模型中存在自相关时，误差项是相关的。这意味着误差项协方差矩阵的非对角值不全是0。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mx"><img src="../Images/e3b746469837512092918b9f8630afc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z9x6vjOI0ViHxo522930KQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图5(作者图片)</p></figure><p id="b90e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有一些可能的自相关来源。在<strong class="kw iu">时序数据中，</strong>时间是产生自相关的因素。例如，当前股价受到前几个交易日的价格影响(例如，股价在大幅上涨后更有可能下跌)。在<strong class="kw iu">横截面数据</strong>中，相邻单元倾向于具有相似的特征。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="b76c" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated"><strong class="ak">异方差和</strong>自相关的结果是什么？</h2><blockquote class="nf ng nh"><p id="9740" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">只要<a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"> <strong class="kw iu">零条件均值</strong>的假设(即误差项的期望值对解释变量的所有值都是零条件的)成立，即使在异方差和自相关的情况下，OLSE也保持<strong class="kw iu">无偏</strong>。</a></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nm"><img src="../Images/3b36ed92dd615a6d8b6d1142ab4be1db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F3gMjrdi9d9eIVUr.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图6(作者图片)</p></figure><blockquote class="nf ng nh"><p id="abbc" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated"><em class="it">异方差或自相关下的OLS估计量</em> <strong class="kw iu"> <em class="it">不再具有所有线性无偏估计量中最小的方差</em> </strong> <em class="it">因为</em> <a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"> <em class="it">高斯-马尔可夫定理要求同方差。</em> </a></p></blockquote><p id="0eab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以异方差或自相关<em class="mu"> </em>下的OLS估计量<strong class="kw iu">不再是蓝色的</strong>。与同方差下相比，OLSE<strong class="kw iu">效率不高</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nn"><img src="../Images/8d8f5d8bd7c7e1423dbd29361727cb41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7FgYh1HkV6wmaAqIymHkAQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图7(作者图片)</p></figure><blockquote class="nf ng nh"><p id="e42a" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">由于OLS估计量的方差在异方差或自相关下是无效的，统计推断可能会提供<strong class="kw iu">误导性结果</strong>。</p></blockquote></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h2 id="64ef" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated">异方差和自相关的补救方法是什么？</h2><h2 id="755b" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated"><strong class="ak">补救措施1:异方差一致性(HC)和</strong>异方差自相关一致性(HAC)标准误差</h2><p id="62e2" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">在异方差或自相关的情况下，我们仍然可以使用<a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"> <strong class="kw iu">低效的</strong> </a> OLS估计量，但许多文献建议使用<strong class="kw iu">异方差一致(HC)标准误差</strong>(也称为稳健标准误差，白色标准误差)或<strong class="kw iu">异方差-自相关一致(HAC)标准误差</strong>(也称为纽西标准误差)，以允许异方差或自相关的存在(见图7)。这些是最简单和最常见的解决方案。</p><p id="0563" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">许多计量经济学家认为，我们应该始终使用稳健的标准差，因为我们永远无法依赖同伦方差。</p><h2 id="fc7b" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated"><strong class="ak">补救2: </strong>广义最小二乘法(GLS)和可行GLS (FGLS)</h2><p id="90a0" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">代替接受低效的OLS估计器和校正标准误差，我们可以通过使用广义最小二乘法(GLS)使用完全高效的估计器(即，无偏和具有最小方差)来校正异方差或自相关。</p><blockquote class="nf ng nh"><p id="e522" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated">在异方差或自相关情况下，尽管OLS估计量和GLS估计量都是<strong class="kw iu">无偏的</strong>，但GLS估计量的<strong class="kw iu">方差比OLS估计量的</strong>方差小。</p></blockquote><p id="068d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果存在异方差或自相关，并且我们或者<strong class="kw iu">知道</strong>误差项的方差-协方差矩阵，或者<strong class="kw iu">可以根据经验估计它</strong>，那么我们可以将其转换成一个同方差模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi no"><img src="../Images/cd814f4b3b587a8ce2eab4f84d200bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dVqzRh5rUbCGC3qiJtjnCA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图8(作者图片)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi np"><img src="../Images/5bafe453034e14b638bc8edccd479bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zycyqNHZh3XZoxsQlheHnA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图9(作者图片)</p></figure><blockquote class="nf ng nh"><p id="06c8" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated"><strong class="kw iu">问:变换后的模型是齐次的吗？</strong></p><p id="bd06" class="ku kv mu kw b kx ky ju kz la lb jx lc ni le lf lg nj li lj lk nk lm ln lo lp im bi translated"><strong class="kw iu">答:是的，转换后的模型中的误差项具有恒定方差和iid。</strong></p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nq"><img src="../Images/08b80e9890e656496139c4c00e5f1187.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HLD0Cb7ZpXa4tg1ihC4IYQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图10(作者图片)</p></figure><p id="a703" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">转换后的模型满足同方差假设，因此，转换后模型的OLS估计器(即<strong class="kw iu"> GLS估计器</strong>)是<strong class="kw iu">有效的</strong>。GLS估计量可以计算为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nr"><img src="../Images/d1164fcdb65e1b6ba12db72c55e95409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O2DaPcpGJb40jxNDkenArw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图11(作者图片)</p></figure><p id="f57b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们<strong class="kw iu">知道<strong class="kw iu">σ2ω</strong>或<strong class="kw iu">σ</strong>的值，我们可以将它们的值代入一个封闭解中，找到GLS估计量。</strong></p><p id="e6fe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们<strong class="kw iu">不知道</strong>σ2ω或<strong class="kw iu">σ的值，那么</strong>这个百万美元的问题就是“我们能估计它们的值吗？”答案是肯定的。处理这种情况的一个常见办法是采用可行的GLS ( <strong class="kw iu"> FGLS </strong>)。</p><h2 id="d7a6" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated"><strong class="ak">如何在</strong>异方差下应用FGLS？</h2><p id="4aad" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">正如伍尔德里奇的《计量经济学导论:现代方法》中所讨论的，我们可以假设</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ns"><img src="../Images/e109dd43a447283f0173ea1dfb9a6762.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VI6tLt6cdJ-fZkzpehV7Nw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图12(作者图片)</p></figure><p id="0653" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们姑且称之为<strong class="kw iu"> u </strong>的估计，FGLS模型中的权重，<strong class="kw iu"> W，</strong>(又名，<strong class="kw iu">加权最小二乘估计(WLS) </strong>)。</p><p id="97ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">校正异方差的一种可行的GLS方法:</p><p id="4fdd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第一步</strong>:让OLS照原样运行，获得残差，即Ui hat。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nt"><img src="../Images/b6dda11be2208073103c2ffbc088b749.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4SwYJgyhNl5FQAbe84Q_Q.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图13(作者图片)</p></figure><p id="1b37" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第2步</strong>:我们首先平方残差，然后取自然对数，从而创建一个新变量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nu"><img src="../Images/8e4ba0c705dfebf655cbcd401f37de2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qB_PV4sxlt0b55xMEL-4hQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图14(作者图片)</p></figure><p id="a089" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第三步</strong>:在Xs上回归这个新创建的变量，然后预测它们的拟合值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi lq"><img src="../Images/78e804055cd34caa0c3f1e329d45fc1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCj0qdNwXCJVBedweth5NA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图15(作者图片)</p></figure><p id="36a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第四步</strong>:对第三步得到的拟合值取幂，称之为权重w，然后创建一个新的矩阵p，(即N×N矩阵)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nv"><img src="../Images/b06535bfcf10e27349117612cfdc3d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmVdky_G8SsCPcexxjV_oA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图16(作者图片)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nw"><img src="../Images/7dc779a6b4a0996bbd4d9eeebdd2224a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZbDfCEJbpey-gKYJYByQ9g.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图17(作者图片)</p></figure><p id="f917" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第五步</strong>:通过乘以新矩阵p来变换Y和X。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nx"><img src="../Images/36666cdd64cf0614cb5ab3ad15f94d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0KiWG8Bv9HXscQd-IIIrA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图18(作者图片)</p></figure><p id="2020" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">步骤6 </strong>:对转换后的模型应用OLS，我们得到的β hat将是一个有效的GLS估计量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ny"><img src="../Images/5cbeb2e463a08f70551c9aea5c05aa17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-CUJ0z5HFaOgW9qHNL0Zw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图19(作者图片)</p></figure><h2 id="3fee" class="lv lw it bd lx ly lz dn ma mb mc dp md ld me mf mg lh mh mi mj ll mk ml mm mn bi translated">如何在自相关下应用<strong class="ak"> FGLS？</strong></h2><p id="02e9" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">对于大多数具有自相关的时间序列数据，<strong class="kw iu">一阶自回归</strong>扰动(即AR(1))校正就足够了。我们有</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi nz"><img src="../Images/7bf08d1e733d4493656f80f326f7c685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*StsmlljF48BGY77vvIfP_w.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图20(作者图片)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oa"><img src="../Images/8fc13496d1fd987995b25a10f385ae27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L6kcmvwTTY0ae4QuHSEjrQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图21(作者图片)</p></figure><p id="f971" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第一步</strong>:让OLS照原样运行，得到剩余向量e</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ob"><img src="../Images/fa0a5dce94f5cca839659c9ea8ef20f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFHqIysxEZ57QtCE9r1nhA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图22(作者图片)</p></figure><p id="f737" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第二步</strong>:用r估计ρ，然后创建一个新的矩阵p，(即N×N矩阵)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oc"><img src="../Images/283f1ffb9e6961472dbc8c99029d6b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wsH7LdN0nsa12IUYOpCGqw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图23(作者图片)</p></figure><p id="5904" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">第三步</strong>:通过乘以新矩阵p，对Y和X都进行变换，第一次观测与其他观测不同。对于我们的应用，我们可以<strong class="kw iu">忽略</strong>第一个观察值(即t=1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi od"><img src="../Images/22ca3d76e3090d5a76e598a630087795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35EqzJ9jwNUwg211MYuToQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图24(作者图片)</p></figure><p id="7a72" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">步骤4 </strong>:对变换后的模型应用OLS，获得GLS估计量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oe"><img src="../Images/3f8601902aa5cd397ad00c799d3c4b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ixFs0-Y6Pq99HDl3B0mIWg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图25(作者图片)</p></figure><h1 id="6a08" class="of lw it bd lx og oh oi ma oj ok ol md jz om ka mg kc on kd mj kf oo kg mm op bi translated">最终注释</h1><p id="68a9" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">当线性回归模型中存在异方差时，误差项的方差不是常数；当存在自相关时，误差项的协方差不为零。</p><p id="c3dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在异方差或自相关的情况下，OLS估计量仍然是无偏的，但不再有效，这意味着它不会有最小方差。</p><p id="2c32" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了解决异方差或自相关问题，我们可以获得稳健的OLS估计量的标准误差，或者使估计量更有效，我们可以进一步获得FGLS的GLS估计量。</p><p id="6f3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你对<strong class="kw iu">线性回归</strong>和<strong class="kw iu">因果推断</strong>感兴趣，这里有一些相关的帖子可以浏览。</p><ul class=""><li id="015e" class="oq or it kw b kx ky la lb ld os lh ot ll ou lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/causal-inference-econometric-models-vs-a-b-testing-190781fe82c5"> <strong class="kw iu">因果推断:计量经济模型vs. A/B检验</strong> </a></li><li id="d2ba" class="oq or it kw b kx oz la pa ld pb lh pc ll pd lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-vs-logistic-regression-ols-maximum-likelihood-estimation-gradient-descent-bcfac2c7b8e4"> <strong class="kw iu">线性回归与逻辑回归:OLS、最大似然估计、梯度下降</strong> </a></li><li id="ba05" class="oq or it kw b kx oz la pa ld pb lh pc ll pd lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"><strong class="kw iu">OLS线性回归:无偏、一致、蓝色、最佳(有效)估计量</strong> </a></li><li id="d4bf" class="oq or it kw b kx oz la pa ld pb lh pc ll pd lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/understand-bias-and-variance-in-causal-inference-with-linear-regression-a02e0a9622bc"> <strong class="kw iu">线性回归因果推断:省略变量和无关变量</strong> </a></li><li id="ad7b" class="oq or it kw b kx oz la pa ld pb lh pc ll pd lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/causal-inference-with-linear-regression-endogeneity-9d9492663bac"> <strong class="kw iu">线性回归因果推断:内生性</strong> </a></li><li id="9874" class="oq or it kw b kx oz la pa ld pb lh pc ll pd lp ov ow ox oy bi translated"><a class="ae nl" rel="noopener" target="_blank" href="/linear-regression-with-ols-heteroskedasticity-and-autocorrelation-c12f1f65c13"> <strong class="kw iu">与OLS的线性回归:异方差和自相关</strong> </a></li></ul><h1 id="e8e7" class="of lw it bd lx og oh oi ma oj ok ol md jz om ka mg kc on kd mj kf oo kg mm op bi translated">感谢您的阅读！！！</h1><p id="afde" class="pw-post-body-paragraph ku kv it kw b kx mo ju kz la mp jx lc ld mq lf lg lh mr lj lk ll ms ln lo lp im bi translated">如果你喜欢这篇文章，并且想<strong class="kw iu">请我喝杯咖啡，</strong>请<a class="ae nl" href="https://ko-fi.com/aaronzhu" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="4f07" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可以注册一个<a class="ae nl" href="https://aaron-zhu.medium.com/membership" rel="noopener"> <strong class="kw iu">会员</strong> </a>来解锁我的文章的全部访问权限，并且可以无限制地访问介质上的所有内容。如果你想在我发表新文章时收到电子邮件通知，请订阅。</p></div></div>    
</body>
</html>