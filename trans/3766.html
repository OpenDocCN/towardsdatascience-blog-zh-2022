<html>
<head>
<title>The Noisy Elephant</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">吵闹的大象</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-noisy-elephant-79e9071536e#2022-08-22">https://towardsdatascience.com/the-noisy-elephant-79e9071536e#2022-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="26ae" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">无法获得更多数据？噪音小一点可能会有用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b200eced7c1bb0b48491e0fd753f519f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oEBlzrmkB6n47aS9l35Crw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1 | <a class="ae kv" href="https://pixabay.com/images/id-5172162/" rel="noopener ugc nofollow" target="_blank">图片</a>取自<a class="ae kv" href="https://pixabay.com/users/dimadim_art-11205138/" rel="noopener ugc nofollow" target="_blank"> DimaDim_art </a>来自pixabay。</p></figure><p id="fa61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在制造业或医疗保健等更传统的行业，机器学习才刚刚开始展现其增加价值的潜力。这些行业的关键将是从以模型为中心转向以数据为中心的机器学习开发。[1]正如吴恩达(联合创始人<a class="ae kv" href="https://www.coursera.org" rel="noopener ugc nofollow" target="_blank"> Coursera </a>和<a class="ae kv" href="https://www.deeplearning.ai" rel="noopener ugc nofollow" target="_blank"> deeplearning.ai </a>，谷歌大脑负责人[2])指出的，在这些行业，关键将是接受机器学习的“以数据为中心”的观点，重点是数据质量而不是数量。[3]</p><p id="e259" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文中，我们将探讨噪声(质量)和数据集大小(数量)对高斯过程回归的影响。[5]我们将会看到，提高数据质量并不会增加数据量，反而会提高拟合质量。我将分三步走。首先，我将介绍数据集。其次，我将定义要模拟并添加到数据中的噪声。第三，我将探讨数据集大小和噪声对回归模型准确性的影响。这些图和数值实验是使用Julia 生成的。代码可以在<a class="ae kv" href="https://github.com/lnemec/VonNeumannElephant" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。如果没有说明，这些数字是由代码(作者)生成的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="674e" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">1.约翰·冯·诺依曼大象</h1><p id="57eb" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">为了探索数据集大小和噪声之间的关系，我们使用图2所示的冯诺依曼大象[6]。作为一个玩具数据集。</p><blockquote class="mw mx my"><p id="547c" class="kw kx mz ky b kz la jr lb lc ld ju le na lg lh li nb lk ll lm nc lo lp lq lr ij bi translated"><strong class="ky ir">注:</strong> <a class="ae kv" href="https://en.wikipedia.org/wiki/John_von_Neumann" rel="noopener ugc nofollow" target="_blank">约翰·冯·诺依曼(1903 — 1957) </a>是匈牙利出生的数学家。他在包括数学、物理、计算机科学和统计学在内的许多领域做出了重大贡献。在1953年与恩利克·费密的一次会面中，他批评了自己的工作，说“<strong class="ky ir">有了四个参数，我就能适应一头大象，有了五个参数，我就能让它扭动鼻子</strong>”[7]</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/15ea0a8bf5b0312fe456d553182baeb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*lA_p_0OnHpegTzkZZ3tG_A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2 | j . Mayer等人[6]参数化的约翰·冯·诺依曼大象周长图</p></figure><p id="1f06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大象的周长(图2)由一组点描述(<em class="mz"> x(t)，y(t) </em>，其中<em class="mz"> t </em>是一个参数。将<em class="mz"> t </em>解释为时间J. Mayer <em class="mz">等人</em>【6】将<em class="mz"> x(t) </em>和<em class="mz"> y(t) </em>分别展开为<a class="ae kv" href="https://en.wikipedia.org/wiki/Fourier_series" rel="noopener ugc nofollow" target="_blank">傅立叶级数</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/523ccd2137b03253044c0c0e4b833cab.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*rT9zmUyhVq8EdnDZkeniVw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">方程式1 |傅立叶展开式</p></figure><p id="3e6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中，上下标【T14(x，y)】表示<em class="mz"> x </em>和<em class="mz"> y </em>展开，下下标<em class="mz"> k </em>表示傅里叶展开中的<em class="mz">第k</em>项。表1列出了J. Mayer等人<em class="mz">发现的系数(A，B)。表1中列出的值还包括摆动参数<em class="mz">摆动系数。=40 </em>和眼睛的坐标<em class="mz">xₑ=yₑ=20</em>【6】。</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表1 |生成冯诺依曼象的傅立叶展开系数。[6]</p></figure><p id="51e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，我们需要24个实系数来制作大象，因为k的范围从k=0到k=5，每个k需要四个系数。然而，J. Mayer <em class="mz">等人</em>发现大多数系数可以设置为零，只留下八个非零参数。如果每对系数进一步总结成一个复数，大象轮廓(和躯干摆动)实际上被编码成一组四个(加一个)复数参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d52bf5f3a6112a6dc621f6bb8742b4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*UG8lC6JmzC9z5zXGaZV-uA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3 |冯·诺依曼象(左上)和傅立叶级数展开x(t)(左下)和y(t)(右上)的参数图。</p></figure><p id="1d86" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下文中，我们将使用曲线<em class="mz"> x(t) </em>和<em class="mz"> y(t) </em>，其中<em class="mz">t =[-π，π] </em>用于我们的实验(如图3所示)。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="5b2f" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">2.噪音</h1><p id="cb5e" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">对于噪声，我们使用从<a class="ae kv" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" rel="noopener ugc nofollow" target="_blank">均匀分布</a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank">标准正态分布</a>或<a class="ae kv" href="https://en.wikipedia.org/wiki/Skew_normal_distribution" rel="noopener ugc nofollow" target="_blank">偏斜正态分布</a>中抽取的随机数。噪声由伪随机数发生器产生。我们在<a class="ae kv" href="https://julialang.org" rel="noopener ugc nofollow" target="_blank"> Julia </a>中使用基于<a class="ae kv" href="https://arxiv.org/abs/1805.01407" rel="noopener ugc nofollow" target="_blank"> xoshiro </a>算法的默认伪随机数发生器。</p><p id="cc88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Continuous_uniform_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> 2.1均匀分布</strong> </a></p><p id="8a01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当从连续均匀分布中取样时，区间<em class="mz">【a，b】</em>中的每个实数都是等概率的<em class="mz">。</em>图4显示了曲线<em class="mz"> x(t) </em>和<em class="mz"> y(t) </em>包括直方图中的均匀分布噪声。在图4中，随机数的范围从<em class="mz"> a=-1.5 </em>到<em class="mz"> b=1.5 </em>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/b236b9c06fdc7b44077ba2e366557632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*yZ4yR7PYBeZNA5SsqW6VMA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4 |显示了曲线x(t)和y(t)以及均匀分布噪声和噪声直方图(δx，δy)。噪声以0为中心，范围在[-1.5，1.5]之间。</p></figure><p id="d811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Normal_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> 2.2标准正态分布</strong> </a></p><p id="4d6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">标准正态分布(也称为高斯分布)是实值随机变量的连续概率分布。方程给出了归一化概率密度函数(pdf)的一般形式。2</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7c3487b46e1b81a8132051c259533fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*WBsa-1m2xA2gWt2wmRX0zQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">等式2 |归一化概率密度函数的一般形式</p></figure><p id="a5d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中参数μ是平均值(或期望值)，σ是标准正态分布<a class="ae kv" href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener ugc nofollow" target="_blank">的方差</a>。标准正态分布是一个对称分布，其均值<a class="ae kv" href="https://en.wikipedia.org/wiki/Mean" rel="noopener ugc nofollow" target="_blank">、</a><a class="ae kv" href="https://en.wikipedia.org/wiki/Median" rel="noopener ugc nofollow" target="_blank">中位数</a>和<a class="ae kv" href="https://en.wikipedia.org/wiki/Mode_(statistics)" rel="noopener ugc nofollow" target="_blank">众数</a>相等。标准正态分布在统计学中很重要的原因之一是<a class="ae kv" rel="noopener" target="_blank" href="/the-one-theorem-every-data-scientist-should-know-f7c501d54bad">中心极限定理</a>。它指出，在某些条件下，许多具有有限均值和方差的独立随机变量的平均值的抽样分布接近正态分布，因为起作用的随机变量的数目趋于无穷大。[8]被认为是许多独立过程之和的物理量，如测量误差，通常是正态分布的。[9]因此，噪声通常可以近似为标准的正态分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/78383795315b6559efc27c74049be72e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CcO0b-iBYIn39roL9IqnzQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5 |显示了数据x(t)和y(t)加上标准正态分布噪声以及噪声直方图(δx，δy)。噪声的均值为0，标准差为σ=2。</p></figure><p id="b388" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图5显示了数据曲线<em class="mz"> x(t) </em>和<em class="mz"> y(t) </em>，包括标准正态分布产生的噪声。在示例中(图5)，噪声的均值为μ=0，标准差为σ=2。</p><p id="2fda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Skew_normal_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> 2.3偏斜正态分布</strong> </a></p><p id="b888" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">偏斜正态分布代表一种非对称扰动正态分布。该分布可用于模拟不对称噪声，其中一条尾巴比另一条长。在偏态正态分布中，平均值和中位数通常是不同的。偏斜正态概率密度函数(pdf)的一般形式，如等式所示。3、是标准正态分布pdf<em class="mz">φ(x ')</em>和误差函数ψ(α x ')的乘积。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/e1fc2a340a7004ddba8da2172c86b099.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*YOTwIIQXv4OmrbCByM5e_g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">等式3 |偏斜正态概率密度函数</p></figure><p id="5e7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中位置由ξ给出，标度由ω给出，参数α定义偏斜度。<em class="mz">φ(x’)</em>成为正态分布(方程式。2)对于等式中的α=0。3.通常，参数α被称为形状参数，因为它调节pdf的形状。如果α &gt;为0，则分布是右偏的，如果α &lt;为0，则分布是左偏的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/8875ff896e09d2158c53d88100ae1c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*YaHTVOWFUDTOKDacrVSxVA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6 |显示了曲线x(t)和y(t)加上偏斜的标准正态分布噪声以及噪声直方图(δx，δy)。位置ξ=0，比例ω=3，形状α=4。</p></figure><p id="6895" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图6显示了数据曲线<em class="mz"> x(t) </em>和<em class="mz"> y(t) </em>，包括偏斜正态分布产生的噪声。噪声是使用参数location ξ=0，scale ω=3，shape α=4生成的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="e5a5" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">3.第一个实验:数据集大小和回归质量</h1><p id="f18d" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">对于第一个实验，让我们使用数据<em class="mz"> y(t) </em>并添加由标准正态分布产生的噪声，其中<em class="mz"> μ=0 </em>和<em class="mz"> σ=2 </em>(见图5)。对于本例，我们采用如上所述的具有<em class="mz"> N=1000 </em>个数据点的数据集，从中随机选择<em class="mz"> 10、50、100、</em>和<em class="mz"> 500 </em>个数据点，如图7所示。为了拟合采样点，我们使用高斯过程。</p><p id="cee2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么是高斯过程？除了被广泛使用之外，高斯过程在小数据集上工作得很好，并且与其他可比的机器学习方法相比，高斯过程在训练或推断期间更容易确定问题的原因。例如，高斯过程已经被月球探测器公司X在一个项目中使用，该项目是用平流层气球扩展互联网连接。利用高斯过程，每个气球决定如何最好地利用盛行风，使自己成为一个大型通信网络的一部分。[4]</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/fa4b258ee27c7e6f54505bfa98585266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Umbx9SfxLk46smtvGK7ViQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图7 |显示了高斯过程(a)对数据(蓝点)的拟合(青色线)和置信区间0.95(蓝带)，10(b)50(c)100(d)500个数据点。</p></figure><p id="002a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了评估高斯过程回归的质量，我们基于真实值和拟合值之间的差异来计算误差。关于机器学习回归中的错误的简明介绍，参见参考文献。[10].在这里，我们计算<a class="ae kv" href="https://en.wikipedia.org/wiki/Mean_absolute_error" rel="noopener ugc nofollow" target="_blank">平均绝对误差(MAE) </a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差(MSE) </a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/Root-mean-square_deviation" rel="noopener ugc nofollow" target="_blank">均方根误差(RMSE) </a>。表2列出了对应于我们上述回归(图7)的MAE、MSE和RMSE。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表2 |对应于图7所示回归的MAE、MSE和RMSE</p></figure><p id="0929" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从图7和Tab。2，我们看到拟合的质量如何随着更多的数据点而提高。随着数据越来越多，拟合度越来越高，这并不令人惊讶。图8也在双对数图中显示了这种行为。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/eb97d8ba0ffd16ad52cc4d8e1365c5c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UKOkzaOd2BFRnSbiXqN81g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图8 |显示了与图7 /表2所示回归相对应的MAE、MSE和RMSE。轴以对数刻度显示。灰色虚线表示用于比较的1/N比例。</p></figure><p id="14cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到，将点数从N=50增加到N=500会使RMSE降低60%。稍后，我们将看到将噪声的影响减半会产生类似的减少。</p><blockquote class="mw mx my"><p id="7a5e" class="kw kx mz ky b kz la jr lb lc ld ju le na lg lh li nb lk ll lm nc lo lp lq lr ij bi translated"><strong class="ky ir">注意:</strong>对于高斯过程回归，我们使用平方指数(se)函数作为核函数(等式)。4).在高斯过程回归中，SE核是大多数机器学习库中的默认核。与其他内核相比，SE有一些优势。例如，在其先验中的每个函数都是无限多次可微的。此外，它也只有两个参数:长度标度<em class="iq"> ℓ </em>和输出方差σ。长度标尺<em class="iq"> ℓ </em>决定函数中“摆动”的长度。输出方差σ决定了函数与其均值的平均距离。对于图7所示的拟合，我们选择了超参数<em class="iq"> ℓ=8 </em>和<em class="iq"> σ=75。</em></p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/c0d8858408a4676a76f8739ad3926084.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*UE0eUaMepoDUoWwseEC3sg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">等式4 |平方指数核</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="0bee" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">4.第二个实验:噪声类型的影响</h1><p id="7202" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">接下来，我们使用数据x <em class="mz"> (t) </em>并添加由三种不同分布产生的噪声:均匀分布、标准正态分布和偏斜正态分布，如<em class="mz">章节所述。2 </em>。对于均匀分布，我们从区间<em class="mz"> a=-2.0 </em>到<em class="mz"> b=2.0 </em>进行采样。对于标准正态分布，我们使用参数<em class="mz"> μ=0 </em>表示平均值，使用参数<em class="mz"> σ =4.0 </em>表示方差。对于偏态正态分布，我们使用参数<em class="mz"> ξ=0 </em>、<em class="mz"> ω=2.0 </em>、<em class="mz"> α=2.0 </em>。对于所有三种分布，我们使用N=1000个数据点的数据集。从数据集中，我们随机选择了500个数据点，如图9的左栏所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/2119e4c6d3a8d2e555120cfa64bb0ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ttujGJE4QROcUsW7hgTnRg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图9 |左栏:基于不同分布的曲线x(t)和y(t)加上噪声，以及噪声直方图(δx，δy)。右栏:显示拟合(青色线)采样点y(t)+δy(蓝色点)和置信区间(蓝色带)，由具有500个数据点的高斯过程给出。从上到下，它显示了从均匀(rand)、标准正态(randn)和偏斜正态(skewed)分布中提取的噪声。</p></figure><p id="5e9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用高斯过程回归，就像之前在第二节中一样。3.高斯过程回归的结果显示在图9的右栏中。数据点显示为蓝色点，结果拟合为青色线。此外，我们看到拟合的置信区间(0.95)并将其可视化为蓝带。</p><p id="4de4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于均匀噪声和高斯噪声，均方根误差分别为0.13和0.31。高斯拟合RMSE更高，因为噪声的方差也更大。偏斜的正常情况更困难。在高斯和均匀情况下，最小化拟合RMSE相当于找到最大似然拟合。然而，偏斜正态情况更困难，因为均值和众数(最大似然)是不同的。由于高斯过程回归优化最大似然拟合，而不是RMSE最小化，我们预计RMSE更高。事实上，RMSE是1.4，如图9所示。总之，我们看到了噪声的规模和形状如何影响我们所期望的拟合RMSE。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f5b4" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">5.第三个实验:噪音的影响</h1><p id="4692" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在第三个实验中，我们使用曲线x <em class="mz"> (t) </em>，并添加均匀、标准正态和偏斜正态分布产生的噪声，如<em class="mz">节所述。2 </em>。我们按如下方式改变每个分布的噪声比例:</p><ul class=""><li id="0936" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">均匀分布:[a，b] = {[-1，1]，[-2，2]，[-4，4]，[-8，8]}；平均值= 0</li><li id="5e9b" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">正态分布:σ={1，2，4，8 }；平均值<em class="mz"> μ=0 </em></li><li id="5d65" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">偏斜正态分布:ω={1，2，4，8 }；参数<em class="mz"> ξ=0 </em>，<em class="mz"> α=2.0 </em></li></ul><p id="8893" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们对每个分布使用N=5000个数据点的数据集。我们从数据集中随机选择{50，100，500，1000}个点。对于数据点的规模、分布和数量的每种组合，我们使用高斯过程回归并计算拟合RMSE值，如前第节所述。3.RMSEs在表中列出。下面3。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/014d01319b51292b29b2de9990e5a33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RcIphTrUY3MGpcQt1j9tA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表3|生成数据中不同噪声等级的高斯过程回归的RMSE。噪声采样自均匀、正态和偏斜分布。数据集大小从50到1000个数据点不等。</p></figure><p id="7fec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三个实验表明，对于所有三种分布，数据点的数量必须随着噪声规模的增加而增加，以保持与RSME测量的相同的拟合质量。例如，从N=100个点的区间[-2，2](标度= 2)采样的均匀噪声开始，我们可以将点数增加到N=1000，以减少48%的RMSE，或者通过从更小的区间[-1，1](标度=1)采样来降低噪声，以减少33%的RMSE。看着标签。3，我们看到了其他尺度、数据集大小和噪声类型的类似权衡— <strong class="ky ir">将噪声减半与将数据集大小增加10倍产生类似的改善。</strong></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="1c8c" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">6.结论</h1><p id="5ebe" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们已经看到，更多的噪声数据导致更差的拟合。此外，即使对于相同的方差，噪声的形状也会对拟合质量产生深远的影响。最后，我们比较了改进数据质量和数量，发现降低噪声可以产生与增加数据点数量相似的拟合改进。</p><p id="b306" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在工业应用中，数据集很小，更多的数据很难获得，理解、控制和减少数据的噪声提供了一种从根本上提高拟合质量的方法。有多种方法可以控制和有效地降低噪声。关于灵感，参见参考文献。[11].</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="af16" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">参考</h1><ol class=""><li id="6f8d" class="nm nn iq ky b kz mr lc ms lf ob lj oc ln od lr oe ns nt nu bi translated">吴恩达“<a class="ae kv" href="https://hbr.org/2021/07/ai-doesnt-have-to-be-too-complicated-or-expensive-for-your-business" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> AI对你的业务来说不必太复杂或太昂贵</em> </a>”，《哈佛商业评论》(2021年7月)</li><li id="1255" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">维基百科文章“<a class="ae kv" href="https://en.wikipedia.org/wiki/Andrew_Ng" rel="noopener ugc nofollow" target="_blank"> <em class="mz">吴恩达</em></a>”(2021年12月)</li><li id="ed14" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">谷歌大脑 的联合创始人尼古拉斯·戈登(Nicholas Gordon)“<a class="ae kv" href="https://fortune.com/2021/07/30/ai-adoption-big-data-andrew-ng-consumer-internet/" rel="noopener ugc nofollow" target="_blank"><em class="mz">不要相信‘大数据’的宣传”，fortune.com(2021年7月)</em></a></li><li id="dbf3" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">詹姆士·威尔森、保罗·r·多尔蒂和蔡斯·达文波特"<a class="ae kv" href="https://hbr.org/2019/01/the-future-of-ai-will-be-about-less-data-not-more" rel="noopener ugc nofollow" target="_blank"> <em class="mz">人工智能的未来将是更少的数据，而不是更多的</em> </a>，《哈佛商业评论》(2019年1月)</li><li id="64d9" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">麦凯、戴维、j . c .《<a class="ae kv" href="http://www.inference.phy.cam.ac.uk/itprnn/book.pdf" rel="noopener ugc nofollow" target="_blank"><em class="mz">信息论、推理和学习算法</em> </a> <em class="mz">》，</em>剑桥大学出版社。ISBN 978-0521642989(2003年9月)<br/> Carl Eduard Rasmussen和Christopher K.I. Williams，“<a class="ae kv" href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf" rel="noopener ugc nofollow" target="_blank">机器学习的高斯过程</a>”，麻省理工学院出版社ISBN 978-0262182539(2005年11月)</li><li id="0d15" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">于尔根·迈耶、哈立德·凯里和黄邦贤·霍华德“<a class="ae kv" href="https://aapt.scitation.org/doi/10.1119/1.3254017" rel="noopener ugc nofollow" target="_blank"> <em class="mz">用四个复杂参数</em> </a>画一头大象”，《美国物理学报》78，648，DOI:<a class="ae kv" href="https://doi.org/10.1119/1.3254017" rel="noopener ugc nofollow" target="_blank">10.1119/1.3254017</a>(2010年5月)</li><li id="b6c6" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated">弗里曼·戴森<a class="ae kv" href="https://www.nature.com/articles/427297a" rel="noopener ugc nofollow" target="_blank"> <em class="mz">与恩利克·费密</em> </a>《自然》427，6972，297，DOI:<a class="ae kv" href="https://doi.org/10.1038/427297a" rel="noopener ugc nofollow" target="_blank">10.1038/427297 A</a>(2004年1月)</li><li id="e586" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated"><a class="of og ep" href="https://medium.com/u/75b5f5a46f52?source=post_page-----79e9071536e--------------------------------" rel="noopener" target="_blank">Julia Kho</a><a class="ae kv" rel="noopener" target="_blank" href="/the-one-theorem-every-data-scientist-should-know-f7c501d54bad">每个数据科学家都应该知道的一个定理</a>，<a class="ae kv" href="https://towardsdatascience.com" rel="noopener" target="_blank">Medium.com—走向数据科学</a>(2018年10月)</li><li id="a1fc" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated"><a class="of og ep" href="https://medium.com/u/f9f30269fe4f?source=post_page-----79e9071536e--------------------------------" rel="noopener" target="_blank">库珀·道尔</a><a class="ae kv" rel="noopener" target="_blank" href="/the-signal-and-the-noise-d82b8630c3ad"><em class="mz">信号与噪音:中心极限定理如何使数据科学成为可能</em> </a>，<a class="ae kv" href="https://towardsdatascience.com" rel="noopener" target="_blank">Medium.com——走向数据科学</a>(2021年9月)</li><li id="a810" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated"><a class="of og ep" href="https://medium.com/u/d0d529173bc4?source=post_page-----79e9071536e--------------------------------" rel="noopener" target="_blank"> Eugenio Zuccarelli </a>“机器学习中的性能指标——第2部分:回归”，<a class="ae kv" rel="noopener" target="_blank" href="/performance-metrics-in-machine-learning-part-2-regression-c60608f3ef6a">Medium.com——迈向数据科学</a>(2021年1月)</li><li id="2577" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr oe ns nt nu bi translated"><a class="of og ep" href="https://medium.com/u/bf0160c6bb?source=post_page-----79e9071536e--------------------------------" rel="noopener" target="_blank"> Andrew Zhu </a>“用Python中的傅里叶变换清理数据噪声”，【Medium.com】—走向数据科学(2021年10月)</li></ol></div></div>    
</body>
</html>