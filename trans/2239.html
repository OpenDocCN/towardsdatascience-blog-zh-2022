<html>
<head>
<title>Accessing the NYC Taxi Data in 2022</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">访问2022年纽约市的出租车数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/accessing-the-nyc-taxi-data-in-2022-8363adfda76a#2022-05-17">https://towardsdatascience.com/accessing-the-nyc-taxi-data-in-2022-8363adfda76a#2022-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="77d6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于最近的变化你需要知道的一切</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f0b61774eec19ae69ff890d8c7a536e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P444fv3gmbNzbCOKk203pg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由Benjamin Gremler通过Unsplash提供</p></figure><p id="5f02" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">截至2022年5月13日，对纽约市出租车数据的访问已发生变化。拼花现在已经成为新的默认文件格式，而不是CSV。实际上，这意味着您需要更改代码中的两件事:</p><ol class=""><li id="698d" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">将路径更改为S3桶</li><li id="06f0" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">使用<code class="fe mi mj mk ml b">dd.read_parquet()</code>方法，而不是你常用的<code class="fe mi mj mk ml b">dd.read_csv()</code>或<code class="fe mi mj mk ml b">pd.read_csv()</code></li></ol><p id="0acf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章提供了变化的背景，解释了拼花文件格式的好处，并展示了对纽约市11年出租车数据的运行计算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/fdd09ab75535bad21e234415463ac6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dN2bT6yvgs2WGMWa.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae mn" href="https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page" rel="noopener ugc nofollow" target="_blank">www1.nyc.gov</a></p></figure><h1 id="10cf" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">你多年来一直在做的事情</h1><p id="3bf8" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><a class="ae mn" href="https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page" rel="noopener ugc nofollow" target="_blank"> NYC TLC数据集</a>是最知名的公共数据集之一。这是为数不多的既大(&gt; 100GBs) <em class="nl">又相对干净的公共数据集之一。正因为如此，许多公司将其用于演示和内部测试。十多年来，数据集一直是大数据领域的一个可靠特征。</em></p><p id="1fc9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到了周末，这种情况突然发生了变化。如果你现在尝试拨打你熟悉的<code class="fe mi mj mk ml b">read_csv</code>电话，你会遇到一个<code class="fe mi mj mk ml b">IndexError: list index out of range</code>:</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="6475" class="nq mp it ml b gy nr ns l nt nu"># read in 2012 CSV data <br/>ddf = dd.read_csv("s3://nyc-tlc/trip data/yellow_tripdata_2012-*.csv")</span></pre><p id="1548" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将产生如下消息:</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="df64" class="nq mp it ml b gy nr ns l nt nu">--------------------------------------------------------------------------- IndexError Traceback (most recent call last)<br/> Input In [21], in &lt;cell line: 2&gt;() <strong class="ml iu"> 1</strong> # read in 2012 CSV data ----&gt; 2 ddf = dd.read_csv(<strong class="ml iu"> 3</strong> "s3://nyc-tlc/trip data/yellow_tripdata_2012-*.csv",<strong class="ml iu"> 4</strong> ) File ~/mambaforge/envs/dask-dataframes/lib/python3.9/site-packages/dask/dataframe/io/csv.py:741, in make_reader.&lt;locals&gt;.read(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)<strong class="ml iu"> 728</strong> <strong class="ml iu">def</strong> read(<strong class="ml iu"> 729</strong> urlpath,<strong class="ml iu"> 730</strong> blocksize="default", (...)<strong class="ml iu"> 739</strong> **kwargs,<strong class="ml iu"> 740</strong> ): --&gt; 741<strong class="ml iu">return</strong> read_pandas(<strong class="ml iu"> 742</strong> reader,<strong class="ml iu"> 743</strong> urlpath,<strong class="ml iu"> 744</strong> blocksize=blocksize,<strong class="ml iu"> 745</strong> lineterminator=lineterminator,<strong class="ml iu"> 746</strong> compression=compression,<strong class="ml iu"> 747</strong> sample=sample,<strong class="ml iu"> 748</strong> sample_rows=sample_rows,<strong class="ml iu"> 749</strong> enforce=enforce,<strong class="ml iu"> 750</strong> assume_missing=assume_missing,<strong class="ml iu"> 751</strong> storage_options=storage_options,<strong class="ml iu"> 752</strong> include_path_column=include_path_column,<strong class="ml iu"> 753</strong> **kwargs,<strong class="ml iu"> 754</strong> ) File ~/mambaforge/envs/dask-dataframes/lib/python3.9/site-packages/dask/dataframe/io/csv.py:520, in read_pandas(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)<strong class="ml iu"> 515</strong> paths = get_fs_token_paths(urlpath, mode="rb", storage_options=storage_options)[<strong class="ml iu"> 516</strong> 2<strong class="ml iu"> 517</strong> ]<strong class="ml iu"> 519</strong> # Infer compression from first path --&gt; 520 compression = infer_compression(paths[0])<strong class="ml iu"> 522</strong> <strong class="ml iu">if</strong> blocksize == "default":<strong class="ml iu"> 523</strong> blocksize = AUTO_BLOCKSIZE</span><span id="50d1" class="nq mp it ml b gy nv ns l nt nu">IndexError: list index out of range</span></pre><h1 id="86b5" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">换成拼花地板</h1><p id="b020" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">拼花地板已经成为纽约市TLC数据的新默认值。要访问数据，您需要:</p><ol class=""><li id="19fd" class="lu lv it la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">将S3存储桶的路径改为使用文件扩展名<code class="fe mi mj mk ml b">.parquet</code>而不是<code class="fe mi mj mk ml b">.csv</code></li><li id="88a0" class="lu lv it la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">使用<code class="fe mi mj mk ml b">dd.read_parquet()</code>方法代替<code class="fe mi mj mk ml b">dd.read_csv()</code></li></ol><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="0f88" class="nq mp it ml b gy nr ns l nt nu"># read in 2012 Parquet data <br/>ddf = dd.read_parquet("s3://nyc-tlc/trip data/yellow_tripdata_2012-*.parquet") </span><span id="2ee0" class="nq mp it ml b gy nv ns l nt nu">ddf.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/71f8d05227ed96c0f12d1513c08091cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bvWJakRmwTwlYUpR.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者提供的图片(为便于阅读，已截断)</p></figure><p id="36bf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae mn" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> Dask </strong> </a> <strong class="la iu">是按比例读取纽约市新出租车数据的最佳方式。Dask使您能够最大限度地提高拼花文件格式的并行读/写能力。</strong></p><p id="70ae" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你也可以通过<code class="fe mi mj mk ml b">pd.read_parquet()</code>使用pandas，但这意味着你只能使用一个CPU内核来处理数据。这将使你的工作流程变得更慢，可扩展性更差。</p><p id="6ff5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">阅读这篇文章了解更多关于Dask如何帮助你加速数据分析的信息。</p><h1 id="5418" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">旧习难改</h1><p id="11cc" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">如果你真的，真的，真的想使用一个较慢的并行I/O，较少的压缩选项，没有列修剪或谓词下推的劣质文件格式😉您仍然可以访问<code class="fe mi mj mk ml b">csv_backup</code>目录中的CSV数据:</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="017e" class="nq mp it ml b gy nr ns l nt nu"># read in 2012 CSV data <br/>ddf = dd.read_csv("s3://nyc-tlc/csv_backup/yellow_tripdata_2012-*.csv")</span></pre><p id="ff94" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，与新的Parquet文件相比，这些CSV文件的并行I/O速度较慢，压缩选项较少，并且没有列修剪或谓词下推。如果您正在大规模工作，除非您有非常充分的理由使用CSV，否则您通常应该使用拼花地板而不是CSV。<a class="ae mn" href="https://coiled.io/blog/writing-parquet-files-with-dask-using-to_parquet/" rel="noopener ugc nofollow" target="_blank">阅读这个博客</a>，了解更多关于如何用Dask编写拼花文件的信息。</p><h1 id="f73a" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">还有更好的</h1><p id="107e" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">NYC TLC拼花文件的唯一缺点是下载这些拼花文件需要很长时间，因为每年有12个非常大的分区。为了并行IO和更快的计算，最好将数据集重新分区到更优化的大小。</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="a16f" class="nq mp it ml b gy nr ns l nt nu">ddf = ddf.repartition(partition_size="100MB")</span></pre><p id="f65e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码演示了对2011年到2021年的NYC TLC数据执行groupby计算。这是磁盘上超过200GB的未压缩数据。您的本地机器不太可能有运行该分析的内存。我们将在一个有50个工人和16GB内存的卷状集群上运行我们的计算。<a class="ae mn" href="https://docs.coiled.io/user_guide/getting_started.html" rel="noopener ugc nofollow" target="_blank">阅读文档</a>开始使用Coiled。</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="e33a" class="nq mp it ml b gy nr ns l nt nu">from coiled import Cluster <br/>from distributed import Client <br/>import dask.dataframe as dd </span><span id="b411" class="nq mp it ml b gy nv ns l nt nu"># launch Coiled cluster <br/>cluster = Cluster( <br/>    name="dataframes", <br/>    n_workers=50, <br/>    worker_memory="16GiB", <br/>    software="coiled-examples/dask-dataframes",<br/>) </span><span id="32b5" class="nq mp it ml b gy nv ns l nt nu"># connect Dask to Coiled <br/>client = Client(cluster)</span></pre><p id="dfa8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以加载我们的数据集:</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="bbe0" class="nq mp it ml b gy nr ns l nt nu"># read in all data for 2011-2021 <br/>ddf = dd.read_parquet("s3://nyc-tlc/trip data/yellow_tripdata_2011-*.parquet") </span><span id="3258" class="nq mp it ml b gy nv ns l nt nu">for i in range(2012,2022): <br/>   ddf_temp = dd.read_parquet(f"s3://nyc-tlc/trip data/yellow_tripdata_{i}-*.parquet") <br/>    ddf = ddf.append(ddf_temp) </span><span id="93ee" class="nq mp it ml b gy nv ns l nt nu"># repartition dataset <br/>ddf = ddf.repartition(partition_size="100MB").persist()</span></pre><p id="645f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在通过计算来运行我们的组:</p><pre class="kj kk kl km gt nm ml nn no aw np bi"><span id="c4da" class="nq mp it ml b gy nr ns l nt nu">%%time <br/># perform groupby aggregation ddf.groupby('passenger_count').trip_distance.mean().compute()</span><span id="2933" class="nq mp it ml b gy nv ns l nt nu">CPU times: user 526 ms, sys: 55.1 ms, total: 582 ms <br/>Wall time: 10.3 s </span><span id="ce71" class="nq mp it ml b gy nv ns l nt nu">passenger_count<br/>49.0      0.000000<br/>208.0     0.241961<br/>10.0      0.386429<br/>19.0      0.690000<br/>211.0     0.970000<br/>192.0     1.010000<br/>254.0     1.020000<br/>223.0     1.160000<br/>96.0      1.195000<br/>177.0     1.340000<br/>33.0      1.615000<br/>249.0     1.690000<br/>193.0     1.740000<br/>112.0     1.800000<br/>97.0      1.870000<br/>129.0     2.050000<br/>37.0      2.160000<br/>0.0       2.522421<br/>47.0      2.560000<br/>15.0      2.590000<br/>255.0     2.953333<br/>6.0       2.975480<br/>5.0       3.001735<br/>70.0      3.060000<br/>7.0       3.288784<br/>247.0     3.310000<br/>58.0      3.460000<br/>225.0     4.830000<br/>8.0       4.950078<br/>250.0     5.010000<br/>4.0       5.028690<br/>9.0       5.675410<br/>2.0       5.869093<br/>3.0       5.931338<br/>1.0       6.567514<br/>61.0      8.780000<br/>65.0     18.520000<br/>36.0     20.160000<br/>Name: trip_distance, dtype: float64</span></pre><h1 id="8fa9" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">拼花地板是你的新朋友</h1><p id="bb59" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">是的，这种访问更改是痛苦的，并且意味着您可能必须更新一些遗留代码。但这种改变是有充分理由的:Parquet是一种更有效的文件格式，尤其是在处理这种规模的数据集时，最好以并行方式读取。Parquet使您能够执行节省时间的操作，比如并行IO、列修剪和谓词下推。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/f8235beb87a8ca791c929e5a8049760b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OHTWsNcR2qffIfNo.png"/></div></figure><p id="0f9f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae mn" href="https://coiled.io/blog/parquet-file-column-pruning-predicate-pushdown/" rel="noopener ugc nofollow" target="_blank">阅读我们关于使用Parquet优于CSV或JSON的所有优势的帖子</a>,了解更多信息并更详细地检查上述基准。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="378f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nl">原载于2022年5月17日</em><a class="ae mn" href="https://coiled.io/blog/nyc-taxi-parquet-csv-index-error/" rel="noopener ugc nofollow" target="_blank"><em class="nl">https://coiled . io</em></a><em class="nl">。</em></p></div></div>    
</body>
</html>