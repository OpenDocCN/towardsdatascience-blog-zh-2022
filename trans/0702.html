<html>
<head>
<title>Graph Neural Networks: A learning journey since 2008 — Graph Attention Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图形神经网络:2008 年以来的学习之旅——图形注意网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-neural-networks-a-learning-journey-since-2008-graph-attention-networks-f8c39189e7fc#2022-02-28">https://towardsdatascience.com/graph-neural-networks-a-learning-journey-since-2008-graph-attention-networks-f8c39189e7fc#2022-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8e75" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">今天我们将深入研究图形注意力网络(GAT)的理论和实现。一言以蔽之:关注摇滚，图表摇滚，GAT 的作者摇滚！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bfbe4a824e683b578799611d2f50bf5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t7V6x4E8sabV2uk_kJjozQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://unsplash.com/photos/Q4RuIsRuMcs" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@pascale_amez" rel="noopener ugc nofollow" target="_blank"> Pascale Amez </a>拍摄</p></figure><p id="f275" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">通过我的推荐链接加入 Medium 来支持我的写作和项目:</em></p><div class="lw lx gp gr ly lz"><a href="https://stefanobosisio1.medium.com/membership" rel="noopener follow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">通过我的推荐链接加入 Medium-Stefano Bosisio</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">stefanobosisio1.medium.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ks lz"/></div></div></a></div><p id="0f6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我以前关于图和 M 的帖子</p><ul class=""><li id="c75d" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-part-1-7df897834df9?source=your_stories_page----------------------------------------">图形神经网络:2008 年以来的学习之旅——第一部分</a></li><li id="1608" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-part-2-22dbf7a3b0d?source=your_stories_page----------------------------------------">图形神经网络:2008 年以来的学习之旅——第二部分</a></li><li id="c8b1" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-deep-walk-e424e716070a?source=your_stories_page----------------------------------------">图形神经网络:2008 年以来的学习之旅——深度行走</a></li><li id="6814" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-python-deep-walk-29c3e31432f?source=your_stories_page----------------------------------------">图形神经网络:2008 年以来的学习之旅——Python&amp;深度行走</a></li><li id="d5bd" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-graph-convolution-network-aadd77e91606">图形神经网络:2008 年以来的学习历程——图形卷积网络</a></li><li id="4c62" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-python-graph-convolutional-network-5edfd99f8190">图神经网络:2008 年以来的学习之旅——Python&amp;图卷积网络</a></li><li id="85b9" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/graph-neural-networks-a-learning-journey-since-2008-diffusion-convolutional-neural-networks-329d45471fd9">图形神经网络:2008 年以来的学习之旅——扩散卷积神经网络</a></li></ul><p id="ba16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欢迎回到我的图形神经网络系列。今天我要向大家介绍一个最伟大的图形神经网络框架下的基础理论:图注意力网络(GAT)[1]由 Velickovic，Cucurull，Casanova，Romero，莉雅和 Bengio 于 2018 年发表(你应该只听到这些名字就起鸡皮疙瘩！)这种 ML-graph 方法有什么新的地方？我们来分析一下前几集看到的内容。</p><p id="a17a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初，Gori 和 Scarselli[5–9]提出了图形神经网络(GNNs ),其中递归神经网络被推广为直接与图形对象交互。gnn 基于 Banach 不动点定理。一旦达到平衡，运行神经网络以返回输出。相比之下，GNN 不能利用表征学习，其可扩展性非常有限，由于收敛问题。</p><p id="7c17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到的另一种方法是 Perozzi 在 2014 年提出的 Deep Walk [6]及其在 2017 年的演变[7]。深度行走标志着节点嵌入的概念，即通过 skip gram[8–12]获得的节点的潜在表示(或社会表示)。这个模型在半无人监督的模式下工作，尽管可扩展性和表示学习可能仍有问题。</p><p id="127a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，已经提出了进一步的图形神经网络框架。谱方法[13–17]，其中图形拉普拉斯表示、特征值分解和卷积是关键要素。卷积可以通过扩散概念来进一步利用。在这种方法[18–22]中，算法学习每个节点的特定权重矩阵，计算转换矩阵的幂来描述节点的邻域。虽然这些技术非常成功，但它们直接依赖于拉普拉斯的特征基，限制了我们可以研究的图形种类。因此，一旦我们将我们的模型训练到一个特定的图，我们就不能使用这个模型在不同的结构图上运行预测。</p><p id="fa5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在 GAT 中，作者强调了注意力的力量。注意力算法直接来源于神经机器翻译问题或序列对序列(Seq2Seq)。如果我从法语翻译成英语，我将不得不考虑输入和输出序列之间的长度差异，以及在给定词汇和目标序列的情况下我可以使用的最佳术语。注意力不仅可以解决不同长度的问题，还可以检测输入的最相关部分，以优化和最大化给定输入序列的输出概率。</p><p id="55e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们跳到注意力是如何工作的，以及一切是如何开始的。</p><h1 id="1d27" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">注意:什么？谁啊。在哪里？什么时候？为什么？</h1><p id="cdf3" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">注意力算法起源于 Cho 的 RNN 编码器-解码器模型[14]。作者正在寻找一种有效的方法来改进 seq2seq 翻译的 ML 模型。编码器-解码器模型是递归神经网络(RNN)的堆叠组合。编码器将符号序列编码成固定长度的向量表示，而解码器以另一种符号范例对给定的表示进行解码。</p><p id="7288" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图 1 显示了 Cho 算法的工作原理。给定输入序列<strong class="lb iu"> x </strong>(例如<code class="fe nz oa ob oc b">Je m'appelle S</code>)，该模型试图最大化目标序列<strong class="lb iu"> y: </strong>的条件对数似然</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/71335080b8b8af05af6404e00027f8c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*oqMGYq70FppRxptBkrr7cQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 1:给定输入序列 x 和目标序列 y，RNN 编码器-解码器试图最大化条件对数似然</p></figure><p id="b650" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输入序列用大小为<code class="fe nz oa ob oc b">hidden_size</code>的嵌入层解码，然后在 GRU 单元中处理。GRU 的隐藏状态，称为<code class="fe nz oa ob oc b">context_vector</code>，与目标序列一起被提供给解码器。解码器将输入序列和上下文向量一起投影到嵌入空间。最后，一个 GRU 和一个线性层在<strong class="lb iu"> x </strong>和<strong class="lb iu"> y </strong>之间创建一个映射</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/2e1a46e0554f6dd36190c9aecf20c321.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SsuE3f79NhelbdJ_EC9I6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 Cho 的 RNN 编码器-解码器模型的逻辑示意图。编码器对输入序列进行消化。编码器的隐藏状态与目标序列一起被用作解码器的输入，以便找到序列到序列的正确映射。</p></figure><p id="23bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图 2 显示了如何在 Pytorch 中对 Cho 的编码器和解码器进行编码的示例代码。一个关键的区别是解码器类将在嵌入的目标空间中映射输入。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 Cho 的 RNN 模型的编码器和解码器的示例代码。这两个模型都依赖于嵌入层和 GRU。</p></figure><p id="58e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras 提供了进一步的可视化帮助，我们可以用一种简单的方式对这个模型进行编码，以显示输入信息是如何处理的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 Cho 的 RNN 编码器-解码器的 Keras 实现。在这里，您可以进一步看到当将编码器 GRU 的隐藏状态传递给解码器时，注意力是如何被触发的。</p></figure><p id="1abd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2016 年晚些时候，Bahdanau 扩展了 Cho 的模型[26，28]，用<em class="lv">比对分数构建了注意力算法。</em>校准分数进一步增强了编码器的输出，定义了它与给定输出的匹配程度*:</p><ul class=""><li id="e863" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated">每个编码器的 GRU 输入<em class="lv"> x₁、x₂、x₃ </em> …都有各自的隐藏状态<em class="lv"> h₁、h₂、h₃ </em></li><li id="8a2f" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu mt mu mv mw bi translated">解码器开始计算比对分数，例如 e <em class="lv"> ₁₁ </em>，e <em class="lv"> ₁₂ </em>，e <em class="lv"> ₁₃ </em>(等式 2)。校准分数是通过函数<em class="lv"> a — </em>通常是前馈线性神经网络来定义的，该函数作用于解码器的输出状态<em class="lv"> s </em>和编码器的输出<em class="lv"> h. </em></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/610e703d3d7e4b6ae286b7bdc3e3b532.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*eqvAf6pNz8ZN9ZoNuadNxg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 2:对准分数被定义为作用于解码器的输出状态 s 和编码器的输出 h 的函数 a</p></figure><ul class=""><li id="feee" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated">在第一步，解码器输出为 0，因此校准分数定义为:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/54c550668c902aa3703eef08c47a2d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*1CK-3XgE_1DhZnswC0qYvQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 3:第一次迭代中的对齐分数，其中解码器的输出为 0。</p></figure><ul class=""><li id="91c1" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated"><em class="lv"/>是简单的<code class="fe nz oa ob oc b">pytorch.nn.Linear</code>前馈神经网络，其输出α <strong class="lb iu"> </strong>然后用 softmax 函数(等式 4)归一化:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/b1facd7dacbfc05bc155dca7b1273eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*nyraCJW4bmpj9wmRWIm1AQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 4:来自神经网络的一般 softmax-ed 输出以及等式 3 的 3 个输入的示例</p></figure><ul class=""><li id="b0b4" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated">然后，归一化对齐分数被用于更新输出编码器的上下文向量 c，并被注入到解码器 GRU 中:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/8d0b3646708f1d49f2e921be88863813.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*cFwIDBFXwh1a2_uQqVPLGw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 5:输出对齐权重用于将每个上下文向量与给定目标对齐</p></figure><ul class=""><li id="3ce8" class="mo mp it lb b lc ld lf lg li mq lm mr lq ms lu mt mu mv mw bi translated">循环重复，新解码器的输出<em class="lv"> s </em>用于计算比对分数</li></ul><p id="3b15" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过添加由前馈神经网络、softmax 和注意权重/对齐分数与编码器输出之间的矩阵乘法组成的注意层，可以在 PyTorch 中将该方案容易地应用于 Cho 的模型(图 2 ):</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:在 Cho 的 RNN 编码器-解码器中添加注意层。</p></figure><p id="e5d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，Bahdanau 的方法旨在将编码器的所有隐藏状态传递给 RNN 解码器，并进一步将注意力/对准分数层应用于解码器架构。从这里我们可以开始研究图形注意力网络算法</p><h1 id="eb0b" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">图形注意网络</h1><p id="7298" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">从 Bahdanau 的注意力方法开始，Velickovic 等人开始使用图形注意力网络框架——然而，我必须强调，GAT 对注意力机制的特定选择是不可知的。现在，让我们考虑一个有<em class="lv"> N </em>个节点的图，每个节点有<em class="lv"> F </em>个特征。这里注意机制的整体过程是摄取一组节点特征<em class="lv"/><strong class="lb iu"><em class="lv"/></strong>(维度为<em class="lv"> F </em>)并返回这些特征的一个输出表示<strong class="lb iu"><em class="lv"/></strong><em class="lv">'</em>(维度为<em class="lv"> F' </em>)。要素的输出表示将调用一些潜在要素，这允许网络在节点级别运行预测。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/90eabb16eafcea8b20c3a3f6ff49dd24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ROFci09artS-Trx06edjfQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 GAT 工作流程和注意力的示意图。</p></figure><p id="55c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图 5 报告了 GAT 的作用方案。节点共享一个权重矩阵<em class="lv"> </em> <strong class="lb iu"> <em class="lv"> W </em> </strong>，其维数为<em class="lv">FxF’。</em>权重矩阵<strong class="lb iu"> <em class="lv"> W </em> </strong>与每个节点的特征矩阵相乘以执行第一线性变换。它遵循第二线性变换，通过<em class="lv">自关注</em>机制，通过应用前馈神经网络<em class="lv"> a，</em>返回<em class="lv">关注系数 e: </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b4a8eb74fa9bf0e97d48dd3716a19f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/1*mTfcEnjOvnmWA6nCW9ysnA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 6:表示节点 j 的特征对节点 I 的重要性的关注系数</p></figure><p id="28a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从<em class="lv"> a </em>输出的注意系数在到达 softmax 层之前通过 LeakyReLu。softmax 在节点<em class="lv"> j </em>的特征上被归一化，以使所有系数在不同节点之间容易比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/11c56ded71f06ae1a1d0cb672c886894.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*sZRtfFFC-PUE0bhKq5gK9g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 7:相对于节点 j 特征的归一化(softmax)关注系数</p></figure><p id="5b4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，应用非线性<em class="lv"> σ </em>得到最终的特征描述<strong class="lb iu"><em class="lv">h’</em></strong>。为了进一步稳定自我注意机制中的学习过程，作者扩展了该算法以使用<em class="lv">多头注意。</em>这种方法包括在图表的不同部分运行多个注意力层，以便掌握一些长期的依赖关系。长程相关性是指相距很远的节点之间的关系。最终的特征集合可以连接在一起，并且如 GAT 的论文中所提议的，进行平均以返回最终节点的预测。这种平均过程突出了 GAT 的输出是来自目标节点邻域的聚集信息。</p><p id="a860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看看如何在 PyTorch 中实现 GAT 方法，而在下一个故事中，我们将处理数据集和预测以及优化 GAT 的技巧！</p><h1 id="ed25" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">加特&amp;皮托奇</h1><p id="9505" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">图 6 显示了 GAT 核心部分的简单 PyTorch 实现。在<code class="fe nz oa ob oc b">call</code>函数中，GAT 接收节点的特征和边(<code class="fe nz oa ob oc b">input</code>)作为输入，报告图形结构信息。输入节点状态/特征最初乘以权重矩阵<strong class="lb iu"> W </strong>以执行第一线性变换:<code class="fe nz oa ob oc b">node_states_transformed = tf.matmul(node_states, self.kernel)</code>。将转换后的状态与结构信息<code class="fe nz oa ob oc b">node_states_expanded</code>收集在一起，并从那里运行进一步的线性转换以获得关注系数:<code class="fe nz oa ob oc b">attention_scores = tf.nn.leaky_relu(tf.matmul(node_states_expanded, self.kernel_attention))</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 PyTorch 中注意机制的实现</p></figure><p id="dbf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，softmax 被应用到<code class="fe nz oa ob oc b">attention_scores</code>(第 70–79 行)，来自关注层的邻域特征信息被返回到主函数。</p><p id="feed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个最重要的一点是实现了<em class="lv">多头关注。</em>该类定义了并行运行的关注层的数量，以及关注层单元。最终输出是所有串联注意力输出的平均值:<code class="fe nz oa ob oc b">tf.reduce_mean(tf.stack(outputs, axis=-1), axis=-1)</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 7:多头注意力的实现</p></figure><p id="b8af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们以 GAT 的最终实现来结束这个故事，对算法有一个全面清晰的了解:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="of og l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 GAT 模型的最终代码。</p></figure><p id="9d21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天到此为止，请在下一个故事中欣赏我，我们将把 GAT 应用于数据集，看看 GAT 的真正威力是什么:)</p></div><div class="ab cl oo op hx oq" role="separator"><span class="or bw bk os ot ou"/><span class="or bw bk os ot ou"/><span class="or bw bk os ot"/></div><div class="im in io ip iq"><p id="deeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有任何问题或意见，请随时给我发电子邮件，地址是:stefanobosisio1@gmail.com，或者直接在 Medium 这里。</p><h1 id="e12a" class="nc nd it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">文献学</h1><ol class=""><li id="5060" class="mo mp it lb b lc nu lf nv li ov lm ow lq ox lu oy mu mv mw bi translated">《图形注意网络》<em class="lv"> arXiv 预印本 arXiv:1710.10903 </em> (2017)。</li><li id="8111" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">《图形神经网络模型》<em class="lv"> IEEE 神经网络汇刊</em>20.1(2008):61–80。</li><li id="532d" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">《图形神经网络的计算能力》IEEE 神经网络汇刊 20.1(2008):81–102。</li><li id="53bd" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">《网页排序的图形神经网络》。<em class="lv">2005 年 IEEE/WIC/ACM 网络智能国际会议(WI'05) </em>。IEEE，2005 年。</li><li id="d4bc" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">哥里、马尔科、加布里埃尔·蒙法迪尼和佛朗哥·斯卡塞利。"一个在图形领域学习的新模型."<em class="lv">议事录。2005 年 IEEE 神经网络国际联合会议</em>。第二卷。№2005.2005.</li><li id="00c0" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">佩罗齐、布莱恩、拉米·艾尔弗和史蒂文·斯基纳。"深度行走:社交表征的在线学习."<em class="lv">第 20 届 ACM SIGKDD 知识发现和数据挖掘国际会议论文集</em>。2014.</li><li id="d4e2" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">佩罗齐、布莱恩等人“不要走，跳过！多尺度网络嵌入的在线学习。”<em class="lv">2017 年 IEEE/ACM 社交网络分析与挖掘进展国际会议论文集 2017 </em>。2017.</li><li id="7a70" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">《向量空间中单词表征的有效估计》<em class="lv"> arXiv 预印本 arXiv:1301.3781 </em> (2013)。</li><li id="8e7e" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">单词和短语的分布式表征及其组合性。<em class="lv">神经信息处理系统的进展</em>。2013.</li><li id="80da" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">大卫·格思里等着，〈跳过语法建模的更近距离观察〉。<em class="lv"> LREC </em>。第六卷。2006.</li><li id="b7d3" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">Gittens，Alex，Dimitris Achlioptas 和 Michael W. Mahoney。" Skip-Gram Zipf+Uniform =矢量可加性."<em class="lv">计算语言学协会第 55 届年会论文集(第 1 卷:长篇论文)</em>。2017.</li><li id="5fe8" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">明诺、大卫和劳雷·汤普森。"负抽样跳跃图的奇异几何."<em class="lv">自然语言处理中的经验方法</em>。2017.</li><li id="9f04" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">基普夫，托马斯 n，和马克斯韦林。"图卷积网络的半监督分类."<em class="lv"> arXiv 预印本 arXiv:1609.02907 </em> (2016)。</li><li id="a2ed" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">琼·布鲁纳等着《图上的谱网络和深局部连通网络》第二届学习代表国际会议，ICLR。第 2014 卷。2014.</li><li id="ac6b" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">迪费拉德、米歇尔、泽维尔·布列松和皮埃尔·范德盖恩斯特。"具有快速局部谱滤波的图上的卷积神经网络."<em class="lv">神经信息处理系统进展</em>29(2016):3844–3852。</li><li id="e39d" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">学习分子指纹的图形卷积网络。<em class="lv"> arXiv 预印本 arXiv:1509.09292 </em> (2015)。</li><li id="6ac0" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">哈蒙德、大卫·k、皮埃尔·范德盖恩斯特和雷米·格里邦瓦尔。"通过谱图论研究图上的小波."<em class="lv">应用和计算谐波分析</em>30.2(2011):129–150。</li><li id="1bd2" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">阿特伍德，詹姆斯和唐·陶斯利。"扩散卷积神经网络."<em class="lv">神经信息处理系统的进展</em>。2016.</li><li id="d8a8" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">稀疏扩散-卷积神经网络。<em class="lv"> arXiv 预印本 arXiv:1710.09813 </em> (2017)。</li><li id="f180" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">叶，侬。"用于异常检测的时间行为的马尔可夫链模型."2000 年 IEEE 系统、人和控制论信息保证和安全研讨会会议录。第 166 卷。纽约西点军校，2000 年。</li><li id="1fc2" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">海因斯布莱恩。"马尔可夫链中的第一个环节."<em class="lv">美国科学家</em> 101.2 (2013): 252。</li><li id="f398" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">奥雷，史蒂文。<em class="lv">马尔可夫链转移概率的极限定理</em>。伦敦:范·诺斯特朗，1971 年。</li><li id="36f0" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">使用统计机器翻译的 RNN 编码解码器学习短语表达<em class="lv"> arXiv 预印本 arXiv:1406.1078 </em> (2014)。</li><li id="da9d" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">基于注意力的语音识别模型。<em class="lv">神经信息处理系统进展</em> 28 (2015)。</li><li id="29b6" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">基于端到端注意力的大词汇量语音识别。<em class="lv"> 2016 年 IEEE 声学、语音和信号处理国际会议(ICASSP) </em>。IEEE，2016。</li><li id="a76a" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">Bahdanau、Dzmitry、Kyunghyun Cho 和 Yoshua Bengio。"通过联合学习对齐和翻译的神经机器翻译."<em class="lv"> arXiv 预印本 arXiv:1409.0473 </em> (2014)。</li><li id="1b3a" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">你所需要的只是关注。<em class="lv">神经信息处理系统进展</em> 30 (2017)。</li><li id="817f" class="mo mp it lb b lc mx lf my li mz lm na lq nb lu oy mu mv mw bi translated">Luong，Minh-Thang，Hieu Pham 和 Christopher D. Manning。"基于注意力的神经机器翻译的有效方法."<em class="lv"> arXiv 预印本 arXiv:1508.04025 </em> (2015)。</li></ol><p id="e90a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">*:<a class="ae ky" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener ugc nofollow" target="_blank">https://jalammar . github . io/visualizing-neural-machine-translation-mechanics-of-seq 2 seq-models-with-attention/</a>这里是 seq2seq with attention 的优秀可视化流程</p></div></div>    
</body>
</html>