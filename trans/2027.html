<html>
<head>
<title>Can Weak Labeling Replace Human-Labeled Data?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">弱标记能代替人类标记的数据吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-weak-labeling-replace-human-labeled-data-bfd06766a816#2022-05-08">https://towardsdatascience.com/can-weak-labeling-replace-human-labeled-data-bfd06766a816#2022-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="504d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">弱监管与全监管的逐步比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c569f061e3d075a15e10f3a51a5a5e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kcgdlmbz6RSfbvQqlAisCg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@homajob?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae ky" href="https://unsplash.com/s/photos/learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="529a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">近年来，由于深度学习模型的出现，自然语言处理(NLP)取得了重大进展。从智能聊天机器人到从非结构化文档中自动提取数据，使用NLP的现实应用越来越普遍，并为许多公司带来了真正的商业价值。然而，这些模型仍然需要手动标记的训练数据来微调它们以适应特定的业务用例。收集这些数据可能需要几个月的时间，标记这些数据甚至需要更长的时间，尤其是在需要领域专家并且文本中有多个类需要识别的情况下。可以想象，这可能成为许多企业的真正采用障碍，因为主题专家很难找到，而且价格昂贵。</p><p id="cc3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决这个问题，研究人员采用了弱形式的监督，例如使用启发式生成的标签函数和外部知识库来以编程方式标记数据。虽然这种方法很有希望，但与完全监督相比，它对模型性能的影响仍不清楚。</p><p id="4daa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将从职位描述中生成两个训练数据集:一个通过弱标记生成，另一个通过使用<a class="ae ky" href="https://ubiai.tools" rel="noopener ugc nofollow" target="_blank">ubai</a>手工标记生成。然后，我们将比较模型在NER任务中的表现，该任务旨在从职位描述中提取技能、经验、文凭和文凭专业。数据和笔记本都在我的<a class="ae ky" href="https://github.com/walidamamou/weak_labeling.git" rel="noopener ugc nofollow" target="_blank"> github repo </a>里。</p><h1 id="4048" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">监管不力</h1><p id="6573" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在弱监督的情况下，用户定义一组函数和规则，将有噪声的标签(即可能不正确的标签)分配给未标记的数据。标记功能可以是模式的形式，例如正则表达式、字典、本体、预先训练的机器学习模型或群体注释。</p><p id="23c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">弱监督流水线具有三个组件:(1)用户定义的标签函数和启发式函数，(2)统计模型，其将来自函数的标签作为输入，并输出概率标签，以及(3)机器学习模型，其在来自统计模型的概率训练标签上被训练。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/9aa2fcff5307e7b328b8471e9532a76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-zK6vJQv63CB9mohSXqSQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="e8b1" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Skweak</h1><p id="31a0" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本教程中，我们将使用Skweak库执行弱标记。根据库创建者[1]:</p><blockquote class="mt"><p id="7daf" class="mu mv it bd mw mx my mz na nb nc lu dk translated"><a class="ae ky" href="https://github.com/NorskRegnesentral/skweak" rel="noopener ugc nofollow" target="_blank"> Skweak是一个基于Python的软件工具包，它使用弱监督为这个问题提供了一个具体的解决方案。</a> <code class="fe nd ne nf ng b"><a class="ae ky" href="https://github.com/NorskRegnesentral/skweak" rel="noopener ugc nofollow" target="_blank">skweak</a></code> <a class="ae ky" href="https://github.com/NorskRegnesentral/skweak" rel="noopener ugc nofollow" target="_blank">是围绕一个非常简单的想法构建的:我们定义了一组<em class="nh">标注函数</em>来自动标注我们的文档，然后<em class="nh">聚集</em>它们的结果来获得我们的语料库的标注版本，而不是手工标注文本。</a></p></blockquote><p id="abc0" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">要了解更多关于skweak库的信息，请阅读原文“<a class="ae ky" href="http://arxiv.org/abs/2104.09683" rel="noopener ugc nofollow" target="_blank"> skweak:弱监管使NLP变得容易</a>”。</p><h1 id="50ee" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">标签功能</h1><p id="49ff" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">为了执行弱标注，我们将编写一组函数，对与我们想要标注的语料库相关的字典、模式、知识库和规则进行编码。在本教程中，我们将添加一些功能，这些功能将从职位描述中自动标记实体技能、经验、文凭和文凭_专业。将这些函数应用于未标记的数据后，将使用skweak库提供的统计模型将结果聚合到单个概率注记图层中。</p><p id="0e8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将创建一个skills Skills_Data.json字典，并将其添加到我们的函数lf3中来注释技能实体。该词典是从公开可用的数据集中获得的。</p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="dcf5" class="nr lw it ng b gy ns nt l nu nv"><em class="nw">#Create_Skills_Function_from_dictionary</em><br/><strong class="ng iu">import</strong> spacy<strong class="ng iu">,</strong> re<br/><strong class="ng iu">from</strong> skweak <strong class="ng iu">import</strong> heuristics, gazetteers, generative, utils<br/>tries<strong class="ng iu">=</strong>gazetteers<strong class="ng iu">.</strong>extract_json_data('data/Skills_Data.json')<br/>nlp<strong class="ng iu">=</strong>spacy<strong class="ng iu">.</strong>load('en_core_web_md' , disable<strong class="ng iu">=</strong>['ner'])<br/>gazetteer <strong class="ng iu">=</strong> gazetteers<strong class="ng iu">.</strong>GazetteerAnnotator("SKILLS", tries)<br/>lf3<strong class="ng iu">=</strong> gazetteers<strong class="ng iu">.</strong>GazetteerAnnotator("SKILLS", tries)</span></pre><p id="093f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于经验实体，我们使用正则表达式模式来获取经验的年数:</p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="b09d" class="nr lw it ng b gy ns nt l nu nv"><em class="nw">#Create_Function_Foe_Experience_Detection(Use Regex)</em><br/><strong class="ng iu">def</strong> experience_detector (doc):<br/>    expression<strong class="ng iu">=</strong>r'[0-9][+] years'<br/>    <strong class="ng iu">for</strong> match <strong class="ng iu">in</strong> re<strong class="ng iu">.</strong>finditer(expression, doc<strong class="ng iu">.</strong>text):<br/>        start, end <strong class="ng iu">=</strong> match<strong class="ng iu">.</strong>span()<br/>        span <strong class="ng iu">=</strong> doc<strong class="ng iu">.</strong>char_span(start, end)<br/>        <strong class="ng iu">if</strong>(span):<br/>            <strong class="ng iu">yield</strong> span<strong class="ng iu">.</strong>start , span<strong class="ng iu">.</strong>end ,  "EXPERIENCE"<br/>lf1 <strong class="ng iu">=</strong> heuristics<strong class="ng iu">.</strong>FunctionAnnotator("experience", experience_detector)</span></pre><p id="6bbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于实体DIPLOMA和DPLOMA_MAJOR，我们使用来自<a class="ae ky" href="https://www.kaggle.com/datasets/zusmani/pakistanintellectualcapitalcs" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>和regex:</p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="f05e" class="nr lw it ng b gy ns nt l nu nv"><strong class="ng iu">with</strong> open('Diploma_Dic.json' , 'r' , encoding<strong class="ng iu">=</strong>'UTF-8') <strong class="ng iu">as</strong> f :<br/>    DIPLOMA<strong class="ng iu">=</strong>json<strong class="ng iu">.</strong>load(f)<br/><br/>print(len(DIPLOMA))<br/><strong class="ng iu">with</strong> open ('Diploma_Major_Dic.json' ,encoding<strong class="ng iu">=</strong>'UTF-8') <strong class="ng iu">as</strong> f :<br/>    DIPLOMA_MAJOR<strong class="ng iu">=</strong>json<strong class="ng iu">.</strong>load(f)</span><span id="397f" class="nr lw it ng b gy nx nt l nu nv"><em class="nw">#Create Diploma_Function</em><br/><strong class="ng iu">def</strong> Diploma_fun(doc):<br/>    <strong class="ng iu">for</strong> key <strong class="ng iu">in</strong> DIPLOMA:<br/>                <strong class="ng iu">for</strong> match <strong class="ng iu">in</strong> re<strong class="ng iu">.</strong>finditer(key , doc<strong class="ng iu">.</strong>text , re<strong class="ng iu">.</strong>IGNORECASE):<br/>                    start, end <strong class="ng iu">=</strong> match<strong class="ng iu">.</strong>span()<br/>                    span <strong class="ng iu">=</strong> doc<strong class="ng iu">.</strong>char_span(start, end)<br/>                    <strong class="ng iu">if</strong>(span):<br/>                        <strong class="ng iu">yield</strong> (span<strong class="ng iu">.</strong>start , span<strong class="ng iu">.</strong>end ,  "DIPLOMA")<br/>    <br/>lf4 <strong class="ng iu">=</strong> heuristics<strong class="ng iu">.</strong>FunctionAnnotator("Diploma", Diploma_fun)</span><span id="2715" class="nr lw it ng b gy nx nt l nu nv"><em class="nw">#Create_Diploma_Major_Function</em><br/><strong class="ng iu">def</strong> Diploma_major_fun(doc):  <br/>    <strong class="ng iu">for</strong> key <strong class="ng iu">in</strong> DIPLOMA_MAJOR:<br/>                <strong class="ng iu">for</strong> match <strong class="ng iu">in</strong> re<strong class="ng iu">.</strong>finditer(key , doc<strong class="ng iu">.</strong>text , re<strong class="ng iu">.</strong>IGNORECASE):<br/>                    start, end <strong class="ng iu">=</strong> match<strong class="ng iu">.</strong>span()<br/>                    span <strong class="ng iu">=</strong> doc<strong class="ng iu">.</strong>char_span(start, end)<br/>                    <strong class="ng iu">if</strong>(span):<br/>                        <strong class="ng iu">yield</strong> (span<strong class="ng iu">.</strong>start , span<strong class="ng iu">.</strong>end ,  "DIPLOMA_MAJOR")<br/>    <br/>lf2 <strong class="ng iu">=</strong> heuristics<strong class="ng iu">.</strong>FunctionAnnotator("Diploma_major", Diploma_major_fun)</span><span id="b63e" class="nr lw it ng b gy nx nt l nu nv"><em class="nw">#Create_Function_For_diploma_major(Use Regex)</em><br/><strong class="ng iu">def</strong> diploma_major_detector (doc):<br/>    expression<strong class="ng iu">=</strong>re<strong class="ng iu">.</strong>compile(r"(^.*(Ph.D|MS|Master|BA|Bachelor|BS)\S*) in (\S*)")<br/>    <strong class="ng iu">for</strong> match <strong class="ng iu">in</strong> re<strong class="ng iu">.</strong>finditer(expression, doc<strong class="ng iu">.</strong>text):<br/>        start, end <strong class="ng iu">=</strong> match<strong class="ng iu">.</strong>span(3)<br/>        span <strong class="ng iu">=</strong> doc<strong class="ng iu">.</strong>char_span(start, end)<br/>        <strong class="ng iu">if</strong>(span):<br/>            <strong class="ng iu">yield</strong> span<strong class="ng iu">.</strong>start , span<strong class="ng iu">.</strong>end ,  "DIPLOMA_MAJOR"<br/><br/>lf5 <strong class="ng iu">=</strong> heuristics<strong class="ng iu">.</strong>FunctionAnnotator("Diploma_major", diploma_major_detector)</span></pre><p id="75e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将所有函数聚合在一起，并使用Skweak的统计模型来找到自动标记数据的最佳协议。</p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="9d9e" class="nr lw it ng b gy ns nt l nu nv"><em class="nw">#create_corpus_annotated_to_train_the_model</em><br/>docs<strong class="ng iu">=</strong>[]<br/><strong class="ng iu">with</strong> open('Corpus.txt' , 'r') <strong class="ng iu">as</strong> f :<br/>    data<strong class="ng iu">=</strong>f<strong class="ng iu">.</strong>readlines()<br/>    <strong class="ng iu">for</strong> text <strong class="ng iu">in</strong> data:<br/>        <strong class="ng iu">if</strong> (len(text) <strong class="ng iu">!=</strong>1):<br/>            newtext<strong class="ng iu">=</strong>str(text)<br/>            doc<strong class="ng iu">=</strong>nlp(newtext)<br/>            doc<strong class="ng iu">=</strong>lf1(lf2(lf3(lf4(lf5(doc)))))<br/>            print(doc<strong class="ng iu">.</strong>spans)<br/>            docs<strong class="ng iu">.</strong>append(doc)</span><span id="48d7" class="nr lw it ng b gy nx nt l nu nv"><strong class="ng iu">from</strong> skweak <strong class="ng iu">import</strong> aggregation<br/>model <strong class="ng iu">=</strong> aggregation<strong class="ng iu">.</strong>HMM("hmm", ["DIPLOMA", "DIPLOMA_MAJOR" , "EXPERIENCE" , "SKILLS"])<br/>docs <strong class="ng iu">=</strong> model<strong class="ng iu">.</strong>fit_and_aggregate(docs)</span></pre><p id="b2a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们终于准备好训练模型了！我们选择训练spaCy模型，因为它很容易与skweak库集成，但我们当然可以使用任何其他模型，例如变压器。github repo中提供了带注释的数据集。</p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="f18e" class="nr lw it ng b gy ns nt l nu nv"><strong class="ng iu">for</strong> doc <strong class="ng iu">in</strong> docs:<br/>    doc<strong class="ng iu">.</strong>ents <strong class="ng iu">=</strong> doc<strong class="ng iu">.</strong>spans["hmm"]<br/>utils<strong class="ng iu">.</strong>docbin_writer(docs, "train.spacy")</span><span id="002d" class="nr lw it ng b gy nx nt l nu nv"><strong class="ng iu">!</strong>python -m spacy train config.cfg --output ./output --paths.train train.spacy --paths.dev train.spacy</span></pre><p id="9209" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们已经准备好使用两个数据集来运行训练，完全手工标记和弱标记，具有相同数量的文档:</p><p id="eefa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">手工标注数据集模型性能:</strong></p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="5b1a" class="nr lw it ng b gy ns nt l nu nv"><strong class="ng iu">================================== Results ==================================</strong><br/><br/>TOK     100.00<br/>NER P   74.27 <br/>NER R   80.10 <br/>NER F   77.08 <br/>SPEED   4506  <br/><br/><strong class="ng iu"><br/>=============================== NER (per type) ===============================</strong><br/><br/>                    P       R       F<br/>DIPLOMA         85.71   66.67   75.00<br/>DIPLOMA_MAJOR   33.33   16.67   22.22<br/>EXPERIENCE      81.82   81.82   81.82<br/>SKILLS          74.05   83.03   78.29</span></pre><p id="dba4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">弱标签数据集模型性能:</strong></p><pre class="kj kk kl km gt nn ng no np aw nq bi"><span id="7ff6" class="nr lw it ng b gy ns nt l nu nv"><strong class="ng iu">================================== Results ==================================</strong><br/><br/>TOK     100.00<br/>NER P   31.78 <br/>NER R   17.80 <br/>NER F   22.82 <br/>SPEED   2711  <br/><br/><strong class="ng iu"><br/>=============================== NER (per type) ===============================</strong><br/><br/>                     P       R       F<br/>DIPLOMA          33.33   22.22   26.67<br/>DIPLOMA_MAJOR    14.29   50.00   22.22<br/>EXPERIENCE      100.00   27.27   42.86<br/>SKILLS           33.77   15.76   21.49</span></pre><p id="3312" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，人工标记数据集的模型性能明显优于弱标记数据集，有监督数据集的模型性能为0.77，弱监督数据集的模型性能为0.22。如果我们深入挖掘，会发现性能差距在实体层面依然成立(体验实体除外)。</p><p id="19ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过添加更多的标注功能，如人群标注、模型标注、规则、字典，我们当然可以预期模型性能的改善，但还不清楚性能是否会与主题专家标注的数据相匹配。第二，找出正确的自动标记功能是一个迭代和特别的过程。当处理高度技术性的数据集(如医疗记录、法律文档或科学文章)时，这个问题变得更加严重，在某些情况下，它无法正确捕获用户想要编码的领域知识。</p><h1 id="4240" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="0fda" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本教程中，我们演示了由弱标记数据和手动标记数据训练的模型性能之间的逐步比较。我们已经表明，在这个特定的用例中，弱标记数据集的模型性能明显低于完全监督方法的性能。这并不一定意味着弱标记没有用。我们可以使用弱标注对数据集进行预标注，从而引导我们的标注项目，但我们不能依赖它来执行完全无监督的标注。</p><p id="b739" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Twitter上关注我们<a class="ae ky" href="https://twitter.com/UBIAI5" rel="noopener ugc nofollow" target="_blank"> @UBIAI5 </a>或<a class="ae ky" href="https://walidamamou.medium.com/subscribe" rel="noopener">订阅这里</a>！</p><p id="880e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献:</strong></p><ol class=""><li id="6daf" class="ny nz it lb b lc ld lf lg li oa lm ob lq oc lu od oe of og bi translated"><a class="ae ky" href="https://github.com/NorskRegnesentral/skweak" rel="noopener ugc nofollow" target="_blank">https://github.com/NorskRegnesentral/skweak</a></li></ol></div></div>    
</body>
</html>