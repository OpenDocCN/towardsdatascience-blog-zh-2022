<html>
<head>
<title>A Deep-Dive into Generalized Least Squares Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究广义最小二乘估计</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-deep-dive-into-generalized-least-squares-estimation-8bf5319edd7d#2022-11-01">https://towardsdatascience.com/a-deep-dive-into-generalized-least-squares-estimation-8bf5319edd7d#2022-11-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9d94d626f8310ae1a5cd095e5b16e0ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p9co_EfHEP_D9eXpZee_Cw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/users/clker-free-vector-images-3736/" rel="noopener ugc nofollow" target="_blank"> Clker-Free-Vector-Images </a>来自<a class="ae jd" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a> ( <a class="ae jd" href="https://pixabay.com/service/license/" rel="noopener ugc nofollow" target="_blank"> Pixabay许可</a>)</p></figure><div class=""/><div class=""><h2 id="1663" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">详细介绍如何在异方差、自相关数据集上拟合稳健的GLS模型</h2></div><p id="f5f7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">广义最小二乘</strong> ( <strong class="kx jh"> GLS </strong>)估计是普通最小二乘(OLS)估计技术的推广。GLS特别适用于拟合呈现异方差(即非恒定方差)和/或自相关的数据集的线性模型。真实世界的数据集通常表现出这些特征，这使得GLS成为OLS估计的非常有用的替代方法。</p><h1 id="f54a" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">GLS估计量的动机</h1><p id="ec2b" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">当我们使用<strong class="kx jh">普通最小二乘</strong> ( <strong class="kx jh"> OLS </strong>)估计技术来拟合数据集的线性模型时，我们做出两个关键假设:</p><ol class=""><li id="6f11" class="mo mp jg kx b ky kz lb lc le mq li mr lm ms lq mt mu mv mw bi translated">回归模型的误差方差是恒定的，即误差为<strong class="kx jh">同伦方差</strong>，并且</li><li id="195c" class="mo mp jg kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">这些误差彼此之间或它们自身之间没有关联。</li></ol><p id="7922" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但在现实世界的数据集中，这些假设中的一个或两个通常都不成立。例如，考虑以下美国县级贫困模型:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/cd1550268eb4f6a7b66b789ed2101478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b-Rz1BmUNQFV-OmM.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">估算县级贫困的线性模型(图片由作者提供)</p></figure><p id="042f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于一个给定的数据集，一个统计包，如<a class="ae jd" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> statsmodels </a>可以用来估计这个模型。使用statsmodels对来自美国人口普查局的2015–2019年<a class="ae jd" href="https://www.census.gov/programs-surveys/acs/data.html" rel="noopener ugc nofollow" target="_blank">美国社区调查(ACS) </a> 5年估计数据(参见文章底部的使用条款)进行的线性模型的OLS估计产生了以下拟合模型:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/972135f97c89a0e472a743aa0331411b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-pla10vUeOWMC7ofEdZ1g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">利用OLS估算县级贫困程度(图片由作者提供)</p></figure><p id="465e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里，<em class="ni"> e_i </em>是回归的残差。</p><p id="0996" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是Statsmodels生成的模型训练摘要，其中显示了所有系数在p &lt; .001:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/20eb1b560bfab509a1ac77db25c1525f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hCBwEGUcDCmdnRxLb_jyaw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Training summary of the linear model (Image by Author)</p></figure><p id="6784" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">At face-value, this fitted model seems sound. But a plot of the residual errors <em class="ni"> e_i </em>处相对于相应的<em class="ni">预测值</em>Percent _ Households _ Below _ Level具有统计显著性，这揭示了一个严重的问题:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/573ff8627b8e704503afce4174d7b323.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*B-MH3LPpaw0wZydT.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">拟合模型的残差与响应变量的估计值的关系图。显示红线只是为了说明模型残差中方差的增加模式(图片由作者提供)</p></figure><p id="3d47" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">模型的误差(由拟合模型的残差估计)明显是异方差的。在这种情况下，误差方差作为<strong class="kx jh"> <em class="ni"> y </em> </strong> <em class="ni"> _cap </em>的函数增加。</p><p id="ae2f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这应该让我们怀疑评估软件报告的标准误差、p值和置信区间。</p><p id="6852" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是潜在的问题。</p><h2 id="2129" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">OLS估计量的问题是</h2><p id="f1c9" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在使用OLS估计量时，我们倾向于假设模型的误差是同方差和不相关的。因此，我们用于估计估计系数方差的公式也做了相同的假设。但是正如我们在上面的例子中看到的，如果误差是异方差的和/或相关的，方差公式输出的估计系数的方差值是不正确的。方差的不正确估计会导致以下度量估计的下游误差:</p><ul class=""><li id="f094" class="mo mp jg kx b ky kz lb lc le mq li mr lm ms lq nw mu mv mw bi translated">系数的不正确标准误差(标准误差是方差的平方根)。</li><li id="2313" class="mo mp jg kx b ky mx lb my le mz li na lm nb lq nw mu mv mw bi translated">系数估计值的z分数不正确(系数的z分数与标准误差成反比)。</li><li id="e450" class="mo mp jg kx b ky mx lb my le mz li na lm nb lq nw mu mv mw bi translated">系数估计值的p值不正确。错误计算的p值可能会导致某些系数被错误地报告为具有统计显著性(反之亦然)。</li><li id="416a" class="mo mp jg kx b ky mx lb my le mz li na lm nb lq nw mu mv mw bi translated">最后，系数估计的置信区间不正确。</li></ul><p id="7c8b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总的来说，推理过程产生了不正确的结果，尽管从表面上看，拟合的模型似乎完全没有问题。</p><blockquote class="nx ny nz"><p id="7efd" class="kv kw ni kx b ky kz kh la lb lc kk ld oa lf lg lh ob lj lk ll oc ln lo lp lq ij bi translated">可以看出，当模型的误差是异方差的和/或相关的时，OLS估计器虽然仍然是<a class="ae jd" rel="noopener" target="_blank" href="/the-consistent-estimator-913fab06f4f3">一致的</a>和<a class="ae jd" rel="noopener" target="_blank" href="/understanding-estimation-bias-and-the-bias-variance-tradeoff-79ba42ab79c">无偏的</a>，但不再产生模型系数的最低可能方差估计。至少理论上有可能设计另一种估计器，它将产生具有更低方差的系数估计，从而具有更高的<a class="ae jd" href="https://en.wikipedia.org/wiki/Accuracy_and_precision" rel="noopener ugc nofollow" target="_blank">精度</a>。</p><p id="b0b9" class="kv kw ni kx b ky kz kh la lb lc kk ld oa lf lg lh ob lj lk ll oc ln lo lp lq ij bi translated">简而言之，OLS估计器不再有效。</p></blockquote><h2 id="e4e1" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">补救措施</h2><p id="370d" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">处理异方差误差的一种常见方法(尽管对于相关误差来说不那么常见)是使用所谓的<strong class="kx jh"> White的异方差一致性估计量</strong>。我在我的文章“<a class="ae jd" rel="noopener" target="_blank" href="/introducing-the-whites-heteroskedasticity-consistent-estimator-821beee28516">介绍White的异方差一致性估计量</a>”中详细介绍了这个估计量。</p><p id="af2c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是White的HC估计量有一些缺点，其中主要的是它只考虑了异方差，而没有考虑误差之间的相关性。第二个问题是，在样本大小的样本中，白色HC估计器会低估系数估计中的方差，从而导致与OLS估计器相同的问题。</p><h2 id="e6b7" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">获得GLS估计量</h2><p id="d5f4" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">处理异方差和/或相关误差的更直接的方法是遵循以下两点计划:</p><ol class=""><li id="517a" class="mo mp jg kx b ky kz lb lc le mq li mr lm ms lq mt mu mv mw bi translated">使用OLS拟合数据集的线性模型。使用拟合模型的残差作为线性模型误差的代理，创建一个使用拟合模型残差观察到的异方差性和/或相关性的模型。</li><li id="6ce2" class="mo mp jg kx b ky mx lb my le mz li na lm nb lq mt mu mv mw bi translated">设计一个估计器，在其估计技术中使用这些<em class="ni">模型化的</em>方差和相关值。</li></ol><p id="8882" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种估计量对于模型误差项中的异方差性和相关性都是稳健的。这正是<strong class="kx jh">广义最小二乘(GLS) </strong>估计器采用的方法。</p><h1 id="93b8" class="lr ls jg bd lt lu lv lw lx ly lz ma mb km mc kn md kp me kq mf ks mg kt mh mi bi translated">GLS技术的发展</h1><p id="66ad" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在这一节中，我们将从基本原理出发开发GLS估计量，并了解如何使用它。</p><p id="4820" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们从下面的线性模型开始:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/4f486582a9a83d677f3cf0dac9d1c284.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*eE8xLPd3VQR6lFXx.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">线性模型(图片由作者提供)</p></figure><p id="5989" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="ni"> y </em> </strong>是响应变量。对于大小为<em class="ni"> n </em>的数据集，<strong class="kx jh"> <em class="ni"> y </em> </strong>是大小为<em class="ni">【n×1】</em>的列向量。假设模型有<em class="ni"> k个</em>回归变量，包括截距。<strong class="kx jh"> <em class="ni"> β </em> </strong>为回归系数<em class="ni">【β_ 1，β_2，…，β_ k】</em>的列向量，其中<em class="ni"> β_1 </em>为截距。<strong class="kx jh"> <em class="ni"> X </em> </strong>是回归变量的矩阵，包括矩阵第1列截距的占位符。<strong class="kx jh"> <em class="ni"> X </em> </strong>大小为<em class="ni">【n X k】</em>。</p><p id="cbe4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据集中第<em class="ni">个</em>样本为元组:<em class="ni"> (y_i，</em><strong class="kx jh"><em class="ni">x</em></strong><em class="ni">_ I)</em>其中<em class="ni"> y_i </em>为标量(纯数)<strong class="kx jh"><em class="ni">x</em></strong><em class="ni">_ I</em>为大小为<em class="ni">【1 x k】</em>的行向量。</p><p id="2194" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通常，回归模型帮助我们“解释”响应变量<strong class="kx jh"><em class="ni">【y】</em></strong>中的一些方差。模型无法解释的东西“漏”进了模型的误差项<strong class="kx jh"><em class="ni"/></strong>。就像<strong class="kx jh"><em class="ni">y</em></strong><strong class="kx jh"><em class="ni">ϵ</em></strong>是大小为<em class="ni">【n×1】</em>的列向量。</p><p id="7763" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是等式(1)的矩阵形式:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4ecded15248d5116f7627cb24f587bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/0*pWJTMTvBADjlJCUa.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">线性模型(图片由作者提供)</p></figure><p id="8b76" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以看出， 的系数向量<strong class="kx jh"> <em class="ni"> β的普通最小二乘(OLS)估计产生以下估计量:</em></strong></p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b7c6da3cd8ba8d215fbb60709c398e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*nVwIbaVMiX2rsVH8sFbJCg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">估计系数的向量，使用普通最小二乘法进行估计(图片由作者提供)</p></figure><p id="23b7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上式中，<strong class="kx jh"> <em class="ni"> X </em> </strong> <em class="ni"> ' </em>是<strong class="kx jh"> <em class="ni"> X </em> </strong>的<a class="ae jd" href="https://en.wikipedia.org/wiki/Transpose" rel="noopener ugc nofollow" target="_blank">转置</a>。矩阵转置操作实质上是沿着矩阵的主对角线翻转矩阵，即从左上延伸到右下的对角线。转置操作在概念上翻转矩阵。由于<strong class="kx jh"><em class="ni"/></strong>的大小为<em class="ni">【n X k】</em>，其转置<strong class="kx jh"> <em class="ni"> X </em> </strong> <em class="ni"> ' </em>的大小为<em class="ni">【k X n】</em>。</p><p id="69cb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们在等式(2)中看到的另一种矩阵运算是上标中的<em class="ni"> (-1) </em>，它表示<a class="ae jd" href="https://en.wikipedia.org/wiki/Invertible_matrix" rel="noopener ugc nofollow" target="_blank">矩阵的逆</a>。矩阵求逆相当于对一个数做1的运算。</p><p id="d524" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将等式(1)代入等式(2)，我们得到以下结果:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/76105c0f6c503c5d1c5d076ee01f6179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*Gz_sWnbmu4DAte1dAN3fSQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">将等式(1)代入等式(2)(图片由作者提供)</p></figure><p id="01d7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在简化了上面的结果位之后(我已经在本文的<a class="ae jd" rel="noopener" target="_blank" href="/a-deep-dive-into-the-variance-covariance-matrices-of-classical-linear-regression-models-4322b2cdc8e6">中详述了简化)，我们得到了下面的系数估计的有用公式。以下结果显示了误差项<strong class="kx jh"> <em class="ni"> ϵ </em> </strong>对OLS估计的系数值的影响:</a></p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/cc7879938599c2b250fb19597eab2a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*m7_L1Hon8AAsFYIB1ID61A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd oi"><em class="oj"/></strong><em class="oj">的OLS估计量作为</em> <strong class="bd oi"> <em class="oj"> X </em> </strong> <em class="oj">和</em> <strong class="bd oi"> <em class="oj"> ϵ </em> </strong> <em class="oj">(图片由作者提供)</em></p></figure><p id="ba80" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于<strong class="kx jh"> <em class="ni"> β </em> </strong> <em class="ni"> _cap </em>是<strong class="kx jh"> <em class="ni"> β </em> </strong>的估计值，<strong class="kx jh"><em class="ni">β</em></strong><em class="ni">_ cap</em>是一个随机变量，它有均值和方差。</p><p id="052b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以看出，<strong class="kx jh"><em class="ni"/></strong><em class="ni">_ cap</em>的均值(也叫期望值)就是总体水平的值<strong class="kx jh"> <em class="ni"> β。</em> </strong>具体来说，<strong class="kx jh"><em class="ni">β</em></strong><em class="ni">_ cap</em><a class="ae jd" rel="noopener" target="_blank" href="/understanding-conditional-variance-and-conditional-covariance-8b661067fc18">以</a> <strong class="kx jh"> <em class="ni"> X </em> </strong>为条件的期望是<strong class="kx jh"> <em class="ni"> β。</em>T41】</strong></p><p id="dbab" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ni"/><em class="ni">_ cap</em>以<strong class="kx jh"> <em class="ni"> X </em> </strong>为条件的方差用<em class="ni">Var(</em><strong class="kx jh"><em class="ni"/></strong><em class="ni">_ cap</em><strong class="kx jh"><em class="ni">| X</em></strong><em class="ni">)</em>表示。为了计算<em class="ni">Var(</em><strong class="kx jh"><em class="ni">β</em></strong><em class="ni">_ cap</em><strong class="kx jh"><em class="ni">| X</em></strong><em class="ni">)</em>)，我们采用以下公式计算(条件)方差:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/b8aca93d0a59d4739e7dbc3b3f54725f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vBNTrJVqLdNR859a8Nfz5g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">一个<strong class="bd oi">矩阵</strong>随机变量<strong class="bd oi"> Z </strong>的条件方差公式，用<strong class="bd oi"> Z </strong>表示，其均值(期望值)E( <strong class="bd oi"> Z </strong>)和退化的<strong class="bd oi"> Z </strong>的转置(图片由作者提供)</p></figure><p id="6b64" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">代入<strong class="kx jh"><em class="ni">Z</em></strong><em class="ni">=</em><strong class="kx jh"><em class="ni">β</em></strong><em class="ni">_ cap</em>，和<em class="ni">E(</em><strong class="kx jh"><em class="ni">)Z</em></strong><em class="ni">)</em>=<strong class="kx jh"><em class="ni">β</em></strong>，我们得到:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ol"><img src="../Images/5cbc6656a2c3caf61e99dfa438d04fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9CECxkIElkK20FWJNBSsg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">系数估计值的条件方差(图片由作者提供)</p></figure><p id="5ad8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上述等式的R.H.S .中，我们将等式(3)中的<strong class="kx jh"> <em class="ni"> β_cap </em> </strong>替换为<strong class="kx jh"> <em class="ni"> β + Aϵ </em> </strong>，经过大量的简化(细节在此<a class="ae jd" rel="noopener" target="_blank" href="/a-deep-dive-into-the-variance-covariance-matrices-of-classical-linear-regression-models-4322b2cdc8e6">和</a>)后，我们得到估计系数方差的以下公式:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi om"><img src="../Images/0cf7de479850e3e52cd047ab7d40356a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*tGe5rntbBk9I-3QI5QB8Tw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">线性回归模型的OLS估计系数的方差公式(图片由作者提供)</p></figure><p id="6ea5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">中间的术语(蓝色)值得注意。</p><p id="652a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回想一下<strong class="kx jh"> <em class="ni"> ϵ </em> </strong>是模型的误差项。因此，根据定义，<strong class="kx jh"><em class="ni"/></strong>是一个随机变量。<strong class="kx jh"> <em class="ni"> ϵ </em> </strong>是一个大小为<em class="ni">【n×1】</em><strong class="kx jh"><em class="ni"/></strong>的矩阵，大小为<em class="ni">【1×n】。</em>由此可见，按<a class="ae jd" href="https://en.wikipedia.org/wiki/Matrix_multiplication" rel="noopener ugc nofollow" target="_blank">矩阵乘法的规则</a>、<strong class="kx jh">、<em class="ni">、</em>、</strong>是一个大小为<em class="ni">、【n×n】的矩阵。</em> <strong class="kx jh"> <em class="ni"> ϵϵ' </em> </strong>也是一个随机变量。</p><p id="9faf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ni">e[(</em><strong class="kx jh"><em class="ni">【ϵϵ'】</em></strong><em class="ni">)<em class="ni"><strong class="kx jh"><em class="ni">| x</em></strong><em class="ni">】</em>是随机变量的期望<em class="ni">(</em><strong class="kx jh"><em class="ni">【ϵϵ'</em></strong><em class="ni">)</em>条件制约于<strong class="kx jh"><em class="ni"/></strong><em class="ni">e[(</em><strong class="kx jh"/></em></em></p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="ab gu cl on"><img src="../Images/7b0f03c4ea67bd840bc12e5deb5d102e.png" data-original-src="https://miro.medium.com/v2/format:webp/0*NNJzXlpNJxnFhXxT.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">模型误差项的条件方差-协方差矩阵(图片由作者提供)</p></figure><p id="54e3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于假设误差项的平均值为零(线性模型的中心假设)，沿主对角线的元素，即从上述矩阵的左上延伸到右下的元素，包含<em class="ni">e[(ϵ_i*ϵ_i)</em><strong class="kx jh"><em class="ni">| x</em></strong><em class="ni">]</em>，实际上是误差项 <em class="ni"> ϵ_i、</em>和所有非对角线元素<em class="ni"> E[(ϵ_i*ϵ_j)的<strong class="kx jh">条件方差</strong></em></p><p id="3475" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由此可见，<em class="ni">e[(</em><strong class="kx jh"><em class="ni"/></strong><em class="ni">)</em><strong class="kx jh"><em class="ni">| x</em></strong><em class="ni">]</em>是方差-协方差矩阵；简而言之，<strong class="kx jh">误差项的协方差矩阵</strong>。</p><p id="d5b3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在统计文献中，误差的协方差矩阵通常表示如下:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oo"><img src="../Images/8c638f85ba9b58639d507a18013c96aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-08jweGms64c8MYArHGbg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">回归误差的协方差矩阵(图片来自作者)</p></figure><p id="75d9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">σ是一个比例因子，一个常数，我们从矩阵中提取出来，使得<em class="ni"> ω_ij=ρ_ij/σ </em>。得到的“omegas”的<em class="ni">【n×n】</em>矩阵用大写希腊字母<strong class="kx jh"><em class="ni">ω</em></strong>表示。</p><p id="fec8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，</p><p id="7130" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ni">e[(</em><strong class="kx jh"><em class="ni"/></strong><em class="ni">)</em><strong class="kx jh"><em class="ni">| x</em></strong><em class="ni">]=σ</em><strong class="kx jh"><em class="ni">ω</em></strong></p><p id="f36f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"><em class="ni">ω</em></strong>的主对角线元素包含误差的(缩放)方差，而<strong class="kx jh"><em class="ni">ω</em></strong>的所有其他元素包含误差的(缩放)协方差。</p><p id="e8aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果模型的误差是同方差的(恒方差)，那么<strong class="kx jh"><em class="ni"/></strong>的所有主对角线元素都是<em class="ni"> 1 </em>，即对于所有<em class="ni"> i </em>来说<em class="ni"> ω_ii = 1 </em>。</p><p id="2cb8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果误差不相关，则<strong class="kx jh"><em class="ni">ω</em></strong>的所有非对角线元素均为0。</p><p id="3273" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，对于同分布、不相关的误差，协方差矩阵采用以下形式:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi op"><img src="../Images/e26e2a3d0eef8212c4d190fc531d079a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSiLT1lAm7M6EzeP8sy58A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">当误差为同方差且非自相关时，回归模型误差的协方差矩阵(图片由作者提供)</p></figure><p id="bba1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在等式(5)中，<strong class="kx jh"> <em class="ni"> I </em> </strong>为大小<em class="ni">【n×n】</em>的单位矩阵。将等式(5)代入等式(4)并稍微简化，我们得到这个漂亮的小结果:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/f8d0a88958cf6fa638e5c9b3ca8caca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*bf2zpbHpiMdSfMgMhy1OPw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">当模型误差为<strong class="bd oi">同方差</strong>和<strong class="bd oi">非自相关</strong>时，拟合回归系数的协方差矩阵公式(图片由作者提供)</p></figure><p id="00ba" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是，如果模型的误差是异方差的和/或相关的，误差的协方差矩阵就不再是<em class="ni">σ</em>T52】T53】IT55】了，上面的方差公式会产生不正确的结果，导致我们在文章开始时讨论的所有问题。</p><h2 id="7245" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">广义最小二乘法</h2><p id="6e61" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">解决这个问题的直接方法是<strong class="kx jh"> GLS </strong>。我们首先定义一个大小为<em class="ni">【n x n】</em>的方阵<strong class="kx jh"> <em class="ni"> C </em> </strong>和一个大小为<em class="ni">【n x n】</em>的对角矩阵<strong class="kx jh"> <em class="ni"> D </em> </strong>，使得协方差矩阵<strong class="kx jh"><em class="ni"/></strong>可以表示为<strong class="kx jh"><em class="ni">C<em class="ni">的乘积</em></em></strong></p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e9f13aecda7f8173e7e2e8451a0b99de.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*gbAhIfAU22os-SdOUO2P6A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="ebed" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在某些条件下(除了说<strong class="kx jh"><em class="ni">【C】</em></strong>是所谓的<a class="ae jd" href="https://en.wikipedia.org/wiki/Orthogonal_matrix" rel="noopener ugc nofollow" target="_blank">正交矩阵</a>，我们不会在这里深入讨论)，总是有可能找到两个这样的矩阵<strong class="kx jh"> <em class="ni"> C </em> </strong>和<strong class="kx jh"> <em class="ni"> D </em> </strong>。顺便说一下，对角矩阵是指不沿着主对角线的所有元素都为零的矩阵。下面是<strong class="kx jh"> <em class="ni"> D </em> </strong>的样子:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi os"><img src="../Images/5a053a7f0176d127b7575aa774e98ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*Qi8pM6SOD12rQPCSfSVcuQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd oi"> D </strong>矩阵(图片作者提供)</p></figure><p id="bd77" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">主对角线元素<em class="ni"> d_ii </em>可能或可能不都具有相同的值。单位矩阵<strong class="kx jh"> <em class="ni"> I </em> </strong>是所有对角元素都为1的对角矩阵的例子。</p><p id="2b44" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们定义一个矩阵<strong class="kx jh"> <em class="ni"> G </em> </strong>使得它的转置是矩阵<strong class="kx jh"> <em class="ni"> C </em> </strong>和<strong class="kx jh"> <em class="ni"> D </em> </strong>的以下乘法:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/3d0f1d951addb4f8491db83de80c451c.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*HoKj825MBXwTqk84OohKUQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">矩阵G(作者图片)</p></figure><p id="1bff" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="ni"> D </em> </strong>的指数版值得解释一下。如果<strong class="kx jh"> <em class="ni"> D </em> </strong>的对角元素是<em class="ni"> d_ii </em>，那么<strong class="kx jh"> <em class="ni"> D </em> </strong>的幂(-1/2)本质上是矩阵的“平方根”的逆，它包含对角元素<em class="ni"> 1/√d_ii </em>，如下:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ba04bd46aa3b76e7cb12c69ccf49421e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*4v1LC4M9AlrAeZqPquiY5A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">对角矩阵<strong class="bd oi"> <em class="oj"> D </em> </strong>，<strong class="bd oi"> <em class="oj"> D </em> </strong>的逆“平方根”(图片由作者提供)</p></figure><p id="d2aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们很快就会明白为什么要进行这些神秘的转变。</p><p id="ce11" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们回忆一下我们在文章开头一直提到的线性模型的等式，在等式(1)中:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/4f486582a9a83d677f3cf0dac9d1c284.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*eE8xLPd3VQR6lFXx.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">线性模型(图片由作者提供)</p></figure><p id="af14" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将等式(1)的两边左乘<strong class="kx jh"> <em class="ni"> G </em> </strong>如下:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/ddd8b38e434953b2d0205ef0569fa948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*Pl5LDV5lSnug0S9Niqa5wA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">转换后的线性模型(图片由作者提供)</p></figure><p id="ba97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们说服自己，方程(9)中的模型仍然是线性模型。<strong class="kx jh"> <em class="ni"> G </em> </strong>是大小为<em class="ni">【n×n】</em>的方阵。由于<strong class="kx jh"> <em class="ni"> y </em> </strong>是一个大小为<em class="ni">【n×1】</em><strong class="kx jh"><em class="ni">Gy</em></strong>只是大小为<em class="ni">【n×1】</em>的<strong class="kx jh"> <em class="ni"> y </em> </strong>的缩小版。同样，<strong class="kx jh"><em class="ni"/></strong>的大小为<em class="ni">【n X k】</em>，因此<em class="ni">(</em><strong class="kx jh"><em class="ni">【GX】</em></strong><em class="ni">)</em>是大小为<em class="ni">【n X k】</em>的<strong class="kx jh"><em class="ni"/></strong>的缩小版。而<em class="ni">(</em><strong class="kx jh"><em class="ni">)gϵ</em></strong><em class="ni">)</em>是尺寸<em class="ni">【n×1】</em>的ϵ<em class="ni"/>的缩小版。因此，等式(1)是<strong class="kx jh"><em class="ni"/></strong>的缩放(有些人可能会说是变换)版本对<strong class="kx jh"><em class="ni"/></strong><em class="ni">的相应缩放(变换)版本的回归。</em>原始线性模型的系数<strong class="kx jh"> <em class="ni"> β </em> </strong>将同样适用于等式(9)的缩放模型。</p><p id="2aec" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了方便起见，我们将<strong class="kx jh"> <em class="ni"> Gy </em> </strong>替换为<strong class="kx jh"> <em class="ni"> y </em> </strong> *，<strong class="kx jh"> <em class="ni"> GX </em> </strong>替换为<strong class="kx jh"><em class="ni">【x</em></strong>*和<em class="ni"/>替换为<strong class="kx jh"><em class="ni"/></strong>*:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/e10cc9a21c890ee58f163014a1700772.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*NIPUYCJH6hTrCMnVqGwnHQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">转换(缩放)的线性模型(图片由作者提供)</p></figure><p id="cca6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为等式(10)是有效的线性模型，所以适用于线性模型的所有结果对它都成立。首先，误差项<strong class="kx jh"> <em class="ni"> ϵ </em> </strong> *的方差可表述如下:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/1724667624ee672adb7f4acfe7b7d3c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3WWd5q6IL-RwvSKT0mkRGg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">缩放线性模型的误差项<strong class="bd oi"> <em class="oj"> ϵ </em> </strong> *的方差(图片由作者提供)</p></figure><p id="a595" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在等式(1)中，我们已经用右侧的<strong class="kx jh"> <em class="ni"> Gϵ </em> </strong>替换了<strong class="kx jh"> <em class="ni"> ϵ </em> </strong> *。我们将上述等式的右侧简化如下:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/bcd5ba749cc8f486e23db44b0e3f7094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lqFVT04T04R3Wc7LA_FU6Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">研究比例模型误差协方差矩阵的公式(图片由作者提供)</p></figure><p id="4dc9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在将处理等式(12)中的黄色位。为此，我们将使用等式(7)和(8)计算<strong class="kx jh"><em class="ni">ω</em></strong>和<strong class="kx jh"> <em class="ni"> G </em> </strong>，我们将在下面复制这些等式:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi or"><img src="../Images/e9f13aecda7f8173e7e2e8451a0b99de.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*gbAhIfAU22os-SdOUO2P6A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/3d0f1d951addb4f8491db83de80c451c.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*HoKj825MBXwTqk84OohKUQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">矩阵G(作者图片)</p></figure><p id="8a75" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将在等式(12)中使用这些替换，如下所示:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oz"><img src="../Images/b3cc3792fbd3df178b3f050abc803402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*96IogtOuSTvcSe_1Daad_w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="5864" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在等式(13)中，我们使用了恒等式(G')' = G，即转置的转置返回给我们原始矩阵。</p><p id="d58e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们简化等式(13)的均方根:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/53a8313e97b47ecfcee2747074a54d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VDc8jOyeGS2sQW5_PF3nBQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">术语的简化<strong class="bd oi"><em class="oj">GωG '</em></strong><em class="oj">(图片由作者提供)</em></p></figure><p id="b94b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们之前提到过<strong class="kx jh"> <em class="ni"> C </em> </strong>是一个正交矩阵。正交矩阵的一个特性是它的转置等于它的逆矩阵:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/67e668c86391a1fc74910860454d665b.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*WPpfKTovhULqXqXWk5TA4Q.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">正交矩阵的转置与其逆矩阵相同(图片由作者提供)</p></figure><p id="a7df" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这意味着<strong class="kx jh"> <em class="ni"> C </em> </strong>和<strong class="kx jh"> <em class="ni"> C </em> </strong>的乘积与<strong class="kx jh"> <em class="ni"> C </em> </strong>及其逆的乘积相同。<strong class="kx jh"> <em class="ni"> C </em> </strong>与其逆的乘积就是单位矩阵<strong class="kx jh"> <em class="ni"> I </em> </strong>。这个结果就是<em class="ni"> N </em>乘以<em class="ni"> (1/N) </em>等于<em class="ni"> 1 </em>的矩阵等效值。</p><p id="b4be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这暗示着<strong class="kx jh"><em class="ni">C</em></strong>’<strong class="kx jh"><em class="ni">C</em></strong>=<strong class="kx jh"><em class="ni">I</em></strong>。让我们继续简化<strong class="kx jh"><em class="ni">GωG’</em></strong>:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pa"><img src="../Images/6dc1a3f160c145cca601495fcec1da6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHRoLzwnfVD1ZPNwqptSlQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">术语<strong class="bd oi"><em class="oj">GωG’</em></strong><em class="oj">(图片由作者提供)</em></p></figure><p id="1d12" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了进一步简化方程(14)的R.H.S .，我们必须回忆对角矩阵<strong class="kx jh"><em class="ni">【D】</em></strong>，<strong class="kx jh"> <em class="ni"> D </em> </strong>的幂的性质:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ba04bd46aa3b76e7cb12c69ccf49421e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*4v1LC4M9AlrAeZqPquiY5A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">对角矩阵<strong class="bd oi"> <em class="oj"> D </em> </strong>，<strong class="bd oi"> <em class="oj"> D </em> </strong>的逆“平方根”(图片由作者提供)</p></figure><p id="69da" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此外，对角矩阵的转置是相同的矩阵，因为转置操作简单地围绕主对角线翻转矩阵，并且在对角矩阵中，所有非对角元素都是0。</p><p id="0b97" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">理解了这个设置后，可以看出下面的乘积等同于一个大小为<em class="ni">【n×n】:</em>的单位矩阵</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/226f34e37d77a7e7b84e6657e582b2b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*Ffad7tLPcGIHfM6Tz4N0Gw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">(图片由作者提供)</p></figure><p id="f809" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将这个结果代入等式(14)，我们得到:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi pd"><img src="../Images/6ffdae2aea6fbb04b5f70b16aa48aec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qbxq3j2SI-oBoQukt6zDDg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd oi">GωG '</strong><em class="oj">解析为</em>【n×n】<em class="oj">单位矩阵(图片由作者提供)</em></p></figure><p id="2139" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将等式(15)代入等式(12)，然后代入等式(11)，我们得到缩放回归模型<strong class="kx jh"><em class="ni">y</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">x</em></strong><em class="ni">*</em><strong class="kx jh"><em class="ni">β</em></strong><em class="ni">+</em><strong class="kx jh"><em class="ni">【ϵ</em></strong><em class="ni">*</em>其中<strong class="kx jh"> <em class="ni"> y </em><strong class="kx jh"><em class="ni">x</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">GX</em></strong>和<strong class="kx jh"><em class="ni">ϵ</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">gϵ. </em> </strong>我们把这个结果总结如下:</strong></p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/51031dbd751744bd819f533a431296b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*pE_nY2eLWydDAyG7RNJCDg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">缩放线性模型的误差协方差矩阵<strong class="bd oi"><em class="oj">y</em></strong><em class="oj">* =</em><strong class="bd oi"><em class="oj">x</em></strong><em class="oj">*</em><strong class="bd oi"><em class="oj">β</em></strong><em class="oj">+</em><strong class="bd oi"><em class="oj">ϵ</em></strong><em class="oj">*(图片由作者提供)</em></p></figure><p id="a025" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">方程式(16)是GLS技术发展中的一个重要结果。它陈述了比例线性模型的误差是同伦的(即，恒定方差)和不相关的。因此，该线性模型<em class="ni">的<strong class="kx jh"> <em class="ni"> β </em> </strong>的最小二乘估计器必然是有效的，即具有最低可能的方差(除了一致和无偏之外)。</em></p><p id="8d5a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这使我们得出一个重要的结果:</p><blockquote class="nx ny nz"><p id="bc7a" class="kv kw ni kx b ky kz kh la lb lc kk ld oa lf lg lh ob lj lk ll oc ln lo lp lq ij bi translated">即使数据表现出异方差性和/或自相关性，我们开发的缩放(转换)线性回归模型也可以使用高效、一致和无偏的最小二乘估计器进行拟合，换句话说，它将是该模型的<strong class="kx jh">B</strong>est<strong class="kx jh">L</strong>linear<strong class="kx jh">U</strong>n biased<strong class="kx jh">E</strong>估计器。</p></blockquote><p id="c2fe" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们如何为缩尺模型开发这样一个最小二乘估计器？我们的做法如下:</p><p id="3402" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回忆等式(2)，等式(2)说明线性模型<strong class="kx jh"><em class="ni">y</em></strong><em class="ni">=</em><strong class="kx jh"><em class="ni">xβ</em></strong><em class="ni">+</em><strong class="kx jh"><em class="ni">ϵ</em></strong>的最小二乘估计量由以下公式给出:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b7c6da3cd8ba8d215fbb60709c398e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*nVwIbaVMiX2rsVH8sFbJCg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">估计系数的向量，使用普通最小二乘法进行估计(图片由作者提供)</p></figure><p id="e64a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在等式(2)中，如果我们将<strong class="kx jh"> <em class="ni"> y </em> </strong>替换为<strong class="kx jh"> <em class="ni"> y </em> </strong> <em class="ni"> * </em>以及将<strong class="kx jh"> <em class="ni"> X </em> </strong>替换为<strong class="kx jh"> <em class="ni"> X </em> </strong> *，我们得到缩放线性模型的以下估计量:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/806b166810e487219fece7b223ebf88b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*KNlS9sAixhdqKfyjdvr4EA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd oi">β</strong>T20【GLS估计量】(图片由作者提供)</p></figure><p id="6385" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了简化Eq (17)，我们用<strong class="kx jh"><em class="ni">y</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">gy</em></strong><em class="ni">，</em><strong class="kx jh"><em class="ni">x</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">GX</em></strong>和<strong class="kx jh"><em class="ni">ϵ</em></strong><em class="ni">* =</em><strong class="kx jh"><em class="ni">gϵ.</em> </strong>我们还利用了<em class="ni">(</em><strong class="kx jh"><em class="ni">【GX】</em></strong><em class="ni">)’=</em><strong class="kx jh"><em class="ni">X</em></strong><em class="ni">’</em><strong class="kx jh"><em class="ni">G</em></strong><em class="ni">’。</em>我们还利用了<strong class="kx jh"><em class="ni">ω</em></strong>矩阵的逆是<strong class="kx jh"> <em class="ni"> G'G </em> </strong>的结果。后一个结果由等式(7)和(8)得出。这些替换如下所示:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/dd0999e91096072d634aba035d7d5c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*wEa3ZpZjl10dEHjYzJtt-A.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">GLS估计量为<strong class="bd oi"><em class="oj"/></strong><em class="oj">(图片由作者提供)</em></p></figure><p id="f134" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">等式(18)是GLS估计量(也称为艾特肯广义最小二乘估计量)。无论数据集是否表现出异方差性和/或自相关性，它都是一个有效的、一致的、无偏的估计量。换句话说，保证是系数向量<strong class="kx jh"><em class="ni"/></strong>β的<strong class="kx jh">B</strong>est<strong class="kx jh">L</strong>linear<strong class="kx jh">U</strong>n biased<strong class="kx jh">E</strong>estimator。</p><p id="855a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">只有一个问题。</p><p id="4e74" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它依赖于我们知道误差的协方差矩阵<strong class="kx jh"><em class="ni">ω</em></strong>。但是<strong class="kx jh"><em class="ni">ω</em></strong>本质上是不可观测的，因为它包含了实验者无法直接观测到的模型误差项的协方差。</p><p id="7ca5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">解决方法是建立一个<strong class="kx jh"><em class="ni">ω</em></strong>的模型，并进行估算。然后使用GLS估计器<strong class="kx jh"> <em class="ni">使用该估计来估计<strong class="kx jh"> <em class="ni"> β </em> </strong>。</em> </strong>这种使用<strong class="kx jh"><em class="ni">ω</em></strong>的估计版本的策略有时被称为<strong class="kx jh">可行广义最小二乘</strong> ( <strong class="kx jh"> FGLS </strong>)技术。</p><p id="5901" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">估算<strong class="kx jh"><em class="ni">ω有几种策略。</em> </strong>其中一个这样的手法型号<strong class="kx jh"><em class="ni">ω</em></strong>为:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ph"><img src="../Images/23f630c06633e5afa13f774eb08adbcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fvYDT-yEEfYUKPFoLPLQJw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">一模一样的<strong class="bd oi"><em class="oj">ω</em></strong><em class="oj">(图片由作者提供)</em></p></figure><p id="6647" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面的模型中，<em class="ni"> ω_ii </em>是数据集中第<em class="ni">与第</em>行对应的第<em class="ni">与第</em>误差<em class="ni"> ϵ_i </em>的方差。我们估计<em class="ni"> n </em>方差<em class="ni">ωII</em>，方法是回归拟合数据集的OLS模型中<strong class="kx jh">yy</strong>预测值的残差(我们将在下周的本文第二部分中看到如何做)。</p><p id="b50d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ni"> ρ </em>是第<em class="ni">个</em>和第<em class="ni"> (i+1)个</em>误差项之间的相关性，即<em class="ni"> ϵ_i </em>和<em class="ni">ϵ_(i+1</em>。我们通过拟合数据集的OLS模型残差的自相关图来估计<em class="ni"> ρ </em>。</p><p id="bde7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上述矩阵中，我们假设误差项之间的相关性按照幂律衰减，即<em class="ni"/>、<em class="ni"> ρ </em>、…等。随着相应数据集行之间的间隔增加。</p><p id="66ec" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文的第二部分(将于下周发表)，我们将通过一个教程来学习如何使用广义最小二乘估计量来拟合ACS数据集的线性模型，以估计美国的县级贫困率。</p><p id="2d75" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">敬请期待！</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><h1 id="5113" class="lr ls jg bd lt lu pp lw lx ly pq ma mb km pr kn md kp ps kq mf ks pt kt mh mi bi translated">参考文献、引文和版权</h1><h2 id="0351" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">数据集</h2><p id="4021" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">本文使用的<a class="ae jd" href="https://www.census.gov/programs-surveys/acs/data.html" rel="noopener ugc nofollow" target="_blank">美国社区调查数据集</a>可以从这里<a class="ae jd" href="https://gist.github.com/sachinsdate/0b8ebc2b26afb67a1e83e752c69e1a25" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">下载</strong> </a>。使用公开可用的<a class="ae jd" href="https://www.census.gov/data/developers.html" rel="noopener ugc nofollow" target="_blank">API</a>(参见<a class="ae jd" href="https://www.census.gov/data/developers/about/terms-of-service.html" rel="noopener ugc nofollow" target="_blank">服务条款</a>和<a class="ae jd" href="https://ask.census.gov/prweb/PRServletCustom?pyActivity=pyMobileSnapStart&amp;ArticleID=KCP-4928" rel="noopener ugc nofollow" target="_blank">此链接</a>)可以从美国人口普查局的网站获取完整的ACS数据集，或者直接从人口普查局的<a class="ae jd" href="https://experience.arcgis.com/experience/13a111e06ad242fba0fb62f25199c7dd/page/Page-1/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">社区资源管理器</strong> </a>网站获取。</p><h2 id="12d0" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">纸</h2><p id="1b2f" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">艾特肯(1936)。四。—关于最小二乘法和观测值的线性组合。<em class="ni">爱丁堡皇家学会会议录，</em> <em class="ni"> 55 </em>，42–48。土井:10.1017037686687</p><h2 id="7785" class="nk ls jg bd lt nl nm dn lx nn no dp mb le np nq md li nr ns mf lm nt nu mh nv bi translated">形象</h2><p id="ffda" class="pw-post-body-paragraph kv kw jg kx b ky mj kh la lb mk kk ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">本文中所有图片的版权归<a class="ae jd" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY-NC-SA </a>所有，除非图片下面提到了不同的来源和版权。</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><p id="7f90" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ni">如果你喜欢这篇文章，请关注我的</em><a class="ae jd" href="https://timeseriesreasoning.medium.com" rel="noopener"><strong class="kx jh"><em class="ni">Sachin Date</em></strong></a><em class="ni">获取关于回归、时间序列分析和预测主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>