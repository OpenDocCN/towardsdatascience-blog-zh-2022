<html>
<head>
<title>What are Model Agnostic Methods?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是模型不可知的方法？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-are-model-agnostic-methods-387b0e8441ef#2022-04-05">https://towardsdatascience.com/what-are-model-agnostic-methods-387b0e8441ef#2022-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="def9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">所有强大的方法都可以用于任何模型</h2></div><p id="cb51" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不可知论者思考上帝的存在。谢天谢地，机器学习还没有完全实现。当我们谈到不可知论方法时，我们指的是可以用于任何模型的方法。我们将详细阐述这个定义，重点是可解释性的不可知论方法。我们将讨论这些可解释性方法的不同分类。这是全球与地方的解释和置换与替代模型。一些方法不是模型不可知的。我们将通过讨论这些来结束。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/01c5c2b08c7c65876e5363e6db6b05ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GYZGSFcMydEGlnwSBTOb5A.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">来源:<a class="ae lu" href="https://www.flaticon.com/free-icon/research_1284102" rel="noopener ugc nofollow" target="_blank"> flaticon </a></p></figure><h1 id="c675" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型不可知的方法</h1><p id="12d7" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">模型不可知的方法可以应用于任何模型。当使用模型不可知的方法时，在模型被训练之后，它可以被视为一个黑盒。换句话说，该方法不要求我们研究模型的内部工作。如果我们想在不同的模型上使用该方法，我们只需将它们交换出来。但是方法做什么呢？</p><p id="ec67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，大多数<strong class="kk iu"> <em class="ms">评估</em> </strong>度量是模型不可知的。以图1中的精度计算为例。我们首先使用模型对测试集进行预测。那么准确度就是预测正确的实际值的百分比。为了进行这种计算，我们只需将试验数据与预测值进行比较。有些模型可能比其他模型更精确，但计算结果是一样的。其他评估指标，如精确度、召回率和均方误差，都是与模型无关的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/aeb0e3d444edbbcc478c8edba2f9ffa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DfHm3DsCLdPEIoFDlRLI3A.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图1:精确度计算概述(来源:作者)</p></figure><p id="9819" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在选择模型时，模型不可知的评估方法提供了灵活性。您不必为每个模型类型开发不同的评估框架。这也允许您使用相同的指标来比较许多模型。当您想要比较模型性能时，这种一致性是非常重要的。</p><h1 id="0b67" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">可解释的机器学习</h1><p id="7780" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在实践中，将<strong class="kk iu"> <em class="ms">评估</em> </strong>度量称为模型不可知的并不常见。当我们谈论<strong class="kk iu"> <em class="ms">可解释的ML </em> </strong>或<strong class="kk iu"> <em class="ms">可解释的AI </em> </strong>方法时，这个术语最为突出。这些用于理解模型如何做出预测。我们将讨论这些方法的几个例子，以及如何对它们进行分类/分组。最后，我们将讨论一些方法在理论上是不可知论的，但在实践中并不总是如此。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mu"><img src="../Images/0a0139f9184fe3eedd2c1118053e3001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ixgagIx9zcNe3AqMUgjebA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated"><em class="mv">可解释ML </em>方法分类概述</p></figure><h2 id="2990" class="mw lw it bd lx mx my dn mb mz na dp mf kr nb nc mh kv nd ne mj kz nf ng ml nh bi translated">全局方法与局部方法</h2><p id="ade0" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们对模型不可知方法进行分类的第一种方式是根据它们试图解释的内容。<strong class="kk iu"> <em class="ms">局部</em> </strong>解读旨在理解个体预测是如何做出的。这就是每个模型特征改变预测的方式。我们可以使用<strong class="kk iu"> <em class="ms">全局</em> </strong>解释来解释模型如何从整体上做出预测。这意味着我们只能对所有预测的趋势做出断言。</p><p id="7783" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更好地理解这一点，我们在图2中举了一个部分依赖图(PDP)的例子。这是一种常见的<strong class="kk iu"> <em class="ms">全局</em> </strong>可解释性方法。该图是为用于预测二手车价格的模型而创建的。在x轴上，我们有对汽车进行的<strong class="kk iu"> <em class="ms">修理</em> </strong>的次数。y轴(部分yhat)给出平均预测价格。由此可见，汽车价格往往与维修次数成非线性关系。然而，我们不能对每辆车说同样的话。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ni"><img src="../Images/f25beea41996971dba213c2ec3bfd77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkq5v2FfLbNQnYqK6LJlTQ.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图2:PDP的示例</p></figure><p id="600f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们不会详细介绍我们是如何创建这个PDP的。如果你感兴趣，下面的文章会很有用。它带你一步一步地了解情节是如何创建的。我们还讨论了其他全局模型不可知的方法。那就是互信息和特征重要性。</p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/finding-and-visualising-non-linear-relationships-4ecd63a43e7e"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">发现并可视化非线性关系</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">用部分相关图(PDP)、互信息和特征重要性分析非线性关系</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa lo nm"/></div></div></a></div><p id="f29f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于<strong class="kk iu"> <em class="ms">局部</em> </strong>的诠释，SHAP是一种常见的方法。在图3中，您可以看到单个预测的SHAP瀑布图。这是一个用来预测鲍鱼壳年轮数量的模型。这里我们将模型的预测值f(x)与平均预测值E[f(x)]进行比较。我们可以看到每个特征是如何影响预测的。例如，<strong class="kk iu"> <em class="ms">剥壳重量</em> </strong>的值使预测的环数增加了1.81。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ob"><img src="../Images/947579dc4be69e258af4cf759847d309.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pjv1tf23gv7TJj5BPusPCQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图3:SHAP瀑布图的例子</p></figure><p id="efb3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以我们可以看到SHAP是如何被用来解释个人预测的。我们还可以聚合SHAP值，以了解模型如何从整体上进行预测。从这个意义上说，地方和全球解释之间的界限可能会模糊。你可以在图4的蜂群图中看到这样的例子。在这里，我们绘制了模型所做的所有预测的SHAP值。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oc"><img src="../Images/ff885edad5c6c5fef7df0e22ae29044d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dvCW_sm0y4bTV9YtF5MfIA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图4:使用蜂群图来聚集SHAP值</p></figure><p id="3c1a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">蜂群图只是我们聚集SHAP值的方法之一。下面的<strong class="kk iu">视频</strong>讨论了一些其他有用的聚合。我们将深入探讨如何解读这些图表。如果你想要更多，那就来看看我的<a class="ae lu" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu"> SHAP课程</strong> </a> <strong class="kk iu">。</strong>注册我的<a class="ae lu" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank"> <strong class="kk iu">简讯</strong> </a>:)即可免费获取</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="od oe l"/></div></figure><h2 id="c1ad" class="mw lw it bd lx mx my dn mb mz na dp mf kr nb nc mh kv nd ne mj kz nf ng ml nh bi translated">置换与替代模型</h2><p id="e6e9" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们对解释方法进行分类的第二种方式是根据它们是如何计算的。<strong class="kk iu"> <em class="ms">置换</em> </strong>方法涉及改变输入数据和测量模型预测的变化。这就是上面的PDP是如何创建的。对于每辆车，我们更改/置换了<strong class="kk iu"> <em class="ms">维修</em> </strong>特征值，并记录了模型预测。然后我们取每个<strong class="kk iu"> <em class="ms">修理</em> </strong>值的平均预测值。冰图、特征重要性和SHAP等其他方法都是排列方法。</p><p id="6311" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一种方法使用<strong class="kk iu"> <em class="ms">代理模型</em> </strong>，您可以在图5中看到一个概述。在这里，模型首先被训练并用于进行预测。然后使用原始模型的预测来训练代理模型。也就是代替目标变量。重要的是，代理模型是一个内在可解释的模型。这些模型，如线性回归或决策树，不需要像SHAP/PDP这样的技术。它们可以通过直接查看模型的结构或参数来解释。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/059993d7970c619d0d99fae66493cb40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gTH1tcBLuw00p83qBBm7Fw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图5:代理模型方法概述</p></figure><p id="c0a4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，我们可以通过直接解释替代模型来理解原始模型的预测。如果我们对所有预测都这样做，它被称为<strong class="kk iu"> <em class="ms">全局代理模型</em> </strong>。与其他全局方法一样，这些方法可以帮助我们从整体上理解原始模型。其他方法，比如LIME，可以用来创建<strong class="kk iu"> <em class="ms">局部代理模型</em> </strong>。这些组合排列和代理模型来训练模型对个人的预测。</p><h2 id="3145" class="mw lw it bd lx mx my dn mb mz na dp mf kr nb nc mh kv nd ne mj kz nf ng ml nh bi translated">原则与实践中的模型不可知</h2><p id="f452" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们讨论的所有方法在理论上都是模型不可知的。为了实际使用它们，我们需要实现它们。一个实现不一定支持所有的建模包。例如，Friedman的h-statistic是一种用于突出模型中重要交互的方法。在Python中，该方法没有与模型无关的实现。据我所知，scikit-learn梯度增强模型只有一个<a class="ae lu" href="https://pypi.org/project/sklearn-gbmi/" rel="noopener ugc nofollow" target="_blank">实现</a>。</p><p id="a13e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当谈到SHAP时，另一个考虑是有不同的方法来近似这些值。KernelSHAP是一个真正的模型不可知的方法。但是，它明显比TreeSHAP慢。缺点是TreeSHAP只能和基于树的算法一起使用。这意味着如果你想节省时间，你需要限制自己使用这些算法。</p><p id="b23b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了SHAP，也有可能扩展这种方法。也就是说，一个特征的贡献可以分解为它的主要和交互作用。这使我们能够分析数据中的相互作用。但是，这种实现只适用于基于树的算法。这是因为我们上面提到的计算成本。估计主效应和交互效应需要的时间太长了。</p><h1 id="8fbd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">非不可知方法</h1><p id="2b5a" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">不可知论方法的好处意味着它们是常见的。还有一些方法只能用于特定的模型。首先，我们在上面提到了固有的可解释模型。这些都可以直接解读。然而，它们的精确解释方式将取决于您使用的模型。</p><p id="660a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这方面的一个例子可以在下面的文章中找到。在这里，我们建立了一个模型来预测推文的情绪。这是使用单词袋方法和支持向量机(SVM)完成的。通过训练SVM的过程，训练集中的每个N元语法被赋予一个权重。我们通过查看这些权重来解释SVM，从而结束本文。</p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/introduction-to-sentiment-analysis-f623f7d40bfa"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">情感分析简介</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">用Python创建您的第一个情感分析模型</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nv l"><div class="of l nx ny nz nv oa lo nm"/></div></div></a></div><p id="31b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以在图6中看到这些权重的一些示例。具有正权重的n-gram与积极情绪相关联。换句话说，如果一条推文包含这些词中的一个，我们更有可能预测到积极的情绪。同样，那些负权重的人与消极情绪有关。也有单词没有关联情感的情况。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi og"><img src="../Images/dbc1deed6441b1caabecdf7ac5ab579b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ipwr7rw1mJ5QWBXvtH4PkQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图6:情绪分析模型的SVM参数权重</p></figure><p id="2d0c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以这种方式解释SVM是一种非不可知论的方法。我们将无法解释像决策树或随机森林这样的模型。这是因为它们没有参数权重。同样，它也不适用于神经网络。这些模型可能有参数权重，但它们太复杂，无法以这种方式可视化。</p><p id="4f58" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">非不可知论的方法也已经被开发用于不可内在解释的模型。由于深度学习的成功，这对于神经网络来说是最常见的。一些方法包括逐像素分解和<a class="ae lu" href="https://github.com/kundajelab/deeplift" rel="noopener ugc nofollow" target="_blank">深度提升</a>。最终，这些方法只能用于神经网络。在某些情况下，它们只能用于特定的神经网络架构。</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="fada" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我希望这篇文章对你有帮助！你可以成为我的<a class="ae lu" href="https://conorosullyds.medium.com/membership" rel="noopener"> <strong class="kk iu">推荐会员</strong> </a> <strong class="kk iu">来支持我。你可以访问Medium上的所有文章，我可以得到你的部分费用。</strong></p><div class="nj nk gp gr nl nm"><a href="https://conorosullyds.medium.com/membership" rel="noopener follow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">通过我的推荐链接加入Medium康纳·奥沙利文</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">conorosullyds.medium.com</p></div></div><div class="nv l"><div class="oo l nx ny nz nv oa lo nm"/></div></div></a></div><p id="7356" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在|<a class="ae lu" href="https://twitter.com/conorosullyDS" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae lu" href="https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae lu" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank">时事通讯</a>上找到我——注册免费参加<a class="ae lu" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> Python SHAP课程</a></p><h2 id="1378" class="mw lw it bd lx mx my dn mb mz na dp mf kr nb nc mh kv nd ne mj kz nf ng ml nh bi translated">图像来源</h2><p id="861d" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">所有图片都是我自己的或从<a class="ae lu" href="http://www.flaticon.com/" rel="noopener ugc nofollow" target="_blank">www.flaticon.com</a>获得。在后者的情况下，我拥有他们的<a class="ae lu" href="https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-" rel="noopener ugc nofollow" target="_blank">保费计划</a>中定义的“完全许可”。</p><h2 id="b905" class="mw lw it bd lx mx my dn mb mz na dp mf kr nb nc mh kv nd ne mj kz nf ng ml nh bi translated">参考</h2><p id="64b7" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">M.T. Ribeiro，S. Singh和C. Guestrin，<em class="ms">机器学习的模型不可知可解释性【https://arxiv.org/abs/1606.05386</em>(2016)<a class="ae lu" href="https://arxiv.org/abs/1606.05386" rel="noopener ugc nofollow" target="_blank"/></p><p id="4839" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">C.Molnar，<em class="ms">可解释机器学习</em>(2021)<a class="ae lu" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">https://christophm . github . io/Interpretable-ml-book/shap . html</a></p><p id="04d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="op oq ep" href="https://medium.com/u/fb96be98b7b9?source=post_page-----387b0e8441ef--------------------------------" rel="noopener" target="_blank">亨尼·德·哈德</a> <em class="ms">解释任何机器学习模型的模型不可知方法</em>(2020)<em class="ms"/><a class="ae lu" rel="noopener" target="_blank" href="/model-agnostic-methods-for-interpreting-any-machine-learning-model-4f10787ef504">https://towardsdatascience . com/Model-Agnostic-Methods-for-Interpreting-any-Machine-Learning-Model-4f 10787 ef 504</a></p></div></div>    
</body>
</html>