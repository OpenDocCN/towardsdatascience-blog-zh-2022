<html>
<head>
<title>Cost-efficient &amp; Scalable YOLOv5 Model Inference In Production</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生产中经济高效且可扩展的YOLOv5模型推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cost-efficient-scalabel-yolov5-model-inference-in-production-ebe814d44f75#2022-08-04">https://towardsdatascience.com/cost-efficient-scalabel-yolov5-model-inference-in-production-ebe814d44f75#2022-08-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c43e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">不仅仅是AWS Lambda</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ba07e7260e7ea69e883211bc4e5bb20e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JtBD-orYmOy3Hgon"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克拉克·蒂布斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b707" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">推理成本可能占计算成本的很大一部分，为了解决这一问题并降低高昂的推理成本，AWS已经为各种场景提供了几种模型推理解决方案:</p><ul class=""><li id="dac5" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html" rel="noopener ugc nofollow" target="_blank">实时推断</a></li><li id="f23f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html" rel="noopener ugc nofollow" target="_blank">批量转换</a></li><li id="27eb" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html" rel="noopener ugc nofollow" target="_blank">异步推理</a></li><li id="8b8d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html" rel="noopener ugc nofollow" target="_blank">无服务器推断</a></li></ul><p id="eb7d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，如果您正在寻找一个更加灵活、可定制、成本更低的无服务器解决方案，该怎么办呢？最重要的是，如果您的组织正在处理多云基础架构，它可能会被“提升并转移”到其他云平台。或者担心解决方案被某个特定提供商锁定？</p><p id="02dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欢迎来到BGL关于如何实现AWS Lambda作为模型推理服务来处理生产中大量推理请求的故事。</p><h2 id="ca79" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lf mp mq mr lj ms mt mu ln mv mw mx my bi translated"><strong class="ak"> <em class="mz">上下文</em> </strong></h2><p id="9ee5" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">我们的工程团队正在构建一个人工智能产品，以自动化几个业务流程。<a class="ae kv" href="https://huggingface.co/docs/transformers/index" rel="noopener ugc nofollow" target="_blank">拥抱人脸转换器</a>(用于NLP任务)和<a class="ae kv" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">约洛夫5 </a>(用于对象检测任务)框架都被集成，并且已经基于商业案例和数据集训练了几个模型。推理API与现有的业务工作流相集成，以实现流程的自动化，因此组织可以将资源从繁琐和低价值的工作中抽离出来，并降低运营成本。</p><p id="e1db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前的系统每天处理1000多个推理请求，在不久的将来，数量将增长50倍。一旦候选模型被部署到生产环境并稳定下来，主要的成本就在模型推理上了。</p><h2 id="2060" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lf mp mq mr lj ms mt mu ln mv mw mx my bi translated"><strong class="ak"> <em class="mz">方案设计</em> </strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/a66a6ed930aa11ed2c3396cdc82a7f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*IJp877jn76ci5dt9PBn-4g.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3bf4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该解决方案利用几个AWS服务来实现以下目的(在该解决方案的上下文中):</p><ul class=""><li id="b110" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">Sagemaker:培训定制模型</li><li id="dd14" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">EFS:存储已训练模型的工件，作为主要的模型加载源</li><li id="bb16" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">S3:存储已训练模型的工件，作为第二个模型加载源</li><li id="114f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">ECR:托管Lambda docker映像</li><li id="7ab7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">EventBridge:调用Lambda的“调度程序”</li><li id="e0ee" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">系统管理器:在参数存储中存储模型路径</li></ul><p id="ca48" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ng">训练</em> </strong></p><ol class=""><li id="fbb2" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr nh ly lz ma bi translated">Sagemaker通常会将模型工件压缩并输出到S3。此外，在这种情况下，通过添加额外的Sagemaker通道名称，还将一个副本保存到EFS(在3.2中解释)。</li></ol><p id="b361" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"><em class="ng">λ部署</em> </strong></p><p id="1f9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.1 <a class="ae kv" href="https://www.serverless.com/" rel="noopener ugc nofollow" target="_blank">无服务器框架</a>用于管理Lambda配置，通过Jenkins和docker将所有必需的包和Lambda脚本构建到Docker映像中，并进一步推送到ECR。</p><p id="b677" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:模型人工制品并没有嵌入到这幅图像中，它们留在了S3和EFS。</p><p id="9fde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一个用于构建Lambda映像的docker文件示例:</p><ul class=""><li id="2ca8" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">来自AWS(public.ecr.aws/lambda/python:3.8.2021.11.04.16)的公共lambda基本图像</li><li id="a18f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">复制用awslambda.py编写的Lambda逻辑</li><li id="3713" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">复制YOLOv5项目(最初克隆自<a class="ae kv" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLOv5 </a>)作为在Lambda中本地加载YOLOv5训练模型将需要它</li><li id="163a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">所有需要的包都在一个单独的文件中定义，这个文件叫做lambda-requirements.txt，在同一个目录下</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/e97dce53f6ed903fe83d19ce10248e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fep_Mnut6sRiB-ZgDFcfKg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4686" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.2每个Lambda都配置了一个关联的EventBridge规则(在无服务器YAML文件中)。EventBridge每5分钟调用一次Lambda，有两个重要目的:</p><ul class=""><li id="145b" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">保持Lambda温暖以避免冷启动而不触发实际的推理请求</li><li id="5a46" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在第一个预热请求中预加载期望的模型，然后缓存它(通过全局变量)，这将显著减少由后续实际推理请求的模型加载所导致的推理提前期</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/35d526852517dfacfa5c89192e592666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rtdqP1lfxvO2LOAT-PM8kQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="db8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的代码片段显示了无服务器YAML文件中使用的Lambda配置的结构。详情请参考<a class="ae kv" href="https://medium.com/@grdustin/cost-efficient-yolov5-model-inference-in-production-ebe814d44f75" rel="noopener">无服务器框架文档</a>，要点如下:</p><ul class=""><li id="f10f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">ephemeralStorageSize 5120会将Lambda的“/tmp”文件夹的大小配置为5120MB(在3.2中解释)</li><li id="f02c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">模型桶和路径作为EventBridge调用的输入参数(在3.1中解释)</li></ul><p id="e6f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ng">推论</em> </strong></p><p id="17da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图解释了Lambda处理逻辑，背后的原理是检查调用是否被触发:</p><ul class=""><li id="26b0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">通过lambda warming请求(通过EventBridge) -&gt;加载模式(第一次)&amp; cache--&gt;不处理推理返回，<strong class="ky ir">或</strong></li><li id="f5a1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">由实际推理请求-&gt;过程推理-&gt;返回推理结果</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/9fc36bb3d366275bec356a7eddd1ac37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oEksghd3i7rIYSh_LMqsGg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5000" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.1 S3桶和相应的模型路径保存在系统管理器参数存储中，因此这与Lambda部署是分离的。工程师可以通过更改参数将Lambda指向任何所需的模型，而无需重新部署该Lambda。</p><p id="90e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.2 EFS是一个文件系统，所以直接从EFS挂载和加载模型要快得多(请密切关注EFS的带宽成本)。如果EFS加载失败(路径无效、带宽受限等)，Lambda会将模型工件从S3下载到本地的'/tmp '目录，并从那里加载模型。确保Lambda有足够的存储空间用于“/tmp”(在我们的例子中，ephemeralStorageSize参数被设置为5120MB)是很重要的！</p><p id="0154" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Lambda中本地加载YOLOv5模型非常简单:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/729838d2cfdcc8cb72e4126dcb04de8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZCP-MgKgOKgYYIRJVb2cKQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><ul class=""><li id="248e" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">确保您复制了yolov5项目目录(在2.1中提到)并将目录的路径设置为repo_or_dir</li><li id="9cb5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用模型=“自定义”和来源=“本地”</li><li id="2ccf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">该路径指向有效的*。pt YOLOv5训练模型。</li></ul><h2 id="d960" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lf mp mq mr lj ms mt mu ln mv mw mx my bi translated">限制</h2><blockquote class="nm nn no"><p id="16b1" class="kw kx ng ky b kz la jr lb lc ld ju le np lg lh li nq lk ll lm nr lo lp lq lr ij bi translated">所有的模型都是错的，但有些是有用的——乔治·博克斯</p><p id="6903" class="kw kx ng ky b kz la jr lb lc ld ju le np lg lh li nq lk ll lm nr lo lp lq lr ij bi translated">所有的解决方案都是错的，但有些是有用的——本文作者:)</p></blockquote><p id="6a2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没有完美的解决方案，所有解决方案都有权衡和限制，建议的解决方案的一些限制包括:</p><ul class=""><li id="159d" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">Lambda推理不是为要求实时处理和极低延迟的实时推理而设置的</li><li id="b1e8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">Lambda有15分钟的运行时间限制，如果推理时间太长，就会失败</li><li id="040f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">EFS带宽费用是额外的费用，但是你可以切换到S3下载和加载作为主要方法，EFS安装和加载作为次要方法。它速度较慢，但成本较低，并且批量推断通常对延迟不敏感</li></ul><h2 id="1662" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lf mp mq mr lj ms mt mu ln mv mw mx my bi translated">潜在提升和转移</h2><p id="5979" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">该解决方案的一些功能/设计模式可能会被提升并转移到其他云平台(例如Azure、GCP ),因为它们提供与AWS类似的服务，其中两个有价值的服务是:</p><ul class=""><li id="c83c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">使用低成本的无服务器计算机服务(Azure函数、GCP函数)来服务模型批量推理，并与“调度程序”集成以保持服务“温暖”</li><li id="2f58" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">设计预加载和缓存模型的逻辑，以减少推理处理时间</li></ul><h2 id="d99e" class="mg mh iq bd mi mj mk dn ml mm mn dp mo lf mp mq mr lj ms mt mu ln mv mw mx my bi translated"><strong class="ak">总结</strong></h2><p id="a879" class="pw-post-body-paragraph kw kx iq ky b kz na jr lb lc nb ju le lf nc lh li lj nd ll lm ln ne lp lq lr ij bi translated">感谢您的阅读，希望您喜欢这篇文章，以下是一些要点:</p><ul class=""><li id="7fd8" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">AWS Lambda、EFS和S3可以组合成一个经济高效、可扩展且健壮的服务，用于模型批量推理(最多15分钟)</li><li id="b165" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">正确实现AWS EventBridge Lambda触发器有助于最小化Lambda冷启动</li><li id="01b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在Lambda中实现模型预加载和缓存逻辑将有助于减少模型推理的交付时间</li><li id="c098" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">将模型路径作为系统参数传递，而不是将模型嵌入到Lambda图像中，这样可以获得更大的灵活性(解耦)</li><li id="4bb9" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在其他云平台上应用类似的概念有潜在的提升和转变机会</li></ul></div></div>    
</body>
</html>