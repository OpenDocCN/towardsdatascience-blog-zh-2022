<html>
<head>
<title>Saving Multiple Images in Tensorboard with tf.summary.image</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用tf.summary.image在Tensorboard中保存多个图像</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/saving-multiple-images-in-tensorboard-with-tf-summary-image-15df9c11d6c9#2022-10-19">https://towardsdatascience.com/saving-multiple-images-in-tensorboard-with-tf-summary-image-15df9c11d6c9#2022-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b78e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在Tensorboard内存储多个图像，以查看您的神经网络的演变。GAN模型的案例应用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/616501578e8384387d3b3daa4888d974.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4httPbpz-KxRcGCAmC8wgg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">桑尼·萨希尔在<a class="ae kv" href="https://unsplash.com/collections/10458041/dashboard?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片。由作者编辑。</p></figure><p id="fa56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> R </span>最近，我一直在开发一个图像生成模型，并且需要在<strong class="ky ir"> Tensorboard </strong>中保存一些图像，以查看该模型在每个时代是如何发展的。</p><p id="3ac8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经过长时间的搜索和几个文档文件，我终于得出了您可以在图像中看到的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mb"><img src="../Images/a2eb6686338dcc9f1cf65c1d0c06feb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*et6Y1i4ZUdyV7Kr6tVIPww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自Tensorboard项目。上面的图像是给予神经网络的输入，中间的图像是网络的输出(翻译的图像)，而下面的是基础事实(模型应该输出的内容)。图像顶部的进度条表示图像生成的时间。作者图片</p></figure><p id="4b88" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，这个模型使用Pix2Pix模型[ <a class="ae kv" href="https://arxiv.org/pdf/1611.07004" rel="noopener ugc nofollow" target="_blank">链接到paper </a> ]，试图将给定的图像“翻译”成莫奈的艺术绘画。您可以在Kaggle存储库[ <a class="ae kv" href="https://www.kaggle.com/datasets/shcsteven/paired-landscape-and-monetstylised-image" rel="noopener ugc nofollow" target="_blank">链接</a> ]中找到您正在查看的数据集</p><p id="07fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注1 </strong>。由于我只是想显示仪表板，模型被训练的时期数量非常少，所以结果看起来很差。</p><h1 id="df21" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">为什么使用Tensorboard</h1><p id="ec21" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated"><strong class="ky ir"> Tensorboard </strong>是一个可视化工具，它提供了分析神经网络性能的框架。它可以使用<em class="mz"> Tensorflow </em>和<em class="mz"> Pytorch </em>库进行集成，在您机器的本地端口上生成一个接口，用于投影损失函数的演变等指标或跟踪定制指标，如本例中生成的图像。</p><p id="0795" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些可视化对于神经网络模型的开发阶段来说是必不可少的<strong class="ky ir">、允许我们检测关键问题，例如<strong class="ky ir">过拟合/欠拟合</strong>、测量和<strong class="ky ir">比较多个模型</strong>，或者提供关于哪些改变可以提高整体性能的见解<strong class="ky ir">(超参数调整)</strong> <br/>例如，分析每个时期上生成的图像可以帮助我们检测生成器中的弱点，例如粒状模式的生成或模式崩溃导致的停滞，但这些是另一篇文章的主题</strong></p><p id="e0d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想了解更多关于Tensorboard的信息，可以查看文档<a class="ae kv" href="https://www.tensorflow.org/tensorboard/get_started" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="75b6" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">密码</h1><p id="e14a" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">我不想浪费你的时间，所以下面是保存图片的代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">喀拉斯。回调子类。作者代码</p></figure><p id="e8ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，使用自定义回调启动培训:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用自定义回调训练Pix2Pix模型。作者代码</p></figure><h2 id="0730" class="nc md iq bd me nd ne dn mi nf ng dp mm lf nh ni mo lj nj nk mq ln nl nm ms nn bi translated">代码解释</h2><p id="d829" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">对于那些不复制和粘贴代码的人，让我解释一下当你运行上面的代码时会发生什么。</p><p id="c6b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步我们需要创建一个<code class="fe no np nq nr b">keras-callbacks</code>子类，在那里我们可以定义我们的自定义回调。<br/>回调是在训练过程中以指定的频率执行的功能<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback" rel="noopener ugc nofollow" target="_blank">参见文档</a>。要告诉Tensorflow在训练时使用回调，我们只需以列表对象的形式将它们作为参数传递(参见第5步)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/476baf79c8a40ad5181731b8dc7692f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JofHt_L7FArQuX2NZFUFEw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自代码。作者图片</p></figure><p id="e6af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，回调类接收来自训练集和验证集的一批图像、模型的生成器(这样我们就可以生成图像)和存储图像的路径(<code class="fe no np nq nr b">logdir</code>)作为参数，这些图像将在Tensorboard中显示。</p><p id="f2b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还定义了实例变量<code class="fe no np nq nr b">self.writer</code>，它为给定的日志目录创建一个摘要文件编写器(我们将在这里存储信息，以便稍后在Tensorboard上显示)</p><p id="2813" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【T22日我们定义了de类方法<code class="fe no np nq nr b">on_epoch_end</code>，顾名思义，它将在每个历元之后执行。</p><p id="339a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注2 </strong>。接收此方法的参数以Tensorflow为前缀，所以不要试图更改它们。</p><p id="408b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<code class="fe no np nq nr b">on_epoch_end</code>方法中，我们还必须定义一个函数来生成图像(这样代码看起来更干净、更有条理)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/04f5b068c1835477603e77fc3e6f4c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iu9sev_TvPMOVakR_KdQxw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自代码。作者图片</p></figure><p id="c219" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">函数<code class="fe no np nq nr b">generate_imgs</code>获取一组图像(来自Tensorflow.data的TakeDataset元素)和生成器(<em class="mz"> g </em>)，并返回一个3显示图像的列表，该列表垂直连接输入图像<code class="fe no np nq nr b">x</code>、由模型<code class="fe no np nq nr b">out</code>翻译的图像和地面实况<code class="fe no np nq nr b">y</code>。如果我们不连接这些图像，它们将显示在Tensorboard的不同卡片上。</p><p id="7101" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注3 </strong>。在连接之前，我们必须使用函数<code class="fe no np nq nr b">tf.squeeze()</code>移除批量维度，以防止出现异常。</p><p id="7179" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第三</strong>接下来，我们使用<code class="fe no np nq nr b">tf.summary.image()</code>保存图像</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/2559fbfeaf706f0015d1d7ca5bf4a8c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uEZk3ZDqP28-Nl3n1EKX1g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自代码。作者图片</p></figure><p id="ce6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一行<code class="fe no np nq nr b">self.writer.as_default()</code>告诉Tensorflow将接下来的操作存储在同一个图中(即<em class="mz">自写器</em>图)，这样回调在每个时期后生成的所有图像都将被记录在同一个文件中【check <a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/Graph#as_default" rel="noopener ugc nofollow" target="_blank"> doc </a>，<a class="ae kv" href="https://stackoverflow.com/questions/56421878/why-do-i-need-as-default-to-write-instructions-in-a-tensorflow-graph" rel="noopener ugc nofollow" target="_blank"> link </a> ] <br/>接下来，<code class="fe no np nq nr b">tf.name_scope()</code>函数将为每个图像的名称添加前缀“<em class="mz"> train/ </em>或“<em class="mz"> val/ </em>”， 因此，训练和验证生成的图像保存在工作目录的不同文件夹中(<strong class="ky ir">在Tensorboard中，这反映为不同的部分</strong>，但实际上两个文件的名称相同，属于同一个摘要文件)</p><p id="09b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注4 </strong>。在这种情况下，我再次将图像的名称定义为范围，因此它们将被命名为“<em class="mz"> train/train/ </em>或“<em class="mz"> val/val </em>”，但是对于进一步的项目，我建议更改它。</p><p id="7cf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第四个<strong class="ky ir">初始化类。回到我们创建模型的train.py文件，我们通过调用它来初始化这个类(第9行)。对于这个项目，我决定从训练集中取4张图片，从验证中取另外4张图片，每张图片来自不同的批次。接下来，我指定生成器(pix2pix是一个<em class="mz"> keras.model </em>所以我可以调用生成器作为方法)和保存摘要的logdir。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/31d60a02985007bcfe26ba554b93c881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R0fqiu5-7WudpigIrRd6TA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自代码。作者图片</p></figure><p id="2fd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注5 </strong>。有人可能会认为，如果我们将生成器作为参数传递，那么在训练期间，它们的权重不会更新，结果也不会正确。然而，Tensorflow设法做到了这一点，因为我们正在传递一个指向所创建的类pix2pix的类实例<code class="fe no np nq nr b">pix2pix.g</code>，即当pix2pix更新其权重时，它将应用于其所有实例。<br/>我亲自检查了这一点(如果你不相信我，你也可以这样做),在自定义回调中添加了一行:</p><p id="150f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe no np nq nr b">print(self.g.get_weights()[0][0][0][0])</code></p><p id="49b5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果是每个时期的第一个神经元权重的打印，因此您可以注意到修改。</p><p id="5117" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">第五次</strong>使用自定义回调训练模型</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/3d343c56d5e8d8070de7188a05b50e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5smgyPyWy97LYm8T1LWYdA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">截图取自代码。作者图片</p></figure><h1 id="6c61" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">结论</h1><p id="c0a9" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">能够在训练阶段可视化您的模型的演变对于良好的开发是至关重要的，并且提供关于采取什么方向来提高模型的准确性和性能的关键见解。</p><p id="c661" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，<strong class="ky ir">考虑评估我们的定制指标的成本</strong>也很重要，因为对于训练模型来说，时间是一个重要的事实。在这个项目示例中，根据您的硬件和映像大小，打开映像包并测试生成器可能需要额外的几分钟时间，这大大降低了培训的速度。</p><p id="9bc7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">解决这个问题的一个好办法是建立一个<em class="mz">频率变量</em>，它将与自定义回调类中的纪元编号进行比较，这样如果<code class="fe no np nq nr b">epoch % frequency == 0</code>，我们就可以测试生成器并保存结果。</p><p id="86de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望这篇文章是有用和有帮助的，更多关于人工智能和数据科学的文章，你可以查看我的其他文章。</p></div></div>    
</body>
</html>