<html>
<head>
<title>A Practical Introduction to Hierarchical clustering from scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">scikit-learn 中的分层聚类实用介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-introduction-to-hierarchical-clustering-from-scikit-learn-ffaf8ee2670c#2022-03-07">https://towardsdatascience.com/a-practical-introduction-to-hierarchical-clustering-from-scikit-learn-ffaf8ee2670c#2022-03-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="afc2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">UCL 数据科学学会研讨会 17:什么是层次聚类、实现、解释和评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/276de1c1ce15fef0abbab3fe8d6349a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9epqGxJ5s0MSoy--TMgyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b96f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">今年，作为 UCL 数据科学协会的科学负责人，该协会将在整个学年举办一系列 20 场研讨会，主题包括数据科学家工具包 Python 的介绍以及机器学习方法。每个人的目标是创建一系列的小博客文章，这些文章将概述主要观点，并为任何希望跟进的人提供完整研讨会的链接。所有这些都可以在我们的<a class="ae lu" href="https://github.com/UCL-DSS" rel="noopener ugc nofollow" target="_blank"> GitHub </a>资源库中找到，并将在全年更新新的研讨会和挑战。</p><p id="0b8f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本系列的第 17 个研讨会是 Python 数据科学研讨会系列的一部分，涵盖了 scikit-learn 的层次聚类。在本次研讨会中，我们将介绍什么是层次聚类，如何实现该模型，解释结果，以及可视化的树状图。一如既往，这篇博文是整个研讨会的总结，可以在<a class="ae lu" href="https://github.com/UCL-DSS/hierarchical_clustering" rel="noopener ugc nofollow" target="_blank">这里</a>找到，它更详细地涵盖了这些主题，并提供了数据集。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="41aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您错过了之前的任何研讨会，您可以在这里找到:</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/a-practical-introduction-to-kmeans-clustering-using-scikit-learn-fd9cff95144b"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">使用 scikit-learn 进行 Kmeans 聚类的实用介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 16:什么是 Kmeans 集群、实现、评估和解释</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/a-practical-introduction-to-support-vector-machines-from-scikit-learn-6e678cf1f228"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">来自 scikit-learn 的支持向量机实用介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 15:什么是支持向量机，如何实现它们，以及如何评估它们</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a href="https://python.plainenglish.io/a-practical-introduction-to-random-forest-classifiers-from-scikit-learn-536e305d8d87" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">scikit-learn 中随机森林分类器的实用介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 14:什么是随机森林分类器、实现、评估和改进</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">python .平原英语. io</p></div></div><div class="mo l"><div class="mv l mq mr ms mo mt ks mf"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="1b90" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">什么是层次聚类？</strong></p><p id="79c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">分层聚类是称为聚类的无监督学习模型组的一部分。这意味着我们没有一个明确的目标变量，不像传统的回归或分类任务。因此，这种机器学习算法的要点是通过对所选变量使用定义的距离度量来识别具有相似特征的不同对象群。属于这个家族的其他机器学习算法包括 Kmeans 或 DBscan。</p><p id="9c1e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种特定的算法有两种主要的风格或形式:自顶向下或自底向上。第一种是自上而下的，首先将所有点视为一个单独的聚类，然后逐渐将它们分解成单独的聚类(分裂的),直到它们都是自己的聚类的一部分。第二种是自底向上的，从所有点都是它们自己的聚类的一部分的基础开始，然后迭代地将两个最近的点分组在一起，直到它们都是单个聚类的一部分(聚集的)。这种聚类的层次结构可以表示为如下的树(或树状图)。当我们沿着 y 轴向上走时，这就代表了单个的集群和距离的增加。这可以想象为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ca"><img src="../Images/f6c15c5dfdf7c8fb491eb9069dca899a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_BKB4TvxjCHHksoCzsy4sQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4524" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最常见的形式是我们在这里使用的凝聚法。</p><p id="0c71" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与其他聚类方法相比，层次聚类的优势在于它不需要指定聚类的数量，算法对距离度量不太敏感，并且当我们期望数据具有层次结构时，它非常有用。然而，这是以较低的效率为代价的，因为时间复杂度更高，并且没有自然的性能指标可以使用。</p><h2 id="8956" class="mw mx it bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">履行</h2><p id="ca9c" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">分层聚类方法的应用将针对从伦敦犯罪数据存储中提取的伦敦犯罪数据，这些数据是关于在本地超级输出区域规模(人口普查几何)发生的犯罪的。选择这一级别是因为它们代表了每个地区家庭数量方面最标准化的单位，减少了由于非标准地理单位而可能出现的一些潜在差异。</p><p id="dd45" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为此，我们重点关注伦敦的 10 种主要犯罪类型，它们在每个 LSOA 的总体犯罪中所占的比例如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/276de1c1ce15fef0abbab3fe8d6349a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z9epqGxJ5s0MSoy--TMgyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="7a8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于这种分布，我们可以尝试对结果进行聚类，以了解聚类是如何发展的。这可以通过以下方式实现:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="99b6" class="mw mx it nv b gy nz oa l ob oc">#import the necessary module<br/>from sklearn.cluster import AgglomerativeClustering</span><span id="0dc4" class="mw mx it nv b gy od oa l ob oc">#create the model that we want, setting the linkage to ward, the distance threshold to 4 and <br/>#set the number of clusters to none so that we can plot the dendrogram afterwards<br/>model = AgglomerativeClustering(linkage="ward", <br/>                                distance_threshold = 7, <br/>                                n_clusters=None)<br/>#fit the model to the data<br/>model.fit(crime_clus)</span></pre><h2 id="56cd" class="mw mx it bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">解释</h2><p id="b0c1" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">正如我们在开始时所说，该模型是一种无监督的机器学习算法，这意味着我们不一定知道要实现的最佳聚类数，除非我们有一些先验理论或数据解释。这种方法也不同于 Kmeans 聚类，在 k means 聚类中，我们可以使用“肘方法”或“轮廓分数”来确定最佳的聚类数。因此，选择正确的模型实现取决于您的目的以及您自己和您的受众是否能够理解这些组。</p><p id="6a5a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我们的例子中，由于我们的模型在本质上是地理的，所以我们既可以根据每个聚类内的值分布来解释模型，也可以根据地理来解释模型。这可以通过以下方式实现:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="12be" class="mw mx it nv b gy nz oa l ob oc">London_crime["Aggl_clus"] = model.labels_</span><span id="f862" class="mw mx it nv b gy od oa l ob oc">fig, ax = plt.subplots(figsize = (10,10))</span><span id="1cb5" class="mw mx it nv b gy od oa l ob oc">London_crime.plot(column = "Aggl_clus", <br/>                  categorical = True, <br/>                  legend=True, <br/>                  ax=ax,<br/>                  alpha = 0.7,<br/>                 cmap = "tab10")</span><span id="d60f" class="mw mx it nv b gy od oa l ob oc">cx.add_basemap(ax = ax,<br/>               crs = "EPSG:27700")</span><span id="857b" class="mw mx it nv b gy od oa l ob oc">ax.set_axis_off()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/112725feed72f3047390abc7a81c9c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UIYWt5Uf79Sfx6iHEl1-1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="11b2" class="mw mx it nv b gy nz oa l ob oc">agglom_means =London_crime.groupby("Aggl_clus")[to_plot].mean()<br/>agglom_means_T = agglom_means.T.round(3)</span><span id="9a2f" class="mw mx it nv b gy od oa l ob oc">#agglom_means_T.reset_index(inplace=True)<br/>agglom_means_T = pd.DataFrame(agglom_means_T)</span><span id="c559" class="mw mx it nv b gy od oa l ob oc">agglom_means_T.reset_index(inplace=True)</span><span id="440b" class="mw mx it nv b gy od oa l ob oc">#get the colours<br/>colors = ["#1f77b4", "#d62728", "#e377c2", "#17becf"]</span><span id="dcde" class="mw mx it nv b gy od oa l ob oc">#create subplots for each cluster<br/>fig, ax = plt.subplots(1,4, figsize = (15,8), sharey = True, sharex = True)<br/>#flatten the axis<br/>axis = ax.flatten()</span><span id="3ab0" class="mw mx it nv b gy od oa l ob oc">#going over each column<br/>for i, col  in enumerate(agglom_means_T.columns):<br/>    #ignore the index column<br/>    if col != "index":<br/>        ax = axis[i-1]<br/>        #plot the bar chart<br/>        ax.bar(height = agglom_means_T[col], x=agglom_means_T["index"], color = colors[i-1] )<br/>        #rotate the x-ticks<br/>        ax.set_xticklabels(labels =agglom_means_T["index"], rotation = 90)<br/>        #set the title<br/>        ax.set_title(f"Cluster {col}", fontsize = 20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/dc35182e2b5c2a5cb777ebb70af502dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hDyCmkR2ZG_J1ANEYY3d2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4517" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由此我们可以看出，与其他群组相比，群组 0 平均具有相对较高的人身暴力、纵火、刑事损害和毒品犯罪。灌肠 1 是占主导地位的盗窃案件相对较低的车辆犯罪。第二组主要是入室盗窃，而第三组主要是车辆犯罪，这表明每个地区的犯罪性质不同。</p><p id="1c37" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于这些，我们可以分配标签，例如:</p><ul class=""><li id="c9f5" class="og oh it la b lb lc le lf lh oi ll oj lp ok lt ol om on oo bi translated">第 1 组:对人的暴力行为</li><li id="ae0c" class="og oh it la b lb op le oq lh or ll os lp ot lt ol om on oo bi translated"><strong class="la iu">集群二</strong>:盗窃</li><li id="534f" class="og oh it la b lb op le oq lh or ll os lp ot lt ol om on oo bi translated"><strong class="la iu">集群 3 </strong>:入室盗窃</li><li id="79b3" class="og oh it la b lb op le oq lh or ll os lp ot lt ol om on oo bi translated"><strong class="la iu">群组 4 </strong>:车辆违法行为</li></ul><h2 id="8aba" class="mw mx it bd my mz na dn nb nc nd dp ne lh nf ng nh ll ni nj nk lp nl nm nn no bi translated">估价</h2><p id="b140" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">衡量这种聚类是否表现良好的一个很好的指标是聚类的大小。这是因为如果一个聚类占主导地位，那么它表明该聚类不一定表现良好(取决于您对底层数据的理论。我们可以这样检查:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="bce8" class="mw mx it nv b gy nz oa l ob oc">agglom_sizes = London_crime.groupby("Aggl_clus").size()<br/>agglom_sizes</span><span id="6b56" class="mw mx it nv b gy od oa l ob oc">#out:<br/>Aggl_clus<br/>0    2455<br/>1    1083<br/>2     651<br/>3     640</span></pre><p id="d278" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到集群 0 占主导地位，这表明这可能会被打破，取决于如何构建层次结构。</p><p id="b679" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设这是层次聚类，我们可以通过绘制模型的树状图来了解模型的行为。这显示了模型如何表现的层次结构，目的是能够看到集群的层次结构如何相互适应，以及我们是否应该以更多或更少的组为目标。这可以通过以下方式实现:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="de40" class="mw mx it nv b gy nz oa l ob oc">import numpy as np<br/>from scipy.cluster.hierarchy import dendrogram</span><span id="d0c8" class="mw mx it nv b gy od oa l ob oc">def plot_dendrogram(model, **kwargs):<br/>    <br/>    counts = np.zeros(model.children_.shape[0])<br/>    n_samples = len(model.labels_)<br/>    for i, merge in enumerate(model.children_):<br/>        current_count = 0<br/>        for child_idx in merge:<br/>            if child_idx &lt; n_samples:<br/>                current_count +=1<br/>            else:<br/>                current_count += counts[child_idx-n_samples]<br/>        counts[i] = current_count<br/>        <br/>    linkage_matrix = np.column_stack([model.children_, model.distances_,<br/>                                     counts]).astype(float)<br/>    <br/>    dendrogram(linkage_matrix, **kwargs)</span><span id="af7b" class="mw mx it nv b gy od oa l ob oc">fig, ax = plt.subplots(figsize = (10,10))<br/>ax.set_title("Hierarchical clustering dendrogram")<br/>#plot the top three levels of the dendrogram<br/>plot_dendrogram(model, truncate_mode='level', p=3)<br/>plt.axhline(y = 7, color = "r", linestyle = "--")<br/>plt.axhline(y = 6, color = "r", linestyle = "--")<br/>plt.axhline(y = 9, color = "r", linestyle = "--")<br/>ax.set_xlabel("Number of points in node")<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/308fce584250df49be9266a68eac2b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wYbNqLKIeOU_fX_VDWqI0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b2bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这表明，使用当前的距离度量，我们得到四个聚类，然而，我们可以看到，在稍大的距离处，出现三个聚类而不是四个，或者在稍小的距离处，则可能出现五个聚类。</p><p id="47de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这样，我们可以更详细地探索聚类及其可解释性如何随着模型本身内的不同距离而变化，或者随着数据的不同标准化、不同距离、甚至模型内的不同联系而改变模型实现。这也可以包括地理约束模型，将周围的 LSOAs 考虑到模型中，如此处的<a class="ae lu" rel="noopener" target="_blank" href="/introduction-to-hierarchical-clustering-part-3-spatial-clustering-1f8cbd451173">所示</a>。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="747e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果您想了解我们协会的更多信息，请随时关注我们的社交网站:</p><p id="a976" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">https://www.facebook.com/ucldata 脸书<a class="ae lu" href="https://www.facebook.com/ucldata" rel="noopener ugc nofollow" target="_blank"/></p><p id="a7be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">insta gram:https://www.instagram.com/ucl.datasci/<a class="ae lu" href="https://www.instagram.com/ucl.datasci/" rel="noopener ugc nofollow" target="_blank"/></p><p id="6dea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">领英:<a class="ae lu" href="https://www.linkedin.com/company/ucldata/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/ucldata/</a></p><p id="1f5b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想了解 UCL 数据科学协会和其他优秀作者的最新信息，请使用我下面的推荐代码注册 medium。</p><div class="mc md gp gr me mf"><a href="https://philip-wilkinson.medium.com/membership" rel="noopener follow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">通过我的推荐链接加入媒体-菲利普·威尔金森</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">philip-wilkinson.medium.com</p></div></div><div class="mo l"><div class="ov l mq mr ms mo mt ks mf"/></div></div></a></div><p id="2885" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者在媒体上查看我的其他商店，例如:</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/an-introduction-to-sql-for-data-scientists-e3bb539decdf"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">数据科学家的 SQL 介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会工作坊 9:什么是 SQL，选择数据，查询数据，汇总统计，分组数据和…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="ow l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/git-and-github-basics-for-data-scientists-b9fd96f8a02a"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">面向数据科学家的 Git 和 GitHub 基础知识</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学研讨会 8:什么是 Git，创建本地存储库，提交第一批文件，链接到远程…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="ox l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/multi-variate-outlier-detection-in-python-e900a338da10"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">Python 中的多变量异常检测</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">能够检测数据集中异常值/异常值的六种方法</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="oy l mq mr ms mo mt ks mf"/></div></div></a></div></div></div>    
</body>
</html>