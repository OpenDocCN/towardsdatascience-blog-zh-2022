<html>
<head>
<title>Convolutional Neural Networks for EEG Brain-Computer Interfaces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于脑电图脑-机接口的卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-networks-for-eeg-brain-computer-interfaces-9ee9f3dd2b81#2022-09-13">https://towardsdatascience.com/convolutional-neural-networks-for-eeg-brain-computer-interfaces-9ee9f3dd2b81#2022-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="27e3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">PyTorch和TensorFlow中的代码示例</h2></div><p id="9a6d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">深度学习(DL)在各个领域的受欢迎程度都有了巨大的增长。DL也已经被用于脑-机接口(BCI)和脑电图(EEG)。然而，DL模型需要适应脑电图数据。这是如何做到的？在BCIs领域，DL方法有多成功？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/da70833eec0d9f1a609ca7629e28c524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w5QN2SFAX3FQUN0F"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图一。乔希·里默尔在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4ce4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我们首先解释了为什么对于脑机接口来说，与传统的机器学习(ML)方法相比，DL更有优势。我们解释卷积神经网络(CNN)如何工作，以及它们如何被改变和用于脑电图数据。我们将深入研究一个特定的网络EEGNET，并在PyTorch和TensorFlow中提供EEGNET的代码示例。最后，我们讨论了如何对脑电图数据进行深度迁移学习。</p><p id="a14c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该职位的组织结构如下:</p><ol class=""><li id="8171" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld ma mb mc md bi translated">为什么要用深度学习？</li><li id="b935" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">脑电图数据的专用CNN</li><li id="eec1" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">解释最流行的CNN脑电图数据:EEGNET</li><li id="971a" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">TensorFlow和PyTorch中的代码示例EEGNET</li><li id="3a6d" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">深度迁移学习可能吗？</li></ol><p id="ef32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">尽情享受吧！</p><h2 id="525d" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">为什么要深度学习？</h2><p id="4cf9" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">在BCI领域，两种常见的分类方法是公共空间模式(CSP)和黎曼几何(RG)。这两种方法之前都有大量的预处理，其中最重要的一步是频率滤波，这是一种提取特征的方法。CSP和RG在<a class="ae lu" href="https://medium.com/the-ultimate-bedroom-bci-guide/effective-machine-learning-for-eeg-bcis-fe322e584627" rel="noopener">这里</a>有更详细的解释，频率滤波在<a class="ae lu" href="https://medium.com/the-ultimate-bedroom-bci-guide/feature-engineering-for-motor-imagery-bcis-with-code-examples-b296992b0936" rel="noopener">这篇文章</a>有更详细的解释。</p><p id="3f0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于特征提取步骤的滤波器范围必须由研究者手动选择，这引入了主观偏见。其次，受试者之间最显著的大脑信号的频率范围也不同。由于手动寻找每个对象的最佳范围可能非常彻底，研究人员通常选择一个大致的范围(例如8-40赫兹)，希望这个范围对所有对象都足够了。</p><p id="d8e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是DL发挥作用的地方。</p><p id="8cad" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DL的优势在于它是一种端到端的方法，其中在模型中结合了特征提取和分类。DL模型可以从原始脑电图数据中提取特征，这意味着数据可以在没有研究人员手动选择过滤器的情况下进行预处理。一些研究使用原始脑电图数据[1]，而其他研究仅在1–100Hz的宽范围内应用带通滤波器，以最大限度地减少极低频和高频噪声伪像[2]。</p><p id="4fc6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种端到端方法消除了研究人员对频率滤波的主观偏见，DL模型能够了解每个个体对象的最佳范围。</p><p id="7c00" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们知道了DL的优点，让我们看看DL是如何在BCI领域使用的！</p><h2 id="9a04" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">脑电卷积神经网络</h2><p id="1c3a" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">DL在BCI领域最突出的例子是卷积神经网络(CNN)的应用，它最初用于图像等计算机视觉任务，但也用于音频信号。</p><p id="44bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图像和音频信号通常具有分层结构，其中附近的特征对于当前特征是重要的，而远处的特征不那么重要。当EEG数据被视为2D阵列，以时间步长数为宽度，以电极数为高度时(如图2所示)，EEG数据具有与图像或音频信号相似的特征。附近时间点的数据对于当前数据点以及同一时间点其他通道的数据都很重要。使用卷积和非线性，CNN可以在这些类型的数据中学习局部非线性特征和局部模式。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nh"><img src="../Images/3c20ec6983f79330f0c40204f00429d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v13vF7Z79a869hafuVGJzg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图2:脑电图数据示例。脑电图数据可以被视为一个2D阵列，行是电极通道，列是时间点。图片作者。</p></figure><p id="d513" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CNN通过使用内核来工作。内核是数据上的滑动窗口，从左到右、从上到下扫描。对于每次扫描，计算该窗口中的数据与内核值的点积，本质上总结了该窗口中数据的信息。下面的图3给出了一个直观的例子。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/345771e433a66e1828a47f914bb1bc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/1*Y9OPo-NhjoYdWPnOTWniZg.gif"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图3:CNN的滑动窗口。图片来自作者，灵感来自<a class="ae lu" href="https://giphy.com/gifs/blog-daniel-keypoints-i4NjAwytgIRDW" rel="noopener ugc nofollow" target="_blank">来源</a>。</p></figure><p id="32fd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于EEG数据的CNN，最流行的模型是用所谓的时间和空间卷积开发的。</p><p id="f3b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">时间卷积的核大小为<em class="nj"> 1 x时间点，</em>，其中滑动窗口将在特定时间帧内遍历每个通道，因此汇总了每个通道在该时间帧内的EEG数据。</p><p id="645a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个时间点，对所有通道应用空间卷积，从而汇总所有通道的信息。卷积可以用不同的内核值应用多次，创建不同类型的原始数据摘要(称为特征映射)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nk"><img src="../Images/a7df625f27306229d344a466b1ef2c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9hBPUYQKpIbO0iihrKrxMg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图4:应用于脑电图数据的时间卷积和空间卷积。图片作者。</p></figure><p id="75da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种卷积的目的是通过用时间卷积表示频率滤波，用空间卷积表示空间滤波来表示CSP流水线。</p><p id="754e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">EEGNET是用于EEG分类的最流行的DL模型之一[1]。EEGNET以其相对较大的网络和有限的参数数量而闻名，在最近的研究中被大量使用。</p><p id="3238" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们详细解释EEGNET，并附上代码示例！</p><h2 id="0699" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">EEGNET</h2><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nl"><img src="../Images/4a15aea25f41123cda8a04c5f56247fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dR-vWIOy8AHgMi1BrDi4nA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图5:为我们的研究调整的EEGNET网络。图片作者。</p></figure><p id="b524" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">EEGNET由一个时间和空间卷积组成，但也有另一种形式的卷积，称为可分离卷积。在以下章节中，将对EEGNET进行解释。</p><p id="e7ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，原始的EEGNET与我们在这里解释的实现略有不同。例如，原始论文的作者将模型应用于<em class="nj"> 64个电极通道x 128个时间点</em>的EEG数据，而我们使用的是<em class="nj"> 8个电极通道x 500个时间点</em>的EEG数据。一般来说，建议在将网络应用于您自己的数据时，试验一下内核大小和参数值。</p><p id="dba7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">网络的第一层是时间卷积。卷积的内核大小与原始的EEGNET保持一致，大小为<em class="nj"> 1 x 64 </em>。该层中的特征地图的数量，命名为过滤器大小(<em class="nj"> fz </em>)，是基于超参数搜索选择的。每个卷积层在卷积后应用批量归一化，以归一化前一层的输出，从而确保下一层的归一化输入。</p><p id="735c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二层是大小为<em class="nj"> 8 x 1 </em>的空间卷积。第一尺寸等于电极通道的数量。来自前一层的特征图的数量乘以深度参数(<em class="nj"> D </em>)，该深度参数也是基于超参数搜索选择的。应用批量标准化后，用指数线性单位(ELU)实现非线性。当<em class="nj"> x &gt; 0，</em>时，ELU保持输出<em class="nj"> x </em>不变，并且对于<em class="nj"> x ≤ 0 </em>，函数<em class="nj">exp(x)—1</em>被应用。</p><p id="bfef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，应用步长为5的核大小为<em class="nj">5×1</em>的时间平均池，对每5个时间点的数据进行平均以降低维数。由于我们研究中的输入大小(500)不能被原始网络中的步幅值8整除，所以我们选择了步幅值5。</p><p id="2c43" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">平均汇集后，辍学层紧随其后。在训练期间，dropout以一定的概率随机地将输入的一些元素置零<em class="nj"> pdrop </em>。这通过减少特定节点对早期层中的节点的依赖性来防止对训练数据的过度拟合，因为节点对之间的高度依赖性可能导致对训练数据中的特定特征的过度拟合，这不会出现在验证和测试数据中。通过超参数搜索找到了<em class="nj"> pdrop </em>的值。</p><p id="13f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，应用一个可分离的卷积层，该卷积层由一个核大小为<em class="nj"> 1 x 16 </em>的时间卷积组成，如在原始EEGNET中所使用的，紧接着是一个<em class="nj"> 1 x 1 </em>卷积，该卷积对来自前一层的所有特征映射上分组的核进行，本质上概括了特征映射上的时间卷积的输出。在这一层，另一批标准化和ELU被应用。</p><p id="563e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">之后，应用了另一个<em class="nj"> 5 x 1 </em>平均池，然后是一个dropout层。最后，数据被展平，并且应用了线性层。</p><p id="471c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与最初的EEGNET一样，上面解释的所有卷积层都是以步长1应用的，没有添加偏移。对于时间卷积，使用“相同”填充，其中零被添加到输入的左侧和右侧，以在卷积后具有相同的输出大小。</p><p id="7cf1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为优化方法，使用了Adam优化器。Adam的学习率<em class="nj"> lr </em>也是通过超参数搜索找到的。</p><h2 id="698c" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">PyTorch和TensorFlow中的EEGNET</h2><p id="13d6" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">现在所有的解释都结束了，让我们看看如何编写这个模型！</p><p id="fb12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初的作者在他们的<a class="ae lu" href="https://github.com/vlawhern/arl-eegmodels/blob/master/EEGModels.py" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>中提供了他们在TensorFlow中的模型实现。它们在TensorFlow中实现，归结为以下代码:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1e09" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的实现是在PyTorch中开发的，可归结为:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h2 id="e134" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">转移学习？</h2><p id="05ec" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">EEGNET在应用单个个体的数据时，很可能会表现得非常糟糕。为什么？仅仅是因为数据量不足以让EEGNET正确校准。由于这个原因，迁移学习(TL)已经被用于BCI领域，在将模型应用于新的主题之前，模型将从多个主题的数据中学习。然而，最初的实验表明，用于EEG数据的TL伴随着许多困难和问题。让我们检查一下。</p><p id="ca14" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">噪音可变性:</strong>脑电图捕捉源自你大脑的电活动。然而，脑电图电极不是智能设备。他们不能区分来自大脑的电信号和其他电信号。这可能是很多信号。想想你的手机，显示器，空调，你能想到的。这里的难点在于，这些噪声源每天都不一样，在其他环境中也不一样。这种噪音的可变性会导致您自己的实验中的受试者和会话之间的差异。但是想象一下在完全不同的环境中捕获的数据集之间的差异。尽管这种噪声只会少量影响EEG数据，但当在多个数据集或多个受试者的数据上训练通用模型时，它仍然会带来困难[3]。</p><p id="4ee5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">脑电图仪:</strong>另一个可变性的来源是脑电图仪本身。这里的主要组成部分是将帽子放置在对象的头上。虽然我们有一个标准化的电极放置方法(<a class="ae lu" href="https://en.wikipedia.org/wiki/10%E2%80%9320_system_(EEG)" rel="noopener ugc nofollow" target="_blank">10–20国际系统</a>)，但是测量受试者头部的距离以及随后放置电极帽是一个稍微主观的过程。这导致受试者或会话之间的帽放置的微小差异，从而导致EEG信号的差异，因为电极可能离源自大脑的原始信号更远或更近。同样，当比较多个数据集的EEG数据时，这个问题变得更大。其他实验可能使用了不同的EEG设备，这些设备具有不同的材料和略微不同的帽放置..</p><p id="7ae6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">神经可变性:</strong>大脑是一个复杂的器官。自然，用脑电图捕捉一个人的想法似乎很容易，但潜在的机制在受试者之间的差异中起着很大的作用，而且在同一受试者的日常差异中也是如此。</p><p id="966a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">人们发现，对于相同的受试者，在相同的环境下执行相同的任务，大脑信号每天都不同[2]。这可能会在DTL过程中造成问题，而且还会使多天使用同一个模型变得困难。因此，模型应该每天微调或重新训练。</p><p id="935f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让DTL变得更加困难的是，一些受试者没有表现出足够强的大脑信号来被DL模型识别为模式[4]。在您的数据集中有这样的主题会在训练期间混淆DL模型。</p><p id="004e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，我们的思维方式也因人而异。如果我们以运动想象为例，我们可以用两种方式来实现它:</p><ul class=""><li id="5fbc" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld no mb mc md bi translated">动觉:想象以第一人称视角执行运动任务。</li><li id="7631" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">视觉:想象某人或你自己从第三人称视角执行运动任务。</li></ul><p id="4861" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">已经发现，与后者相比，第一种方法导致更清晰的大脑活动模式[5]。如果数据集包含两种方法的混合，这也会给DTL的学习过程带来问题。</p><p id="cbfc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">一种用于EEG迁移学习的方法:</strong>为了总结迁移学习的主题，给出了将迁移学习应用于EEG数据的指南列表:</p><ul class=""><li id="0290" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld no mb mc md bi translated">为了确保受试者之间的数据相似，最好的办法是自己收集数据。在收集数据的过程中，你可以控制对受试者的指示(例如，指示他们只进行动觉运动想象)。还有，用的是同一个脑电图仪，环境尽可能的相似，帽子放置你有控制权。</li><li id="e75a" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">要执行DTL，请在多个主题的数据上训练您的模型。对于特定的主题或会话，总是收集少量的数据来执行微调。将通用模型直接应用于新的主题或会话很可能会产生不好的结果。</li><li id="40e6" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">在训练过程中，在训练集中有多个主题，但在验证集中也有一个主题。在每个历元之后，通过对来自该主题的少量数据微调当前模型来模拟微调过程，然后通过对该主题的剩余数据应用模型来获得您的验证准确性。</li></ul><h2 id="bc8e" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">结论</h2><p id="2b57" class="pw-post-body-paragraph ki kj it kk b kl nc ju kn ko nd jx kq kr ne kt ku kv nf kx ky kz ng lb lc ld im bi translated">在这篇文章中，我们讨论了:</p><ul class=""><li id="f444" class="lv lw it kk b kl km ko kp kr lx kv ly kz lz ld no mb mc md bi translated">深度学习如何凭借端到端学习的优势进入BCI领域</li><li id="ab06" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">为什么卷积神经网络是BCI领域最受欢迎的深度学习模型，以及它们是如何工作的</li><li id="cdc9" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">关于EEGNET的深入解释，EEG net是最受欢迎的EEG数据模型</li><li id="082a" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">然后，我们在TensorFlow和PyTorch中提供了EEGNET的代码</li><li id="fca2" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld no mb mc md bi translated">最后，我们讨论了在应用深度迁移学习时可能遇到的问题，以及如何通过专门的培训过程来克服这些问题。</li></ul><p id="382c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读。如果感兴趣的话，可以在我的另一篇文章<a class="ae lu" href="https://medium.com/@timdb877/i-built-a-brain-computer-interface-to-play-space-invaders-using-thoughts-23980cb4faf7" rel="noopener">这里</a>中找到关于建立BCI系统所需的所有步骤的更多细节。</p><h2 id="17f1" class="mj mk it bd ml mm mn dn mo mp mq dp mr kr ms mt mu kv mv mw mx kz my mz na nb bi translated">参考</h2><ol class=""><li id="2d3d" class="lv lw it kk b kl nc ko nd kr np kv nq kz nr ld ma mb mc md bi translated">弗农·劳赫恩、阿米莉亚·J·梭伦、尼古拉斯·R·韦托维奇、斯蒂芬·M·戈登、周平雄和布伦特·J·兰斯。<a class="ae lu" href="https://arxiv.org/abs/1611.08024" rel="noopener ugc nofollow" target="_blank"> Eegnet:基于eeg的脑-计算机接口的紧凑卷积神经网络</a>。神经工程学报，15(5):056013，2018。</li><li id="da02" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">张策，金永根，阿齐姆·埃斯坎达里安。<a class="ae lu" href="https://arxiv.org/abs/2101.10932?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29" rel="noopener ugc nofollow" target="_blank"> EEG-Inception:用于基于EEG的运动想象分类的精确且健壮的端对端神经网络</a>。神经工程学报18.4 (2021): 046014。</li><li id="cab6" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">雅尔达·沙里亚里、特里萨·M·沃恩、LM·麦卡恩、布伦丹·Z·艾利森、乔纳森·R·沃尔帕和迪安·J·克鲁森斯基。<a class="ae lu" href="https://pubmed.ncbi.nlm.nih.gov/31108477/" rel="noopener ugc nofollow" target="_blank">使用纵向脑电图数据对肌萎缩侧索硬化患者脑机接口性能变化的探索。</a>神经工程杂志，16(5):056031，2019。</li><li id="c0c8" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">Benjamin Blankertz、Claudia Sanelli、Sebastian Halder、E . Hammer、Andrea Kübler、Klaus-Robert Müller、Gabriel Curio和Thorsten Dickhaus。<a class="ae lu" href="https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-10-S1-P84" rel="noopener ugc nofollow" target="_blank">预测bci性能研究bci文盲。英国医学委员会神经科学，10(增刊1):2009年第84页</a></li><li id="cb7b" class="lv lw it kk b kl me ko mf kr mg kv mh kz mi ld ma mb mc md bi translated">克里斯塔·纽珀、莱因霍尔德·舍雷尔、米丽娅姆·赖纳和格特·普福尔茨赫勒。运动动作的想象:<a class="ae lu" href="https://pubmed.ncbi.nlm.nih.gov/16236487/" rel="noopener ugc nofollow" target="_blank">单次脑电图中动觉和视觉-运动想象模式的差异效应</a>。认知大脑研究，25(3):668–677，2005。</li></ol></div></div>    
</body>
</html>