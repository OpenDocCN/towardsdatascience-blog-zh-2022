<html>
<head>
<title>Model Evaluation in Scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Scikit-learn 中的模型评估</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/model-evaluation-in-scikit-learn-abce32ee4a99#2022-03-17">https://towardsdatascience.com/model-evaluation-in-scikit-learn-abce32ee4a99#2022-03-17</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="4d4c" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="5186" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">关于如何使用 scikit-learn 计算最常见的回归和分类指标的教程。</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/653a06b1582e34d4e10c109c9e383de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DkeHESi-vAunmot8"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated"><a class="ae lk" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="b2de" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">Scikit-learn 是最流行的用于机器学习的 Python 库之一。它提供了模型、数据集和其他有用的功能。在本文中，我将描述 scikit-learn 为模型评估提供的最流行的技术。</p><p id="21e4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><strong class="ln jg">模型评估允许我们评估模型的性能，并比较不同的模型，以选择最佳模型投入生产。</strong>模型评估有不同的技术，这取决于我们想要解决的具体任务。在本文中，我们重点关注以下任务:</p><ul class=""><li id="3c90" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated">回归</li><li id="9c7d" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated">分类</li></ul><p id="19dd" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">对于每个任务，我将通过一个实际的例子来描述如何计算最流行的指标。</p><h1 id="1073" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">1 加载数据集</h1><p id="715a" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">作为一个示例数据集，我使用由<a class="ae lk" href="https://archive.ics.uci.edu/ml/datasets/wine+quality" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习库</a>提供的<strong class="ln jg">葡萄酒质量数据集</strong>。要使用此数据集，您应该正确引用来源，如下所示:</p><ul class=""><li id="fa85" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated">Dua d .和 Graff c .(2019 年)。UCI 机器学习知识库[http://archive . ics . UCI . edu/ml]。加州欧文:加州大学信息与计算机科学学院。</li><li id="8d2a" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated">页（page 的缩写）科尔特斯、塞德伊拉、阿尔梅达、马托斯和雷伊斯。<br/>通过物理化学特性的数据挖掘建立葡萄酒偏好模型。在决策支持系统中，爱思唯尔，47(4):547–553，2009。</li></ul><p id="134a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我下载了数据文件夹，其中包含两个数据集:一个是红酒数据集，另一个是白酒数据集。我构建了一个数据集，它是两个数据集的串联，如下所示。</p><p id="a5e4" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我将两个数据集都作为熊猫数据帧加载，然后合并它们:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="f4d2" class="nx mw iw nt b gz ny nz l oa ob">import pandas as pd</span><span id="e3ed" class="nx mw iw nt b gz oc nz l oa ob">targets = ['red', 'white']<br/>df_list = []<br/>df = pd.DataFrame()<br/>for target in targets:<br/>    df_temp = pd.read_csv(f"../Datasets/winequality-{target}.csv", sep=';')<br/>    df_temp['target'] = target<br/>    df_list.append(df_temp)<br/>    print(df_temp.shape)</span><span id="2590" class="nx mw iw nt b gz oc nz l oa ob">df = pd.concat([df_list[0], df_list[1]])</span></pre><p id="24f5" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我添加了一个新列，它包含原始数据集名称(红色或白色)。数据集如下表所示:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj od"><img src="../Images/9979d9a656af15b30675cd4a8afd4fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNd-0IWEleQM44V1IabBMw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="bb5c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">数据集包含 6497 行和 13 列。</p><p id="feeb" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我定义一个函数，它对所有分类列进行编码:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="15e4" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.preprocessing import LabelEncoder</span><span id="4e25" class="nx mw iw nt b gz oc nz l oa ob">def <strong class="nt jg">transform_categorical</strong>(data):<br/>    categories = (data.dtypes =="object")<br/>    cat_cols = list(categories[categories].index)<br/>    label_encoder = LabelEncoder()<br/>    for col in cat_cols:<br/>        data[col] = label_encoder.fit_transform(data[col])</span></pre><p id="f65f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我还定义了另一个函数，它缩放数字列:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="4554" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.preprocessing import MinMaxScaler</span><span id="77b4" class="nx mw iw nt b gz oc nz l oa ob">def <strong class="nt jg">scale_numerical</strong>(data):<br/>    scaler = MinMaxScaler()<br/>    data[data.columns] = scaler.fit_transform(data[data.columns])</span></pre><h1 id="77cb" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">2 回归</h1><p id="8967" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">为了评估回归模型，最常用的指标是:</p><ul class=""><li id="88f2" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated"><strong class="ln jg">平均绝对误差</strong> —实际值与预测值之差的平均值。它衡量预测与实际产出的差距。MAE 越低，模型越好。</li><li id="1e38" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><strong class="ln jg">均方根误差</strong> —均方误差的平方根(MSE)。MSE 计算实际值和预测值之差的平方的平均值。</li><li id="2181" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><strong class="ln jg"> R2 分数</strong>—Y 中可以用 x 解释的方差比例</li></ul><p id="f8a7" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为一项回归任务，我希望在给定其他特征的情况下，预测每个记录的 pH 值。我将 X 和 y 变量定义如下:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="0e79" class="nx mw iw nt b gz ny nz l oa ob">X = df.drop("pH", axis = 1)<br/>y = df["pH"]</span></pre><p id="f73b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，我将类别转换成数字，并对数字进行缩放:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="3837" class="nx mw iw nt b gz ny nz l oa ob">transform_categorical(X)<br/>scale_numerical(X)</span></pre><p id="9782" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">因此，我有以下输入数据集:</p><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj oe"><img src="../Images/3d2f8e30aaf9b913fa08b65032204a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LB16bhUZPz4_9yUjXtUduw.png"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="ec71" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我将数据集分为训练集和测试集:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="924a" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = <strong class="nt jg">train_test_split</strong>(X, y, test_size=0.20, random_state=42)</span></pre><p id="8398" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我定义了一个辅助函数，它接收模型作为输入，然后对其进行训练和测试:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="8a59" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error<br/>import numpy as np</span><span id="8657" class="nx mw iw nt b gz oc nz l oa ob">def <strong class="nt jg">run_experiment</strong>(model):<br/>    model.fit(X_train, y_train)<br/>    y_pred = model.predict(X_test)<br/>    print("R^2 : ", r2_score(y_test, y_pred))<br/>    print("MAE :", mean_absolute_error(y_test,y_pred))<br/>    print("RMSE:",np.sqrt(mean_squared_error(y_test, y_pred)))</span></pre><p id="c286" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在我建立一个线性回归模型，并测试它的性能:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="faa7" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.linear_model import LinearRegression<br/>model = <strong class="nt jg">LinearRegression</strong>()<br/>run_experiment(model)</span></pre><p id="85bb" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为输出，<code class="fe of og oh nt b">run_experiment()</code>函数返回以下结果:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="1f01" class="nx mw iw nt b gz ny nz l oa ob">R^2 :  0.6508427991759342<br/>MAE : 0.07476031320105749<br/>RMSE: 0.09761343652989583</span></pre><p id="8c64" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我还建立了另一个回归模型，基于随机梯度下降:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="9f84" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.linear_model import SGDRegressor<br/>model = SGDRegressor()<br/>run_experiment(model)</span></pre><p id="2d04" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为输出，我得到了以下结果:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="fc29" class="nx mw iw nt b gz ny nz l oa ob">R^2 :  0.6243269738606405<br/>MAE : 0.07703814197219305<br/>RMSE: 0.10125211591520658</span></pre><p id="7b3d" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">两个实验的比较表明，线性回归器具有较低的 RMSE，因此它优于另一个模型。</p><h1 id="1463" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">3 分类</h1><p id="d06c" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">最常见的分类评估指标有:</p><ul class=""><li id="824a" class="mh mi iw ln b lo lp lr ls lu mj ly mk mc ml mg mm mn mo mp bi translated"><strong class="ln jg">精确</strong>——在所有积极的预测中，数一数有多少是真正积极的。</li><li id="73c3" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><strong class="ln jg">回忆</strong> —在所有真正的阳性病例中，统计有多少被预测为阳性。</li><li id="5dd1" class="mh mi iw ln b lo mq lr mr lu ms ly mt mc mu mg mm mn mo mp bi translated"><strong class="ln jg">准确性</strong> —在所有案例中，计算有多少案例被正确预测。</li></ul><p id="14d1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">作为分类任务，我考虑目标类(红/白)的预测。因此，我构建 X 和 y 变量如下:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="b54a" class="nx mw iw nt b gz ny nz l oa ob">X = df.drop("target", axis = 1)<br/>y = df["target"]</span></pre><p id="142c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我将分类列转换为数字列，然后缩放所有数字列:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="3e85" class="nx mw iw nt b gz ny nz l oa ob">transform_categorical(X)<br/>scale_numerical(X)</span></pre><p id="ed99" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我还对目标类进行了编码:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="e7d0" class="nx mw iw nt b gz ny nz l oa ob">label_encoder = LabelEncoder()<br/>y = label_encoder.fit_transform(y)</span></pre><p id="2558" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我将数据集分为训练集和测试集:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="22df" class="nx mw iw nt b gz ny nz l oa ob">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)</span></pre><p id="4bd6" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">现在，我定义一个辅助函数，它接收模型作为输入，通过计算之前定义的指标来训练和测试它:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="bfd3" class="nx mw iw nt b gz ny nz l oa ob">def <strong class="nt jg">run_experiment</strong>(model):<br/>    model.fit(X_train, y_train)<br/>    <br/>    y_pred = model.predict(X_test)<br/>    <br/>    plot_confusion_matrix(model, X_test, y_test, cmap='GnBu')<br/>    plt.show()</span><span id="f38c" class="nx mw iw nt b gz oc nz l oa ob">    print('Precision: %.3f' % precision_score(y_test, y_pred))<br/>    print('Recall: %.3f' % recall_score(y_test, y_pred))<br/>    print('F1: %.3f' % f1_score(y_test, y_pred))<br/>    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))</span></pre><p id="ef35" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我构建了一个随机森林分类器，然后计算它的性能:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="7ceb" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.ensemble import RandomForestClassifier</span><span id="39ca" class="nx mw iw nt b gz oc nz l oa ob">model = RandomForestClassifier()<br/>run_experiment(model)</span></pre><p id="23b1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该函数返回以下输出:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="bfda" class="nx mw iw nt b gz ny nz l oa ob">Precision: 0.994<br/>Recall: 0.999<br/>F1: 0.996<br/>Accuracy: 0.995</span></pre><p id="63f0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我还训练了一个决策树分类器:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="7cec" class="nx mw iw nt b gz ny nz l oa ob">from sklearn.tree import DecisionTreeClassifier</span><span id="04ee" class="nx mw iw nt b gz oc nz l oa ob">model = DecisionTreeClassifier()<br/>run_experiment(model)</span></pre><p id="a13e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该函数返回以下输出:</p><pre class="kv kw kx ky gu ns nt nu nv aw nw bi"><span id="8720" class="nx mw iw nt b gz ny nz l oa ob">Precision: 0.992<br/>Recall: 0.985<br/>F1: 0.988<br/>Accuracy: 0.983</span></pre><p id="b29e" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">就准确性而言，随机森林分类器的性能优于决策树分类器。</p><h1 id="6abe" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">摘要</h1><p id="d55e" class="pw-post-body-paragraph ll lm iw ln b lo nn kg lq lr no kj lt lu np lw lx ly nq ma mb mc nr me mf mg ip bi translated">恭喜你！您刚刚学习了如何在 scikit-learn 中为分类和回归执行模型评估。所描述的技术没有考虑参数优化，因为本文的目的是展示最常见的评估指标。</p><p id="57c1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你读到这里，对我来说，今天已经很多了。谢谢！你可以在<a class="ae lk" href="https://alod83.medium.com/which-topics-would-you-like-to-read-c68314dc6813" rel="noopener">这篇文章</a>中读到更多关于我的内容。</p><h1 id="d065" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">相关文章</h1><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/an-overview-of-the-scikit-learn-clustering-package-d39a0499814"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">scikit-learn 集群包概述</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">scikit-learn 系列的第二集，解释了用于机器学习的著名 Python 库</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz le ol"/></div></div></a></div><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/an-overview-of-the-scikit-learn-library-episode-1-preprocessing-9b17ab4dde4f"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">Scikit-learn 库概述—第 1 集预处理</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">著名的用于机器学习的 Python 库的剧集中的描述。第一集讲的是…</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz le ol"/></div></div></a></div><div class="oi oj gq gs ok ol"><a rel="noopener follow" target="_blank" href="/understanding-the-n-jobs-parameter-to-speedup-scikit-learn-classification-26e3d1220c28"><div class="om ab fp"><div class="on ab oo cl cj op"><h2 class="bd jg gz z fq oq fs ft or fv fx jf bi translated">了解 n_jobs 参数以加速 scikit-learn 分类</h2><div class="os l"><h3 class="bd b gz z fq oq fs ft or fv fx dk translated">一段现成的代码，演示了使用 n_jobs 参数如何减少培训时间</h3></div><div class="ot l"><p class="bd b dl z fq oq fs ft or fv fx dk translated">towardsdatascience.com</p></div></div><div class="ou l"><div class="pb l ow ox oy ou oz le ol"/></div></div></a></div><h1 id="7cd5" class="mv mw iw bd mx my mz na nb nc nd ne nf kl ng km nh ko ni kp nj kr nk ks nl nm bi translated">从社区收集的文章</h1><div class="oi oj gq gs ok"><div role="button" tabindex="0" class="ab bv gw cb fq pc pd bn pe le ex"><div class="pf l"><div class="ab q"><div class="l di"><img alt="Angelica Lo Duca" class="l de bw pg ph fe" src="../Images/44c4582bc0bc17c1538f0a544262d2b7.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*aJAYMw9TJpvhBsfQHE4WZw.jpeg"/><div class="fb bw l pg ph fc n aw fd"/></div><div class="hk l fp"><p class="bd b dl z fq fr fs ft fu fv fw fx dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://alod83.medium.com/?source=post_page-----abce32ee4a99--------------------------------" rel="noopener follow" target="_top">安吉莉卡·洛·杜卡</a></p></div></div><div class="pk pl gx l"><h2 class="bd jg uz mh fq va fs ft or fv fx jf bi translated">评估指标</h2></div><div class="ab q"><div class="l fp"><a class="bd b be z bi vb au vc vd ve rd vf an eh ei vg vh vi el em eo de bk ep" href="https://alod83.medium.com/list/evaluation-metrics-e157b6c7fea6?source=post_page-----abce32ee4a99--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vj l fp"><span class="bd b dl z dk">2 stories</span></div></div></div><div class="px dh py fq ab pz fp di"><div class="di pp bv pq pr"><div class="dh l"><img alt="" class="dh" src="../Images/e41ec1f7bcd04b7c98af6e90e2db8346.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*E-kl2dexBk-KGyi2"/></div></div><div class="di pp bv ps pt pu"><div class="dh l"><img alt="" class="dh" src="../Images/89a42ef2c9d36fb08fc34910ef483061.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/0*z_B1Ps9MIUVhgdQk"/></div></div><div class="di bv pv pw pu"><div class="dh l"><div class="qa qb qc l nw"/></div></div></div></div></div><div class="oi oj gq gs ok"><div role="button" tabindex="0" class="ab bv gw cb fq pc pd bn pe le ex"><div class="pf l"><div class="ab q"><div class="l di"><img alt="Angelica Lo Duca" class="l de bw pg ph fe" src="../Images/44c4582bc0bc17c1538f0a544262d2b7.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*aJAYMw9TJpvhBsfQHE4WZw.jpeg"/><div class="fb bw l pg ph fc n aw fd"/></div><div class="hk l fp"><p class="bd b dl z fq fr fs ft fu fv fw fx dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://alod83.medium.com/?source=post_page-----abce32ee4a99--------------------------------" rel="noopener follow" target="_top">当归罗杜卡</a></p></div></div><div class="pk pl gx l"><h2 class="bd jg uz mh fq va fs ft or fv fx jf bi translated">数据分析</h2></div><div class="ab q"><div class="l fp"><a class="bd b be z bi vb au vc vd ve rd vf an eh ei vg vh vi el em eo de bk ep" href="https://alod83.medium.com/list/data-analysis-f9326d4a0ec7?source=post_page-----abce32ee4a99--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vj l fp"><span class="bd b dl z dk">4 stories</span></div></div></div><div class="px dh py fq ab pz fp di"><div class="di pp bv pq pr"><div class="dh l"><img alt="" class="dh" src="../Images/a8d3b7a00ffa12ceaa7ea2f4354c1f54.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*j0TmNeX8dnSfcEnEH4KF0A.png"/></div></div><div class="di pp bv ps pt pu"><div class="dh l"><img alt="" class="dh" src="../Images/821a500e022c06fa7da68705af86916c.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*mS_Ix9xschUWuAwjLHYHRg.png"/></div></div><div class="di bv pv pw pu"><div class="dh l"><img alt="" class="dh" src="../Images/02be5f590a0b79ccf3733fd22f208f43.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*l2j1m2WR6aXJbU1_7dIbbg.jpeg"/></div></div></div></div></div></div></div>    
</body>
</html>