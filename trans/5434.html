<html>
<head>
<title>Large-Scale Knowledge Graph Completion on Graphcore IPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Graphcore IPUs 上的大规模知识图完成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/large-scale-knowledge-graph-completion-on-ipu-4cf386dfa826#2022-12-06">https://towardsdatascience.com/large-scale-knowledge-graph-completion-on-ipu-4cf386dfa826#2022-12-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b5d3" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">neur IPS 2022 OGB-LSC 知识图表竞赛的获胜者</h2><div class=""/><div class=""><h2 id="2195" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">通过快速实验、仔细调谐和大型集合进行准确预测</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/0ac358761dc25f7f986925eaf3b31552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTkqYMhcM5t4VqHwaPERiQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">知识图嵌入模型的计算图的绘制。图片作者。</p></figure><p id="e5ba" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi ma translated">表示图结构数据的机器学习方法变得越来越重要。该领域研究人员面临的主要挑战之一是模型对大型数据集的可扩展性。作为<a class="ae mj" href="https://neurips.cc/Conferences/2022/CompetitionTrack" rel="noopener ugc nofollow" target="_blank"> NeurIPS 2022 竞赛赛道计划</a>的一部分，<a class="ae mj" href="https://ogb.stanford.edu/docs/lsc/" rel="noopener ugc nofollow" target="_blank"> Open Graph Benchmark 大规模挑战赛(OGB-LSC) </a>旨在通过鼓励 graph ML 研究社区与实际大小的数据集合作，开发能够满足现实世界需求的解决方案，来推动图形表示学习的边界。</p><p id="4b43" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这篇博文中，我们展示了 Graphcore 提交给<a class="ae mj" href="https://ogb.stanford.edu/neurips2022/" rel="noopener ugc nofollow" target="_blank"> OGB-LSC@NeurIPS 2022 </a>知识图谱的获奖作品。我们深入探讨了机器学习模型、数据集考虑因素、集成策略以及我们实现这一成功的高效执行方案。关于我们方法的更深入的信息可以在<a class="ae mj" href="https://arxiv.org/abs/2211.12281" rel="noopener ugc nofollow" target="_blank">论文</a>【1】中找到。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="14b4" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">什么是知识图？</h2><p id="82b8" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">知识图是通过捕捉现实世界实体之间的关系来构建和表示知识的一种非常自然的方式。事实表示为三元组(<em class="no">头</em>、<em class="no">关系</em>、<em class="no">尾</em>)，其中关系描述了<em class="no">头</em>和<em class="no">尾</em>实体之间的链接。例如，三联(<em class="no">杰弗里·辛顿</em>、<em class="no">毕业于</em>、<em class="no">剑桥大学国王学院</em>)是图 1 中知识图陈述的七个事实之一。知识图的应用范围从<a class="ae mj" href="https://arxiv.org/abs/2102.10062" rel="noopener ugc nofollow" target="_blank">药物发现</a>到<a class="ae mj" href="https://aclanthology.org/P17-1021/" rel="noopener ugc nofollow" target="_blank">问答</a>和<a class="ae mj" href="https://dl.acm.org/doi/abs/10.1145/2939672.2939673" rel="noopener ugc nofollow" target="_blank">推荐系统</a>【2–4】。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/5b04f9ba55592d3cd607b40e460bcd96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V1NLVyrkNSK2tOG7sOphTg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 WikiKG90Mv2 知识图的一个小子图。一个可能的查询可能是(Geoffrey Hinton，出生于？).图片作者。改编自[5]。</p></figure><p id="13fa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">知识图嵌入(KGE)模型通过学习低维向量空间中的实体和关系的嵌入来对知识图进行推理，使得三元组的似然性通过头部、关系和尾部嵌入的评分函数来测量。通过最大化阳性样本的分数和最小化阴性样本的分数，在阳性(真实)三元组和阴性(随机抽取)三元组的批次上训练 KGE 模型。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/dc10061bb2004c0ff56a3143bc6ceaad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoP6evP0nHvHHNuCtdmWEg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 2:评分函数的三个不同例子:TransE 度量头+关系和尾嵌入之间的距离；TransH 在应用 TransE 之前将头部和尾部嵌入投影到依赖关系的超平面上；在 RotatE 中，该关系描述了复数值头嵌入的旋转。在所有三个模型中，负距离可以用作分数。图片作者。</p></figure><p id="76aa" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">虽然知识图文献通常关注相对较小的图，但是商业价值的实际应用越来越需要在具有数亿甚至数十亿个实体和三元组的图上进行推理。WikiKG90Mv2 是基于 Wikidata 的大规模知识图，由超过 9000 万个节点和 6 亿个三元组组成。知识图通常是不完整的:虽然现有的三元组可以被认为是真实的，但两个实体之间没有关系就没有真值。因此比赛的任务是完成三个一组的形式(<em class="no">头</em>、<em class="no">关系</em>、<em class="no">？</em>)，比如(<em class="no">杰弗里·辛顿</em>、<em class="no">出生于</em>、<em class="no">？</em>)，见图 1。WikiKG90Mv2 数据集的巨大规模是实现快速准确的知识图完成模型的主要挑战之一，因为我们最大的模型消耗超过 300 GiB 的参数、优化器状态和功能。为了克服这个问题，我们实现了 BESS(平衡实体采样和共享)，这是一个用于训练 KGE 模型的分布式处理方案，可以有效地平衡多个工作人员的通信和计算。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="d75a" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">基于 BESS 的分布式知识图训练</h2><p id="859d" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">BESS 在<em class="no"> D </em>个可用的工人中随机且均匀地划分实体嵌入集。这导致将数据集中的三元组划分为<em class="no"> D </em>桶<em class="no"> {T </em> ₘₙ <em class="no">，m，n = 1，…，D} </em>，其中<em class="no"> T </em> ₘₙ是一组三元组，头实体存储在 worker <em class="no"> m </em>上，尾实体存储在 worker <em class="no"> n </em>上。然后，在培训时，对每个工人<em class="no"> m </em>从<em class="no"> {T </em> ₘₙ <em class="no">，n=1，…，D} </em>中统一抽取一批。类似地，对于每个小批量<em class="no"> </em> BESS 从所有可用的工人中统一抽取尾部来构建负样本。这些阴性样本在微量批次中的所有三个样本中共享，以增加有效的阴性样本量，而不增加阴性样本交流和评分的成本</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nr"><img src="../Images/3a0d23e2331064ee2bb1c21ba71b26c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*tmmCiOvGkKc9NkoZ-vhpXA.gif"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者制作的动画。</p></figure><p id="9622" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因为与实体的数量相比，不同关系类型的数量通常很少，所以关系嵌入在所有工人之间复制，并使用<em class="no"> AllGather </em>操作进行更新。</p><p id="13e3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在推理时，对于一个给定的查询(<em class="no">头</em>、<em class="no">关系</em>、<em class="no">？并且返回前 K 个结果的有序列表。</em></p><p id="3af3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">BESS 方法保证了只有尾部嵌入必须在工人之间交换。同时，它平衡了计算和工作人员之间的通信。我们在 Graphcore Bow Pod16 上使用 BESS 训练 KGE 模型，它受益于在快速 IPU-IPU 链路上运行的集体通信，这使得单独的参数服务器变得过时。此外，14.4 GB 的处理器内存允许在整个系统中高效地使用 DRAM 的总带宽。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="53f7" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">匹配数据集分布</h2><p id="fb74" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">正如挑战组织者所详述的，验证和测试数据集是通过采样三元组创建的，使得关系类型的计数与原始关系计数的立方根成比例。如果不相应地调整来自训练数据集的采样，这将导致严重的泛化差距。因此，我们偏置训练三元组的样本，使得关系类型的结果分布与训练数据集中关系类型计数的立方根相匹配。此程序将训练期间使用的不同关系类型的频率与验证和测试集中的关系分布对齐，并减少训练和验证 MRR 之间的差距(图 3)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/88d582ab919338a419b2735e9d4ab72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*huJUzRkEQa6gthCs7YkRug.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 3:立方根抽样策略调整了关系类型的训练和验证/测试分布(左)，并减少了训练和验证 MRR 之间的差距(右)。图片作者。</p></figure></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="5530" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">多样化的组合，以获得最佳的所有世界</h2><p id="2840" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">BESS 在<a class="ae mj" href="https://www.graphcore.ai/bow-processors" rel="noopener ugc nofollow" target="_blank"> Graphcore Bow Pod16 </a>上实现的吞吐量使我们能够训练 85 个 KGE 模型的非常多样化的集合，该集合结合了五个不同的评分函数(<a class="ae mj" href="https://papers.nips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf" rel="noopener ugc nofollow" target="_blank">转移</a>、<a class="ae mj" href="https://ojs.aaai.org/index.php/AAAI/article/view/8870" rel="noopener ugc nofollow" target="_blank">转移</a>、<a class="ae mj" href="https://arxiv.org/abs/1902.10197" rel="noopener ugc nofollow" target="_blank">旋转</a>、<a class="ae mj" href="https://arxiv.org/abs/1412.6575" rel="noopener ugc nofollow" target="_blank">分散</a>、<a class="ae mj" href="http://proceedings.mlr.press/v48/trouillon16.pdf" rel="noopener ugc nofollow" target="_blank">复杂</a>、【6–10】)和两个不同的损失函数。每个评分函数都有不同的优点和缺点，如表 1 中所总结的，使得具有不同评分函数的模型集合特别有前途。为了进一步提高模型的多样性，我们采用了两种不同的损失函数:log-sigmoid 损失和采样 softmax 交叉熵损失。详见<a class="ae mj" href="https://arxiv.org/abs/2211.12281" rel="noopener ugc nofollow" target="_blank">文件</a>【1】。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/de45ccf1bfb06cf420090dd02a33e4f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkfGE5X1DZAA7XTpXXTCHg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表 1:评分函数及其模拟基本关系属性的能力:S =对称性；AS =反对称性；I =反转；C =构成。图片作者。</p></figure><p id="9cc5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">除了知识图的结构(三元组的集合)，WikiKG90Mv2 数据集为每个实体和关系提供了 768 维的特征向量。我们的模型通过使用可学习的权重矩阵将实体特征投影到实体嵌入空间并将结果添加到可学习的实体嵌入中来利用实体特征。由于不同关系类型的数量很少，我们假设关系特征对于学习良好的关系嵌入并不重要，因此我们在模型中忽略了这些特征。</p><p id="614a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">多个模型的预测使用幂秩集合策略进行组合，概括[11]。每个预测尾部实体根据其在各个预测中排名的平方根倒数获得一个分数:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/402dbadb598c5211ee0f8805ed3a6a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJUxd9PJoYqR8H7o69xsrQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片作者。</p></figure><p id="034c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然后，通过使用该分数对实体进行排名来选择最终预测。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="5dc8" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">结果</h2><p id="7506" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">我们对各种模型进行了训练，验证平均倒数等级(MRR)至少为 0.2，其中最佳的单个模型达到了 0.243 的 MRR(图 4)。我们发现，根据评分函数的不同，模型在不同程度上有助于集成:尽管个体验证的 mrr 较低，但 DistMult 和 ComplEx 模型在集成中表现得非常好(图 4)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/7396d23069f35810400d57d2bbf1759b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wP9a4vQOH7jBd3HWOj3FQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图 4:每个评分函数的 K 个最佳个体模型(虚线)和 K 个最佳模型集合(实线)的验证 MRR。图片作者。</p></figure><p id="b28f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">基于这一证据，我们选择了一个由 85 个 KGE 模型组成的集合(25 个最佳 trans、DistMult 和 ComplEx 模型，以及 5 个最佳 trans 和 RotatE 模型)，在测试-挑战数据集上实现了 0.2922 的验证 MRR 和 0.2562 的 MRR，<a class="ae mj" href="https://ogb.stanford.edu/neurips2022/results/#winners_wikikg90mv2" rel="noopener ugc nofollow" target="_blank">赢得了 2022 年开放图基准大规模挑战</a>的 WikiKG90Mv2 赛道。</p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><p id="c104" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi ma translated">对大量知识图进行快速准确的推理是一项重要而又富有挑战性的机器学习应用。我们使用一种新颖的分布框架来提高 KGE 模型对大型图形的可伸缩性，并展示了良好调整的模型的多样性集合的优势。虽然这些方法不是灵丹妙药，但我们希望我们的见解有助于社区创建快速准确的知识图嵌入模型，并加速它们在现实世界应用中的采用。</p><p id="8e90" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae mj" href="https://arxiv.org/abs/2211.12281" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">读论文</strong> </a> <strong class="lg ja"> | </strong> <a class="ae mj" href="https://github.com/graphcore/distributed-kge-poplar" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">访问代码</strong> </a></p></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h2 id="83aa" class="mr ms iq bd mt mu mv dn mw mx my dp mz ln na nb nc lr nd ne nf lv ng nh ni iw bi translated">参考</h2><p id="df83" class="pw-post-body-paragraph le lf iq lg b lh nj ka lj lk nk kd lm ln nl lp lq lr nm lt lu lv nn lx ly lz ij bi translated">[1] A. Cattaneo，D. Justus，H. Mellor，D. Orr，J. Maloberti，Z. Liu，T. Farnsworth，A. Fitzgibbon，B. Banaszewski，C. Luschi，<a class="ae mj" href="https://arxiv.org/abs/2211.12281" rel="noopener ugc nofollow" target="_blank"> BESS:面向大规模知识图完成的平衡实体采样与共享</a> (2022)，<em class="no"> arXiv 预印本 arXiv:2211.12281 </em>。</p><p id="a0fe" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2] S. Bonner，I.P. Barrett，C. Ye，R. Swiers，O. Engkvist，A. Bender，C.T. Hoyt，W.L. Hamilton，<a class="ae mj" href="https://arxiv.org/abs/2102.10062" rel="noopener ugc nofollow" target="_blank">与药物发现相关的生物医学数据集回顾:知识图视角</a> (2022)，<em class="no">生物信息学简报</em>，<em class="no"> 23 </em> (6)，第 bbac404 页。</p><p id="5f58" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[3]郝，张，刘，何，刘，吴，赵，<a class="ae mj" href="https://aclanthology.org/P17-1021/" rel="noopener ugc nofollow" target="_blank"/>(2017)，计算语言学协会第 55 届年会论文集<em class="no">(第一卷:长论文)</em>(第 221-231 页)。</p><p id="e3ef" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[4] F. Zhang，N.J. Yuan，D. Lian，X. Xie，W.Y. Ma，<a class="ae mj" href="https://dl.acm.org/doi/10.1145/2939672.2939673" rel="noopener ugc nofollow" target="_blank">面向推荐系统的协同知识库嵌入</a> (2016)，载于<em class="no">第 22 届 ACM SIGKDD 知识发现与数据挖掘国际会议论文集</em>(第 353–362 页)。</p><p id="dc5d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[5] W. Hu，M. Fey，H. Ren，M. Nakata，Y. Dong，J. Leskovec，<a class="ae mj" href="https://arxiv.org/abs/2103.09430" rel="noopener ugc nofollow" target="_blank">-LSC:机器学习对图的大规模挑战</a> (2021)，<em class="no"> arXiv 预印本 arXiv:2103.09430 </em>。</p><p id="7888" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[6] A. Bordes，N. Usunier，A. Garcia-Duran，J. Weston，O. Yakhnenko，<a class="ae mj" href="https://papers.nips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf" rel="noopener ugc nofollow" target="_blank">翻译用于多关系数据建模的嵌入</a> (2013)。<em class="no">神经信息处理系统的进展</em>、<em class="no"> 26 </em>。</p><p id="1127" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[7] Z. Wang，J. Zhang，J. Feng，Z. Chen，<a class="ae mj" href="https://ojs.aaai.org/index.php/AAAI/article/view/8870" rel="noopener ugc nofollow" target="_blank">超平面上平移的知识图嵌入</a> (2014)，<em class="no">AAAI 人工智能会议论文集</em>(第 28 卷第 1 期)。</p><p id="cd9c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[8] Z. Sun，Z.H. Deng，J.Y. Nie，J. Tang，<a class="ae mj" href="https://arxiv.org/abs/1902.10197" rel="noopener ugc nofollow" target="_blank">旋转:复空间中关系旋转的知识图嵌入</a> (2019)，<em class="no"> arXiv 预印本 arXiv:1902.10197 </em>。</p><p id="c47a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[9] B. Yang，W.T. Yih，X. He，J. Gao，L. Deng，<a class="ae mj" href="https://arxiv.org/abs/1412.6575" rel="noopener ugc nofollow" target="_blank">在知识库中嵌入用于学习和推理的实体和关系</a> (2014)，<em class="no"> arXiv 预印本 arXiv:1412.6575 </em>。</p><p id="8e44" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[10] T. Trouillon，C.R. Dance，J. Welbl，S. Riedel，e .Gaussier，G. Bouchard，<a class="ae mj" href="http://proceedings.mlr.press/v48/trouillon16.pdf" rel="noopener ugc nofollow" target="_blank">通过复张量分解的知识图完成</a> (2017)，<em class="no"> arXiv 预印本 arXiv:1702.06879 </em>。</p><p id="41f0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[11] G.V .科马克，C.L. Clarke，S. Buettcher，<a class="ae mj" href="https://dl.acm.org/doi/10.1145/1571941.1572114" rel="noopener ugc nofollow" target="_blank">互逆秩融合优于孔多塞和个体秩学习方法</a> (2009)，在<em class="no">第 32 届国际 ACM SIGIR 信息检索研究与发展会议论文集</em>(第 758-759 页)中。</p></div></div>    
</body>
</html>