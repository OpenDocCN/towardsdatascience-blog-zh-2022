<html>
<head>
<title>Stat Stories: Normalizing Flows as an Application of Variable Transformation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Stat Stories:将流程规范化作为变量转换的应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stat-stories-normalizing-flows-as-an-application-of-variable-transformation-7b7beda7b03b#2022-10-12">https://towardsdatascience.com/stat-stories-normalizing-flows-as-an-application-of-variable-transformation-7b7beda7b03b#2022-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b72d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">易处理分布的生成模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cd374d4517da07f232327bf347a6c89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1bWrErb0X3_DIG7oKLjdg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">加利福尼亚州的箭头湖，图片由作者提供</p></figure><p id="eaa7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">在我之前的<em class="md">统计故事</em>系列的集中，我谈到了生成新分布的变量转换方法。对单变量和多变量分布的变量转换的讨论导致<strong class="la iu">标准化流程</strong>。</p><p id="8c6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我推荐阅读关于生成新分布的变量转换的讨论，作为理解规范化流程的先决条件。</p><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">统计故事:生成新分布的变量转换</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">统计分布的变换</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ks mh"/></div></div></a></div><div class="me mf gp gr mg mh"><a rel="noopener follow" target="_blank" href="/stat-stories-multivariate-transformation-for-statistical-distributions-7077a374b3b4"><div class="mi ab fo"><div class="mj ab mk cl cj ml"><h2 class="bd iu gy z fp mm fr fs mn fu fw is bi translated">统计故事:统计分布的多元变换</h2><div class="mo l"><h3 class="bd b gy z fp mm fr fs mn fu fw dk translated">标准化流程的先驱</h3></div><div class="mp l"><p class="bd b dl z fp mm fr fs mn fu fw dk translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="mw l ms mt mu mq mv ks mh"/></div></div></a></div><h1 id="5c16" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated"><strong class="ak">简介</strong></h1><p id="0f21" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">统计机器学习中的一个大挑战是，如果我们已经从某个分布中获得了样本，就要对概率分布进行建模。<a class="ae nu" href="https://www.researchgate.net/profile/Martin-Cadeiras/publication/220385824_Clustering_and_Classification_through_Normalizing_Flows_in_Feature_Space/links/54da12330cf2464758204dbb/Clustering-and-Classification-through-Normalizing-Flows-in-Feature-Space.pdf" rel="noopener ugc nofollow" target="_blank"> Tabak和VandenEijnden【2010】</a>以及Tabak和Turner【2013】在聚类、分类和密度估计的背景下首次提出了流的标准化。</p><p id="07f7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">定义</strong>:标准化流程可以定义为将简单的概率分布(如均匀分布)转换为复杂的分布(如通过应用一系列可逆转换，可以为您提供猫图像的随机样本)。</p><p id="36a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为一系列可逆变换的结果，我们可以通过选择一个简单的初始密度函数，然后将一些参数化的、可逆的和可微的变换链接在一起，获得<a class="ae nu" href="https://rahulbhadani.medium.com/stat-stories-common-families-of-statistical-distributions-part-2-4bdea86c3132?source=user_profile---------1----------------------------" rel="noopener">新的分布族</a>。这样，我们可以获得对应于新密度的样本。</p><p id="9166" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">需要注意的一点是，在规范化流的上下文中，与我在<a class="ae nu" href="https://rahulbhadani.medium.com/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30" rel="noopener">https://rahulbhadani . medium . com/stat-stories-variable-transformation-to-generate-new-distributions-d 4607 CB 32 c 30</a>中最初的讨论相比，转换是参数化的，在那里我使用的转换不包含任何参数。然而，想法保持不变。</p><p id="7955" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们再次看看变量变换的公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/15b3f40c7ddeb9ae688e1984e04764a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*giKWsw-VAMxtC70J.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式1。多元分布的转换公式(由作者创建)</p></figure><p id="acd5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="md"> U </em>是新分布的多元随机向量，X是原始初始分布的多元随机向量。<em class="md"> J </em>是雅可比的。在规范化流的上下文中，新的密度函数<em class="md"> fᵤ </em>被称为<em class="md">向前推，</em>和<em class="md"> g </em>被称为生成器。这种从最初的简单密度到最终的复杂密度的运动称为生成方向。反函数g⁻沿称为<em class="md">归一化方向</em>的相反方向移动。这就是为什么整个转换过程被称为规范化流程。为了生成对应于<em class="md"> U的数据点，</em>应用变换<strong class="la iu">U</strong>=<em class="md">g</em>(<strong class="la iu">x</strong>)。</p><p id="5483" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于规范化流程定义的更详细和正式的方法，我推荐看一下<strong class="la iu">规范化流程:当前方法的介绍和回顾【https://arxiv.org/pdf/1908.09257.pdf】(<a class="ae nu" href="https://arxiv.org/pdf/1908.09257.pdf" rel="noopener ugc nofollow" target="_blank"/>)T21。</strong></p><h1 id="2e2c" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">标准化流程的应用</h1><p id="4b54" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">虽然诸如生成对抗网络(GAN)和变分自动编码器(VAN)的其他统计方法已经能够在诸如学习图像的分布和其他复杂数据集的困难任务上执行引人注目的结果，但是它们不允许评估密度估计和计算新数据点的概率密度。从这个意义上说，让流动正常化是有说服力的。该方法可以执行密度估计和采样以及变分推断。</p><h2 id="6984" class="nw my it bd mz nx ny dn nd nz oa dp nh lh ob oc nj ll od oe nl lp of og nn oh bi translated">密度估计和抽样</h2><p id="dd53" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">考虑一个变换<strong class="la iu">u</strong>=<em class="md">g</em>(<strong class="la iu">x；</strong> <em class="md"> θ </em>，即<em class="md"> g </em>由参数向量<em class="md"> θ </em>参数化。初始概率密度函数<em class="md"> fₓ </em>由向量<em class="md"> φ </em>参数化，即<em class="md"> fₓ(x | φ)。</em>如果我们有对应于期望分布F_U的样本点𝓓，那么我们可以如下执行参数<em class="md">θ=(θ，φ) </em>的对数似然估计:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/f59d8c4470b749db1984542f15695393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PRwgSwWIi9aWATA1ES2BMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式2:对数似然估计(由作者创建)</p></figure><p id="d2c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在神经网络训练期间，参数进化以最大化对数似然。在选择诸如对抗性损失的损失函数时，有许多选择可以做出，但是选择完全取决于应用。</p><p id="c562" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下一篇文章中，我将从更广泛的背景中单独讨论<strong class="la iu">变分推理</strong>。请务必<a class="ae nu" href="https://rahulbhadani.medium.com/subscribe" rel="noopener">订阅我的电子邮件列表</a>以收到相关通知。同时，让我们看一些使用Python的代码。</p><h2 id="0f0e" class="nw my it bd mz nx ny dn nd nz oa dp nh lh ob oc nj ll od oe nl lp of og nn oh bi translated">例子</h2><p id="9928" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">例如，我将使用Flowtorch库，它可以通过</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="7e6d" class="nw my it ok b gy oo op l oq or">pip install flowtorch</span></pre><p id="cf9c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在我的<a class="ae nu" rel="noopener" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30">前几篇文章</a>中，我手动推导了转换后的密度函数，我们可以使用Flowtorch的标准化流程实现来学习转换和估计密度。</p><p id="14d7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看两个同心圆数据集的样本</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="d458" class="nw my it ok b gy oo op l oq or">import numpy as np<br/>from sklearn import datasets<br/>from sklearn.preprocessing import StandardScaler<br/><br/>n_samples = 1000<br/>X, y = datasets.make_circles(n_samples=n_samples, factor=0.5, noise=0.05)<br/>X = StandardScaler().fit_transform(X)<br/><br/>plt.title(r'Samples from $p(x_1,x_2)$')<br/>plt.xlabel(r'$x_1$')<br/>plt.ylabel(r'$x_2$')<br/>plt.scatter(X[:,0], X[:,1], alpha=0.5)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/2b145c8dc3d3779343ed9fc040b0fa99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*ewHbjlImKQUrVw78p716VQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">同心圆数据集的样本:联合分布(由作者创建)</p></figure><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="5417" class="nw my it ok b gy oo op l oq or">plt.subplot(1, 2, 1)<br/>sns.distplot(X[:,0], <em class="md">hist</em><strong class="ok iu">=</strong>False, <em class="md">kde</em><strong class="ok iu">=</strong>True,<br/><em class="md">bins</em><strong class="ok iu">=</strong>None,<em class="md">hist_kws</em><strong class="ok iu">=</strong>{'edgecolor':'black'}, <em class="md">kde_kws</em><strong class="ok iu">=</strong>{'linewidth': 2})</span><span id="324d" class="nw my it ok b gy ot op l oq or">plt.title(<strong class="ok iu">r</strong>'$p(x_1)$')<br/>plt.subplot(1, 2, 2)<br/>sns.distplot(X[:,1], <em class="md">hist</em><strong class="ok iu">=</strong>False, <em class="md">kde</em><strong class="ok iu">=</strong>True, <em class="md">bins</em><strong class="ok iu">=</strong>None, <em class="md">hist_kws</em><strong class="ok iu">=</strong>{'edgecolor':'black'}, <em class="md">kde_kws</em><strong class="ok iu">=</strong>{'linewidth': 2})</span><span id="86ac" class="nw my it ok b gy ot op l oq or">plt.title(<strong class="ok iu">r</strong>'$p(x_2)$')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/f65e7d193ed9b061c1d97263373ff91d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*-z6hvs6b3iYdYWv9t6ttqw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">边缘分布(由作者创建)</p></figure><p id="9b04" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以学习边际变换<code class="fe ov ow ox ok b">bij.Spline.</code>节点和样条的导数充当可以使用随机梯度下降学习的参数:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="eef4" class="nw my it ok b gy oo op l oq or">dist_x = torch.distributions.Independent(<br/>  torch.distributions.Normal(torch.zeros(2), torch.ones(2)), <br/>  1<br/>)<br/>bijector = bij.Spline()<br/>dist_y = dist.Flow(dist_x, bijector)</span><span id="fd1c" class="nw my it ok b gy ot op l oq or"><br/>optimizer = torch.optim.Adam(dist_y.parameters(), lr=1e-2)<br/>steps = 5000</span><span id="66ce" class="nw my it ok b gy ot op l oq or">X = torch.Tensor(X)<br/>for step in range(steps):<br/>    optimizer.zero_grad()<br/>    loss = -dist_y.log_prob(X).mean()<br/>    loss.backward()<br/>    optimizer.step()<br/><br/>    if step % 200 == 0:<br/>        print('step: {}, loss: {}'.format(step, loss.item()))</span></pre><p id="8d85" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以根据学习后的变换分布绘制样本:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="5d39" class="nw my it ok b gy oo op l oq or">X_flow = dist_y.sample(torch.Size([1000,])).detach().numpy()<br/>plt.title(r'Joint Distribution')<br/>plt.xlabel(r'$x_1$')<br/>plt.ylabel(r'$x_2$')<br/>plt.scatter(X[:,0], X[:,1], label='data', alpha=0.5)<br/>plt.scatter(X_flow[:,0], X_flow[:,1], color='firebrick', label='flow', alpha=0.5)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/4798136e4201c4d2bfaf582dfae5bd55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*xIbebZlVrl7W-57Com7XRw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用红点显示来自新学习的变换分布的样本。(作者创作)</p></figure><p id="b94a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以画出学习到的边际分布:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="0c7a" class="nw my it ok b gy oo op l oq or">plt.subplot(1, 2, 1)<br/>sns.distplot(X[:,0], hist=False, kde=True,<br/>             bins=None,<br/>             hist_kws={'edgecolor':'black'},<br/>             kde_kws={'linewidth': 2},<br/>             label='data')<br/>sns.distplot(X_flow[:,0], hist=False, kde=True,<br/>             bins=None, color='firebrick',<br/>             hist_kws={'edgecolor':'black'},<br/>             kde_kws={'linewidth': 2},<br/>             label='flow')<br/>plt.title(r'$p(x_1)$')<br/>plt.subplot(1, 2, 2)<br/>sns.distplot(X[:,1], hist=False, kde=True,<br/>             bins=None,<br/>             hist_kws={'edgecolor':'black'},<br/>             kde_kws={'linewidth': 2},<br/>             label='data')<br/>sns.distplot(X_flow[:,1], hist=False, kde=True,<br/>             bins=None, color='firebrick',<br/>             hist_kws={'edgecolor':'black'},<br/>             kde_kws={'linewidth': 2},<br/>             label='flow')<br/>plt.title(r'$p(x_2)$')<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/6090f8aa9b18f12965394b1cd26225a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*fu3GJHgpvarB3XU4ZKviGA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">学习边际分布(由作者创建)</p></figure><p id="486b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这从情节上看，似乎接近实际分布。当然，我们可以做得更好，但那是以后的事了。</p><p id="5de9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有其他几个库可以使用规范化流方法，比如<code class="fe ov ow ox ok b">normflows</code>、<code class="fe ov ow ox ok b">ProbFlow</code>等。此外，我发现以下资源很有帮助:</p><ol class=""><li id="68df" class="oz pa it la b lb lc le lf lh pb ll pc lp pd lt pe pf pg ph bi translated"><a class="ae nu" href="https://gowrishankar.info/blog/normalizing-flows-a-practical-guide-using-tensorflow-probability/" rel="noopener ugc nofollow" target="_blank">https://gowrishankar . info/blog/normalizing-flows-a-practical-guide-using-tensor flow-probability/</a></li><li id="d967" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://github.com/LukasRinder/normalizing-flows" rel="noopener ugc nofollow" target="_blank">https://github.com/LukasRinder/normalizing-flows</a></li><li id="bc0f" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://probflow.readthedocs.io/en/latest/examples/normalizing_flows.html" rel="noopener ugc nofollow" target="_blank">https://prob flow . readthedocs . io/en/latest/examples/normalizing _ flows . html</a></li><li id="b7eb" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://github.com/VincentStimper/normalizing-flows" rel="noopener ugc nofollow" target="_blank">https://github.com/VincentStimper/normalizing-flows</a></li><li id="9288" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://github.com/tatsy/normalizing-flows-pytorch" rel="noopener ugc nofollow" target="_blank">https://github.com/tatsy/normalizing-flows-pytorch</a></li><li id="cc26" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://vishakh.me/posts/normalizing_flows/" rel="noopener ugc nofollow" target="_blank">https://vishakh.me/posts/normalizing_flows/</a></li><li id="e878" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated"><a class="ae nu" href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial11/NF_image_modeling.html" rel="noopener ugc nofollow" target="_blank">https://UVA DLC-notebooks . readthedocs . io/en/latest/tutorial _ notebooks/tutorial 11/NF _ image _ modeling . html</a></li><li id="7a15" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated">https://gebob19.github.io/normalizing-flows/<a class="ae nu" href="https://gebob19.github.io/normalizing-flows/" rel="noopener ugc nofollow" target="_blank"/></li></ol><h2 id="90ea" class="nw my it bd mz nx ny dn nd nz oa dp nh lh ob oc nj ll od oe nl lp of og nn oh bi translated">结论</h2><p id="1129" class="pw-post-body-paragraph ky kz it la b lb np ju ld le nq jx lg lh nr lj lk ll ns ln lo lp nt lr ls lt im bi translated">本文简要介绍了从变量转换到生成新分布的规范化流程方法。这种与神经网络相结合的统计方法的应用范围从伪图像生成到异常检测以及发现新的分子和材料。我建议读者查看我上面提到的参考资料，以便更深入地理解规范化流程。在以后的文章中，我将介绍流规范化的新进展。</p><p id="be9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面Python代码关联的笔记本可以在这里获得:<a class="ae nu" href="https://github.com/rahulbhadani/medium.com/blob/ec92a9bc7b2aa165df630ed5e268ec58fc0716a2/10_09_2022/normflow.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/rahulbhadani/medium . com/blob/EC 92 a9 BC 7 B2 aa 165 df 630 ed 5 e 268 EC 58 fc 0716 a 2/10 _ 09 _ 2022/norm flow . ipynb</a></p><h1 id="7f7f" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">参考</h1><ol class=""><li id="c9f7" class="oz pa it la b lb np le nq lh pn ll po lp pp lt pe pf pg ph bi translated">通过对特征空间中的<br/>流进行归一化进行聚类和分类<a class="ae nu" href="https://www.researchgate.net/profile/Martin-Cadeiras/publication/220385824_Clustering_and_Classification_through_Normalizing_Flows_in_Feature_Space/links/54da12330cf2464758204dbb/Clustering-and-Classification-through-Normalizing-Flows-in-Feature-Space.pdf" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/profile/Martin-Cadeiras/publication/220385824 _ Clustering _ and _ class ification _ through _ Normalizing _ Flows _ in _ Feature _ Space/links/54da 12330 cf 2464758204 dbb/Clustering-and-class ification-through-Normalizing-Flows-in-Feature-Space . pdf</a></li><li id="85a6" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated">一族非参数密度估计<br/>算法<a class="ae nu" href="https://ri.conicet.gov.ar/bitstream/handle/11336/8930/CONICET_Digital_Nro.12124.pdf?sequence=1" rel="noopener ugc nofollow" target="_blank">https://ri . coni et . gov . ar/bitstream/handle/11336/8930/coni et _ Digital _ nro . 12124 . pdf？序列=1 </a></li><li id="577d" class="oz pa it la b lb pi le pj lh pk ll pl lp pm lt pe pf pg ph bi translated">Kobyzev，I .，Prince，S. J .，&amp; Brubaker，M. A. (2020)。标准化流程:当前方法的介绍和评论。<em class="md"> IEEE模式分析与机器智能汇刊</em>，<em class="md"> 43 </em> (11)，3964–3979。</li></ol></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><p id="77d6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望这篇文章有助于你开始一个令人兴奋的统计学和数据科学的话题。</p></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><p id="115b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这有帮助吗？ <a class="ae nu" href="https://www.buymeacoffee.com/rahulbhadani" rel="noopener ugc nofollow" target="_blank"> <em class="md">给我买杯咖啡</em> </a> <em class="md">。</em></p><p id="dfbf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">喜欢我的作品？加入我的 <a class="ae nu" href="https://rahulbhadani.medium.com/subscribe" rel="noopener"> <em class="md">邮箱列表</em> </a> <em class="md">。</em></p><p id="a02c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md">想了解更多STEM相关话题？加入</em> <a class="ae nu" href="https://rahulbhadani.medium.com/membership" rel="noopener"> <em class="md">中等</em> </a> <em class="md">。</em></p></div></div>    
</body>
</html>