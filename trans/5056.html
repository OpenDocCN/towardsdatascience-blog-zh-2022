<html>
<head>
<title>Can I Trust My Model’s Probabilities? A Deep Dive into Probability Calibration</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我能相信我的模型的概率吗？深入探讨概率校准</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-i-trust-my-models-probabilities-a-deep-dive-into-probability-calibration-fc3886cfc677#2022-11-10">https://towardsdatascience.com/can-i-trust-my-models-probabilities-a-deep-dive-into-probability-calibration-fc3886cfc677#2022-11-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="b7e9" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">数据科学统计学</h2><div class=""/><div class=""><h2 id="927b" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">概率校准实用指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/6393973567cfc5bdc6a7c4d4f853e28d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*53y4xPBFWjkpskYM"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@edge2edgemedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Edge2Edge 媒体</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="5fb2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">假设你有一个二元分类器和两个观察值；模型将它们分别评分为<code class="fe mb mc md me b">0.6</code>和<code class="fe mb mc md me b">0.99</code>。具有<code class="fe mb mc md me b">0.99</code>分数的样本属于阳性类的可能性更大吗？对某些模型来说，这是真的，但对其他模型来说可能不是。</p><p id="2ef3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇博文将深入探讨概率校准——这是每个数据科学家和机器学习工程师的必备工具。概率校准允许我们确保来自我们的模型的较高分数更可能属于正类。</p><p id="02d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这篇文章将提供可复制的开源软件代码示例，这样你就可以用你的数据运行它了！我们将使用<a class="ae le" href="https://github.com/ploomber/sklearn-evaluation?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> sklearn-evaluation </a>进行绘图，使用<a class="ae le" href="https://github.com/ploomber/ploomber?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> Ploomber </a>并行执行我们的实验。</p><blockquote class="mf mg mh"><p id="02b8" class="lf lg mi lh b li lj ka lk ll lm kd ln mj lp lq lr mk lt lu lv ml lx ly lz ma ij bi translated">嗨！我叫爱德华多，我喜欢写关于数据科学的所有东西。如果您想了解我的最新内容。在<a class="ae le" href="https://medium.com/@edublancas?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener">媒体</a>或<a class="ae le" href="https://twitter.com/edublancas?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我。感谢阅读！</p></blockquote><h1 id="2644" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated"><strong class="ak">什么是概率校准？</strong></h1><p id="f55e" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">当训练一个二元分类器时，我们感兴趣的是发现一个特定的观察值是否属于正类。<em class="mi">正类</em>的意思取决于上下文。例如，如果处理电子邮件过滤器，这可能意味着某个特定的邮件是垃圾邮件。如果致力于内容审核，这可能意味着<em class="mi">有害帖子</em>。</p><p id="d26b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">使用一个实数值范围内的数字比是/否答案提供了更多的信息。幸运的是，大多数二元分类器可以输出分数(注意，这里我使用的是单词<em class="mi">分数</em>，而不是<em class="mi">概率</em>，因为后者有严格的定义)。</p><p id="0e36" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看一个逻辑回归的例子:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a573" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe mb mc md me b">predict_proba</code>函数允许我们输出分数(对于逻辑回归的情况，这是独立的概率):</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="05a4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4766" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">输出中的每一行代表属于类别<code class="fe mb mc md me b">0</code>(第一列)或类别<code class="fe mb mc md me b">1</code>(第二列)的概率。不出所料，行加起来是<code class="fe mb mc md me b">1</code>。</p><p id="c6a6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">直觉上，我们期望模型在对特定预测更有信心时给出更高的概率。例如，如果属于类别<code class="fe mb mc md me b">1</code>的概率是<code class="fe mb mc md me b">0.6</code>，我们可以假设该模型不像一个概率估计为<code class="fe mb mc md me b">0.99</code>的例子那样有信心。这是校准良好的模型所表现出的特性。</p><p id="bd7f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这个属性是有利的，因为它允许我们对干预进行优先级排序。例如，如果致力于内容审核，我们可能有一个模型将内容分类为<em class="mi">无害</em>或<em class="mi">有害</em>；一旦我们获得了预测，我们可能会决定只要求审查团队检查那些被标记为<em class="mi">有害的</em>，而忽略其余的。但是团队能力有限，最好只关注危害概率大的帖子。为了做到这一点，我们可以对所有的新帖子进行评分，取分数最高的前<code class="fe mb mc md me b">N</code>，然后将这些帖子交给评审团队。</p><p id="6cfb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，模型并不总是表现出这种特性，因此，如果我们想要根据输出概率对预测进行优先排序，我们必须确保我们的模型是校准良好的。</p><p id="b4bb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看我们的逻辑回归是否被校准。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="26cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nl"><img src="../Images/5d48b4d9698dc7cb9be36862ed820673.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mfxX65_EexKvFJHa0GW3vw.png"/></div></div></figure><p id="3797" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在让我们按概率箱分组，并检查该箱内属于正类的样本的比例:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1e5d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="cc3f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到该模型得到了合理的校准。对于<code class="fe mb mc md me b">0.0</code>和<code class="fe mb mc md me b">0.1</code>之间的输出，没有样本属于阳性类别。对于其余部分，实际正类样本的比例接近值边界。比如<code class="fe mb mc md me b">0.3</code>到<code class="fe mb mc md me b">0.4</code>之间的，29%属于正类。逻辑回归由于其<a class="ae le" href="https://en.wikipedia.org/wiki/Loss_functions_for_classification?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">损失函数</a>而返回精确校准的概率。</p><p id="b70c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">很难评估表格中的数字；这就是校准曲线的用武之地，它允许我们直观地评估校准。</p><h1 id="e977" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">什么是校准曲线？</h1><p id="6a57" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">校准曲线是模型校准的图形表示。它允许我们将我们的模型与一个目标进行比较:一个完美校准的模型。</p><p id="4465" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个完全校准的模型将在 10%确信该模型属于正类时输出得分<code class="fe mb mc md me b">0.1</code>，在 20%确信时输出得分<code class="fe mb mc md me b">0.2</code>，以此类推。所以如果我们画这个，我们会有一条直线:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nm"><img src="../Images/fc248b24f0553ba35ff2a6aa59f46397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JPeXPIMOE3NoQuxJoIXD0g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">完美校准的模型。图片作者。</p></figure><p id="8f61" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">此外，校准曲线允许我们比较几个模型。例如，如果我们想要将一个校准良好的模型部署到生产中，我们可能会训练几个模型，然后部署一个校准更好的模型。</p><h1 id="d237" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">恋恋笔记本</h1><p id="e753" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">我们将使用笔记本来运行我们的实验并更改模型类型(例如，逻辑回归、随机森林等)。)和数据集大小。这里可以看到<a class="ae le" href="https://github.com/ploomber/posts/blob/master/calibration-curve/fit.ipynb?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">源代码</a>。</p><p id="afeb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">笔记本很简单:它生成样本数据，拟合模型，对样本外预测进行评分，并保存它们。运行所有实验后，我们将下载模型的预测，并使用它们绘制校准曲线和其他曲线。</p><h1 id="e866" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">运行实验</h1><p id="179b" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">为了加速我们的实验，我们将使用<a class="ae le" href="https://www.cloud.ploomber.io/signin.html?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> Ploomber Cloud </a>，它允许我们参数化并并行运行笔记本。</p><p id="6907" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mi">注意:本节中的命令是 bash 命令。在终端中运行它们，或者添加</em> <code class="fe mb mc md me b"><em class="mi">%%sh</em></code> <em class="mi">魔法，如果你在 Jupyter 中执行它们的话。</em></p><p id="a760" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们下载笔记本:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="49d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e6fa" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，让我们运行我们的参数化笔记本。这将触发我们所有的平行实验:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4a0a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="030f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">大约一分钟后，我们将看到所有 28 个实验都已执行完毕:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="0eab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1f33" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们下载概率估计:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="ad6f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h1 id="0b53" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">加载输出</h1><p id="2518" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">每个实验都将模型的预测存储在一个<code class="fe mb mc md me b">.parquet</code>文件中。让我们加载数据来生成一个数据框，其中包含模型类型、样本大小和模型概率的路径(由<code class="fe mb mc md me b">predict_proba</code>方法生成)。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="0d5e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nn"><img src="../Images/d06d97a1db5efaf36d2753f122f84192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B691tF1Q0dBB68hccaEoCg.png"/></div></div></figure><p id="2cfb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><code class="fe mb mc md me b">name</code>是型号名称。<code class="fe mb mc md me b">n_samples</code>是样本大小，<code class="fe mb mc md me b">path</code>是每个实验生成的输出数据的路径。</p><h1 id="1b9c" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">逻辑回归:一个校准良好的模型</h1><p id="0429" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">逻辑回归是一个特例，因为它的目标函数是最小化对数损失函数，所以通过设计得到了很好的校准。</p><p id="638e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看它的校准曲线:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="ba83" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/0fd1faab864ddb9bae3f4dbb81dbf956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cuozszJGUS4OPLX9u0UmHg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">逻辑回归校准曲线。图片作者。</p></figure><p id="1061" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">您可以看到概率曲线非常类似于一个完美校准的模型。</p><h1 id="1d5c" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">样本大小的影响</h1><p id="1ceb" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">在上一节中，我们展示了逻辑回归是用来产生校准概率的。但是要注意样本大小。如果没有足够大的训练集，模型可能没有足够的信息来校准概率。下图显示了随着样本量的增加，逻辑回归模型的校准曲线:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="72bb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/aa8d5d022e926a27b0061fe60ffe6692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yq_uIqwQ9r2tw-1Apn6tpg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同样本量的逻辑回归校准曲线。图片作者。</p></figure><p id="d50f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以看到，对于 1，000 个样本，校准效果很差。然而，一旦你通过了 10，000 个样本，更多的数据不会显著改善校准。请注意，这种影响取决于您的数据的动态性；在您的用例中，您可能需要更多或更少的数据。</p><h1 id="24d0" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">非校准估计量</h1><p id="7a32" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">虽然逻辑回归被设计为产生校准的概率，但是其他模型不显示这种属性。让我们看看 AdaBoost 分类器的校准图:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="7397" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/6ff73d7644f656744ce575b3ef817872.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zqLroApuIMyUeIJ03QOqfQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同样本量下的 AdaBoost 校准曲线。图片作者。</p></figure><p id="fc21" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">可以看到校准曲线看起来高度失真:阳性分数(y 轴)与其对应的平均预测值(x 轴)相差甚远；此外，该模型甚至不产生沿整个<code class="fe mb mc md me b">0.0</code>到<code class="fe mb mc md me b">1.0</code>轴的值。</p><p id="b649" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">即使样本量为 1000，000，曲线也可以更好。在接下来的章节中，我们将看到如何解决这个问题，但是现在，记住这一点:不是所有的模型都会默认产生校准的概率。特别是，最大间隔方法，如 boosting (AdaBoost 是其中之一)、支持向量机和朴素贝叶斯产生未校准的概率(Niculescu-Mizil 和 Caruana，2005)。</p><p id="3dfb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">AdaBoost(不同于逻辑回归)有一个不同的优化目标，不产生校准概率。然而，这并不意味着模型不准确，因为在创建二元响应时，分类器是通过其准确性来评估的。我们来对比一下两款机型的性能。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="3af3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们绘制并比较分类指标。AdaBoost 的指标显示在每个方块的上半部分，而逻辑回归的指标显示在下半部分。我们将看到两种型号具有相似的性能:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="9d67" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi np"><img src="../Images/fa984970d577eaf18357ac09eede5313.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7OpxVXP66GCP2xsh1HmrA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">AdaBoost 和逻辑回归度量比较。图片作者。</p></figure><h1 id="7d79" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">概率分布的重要性</h1><p id="409c" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">到目前为止，我们仅使用校准曲线来判断分类器是否经过校准。然而，另一个需要考虑的关键因素是模型预测的分布。也就是分值有多常见或者多罕见。</p><p id="3dd4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看随机森林校准曲线:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="8b04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/65456ba93d273079ede286ae17f021df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fttNhDiIB2NdEyJU_6oCDA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">随机森林与逻辑回归校准曲线。图片作者。</p></figure><p id="08d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">随机森林遵循与逻辑回归相似的模式:样本量越大，校准越好。众所周知，随机森林能够提供精确的概率(Niculescu-Mizil 和 Caruana，2005 年)。</p><p id="2716" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，这只是一部分情况。首先，让我们看看输出概率的分布:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="92d6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nr"><img src="../Images/bcbefeafb972dcb57287f693db532c33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rfbOx0s0hLndOyl_nxTJjQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">随机森林与概率的逻辑回归分布。图片作者。</p></figure><p id="bbec" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们可以看到，随机森林将概率推向<code class="fe mb mc md me b">0.0</code>和<code class="fe mb mc md me b">1.0</code>，而来自逻辑回归的概率则不那么偏斜。当随机森林被校准时，在<code class="fe mb mc md me b">0.2</code>到<code class="fe mb mc md me b">0.8</code>区域没有很多观察值。另一方面，逻辑回归在<code class="fe mb mc md me b">0.0</code>到<code class="fe mb mc md me b">1.0</code>区域一直有支撑。</p><p id="5271" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个更极端的例子是当使用一棵树时:我们会看到一个更加偏斜的概率分布。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="5e9a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ns"><img src="../Images/5f24d3e1687736dfbc76b03c7485d6a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvyDlSffvzxazUedqGokjg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">概率的决策树分布。图片作者。</p></figure><p id="1c85" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看概率曲线:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a66d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/121bea878dec0e5510c8cf114d0e870e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MN-AtKqjRgN0nJQEC87omQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同样本量的决策树概率曲线。图片作者。</p></figure><p id="0305" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">你可以看到我们的两个点(<code class="fe mb mc md me b">0.0</code>和<code class="fe mb mc md me b">1.0</code>)被校准了(它们相当接近虚线)。但是，由于模型没有输出具有其他值的概率，因此不再存在更多数据。</p><h1 id="e651" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">校准分类器</h1><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/2871b6cb7e49815d390499fa3705c861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzjuduA4cxiy3Aoek9r_2A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">培训/校准/测试分割。图片作者。</p></figure><p id="7b68" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有几种技术可以校准分类器。它们通过使用您的模型的未校准预测作为输入来训练第二个模型，该模型将未校准分数映射到校准概率。我们必须使用一组新的观察数据来拟合第二个模型。否则，我们将在模型中引入偏差。</p><p id="9ab3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有两种广泛使用的方法:普拉特的方法和保序回归。当数据较少时，建议使用 Platt 的方法。相反，当我们有足够的数据来防止过度拟合时，保序回归更好(Niculescu-Mizil 和 Caruana，2005)。</p><p id="3a0e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">考虑到校准不会自动产生校准良好的模型。可以更好地校准预测的模型是提升树、随机森林、支持向量机、袋装树和神经网络(Niculescu-Mizil 和 Caruana，2005)。</p><p id="49cb" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">请记住，校准分类器会增加开发和部署过程的复杂性。因此，在尝试校准模型之前，确保没有更直接的方法来进行更好的数据清理或使用逻辑回归。</p><p id="eca5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">让我们看看如何使用 Platt 的方法训练、校准和测试分割来校准分类器:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a59b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/be9b884d3e0f74f71aae392b70983473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*22MGbG1m31_LAHvskpJWIQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">未校准与校准模型。图片作者。</p></figure><p id="6e61" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">或者，您可以使用交叉验证和测试折叠来评估和校准模型。让我们看一个使用交叉验证和保序回归的例子:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/c801afe1bfafcaa32a7475808a413b30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PbhXlXrwqwXnw0k-GKcVaA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用交叉验证进行校准。图片作者。</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="bc3a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi no"><img src="../Images/2f713fc05f5ab64395c4a99b8311583d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UbwBnVuiDg6T8VdER0Ewhw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">未校准与校准模型(使用交叉验证)。图片作者。</p></figure><h1 id="116c" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">校准多类别模型</h1><p id="698c" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">在上一节中，我们讨论了用于校准分类器的方法(普拉特方法和保序回归)，这些方法仅支持二元分类。</p><p id="f071" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">然而，校准方法可以通过遵循<em class="mi">一对一</em> <a class="ae le" href="https://scikit-learn.org/stable/modules/multiclass.html?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve#ovr-classification" rel="noopener ugc nofollow" target="_blank">策略</a>扩展到支持多个类别，如下例所示:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="8483" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nq"><img src="../Images/67f454e831a243326f8449aeac2dcd92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2wC8B34VknRlBhBozBAlwA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">未校准与校准的多级模型。图片作者。</p></figure><h1 id="7e46" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">结束语</h1><p id="8151" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">在这篇博文中，我们深入探讨了概率校准，这是一个实用的工具，可以帮助你开发更好的预测模型。我们还讨论了为什么有些模型无需额外步骤就能显示校准预测，而其他模型则需要第二个模型来校准其预测。通过一些模拟，我们还演示了样本大小的影响，并比较了几个模型的校准曲线。</p><p id="cc7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">为了并行运行我们的实验，我们使用了<a class="ae le" href="https://www.cloud.ploomber.io/signin.html?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> Ploomber Cloud </a>，为了生成我们的评估图，我们使用了<a class="ae le" href="https://github.com/ploomber/sklearn-evaluation?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> sklearn-evaluation </a>。Ploomber Cloud 有一个免费层，sklearn-evaluation 是开源的，所以你可以从这里获取<a class="ae le" href="https://github.com/ploomber/posts/blob/master/calibration-curve/fit.ipynb?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">这篇笔记本格式的文章，获得</a><a class="ae le" href="https://www.cloud.ploomber.io/signin.html?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"> API 密钥</a>，然后用你的数据运行代码。</p><p id="3d43" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">如果您有任何问题，欢迎加入我们的<a class="ae le" href="https://ploomber.io/community?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">社区</a>！</p><h1 id="cad5" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">参考</h1><ul class=""><li id="fb50" class="nv nw iq lh b li ne ll nf lo nx ls ny lw nz ma oa ob oc od bi translated"><a class="ae le" href="https://scikit-learn.org/stable/modules/calibration.html?utm_source=ploomber&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">概率校准(scikit-learn 文档)</a></li><li id="8e25" class="nv nw iq lh b li oe ll of lo og ls oh lw oi ma oa ob oc od bi translated"><a class="ae le" href="https://scikit-learn.org/stable/modules/calibration.html?utm_source=ploomber&amp;utm_medium=blog&amp;utm_campaign=calibration-curve#calibrating-a-classifier" rel="noopener ugc nofollow" target="_blank">校准分类器(scikit-learn 文档)</a></li><li id="2ba7" class="nv nw iq lh b li oe ll of lo og ls oh lw oi ma oa ob oc od bi translated">【David S. Rosenberg 的概率校准笔记</li><li id="ab1a" class="nv nw iq lh b li oe ll of lo og ls oh lw oi ma oa ob oc od bi translated"><a class="ae le" href="https://developers.google.com/machine-learning/crash-course/classification/prediction-bias?utm_source=ploomber&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">分类:预测偏差</a></li><li id="18fb" class="nv nw iq lh b li oe ll of lo og ls oh lw oi ma oa ob oc od bi translated"><a class="ae le" href="https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf?utm_source=ploomber&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank">用监督学习预测好的概率。亚历山德鲁·尼古列斯库-米齐尔和里奇·卡鲁阿纳(2005 年)</a></li></ul><h1 id="f09c" class="mm mn iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">使用的包</h1><p id="4e0e" class="pw-post-body-paragraph lf lg iq lh b li ne ka lk ll nf kd ln lo ng lq lr ls nh lu lv lw ni ly lz ma ij bi translated">以下是我们用于代码示例的版本:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="f8e2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">控制台输出(1/1): </strong></p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nj nk l"/></div></figure></div><div class="ab cl oj ok hu ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="ij ik il im in"><p id="2f47" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mi">最初发表于</em><a class="ae le" href="https://ploomber.io/blog/calibration-curve/?utm_source=medium&amp;utm_medium=blog&amp;utm_campaign=calibration-curve" rel="noopener ugc nofollow" target="_blank"><em class="mi">ploomber . io</em></a><em class="mi">。</em></p></div></div>    
</body>
</html>