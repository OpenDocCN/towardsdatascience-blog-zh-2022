<html>
<head>
<title>Deploying Machine Learning models with TensorFlow Serving — an introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow服务部署机器学习模型—简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-machine-learning-models-with-tensorflow-serving-an-introduction-6d49697a1315#2022-02-24">https://towardsdatascience.com/deploying-machine-learning-models-with-tensorflow-serving-an-introduction-6d49697a1315#2022-02-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8623" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从初始环境设置到使用TensorFlow服务和Docker服务和管理多个模型版本的分步教程</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/bb1a8865c113eb448c111ad42aff1abe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*R4MhWwQDq6a4Pd0h"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Patrick Robert Doyle 在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h1 id="192a" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">目录</h1><ol class=""><li id="07ad" class="md me it js b jt mf jx mg kb mh kf mi kj mj kn mk ml mm mn bi translated"><a class="ae le" href="#cfca" rel="noopener ugc nofollow">简介</a></li><li id="9948" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae le" href="#d1c7" rel="noopener ugc nofollow">环境设置</a></li><li id="79d5" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae le" href="#904e" rel="noopener ugc nofollow">创建机器学习模型</a> <br/> 3.1 <a class="ae le" href="#4558" rel="noopener ugc nofollow">数据生成</a> <br/> 3.2 <a class="ae le" href="#15cc" rel="noopener ugc nofollow">分割训练、验证和测试集</a> <br/> 3.3 <a class="ae le" href="#4a91" rel="noopener ugc nofollow">训练并保存回归模型</a></li><li id="6df6" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae le" href="#d0c4" rel="noopener ugc nofollow">服务于模型</a> <br/> 4.1 <a class="ae le" href="#d2ec" rel="noopener ugc nofollow">安装TensorFlow服务于Docker </a> <br/> 4.2 <a class="ae le" href="#b941" rel="noopener ugc nofollow">服务于最新模型</a> <br/> 4.3 <a class="ae le" href="#8fea" rel="noopener ugc nofollow">服务于多个模型版本</a> <br/> 4.4 <a class="ae le" href="#2c22" rel="noopener ugc nofollow">将自定义标签应用于模型版本</a> <br/> 4.5 <a class="ae le" href="#1f9f" rel="noopener ugc nofollow">随着时间的推移自动重新加载配置</a></li><li id="e40c" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae le" href="#5fa8" rel="noopener ugc nofollow">结论</a></li><li id="788a" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mk ml mm mn bi translated"><a class="ae le" href="#4675" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="cfca" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">1.介绍</h1><p id="7c5b" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">这篇文章涵盖了使用<strong class="js iu"> TensorFlow Serving </strong>作为web服务开始服务机器学习模型所需的所有步骤，TensorFlow是一个灵活的高性能服务系统。</p><p id="60a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个例子中，我们将建立一个虚拟环境，在这个环境中，我们将为一个回归问题生成合成数据，训练多个模型，最后将它们部署为web服务，从REST APIs访问预测。</p><p id="09f6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本教程的唯一先决条件是安装了<strong class="js iu"> Python </strong>和<strong class="js iu"> Docker引擎</strong>的工作机器。我们将最终使用<strong class="js iu"> curl⁴ </strong>来编写API调用，并通过它们的预测端点来消费机器学习模型。</p><h1 id="d1c7" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">2.环境设置</h1><p id="3068" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">一个<code class="fe mw mx my mz b">virtual environment</code>是一个自洽的Python环境，可以创建它来管理和分离项目:它提供了隔离，因此依赖关系不会影响同一操作系统上的其他包。</p><p id="4c6b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于本教程，我们在<code class="fe mw mx my mz b">myProject</code>文件夹中创建一个<code class="fe mw mx my mz b">virtual environment</code>。从命令行:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="aae3" class="ne lg it mz b gy nf ng l nh ni"># create the virtual environment<br/>python -m venv /myProject</span><span id="1211" class="ne lg it mz b gy nj ng l nh ni"># activate the environment<br/>myProject\Scripts\activate</span></pre><p id="8a65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦环境被激活，我们就可以安装所需的依赖项:</p><ul class=""><li id="3582" class="md me it js b jt ju jx jy kb nk kf nl kj nm kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">pip install scikit-learn</code>利用便捷的数据准备方法；</li><li id="d311" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">pip install tensorflow</code>用于机器学习开发；</li><li id="3318" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">pip install matplotlib</code>以可视化方式探索数据和模型度量；</li><li id="6537" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">pip install jupyter</code>使用笔记本。</li></ul><p id="c63f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">安装完依赖项后，我们通过执行以下命令来启动Jupyter Notebook:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="dbad" class="ne lg it mz b gy nf ng l nh ni">jupyter notebook</span></pre><p id="39ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从Jupyter Notebook web界面，我们可以在<code class="fe mw mx my mz b">myProject</code>文件夹中创建一个笔记本(<code class="fe mw mx my mz b">create_models.ipynb</code>),因为我们将使用它来生成通过TensorFlow服务提供的机器学习模型。</p><h1 id="904e" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">3.创建机器学习模型</h1><p id="64dc" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">从我们的笔记本开始，我们导入以前安装的依赖项:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="4558" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">3.1数据生成</h2><p id="d170" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们生成如下合成数据:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/0eb90dbbfc93fa2140c8531973003dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*GNdKpzBg37hto_g2-4fk9A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片作者。</p></figure><h2 id="15cc" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">3.2培训、验证和测试集的划分</h2><p id="13ff" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们将数据集分为:</p><ul class=""><li id="70ac" class="md me it js b jt ju jx jy kb nk kf nl kj nm kn nn ml mm mn bi translated"><strong class="js iu">训练和验证组</strong>:在训练过程中使用。</li><li id="8435" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><strong class="js iu">测试集</strong>:用于估计样本外性能。</li></ul><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="2b10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们观察获得的集合:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/7b50c83d425477aa392f6201301168be.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*TPOiadCs2SPnRfOMbVonMw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">训练、验证和测试集。图片作者。</p></figure><p id="399c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我们训练一个新的模型时，我们希望将它存储在我们项目根的一个子文件夹中，这个子文件夹被随意命名为<code class="fe mw mx my mz b">saved_models</code>。在这个空间中，我们将每个模型保存在一个专用的目录中，该目录用增量整数命名:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="4a91" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">3.3训练和保存回归模型</h2><p id="2c7c" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们拟合了由致密层构成的第一个简单模型:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/406719c4b269fb2ef84de9ea4de653d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*Pk3wsykKC514usELUQhztg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">第一个模型的训练历史。图片作者。</p></figure><p id="8985" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们创建另一个略有不同的模型:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/438c8b2df9315845328983c8b05011c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*dn5iyNked_RTwmrRyS_msg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">第二个模型的训练历史。图片作者。</p></figure><p id="4325" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以观察两个不同模型的测试集预测:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b33872984ad3a18e62ebaf42920f7bbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*OjK46-dL4i2g9n8FuzQkZw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">测试集预测。图片作者。</p></figure><p id="9f10" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过浏览<code class="fe mw mx my mz b">./myProject/saved_models</code>文件夹的内容，我们可以观察到训练好的模型保存在专用目录中:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi od"><img src="../Images/8c4933776d70272b83e2a1e91f4725d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*_FBM3BoyCGR1L5wMwPKYBA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">保存在saved_models文件夹中的增量命名目录中的模型。</p></figure><p id="dc33" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的最终目标是探索如何使用TensorFlow服务将一组给定的模型部署为用于推理的web服务。因此，我们不会更深入地研究建模任务，尽管人们可能会测试不同的模型或进一步改进训练策略。</p><h1 id="d0c4" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">4.为模特服务</h1><h2 id="d2ec" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">4.1使用Docker安装TensorFlow服务</h2><p id="c0ec" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">开始TensorFlow服务最简单的方法是拉最新的docker image⁵.从命令行:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="276e" class="ne lg it mz b gy nf ng l nh ni">docker pull tensorflow/serving</span></pre><p id="83ff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">提取映像后，我们可以通过运行以下命令来检查其可用性:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="0164" class="ne lg it mz b gy nf ng l nh ni">docker images</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/8c43b611f5c8151842837a8a597cebb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*mpnRSYzqlpVPrMaKsCWqqw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">拉最新的TensorFlow服务Docker图片。图片作者。</p></figure><h2 id="b941" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">4.2提供最新型号</h2><p id="4b4a" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们从提取的图像创建一个运行容器:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="c4ae" class="ne lg it mz b gy nf ng l nh ni">docker run --name myTFServing -it -v C:\myProject:/myProject -p 9001:9001 --entrypoint /bin/bash tensorflow/serving</span></pre><p id="a35b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们更详细地研究一下这个命令:</p><ul class=""><li id="75ca" class="md me it js b jt ju jx jy kb nk kf nl kj nm kn nn ml mm mn bi translated">从输入图像创建一个容器。</li><li id="98ff" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">--name &lt;myName&gt;</code>设置一个名称来标识Docker容器。</li><li id="895a" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">-it</code>在交互模式下启动容器。</li><li id="b5b7" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">-v &lt;host_volume&gt;:&lt;container_volume&gt;</code>将主机上的卷绑定到容器内的目录。在我们的例子中，容器将从容器内的<code class="fe mw mx my mz b">/myProject</code>目录访问主机上的项目文件夹<code class="fe mw mx my mz b">C:\myProject</code>。</li><li id="8721" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">-p &lt;host_port&gt;:&lt;container_port&gt;</code>将主机的端口绑定到容器的端口。</li><li id="c37d" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">--entrypoint</code>指定容器启动时应该运行的可执行文件。在我们这里，<code class="fe mw mx my mz b">/bin/bash</code>。</li><li id="0b89" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated"><code class="fe mw mx my mz b">tensorflow/serving</code>是从中派生容器的图像的名称。</li></ul><p id="65e4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从容器内部，我们检查是否存在<code class="fe mw mx my mz b">/myProject</code>文件夹及其内容，这应该与主机上的<code class="fe mw mx my mz b">C:\myProject</code>相同:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi of"><img src="../Images/dc756bb51f11172611c443577b7274ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*0eLCCC2hrckoTR2xaBD7zw.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由于Docker卷，容器可以访问主机上的项目根。图片作者。</p></figure><p id="8cd2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">当我们在容器内部时，我们启动TensorFlow，如下所示:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="2a56" class="ne lg it mz b gy nf ng l nh ni">tensorflow_model_server <br/>  --rest_api_port=9001 <br/>  --model_name=regression_experiments <br/>  --model_base_path=/myProject/saved_models</span></pre><p id="6f83" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们注意到，我们将存储模型的文件夹传递给了<code class="fe mw mx my mz b">model_base_path</code>标志，并用<code class="fe mw mx my mz b">model_name</code>为模型指定一个任意的名称。该名称将成为TensorFlow服务公开的端点的一部分。</p><p id="7cb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">一旦命令被执行，日志显示只有最新的模型被加载用于推断:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/9482bbc7608da5ec031254e93cc82fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HCEllhcRw7SxZ5Uncm4XVg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">默认情况下，会加载最新的模型进行推理。图片作者。</p></figure><p id="e8cd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以通过从容器外部使用<code class="fe mw mx my mz b">curl</code>执行API调用来测试预测。例如，我们从获得可用模型开始:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="3abb" class="ne lg it mz b gy nf ng l nh ni">curl -X GET http:/localhost:9001/v1/models/regression_experiments</span></pre><p id="12fe" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该调用返回:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/722803eb0b7ea3a2c45eba7b58e5c351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*p-MZ3owvqzfSr3-Zjweg2A.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片作者。</p></figure><p id="8c54" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">事实上，默认情况下，TensorFlow Serving只自动加载model_base_path中可用的不同模型的最新版本。</p><p id="b824" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们测试一个预测如下:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="156e" class="ne lg it mz b gy nf ng l nh ni">curl -X POST "http://localhost:9001/v1/models/regression_experiments:predict" ^<br/>-H "Content-Type: application/json" ^<br/>-d "{\"instances\":[[1.0], [2.0], [5.0]]}"</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/b0b35eaa9ac1cccdf5511a8a5201d0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OJN7PP6Nqt6StK03faXZMQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">TensorFlow服务成功服务于model_base_path中的最新模型。图片作者。</p></figure><p id="32b9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">注意事项</strong></p><ul class=""><li id="edab" class="md me it js b jt ju jx jy kb nk kf nl kj nm kn nn ml mm mn bi translated">在Windows机器上，<code class="fe mw mx my mz b">^</code>字符可以用于curl语句中的换行符。在MacOS或Unix系统上，应该使用反斜杠<code class="fe mw mx my mz b">\</code>字符。</li><li id="f046" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nn ml mm mn bi translated">人们可能想交替使用双引号<code class="fe mw mx my mz b">"</code>和单引号<code class="fe mw mx my mz b">'</code>来编写curl语句。例如，通过键入:<code class="fe mw mx my mz b">-d '{"instances":[..]}'</code>。在Windows上，这可能会导致以下消息:<code class="fe mw mx my mz b">{"error":"Malformed request: POST /v1/models/regression_experiments/predict"}</code>，或者其他curl / JSON解析错误。为了避免任何问题，命令应该只包含双引号<code class="fe mw mx my mz b">"</code>(嵌套时用反斜杠屏蔽)。</li></ul><h2 id="8fea" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">4.3提供多种型号版本</h2><p id="c0bf" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">在真实的场景中，我们可能需要一次公开多个模型。例如，我们可能希望逐渐将流量从服务的先前版本切换到新版本(<strong class="js iu">蓝绿色部署</strong>)，或者我们可能需要随机地将用户重定向到多个共存版本中的一个以进行测试(<strong class="js iu"> A/B测试</strong>)。</p><p id="9e54" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以很容易地指示TensorFlow Serving加载不同的模型版本，并使用<strong class="js iu">配置files⁶ </strong>进行推理。</p><p id="04e1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在<code class="fe mw mx my mz b">myProject</code>文件夹中，我们如下创建<code class="fe mw mx my mz b">cfg1.conf</code>文件:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="6117" class="ne lg it mz b gy nf ng l nh ni">model_config_list {<br/>  config {<br/>    name: 'regression_experiments'<br/>    base_path: '/myProject/saved_models'<br/>    model_platform: 'tensorflow'<br/>    model_version_policy: {all: {}}<br/>  }<br/>}</span></pre><p id="7538" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个文件中，我们设置了一个策略，指示TensorFlow考虑给定基本路径中的所有可用模型。</p><p id="a625" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们从容器开始TensorFlow服务，如下所示:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="e13d" class="ne lg it mz b gy nf ng l nh ni"># entering the container in interactive mode<br/>docker exec -it myTFServing bin/bash</span><span id="c032" class="ne lg it mz b gy nj ng l nh ni"># starting TensorFlow Serving with configuration file<br/>tensorflow_model_server <br/>  --rest_api_port=9001 <br/>  --allow_version_labels_for_unavailable_models <br/>  --model_config_file=/myProject/cfg1.conf</span></pre><p id="6d48" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从服务日志中，我们可以看到现在两个型号版本都是在启动时加载的:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/3dd74a266119b6db9dc815c298b5b000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysxvhLBmVrIBxno_T9oXYA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">服务启动时的TensorFlow服务日志。图片作者。</p></figure><p id="01ef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们用来自容器外部的GET请求来检查可用的模型:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="cbd9" class="ne lg it mz b gy nf ng l nh ni">curl -X GET http:/localhost:9001/v1/models/regression_experiments</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e6ec9221b80b71c21915f6d9eed6c5d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*kYLKgzyKeSav9FKvjmvvPQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图片作者。</p></figure><p id="acac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在可以对服务执行外部API调用，并随意将流量重定向到任何所需的版本，如下所示:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="4687" class="ne lg it mz b gy nf ng l nh ni"># call to model version 1<br/>curl -X POST<br/>"http://localhost:9001/v1/models/regression_experiments/<strong class="mz iu"><em class="oj">versions/1:predict</em></strong>" ^<br/>-H "Content-Type: application/json" ^<br/>-d "{\"instances\":[[1.0], [2.0], [5.0]]}"</span><span id="813d" class="ne lg it mz b gy nj ng l nh ni"># call to model version 2<br/>curl -X POST "http://localhost:9001/v1/models/regression_experiments/<strong class="mz iu"><em class="oj">versions/2:predict</em></strong>" ^<br/>-H "Content-Type: application/json" ^<br/>-d "{\"instances\":[[1.0], [2.0], [5.0]]}"</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/7e3b645a17b74407b318fe39b0031e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bdETgob-8FHWkrL0RXs4gA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">不同模型版本的预测。图片作者。</p></figure><h2 id="2c22" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">4.4将自定义标签应用于模型版本</h2><p id="5b3b" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们可以很容易地将字符串标签应用到模型versions⁶.通过这种方式，可以向我们的预测服务添加一个“语义抽象”层，从而提高可读性并促进DevOps实践。例如，通过REST接口消费我们的模型的集成层可能更喜欢调用“<em class="oj">生产</em>或“<em class="oj">测试</em>”版本，而不是像“<em class="oj"> 23 </em>或“<em class="oj"> 57 </em>”这样的随机整数。</p><p id="9d6e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这一结果可以通过在配置文件中指定所需的标签来实现。让我们在项目目录中创建一个<code class="fe mw mx my mz b">cfg2.conf</code>文件，如下所示:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="fa0d" class="ne lg it mz b gy nf ng l nh ni">model_config_list {<br/>  config {<br/>    name: 'regression_experiments'<br/>    base_path: '/myProject/saved_models'<br/>    model_platform: 'tensorflow'<br/>    model_version_policy {<br/>      specific {<br/>        versions: 1<br/>        versions: 2<br/>      }<br/>    }<br/>    version_labels {<br/>      key: 'production'<br/>      value: 1<br/>    }<br/>    version_labels {<br/>      key: 'test'<br/>      value: 2<br/>    }<br/>  }<br/>}</span></pre><p id="7297" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个文件中，我们将我们的模型版本分别分配给<code class="fe mw mx my mz b">production</code>和<code class="fe mw mx my mz b">test</code>标签。我们现在可以启动服务了:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="c5c5" class="ne lg it mz b gy nf ng l nh ni"># entering the container in interactive mode<br/>docker exec -it myTFServing bin/bash</span><span id="1ba3" class="ne lg it mz b gy nj ng l nh ni"># starting TensorFlow Serving with configuration file<br/>tensorflow_model_server <br/>  --rest_api_port=9001 <br/>  --allow_version_labels_for_unavailable_models <br/>  --model_config_file=/myProject/cfg2.conf</span></pre><p id="94e3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">服务启动后，我们可以执行外部API调用。值得注意的是，这次终点将是<code class="fe mw mx my mz b">/v1/models/&lt;model_name&gt;/<strong class="js iu">labels</strong>/</code>而不是<code class="fe mw mx my mz b">/v1/models/&lt;model_name&gt;/<strong class="js iu">versions</strong>/</code>:</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="8a5d" class="ne lg it mz b gy nf ng l nh ni"># call to production model<br/>curl -X POST<br/>"http://localhost:9001/v1/models/regression_experiments/<strong class="mz iu"><em class="oj">labels/production:predict</em></strong>" ^<br/>-H "Content-Type: application/json" ^<br/>-d "{\"instances\":[[1.0], [2.0], [5.0]]}"</span><span id="0ca0" class="ne lg it mz b gy nj ng l nh ni"># call to test model<br/>curl -X POST "http://localhost:9001/v1/models/regression_experiments/<strong class="mz iu"><em class="oj">labels/test:predict</em></strong>" ^<br/>-H "Content-Type: application/json" ^<br/>-d "{\"instances\":[[1.0], [2.0], [5.0]]}"</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/bc7b1d65bd4c01ce69385e6ed2ef8d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dL2vQFOAEvM76vQCXV77yQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">从模型的生产实例进行推断。图片作者。</p></figure><h2 id="1f9f" class="ne lg it bd lh nq nr dn ll ns nt dp lp kb nu nv lt kf nw nx lx kj ny nz mb oa bi translated">4.5随着时间的推移自动重新加载配置</h2><p id="b675" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">我们在启动时通过将配置文件传递给<code class="fe mw mx my mz b">--model_config_file</code>标志来使用它们。</p><p id="37ce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们还可以传递<code class="fe mw mx my mz b">--model_config_file_poll_wait_seconds</code>标志来指示TensorFlow Serving定期检查指定路径的配置文件中的更新。例如，语句</p><pre class="kp kq kr ks gt na mz nb nc aw nd bi"><span id="0300" class="ne lg it mz b gy nf ng l nh ni"># entering the container in interactive mode<br/>docker exec -it myTFServing bin/bash</span><span id="3b2e" class="ne lg it mz b gy nj ng l nh ni"># starting TensorFlow Serving<br/>tensorflow_model_server <br/>  --rest_api_port=9001 <br/>  --allow_version_labels_for_unavailable_models <br/>  --model_config_file=/myProject/cfg2.conf <br/>  --model_config_file_poll_wait_seconds=30</span></pre><p id="f884" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将基于来自<code class="fe mw mx my mz b">cfg2.conf</code>文件的配置启动<code class="fe mw mx my mz b">myTFServing</code>容器中的服务，并且更新将被定期提取。我们可以从日志中验证系统如何每30秒检查一次更新:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi om"><img src="../Images/d09dd4fd4a934df1dea35bd9dacc87cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXFCyo-aLI8iP1R2zSNBog.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">模型_配置_文件_轮询_等待_秒标志的效果。图片作者。</p></figure><h1 id="5fa8" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">5.结论</h1><p id="0ea9" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">在这篇文章中，我们探讨了如何使用TensorFlow服务部署模型，使得预测可以通过REST APIs轻松访问。</p><p id="2020" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">特别是我们从零开始。我们创建了一个虚拟环境，在该环境中，我们安装了生成合成数据和适应多个模型所需的最小依赖集。然后，我们提取TensorFlow服务Docker映像，并从中创建一个运行容器，涵盖了管理和服务多个模型版本所需的所有步骤。</p><h1 id="4675" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">6.参考</h1><p id="76fc" class="pw-post-body-paragraph jq jr it js b jt mf jv jw jx mg jz ka kb mt kd ke kf mu kh ki kj mv kl km kn im bi translated">[1]<a class="ae le" href="https://www.tensorflow.org/tfx/serving/architecture" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/serving/architecture</a></p><p id="4565" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://docs.python.org/3/using/" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/using/</a></p><p id="2d8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://docs.docker.com/engine/install/" rel="noopener ugc nofollow" target="_blank">https://docs.docker.com/engine/install/</a></p><p id="db66" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://curl.se/" rel="noopener ugc nofollow" target="_blank">https://curl.se/</a></p><p id="8908" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/serving/docker" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/serving/docker</a></p><p id="b75a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae le" href="https://www.tensorflow.org/tfx/serving/serving_config" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tfx/serving/serving_config</a></p></div></div>    
</body>
</html>