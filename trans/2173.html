<html>
<head>
<title>NLP: Explore Data Artifacts in SNLI Dataset with Checklist and ELECTRA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP:使用Checklist和ELECTRA探索SNLI数据集中的数据工件</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-explore-data-artifacts-in-snli-dataset-with-checklist-and-electra-ebbdd1b83cd0#2022-05-15">https://towardsdatascience.com/nlp-explore-data-artifacts-in-snli-dataset-with-checklist-and-electra-ebbdd1b83cd0#2022-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0564" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">前提假设句中的中性偏差和矛盾偏差</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/682d5de06ec553f6c28f0dedd79a12e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHMMmJFbAAPwY5XgshC0EA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@possessedphotography" rel="noopener ugc nofollow" target="_blank">走火入魔摄影</a> <strong class="bd kz"> </strong>在<a class="ae ky" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h2 id="9b84" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">动机</h2><p id="abf7" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">自然语言推理(NLI)是一种广泛研究的自然语言处理任务，用于确定两个陈述(前提和假设)之间的蕴涵关系。斯坦福NLI语料库(1.0版本)是57万个人工书写的英语句子对的集合，人工标记用于在NLI任务上训练NLP模型。虽然有最先进的NLP模型可以在验证集上实现高精度，但由于SNLI的构造方式，这些训练过的模型是否理解自然语言的问题仍然存在争议。众所周知，SNLI数据集包含基于性别、种族和民族刻板印象的刻板偏见。在本文中，我们将通过在ELECTRA-small模型上使用带有检查表的行为测试来分析和评估泛化性能，探索SNLI训练示例偏差，该模型具有<strong class="ly iu">两个不同的输入</strong>:一个具有<strong class="ly iu">前提-假设对</strong>，一个仅具有<strong class="ly iu">假设</strong>。</p><h2 id="ba12" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">SNLI数据集</h2><p id="bed6" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">SNLI数据集是通过向众包工作者展示一个前提句子(来源于Flickr图片说明)并要求他们为三个标签(蕴涵、NEU-特拉、矛盾)中的每一个生成相应的假设句子来创建的，这可能包含认知偏差。许多最新的NLP模型在验证集上实现了高精度。然而，验证集的准确性并不保证SNLI数据集范围之外的看不见的数据的成功。因此，重要的是采取替代方法，如<strong class="ly iu">行为测试</strong>来评估NLI任务的NLP模型。</p><p id="f6cd" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">为简单起见，我们可以利用拥抱面部的<a class="ae ky" href="https://huggingface.co/datasets/snli" rel="noopener ugc nofollow" target="_blank"> SNLI数据集</a>。这个数据集有三个部分:训练、验证和测试。训练集有大约55万个实例，而验证集和测试集各只有1万个实例。数据集中有三列:前提、假设和标签。有三种标签类别:蕴涵、中性和矛盾。</p><h2 id="fdbf" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">行为测试</strong></h2><p id="7588" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">在研究论文中提出的行为测试:<a class="ae ky" href="https://homes.cs.washington.edu/~marcotcr/acl20_checklist.pdf" rel="noopener ugc nofollow" target="_blank">超越准确性:在NLP模型上使用CheckLis </a> t对NLP模型进行行为测试，类似于软件工程世界中的单元测试。如果我们使用单元测试来探索软件核心功能的早期问题，那么行为测试结果将被用作判断训练好的NLP模型的泛化和探索偏差的主要标准。</p><p id="78d4" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><a class="ae ky" href="https://github.com/marcotcr/checklist" rel="noopener ugc nofollow" target="_blank"> CheckList </a>是一个开源库，有助于在经过训练的模型上执行行为测试。如<a class="ae ky" href="https://github.com/marcotcr/checklist" rel="noopener ugc nofollow" target="_blank">清单站点</a>所述，清单测试基于以下标准生成:</p><ol class=""><li id="2e55" class="mu mv it ly b lz mp mc mq lj mw ln mx lr my mo mz na nb nc bi translated">词汇+词性(任务的重要单词或单词类型)</li><li id="1188" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">健壮性(打字错误、无关的更改)</li><li id="822a" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">NER(正确理解命名实体)</li><li id="17fc" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">公平性、时间性(理解事件的顺序)</li><li id="e798" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">否定和语义角色标注(理解角色，如施事、宾语等)</li></ol><p id="e379" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">本文只看词汇量+词性能力，这是对情感词的基本理解。</p><h2 id="2994" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">伊利克特拉</h2><p id="e62c" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated"><a class="ae ky" href="https://github.com/google-research/electra" rel="noopener ugc nofollow" target="_blank"> ELECTRA </a> ( <em class="ni"> E </em>有效<em class="ni"> L </em>获得<em class="ni">E</em>n根据<em class="ni"> C </em>分类<em class="ni">T</em>oken<em class="ni">R</em>E<em class="ni">A</em>准确)是一种自我监督的语言表征学习方法。它可以用于使用相对较少的计算来预训练变压器网络。即使在单个GPU上训练，ELECTRA-small也能取得很好的效果。我们将用默认的启动代码和默认的超参数来训练ELECTRA-small模型3个时期。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/964ccbbe143ab69f7ebdfe8193d7dbbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eFwseZtO3CPPreo93OGhXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供，灵感来自<a class="ae ky" href="https://openreview.net/pdf?id=r1xMH1BtvB" rel="noopener ugc nofollow" target="_blank"> ELECTRA研究论文</a></p></figure><h2 id="9332" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">方法</h2><p id="7a80" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">我们分四步进行实验:</p><ol class=""><li id="0cf7" class="mu mv it ly b lz mp mc mq lj mw ln mx lr my mo mz na nb nc bi translated">我们将使用<strong class="ly iu">前提和假设对</strong>作为输入，在SNLI数据集上训练模型，并利用给定启动代码的默认设置来获得基线，以分析我们的实验结果。</li><li id="2cdb" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">我们将使用检查表来评估词汇+词性能力在最低功能测试(MFT)中的表现。</li><li id="ea61" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">我们将使用与步骤1相同的配置训练另一个模型。但是，我们将删除前提列，只使用假设列作为输入。</li><li id="a4e3" class="mu mv it ly b lz nd mc ne lj nf ln ng lr nh mo mz na nb nc bi translated">最后，我们比较了在步骤1和步骤3中训练的模型上的行为测试结果，并总结了我们的实验。</li></ol><h2 id="9622" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">火车模型</h2><ol class=""><li id="a554" class="mu mv it ly b lz ma mc md lj nk ln nl lr nm mo mz na nb nc bi translated">使用pypi的以下命令安装<a class="ae ky" href="https://github.com/marcotcr/checklist" rel="noopener ugc nofollow" target="_blank">清单</a>:</li></ol><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="2822" class="la lb it no b gy ns nt l nu nv">pip install checklist<br/>jupyter nbextension install --py --sys-prefix checklist.viewer<br/>jupyter nbextension enable --py --sys-prefix checklist.viewer</span></pre><p id="cc1b" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">2.安装pytorch:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="3fab" class="la lb it no b gy ns nt l nu nv">pip install torch</span></pre><p id="a620" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">3.安装空间模型:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="606d" class="la lb it no b gy ns nt l nu nv">python -m spacy download en_core_web_sm</span></pre><p id="a80a" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">4.关闭本<a class="ae ky" href="https://github.com/cmphan/SNLI_ELECTRA_CheckList" rel="noopener ugc nofollow" target="_blank">回购</a>:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="2658" class="la lb it no b gy ns nt l nu nv">git clone <a class="ae ky" href="https://github.com/cmphan/SNLI_ELECTRA_CheckList.git" rel="noopener ugc nofollow" target="_blank">https://github.com/cmphan/SNLI_ELECTRA_CheckList.git</a></span></pre><p id="96d7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">运行以下命令安装依赖项</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="6a7e" class="la lb it no b gy ns nt l nu nv">pip install --upgrade pip<br/>pip install -r requirements.txt</span></pre><p id="0ab7" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">5.要使用SNLI自然语言推理数据集<strong class="ly iu"> </strong>训练ELECTRA-small模型<strong class="ly iu">假设前提模型</strong>，可以运行以下命令。请注意，这可能需要几个小时</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="7ec7" class="la lb it no b gy ns nt l nu nv">python3 run_hypothesis_premise.py --do_train --task nli --dataset snli --output_dir ./trained_model/</span></pre><p id="16a1" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">6.要评估最终训练模型的准确性，您可以使用以下命令:</p><pre class="kj kk kl km gt nn no np nq aw nr bi"><span id="2ccd" class="la lb it no b gy ns nt l nu nv">python3 run_hypothesis_premise.py --do_eval --task nli --dataset snli --model ./trained_model/ --output_dir ./eval_output/</span></pre><p id="9051" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">7.对“run_hypothesis_only.py”文件重复4–6的相同步骤，以训练<strong class="ly iu">仅假设模型</strong></p><h2 id="74c4" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最低功能测试(MFT)</h2><p id="82e5" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">我们将把<a class="ae ky" href="https://github.com/marcotcr/checklist" rel="noopener ugc nofollow" target="_blank">检查表</a>测试应用于两个训练模型:<strong class="ly iu">假设-前提</strong>和<strong class="ly iu">仅假设</strong>，并比较它们的性能。</p><p id="99a6" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">首先，我们导入清单所需的库。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="94f2" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">标签的数量有三种:蕴涵、中性和矛盾。训练好的模型在“trained_model”文件夹中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="a905" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">为了测试您自己的模型，我们需要获得对<code class="fe ny nz oa no b">release_data/sentiment/tests_n500</code>中文本的预测，并将它们保存在一个文件中，其中每行有4个数字:预测(0代表负，1代表中性，2代表正)和预测概率(负，中性，正)。我们将每个标签的概率写入<code class="fe ny nz oa no b">predictions.txt</code>文件。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="9592" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">如在<a class="ae ky" href="https://github.com/marcotcr/checklist" rel="noopener ugc nofollow" target="_blank">清单</a>测试说明中，标签将0定义为阴性，1定义为中性，2定义为阳性，而HuggingFace上的SNLI数据集使用0表示蕴涵，1表示中性，2表示矛盾。因此，我们必须应用线性映射层，以使经过训练的模型预测结果与清单测试一起工作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/fa3d010a7cc85b227762f0941997a4a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BrRVjqDkt24X2IY1Qjb_bQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="8264" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">因此，我们将ELECTRA模型的预测映射到清单标签，并获得最高的标签结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="936c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">最后，我们可以加载情感分析套件并可视化MFT结果</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h2 id="2a70" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated"><strong class="ak">前提-假设模型MFT </strong>结果</h2><p id="ac7e" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">对于<strong class="ly iu">前提假设</strong>模型，行为测试失败率如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/785f4765f65a1bdd5b487a3488b03b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDXxne8zBVpT1E9cub7o1w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/1222bbdd26525be81f2f8d582d9302cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DE-DFK7EEmCIU4z2R9UwXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="e99f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">虽然该模型在验证测试中达到了88.996 %，但它在泛化能力上的表现并不像行为测试表结果所显示的那样好。我们可以看看词汇能力的失败率，以探索训练模型的弱点，并分析这一结果如何暴露训练示例中中性和负面关系的形成中的偏差。词汇能力(MFT)结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/01d7eaae39e73b95dec57ba05ca138db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TojRl6mbE-TbUIxfSYsoug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/8c7a320baceba3f11d4eb55cecf0b27c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5p654WQoDthGxNBcQv4ZA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="47ce" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">对于情感，即<em class="ni">词汇+词性</em>能力，经过训练的前提假设模型可以很好地识别单个正面单词，而它在检测负面和中性单词方面有困难。验证集上的高准确率并不意味着模型对自然语言的理解。具体来说，该模型在单个否定词、单个中性词和上下文中的中性词等领域100%失败。</p><h2 id="3026" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">中立和消极的偏见</h2><p id="0294" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">由于经过训练的模型在正面词示例上表现良好，因此我们可以专注于分析负面词和中性词示例。</p><p id="0232" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">中性:</strong>该模型在中性词上100%失败。在许多例子中，中性动词和形容词与航空公司名词一起使用，如座位、飞行员、航班等。例如，“飞机是国际的”，“飞机是美国的”，“服务是澳大利亚的”，模型预测2(积极的)而不是1(中性的)。这主要是因为在SNLI训练例子中形成中性假设的方式。大多数是通过原因和目的条款添加的。例如，前提句为“两只狗正在穿过一片田野”，中性假设将为“一些小狗正在跑着抓棍子。”以这种方式形成训练示例将导致训练的模型仅将带有目的子句的句子识别为中性，这就是为什么它不能在清单测试中检测简单句子中的中性情感。</p><p id="abb9" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">负面:</strong>经过训练的模型在识别负面情绪方面也100%失败。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/32143f11ef32c4a50c22e0c2e6336608.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*L_f0Bj5-jQbfTez79Xbn7g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="dafe" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">训练样本中的偏差是训练后的模型在泛化能力方面表现不佳的主要原因。许多众包工作者认为前提-假设对是矛盾的，但事实并非如此。例如，前提假设对:“三只狗在跑道上赛跑。”和“三只猫在一条跑道上赛跑。”因为诸如“狗”和“猫”之类的单词，这使得训练过的模型不能理解简单的负面单词。</p><h2 id="8cc1" class="la lb it bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">假设仅模拟MFT结果</h2><p id="7b5e" class="pw-post-body-paragraph lw lx it ly b lz ma ju mb mc md jx me lj mf mg mh ln mi mj mk lr ml mm mn mo im bi translated">我们使用相同的ELECTRA-small模型，相同的起始代码和训练超参数，但我们删除了前提列，只使用假设句子进行训练。这背后的动机是因为可以访问假设的基线系统只能在基于先前背景知识理解语言的意义上执行NLI。一个只有假设的基线实际上可以在10个NLI式数据集的大多数数据集上执行高于多数类的性能。</p><p id="ed8c" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">在最小功能测试中，<strong class="ly iu">假设模型</strong>的清单结果是有希望的，<strong class="ly iu">显著提高了模型在<em class="ni">词汇+词性</em>能力上的性能</strong>，尤其是在否定词和中性词方面。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/099fb19242206fd0f09767254c71d8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*azgs7lxrmktAaBujDn3X9A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/3f9165b803ac7bc21bdeef0f5cfdc477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*osUVb5sMy_T9DYfyKVp9Gg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0ba0" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">通过从训练示例中移除前提列，我们在仅假设情感分类的验证测试上仅获得69.630 %。然而，我们也消除了在形成句子之间的中性和负面关系时的偏见，并且帮助训练的假设仅更好地理解中性和负面情绪。与前提-假设模型在“单个否定词”、“单个中性词”和“上下文中的中性词”领域获得的100.0 %的失败率不同，该模型大幅降低了失败率，并显示了其对自然语言的理解。然而，“单个正面词”的失败率增加到79.4 %，这意味着仅假设模型不能很好地检测正面情绪。在SNLI数据集中，蕴涵关系主要是基于更具体的词的概括而形成的。比如前提句:“两只狗正在穿过一片田野。”需要假设句子:“户外有动物。”。显然，诸如<em class="ni">动物</em>、<em class="ni">乐器</em>和<em class="ni">户外</em>等通用词被选择来概括类似<em class="ni">狗</em>、<em class="ni">吉他</em>和<em class="ni">海滩等词。</em>因此，当我们在该模型的训练示例中删除前提列时，我们也影响了积极情感的这一概括方面，并影响了训练后的模型在类似MFT的概括测试中识别积极词语。</p><p id="0dcb" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated"><strong class="ly iu">结论</strong></p><p id="0a49" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">总体而言，通过比较在<strong class="ly iu">前提-假设</strong>和<strong class="ly iu">仅假设</strong>模型上的清单测试结果，我们可以探索SNLI数据集中的注释伪像和偏差，其影响泛化上下文中的训练模型性能。我们能够验证SNLI数据集形成在蕴涵关系上没有问题，因为训练的模型只有2.9 %的失败率。然而，在中性和矛盾关系中仍然存在偏差，并且训练的模型仅通过学习假设句子来提高对其否定和中性词的理解。通过删除前提列，行为测试在消极和中性方面的改进加强了这样一个事实，即在前提假设对示例中仍然存在矛盾和中性关系的问题。我们希望进一步的研究能够消除在构建未来NLI数据集时的人为偏见。</p><p id="453e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">希望本文对您有所帮助，帮助您更好地排查训练好的模型性能问题。</p><p id="fb9e" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">请随意使用本文的源代码:</p><div class="oj ok gp gr ol om"><a href="https://github.com/cmphan/SNLI_ELECTRA_CheckList" rel="noopener  ugc nofollow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">GitHub-cm phan/SNLI _ ELECTRA _清单</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">CS388中的项目:德州大学奥斯汀分校Greg Durrett教授的自然语言处理课程你需要Python &gt;= 3.6才能运行…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">github.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div><p id="c184" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">参考文章/研究论文:</p><p id="67bd" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">塞缪尔·r·鲍曼、加博·安格利、克里斯托弗·波茨和克里斯托弗·d·曼宁。2015.用于学习自然语言推理的大型标注语料库。</p><p id="4564" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">凯文·克拉克，Minh-Thang Luong，郭诉乐，克里斯托弗·曼宁。2020.<a class="ae ky" href="https://arxiv.org/pdf/2003.10555.pdf" rel="noopener ugc nofollow" target="_blank">伊莱克特:预先训练文本编码器作为鉴别器而不是生成器。</a></p><p id="6fa5" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">Suchin Gururangan，Swabha Swayamdipta，Omer Levy，Roy Schwartz，Samuel R. Bowman和Noah A. Smith。2018.<a class="ae ky" href="https://arxiv.org/pdf/1803.02324.pdf" rel="noopener ugc nofollow" target="_blank">自然语言推理数据中的标注神器。</a></p><p id="23c6" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">亚当·波利亚克、杰森·纳拉多斯基、阿帕拉吉塔·哈尔达尔、雷切尔·鲁丁格和本杰明·范·杜尔梅。2018.<a class="ae ky" href="https://arxiv.org/pdf/1805.01042.pdf" rel="noopener ugc nofollow" target="_blank">自然语言推理中的假设只有基线。</a></p><p id="8af3" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">马尔科·图利奥·里贝罗、吴桐双、卡洛斯·盖斯特林和萨梅尔·辛格。2020.<a class="ae ky" href="https://arxiv.org/pdf/2005.04118.pdf" rel="noopener ugc nofollow" target="_blank">超越准确性:带检查表的nlp模型的行为测试。</a></p><p id="856f" class="pw-post-body-paragraph lw lx it ly b lz mp ju mb mc mq jx me lj mr mg mh ln ms mj mk lr mt mm mn mo im bi translated">瑞秋·鲁丁格，钱德勒·梅，本杰明·杜尔梅。2017.<a class="ae ky" href="https://aclanthology.org/W17-1609.pdf" rel="noopener ugc nofollow" target="_blank">自然语言推理中的社会偏见。</a>第74–79页。</p></div></div>    
</body>
</html>