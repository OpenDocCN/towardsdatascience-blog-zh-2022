<html>
<head>
<title>LazyProphet: Time Series Forecasting with LightGBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LazyProphet:用 LightGBM 进行时间序列预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lazyprophet-time-series-forecasting-with-lightgbm-3745bafe5ce5#2022-02-23">https://towardsdatascience.com/lazyprophet-time-series-forecasting-with-lightgbm-3745bafe5ce5#2022-02-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b1bc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">都是关于功能的</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/560d39c7c5d8f8cb7c064836ee1859d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOFNNlSzJmEjxsCkOKvmqQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@lavalaye" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kz">塞巴斯蒂安·拉瓦雷</strong> </a>在<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的图像</p></figure><p id="4f71" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">当我们考虑时间序列空间中的提升树时，通常是关于 M5 竞赛，其中十大参赛作品中有很大一部分使用了 LightGBM。然而，当观察单变量情况下提升树的性能时，没有大量的外部特征可以利用，它们的性能已经…粗糙了。</p><p id="5d11" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">直到现在。</p><h1 id="272f" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第一部分:简介</h1><p id="8aea" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">首先，我应该提出一些警告。M4 比赛中的亚军确实使用了提升树。然而，它是作为一个元模型来集成其他更传统的时间序列方法。我在 M4 看到的所有基准测试都相当糟糕，有时甚至无法与天真的预测者相提并论。我在这里使用的主要资源来自为<a class="ae ky" href="https://www.sktime.org/en/stable/" rel="noopener ugc nofollow" target="_blank"> Sktime </a>包和他们的<a class="ae ky" href="https://arxiv.org/pdf/2005.08067.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>【1】所做的出色工作:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/abdf39219390072c7597b2ca1bfb39b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*6a-pNmdLdC9laKpXi92B1A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·洛宁、<a class="ae ky" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kir%C3%A1ly%2C+F" rel="noopener ugc nofollow" target="_blank">弗朗茨·基拉里</a>的表格，摘自他们的<a class="ae ky" href="https://arxiv.org/pdf/2005.08067.pdf" rel="noopener ugc nofollow" target="_blank"> Sktime 论文</a></p></figure><p id="a5b6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">任何带有“XGB”或“RF”的模型都使用基于树的集合。我们确实看到一个例子，Xgboost 在每小时的数据集中提供了最好的结果，为 10.9！然后，我们意识到这些只是他们在他们的框架中尝试的模型，M4 的获奖者在同一数据集上得了 9.3 分…</p><p id="fc11" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">试着记住这张图表中的一些数字，特别是 XGB-s 的每小时数据集的 10.9 和每周数据集中树木的“最佳”结果:RF-t-s 的 9.0。</p><p id="4cb3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们的目标是使用快速 LightGBM 程序彻底粉碎这些数字，该程序适合各个时间序列，在速度上与 stat 方法相当。</p><p id="9204" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">所以，没时间优化了。</p><p id="4f32" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">听起来相当困难，我们的第一想法可能是我们<strong class="lc iu">有</strong>来优化我们的树。增强树非常复杂，我们正在拟合单个数据集，因此它们必须有不同的参数。</p><p id="4707" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">但都是功能的问题。</p><h1 id="68fb" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 2 部分:功能</h1><p id="0a0c" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">当查看单变量空间中树的其他实现时，您会看到一些特征工程，如宁滨，使用目标的滞后值，简单的计数器，季节性虚拟，可能还有傅立叶基函数。如果你想后悔安装助推树，并希望你坚持使用指数平滑器，这一切都很好。主题是我们必须特征化我们的时间元素，并将其表示为表格数据以提供给树，我们的实现:<a class="ae ky" href="https://github.com/tblume1992/LazyProphet" rel="noopener ugc nofollow" target="_blank">lazy profet</a>也不例外。但是，我们有一个额外的特征工程元素，我在任何地方都没有见过(尽管它非常简单，所以这不可能是新颖的)。</p><p id="ceda" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将…“把这些点连接起来”。</p><p id="fe95" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">很简单，我们连接我们系列的第一个点，并在中间拟合一条线到另一个点，然后将该点连接到最后一个点。重复几次，同时改变哪一点作为“拐点”,你就成功了。</p><p id="a8d2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">希望这张图能很好地说明这一点。蓝线是一个时间序列，其他线只是“连接这些点”:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/b9ad818256df16211c7810796e225241.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*IaEwQXyzuFQhiK2yo3GC3Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="ef2b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">原来，这些只是加权的分段线性基函数。(再说一次，如果你知道这方面的任何研究，一定要让我知道，因为我真的找不到任何关于这个具体实现的东西。)这样做的一个不利之处是，这些线的外推可能会有偏差。为了处理这个问题，我们将加入一个“衰减”因子，它只是惩罚从中点到终点的每条线的斜率。</p><p id="fd4a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">就这样，就这样。把这些坏男孩连同滞后的目标值和傅立叶基函数一起扔进去，你就成功了！对于某些问题，几乎达到了最先进的性能，而且对我们的要求很低，因此被称为“LazyProphet”。</p><p id="ab03" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">但是让我们得到一些结果来支持这个观点。</p><h1 id="ef18" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">第 3 节:守则</h1><p id="978c" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">这些数据集都是开源的，并且在 M 竞赛<a class="ae ky" href="https://github.com/Mcompetitions/M4-methods/tree/master/Dataset" rel="noopener ugc nofollow" target="_blank"> github </a>上直播。它被标准训练和测试分割，因此我们将使用训练 csv 进行拟合，而测试 csv 仅用于使用 SMAPE 进行评估。让我们将数据和 LazyProphet 一起导入，如果您还没有安装它，请从 pip 中获取它。</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="813c" class="na lx it mw b gy nb nc l nd ne">pip install LazyProphet</span></pre><p id="1e9c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">安装后，让我们开始编码:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="af89" class="na lx it mw b gy nb nc l nd ne">import matplotlib.pyplot as plt<br/>import numpy as np<br/>from tqdm import tqdm<br/>import pandas as pd<br/>from LazyProphet  import LazyProphet as lp</span><span id="2a82" class="na lx it mw b gy nf nc l nd ne"><br/>train_df = pd.read_csv(r'm4-weekly-train.csv')<br/>test_df = pd.read_csv(r'm4-weekly-test.csv')<br/>train_df.index = train_df['V1']<br/>train_df = train_df.drop('V1', axis = 1)<br/>test_df.index = test_df['V1']<br/>test_df = test_df.drop('V1', axis = 1)</span></pre><p id="8690" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这里，我们只需导入所有必需的包，并将数据作为每周数据的标准数据帧读入。接下来，让我们创建 SMAPE 函数，该函数将返回给定预测和实际值的 SMAPE:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="0788" class="na lx it mw b gy nb nc l nd ne">def smape(A, F):<br/>    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) +       np.abs(F)))</span></pre><p id="3055" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们的实验中，我们将采用所有时间序列的平均值来与其他模型进行比较。对于健全性检查，我们还将获得“天真”的平均得分，以确保我们所做的与竞争中所做的一致。也就是说，我们将简单地遍历数据帧并进行惰性拟合和预测。代码可以通过<strong class="lc iu">而不是</strong>执行 for 循环来优化，但是这样做也很好！</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="00c8" class="na lx it mw b gy nb nc l nd ne">smapes = []<br/>naive_smape = []<br/>j = tqdm(range(len(train_df)))<br/>for row in j:<br/>    y = train_df.iloc[row, :].dropna()<br/>    y_test = test_df.iloc[row, :].dropna()<br/>    j.set_description(f'{np.mean(smapes)}, {np.mean(naive_smape)}')<br/>    lp_model = LazyProphet(scale=True,<br/>                            seasonal_period=52,<br/>                            n_basis=10,<br/>                            fourier_order=10,<br/>                            ar=list(range(1, 53)),<br/>                            decay=.99,<br/>                            linear_trend=None,<br/>                            decay_average=False)<br/>    fitted = lp_model.fit(y)<br/>    predictions = lp_model.predict(len(y_test)).reshape(-1)<br/>    smapes.append(smape(y_test.values,      pd.Series(predictions).clip(lower=0)))<br/>    naive_smape.append(smape(y_test.values, np.tile(y.iloc[-1], len(y_test))))  <br/>print(np.mean(smapes))<br/>print(np.mean(naive_smape))</span></pre><p id="7880" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们查看结果之前，让我们快速了解一下 LazyProphet 参数。</p><ol class=""><li id="f647" class="ng nh it lc b ld le lg lh lj ni ln nj lr nk lv nl nm nn no bi translated"><code class="fe np nq nr mw b">scale</code> <strong class="lc iu"> : </strong>这个很简单，简单的看是否缩放数据。默认值为 True，因此我们在这里只是明确说明。</li><li id="dce6" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">seasonal_period</code>:该参数控制季节性的傅立叶基函数，因为这是我们使用的<code class="fe np nq nr mw b">52</code>的周频率。</li><li id="6f75" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">n_basis</code>:该参数控制我们正在申请专利的加权分段线性基函数。这只是要使用的函数数量的一个整数。</li><li id="f0e5" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">fourier_order</code>:用于季节性的正弦和余弦对数。</li><li id="3243" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">ar</code>:使用什么滞后目标变量值。我们可以接受一个倍数的列表，然后简单地传递一个 1-52 的列表。</li><li id="2ee8" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">decay</code>:用于惩罚基函数“右侧”的衰减因子。设置为<code class="fe np nq nr mw b">0.99</code>表示斜率乘以(1- 0.99)或 0.01。</li><li id="d948" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">linear_trend</code>:树的一个主要缺点是它们不能推断出以前数据的界限。我提到过吗？是的，这可能是个大问题。为了克服这一点，有一些针对多项式趋势的即兴测试，如果检测到一个趋势，我们将线性回归拟合为去趋势。通过<code class="fe np nq nr mw b">None</code>表示将会有测试，通过<code class="fe np nq nr mw b">True</code>表示总是去趋势，通过<code class="fe np nq nr mw b">False</code>表示不测试并且从不使用线性趋势。</li><li id="1cde" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated"><code class="fe np nq nr mw b">decay_average</code>:使用衰减率时，这不是一个有用的参数。这主要是做奇怪事情的奇怪的黑魔法。试试吧！但是不要用。通过<code class="fe np nq nr mw b">True</code>本质上只是对基函数的所有未来值进行平均。在我的测试中，这在使用 elasticnet 过程时很有用，但在使用 LightGBM 时就没那么有用了。</li></ol><p id="212e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我们得到结果之前，让我们继续并适应每小时的数据集:</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="0fe4" class="na lx it mw b gy nb nc l nd ne">train_df = pd.read_csv(r'm4-hourly-train.csv')<br/>test_df = pd.read_csv(r'm4-hourly-test.csv')<br/>train_df.index = train_df['V1']<br/>train_df = train_df.drop('V1', axis = 1)<br/>test_df.index = test_df['V1']<br/>test_df = test_df.drop('V1', axis = 1)</span><span id="a87f" class="na lx it mw b gy nf nc l nd ne">smapes = []<br/>naive_smape = []<br/>j = tqdm(range(len(train_df)))<br/>for row in j:<br/>    y = train_df.iloc[row, :].dropna()<br/>    y_test = test_df.iloc[row, :].dropna()<br/>    j.set_description(f'{np.mean(smapes)}, {np.mean(naive_smape)}')<br/>    lp_model = LazyProphet(seasonal_period=[24,168],<br/>                            n_basis=10,<br/>                            fourier_order=10,<br/>                            ar=list(range(1, 25)),<br/>                            decay=.99)<br/>    fitted = lp_model.fit(y)<br/>    predictions = lp_model.predict(len(y_test)).reshape(-1)<br/>    smapes.append(smape(y_test.values, pd.Series(predictions).clip(lower=0)))<br/>    naive_smape.append(smape(y_test.values, np.tile(y.iloc[-1], len(y_test))))  <br/>print(np.mean(smapes))<br/>print(np.mean(naive_smape))</span></pre><p id="cc8e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">好吧，我们真正改变的是<code class="fe np nq nr mw b">seasonal_period</code>和<code class="fe np nq nr mw b">ar</code>参数。当把一个列表传递给<code class="fe np nq nr mw b">seasonal_period</code>时，它将为列表中的所有东西建立季节基函数。<code class="fe np nq nr mw b">ar</code>进行了调整，以适应新的主要季节周期 24。就是这样！</p><h1 id="9220" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">第四节:结果</strong></h1><p id="aa30" class="pw-post-body-paragraph la lb it lc b ld mo ju lf lg mp jx li lj mq ll lm ln mr lp lq lr ms lt lu lv im bi translated">还记得上面的 Sktime 结果吗？你其实不必，这里有一张表:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/6427518e7046ba59ecea3e0bb0009652.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*0xLhJUv6wpSfQHIUU5ZmYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="018f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因此，LazyProphet 击败了 Sktime 的最佳模型，其中包括几种不同的基于树的方法。在每小时的数据集上，我们确实输给了 M4 的冠军，但平均而言，我们实际上总体上优于 ES-RNN。这里要认识到的重要一点是，我们是用默认参数做到这一点的…</p><pre class="kj kk kl km gt mv mw mx my aw mz bi"><span id="b400" class="na lx it mw b gy nb nc l nd ne">boosting_params = {<br/>                    "objective": "regression",<br/>                    "metric": "rmse",<br/>                    "verbosity": -1,<br/>                    "boosting_type": "gbdt",<br/>                    "seed": 42,<br/>                    'linear_tree': False,<br/>                    'learning_rate': .15,<br/>                    'min_child_samples': 5,<br/>                    'num_leaves': 31,<br/>                    'num_iterations': 50<br/>                    }</span></pre><p id="6d7b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你想改变这些，你可以在创建 LazyProphet 类时传递你自己的 dict。这些甚至可以针对每个时间序列进行优化，以获得更多收益。</p><p id="3bca" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">但是，让我们将我们的结果与我们的目标进行比较:</p><ol class=""><li id="7054" class="ng nh it lc b ld le lg lh lj ni ln nj lr nk lv nl nm nn no bi translated">我们进行了零参数优化(针对不同的季节进行了细微的修改)。</li><li id="0b9f" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated">我们分别拟合每个时间序列。</li><li id="5386" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated">我们在我的本地机器上“懒洋洋地”用了一分多钟就做出了预测。</li><li id="42a9" class="ng nh it lc b ld ns lg nt lj nu ln nv lr nw lv nl nm nn no bi translated">我们击败了基准测试中的所有其他树方法，甚至平均击败了 M4 的获胜者。</li></ol><p id="94ff" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我得说我们相当成功！</p><p id="bed7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">你可能会问，“其他数据集的结果在哪里？”</p><p id="8cf2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">不幸的是，我们的成功没有持续多久。一般来说，其他数据集的数据要少得多，因此我们的方法往往会显著降低性能。据我所知，LazyProphet 往往以高频率和可观的数据量大放异彩。当然，我们可以尝试用一个 LightGBM 模型来拟合所有的时间序列，但是我们可以留到下次再做！</p><p id="7ec8" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">由于我们只是使用 LightGBM，您可以改变目标并尝试时间序列分类！或者使用分位数目标作为预测界限！有很多很酷的东西可以尝试。</p><p id="115c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你觉得这很有趣，我鼓励你看看我用另一种土生土长的方法对 M4 比赛的另一种看法:<a class="ae ky" href="https://github.com/tblume1992/ThymeBoost" rel="noopener ugc nofollow" target="_blank">百里香增强。</a></p><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/the-m4-time-series-forecasting-competition-with-thymeboost-b31196fc319"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">用百里香增强软件进行 M4 时间序列预测竞赛</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">第 1 部分:每周数据集</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/thymeboost-a0529353bf34"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">用百里香增强进行时间序列预测</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">一种梯度增强的时间序列分解方法</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="oq l om on oo ok op ks ob"/></div></div></a></div><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/gradient-boosted-arima-for-time-series-forecasting-e093f80772f6"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">时间序列预测的梯度增强 ARIMA</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">提升 PmdArima 的 Auto-Arima 性能</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="or l om on oo ok op ks ob"/></div></div></a></div><p id="3779" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">参考文献:</strong></p><p id="538f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">[1]<a class="ae ky" href="https://arxiv.org/abs/2005.08067" rel="noopener ugc nofollow" target="_blank">Markus lning，Franz Király:《用 sktime 进行预测:设计 sktime 的新预测 API 并应用于复制和扩展 M4 研究》，2020 年；arXiv:2005.08067 </a></p></div></div>    
</body>
</html>