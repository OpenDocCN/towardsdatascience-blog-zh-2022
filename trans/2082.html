<html>
<head>
<title>Understanding l1 and l2 Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解l1和l2正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-l1-and-l2-regularization-93918a5ac8d0#2022-05-10">https://towardsdatascience.com/understanding-l1-and-l2-regularization-93918a5ac8d0#2022-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fe0a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">线性回归模型中的正则化综述。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d43ea8bbdd1e0032e89f7b8141cb0348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeINTX82W7vwqLMHHWEaTQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">l1和l2用图形表示。来源:https://commons.wikimedia.org/wiki/File:Regularization.jpg</p></figure><p id="9b31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当训练机器学习模型时，我们的模型可能在训练集上表现准确，但在测试数据上表现不佳。</p><p id="0f81" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们有一个过度拟合的问题；事实上，当我们的机器学习模型试图覆盖所有数据点(或更多)<strong class="lb iu">，而不是给定数据集</strong>中存在的所需数据点时，就会发生<strong class="lb iu">过度拟合</strong> <strong class="lb iu">。因此，模型开始缓存数据集中存在的噪音和不准确的值，所有这些因素都会降低模型的效率和准确性。</strong></p><p id="5be2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当过度拟合发生时，有很多方法可以避免过度拟合；在线性回归的情况下，避免过度拟合的一种方法是使用通常称为l1和l2的两种正则化方法之一，我们将在本文中了解它们。</p><h1 id="3931" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.一些回归概念</h1><p id="7124" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">让我们从了解回归的基础开始。正如维基百科所说:</p><blockquote class="ms mt mu"><p id="22bb" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">回归分析是一组统计过程，用于估计因变量(通常称为“结果”或“响应”变量)与一个或多个自变量(通常称为“预测值”、“协变量”、“解释变量”或“特征”)之间的关系。</p></blockquote><p id="43ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">线性回归公式为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b149695ec58ddc2b4c29184a087c5c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*YfdjbbcKclQ1FIanpIau8A.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归公式。图片作者。</p></figure><p id="b668" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中“Yi”是因变量(也称为“响应”)的(向量)，而“X”是自变量(也称为“特征”)的(向量)。α和β是系数<strong class="lb iu">，回归的“游戏”全靠寻找“最佳参数”</strong>。有了“最佳参数”,我们可以找到“最佳拟合”给定数据的“最佳直线”,这样我们就可以在给出未来输入(新特性值)时估计未来的结果值。</p><p id="578b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想强调X和Y是向量的事实，因为在机器学习中，我们总是必须处理多个特征，所以在线性回归的情况下，我们不能在X和Y之间画一条线，就像我们在高中(或大学)只有“一个X”(一个自变量)时可以做的那样。在这些情况下，所有的特征都以某种方式对结果有贡献，所以我们不能仅仅绘制一个图，因为这将是一个多变量的图(我们无论如何都可以这样做，但是非常复杂)。</p><p id="23f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当线性回归出现过拟合时，我们可以尝试正则化我们的线性模型；<strong class="lb iu">正则化</strong>是机器学习中惩罚复杂模型最常用的技术:它<strong class="lb iu">通过惩罚具有高值的回归系数来避免过度拟合。</strong>更具体地说，减少参数，缩小(简化)模型；其目的是试图减少模型的方差，而不显著增加偏差。</p><p id="4176" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在实践中，在正则化模型(l1和l2)中，我们将所谓的“成本函数”(或“损失函数”)添加到我们的线性模型中，它是我们的模型在估计X和y之间的关系的能力方面“错误程度”的度量。成本函数的“类型”将l1与l2区分开来。</p><h1 id="c89f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.L1正则化或套索正则化</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="na nb l"/></div></figure><p id="f2cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Lasso(最小绝对和选择算子)回归执行L1正则化，它添加了一个等于系数幅度绝对值的<strong class="lb iu">惩罚</strong>，正如我们在上面蓝色矩形的图像中看到的(λ是正则化参数)。这种类型的正则化使用收缩，即数据值向中心点收缩，例如平均值。</p><p id="4009" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种类型的正则化可以产生系数很少的稀疏模型；事实上，有些系数可以变为零，可以从模型中消除。这意味着这种类型的模型也执行特征选择(因为一些系数可以变成0，这意味着系数为0的特征被消除)，并且当我们具有“大量”特征时，它将被选择，因为它简化了模型。因此，当我们必须处理“大量”特性时，这个模型是很好的。</p><p id="11cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们看看本文顶部的图像，惩罚因子的绝对值可以用图形表示为一个(旋转的)正方形，而椭圆轮廓是成本函数。如果成本函数(省略号)“命中”(旋转的)正方形的一个角，则对应于轴的系数被收缩为零，并且相关特征被消除。</p><p id="8dbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">套索回归的一个问题是<strong class="lb iu">多重共线性</strong>；我的意思是，如果有两个或更多高度相关的变量，那么Lasso回归随机选择其中一个，这对于我们模型的解释是不利的。为了避免这种情况，我建议您绘制一个相关矩阵，找到最终高度相关的特征并删除其中一个(例如，如果feature_1和feature_2高度相关，您可以决定删除feature_2，因为<strong class="lb iu">高度相关的变量对最终解决方案</strong>具有相同的影响)。</p><h1 id="509a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.L2正则化或岭正则化</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ba7e6e98b0d3371e574f3de754315b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*UbwVpxCOUubyflFbP7Golg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">岭回归公式。来源:<a class="ae ky" href="https://openclassrooms.com/en/courses/6401081-improve-the-performance-of-a-machine-learning-model/6561486-improve-your-regression-with-regularization" rel="noopener ugc nofollow" target="_blank">https://open classrooms . com/en/courses/6401081-improve-the-performance-of-a machine-learning-model/6561486-improve-your-regulatory</a>(CC BY-SA 4.0)</p></figure><p id="caa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">岭回归</strong>是一种在线性自变量高度相关的场景<strong class="lb iu">中估计多元回归模型系数的方法。</strong></p><p id="2c30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型增加了一个成本函数，即系数幅度的平方值<strong class="lb iu"> </strong>，事实上，如果我们观看本文的第一幅图像，成本函数的几何表示在这种情况下是一个圆形。</p><p id="4bf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，这个模型不执行特征选择:<strong class="lb iu"> </strong>它降低了模型的复杂性，但没有减少自变量的数量，因为它不会导致系数为0。这意味着最终的模型将包括所有的独立变量。为了避免这一问题，由于当要素高度相关时必须使用山脊线，因此在这里(比使用套索模型更重要)使用相关矩阵研究要素并决定从正在执行的研究中删除哪些要素非常重要。</p><h1 id="8f05" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="8307" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">正如我们已经看到的，当我们的模型出现过度拟合的问题时，必须执行正则化。</p><p id="cb0a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于线性回归模型，当我们有很多特征时，我们最好使用Lasso正则化，因为它执行均匀的特征选择；如果我们有高度相关的特征，我们最好使用岭模型。</p><p id="186b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，如果你对相关和回归的区别有疑问，可以在这里阅读我关于这个话题的澄清文章<a class="ae ky" rel="noopener" target="_blank" href="/the-difference-between-correlation-and-regression-134a5b367f7c">。</a></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="4d1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mv">需要Python和数据科学方面的内容来开始或促进您的职业生涯？下面是我的一些文章，可以帮到你:</em></p><p id="3bd6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> Python: </strong></p><ul class=""><li id="0472" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/loops-and-statements-in-python-a-deep-understanding-with-examples-2099fc6e37d7?source=your_stories_page-------------------------------------">Python中的循环和语句:深入理解(附示例)</a></li><li id="c753" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/python-loops-a-complete-guide-on-how-to-iterate-in-python-b29e0d12211d"> Python循环:如何在Python中迭代的完整指南</a></li><li id="3267" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/5-python-libraries-to-learn-to-start-your-data-science-career-2cd24a223431">学习5个Python库开始你的数据科学生涯</a></li><li id="c154" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-study-python-for-data-science-888a1ad649ae">数据科学如何学习Python</a></li></ul><p id="55d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">数据科学:</strong></p><ul class=""><li id="96df" class="nk nl it lb b lc ld lf lg li nm lm nn lq no lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-study-data-science-even-if-you-work-or-study-full-time-b52ace31edac">即使全职工作(或学习)也要如何学习数据科学</a></li><li id="7c08" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-deal-with-missing-values-in-data-science-9e5a56fbe928">如何处理数据科学中的缺失值</a></li><li id="efdf" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-perform-feature-selection-in-a-data-science-project-591ba96f86eb">如何在数据科学项目中执行特征选择</a></li><li id="6ee8" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-detect-outliers-in-a-data-science-project-17f39653fb17?source=your_stories_page-------------------------------------">如何检测数据科学项目中的异常值</a></li><li id="78f2" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/two-methods-for-performing-graphical-residuals-analysis-6899fd4c78e5">执行图形残差分析的两种方法</a></li><li id="1b19" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://medium.com/mlearning-ai/how-to-easily-validate-your-ml-models-with-learning-curves-21cc01636083" rel="noopener">如何利用学习曲线轻松验证您的ML模型</a></li><li id="5f5f" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/what-is-the-difference-between-a-barplot-and-a-histogram-e62d0e532e7d">柱状图和柱状图有什么区别？</a></li><li id="c8ed" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/the-difference-between-correlation-and-regression-134a5b367f7c?source=your_stories_page-------------------------------------">相关和回归的区别</a></li><li id="03ea" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/understanding-l1-and-l2-regularization-93918a5ac8d0?source=your_stories_page-------------------------------------">了解l1和l2正规化</a></li><li id="56ff" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" href="https://medium.com/mlearning-ai/logistic-regression-lets-clear-it-up-8bf20e9b328a?source=your_stories_page-------------------------------------" rel="noopener">逻辑回归:我们来搞清楚！</a></li><li id="30c6" class="nk nl it lb b lc nt lf nu li nv lm nw lq nx lu np nq nr ns bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/what-is-a-trained-model-5c872cfa8448?source=your_stories_page-------------------------------------">什么是训练有素的模特？</a></li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="ac7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑成为会员:你可以免费支持我和其他像我一样的作家。点击 <a class="ae ky" href="https://federicotrotta.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="mv">这里</em></strong></a><strong class="lb iu"><em class="mv"/></strong><em class="mv">成为会员。</em></p></div></div>    
</body>
</html>