<html>
<head>
<title>Distributed Forecast of 1M Time Series in Under 15 Minutes with Spark, Nixtla, and Fugue</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用Spark、Nixtla和Fugue对15分钟以内的1M时间序列进行分布式预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/distributed-forecast-of-1m-time-series-in-under-15-minutes-with-spark-nixtla-and-fugue-e9892da6fd5c#2022-09-16">https://towardsdatascience.com/distributed-forecast-of-1m-time-series-in-under-15-minutes-with-spark-nixtla-and-fugue-e9892da6fd5c#2022-09-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c28c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用开源项目StatsForecast、Fugue和Spark进行可扩展的时间序列建模</h2></div><p id="04ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由凯文·科、<a class="lb lc ep" href="https://medium.com/u/6926bdc4ca1e?source=post_page-----e9892da6fd5c--------------------------------" rel="noopener" target="_blank">汪涵</a>、<a class="lb lc ep" href="https://medium.com/u/76b639655285?source=post_page-----e9892da6fd5c--------------------------------" rel="noopener" target="_blank">马克斯·梅根塔尔</a>和<a class="lb lc ep" href="https://medium.com/u/2855bd3e0293?source=post_page-----e9892da6fd5c--------------------------------" rel="noopener" target="_blank">费德里科·加尔萨·拉米雷斯</a>主演。</p><p id="289e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> TL:DR我们将展示如何利用Spark的分布式能力和StatsForecast的高效代码在几分钟内拟合数百万个模型。</strong></p><p id="3b60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对一段时间内收集的数据进行趋势和季节性的时间序列建模、分析和预测是一种快速增长的软件应用。</p><p id="e559" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从电力和经济到医疗保健分析，企业每天都在收集时间序列数据，以预测模式并构建更好的数据驱动型产品体验。例如，温度和湿度预测用于制造以防止缺陷，流指标预测有助于识别音乐的流行艺术家，对供应链中不同位置的数千个SKU的销售预测用于优化库存成本。随着数据生成量的增加，预测的必要性已经从模拟几个时间序列发展到预测数百万个时间序列。</p><h1 id="1cc2" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">动机</h1><p id="d514" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><a class="ae ma" href="https://github.com/Nixtla" rel="noopener ugc nofollow" target="_blank"> Nixtla </a>是一个开源项目，专注于最先进的时间序列预测。他们有几个库，例如用于统计模型的<a class="ae ma" href="https://github.com/Nixtla/statsforecast" rel="noopener ugc nofollow" target="_blank"> StatsForecast </a>，用于深度学习的<a class="ae ma" href="https://github.com/Nixtla/neuralforecast" rel="noopener ugc nofollow" target="_blank"> NeuralForecast </a>，以及用于预测不同层级的聚合的<a class="ae ma" href="https://github.com/Nixtla/hierarchicalforecast" rel="noopener ugc nofollow" target="_blank"> HierarchicalForecast </a>。这些是面向生产的时间序列库，侧重于不同的建模技术。</p><p id="7f0d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文着眼于<a class="ae ma" href="https://github.com/Nixtla/statsforecast" rel="noopener ugc nofollow" target="_blank"> StatsForecast </a>，这是一个拥有统计和计量经济学模型的快速预测库。Nixtla的AutoARIMA模型比<a class="ae ma" href="http://alkaline-ml.com/pmdarima/" rel="noopener ugc nofollow" target="_blank">的pmdarima </a>快20倍，ETS(误差、趋势、季节)模型比<a class="ae ma" href="https://github.com/statsmodels/statsmodels" rel="noopener ugc nofollow" target="_blank">的statsmodels </a>快4倍，而且更稳健。要复制的基准和代码可以在<a class="ae ma" href="https://github.com/Nixtla/statsforecast#-accuracy---speed" rel="noopener ugc nofollow" target="_blank">这里</a>找到。性能提升的很大一部分是由于使用了名为<a class="ae ma" href="https://numba.pydata.org/" rel="noopener ugc nofollow" target="_blank"> numba </a>的JIT编译器来实现高速度。</p><p id="f75e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更快的迭代时间意味着数据科学家可以运行更多的实验，并更快地收敛到更准确的模型。这也意味着大规模运行基准测试变得更加容易。</p><p id="c286" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们对StatsForecast库在使用<a class="ae ma" href="https://github.com/fugue-project/fugue/" rel="noopener ugc nofollow" target="_blank">赋格</a>库拟合<a class="ae ma" href="https://spark.apache.org/docs/latest/api/python/index.html" rel="noopener ugc nofollow" target="_blank"> Spark </a>或<a class="ae ma" href="https://github.com/dask/dask" rel="noopener ugc nofollow" target="_blank"> Dask </a>模型时的可伸缩性感兴趣。这种结合将允许我们在一个临时集群上快速地分布训练大量的模型。</p><h1 id="4dca" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">实验设置</h1><p id="c2c7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">当处理大型时间序列数据时，用户通常必须处理数千个逻辑上独立的时间序列(想想不同用户或不同产品销售的遥测数据)。在这种情况下，我们可以在所有系列上训练一个大模型，或者我们可以为每个系列创建一个模型。这两种方法都是有效的，因为较大的模型将获得整个群体的趋势，而训练数千个模型可能更好地拟合单个系列数据。</p><p id="2d2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mb">注意:要在一个模型中获得时间序列人口的微观和宏观趋势，请检查Nixtla</em><a class="ae ma" href="https://github.com/Nixtla/hierarchicalforecast" rel="noopener ugc nofollow" target="_blank"><em class="mb">hierarchical forecast</em></a><em class="mb">库，但这也是计算成本更高、规模更棘手的方法。</em></p><p id="48d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文将讨论我们为每个单变量时间序列训练几个模型(AutoARIMA或ETS)的场景。对于此设置，我们按时间序列对完整数据进行分组，然后为每个组训练每个模型。下图说明了这一点。分布式数据帧可以是Spark或Dask数据帧。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mc"><img src="../Images/2c064febeed0c3c53732899cf12aa440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HbHd-D8XmtN5F2bI.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">按分区自动排序—按作者排序的图像</p></figure><p id="e521" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Nixtla之前发布了关于在Ray上分发这个模型训练的基准测试。设置和结果可以在这个博客中找到<a class="ae ma" href="https://www.anyscale.com/blog/how-nixtla-uses-ray-to-accurately-predict-more-than-a-million-time-series" rel="noopener ugc nofollow" target="_blank">。结果也如下所示。在35分钟内运行一百万个AutoARIMA模型需要2000个CPU。我们将把它与在Spark上运行进行比较。</a></p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi ms"><img src="../Images/fcc7744a89fec8a708fb934f1b811e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bnlD5NAslUxfTniv.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">光线结果的统计预测—图片由作者提供</p></figure><h1 id="d48a" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">统计预测代码</h1><p id="c07a" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">首先，我们将查看用于在<a class="ae ma" href="https://docs.ray.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">射线</a>上分布式运行AutoARIMA的StatsForecast代码。这是运行一百万时间序列场景的简化版本。它还为最近的StatsForecast v1.0.0版本进行了更新，因此它看起来可能与以前基准测试中的代码有点不同。</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="mt mu l"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">射线上分布式运行状态预测</p></figure><p id="6b0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">StatsForecast的界面非常小。它已经被设计为对每组数据执行AutoARIMA。只需提供<code class="fe mv mw mx my b">ray_address</code>就可以让这个代码片段分布式运行。如果没有它，<code class="fe mv mw mx my b">n_jobs</code>将指示用于预测的并行流程的数量。<code class="fe mv mw mx my b">model.forecast()</code>将在一个步骤中完成拟合和预测，并在时间范围内输入到该方法中进行预测。</p><h1 id="b28b" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">用神游在Spark和Dask上运行</h1><p id="3db7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated"><a class="ae ma" href="https://github.com/fugue-project/fugue" rel="noopener ugc nofollow" target="_blank"> Fugue </a>是一个抽象层，将Python、Pandas和SQL代码移植到Spark和Dask。最少的接口是<code class="fe mv mw mx my b">transform()</code>函数。这个函数接收一个函数和数据帧，并把它送到Spark或Dask。我们可以使用<code class="fe mv mw mx my b">transform()</code>函数来激活StatsForecast的执行。</p><p id="366d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的代码有两个部分。首先，我们在<code class="fe mv mw mx my b">forecast_series</code>函数中定义了预测逻辑。为了简单起见，一些参数是硬编码的。最重要的是那个<code class="fe mv mw mx my b">n_jobs=1</code>。这是因为Spark或Dask已经充当了并行化层，拥有两级并行会导致资源死锁。</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="mt mu l"/></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">运行状态预测与神游火花</p></figure><p id="5e7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次，<code class="fe mv mw mx my b">transform()</code>函数用于在Spark上应用<code class="fe mv mw mx my b">forecast_series()</code>函数。前两个参数是要应用的数据帧和函数。输出模式是Spark的一个需求，所以我们需要将它传入，分区参数将负责通过<code class="fe mv mw mx my b">unique_id</code>分割时间序列建模。</p><p id="8d8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这段代码已经运行并返回一个Spark DataFrame输出。</p><h1 id="f94c" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">尼克斯特拉氏河豚</h1><p id="6ff2" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">上面的<code class="fe mv mw mx my b">transform()</code>是大致看看神游能做什么。实际上，Fugue和Nixtla团队合作向StatsForecast库中添加了一个更加本地化的<code class="fe mv mw mx my b">FugueBackend</code>。伴随它的是一个实用的<code class="fe mv mw mx my b">forecast()</code>功能，用于简化预测界面。下面是对一百万个时间序列运行StatsForecast的端到端示例。</p><figure class="md me mf mg gt mh"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5572" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们只需要创建FugueBackend，它接收一个SparkSession并将其传递给<code class="fe mv mw mx my b">forecast()</code>。该函数可以采用数据帧或数据的文件路径。如果提供了文件路径，它将与并行后端一起加载。在上面的例子中，我们在每次运行实验来生成基准时都替换了这个文件。</p><p id="edba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样重要的是要注意，我们可以在对完整数据运行<code class="fe mv mw mx my b">forecast()</code>之前进行本地测试。我们所要做的就是不为平行论证提供任何东西；一切都将在熊猫身上按顺序运行。</p><h1 id="000f" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">基准测试结果</h1><p id="cd30" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">基准测试结果如下所示。在撰写本文时，Dask和Ray发布了最新版本，所以只有Spark指标是最新的。在用更新运行这些实验之后，我们将发表一篇后续文章。</p><figure class="md me mf mg gt mh gh gi paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="gh gi mz"><img src="../Images/bdfe0ef9e927923219e9e7b09e78db12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2ovS-D5XHQcVQobK.png"/></div></div><p class="mo mp gj gh gi mq mr bd b be z dk translated">Spark和Dask stats基准测试大规模预测</p></figure><p id="6461" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mb">注意:我们试图使用2000个CPU，但是受到AWS上可用计算实例的限制。</em></p><p id="3f87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里重要的部分是AutoARIMA在不到15分钟的时间内训练了一百万个时间序列模型。集群配置附在附录中。用很少的几行代码，我们就能够分布式地编排这些时间序列模型的训练。</p><h1 id="cca1" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">结论</h1><p id="1fbe" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">分散地训练数千个时间序列模型通常需要使用Spark和Dask进行大量编码，但是我们能够用很少几行代码运行这些实验。Nixtla的StatsForecast能够快速利用所有可用的计算资源，为每个时间序列找到最佳模型。所有用户需要做的就是提供一个相关的并行后端(Ray或Fugue)在集群上运行。</p><p id="b041" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在一百万时间序列的规模上，我们对AutoARIMA的总训练时间为12分钟。这相当于我们立即运行了近400个cpu小时，允许数据科学家快速大规模迭代，而无需编写显式的并行化代码。因为我们使用了一个短暂的集群，所以成本实际上与在EC2实例上顺序运行这个集群(在所有内核上并行化)是一样的。</p><h1 id="7b15" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">资源</h1><ol class=""><li id="05a7" class="na nb iq kh b ki lv kl lw ko nc ks nd kw ne la nf ng nh ni bi translated"><a class="ae ma" href="https://github.com/Nixtla/statsforecast" rel="noopener ugc nofollow" target="_blank"> Nixtla StatsForecast回购</a></li><li id="81c3" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae ma" href="https://nixtla.github.io/statsforecast/" rel="noopener ugc nofollow" target="_blank">统计预测文档</a></li><li id="e5a6" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae ma" href="https://github.com/fugue-project/fugue/" rel="noopener ugc nofollow" target="_blank">赋格回购</a></li><li id="e1b8" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae ma" href="https://fugue-tutorials.readthedocs.io/" rel="noopener ugc nofollow" target="_blank">赋格教程</a></li></ol><p id="a1fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要与我们聊天:</p><ol class=""><li id="76b8" class="na nb iq kh b ki kj kl km ko no ks np kw nq la nf ng nh ni bi translated"><a class="ae ma" href="http://slack.fugue.ai/" rel="noopener ugc nofollow" target="_blank">赋格松弛</a></li><li id="51b4" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated"><a class="ae ma" href="https://join.slack.com/t/nixtlaworkspace/shared_invite/zt-135dssye9-fWTzMpv2WBthq8NK0Yvu6A" rel="noopener ugc nofollow" target="_blank">尼克斯特拉松驰</a></li></ol><h1 id="030f" class="ld le iq bd lf lg lh li lj lk ll lm ln jw lo jx lp jz lq ka lr kc ls kd lt lu bi translated">附录</h1><p id="a9e3" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">对任何人来说。对集群配置感兴趣，可以看下面。这将启动Databricks集群。重要的是使用机器的<code class="fe mv mw mx my b">node_type_id</code>。</p><pre class="md me mf mg gt nr my ns nt aw nu bi"><span id="80d6" class="nv le iq my b gy nw nx l ny nz">{<br/>    "num_workers": 20,<br/>    "cluster_name": "fugue-nixtla-2",<br/>    "spark_version": "10.4.x-scala2.12",<br/>    "spark_conf": {<br/>        "spark.speculation": "true",<br/>        "spark.sql.shuffle.partitions": "8000",<br/>        "spark.sql.adaptive.enabled": "false",<br/>        "spark.task.cpus": "1"<br/>    },<br/>    "aws_attributes": {<br/>        "first_on_demand": 1,<br/>        "availability": "SPOT_WITH_FALLBACK",<br/>        "zone_id": "us-west-2c",<br/>        "spot_bid_price_percent": 100,<br/>        "ebs_volume_type": "GENERAL_PURPOSE_SSD",<br/>        "ebs_volume_count": 1,<br/>        "ebs_volume_size": 32<br/>    },<br/>    "node_type_id": "m5.24xlarge",<br/>    "driver_node_type_id": "m5.2xlarge",<br/>    "ssh_public_keys": [],<br/>    "custom_tags": {},<br/>    "spark_env_vars": {<br/>        "MKL_NUM_THREADS": "1",<br/>        "OPENBLAS_NUM_THREADS": "1",<br/>        "VECLIB_MAXIMUM_THREADS": "1",<br/>        "OMP_NUM_THREADS": "1",<br/>        "NUMEXPR_NUM_THREADS": "1"<br/>    },<br/>    "autotermination_minutes": 20,<br/>    "enable_elastic_disk": false,<br/>    "cluster_source": "UI",<br/>    "init_scripts": [],<br/>    "runtime_engine": "STANDARD",<br/>    "cluster_id": "0728-004950-oefym0ss"<br/>}</span></pre></div></div>    
</body>
</html>