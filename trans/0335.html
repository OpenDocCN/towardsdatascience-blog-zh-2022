<html>
<head>
<title>Long-Form QA beyond ELI5: an updated dataset and approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越ELI5的长篇问答:一个更新的数据集和方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/long-form-qa-beyond-eli5-an-updated-dataset-and-approach-319cb841aabb#2022-02-14">https://towardsdatascience.com/long-form-qa-beyond-eli5-an-updated-dataset-and-approach-319cb841aabb#2022-02-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1851" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们介绍了ELI5数据集的后继者，这是一个构建长格式问题回答(LFQA)的基础，这是一个为开放式问题生成详细答案的任务</h2></div><p id="8747" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每天我们打开笔记本电脑和智能手机，打开网络浏览器，导航到我们最喜欢的搜索引擎，搜索我们问题的答案。这种惯例框定了我们的个人和职业生活。现代搜索引擎提供网站推荐，而不是简单的答案。但这种情况即将改变。</p><p id="76dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一代搜索引擎的原型已经在这里，它们只是对公众隐藏起来，目前仅限于OpenAI和DeepMind等公司的研究实验室。仅仅相隔几天，2021年12月，OpenAI和DeepMind都发布了这些系统的预览。OpenAI展示了一个系统，它可以综合我们网络搜索类问题的原始答案，同时引用网络参考来支持这些答案。DeepMind发布了一个检索增强的Transformer (RETRO)，专门从事知识密集型开放式问题回答。</p><p id="34a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些都是令人兴奋的发展，但基于所谓的长格式问答(LFQA)的系统仍未准备好被广泛采用。我们希望今天发布的LFQA数据集是朝着正确方向迈出的又一步。除了LFQA数据集，我们还发布了基于BART的Seq2Seq模型的新版本，用于抽象答案生成和匹配基于DPR的问题和上下文段落编码器。</p><p id="665f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们深入研究数据集，这是LFQA系统背后的一个重要难题，以及我们改进它的工作。我们将涵盖最初的绊脚石和我们前进的尝试，并解决阻碍这一激动人心的领域进展的一些障碍。</p><p id="5326" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">背景</strong></p><p id="0fda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在过去的几年里，我们见证了自然语言处理(NLP)的惊人进步。基于最新语言模型(BERT、Roberta等)的问答系统。)可以相对轻松且精确地回答基于仿真陈述的问题。这些问答系统提出一个问题，找到相关的文档段落，并通过扫描正确的单词标记范围来提取最可能的答案。</p><p id="c421" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，研究人员开发了更复杂的问答系统，可以回答需要大段答案的开放式问题。这些系统通常被归类为长格式问题回答(LFQA)系统。它们通过在大型文档库中查询相关信息，然后使用检索到的文档来生成精确的多句子答案。与给定查询相关的文档，通俗地称为上下文段落，不仅仅用作提取的答案的源标记，而是为原始的、抽象的长形式答案的合成提供更大的上下文。LFQA系统通常由三部分组成:</p><ul class=""><li id="28e2" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">包含各种主题的内容段落的文档存储</li><li id="d249" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">检索器模型对文档/问题进行编码，以便可以查询文档存储</li><li id="fb66" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">Seq2Seq语言模型能够在给出问题和从文档存储中检索的上下文段落时生成整段的答案</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/c1bfbe086b58957f539ab002921f29e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CYTPdp-ajl6wSddqMhb3Qw.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">LFQA架构—作者图片</p></figure><p id="cf53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">动机</strong></p><p id="9a20" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些组成部分提出了一些挑战，但最近取得了进展。2019年，Angel Fan等人在他们的开创性研究论文<a class="ae mf" href="https://arxiv.org/abs/1907.09190" rel="noopener ugc nofollow" target="_blank">“Eli 5:长格式问答”</a>中正式介绍了长格式问答的任务。它包含了来自Reddit论坛的27万个问题/答案对的数据集，“像我五岁一样解释”(ELI5)，这是一个在线社区，致力于使用五岁儿童可以理解的语言回答复杂的问题。ELI5数据集由不同的问题组成，这些问题需要大段的答案。尽管生成ELI5答案的Seq2Seq模型产生了相对可理解的答案，但人类评估者在超过86%的情况下更喜欢黄金答案，这表明了未来改进的潜力。</p><p id="1f4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，Krishna等人在他们的论文<a class="ae mf" href="https://arxiv.org/abs/2103.06332" rel="noopener ugc nofollow" target="_blank">“长格式问题回答进展的障碍”</a>中描述了他们如何使用REALM初始化的、基于BERT的检索器和基于路由转换器的Seq2Seq答案生成模型来改进原始LFQA任务。除了在LFQA任务KILT基准上达到“最先进”水平，Krishna等人还发现了LFQA的四个悬而未决的问题:</p><ul class=""><li id="f1de" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">ELI5数据集具有显著的训练/验证/测试数据集重叠</li><li id="0b09" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">答案生成不以检索(上下文段落)为基础</li><li id="b9a7" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">LFQA任务指标需要改进</li><li id="8ec4" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">人工评估具有挑战性，但对于评估LFQA是必要的</li></ul><p id="f2b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些问题中的每一个对于整体上改进LFQA任务都是非常重要的。</p><p id="01b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> LFQA数据集—减少ELI5训练/验证/测试重叠</strong></p><p id="b241" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">着眼于推进和改进LFQA，我们创建了一个训练/验证/测试数据集，与ELI5数据集相比，该数据集减少了重叠。我们怀疑减少重叠可能会改善答案在各自检索中的基础。</p><p id="0f2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用<a class="ae mf" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子-BERT </a> (SBERT)、语义搜索工具和HuggingFace (HF) ELI5数据集来比较训练、测试和验证集中的问题，以衡量语义相似性。更准确地说，我们比较了数据集问题的前K个相似性得分(K = 1，2，3 ),并证实了Krishna等人报告的重叠结果。</p><p id="52db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用人类的判断，我们已经发现高于余弦相似度阈值0.8的问题非常相似，而高于0.84的问题几乎是相互转述。以下是从KILT ELI5验证集中选择的几个示例问题，训练集中最相似的“兄弟”问题，以及它们各自的余弦相似性。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/f1ad3fe503ac90cf9a03c1078bd8ce55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*Z4QFn2XbBEzXgqso8SvaPA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">ELI5问题示例—作者图片</p></figure><p id="5c90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Krishna等人进行了一项人类研究，发现“81%的验证集问题在训练集中至少有一个释义，而所有带注释的问题在训练集中至少有一个主题相似的问题，这表明大量的训练/验证重叠。”</p><p id="0c30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用SBert，我们为验证和测试集中的每个问题在训练集中搜索语义最相似的问题。然后，我们绘制了数据集中训练/验证和训练/测试问题之间语义相似性的概率。如下面的重叠概率图所示，在训练集中，验证问题具有非常相似的问题“兄弟”的概率确实很大。然而，我们的估计比Krishna等人报告的81%要小一些，更接近60-65%。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/a55daed391c25d48bab9487c083ed702.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*0DLQcOfx7iqJjfMi98BfXg.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">ELI5训练/验证和训练/测试重叠(0–1相似性范围的50个箱)-按作者分类的图像</p></figure><p id="713c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然比训练/验证重叠稍小，但是测试和训练集问题之间显著语义相似的概率也很高。</p><p id="5868" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新的LFQA数据集包含来自三个Reddit论坛的问题/答案对:r/explainelikeimfive、r/ask histories和r/askscience。我们的目标是创建一个新的LFQA数据集，包含训练/验证/测试分割，以便:</p><ul class=""><li id="45f5" class="lb lc iq kh b ki kj kl km ko ld ks le kw lf la lg lh li lj bi translated">所有三个子网格在所有分割中被同等地表示</li><li id="7987" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">与旧的ELI5数据集相比，训练/验证/测试重叠被最小化，同时保持数据集的大小</li><li id="d806" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">验证/测试分割包含来自数据集的KILT版本的所有ELI5测试/验证示例</li><li id="4c05" class="lb lc iq kh b ki lk kl ll ko lm ks ln kw lo la lg lh li lj bi translated">验证和测试分割包括具有高Reddit分数(投票)的问题</li></ul><p id="f53a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于问题嵌入在空间上不是均匀分布的，我们求助于层次聚类。在问题空间的密集部分中具有0.9点积的两个问题可能需要不同的答案，而相反，在空间的稀疏部分中具有0.8点积的问题可能是同一问题。</p><p id="1367" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在分层问题聚类之后，我们尝试了一种只选择叶节点的启发式方法，但是这种方法导致数据集的数据点太少。由于一些非叶节点彼此非常接近，我们添加了一个自适应停止标准，该标准只到达某个深度、连接相似性阈值或子树中的一些项目。正如我们将在下面看到的，0.83的点积相似性阈值产生了适当大小的数据集，但训练/验证/测试重叠更小。正如您在下面的相似性概率图中看到的，与ELI5数据集(左)相比，新的LFQA数据集(右)的训练/验证重叠显著减少，相似性更高。只有一小部分问题的最大相似度为0.83——大多数重叠问题的相似度为0.75及以下。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/0e1f84505da184437cd48bc18601099b.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*YHX4E9DBGqsMgnJwN4e0Hw.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">ELI5与LFQA训练/验证重叠(0–1相似性范围的50个箱)-按作者分类的图像</p></figure><p id="d7d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，训练/测试重叠也减少了。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/d2b527fcd3e6221885a68fc4503b62f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*go30MB2xVsSkZpbzMyDaNA.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">ELI5与LFQA训练/测试重叠(0–1相似性范围的50个箱)—作者图片</p></figure><p id="fecd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是从LFQA验证集中选择的几个示例问题，它们在训练集中最相似的“兄弟”问题，以及它们各自的余弦相似性。在训练/验证和训练/测试集中没有相似性超过0.83的问题。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/dc074fa4f9d3afb887f921368585ff01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*CixxnbEtrqLZmGZp473oUw.png"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">LFQA问题示例—作者图片</p></figure><p id="d10f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LFQA DPR寻回犬</p><p id="3bb8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了生成所提问题的答案，抽象答案生成模型依赖于检索器来找到相关的上下文段落。LFQA检索器由基于DPR的问题和上下文编码器组成。</p><p id="1409" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们分两个阶段使用<a class="ae mf" href="https://github.com/facebookresearch/dpr-scale/" rel="noopener ugc nofollow" target="_blank"> FAIR的dpr-scale </a>训练我们的DPR寻回犬。在第一阶段，我们使用基于PAQ的预训练检查点，并在LFQA数据集的问答对上微调检索器。由于dpr-scale需要具有阳性、阴性和硬阴性样本的dpr格式的训练集输入，我们创建了一个训练文件，其中阳性对应于一个答案，阴性是与问题无关的答案，而硬阴性样本选自余弦相似度在0.55和0.65之间的问题的答案。在第二阶段，我们使用来自第一阶段创建的维基百科/Faiss索引而不是来自LFQA数据集答案的正面、负面和硬负面来创建新的DPR训练集。更准确地说，对于每个数据集问题，我们查询第一阶段维基百科/Faiss索引，随后使用SBert交叉编码器对topk=50的问题/答案(段落)对进行评分。交叉编码器选择正样本以对应于具有最高分数的段落，底部的七个答案被选择用于硬负样本，而负样本再次是与给定数据集问题无关的答案。在用维基百科来源的正面、负面和硬负面段落创建了DPR格式的训练文件后，我们使用dpr-scale训练了DPR的问题/段落编码器。新的LFQA DPR检索器的性能略低于Krishna等人使用的REALM检索器，R-precision的KILT基准性能为11.2，Recall@5的KILT基准性能为19.5。</p><p id="db93" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">演示</strong></p><p id="1cdb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了纪念新的LFQA数据集、基于LFQA BART的Seq2Seq模型和基于DPR的retriever模型的发布，我们还在https://huggingface.co/spaces/lfqa/lfqa<a class="ae mf" href="https://huggingface.co/spaces/lfqa/lfqa" rel="noopener ugc nofollow" target="_blank">发布了维基百科助手的HuggingFace Spaces演示</a></p><p id="09ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了找到与问题相关的维基百科上下文段落，我们使用cortex.dev ML部署平台在AWS云上部署了一个上下文服务器。上下文服务器包含加载到FAISS索引中的维基百科快照的编码版本。用户可以问与科学、历史和维基百科上的其他不同主题相关的长格式开放式问题。给定一个任意的用户问题，DPR检索器将从上下文服务器中检索相关的文档，并将它们传递给BART LFQA模型，该模型将生成一个抽象的答案，并且传递给文本到语音模型，该模型将生成一个音频响应。在前面提到的HuggingFace Spaces位置可以获得演示以及模型训练代码和实用程序。</p><p id="f7a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们今天发布的LFQA数据集有226147个训练，3020个验证和10000个测试样本。LFQA数据集具有显著减少的训练/验证/测试重叠，可以成为解决长格式问题回答中剩余障碍的垫脚石。</p><p id="53cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">LFQA数据集、基于DPR的检索器和新的基于LFQA BART的抽象答案生成模型都可以在https://huggingface.co/vblagoje<a class="ae mf" href="https://huggingface.co/vblagoje" rel="noopener ugc nofollow" target="_blank">的HuggingFace hub上获得</a></p><p id="5f3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们要感谢Yacine Jernite在整个项目中提供的宝贵反馈。布兰登·陈、巴勃罗·罗德里格斯·贝托雷罗、苏奇米特·马哈帕特拉和克里斯蒂娜·克雷斯勒对本文的初稿提供了反馈。</p><p id="739d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> BibTeX引文</strong></p><pre class="lq lr ls lt gt ml mm mn mo aw mp bi"><span id="6f38" class="mq mr iq mm b gy ms mt l mu mv">@article{blagojevic2022lfqa,<br/>  author={Vladimir Blagojevic},<br/>  title={Long-Form QA beyond ELI5: an updated dataset and approach},<br/>  year={2022},<br/>  url={towardsdatascience.com/long-form-qa-beyond-eli5-an-updated-dataset-and-approach-319cb841aabb},<br/>}</span></pre><p id="796e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">附录</strong></p><p id="7e63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">来自验证集的示例问题及其生成的答案</strong></p><p id="cd8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">是什么造成了高空喷气式飞机后面的尾迹？</p><p id="535b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它被称为轨迹，是由喷气发动机排气中的水蒸气凝结造成的。水蒸气凝结在喷流的排气羽流上，当它凝结时，会在喷流后面留下一条尾迹。</p><p id="39dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为什么我可以在嘈杂的环境中入睡(学校讲座、公共交通、电影院等)，但当我在床上时，更小的噪音也会打扰我的睡眠？</p><p id="7c56" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我认为这与你大脑的工作方式有关。当你处于安静的环境中时，你的大脑不需要像醒着时那样处理大量的信息，所以你不需要那么多的处理能力来入睡。这就是为什么你会在嘈杂的环境中睡着(学校讲座、公共交通、电影院等)。)但是更小的噪音也会打扰你的睡眠。</p><p id="9a1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">马里正在发生什么，德国和法国与此有什么关系？</p><p id="4ab4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">马里是非洲萨赫勒地区的一个国家。它有大量的穆斯林人口。过去几年，马里发生了多起恐怖袭击事件。马里政府无力阻止这些袭击，被迫诉诸军事行动来阻止这些袭击。德国和法国决定向马里派兵，帮助马里政府打击恐怖分子。这是欧盟军队首次在非洲部署。</p><p id="633d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">教皇实际上是做什么的？</p><p id="a332" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">教皇是罗马天主教会的领袖。他也是整个天主教会的领袖。教皇是由枢机主教团选出的，枢机主教团是由教会的主教们选出的一群枢机主教。该学院由来自世界各地的主教组成，教皇由他们推选为罗马主教。</p></div></div>    
</body>
</html>