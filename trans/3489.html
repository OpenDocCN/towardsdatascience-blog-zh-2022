<html>
<head>
<title>Transfer Learning and Twin Network for Image Classification using Flux.jl</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于Flux.jl的迁移学习和孪生网络图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-and-twin-network-for-image-classification-using-flux-jl-cbe012ced146#2022-08-02">https://towardsdatascience.com/transfer-learning-and-twin-network-for-image-classification-using-flux-jl-cbe012ced146#2022-08-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="436b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用数据加载器、Metalhead.jl和双网络设计解决挑战</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0244d4421078afc630a79649c8d7976f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H76ipwZg7g9KH4CE"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卢卡·布拉沃在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f81b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今年早些时候，我在PyTorch从事一个项目，旨在创建一个深度学习模型，可以检测未知物种中的疾病。最近，我决定在Julia中重建该项目，并将其作为学习<a class="ae kv" href="https://fluxml.ai" rel="noopener ugc nofollow" target="_blank">flux . JL</a>【1】的一个练习，这是Julia最受欢迎的深度学习包(<a class="ae kv" href="https://juliahub.com/ui/Packages" rel="noopener ugc nofollow" target="_blank">至少按GitHub上的星级数评级</a>)。但是在这样做的时候，我遇到了一些挑战，这些挑战我在网上或文档中找不到好的例子。因此，我决定写下这篇文章，作为任何想做和我类似事情的人的资源。</p><h1 id="66eb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">这是给谁的？</h1><p id="974d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">因为Flux.jl(以下简称“Flux”)是一个深度学习包，所以我写这篇文章主要是为了让熟悉迁移学习等深度学习概念的受众。</p><p id="32fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然我也是带着一个半新手(像我一样)的想法来写这篇文章的，但是其他人可能会觉得这篇文章很有价值。请记住，我写这篇文章并不是为了全面介绍或指导Julia或Flux。为此，我将尊重其他资源，如正式的朱莉娅和通量文件，分别。</p><p id="2f57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我与PyTorch做了几次比较。理解我的观点并不需要PyTorch的经验，但是有PyTorch经验的人可能会觉得特别有趣。</p><h1 id="fb42" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么是朱莉娅？还有为什么是Flux.jl？</h1><p id="0387" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果你已经使用了Julia和/或Flux，你可以跳过这一节。此外，许多其他人已经写了很多关于这个问题的帖子，所以我会很简短。</p><p id="55ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最终是我喜欢朱莉娅。它擅长数值计算，编程是一种真正的乐趣，而且速度很快。本机速度快:不需要NumPy或其他封装底层C++代码的包装器。</p><p id="4635" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">至于为什么是Flux，那是因为它是Julia中最流行的深度学习框架，用纯Julia编写，可与Julia生态系统组合。这个项目看起来和任何最终学习通量的项目一样好。</p><h1 id="94e6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">项目本身</h1><p id="c574" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">好了，现在我已经无耻地说服了朱莉娅，是时候了解一下这个项目本身了。我使用了三个数据集——<a class="ae kv" href="https://data.mendeley.com/datasets/tywbtsjrjv/1" rel="noopener ugc nofollow" target="_blank">plant village</a>【2】、<a class="ae kv" href="https://data.mendeley.com/datasets/hb74ynkjcn/1" rel="noopener ugc nofollow" target="_blank">plant leaves</a>【3】和<a class="ae kv" href="https://data.mendeley.com/datasets/t6j2h22jpx/1" rel="noopener ugc nofollow" target="_blank">plant aek</a>【4】——涵盖了许多不同的物种。我使用PlantVillage作为训练集，另外两个组合作为测试集。这意味着模型必须学习一些对未知物种通用的东西，因为测试集将包含未经训练的物种。</p><p id="251f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">了解这一点后，我创建了三个模型:</p><ol class=""><li id="78bf" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">使用ResNet迁移学习的基线</li><li id="806a" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">具有定制CNN架构的双(又名，<a class="ae kv" href="https://en.wikipedia.org/wiki/Siamese_neural_network" rel="noopener ugc nofollow" target="_blank">连体</a>)神经网络</li><li id="4f40" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">具有迁移学习双路径的双神经网络</li></ol><p id="39c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的其余部分将详细介绍处理数据以及创建和训练模型的一些挑战和难点。</p><h1 id="7aa4" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">处理数据</h1><p id="f041" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">第一个挑战是数据集的形式不正确。我不会在这里详述我是如何预处理它们的，但简单来说，我创建了两个图像目录，<em class="mp"> train </em>和<em class="mp"> test </em>。两者都写满了一长串的图片，分别叫做<em class="mp">img0.jpg</em>、<em class="mp">img1.jpg</em>、<em class="mp">img2.jpg</em>等等。我还创建了两个CSV——一个用于训练集，一个用于测试集——包含一列文件名，一列二进制标签。</p><p id="14d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的结构很关键，因为总的数据集超过10 GB，肯定不适合我的PC的内存，更不用说我的GPU的内存了。正因为如此，我们需要使用一个<code class="fe ne nf ng nh b">DataLoader</code>。(如果你用过PyTorch，你会很熟悉；这和PyTorch中的概念基本相同。)</p><p id="f74d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要在Flux中做到这一点，我们需要创建一个自定义结构来包装我们的数据集，以允许它成批地加载数据。为了让我们的自定义结构能够构造一个数据加载器，我们需要做的就是为这个类型定义两个方法:<code class="fe ne nf ng nh b">length</code>和<code class="fe ne nf ng nh b">getindex</code>。下面是我们将用于数据集的实现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="3937" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本质上，它的工作方式是当Flux试图检索一批图像时，它会调用<code class="fe ne nf ng nh b">getindex(dataloader, i:i+batchsize)</code>，这在Julia中相当于<code class="fe ne nf ng nh b">dataloader[i:i+batchsize]</code>。因此，我们的自定义<code class="fe ne nf ng nh b">getindex</code>函数获取文件名列表，获取适当的文件名，加载这些图像，然后处理它们并将其重塑为适当的<code class="fe ne nf ng nh b">HEIGHT × WIDTH × COLOR × NUMBER</code>形状。对标签进行类似的操作。</p><p id="7137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们的培训、验证和测试数据加载器可以非常容易地完成:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><h1 id="1944" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">制作一些模型</h1><p id="97d0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">数据加载器准备就绪后，下一步是创建模型。其中第一个是基于ResNet的迁移学习模型。这实际上被证明是相对具有挑战性的工作，虽然希望它会很快得到解决。</p><p id="16f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" href="https://fluxml.ai/Metalhead.jl/dev/README.html" rel="noopener ugc nofollow" target="_blank"> Metalhead.jl </a>包中——包含用于迁移学习的计算机视觉通量模型——创建一个带有预训练权重的ResNet18模型应该像<code class="fe ne nf ng nh b">model = ResNet(18; pretrain = true)</code>一样简单。然而，至少在撰写本文时，创建预训练模型会导致错误。这可能是因为Metalhead.jl仍在添加预训练的权重。终于在HuggingFace上找到了<em class="mp"> .tar.gz </em>文件，里面包含了这里的权重<a class="ae kv" href="https://huggingface.co/FluxML/resnet18" rel="noopener ugc nofollow" target="_blank">。提取tarball后得到一个普通的<em class="mp">。bson </em>文件，我们可以使用以下代码来加载权重，并创建我们自己的自定义通量模型，具有单个二进制输出:</a></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="0d40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(注:如果有比这更优雅的方式来改变ResNet的最后一层，请告诉我。)</p><p id="5cb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着预训练迁移学习模型的建立，只剩下两个孪生网络模型。然而，与迁移学习不同，我们必须学习如何手动创建模型。(如果你习惯了PyTorch，这就是Flux与PyTorch大相径庭的地方。)</p><p id="c8c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Flux文档和其他在线资源创建CNN相对容易。然而，Flux没有内置层来表示具有参数共享的孪生网络。它最接近的是<code class="fe ne nf ng nh b">Parallel</code>层，这个层<em class="mp">不</em>使用参数共享。</p><p id="9436" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，Flux确实有文档<a class="ae kv" href="https://fluxml.ai/Flux.jl/stable/models/advanced/#Custom-multiple-input-or-output-layer" rel="noopener ugc nofollow" target="_blank">在这里</a>关于如何创建定制的多输入或输出层。在我们的例子中，我们可以用来创建自定义<code class="fe ne nf ng nh b">Twin</code>层的代码如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="905b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先注意，它以一个简单的结构<code class="fe ne nf ng nh b">Twin</code>开始，有两个字段<code class="fe ne nf ng nh b">combine</code>和<code class="fe ne nf ng nh b">path</code>。<code class="fe ne nf ng nh b">path </code>是我们的两个图像输入将经过的网络，<code class="fe ne nf ng nh b">combine</code>是最终将来自<code class="fe ne nf ng nh b">path </code>的输出组合在一起的功能。</p><p id="2c06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，使用<code class="fe ne nf ng nh b">Flux.@functor</code>告诉Flux像对待常规Flux层一样对待我们的结构，并且<code class="fe ne nf ng nh b">(m::Twin)(Xs::Tuple) = m.combine(map(X -&gt; m.path(X), Xs)…)</code>定义向前传递，其中元组Xs中的所有输入X都通过<code class="fe ne nf ng nh b">path</code>馈送，然后所有输出都通过<code class="fe ne nf ng nh b">combine</code>传递。</p><p id="8a11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要创建具有定制CNN架构的Twin网络，我们可以执行以下操作:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="eb1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，我们实际上使用<code class="fe ne nf ng nh b">Flux.Bilinear</code>层作为<code class="fe ne nf ng nh b">combine</code>，这实质上创建了一个完全连接到两个独立输入的输出层。以上两个输入是<code class="fe ne nf ng nh b">path</code>的输出，即自定义CNN架构。或者，我们可以以某种方式使用<code class="fe ne nf ng nh b">hcat</code>或<code class="fe ne nf ng nh b">vcat</code>作为<code class="fe ne nf ng nh b">combine</code>，然后在最后添加一个<code class="fe ne nf ng nh b">Dense</code>层，但是这个解决方案对于这个问题来说似乎更优雅。</p><p id="3bb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，要使用ResNet创建Twin网络，我们可以执行以下操作:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="eb06" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意我们如何使用与之前相同的技巧，使用一个<code class="fe ne nf ng nh b">Flux.Bilinear</code>层作为<code class="fe ne nf ng nh b">combine</code>，并使用一个与之前类似的技巧来使用预训练的ResNet作为<code class="fe ne nf ng nh b">path</code>。</p><h1 id="fcd0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">训练时间</h1><p id="81ff" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在我们已经准备好了数据加载器和模型，剩下的就是训练了。通常在Flux中，我们可以使用一个简单的一行程序，<code class="fe ne nf ng nh b">@epochs 2 Flux.train!(loss, ps, dataset, opt)</code>，用于训练循环，但是我们确实有一些定制的东西想要用我们的来做。</p><p id="da79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，非孪生网络的训练循环:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="da85" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里要展开的内容很多，但本质上它做了几件事:</p><ol class=""><li id="c67a" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">它创建了一个助手结构，用于跟踪我们想要的任何验证指标。在这种情况下，每个历元的损失和精度。</li><li id="7624" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">它只选择最后一层参数进行训练。如果我们想的话，我们<em class="mp">可以</em>训练整个模型，但是那会在计算上更加费力。这是不必要的，因为我们用的是预训练的砝码。</li><li id="a7af" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">对于每个历元，它遍历训练集的所有批次进行训练。然后，它计算整个验证集(当然是分批的)的准确性和损失。如果历元的验证精度得到提高，则可以省去模型。如果没有，它继续到下一个纪元。</li></ol><p id="86b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们在这里可以做得更多，例如，提前停止，但以上足以获得大致的想法。</p><p id="bbb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，双网络的训练循环非常相似，但略有不同:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="886f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先注意，我们使用了一个同名的函数，<code class="fe ne nf ng nh b">train!</code>，但是函数签名略有不同。这使得Julia能够根据我们训练的网络类型分配正确的功能。</p><p id="54aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还要注意，Twin ResNet模型冻结了它的预训练参数，而我们训练所有的Twin自定义CNN参数。</p><p id="1823" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除此之外，训练循环的其余部分基本相同，只是我们必须使用两个训练数据加载器和两个验证数据加载器。这为我们提供了每批的两个输入和两组标签，我们将其适当地输入到孪生模型中。最后，请注意，孪生模型预测两个输入图像是否具有相同的标签，而常规非孪生网络仅直接预测标签。</p><p id="ed79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样，为所有三个模型的测试集构建测试循环应该不会太难。因为这篇文章的目的是讨论我在网上找不到例子的主要难点，所以我将测试部分留给读者作为练习。</p><h1 id="406a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">最后的想法</h1><p id="48ba" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">他们所说的Julia生态系统的现状有一定的真实性，即它可能不成熟，人们需要愿意处理有限的文档和/或稀缺的例子。</p><p id="31a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最大的挑战是弥合从相对容易、简单的示例到更高级的技术之间的差距，对于这些技术来说，示例很少。但是这也揭示了Julia的一个优势:因为它天生就很快，所以搜索一个包的源代码来找到答案通常非常容易。有几次，我发现自己在浏览Flux源代码，寻找一些东西是如何工作的。每次我都能非常轻松快捷地找到答案。我不确定我是否有足够的勇气为PyTorch尝试类似的事情。</p><p id="a71a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个挑战是Metalhead.jl的不成熟状态，这在Julia生态系统中肯定不是唯一一个功能不完整的。</p><p id="e7f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我上一个挑战实际上是一个心态挑战。Python和Julia生态系统之间的一个根本区别是许多重要包的规模。例如，PyTorch因为其内部的C++需要做所有的事情，而纯Julia包可以轻松地互操作和组合。因此，你不会看到Flux有PyTorch那么多的特性。相反，你会在其他包中看到很多这样的功能，比如MLUtils.jl、CUDA.jl、BSON.jl、Metalhead.jl以及其他无数的包。记住这一点，无论何时用Julia编程，你都可以节省一些时间和精力。</p><p id="9b0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为最后一个想法，我发现通量是相当愉快和优雅的…一旦我掌握了它。我以后肯定会用Flux做更多的深度学习。</p><h1 id="5c8e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="962e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1] M. Innes，Flux:优雅的机器学习与Julia (2018)，《开源软件杂志》</p><p id="d24a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] Arun Pandian J .和G. Gopal，数据用于:使用9层深度卷积神经网络识别植物叶部病害(2019)，Mendeley数据</p><p id="687b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] S. S. Chouhan、A. Kaul和U. P. Singh,《叶片图像数据库:植物病理学植物保护实践》( 2019年), Mendely Data</p><p id="69cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] V. P. Kour和S. Arora，PlantaeK:查谟和克什米尔本地植物叶数据库(2019年)，Mendeley数据</p></div></div>    
</body>
</html>