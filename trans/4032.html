<html>
<head>
<title>Sigmoid and SoftMax Functions in 5 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Sigmoid和SoftMax功能在5分钟内完成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9#2022-09-08">https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9#2022-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0741" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">机器学习中两个最常用的激活函数背后的数学原理</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/61e6fc0a6631387dc173eb43e4d97e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SgscrlOX-P8eljSZukn9dQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com/@malcoo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@malcoo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Tomámalík</a>拍摄。作者编辑</p></figure><p id="f1fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> T </span> he Sigmoid和SoftMax函数定义了用于机器学习的<strong class="ky ir">激活函数</strong>，更具体地说是用于<strong class="ky ir">分类方法的深度学习领域。</strong></p><p id="2519" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="http://a" rel="noopener ugc nofollow" target="_blank"> <em class="mb">激活函数</em> </a>:对神经元的加权和进行变换，使输出为非线性的函数</p><blockquote class="mc md me"><p id="efb6" class="kw kx mb ky b kz la jr lb lc ld ju le mf lg lh li mg lk ll lm mh lo lp lq lr ij bi translated">注意。sigmoid函数也被称为<strong class="ky ir">逻辑函数</strong>,因为它最初是通过逻辑回归算法引入的</p></blockquote><p id="3af2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两个函数都从实数R的范围中取一个值χ，并输出一个介于0和1之间的数，该数代表χ属于某一类的概率<strong class="ky ir">和</strong>。</p><p id="43ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="http://b" rel="noopener ugc nofollow" target="_blank"> <em class="mb">符号</em> </a> : <em class="mb"> P(Y=k|X=x) </em>读作“给定输入X为X，Y为k的概率”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mi"><img src="../Images/0ff2aeb048a17204f973d9ed9a1a00ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrgeNELaRQxriLmBrGweMA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">图一</strong>。Sigmoid和SoftMax函数的图示。输出读作“给定输入X，Y成为类k的概率”。作者图片</p></figure><p id="b31a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">但是如果两个函数映射相同的转换(即做相同的事情)，它们之间的区别是什么？<br/> </strong> Sigmoid用于<strong class="ky ir">二元分类</strong>方法，其中我们只有2个类，而SoftMax适用于<strong class="ky ir">多类问题</strong>。实际上，SoftMax函数是Sigmoid函数的扩展。<br/>因此，两个函数的输入和输出略有不同，因为<strong class="ky ir"> Sigmoid </strong>只接收一个输入，并且只输出一个表示属于<em class="mb"> class1 </em>的概率的数字(记住我们只有2个类，因此属于<em class="mb"> class2的概率= 1 - P(class1) </em>)。而另一方面,<strong class="ky ir"> SoftMax </strong>是矢量化的，这意味着它采用一个与我们拥有的类具有相同条目数量的向量，并输出另一个向量，其中每个分量代表属于该类的概率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/d41fdbff7c97468f9f6e32c7e26c51d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WfERQXN_BtLi1eAh36_mvw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">图二</strong>。每个功能的输出图示。一个重要的性质是将每个Sigmoid类的所有概率相加，并且SoftMax应该等于1。在Sigmoid的情况下，我们得到P(Y=class2|X) = 1 - P(Y=class1|X)。作者图片</p></figure><p id="ed97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经知道每个函数的作用以及在什么情况下使用它们。唯一剩下的就是数学公式(<em class="mb">更多的数学符号！</em>)</p><h1 id="4af2" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">Sigmoid和SoftMax函数的数学公式</h1><h2 id="3b4f" class="nd mm iq bd mn ne nf dn mr ng nh dp mv lf ni nj mx lj nk nl mz ln nm nn nb no bi translated">Sigmoid函数</h2><p id="1aba" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">假设我们的模型输出单个值<em class="mb"> X </em>，它可以从实数X ∈ (-∞，+∞)中取任何值，我们希望将该数字转换为概率P ∈ [0，1]，它表示属于第一类的概率(我们只有两个类)。</p><p id="a146" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，要解决这个问题，我们必须以相反的方式思考。我怎么把一个概率P ∈ [0，1]转换成一个值X ∈ (-∞，+∞)？<br/>虽然看起来不合逻辑，但解决之道在于<strong class="ky ir">赌马</strong> ( <em class="mb">数学家向来喜欢游戏</em>)。</p><p id="de33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在赛马投注中，有一个常用术语叫做<strong class="ky ir"> <em class="mb">赔率</em></strong>【1】。当我们说17号马赢得比赛的几率是3/8时，我们实际上是说在11场比赛后，这匹马将赢得其中的3场，输掉8场。在数学上，赔率可以被视为两个独立事件之间的比率，并表示为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3f38aa6c3b0961527b9bc263ad8b9905.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/0*zkV8Raj1f_jNc7Xl.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">赔率公式</strong></p></figure><p id="0b9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">赔率可以取任何正值，因此没有上限限制[0，+∞]。然而，如果我们取对数奇数，我们发现范围值变为(-∞，+∞)。<em class="mb">赔率</em>的<em class="mb">日志</em>称为<strong class="ky ir"><em class="mb">logit函数:</em> </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1059c5f019d9b907ca82c3b27a4f4163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*EiISMMwiWNlM5jlV.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj"> Logit函数公式</strong>。将概率从(0，1)映射到整个实数范围(-∞，+∞)</p></figure><p id="e26e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们寻找的函数，即逻辑函数或SIGMOID函数，是logit的逆函数(将范围(-∞，+∞)中的值映射到[0，1])</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/d37d4acc978213083e03fb137143d95e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8utJ94u3tyHNr5q6.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算logit函数的反函数</p></figure><p id="cdaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从而得到公式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/89af9e8df4f66e902ee9284b2c788fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/0*feWPpwwcGrXBh5Oq.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj"> Sigmoid函数公式。</strong></p></figure><p id="7863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中X表示输入(在神经网络的情况下，输入是最后一个神经元的加权和，通常由z = x1 w1 + x2 w2 + … + xn wn表示)</p><h2 id="52b9" class="nd mm iq bd mn ne nf dn mr ng nh dp mv lf ni nj mx lj nk nl mz ln nm nn nb no bi translated">SoftMax函数</h2><p id="0ff8" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated">另一方面，我们已经看到SoftMax接受一个向量作为输入。这个向量和我们的类有相同的维数。我们称它为X(尽管神经网络中另一个常见的符号是Z，其中向量的每个元素都是倒数第二层的输出)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/94e61d6312c5c8bb128cd1fcd937ecf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:296/format:webp/0*33nx3nn881GMFZ-j.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">k类的输入向量</p></figure><p id="ec1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与Sigmoid函数相同，输入属于真实值(在这种情况下是每个向量条目)<em class="mb">Xi</em>∑(-∞，+∞)并且我们想要输出一个向量，其中每个分量是概率P ∈ [0，1]。此外，输出向量必须是<strong class="ky ir">所有预测类别的概率分布</strong>，即向量的所有条目必须加起来为1。这个限制可以解释为每个输入必须属于一个类，并且只能属于一个类。</p><p id="ad74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以认为X是包含每个类的P(Y=i|X)的逻辑的向量，因为逻辑可以是任何实数(这里我表示类号)。还记得logit ∈ (-∞，+∞)吗</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/91fab18fe938dcda2ae64d3ce91188fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/0*O6skKwfNYgohsKWI.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">给定x，Y属于第I类的概率的对数</p></figure><p id="31e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，与二元分类问题不同，我们不能应用Sigmoid函数。原因是，当应用Sigmoid时，我们获得的是孤立的概率，而不是所有预测类别上的<strong class="ky ir">概率分布，因此输出向量元素的总和不是1 [2]。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/16323d86bb7229c27fce74a64364d597.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wpALcIgRDRmbNT-C2Hejog.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">图3 </strong>。为什么sigmoid函数不能用于多类分类？请注意，输出向量元素的总和不是1。作者图片</p></figure><p id="5ade" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要将X转换成概率分布，我们可以应用指数函数并获得几率∈ [0，+∞)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/92332c2399f7e18bf1bed798e09bd8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/0*0rWPpwOYcQ6lG6CD.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">记住X是一个向量，因此log(odds)和odds也是向量</p></figure><p id="222d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在此之后，我们可以看到，奇数是一个关于概率的单调递增函数。因此，当概率增加时，赔率也以指数方式增加[2]。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/41d26f5a89e763f1b50b99e7a8c39e82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DI_6mCkiwOi0DhhaXXFmMA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">图4 </strong>。奇函数图。来自<a class="ae kv" href="https://www.geogebra.org/calculator" rel="noopener ugc nofollow" target="_blank"> Geogebra </a>的截图</p></figure><p id="9ad1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们可以使用odd(或其等价的<em class="mb"> exp(logit) </em>)作为分数来预测概率，因为odd越高，概率越高。</p><p id="96e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们可以通过除以所有赔率的总和来归一化结果，这样范围值从[0，+∞)变为[0，1]，并且我们确保所有元素的总和等于1，从而构建所有预测类的概率分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/b70f1128942441b587044796de2f80a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/0*r3BsKAIGgoaZNfZO.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj"> SoftMax函数公式</strong></p></figure><p id="1200" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，如果我们举一个和之前一样的例子，我们会看到输出向量确实是一个概率分布，它的所有条目加起来都是1</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/27de4fb9130833eef875b6467cbef453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jEvI_ma5pRQF0UEhFIUbNA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mj">图5 </strong>。使用SoftMax，我们可以获得所有预测类别的概率分布。注:为便于阅读，结果已精确到小数点后3位。作者图片</p></figure></div><div class="ab cl oe of hu og" role="separator"><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj ok"/><span class="oh bw bk oi oj"/></div><div class="ij ik il im in"><h1 id="2f78" class="ml mm iq bd mn mo ol mq mr ms om mu mv jw on jx mx jz oo ka mz kc op kd nb nc bi translated">参考资料和资源</h1><p id="5a5e" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf nr lh li lj ns ll lm ln nt lp lq lr ij bi translated"><strong class="ky ir"/><a class="ae kv" href="https://www.geo.fu-berlin.de/en/v/soga/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html#:~:text=The%20inverse%20form%20of%20the,back%20from%20logits%20to%20probabilities.&amp;text=The%20logistic%20function%20for%20the,%2C6%5D%20is%20shown%20below." rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">logit函数</strong> </a> <strong class="ky ir">。Hartmann，k .，Krois，j .，Waske，B. (2018年):SOGA电子学习项目:统计和地理空间数据分析。柏林自由大学地球科学系。</strong></p><p id="9a68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">【2】</strong><a class="ae kv" href="https://youtu.be/Qn4Fme1fK-M" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">Youtube。深度学习中的logit和soft max</strong></a>。闵素赫。2019</p></div></div>    
</body>
</html>