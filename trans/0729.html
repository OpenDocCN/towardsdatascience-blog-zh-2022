<html>
<head>
<title>Deploying Gradio App on Spaces Using DagsHub: A Beginner’s Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 DagsHub 在空间上部署 Gradio 应用程序:初学者教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-gradio-app-on-spaces-using-dagshub-a-beginners-tutorial-a42664abcc14#2022-03-01">https://towardsdatascience.com/deploying-gradio-app-on-spaces-using-dagshub-a-beginners-tutorial-a42664abcc14#2022-03-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3bed" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于项目的教程介绍了 MLOps 集成，如 DVC，DagsHub，Gradio web 框架，和拥抱脸空间</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ad8575f1645441e9a3312762b7094300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ttWU99MdhcyfJ9r3pU7Jxw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者封面</p></figure><p id="4912" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于公司正在为其复杂的机器学习(ML)模型寻找易于部署的解决方案，因此对 MLOps 工具的需求很高。为了使事情简单有效，我们将把 DVC，DagsHub，Gradio 和拥抱脸空间整合到我们的合作 ML 项目中。</p><p id="1abf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本教程中，我们将了解端到端的机器学习集成，并使用它们来创建图像生成 web 应用程序。我们将使用 Gradio 开发开源项目 SavtaDepth 的模型推理，它将提供一个用户友好的 web 界面。SavtaDepth 通过预测深度维度将 2D 图像转换为 3D 图像。这是一个初学者友好的教程，这意味着我们将学习一些技巧来简化复杂 ML 模型的部署过程。</p><h1 id="ff33" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">SavtaDepth 项目</h1><p id="51dc" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated"><a class="ae lr" href="https://dagshub.com/OperationSavta/SavtaDepth" rel="noopener ugc nofollow" target="_blank"> SavtaDepth </a>是一个用于单目深度估计的合作开源数据科学项目。它拍摄 2D 图像并估计物体的深度。深度估计用于创建 3D 图像、3D 绘图、安全监控和自动驾驶汽车。单目深度估计的目标是预测每个像素的深度值或推断深度信息，仅给定单个 RGB 图像作为输入— <a class="ae lr" href="https://keras.io/examples/vision/depth_estimation/" rel="noopener ugc nofollow" target="_blank"> (keras.io) </a>。</p><p id="1796" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该项目使用<a class="ae lr" href="https://paperswithcode.com/method/u-net" rel="noopener ugc nofollow" target="_blank"> U-Net </a>模型，作者已经将最后一层从对象分割改为深度估计。模型在<a class="ae lr" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY 4.0 </a> license 下的<a class="ae lr" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU 深度数据集 V2 </a>上进行训练。该数据集包含来自微软<a class="ae lr" href="http://www.xbox.com/kinect" rel="noopener ugc nofollow" target="_blank"> Kinect </a>的 RGB 和深度相机记录的各种室内场景的视频序列。该项目仍然是活跃的，因此贡献者可以帮助改善结果。如果你对这个项目感兴趣，请阅读投稿指南。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/a1d3da2a1cc9c9cf9c9556f0e542ead2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TUyxCvtadYnbfOik"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片|单目深度估计</p></figure><h1 id="ee08" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">集成</h1><p id="ee31" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在这一节中，我们将了解使我们的项目与众不同的各种集成。我们还将了解这些工具如何融入我们的项目生态系统。</p><ul class=""><li id="f09b" class="mq mr iq kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><a class="ae lr" href="https://dvc.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> DVC </strong> </a>是一个开源版本控制的机器学习系统。它附带了数据和模型版本控制、模型度量监控和重现实验。它是 Git 的一个扩展，所以学习 DVC 会很自然。</li><li id="65ff" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://dagshub.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> DagsHub </strong> </a>是一个类似 GitHub 的社区第一平台，用于机器学习和数据科学项目。它使其用户能够利用流行的开源工具来版本化数据集&amp;模型、跟踪实验、标记数据和可视化结果。</li><li id="9a97" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://www.gradio.app/" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> Gradio </strong> </a>是为您的机器学习模型创建用户友好的 web 界面的最快方法。您可以在几分钟内构建并共享您的应用程序。它还带有 FastAPI 支持，这意味着您可以在任何地方访问该模型。</li><li id="55c9" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://huggingface.co/spaces" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> Spaces </strong> </a>是拥抱脸新推出的机器学习应用分享平台。您可以构建 Streamlit、Gradio 或 HTML web 应用程序，并使用几行代码将它们部署到空间中。</li></ul><p id="2a75" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这个项目中，我们将使用<strong class="kx ir"> DVC </strong>进行数据和模型版本控制，使用<strong class="kx ir"> DagsHub </strong>进行远程存储，使用<strong class="kx ir"> Gradio </strong>进行 ML 应用程序接口，使用<strong class="kx ir"> Spaces </strong>作为 web 服务器。</p><h1 id="2934" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Gradio WebApp</h1><p id="320f" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">Gradio 是一个轻量级的强大的网络界面，用于创建机器学习演示。在本节中，我们将学习如何添加图像，使用 FastAI 运行模型推理，并输出生成的结果。为了运行 web 应用程序而不出现依赖问题，我们需要首先安装<a class="ae lr" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>、<a class="ae lr" href="https://pypi.org/project/fastai/" rel="noopener ugc nofollow" target="_blank"> FastAI </a>和<a class="ae lr" href="https://www.gradio.app/" rel="noopener ugc nofollow" target="_blank"> Gradio </a>。</p><h2 id="426b" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">模型推理</h2><p id="177d" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">为了简单起见，我只添加了重要的部分，并删除了数据加载器。您可以通过查看 SavtaDepth <a class="ae lr" href="https://colab.research.google.com/drive/1XU4DgQ217_hUMU1dllppeQNw3pTRlHy1?usp=sharing" rel="noopener ugc nofollow" target="_blank">笔记本</a>了解更多关于图像数据加载器和<em class="nq"> create_data </em>功能的信息。</p><p id="c9e8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们只是使用 FastAI 的函数<em class="nq"> unet_learner </em>来创建模型架构，然后加载最新的模型检查点。最后，我们将创建一个<em class="nq"> gen </em>函数，该函数将以 Numpy 数组的形式获取图像，并运行预测以生成黑白 3D 图像。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="e954" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">网络界面</h2><p id="d272" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">创建 Gradio web 界面很容易。我们只需要定制<em class="nq"> gradio。我们的用例与 Vallah 的接口</em>函数！！！您的 web 应用程序已准备就绪。</p><p id="f8dd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们仔细看看<em class="nq">接口</em>函数中使用的参数:</p><ul class=""><li id="0e2c" class="mq mr iq kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><strong class="kx ir">第一个</strong>参数是<em class="nq"> fn </em>。我们需要为它提供模型推理，它接受输入并返回输出。在我们的例子中，它<em class="nq">生成</em>函数。</li><li id="6091" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">第二个</strong>参数是<em class="nq">输入</em>。我们正在将图像形状转换为 640X480 Numpy 数组。这个功能自动为我们做了大部分的图像处理工作。</li><li id="959a" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">第三个</strong>参数是<em class="nq">输出</em>。在我们的例子中，它是一个图像。所有的后处理都是由 Gradio 自动完成的。因此，我们不必担心使用 PIL 包来显示图像。</li><li id="587f" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">标题</strong>取一个字符串显示应用名称或标题。</li><li id="4c16" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">描述</strong>采用一个简单的字符串、markdown 或 HTML 来显示副标题或标题下的图像。</li><li id="346a" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">文章</strong>是应用程序的页脚，你可以在这里写申请信息，比如你的研究和项目库的链接。它还接受简单的文本、markdown 或 HTML。</li><li id="8471" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">示例</strong>可用作示例输入，这样我们就不必寻找图像来运行应用程序。在我们的例子中，我们已经创建了一个文件夹，并从数据集的一个测试子集中复制了两个图像。这些示例接受一个相对文件路径数组，如下所示。</li><li id="2e31" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir">主题是自定义 UI 的</strong>，你可以在<a class="ae lr" href="https://www.gradio.app/docs/" rel="noopener ugc nofollow" target="_blank">文档</a>中找到更多关于主题的信息。</li><li id="a569" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir"> allow_flagging </strong>是一个很酷的功能，可以帮助你跟踪模型的性能。您可以标记错误的预测，以便开发人员可以根据反馈改进模型。</li><li id="0d46" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><strong class="kx ir"> enable_queue </strong>用于防止推理超时。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="3704" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在最终版本中，我使用 HTML 脚本对<strong class="kx ir">描述</strong>和<strong class="kx ir">文章</strong>做了一些修改。随时检查我的<a class="ae lr" href="https://dagshub.com/kingabzpro/SavtaDepth/src/main/app/app_savta.py" rel="noopener ugc nofollow" target="_blank">代码</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/8f0a709a7f4b74174bbb498358a80b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-OAa0Cdnl6pfCBVY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者 Gif</p></figure><h2 id="4542" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">部署</h2><p id="5760" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">在本节中，我们将学习如何将 Gradio 应用程序部署到拥抱面部空间。为此，我们需要使用拥抱脸网站创建新的空间，然后在 savta_app.py、README.md 和 requirement.txt 文件中进行更改。</p><h2 id="ea26" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">拥抱面部空间</h2><p id="bd57" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">通过拥抱 Face 机器学习应用程序共享平台，人们可以在各种 Python web 框架上创建应用程序，并使用简单的 Git 函数进行部署。您还可以查看特色空间，体验最新的 ML 模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/0813e2525649d3fffe7bd0d4605f904c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SXPU3x6enEMUmmc2"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae lr" href="https://huggingface.co/spaces" rel="noopener ugc nofollow" target="_blank">空间——拥抱脸</a></p></figure><p id="3857" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们开始部署之前，我们需要首先创建一个<a class="ae lr" href="https://huggingface.co/new-space" rel="noopener ugc nofollow" target="_blank">新空间</a>，然后我们需要添加空间的名称、许可证，并选择 SDK。之后，我们可以克隆空间或者向当前的 Git 存储库添加一个远程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9117e620a8123e1971c6690247e46c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/0*n8buZtX7wTbNW9BH"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="d973" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">建立 DVC</h2><p id="fcad" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">用空间整合 DVC 很容易。我们只需要在主 Python 文件中运行一个 shell 脚本。下面的代码只从训练和测试数据集中提取了一个模型和一些样本。最后，它去掉了<strong class="kx ir">。dvc </strong>文件夹来优化存储。确保在模型推理函数之前添加此代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="cf4e" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">自定义环境</h2><p id="e809" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">为了将 Gradio 应用程序部署到 Spaces，我们需要做一些更改以避免错误和依赖性问题。</p><p id="b79b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">添加拥抱脸遥控器</strong></p><p id="89b6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们需要将 Space remote 添加到当前项目中。空间远程地址应该是这样的</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="e678" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> README.md </strong></p><p id="d0f1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后转到您的<strong class="kx ir"> README.md </strong>文件，以<strong class="kx ir"> yml </strong>的形式添加元数据。这些元数据将告诉 Space 应用程序文件的位置、封面的表情符号、应用程序缩略图的颜色渐变、SDK 和许可证信息。您可以自定义颜色和表情符号，让您的缩略图更加醒目。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="3a66" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> requirements.txt </strong></p><p id="5b5c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们受限于 CPU，为了优化存储，我们将使用 PyTorch CPU 版本。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/00b63db390b94c53da85451fcc402c59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cgp83bH332rV5cun"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae lr" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">入门| PyTorch </a></p></figure><p id="cb1c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将只包含运行模型推理和 web 界面所必需的包到<em class="nq"> requirements.txt </em>文件中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h2 id="8f08" class="ne lt iq bd lu nf ng dn ly nh ni dp mc le nj nk me li nl nm mg lm nn no mi np bi translated">最後的</h2><p id="7c74" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">完成所有更改后，就该提交代码并将其推送到 Space 远程服务器了。初始远程空间有 README.md 和。gitattributes，所以为了避免冲突，我们将使用<strong class="kx ir"> -f </strong>标志。我们将使用<strong class="kx ir"> master:main </strong>将所有文件从本地(主分支)发送到远程(主分支)服务器。</p><blockquote class="nx ny nz"><p id="bfca" class="kv kw nq kx b ky kz jr la lb lc ju ld oa lf lg lh ob lj lk ll oc ln lo lp lq ij bi translated"><strong class="kx ir">警告:</strong>请在开始时只使用一次<strong class="kx ir"> -f </strong>标志，避免使用它，因为它会覆盖其他人的工作。</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="e706" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">按下代码后，你会在你的应用上看到一个“<strong class="kx ir">大厦”</strong>的标志。大约需要 3 分钟来构建。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/38f9388bac9949eb0768d085e8e49eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/0*hJenmPUQfquFUTy7"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3af9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">恭喜您，您的应用已成功部署，可以在朋友和同事之间共享。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/8436d35897377b74ae837140268a6709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2oxRPgSNNajXX7BH"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者| <a class="ae lr" href="https://huggingface.co/spaces/kingabzpro/savtadepth" rel="noopener ugc nofollow" target="_blank">拥抱脸空间</a></p></figure><h1 id="82e3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">奖金</h1><p id="f568" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">额外的部分是给 MLOps 爱好者的，他们总是渴望学习更多集成新工具和数据库的方法。在这一部分，我们将整合拥抱脸<a class="ae lr" href="https://huggingface.co/datasets" rel="noopener ugc nofollow" target="_blank">数据集</a>来收集所有的标志。这些标志将包括输入图像、输出图像和 CSV 文件。flag 选项有助于我们跟踪模型性能，并且我们可以在以后使用该数据集来提高模型性能。</p><p id="7377" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们需要将下面的代码添加到<em class="nq"> savta_app.py </em>文件中，以便集成工作。它将使用<em class="nq">HuggingFaceDatasetSaver</em>来创建和更新标志数据集。该函数需要两个参数<em class="nq"> HF_TOKEN </em>，您可以在<a class="ae lr" href="https://huggingface.co/settings/tokens" rel="noopener ugc nofollow" target="_blank">设置</a>和数据集名称中找到。最后，您可以在 Gradio 接口函数中将对象添加到<strong class="kx ir"> flagging_callback </strong>中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nr ns l"/></div></figure><p id="9974" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您还需要在空间设置中设置<em class="nq"> HF_TOKEN </em>环境变量。只需复制并粘贴<a class="ae lr" href="https://huggingface.co/settings/tokens" rel="noopener ugc nofollow" target="_blank">用户访问令牌</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2c0acf77d3d198af6390895a54a140c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/0*ZppVNG9I0BIP6BYN"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="94c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">之后，转到应用程序并标记几个预测，以便您可以在您的个人资料下看到标记的数据集。在我们的例子中，可以公开访问的是<a class="ae lr" href="https://huggingface.co/datasets/kingabzpro/savtadepth-flags" rel="noopener ugc nofollow" target="_blank"> savtadepth-flags </a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/705e8396e6a9f223d1cf8778e3c65ce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AWYswgYK_-RUflrS"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图像来自<a class="ae lr" href="https://huggingface.co/datasets/kingabzpro/savtadepth-flags" rel="noopener ugc nofollow" target="_blank"> savtadepth-flags </a></p></figure><h1 id="032f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="0a2c" class="pw-post-body-paragraph kv kw iq kx b ky mk jr la lb ml ju ld le mm lg lh li mn lk ll lm mo lo lp lq ij bi translated">拥抱面部空间提供了一个易于部署的平台，数据科学家可以通过用户友好的界面测试和分享机器学习模型。如果你是机器学习的初学者，想体验端到端的产品开发，那就尝试在 Gradio 上开发你的 app，与 DagsHub 集成，最后部署到 Spaces。它还将帮助你创建一个强大的投资组合，其中你可以提到部署机器学习模型的经验。</p><p id="411c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本教程中，我们学习了如何使用 Git、DVC、DagsHub、Gradio 和 Hugging Face Space 来创建和部署复杂的机器学习应用程序。这是你成为 MLOps 工程师的第一步。</p><p id="916d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">项目资源:</strong></p><ul class=""><li id="8d7b" class="mq mr iq kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated"><a class="ae lr" href="https://huggingface.co/spaces/kingabzpro/savtadepth" rel="noopener ugc nofollow" target="_blank"> SavtaDepth WebApp </a></li><li id="2da8" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://huggingface.co/datasets/kingabzpro/savtadepth-flags" rel="noopener ugc nofollow" target="_blank">标记数据库</a></li><li id="4439" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://dagshub.com/OperationSavta/SavtaDepth" rel="noopener ugc nofollow" target="_blank"> SavtaDepth 项目</a></li><li id="aeb7" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://dagshub.com/kingabzpro/SavtaDepth/src/dagshub" rel="noopener ugc nofollow" target="_blank"> SavtaDepth Fork + WebApp </a></li><li id="232e" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://colab.research.google.com/drive/1XU4DgQ217_hUMU1dllppeQNw3pTRlHy1?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌 Colab 演示</a></li><li id="6ab7" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated"><a class="ae lr" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank">项目数据集</a></li></ul><p id="638a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">数据集参考:</strong> Nathan Silberman，P. K .，Derek Hoiem en Fergus，r .(2012)“RGBD 图像的室内分割和支持推断”，载于<em class="nq"> ECCV </em>。</p></div></div>    
</body>
</html>