<html>
<head>
<title>KNN Regression Model in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的KNN回归模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/knn-regression-model-in-python-9868f21c9fa2#2022-05-17">https://towardsdatascience.com/knn-regression-model-in-python-9868f21c9fa2#2022-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dcbc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将线性模型的简单性与K近邻的强大功能相结合</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ee96e1c9c277cc2124f43823b0eced6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vO-mCzfqazWr6wXUCE_bPQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@derickray?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">吴镇男·麦金尼</a>在<a class="ae ky" href="https://unsplash.com/s/photos/neighbor?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h2 id="dc3f" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">回归</h2><p id="66a2" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">回归是一种非常简单的算法。在Medium中快速搜索一下，你会发现数百个关于线性回归的帖子。</p><p id="4058" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">因此，我不会花太多时间来定义它。我只想说</p><blockquote class="mt"><p id="ad99" class="mu mv it bd mw mx my mz na nb nc mn dk translated">线性回归是一种统计建模工具，它帮助我们根据解释变量和响应变量之间的线性关系来预测值。</p></blockquote><h2 id="ba2f" class="kz la it bd lb lc nd dn le lf ne dp lh li nf lk ll lm ng lo lp lq nh ls lt lu bi translated">k-最近邻</h2><p id="5282" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">K-最近邻(或简称为KNN)算法通过获取给定点并评估其“K”个邻居来寻找相似性。它可用于分类或回归。</p><p id="5af9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这个想法是基于这样一个事实:在空间中，相似的数据点比彼此差异很大的数据点更接近。所以，如果你观察下面的图片，它非常有意义。让我们选择点<strong class="lx iu"> X </strong>并查看它的5个最近的邻居，然后我可以更好地确定那个点是什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/65986e819a035e1387afa3dbce080cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jz9WO8NRWHlVx7qLtN88MQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">点X很可能是另一个三角形。你同意吗？图片由作者提供。</p></figure><p id="b061" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">请注意，这些最近的点中有4个是三角形，只有一个是正方形。圆“集群”是太远的方式来考虑。所以，根据KNN逻辑，我们可以断定X点是一个三角形。</p><h2 id="a998" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">KNN回归</h2><p id="e062" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">KNN回归逻辑与上面图片中解释的非常相似。唯一的区别是，它与数字打交道。因此，来自<code class="fe nj nk nl nm b">sklearn</code>库的<code class="fe nj nk nl nm b">KNeighborsRegressor()</code>算法将做的是计算数据集的回归，然后用选择的数字获取<code class="fe nj nk nl nm b">n_neighbors</code>参数，检查那些邻居的结果并对结果取平均，给你一个估计的结果。</p><p id="d41a" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">文献以一种奇特的方式说。看:</p><blockquote class="mt"><p id="e754" class="mu mv it bd mw mx my mz na nb nc mn dk translated">通过对与训练集中的最近邻居相关联的目标进行局部插值来预测目标。</p></blockquote><h2 id="dcf9" class="kz la it bd lb lc nd dn le lf ne dp lh li nf lk ll lm ng lo lp lq nh ls lt lu bi translated">示例代码</h2><p id="6afa" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">以下是使用KNN回归器的模型代码。</p><p id="65eb" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">本练习中使用的数据集是来自seaborn的拥有知识共享许可的<a class="ae ky" href="https://github.com/mwaskom/seaborn-data/blob/master/diamonds.csv" rel="noopener ugc nofollow" target="_blank"> Diamonds </a>。我会根据切割来模拟钻石的克拉。</p><p id="7fa6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">首先，让我们创建一个pairplot来检查最佳线性关系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/fc7863523962d11eec9d1485f5fb1ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IAZVkjaV79NeGxNNwPcTzA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将解释变量与目标变量配对。图片由作者提供。</p></figure><p id="1064" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">从这个图中，我们可以看到好的变量是<em class="no"> x，y </em>和<em class="no"> z，</em>，因为它们的散点图显示那里有一个可能的线性回归。</p><p id="141f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">所以我隔离了他们。</p><pre class="kj kk kl km gt np nm nq nr aw ns bi"><span id="c842" class="kz la it nm b gy nt nu l nv nw">X <strong class="nm iu">=</strong> df[['x', 'y', 'z']]<br/>y <strong class="nm iu">=</strong> df<strong class="nm iu">.</strong>carat</span><span id="0666" class="kz la it nm b gy nx nu l nv nw"># Train test split <br/>X_train, X_test, y_train, y_test <strong class="nm iu">=</strong> train_test_split(X, y, test_size<strong class="nm iu">=</strong> 0.2, random_state<strong class="nm iu">=</strong>12)</span></pre><p id="8168" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">然后我检查缺失值。根本没有。</p><p id="193f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我继续移除离群值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/c8edc2dda99a30ddf5f4257bcc4d0f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KAb1dLkfc-YlS7cfcHuaIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">包含和不包含异常值的数据集。图片由作者提供。</p></figure><p id="e53b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们可以看到，没有异常值的数据集显示了一条轻微的指数曲线。所以我也尝试了对数转换，以查看更好的线性关系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/710630ea0c1b9adc5c9faeeebd566ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fk-h8FvgM59h5HjP8XrI8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对数变换后。图片由作者提供。</p></figure><p id="9e73" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">下一步是建立数据模型。</p><p id="2fbd" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我已经创建了3个不同的模型。无对数变换的线性回归。对数变换线性回归和KNN回归。</p><p id="bc36" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/a7fc67a35ea6e92b1d738d11887d941f.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*OhFfsnkb1WODSAD6C9cAzA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">车型对比。图片由作者提供。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/68647d50082b5b7bf45073d581a86258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w9kJzKCpC-Gf7Fl3aa9tuw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNN vs对数转换回归。图片由作者提供。</p></figure><p id="6820" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">结果对KNN来说相当不错。它在右端有几个高估的值，但可以接受。好的方面是，它甚至不需要变量转换就给了我这么好的改进(几乎比标准LR高5%)。所以，你能看出KNN平均线对于线性回归有多有意思吗？这听起来像是“回归的装袋模型”的简单版本。</p><p id="448e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">对于对数变换LR，当它在左端显示最大误差时，发生相反的情况。</p><h2 id="5aa3" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在你走之前</h2><p id="53df" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我鼓励你看看KNN回归，看看它适合你的项目。</p><p id="761b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是另一种回归，你可以将它添加到你的工具箱中，以便能够建立更强大和更准确的模型，而不一定比它需要的更复杂。</p><p id="3682" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">数据科学不是关于复杂的事情，而是能够解决问题。</p><p id="b692" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">完整代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="2081" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">如果你想订阅Medium，这里有一个<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">推荐代码</a>。</p><p id="52a6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">另外，我的博客有更多的内容。</p><div class="oe of gp gr og oh"><a href="https://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ks oh"/></div></div></a></div><p id="d3f7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">Git Hub代码:完整的代码<a class="ae ky" href="https://github.com/gurezende/Studying/blob/master/Python/Linear%20Regression/KNN_Regression.ipynb" rel="noopener ugc nofollow" target="_blank">可以在这里找到</a>。</p><h2 id="b960" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">参考</h2><div class="oe of gp gr og oh"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab fo"><div class="oj ab ok cl cj ol"><h2 class="bd iu gy z fp om fr fs on fu fw is bi translated">sk learn . neighbors . kneighborsregressor</h2><div class="oo l"><h3 class="bd b gy z fp om fr fs on fu fw dk translated">基于k近邻的回归。通过对与目标相关联的目标进行局部插值来预测目标</h3></div><div class="op l"><p class="bd b dl z fp om fr fs on fu fw dk translated">scikit-learn.org</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov ks oh"/></div></div></a></div></div></div>    
</body>
</html>