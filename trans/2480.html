<html>
<head>
<title>An Introduction to Bayesian Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-bayesian-inference-2cee9416504c#2022-05-30">https://towardsdatascience.com/an-introduction-to-bayesian-inference-2cee9416504c#2022-05-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cc98" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">贝叶斯推理方法的数学+代码介绍-马尔可夫链蒙特卡罗和变分推理。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/21e2e5de092bdaaa301f25ad465cb81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F73v8EAs1SALtHps"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="4877" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在之前的<a class="ae ky" rel="noopener" target="_blank" href="/an-introductory-primer-to-bayesian-statistics-3415ffa28488">博客文章</a>中，我介绍了贝叶斯统计的世界。它检查了贝叶斯统计如何提出一种方法，将证据纳入我们的模型，以获得更好的模型。这个过程被称为推理，这是获得/逼近后验概率的一种奇特的数学说法。</p><p id="360d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，贝叶斯统计的一个大问题是，除了最简单的模型，通常不可能找到分析或精确的解决方案。因此，更常用的近似推断方法侧重于寻找后验估计值。在这篇博文中，我将介绍两种方法:<strong class="lb iu">变分推理</strong>和<strong class="lb iu">马尔可夫链蒙特卡罗</strong>。</p><h1 id="5524" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">问题</strong></h1><p id="9c2e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">让我们首先用贝叶斯推理来重新审视这个问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/97ff8aaa2ceb28654d154e370f74ed45.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*9mGZauYOZEIeMhC7OvioGQ.png"/></div></figure><p id="bf1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">贝叶斯公式告诉我们如何将似然性P(X|θ)与先验P(θ)相结合以获得后验。P(X)观察到X的概率被称为<strong class="lb iu">证据</strong>，可以通过对所有可能的θ值取一个期望值来计算。这将导致必须计算多个变量的积分或总和，这是非常困难的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c6123f9b7ffdab929213bc42eacf9901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*z1x6zmFTA_PCtX5hPUol9A.png"/></div></figure><p id="227e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两种方法不是计算P(X ),而是变分推理和MCMC使用来自分子的信息来直接估计后验概率，完全绕过这个积分。</p><p id="96f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看这两种方法在一个玩具示例的上下文中是如何工作的:对2-混合高斯分布建模。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/d8589ed96598fa3a54d063c896a428f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*_LU90Nn9lIpFA8Br50xN_A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">目标分布-按作者分类的图像</p></figure><h1 id="f77b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">变分推理</h1><p id="a644" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">变分推理(VI)是一种逼近特定概率分布的技术。VI通过从尽可能接近目标分布<em class="mv"> p </em>的分布族<em class="mv"> Q </em>中找到概率分布<em class="mv"> q </em>来实现这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/c89a1e1d2b14be6caa596b2ff31ab151.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*zuevP3zLCis9pZq7LSP0Lw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KL散度公式</p></figure><p id="0bfc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是通过使用Kullber-Lieback散度(KL-Divergence)作为我们的损失函数来实现的。KL散度是一个量化两个分布之间差异的函数。由于函数是可微的，我们可以使用基于梯度的方法来优化函数。执行这种优化将返回后验分布的局部最优值。</p><blockquote class="mx my mz"><p id="0565" class="kz la mv lb b lc ld ju le lf lg jx lh na lj lk ll nb ln lo lp nc lr ls lt lu im bi translated">尽管KL散度衡量两个分布之间的差异，但它不是距离度量。KL(q||p) ≠ KL(p||q)除非p=q其中KL散度= 0</p></blockquote><p id="744e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我们仍然面临一个大问题，首先获得后验p(x)的函数！假设我们可以找到一个函数<em class="mv"> p^ </em>，它与<em class="mv"> p </em>非常相似，具有相同的最小值。如果是这样的话，我们可以使用梯度下降来优化KL(<em class="mv">q</em>|<em class="mv">p^</em>)，并且我们的近似<em class="mv"> q </em>应该是对<em class="mv"> p </em>的最佳可能估计。</p><p id="4948" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个函数<em class="mv"> p^ </em>就是原始贝叶斯公式中的p(x |θ)\乘以P(θ)。这本质上是后验的，没有难以计算的归一化常数/证据。两个函数p(x)和p^(x通过下面的等式相关。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/fe935ef6cfb18f7bfd3a1b074e6deef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*8-35OpQfETaxisPotPAlXQ.png"/></div></figure><p id="46c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看当我们取KL-散度(q||p)时会发生什么</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/dc842e3ae248d1fd4dd421f649845b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXTUPieFOKcBi0xUaOvbSA.png"/></div></div></figure><blockquote class="mx my mz"><p id="efa6" class="kz la mv lb b lc ld ju le lf lg jx lh na lj lk ll nb ln lo lp nc lr ls lt lu im bi translated">∑ q(x)和Z(θ)是与x无关的常数</p></blockquote><p id="2e55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KL( <em class="mv"> q </em> || <em class="mv"> p </em>)和KL( <em class="mv"> q </em> || <em class="mv"> p^ </em>)之差是一个常数<strong class="lb iu"> <em class="mv"> log </em> Z(θ) </strong>，两个函数将具有相同的最小值。</p><p id="04c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这允许通过调整<em class="mv"> q </em>的参数使用梯度下降的优化程序，以最小化KL损失。</p><p id="88ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们知道KL-散度KL(<em class="mv">q</em>|<em class="mv">P</em>)总是≥0，我们就可以推导出<strong class="lb iu"> <em class="mv"> log </em> Z(θ) </strong>或证据P(X)的附加性质。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/7d46332e2f7f18428f0569effa5fdfb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*6Tq757AsD4tqnfD8r9bwCQ.png"/></div></figure><p id="8511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，KL(<em class="mv">q</em>|<em class="mv">p^</em>)将总是大于<strong class="lb iu"> <em class="mv"> log </em> Z(θ) </strong>，这也是来自等式2的<strong class="lb iu"> <em class="mv"> log </em> P(X) </strong>。具体地，这种损失可以被解释为证据P(X)的下限。正因为如此，之前我们描述为KL(<em class="mv">q</em>|<em class="mv">p^</em>)的函数也被称为证据下界(ELBO)。我们的函数代表对数似然<strong class="lb iu"> <em class="mv">对数</em> P(X) </strong>的下界。最大化这将意味着<strong class="lb iu">增加在所有可能的θ值上看到数据</strong>的可能性。</p><h2 id="e462" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated"><strong class="ak">代码实现</strong></h2><p id="b82c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Pyro和Tensorflow Probability是两个可以相对快速地执行变分推理的包，但是对于本教程，我们将使用JAX来执行一个实现。JAX本质上是具有自动微分的numpy，它将帮助我们更好地理解在我们简单的玩具例子上执行VI时在引擎盖下发生了什么。</p><p id="1ab3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本质上，JAX允许对给定函数的梯度进行数值计算。为了使用它，我们只需要定义返回KL散度损失的函数。我们的函数有3个参数，数据(X)以及我们试图拟合的高斯分布的均值和标准差参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">获得KL散度的函数</p></figure><p id="501c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦写好函数，我们就可以使用<code class="fe nu nv nw nx b">jax.grad</code>自动获得梯度。<code class="fe nu nv nw nx b">argnums</code>参数告诉Jax我们想要哪个参数的梯度。由此，我们创建了两个函数<code class="fe nu nv nw nx b">mu_grad_kl</code>和<code class="fe nu nv nw nx b">sigma_grad_kl</code>，它们将给出各自的梯度更新。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">变分推理梯度下降</p></figure><p id="92ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之后，我们可以使用简单的梯度下降算法来获得拟合分布的参数。注意，由于KL散度函数不是凸的，所以所获得的参数只能保证是局部最优，而不是全局最优。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/c353bb78f5ba740260f4477e7929f237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*D-_YGIfKhuvH5lP5ZdpheQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">双高斯目标的单高斯拟合—作者提供的图像</p></figure><p id="828c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如所料，估计并不完美，仅仅是因为我们的变分模型(单高斯分布)对于目标(混合分布)来说不是一个好的模型。使用混合分布模型作为拟合，我们将能够更好地估计目标。在更复杂的情况下，找到一个好的变分模型是非常困难的。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h1 id="d2dd" class="lv lw it bd lx ly of ma mb mc og me mf jz oh ka mh kc oi kd mj kf oj kg ml mm bi translated"><strong class="ak"> MCMC </strong></h1><p id="74d9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">一种替代方法是从分布中取样，而不是用变分推断来近似分布。如果我们可以很容易地从后验分布中抽取无偏样本，我们就可以获得均值和方差，并使用这些信息进行估计。</p><h2 id="a761" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated"><strong class="ak">为什么直接取样不起作用？</strong></h2><p id="c8bf" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">不幸的是，对复杂且未知的分布进行采样并不总是那么容易。因为我们有一个非标准化的概率分布，普通分布(指数，高斯)的抽样算法不起作用。因此，我们求助于使用其他方法。</p><p id="ea4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">马尔可夫链蒙特卡罗(MCMC)描述了一组特定的采样方法，用于在没有精确概率密度函数的情况下逼近分布<strong class="lb iu">。在深入研究细节之前，让我们首先了解MCMC算法的两个组成部分。</strong></p><p id="543d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">算法的<strong class="lb iu">蒙特卡罗</strong>部分简单地指随机抽样。蒙特卡罗方法是一类基于重复随机抽样的方法。假设我们有一枚硬币，想估计它正面朝上的概率。蒙特卡罗方法是抛硬币很多次，并使用观察结果来预测参数。</p><p id="855e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">马尔可夫链是一种控制一系列事件之间行为的数学模型。链中的每个节点代表一个状态，并通过链接连接在一起，链接是状态之间的转移概率。马尔可夫链的独特之处在于，链中的下一个状态只取决于前一个状态。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/25fa0929dcfaa295dc58de9ed28475a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-XuAuOz-lO_tvWcwoZzXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自马尔可夫链的样本—作者图片</p></figure><p id="4436" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的例子中，马尔可夫链中的每个节点都是一个样本。每个样本仅依赖于它之前的样本，并且<strong class="lb iu">转移概率</strong>告诉我们如何从链中导出样本，并且重复进行(蒙特卡罗)以逼近目标分布。</p><p id="a090" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定正确的转移概率，可以证明当样本数量接近无穷大时，样本的分布将是我们从中采样的目标分布。</p><blockquote class="mx my mz"><p id="7a9d" class="kz la mv lb b lc ld ju le lf lg jx lh na lj lk ll nb ln lo lp nc lr ls lt lu im bi translated">捷径解释:所有的MCMC算法都建立了一个平稳分布为后验的马尔可夫链。给定足够的时间，马尔可夫链将收敛到这个平稳分布，并产生无偏样本。</p></blockquote><p id="da73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为它只有在一段时间后才能达到正确的估计值，所以在使用MCMC时，我们必须执行额外的步骤。通常，我们看样本的痕迹，观察它们如何随时间变化。理想情况下，样本应该停止波动，并开始向某个值/范围收敛。</p><p id="f4a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随后，我们在开始时丢弃一部分样本。第一组样本是“预烧”期，在此期间，算法尚未向稳定分布收敛。</p><h2 id="ad49" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated"><strong class="ak">大都会黑斯廷斯算法</strong></h2><p id="1cc2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，我们对MCMC如何工作有了一些简单的直觉，让我们看看如何才能得到“正确的跃迁概率”。一种常见的MCMC算法Metropolis Hastings算法被用作例子。</p><p id="0226" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此我们要做两件事。非标准化概率密度(P)和转移函数(Q)。p返回一个描述状态概率的值，而Q描述到达一个新状态x '的概率，假设我们处于前一个状态x。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/5918d0a5fa51b1a5dd3c2695bc4d4ebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*AVOrcPSfE0IP0og6eezf_Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Metropolis-Hastings算法的接受概率</p></figure><p id="d3dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个转移函数可以是简单对称的，就像正态分布一样。<strong class="lb iu"> Q(x'|x) ~ N(x，3) </strong>。本质上，在每个实例中，我们从一个法线(0，3)采样，我们得到的值被加到<em class="mv"> x </em>以获得下一个点。</p><p id="50b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于正态分布是对称的，转移函数项<strong class="lb iu"> Q(x|x') </strong>和<strong class="lb iu"> Q(x'|x) </strong>将在我们的接受概率中抵消。</p><p id="6c07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样我们就可以为MH算法构造伪代码了</p><h2 id="9625" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated"><strong class="ak">算法:</strong></h2><pre class="kj kk kl km gt om nx on oo aw op bi"><span id="a533" class="ng lw it nx b gy oq or l os ot">1. Start from random sample poiint<br/>2. Sample from Transtion function to get next point<br/>3. Evaluate the function at th new point<br/>4. Use the criteria to accept/reject the sample<br/>   a. If accept: Add new sample<br/>   b. Else: Add previous sample<br/>5. Reject earlier samples for the burn-in period.</span></pre><p id="6028" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接受概率有助于算法调整获得的样本。仍将获得来自较低概率密度的样本，但是与高概率样本相比，速率较低。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Metropolis Hastings算法的代码实现</p></figure><p id="9598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦收集了所有的样本，可以丢弃其中的一半作为老化期，以获得下面的样本</p><h1 id="16fc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">比较两种方法</strong></h1><p id="ceea" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">从所示的两个例子来看，MCMC似乎是更好的推断方法</p><ul class=""><li id="02ca" class="ou ov it lb b lc ld lf lg li ow lm ox lq oy lu oz pa pb pc bi translated">不需要任何关于后验的事先假设</li><li id="1831" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated">可以收敛到全局最优</li><li id="b7e9" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated">算法很简单</li></ul><p id="d5b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，MCMC背后的一个大缺点是，对于大量的维度，它的性能比VI差。虽然可以保证收敛到最佳分布，但这可能需要非常长的时间。当使用MCMC训练大型贝叶斯网络时，这可能是一个巨大的问题，其中变量的数量可以是几百/几千。</p><p id="7d57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，变分推理使用梯度下降进行训练，并可以利用现代深度学习框架来使用GPU并行化计算。此外，寻找全局最优可以被认为是不必要的，因为大多数最先进的神经网络在没有达到全局最优的情况下表现得非常好。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="71a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这篇文章，请在Medium上关注我！<br/>在LinkedIn上连接:<a class="ae ky" href="https://www.linkedin.com/in/reo-neo/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/reo-neo/</a></p></div></div>    
</body>
</html>