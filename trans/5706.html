<html>
<head>
<title>5 Data Similarity Metrics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5 个数据相似性指标</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-data-similarity-metrics-f358a560855f#2022-12-27">https://towardsdatascience.com/5-data-similarity-metrics-f358a560855f#2022-12-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/8f91b04c5b0b2ef6b34926b9bb01ec8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ogL3OVepn9xNMXD0"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">亚历山大·格雷在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="b602" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">理解数据分析和机器学习中的相似性度量:综合指南</h2></div><p id="e177" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">前言:本文给出了关于给定主题的信息摘要。它不应被视为原创研究。本文中包含的信息和代码可能受到我过去从各种在线文章、研究论文、书籍和开源代码中读到或看到的东西的影响。</em></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="1877" class="lz ma jg bd mb mc md me mf mg mh mi mj km mk kn ml kp mm kq mn ks mo kt mp mq bi translated">介绍</h1><p id="6386" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">相似性度量是许多数据分析和机器学习任务中的重要工具，允许我们比较和评估不同数据之间的相似性。有许多不同的度量标准，每种都有优缺点，适合不同的数据类型和任务。</p><p id="a826" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文将探讨一些最常见的相似性度量标准，并比较它们的优缺点。通过了解这些指标的特点和局限性，我们可以选择最适合我们具体需求的指标，并确保我们结果的准确性和相关性。</p><ul class=""><li id="8f4f" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx jh">欧几里德距离</strong></li></ul><p id="caa8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此指标计算 n 维空间中两点之间的直线距离。它通常用于连续的数值数据，易于理解和实现。然而，它可能对异常值敏感，并且不考虑不同特征的相对重要性。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="7fe6" class="no ma jg nk b be np nq l nr ns">from scipy.spatial import distance<br/><br/># Calculate Euclidean distance between two points<br/>point1 = [1, 2, 3]<br/>point2 = [4, 5, 6]<br/><br/># Use the euclidean function from scipy's distance module to calculate the Euclidean distance<br/>euclidean_distance = distance.euclidean(point1, point2)</span></pre><ul class=""><li id="a103" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx jh">曼哈顿距离</strong></li></ul><p id="f177" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该指标通过考虑两点在每个维度上坐标的绝对差异并求和来计算两点之间的距离。与欧氏距离相比，它对异常值不太敏感，但在某些情况下，它可能无法准确反映点之间的实际距离。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="c00e" class="no ma jg nk b be np nq l nr ns">from scipy.spatial import distance<br/><br/># Calculate Manhattan distance between two points<br/>point1 = [1, 2, 3]<br/>point2 = [4, 5, 6]<br/><br/># Use the cityblock function from scipy's distance module to calculate the Manhattan distance<br/>manhattan_distance = distance.cityblock(point1, point2)<br/><br/># Print the result<br/>print("Manhattan Distance between the given two points: " + \<br/>      str(manhattan_distance))</span></pre><ul class=""><li id="4ac0" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx jh">余弦相似度</strong></li></ul><p id="8867" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该指标通过考虑两个向量的角度来计算它们之间的相似性。它通常用于文本数据，并且不受向量大小变化的影响。但是，它没有考虑不同特性的相对重要性。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="9387" class="no ma jg nk b be np nq l nr ns">from sklearn.metrics.pairwise import cosine_similarity<br/><br/># Calculate cosine similarity between two vectors<br/>vector1 = [1, 2, 3]<br/>vector2 = [4, 5, 6]<br/><br/># Use the cosine_similarity function from scikit-learn to calculate the similarity<br/>cosine_sim = cosine_similarity([vector1], [vector2])[0][0]<br/><br/># Print the result<br/>print("Cosine Similarity between the given two vectors: " + \<br/>      str(cosine_sim))Jaccard Similarity</span></pre><ul class=""><li id="5ad4" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated">雅克卡相似性</li></ul><p id="8734" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此度量通过考虑两个集合的交集和并集的大小来计算它们之间的相似性。它通常用于分类数据，并且不受集合大小变化的影响。但是，它不考虑元素集的顺序或频率。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="f7d7" class="no ma jg nk b be np nq l nr ns">def jaccard_similarity(list1, list2):<br/>    """<br/>    Calculates the Jaccard similarity between two lists.<br/>    <br/>    Parameters:<br/>    list1 (list): The first list to compare.<br/>    list2 (list): The second list to compare.<br/>    <br/>    Returns:<br/>    float: The Jaccard similarity between the two lists.<br/>    """<br/>    # Convert the lists to sets for easier comparison<br/>    s1 = set(list1)<br/>    s2 = set(list2)<br/>    <br/>    # Calculate the Jaccard similarity by taking the length of the intersection of the sets<br/>    # and dividing it by the length of the union of the sets<br/>    return float(len(s1.intersection(s2)) / len(s1.union(s2)))<br/><br/># Calculate Jaccard similarity between two sets<br/>set1 = [1, 2, 3]<br/>set2 = [2, 3, 4]<br/>jaccard_sim = jaccard_similarity(set1, set2)<br/><br/># Print the result<br/>print("Jaccard Similarity between the given two sets: " + \<br/>      str(jaccard_sim))</span></pre><ul class=""><li id="289d" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx jh">皮尔逊相关系数</strong></li></ul><p id="d821" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此指标计算两个变量之间的线性相关性。它通常用于连续的数值数据，并考虑不同特征的相对重要性。然而，它可能无法准确反映非线性关系。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="0b5d" class="no ma jg nk b be np nq l nr ns">import numpy as np<br/><br/># Calculate Pearson correlation coefficient between two variables<br/>x = [1, 2, 3, 4]<br/>y = [2, 3, 4, 5]<br/><br/># Numpy corrcoef function to calculate the Pearson correlation coefficient and p-value<br/>pearson_corr = np.corrcoef(x, y)[0][1]<br/><br/># Print the result<br/>print("Pearson Correlation between the given two variables: " + \<br/>      str(pearson_corr))</span></pre><p id="f0ea" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们已经回顾了这些距离度量的基础，让我们考虑一个实际的场景，并应用它们来比较结果。</p><h1 id="60d7" class="lz ma jg bd mb mc nt me mf mg nu mi mj km nv kn ml kp nw kq mn ks nx kt mp mq bi translated">方案</h1><p id="73fa" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">假设我们有 5 个带有数字属性的商品，我们想要比较这些商品之间的相似性，以便于应用，比如聚类、分类或者推荐。</p><p id="8d33" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下代码使用各种距离度量计算给定产品及其属性的相似性度量，然后在热图中绘制结果以供评估。</p><pre class="nf ng nh ni gt nj nk nl bn nm nn bi"><span id="bc21" class="no ma jg nk b be np nq l nr ns">import numpy as np<br/>import seaborn as sns<br/>import random<br/>import matplotlib.pyplot as plt<br/>import pprint<br/><br/>def calculate_similarities(products):<br/>    """Calculate the similarity measures between all pairs of products.<br/>    <br/>    Parameters<br/>    ----------<br/>    products : list<br/>        A list of dictionaries containing the attributes of the products.<br/>    <br/>    Returns<br/>    -------<br/>    euclidean_similarities : numpy array<br/>        An array containing the Euclidean distance between each pair of products.<br/>    manhattan_distances : numpy array<br/>        An array containing the Manhattan distance between each pair of products.<br/>    cosine_similarities : numpy array<br/>        An array containing the cosine similarity between each pair of products.<br/>    jaccard_similarities : numpy array<br/>        An array containing the Jaccard index between each pair of products.<br/>    pearson_similarities : numpy array<br/>        An array containing the Pearson correlation coefficient between each pair of products.<br/>    """<br/>    # Initialize arrays to store the similarity measures<br/>    euclidean_similarities = np.zeros((len(products), len(products)))<br/>    manhattan_distances = np.zeros((len(products), len(products)))<br/>    cosine_similarities = np.zeros((len(products), len(products)))<br/>    jaccard_similarities = np.zeros((len(products), len(products)))<br/>    pearson_similarities = np.zeros((len(products), len(products)))<br/><br/>    # Calculate all the similarity measures in a single loop<br/>    for i in range(len(products)):<br/>        for j in range(i+1, len(products)):<br/>            p1 = products[i]['attributes']<br/>            p2 = products[j]['attributes']<br/><br/>            # Calculate Euclidean distance<br/>            euclidean_similarities[i][j] = distance.euclidean(p1, p2)<br/>            euclidean_similarities[j][i] = euclidean_similarities[i][j]<br/><br/>            # Calculate Manhattan distance<br/>            manhattan_distances[i][j] = distance.cityblock(p1, p2)<br/>            manhattan_distances[j][i] = manhattan_distances[i][j]<br/><br/>            # Calculate cosine similarity<br/>            cosine_similarities[i][j] = cosine_similarity([p1], [p2])[0][0]<br/>            cosine_similarities[j][i] = cosine_similarities[i][j]<br/><br/>            # Calculate Jaccard index<br/>            jaccard_similarities[i][j] = jaccard_similarity(p1, p2)<br/>            jaccard_similarities[j][i] = jaccard_similarities[i][j]<br/><br/>            # Calculate Pearson correlation coefficient<br/>            pearson_similarities[i][j] = np.corrcoef(p1, p2)[0][1]<br/>            pearson_similarities[j][i] = pearson_similarities[i][j]<br/>            <br/>    return euclidean_similarities, manhattan_distances, cosine_similarities, jaccard_similarities, pearson_similarities<br/><br/>def plot_similarities(similarities_list, labels, titles):<br/>    """Plot the given similarities as heatmaps in subplots.<br/>    <br/>    Parameters<br/>    ----------<br/>    similarities_list : list of numpy arrays<br/>        A list of arrays containing the similarities between the products.<br/>    labels : list<br/>        A list of strings containing the labels for the products.<br/>    titles : list<br/>        A list of strings containing the titles for each plot.<br/>    <br/>    Returns<br/>    -------<br/>    None<br/>        This function does not return any values. It only plots the heatmaps.<br/>    """<br/>    # Set up the plot<br/>    fig, ax = plt.subplots(nrows=1, <br/>                           ncols=len(similarities_list), figsize=(6*len(similarities_list), 6/1.680))<br/><br/>    for i, similarities in enumerate(similarities_list):<br/>        # Plot the heatmap<br/>        sns.heatmap(similarities, xticklabels=labels, yticklabels=labels, ax=ax[i])<br/>        ax[i].set_title(titles[i])<br/>        ax[i].set_xlabel("Product")<br/>        ax[i].set_ylabel("Product")<br/>    <br/>    # Show the plot<br/>    plt.show()<br/><br/># Define the products and their attributes<br/>products = [<br/>    {'name': 'Product 1', 'attributes': random.sample(range(1, 11), 5)},<br/>    {'name': 'Product 2', 'attributes': random.sample(range(1, 11), 5)},<br/>    {'name': 'Product 3', 'attributes': random.sample(range(1, 11), 5)},<br/>    {'name': 'Product 4', 'attributes': random.sample(range(1, 11), 5)},<br/>    {'name': 'Product 5', 'attributes': random.sample(range(1, 11), 5)}<br/>]<br/><br/>pprint.pprint(products)<br/><br/>euclidean_similarities, manhattan_distances, \<br/>cosine_similarities, jaccard_similarities, \<br/>pearson_similarities = calculate_similarities(products)<br/><br/># Set the labels for the x-axis and y-axis<br/>product_labels = [product['name'] for product in products]<br/><br/># List of similarity measures and their titles<br/>similarities_list = [euclidean_similarities, cosine_similarities, pearson_similarities, <br/>                     jaccard_similarities, manhattan_distances]<br/>titles = ["Euclidean Distance", "Cosine Similarity", "Pearson Correlation Coefficient", <br/>          "Jaccard Index", "Manhattan Distance"]<br/><br/># Plot the heatmaps<br/>plot_similarities(similarities_list, product_labels, titles)</span></pre><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/5e84c980b5e03fc5af78ddd71b7eb6a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7su6ZtbUKWekH8ahdF1w-g.png"/></div></div></figure><p id="8392" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如我们从图表中看到的，每个相似性指标都会生成一个热图，以不同的尺度表示产品之间的不同相似性。虽然每个相似性度量都可以用于根据度量值解释两个产品是否相似，但是在比较不同距离度量的结果时，很难确定相似性的真实度量。</p><p id="415d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">如何修正公制？</strong></p><p id="f114" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在选择相似性度量时，没有单一的“正确”答案，因为不同的度量更适合不同类型的数据和不同的分析目标。但是，有一些因素可以帮助缩小适用于给定情况的可能指标的范围。选择相似性度量标准时要考虑的一些事项包括:</p><ul class=""><li id="d5e6" class="mw mx jg kx b ky kz lb lc le my li mz lm na lq nb nc nd ne bi translated"><strong class="kx jh">数据类型</strong>:一些指标更适合连续数据，而另一些则更适合分类或二进制数据。</li><li id="f434" class="mw mx jg kx b ky nz lb oa le ob li oc lm od lq nb nc nd ne bi translated"><strong class="kx jh">数据的特性</strong>:不同的度量对数据的不同方面敏感，比如属性之间的差异大小或者属性之间的角度。考虑数据的哪些特征对您的分析最重要，并选择对这些特征敏感的相似性度量。</li><li id="3fca" class="mw mx jg kx b ky nz lb oa le ob li oc lm od lq nb nc nd ne bi translated"><strong class="kx jh">您分析的目标</strong>:不同的指标可以突出显示数据中不同的模式或关系，因此，请考虑您试图从分析中了解什么，并选择一个非常适合此目的的距离指标。</li></ul><p id="c276" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">就我个人而言，在选择相似性度量时，我经常使用下面的图表作为起点。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/3ee5f20b773c58f885658a2b85d7647d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2WhX1CV-ueFNdsE5YHF9A.png"/></div></div></figure><p id="12aa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样，在选择相似性度量时，仔细考虑数据类型和特征以及分析的具体目标也很重要。</p><p id="05bd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文中使用的所有代码都可以在<a class="ae jd" href="https://github.com/kapadias/medium-articles/blob/master/general-data-science/similarities-measures/similarity-measures.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>中找到。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="568c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">感谢阅读。如果你有任何反馈，欢迎评论这篇文章，给我发消息</em> <a class="ae jd" href="https://www.linkedin.com/in/shashankkapadia/" rel="noopener ugc nofollow" target="_blank"> <em class="lr"> LinkedIn </em> </a> <em class="lr">，或者给我发邮件</em></p><p id="5a37" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你喜欢这篇文章，请阅读我的其他文章</p><div class="ip iq gp gr ir of"><a rel="noopener follow" target="_blank" href="/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jh gy z fp ok fr fs ol fu fw jf bi translated">评估主题模型:潜在狄利克雷分配(LDA)</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">构建可解释主题模型的分步指南</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot ix of"/></div></div></a></div><div class="ip iq gp gr ir of"><a rel="noopener follow" target="_blank" href="/recommendation-system-in-python-lightfm-61c85010ce17"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd jh gy z fp ok fr fs ol fu fw jf bi translated">Python 中的推荐系统:LightFM</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">使用 LightFM 在 Python 中构建推荐系统的分步指南</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="ou l oq or os oo ot ix of"/></div></div></a></div></div></div>    
</body>
</html>