<html>
<head>
<title>Generate MNIST Digits Using Shallow and Deep Autoencoders in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras中的浅层和深层自动编码器生成MNIST数字</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-mnist-digits-using-shallow-and-deep-autoencoders-in-keras-fb011dd3fec3#2022-08-09">https://towardsdatascience.com/generate-mnist-digits-using-shallow-and-deep-autoencoders-in-keras-fb011dd3fec3#2022-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b090" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用函数式API —神经网络和深度学习课程:第29部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b6e87e7de483f0cd1a3bbc38920afe36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qif-b5eyeuFoUE0KhzdEFQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原照片由<a class="ae ky" href="https://unsplash.com/@refargotohp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> refargotohp </a>在<a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄，由作者编辑</p></figure><p id="e934" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们忽略了算法的实际应用，那么算法是没有用的。</p><p id="8bde" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经讨论了自动编码器背后的原理。是时候讨论它们的实际应用了。在此之前，您应该知道自动编码器是如何在Keras中实现的。</p><p id="13d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在本文中，我将通过在MNIST数据上构建两个自动编码器模型来讨论自动编码器的Keras实现(参见最后的数据集<a class="ae ky" href="#a6cd" rel="noopener ugc nofollow">引文</a>)。还将定义一些与自动编码器模型架构相关的重要关键字。</p><h2 id="6152" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">先决条件</h2><p id="a46f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我推荐你阅读下面的文章作为这篇文章的先决条件。</p><ul class=""><li id="38b9" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><a class="ae ky" href="https://rukshanpramoditha.medium.com/an-introduction-to-autoencoders-in-deep-learning-ab5a5861f81e" rel="noopener"> <strong class="lb iu">深度学习中的自动编码器介绍</strong> </a>(推荐使用，因为你需要在实现之前了解自动编码器的原理)</li><li id="2559" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://rukshanpramoditha.medium.com/two-different-ways-to-build-keras-models-sequential-api-and-functional-api-868e64594820" rel="noopener"> <strong class="lb iu">构建Keras模型的两种不同方式:顺序API和函数API </strong> </a>(推荐使用，因为您将在这里使用Keras函数API来构建autoencoder模型)</li><li id="6f35" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><a class="ae ky" href="https://rukshanpramoditha.medium.com/acquire-understand-and-prepare-the-mnist-dataset-3d71a84e07e7" rel="noopener"> <strong class="lb iu">获取、理解并准备MNIST数据集</strong> </a>(推荐使用，因为您将在此使用MNIST数据集构建自动编码器模型)</li></ul><h1 id="7cff" class="nh lw it bd lx ni nj nk ma nl nm nn md jz no ka mg kc np kd mj kf nq kg mm nr bi translated">自动编码器的基本分类</h1><p id="66b7" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们从自动编码器模型的一些基本分类和定义与自动编码器相关的重要关键字开始。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/2739e72cb75dba09b2f39fb1a8645ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*nEKfOKF6RBwWVlBurTl75g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">自动编码器的基本分类</strong>(图片由作者提供，用draw.io制作)</p></figure><h2 id="0d6f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">欠完整与过完整自动编码器</h2><p id="d3d5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">当自动编码器的潜在向量的维数小于输入的维数时，称为<strong class="lb iu"> <em class="nu">欠完备自动编码器</em> </strong>。这种类型的自动编码器通常只尝试学习数据中最重要的特征。</p><p id="f939" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，当自动编码器的潜在向量的维数大于或等于输入的维数时，它被称为<strong class="lb iu"> <em class="nu">过完全自动编码器</em> </strong>，它试图复制输入而不学习任何重要的特征。</p><p id="c278" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在这里构建的自动编码器模型属于<em class="nu">欠完整自动编码器</em>类别。</p><h2 id="63cc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">浅层自动编码器与深层自动编码器</h2><p id="4660" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">只有一个隐藏层的自动编码器称为<strong class="lb iu"> <em class="nu">浅层自动编码器</em> </strong>，而有多个隐藏层的自动编码器称为<strong class="lb iu"> <em class="nu">深层自动编码器</em> </strong>，在某些情况下也称为<strong class="lb iu"> <em class="nu">多层自动编码器</em> </strong>。</p><h2 id="33d9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">自动编码器中不同类型的层</h2><p id="3b4b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">自动编码器的编码器和解码器部分可以使用全连接(密集)层来构建。但是，它们不仅限于完全连接的层。诸如卷积层的其他层类型可以用于自动编码器的编码器和解码器部分。</p><h1 id="28b7" class="nh lw it bd lx ni nj nk ma nl nm nn md jz no ka mg kc np kd mj kf nq kg mm nr bi translated">设计MNIST数据自动编码器的体系结构</h1><h2 id="4232" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">浅层自动编码器</h2><p id="d38c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们将为MNIST数据构建一个带有一个隐藏层的自动编码器，并查看模型的输出。我们将使用Keras函数式API方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/d3e344ae3bf62b49a1e1aa9ba23e2e55.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*OU19y3l5u1IXmCNKl6_5JA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">浅层自动编码器架构</strong>(图片由作者提供，用draw.io制作)</p></figure><ul class=""><li id="d040" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">步骤1: </strong>定义浅层自动编码器架构。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">编码浅层自动编码器的架构</strong>(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/652ef07af1fde6e5a65bd8bc058f0014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*ELf2axt-aQKLGsDU2LVJ8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">浅层自动编码器架构</strong>(图片由作者提供)</p></figure><p id="29a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自动编码器输出层的大小应该与其输入层的大小相同。否则，输入的重建将是不可能的。</p><p id="8c31" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面代码中的<strong class="lb iu"> <em class="nu"> autoencoder </em> </strong>变量包含编码器和解码器两部分。调用<code class="fe nz oa ob oc b">autoencoder.fit()</code>将输入压缩成潜向量，然后将给定的输入重构为输出。调用<code class="fe nz oa ob oc b">autoencoder.predict()</code>为新的输入数据执行这个过程。</p><p id="c9c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上述代码中的<strong class="lb iu"> <em class="nu"> latent_model </em> </strong>变量输出输入的潜在表示。它包含输入的最重要的特征，并且一旦被训练就可以用于维数减少的目的，这在这里是可选的。调用<code class="fe nz oa ob oc b">latent_model.fit()</code>将输入映射到潜在空间。调用<code class="fe nz oa ob oc b">latent_model.predict()</code>编码新的输入数据。</p><ul class=""><li id="244a" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">步骤2: </strong>采集并准备MNIST数据集。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><p id="54c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，自动编码器不需要标签，因为它们是无监督的学习算法。</p><ul class=""><li id="c88c" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">第三步:</strong>编译、训练、监控损失函数。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1bee6a7964f364c13fd00579e78a426f.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*M26h-fnkCtk-2F84pOF5TA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="4065" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调用<code class="fe nz oa ob oc b">compile()</code>方法为训练准备模型。也就是说，我们声明损失函数的类型和模型的优化器。</p><p id="928f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，我们使用<code class="fe nz oa ob oc b">(X_train, y_train)</code>训练我们的模型，使用<code class="fe nz oa ob oc b">(X_test, y_test)</code>验证我们的模型。但是，在这里，我们使用<code class="fe nz oa ob oc b">(X_train, X_train)</code>训练我们的自动编码器模型，并使用<code class="fe nz oa ob oc b">(X_test, X_test)</code>验证我们的自动编码器模型。我们忽略了<code class="fe nz oa ob oc b">y_train</code>和<code class="fe nz oa ob oc b">y_test</code>部分。这是因为自动编码器是不需要标签的无监督学习算法，输入和输出应该是相同的。</p><ul class=""><li id="aeea" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">第四步:</strong>通过重构输入来测试模型。</li></ul><p id="bde0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以绘制原始MNIST数字如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/45077a9734db9c8423bd36fadc892d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*XuYTuL7NHw0ysaTy01LeSQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">原始MNIST图片</strong>(图片由作者提供)</p></figure><p id="34c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以通过我们的浅层自动编码器模型来绘制重建的MNIST数字。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/94786e3ae90a66ceb226c5f67a18aebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*gir55zxaNEUBkXKY-qpbow.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">浅层自动编码器重建MNIST数字</strong>(图片作者提供)</p></figure><p id="bf04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重建的图像与原始图像不太匹配，但它们仍然是可识别的。换句话说，重建图像的质量并不完美。原因是我们在自动编码器模型中只使用了一个隐藏层。这不足以捕捉MNSIT数字数据中复杂的非线性模式。因此，在下一节，我们将增加隐藏层的数量，并建立一个深度(多层)自动编码器。</p><h2 id="1634" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">深层(多层)自动编码器</h2><p id="738c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们将为MNIST数据构建一个具有多个隐藏层的自动编码器，并查看模型的输出。我们将使用Keras函数式API方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/667f78cb8b6a65846ecb49ccf30ef6f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*RHSJH1sl0K4oApTAnZmqtw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">深度自动编码器架构</strong>(图片由作者提供，用draw.io制作)</p></figure><ul class=""><li id="2f94" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">步骤1: </strong>定义深度自动编码器架构。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">编码深度自动编码器的架构</strong>(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/02f1911b550dc60cdbaccd8b82e93bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*3l55HsW3OflDQbramPcu0g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">深度自动编码器架构</strong>(图片由作者提供)</p></figure><ul class=""><li id="3d19" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">步骤2: </strong>如前所述采集并准备MNIST数据集。</li><li id="5187" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">第三步:</strong>编译、训练、监控损失函数。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nw nx l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/fc7b1fdb521140f414bdbd9441b900c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*VvFgfBzBzhvlRk28a83nCQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><ul class=""><li id="83cf" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">第四步:</strong>通过重构输入来测试模型。</li></ul><p id="5182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以像前面一样画出原始的MNIST数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/fd88275a7827ad9348c60b193e601efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*sza2gbUAtBs8jhdSa6FC0Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">原始MNIST图片</strong>(图片由作者提供)</p></figure><p id="b218" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以像前面一样通过我们的深度自动编码器模型来绘制重建的MNIST数字。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/0eae11187896038f762bf87d099dd316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*y9MLExDanhty0shV5ZRnoA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">深度自动编码器重建的MNIST数字</strong>(图片由作者提供)</p></figure><p id="76df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这一次，重建图像的质量有所提高！这是因为我们在自动编码器中使用了许多隐藏层。</p><p id="5eb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是对比。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/75920ece6373b0cc4cca83fe9d32c02b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*hRw613gYpeNuUEUCTRFODg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="d0c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只有一个隐藏层的浅层自动编码器在生成MNIST数字上表现不佳。这是因为单个隐藏层不足以捕捉MNIST数据中存在的更复杂的非线性模式。具有多个隐藏层的深层(多层)自动编码器在产生MNIST数字方面表现良好。</p><p id="04f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着我们增加隐藏层的数量(一个超参数！)在自动编码器中，模型倾向于很好地学习复杂的非线性关系。我们可以尝试不同数量的隐藏层。这是自动编码器中的一种超参数调整。自动编码器的其他重要超参数是<em class="nu">潜在向量的维数</em>、<em class="nu">隐藏层中的节点数</em>、<em class="nu">损失函数的类型</em>、<em class="nu">优化器的类型</em>、<em class="nu">学习速率</em>、<em class="nu">批量大小</em>、<em class="nu">时期数</em>以及隐藏层中使用的激活函数的类型<em class="nu"/>。</p><p id="9921" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，自动编码器的参数是与全连接层中的每个节点相关联的权重和偏差。</p><p id="b4d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当训练自动编码器时，我们试图通过最小化损失函数来最小化重建误差，该损失函数在训练的每个时期多次更新权重和偏差(参数)的值。</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="8705" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的帖子到此结束。</p><p id="643c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您有任何问题或反馈，请告诉我。</p><h2 id="a34a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">阅读下一篇(推荐)</h2><ul class=""><li id="15ba" class="mt mu it lb b lc mo lf mp li or lm os lq ot lu my mz na nb bi translated">阅读我的“<a class="ae ky" href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75" rel="noopener">神经网络和深度学习课程</a>”的所有剧集。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75"><div class="gh gi ou"><img src="../Images/e485e774f61ca79d36cd0e9e73dc9b5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*IZPnwNH2r73JJXvQWUUsrg.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nt">点击图片进入我的神经网络和深度学习课程</strong>(作者截图)</p></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="3ec1" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">支持我当作家</h2><p id="0737" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我希望你喜欢阅读这篇文章。如果你愿意支持我成为一名作家，请考虑注册成为会员，不受限制地接触媒体。它只需要每月5美元，我会收到你的会员费的一部分。</p><div class="ov ow gp gr ox oy"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">通过我的推荐链接加入Medium</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">阅读Rukshan Pramoditha(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm ks oy"/></div></div></a></div><p id="34c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nu">或者，您也可以考虑通过点击本文底部的</em> <strong class="lb iu"> <em class="nu">给小费</em> </strong> <em class="nu">按钮进行小额捐赠。</em></p><p id="2329" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你一直以来的支持！下一篇文章再见。祝大家学习愉快！</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="a6cd" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">MNIST数据集信息</h2><ul class=""><li id="da74" class="mt mu it lb b lc mo lf mp li or lm os lq ot lu my mz na nb bi translated"><strong class="lb iu">引用:</strong>邓，l，2012。用于机器学习研究的手写数字图像mnist数据库。<strong class="lb iu"> IEEE信号处理杂志</strong>，29(6)，第141–142页。</li><li id="3dd2" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">【http://yann.lecun.com/exdb/mnist/】来源:<a class="ae ky" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"/></li><li id="f65d" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">许可:</strong><em class="nu">Yann le Cun</em>(NYU库朗研究所)和<em class="nu"> Corinna Cortes </em>(纽约谷歌实验室)持有MNIST数据集的版权，该数据集在<em class="nu">知识共享署名-共享4.0国际许可</em>(<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">CC BY-SA</strong></a>)下可用。你可以在这里了解更多关于不同数据集许可类型的信息。</li></ul></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="b6a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="pn po ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----fb011dd3fec3--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lb iu">2022–08–09</strong></p></div></div>    
</body>
</html>