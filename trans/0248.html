<html>
<head>
<title>Explainable AI: Understanding the Decisions of a Convolutional Neural Network — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的人工智能:理解卷积神经网络的决策——第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-ai-understanding-the-decisions-of-a-convolutional-neural-network-part-1-1a9cf26364fd#2022-02-10">https://towardsdatascience.com/explainable-ai-understanding-the-decisions-of-a-convolutional-neural-network-part-1-1a9cf26364fd#2022-02-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a14e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">深入局部可解释的模型不可知解释(LIME)</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1fc19e67dad992b9bdad7816a79fca3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5j7jhBpUMQnT7IcQ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">丹尼·米勒在<a class="ae kv" href="https://unsplash.com/s/photos/network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="7aaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们如何定义一个卷积神经网络(CNN)的质量？一个模型在给定任务中的性能通常由一些(简单的)预定义的度量来衡量。甚至还有一个<a class="ae kv" href="https://paperswithcode.com/task/image-classification" rel="noopener ugc nofollow" target="_blank">的地方</a>用来比较标准化数据集上最先进的图像分类模型的准确性。然而，如果你在现实世界中从事一个项目，如果一个模型有惊人的最高精确度，那么它的质量和价值是什么？除了这些简单的量化指标之外，我们还能对模型的质量提出什么要求呢？</p><p id="221c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是可解释的人工智能(XAI)的用武之地。XAI系统可以被定义为“一个自我解释的智能系统，描述了其决策和预测背后的推理”。[1]向您的ML管道中添加一个可解释的组件不仅提供了<em class="ls">模型的可解释性</em>，而且还可以使业务利益相关者获得对您的模型的信任，或者可以用于评估(并修复)您的模型中的系统偏差。[1]</p><p id="4e60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在几个部分中，我将讨论可用于图像分类项目的几种XAI方法的内部工作原理和利弊。在文献中，这些方法通常被称为<em class="ls">像素属性方法</em>、<em class="ls">显著图、</em>或<em class="ls">灵敏度图</em>。对于某些方法，提供了代码，因此可以在您自己的项目中实现。所有的代码都可以在这里找到<a class="ae kv" href="https://github.com/RikKraanVantage/explainable_AI" rel="noopener ugc nofollow" target="_blank"/>。这是第一个博客，旨在解释基于输入的归因模型，重点是本地可解释的模型不可知的解释(在短期内)。[2]</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="0e98" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated"><strong class="ak">方法</strong></h1><p id="bdd3" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">存在许多不同的方法来获得<em class="ls">像素属性图。</em>一般来说，这些方法可以分为两个主流:基于前向传递(或输入)的归因模型和基于后向传递(或梯度)的归因模型。</p><h1 id="1046" class="ma mb iq bd mc md mx mf mg mh my mj mk jw mz jx mm jz na ka mo kc nb kd mq mr bi translated"><strong class="ak">第1部分:基于正向传递(或输入)的归因模型</strong></h1><p id="a783" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">这些方法是模型不可知的。这些模型背后的主要直觉非常简单。拍摄输入图像；对输入进行一些调整，并观察对预测的影响。调整可以包括例如输入部分的部分遮挡或扰动。可能最著名的例子是局部可解释的模型不可知解释(或LIME)。[2]</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d947c8792e2431997a36c4cc2a60ce4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*72wYouVnwbvYx_eIxi8dSg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">石灰|照片由<a class="ae kv" href="https://unsplash.com/@shaunmcreatives?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Shaun Meintjes </a>在<a class="ae kv" href="https://unsplash.com/photos/8B6AdgoB5xA?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="048b" class="ma mb iq bd mc md mx mf mg mh my mj mk jw mz jx mm jz na ka mo kc nb kd mq mr bi translated">局部可解释的模型不可知解释(LIME)</h1><p id="23c2" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">LIME可用于所有类型的数据，不仅限于图像分类。虽然当用于解释图像分类模型时，它通常被称为<em class="ls">像素属性方法，</em> LIME对单个像素不起作用，因为这些可能不会改变预测太多。相反，LIME利用了所谓的“超像素”,即按位置颜色分组的图像小区域。这些超像素区域用于多次扰乱图像，并识别这些变化对预测的影响。最终，对这些扰动图像的预测被用于训练更简单(且可解释)的模型，例如线性回归，以识别哪些超像素区域对预测特定类别最重要。</p><h2 id="708c" class="nd mb iq bd mc ne nf dn mg ng nh dp mk lf ni nj mm lj nk nl mo ln nm nn mq no bi translated"><strong class="ak">概述</strong></h2><p id="730a" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">最初阅读原始论文可能会令人望而生畏，但提取后创建属性地图的步骤非常容易理解:</p><pre class="kg kh ki kj gt np nq nr ns aw nt bi"><span id="afc5" class="nd mb iq nq b gy nu nv l nw nx">1. Generate superpixel areas</span><span id="540f" class="nd mb iq nq b gy ny nv l nw nx">2. Create perturbed images by randomly filling some of the superpixel areas with a solid black color</span><span id="48f1" class="nd mb iq nq b gy ny nv l nw nx">3. For each perturbed image: <br/>    a. Make predictions for the perturbed image<br/>    b. Create weights based on the difference between the perturbed image and the original image (smaller distance == larger weight)</span><span id="65c4" class="nd mb iq nq b gy ny nv l nw nx">4. Fit a simple interpretable model using the predictions on all perturbed images and the created weights.</span><span id="dab4" class="nd mb iq nq b gy ny nv l nw nx">5. Define the number of superpixels that should be plotted and plot the superpixels with the highest importance in the simple model (i.e. coefficient if a Linear Regression is used).</span></pre><p id="7656" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更直观地概述这些步骤，请参见下图。左图为原图。此外，该图还展示了所有超像素区域的轮廓。第三个图描绘了扰动图像的样本，其将用于识别通过扰动原始图片的黑色区域将改变多少预测。最后一个图表示根据LIME预测‘巨嘴鸟’级的最重要区域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/4a4a601332580223d8c40e87ffc8454a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPhQ12OKnxH31AQNja6FnQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多个图展示了a)原始输入图像，b)所有超像素区域的边界，c)扰动图像的样本，以及d)预测“巨嘴鸟”类别的最重要的超像素区域(图片由作者提供)</p></figure></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="ef7c" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">利弊</h1><p id="5e32" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">LIME的主要优点之一是它是模型不可知的，可以用于任何模型。这也意味着底层模型可以很容易地被替换，而不必用LIME调整代码进行解释。此外，LIME使用“简单”的可理解模型来解释模型的决策，因此作为一名数据科学家，很容易向最终用户解释。这也是唯一可以用于图像、文本和表格数据的方法之一。因此，如果你在一个生产中有几个模型的公司工作，选择LIME来解释可能是一个好的选择，因为最终用户只需要理解一个方法的直觉。</p><p id="47ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该方法也有一些缺点。这可能是计算密集型的，尤其是当使用大型CNN时，因为必须对每个受干扰的图像进行预测。在应用石灰时也有很多选择要做:多少超像素区域合适？对于可解释性，应该使用什么简单的模型？在可解释图中应该画出多少超像素区域？这些都是应该根据您自己的情况进行调整的参数，找到最佳解决方案可能需要一些时间。最后，拟合的简单(可解释的)模型近似于CNN，但并不能真正解释它。这款合体没有质量检查，所以可能会有误导。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="becf" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">亲自动手</h1><p id="133c" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">关于如何使用石灰的笔记本范例可以在https://github.com/RikKraanVantage/explainable_AI<a class="ae kv" href="https://github.com/RikKraanVantage/explainable_AI" rel="noopener ugc nofollow" target="_blank">的以下储存库中找到。这里包括了为你自己的项目复制LIME解释所必需的代码。</a></p><p id="2908" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接下来的部分中，将通过代码片段来介绍为您自己的项目复制LIME解释的步骤。本例中使用的基本模型是一个具有预训练的<code class="fe oa ob oc nq b">imagenet</code>权重的<code class="fe oa ob oc nq b">tf.keras.applications.EfficientNetB0</code>，但是可以使用任何CNN。</p><ol class=""><li id="dc2c" class="od oe iq ky b kz la lc ld lf of lj og ln oh lr oi oj ok ol bi translated"><strong class="ky ir">生成超像素区域</strong></li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4af1769a399369c7ff4bc4d20d322c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*y0UPV4nkJF8iic95UGOv-g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">超像素边界(图片由作者提供)</p></figure><p id="931d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了生成超像素区域，使用由<code class="fe oa ob oc nq b">scikit-image</code>实现的<code class="fe oa ob oc nq b">quickshift</code>算法。该算法基于颜色(和位置)分割图像，但是也可以使用更高级的聚类算法。对于这个算法，一些参数可以被调整(<code class="fe oa ob oc nq b">kernel_size</code>、<code class="fe oa ob oc nq b">max_distance</code>和<code class="fe oa ob oc nq b">ratio</code>)。基本上，这些参数定义了创建多少超像素区域。有关如何调整这些参数的更多信息，请参见<a class="ae kv" href="https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.quickshift" rel="noopener ugc nofollow" target="_blank">https://sci kit-image . org/docs/stable/API/skim age . segmentation . html # skim age . segmentation . quick shift</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="06cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.<strong class="ky ir">生成扰动图像</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/4515d7674554aa182ed3679f17448f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*1-Ngv2mpPST8J7Pj2Ec2aA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">扰动图像(作者提供的图像)</p></figure><p id="fa16" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过创建<code class="fe oa ob oc nq b">perturbation vectors</code>生成扰动图像。这些是长度为<code class="fe oa ob oc nq b">super_pixel_count</code>的二进制向量。这些向量为特定的扰动图像定义了哪些超像素区域应该被扰动，哪些不应该被扰动。<code class="fe oa ob oc nq b">perturbation vectors</code>的数量是可以调整的，但是要知道增加它会带来所需计算能力的增加。</p><p id="1da7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了生成<code class="fe oa ob oc nq b">perturbation vectors</code>，我们使用Numpy的<code class="fe oa ob oc nq b">np.random.binomial()</code>函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="0d6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有几个向量可以用来扰乱图像:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="2aac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.<strong class="ky ir">对扰动图像进行预测并生成权重</strong></p><p id="5ba4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预测所有扰动的图像是简单的，计算权重稍微复杂一些。为了创建权重，我们首先计算原始图像和扰动图像之间的距离。更具体地，我们计算原始图像的扰动向量(只有一个，因为没有扰动)<code class="fe oa ob oc nq b">[1, 1, 1, 1, 1, 1, ..., 1]</code>和随机扰动向量<code class="fe oa ob oc nq b">[1, 0, 1, 0, 0, 0, 1 ..., 1]</code>之间的距离。为此，我们利用了<code class="fe oa ob oc nq b">sklearn</code>的<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html" rel="noopener ugc nofollow" target="_blank">成对距离</a>度量。随后，我们对距离应用核函数来创建权重。这最后一步确保扰动向量越接近原始图像，权重就越高。为什么这是必要的？让我们假设我们有一个只有1个扰动超像素区域的扰动图像。该样本非常有价值，因为它提供了关于特定超像素区域的大量信息(即，如果扰动图像上特定类别的预测与原始图像上的预测非常不同，则我们知道该超像素区域对于预测特定类别非常重要)。此外，如果我们有一个图像，其中所有区域都被扰动(零的向量)，对特定类别的预测可能会非常不同，只是它提供了很少的关于哪个超像素区域对预测是重要的信息。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="eb9f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.<strong class="ky ir">拟合一个简单的可解释模型</strong></p><p id="a59c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是使用<code class="fe oa ob oc nq b">perturbation_vectors</code>对扰动图像的预测和新创建的权重来拟合一个简单(且可解释)的模型。可以使用多种型号，最简单的方法是使用开箱即用的<code class="fe oa ob oc nq b">sklearn</code>型号。对于这个例子，使用了一个<code class="fe oa ob oc nq b">DecisionTreeRegressor</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="da5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意，输入到函数中的<code class="fe oa ob oc nq b">predictions</code>应该只包含对感兴趣类别的每个扰动图像的预测。所以这个向量的形状是<code class="fe oa ob oc nq b">(num_perturbations, 1)</code>。结果是包含用于预测指定类别的每个超像素区域的<code class="fe oa ob oc nq b">feature_importance</code>的向量。</p><p id="d348" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.<strong class="ky ir">剧情解说</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/1851063e5b7bfd67c258f9f3d4fc9c16.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*s3qkeQr1CYdrczLxXoM8nQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">石灰说明(图片由作者提供)</p></figure><p id="51e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，解释可以被绘制出来。首先，应该定义将要描绘的超像素区域的数量。这可以通过设置重要性阈值、取超像素区域总数的一部分或者仅仅通过硬编码一个数字来实现。在这个例子中，我总共绘制了4个超像素区域。根据LIME的说法，似乎巨嘴鸟的喙和眼睛周围的白色区域是模型检测它的重要区域(因为这些区域是拟合的简单模型的最重要特征)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="32b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">结论</strong></p><p id="4770" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博客展示了XAI最常用的方法之一的直觉和利弊。代码片段显示实现它相当简单。下一部分将讨论和实现基于梯度的属性方法。检查仓库中的所有代码示例:【https://github.com/RikKraanVantage/explainable_AI<a class="ae kv" href="https://github.com/RikKraanVantage/explainable_AI" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="cf41" class="ma mb iq bd mc md mx mf mg mh my mj mk jw mz jx mm jz na ka mo kc nb kd mq mr bi translated">关于作者</h1><p id="6ca1" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated"><a class="ae kv" href="https://www.linkedin.com/in/rikkraan/" rel="noopener ugc nofollow" target="_blank"> Rik Kraan </a>是一名放射学博士，在荷兰数据科学咨询公司<strong class="ky ir"> BigData Republic </strong>担任数据科学家。通过rik.kraan@bigdatarepublic.nl联系。</p><h1 id="0f37" class="ma mb iq bd mc md mx mf mg mh my mj mk jw mz jx mm jz na ka mo kc nb kd mq mr bi translated"><strong class="ak">来源</strong></h1><p id="1ea6" class="pw-post-body-paragraph kw kx iq ky b kz ms jr lb lc mt ju le lf mu lh li lj mv ll lm ln mw lp lq lr ij bi translated">[1]西纳·莫塞尼、尼卢法尔·扎雷和埃里克·拉冈。2020.可解释人工智能系统设计和评估的多学科调查和框架。ACM Trans互动。智能。系统。1、1、第一条(2020年1月)，46页。<a class="ae kv" href="https://doi.org/10.1145/3387166" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1145/3387166</a><br/>【2】里贝罗、马尔科·图利奥、萨梅尔·辛格、卡洛斯·盖斯特林。“我为什么要相信你？:解释任何分类器的预测。第22届ACM SIGKDD知识发现和数据挖掘国际会议论文集。美国计算机学会(2016年)。</p></div></div>    
</body>
</html>