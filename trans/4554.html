<html>
<head>
<title>Explainable Boosting Machine: Bridging the Gap between ML and Explainability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的助推机器:弥合ML和可解释性之间的鸿沟</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ebm-bridging-the-gap-between-ml-and-explainability-9c58953deb33#2022-10-10">https://towardsdatascience.com/ebm-bridging-the-gap-between-ml-and-explainability-9c58953deb33#2022-10-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="513e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">什么是可解释性，为什么它很重要？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6b7cc59e290e22096bc7bb3635245886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEmRF9ChwWj2TldXNVK5tA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">安德烈·德·森蒂斯峰在<a class="ae kv" href="https://unsplash.com/s/photos/ai?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="eb4f" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">什么是可解释性，为什么它很重要？</strong></h2><p id="188e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">人工智能在过去几十年中不断发展，已经在各个领域找到了应用，包括医疗保健、军事、银行和自动驾驶汽车等关键系统。然而，很多时候，许多机器学习模型的黑盒性质阻碍了它们的采用。例如，在商业中，机器学习的应用将是预测未来销售、预测客户流失、锁定客户等。黑箱模型或许能够准确预测未来的销售或客户流失，但它无法解释不同的因素如何影响产出。这在银行业等行业尤其重要，因为这些行业受到监管机构的监管，这些机构要求其模型透明、结构公正。此外，对模型决策的理解有助于企业理解不同因素如何影响其业务，更好地为不确定的未来做准备，并做出更好的战略决策。这是通过可解释的或玻璃盒子的ML模型提供给他们的。</p><p id="613e" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">机器学习中的可解释性指的是模型或建模技术解开模型内关系的能力。根据算法提供的可解释性水平，机器学习模型可以大致分为两类:玻璃盒模型和黑盒模型。本文探讨了什么是玻璃盒模型和黑盒模型，是什么赋予了玻璃盒模型的可解释性，以及一种称为可解释助推机(EBM)的玻璃盒模型。</p><p id="1fdc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">玻璃盒型号:</strong></p><p id="7c7a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这些都是固有解释的模型。属于这一类的两个最简单的模型是线性回归和逻辑回归。以逻辑回归为例，它将概率预测为一个或多个独立变量的线性组合的函数。这个模型的等式可以写成:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/d52e159be358a1597c9464c5b330a740.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*rBZaaTTC84nA1Z9x-L6OmA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="175a" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">其中p是事件发生的概率，log(p/(1-p))是事件的对数概率。这种将对数概率表示为独立变量的线性组合的能力使得该模型具有可解释性。对于这个逻辑回归模型，可以说变量x1的单位变化改变了事件的对数概率β1。注意，为了便于解释，因变量不需要与自变量具有线性关系。例如，即使是以下形式的“广义加性模型”</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/d14bbe5e33cc9bf51f45f2f94a1e14fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*WmAuSwB5njcpTuydCqpEUw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ef9b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">是可以解释的，因为你可以估计任何变量x的变化是如何影响目标y的</p><p id="0952" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">黑盒模型:</strong></p><p id="5b01" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在这些模型中，自变量和因变量之间的关系并不明显。诸如随机森林、梯度增强树和神经网络<strong class="lu ir"> </strong>之类的算法是一些黑盒模型。</p><p id="4d86" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">为了进一步说明黑盒的概念，考虑一个简单回归树的例子，它具有以下数学形式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/bd3b2c6b9994429ba50e39308b90363a.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*7WU7BgDM9nYQHxDUUAlvtg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3d09" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">其中，ki是常数，I(。)是一个指示函数，如果其参数为真，则返回1，否则返回0。</p><p id="14a2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">和Di是训练数据的不相交分区。下面的例子说明了这个等式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/8643ed0bc5700f91eefd42851613410c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iito5SHyPePlw7mY77bpgQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a9cb" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用上述等式的更简洁的表示，我们得到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/f7ed6d19b95e17e2b60f2e0b5a355d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PJvyq27Lp33ObrgvbzRsxA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="193b" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然而，玻璃盒模型虽然可以解释，但与黑盒模型相比往往不够准确。EBM试图通过提供一个与一些黑盒模型一样准确同时又保持相当可解释性的解决方案来弥合这一差距。</p><p id="15d1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">可解释增压机</strong></p><p id="9126" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">什么是循证医学？</strong></p><p id="0cfd" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">EBM是一个广义的加法模型，它使用梯度推进和浅回归树的集合[1]。因此，简单地说，循证医学是以下形式的广义函数</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/094cbcce1681aa9266bc4ffc8700815b.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*tllLLXAML1d17PJ4zQjJFA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="2398" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">其中g(。)是一个链接函数(类似于广义线性模型)。该模型使用非常低的学习率在“循环周期”中一次训练一个特征，因此特征顺序无关紧要[1]。</p><p id="d7ee" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">因此，在迭代1中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4148f93368a0434341372b6b53a3df63.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*SI0tDEq1Clba-pohqRNbRQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1e20" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在迭代2中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/24e882744ede4360f837664124f95ce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*nDO4-dh7GYGIfk2TACKGlg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ef91" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这一直持续到迭代r。每个特征的最终函数是通过将该特征的所有函数相加而获得的，即</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/cfc3cead6b901c78c372dd8df73761c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*xHBbq7tfaj2NaV2mGrhHAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cc3c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">诸如此类。</p><p id="1266" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">对于每一个特征，EBM计算一个f(xi)对xi表，用它来产生得分对xi图，帮助理解xi和易之间的关系以及每一个特征对易预测的贡献。然而，循证医学并不止于此。它还包括变量之间的二维相互作用。由于二维交互仍然可以在二维平面上呈现为热图，因此包含二维交互的模型仍然是可解释的。因此，EBM的最终形式可以表示为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/cd5071a8d136442427347b201ecd44ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*qrdEjUKZh-eNZy7ojRMQVw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="158c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">传统上，确定交互项在所需的计算能力方面是复杂的，尤其是对于具有大量变量的大型数据集。EBM通过提出两阶段构建方法和使用FAST有效地对成对交互进行排序来解决这个问题。这种方法的两个阶段是:</p><p id="3c83" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">1.在第一阶段，仅使用一维组件构建最佳的附加模型。</p><p id="f13d" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">2.在阶段2中，固定一维函数并为残差上的成对相互作用构建模型，即，使用FAST选择前K个相互作用对，并使用残差R上的对来拟合模型，其中K是根据计算能力选择的。[2]</p><p id="f6ea" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">由于EBM通过将每个特征的贡献相加来计算最终输出，因此很容易可视化和理解各个特征和交互项的贡献。然而，由于预测的这种模块化，EBM必须支付额外的训练成本，这使得它比类似的方法要慢一些。但是这并没有使它在预测过程中变慢，因为进行预测涉及到简单的加法和特征函数内部的查找。事实上，这使得EBMs成为预测中执行速度最快的模型之一[1]。</p><p id="6c51" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">循证医学实例:</strong></p><p id="9910" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在下面的例子中，我使用了来自Kaggle [3]的信用卡欺诈检测数据集。根据ODC ODBL许可协议，该数据集可供用户自由共享、修改和使用。</p><p id="0fe0" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">数据集描述:</strong></p><p id="76b5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">该数据集包含欧洲持卡人在2013年9月的信用卡交易。数据集高度不平衡，正类(欺诈)占所有交易的0.172%。它包含从V1到V28的特征，这些特征是在PCA之后获得的。不使用PCA进行转换的唯一特征是时间(数据集中第一次和每次交易之间经过的秒数)、数量(每次交易中使用的数量)和类别(目标变量)[3]。</p><p id="5695" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">循证医学模式:</strong></p><p id="17fb" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">由于数据已经被处理，我们将直接进入建模部分。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/4559cf6f6e9b7e4c224afbaa46808137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NiCRlbyBbgP4DC8kWb9hIQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0a86" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">一旦我们有了模型，让我们看看模型是如何表现的。循证医学提供了两种解释:全局和局部。</p><p id="2403" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">全局解释:</strong></p><p id="0cbf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">全局解释有助于我们理解特性对模型的整体贡献，以及每个特性与模型的关系。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div></figure><ol class=""><li id="7172" class="nd ne iq lu b lv ml ly mm lf nf lj ng ln nh mk ni nj nk nl bi translated">了解特征对模型的整体贡献</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/11a59209b9cacad3dbbe4fbc05da0fe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVA0d2-stikzNFci4AiwDw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bee4" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">还可以通过使用ebm.feature_importances_和ebm.feature_names来获取特征和特征重要性</p><p id="2de5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">特征(x) v/s目标(y)关系:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/06660e29f3192bce228cb0190a6ec110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HLozuIOqBbj69q2l63JRg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="c7f3" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">局部解释:</strong></p><p id="4202" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">局部解释有助于我们理解在每次预测中，即在局部水平上发生了什么。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/6210b32b3310784dc81d628c290dd123.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bopTiwAU_bSI-x4zXH2Liw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/68b8733350a1dfc0b70bafae711eda68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oTeGOrFN0ku7G-kb9ZXOXQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5ed1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">从EBM获得预测:</strong></p><p id="bad3" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">由于数据集非常不平衡，我们使用“精确召回曲线下的面积”这一指标来测试模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="na nb l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/56c39ca6717836f7c3d73e8186e37375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ca40L8VJM2GGh_C_IAgrfA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9a6c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">让我们比较一下EBM和xg-boost的竞争情况:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/492eadb566cb3cda7d5920ba0932bde0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQx4yjvPviCMd0bfe59JRg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1391" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">很接近吧！</p><p id="27bc" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">参考资料:</p><p id="d347" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">[1]https://interpret.ml/docs/ebm.html<a class="ae kv" href="https://interpret.ml/docs/ebm.html" rel="noopener ugc nofollow" target="_blank"/></p><p id="daa9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">[2]尹娄，丰富卡鲁阿纳，约翰内斯·盖尔克，和贾尔斯·胡克。具有成对交互的精确可理解模型。第19届ACM SIGKDD知识发现和数据挖掘国际会议论文集，623–631。2013.</p><p id="2d41" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">[3]<a class="ae kv" href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud</a></p></div></div>    
</body>
</html>