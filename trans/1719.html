<html>
<head>
<title>How to Make Artistic Images with Neural Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用神经风格转移制作艺术形象</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-make-artistic-images-with-neural-style-transfer-345a376d56cf#2022-04-22">https://towardsdatascience.com/how-to-make-artistic-images-with-neural-style-transfer-345a376d56cf#2022-04-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b61b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用python实现名画风格到图像的转换</h2></div><p id="8e7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">机器学习的深度学习子领域在图像处理中特别有用。卷积神经网络是深度学习的子单元之一，它通过使用卷积层为用户提供灵活的访问，卷积层呈现图像内容的几个特征。这些功能可以由开发者配置用于许多领域，例如图像分类和识别标题下的对象检测和图像分割。本文解释了神经风格转移，这是指使用预训练的模型VGG-19在保留图像内容的同时转移图像的风格。图1是用文森特·梵高的名画《星夜》和作者的一张照片创作的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/5ce54b49dcaf964f97dc75c422861a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VeETkxipE0bS3vl1fcnE4Q.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图一。作者与星夜的图像，作者的图像</p></figure><h1 id="3740" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">神经类型转移</h1><p id="17aa" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">为了让主题更容易理解，提醒CNN一些要知道的基本事情是有好处的。卷积神经网络(CNN)，顾名思义，使用卷积过程，通过基本的数学像素运算来过滤图像。这种过滤揭示了图像的各种特征(边缘、纹理、颜色等。)，从而为模型提供了一个更有意义、更轻松的学习过程。</p><p id="7d2c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所构建的CNN架构按照它所遵循的层次来提取图像的特征，换句话说，网络是分层学习特征的。这些提取的特征还提供了关于图像细节的信息。例如，当低层去除边缘、像素和纹理时，高层学习关于图像的形状和更多技术特征。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b9f42eff247a484100dcaff6865277a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/1*CGb8x5qIXzDiZdsIylXmrw.gif"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图二。一个充满活力的足球运动员的作者的形象，由翁贝特·波丘尼绘画，作者的形象</p></figure><blockquote class="ms mt mu"><p id="088a" class="ki kj mv kk b kl km ju kn ko kp jx kq mw ks kt ku mx kw kx ky my la lb lc ld im bi translated">《足球运动员的活力》，意大利画家翁贝特·波丘尼未来主义时期的最佳作品之一，1913年。根据博乔尼的观点，没有必要为了在画中描绘一个人而画一个人。由于这个原因，他通过描绘演员来关注动作，因此只有他的腿是可见的。</p></blockquote><p id="492c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用上述方法将神经网络转移与以下过程混合:</p><h2 id="ec5f" class="mz lv it bd lw na nb dn ma nc nd dp me kr ne nf mg kv ng nh mi kz ni nj mk nk bi translated"><strong class="ak">图像:</strong></h2><p id="f7ef" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">将导入两个图像:内容图像和样式图像。内容形象，顾名思义就是受风格形象影响的主要形象。样式图像是提供内容图像的图像。需要低层特征，因为样式图像是一个馈线。另一方面，内容图像需要网络的更高层特征来维持其属性。</p><h2 id="e190" class="mz lv it bd lw na nb dn ma nc nd dp me kr ne nf mg kv ng nh mi kz ni nj mk nk bi translated"><strong class="ak">网络:</strong></h2><p id="5dcf" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">使用imagenet权重构建VGG-19预训练模型。原始论文的作者建议使用VGG-19。通过尝试/构建不同的模型也可以获得独特的结果。特征地图必须提供最佳结果，因为这里研究的是提取图像的特征。VGG-19被推荐为标准。使用该网络提取内容图像和样式图像属性。</p><p id="3e36" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">提取更高层的特征，以便保留内容图像的主要属性。这些层可以是conv4_2和/或conv5_2。当然，尝试不同的组合会产生明显不同的视觉效果。对于风格图像，通过以各种方式使用低特征，即conv1_1、conv2_1、conv3_1、conv4_1和conv5_1组合，获得各种视觉结果。</p><h2 id="ca50" class="mz lv it bd lw na nb dn ma nc nd dp me kr ne nf mg kv ng nh mi kz ni nj mk nk bi translated"><strong class="ak">损失</strong></h2><p id="1447" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">:内容损失:</strong>是指利用网络从内容图像和生成图像中提取的特征之间的相似性。</p><p id="70b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">风格损失:</strong>风格损失表示风格损失风格图像和生成图像之间激活层相关性的相似性。这里，生成的图像和样式图像之间的相关性通过gram矩阵找到。</p><p id="5ef7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> Gram Matrix: </strong>相关值，表示风格图像与生成图像的相似度，是本题的关键点之一。使用卷积层提取图像的各种特征。这些特征是边缘、点、曲线、线条、纹理、颜色分布等。相关性确定这些特征之间的关系，并且更新样式损失值以在样式图像和生成的图像中保持这种关系。更具体地说，如图1所示，星夜表中的太阳(黄色圆圈)在生成的图像中也显示为黄色圆圈。已经确定黄色和具有gram矩阵的圆之间存在关系，并且已经尝试通过减少风格损失将这种关系转移到生成的图像。</p><p id="fccf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">总损失:</strong>总损失计算为如上所述获得的样式损失+内容损失。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nl"><img src="../Images/951816e7c94552835c111c6690fbe293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lF9fPh4WPnBdZRW5zhrP1w.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图3。样式传递算法，<a class="ae nm" href="http://L. A. Gatys, A. S. Ecker, and M. Bethge, &quot;Image Style Transfer Using Convolutional Neural Networks.&quot;" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="6a0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图3显示了原始论文的风格转换算法(计算损失)。这篇文章可以从下面的参考文献部分获得。以下代码块包括使用Python中的Tensorflow实现神经样式转换:</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="92b3" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">结论</h1><p id="a55e" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">神经风格转移最令人愉快的方面是，通过超参数调整获得了各种视觉结果，而不是结果的一致性。这里获得的各种结果是通过改变</p><ul class=""><li id="75f2" class="np nq it kk b kl km ko kp kr nr kv ns kz nt ld nu nv nw nx bi translated">content_weight=1e4，</li><li id="5ee8" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">style_weight=1e2，</li><li id="bf69" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">content _ layers =[' block 5 _ con v2 ']</li><li id="7757" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">style_layers = ['block1_conv1 '，' block2_conv1 '，' block3_conv1 '，' block4_conv1 '，' block5_conv1']</li></ul><p id="433b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">上面代码块中的超参数和结果如图4和图5所示。可以看出，以高风格损失权重开始的图像的纹理更倾向于内容图像。另一方面，图5所示的图像以低风格损失权重开始，趋向于风格图像，这意味着与图4相比，从风格图像提取的特征被更好地转移。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7d0ba9f96da1e177f57760ee11f883ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/1*_QBsDxEVA1IqaolQkPJJxA.gif"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图4。从高style_weight(1.0)开始的过程，图片由作者提供</p></figure><p id="0273" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如上所述，指示生成的图像和内容&amp;风格图像之间的相似性的损失值的初始值被改变，并且以学习速率完成具有梯度下降的训练过程。虽然图像传输的波段范围是用初始损失值设置的，但传输速度是由learning_rate决定的。此外，如上所述，从中提取特征的内容层和样式层也显示了图像的属性被转移了多少(哪些特征)。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8d714e905c4d744067388c659337387a.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/1*5RVLkM7kjfW5GH7yvnsr8w.gif"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图4。从低style_weight(1e2)开始的过程，由作者创建图像</p></figure><p id="dd45" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过用不同的值尝试这些超参数，可以使用上面的代码块直观地观察每个时期的进度。</p><h1 id="d0c1" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">参考</h1><ul class=""><li id="63bd" class="np nq it kk b kl mm ko mn kr od kv oe kz of ld nu nv nw nx bi translated">长度使用卷积神经网络的图像风格转换。</li><li id="1b85" class="np nq it kk b kl ny ko nz kr oa kv ob kz oc ld nu nv nw nx bi translated">长度A. Gatys，A. S. Ecker，M. Bethge，《艺术风格的神经算法》，2015。</li></ul></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><div class="lf lg lh li gt on"><a href="https://ibrahimkovan.medium.com/machine-learning-guideline-959da5c6f73d" rel="noopener follow" target="_blank"><div class="oo ab fo"><div class="op ab oq cl cj or"><h2 class="bd iu gy z fp os fr fs ot fu fw is bi translated">机器学习指南</h2><div class="ou l"><h3 class="bd b gy z fp os fr fs ot fu fw dk translated">所有与机器学习相关的文章</h3></div><div class="ov l"><p class="bd b dl z fp os fr fs ot fu fw dk translated">ibrahimkovan.medium.com</p></div></div><div class="ow l"><div class="ox l oy oz pa ow pb lo on"/></div></div></a></div></div></div>    
</body>
</html>