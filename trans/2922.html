<html>
<head>
<title>Object Detection with TensorFlow 2 Object Detection API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow 2对象检测API进行对象检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-with-tensorflow-2-object-detection-api-3f89da0f1045#2022-06-26">https://towardsdatascience.com/object-detection-with-tensorflow-2-object-detection-api-3f89da0f1045#2022-06-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="49dd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">TensorFlow中基于掩模R-CNN的目标检测</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b5aeac2928caea68c1fa8c453cafed25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DnN9sdmYn5sBJYzu"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">乔安娜·科辛斯卡在<a class="ae kv" href="https://unsplash.com/s/photos/object-detection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="645a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">构建对象检测和图像分割模型与其他模型略有不同。主要是因为你必须使用专门的模型，并以特定的方式准备数据。本文将研究如何使用TensorFlow 2对象检测API在自定义数据集上执行对象检测和图像分割。</p><p id="5f70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始吧！</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="15be" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">对象检测数据集</h1><p id="7d28" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在本文中，我们将使用在<a class="ae kv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上可用的<a class="ae kv" href="https://www.kaggle.com/datasets/lplenka/coco-car-damage-detection-dataset" rel="noopener ugc nofollow" target="_blank"> Coco汽车损坏检测数据集</a>。它包含损坏的汽车图像。它可以用来训练一个模型来检测汽车和汽车部件的损坏。数据集已经被注释，并且提供了相应的<a class="ae kv" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> COCO </a>文件。</p><h1 id="9488" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">为对象检测准备数据集</h1><p id="737f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">如果您想要使用自定义数据集，那么您必须自己进行标注和注释。有许多工具和在线平台可以帮助你实现这一点。如果你想坚持开源，Labelme 是一个很好的选择。</p><p id="9383" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的视频展示了如何在汽车数据集上创建多边形。完成注释后，您必须保存它。保存后，Labelme会将生成的JSON文件存储在与数据相同的文件夹中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/4a76fc348ac4f27c996a5880e8fc5c88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*aWXqxrjACnBwcpOd.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="810e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你正在寻找一个在线工具，这里有一些我接触过的平台:</p><ul class=""><li id="57e6" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><a class="ae kv" href="https://universe.roboflow.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">robof low Universe</strong></a>提供了众多的物体检测和图像分割数据集。您可以搜索平台并切换汽车图像数据集。如果你选择那条路线，从平台下载<a class="ae kv" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecord </a>格式。如果您有一个定制的数据集，您也可以在Roboflow 上执行<a class="ae kv" href="https://roboflow.com/annotate" rel="noopener ugc nofollow" target="_blank">注释。</a></li><li id="6e4e" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://ango.ai/open-dataset/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Ango AI </strong> </a>提供一些公共数据集来启动你的分类和物体检测项目。他们还提供了一个平台，你可以用它来标记和注释图像。</li><li id="d128" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://segments.ai/explore" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">Segments AI</strong></a><strong class="ky ir"/>列出了一些可以克隆到项目中的对象检测和图像分割数据集。您还可以在他们平台上执行注释。</li></ul><h1 id="06b7" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">什么是TensorFlow 2物体检测API？</h1><p id="600f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated"><strong class="ky ir"> TensorFlow对象检测API </strong>是一个开源的计算机视觉框架，用于构建对象检测和图像分割模型，可以在同一幅图像中定位多个对象。该框架适用于TensorFlow 1和2。然而，我们鼓励用户使用TF 2版本，因为它包含了新的架构。</p><p id="e5fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow 2对象检测API支持的一些架构和模型包括:</p><ul class=""><li id="2534" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><a class="ae kv" href="https://arxiv.org/abs/1904.08189" rel="noopener ugc nofollow" target="_blank">中心网</a></li><li id="6e99" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank">效率检测</a></li><li id="9d2d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">固态硬盘<a class="ae kv" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank">移动互联网</a></li><li id="1c1a" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">固态硬盘<a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet </a></li><li id="eeef" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">更快的R-CNN </li><li id="494c" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://paperswithcode.com/method/extremenet" rel="noopener ugc nofollow" target="_blank">极限网</a></li><li id="9ec0" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank">屏蔽RCNN </a></li></ul><p id="eeb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型可以从<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2检测模型动物园</a>下载。您需要它们相应的配置文件来从头开始训练一个对象检测模型。在这个项目中，我们将使用掩码RCNN模型，但您也可以尝试其他模型。</p><h1 id="dfd4" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">在Google Colab上安装TensorFlow 2对象检测API</h1><p id="7b75" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">此时，您现在有了一个对象检测数据集。汽车图像数据和相应的COCO JSON文件，或者是您自己创建或下载的数据集。</p><p id="0548" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将在Google Colab上运行这个项目，以利用免费的GPU资源来训练模型。让我们在Colab上安装TensorFlow 2对象检测API。第一步是克隆TF 2对象检测GitHub repo:</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="2f0b" class="nv ma iq nr b gy nw nx l ny nz">!git clone <a class="ae kv" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models.git</a></span></pre><p id="38e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，运行这些命令在Colab上安装TF 2对象检测API:</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="7c8a" class="nv ma iq nr b gy nw nx l ny nz">%%bash cd models/research # Compile protos. protoc object_detection/protos/*.proto --python_out=. # Install TensorFlow Object Detection API. cp object_detection/packages/tf2/setup.py . python -m pip install --use-feature=2020-resolver .</span></pre><h1 id="74bd" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">在本地安装TensorFlow 2对象检测API</h1><p id="5bee" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">如果您想在本地使用API，开发人员建议您使用<a class="ae kv" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>安装它:</p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="34cc" class="nv ma iq nr b gy nw nx l ny nz"># From the root of the git repository docker build -f research/object_detection/dockerfiles/tf2/Dockerfile -t od . docker run -it od</span></pre><p id="5148" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，导入对象检测API和几个其他常见的数据科学包。如果您能够导入对象检测包，这意味着安装运行成功。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="bee7" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">下载对象检测数据集</h1><p id="bd93" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们将要训练的模型的数据集和配置文件可以从这个<a class="ae kv" href="https://github.com/mlnuggets/maskrcnn" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>下载。从对象检测报告下载<a class="ae kv" href="https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2" rel="noopener ugc nofollow" target="_blank">配置后，您必须进行一些更改。我们稍后将讨论这些变化。</a></p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="2dcf" class="nv ma iq nr b gy nw nx l ny nz">!git clone <a class="ae kv" href="https://github.com/mlnuggets/maskrcnn.git" rel="noopener ugc nofollow" target="_blank">https://github.com/mlnuggets/maskrcnn.git</a></span></pre><h1 id="c808" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">下载面具R-CNN模型</h1><p id="797e" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一步是下载我们将微调的<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener ugc nofollow" target="_blank">屏蔽R-CNN模型</a>。提取文件以获取训练好的模型检查点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b5e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">压缩文件还包含模型的配置文件。下载完每个模型后，您必须编辑这个文件。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/593000f7b45431892d3ed592a29b7f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Kagdi-m4PK12zacP.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="148a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看配置文件中需要更新的项目。</p><h1 id="9993" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">编辑对象检测管道配置文件</h1><p id="0c77" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">克隆<a class="ae kv" href="https://github.com/mlnuggets/maskrcnn" rel="noopener ugc nofollow" target="_blank">这个回购</a>后你将得到的配置文件已经被编辑，可以在Google Colab上顺利运行。如果你在其他地方运行这个项目，你需要更新文件路径。简而言之，以下是从<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8.config" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2对象检测API repo </a>下载Mask RCNN配置文件后需要更新的项目:</p><ul class=""><li id="221f" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><code class="fe od oe of nr b">num_classes</code>到5，因为数据集有5个类，<code class="fe od oe of nr b">headlamp</code>、<code class="fe od oe of nr b">front_bumper</code>、<code class="fe od oe of nr b">hood</code>、<code class="fe od oe of nr b">door</code>和<code class="fe od oe of nr b">rear_bumper</code>。</li><li id="a15d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">image_resizer</code>从1024减少到512，减小图像尺寸，从而减少训练时间。</li><li id="b8df" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">num_steps</code>从20万到1000以减少训练时间。步骤越多，训练模型所需的时间就越长。如果损失仍在减少，验证指标在上升，您可以增加步骤。</li><li id="cc54" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">batch_size = 1</code>指定训练时要输入内存的图像数量。</li><li id="c264" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">fine_tune_checkpoint</code>指向上面下载的Mask R-CNN模型的路径。这确保了我们不是从零开始训练模型。</li><li id="98cb" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">从<code class="fe od oe of nr b">classification</code>的<code class="fe od oe of nr b">fine_tune_checkpoint_type</code>到<code class="fe od oe of nr b">detection</code>，因为我们正在训练一个物体检测模型。</li><li id="ed9b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">train_input_reader</code>指向<code class="fe od oe of nr b">label_map_path</code>和TFRecords的路径。稍后再谈TF唱片。</li><li id="adba" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">eval_input_reader</code>与<code class="fe od oe of nr b">train_input_reader</code>相同，但用于测试数据。</li></ul><h1 id="52f3" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">将图像转换为TFRecords</h1><p id="09d0" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">物体检测模型期望图像为<a class="ae kv" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecord </a>格式。幸运的是，<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_coco_tf_record.py" rel="noopener ugc nofollow" target="_blank"> TensorFlow 2对象检测API </a> repo提供了执行转换的脚本。该脚本采用以下参数:</p><ul class=""><li id="5e51" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">训练图像的目录。</li><li id="b73d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">包含测试图像的文件夹。</li><li id="ba09" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">包含训练图像注释的文件。</li><li id="651b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">包含测试图像注释的文件。</li><li id="ddaa" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">应存储生成的TFRecords的目录。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="5cb4" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">训练模型</h1><p id="1d88" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在，您已经拥有了训练这个Mask R-CNN对象检测模型所需的一切。下一步是运行<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py" rel="noopener ugc nofollow" target="_blank">培训脚本</a>。模型定型脚本采用以下参数:</p><ul class=""><li id="f63b" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><code class="fe od oe of nr b">pipeline_config_path</code>更新模型配置文件的路径。</li><li id="26f3" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">model_dir</code>将保存训练模型的目录。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/610b14b0192cda473f008baf827e57e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-7Q1qdhjJ2rq9_oa.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b096" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Colab上你可能会得到一个<a class="ae kv" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"><em class="og">OpenCV</em></a><em class="og">错误。这个错误可以通过安装正确版本的OpenCV来修复。</em></p><pre class="kg kh ki kj gt nq nr ns nt aw nu bi"><span id="eb85" class="nv ma iq nr b gy nw nx l ny nz">pip uninstall opencv-python-headless==4.5.5.62 pip install opencv-python-headless==4.5.2.52</span><span id="6d72" class="nv ma iq nr b gy oh nx l ny nz"><em class="og">If you get a </em><a class="ae kv" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank"><em class="og">cuDNN</em></a><em class="og"> error, you can fix it by installing the right version of cuDNN.</em></span><span id="9f46" class="nv ma iq nr b gy oh nx l ny nz">!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2</span></pre><h1 id="8be8" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">模型评估和可视化</h1><p id="de5c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">训练完成后，您可以运行<a class="ae kv" href="https://www.tensorflow.org/tensorboard/get_started" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>来显示训练和测试指标的可视化，例如定位损失。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/41effbe264bdebbd561f706ffb1a0e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M1tKkmfq3bLMuhsv.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="338c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">阅读更多:</strong> <a class="ae kv" href="https://www.machinelearningnuggets.com/tensorboard-tutorial/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> TensorBoard教程(深潜附实例和笔记本)</strong> </a></p><h1 id="06e8" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">运行转换脚本</h1><p id="1a3a" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一步是<a class="ae kv" href="https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py" rel="noopener ugc nofollow" target="_blank">导出模型进行推理。</a>转换脚本预期:</p><ul class=""><li id="eacc" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><code class="fe od oe of nr b">trained_checkpoint_dir</code>训练好的模型的最后一个检查点。</li><li id="9f8f" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">output_directory</code>保存导出模型的位置。</li><li id="e5c4" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><code class="fe od oe of nr b">pipeline_config_path</code>管道配置文件的路径。</li></ul><p id="7115" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">转换脚本将输出检查点文件、一个<a class="ae kv" href="https://www.tensorflow.org/guide/saved_model" rel="noopener ugc nofollow" target="_blank"> SavedModel </a>和模型配置文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a7bebe00b6743563133a105f389fe676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*X54j-6H37r7uZWsD.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="0600" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">从Google Colab下载模型</h1><p id="cf54" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">您可能希望下载转换后的模型或训练模型。这可以通过压缩文件并使用Colab工具下载压缩文件来实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="6d09" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">基于掩模R-CNN的目标检测</h1><p id="bf70" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在是时候使用训练好的Mask R-CNN模型对测试汽车图像执行对象检测了。幸运的是，TensorFlow 2对象检测API提供了完成这项工作所需的所有实用程序。第一个是加载图像并将其转换成<a class="ae kv" href="https://www.machinelearningnuggets.com/numpy-tutorial/" rel="noopener ugc nofollow" target="_blank"> NumPy数组的函数。</a></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="452b" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">将图像从文件加载到NumPy数组中</h1><p id="e688" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">该函数需要一个图像文件的路径，并返回一个<a class="ae kv" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html" rel="noopener ugc nofollow" target="_blank"> NumPy数组。</a></p><h1 id="7602" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">可视化检测</h1><p id="6756" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一个实用程序是使用<a class="ae kv" href="https://www.machinelearningnuggets.com/data-visualization-with-matplotlib/" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>绘制检测结果的函数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="911b" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">从最后一个检查点创建模型</h1><p id="8477" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在让我们从最后保存的模型检查点创建一个检测模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="4af3" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">用于推理解码的地图标签</h1><p id="5421" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">接下来，我们声明对解码模型输出很重要的变量。例如，类别和包含培训类别的文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="d964" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">对测试图像运行检测器</h1><p id="146b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一步是在一些测试图像上运行Mask R-CNN对象检测模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/69121ab2c2564bc50b1e381ca7dfe305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*94hQgbd4C0opxlIU.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="d8b6" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">基于掩模R-CNN的图像分割</h1><p id="1053" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">掩模R-CNN对象检测模型可以用于对象检测和图像分割。让我们从加载微调后的模型开始。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="20ab" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">设置标签地图</h1><p id="fdb2" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">模型还需要标签来解码输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="2ad1" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">设置测试图像路径</h1><p id="757f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一步是定义测试图像的路径。在这种情况下，我们将使用所有的测试图像，因为它们并不多。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="2521" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">创建推理函数</h1><p id="495f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">TensorFlow 2对象检测API报告中也提供了分段实用程序。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><h1 id="392b" class="lz ma iq bd mb mc mw me mf mg mx mi mj jw my jx ml jz mz ka mn kc na kd mp mq bi translated">执行分割和检测</h1><p id="e365" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">下一步是加载一个图像作为一个<a class="ae kv" href="https://numpy.org/doc/stable/reference/generated/numpy.array.html" rel="noopener ugc nofollow" target="_blank"> NumPy数组</a>，并使用上面的函数开始检测物体。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/fbaadbf06523e5c830aadb5eee44399a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*qyTUBXNLSYLtzLxy.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="95e8" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">最后的想法</h1><p id="1bc7" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在本文中，我们看到了如何使用TensorFlow 2对象检测API训练对象检测模型。更具体地说，我们涵盖了:</p><ul class=""><li id="ea3d" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">对象检测任务的数据集准备。</li><li id="5143" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">TensorFlow 2对象检测API。</li><li id="e2e8" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">如何在本地和Google Colab上安装TensorFlow物体检测API？</li><li id="acc4" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">设置屏蔽R-CNN对象检测模型的配置。</li><li id="33f9" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">将图像转换为TFRecord格式。</li><li id="7d88" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">训练对象检测模型。</li><li id="c35d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">评估对象检测模型。</li><li id="004b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">使用掩模R-CNN进行目标检测。</li><li id="9070" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">基于掩模R-CNN模型的图像分割。</li></ul><p id="96ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">点击<a class="ae kv" href="https://colab.research.google.com/github/mlnuggets/maskrcnn/blob/main/Object_detection_with_TensorFlow_2_Object_detection_API.ipynb" rel="noopener ugc nofollow" target="_blank"> Colab链接</a>从头到尾尝试该项目。您也可以用另一个数据集替换该数据集。如果更改模型，记得编辑模型配置文件。始终确保配置文件中的路径指向正确的位置。</p><p id="2333" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.linkedin.com/in/mwitiderrick/" rel="noopener ugc nofollow" target="_blank">在LinkedIn上关注我</a>获取更多技术资源。</p><p id="ed00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="og">数据集引用</em></p><p id="15f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据由Kaggle 上的<a class="ae kv" href="https://www.kaggle.com/datasets/lplenka/coco-car-damage-detection-dataset" rel="noopener ugc nofollow" target="_blank"> LPLENKA在</a><a class="ae kv" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CC0: Public Domain </a>许可下提供。</p></div></div>    
</body>
</html>