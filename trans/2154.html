<html>
<head>
<title>Open Pretrained Transformer (OPT) Is a Milestone for Addressing Accessibility</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开放式预训练转换器(OPT)是解决可访问性的一个里程碑</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/open-pretrained-transformer-opt-is-a-milestone-for-addressing-accessibility-47e546a48a51#2022-05-13">https://towardsdatascience.com/open-pretrained-transformer-opt-is-a-milestone-for-addressing-accessibility-47e546a48a51#2022-05-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="78e4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">选择加入GPT-3人出局</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0bb7b37698d94f2530a553ad1c944e7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rxlbzPU_AxZAOXkrhzuJrQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的格尔德·奥特曼</p></figure><p id="c551" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2022年5月3日，Meta AI公布了新的大型语言模型(LLM)开放式预训练转换器(OPT-175B)。在这篇文章中，我们将谈论OPT如何在机器学习领域，特别是自然语言处理(NLP)领域，建立了一个可重复性的基准。</p><p id="a7e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">再现性是怎么回事？</strong></p><p id="2c23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可访问性与再现性问题密切相关。如果你能获得有关该方法的信息，你可以复制这个实验。为什么再现性如此重要？让我们从更广阔的角度来看待这个问题，并回到过去。大约在16世纪，<em class="lv">智人</em>对他们获取知识的方式做出了重大改变。<em class="lv">智人</em>不再假设信息是正确的，而是开始使用科学的方法来确定假设，进行实验，分析结果，并得出结论。在过去的几个世纪里，科学家们利用这一过程来建立我们对自然世界及其规律的集体理解。通过关注科学发现的透明度和再现性，我们在技术上取得了巨大进步。(必须注意，定性方法不一定要产生可重复的结果。是的，定性的方法仍然很强)。</p><p id="3505" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管可重复性是定量科学方法的一个基本考虑因素，但2016年《自然》<em class="lv"/>杂志上的一项调查显示，超过70%的研究人员在试图重现另一位研究人员的实验时失败了，超过50%的人在重现自己的实验时失败了(Pineau等人，2021；贝克，2016)。</p><p id="6f63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个严重的问题。评估研究主张的可信度是科学过程中一个核心的、持续的、费力的部分(Alipourfard et al .，2021)。如果一个科学发现是不可复制的，它就违反了科学方法的一个基本前提。Joelle Pineau等人(2021)指出，机器学习研究的挑战之一是确保呈现和发布的结果是合理和可靠的。(注:Joelle Pineau是脸书人工智能研究所的联合董事总经理，麦吉尔大学副教授。她在让巴勒斯坦被占领土变得可及方面发挥了作用。)</p><p id="117b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，学术论文并不总是提供可重复的结果，比如缺少步骤或缺乏关于其方法的信息。作为一名数据科学家，我在阅读ML论文时也多次遇到可重复性问题。</p><p id="a47e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> GPT-3和再现性问题</strong></p><p id="93f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们谈论再现性问题时，我们有一只大象在房间里，GPT-3。在将近两年的时间里，OpenAI对不公开该模型给出了粗略的解释。关于GPT-3，OpenAI曾表示“公开太危险了”Meta AI显然认为安全不应该是一个让公众无法接触到的模型。在阅读了<a class="ae ky" href="https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/" rel="noopener ugc nofollow" target="_blank">梅塔关于OPT-175B </a>的博客文章后，我们可以看到，如果你做了严谨的功课，在负责任的同时公开一个LLM是可能的。</p><p id="37ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【Meta AI对OPT的可访问性持什么态度？</p><ul class=""><li id="ec09" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">Meta AI团队已经注意使OPT模型可以公开访问。他们使用了负责任人工智能的指导方针。我知道脸书和负责任相处不好，但我们在这里。欢迎来到2022年！</li><li id="4b8d" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">OPT团队与拥抱脸紧密合作。OPT于5月3日公布。目前<a class="ae ky" href="https://huggingface.co/patrickvonplaten" rel="noopener ugc nofollow" target="_blank">抱脸</a>上有6款:125M、350M、1.3B、2.7B、6.7B、30B参数截止5月11日。175B参数可通过应用程序访问。<a class="ae ky" href="https://github.com/facebookresearch/metaseq/issues/88" rel="noopener ugc nofollow" target="_blank"> Stephen Roller </a>，OPT论文的第二作者，正与拥抱脸团队合作，使各种各样的OPT模型易于使用。</li><li id="8b6e" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">OPT团队(包括<a class="ae ky" href="https://arxiv.org/abs/2205.01068" rel="noopener ugc nofollow" target="_blank"> OPT论文</a>作者)非常活跃，并对<a class="ae ky" href="https://github.com/facebookresearch/metaseq/issues" rel="noopener ugc nofollow" target="_blank"> Github问题</a>做出快速回复。</li><li id="ab00" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">OPT在公开可用的数据集上接受培训，以允许更多的社区参与了解这一基础新技术。</li></ul><p id="c3e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">当前OPT的可访问性挑战</strong></p><ul class=""><li id="062c" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated">根据官方<a class="ae ky" href="https://github.com/facebookresearch/metaseq/blob/main/docs/api.md#:~:text=Right%20now%20only%20on%20Azure%2C%20as%20it%20requires%20the%2080GB%20A100s" rel="noopener ugc nofollow" target="_blank">指南</a>，OPT需要一个A100 80GB的GPU。这对用户来说是一个巨大的可访问性障碍。</li><li id="4b15" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">目前，它只运行在Azure云服务上(基于官方指南)。在我的本地机器上安装OPT时，我看到OPT有AWS的基础设施。我相信我们会看到OPT与其他云计算平台的集成。</li><li id="4ca5" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">各种安装问题。例如，它不适用于Python 3.10.2，因为Python 3.10.2不支持所需的torch版本(1.10.2)。</li><li id="aa08" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated">Metaseq是使用OPT的基本代码。不幸的是，<a class="ae ky" href="https://github.com/facebookresearch/metaseq/issues/88#:~:text=Metaseq%20is%20notoriously%20unfriendly" rel="noopener ugc nofollow" target="_blank">斯蒂芬·罗拉</a>说，<em class="lv">梅塔塞克是出了名的不友好。</em></li></ul><p id="eaab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OPT是一个令人兴奋的大型语言模型。一旦它变得更加用户友好，它将是NLP领域的游戏规则改变者。在这篇文章中，我们想分享我们对OPT语言模型可访问性方面的第一印象。在GPT-3炒作和无法访问它之后，我们希望OPT将带来对大型语言模型开发的新理解。拥抱脸和变形金刚库集成完成后，我们将有机会尝试它，并在这里再次分享我们的经验！<br/>编辑:5月12日，各种OPT模型已经可以通过变形金刚图书馆访问)</p><p id="cdbd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">埃尼斯·格克切——NLP数据科学家</p><p id="caf4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">穆罕默德·埃姆雷·塞内尔 —博阿济奇大学计算机科学</p><p id="368e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢<a class="ae ky" href="https://www.linkedin.com/in/mel-meder/" rel="noopener ugc nofollow" target="_blank">梅尔·梅德</a>校对文章</p><p id="17fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">参考文献</strong>:</p><p id="854d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">阿里普法德，n .，阿伦特，b .，本杰明，D. M .，本克勒，n .，毕晓普，m .，伯斯坦，m，…和吴，J. (2021)。对公开研究和证据的系统化信心。</p><p id="90f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">贝克，M. (2016)。1500名科学家揭开再现性的盖子。自然，533(7604)。</p><p id="dd3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">皮诺，j .，文森特-拉马尔，p .，辛哈，k .，拉里维埃，v .，贝格尔齐默，a .，阿尔凯-Buc，f .，… &amp;拉罗歇尔，H. (2021)。提高机器学习研究的再现性:来自NeurIPS 2019再现性计划的报告。<em class="lv">机器学习研究杂志</em>，<em class="lv"> 22 </em>。</p></div></div>    
</body>
</html>