<html>
<head>
<title>Train Mask R-CNN Net for Object Detection in 60 Lines of Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用60行代码训练用于目标检测的掩模R-CNN网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-mask-rcnn-net-for-object-detection-in-60-lines-of-code-9b6bbff292c3#2022-06-01">https://towardsdatascience.com/train-mask-rcnn-net-for-object-detection-in-60-lines-of-code-9b6bbff292c3#2022-06-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3eeb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用最少代码的循序渐进教程</h2></div><p id="c2b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对象检测和实例分割是识别和分割图像中的对象的任务。这包括为每个对象找到边界框、覆盖确切对象的遮罩和对象类。<a class="ae lb" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank">屏蔽R-CNN </a>是实现这一点最常见的方法之一。</p><p id="5a96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本教程旨在解释如何用最少的代码(60行，不包括空格)训练这样一个网络。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/1533e23bbf5b0745f3e518841f52ceaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hIBM3fJk4AsE1KBDqREIFg.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">对象检测/实例分割的例子。图像出现在左侧，对象及其类出现在右侧。</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3f87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">代码可在:<a class="ae lb" href="https://github.com/sagieppel/Train_Mask-RCNN-for-object-detection-in_In_60_Lines-of-Code" rel="noopener ugc nofollow" target="_blank">https://github . com/sagieppel/Train _ Mask-RCNN-for-object-detection-In _ In _ 60 _ Lines-of-Code</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="fa13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该项目将使用Pytorch 1.1和OpenCV包。</p><p id="3125" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，PyTorch MaskRCNN的实现可能与较新的PyTorch版本有一些问题，因此PyTorch 1.1是一个安全的选择。</p><p id="742c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Pytorch安装说明可从以下网址获得:</p><p id="f9d0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">【https://pytorch.org/get-started/locally/ T4】</p><p id="00ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">OpenCV可以通过以下方式安装:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="8a67" class="me mf iq ma b gy mg mh l mi mj">pip install opencv-python</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="40a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要一个数据集进行训练。我们将使用可以从这里下载的<a class="ae lb" href="https://www.cs.toronto.edu/chemselfies/" rel="noopener ugc nofollow" target="_blank"> LabPics V2 </a>数据集:</p><p id="3aab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://zenodo.org/record/4736111/files/LabPicsChemistry.zip?download=1" rel="noopener ugc nofollow" target="_blank">https://Zeno do . org/record/4736111/files/labpicschemistry . zip？下载=1 </a></p><p id="b025" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该数据集在麻省理工学院的许可下可以免费使用。</p><p id="fea7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将训练网络来检测图像中的所有血管。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="bf50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们可以开始写代码了。</p><p id="5a0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们导入包并定义主要的训练参数:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="d849" class="me mf iq ma b gy mg mh l mi mj">import random<br/>from torchvision.models.detection.faster_rcnn import FastRCNNPredictor<br/>import numpy as np<br/>import torch.utils.data<br/>import cv2<br/>import torchvision.models.segmentation<br/>import torch<br/>import os</span><span id="8fb1" class="me mf iq ma b gy mk mh l mi mj">batchSize=2<br/>imageSize=[600,600]</span><span id="3421" class="me mf iq ma b gy mk mh l mi mj">device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')</span></pre><p id="dcca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> imageSize=[Width，height] </em>是用于训练的图像的尺寸。训练过程中的所有图像都将调整到这个大小。</p><p id="41df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> batchSize: i </em> s将用于每次训练迭代的图像数量。</p><p id="8006" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml">批次大小*宽度*高度</em>将与训练的内存需求成比例。根据您的硬件，可能有必要使用较小的批处理大小或图像大小来避免内存不足的问题。</p><p id="197e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，由于我们只使用单一的图像大小进行训练，因此训练后的网络很可能仅限于使用这种大小的图像。在大多数情况下，您想要做的是改变每个训练批次的大小。</p><p id="d364" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml">设备:</em>自动设置网将要运行的设备(GPU或CPU)，在实践训练中没有强大的GPU是极其缓慢的。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="108f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们创建数据集中所有图像的列表:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="f98a" class="me mf iq ma b gy mg mh l mi mj">trainDir="LabPicsChemistry/Train"<br/><br/>imgs=[]<br/>for pth in os.listdir(trainDir):<br/>    imgs.append(trainDir+"/"+pth +"//")</span></pre><p id="95c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> TrainDir: </em>是LabPics V2数据集训练文件夹。</p><p id="4fdd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">是训练集中所有图像的列表</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="6682" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们创建一个数据加载器函数，它允许我们加载一批随机图像及其数据用于训练。数据将包含图像:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mm"><img src="../Images/f76cfad71d6ea1222629fe44d7ddf0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jHG2FxjxS3r6lzD7GuAgKA.jpeg"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图像</p></figure><p id="f870" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和图像中所有对象的遮罩。每个蒙版将被保存为黑白(0/1)图像:</p><div class="ld le lf lg gt ab cb"><figure class="mn lh mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><img src="../Images/4c6340b3535b1a2704724e72a3eef2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*bHFrER1YQ_a9TOyO2a-QYg.png"/></div></figure><figure class="mn lh mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><img src="../Images/6a819c010121ec707a8ed0c3fd509c5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*1HsioqPBVr9cTpl_IJMegg.png"/></div></figure><figure class="mn lh mo mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><img src="../Images/fe6cd5455c8c5a72621754bf6f758e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*504F0qcMNutreTjrnB8PJQ.png"/></div></figure></div><div class="ab cb"><figure class="mn lh mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><img src="../Images/5e56c8025dfed5dc56205c2be16b6e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*093WUss4eUU7iSgrh1fpsw.png"/></div></figure><figure class="mn lh mt mp mq mr ms paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><img src="../Images/bc9af690b049a6365510f43559821a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pdeQfgS_Qe233Pa-YfDu0Q.png"/></div><p class="lo lp gj gh gi lq lr bd b be z dk mu di mv mw translated">图像中不同血管的遮罩。</p></figure></div></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="c1a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的数据加载器功能代码是:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="0549" class="me mf iq ma b gy mg mh l mi mj">def loadData():<br/>  batch_Imgs=[]<br/>  batch_Data=[]<br/>  for i in range(batchSize):</span><span id="257d" class="me mf iq ma b gy mk mh l mi mj">        idx=random.randint(0,len(imgs)-1)<br/>        img = cv2.imread(os.path.join(imgs[idx], "Image.jpg"))<br/>        img = cv2.resize(img, imageSize, cv2.INTER_LINEAR)</span><span id="2ed0" class="me mf iq ma b gy mk mh l mi mj">        maskDir=os.path.join(imgs[idx], "Vessels")<br/>        masks=[]<br/>        for mskName in os.listdir(maskDir):<br/>            vesMask = cv2.imread(maskDir+'/'+mskName, 0)<br/>            vesMask = (vesMask &gt; 0).astype(np.uint8) <br/>            vesMask=cv2.resize(vesMask,imageSize,cv2.INTER_NEAREST)<br/>            masks.append(vesMask)</span><span id="00bf" class="me mf iq ma b gy mk mh l mi mj">        num_objs = len(masks)<br/>        if num_objs==0: return loadData()</span><span id="a94f" class="me mf iq ma b gy mk mh l mi mj">        boxes = torch.zeros([num_objs,4], dtype=torch.float32)<br/>        for i in range(num_objs):<br/>            x,y,w,h = cv2.boundingRect(masks[i])<br/>            boxes[i] = torch.tensor([x, y, x+w, y+h])<br/>        masks = torch.as_tensor(masks, dtype=torch.uint8)<br/>        img = torch.as_tensor(img, dtype=torch.float32)</span><span id="e086" class="me mf iq ma b gy mk mh l mi mj">        data = {}<br/>        data["boxes"] =  boxes<br/>        data["labels"] =  torch.ones((num_objs,), dtype=torch.int64)   <br/>        data["masks"] = masks</span><span id="d5e4" class="me mf iq ma b gy mk mh l mi mj">        batch_Imgs.append(img)<br/>        batch_Data.append(data)  <br/>  <br/>  batch_Imgs=torch.stack([torch.as_tensor(d) for d in batch_Imgs],0)<br/>  batch_Imgs = batch_Imgs.swapaxes(1, 3).swapaxes(2, 3)<br/>  return batch_Imags, batch_Data</span></pre><p id="9654" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个函数的作用是加载一组图像，对于每一幅图像，它加载一组图像中血管的掩模。然后，它为每个对象生成边界框和类。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3da8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们一行一行地看看这个函数:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="bf5c" class="me mf iq ma b gy mg mh l mi mj">idx=random.randint(0,len(imgs)-1)<br/>img = cv2.imread(os.path.join(imgs[idx], "Image.jpg"))<br/>img = cv2.resize(img, imageSize, cv2.INTER_LINEAR)</span></pre><p id="0a5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们从列表中选择一个随机图像(<em class="ml"> idx)，</em>加载图像，并将其调整到标准大小(<em class="ml"> imageSize </em>)。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="36e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们加载对象的遮罩。这些遮罩是与RGB图像大小相同的图像，其中对象实例的区域标记为1，其余标记为0。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="e964" class="me mf iq ma b gy mg mh l mi mj">maskDir=os.path.join(imgs[idx], "Vessels")<br/>masks=[] # list of all object mask in the image<br/>for mskName in os.listdir(maskDir):<br/>            vesMask = cv2.imread(maskDir+'/'+mskName, 0) # Read mask<br/>            vesMask = (vesMask &gt; 0).astype(np.uint8) #convert to 0-1<br/>            vesMask=cv2.resize(vesMask,imageSize,cv2.INTER_NEAREST)<br/>            masks.append(vesMask) # add to the mask list</span></pre><p id="1f01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> maskDir: </em>是储存血管实例贴图的子文件夹。</p><p id="1533" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们首先阅读面具。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="f054" class="me mf iq ma b gy mg mh l mi mj">vesMask = cv2.imread(maskDir+'/'+mskName, 0)</span></pre><p id="34a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">遮罩图像以0–255格式存储，并转换为0–1格式:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="0294" class="me mf iq ma b gy mg mh l mi mj">vesMask = (vesMask &gt; 0).astype(np.uint8)</span></pre><p id="c499" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，遮罩被调整到标准图像大小，并被添加到遮罩列表中。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="1cc9" class="me mf iq ma b gy mg mh l mi mj">vesMask=cv2.resize(vesMask,imageSize,cv2.INTER_NEAREST)<br/>masks.append(vesMask) </span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3031" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们使用遮罩为每个对象生成一个边界框。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="08b9" class="me mf iq ma b gy mg mh l mi mj"><br/>boxes = torch.zeros([num_objs,4], dtype=torch.float32)<br/>for i in range(num_objs):<br/>            x,y,w,h = cv2.boundingRect(masks[i])<br/>            boxes[i] = torch.tensor([x, y, x+w, y+h])</span></pre><p id="d2c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，OpenCV具有从遮罩生成边界框的功能:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="0b0f" class="me mf iq ma b gy mg mh l mi mj">x,y,w,h = cv2.boundingRect(masks[i])</span></pre><p id="8f23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> x，y: </em>是包围盒的顶部坐标。</p><p id="78c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> w，h: </em>是边框的宽度和高度。</p><p id="2d7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">掩模RCNN边界框格式需要该框的左上和右下坐标，由:<em class="ml"> [x，y，x+w，y+h]给出。</em></p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="b58d" class="me mf iq ma b gy mg mh l mi mj">boxes[i] = torch.tensor([x, y, x+w, y+h])</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="f7d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们将关于图像的所有信息堆叠到一个字典中。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="df02" class="me mf iq ma b gy mg mh l mi mj"><br/>data = {}<br/>data["boxes"] =  boxes<br/>data["labels"] =  torch.ones((num_objs,), dtype=torch.int64)   <br/>data["masks"] = masks</span></pre><p id="4590" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，对于标签，我们只是为所有内容选择一个。这意味着我们只是把所有对象的类都看作是相同的(1)。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="dc13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们结束了。我们只需要将图像数据加载到训练批次中，并将其转换为PyTorch格式。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="1e14" class="me mf iq ma b gy mg mh l mi mj">        batch_Imgs.append(img)<br/>        batch_Data.append(data)  <br/>batch_Imgs= torch.stack([torch.as_tensor(d) for d in batch_Imgs], 0)<br/>batch_Imgs = batch_Imgs.swapaxes(1, 3).swapaxes(2, 3)<br/>feturn batch_Imags, batch_Data</span></pre><p id="369c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ml"> batch_Imgs，batch_Imgs: </em>是用于训练的图像批次(列表)及其数据。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="c613" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了数据加载器，我们可以开始构建网络了。首先，我们加载一个已经在COCO数据集上进行了预训练的掩模RCNN模型:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="b609" class="me mf iq ma b gy mg mh l mi mj">model=torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)  </span></pre><p id="b60d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用现有知识的预训练模型可以比之前未训练的模型更快地学习新任务和数据集。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="71bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">COCO数据集包含100多个类。在我们的例子中，我们只需要两个类。因此，我们将改变网络的最终层，以预测两个类别:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="d310" class="me mf iq ma b gy mg mh l mi mj">in_features = model.roi_heads.box_predictor.cls_score.in_features <br/>model.roi_heads.box_predictor=FastRCNNPredictor(in_features,num_classes=2)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="20f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们将模型加载到训练设备GPU或CPU:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="38f1" class="me mf iq ma b gy mg mh l mi mj">model.to(device)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="60d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以定义优化器，它将决定净重在训练期间的变化方式:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="e576" class="me mf iq ma b gy mg mh l mi mj">optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-5)</span></pre><p id="03ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用AdamW，它是最新的优化器，具有标准的学习速率<em class="ml"> lr=1e-5 </em></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="ecfe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将模型设置为训练模式:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="be51" class="me mf iq ma b gy mg mh l mi mj">model.train()</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="1194" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经准备好编写主要的训练循环:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="4bda" class="me mf iq ma b gy mg mh l mi mj">for i in range(10001):<br/>   images, targets = loadData()<br/>   images = list(image.to(device) for image in images)<br/>   targets=[{k: v.to(device) for k,v in t.items()} for t in targets]<br/>   <br/>   optimizer.zero_grad()<br/>   loss_dict = model(images, targets)<br/>   losses = sum(loss for loss in loss_dict.values())<br/>   <br/>   losses.backward()<br/>   optimizer.step()<br/>   <br/>   print(i,'loss:', losses.item())<br/>   if i%200==0:<br/>           torch.save(model.state_dict(), str(i)+".torch")<br/>           print("Save model to:",str(i)+".torch")</span></pre><p id="0cf0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们正在为10001次迭代进行训练。</p><p id="dcd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一部分是使用我们刚刚定义的数据加载器函数加载数据:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="3f96" class="me mf iq ma b gy mg mh l mi mj">images, targets = loadData()</span></pre><p id="3731" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们将数据加载到训练设备(CPU/GPU)中</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="667a" class="me mf iq ma b gy mg mh l mi mj">images = list(image.to(device) for image in images)<br/>targets=[{k: v.to(device) for k,v in t.items()} for t in targets]</span></pre><p id="c8f6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们获取图像和数据，并通过我们的神经网络来计算损失:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="ec3b" class="me mf iq ma b gy mg mh l mi mj">loss_dict = model(images, targets)</span></pre><p id="71e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">损失由几个部分组成:类损失、边界框损失和遮罩损失。我们将所有这些部分相加，得出一个单一数字的总损耗:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="b213" class="me mf iq ma b gy mg mh l mi mj">losses = sum(loss for loss in loss_dict.values())</span></pre><p id="7cce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们有了损失，我们可以使用反向传播来更新神经网络的权重。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="0047" class="me mf iq ma b gy mg mh l mi mj">losses.backward()<br/>optimizer.step()</span></pre><p id="900f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望每500步保存一次训练好的模型，以便以后使用。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="623b" class="me mf iq ma b gy mg mh l mi mj">if i%500==0:<br/>    torch.save(model.state_dict(), str(i)+".torch")</span></pre><p id="d2e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">仅此而已。经过4-10k的训练迭代，应该开始有不错的效果了。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3d50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整代码可以在这里找到:<a class="ae lb" href="https://github.com/sagieppel/Train_Mask-RCNN-for-object-detection-in_In_60_Lines-of-Code/blob/main/train.py" rel="noopener ugc nofollow" target="_blank">https://github . com/sagieppel/Train _ Mask-RCNN-for-object-detection-In _ In _ 60 _ Lines-of-Code/blob/main/Train . py</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a659" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们完成培训，我们想测试我们的模型。</p><p id="87d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们将使用此处提供的评估脚本:<a class="ae lb" href="https://github.com/sagieppel/Train_Mask-RCNN-for-object-detection-in_In_60_Lines-of-Code/blob/main/test.py" rel="noopener ugc nofollow" target="_blank">https://github . com/sagieppel/Train _ Mask-RCNN-for-object-detection-In _ In _ 60 _ Lines-of-Code/blob/main/test . py</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="c170" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该脚本类似于培训脚本。第一部分只是像以前一样加载网络。</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="9130" class="me mf iq ma b gy mg mh l mi mj">device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  <br/>model=torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) <br/>in_features = model.roi_heads.box_predictor.cls_score.in_features <br/>model.roi_heads.box_predictor=FastRCNNPredictor(in_features,num_classes=2)</span><span id="dbd4" class="me mf iq ma b gy mk mh l mi mj">model.load_state_dict(torch.load("10000.torch"))<br/>model.to(device)# move model to the right devic<br/>model.eval()</span></pre><p id="afc3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">唯一的区别是我们还添加了一行来加载保存的模型，并将模型设置为评估状态而不是训练状态:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="fcb9" class="me mf iq ma b gy mg mh l mi mj">model.load_state_dict(torch.load("10000.torch"))<br/>model.eval()</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="ad49" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们加载一个图像，将其调整为标准大小，并将其转换为PyTorch格式:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="7efa" class="me mf iq ma b gy mg mh l mi mj">images = cv2.imread(imgPath)<br/>images = cv2.resize(images, imageSize, cv2.INTER_LINEAR)<br/>images = torch.as_tensor(images, dtype=torch.float32).unsqueeze(0)<br/>images=images.swapaxes(1, 3).swapaxes(2, 3)<br/>images = list(image.to(device) for image in images)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a86c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在网上运行图像:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="8246" class="me mf iq ma b gy mg mh l mi mj">with torch.no_grad():<br/>    pred = model(images)</span></pre><p id="bfe8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将通过网络运行图像，并获得图像中对象的预测。注意，我们不是在训练网络，所以我们不需要收集梯度(no_grad ),这使得网络运行得更快。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a8bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预测由几个部分组成:“掩模”，对应于图像中每个对象的掩模(区域)。“分数”对应于预测的掩码正确的可能性。此外，我们有预测的边界框和类，但我们不会使用它们。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="3546" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将检查所有的预测，并且只显示那些“分数”大于0.8的对象:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="8c36" class="me mf iq ma b gy mg mh l mi mj">im= images[0].swapaxes(0, 2).swapaxes(0, 1).detach().cpu().numpy().astype(np.uint8)</span><span id="8da9" class="me mf iq ma b gy mk mh l mi mj">im2 = im.copy()</span><span id="78e2" class="me mf iq ma b gy mk mh l mi mj">for i in range(len(pred[0]['masks'])):<br/>    msk=pred[0]['masks'][i,0].detach().cpu().numpy()<br/>    scr=pred[0]['scores'][i].detach().cpu().numpy()<br/>    if scr&gt;0.8 :<br/>        im2[:,:,0][msk&gt;0.5] = random.randint(0,255)<br/>        im2[:, :, 1][msk &gt; 0.5] = random.randint(0,255)<br/>        im2[:, :, 2][msk &gt; 0.5] = random.randint(0, 255)<br/>cv2.imshow(str(scr), np.hstack([im,im2]))<br/>cv2.waitKey()</span></pre><p id="1890" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，预测的对象“遮罩”以与图像相同的大小保存为矩阵，每个像素具有与它是对象的一部分的可能性相对应的值。</p><p id="d7cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以假设只有值大于0.5的像素可能是物体的一部分。我们通过为每个对象用不同的随机颜色标记这些像素来显示这一点:</p><pre class="ld le lf lg gt lz ma mb mc aw md bi"><span id="e26d" class="me mf iq ma b gy mg mh l mi mj">im2[:,:,0][msk&gt;0.5] = random.randint(0,255)<br/>im2[:, :, 1][msk &gt; 0.5] = random.randint(0,255)<br/>im2[:, :, 2][msk &gt; 0.5] = random.randint(0, 255)</span></pre><p id="1988" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果可以在这里看到:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mx"><img src="../Images/9c4c042ac2ec738912ea189a35b0f598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0bpNqZ1nkZODU4A-dNYfLA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">左边是原始图像，右边是预测对象区域。</p></figure><p id="853b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的测试代码可以在这里找到:</p><div class="my mz gp gr na nb"><a href="https://github.com/sagieppel/Train_Mask-RCNN-for-object-detection-in_In_60_Lines-of-Code/blob/main/test.py" rel="noopener  ugc nofollow" target="_blank"><div class="nc ab fo"><div class="nd ab ne cl cj nf"><h2 class="bd ir gy z fp ng fr fs nh fu fw ip bi translated">train _ Mask-RCNN-for-object-detection-In _ 60 _ Lines-of-Code/test . py at main…</h2><div class="ni l"><h3 class="bd b gy z fp ng fr fs nh fu fw dk translated">此文件包含双向Unicode文本，其解释或编译可能与下面显示的不同…</h3></div><div class="nj l"><p class="bd b dl z fp ng fr fs nh fu fw dk translated">github.com</p></div></div><div class="nk l"><div class="nl l nm nn no nk np lm nb"/></div></div></a></div></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="edf6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用PyTorch屏蔽RCNN的教程:</p><p id="4074" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/intermediate/torch vision _ tutorial . html</a></p><p id="3a10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原版掩模RCNN论文可从这里下载:</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="nq nr l"/></div></figure></div></div>    
</body>
</html>