<html>
<head>
<title>Topic Modeling with Latent Semantic Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于潜在语义分析的主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-with-latent-semantic-analysis-58aeab6ab2f2#2022-03-01">https://towardsdatascience.com/topic-modeling-with-latent-semantic-analysis-58aeab6ab2f2#2022-03-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="13aa" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索一种从文本中提取主题的流行方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9c5387d04581d4e179b59f2a2b982ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tDbOT7byryIzwIly"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">布雷特·乔丹在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3e62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">想想目前流通的大量文本。新闻文章、博客文章、在线评论、电子邮件和简历都是大量存在的文本数据的例子。</p><p id="021f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于大量非结构化数据以这些文档的形式涌入，我们需要一种自动化的方法来分析这些大量的文本。</p><p id="f044" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是主题建模发挥作用的地方。主题建模是一种无监督的学习方法，允许我们从文档中提取主题。</p><p id="3192" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它在诸如文档聚类和信息检索等许多应用中起着至关重要的作用。</p><p id="37ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们提供了一个最流行的主题建模方法的概述:潜在语义分析。</p><h2 id="781d" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">重要的一点</h2><p id="cf4b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在讨论潜在语义分析之前，理解“主题”在NLP中的含义是很重要的。</p><p id="abf0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个<strong class="lb iu">主题</strong>由一组强相关的单词定义。例如，单词“土豆”、“汤”和“吃”可以代表主题“食物”。</p><p id="a0ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于文档不受有限的一组单词的限制，它们通常包含多个主题。我们可以通过找到与文档最相关的主题，将文档分配给主题。</p><h2 id="7291" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">潜在语义分析</h2><p id="1bc0" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">潜在语义分析(LSA)是一种允许我们通过将文本转换成单词-主题和文档-主题矩阵来从文档中提取主题的方法。</p><p id="1887" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LSA的程序相对简单:</p><ol class=""><li id="7b58" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">将文本语料库转换成文档术语矩阵</li><li id="d53e" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">实现截断奇异值分解</li><li id="b00a" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">用提取的主题对单词/文档进行编码</li></ol><p id="6b38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单吧？</p><p id="4c09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，我可能忽略了一些细节。让我们一次检查一个步骤。</p><p id="2ffb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。将原始文本转换成文档术语矩阵</strong></p><p id="bc25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在从文档中导出主题之前，必须将文本转换成文档术语矩阵。这通常通过单词袋或TF-IDF算法来完成。</p><p id="87b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。实现截断奇异值分解</strong></p><p id="835a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">截断奇异值分解(SVD)是LSA的核心。该操作是从给定的文档集合中获取主题的关键。</p><p id="8094" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数学上，可以用下面的公式来解释:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/bd397f3590455a37a25415e4654270a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/1*w_MxVHkldOQaFzo7m3fIFg.gif"/></div></figure><p id="23b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个公式乍一看令人生畏，但它相当简单。</p><p id="2144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通俗地说，该操作将高维文档术语矩阵分解成3个更小的矩阵(U、S和V)。</p><p id="658d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量A表示<em class="ni">文档术语矩阵</em>，在每个文档和单词对之间分配一个基于计数的值。该矩阵具有n×m个维度，其中n表示文档的数量，m表示单词的数量。</p><p id="9733" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量U代表<em class="ni">文档-主题矩阵</em>。本质上，它的值显示了每个文档与其派生主题之间的关联强度。矩阵有n×r个维度，n代表文档的数量，r代表主题的数量。</p><p id="b19f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量S表示评估文档集合中每个主题的“强度”的对角矩阵。矩阵有r×r维，r代表主题的数量。</p><p id="f420" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">变量V代表<em class="ni">词-主题矩阵</em>。它的值显示了每个单词和派生主题之间的关联强度。矩阵有m×r维，m代表字数，r代表题目数。</p><p id="8aa8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，虽然语料库中的文档和单词的数量总是恒定的，但是主题的数量不是固定的变量，因为它是由运行操作的人决定的。因此，SVD的输出取决于您希望提取的主题数量。例如，与提取4个主题的SVD相比，提取3个主题的SVD将产生不同的矩阵。</p><p id="4aab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。用衍生主题编码单词/文档</strong></p><p id="22b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过SVD操作，我们能够将文档术语矩阵转换成文档主题矩阵(U)和单词主题矩阵(V)。这些矩阵允许我们找到与每个主题关联最强的单词。</p><p id="9c70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用这些信息来决定每个派生主题代表什么。</p><p id="5207" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以确定哪些文档属于哪个主题。</p><h2 id="628c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">限制</h2><p id="2703" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">LSA使我们能够快速有效地发现文档中的潜在主题。话虽如此，但它确实有自己的缺点。</p><p id="cd25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，在进行LSA时，一些信息的丢失是不可避免的。</p><p id="9428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当文档被转换成文档-术语矩阵时，词序被完全忽略。由于词序在单词的语义值中起着很大的作用，省略它会导致主题建模过程中的信息丢失。</p><p id="4d4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，LSA无法解释同形异义或一词多义。因为该技术基于单词出现的上下文来评估单词，所以它不能识别具有多重含义的单词，也不能通过单词在文本中的使用来区分这些单词。</p><p id="2f86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于给定的一组文档，也很难确定主题的最佳数量。虽然在寻找表示文档集合的理想主题数量方面有几种思想流派，但是没有一种确定的方法可以实现这一点。</p><p id="ad38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，LSA缺乏可解释性。即使在成功地提取了具有强关联性的词语集的主题之后，从这些词语集中获得洞察力也是具有挑战性的，因为很难确定每组词语代表什么主题。</p><h2 id="3bff" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated"><strong class="ak">案例研究</strong></h2><p id="4771" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在我们已经给出了LSA的概要，让我们看看如何用Python实现它。</p><p id="f19a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个案例研究将主要利用<a class="ae ky" href="https://radimrehurek.com/gensim/" rel="noopener ugc nofollow" target="_blank"> Gensim </a>库，这是一个专注于主题建模的开源库。</p><p id="e08a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用一个包含乐器评论的数据集，看看我们如何从中挖掘出主要话题。数据集(无版权)可以在这里获得<a class="ae ky" href="https://www.kaggle.com/eswarchandt/amazon-music-reviews?select=Musical_instruments_reviews.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="260e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是数据预览:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f5bb5fb6998ccb9f6388ae43fa17b6be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*MMGbROfVjoOcFV4eyTRAhQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="eb46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一步是将这些评论转换成文档术语矩阵。</p><p id="8428" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们必须对文本进行一些预处理。这需要将所有文本小写，删除标点符号、停用词、短词(即少于3个字符的词)，并用词干将每个词还原为其基本形式。</p><p id="7894" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些都可以通过preprocess_string函数来实现，该函数将给定的文本转换成一系列经过处理的标记。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="e4b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是预处理后文本的快速预览。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/5fdbdd9deb6c41259abe8c3aa1d66955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMlPzB1C6fOpv8LueHN88Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="817c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以使用单词袋模型将这些经过处理的评论转换成文档术语矩阵。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a70e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们必须对这个矩阵进行截断奇异值分解。在Gensim库中，我们可以使用<a class="ae ky" href="https://radimrehurek.com/gensim/models/lsimodel.html" rel="noopener ugc nofollow" target="_blank"> LSImodel </a>来构建一个在给定矩阵上执行SVD的模型。</p><p id="bde2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，在我们创建低维矩阵之前，我们需要确定应该从这些综述中提取的主题数量。</p><p id="72f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">寻找最佳主题数量的一种方法是使用一致性分数度量。一致性分数实质上显示了来自每个主题的单词在语义值方面有多相似，较高的分数对应于较高的相似性。</p><p id="e9b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们可以用Gensim模块获得一致性分数。让我们来看看2到10个主题的连贯性得分如何。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0f18d40ca80772d201b88a2bcf7b6e4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*5Ky9rMFJNnOF3NSP4UnrNQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="8021" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2个主题的一致性得分最高，所以这是我们在执行SVD时将提取的主题数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="8247" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们能够从文档术语矩阵中获得2个主题。这样一来，我们就可以看到哪些词与每个话题的关联最强，并推断出这些话题代表了什么。</p><p id="2c72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们来看看与每个话题关联最强的5个单词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/94bc4d48a0116a3fcf852860190b0891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cItncgGYmrWgF8HXk-JMiQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="7cce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据给定的词，主题0可以表示针对使用产品时产生的声音或噪音的评论，而主题1可以表示针对设备本身的评论。</p><p id="6388" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我们可以看到模型为每个文档和主题配对分配了什么值。</p><p id="241f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，文档通常有多个主题。但是，有些主题与文档的关联比其他主题更强。因此，我们可以通过找到记录最高值的主题来确定文档属于哪个主题。</p><p id="4a96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看一个样本评论作为例子。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/75544ebc4bf4454a34f3ddd7857cce9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*w3WTWFmcXpp1z2G2h9Gl0g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="e4da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">样本评论的主题0和主题1的得分分别为0.88和0.22。虽然这两个主题都出现在评论中，但是主题0比主题1具有更高的价值，因此我们可以将该评论分配给主题0。</p><p id="f4f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看属于每个主题的评论。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/2fb6afb1d32c5659b937dc0f76d888a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BGgpMgidWggpoKLJxZNWHg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="d3f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主题0中的示例文本讨论了购买电子管尖叫器后乐器的声音，而主题1中的示例文本则更关注购买的踏板本身的质量。这符合两个衍生话题的解读。</p><h2 id="39d4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">结论</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/f7511da90102dd58b085a1bb78629699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YDkXjCLkVPzCUrm6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@prateekkatyal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Prateek Katyal </a>拍摄</p></figure><p id="6768" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您已经对如何使用LSA在一组文档中找到潜在主题有了一些了解。</p><p id="d6e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这种技术相对快速有效，但由于其局限性，应该谨慎使用。</p><p id="3f6e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我祝你在NLP的努力中好运！</p><h2 id="5b44" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参考</h2><ol class=""><li id="9128" class="mt mu it lb b lc mo lf mp li ns lm nt lq nu lu my mz na nb bi translated">麦考利法官(未注明)。<em class="ni">亚马逊产品数据</em>。亚马逊评论数据。于2022年3月1日从http://jmcauley.ucsd.edu/data/amazon/取回</li></ol></div></div>    
</body>
</html>