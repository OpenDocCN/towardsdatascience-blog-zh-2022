<html>
<head>
<title>Introduction to Image Embedding and Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像嵌入和精度简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-image-embedding-and-accuracy-53473e8965f#2022-09-29">https://towardsdatascience.com/introduction-to-image-embedding-and-accuracy-53473e8965f#2022-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="ea5b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/image-autoencoder" rel="noopener" target="_blank">潜在空间的广泛介绍</a></h2><div class=""/><div class=""><h2 id="e589" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">通过聚类、线性判别分析和性能评估</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/4bbb039abe893e888aa093027d102258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wX-Iw76VQXQ0PEX1"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@thematthoward?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马特·霍华德</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">号航天飞机</a>上拍摄的照片</p></figure><p id="afd8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">前一章</a>是嵌入、相似性和聚类的概述。本章通过扩展嵌入的概念将图像也包括在内，从而建立在这些基础之上。我们将探索在<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">上一章</a>中介绍的K-Means聚类在图像嵌入中的表现，并介绍通过准确度和召回率来衡量性能的方法。引入了一种简单的线性判别分析形式的潜在空间嵌入(LSE)，以帮助我们理解聚类和性能是如何作用于图像的。本章不解释伦敦经济学院，因为它将在下一章介绍。</p><p id="55e9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">目录:</p><ul class=""><li id="d502" class="mb mc iq lh b li lj ll lm lo md ls me lw mf ma mg mh mi mj bi translated">2.1图像嵌入</li><li id="b04d" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">2.2集群性能</li><li id="3dee" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">2.3讨论</li><li id="537e" class="mb mc iq lh b li mk ll ml lo mm ls mn lw mo ma mg mh mi mj bi translated">2.4结论</li></ul></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="0560" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated">2.1图像嵌入</h2><p id="2db3" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated"><a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">第1章</a>解释了相同对象的不同嵌入如何适用于不同的应用。以图像形式嵌入书籍不适合书籍推荐，但需要以流派形式嵌入。然而，我们不能阅读使用体裁嵌入的书，因为这个应用程序需要实际的文本。一般来说，当使用嵌入时，目标是找到一种嵌入方法，为我们提供适合应用的相似性。</p><p id="f47e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当寻找相似之处时，图像是一种复杂的嵌入形式。一个例子可能是一个用例，我们需要一个移动应用程序来帮助我们识别我们正在观察的<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank">动物</a>。在这里，我们需要找到图像和动物物种之间的相似之处。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/f82aedcb4c616bd8067f7d5bf8ed1d5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PWg_YLGWFhcb51mzFPw0OQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.1 —作为数据集类别示例的动物图像:<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank">动物-10 </a>。在<a class="ae le" href="https://unsplash.com/photos/75715CVEJhI" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae le" href="https://unsplash.com/@sadmax" rel="noopener ugc nofollow" target="_blank"> Amber Kipp </a>的猫照，在<a class="ae le" href="https://www.pexels.com/photo/brown-and-white-short-coated-puppy-1805164/" rel="noopener ugc nofollow" target="_blank"> Pexel </a>上<a class="ae le" href="https://www.pexels.com/@valeriya/" rel="noopener ugc nofollow" target="_blank"> Valeria Boltneva </a>的狗照，在<a class="ae le" href="https://www.pexels.com/photo/red-and-black-rooster-on-green-grass-3820303/" rel="noopener ugc nofollow" target="_blank"> Pexel </a>上<a class="ae le" href="https://www.pexels.com/@erik-karits-2093459/" rel="noopener ugc nofollow" target="_blank"> Erik Karits </a>的鸡照，在<a class="ae le" href="https://unsplash.com/photos/nUCt1PjRNHE" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae le" href="https://unsplash.com/@gabrielizalo" rel="noopener ugc nofollow" target="_blank"> Gabriel Porras </a>的牛照。</p></figure><p id="1605" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">图像是我们在现实世界中看到的嵌入物。图像包括像素，每个像素是一种颜色。上面的图像是由10.000个这样的像素组合而成的。确切地说是图像)。每个像素提供了少量独特的信息，我们只能获得所有像素的完整图像。每个像素代表一种知识，因此应该有自己独特的维度。第一章展示了如何用两种体裁来表现一本书，给它两个维度。然而，一个250x400像素的灰度图像总共有100.000个维度！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nu"><img src="../Images/d3866de92c3f430340e5f2968bb860c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e95JZDyJSh7XvTuED6we8A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.2 —将图像转化为数字的过程。摘自<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">第一章</a>，图1.1。由<a class="ae le" href="https://unsplash.com/photos/gL2jT6xHYOY" rel="noopener ugc nofollow" target="_blank">杰斯·贝利</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的图书照片</p></figure><p id="f48d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">那么问题就变成了，像素嵌入可以用来对图像中的动物进行分类吗？图2.1有四组动物(即猫、狗、鸡和牛)。从<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank"> Animal-10 </a>数据集中提取每组的16幅图像，并放置在图2.3中的坐标系内(每组动物都有独特的颜色)。这些动物来自于<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank">ka ggle</a>【1】上的<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank"> Animal-10 </a>数据集，可以免费下载。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nv"><img src="../Images/9a36a61e4628780f3825ede0aff46652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUVPiTCAfpe0KRms5XDnIQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.3 —图2.1中的四种动物在2D空间中各有16张图片。线性判别分析(LDA)用于将图像转换为2D，因为它侧重于分类。</p></figure><p id="8367" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">细心的读者可能会认识到，该图只显示了两个维度，而不是所有的100.000。为了简单起见，我们从二维开始，然后将技术扩展到所有100.000维。关键要点是，彩色点没有清晰的单一颜色组，而是全部混合在一起。</p><p id="b610" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><a class="ae le" rel="noopener" target="_blank" href="/principal-component-analysis-pca-explained-visually-with-zero-math-1cbf392b9e7d">主成分分析【2】</a>(PCA)和<a class="ae le" rel="noopener" target="_blank" href="/linear-discriminant-analysis-explained-f88be6c1e00b">线性判别分析【3】</a>(LDA)都可以将一幅图像变换成2D。PCA侧重于转换没有类的数据，LDA侧重于转换有类的数据。LDA用于将图像转换为2D，因为每幅图像中的动物是预先已知的。</p><p id="e35f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">图像嵌入</strong>部分的剩余部分解释了如何从图2.3生成图形。您可以继续阅读下一节<strong class="lh ja"> 2.2集群性能</strong>，跳过如何生成图表的详细说明</p><p id="469c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">如何从图2.3中生成图形的详细说明:<br/> </strong>图2.3中的点代表Kaggle上托管的<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank"> <em class="nw"> Animal-10 </em> </a>数据集的动物。该数据集可以在免费登录后从网站下载。下载按钮在图2.4中突出显示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nx"><img src="../Images/72f12fbdb64285534d50834dd13d1c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcQsCdIuOL5l4AO01RCMEw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.4—ka ggle上的Animal-10数据集，突出显示了下载按钮。</p></figure><p id="857d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">将从Kaggle下载一个“存档”文件夹，由一个名为<em class="nw"> raw-img </em>的文件夹和一个名为<em class="nw"> translate.py </em>的文件组成。将<em class="nw"> raw-img </em> <em class="nw">文件夹</em>放在已知位置；参见图2.5。我们在代码2.1中定义了数据集的位置，以便以后可以访问它。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ny"><img src="../Images/343c7cccb6cadd15235b83597fab50f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rd0hTKjojWzkGhLkmpyrWQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.5 —将“raw-img”文件移动到已知位置。在本例中，它被移动到“数据集/动物/”文件夹中。代码2.1中提到了该位置。</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.1 —定义动物10文件夹的位置</p></figure><p id="de28" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">现在，我们可以通过定义动物的名称和要提取的图像数量，为每个动物组(即猫、狗、鸡和牛)提取十六个图像。代码2.2使用这些信息来遍历每个动物文件夹，加载16个图像并使它们大小相同。比较相同大小的图像更容易，并且是LDA等功能所必需的。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.2 —加载16张猫、狗、鸡和牛的图片。</p></figure><p id="42a6" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们现在可以为每只动物显示一张图片，以检查数据是否正确加载。每只动物显示一幅图像的代码可在代码2.3中找到。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.3 —为每只动物展示一张图片</p></figure><p id="9f5b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">之后，通过使用代码2.4，可以使用<a class="ae le" rel="noopener" target="_blank" href="/linear-discriminant-analysis-explained-f88be6c1e00b">线性判别分析</a> (LDA)将图像转换成2D。在将图像转换到2D之前，必须“调整”LDA。拟合是教导LDA如何转换数据的过程。通过首先定义在变换完成后图像应该具有多少维度，然后给LDA哪些图像属于同一类的例子(即，给LDA图像并告诉其中是哪种动物)来进行拟合。它使用这些信息来计算如何转换这些和未来的图像。最后一步是使用LDA将我们的16x4图像转换为2D。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.4 —将动物图像转换为2D</p></figure><p id="329f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2D点可以用代码2.5绘制在如图2.3所示的图表中。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.5-从多个类中绘制2D点，每个点使用唯一的颜色。该图应与图2.3相匹配。</p></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="78a1" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated">2.2集群性能</h2><p id="7274" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">我们在<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">第1章</a>中学习了如何使用K-Means将k-clusters应用于无色数据(没有类别/没有预定义动物的数据)。K-Means侧重于在数据中找到K个组，并在每个组的中心放置一个点。该点被放置在中心以最好地代表其组，因为它到所有点的距离最短。我们的例子与K-Means略有不同，因为我们已经知道了组(相同动物物种的图像来自同一个组)。然而，K-Means的想法可以通过在每个组/动物的中心放置一个点来最好地代表它。图2.6使用等式2.1添加了新的中心点。代码2.6显示了如何添加集群并绘制新的图表。<strong class="lh ja"> OBS！</strong>代码的输出不会突出显示带有黑色边框的集群。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ob"><img src="../Images/e31e74330a0a661a70ee9b74dcd5ff8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tdDlDwRwJfuy2wwdWJ-O_g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.6-每组/每只动物的中心都标有一个用黑色边框突出显示的新点。橙色:狗，红色:牛，绿色:鸡，蓝猫:</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oc"><img src="../Images/018ecdebe48fbb144c1963c83c2593dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pTF3CDCvFiOK4b7gBRdWHQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式2.1-计算组的中心</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.6 —找到每个动物群的中心，并将其与其余动物群一起标绘</p></figure><p id="c8df" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">棘手的部分是，当我们得到一张新的图像并想弄清楚上面是哪种动物时会发生什么。图2.7显示了我们计算从新的变换图像到每个聚类的距离，因为每个聚类代表一个动物群。距离越小意味着相似度越高；使用欧几里德相似性选择最接近的聚类作为最佳拟合。等式2.2显示了如何计算两点之间的相似性。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi od"><img src="../Images/ffa7724c723d7432bb09bafee6a31c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j5vhNemFbLhhrbvGdjaOpw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.7-测量到每个中心的距离，并选择最近的一个作为其组</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oe"><img src="../Images/02928a8b5351532fc2452516706133e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hW4l2RV7lRdMvkAZu_gVIA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式2.2-计算两点间欧几里得相似性得分的公式</p></figure><p id="182a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">那么，我们如何计算我们的集群识别动物的能力呢？一种简单的方法是首先忘记每个点属于哪个组，然后使用等式2.2来计算它们与哪个组最接近/最相似。图2.8和代码2.7使用这种方法来改变每个点的颜色，以匹配最近的聚类(继续阅读，很快就有意义了！).</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi of"><img src="../Images/f88f0f746e3ae046233b23d729bc067c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MbIZuL6RT8a-XkR10C2jPw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.8-点被重新分配，因此它们现在属于离它们最近的组</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.7-通过计算最接近的类来分配点</p></figure><p id="b64e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当我们改变每个点的颜色以匹配最近的聚类时，会发生四种情况。我们举一个简单的例子来解释发生了什么。为了简单起见，这个例子使用了Corona测试而不是集群。电晕测试可以是<em class="nw">阳性</em>或<em class="nw">阴性</em>。当测试呈阳性时，会发生两种情况，要么是真的呈阳性，称为<em class="nw">真阳性，</em>，要么是假的，称为<em class="nw">假阳性</em>。如果测试为阴性，也会发生同样的事情，它可能是真的，称为<em class="nw">真阴性</em>，也可能是假的，称为<em class="nw">假阴性</em>。当测试得到更多的真阳性和真阴性时，我们更信任它。</p><p id="16cf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们的情况更复杂，因为我们有四个结果，而不是两个(即四个聚类/动物类型对<em class="nw">阳性</em>和<em class="nw">阴性</em>)。我们当时观察单个集群，以确定其性能如何。当我们确定它的性能时，同样的四种情况(真阳性、假阳性、真阴性和假阴性)也会发生。让我们关注蓝色的簇:前后都是蓝色的点被称为<em class="nw">真阳性(TP) </em>。之前是另一种颜色但现在是蓝色的点被称为<em class="nw">假阳性(FP) </em>。之前是蓝色但现在是另一种颜色的点被称为<em class="nw">假阴性(FN)。</em>最后，前后都是另一种颜色的点被称为<em class="nw">真底片(TN) </em>。图2.9展示了关注蓝色集群时的每个场景。</p><p id="c39a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们必须为每个集群继续这一过程，以确定每个集群的表现如何。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi og"><img src="../Images/e736933d2e485fc13547b9a0873154fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Yvns9MjgL2b7GR-0MsDlw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.9 —一个聚类的表现如何可以通过观察重新分配点后它有多少真阳性和假阳性以及真阴性和假阴性来衡量</p></figure><p id="abd9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们在图2.8中使用的方法是有问题的，因为我们只使用现有的点来评估性能。这些点被用于创建/拟合LDA，并且LDA自然更擅长获得这些正确的点。好消息是，我们在Animal-10数据集中有更多的图像可以测试！代码2.8显示了如何从每个动物类加载128张图片并转换到2D。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.8-为每个动物类别加载128幅图像，并使用代码2.2和2.4中定义的函数将它们转换为2D。</p></figure><p id="b485" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个集群的表现如何可以通过<a class="ae le" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" rel="noopener ugc nofollow" target="_blank">精度和召回</a> [4]来衡量。<em class="nw"> Precision </em>测量真阳性和假阳性之间的比率——因此，该聚类仅预测自己的点就有多好。<em class="nw">回忆</em>测量真阳性和假阴性之间的比率——因此，当预测时，聚类在包括其所有点方面有多好。公式2.3显示了精度公式，公式2.4显示了召回公式。代码2.9计算所有512个图像(128个图像pr)的每个聚类的阳性和阴性以及精确度和召回率。类)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oh"><img src="../Images/697afaf6c153a08d09ce04c2643ed916.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVt7CPJdJ4VJ-oScmhgznQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式2.3-计算聚类精度的公式。它是真阳性和假阳性之间的比率</p></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/d0ca1e26f9ef48cc97c4abf7bfb76417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgx650FQONsYu1Fmg4qMeg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">等式2.4 —计算聚类召回率的公式。它是真阳性和假阴性之间的比率</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.9 —计算2D所有512个(128*4类)图像的每个集群的性能</p></figure><p id="5e7c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">2D图像的精度和召回率结果可在表2.1中找到。平均准确率34%，平均召回率33%，一点都不伟大！但是等等，我们只用了二维？让我们对所有100.000维尝试相同的计算，看看它是否比以前执行得更好。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/a9a59e9d591dc65257c664fbaa5c1426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TkC1uX1-dn5GHt1_fxXJDQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表2.1-使用LDA将点转换为2D时的精度和召回率</p></figure><p id="83d4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">表2.2显示了所有100.000尺寸的结果以及代码2.10如何获得它们。平均准确率31%，平均召回率30%，比以前更差了！LDA表现得更好，因为它专注于分离每个组，并使它们更加不同，即使只是一点点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/5fd668ebd96a341a7b177591249b24db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wafGSAtCZJSyiNJuzwaiUw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表2.2-使用无任何变换的点时的精度和召回率</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.10-在不转换数据的情况下使用所有维度时计算聚类准确度的代码</p></figure><p id="6a9a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">但是等等LDA只使用了两个维度…如果两者都转换数据并让它有更多的维度呢？LDA的最大维数是“类数-1”，在我们的例子中是4–1 = 3。表2.3显示了我们使用所有三个维度时的结果，代码2.11显示了如何获得它。平均准确率是38%，平均召回率是38%，仍然不是很好，但比以前好！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/d58c045b69377da9a3b4674746f539bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JPQU_j0b1Q0uXyEojBuJiw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">表2.3-使用LDA将点转换为3D时的精度和召回率</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.11-使用LDA将其转换为3D时用于计算聚类精度的代码</p></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="c920" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated"><strong class="ak"> 2.3讨论</strong></h2><p id="bc2c" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">3D LDA仅获得38%的分数，因为它仅使用每组16幅图像来训练LDA，并且因为它像未变换的图像一样，仅查看像素颜色。</p><p id="f757" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">当训练时，更多的图像给予LDA更多的上下文，因为它有更多的图像可以在图上绘制的例子。如果我们有16个图像而不是单个图像，则更容易判断来自同一组的未来点将在哪里。同样，128张图片比16张图片给我们更多的信息。图2.10描绘了每组128幅图像；左图使用在64 (16*4)幅图像上训练的LDA，右图使用在512 (128*4)幅图像上训练的LDA。该图说明了当在更多图像上训练时，LDA如何更好地分离点。代码2.11显示了如何绘制这两个图形。</p><p id="ad00" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">LDA在转换图像时只查看像素颜色。这种方法有局限性，因为它优先考虑像素的颜色，而不是图像中的形状。这意味着棕色的猫和棕色的狗会比白色的狗和棕色的猫更相似！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nt"><img src="../Images/8edc98a1c900fd53f4c5cd7081435e1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CW1zKXLkpU9iOF7Tnk5fMw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图2.10–512张动物图像，使用LDA对每组16张图像(左)和每组128张图像(右)进行训练</p></figure><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="nz oa l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">代码2.11 —创建一个新的LDA，它将图像转换为2D，并用每组128幅图像进行训练。</p></figure><p id="ad37" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在第3章<strong class="lh ja">图像潜在空间嵌入简介</strong>中，我们将利用我们所了解的图像嵌入和LDA的优缺点来提高动物识别应用的准确性。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="798a" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated">2.4结论</h2><p id="1b0f" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">我们现在已经学完了第2章，以及图像嵌入和精确度的介绍。</p><p id="0459" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一部分，<strong class="lh ja">图像嵌入，</strong>解释了图像由像素组成，每个像素代表一种颜色。每种颜色都是一个维度，就像第一章中的“人生旅程”和“小说”是书籍的维度。我们使用了来自四个动物群体(即猫、狗、鸡和牛)的64幅图像来展示如何在Python中嵌入图像。使用线性判别分析(LDA)将每幅图像转换成2D，从而可以将它们绘制成图表并显示它们的相似性。</p><p id="387b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第二部分，<strong class="lh ja">集群性能</strong>，看我们如何通过在每个动物群的中心放置一个点来表示它们。这些点可以通过计算图像最接近哪个中心来帮助识别图像中的动物。精确度和召回率是确定一种方法如何识别正确动物的两种方法。Precision检查有多少图像被识别为正确的动物，而Recall检查每个中心在包括其物种的所有图像方面有多好。对没有转换的图像和使用LDAs转换为2D和3D的图像进行了性能测试。</p><p id="61ed" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">精度和召回率显示</strong>用LDA转换的图像比未转换的图像更好地识别正确的动物种类(38%对31%)。原因是LDA变换图像以使每个组更明显。然而，图像和LDA只看颜色，而不看图像中的内容的形式。这意味着两种方法都认为棕色的猫和棕色的狗比棕色的狗和白色的狗更相似。</p><p id="4b04" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第3章，<strong class="lh ja">图像潜在空间嵌入简介</strong>，利用我们从图像嵌入和LDA的优缺点中学到的知识来提高动物识别应用的准确性。第三章利用变换的强度，解决了只看颜色的问题，达到了更好的精度。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="ec35" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated">参考</h2><p id="9c78" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">[1]科拉多·阿莱西奥，<a class="ae le" href="https://www.kaggle.com/datasets/alessiocorrado99/animals10" rel="noopener ugc nofollow" target="_blank">动物-10 </a>，Kaggle.com</p><p id="c204" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2] Casey Cheng，<a class="ae le" rel="noopener" target="_blank" href="/principal-component-analysis-pca-explained-visually-with-zero-math-1cbf392b9e7d">用零数学直观地解释主成分分析法</a> (2022)，</p><p id="61b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3]杨，，<a class="ae le" rel="noopener" target="_blank" href="/linear-discriminant-analysis-explained-f88be6c1e00b">线性判别分析，</a> (2020)解释</p><p id="4ed7" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4]谷歌开发者，<a class="ae le" href="https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall" rel="noopener ugc nofollow" target="_blank">分类:精度与召回</a> (2022)，developers.google.com</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="f98a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">所有图片和代码，除非另有说明，均为作者所有。</p><p id="f0a2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">感谢你阅读这本关于潜在空间的书！当分享我们的想法时，我们学得最好，所以请分享一个评论，无论是一个问题，新的见解，还是一个分歧。任何建议和改进都非常感谢！</p><p id="42af" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="nw">如果你喜欢这本书，并且对机器学习和数据科学的新见解感兴趣，请注册中级会员，以便完全访问我的内容。关注我，以便在我发布新章节或帖子时收到电子邮件。</em></p><div class="om on gp gr oo op"><a href="https://medium.com/@mathiasgronne/membership" rel="noopener follow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd ja gy z fp ou fr fs ov fu fw iz bi translated">马蒂亚斯·格朗内——中等</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">对图像嵌入和自动编码器的广泛介绍，对这本书及其章节的介绍——他们说…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">medium.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ky op"/></div></div></a></div></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="5fd5" class="mw mx iq bd my mz na dn nb nc nd dp ne lo nf ng nh ls ni nj nk lw nl nm nn iw bi translated">书籍章节</h2><p id="3f3c" class="pw-post-body-paragraph lf lg iq lh b li no ka lk ll np kd ln lo nq lq lr ls nr lu lv lw ns ly lz ma ij bi translated">简介:<a class="ae le" rel="noopener" target="_blank" href="/an-extensive-introduction-to-image-embedding-and-auto-encoders-0-6-5c5d9a18fcaa">进入图像嵌入和潜在空间</a></p><p id="737a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第1章:<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-embedding-clustering-and-similarity-11dd80b00061">嵌入、聚类和相似性介绍</a></p><p id="fd8b" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第2章:<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-image-embedding-and-accuracy-53473e8965f">图像嵌入和精度介绍</a></p></div></div>    
</body>
</html>