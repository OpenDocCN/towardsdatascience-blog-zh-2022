<html>
<head>
<title>Implementing ConvNext in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中实现ConvNext</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-convnext-in-pytorch-7e37a67abba6#2022-04-21">https://towardsdatascience.com/implementing-convnext-in-pytorch-7e37a67abba6#2022-04-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6a72b6ec7864de112732da25a0d21da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeL9Eq0dr5anZNAoJxAXwA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><div class=""/><div class=""><h2 id="f8bd" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated"><em class="kx">击败变形金刚的新康文网</em></h2></div><p id="9986" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">嘿，我在</em><a class="ae lv" href="https://www.linkedin.com/in/francesco-saverio-zuppichini-94659a150/" rel="noopener ugc nofollow" target="_blank"><em class="lu">LinkedIn</em></a><em class="lu">过来打个招呼👋</em></p><p id="5d02" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你好。！今天，我们将在PyTorch中实现著名的ConvNext，这是在2020年代的ConvNet中提出的。</p><p id="ca7d" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的代码是<a class="ae lv" href="https://github.com/FrancescoSaverioZuppichini/ConvNext" rel="noopener ugc nofollow" target="_blank">这里的</a>，这篇文章的互动版本可以从<a class="ae lv" href="https://github.com/FrancescoSaverioZuppichini/ConvNext/blob/main/README.ipynb" rel="noopener ugc nofollow" target="_blank">这里的</a>下载。</p><p id="f3b0" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们开始吧！</p><p id="4cd4" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文提出了一种新的基于卷积的体系结构，它不仅优于基于变换器的模型(如Swin ),而且可以随数据量的增加而扩展！下图显示了不同数据集/模型大小下的ConvNext精度。</p><figure class="lx ly lz ma gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lw"><img src="../Images/24655862c394c3012cc5defb2b8c5472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GRrjoxhPRfkK6q_U.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自<a class="ae lv" href="https://arxiv.org/abs/2201.03545" rel="noopener ugc nofollow" target="_blank">2020年代的conv net</a></p></figure><p id="c5c8" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，作者开始采用众所周知的ResNet架构，并根据过去十年的新的最佳实践和发现对其进行迭代改进。作者关注Swin-Transformer，并密切关注其设计选择。论文一流，强烈推荐阅读:)</p><p id="943a" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下图显示了所有不同的改进以及每项改进后各自的性能。</p><figure class="lx ly lz ma gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mb"><img src="../Images/3ebecf776faa14e1d6816566ccadb8f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*evJWJZCri0xHLqHU.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图片来自<a class="ae lv" href="https://arxiv.org/abs/2201.03545" rel="noopener ugc nofollow" target="_blank">2020年代的conv net</a></p></figure><p id="b2cf" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">他们将路线图分为两部分:宏观设计和微观设计。宏观设计是我们从高层次的角度所做的所有改变，例如阶段的数量，而微观设计更多的是关于更小的事情，例如使用哪个激活。</p><p id="3d22" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们现在将从一个经典的瓶颈块开始，一个接一个地应用每个更改。</p><h1 id="c679" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">起点:ResNet</h1><p id="201a" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">如你所知(如果你没有我有一篇<a class="ae lv" href="https://medium.com/p/a7da63c7b278" rel="noopener">关于在PyTorch </a>中实现ResNet的文章)ResNet使用了一个残余瓶颈块，这将是我们的起点。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="4a26" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们检查它是否工作</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="51cf" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 64, 7, 7])</span></pre><p id="b31a" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们再定义一个<code class="fe nl nm nn nc b">Stage</code>，一个<code class="fe nl nm nn nc b">blocks</code>的集合。每个阶段通常以因子<code class="fe nl nm nn nc b">2</code>对输入进行下采样，这在第一个模块中完成。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="878c" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 64, 4, 4])</span></pre><p id="9253" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">酷，注意输入是如何从<code class="fe nl nm nn nc b">7x7</code>减少到<code class="fe nl nm nn nc b">4x4</code>的。</p><p id="b347" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ResNet也有所谓的<code class="fe nl nm nn nc b">stem</code>，它是模型中的第一层，对输入图像进行大量的下采样。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="2754" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很好，现在我们可以定义<code class="fe nl nm nn nc b">ConvNextEncoder</code>来保存一个阶段列表，并将一个图像作为输入来产生最终的嵌入。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="8212" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 2048, 7, 7])</span></pre><p id="8528" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是你的普通<code class="fe nl nm nn nc b">resnet50</code>编码器，如果你附加一个分类头，你会得到一个很好的旧resnet50，准备好接受图像分类任务的训练。</p><h1 id="e2d9" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">宏观设计</h1><h1 id="7553" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">更改阶段计算比率</h1><p id="f424" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">在ResNet中，我们有4个阶段，Swin变压器使用比率<code class="fe nl nm nn nc b">1:1:3:1</code>(因此第一阶段有一个模块，第二阶段有一个模块，第三阶段有三个模块...).将ResNet50调整到这个比率(<code class="fe nl nm nn nc b">(3, 4, 6, 3)</code>-&gt;-<code class="fe nl nm nn nc b">(3, 3, 9, 3)</code>)会导致性能从<code class="fe nl nm nn nc b">78.8%</code>增加到<code class="fe nl nm nn nc b">79.4%</code>。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="ecf8" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">将词干改为“Patchify”</h1><p id="9127" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">ResNet stem使用非常激进的7x7 conv和maxpool对输入图像进行大幅缩减采样。然而，《变形金刚》使用了“patchify”词干，这意味着它们将输入图像嵌入到补丁中。Vision Transfomers使用非常激进的补丁(16x16)，作者使用conv层实现的4x4补丁。精度从<code class="fe nl nm nn nc b">79.4%</code>变为<code class="fe nl nm nn nc b">79.5%</code>，表明修补工作正常。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="80dd" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">ResNeXt-ify</h1><p id="c9f3" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated"><a class="ae lv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNetXt </a>对瓶颈中的3x3 conv层采用分组卷积来减少FLOPS。在ConvNext中，它们使用深度卷积(就像在MobileNet和后来的EfficientNet中一样)。深度方向卷积是分组卷积，组数等于输入通道数。</p><p id="7385" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作者注意到，这与自我关注中的加权和运算非常相似，后者只在空间维度上混合信息。使用深度方向的convs会降低精度(因为我们没有像ResNetXt那样增加宽度)，这是意料之中的。</p><p id="f2a7" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我们在<code class="fe nl nm nn nc b">BottleNeck</code>块中把我们的3x3 conv改为</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="bd6c" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">倒置瓶颈</h1><p id="c604" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">我们的瓶颈首先是通过1x1 conv减少功能，然后应用3x3 conv，最后将功能扩展到原始大小。一个倒置的瓶颈块，做相反的事情。我有一整篇文章<a class="ae lv" href="https://medium.com/p/89d7b7e7c6bc" rel="noopener">对它们进行了很好的可视化。</a></p><p id="f6f4" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以我们从<code class="fe nl nm nn nc b">wide -&gt; narrow -&gt; wide</code>到<code class="fe nl nm nn nc b">narrow -&gt; wide -&gt; narrow</code>。</p><p id="d90e" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这类似于变形金刚，因为MLP层遵循<code class="fe nl nm nn nc b">narrow -&gt; wide -&gt; narrow</code>设计，MLP中的第二个密集层将输入的特征扩展了四倍。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="faaa" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">大型内核</h1><p id="51ca" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">现代视觉转换器，如Swin，使用更大的内核大小(7x7)。增加内核大小将使计算更昂贵，所以我们向上移动大的深度方向conv，这样我们将有更少的通道。作者指出，这类似于变形金刚模型，其中多头自我关注(MSA)在MLP层之前完成。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="926c" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这增加了从<code class="fe nl nm nn nc b">79.9%</code>到<code class="fe nl nm nn nc b">80.6%</code>的精确度</p><h1 id="cec3" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">微观设计</h1><h1 id="4546" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">用GELU替换ReLU</h1><p id="fc33" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">既然最先进的变形金刚都用葛鲁，为什么不在我们的模型里用呢？作者报告说准确性保持不变。在<code class="fe nl nm nn nc b">nn.GELU</code>的PyTorch GELU。</p><h1 id="f721" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">更少的激活功能</h1><p id="1acb" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">我们的模块有三个激活功能。而在变压器模块中，只有一个激活功能，即MLP模块内部的激活功能。作者移除了除了中间conv层之后的激活之外的所有激活。这提高了<code class="fe nl nm nn nc b">81.3%</code>匹配Swin-T的准确性！</p><h1 id="7235" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">更少的标准化图层</h1><p id="f262" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">与激活类似，变形金刚块具有较少的规范化层。作者决定删除所有批次，只保留conv中部之前的批次。</p><h1 id="a052" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">用LN代替BN</h1><p id="d866" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">嗯，他们用图层替换了批次图层。他们注意到在最初的ResNet中这样做会影响性能，但是在我们做了所有的修改之后，性能提高到了<code class="fe nl nm nn nc b">81.5%</code></p><p id="3864" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，让我们应用它们</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><h1 id="0c50" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">分隔缩减像素采样图层。</h1><p id="6f6b" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">在ResNet中，下采样由<code class="fe nl nm nn nc b">stride=2</code> conv完成。变压器(和其他conv网)有一个单独的下降采样块。作者移除了<code class="fe nl nm nn nc b">stride=2</code>，并使用<code class="fe nl nm nn nc b">2x2</code> <code class="fe nl nm nn nc b">stride=2</code> conv在三次转换之前添加了一个下采样模块。在下采样操作之前需要进行归一化，以保持训练期间的稳定性。我们可以将这个模块添加到我们的<code class="fe nl nm nn nc b">ConvNexStage</code>中。最后，我们到达<code class="fe nl nm nn nc b">82.0%</code>超越Swin！</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="a767" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在我们可以清洁我们的<code class="fe nl nm nn nc b">BottleNeckBlock</code></p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="c1bb" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们终于到达了最后一个街区！让我们测试一下</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="8a35" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 62, 7, 7])</span></pre><h1 id="fa6d" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">最后润色</h1><p id="a54b" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">他们还添加了随机深度，也称为下降路径，(我有一篇关于它的文章<a class="ae lv" rel="noopener" target="_blank" href="/implementing-stochastic-depth-drop-path-in-pytorch-291498c4a974">和图层比例。</a></p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="f011" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好了🎉我们找到了！看看有没有效果！</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="5b74" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 62, 7, 7])</span></pre><p id="10d7" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">超级！我们需要在编码器中创建丢弃路径概率</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="db7a" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 2048, 3, 3])</span></pre><p id="e423" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了得到用于图像分类的最终ConvNext，我们需要在编码器上应用一个分类头。我们还在最后一个线性图层前添加了一个<code class="fe nl nm nn nc b">LayerNorm</code>。</p><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><figure class="lx ly lz ma gt iv"><div class="bz fp l di"><div class="mz na l"/></div></figure><pre class="lx ly lz ma gt nb nc nd ne aw nf bi"><span id="4ee1" class="ng md ji nc b gy nh ni l nj nk">torch.Size([1, 1000])</span></pre><p id="05d6" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在你有了！</p><h1 id="a625" class="mc md ji bd me mf mg mh mi mj mk ml mm ko mn kp mo kr mp ks mq ku mr kv ms mt bi translated">结论</h1><p id="88c0" class="pw-post-body-paragraph ky kz ji la b lb mu kj ld le mv km lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">在本文中，我们一步步地看到了作者为从ResNet创建ConvNext所做的所有更改。我希望这有用:)</p><p id="5532" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的阅读！</p><p id="61af" class="pw-post-body-paragraph ky kz ji la b lb lc kj ld le lf km lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">弗朗西斯科</p></div></div>    
</body>
</html>