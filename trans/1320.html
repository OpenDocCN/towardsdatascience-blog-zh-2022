<html>
<head>
<title>Pixel-level Dense Contrastive Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像素级密集对比学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pixel-level-dense-contrastive-learning-6558691eeb67#2022-04-03">https://towardsdatascience.com/pixel-level-dense-contrastive-learning-6558691eeb67#2022-04-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f49" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于主动采样策略的密集对比学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4af98b3e942559b6a53eaed3c5143143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dzdKk35ph0oczsMi"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汤姆·温克尔斯在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8acc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对比学习是一种无标签的自我监督学习过程。由于它能够经济有效地提高模型性能，近年来被越来越多的深度学习项目用作预训练过程，形成了无监督预训练和有监督微调的模型训练范式。</p><p id="0db8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，几乎所有应用良好的CL算法都是为全局特征设计的，这可以提高依赖于全局特征的任务(例如图像分类)的模型性能。而对于其他需要局部特征的任务，比如语义分割和对象检测，这些算法就不那么有效。</p><p id="a7c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于那些对CL算法基础感兴趣的人，我介绍我以前的博客<a class="ae ky" href="https://medium.com/geekculture/understanding-contrastive-learning-and-moco-efe491e4eed9" rel="noopener">理解对比学习和MoCo </a>。在本文中，我将简要介绍全局级CL算法的局限性，并讨论区域级CL算法作为解决方案。</p><h2 id="6c63" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">全球对比学习(GCL)</h2><p id="e44e" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">无监督的CL算法是自学的学习者，其中正对被拉在一起，负对被推开。例如，输入图像及其增强版本形成正对，而任意两个不同的(增强)图像形成负对。结果，相似图像的特征向量在潜在空间中形成一个簇，这导致了无监督的聚类效果。</p><h2 id="8fde" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">GCL的极限</h2><p id="dcf6" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">上面讨论的CL算法使用全局汇集的特征进行学习。首先将特征向量归一化到单位超球面上，然后将正对的特征向量拉在一起，将负对的特征向量推开。由于局部细节被排除在外，训练好的网络很难进行微调，以实现高密度任务的高精度。</p><p id="3e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了实现高密度任务的高性能，我们最好保留本地特性。然而，包含局部细节的特征图对于对比学习来说太大了。回想一下，在GCL，使用空间大小为1×1的全局特征向量来计算对比损失，如下所示，其中sim是两个向量的内积。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/f92a2779b450a0c5135e0d91be102a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3MgNEbKfFJ-pKgAp.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对比损失</p></figure><p id="c2c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意，如果我们使用空间大小为HxW的特征图来计算损失，复杂度得到二次改善。</strong>此外，负对的数量可能非常多，在<a class="ae ky" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>中大约为4000 ~ 8000个。因此，用大的空间特征图计算对比损失是不可行的。</p><h2 id="42f5" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">区域对比学习(RCL)</h2><p id="002f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">由于上述问题，保留空间特征而不将它们全部用于CL是至关重要的。这里可以使用主动采样策略，其中对于CL只采样一小部分空间像素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/fc7cfffdabcd6e95738bf00efe6a64f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMdsCktiI-SSkDGAF7WoUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(记录)</p></figure><p id="0a8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在2022年ICLR奥运会上，伦敦帝国理工学院的研究人员提出了一种叫做ReCo的区域CL新方法。通过主动采样策略，学习过程需要更少的内存并且变得高效。与传统的CL不同，由于正负对是在像素级构建的，<strong class="lb iu"> ReCo是监督的CL，其中每个图像像素的标签都是必需的</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/d26c4795aab4c38837cefa68e324568e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gWx1pDQ9K87PC2kiv0RaVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">像素级对比损失</p></figure><p id="ac19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据上述损失函数，在学习到的潜在空间中，对于每个查询像素向量，正键是其语义标签与查询相同的所有像素向量的<strong class="lb iu">平均值</strong>。另一方面，负关键字是具有来自查询的不同标签的像素向量。总损失是从小批量中的所有类采样的所有查询像素的总和。</p><h2 id="3632" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">主动采样策略</h2><p id="5236" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">虽然计算高分辨率图像的所有像素的损失是昂贵的，但作者以主动学习的方式引入了硬负挖掘，以将学习资源集中在稀疏的像素集合上。</p><p id="fbe9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了选择一个稀疏的像素集，使训练过程有效和高效，我们应该考虑主动采样的两个部分:关键采样和查询采样。</p><p id="73fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mw">活动键采样</em></p><p id="98cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主动关键采样是对某个查询像素的关键像素进行采样。回想一下，正关键字是其标签与查询像素相同的所有像素向量的平均值，正关键字是固定的。因此，只对负键进行采样。</p><p id="a08e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">负键包括硬样本和易样本。<strong class="lb iu">对于一个查询像素，如果它与某一类的负关键字之间的距离已经足够远，那么该类的负关键字就是简单样本，不需要再进行采样。另一方面，如果距离很近，将它们区分开来将是模糊的，并且该类的负键是硬样本，并且需要被采样以学习更准确的判定边界。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/71adb14eb4102e728edff4ed59efc8ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-oWzdR5MDsUVBHip_Xcy3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">4个类的成对类关系图</p></figure><p id="9ed9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在关键采样之前，知道每对不同类别向量之间的距离是很重要的。作者使用每一个小批量更新的成对类关系图。查询类别和不同类别之间的关系是这两个类别的平均潜在向量之间的softmax归一化内积。对于如上所示的4个类的例子，在查询类为0且负关键类为1的以水颜色标记的位置，其关系值在右侧计算。因为关系值是softmax归一化的，所以该值只是显示两个类别的学习的潜在向量的相似性的概率。高概率意味着相似性很高，应该从该类中采样更多的负对，而低概率意味着相似性已经很低，来自该类的少量负样本就足够了。结果，降低了概率值以使不同类别的潜在向量可区分。</p><p id="653e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们只考虑不同类之间的关系，所以不使用上述4x4表的对角线，并且用x标记。其他元素可以类似于上面讨论的water color元素来计算。</p><p id="af4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mw">主动查询采样</em></p><p id="90cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于语义分割任务中的类别不平衡，采用所有像素进行查询会使普通类别(包括背景类别)过拟合。此外，没有必要这样做，因为大多数像素容易被很好地分类。关注一小部分硬像素对于模型性能至关重要。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/cd833f0971057f6d370574878d7140aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-sIxRTIxhEg03K7R4nW0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">根据置信度图的简单和困难查询</p></figure><p id="c053" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所示，作者建议使用分类置信度图和阈值来过滤硬查询。我们可以注意到，硬查询位于不同语义区域的边界，而简单查询位于每个区域的内部。在训练过程中，我们可以动态地增加阈值来关注硬查询。</p><p id="726a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mw">一种半监督学习算法</em></p><p id="85f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于语义分割数据集的标记非常耗时，作者还提出了一种半监督学习算法来利用标记和未标记的图像。<strong class="lb iu">这很有帮助，如果你有自己的未标记数据集，但仍想尝试这种算法，你可以与另一个具有相似语义标签的已标记数据集相结合。</strong>半监督学习算法基于著名的<a class="ae ky" href="https://arxiv.org/pdf/1703.01780.pdf" rel="noopener ugc nofollow" target="_blank">均值教师框架</a>，其中使用了师生模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/aa956160fc03a636433873f5afae3b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zdiVR4IHSlprM87QgmtKSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">半监督学习框架</p></figure><p id="97a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上图从左到右，学习框架包含三个部分:针对标注数据的监督语义切分学习；无标记数据的无监督语义分割学习:和像素级对比学习识别。相应地，损失函数也包含三个部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/0dcea5a51ce8fbc1ba4680482e554e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1_fNmHHS82fmfEkECfgFEg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最终损失函数</p></figure><p id="13aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于无监督部分没有地面真实标签，生成的高置信度伪标签用于ReCo部分，使得ReCo学习可靠。</p><h2 id="14a1" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">RCL的重要性</h2><p id="9c15" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">通过RCL，我们可以对模型进行密集对比学习，这有利于下游的密集任务。ReCo在这里只是语义分割的一个例子。在不久的将来，更具体的密集任务如对象检测、关键点检测等。会在对比学习文献中被考虑，这对一般的人工智能发展是重要的。</p><h2 id="68b4" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">参考</h2><p id="a30c" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1703.01780.pdf" rel="noopener ugc nofollow" target="_blank">均值教师是更好的榜样:加权平均一致性目标提高半监督深度学习结果，2018 </a></p><p id="e38c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">视觉表征对比学习的简单框架，2020 </a></p><p id="ac91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://medium.com/geekculture/understanding-contrastive-learning-and-moco-efe491e4eed9" rel="noopener">理解对比学习和MoCo，2021 </a></p><p id="dfc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://arxiv.org/pdf/2104.04465.pdf" rel="noopener ugc nofollow" target="_blank">带区域对比的自举语义分割，2022 </a></p><div class="nb nc gp gr nd ne"><a href="https://dushuchen.medium.com/membership" rel="noopener follow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">加入我的介绍链接-陈数杜媒体</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">阅读陈数·杜(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">dushuchen.medium.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ks ne"/></div></div></a></div></div></div>    
</body>
</html>