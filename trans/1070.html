<html>
<head>
<title>Top 4 Linear Regression Variations in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的四大线性回归变量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/top-machine-learning-algorithms-for-regression-c67258a2c0ac#2022-03-21">https://towardsdatascience.com/top-machine-learning-algorithms-for-regression-c67258a2c0ac#2022-03-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3200" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">初学者友好的实现和比较指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6cc31ff913b6adaf9b80216d8e55ebbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0V_GsMAi2zN0OcNi7hm-vw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回归的机器学习算法(原图来自我的<a class="ae ky" href="https://www.visual-design.net/" rel="noopener ugc nofollow" target="_blank">网站</a></p></figure><p id="b870" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我之前的文章“<a class="ae ky" rel="noopener" target="_blank" href="/top-machine-learning-algorithms-for-classification-2197870ff501?source=your_stories_page----------------------------------------">用于分类的顶级机器学习算法</a>”中，我们介绍了常见的分类算法。现在让我们深入到监督学习的另一个类别——回归，其中输出变量是连续的数字。主要是，如何实现和比较四种常见类型的回归模型:</p><ul class=""><li id="61df" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">线性回归</li><li id="3d74" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">套索回归</li><li id="da2f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">里脊回归</li><li id="4cce" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">多项式回归</li></ul><p id="725f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢视频演练，请查看我在本文末尾的 YouTube 视频。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="6e3c" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">线性回归</h1><p id="d0fd" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">线性回归找到自变量和因变量之间的最佳线性关系，从而做出相应的预测。最简单的形式是<em class="nn"> y = b0 + b1x。</em>当只有一个输入特征时，线性回归模型拟合 2 维空间中的直线，以最小化预测值和实际值之间的残差。测量残差大小的常用成本函数是残差平方和(RSS)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/11505a0f57fd7b6ba1f4fe3df7c00cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/0*bNWinPWM-YobbRnf.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归(作者图片)</p></figure><p id="09ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着更多功能的引入，简单线性回归演变为多元线性回归<em class="nn"> y = b0 + b1x1 + b2x2 + … + bnxn。</em>如果你想要<a class="ae ky" rel="noopener" target="_blank" href="/a-practical-guide-to-linear-regression-3b1cb9e501a6">简单线性回归模型</a>的具体指南，请随意查看我的文章。</p><div class="np nq gp gr nr ns"><a rel="noopener follow" target="_blank" href="/a-practical-guide-to-linear-regression-3b1cb9e501a6"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">线性回归实用指南</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">从 EDA 到特征工程再到模型评估</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og ks ns"/></div></div></a></div><h1 id="ef21" class="mq mr it bd ms mt oh mv mw mx oi mz na jz oj ka nc kc ok kd ne kf ol kg ng nh bi translated">套索回归</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7e5c48ed29847bf5f69a45f008b25ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*QR9yRj05wnsN2hWl.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉索回归(图片由作者提供)</p></figure><p id="dc62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Lasso 回归是 L1 正则化的线性回归的变体。听起来令人畏惧？简单地说，它给回归模型试图最小化的残差(RSS)增加了一个额外的元素。它被称为 L1 正则化，因为这个增加的正则化项与系数的绝对值成比例。上面的项是基于最简单的线性回归形式<em class="nn"> y = b0 + b1x。</em></p><p id="b2ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与岭回归相比，它更好地将某些特征的系数变为 0，因此是一种合适的特征消除技术。您将在后面的“特性重要性”一节中看到。</p><h1 id="349a" class="mq mr it bd ms mt oh mv mw mx oi mz na jz oj ka nc kc ok kd ne kf ol kg ng nh bi translated">里脊回归</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fa5ccc04c88301d977833c829679c8db.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*xNWgFgRrx9r7a8gF.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">岭回归(图片作者提供)</p></figure><p id="25f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">岭回归是 L2 正则化的另一种回归变体。因此不难推断，正则项是基于系数的<strong class="lb iu">平方值</strong>——2 次。与 Lasso 回归相比，岭回归具有<strong class="lb iu">收敛速度快、计算量小的优点。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e1a75aae0a881b7ef6e1795a10824026.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*AoYf4dHVdm35cI6W.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">正则化强度(图片由作者提供)</p></figure><p id="00cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拉索和脊线的正则化强度由λ值决定。λ值越大，系数越小，模型越平坦，方差越小。因此，正则化技术通常用于防止模型过拟合。</p><h1 id="3ed2" class="mq mr it bd ms mt oh mv mw mx oi mz na jz oj ka nc kc ok kd ne kf ol kg ng nh bi translated">多项式回归</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/fd632fcce7a09e90a80d2e704675b492.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*YR0CMvkkpUbp3uPc.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多项式回归(作者图片)</p></figure><p id="17d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">多项式回归是线性回归通过多项式特征变换的一种变体。它增加了独立变量之间的相互作用。<code class="fe on oo op oq b">PolynomialFeatures(degree = 2)</code>用于将输入特征转换到最大程度 2。例如，如果原始输入要素是 x1、x2、x3，这会将要素扩展为 x1、x2、x3、x1、x1x2、x1x3、x2、x2x3、x3。结果，该关系不再是线性的，而是能够提供对数据的非线性拟合。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="1270" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">实践中的回归模型</h1><p id="cf88" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在所有的理论之后，时间来实现和比较这些回归模型，并探索不同的 lambda 值如何影响模型性能。</p><p id="e711" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有兴趣获得这个项目的完整代码，请查看<a class="ae ky" href="https://www.visual-design.net/code-snippets" rel="noopener ugc nofollow" target="_blank">代码片段</a>。</p><h2 id="bd62" class="or mr it bd ms os ot dn mw ou ov dp na li ow ox nc lm oy oz ne lq pa pb ng pc bi translated">1.目标和数据集概述</h2><p id="3823" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">该项目旨在使用回归模型，根据其他因素“人均国内生产总值”、“社会支持”、“健康预期寿命”、“做出生活选择的自由”、“慷慨程度”和“对腐败的看法”来预测国家幸福指数。</p><p id="158c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用的是 Kaggle 上的<a class="ae ky" href="https://www.kaggle.com/unsdsn/world-happiness" rel="noopener ugc nofollow" target="_blank">《世界幸福报告》</a>数据集，包含 156 个条目，9 个特征。<code class="fe on oo op oq b">df.describe()</code>用于提供数据集的概述。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/e24d7f55046986e99fe2a31e48ab2a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RFXAuUX324hWA1hE68z2sA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集概述(按作者分类的图片)</p></figure><h2 id="281b" class="or mr it bd ms os ot dn mw ou ov dp na li ow ox nc lm oy oz ne lq pa pb ng pc bi translated">2.数据探索和特征工程</h2><p id="145d" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated"><strong class="lb iu"> 1)删除冗余特征</strong></p><p id="8734" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特性<em class="nn">“总体排名”</em>被删除，因为它是目标<em class="nn">“得分”</em>的直接反映。此外，<em class="nn">“国家或地区”</em>被删除，因为它不会给预测带来任何值。</p><p id="e6ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2)单变量分析</strong></p><p id="e5f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应用直方图了解每个特征的分布。如下图所示，<em class="nn">“社会支持”</em>似乎严重左倾，而<em class="nn">“慷慨”</em>和<em class="nn">“对腐败的看法”</em>则是右倾——这为转换的特征工程技术提供了信息。</p><pre class="kj kk kl km gt pe oq pf pg aw ph bi"><span id="871b" class="or mr it oq b gy pi pj l pk pl"># univariate analysis<br/>fig = plt.figure(figsize=(16, 8))  <br/>i = 0<br/>for column in df:<br/>    sub = fig.add_subplot(2,4 , i + 1)<br/>    sub.set_xlabel(column)<br/>    df[column].plot(kind = 'hist')<br/>    i = i + 1</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/e53e2572f919b78cd6bc46b1727d0b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sfq_g4q9AA096P8acnz9mQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单变量分析(图片由作者提供)</p></figure><p id="9a5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还可以将直方图与下面的偏斜度结合起来，以量化特征是否严重向左或向右偏斜。</p><pre class="kj kk kl km gt pe oq pf pg aw ph bi"><span id="d620" class="or mr it oq b gy pi pj l pk pl">skew_limit = 0.7<br/>for col in df.columns:<br/>    skewness = df[col].skew()<br/>    if skewness + skew_limit &lt; 0:<br/>        print(col, ": left skewed", str(skewness))<br/>    elif skewness &gt; skew_limit:<br/>        print(col, ": right skewed", str(skewness))<br/>    else: <br/>        print(col, ": not skewed", str(skewness))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/8f167cdea79449800efa2136c46d2f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*-6LmmUQSpyfRZOcjwP84uA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">偏斜度</p></figure><p id="ea2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3)平方根变换</strong></p><p id="7488" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe on oo op oq b"><em class="nn">np.sqrt</em></code> <em class="nn"> </em>是<em class="nn"> </em>应用于变换<strong class="lb iu">右斜特征</strong> — <em class="nn">“慷慨”和“对腐败的看法”</em>。因此，这两个特征变得更加正态分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/b2444ede5054116595b5b095ec198152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a4FsHUtdyoA-nv-PLhl41A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平方根变换(图片由作者提供)</p></figure><p id="512f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4)日志转换</strong></p><p id="8d85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe on oo op oq b"><em class="nn">np.log(2 — df['Social Support'])</em></code>用于变换<strong class="lb iu">左歪斜特征</strong>。偏斜度从 1.13 显著降低到 0.39。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/56fd98a6a7da293b3b120e03e15ab5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rHGYZDoKmM8GroySHmGbWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">日志转换(图片由作者提供)</p></figure><p id="4537" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 5)双变量分析</strong></p><p id="e56d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe on oo op oq b"><em class="nn">sns.pairplot(df)</em></code>可以用来可视化变换后特征之间的相关性。散点图表明<em class="nn">“人均 GDP”、“社会支持”、“健康预期寿命”</em>与目标特征<em class="nn">“得分”</em>相关，因此可能具有较高的系数值。让我们在后面的部分看看是否是这样。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/73d990549260656d0f3644ae50600bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgXU_q3pUrx5g98Rs70nHw.png"/></div></div></figure><p id="7a3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 6)特征缩放</strong></p><p id="b786" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于正则化技术正在操纵系数值，这使得模型性能对特征的比例敏感。所以特征应该被转换成相同的比例。我在三种定标器上做了实验——标准定标器、最小最大定标器和鲁棒定标器。</p><p id="29f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看我的文章“3 种常见的数据转换技术”以获得更全面的数据转换技术指南。</p><div class="np nq gp gr nr ns"><a rel="noopener follow" target="_blank" href="/data-transformation-and-feature-engineering-e3c7dfbb4899"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">3 种常见的数据转换技术</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">如何为您的数据选择合适的</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="pq l od oe of ob og ks ns"/></div></div></a></div><p id="f7bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，缩放器仅适合使用训练集，然后将变换应用于训练集和测试集。所以，应该先拆分数据集。</p><pre class="kj kk kl km gt pe oq pf pg aw ph bi"><span id="504e" class="or mr it oq b gy pi pj l pk pl">from sklearn.model_selection import train_test_split</span><span id="28b5" class="or mr it oq b gy pr pj l pk pl">X = df.drop(['Score'], axis=1)<br/>y = df['Score']</span><span id="75bb" class="or mr it oq b gy pr pj l pk pl">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span><span id="b066" class="or mr it oq b gy pr pj l pk pl">print(X_train.shape, X_test.shape)</span></pre><p id="2672" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，迭代这 3 个缩放器，比较它们的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/ded2ea4e8e33524d1ed0167fbf7ee674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gah7RgnwwCM8bmE6xEyDCw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征缩放代码(图片由作者提供)</p></figure><p id="56a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，缩放器不会影响数据的分布和形状，但会改变数据的范围。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/bc72aed1ec551040abf98538208be6b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsH8pqOdIMKxXmnDzV0k9g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征比例比较(图片由作者提供)</p></figure><p id="db53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要获得更全面的 EDA 和特征工程指南，请查看我的精选列表。</p><div class="np nq gp gr nr"><div role="button" tabindex="0" class="ab bv gv cb fp pu pv bn pw ks ex"><div class="px l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw py pz fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l py pz fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="qc qd gw l"><h2 class="bd iu vo lv fp vp fr fs ny fu fw is bi translated">EDA 和特征工程技术</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vq au vr vs vt sf vu an eh ei vv vw vx el em eo de bk ep" href="https://destingong.medium.com/list/eda-and-feature-engineering-techniques-e0696974ed54?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vy l fo"><span class="bd b dl z dk">9 stories</span></div></div></div><div class="qp dh qq fp ab qr fo di"><div class="di qh bv qi qj"><div class="dh l"><img alt="" class="dh" src="../Images/7fc2bdc73b7b052566cf26034941c232.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*1rSjmR6nGHPFoe_rBHI45A.png"/></div></div><div class="di qh bv qk ql qm"><div class="dh l"><img alt="" class="dh" src="../Images/a7c4110e9a854cf9e9eba83dfa46e7d3.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*h1kR6Z_ZWGe0fRY_tqzxUw.png"/></div></div><div class="di bv qn qo qm"><div class="dh l"><img alt="" class="dh" src="../Images/3ac6d4f7832c8daa758f71b1e479406c.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*Tjy4bJ_YB_Lbx4fP-Tldzw.png"/></div></div></div></div></div><h2 id="8617" class="or mr it bd ms os ot dn mw ou ov dp na li ow ox nc lm oy oz ne lq pa pb ng pc bi translated">3.回归模型比较</h2><p id="669c" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">现在我们来比较下面三种线性回归模型——线性回归、岭回归和套索回归。</p><pre class="kj kk kl km gt pe oq pf pg aw ph bi"><span id="6493" class="or mr it oq b gy pi pj l pk pl">lr = LinearRegression().fit(X_train, y_train)<br/>l2 = Ridge(alpha = 0.1).fit(X_train, y_train)<br/>l1 = Lasso(alpha = 0.001).fit(X_train, y_train)</span></pre><p id="4f1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1)预测比较</strong></p><p id="ed4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，在一个散点图中可视化三个模型的预测值与实际值，这表明在当前的参数设置下，它们的预测大部分相互重叠。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qv"><img src="../Images/ba5a9c88e6dd20cfac0b78eacad1b88d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*42fTTvyZBpA3DEruJ81sdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回归预测比较(图片由作者提供)</p></figure><p id="1c4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2)特征重要性</strong></p><p id="8d48" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二步是实验不同的 lambda 值(scikit-learn 中的 alpha)如何影响模型。具体来说，当 alpha 值从 0.0001 增加到 1 时，<strong class="lb iu">特征重要性和系数值</strong>如何变化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qw"><img src="../Images/995753692c2c6e8fa2068a5ec8108945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PeJBjL4pP0Jej3EU6mvWew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征重要性代码(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qx"><img src="../Images/24bc9382732bfc39ec0d6fc6ba6dd22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxAS5ZI3NlrP6RarI-l62g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">套索与山脊的特征重要性(图片由作者提供)</p></figure><p id="2c24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于 Lasso 和 Ridge 模型生成的系数值，<em class="nn">“人均 GDP”、“社会支持”、“健康预期寿命”</em>似乎是前 3 个最重要的特征。这与之前散点图的发现一致，表明它们是“<em class="nn">乡村快乐得分</em>”的主要驱动力。并排比较还表明，alpha 值的增加在不同程度上影响 Lasso 和 Ridge，Lasso 中的特征被更强烈地抑制。这就是为什么<strong class="lb iu">套索经常被选择用于特征选择的目的。</strong></p><p id="b0cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3)应用多项式效果</strong></p><p id="8b2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，还引入了多项式要素来增强基线线性回归，从而将要素数量从 6 个增加到 27 个。</p><pre class="kj kk kl km gt pe oq pf pg aw ph bi"><span id="dd9d" class="or mr it oq b gy pi pj l pk pl">from sklearn.preprocessing import PolynomialFeatures<br/>pf = PolynomialFeatures(degree = 2, include_bias = False)<br/>X_train_poly = pf.fit_transform(X_train)<br/>X_test_poly = pf.fit_transform(X_test)</span></pre><p id="3c3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看看它们在多项式变换后的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qy"><img src="../Images/16275568d1213f43b725cd768543feaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*DIxIZvcfP3Mq9__6LQi7JQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">多项式特征单变量分析(图片由作者提供)</p></figure><h2 id="d9b2" class="or mr it bd ms os ot dn mw ou ov dp na li ow ox nc lm oy oz ne lq pa pb ng pc bi translated">4.模型评估</h2><p id="f5c7" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">最后一步，评估多项式效应前后 Lasso 回归与岭回归模型的性能。在下面的代码中，我实现了四个模型:</p><ul class=""><li id="844d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">l2:没有多项式特征的岭回归</li><li id="2e26" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">l2_poly:具有多项式特征的岭回归</li><li id="558c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">l1:无多项式特征的套索回归</li><li id="327c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">l1_poly:具有多项式要素的套索回归</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qz"><img src="../Images/707a5239b346e80b9a3b400dbbd1a6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*tVRlqDH2cQxPaqwUZiVavg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">回归模型评估(图片由作者提供)</p></figure><p id="a495" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">常见的回归模型评估指标有 MAE、MSE、RMSE 和 R 平方——查看我的文章“<a class="ae ky" rel="noopener" target="_blank" href="/a-practical-guide-to-linear-regression-3b1cb9e501a6?source=your_stories_page----------------------------------------">线性回归实用指南</a>”了解详细解释。在这里，我使用 MSE(均方误差)来评估模型性能。</p><p id="a153" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1)通过在一个图表中比较<strong class="lb iu">山脊与套索，</strong>表明当α值较低时，它们具有相似的精度，但是当α值接近 1 时，套索显著恶化。在多项式变换之前和之后观察到相同的模式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ra"><img src="../Images/f32cd396ea132a2eb085124dcba69b6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QlmfbuWbMDdMCqZobwomrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一张图中的山脊与套索(图片由作者提供)</p></figure><p id="a463" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2)通过在一个图表中比较<strong class="lb iu">之前与之后的多项式效应，</strong>我们可以知道，多项式总体上降低了 MSE，从而增强了模型性能。当α增加到 1 时，这种效应在岭回归中更显著，当α接近 0.0001 时，这种效应在套索回归中更显著。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi rb"><img src="../Images/7495ee548bcf85823df0ab9366980397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JkF2ROalArrtQwxQHZEdvg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个图表中多项式效果的前后对比(图片由作者提供)</p></figure><p id="ead0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，即使多项式变换提高了回归模型的性能，它也会使模型的可解释性变得更加困难-很难从多项式回归中分辨出主要的模型驱动因素。</p><p id="dcb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更少的错误并不总是保证更好的模型，它将在基于项目目标的可预测性和可解释性之间找到正确的平衡。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="672c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">感谢到达终点。如果你想阅读更多我关于媒介的文章，我将非常感谢你的支持，注册成为</strong> <a class="ae ky" href="https://destingong.medium.com/membership" rel="noopener"> <strong class="lb iu">媒介会员</strong> </a> <strong class="lb iu">。</strong></p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="5a66" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">带回家的信息</h1><p id="646a" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">希望本文提供了不同类型回归模型的一般思路，包括:</p><ul class=""><li id="69a0" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">线性回归</li><li id="de77" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">里脊回归</li><li id="54b9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">套索回归</li><li id="bd0e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">多项式回归</li></ul><p id="7b43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还将演练:</p><ul class=""><li id="71d1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">回归模型的基本 EDA 和特征工程技术。</li><li id="95d7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">不同 alpha 值下的特征重要性</li><li id="8bbc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">套索和脊的模型比较</li><li id="ddd3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">多项式特征前后的模型比较</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="rc rd l"/></div></figure><h2 id="0689" class="or mr it bd ms os ot dn mw ou ov dp na li ow ox nc lm oy oz ne lq pa pb ng pc bi translated">更多这样的文章</h2><div class="np nq gp gr nr ns"><a rel="noopener follow" target="_blank" href="/top-machine-learning-algorithms-for-classification-2197870ff501"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd iu gy z fp nx fr fs ny fu fw is bi translated">用于分类的 6 大机器学习算法</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">如何用 Python 构建机器学习模型管道</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="re l od oe of ob og ks ns"/></div></div></a></div><div class="np nq gp gr nr"><div role="button" tabindex="0" class="ab bv gv cb fp pu pv bn pw ks ex"><div class="px l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw py pz fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l py pz fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="qc qd gw l"><h2 class="bd iu vo lv fp vp fr fs ny fu fw is bi translated">机器学习实用指南</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vq au vr vs vt sf vu an eh ei vv vw vx el em eo de bk ep" href="https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vy l fo"><span class="bd b dl z dk">10 stories</span></div></div></div><div class="qp dh qq fp ab qr fo di"><div class="di qh bv qi qj"><div class="dh l"><img alt="Principal Component Analysis for ML" class="dh" src="../Images/1edea120a42bd7dc8ab4a4fcdd5b822d.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*swd_PY6vTCyPnsgBYoFZfA.png"/></div></div><div class="di qh bv qk ql qm"><div class="dh l"><img alt="Time Series Analysis" class="dh" src="../Images/fda8795039b423777fc8e9d8c0dc0d07.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*8sSAHftNwd_RNJ3k4VA0pA.png"/></div></div><div class="di bv qn qo qm"><div class="dh l"><img alt="deep learning cheatsheet for beginner" class="dh" src="../Images/b2a4e3806c454a795ddfae0b02828b30.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uNyD4yNMH-DnOel1wzxOOA.png"/></div></div></div></div></div><div class="np nq gp gr nr"><div role="button" tabindex="0" class="ab bv gv cb fp pu pv bn pw ks ex"><div class="px l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw py pz fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l py pz fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="qc qd gw l"><h2 class="bd iu vo lv fp vp fr fs ny fu fw is bi translated">开始学习数据科学</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vq au vr vs vt sf vu an eh ei vv vw vx el em eo de bk ep" href="https://destingong.medium.com/list/get-started-in-data-science-8006bb4ba3ad?source=post_page-----c67258a2c0ac--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="vy l fo"><span class="bd b dl z dk">8 stories</span></div></div></div><div class="qp dh qq fp ab qr fo di"><div class="di qh bv qi qj"><div class="dh l"><img alt="" class="dh" src="../Images/d302bbd526df8af0e847419971dc535a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*__Lp9NvZvtLrZ00KKyoS_A.png"/></div></div><div class="di qh bv qk ql qm"><div class="dh l"><img alt="Statistical Tests in Python" class="dh" src="../Images/2ff8d4b6d8bd95fde596b31de22ef09e.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2hGMrCjLtVKtOKD_QnyuWA.png"/></div></div><div class="di bv qn qo qm"><div class="dh l"><img alt="" class="dh" src="../Images/ae659430af3f4c100a2e11f1f558462c.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*wCpwHS7BWBe6JnHfIMSWrQ.png"/></div></div></div></div></div></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="c7d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nn">原载于 2022 年 3 月 20 日 https://www.visual-design.net</em><a class="ae ky" href="https://www.visual-design.net/post/top-machine-learning-algorithms-for-regression" rel="noopener ugc nofollow" target="_blank"><em class="nn"/></a><em class="nn">。</em></p></div></div>    
</body>
</html>