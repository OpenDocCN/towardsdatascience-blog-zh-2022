<html>
<head>
<title>Ultra TinyML: Machine Learning for 8-bit Microcontroller</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ultra tiny ml:8位微控制器的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ultra-tinyml-machine-learning-for-8-bit-microcontroller-9ec8f7c8dd12#2022-02-21">https://towardsdatascience.com/ultra-tinyml-machine-learning-for-8-bit-microcontroller-9ec8f7c8dd12#2022-02-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9473" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何用Arduino和内乌顿TinyML创建手势识别系统</h2></div><blockquote class="kf kg kh"><p id="0eb9" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">“一个错误重复多次就是一个决定”——p·科埃略</p></blockquote><p id="fd18" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">TinyML是机器学习的一个子领域，研究在小型低功耗设备上运行ML模型的方式。</p><p id="b676" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">在这篇文章中，我将展示一种开始使用TinyML的简单方法:在<em class="kk"> Arduino </em>板上实现一个机器学习模型，同时创建一些很酷的东西:一个基于<strong class="kl ir">加速度计</strong>的<strong class="kl ir">手势识别系统</strong>。</p><blockquote class="kf kg kh"><p id="fb81" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">手势识别是一个试图通过使用数学算法来识别人类手势的过程。</p></blockquote><p id="29df" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">为了使实验更简单，该系统被设计为只识别两种手势:一种<em class="kk">出拳</em>和一种<em class="kk">弯曲</em>运动。<br/>这个，在数据科学领域，叫做<a class="ae li" href="https://en.wikipedia.org/wiki/Binary_classification" rel="noopener ugc nofollow" target="_blank"> <strong class="kl ir">二元分类</strong> </a>。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/26adde7f458568942d6b5550aa5f5e6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/1*U5H6V_kNUd_vx7rS7bwj5w.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">“出拳”手势。图片作者。</p></figure><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/03da0deaeafadb5c390a53842c482cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/1*GfPQRc5crwRAtxuzNdAbcg.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">“伸缩”手势。图片作者。</p></figure><p id="65bb" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><em class="kk">但是……为什么要“超”TinyML？</em></p><p id="b795" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">这项实验的最大挑战是试图在一个非常小的设备上运行预测模型:一个8位T21微控制器。<br/>要实现这一点，可以使用<a class="ae li" href="https://bit.ly/36rN4Pg" rel="noopener ugc nofollow" target="_blank"> <em class="kk">内乌顿</em> </a>。</p><p id="e53d" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">内乌顿是一个TinyML框架。它允许在没有任何编码和很少机器学习经验的情况下自动构建神经网络，并将它们嵌入到小型计算设备中。<br/>支持<strong class="kl ir"> 8 </strong>、<strong class="kl ir"> 16 </strong>、<strong class="kl ir"> 32位</strong>微控制器，不像<a class="ae li" href="https://www.tensorflow.org/lite/microcontrollers" rel="noopener ugc nofollow" target="_blank"><em class="kk">tensor flow Lite</em></a>TinyML框架只支持32位。你不需要一个强大的机器来使用<em class="kk">内乌顿，</em>它是一个运行在网络浏览器上的在线软件工具。<br/>使用免费计划，你可以训练和下载无限数量的模型。</p><p id="7462" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><em class="kk">…我们开始吧！</em></p><p id="165b" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">实验分为三步:</p><ol class=""><li id="352b" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le mb mc md me bi translated"><strong class="kl ir">捕获</strong>训练<strong class="kl ir">数据集</strong></li><li id="8161" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le mb mc md me bi translated"><strong class="kl ir">训练</strong>模型使用<em class="kk">内乌顿</em></li><li id="06e4" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le mb mc md me bi translated"><strong class="kl ir">部署</strong>并在<em class="kk"> Arduino </em>上运行模型</li></ol><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/d924685119ff3224866e5f08b736fde1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eJlTf6dqCdcd5wx9_K8lkQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">实验流程。图片作者。</p></figure><h1 id="b8b0" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">硬件系统</h1><p id="9ab0" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">手势识别系统由以下部分组成:</p><ul class=""><li id="4bea" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">一款单片机:<strong class="kl ir"/><a class="ae li" href="https://store.arduino.cc/products/arduino-mega-2560-rev3" rel="noopener ugc nofollow" target="_blank"><strong class="kl ir">Arduino Mega 2560</strong></a></li><li id="14ab" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">加速度传感器<strong class="kl ir">:</strong><a class="ae li" href="https://www.amazon.it/Aukru-MPU-6050-Giroscopio-Accelerometro-Arduino/dp/B00PL70P7K" rel="noopener ugc nofollow" target="_blank"><strong class="kl ir">GY-521</strong></a><strong class="kl ir"/>模块</li></ul><p id="3d66" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><strong class="kl ir"> Arduino Mega 2560 </strong>是一个基于<strong class="kl ir"> ATmega2560 </strong>的微控制器板:一个低功耗<strong class="kl ir"> 8位MCU </strong>，带有256KB闪存、32个通用工作寄存器、UART接口、10位A/D转换器和许多其他外设。<br/> Mega 2560板是为复杂项目设计的:它比其他<em class="kk"> Arduino </em>板(<em class="kk"> Uno、Nano、Micro等)有更大的<strong class="kl ir">空间</strong>。)</em>。这使得它非常适合有大量数据要处理的机器学习应用程序。</p><p id="b992" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><strong class="kl ir"> GY-521 </strong>模块是围绕<em class="kk">InvenSense</em><strong class="kl ir">MPU-6050</strong>构建的:一种在单个IC中包含三轴MEMS加速度计和三轴MEMS陀螺仪的传感器。<br/>它的操作非常精确，因为每个通道都包含一个精确的数字转换器。它能够同时捕捉X、Y和Z轴的值。使用<strong class="kl ir"> I2C </strong>接口与MCU进行通信。</p><p id="910f" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面是用<a class="ae li" href="https://fritzing.org/" rel="noopener ugc nofollow" target="_blank">烧结</a>软件设计的连接电路:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nn"><img src="../Images/f5d3f3064b2352d83718cf5094bbb0f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqAhHFAaVu55W5H3J3n4OQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">连接电路:Arduino Mega2560和GY-521。图片作者。</p></figure><p id="be2f" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">GY-521由<em class="kk"> Arduino </em> Mega power部分的<em class="kk"> 5V </em>和<em class="kk"> GND </em>引脚供电，数据通讯使用<em class="kk"> I2C </em>引脚(引脚20和引脚21)。<br/>剩余的引脚是可选的，对该应用没有用处。</p><p id="5194" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">为了验证GY-521模块是否正确供电，连接<em class="kk"> Arduino </em>板的USB电缆，并检查安装在传感器板上的LED是否打开。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi no"><img src="../Images/4dcebb1b925370b1b393fdfa32d4b3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/1*XRJb_YgSaOz49QgTX0ZBYA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">GY-521: LED位置。图片作者。</p></figure><p id="1e03" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">验证传感器电源后，通过下载<a class="ae li" href="https://learn.adafruit.com/mpu6050-6-dof-accelerometer-and-gyro/arduino" rel="noopener ugc nofollow" target="_blank"> Adafruit MPU6050 Arduino库</a>并打开<em class="kk">绘图仪</em>示例，检查<em class="kk"> I2C </em>通信是否正常工作。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi np"><img src="../Images/6d807f3d2382901625fcc07f8922da86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IzHEK9ztiJQZq7QVlKW-Ew.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">在Arduino IDE中添加库。图片作者。</p></figure><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nq"><img src="../Images/14341e06b762571e2e01bfc0834a439b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3zVQWg4JDbXbrosH-1oGw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Adafruit MPU6050库。图片作者。</p></figure><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/3f54eb787d47d1305cdad84b881ede7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*XJkHWu_1qk-arVk15TDiLA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">MPU6050示例图片作者。</p></figure><p id="16f3" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">将示例草图上传到<em class="kk"> Arduino </em>板上，打开<em class="kk">工具</em>菜单中的<em class="kk">串行绘图仪</em>，在<em class="kk">波特</em>下拉菜单中设置115200，并“摇动”传感器板。预期结果如下:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/a0c1e890bacda8dad5e11a51835daec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*q31_yVIqmGKr9rwv77SGYw.gif"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">MPU6050绘图仪的串行绘图仪实例。图片作者。</p></figure><p id="2e0e" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">现在，系统已准备好收集加速度计和陀螺仪数据。</p><h1 id="aab8" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">捕获培训数据</h1><p id="b590" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">建立预测模型的第一步是收集足够的运动测量值。<br/>这组测量被称为<strong class="kl ir">训练数据集</strong>，它将用于训练<em class="kk">内乌顿</em>神经网络构建器。</p><p id="9d53" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">最简单的方法是通过捕捉加速度和陀螺仪测量值并将结果存储在一个文件中，重复几次相同的两个动作(<em class="kk">打孔</em>和<em class="kk">弯曲</em>)。<br/>为此，您创建一个专用于传感器数据采集的<em class="kk"> Arduino </em>草图。该程序将获取每个动作的测量值，并将传感器测量值输出打印在串行端口控制台上。</p><p id="9d59" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">你将完成至少60个动作:第一个动作30个(<em class="kk">出拳</em>)，第二个动作30个(<em class="kk">弯曲</em>)。对于每个动作，您将在1秒时间窗口内获得50个加速度和50个陀螺仪测量值(<em class="kk">采样时间:20毫秒—50Hz </em>)。在这个实验中，60个动作就足够了。通过增加运动测量的数量，可以提高模型的预测能力。然而，大型数据集会导致<em class="kk">过拟合</em>模型。没有“正确的”数据集大小，但建议使用“<em class="kk">试错法</em>”方法。</p><p id="cca5" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><em class="kk"> Arduino </em>草图的串口输出将根据<em class="kk">内乌顿</em>训练<a class="ae li" href="https://lab.neuton.ai/#/support_library/user_guide/TRAINING_DATASET_REQUIREMENTS" rel="noopener ugc nofollow" target="_blank">数据集要求</a>进行格式化:</p><ul class=""><li id="b179" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated"><strong class="kl ir"> CSV </strong>格式:是一种数据库文件格式。文件的每一行都是一个数据记录，由一个或多个用逗号分隔的字段组成。</li><li id="ce1e" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">至少<strong class="kl ir"> 50条数据记录</strong>(对于二元分类任务，意味着每组至少25条数据记录)。</li><li id="5d24" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">第一行必须包含<strong class="kl ir">列名</strong>(例如<em class="kk"> ax0、ay0、az0、gx0、gy0、gz0、… </em>)。</li><li id="b6f4" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">必须存在一个<strong class="kl ir">目标</strong>变量列。每一行必须被分配到一个特定的目标组(在本实验中:对于<em class="kk">冲头</em>，为“0”；对于<em class="kk">弯曲</em>，为“1”)。</li><li id="dc77" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">使用一个<strong class="kl ir">点</strong>作为小数点分隔符。</li></ul><p id="c777" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面，<em class="kk"> Arduino </em>程序用于数据集创建:</p><ul class=""><li id="471d" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">IMU传感器初始化和CSV报头生成:</li></ul><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="8db9" class="ny mq iq nu b gy nz oa l ob oc">#define <strong class="nu ir">NUM_SAMPLES 50</strong></span><span id="3704" class="ny mq iq nu b gy od oa l ob oc">Adafruit_MPU6050 mpu;</span><span id="68ab" class="ny mq iq nu b gy od oa l ob oc">void <strong class="nu ir">setup</strong>() {<br/>  // init serial port<br/>  <strong class="nu ir">Serial.begin</strong>(115200);<br/>  while (!Serial) {<br/>    delay(10);<br/>  }</span><span id="b1c4" class="ny mq iq nu b gy od oa l ob oc">  // init IMU sensor<br/>  if (!<strong class="nu ir">mpu.begin</strong>()) {<br/>    while (1) {<br/>      delay(10);<br/>    }<br/>  }<br/>  <br/>  // configure IMU sensor<br/>  // <em class="kk">[...]</em></span><span id="be84" class="ny mq iq nu b gy od oa l ob oc">  // print the CSV header (ax0,ay0,az0,...,gx49,gy49,gz49,target)<br/>  for (int i=0; i&lt;<strong class="nu ir">NUM_SAMPLES</strong>; i++) {<br/>    Serial.print("<strong class="nu ir">aX</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",<strong class="nu ir">aY</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",<strong class="nu ir">aZ</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",<strong class="nu ir">gX</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",<strong class="nu ir">gY</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",<strong class="nu ir">gZ</strong>");<br/>    Serial.print(i);<br/>    Serial.print(",");<br/>  }<br/>  Serial.println("<strong class="nu ir">target</strong>");<br/>}</span></pre><ul class=""><li id="0e0b" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">采集30个连续运动。如果加速度总和高于某个阈值(例如<em class="kk"/><em class="kk">2.5g</em>)，则检测到运动开始。</li></ul><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="5350" class="ny mq iq nu b gy nz oa l ob oc">#define <strong class="nu ir">NUM_GESTURES    30</strong></span><span id="03f2" class="ny mq iq nu b gy od oa l ob oc">#define GESTURE_0       0<br/>#define GESTURE_1       1<br/>#define <strong class="nu ir">GESTURE_TARGET  </strong>GESTURE_0 <br/>//#define <strong class="nu ir">GESTURE_TARGET  </strong>GESTURE_1 </span><span id="9272" class="ny mq iq nu b gy od oa l ob oc">void <strong class="nu ir">loop</strong>() {<br/>  sensors_event_t a, g, temp;<br/>  <br/>  while(gesturesRead &lt; NUM_GESTURES) {<br/>    // wait for significant motion<br/>    while (samplesRead == NUM_SAMPLES) {<br/>      // read the acceleration data<br/>      mpu.getEvent(&amp;a, &amp;g, &amp;temp);<br/>      <br/>      // sum up the absolutes<br/>      float aSum = fabs(a.acceleration.x) + <br/>                   fabs(a.acceleration.y) + <br/>                   fabs(a.acceleration.z);<br/>      <br/>      // check if it's above the threshold<br/>      if (aSum &gt;= ACC_THRESHOLD) {<br/>        // reset the sample read count<br/>        samplesRead = 0;<br/>        break;<br/>      }<br/>    }<br/>  <br/>    // read samples of the detected motion<br/>    while (samplesRead &lt; <strong class="nu ir">NUM_SAMPLES</strong>) {<br/>        // read the acceleration and gyroscope data<br/>        mpu.getEvent(&amp;a, &amp;g, &amp;temp);<br/>  <br/>        samplesRead++;<br/>  <br/>        // print the sensor data in CSV format<br/>        Serial.print(a.acceleration.x, 3);<br/>        Serial.print(',');<br/>        Serial.print(a.acceleration.y, 3);<br/>        Serial.print(',');<br/>        Serial.print(a.acceleration.z, 3);<br/>        Serial.print(',');<br/>        Serial.print(g.gyro.x, 3);<br/>        Serial.print(',');<br/>        Serial.print(g.gyro.y, 3);<br/>        Serial.print(',');<br/>        Serial.print(g.gyro.z, 3);<br/>        Serial.print(',');</span><span id="fb0b" class="ny mq iq nu b gy od oa l ob oc">        // print target at the end of samples acquisition<br/>        if (samplesRead == <strong class="nu ir">NUM_SAMPLES</strong>) {<br/>          Serial.println(<strong class="nu ir">GESTURE_TARGET</strong>);<br/>        }<br/>        <br/>        delay(10);<br/>    }<br/>    gesturesRead++;<br/>  }<br/>}</span></pre><p id="725d" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">首先，在串行监视器打开并且<em class="kk">手势_目标</em>设置为<strong class="kl ir">手势_0 </strong>的情况下运行上面的草图。然后，在<em class="kk">手势_目标</em>设置为<strong class="kl ir">手势_1 </strong>的情况下运行。每次执行时，执行相同的动作30次，尽可能确保动作以相同的方式执行。</p><p id="a9a8" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">将两个动作的串行监视器输出复制到一个文本文件中，并将其重命名为“trainingdata”。<strong class="kl ir"> csv </strong>”。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oe"><img src="../Images/e8e31760424ddd2398802a0d13755720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DsusRl5Kt4zQqhkHYMnlNw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">CSV格式的训练数据集示例。图片作者。</p></figure><h1 id="e1ab" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">用内乌顿·丁尼尔训练模型</h1><blockquote class="kf kg kh"><p id="7be7" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">训练模型的过程包括向机器学习算法提供训练数据以供学习。在这个阶段，您尝试将权重和偏差的最佳组合与ML算法相匹配，以最小化损失函数。</p></blockquote><p id="d032" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated"><em class="kk">内乌顿</em>自动执行训练，无需任何用户交互。<br/>用<em class="kk">内乌顿</em>训练神经网络快速简单，分为三个阶段:</p><ol class=""><li id="5ef8" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le mb mc md me bi translated"><strong class="kl ir">数据集</strong>:上传和验证</li><li id="7dbc" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le mb mc md me bi translated"><strong class="kl ir">训练</strong>:自动ML</li><li id="4941" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le mb mc md me bi translated"><strong class="kl ir">预测</strong>:结果分析和模型下载</li></ol><h2 id="1fd7" class="ny mq iq bd mr of og dn mv oh oi dp mz lf oj ok nb lg ol om nd lh on oo nf op bi translated">数据集:上传和验证</h2><ul class=""><li id="dc28" class="lw lx iq kl b km nh kp ni lf oq lg or lh os le nm mc md me bi translated">首先，创建一个新的<em class="kk">内乌顿</em>解决方案，并将其命名为(例如<em class="kk">手势识别</em>)。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ot"><img src="../Images/59025f4adc4b4033149e4396e05a7f34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJvCp9P2QZBROBcKklHOgg.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:添加新的解决方案。图片作者。</p></figure><ul class=""><li id="244c" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">上传CSV训练数据集文件。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ou"><img src="../Images/900ce4f347ae158c28e7c5d0fb18fa9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Usq0AFJRueuSs1KFjzfCA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:上传CSV文件。图片作者。</p></figure><ul class=""><li id="6789" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated"><em class="kk">内乌顿</em>根据数据集要求验证CSV文件。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ov"><img src="../Images/f786179712f9bcd76a10222d114cc7c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vqL_Ztwrgpp6hwmxsJWHsQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:数据集验证。图片作者。</p></figure><ul class=""><li id="8f13" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">如果CSV文件符合要求，将出现绿色复选标记，否则将显示错误消息。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ow"><img src="../Images/12c664660f8734b715743a2e4180f0a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FdTrh6uVaSVVPnjg_u7-RA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:经过验证的数据集。图片作者。</p></figure><ul class=""><li id="16f0" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">选择目标变量的列名(如<em class="kk"> target </em>，点击<em class="kk"> Next </em>)。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ox"><img src="../Images/dd42adbcb1d86554a5ad11b484b69953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOZHw4ksmeB4Lff6n5flDQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:目标变量。图片作者。</p></figure><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oy"><img src="../Images/d6c16a2111a697141a9c6c929975031d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oAzya2i7G5DauDYXS7x19Q.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:数据集内容预览。图片作者。</p></figure><h2 id="a9b8" class="ny mq iq bd mr of og dn mv oh oi dp mz lf oj ok nb lg ol om nd lh on oo nf op bi translated">培训:自动ML</h2><p id="771d" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">现在，让我们进入训练的核心！</p><ul class=""><li id="c40a" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated"><em class="kk">内乌顿</em>分析训练数据集的内容并定义ML任务类型。有了这个数据集，自动检测<strong class="kl ir">二元分类</strong>任务。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oz"><img src="../Images/648df08a180b841a3f47018e940e2ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtODAfV-lFJcNJkbPCgegw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:任务类型。图片作者。</p></figure><ul class=""><li id="2da3" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated"><strong class="kl ir">指标</strong>用于监控和测量模型在训练期间的表现。对于这个实验，您使用了<strong class="kl ir">准确性</strong>度量:它表示预测类的准确性。值越高，模型越好。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi oz"><img src="../Images/3f45e1f3c15c059955432310b9f43748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qRAXg-XiNYb5JXF_MBI2dw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:公制。图片作者。</p></figure><ul class=""><li id="19c1" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">启用<strong class="kl ir"> TinyML </strong>选项，允许<em class="kk">内乌顿</em>为微控制器构建一个微型模型。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ox"><img src="../Images/1e0eeebfb4f2898ea868b13e57eb88aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fxv8sZTfoeqZLZfhpygQ5g.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:TinyML选项。图片作者。</p></figure><ul class=""><li id="848f" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">在TinyML设置页面，在下拉菜单中选择“<strong class="kl ir"><em class="kk"/></strong>，并启用“<strong class="kl ir"> <em class="kk">【浮点数据类型支持】</em> </strong>选项。这是因为实验中使用的微控制器是支持浮点数的8位微控制器。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pa"><img src="../Images/8fb830e683e904f9ef6e734d4b15a08f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y0z3ax9W2Svbl3ZIFY9Ghw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:TinyML设置。图片作者。</p></figure><ul class=""><li id="a43f" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">按下“<em class="kk">开始训练</em>按钮后，您将看到进程进度条和完成百分比。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pb"><img src="../Images/8bd288bf4ef4392afc05a556c0309395.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GMOFqwTBIpkYYCyTg9k64Q.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:训练开始了。图片作者。</p></figure><ul class=""><li id="930e" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">第一步是<strong class="kl ir">数据预处理</strong>。它是准备(<em class="kk">清理、组织、改造等的过程。</em>)原始数据集，使其适合于训练和构建ML模型。</li><li id="5496" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">数据预处理完成后，模型训练开始。这个过程可能需要很长时间；您可以关闭窗口，并在该过程完成后返回。在训练期间，您可以通过观察<strong class="kl ir">模型状态</strong>(<em class="kk">一致</em>)或<em class="kk">不一致</em>)和<strong class="kl ir">目标度量</strong>值来监控实时模型性能。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pc"><img src="../Images/1d307035bea63b9bcf68bfff7fc68c4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qsDQZfAHZ_RqSXVxFjUZ1g.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:数据预处理完成。图片作者。</p></figure><ul class=""><li id="d01f" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">训练完成后，“<em class="kk">状态</em>将变为“<em class="kk">训练完成”</em>。模型是一致的，并已达到最佳预测能力。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pd"><img src="../Images/7248d9bfca1f4fd6ccc208f8d1f9749c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nOHRrBrmD1Al7sUa7JC4zA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:培训完成。图片作者。</p></figure><h2 id="08ee" class="ny mq iq bd mr of og dn mv oh oi dp mz lf oj ok nb lg ol om nd lh on oo nf op bi translated">预测:结果分析和模型下载</h2><p id="7292" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">就这样…模型做好了！</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ou"><img src="../Images/19da5f26da83f2c1f74fad6c40cecb47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*es3PWrUUNFXS02YW-UlgrQ.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:培训完成。图片作者。</p></figure><p id="d806" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">训练程序完成后，您将被重定向到<em class="kk">预测</em>部分。<br/>在本次实验中，模型达到了<strong class="kl ir"> 98% </strong>的准确率。这意味着从100条预测记录中，有98条被分配到了正确的类别……<em class="kk">真令人印象深刻！</em></p><p id="9950" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">而且要嵌入的模型大小小于<em class="kk"> 3KB </em>。<br/>考虑到正在使用的<em class="kk"> Arduino </em>板的内存大小为<em class="kk"> 256KB </em>，8位微控制器的典型内存大小为<em class="kk"> 64KB÷256KB </em>，这是一个非常小的尺寸。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pe"><img src="../Images/f950faf9114990266efd338a804d5c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17svP8qLN_GnfkecluHbIw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:度量。图片作者。</p></figure><p id="a891" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">要下载模型档案，点击<em class="kk">下载</em>按钮。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pf"><img src="../Images/7c40fab059151d8bfa53dea85a3203b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CnAg4lU0rv3d6-xCPnAjsA.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿:预测选项卡。图片作者。</p></figure><h1 id="3cfa" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">在Arduino上部署模型</h1><p id="2baa" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">现在，是时候将生成的模型嵌入微控制器中了。</p><p id="9328" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">从<em class="kk">内乌顿</em>下载的模型档案包括以下文件和文件夹:</p><ul class=""><li id="87ab" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">/ <strong class="kl ir">模型</strong> : <strong class="kl ir"> </strong>紧凑形式(十六进制和二进制)的神经网络模型。</li><li id="805d" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">/ <strong class="kl ir"> neuton </strong> : <strong class="kl ir"> </strong>用于执行预测、计算、数据传输、结果管理、<em class="kk">等的一组功能。</em></li><li id="1b94" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated"><strong class="kl ir"> user_app.c </strong>:一个文件，您可以在其中设置应用程序的逻辑来管理预测。</li></ul><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi pg"><img src="../Images/ecfc53b5fee7d8c4cb68664b9085136a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgsW56HQZ6tDkMDilPJb3A.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿模型档案馆。图片作者。</p></figure><p id="c542" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">首先，修改<strong class="kl ir"> user_app.c </strong>文件，添加初始化模型和运行推理的函数。</p><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="503c" class="ny mq iq nu b gy nz oa l ob oc">/*<br/> * Function: model_init<br/> * ----------------------------<br/> *<br/> *    returns: result of initialization (bool)<br/> */<br/>uint8_t <strong class="nu ir">model_init</strong>() {<br/>   uint8_t res;<br/> <br/>    res = <strong class="nu ir">CalculatorInit</strong>(&amp;neuralNet, NULL);<br/> <br/>    return (ERR_NO_ERROR == res);<br/>}</span><span id="8cb1" class="ny mq iq nu b gy od oa l ob oc">/*<br/> * Function: model_run_inference<br/> * ----------------------------<br/> *<br/> *   sample: input array to make prediction<br/> *   size_in: size of input array<br/> *   size_out: size of result array<br/> *<br/> *   returns: result of prediction<br/> */<br/>float* <strong class="nu ir">model_run_inference</strong>(float* sample, <br/>                           uint32_t size_in, <br/>                           uint32_t *size_out) {<br/>   if (!sample || !size_out)<br/>      return NULL;</span><span id="8d20" class="ny mq iq nu b gy od oa l ob oc">   if (size_in != neuralNet.inputsDim)<br/>      return NULL;</span><span id="5680" class="ny mq iq nu b gy od oa l ob oc">   *size_out = neuralNet.outputsDim;</span><span id="b37c" class="ny mq iq nu b gy od oa l ob oc">   return <strong class="nu ir">CalculatorRunInference</strong>(&amp;neuralNet, sample);<br/>}</span></pre><p id="9867" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">之后，创建<strong class="kl ir"> user_app.h </strong>头文件，允许主应用程序使用用户函数。</p><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="1474" class="ny mq iq nu b gy nz oa l ob oc">uint8_t <strong class="nu ir">model_init</strong>();<br/>float*  <strong class="nu ir">model_run_inference</strong>(float* sample, <br/>                            uint32_t size_in, <br/>                            uint32_t* size_out);</span></pre><p id="730e" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面是<em class="kk"> Arduino </em>主要应用示意图:</p><ul class=""><li id="e2cf" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">型号<strong class="kl ir">初始化</strong></li></ul><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="6f1b" class="ny mq iq nu b gy nz oa l ob oc">#include "src/Gesture Recognition_v1/<strong class="nu ir">user_app.h</strong>"</span><span id="0188" class="ny mq iq nu b gy od oa l ob oc">void <strong class="nu ir">setup</strong>() {<br/>   // init serial port and IMU sensor<br/>   // <em class="kk">[...]</em></span><span id="a214" class="ny mq iq nu b gy od oa l ob oc">   // init Neuton neural network model<br/>   if (!<strong class="nu ir">model_init</strong>()) {<br/>      Serial.print("Failed to initialize Neuton model!");<br/>      while (1) {<br/>        delay(10);<br/>      }<br/>   }<br/>}</span></pre><ul class=""><li id="ff8d" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">模型<strong class="kl ir">推理</strong></li></ul><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="da7d" class="ny mq iq nu b gy nz oa l ob oc">#define GESTURE_ARRAY_SIZE  (6*NUM_SAMPLES+1) </span><span id="a3bb" class="ny mq iq nu b gy od oa l ob oc">void <strong class="nu ir">loop</strong>() {<br/>   sensors_event_t a, g, temp;<br/>   float gestureArray[GESTURE_ARRAY_SIZE]  = {0};</span><span id="8ba9" class="ny mq iq nu b gy od oa l ob oc">   // wait for significant motion<br/>   // <em class="kk">[...]</em></span><span id="5c6c" class="ny mq iq nu b gy od oa l ob oc">   // read samples of the detected motion<br/>   while (samplesRead &lt; NUM_SAMPLES) {<br/>      // read the acceleration and gyroscope data<br/>      mpu.getEvent(&amp;a, &amp;g, &amp;temp);</span><span id="423c" class="ny mq iq nu b gy od oa l ob oc">      // fill gesture array (model input)<br/>      gestureArray[samplesRead*6 + 0] = a.acceleration.x;<br/>      gestureArray[samplesRead*6 + 1] = a.acceleration.y;<br/>      gestureArray[samplesRead*6 + 2] = a.acceleration.z;<br/>      gestureArray[samplesRead*6 + 3] = g.gyro.x;<br/>      gestureArray[samplesRead*6 + 4] = g.gyro.y;<br/>      gestureArray[samplesRead*6 + 5] = g.gyro.z;<br/>    <br/>      samplesRead++;<br/>    <br/>      delay(10);</span><span id="ffd8" class="ny mq iq nu b gy od oa l ob oc">      // check the end of gesture acquisition<br/>      if (samplesRead == <strong class="nu ir">NUM_SAMPLES</strong>) {<br/>         uint32_t size_out = 0;<br/>      <br/>         // run model inference<br/>         float* result = <strong class="nu ir">model_run_inference</strong>(gestureArray,  <br/>                                             GESTURE_ARRAY_SIZE, <br/>                                             &amp;size_out);</span><span id="aa77" class="ny mq iq nu b gy od oa l ob oc">         // check if model inference result is valid<br/>         if (result &amp;&amp; size_out) {<br/>            // check if problem is binary classification<br/>            if (size_out &gt;= <strong class="nu ir">2</strong>) { <br/>               // check if one of the result has &gt;50% of accuracy<br/>               if (result[0] &gt; <strong class="nu ir">0.5</strong>) {<br/>                  Serial.print(<strong class="nu ir">"Detected gesture: 0"</strong>); <br/>                  // <em class="kk">[...]</em><br/>               } else if (result[1] &gt; <strong class="nu ir">0.5</strong>) {<br/>                  Serial.print(<strong class="nu ir">"Detected gesture: 1"</strong>); <br/>                  // <em class="kk">[...]</em><br/>               } else { <br/>                  // solution is not reliable<br/>                  Serial.println("Detected gesture: NONE");<br/>               } <br/>            }<br/>         }<br/>     }<br/>   }<br/>}</span></pre><h1 id="bb19" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">行动模型！</h1><p id="a2cc" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated"><em class="kk">项目和代码准备好了！</em></p><pre class="lk ll lm ln gt nt nu nv nw aw nx bi"><span id="7dea" class="ny mq iq nu b gy nz oa l ob oc">/neuton_gesturerecognition<br/> |- /src<br/> | |- /Gesture Recognition_v1<br/> |   |- /model<br/> |   |- /neuton<br/> |   |- user_app.c<br/> |   |- user_app.h<br/> |- neuton_gesturerecognition.ino</span></pre><p id="6845" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">现在，是时候看看预测模型的运行了！</p><ul class=""><li id="871d" class="lw lx iq kl b km kn kp kq lf ly lg lz lh ma le nm mc md me bi translated">验证硬件系统设置是否正确</li><li id="eb4a" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">打开主应用程序文件</li><li id="5b7f" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">点击<em class="kk">验证</em>按钮，然后点击<em class="kk">上传</em>一</li><li id="5aee" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">打开<em class="kk">串行监视器</em></li><li id="b1fa" class="lw lx iq kl b km mf kp mg lf mh lg mi lh mj le nm mc md me bi translated">把你的硬件系统抓在手里，做一些动作。</li></ul><p id="3297" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">对于每个检测到的运动，模型将尝试猜测运动的类型(0<em class="kk">-击打</em>或1<em class="kk">-弯曲</em>)以及预测的准确性。如果预测的准确度低(<em class="kk"> 0.5 </em>)，则模型不做出决定。</p><p id="0d42" class="pw-post-body-paragraph ki kj iq kl b km kn jr ko kp kq ju kr lf kt ku kv lg kx ky kz lh lb lc ld le ij bi translated">下面是一个模型推理执行的例子:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi ph"><img src="../Images/abded23c2b0f0efeaa8edd35610594cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kpc2kOrFwCGcVQvjGdNbIw.jpeg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">内乌顿手势识别系统的串行监视器输出。图片作者。</p></figure><h1 id="208b" class="mp mq iq bd mr ms mt mu mv mw mx my mz jw na jx nb jz nc ka nd kc ne kd nf ng bi translated">…已经完成了？</h1><p id="539a" class="pw-post-body-paragraph ki kj iq kl b km nh jr ko kp ni ju kr lf nj ku kv lg nk ky kz lh nl lc ld le ij bi translated">用<em class="kk">内乌顿</em>做机器学习简单快捷。在低功耗8位微控制器上实现的模型精度和性能令人印象深刻！<br/> <em class="kk">内乌顿</em>适合快速原型开发。它允许用户专注于应用程序，避免在复杂的手动统计分析中浪费时间。</p><blockquote class="kf kg kh"><p id="5c9c" class="ki kj kk kl b km kn jr ko kp kq ju kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated"><a class="ae li" href="https://github.com/leonardocavagnis/GestureRecognition_Arduino_NeutonTinyML" rel="noopener ugc nofollow" target="_blank">在这里</a>，你可以找到本文描述的所有Arduino草图！</p></blockquote></div></div>    
</body>
</html>