<html>
<head>
<title>Feature Engineering with Image Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用图像数据的特征工程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-engineering-with-image-data-14fe4fcd4353#2022-12-05">https://towardsdatascience.com/feature-engineering-with-image-data-14fe4fcd4353#2022-12-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ae02" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">裁剪、灰度、RGB 通道、强度阈值、边缘检测和颜色过滤器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e3192850cbbb1769d5b4df0df7228f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wlme8xxSxucb57-IdI_8mA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(来源:<a class="ae ky" href="https://www.flaticon.com/free-icon/robotic-dog_9004669?related_id=9004669&amp;origin=pack" rel="noopener ugc nofollow" target="_blank"> flaticon </a>)</p></figure><p id="192e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了特征工程，我们马上会想到表格数据。然而，我们也可以获得图像数据的特征。目标是提取图像中最重要的部分。这样做将更容易找到我们的数据和目标变量之间的映射。</p><p id="8507" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着您可以使用更少的数据和训练更小的模型。较小的模型减少了进行预测所需的时间。这在边缘设备上部署时特别有用。一个额外的好处是，您可以更加确定您的模型使用什么来进行这些预测。</p><p id="d32f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将介绍使用 Python 进行影像要素工程的一些方法:</p><ul class=""><li id="723e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">种植</li><li id="b38f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">灰色鳞片</li><li id="b02e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">选择 RGB 通道</li><li id="2dd0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">强度阈值</li><li id="fafd" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">边缘检测</li><li id="4ec6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">滤色器(即提取给定颜色范围内的像素)</li></ul><p id="5b40" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了让事情变得有趣，我们将为自动驾驶汽车做这件事。如下图所示，我们想用一条赛道的图片来训练一个模型。然后，该模型将被用于预测指导汽车。最后，我们将讨论来自图像数据的特征工程的局限性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mj"><img src="../Images/1d59a816c86e4bf7dd545fb0881bb9b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lk3_e68IEnRPw8mEhvbXCA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">装有摄像头传感器自动驾驶汽车(来源:作者)</p></figure><h1 id="91b8" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">特征工程与增强</h1><p id="57b3" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">在我们深入研究之前，有必要讨论一下图像增强。这种方法与特征工程有相似的目标。然而，它以不同的方式实现它们。</p><h2 id="bb98" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">什么是数据增强？</h2><p id="fa77" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">数据扩充是指我们使用代码系统地或随机地改变数据。对于图像，这包括翻转、调整颜色和添加随机噪声等方法。这些方法允许我们人为地引入噪声并增加数据集的大小。如果你想了解更多关于图像增强的细节，我推荐这篇文章:</p><div class="nt nu gp gr nv nw"><a rel="noopener follow" target="_blank" href="/augmenting-images-for-deep-learning-3f1ea92a891c"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">增强深度学习的图像</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">使用 Python 通过翻转、调整亮度、颜色抖动和随机噪声来增加数据</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok ks nw"/></div></div></a></div><p id="a31d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在生产中，模型需要在不同的条件下运行。这些条件由照明、摄像机角度、房间颜色或背景中的物体等变量决定。</p><p id="37e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据扩充的目标是创建一个对这些条件的变化具有鲁棒性的模型。它通过添加模拟真实世界条件的噪声来做到这一点。例如，改变图像的亮度类似于在一天的不同时间收集数据。</p><p id="b014" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过增加数据集的大小，增强还允许我们训练更复杂的架构。换句话说，它有助于模型参数收敛。</p><h2 id="e148" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">使用图像数据的特征工程</h2><p id="5249" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">特征工程的目标是相似的。我们想创建一个更强大的模型。除了现在，我们去除任何对准确预测不必要的噪音。换句话说，我们去掉了随不同条件而变化的变量。</p><p id="0444" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过提取图像中最重要的方面，我们也简化了问题。这允许我们依赖更简单的模型架构。这意味着我们可以使用更小的数据集来找到输入和目标之间的映射。</p><p id="86da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个重要的区别是在生产中如何处理这些方法。您的模型不会对增强图像进行预测。然而，通过特征工程，您的模型将需要对其接受训练的相同特征进行预测。这意味着你必须能够在生产中进行特征工程。</p><h1 id="6652" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">使用 Python 进行影像特征工程</h1><p id="b91f" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">好了，记住所有这些，让我们继续特征工程。我们会检查代码，你也可以在<a class="ae ky" href="https://github.com/conorosully/medium-articles/blob/master/src/image_tools/image_features.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到这个项目。</p><p id="3db9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将使用下面的导入。我们有一些标准包装(第 2-3 行)。<strong class="lb iu"> Glob </strong>用于处理文件路径(第 5 行)。我们还有一些用来处理图像的包(第 7-8 行)。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="c349" class="oq ml it om b be or os l ot ou">#Imports <br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/><br/>import glob<br/><br/>from PIL import Image<br/>import cv2</span></pre><p id="2a86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，我们将使用用于驱动自动汽车的图像。你可以在<a class="ae ky" href="https://www.kaggle.com/datasets/conorsully1/jatracer-images?select=object_detection" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到这些例子。我们用下面的代码加载其中一个图像。我们首先加载所有图像的文件路径(第 2–3 行)。然后加载(第 8 行)并显示(第 9 行)第一个路径的图像。你可以在<strong class="lb iu">图 1 </strong>中看到这个图像。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="86c6" class="oq ml it om b be or os l ot ou">#Load image paths<br/>read_path = "../../data/direction/"<br/>img_paths = glob.glob(read_path + "*.jpg")<br/><br/>fig = plt.figure(figsize=(10,10))<br/><br/>#Display image<br/>img = Image.open(img_paths[0])<br/>plt.imshow(img) </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/0f88ecd2f8f9497e2c998d28193334d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*6qs6iY-9eS48NjCV8DgWHw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:轨迹图像示例(来源:作者)</p></figure><h2 id="e4d1" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">种植</h2><p id="c8d1" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">一个简单的方法是裁剪图像以移除不想要的外部区域。目的是仅移除预测不需要的图像部分。对于我们的自动汽车，我们可以从背景中去除像素。</p><p id="67f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们加载一个图像(第 2 行)。然后，我们将这个图像转换成一个数组(第 5 行)。该阵列的尺寸为 224 x 224 x 3。图像的高度和宽度是 224 像素，每个像素有一个 R G B 通道。为了裁剪图像，我们只选择 y 轴上从位置 25 开始的像素(第 8 行)。你可以在<strong class="lb iu">图 2 </strong>中看到结果。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="11cc" class="oq ml it om b be or os l ot ou">#Load image<br/>img = Image.open(img_paths[609])<br/><br/>#Covert to array<br/>img = np.array(img)<br/><br/>#Simple crop<br/>crop_img = img[25:,]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/4fd41e19238193be32bb977bbeadb8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*52SOFt9hW_LGuySKokSLJg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:裁剪图像(来源:作者)</p></figure><p id="9f2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能想保持长宽比。在这种情况下，您可以通过将不需要的像素变黑(第 3 行)来获得类似的结果。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="5e08" class="oq ml it om b be or os l ot ou">#Change pixels to black<br/>crop_img = np.array(img)<br/>crop_img[:25,] = [0,0,0]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/aabf2082a078409b2a31f40ae25a1ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*8y3xzfPAxG7UmgoB7VO06g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3:通过改变像素颜色进行裁剪(来源:作者)</p></figure><p id="2582" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过裁剪，我们删除了不必要的像素。我们还可以避免模型过度拟合训练数据。例如，背景中的椅子可能出现在所有左转处。因此，模型可以将这些与左转预测相关联。</p><p id="40e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看着上面的图像，你可能会忍不住进一步裁剪它。也就是说，您可以在不移除任何轨道的情况下裁剪图像的左侧。然而，在<strong class="lb iu">图 4 </strong>中，你可以看到，对于其他图像，我们将移除轨道的重要部分。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="5450" class="oq ml it om b be or os l ot ou">#Additional cropping <br/>crop_img = np.array(img)<br/>crop_img[:25,] = [0,0,0]<br/>crop_img[:,:40] = [0,0,0]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/778a7e021c71341caefef02f6a011c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*u3w-4FUGxSSUZlQSehLtMg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 4:糟糕的裁剪示例(来源:作者)</p></figure><p id="3097" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这又回到了特性工程需要在产品中完成的问题上。这里你不知道什么图像将在什么时间显示给模型。这意味着相同的裁剪功能将需要应用于所有图像。你需要确保它永远不会删除图像的重要部分。</p><h2 id="9d17" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">灰度等级</h2><p id="1a78" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">对于某些应用，图像的颜色并不重要。在这种情况下，我们可以对图像进行灰度处理。我们用 OpenCV 中的<strong class="lb iu"> cvtColor </strong>函数来做这件事(第 2 行)。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="04c0" class="oq ml it om b be or os l ot ou">#Gray scale<br/>gray_img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/eb60488165267bb38d853832aceaa5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*E2G-x9nxvahYZFa06yWT4Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5:图像灰度(来源:作者)</p></figure><p id="ade2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">灰度是通过捕捉图像的颜色强度来实现的。这是通过对 RGB 通道进行加权平均来实现的。具体来说，上面的函数使用以下公式:</p><p id="3532" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">Y</strong>= 0.299 *<strong class="lb iu">R</strong>+0.587 *<strong class="lb iu">G</strong>+0.114 *<strong class="lb iu">B</strong></p><p id="c6e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过查看每个图像的输入值的数量来理解这样做的好处。如果我们使用所有 RGB 通道，它将由<strong class="lb iu"> 150，528 </strong>个值组成(224*224*3)。对于灰度图像，我们现在只有<strong class="lb iu"> 50，176 </strong>个值(224*224)。更简单的输入意味着我们需要更少的数据和更简单的模型。</p><h2 id="7ac0" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">RGB 通道</h2><p id="43bd" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">其中一个渠道可能更重要。我们可以只使用那个通道，而不是灰度。下面，我们选择 R(线 6)、G(线 7)和 B(线 8)通道。每个结果数组的大小都是 224 x 224。您可以在<strong class="lb iu">图 6 </strong>中看到各自的图像。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="d570" class="oq ml it om b be or os l ot ou">#Load image<br/>img = Image.open(img_paths[700])<br/>img = np.array(img)<br/><br/>#Get rgb channels<br/>r_img = img[:, :, 0]<br/>g_img = img[:, :, 1]<br/>b_img = img[:, :, 2]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/bb94c13069b358e80026a812bde97e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JeZa4Rwmeg7EZ1vFxsa6_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6: RGB 通道(来源:作者)</p></figure><p id="3328" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您也可以使用<strong class="lb iu">通道 _ 过滤器</strong>功能。这里，通道参数(c)将根据您想要的通道取值为 0、1 或 2。请记住，有些包会以不同的顺序加载频道。我们使用的是 RGB 的 PIL。但是，如果用 cv2.imread()加载图像，通道将按照 BGR 顺序排列。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="f6fe" class="oq ml it om b be or os l ot ou">def channel_filter(img,c=0):<br/>    """Returns given channel from image pixels"""<br/>    img = np.array(img)<br/>    c_img = img[:, :, c]<br/><br/>    return c_img</span></pre><p id="93e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过这些转换，您需要考虑是否从图像中删除了重要信息。对于我们的应用程序，轨道是橙色的。换句话说，轨道的颜色有助于将其与图像的其他部分区分开来。</p><h2 id="15ac" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">强度阈值</h2><p id="d05b" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">使用灰度时，每个像素的值将在 0 到 255 之间。我们可以通过将输入转换成二进制值来进一步简化输入。如果灰度值高于截止值，像素值为 1，否则为 0。我们称这个截止点为强度阈值。</p><p id="7f10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的函数用于应用该阈值。我们首先对图像进行灰度处理(第 5 行)。如果像素高于截止值，则其值为 1000(第 8 行)。如果我们将像素设置为 1，它将低于截止值。换句话说，在下一步(第 9 行)中，所有像素都将被设置为 0。最后，我们缩放所有像素，使它们取值为 0 或 1(第 11 行)。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="76de" class="oq ml it om b be or os l ot ou">def threshold(img,cutoff=80):<br/>    """Apply intesity thresholding"""<br/>    <br/>    img = np.array(img)<br/>    img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)<br/>    <br/>    #Apply cutoff<br/>    img[img&gt;cutoff] = 1000 #black<br/>    img[img&lt;=cutoff] = 0 #white<br/>    <br/>    img = img/1000<br/><br/>    return img</span></pre><p id="2ce7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自动汽车项目的一部分是避开障碍物。这些是涂成黑色的罐子。在<strong class="lb iu">图 7 </strong>中，您可以看到如何应用强度阈值函数将 tin 从图像的其余部分中分离出来。这是唯一可能的，因为锡是黑色的。换句话说，它的强度大于图像的其余部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/64781ca919e1200b089ffbfe26aee868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-PNaFxqoenPcWjTnsz4hw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 7:具有强度阈值的特征工程(来源:作者)</p></figure><p id="a292" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">截止值可以被视为一个超参数。参见图 7，截止值越大，意味着我们包含的背景噪声越少。不利的一面是我们捕获的罐头更少了。</p><h2 id="4f7b" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">边缘检测</h2><p id="3f63" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">如果我们想分离轨迹，我们可以使用 canny 边缘检测。这是一种用于检测图像边缘的多阶段算法。如果你想了解它是如何工作的，我建议阅读<a class="pa pb ep" href="https://medium.com/u/4c917479ce84?source=post_page-----14fe4fcd4353--------------------------------" rel="noopener" target="_blank">索菲安·萨希尔</a>关于<a class="ae ky" rel="noopener" target="_blank" href="/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123">精明边缘检测</a>的文章。</p><p id="0fd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将该算法应用于<strong class="lb iu"> cv2。Canny </strong>()函数。<strong class="lb iu">阈值 1 </strong>和<strong class="lb iu">阈值 2 </strong>参数用于迟滞程序。这是边缘检测算法的最后一步，用于确定哪些线实际上是边缘。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="fc29" class="oq ml it om b be or os l ot ou">#Apply canny edge detection<br/>edge_img = cv2.Canny(img,threshold1 = 50, threshold2 = 80)</span></pre><p id="cd3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在图 8 中看到一些例子。像强度阈值处理一样，我们只剩下一个二值图——白色代表边缘，黑色代表其他。希望这个轨迹现在更容易与图像的其他部分区分开来。但是，您可以看到背景中的边缘也被检测到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/acfdc209267dd25acbc2d7d3b173bd45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*ArwvoNmX7y6wvHFG7sopcQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 8: canny 边缘检测(来源:作者)</p></figure><h2 id="e4a8" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">滤色器</h2><p id="03be" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们可能会有更好的运气，通过使用像素颜色来隔离轨迹。我们使用下面的<strong class="lb iu"> pixel_filter </strong>函数来实现。使用<strong class="lb iu"> cv2.inRange </strong>()我们将图像转换成二进制图(第 10 行)。这个函数检查一个像素是否落在下面(第 5 行)和上面(第 6 行)列表给定的范围内。具体来说，每个 RGB 通道必须在各自的范围内(例如 134-t ≤ R ≤ 194+t)。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="a8ef" class="oq ml it om b be or os l ot ou">def pixel_filter(img, t=0):<br/>    <br/>    """Filter pixels within range"""<br/>    <br/>    lower = [134-t,84-t,55-t]<br/>    upper = [192+t,121+t,101+t]<br/><br/>    img = np.array(img)<br/>    orange_thresh = 255 - cv2.inRange(img, np.array(lower), np.array(upper))<br/><br/>    return orange_thresh</span></pre><p id="bbd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单地说，该函数确定像素颜色是否足够接近轨道的橙色。你可以在<strong class="lb iu">图 9 </strong>中看到结果。测试参数引入了一些灵活性。使用较高的值，我们可以捕捉更多的轨迹，但保留更多的噪声。这是因为背景中的像素将落在该范围内。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/8632a7f2c68c01b78a21ba52d2bbfc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hoHzppA791L4hSIGEeYPEw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 9:过滤橙色像素(来源:作者)</p></figure><p id="c25f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能想知道我们从哪里得到下限和上限。这就是我们如何知道通道将落在[134，84，55]和[192，121，101]之间？嗯，我们使用 Python 创建的颜色选择器。我们在下面的文章中概述了这是如何创建的。</p><div class="nt nu gp gr nv nw"><a rel="noopener follow" target="_blank" href="/building-a-color-picker-with-python-55e8357539e7"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">用 Python 构建颜色选择器</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">创建一个从图像像素中选择 RGB 通道的工具</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="pd l oh oi oj of ok ks nw"/></div></div></a></div><p id="1df7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<strong class="lb iu">图 10 </strong>中，您可以看到拾取器正在工作。我们从多个图像中选择像素，并尝试在轨道上的不同位置选择它们。这是为了在不同条件下获得全范围的像素值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/6f1a407f696029c1dfe10dc47247af3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*V_ZsJrg-0YWGOCqCFXXQsw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 10:从轨道上挑选颜色(来源:作者)</p></figure><p id="025a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们总共选择了 60 种颜色。这些你都可以在<strong class="lb iu">图 11 </strong>(带加成视错觉)中看到。所有这些颜色的 RGB 通道都存储在一个名为“颜色”的列表中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/c3c75b6d4f369328a314c679e37c77e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4TLK9mpWQrkI1Pym6fX4SA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 11:用拾色器选择的 60 个轨迹像素</p></figure><p id="e0f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们取每个 RGB 通道的最小值和最大值。这给出了下限和上限。</p><pre class="kj kk kl km gt ol om on bn oo op bi"><span id="426d" class="oq ml it om b be or os l ot ou">lower = [min(x[0] for x in colours),<br/>              min(x[1] for x in colours),<br/>              min(x[2] for x in colours)]<br/><br/>upper = [max(x[0] for x in colours),<br/>              max(x[1] for x in colours),<br/>              max(x[2] for x in colours)]</span></pre><h1 id="f1e1" class="mk ml it bd mm mn mo mp mq mr ms mt mu jz mv ka mw kc mx kd my kf mz kg na nb bi translated">特征工程的局限性</h1><p id="1e39" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">经过这一切，你可能不相信。深度学习的一个主要好处是，它可以识别复杂的模式，而不需要特征工程。这是一个很好的观点。</p><p id="3952" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征工程需要批判性思维。你需要弄清楚图像的哪些方面是重要的。然后，您需要编写代码来提取这些方面。对于某些应用程序来说，完成所有这些所需的时间毫无意义。</p><p id="b485" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，对于一些方法，我们已经看到，我们不能消除所有的噪音。例如，强度阈值中的黑色背景。与直觉相反的是，残留的噪音现在可能更难区分什么是重要的。也就是说，剩余的噪声和对象像素具有相同的值(1)。</p><p id="ec27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">真的，当处理相对简单的计算机视觉问题时，好处就来了。我们的轨迹从不改变，物体的颜色也总是一样。对于更复杂的问题，你将需要更多的数据。或者，您可以在较小的数据集上微调预训练模型。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="3d13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢这篇文章！你可以成为我的<a class="ae ky" href="https://conorosullyds.medium.com/membership" rel="noopener"> <strong class="lb iu">推荐会员</strong> </a> <strong class="lb iu"> :) </strong>来支持我</p><div class="nt nu gp gr nv nw"><a href="https://conorosullyds.medium.com/membership" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">通过我的推荐链接加入 Medium 康纳·奥沙利文</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">conorosullyds.medium.com</p></div></div><div class="of l"><div class="pn l oh oi oj of ok ks nw"/></div></div></a></div><p id="7356" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">| <a class="ae ky" href="https://twitter.com/conorosullyDS" rel="noopener ugc nofollow" target="_blank">推特</a> | <a class="ae ky" href="https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w" rel="noopener ugc nofollow" target="_blank"> YouTube </a> | <a class="ae ky" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank">时事通讯</a> —注册免费参加<a class="ae ky" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> Python SHAP 课程</a></p><h2 id="1378" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">图像来源</h2><p id="4c46" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">所有图片都是我自己的或从<a class="ae ky" href="http://www.flaticon.com/" rel="noopener ugc nofollow" target="_blank">www.flaticon.com</a>获得。在后者的情况下，我拥有他们的<a class="ae ky" href="https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-" rel="noopener ugc nofollow" target="_blank">保费计划</a>中定义的“完全许可”。</p><h2 id="ac87" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">资料组</h2><p id="e11d" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated"><strong class="lb iu"> JatRacer 图片</strong> (CC0:公共领域)<a class="ae ky" href="https://www.kaggle.com/datasets/conorsully1/jatracer-images" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets/conorsully1/jatracer-images</a></p><h2 id="b905" class="nh ml it bd mm ni nj dn mq nk nl dp mu li nm nn mw lm no np my lq nq nr na ns bi translated">参考</h2><p id="4958" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">OpenCV，<strong class="lb iu">颜色转换</strong><a class="ae ky" href="https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html" rel="noopener ugc nofollow" target="_blank">https://docs . OpenCV . org/3.4/de/d25/imgproc _ Color _ conversions . html</a></p></div></div>    
</body>
</html>