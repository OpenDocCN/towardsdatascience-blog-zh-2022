<html>
<head>
<title>Are we *under-hyping* AI?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们是否低估了人工智能？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/are-we-under-hyping-ai-cf680dd48b43#2022-03-02">https://towardsdatascience.com/are-we-under-hyping-ai-cf680dd48b43#2022-03-02</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="2133" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank">播客</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">山姆·鲍曼论 AGI，它的潜力和它的安全风险</h2></div><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="kv kw l"/></div></figure><p id="a1ba" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated"><em class="lt">编者按:TDS 播客由杰雷米·哈里斯主持，他是人工智能安全初创公司墨丘利的联合创始人。每周，Jeremie 都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。</em></p></div><div class="ab cl lu lv hw lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="il im in io ip"><p id="7060" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">在谷歌上搜索“人工智能被过度炒作了”这个词，你会找到几十篇文章，来自<em class="lt">《福布斯》</em>、<em class="lt">《连线》</em>和<em class="lt">《科学美国人》</em>，它们都认为“人工智能并不像外表看起来那么令人印象深刻，”以及“在我们拿出真正的人工智能之前，我们还有很长的路要走，你不知道吗。”</p><p id="f477" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">有趣的是，尽管“人工智能被过度炒作”的说法很普遍，但“我们在人工智能方面没有像 think™️那样取得很大进展”的说法往往被框定为某种程度上是一种令人难以置信的尖锐对立的东西。</p><p id="d2e0" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">所有那些不要过度宣传人工智能研究的压力确实影响到了人们——包括研究人员。他们也相应地调整了自己的行为:他们过分回避自己的主张，引用过时的和已经解决的人工智能系统故障模式，通常避免在明确显示人工智能进步全面爆发的点之间画直线。大概都是为了避免被视为人工智能过度爱好者。</p><p id="11f6" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">为什么这很重要？首先，被大肆宣传的人工智能让我们能够保持睡眠——推迟回答许多基本的社会问题，这些问题是在劳动力广泛自动化的情况下出现的。但也许更重要的是，它降低了解决人工智能安全和人工智能对齐关键问题的紧迫感。</p><p id="f99b" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">是的，我们需要小心不要过度宣传人工智能。不使用 AI 的“AI 创业公司”是个问题。人工通用智能几乎肯定要一年后才会出现的预测是一个问题。自信地预言短期内的重大突破绝对会损害该领域的可信度。</p><p id="e5fd" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">但与此同时，我们不能让自己如此谨慎，以至于我们没有准确地传达人工智能进步和潜力的真实程度。那么什么才是正确的平衡呢？</p><p id="d261" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">这就是山姆·鲍曼的切入点。山姆是 NYU 大学的教授，他在那里从事人工智能和语言建模的研究。但对今天的目的来说最重要的是，他是一篇题为“当打击人工智能炒作时，谨慎行事”的论文的作者，在这篇论文中，他探索了一种他称为<em class="lt">的趋势，即低估</em>——研究人员的一种常见做法，包括低估当前人工智能能力的程度，以及以可能(无意中)具有欺骗性的方式过度强调故障模式。</p><p id="9f01" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">在本期“走向数据科学”播客中，Sam 和我一起讨论了“声称不足”及其对人工智能进步的意义。以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="e159" class="mb mc is kz b la lb ld le lg md lk me lo mf ls mg mh mi mj bi translated">萨姆指出，研究人员经常会指向那些探索旧人工智能系统故障模式的过时论文——这些故障模式在现代系统中的持久性尚未得到证明。作为一个例子，他指出<a class="ae mk" href="https://aclanthology.org/D17-1215/" rel="noopener ugc nofollow" target="_blank">贾和</a> (2017)，他们强调了当时流行的语言模型在阅读理解任务中令人惊讶的局限性。贾和梁的文章至今仍被大量引用，暗示当前的人工智能系统也有类似的故障点。但就人工智能而言，2017 年是一个永恒的过去，而且关键的是，它领先于从 2018 年开始彻底改变语言建模的整个变形金刚和基础模型时代。</li><li id="61df" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">另一个用来淡化人工智能能力的常见论点是这样的说法，“人工智能系统可能能够做出很好的预测，但它们并不真正理解任何东西，你知道。不像，<em class="lt">真的懂</em>这一论点通常没有首先定义“理解”是什么意思，也没有解释为什么由人脑进行的统计推断可以称为“理解”，而由机器(通常具有超人的性能)进行的非常相似的过程则不能。</li><li id="1056" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">萨姆归为“索赔不足”一类的第三个趋势是<em class="lt">对抗性数据收集</em>。当研究人员开发旨在探测新模型弱点的基准时，就会发生这种情况。这通常包括寻找令人尴尬的模型失败的例子——比如对人类来说似乎容易分类的句子的错误分类。对抗性的数据收集会通过强调故障点使高性能系统显得“愚笨”,其代价是忽略了我们在比例模型中看到的大画面、定性性能爆炸。</li><li id="aff5" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">Sam 还为那些想以负责任的方式(而不是过度补偿)对抗索赔不足趋势的研究人员分享了一些想法。).</li></ul><p id="9e7e" class="pw-post-body-paragraph kx ky is kz b la lb kc lc ld le kf lf lg lh li lj lk ll lm ln lo lp lq lr ls il bi translated">你可以<a class="ae mk" href="https://twitter.com/sleepinyourhat" rel="noopener ugc nofollow" target="_blank">在 Twitter 上关注 Sam 这里</a>，或者<a class="ae mk" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank"> me 这里</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/a0c9c0ef24cc510f96b40c3748340926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vIdemz7behYJflLViCN6MQ.png"/></div></div></figure><h2 id="fd8b" class="mx my is bd mz na nb dn nc nd ne dp nf lg ng nh ni lk nj nk nl lo nm nn no iy bi translated">章节:</h2><ul class=""><li id="de3f" class="mb mc is kz b la np ld nq lg nr lk ns lo nt ls mg mh mi mj bi translated">0:00 介绍</li><li id="6901" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">2:15 论文概述</li><li id="2e58" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">8:50 令人失望的系统</li><li id="2fcb" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">13:05 潜在的双重标准</li><li id="9a50" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">19:00 远离多模态</li><li id="d4a9" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">23:50 总体影响</li><li id="ed76" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">28:15 出版或灭亡的压力</li><li id="f371" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">32:00 公告差异</li><li id="d1f4" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">36:15 政策角度</li><li id="37d3" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">41:00 建议</li><li id="48a2" class="mb mc is kz b la ml ld mm lg mn lk mo lo mp ls mg mh mi mj bi translated">47:20 总结</li></ul></div></div>    
</body>
</html>