<html>
<head>
<title>What Happens When You Omit Important Variables From Your Regression Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当你忽略回归模型中的重要变量时会发生什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53#2022-04-22">https://towardsdatascience.com/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53#2022-04-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/0733f1a1c9db362bd3ce88a46175693a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*MYFwqPVP4hp05PZZ78lJog.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">省略可变偏差(图片由作者提供)</p></figure><div class=""/><div class=""><h2 id="0826" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">我们将了解什么是遗漏变量偏差，并使用真实数据集说明其计算</h2></div><p id="67d0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将研究在线性回归模型中没有包括重要变量的后果。举例来说，我们将基于汽车特征的真实世界数据集进行讨论。我们的目标是在统计建模中形成一个众所周知的结果，称为<strong class="ks jc">省略变量偏差</strong>，并使用样本数据集说明计算。</p><h1 id="4bd3" class="lm ln jb bd lo lp lq lr ls lt lu lv lw kh lx ki ly kk lz kl ma kn mb ko mc md bi translated">汽车数据集</h1><p id="b817" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated">以下数据包含205辆汽车的规格，摘自1985年版的沃德汽车年鉴。每行包含一组26个关于单个车辆的规格。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mj"><img src="../Images/3a267171b220510400c8104ce37d4a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_wc0IJBq2-DEoeXlOn9hZg.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">汽车数据集(来源:<a class="ae ms" href="https://archive.ics.uci.edu/ml/datasets/automobile" rel="noopener ugc nofollow" target="_blank">加州大学欧文分校</a></p></figure><p id="78a2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将考虑由以下变量组成的数据子集:<br/>城市_英里数<br/>汽车_体积<br/>整备质量<br/>发动机_尺寸</p><p id="11d4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">原始数据集中不存在Car_Volume变量。它是我们添加的一个新变量，如下:Car_Volume = Length*Width*Height。</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/6801b0692cd7ae1de11a976201c9185b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*NWHXBqmVluO0jbrnDEag6A.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">汽车数据集的子集(来源:<a class="ae ms" href="https://archive.ics.uci.edu/ml/datasets/automobile" rel="noopener ugc nofollow" target="_blank">加州大学欧文分校</a>)</p></figure><p id="78dc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">上述4变量版本的数据集可从此处 下载<a class="ae ms" href="https://gist.github.com/sachinsdate/bd617730c4655a01779e1dd86ff30bbe" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc">。</strong></a></p><h2 id="de41" class="mu ln jb bd lo mv mw dn ls mx my dp lw kz mz na ly ld nb nc ma lh nd ne mc nf bi translated">回归目标</h2><p id="462c" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated">我们的回归目标是使用<strong class="ks jc">线性回归模型</strong>回归<strong class="ks jc">发动机尺寸</strong>和<strong class="ks jc">整备质量</strong>的<strong class="ks jc">城市行驶里程</strong>。模型方程为:</p><p id="9797" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">city _ mpg =β_ 1</em><strong class="ks jc"><em class="ng">+</em></strong><em class="ng">β_ 2 *汽车_体积+β_ 3 *整备_重量+β_ 4 *发动机_尺寸+ ϵ </em></p><p id="666e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">回归模型的误差项<em class="ng"> ϵ </em>代表建模者无法测量的所有因素的影响。</p><p id="45e7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">上述方程的矩阵形式如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nh"><img src="../Images/7e058c157ec013ee8c6ec4365dec7bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*1-rutqA9QO-2w4l-LWdt3w.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">线性回归模型的方程(图片由作者提供)</p></figure><p id="e80d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">哪里，</em></p><ul class=""><li id="994a" class="ni nj jb ks b kt ku kw kx kz nk ld nl lh nm ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> y </em> </strong>是一个<em class="ng">【n×1】</em>大小的列向量，包含<em class="ng"> City_MPG的观测值。n </em>是数据点的数量。</li><li id="54e4" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> β </em> </strong>是一个<em class="ng">【4×1】</em>大小的回归模型系数列向量<em class="ng"> β_1、β_2、β_3 </em>、<em class="ng"> β_4 </em>对应于<em class="ng">截距、汽车_体积、整备_重量</em>和<em class="ng">发动机_大小。</em></li><li id="bd21" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"><em class="ng"/></strong>是一个<em class="ng">【n×4】</em>大小的矩阵，包含回归变量的值。这个矩阵的第一列是1的列，它充当截距<em class="ng"> β_1的占位符。</em></li><li id="9148" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"><em class="ng"/></strong>是模型的回归误差的一个<em class="ng">【n×1】</em>大小的列向量。</li></ul><p id="50dc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们用矩阵来说明回归模型的方程是怎样的:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/a7887ad333868e13bd7bc83c33e12378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*TNARDNxr-oO0b0h0an6k6Q.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">包含三个变量和一个截距的线性回归模型(图片由作者提供)</p></figure><p id="833e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在<strong class="ks jc"> <em class="ng"> X </em> </strong>矩阵中，由列向量<strong class="ks jc"><em class="ng">X _ 1 =</em></strong><em class="ng">【X _ 11，…X _ n1】'</em>表示的第一列是1的列。假设样本量为<em class="ng"> n </em>，上述矩阵表示等价于写出以下<em class="ng"> n </em>回归方程组:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/7f83538bb562a144533be37913e93059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*wbE-DbgQd2GeMFwZi4GoPg.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">四个变量和误差项的n个回归方程系统(图片由作者提供)</p></figure><p id="cb23" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，假设我们将这个方程组分成两部分，如下所示:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/6c3893e83b1fe8d7fe8982b4985c27e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*hBTQEq1iQK13iZq_Y5v5PA.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">分成两部分的n方程系统(图片由作者提供)</p></figure><p id="2d13" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下面是上述划分的矩阵表示:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ny"><img src="../Images/c637a5afcba2b3abfa4e267c19f54667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mnq0xKFLYCsExrzkx7VZ0A.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">分成两部分的n方程系统(图片由作者提供)</p></figure><p id="d62d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一般来说，我们可以将上述划分表示如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/abc5dcbde245bdf630578d86147baf89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*wV_dPF8_lvmzY5ZpzKXkjA.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">分区线性回归模型(图片由作者提供)</p></figure><p id="057e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们已经用变量<strong class="ks jc"><em class="ng"/></strong>替换了分割出来的回归变量<strong class="ks jc"><em class="ng">x</em></strong><em class="ng">_ 4</em>，这是一个<em class="ng">【n×1】</em>列向量。<strong class="ks jc"><em class="ng">γ</em></strong><em class="ng"/>(γ)是代替回归系数<em class="ng"> β_4的<em class="ng">【1×1】</em>“矩阵”。</em></p><p id="0718" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当一个人在一组<em class="ng"> n </em>个样本的数据集上训练(也称为“拟合”)上述线性模型时，拟合的模型可以表示如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/5ca2607ea6bdd7c2fc285d2bd6cc503a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*69wqxvBDs_KrpKLVVnM_LQ.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated"><strong class="bd ob">拟合的</strong>分段线性回归模型(图片由作者提供)</p></figure><p id="5d29" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">注意<strong class="ks jc"><em class="ng"/></strong><em class="ng"/>和<strong class="ks jc"> <em class="ng"> γ </em> </strong>上的帽或帽子“^”符号表示它们是拟合值，即<strong class="ks jc"> <em class="ng"> β </em> </strong> <em class="ng"> </em>和<strong class="ks jc"> <em class="ng"> γ </em> </strong>的相应群体水平值的估计值。同样在等式(2)中，残差的列向量<strong class="ks jc"> <em class="ng"> e </em> </strong>代替回归误差的列向量<strong class="ks jc"> <em class="ng"> ϵ.</em></strong><em class="ng">带</em>残差<em class="ng"> e_i </em>是带观测值<em class="ng"> y_i </em>的<em class="ng">和来自拟合模型的对应<em class="ng">带</em>预测值之间的差值。</em></p><p id="29f4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们现在已经为解决当你忽略回归变量时会发生什么的问题做好了准备。</p><h1 id="6163" class="lm ln jb bd lo lp lq lr ls lt lu lv lw kh lx ki ly kk lz kl ma kn mb ko mc md bi translated">省略回归变量的影响</h1><p id="92d8" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated">让我们重新看看汽车数据集的回归模型:</p><p id="e196" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">city _ mpg =β_ 1</em><strong class="ks jc"><em class="ng">+</em></strong><em class="ng">β_ 2 *汽车_体积+β_ 3 *整备_重量+β_ 4 *发动机_尺寸+ ϵ </em></p><p id="4477" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">以下是拟合模型的方程式:</p><p id="55ea" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">City _ MPG =β_ 1 _ cap</em><strong class="ks jc"><em class="ng">+</em></strong><em class="ng">β_ 2 _ cap *汽车_体积+β_ 3 _ cap *整备_重量+β_ 4 _ cap *发动机_尺寸+ e </em></p><p id="d3d8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">假设我们在构建模型时没有包含变量<em class="ng"> Engine_Size </em>。这类似于从等式(1)中省去项<strong class="ks jc"> <em class="ng"> zγ </em> </strong>或者从等式(2)中省去项<strong class="ks jc"> <em class="ng"> zγ_cap </em> </strong>。</p><p id="ecf6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果我们求解方程(2)的其余部分，即<strong class="ks jc"><em class="ng">y</em></strong><em class="ng">=</em><strong class="ks jc"><em class="ng">xβ_ cap</em></strong><em class="ng">+</em><strong class="ks jc"><em class="ng">e</em></strong>，通过最小化残差的平方和<strong class="ks jc"> <em class="ng"> e </em> </strong>，它具有一个漂亮的闭合形式解，可以表示为</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/49e9987ea86eebc1624208fdbacb86cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*jJOtlitCdoYHA-B5UPflCA.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated"><strong class="bd ob"><em class="od">y</em></strong><em class="od">=</em><strong class="bd ob"><em class="od">xβ_ cap</em></strong><em class="od">+</em><em class="od">e</em><em class="od">(图片由作者提供)</em></p></figure><p id="ae36" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上面的等式中:</p><ul class=""><li id="6cf2" class="ni nj jb ks b kt ku kw kx kz nk ld nl lh nm ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> β_cap </em> </strong>是大小为<em class="ng">(k×1)</em>的拟合回归系数的列向量，假设模型中有<em class="ng"> k个</em>回归变量，包括截距，但不包括我们忽略的变量。</li><li id="cb86" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> X </em> </strong>是大小为<em class="ng"> (n x k) </em>的回归变量矩阵。</li><li id="883e" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> X' </em> </strong>是<strong class="ks jc">X</strong>的转置，即<strong class="ks jc"> <em class="ng"> X </em> </strong>的行列互换。就好像<strong class="ks jc"> <em class="ng"> X </em> </strong>已经侧过来了。因此<strong class="ks jc"> <em class="ng"> X' </em> </strong>的大小为<em class="ng">(k×n)</em>。因此，<strong class="ks jc"> <em class="ng"> X'X </em> </strong>的大小为<em class="ng"> (k x k) </em>。回想一下大小为<em class="ng">(k x n)</em><em class="ng">(n x k)</em>的两个矩阵的乘积是大小为<em class="ng"> (k x k) </em>的矩阵。</li><li id="cfda" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> y </em> </strong>是大小为<em class="ng">(n×1)</em>的观测值的列向量。</li></ul><p id="e8c5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">(</em><strong class="ks jc"><em class="ng">X ' X</em></strong><em class="ng">)</em>，大小为<em class="ng"> (k x k) </em>，当与大小为<em class="ng"> (k x n) </em>的<strong class="ks jc"><em class="ng">【X '</em></strong>相乘时，产生大小为<em class="ng"> (k x n) </em>的矩阵，当与大小为<strong class="ks jc"> <em class="ng"> y </em> </strong>相乘时</p><p id="c348" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上面的等式中，我们将等式(1)中的<strong class="ks jc"> <em class="ng"> y </em> </strong>替换为<strong class="ks jc"><em class="ng">xβ</em></strong><em class="ng">+</em><strong class="ks jc"><em class="ng">zγ</em></strong><em class="ng">+</em><strong class="ks jc"><em class="ng">【ϵ</em></strong>:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oe"><img src="../Images/a8aec63d0f50972df10c24edd55960e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DaTY-7mG6Hf1JrejS3wbPA.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">用<strong class="bd ob"><em class="od">xβ</em></strong><em class="od">+</em><strong class="bd ob"><em class="od">zγ</em></strong><em class="od">+</em><strong class="bd ob"><em class="od">ϵ</em></strong>(图片由作者提供)</p></figure><p id="ceac" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">接下来，我们将蓝色括号中的术语分配如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi of"><img src="../Images/945a265a811b3232f8e4b5602dbdea0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AmFuXW_4aqzpAMxBpDUS2w.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">分发括号中的术语后(图片由作者提供)</p></figure><p id="32b1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">等式(3)的R.H.S .上的第一项可以简化为简单的<strong class="ks jc"> <em class="ng"> β </em> </strong>如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi og"><img src="../Images/957a2852d1858b6b276b63eeb071e63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v2-14wklm9-tznXyb4xDNg.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">第一个术语的简化(图片由作者提供)</p></figure><p id="675e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上面的简化中，<strong class="ks jc"> <em class="ng"> I </em> </strong>是一个大小为<em class="ng">(k×k)</em>的单位矩阵。<strong class="ks jc"> <em class="ng"> I </em> </strong>是数字<em class="ng"> 1 </em>的矩阵等价。一个矩阵<strong class="ks jc"> <em class="ng"> A </em> </strong>与<strong class="ks jc"> <em class="ng"> A </em> </strong>的逆矩阵相乘等于<strong class="ks jc"> <em class="ng"> I </em> </strong>，同理，<em class="ng"> (n)*(1/n)=1 </em>。</p><p id="c9b0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们用<strong class="ks jc"> <em class="ng"> β </em> </strong>代替等式(3)的第一项，并将简化的等式(3)重述如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oh"><img src="../Images/e005341fa638755a8a091544ace38aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDbyHrRe6S_9aGs6zVqGuQ.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">方程式(3)的简化版(图片由作者提供)</p></figure><p id="9862" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">上面的等式给了我们第一个提示，变量<strong class="ks jc"><em class="ng">【z】</em></strong><em class="ng"/>的省略可能会导致系数向量<strong class="ks jc"> <em class="ng"> β_cap </em> </strong> <em class="ng"> </em>的拟合值偏离其真实群体值<strong class="ks jc"><em class="ng">β</em></strong><em class="ng"/>，偏离量等于红色框中各项的值。</p><p id="58cf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们回忆一下，拟合回归模型中的<a class="ae ms" rel="noopener" target="_blank" href="/an-illustrated-guide-to-the-variance-covariance-matrices-used-in-regression-analysis-3eb5a5dd2cff">系数估计值是随机变量</a>，它有一个平均值(也称为期望值)和围绕平均值的方差。</p><p id="1a66" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，我们感兴趣的不是<strong class="ks jc"> <em class="ng"> β_cap </em> </strong>的点估计。相反，我们应该计算下面的<a class="ae ms" rel="noopener" target="_blank" href="/understanding-conditional-variance-and-conditional-covariance-8b661067fc18"> <strong class="ks jc">条件估计值</strong></a><strong class="ks jc"><em class="ng">β_ cap</em></strong>的条件均值:</p><p id="a047" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">E(</em><strong class="ks jc"><em class="ng">β_ cap</em></strong><em class="ng">|</em><strong class="ks jc"><em class="ng">X</em></strong><em class="ng">)</em></p><p id="f3eb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">相应地，让我们对上述等式两边的条件期望如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oi"><img src="../Images/17845aa3fbb1e77f856760aa62740044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ayw4V6lqNCKqjDP4BNd2qw.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">接受双方的条件期望后(图片由作者提供)</p></figure><p id="250f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">上面等式的R.H.S .上的蓝色表达式可以使用恒等式<em class="ng">E(</em><strong class="ks jc"><em class="ng">A</em></strong><em class="ng">+</em><strong class="ks jc"><em class="ng">B</em></strong><em class="ng">+</em><strong class="ks jc"><em class="ng">C</em></strong><em class="ng">)= E(</em><strong class="ks jc"><em class="ng">A</em></strong>)</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi oj"><img src="../Images/2d8cbf23eed156367145fa94b1ce1956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xfwtodeSBhcM4sQM8L15A.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">去掉条件期望操作符后(图片由作者提供)</p></figure><p id="ef27" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">右边第一项<em class="ng">E(</em><strong class="ks jc"><em class="ng">β| X</em></strong><em class="ng">)</em>简单来说就是<strong class="ks jc"><em class="ng"/></strong>，即常数的系数的真实总体值。</p><p id="7aeb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在我们考察右边的第二项之前，让我们用恒等式<em class="ng">E(</em><strong class="ks jc"><em class="ng">ABC</em></strong><em class="ng">)= E(</em><strong class="ks jc"><em class="ng">A</em></strong><em class="ng">E(</em><strong class="ks jc"><em class="ng">B</em></strong><em class="ng">)E(</em><strong class="ks jc"><em class="ng">C</em></strong><em class="ng">)</em>假设随机变量<strong class="ks jc"> <em class="ng"/></strong></p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ok"><img src="../Images/b654c2931ca13f86976b8ebc06940b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UlITiQ0BHXCLbwNCLTMDgg.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">等式(4)的第三项使用期望乘积规则简化(图片由作者提供)</p></figure><p id="682e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们得出一个重要的观察结果。</p><p id="1e3f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">线性回归模型的主要假设之一是误差<strong class="ks jc"><em class="ng">【ϵ</em></strong>，以回归变量<strong class="ks jc"> <em class="ng"> X </em> </strong>为条件，具有零均值。</p><p id="207e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">错误是外生的</strong>这一属性意味着<em class="ng">灰色的期望e(</em><strong class="ks jc"><em class="ng">【ϵ】</em></strong><em class="ng">|</em><strong class="ks jc"><em class="ng">x</em></strong><em class="ng">)=</em><strong class="ks jc"><em class="ng">0</em></strong>，其中<strong class="ks jc"> <em class="ng"> 0 </em> </strong>是大小为<em class="ng">的列向量绿色的期望是简单的<strong class="ks jc"><em class="ng">X</em></strong>’(它是<strong class="ks jc"> <em class="ng"> X </em> </strong>的转置)并且它的大小是<em class="ng"> (k x n) </em>。因此，绿色和灰色位相乘在一起就是大小为<em class="ng">(k×1)</em>的列向量<strong class="ks jc"> <em class="ng"> 0 </em> </strong>。最后，黄色位是大小为<em class="ng"> (n x k) </em>的<strong class="ks jc"> <em class="ng"> X </em> </strong>与其大小为<em class="ng"> (k x n) </em>的转置的乘积的倒数。因此，黄色位相当于一个大小为<em class="ng"> (k x k) </em>的矩阵。这个矩阵与<em class="ng">(k×1)</em>列零向量的乘积就是一个大小为<em class="ng">(k×1)</em>的列零向量。</em></p><p id="e3c5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，等式(4)中的第三项实际上消失在大小为<em class="ng">(k×1)</em>的零的列向量中。</p><p id="7d54" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">到目前为止，我们已经表明，在等式(4)中，右边的第一项是列向量<strong class="ks jc"><em class="ng"/></strong><strong class="ks jc"><em class="ng"/></strong>而第三项是列向量<strong class="ks jc"> <em class="ng"> 0 </em> </strong>，两者的大小都是<em class="ng">(k×1)</em><strong class="ks jc"><em class="ng">。</em>T121】</strong></p><p id="0778" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在我们来看等式(4)的第二项。简单来说，我们就用恒等式<em class="ng">E(</em><strong class="ks jc"><em class="ng">AB</em></strong><em class="ng">)= E(</em><strong class="ks jc"><em class="ng">A</em></strong><em class="ng">)E(</em><strong class="ks jc"><em class="ng">B</em></strong><em class="ng">)</em>:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ol"><img src="../Images/f9a78b6c9f058d8b4ffc514427bbfc38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17PPbhzS7Sd4dozlNyKtBQ.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">等式(4)的第二项使用期望乘积规则简化(图片由作者提供)</p></figure><p id="513d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">灰色项简单来说就是<strong class="ks jc"> <em class="ng"> γ </em> </strong>，因为它是<strong class="ks jc"> <em class="ng"> z </em> </strong>的系数的总体水平值，因此它的期望(均值)与它本身相同。</p><p id="1685" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">将R.H.S .上期望值内的绿色位与<strong class="ks jc"> <em class="ng"> y </em> </strong>对<strong class="ks jc"><em class="ng">×T34】</em></strong>的最小二乘回归的闭合形式解进行比较会有所帮助(如下所示):</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/49e9987ea86eebc1624208fdbacb86cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*jJOtlitCdoYHA-B5UPflCA.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated"><strong class="bd ob"><em class="od">y</em></strong><em class="od">=</em><strong class="bd ob"><em class="od">xβ_ cap</em></strong><em class="od">+</em><strong class="bd ob"><em class="od">e</em></strong><em class="od">(图片由作者提供)</em></p></figure><p id="74bc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">很容易看出，绿色位其实是<em class="ng">省略变量</em> <strong class="ks jc"> <em class="ng"> z </em> </strong> <em class="ng">对</em> <strong class="ks jc"> <em class="ng"> X </em> </strong> <em class="ng">的最小二乘回归的封闭形式解！</em></p><p id="38a8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，我们可以将等式(4)的第二项表达如下:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi om"><img src="../Images/8d19403c591671e4e9669e06d0a6abc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LRYXL52lCaVIcjwRLCqqPg.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated"><strong class="bd ob"> z </strong>对<strong class="bd ob"> X </strong>的回归的拟合系数<strong class="bd ob"> <em class="od"> β </em> _zX </strong>的期望值(图片由作者提供)</p></figure><p id="a8ea" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上述等式的R.H.S中:</p><ul class=""><li id="688d" class="ni nj jb ks b kt ku kw kx kz nk ld nl lh nm ll nn no np nq bi translated"><em class="ng"> γ </em><em class="ng"> γ </em>是一个标量，因此没有<strong class="ks jc">加粗</strong>。</li><li id="e8fe" class="ni nj jb ks b kt nr kw ns kz nt ld nu lh nv ll nn no np nq bi translated"><strong class="ks jc"> <em class="ng"> β_cap_zX </em> </strong>是从回归<strong class="ks jc"><em class="ng"/></strong>z到<strong class="ks jc"><em class="ng"/></strong>X中剩余变量的拟合回归系数的向量。</li></ul><p id="d671" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，我们可以将所有的部分放在一起，并在从回归中省略变量<strong class="ks jc"><em class="ng">【z</em></strong>时，说明回归的拟合系数<strong class="ks jc"><em class="ng">【β_ cap】</em></strong><em class="ng">y</em>on<strong class="ks jc"><em class="ng"/></strong><em class="ng"/>的期望值公式:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi on"><img src="../Images/611375652f04170f7aac828a5298bf10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kP0EFPoZOm_Tl1y2wG0XGg.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">当变量从回归中省略时，拟合系数的期望值(图片由作者提供)</p></figure><p id="f2ea" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在等式(5)中，<strong class="ks jc"> <em class="ng"> β_cap_zX </em> </strong>为大小为<em class="ng">(k×1)</em>的列向量，其中<em class="ng"> k </em>为模型中回归系数的个数(不包括<strong class="ks jc"><em class="ng">z</em></strong>)<em class="ng">γ</em>为标量。因此，当我们从模型中省略诸如<strong class="ks jc"> <em class="ng"> z </em> </strong>之类的变量时，得到的模型的拟合系数从其真实总体值<em class="ng">偏离</em>，偏离量与<strong class="ks jc"><em class="ng"/></strong>z与<strong class="ks jc"><em class="ng"/></strong>中剩余变量的协方差成比例，如<em class="ng">E(</em><strong class="ks jc"><em class="ng">β_ cap _ zX</em>所示</strong></p><p id="943f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这一分析表明了以下两种情况:</p><h2 id="2fe2" class="mu ln jb bd lo mv mw dn ls mx my dp lw kz mz na ly ld nb nc ma lh nd ne mc nf bi translated">省略的变量z与x中的其余回归变量相关。</h2><p id="8521" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated">在这种情况下，<em class="ng">E(</em><strong class="ks jc"><em class="ng">β_ cap _ zX</em></strong><em class="ng">|</em><strong class="ks jc"><em class="ng">X</em></strong><em class="ng">)</em>是非零向量。由此，我们得出以下重要结果:</p><blockquote class="oo"><p id="2b23" class="op oq jb bd or os ot ou ov ow ox ll dk translated">当省略的变量与回归模型中的其余变量相关时，剩余回归模型的最小二乘估计不再是无偏的。因此，它不再是蓝色的。</p></blockquote><h2 id="789c" class="mu ln jb bd lo mv oy dn ls mx oz dp lw kz pa na ly ld pb nc ma lh pc ne mc nf bi translated">省略的变量z与其余的回归变量X不相关</h2><p id="eb8d" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated">在这种情况下，列vector<em class="ng">E(</em><strong class="ks jc"><em class="ng">β_ cap _ zX</em></strong><em class="ng">|</em><strong class="ks jc"><em class="ng">X</em></strong><em class="ng">)</em>包含全零。因此，方程R.H.S .的第二项。(5)消失，剩余模型的拟合系数的期望值等于群体值<strong class="ks jc"> <em class="ng"> β </em> </strong> <em class="ng">。</em></p><blockquote class="oo"><p id="4996" class="op oq jb bd or os ot ou ov ow ox ll dk translated">当省略的变量与回归模型中的其余变量不相关时，剩余回归模型的最小二乘估计器继续保持无偏，因此，它保持蓝色<strong class="ak">。</strong></p></blockquote><p id="a9df" class="pw-post-body-paragraph kq kr jb ks b kt pd kc kv kw pe kf ky kz pf lb lc ld pg lf lg lh ph lj lk ll ij bi translated">即使省略的变量与回归变量的其余部分不相关，省略它也是要付出代价的。</p><p id="1b13" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果被省略的变量<strong class="ks jc"> <em class="ng"> z </em> </strong>中的方差已经“解释”了响应变量<strong class="ks jc"> <em class="ng"> y </em> </strong>中的一些方差，那么省略<strong class="ks jc"> <em class="ng"> z </em> </strong>会导致这个无法解释的方差漏入模型的误差项<strong class="ks jc"><em class="ng">【ϵ</em></strong>，导致误差的方差更大并且<a class="ae ms" rel="noopener" target="_blank" href="/the-complete-guide-to-r-squared-adjusted-r-squared-and-pseudo-r-squared-4136650fc06c"> <strong class="ks jc"> <em class="ng"> R平方</em> </strong> </a>到</p><p id="e41f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个结果有一个直观的方面。如果我们继续从模型中移除相关变量，我们最终将只剩下回归的截距，这将我们带到<strong class="ks jc">均值模型</strong>，即<em class="ng">y _ I</em>=<em class="ng">β_ 1</em>+<em class="ng">ϵ_i</em>，其中<em class="ng"> β_1 </em>是<strong class="ks jc"> <em class="ng"> y </em> </strong>的均值。<strong class="ks jc"><em class="ng"/></strong>中所有无法用<strong class="ks jc"> <em class="ng"> y </em> </strong>均值解释的方差，都会溢出到误差项<strong class="ks jc"> <em class="ng"> ϵ </em> </strong>的方差中。</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><p id="1bb2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们回到我们的汽车数据集和回归模型:</p><p id="de66" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">city _ mpg =β_ 1</em><strong class="ks jc"><em class="ng">+</em></strong><em class="ng">β_ 2 *汽车_体积+β_ 3 *整备_重量+β_ 4 *发动机_尺寸+ ϵ </em></p><p id="7335" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们来考察省略<em class="ng"> Engine_Size </em>的效果。根据等式(5)，我们需要回归<em class="ng">汽车体积</em>和<em class="ng">整备质量</em>上的<em class="ng">发动机尺寸</em>(加上截距)。</p><p id="c798" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将使用Python库<a class="ae ms" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Pandas </a>将数据集加载到内存中:</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="cca7" class="mu ln jb pq b gy pu pv l pw px"><strong class="pq jc">import </strong>pandas <strong class="pq jc">as </strong>pd<br/><strong class="pq jc">from </strong>patsy <strong class="pq jc">import </strong>dmatrices<br/><strong class="pq jc">import </strong>numpy <strong class="pq jc">as </strong>np<br/><strong class="pq jc">import </strong>scipy.stats<br/><strong class="pq jc">import </strong>statsmodels.api <strong class="pq jc">as </strong>sm<br/><strong class="pq jc">import </strong>matplotlib.pyplot <strong class="pq jc">as </strong>plt<br/><br/><br/><strong class="pq jc"><em class="ng">#Read the automobiles dataset into a Pandas DataFrame</em></strong><em class="ng"><br/></em>df = pd.read_csv(<strong class="pq jc">'automobile_uciml_4vars.csv'</strong>, header=0)</span></pre><p id="a809" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们打印出前几行:</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="0215" class="mu ln jb pq b gy pu pv l pw px"><strong class="pq jc"><em class="ng">#Print the first few rows of the data set</em></strong><em class="ng"><br/></em>print(df.head())</span></pre><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi py"><img src="../Images/030898c49ca445a6db5130680ad37cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*5HQtTI5FnWSn9xbPKCLfyw.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">autos数据集的前几行(图片由作者提供)</p></figure><p id="6d97" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了判断省略<em class="ng">发动机_尺寸</em>的影响，让我们回归<em class="ng">发动机_尺寸</em>对<em class="ng">汽车_体积</em>和<em class="ng">整备质量</em>的影响。</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="bd6b" class="mu ln jb pq b gy pu pv l pw px"><strong class="pq jc"><em class="ng"># Here's the model expression in Patsy syntax. The intercept's presence is implied.</em></strong><em class="ng"><br/></em>model_expr = <strong class="pq jc">'Engine_Size ~ Car_Volume + Curb_Weight'<br/><br/><em class="ng"># carve out the X and y matrices using Patsy</em></strong><em class="ng"><br/></em>y_train, X_train = <strong class="pq jc">dmatrices</strong>(model_expr,df, <strong class="pq jc">return_type</strong>=<strong class="pq jc">'</strong>dataframe<strong class="pq jc">'</strong>)</span><span id="4752" class="mu ln jb pq b gy pz pv l pw px"><strong class="pq jc"><em class="ng"># Build an OLS regression model using Statsmodels<br/></em></strong>olsr_model = sm.<strong class="pq jc">OLS</strong>(<strong class="pq jc">endog</strong>=y_train, <strong class="pq jc">exog</strong>=X_train)</span><span id="b4c7" class="mu ln jb pq b gy pz pv l pw px"><strong class="pq jc"><em class="ng"># Fit the model on (y, X)<br/></em></strong>olsr_results = olsr_model.<strong class="pq jc">fit</strong>()</span><span id="818f" class="mu ln jb pq b gy pz pv l pw px"><strong class="pq jc"><em class="ng">#Print the training summary of the fitted model<br/></em></strong>print(olsr_results.<strong class="pq jc">summary</strong>())</span></pre><p id="7499" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">以下是培训总结:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi qa"><img src="../Images/8b7025a7d320d5cb05821ea7bcb54e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DOA_ZykqaY2PCaVrRSMyw.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">根据汽车体积和整备质量回归发动机尺寸的训练总结(图片由作者提供)</p></figure><p id="7ce1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">调整后的R平方值0.753和显著的F统计值312.7使我们相信<em class="ng">发动机尺寸</em>与<em class="ng">汽车体积</em>和<em class="ng">整备质量密切相关。</em></p><p id="707d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，等式(5)表明，如果我们从以下回归模型中省略变量<em class="ng"> Engine_Size </em>:</p><p id="5246" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">city _ mpg =β_ 1</em><strong class="ks jc"><em class="ng">+</em></strong><em class="ng">β_ 2 *汽车_体积+β_ 3 *整备_重量+β_ 4 *发动机_尺寸+ ϵ </em></p><p id="f979" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然后城市_MPG 对<em class="ng">汽车_体积</em>和<em class="ng">整备_重量</em>的最小二乘线性回归<em class="ng">将产生拟合系数<strong class="ks jc"><em class="ng">β_ cap</em></strong><em class="ng">=【β_ 1 _ cap，β_2_cap，β_ 3 _ cap】</em>，即<em class="ng">将显著偏离它们的真实人口值</em><strong class="ks jc"><em class="ng">β</em></strong><em class="ng">=]</em></em></p><p id="ad7f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">让我们使用等式(5)使用如下两步程序来估计该偏差:</p><p id="0afa" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">第一步:</strong>我们将首先回归<em class="ng">汽车_体积、</em>整备_重量、<em class="ng">发动机_尺寸</em>(加上<em class="ng">截距</em> ) <em class="ng"> : </em></p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="b2e2" class="mu ln jb pq b gy pu pv l pw px">model_expr = 'City_MPG ~ Car_Volume + Curb_Weight + Engine_Size'</span><span id="dc91" class="mu ln jb pq b gy pz pv l pw px">y_train, X_train = dmatrices(model_expr, df, <strong class="pq jc">return_type</strong>='dataframe')</span><span id="f4e5" class="mu ln jb pq b gy pz pv l pw px">olsr_model = sm.<strong class="pq jc">OLS</strong>(<strong class="pq jc">endog</strong>=y_train, <strong class="pq jc">exog</strong>=X_train)</span><span id="28bc" class="mu ln jb pq b gy pz pv l pw px">olsr_results = olsr_model.<strong class="pq jc">fit</strong>()</span><span id="3701" class="mu ln jb pq b gy pz pv l pw px"><strong class="pq jc">print</strong>(olsr_results.<strong class="pq jc">params</strong>)</span></pre><p id="ae43" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们看到以下输出:</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="9e43" class="mu ln jb pq b gy pu pv l pw px">Intercept      44.218699<br/>Car_Volume      0.000019<br/>Curb_Weight    -0.012464<br/><strong class="pq jc">Engine_Size     0.008221</strong><br/>dtype: float64</span></pre><p id="ec78" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在上面的输出中，<em class="ng"> Engine_Size </em>(高亮显示)的估算系数为<strong class="ks jc"> 0.008221 </strong>。这个值代替了等式(5)中的<em class="ng"> γ </em>。注意，在等式(5)中，<em class="ng"> γ </em>是该系数的真实总体值，而在实践中，我们使用其估计值<strong class="ks jc"> 0.008221。</strong></p><p id="3a1c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc">步骤2: </strong>我们现在将<em class="ng">汽车_体积</em>和<em class="ng">整备_重量</em>上的<em class="ng">发动机_尺寸</em>(加上<em class="ng">截距</em>):</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="5f8b" class="mu ln jb pq b gy pu pv l pw px">model_expr = 'Engine_Size ~ Car_Volume + Curb_Weight'</span><span id="155f" class="mu ln jb pq b gy pz pv l pw px">y_train, X_train = dmatrices(model_expr, df, <strong class="pq jc">return_type</strong>='dataframe')</span><span id="ff6d" class="mu ln jb pq b gy pz pv l pw px">olsr_model = sm.<strong class="pq jc">OLS</strong>(<strong class="pq jc">endog</strong>=y_train, <strong class="pq jc">exog</strong>=X_train)</span><span id="3f56" class="mu ln jb pq b gy pz pv l pw px">olsr_results = olsr_model.<strong class="pq jc">fit</strong>()</span><span id="7e2e" class="mu ln jb pq b gy pz pv l pw px"><strong class="pq jc">print</strong>(olsr_results.<strong class="pq jc">params</strong>)</span></pre><p id="0c80" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们看到以下输出:</p><pre class="mk ml mm mn gt pp pq pr ps aw pt bi"><span id="e1ef" class="mu ln jb pq b gy pu pv l pw px">Intercept      2.256588<br/>Car_Volume    -0.000165<br/>Curb_Weight    0.088617<br/>dtype: float64</span></pre><p id="a725" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这是列向量<em class="ng">E(</em><strong class="ks jc"><em class="ng">β_ cap _ zX</em></strong><em class="ng">|</em><strong class="ks jc"><em class="ng">X</em></strong><em class="ng">):</em></p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/03d97ed7f6596b9471fe70f7eb0a41ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*pBuOZJpgnU3COCVuKHWXgQ.png"/></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">截距、汽车体积和整备质量(按此顺序)的拟合系数的期望值，从汽车体积<em class="od">和整备质量</em>回归<em class="od">发动机尺寸</em>(加上<em class="od">截距</em>)(图片由作者提供)</p></figure><p id="f397" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">根据等式(5)，如果我们通过<em class="ng"> γ </em>(来自步骤1)缩放该向量，如果我们从模型中省略<em class="ng"> Engine_Size </em>，我们将得到回归模型系数估计中引入的偏差估计:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi qc"><img src="../Images/d0abe6bd343e33cf534c5db3a26ff3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6xfvUHEpLyR4Fjr6HcsHw.png"/></div></div><p class="iv iw gj gh gi ix iy bd b be z dk translated">在截距、汽车体积和整备质量(按此顺序)的系数估计中引入的估计偏差，因为从回归模型中忽略了发动机尺寸(图片由作者提供)</p></figure></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><p id="013e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">通过不忽略所讨论的变量来解决偏差问题是很有诱惑力的。但这可能会导致另一个问题。如果省略的变量与模型中的其他变量相关(如<em class="ng"> Engine_Size </em> is)，那么将它添加回去会导致<strong class="ks jc">多重共线性</strong>，这种情况会降低系数的精确度。那是另一篇文章的主题！</p><p id="ce7b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">敬请期待，造型快乐！</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><h1 id="a28b" class="lm ln jb bd lo lp qd lr ls lt qe lv lw kh qf ki ly kk qg kl ma kn qh ko mc md bi translated">参考文献、引文和版权</h1><h2 id="3fb9" class="mu ln jb bd lo mv mw dn ls mx my dp lw kz mz na ly ld nb nc ma lh nd ne mc nf bi translated">数据集</h2><p id="bc16" class="pw-post-body-paragraph kq kr jb ks b kt me kc kv kw mf kf ky kz mg lb lc ld mh lf lg lh mi lj lk ll ij bi translated"><a class="ae ms" href="https://archive.ics.uci.edu/ml/datasets/automobile" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc">汽车数据集</strong> </a> <strong class="ks jc">引用:</strong> Dua，d .和Graff，C. (2019)。UCI机器学习知识库[http://archive . ics . UCI . edu/ml]。加州欧文:加州大学信息与计算机科学学院。(CC BY 4.0) <a class="ae ms" href="https://gist.github.com/sachinsdate/bd617730c4655a01779e1dd86ff30bbe" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc">下载链接</strong> </a></p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><p id="7362" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="ng">如果你喜欢这篇文章，请关注我的</em><a class="ae ms" href="https://timeseriesreasoning.medium.com" rel="noopener"><strong class="ks jc"><em class="ng">Sachin Date</em></strong></a><em class="ng">获取关于回归、时间序列分析和预测主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>