<html>
<head>
<title>Active Learning Overview: Strategies and Uncertainty Measures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主动学习概述:策略和不确定性测量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/active-learning-overview-strategies-and-uncertainty-measures-521565e0b0b#2022-06-18">https://towardsdatascience.com/active-learning-overview-strategies-and-uncertainty-measures-521565e0b0b#2022-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b37f2e3a65597fc0c4c5b139ef515416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Luh777UdzAOJIHg4qa2bQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><div class=""/><div class=""><h2 id="29ff" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">直觉和主动学习术语概述，并动手进行不确定性抽样计算。</h2></div><h1 id="9630" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated">1.主动学习</h1><p id="dd74" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">主动学习是对需要标记的数据进行优先排序的过程的名称，以便对训练监督模型产生最大影响。</p><p id="9288" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">主动学习是一种策略，在这种策略中，学习算法可以交互式地询问用户(教师或oracle ),以便用真正的标签标记新的数据点。主动学习的过程也称为最优实验设计。</p><p id="3b7a" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">主动学习的动机是理解到并非所有标记的例子都同样重要。</p><p id="3793" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">主动学习是一种方法，有时可以大大减少训练模型所需的标记数据量。它通过为专家区分标签工作的优先级来做到这一点。</p><ul class=""><li id="b4ac" class="mn mo jf lo b lp mi ls mj lv mp lz mq md mr mh ms mt mu mv bi translated">主动学习可以在提高准确性的同时降低成本。</li><li id="ff7e" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh ms mt mu mv bi translated">是对现有模型的增强。</li><li id="3afb" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh ms mt mu mv bi translated">是策略/算法，不是模型。</li><li id="bb46" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh ms mt mu mv bi translated">但是可能很难。<strong class="lo jg">“主动学习容易理解，不容易执行上”</strong></li></ul><p id="110b" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">主动学习背后的关键思想是，如果允许机器学习算法选择它学习的数据，它可以用更少的训练标签获得更高的准确性。— <a class="ae nb" href="http://burrsettles.com/pub/settles.activelearning.pdf" rel="noopener ugc nofollow" target="_blank">主动学习文献调查，毛刺落定</a></p><p id="e14d" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">主动学习不是一次收集所有数据的所有标签，而是优先考虑模型最容易混淆的数据，并只请求这些数据的标签。然后，该模型对这少量的标记数据进行一些训练，然后再次为最容易混淆的数据要求更多的标签。</p><p id="a839" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">通过对最容易混淆的例子进行优先排序，该模型可以使专家专注于提供最有用的信息。这有助于模型更快地学习，并让专家跳过对模型没有太大帮助的标记数据。结果是，在某些情况下，我们可以大大减少我们需要从专家那里收集的标签数量，同时仍然可以获得一个很好的模型。这意味着为机器学习项目节省时间和金钱！</p><h1 id="b7d8" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated"><strong class="ak"> 2。主动学习策略</strong></h1><p id="ff69" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated"><strong class="lo jg">主动学习的步骤</strong></p><p id="f300" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">文献中研究了多种方法，涉及如何在标记时区分数据点的优先级以及如何迭代该方法。然而，我们将只介绍最常见和最简单的方法。</p><p id="4fbd" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">在未标记数据集上使用主动学习的步骤是:</p><ol class=""><li id="d287" class="mn mo jf lo b lp mi ls mj lv mp lz mq md mr mh nc mt mu mv bi translated">首先需要做的是，需要手工标记该数据的一个非常小的子样本。</li><li id="8024" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh nc mt mu mv bi translated">一旦有了少量的标记数据，就需要对模型进行训练。该模型当然不会很好，但会帮助我们了解参数空间的哪些区域需要首先标记以改进它。</li><li id="43c7" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh nc mt mu mv bi translated">在训练该模型之后，该模型用于预测每个剩余的未标记数据点的类别。</li><li id="6f67" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh nc mt mu mv bi translated">基于模型的预测，在每个未标记的数据点上选择分数。在下一小节中，我们将介绍一些最常用的可能得分。</li><li id="ba26" class="mn mo jf lo b lp mw ls mx lv my lz mz md na mh nc mt mu mv bi translated">一旦选择了对标记进行优先排序的最佳方法，就可以迭代地重复该过程:可以在新的标记数据集上训练新的模型，该数据集已经基于优先级分数进行了标记。一旦在数据子集上训练了新的模型，未标记的数据点可以通过模型运行，以更新优先化分数，从而继续标记。这样，随着模型变得越来越好，人们可以不断优化标记策略。</li></ol><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b37f2e3a65597fc0c4c5b139ef515416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Luh777UdzAOJIHg4qa2bQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者的AL / Image的一般策略</p></figure><h2 id="f402" class="nh kv jf bd kw ni nj dn la nk nl dp le lv nm nn lg lz no np li md nq nr lk ns bi translated">2.1主动学习方法#1:流</h2><p id="fa4b" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">在基于流的主动学习中，所有训练样本的集合作为流呈现给算法。每个示例都被单独发送给算法进行考虑。该算法必须立即决定是否标记该示例。从该池中选择的训练样本被oracle标记，并且在显示下一个样本以供考虑之前，该标签被算法立即接收。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/a86d934efe22172dc5899c56dce2e90a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RFPzNKQrqedatQ-BQWPSvA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><h2 id="3256" class="nh kv jf bd kw ni nj dn la nk nl dp le lv nm nn lg lz no np li md nq nr lk ns bi translated">2.2.主动学习方法#2:集中</h2><p id="4df2" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">在基于池的采样中，训练样本是从大量未标记的数据中选择的。从该库中选择的训练样本由oracle标记。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nu"><img src="../Images/705deab90a2ac60e0beeb0884b6c53f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yD8tcU2Ub2RRRxhaDDIi3Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><h2 id="0c0c" class="nh kv jf bd kw ni nj dn la nk nl dp le lv nm nn lg lz no np li md nq nr lk ns bi translated">2.3主动学习方法#3:委员会提问</h2><p id="f039" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">用词委员会的质疑是使用多个模型而不是一个。</p><p id="39d4" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">另一种方法，称为委员会查询，维护模型(委员会)的集合，并选择最“有争议”的数据点来标记下一个数据点，即模型不同意的数据点。使用这样的委员会可以让我们克服单一模型所能表达的限制性假设，尽管在任务开始时，我们仍然无法知道我们应该使用什么样的假设。</p><h1 id="72e4" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated"><strong class="ak"> 3。不确定性测量</strong></h1><p id="b4ff" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">识别接下来要标记的最有价值的例子的过程被称为“采样策略”或“查询策略”。抽样过程中的评分函数称为“采集函数”。如果被标记，则具有较高分数的数据点被期望为模型训练产生较高的值。有不同的抽样策略，如不确定性抽样、多样性抽样、预期模型变化等，在本文中，我们将只关注最常用的不确定性测量策略。</p><p id="b1c2" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">不确定性采样是一套技术，用于识别当前机器学习模型中接近决策边界的未标记项目。虽然很容易确定模型何时有信心(有一个结果有很高的信心)，但您有许多方法来计算不确定性，您的选择将取决于您的用例以及对您的特定数据最有效的方法。</p><p id="e2b0" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">最具信息性的例子是分类器最不确定的例子。</p><p id="0107" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">这里的直觉是，模型最不确定的例子可能是最困难的例子——特别是位于类边界附近的例子。学习算法将通过观察困难的例子获得关于类边界的最多信息。</p><p id="a3ef" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">让我们举一个具体的例子，假设你试图建立一个多类分类来区分3类猫，狗，马。该模型可能会给出如下预测:</p><figure class="nd ne nf ng gt is"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="8750" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">此输出很可能来自softmax，它使用指数将对数转换为0–1范围的分数。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/b813c950ba0642a26bba057cb9c29c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mWoTdQMUuYbaUcejnc8vkg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><p id="a13e" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated"><strong class="lo jg"> 3.1。最不自信:</strong></p><p id="7d8e" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">最低置信度取1 (100%置信度)和每个项目最有把握预测的标签之间的差。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/65fe1b3791f45e4c6b1486662a729840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gE7cOU93i8jkMRugH_swXw.png"/></div></div></figure><p id="94d5" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">虽然您可以仅根据置信度对顺序进行排序，但是将不确定性分数转换为0-1范围会很有用，其中1是最不确定的分数。在这种情况下，我们必须将分数正常化。我们从1中减去该值，将结果乘以n/(1-n)，其中n是标签的数量。我们这样做是因为最小置信度绝不会小于1除以标签数，这是所有标签具有相同预测置信度的时候。</p><p id="4df4" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">让我们把这个应用到我们的例子中，不确定性分数将是:<br/>(1–0.9352)*(3/2)= 0.0972。</p><p id="63fc" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">最小置信度是最简单和最常用的方法，它给出了预测的等级顺序，其中您将对预测标签具有最低置信度的项目进行采样。</p><p id="a966" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated"><strong class="lo jg"> 3.2。置信区间抽样</strong></p><p id="28d4" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">不确定性抽样最直观的形式是两个最有把握的预测之间的差异。也就是说，对于模型预测的标签，它比下一个最有信心的标签有多少信心？这被定义为:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/6477bff9bdf8d1d04797c2391d392fd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q4RuNygoyq8toiac_SPJbQ.png"/></div></div></figure><p id="0c63" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">同样，我们可以将其转换为0–1的范围。我们又要从1.0中减去，但是最大可能的分数已经是1了，所以不需要乘以任何因子。</p><p id="8d2c" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">让我们将置信区间抽样应用于我们的示例数据。“猫”和“马”是最有信心和第二有信心的预测。在我们的例子中，这个不确定性分数是1.0-(0.9352–0.0540)= 0.1188。</p><p id="4148" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated"><strong class="lo jg"> 3.3。比率采样</strong></p><p id="4016" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">信心比率是信心边际的一个微小变化，着眼于最高两个分数之间的比率，而不是差异。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/262a25dd05cc6b509fe5b83e972a04f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*7vHM6VsH0LaAzbc1D9NWEA.png"/></div></figure><p id="c63e" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">现在让我们再次插入我们的数字:0.9352 / 0.0540 = 17.3185。</p><p id="0060" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated"><strong class="lo jg"> 3.4。熵采样</strong></p><p id="8dc4" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">应用于概率分布的熵包括将每个概率乘以其自身的对数，然后取负和:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/87dd1ac97da7533451f27ca9c4642725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FC1bpxIalhpoybX-Toi1mQ.png"/></div></div></figure><p id="a380" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">让我们计算示例数据的熵:</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/604b080a00cd3345dc27b4f2fa346f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*ejQyE1A2hu7crqAYSr9SNw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">按作者分类的表格</p></figure><p id="a93a" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">对这些数字求和并求反得出0-SUM(–0.0705，-0.0903，-0.2273)= 0.3881</p><p id="54e7" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">除以标签数量的对数得出0.3881/ log2(3) = 0.6151</p><h1 id="42b7" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated"><strong class="ak">关闭</strong></h1><p id="f64d" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">机器学习社区的大部分焦点是创建更好的算法来从数据中学习。但是获得有用的带注释的数据集是困难的。真的很难。这可能会很昂贵、耗时，并且最终仍然会出现一些问题，比如某些类别中缺少注释。主动学习是这方面的一个重要组成部分，在我看来并没有得到充分利用。</p><h1 id="cf0e" class="ku kv jf bd kw kx ky kz la lb lc ld le kl lf km lg ko lh kp li kr lj ks lk ll bi translated">参考</h1><p id="d8c1" class="pw-post-body-paragraph lm ln jf lo b lp lq kg lr ls lt kj lu lv lw lx ly lz ma mb mc md me mf mg mh ij bi translated">[1]<a class="ae nb" href="https://www.manning.com/books/human-in-the-loop-machine-learning" rel="noopener ugc nofollow" target="_blank">https://www . manning . com/books/human-in-the-loop-machine-learning</a></p><p id="2aa8" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">[2]<a class="ae nb" rel="noopener" target="_blank" href="/introduction-to-active-learning-117e0740d7cc">https://towards data science . com/introduction-to-active-learning-117 e 0740 D7 cc</a></p><p id="1e79" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">[3]<a class="ae nb" href="https://www.cs.cmu.edu/~tom/10701_sp11/recitations/Recitation_13.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . CMU . edu/~ Tom/10701 _ sp11/renditions/returnation _ 13 . pdf</a></p><p id="72dc" class="pw-post-body-paragraph lm ln jf lo b lp mi kg lr ls mj kj lu lv mk lx ly lz ml mb mc md mm mf mg mh ij bi translated">[4]<a class="ae nb" href="https://www.youtube.com/watch?v=l6HFdqk480o&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=l6HFdqk480o&amp;feature = youtu . be</a></p></div></div>    
</body>
</html>