<html>
<head>
<title>Stat Stories: Delta Method in Statistics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计故事:统计学中的 Delta 方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stat-stories-delta-method-in-statistics-bd681fbbf037#2022-11-19">https://towardsdatascience.com/stat-stories-delta-method-in-statistics-bd681fbbf037#2022-11-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7519" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习实践者经常忽略的话题</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7022f2d8051620d6569888fbf2e6997f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TIskdh2aTnQSmm2rYkQSpA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者使用人工智能工具 Dreamstudio 生成的封面照片。</p></figure><p id="206d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated">数据采样是数据科学的核心。从一个给定的总体<em class="md"> f(x)，</em>我们采样数据点。所有这些数据点统称为随机样本，用随机变量<em class="md"> X </em>表示。但我们知道，数据科学是一个概率游戏，通常，我们会多次重复实验。在这种情况下，我们最终得到了<em class="md"> n </em>个随机样本<em class="md"> X₁、X₂、……xₙ</em>(不要与样本中的数据点数量混淆)。通常这些随机样本是独立的，但是同分布的，因此，它们被称为 pdf 或 pmf <em class="md"> f(x)的独立同分布随机变量，或者 iid </em>随机变量<em class="md">。</em></p><p id="9a97" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将讨论 Delta 方法，它提供了一个数学框架，用于在给定 iid 样本的情况下计算极限分布和渐近方差。Delta 方法允许您计算方差已知的随机变量函数的方差(通过一些变换，我们将在后面看到)。这个框架与统计学中的变量转换方法密切相关，我之前已经在<a class="ae me" rel="noopener" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30">详细讨论过</a>。</p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd iu gy z fp mn fr fs mo fu fw is bi translated">统计故事:生成新分布的变量转换</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">统计分布的变换</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw ks mi"/></div></div></a></div><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/stat-stories-multivariate-transformation-for-statistical-distributions-7077a374b3b4"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd iu gy z fp mn fr fs mo fu fw is bi translated">统计故事:统计分布的多元变换</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">标准化流程的先驱</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="mx l mt mu mv mr mw ks mi"/></div></div></a></div><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/stat-stories-normalizing-flows-as-an-application-of-variable-transformation-7b7beda7b03b"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd iu gy z fp mn fr fs mo fu fw is bi translated">Stat Stories:将流程规范化作为变量转换的应用</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">易处理分布的生成模型</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="my l mt mu mv mr mw ks mi"/></div></div></a></div><h1 id="7148" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">基础</h1><p id="96ca" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">给定<em class="md"> iid </em>随机样本<em class="md"> X₁、X₂、……xₙ、</em>他们的联合 pdf 由下式给出</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/5b4929c13a6222cdc67de442e44f684e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pkFzxmxnBKL3vZM_2oolYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 iid 随机变量的联合 PDF</p></figure><p id="0cfc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">特殊情况下，如果所有 iid 样本(我们去掉‘随机’但假设它们在那里)正态分布，均值和方差分别为 0 和 1，那么 X ~ χ ₁，即自由度的卡方分布等于 1。(可以用 Python，R，或者 Julia 写一个简单的脚本来测试)。</p><h2 id="d9af" class="nx na it bd nb ny nz dn nf oa ob dp nj lh oc od nl ll oe of nn lp og oh np oi bi translated">趋同；聚集</h2><p id="25ea" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">分布收敛告诉我们<em class="md"> Xₙ </em>如何收敛到某个极限分布，如<em class="md"> n → ∞ </em>。我们可以在不同层面上讨论融合:</p><ol class=""><li id="9e12" class="oj ok it la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><strong class="la iu">依概率收敛:</strong>一个随机变量序列<em class="md"> X₁，X₂，… Xₙ </em> →ₚ <em class="md"> X </em>如果对每一个<em class="md"> ε &gt; 0 </em>，</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/15fd1ce04dd74697c810aae5bacf2c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*fopjjW_FjQsROu25SovuPw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 2。概率收敛</p></figure><p id="88a8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中→ₚ表示概率收敛。概率收敛的一个应用是<strong class="la iu">弱大数定律</strong>。对于 iid <em class="md"> X₁，X₂，… Xₙ </em>带<em class="md"> 𝔼(X) = μ </em>，而<em class="md"> var(X) &lt; ∞，</em>则(<em class="md"> X +，X₂+ … + Xₙ)/n </em> →ₚ <em class="md"> μ。</em></p><p id="e09b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2 <strong class="la iu">。几乎确定收敛:</strong>我们说<em class="md"> Xₙ → X </em> a.s .(几乎确定)如果</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/84ac2caa2f61210cfa5b4a0c809445d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*5L1zLUTpaKa_FthJmz1iig.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 3。几乎肯定收敛。</p></figure><p id="295a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">几乎必然收敛意味着概率收敛，反之则不成立。强大数定律是几乎必然收敛的结果其中<em class="md"> 𝔼(X) </em> = <em class="md"> μ </em>，var(X) = <em class="md"> σ，</em>然后(<em class="md"> X +，X₂+ … + Xₙ)/n </em> → <em class="md"> μ，a.s. </em></p><p id="d470" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 3。分布的收敛性:</strong>我们说<em class="md"> Xₙ → X </em>如果<em class="md"> Xₙ </em>的分布函数 F_{ <em class="md"> Xₙ} </em>的序列在适当的意义上收敛于<em class="md"> X </em>的序列:<em class="md"> F_{Xₙ}(x) → F_{X}(x) </em>对于所有的<em class="md"> x，</em>其中<em class="md"> F_{X} </em>是连续的<em class="md"> ( </em>注意我的</p><p id="8d2f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">分布的收敛性是分布的性质，而不是与前两种分布不同的特定随机变量。<a class="ae me" rel="noopener" target="_blank" href="/stat-stories-why-is-moment-generating-function-important-25bbc17dad68">矩母函数</a>的收敛意味着分布的收敛，即<em class="md"> M_{X_n}(t) → M_X(t) </em>对于所有<em class="md"> t </em>在<em class="md"> 0 </em>的邻域内。</p><div class="mf mg gp gr mh mi"><a rel="noopener follow" target="_blank" href="/stat-stories-why-is-moment-generating-function-important-25bbc17dad68"><div class="mj ab fo"><div class="mk ab ml cl cj mm"><h2 class="bd iu gy z fp mn fr fs mo fu fw is bi translated">统计故事:为什么矩母函数很重要？</h2><div class="mp l"><h3 class="bd b gy z fp mn fr fs mo fu fw dk translated">什么唯一地决定了概率分布</h3></div><div class="mq l"><p class="bd b dl z fp mn fr fs mo fu fw dk translated">towardsdatascience.com</p></div></div><div class="mr l"><div class="ou l mt mu mv mr mw ks mi"/></div></div></a></div><p id="2882" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">中心极限定理</em> </strong> <em class="md"> </em>是收敛在分布中的一个应用其中，对于<em class="md"> X₁、X₂、……xₙ</em>具有均值<em class="md"> μ </em>和方差<em class="md"> σ </em>，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/19d22f30efc661d5b32445a08ed1af16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*qpjyIgs8eN9CL--_VMbaqg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 4。正态分布通过中心极限定理，一个分布收敛的结果。</p></figure><p id="bcc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">分布收敛的另一个结果是<strong class="la iu">斯卢茨基定理</strong>:</p><blockquote class="ow ox oy"><p id="1d22" class="ky kz md la b lb lc ju ld le lf jx lg oz li lj lk pa lm ln lo pb lq lr ls lt im bi translated"><em class="it">如果</em> Xₙ → X <em class="it">在分配</em>，<em class="it">和</em> Yₙ → c <em class="it">在分配</em>，<em class="it">与</em> c <em class="it">一个常数</em>，<em class="it">那么</em> Xₙ + Yₙ → X + c，Xₙ Yₙ → cX，<em class="it">和</em> Xₙ /Yₙ → X/c，c ≠0，</p></blockquote><h1 id="69e7" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">德尔塔法</h1><p id="c687" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">Delta 方法通过收敛性质和泰勒级数，逼近随机变量函数的渐近行为。通过<a class="ae me" rel="noopener" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30">变量变换方法</a>很容易看出，如果<em class="md"> Xₙ </em>渐近正态，那么任何光滑函数<em class="md"> g(Xₙ) </em>也是渐近正态的。在这种情况下，可以使用 Delta 方法来计算样本平均值函数的渐近分布。</p><p id="199e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果方差很小，那么<em class="md"> Xₙ </em>集中在其均值附近。因此，对于<em class="md"> g(x) </em>来说，重要的是其平均值<em class="md"> μ </em>附近的行为。因此，我们可以使用泰勒级数将<em class="md"> g(x) </em>展开到<em class="md"> μ </em>附近，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/1abad54d503607206e67fcbb81a50786.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D4RrN9WTgZEAC2S9skbN3w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 5。随机变量函数的泰勒级数逼近。</p></figure><p id="d4ca" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就需要以下被称为<strong class="la iu">一阶增量法</strong>的渐近行为:</p><h2 id="14dc" class="nx na it bd nb ny nz dn nf oa ob dp nj lh oc od nl ll oe of nn lp og oh np oi bi translated">一阶增量法</h2><p id="0a02" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">设<em class="md"> Xₙ </em>为满足<em class="md">√n(xₙμ)→n(0，σ ) </em>的随机变量序列。如果<em class="md">g</em><strong class="la iu"><em class="md">'</em></strong><em class="md">(μ)≠0</em>，那么</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/178645fccf48f416d0139e57da353657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nf0YMht9VQYYOWyKh6TNg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等式 6。一阶增量法</p></figure><p id="fd23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它可以按照我之前提到的斯卢茨基定理来写。</p><h2 id="164e" class="nx na it bd nb ny nz dn nf oa ob dp nj lh oc od nl ll oe of nn lp og oh np oi bi translated">二阶增量法</h2><p id="313b" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">如果我们从等式中给泰勒级数增加一项，我们可以得到二阶 delta 方法，当<em class="md">g</em><strong class="la iu"><em class="md">'</em></strong><em class="md">(μ)= 0</em>时，该方法是有用的，但是当<em class="md">g '</em><strong class="la iu"><em class="md">'</em></strong><em class="md">(μ)≠0</em>时，该方法是有用的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/d4f55d48456c9af9740c0a2914b02be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UgzvtxovcaRbDXqHV7Avbg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">方程式 7。二阶增量法。</p></figure><p id="2c80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中<em class="md"> χ ₁ </em>是前面介绍的自由度等于 1 的卡方分布。</p><p id="4f99" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="md">我们来做一点编码。</em>T51】</strong></p><p id="fa27" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑一个均值为 1.5、真实样本方差为 0.25 的随机正态样本。我们感兴趣的是这个样本的方差乘以常数<em class="md"> c = 2.50 </em>的近似值。数学上，使用 Delta 方法，新样本的方差将是 0.25*(2.50 ) = 1.5625。让我们根据经验使用 R 代码来做这个例子:</p><pre class="kj kk kl km gt pf pg ph bn pi pj bi"><span id="c924" class="pk na it pg b be pl pm l pn po">c &lt;- 2.50<br/>trans_sample &lt;- c*sample<br/>var(trans_sample)</span></pre><p id="19ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其输出为 1.563107，非常接近使用 Delta 方法获得的结果。</p><h1 id="7020" class="mz na it bd nb nc nd ne nf ng nh ni nj jz nk ka nl kc nm kd nn kf no kg np nq bi translated">结论</h1><p id="37ce" class="pw-post-body-paragraph ky kz it la b lb nr ju ld le ns jx lg lh nt lj lk ll nu ln lo lp nv lr ls lt im bi translated">在本文中，我介绍了 Delta 方法，这对于学习统计课程的学生来说是一个重要的主题，但通常被数据科学和机器学习从业者所忽略。Delta 方法用于各种应用，例如生存概率乘积的方差、报告率估计的方差、一个参数的方差和该参数与另一个参数的协方差的联合估计以及模型平均等等。我建议读者看看参考资料，进一步了解这个话题。</p></div><div class="ab cl pp pq hx pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="im in io ip iq"><p id="be5e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这有帮助吗？ <a class="ae me" href="https://www.buymeacoffee.com/rahulbhadani" rel="noopener ugc nofollow" target="_blank"> <em class="md">给我买杯咖啡</em> </a> <em class="md">。</em></p><p id="1258" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md">爱我的文字？加入我的</em> <a class="ae me" href="https://rahulbhadani.medium.com/subscribe" rel="noopener"> <em class="md">邮箱列表</em> </a> <em class="md">。</em></p><p id="0d74" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="md">想了解更多 STEM 相关话题？加入</em> <a class="ae me" href="https://rahulbhadani.medium.com/membership" rel="noopener"> <em class="md">中等</em> </a></p></div><div class="ab cl pp pq hx pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="im in io ip iq"><h1 id="ff93" class="mz na it bd nb nc pw ne nf ng px ni nj jz py ka nl kc pz kd nn kf qa kg np nq bi translated">参考</h1><ol class=""><li id="fa82" class="oj ok it la b lb nr le ns lh qb ll qc lp qd lt oo op oq or bi translated"><a class="ae me" href="https://web.archive.org/web/20220609034135/http://www.phidot.org/software/mark/docs/book/pdf/app_2.pdf" rel="noopener ugc nofollow" target="_blank">https://web . archive . org/web/20220609034135/http://www . phi dot . org/software/mark/docs/book/pdf/app _ 2 . pdf</a></li><li id="f71f" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" href="https://web.archive.org/web/20220816054241/https://stats.oarc.ucla.edu/r/faq/how-can-i-estimate-the-standard-error-of-transformed-regression-parameters-in-r-using-the-delta-method/" rel="noopener ugc nofollow" target="_blank">https://web . archive . org/web/20220816054241/https://stats . oarc . UCLA . edu/r/FAQ/how-can-I-estimate-the-standard-error-of-transformed-regression-parameters-in-r-using-the-delta-method/</a></li><li id="4846" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" href="https://web.archive.org/web/20221014235612/https://cran.r-project.org/web/packages/modmarg/vignettes/delta-method.html" rel="noopener ugc nofollow" target="_blank">https://web . archive . org/web/20221014235612/https://cran . r-project . org/web/packages/modmarg/vignettes/delta-method . html</a></li><li id="8aa4" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" href="https://web.archive.org/web/20220903164755/https://bookdown.org/ts_robinson1994/10_fundamental_theorems_for_econometrics/dm.html" rel="noopener ugc nofollow" target="_blank">https://web . archive . org/web/20220903164755/https://book down . org/ts _ Robinson 1994/10 _ 基本面 _ 定理 _ 计量经济学/dm.html </a></li><li id="546a" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated">去 JM。谁发明了德尔塔法？。美国统计学家。2012 年 5 月 1 日；66(2):124–7.</li><li id="7b74" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated">尼尔森·GK、芒特-卡斯·阿兹、斯卡格·HJ、布伦·m,《深度学习中不确定性近似的德尔塔法》。arXiv 预印本 arXiv:1912.00832。2019 Dec3.尼尔森·GK、芒特-卡斯·阿兹、斯卡格·HJ、布伦·m,《深度学习中不确定性近似的德尔塔法》。arXiv 预印本 arXiv:1912.00832。2019 Dec3.</li><li id="a0cd" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated">尼尔森·GK、芒特-卡斯·阿兹、斯卡格·HJ、布伦·m,《用德尔塔法量化深度学习分类中的认知不确定性》。神经网络。2022 年 1 月 1 日；145:164–76.</li><li id="51e0" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated">尼尔森·GK、芒特-卡斯·阿兹、斯卡格·HJ、布伦·m,《深度学习分类中德尔塔法和自助法的比较》。arXiv 预印本 arXiv:2107.01606。2021 年 7 月 4 日。</li></ol></div><div class="ab cl pp pq hx pr" role="separator"><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu pv"/><span class="ps bw bk pt pu"/></div><div class="im in io ip iq"><p id="34c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">统计故事系列相关主题列表:</strong></p><ol class=""><li id="b519" class="oj ok it la b lb lc le lf lh ol ll om lp on lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-variable-transformation-to-generate-new-distributions-d4607cb32c30">https://towards data science . com/stat-stories-variable-transformation-to-generate-new-distributions-d 4607 CB 32 c 30</a></li><li id="7fda" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-multivariate-transformation-for-statistical-distributions-7077a374b3b4">https://towards data science . com/stat-stories-multivarial-transformation-for-statistical-distributions-7077 a 374 B3 b 4</a></li><li id="9eb7" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-normalizing-flows-as-an-application-of-variable-transformation-7b7beda7b03b">https://towards data science . com/stat-stories-normalizing-flow-as-a-application-of-variable-transformation-7 b 7 beda 7 b 03 b</a></li><li id="65f8" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-why-is-moment-generating-function-important-25bbc17dad68">https://towards data science . com/stat-stories-why-moment-generating-function-important-25 BBC 17 dad 68</a></li><li id="5a0b" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-common-families-of-statistical-distributions-part-1-2b704dd6a808">https://towards data science . com/stat-stories-common-family-of-statistical-distributions-part-1-2b 704 DD 6a 808</a></li><li id="69e9" class="oj ok it la b lb qe le qf lh qg ll qh lp qi lt oo op oq or bi translated"><a class="ae me" rel="noopener" target="_blank" href="/stat-stories-common-families-of-statistical-distributions-part-2-4bdea86c3132">https://towards data science . com/stat-stories-common-family-of-statistical-distributions-part-2-4b DEA 86 c 3132</a></li></ol></div></div>    
</body>
</html>