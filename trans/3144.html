<html>
<head>
<title>ML Prediction on Streaming Data Using Kafka Streams</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Kafka流对流数据进行ML预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-prediction-on-streaming-data-using-kafka-streams-1e4ebd21008#2022-07-11">https://towardsdatascience.com/ml-prediction-on-streaming-data-using-kafka-streams-1e4ebd21008#2022-07-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4c9c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过在Scala应用程序中的Kafka流平台上提供经过Python训练的ML模型，提高它们的性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/490a416c32abc3b19f79f82030b1d9c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EECCAcI2LfE-8OmV"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">埃姆雷·卡拉塔什在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="cec1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">1.介绍</h1><p id="8ae0" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">假设您有一个基于Kafka的健壮的流媒体平台，它在将客户的事件数据写入某个仓库之前对其进行清理和丰富。一天，在一次偶然的计划会议上，您的产品经理提出了对传入数据使用机器学习模型(由数据科学团队开发)的要求，并为模型标记的消息生成警报。“没问题”，你回答。“我们可以从数据仓库中选择我们想要的任何数据集，然后运行我们想要的任何模型”。“不完全是”，首相回答。“我们希望尽可能实时地运行。<em class="mk">我们希望在收到事件</em>后不到一分钟，ML模型的结果就可以在Kafka主题中使用。</p><p id="44d3" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这是一个普遍的要求，而且只会越来越流行。对于许多必须对模型结果做出时间敏感决策的客户来说，对流式数据进行实时ML推断的要求变得很重要。</p><p id="182b" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">看起来大数据工程和数据科学配合得很好，应该有一些简单的解决方案，但通常情况下并非如此，使用ML对繁重的数据工作负载进行接近实时的推理涉及到相当多的挑战。例如，在这些挑战中，Python(ML的主流语言)和JVM环境(Java/Scala )(大数据工程和数据流的主流环境)之间存在差异。另一个挑战与我们用于工作负载的数据平台有关。如果你已经在使用Spark，那么你可以使用Spark ML库，但是有时候它不够好，有时候(就像我们的例子)Spark不属于我们的栈或者基础架构。</p><p id="bee3" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">诚然，生态系统意识到了这些挑战，并正在慢慢地用新功能来解决它们，尽管我们特定的通用场景目前留给您几个通用选项。例如，一种方法是将Spark添加到您的堆栈中，并编写一个pySpark作业，将ML推理阶段添加到您的管道中。这将为您的数据科学团队提供更好的Python支持，但也意味着您的数据处理流程可能需要更长时间，并且您还需要向堆栈中添加和维护Spark集群。另一种选择是使用某个第三方模型服务平台，该平台将基于您的模型公开推理服务端点。这可能有助于保持您的性能，但也可能需要额外的基础架构成本，同时对于某些任务来说是多余的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/460711d9ad7377fc527ca7bd4894c362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*yPiuUVa3folHk4fORq56UA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">常见的解决方案是在堆栈中添加一个Spark集群来运行ML推理</p></figure><p id="05fc" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在这篇文章中，我想展示使用Kafka Streams完成这项任务的另一种方法。使用Kafka Streams完成这项任务的优势在于，与Flink或Spark不同，它不需要专用的计算集群。相反，它可以运行在您已经在使用的任何应用服务器或容器环境上，如果您已经在使用Kafka进行流处理，那么它可以非常无缝地嵌入到您的流中。</p><p id="178d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">虽然Spark和Flink都有他们的机器学习库和教程，但使用Kafka Streams来完成这项任务似乎是一个不太常见的用例，我的目标是展示它是如何容易实现的。具体来说，我展示了我们如何使用XGBoost模型——在Python环境中训练的生产级机器学习模型，对Kafka主题的事件流进行实时推理。</p><p id="b70a" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这是一篇非常实用的文章。在第2节中，我们在欺诈检测数据集上训练一个XGBoost分类器。我们在Python环境中的Jupyter笔记本中这样做。第3节举例说明了如何将模型的二进制文件导入并包装到Scala类中，第4节展示了如何将其嵌入到Kafka流应用程序中，并对流数据进行实时预测。在文章的最后，你可以找到一个回购协议的链接，里面有完整的代码。</p><p id="edc8" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">(注意，在很多情况下，我以一种非常不习惯的方式使用Scala。我这样做是为了清晰，因为惯用的Scala有时会令人困惑。)</p><h1 id="9f78" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">2.Python中的XGBoost分类器训练</h1><p id="1328" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对于这个例子，我们首先基于Kaggle <a class="ae kv" href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用欺诈数据集</a>训练一个简单的分类模型。你可以在这里找到完整的模型训练代码<a class="ae kv" href="https://github.com/a-agmon/kafka-streams-ml-model-train/blob/main/fraud_model_training.ipynb" rel="noopener ugc nofollow" target="_blank"/>。重要的一点是，当我们(或我们的数据科学家)对我们模型的结果感到满意后，我们简单地将其保存为简单的二进制形式。这个二进制文件就是我们在Kafka Streams应用程序中加载模型所需的全部内容。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><h1 id="1e36" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">3.Scala中的XGBoost分类器预测</h1><p id="e928" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这一节中，我们开始实现我们的Kafka Streams应用程序，首先将我们的机器学习模型包装在一个Scala对象(singleton)中，我们将使用它对传入的记录进行推理。这个对象将实现<em class="mk">一个predict() </em>方法，我们的流处理应用程序将在每个流事件上使用这个方法。该方法将接收一个记录id和一个字段或要素数组，并将返回一个由记录ID和模型给它的分数组成的元组。</p><p id="673e" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">Scala中的XGBoost模型加载和预测非常简单(尽管应该注意的是，较新的Scala版本中的支持可能是有限的)。在初始导入之后，我们开始将经过*训练的*模型加载到一个Booster变量中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="12a3" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">实现<em class="mk"> predict() </em>方法也相当简单。我们的每个事件都包含一个由10个特征或字段组成的数组，我们需要将它们作为输入提供给我们的模型。</p><p id="2961" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">XGboost用来包装输入向量以进行预测的对象类型是一个<em class="mk"> DMatrix，</em>，它可以通过多种方式构建。我将使用<em class="mk">密集矩阵</em>格式，它基于提供一个表示模型特征或字段的扁平的浮动数组；每个向量的长度(nCols)；以及数据集中向量的数量(nRows)。例如，如果我们的模型用于在具有10个特征或字段的向量上运行推理，并且我们希望一次预测一个向量，那么我们的DMatrix将使用长度= 10、nCols = 10和nRows = 1的浮点数组进行实例化(因为集合中只有一个向量)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="ab78" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这将为我们的分类器对象完成工作，该对象包装了一个经过训练的XGboost ML模型。将有一个带有<em class="mk"> predict() </em>方法的分类器对象，每个记录都将被调用。</p><h1 id="d393" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">4.基于实时数据的Kafka流推理</h1><p id="d26a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在我们进入流应用程序的代码和细节并展示如何在流数据上使用我们的分类器之前，强调在这样的系统中使用Kafka流的优势和动机是很重要的。</p><p id="0222" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">以Spark为例，计算的分配由集群管理器完成，集群管理器从驱动程序应用程序接收指令，并将计算任务分配给专用集群中的执行器节点。每个Spark执行器负责处理一组数据分区。Kafka Streams (KS)的强大之处在于，尽管它同样通过并行性实现了规模，即通过运行流处理应用程序的多个副本，但它并不依赖于专用集群，而是只依赖于Kafka。换句话说，计算节点的生命周期可以由任何容器编排系统(如K8S)或任何其他应用服务器管理，而将协调和管理留给Kafka(和KS库)。这似乎是一个小优势，但这正是Spark最大的痛苦。</p><p id="e4f2" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">事实上，与Spark不同，KS是一个可以导入任何基于JVM的应用程序的库，最重要的是，它可以在任何应用程序基础设施上运行。KS应用程序通常从Kafka主题读取流消息，执行转换，并将结果写入输出主题。Kafka保存和管理状态和有状态转换，如聚合或窗口计算，只需运行应用程序的更多实例即可实现扩展(受限于主题的分区数量和消费者策略)。</p><p id="17cd" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">KS应用程序的基础是拓扑结构，它定义了应用程序的流处理逻辑或者输入数据如何转换为输出数据。在我们的例子中，拓扑将如下运行</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/f682df0a4467e180a6ff040e2aa6e074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LivP9zIknMU11Cbt9LVJJA.png"/></div></div></figure><p id="3e22" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这里的拓扑相当简单。它首先从Kafka上的输入主题中读取流记录，然后使用map操作对每个记录运行模型的predict方法，最后它分割流，并将从模型中获得高分的记录id发送到“可疑事件”输出主题，其余的发送到另一个主题。让我们看看这在代码中是怎样的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="b553" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">我们的起点是从Kafka上的<code class="fe mu mv mw mx b">inputTopic</code>主题开始读取消息的<code class="fe mu mv mw mx b">builder.stream</code>方法。我将很快对此进行更多的解释，但请注意，我们将每个kafka记录键序列化为字符串，将其有效载荷序列化为类型为<code class="fe mu mv mw mx b">PredictRequest</code>的对象。PredictRequest是一个Scala case类，对应于下面的protobuf模式。这确保了与消息生成者的集成是直接的，同时也使得生成我们在处理定制对象时需要提供的反序列化/序列化方法变得更加容易。</p><pre class="kg kh ki kj gt my mx mz na aw nb bi"><span id="70ce" class="nc kx iq mx b gy nd ne l nf ng">message PredictRequest{<br/>  string recordID = 1;<br/>  repeated float featuresVector = 4;<br/>}</span></pre><p id="491d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">接下来，我们使用<code class="fe mu mv mw mx b">map()</code>在每个消息携带的数组上调用我们的分类器的<code class="fe mu mv mw mx b">predict()</code>方法。回想一下，这个方法返回一个recordID和score的元组，它是从map操作流回的。最后，我们使用<code class="fe mu mv mw mx b">split()</code>方法创建流的两个分支——一个用于高于0.5的结果，另一个用于其他结果。然后，我们将流的每个分支发送到它们自己指定的主题。订阅输出主题的任何消费者现在都将收到一个可疑记录id的警报(希望如此),接近实时</p><h2 id="deae" class="nc kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated">关于序列化的最后一点意见:</h2><p id="ea95" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在用Scala编写的KS应用程序中使用定制类或对象，无论是Kafka记录的键还是值，都需要为类型提供一个隐式的<code class="fe mu mv mw mx b">Serde[T]</code>(包括它的序列化器和反序列化器)。因为我使用了一个原型对象作为消息有效载荷，所以大部分繁重的工作都由<code class="fe mu mv mw mx b">scalapbc</code>来完成，它将一个原型模式“编译”成一个Scala类，这个类已经包含了解序列化/序列化这个类的重要方法。让这个隐式val对流方法可用(在范围内或通过导入)可以实现这一点。</p><pre class="kg kh ki kj gt my mx mz na aw nb bi"><span id="5fce" class="nc kx iq mx b gy nd ne l nf ng">implicit val RequestSerde: Serde[PredictRequest] = Serdes.fromFn(</span><span id="7769" class="nc kx iq mx b gy ns ne l nf ng">  //serializer<br/>  (request:PredictRequest) =&gt; request.toByteArray,</span><span id="134b" class="nc kx iq mx b gy ns ne l nf ng">  //deserializer<br/>  (requestBytes:Array[Byte]) =&gt; <br/>Option(PredictRequest.parseFrom(requestBytes))</span><span id="a013" class="nc kx iq mx b gy ns ne l nf ng">)</span></pre><h1 id="0b26" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">5.结论</h1><p id="921f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">实时最大似然预测的需求变得越来越普遍，并且经常给数据流管道带来相当多的挑战。最常见和最可靠的方法通常是使用Spark或Flink，主要是因为它们支持ML和一些Python用例。然而，这些方法的一个缺点是，它们通常需要维护一个专用的计算集群，这有时会过于昂贵或大材小用。</p><p id="3849" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在这篇文章中，我试图基于Kafka Streams勾勒出一种不同的方法，这种方法除了您已经在使用的应用服务器和流平台之外，不需要额外的计算集群。作为一个生产级ML模型的例子，我使用了XGBoost分类器，并展示了如何将在Python环境中训练的模型轻松地包装在Scala对象中，并用于对流数据进行推理。当Kafka被用作流平台时，那么使用KS应用程序在所需的开发、维护和性能工作方面几乎总是有竞争力的。</p><p id="e52d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">希望这将有所帮助！</p><p id="6de1" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">***所有图片，除非特别注明，均为作者所有***</p></div><div class="ab cl nt nu hu nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="ij ik il im in"><h2 id="428c" class="nc kx iq bd ky nh ni dn lc nj nk dp lg lx nl nm li mb nn no lk mf np nq lm nr bi translated">笔记</h2><p id="9bca" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">[1] <em class="mk">信用卡欺诈检测数据集</em>，由<a class="ae kv" href="https://mlg.ulb.ac.be/wordpress/" rel="noopener ugc nofollow" target="_blank">机器学习小组</a>(ULB布鲁塞尔自由大学)收集。在开放数据共享下许可公共使用。作者在这里提到了Kaggle的出版物:Yann-al Le Borgne，Gianluca Bontempi <a class="ae kv" href="https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_2_Background/MachineLearningForFraudDetection.html" rel="noopener ugc nofollow" target="_blank">用于信用卡欺诈检测的可复制机器学习——实用手册</a>。该小组的更多工作和关于数据集的信息可在<a class="ae kv" href="https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="cb43" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">(*)完整回购可在<a class="ae kv" href="https://github.com/a-agmon/kafka-streams-ml-classifier" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><p id="bd0d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">(*)模型训练代码可以在<a class="ae kv" href="https://github.com/a-agmon/kafka-streams-ml-model-train" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><p id="3e0c" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">(*)xdboost JVM包文档可以在<a class="ae kv" href="https://xgboost.readthedocs.io/en/stable/jvm/java_intro.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p></div></div>    
</body>
</html>