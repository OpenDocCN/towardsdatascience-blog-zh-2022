<html>
<head>
<title>How to Build a Proper Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建合适的数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-succesful-machine-learning-models-through-proper-datasets-9058f85de5f7#2022-09-06">https://towardsdatascience.com/building-succesful-machine-learning-models-through-proper-datasets-9058f85de5f7#2022-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f936" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">因为坏数据导致坏模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e5c512c13845ae8bbc64498d44892b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v1jntTVy1GN-ErSyyj5ZQA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com/s/photos/map?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@tabeaschimpf?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Tabea Schimpf </a>拍摄的照片</p></figure><h1 id="a801" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">为什么合适的数据集很重要？</h1><p id="2838" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">从根本上说，机器学习模型是一种基于训练数据对自身进行配置以预测结果的东西。如果您输入的模型训练数据并不代表模型在实际使用时将面临的数据，那么除了有缺陷的预测之外，您什么都不能指望。本文将为您提供创建良好数据集的见解，该数据集能够表示模型在现实世界中使用时将面临的数据。</p><p id="1315" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是在我们开始构建伟大的数据集之前，首先，我们必须理解数据集的<strong class="lt iu">组件</strong>(类、标签、特征和特征向量)。然后，我们将继续进行<strong class="lt iu">数据准备</strong>。这就是我们<strong class="lt iu">处理缺失特征</strong>和<strong class="lt iu">缩放特征</strong>的地方。接下来，我们讨论为什么以及如何对数据集进行<strong class="lt iu">分区。</strong>最后，我们将看看为什么我们应该对我们的数据进行最后一次<strong class="lt iu">检查</strong>以及如何发现仍然可能存在的问题，例如<strong class="lt iu">异常值</strong>和<strong class="lt iu">误标</strong> <strong class="lt iu">数据</strong>。</p><p id="7dbd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们开始吧。</p><h1 id="f985" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据集的组件</h1><h2 id="127b" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">类别和标签</h2><p id="87ad" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在分类任务中，输入要素被映射到离散输出变量。例如，通过考虑输入数据，模型预测输出是“狗”、“猫”、“马”等。这些输出变量被定义为<strong class="lt iu">类</strong>。训练数据中的每个输入都有一个名为<strong class="lt iu">标签</strong>的标识符来表示这些类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/a8855de42485f04872443ac76db48978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_G6qaEllhLEY_Mh10w1_Sw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类模型如何将输入数据分类。</p></figure><p id="c598" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对一个模型来说，输入只是数字。模型不关心或不知道狗的图像或声音样本之间的区别。这也适用于标签。因此，类可以用我们想要的任何方式来表示。在实践中，我们经常使用从0开始的整数值来将标签映射到它们各自的类。下面是一个例子。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="7bb6" class="ms la it ng b gy nk nl l nm nn">┌───────┬────────────┐<br/>│ Label │   Class    │<br/>├───────┼────────────┤<br/>│     0 │ person     │<br/>│     1 │ bicycle    │<br/>│     2 │ car        │<br/>│     3 │ motorcycle │<br/>│     4 │ airplane   │<br/>│     5 │ bus        │<br/>│     6 │ train      │<br/>│     7 │ truck      │<br/>│     8 │ boat       │<br/>│     9 │ traffic    │<br/>└───────┴────────────┘<br/>The table is an exerpt from the <a class="ae ky" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank">COCO dataset</a>, showing its classes and labels.</span></pre><p id="3af6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在上面的示例中，表示自行车的每个输入都标记为1，表示船的每个输入都标记为8。你现在可能会想，我们到底在贴什么标签？一个人或者一条船的投入实际上是什么？这就是最重要的<strong class="lt iu">特性</strong>出现的地方。</p><h2 id="160f" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">特征和特征向量</h2><p id="60ec" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">要素是模型用来生成标签作为输出的输入。如上所述，这些是数字，根据任务的不同代表不同的东西。例如，在包含三种鸢尾花数据的<a class="ae ky" href="https://www.kaggle.com/datasets/uciml/iris" rel="noopener ugc nofollow" target="_blank">鸢尾数据集</a>中，<strong class="lt iu">特征</strong>是萼片和花瓣的尺寸。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="60da" class="ms la it ng b gy nk nl l nm nn">The <strong class="ng iu">four available features </strong>in the iris dataset for the iris flower species known as Setosa are shown below. <br/>(only the first 5 rows of the dataset are shown) </span><span id="5889" class="ms la it ng b gy no nl l nm nn">   <strong class="ng iu">Sepal.Length  Sepal.Width  Petal.Length  Petal.Width   </strong>Species <br/>1          5.1          3.5           1.4          0.2    setosa<br/>2          4.9          3.0           1.4          0.2    setosa<br/>3          4.7          3.2           1.3          0.2    setosa<br/>4          4.6          3.1           1.5          0.2    setosa<br/>5          5.0          3.6           1.4          0.2    setosa</span></pre><blockquote class="np nq nr"><p id="3d26" class="lr ls ns lt b lu mn ju lw lx mo jx lz nt mp mc md nu mq mg mh nv mr mk ml mm im bi translated">注:上述数据集中的<strong class="lt iu"> <em class="it">类</em> </strong>为鸢尾花的不同种类，<strong class="lt iu"> Setosa </strong>，<strong class="lt iu"> Virginica </strong>和<strong class="lt iu"> Versicolor </strong>分别赋予这些类<strong class="lt iu"> <em class="it">标签</em> </strong> 0、1和2。</p></blockquote><p id="073f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，特征只是我们将用作机器学习模型输入的数字。当训练机器学习模型时，该模型学习输入特征和输出标签之间的关系。我们在这里假设特征和标签之间实际上存在关系。在没有要学习的关系的情况下，模型可能无法训练。</p><p id="c7d4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一旦训练结束，学习到的关系用于预测输入<strong class="lt iu">特征向量</strong>(作为输入给出的特征集)的输出标签，其中<strong class="lt iu">未知</strong>类别标签。如果模型继续做出错误的预测，原因可能是用于训练模型的特征不足以识别良好的关系。这就是为什么选择正确的功能在任何机器学习项目的开始都很重要。更多关于选择好的特性和为什么坏的特性应该被忽略的信息可以在我下面的帖子中找到。</p><div class="nw nx gp gr ny nz"><a rel="noopener follow" target="_blank" href="/feature-selection-choosing-the-right-features-for-your-machine-learning-algorithm-379bda9f3e05"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">特征选择:为你的机器学习算法选择正确的特征</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">有时候，少即是多</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">towardsdatascience.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ks nz"/></div></div></a></div><p id="4e40" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">特征可以是不同的类型，例如浮点数、整数、序数值(自然的、有序的类别，其中值之间的差不总是相同的)和分类值(其中数字用作代码，例如男性=0，女性=1)。</p><blockquote class="np nq nr"><p id="ddee" class="lr ls ns lt b lu mn ju lw lx mo jx lz nt mp mc md nu mq mg mh nv mr mk ml mm im bi translated">概述:特征是表示我们已知的东西的数字，可以帮助建立与输出标签的关系。看看下面Iris数据集的一些行，现在显示了所有组件、要素类和标注。包含所有四个特征的每一行是一个特征向量。</p></blockquote><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="9527" class="ms la it ng b gy nk nl l nm nn">                      Features                          <br/>          ________________|_____________________       Class   Label<br/>         |                                      |        |       |<br/><strong class="ng iu">Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species</strong> <br/>    5.1          3.5           1.4          0.2       setosa     0<br/>    7.1          3.0           5.9          2.1       virginica  1<br/>    4.7          3.2           1.3          0.2       setosa     0<br/>    6.5          3.0           5.8          2.2       virginica  1<br/>    6.9          3.1           4.9          1.5       versicolor 2</span></pre><h1 id="2aea" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">准备数据</h1><p id="092a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">既然我们已经很好地掌握了数据集所包含的内容，那么在我们开始构建伟大的数据集之前，有两件重要的事情需要考虑:</p><ul class=""><li id="0188" class="oo op it lt b lu mn lx mo ma oq me or mi os mm ot ou ov ow bi translated">如何处理缺失的特征值</li><li id="3a69" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated">特征缩放</li></ul><h2 id="abf2" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">处理缺失的功能</h2><p id="b03b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">您可能会遇到数据中缺少要素的情况，例如，您可能忘记进行测量，或者某个样本的某些数据已损坏。大多数机器学习模型不具备接受缺失数据的能力，所以我们必须用一些数据来填充这些值。</p><p id="7afd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这种情况下，您可以采取两种方法。您可以添加一个远远超出要素范围的值，因为模型对该值的重视程度较低，或者使用数据集上要素的平均值来代替缺失值。</p><p id="fa5f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在下面的示例中，缺少一些功能，用空格表示。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="a811" class="ms la it ng b gy nk nl l nm nn"><strong class="ng iu">Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Label</strong> <br/>    5.1          3.5           1.4                      0<br/>    7.1                        5.9          2.1         1<br/>    4.7          3.2                        0.2         0<br/>                 3.0           5.8          2.2         1<br/>    6.9          3.1           4.9          1.5         2</span></pre><p id="4732" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">计算所有特征的平均值，如下表所示</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d657" class="ms la it ng b gy nk nl l nm nn"><strong class="ng iu">Sepal.Length  Sepal.Width  Petal.Length  Petal.Width </strong><br/>    5.95         3.2           4.5          1.5          </span></pre><p id="5dea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过用平均值替换缺失值，我们可以获得可用于训练模型的数据集。这并不比拥有真实数据更好，但在数据丢失时应该足够好了。如果数据集足够大，另一种方法是通过生成的直方图识别该模式(最常出现的值)。</p><h2 id="87df" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">特征缩放</h2><p id="c534" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">通常，由不同特征组成的特征向量可以具有多个不同的范围。例如，一组要素的值介于0和1之间，而另一个要素的值介于0和100，000之间。另一个会在-100到100之间。因此，一些特征将由于其较大的范围而支配其他特征，这导致模型在准确性方面受到影响。为了克服这个问题，使用了<strong class="lt iu">特征缩放</strong>。</p><p id="f409" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了理解这一概念以及巩固我们在上述章节中所学的内容，我们将创建一个合成数据集并查看它。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="bf2b" class="ms la it ng b gy nk nl l nm nn">┌────────┬─────┬──────┬──────┬───────────┬────────┬───────┐<br/>│ <strong class="ng iu">Sample</strong> │ <strong class="ng iu">f1  </strong>│<strong class="ng iu">  f2  </strong>│ <strong class="ng iu"> f3 </strong> │<strong class="ng iu">    f4     </strong>│ <strong class="ng iu">  f5   </strong>│<strong class="ng iu"> Label</strong> │<br/>├────────┼─────┼──────┼──────┼───────────┼────────┼───────┤<br/>│      0 │  30 │ 3494 │ 6042 │  0.000892 │ 0.4422 │     0 │<br/>│      1 │  17 │ 6220 │ 7081 │ 0.0003064 │ 0.5731 │     1 │<br/>│      2 │  <strong class="ng iu"><em class="ns">16 │ 3490 │ 1605 │ 0.0002371 │   0.23</em></strong> │     0 │<br/>│      3 │   5 │ 9498 │ 7650 │ 0.0008715 │ 0.8401 │     1 │<br/>│      4 │  48 │ 8521 │ 6680 │ 0.0003957 │ 0.3221 │     1 │<br/>│      5 │  64 │ 2887 │ 6073 │ 0.0005087 │ 0.6635 │     1 │<br/>│      6 │  94 │ 6953 │ 7970 │ 0.0005284 │ 0.9112 │     0 │<br/>│      7 │  39 │ 6837 │ 9967 │ 0.0004239 │ 0.4788 │     1 │<br/>│      8 │  85 │ 9377 │ 4953 │ 0.0003521 │ 0.5061 │     0 │<br/>│      9 │  46 │ 4597 │ 2337 │ 0.0004158 │ 0.8139 │     0 │<br/>└────────┴─────┴──────┴──────┴───────────┴────────┴───────┘<br/>The first column is the sample number. <br/>Each row of a sample is an input to the model, given as a <strong class="ng iu">feature vector.<br/></strong>A feature vector is represented by 5 <strong class="ng iu">features</strong> for each sample<br/>- feature set is {f1, f2, f3, f4, f5}<br/>- Typically the full feature vector is refered to with the uppercase letter (F).<br/>- Feature vector for sample 3 can be refered to as F3. <br/>One feature vector is highlighted in bold for sample 2 in the table.<br/>The last column is the <strong class="ng iu">label</strong>. There are two <strong class="ng iu">classes</strong>, represented by the labels 0 and 1.</span><span id="1311" class="ms la it ng b gy no nl l nm nn">Notice how samples start with 0. This is because we work with Python and Python is 0 indexed.</span></pre><p id="fd8f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在到缩放部分。您可以在我们的综合数据表中看到，不同的特性有不同的范围。让我们看看所有的特征，并考虑它们的最小值、最大值、平均值和范围值。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="acfe" class="ms la it ng b gy nk nl l nm nn">┌──────────┬───────────┬───────────┬──────────┬────────────┐<br/>│ Feature  │   Range   │  Minimum  │ Maximum  │  Average   │<br/>├──────────┼───────────┼───────────┼──────────┼────────────┤<br/>│ f1       │        89 │         5 │       94 │       44.4 │<br/>│ f2       │      6611 │      2887 │     9498 │     6187.4 │<br/>│ f3       │      8362 │      1605 │     9967 │     6035.8 │<br/>│ f4       │ 0.0006549 │ 0.0002371 │ 0.000892 │ 0.00049316 │<br/>│ f5       │    0.6812 │      0.23 │   0.9112 │     0.5781 │<br/>└──────────┴───────────┴───────────┴──────────┴────────────┘</span><span id="572f" class="ms la it ng b gy no nl l nm nn">Notice how the features have widely varying ranges. This means that we should carry out feature scaling.</span></pre><p id="400c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们来看两种缩放方式。首先，我们考虑最简单的方法，称为<strong class="lt iu">，意思是定心</strong>。这是通过减去整个数据集中要素的平均值来实现的。整个集合的平均值就是每个值的总和除以值的总数。</p><p id="34b5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">f1的平均值是44.4。因此，为了使f1居中，我们将属于f1特征的每个样本值替换为值-44.4。对于样本0，它是30–44.4，对于样本2，它是17–44.4，依此类推。对所有值都这样做，我们得到下表。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="5a90" class="ms la it ng b gy nk nl l nm nn">┌────────┬───────┬─────────┬─────────┬─────────────┬─────────┐<br/>│ Sample │  f1   │   f2    │   f3    │     f4      │   f5    │<br/>├────────┼───────┼─────────┼─────────┼─────────────┼─────────┤<br/>│      0 │ -14.4 │ -2693.4 │     6.2 │  0.00039884 │ -0.1359 │<br/>│      1 │ -27.4 │    32.6 │  1045.2 │ -0.00018676 │  -0.005 │<br/>│      2 │ -28.4 │ -2697.4 │ -4430.8 │ -0.00025606 │ -0.3481 │<br/>│      3 │ -39.4 │  3310.6 │  1614.2 │  0.00037834 │   0.262 │<br/>│      4 │   3.6 │  2333.6 │   644.2 │ -0.00009746 │  -0.256 │<br/>│      5 │  19.6 │ -3300.4 │    37.2 │  0.00001554 │  0.0854 │<br/>│      6 │  49.6 │   765.6 │  1934.2 │  0.00003524 │  0.3331 │<br/>│      7 │  -5.4 │   649.6 │  3931.2 │ -0.00006926 │ -0.0993 │<br/>│      8 │  40.6 │  3189.6 │ -1082.8 │ -0.00014106 │  -0.072 │<br/>│      9 │   1.6 │ -1590.4 │ -3698.8 │ -0.00007736 │  0.2358 │<br/>└────────┴───────┴─────────┴─────────┴─────────────┴─────────┘<br/>The synthetic data set we created, after mean centering. <br/>Note that now, the average value for each feature is 0. In other words the center for each feature is 0 and values can be above or below this center.</span></pre><p id="913a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">平均居中足以进行特征缩放。但是我们可以更进一步。请注意，即使我们进行均值居中，范围也是不一样的。通过执行所谓的<strong class="lt iu">标准化</strong>或<strong class="lt iu">标准化</strong>，我们可以将平均值周围的数据分布(标准差)改变到相同的范围内。换句话说，我们把标准差改为1。因为我们还执行均值居中，所以在归一化数据时，除了标准差为1之外，要素的均值为0。</p><p id="7c31" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果我们有一个特征值x，可以简单地用值z代替x，其中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/f84c7c18e97d14604f2b2ae9331f93d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/0*2OH-YZ20f16S0U1M.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">方程式<a class="ae ky" href="https://en.wikipedia.org/wiki/Standard_score" rel="noopener ugc nofollow" target="_blank">计算标准分数。</a></p></figure><p id="b52f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">其中:<em class="ns"> μ </em>是数据集上每个特征的<a class="ae ky" href="https://en.wikipedia.org/wiki/Mean" rel="noopener ugc nofollow" target="_blank">平均值</a>和<em class="ns"> σ </em>的<a class="ae ky" href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener ugc nofollow" target="_blank">标准差</a>。</p><p id="b334" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">幸运的是，由于我们正在使用Python和Numpy，这可以通过一行代码来完成。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="24e2" class="ms la it ng b gy nk nl l nm nn"># Assuming the data is stored in the numpy array F<br/><strong class="ng iu">F = (F - F.mean(axis=0)) / F.std(axis=0)</strong></span></pre><p id="ffb9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这将提供下表:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="dde4" class="ms la it ng b gy nk nl l nm nn">┌────────┬───────┬───────┬───────┬───────┬───────┐<br/>│ Sample │  f1   │  f2   │  f3   │  f4   │  f5   │<br/>├────────┼───────┼───────┼───────┼───────┼───────┤<br/>│      0 │ -0.51 │ -1.14 │     0 │  1.89 │ -0.63 │<br/>│      1 │ -0.98 │  0.01 │  0.43 │ -0.89 │ -0.02 │<br/>│      2 │ -1.01 │ -1.14 │ -1.84 │ -1.21 │ -1.62 │<br/>│      3 │ -1.41 │   1.4 │  0.67 │  1.79 │  1.22 │<br/>│      4 │  0.13 │  0.99 │  0.27 │ -0.46 │ -1.19 │<br/>│      5 │   0.7 │  -1.4 │  0.02 │  0.07 │   0.4 │<br/>│      6 │  1.77 │  0.32 │   0.8 │  0.17 │  1.55 │<br/>│      7 │ -0.19 │  0.28 │  1.64 │ -0.33 │ -0.46 │<br/>│      8 │  1.45 │  1.35 │ -0.45 │ -0.67 │ -0.33 │<br/>│      9 │  0.06 │ -0.67 │ -1.54 │ -0.37 │   1.1 │<br/>└────────┴───────┴───────┴───────┴───────┴───────┘<br/>Now we see that all features are similar to each other, compared to our original dataset. </span></pre><h1 id="9061" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">对数据集进行分区</h1><p id="a579" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">由于我们遵循了上面的步骤，我们现在有了一组很好的特征向量。但是等等！在用它训练我们的模型之前，我们需要做一些事情。我们不应该使用整个数据集来训练我们的模型，因为我们需要将数据集分成两个，或者理想情况下三个子集。这些子集被称为<strong class="lt iu">训练数据</strong>、<strong class="lt iu">验证数据、</strong>和<strong class="lt iu">测试数据</strong>。</p><p id="d853" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">训练数据</strong>用于训练模型。</p><p id="0bd2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">测试数据</strong>用于评估训练模型的准确性和性能。重要的是，模型<em class="ns">永远不要在训练期间看到这些数据，因为那样的话，我们将根据它已经看到的数据来测试模型。</em></p><p id="a7a8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">不是每个型号都需要<strong class="lt iu">验证数据</strong>。但是，当模型是深度学习模型时，它会有所帮助。该数据集的使用类似于训练过程中测试数据的使用。它告诉我们训练过程进行得如何，并提供关于何时停止训练以及模型是否适合数据的信息。</p><p id="1dd9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">综上所述，<strong class="lt iu">训练</strong>和<strong class="lt iu">验证</strong>数据<strong class="lt iu">用于建立模型。<strong class="lt iu">测试数据</strong>被保留以评估模型。</strong></p><h2 id="7981" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">每组应该放多少数据？</h2><p id="9c6a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">根据一些文献，将数据集的90%分成训练数据和5%分别用于验证和测试数据被认为是标准的做法，而其他人建议70%用于训练，15%分别用于较小数据集的验证和测试，或者80%用于训练，10%用于验证和测试。</p><p id="ce07" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">保留数据集中的先验概率很重要。如果一个类以20%的概率存在于现实世界中，这也应该反映在我们的数据集中。这也应该扩展到我们创建的子集。我们如何做到这一点？有两种方法:</p><ul class=""><li id="60de" class="oo op it lt b lu mn lx mo ma oq me or mi os mm ot ou ov ow bi translated">按类别划分</li><li id="018d" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated">随意采样</li></ul><h2 id="68a4" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">按类别划分</h2><p id="e00e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当您处理小型数据集时，可以使用此方法。首先，我们确定每个类有多少个样本。接下来，对于每个类，我们将选择的百分比放在一边，并将所有内容合并在一起。</p><p id="5b2f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">例如，假设我们有500个样本，其中400个属于类别0，100个来自类别1。我们想做一个90/5/5的分割(90%的训练数据，5%的测试和5%的验证)。这意味着我们从类0中随机选择360个样本，从类1中随机选择90个样本来创建训练集。从类别0的剩余未使用的40个样本中，随机选择20个样本用于验证数据，20个用于测试数据。从类别1的剩余未使用的10个样本中，每个样本将进入验证和测试数据集。</p><h2 id="a207" class="ms la it bd lb mt mu dn lf mv mw dp lj ma mx my ll me mz na ln mi nb nc lp nd bi translated">随意采样</h2><p id="1209" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果我们有足够的数据，我们不需要非常精确，并遵循上述方法。相反，我们可以随机化整个数据集，并根据必要的百分比拆分我们的数据。</p><p id="5345" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是如果我们有一个小的数据集呢？我们可以使用诸如<strong class="lt iu"> k倍交叉验证</strong>的方法来确保这种方法的问题，例如训练和测试数据中的不平衡，可以得到缓解。如果你想了解更多关于这个方法的知识，可以看看我下面的帖子。</p><div class="nw nx gp gr ny nz"><a href="https://medium.com/@praveennellihela/what-is-k-fold-cross-validation-5a7bb241d82f" rel="noopener follow" target="_blank"><div class="oa ab fo"><div class="ob ab oc cl cj od"><h2 class="bd iu gy z fp oe fr fs of fu fw is bi translated">什么是K-fold交叉验证？</h2><div class="og l"><h3 class="bd b gy z fp oe fr fs of fu fw dk translated">假设你训练了一个机器学习模型。现在，你需要找出这个模型的表现如何。是不是…</h3></div><div class="oh l"><p class="bd b dl z fp oe fr fs of fu fw dk translated">medium.com</p></div></div><div class="oi l"><div class="pd l ok ol om oi on ks nz"/></div></div></a></div><h1 id="05ba" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">最后看一下我们的数据</h1><p id="5fed" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，我们已经执行了许多操作，以确保我们的数据集足以训练一个模型。我们确保它具有良好的特性，没有缺失的特性，并且这些特性是规范化的。我们还以适当的方式将数据集划分为子集。</p><p id="31ae" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后重要的一步是最后一次查看数据，以确保一切都有意义。这允许我们识别任何<strong class="lt iu">错误标记的数据</strong>和<strong class="lt iu">缺失或异常数据</strong>。这些错误可以通过将数据加载到电子表格中来识别，或者对于更大的数据集，使用Python脚本来汇总数据。我们应该查看平均值、中值、标准偏差以及最大值和最小值，以了解是否有任何异常数据。我们还可以生成<a class="ae ky" href="https://en.wikipedia.org/wiki/Box_plot" rel="noopener ugc nofollow" target="_blank">箱线图</a>来识别异常值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/2f9f20864170f8a4798e23a981421d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rCAQoPDr4nmKaFDQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">迈克尔逊实验的方框图示例，用户:史高斯——自己的作品，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=1501411" rel="noopener ugc nofollow" target="_blank">公共领域</a>，</p></figure><p id="28b3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在执行了上述所有步骤后，我们可以确信我们的数据集是一个合适的数据集，可以帮助模型很好地训练，进而对现实世界的数据产生准确可靠的预测。这可能看起来很费力，但请永远记住，如果你给你的机器学习模型输入垃圾，它们只会输出垃圾。您应该始终确保您的数据集足够好。</p><h1 id="ed86" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><p id="cf4c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这篇文章中，我们看了为什么一个好的数据集是重要的。然后，我们通过查看组件(如类和要素)来了解数据集的构成。我们讨论了数据准备以及如何处理缺失特征和缩放特征。接下来，我们讨论了为什么以及如何对数据集<strong class="lt iu">进行分区。</strong>最后，我们了解了为什么我们应该对我们的数据进行<strong class="lt iu"> </strong>最终检查，以及如何发现仍然存在的问题，例如异常值和错误标记的数据。</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="7630" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你觉得这篇文章有用，可以考虑<a class="ae ky" href="https://medium.com/@praveennellihela/subscribe" rel="noopener">订阅</a>我和<a class="ae ky" href="https://medium.com/@praveennellihela/membership" rel="noopener">加入媒体</a>。你的会员支持我和你直接阅读的其他作家。</p><p id="484a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">感谢您的阅读！在以后的帖子中再见。</p></div></div>    
</body>
</html>