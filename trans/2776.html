<html>
<head>
<title>The Mystery of ADASYN is Revealed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿达辛之迷被揭开了</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-mystery-of-adasyn-is-revealed-73bcba57c3fe#2022-06-15">https://towardsdatascience.com/the-mystery-of-adasyn-is-revealed-73bcba57c3fe#2022-06-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/107198ed5aa7802856e5008cbdff34de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VuZi0iQSYXsV2qU68EUzyQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="http://Eduardo Sánchez" rel="noopener ugc nofollow" target="_blank">艾德亚多·桑奇兹</a>在<a class="ae jd" href="https://unsplash.com/images" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><div class=""/><div class=""><h2 id="5d5e" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">如果你认为你知道ADASYN在预测模型中做什么，你很可能错了。继续读下去，我们将向你展示非凡的真理。</h2></div><p id="8c04" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lr">首席研究员:戴夫·古根海姆/合作研究员:斯里什·蒂鲁马莱</em> </strong></p><p id="3bc6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">前言</strong></p><p id="2e3e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这项研究假设您熟悉类不平衡和ADASYN算法。我们强烈建议我们的读者阅读推出ADASYN的会议文章(只需输入谷歌学术或查看本文的参考资料部分)，然后阅读《走向数据科学》中讨论类别失衡和ADASYN的任意数量的文章。</p><p id="12ad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为这既不是指南，也不是概述；这是一次探索未知领域的航行，有着惊人的发现。</p><p id="f777" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">简介</strong></p><p id="b4fa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一开始，我们想研究三个主要问题:</p><ol class=""><li id="548b" class="ls lt jg kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">学习模型和它们的预测对阶级不平衡有不同的敏感度吗？</li><li id="c73a" class="ls lt jg kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">ADASYN是否在一系列综合样本比率和学习模型中提供稳定的预测？</li><li id="ec77" class="ls lt jg kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">ADASYN到底在用看不见的数据做什么？</li></ol><p id="b7a3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">答案依次是令人惊讶、引人入胜和非同寻常。但首先，我们将分享实验的基础。</p><p id="66d7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">型号定义</strong></p><p id="98d0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这项研究中的所有模型都是使用sci-kit learn库中的RandomForest和LogisticRegression算法进行的，以分别获得关于树和线性结构的信息。在train_test_split中使用“分层=y ”,在GridSearchCV中使用“cv=10 ”,用分层抽样对所有预测模型进行10倍交叉验证。</p><p id="7f51" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随机森林模型的所有超参数都保留其默认状态，并且“random_state=1”应用于所有用于分区、处理(ADASYN)和建模的随机种子选择。</p><p id="2773" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里使用的线性函数是LogisticRegression+GridSearchCV。每个二元逻辑回归分类模型使用以下超参数运行:</p><p id="7c69" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">1)惩罚= 'l2 '</p><p id="80e3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">2) C = 1E42</p><p id="d07f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">3)求解器= 'liblinear '</p><p id="4dbb" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">4) class_weight =无</p><p id="56fa" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">5) cv = 10</p><p id="5448" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">6) max_iter = 5000</p><p id="6c1c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">7)得分=“准确性”</p><p id="485a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">8)随机状态= 1</p><p id="064d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了保持liblinear解算器的使用(它支持l1和l2罚分，并且我们在研究中专门使用它作为公平竞争的场所)，该解算器选择需要设置正则化罚分。在这种情况下，我们选择“l2”或ridge作为惩罚，但因为我们只对ADASYN的效果感兴趣，所以我们通过将“C”设置得非常大来禁用它。通过这种方式，我们不必引入特征缩放作为数据预处理组件，鉴于我们之前的发现，这是有问题的(<a class="ae jd" rel="noopener" target="_blank" href="/the-mystery-of-feature-scaling-is-finally-solved-29a7bb58efc2">特征缩放的奥秘最终被Dave Guggenheim |向数据科学迈进</a>)解决。所有其他超参数都保留默认值。</p><p id="6c56" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于样本大小始终是机器学习的一个问题，如果数据集的每个预测器的样本少于12个，作为泛化误差的设定点(Shmueli，Bruce，Gedeck和Patel 2019)，我们保留10%的人口作为测试样本。对于超过24个样本/预测值的模型，我们将数据集分成相等的两半，50%用于训练，50%用于测试。在这两个值之间，我们使用了一个等式来平衡测试集与足够大的训练集的泛化误差(Abu-Mostafa，Magdon-Ismail，&amp; Lin，2012，第。57).</p><p id="c7e8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中四个数据集包含缺失值，因此为了与之前的研究保持一致，我们使用了缺失值插补的MissForest算法(<a class="ae jd" href="https://pypi.org/project/MissForest/" rel="noopener ugc nofollow" target="_blank"> MissForest PyPI </a>)，因为它能够抵抗噪声、异常值或多重共线性的有害影响。此外，我们选择完全哑编码分类预测器，而不是选择名义或顺序数据类型的替代算法。因为线性模型和树模型都在本研究中，所以对于逻辑回归和随机森林模型，虚拟编码分别具有丢弃和未丢弃的子类型。和往常一样，如果一个潜在的预测值明显较低或没有信息，如身份证号码，它会在数据预处理之前被丢弃。</p><p id="4a6d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">构建这些模型的目的是检查ADASYN的影响，而不是调整模型以获得最佳结果。出于这个原因，我们在模型中引入了尽可能多的默认值，为上述比较创造了一个平台。</p><p id="0c74" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">与我们之前的研究一样，这项工作包含了方差的随机函数，因此结果是基于学习模型看不到的数据。所有混淆矩阵及其相关分析都代表了真实世界的测试数据。</strong></p><p id="fe3b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">数据集</strong></p><p id="4fad" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表1列出了本次分析中使用的30个开源数据集，这些数据集是根据其数据类型和复杂性选择的。UCI索引(<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets.php" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库:数据集</a>)托管了这些数据集的大部分。其他不在UCI索引中的位于Kaggle ( <a class="ae jd" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank">查找开放数据集和机器学习项目| Kaggle </a>)。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/e7efad45ca104a689e9b3537986c74c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*M8vDNWjOJCiJuk1WUY8rvg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表1数据集及其来源(图片由作者提供)</strong></p></figure><p id="6970" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">类别不平衡不足以生成合成样本的数据集被排除在考虑范围之外；否则，它们被选择来代表如图1所示的大范围的不平衡。Classdiff或阶级差异度量是从多数阶级的百分比中减去少数阶级的百分比。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/9e2295af7cfe78079d0a96b61f00e7ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*CWqBP2AmD5qp0NOfxHBTKQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图1数据集及其类别不平衡(图片由作者提供)</strong></p></figure><p id="824c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">目标变量完全是二项式的，因为ADASYN只能对二元分类数据进行操作。现在，关于这些问题…</p><p id="d3c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">学习模型及其预测对班级失衡的敏感度不同吗？</strong></p><p id="df09" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">令人惊讶的答案是否定的，至少对于这两款车型来说是否定的。为了确定这种情况，我们测量了所有数据集的随机森林和逻辑回归的不平衡模型中假阴性测试数据的百分比。假阴性浓度的升高表明对类别不平衡的更大敏感性，这是由于对真阳性(少数类别)的错误分类倾向的增加。详情参见图2。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mg"><img src="../Images/2df96b1182d853c8cb59ba9a466bc78b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*3a3RGWEWOZmiWgwg407ATA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图2类不平衡敏感度结果(图片由作者提供)</strong></p></figure><p id="c3d7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不平衡随机森林模型平均有7.967%的测试数据为假阴性，而不平衡逻辑回归模型平均为8.51%，由于未能拒绝零，多重t检验证实它们代表相同的分布(见图3、4和5)。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/6d9ec88604c455ba275b750a7b8ac058.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*70rX2cqR_2-R_mQXNrwRtQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图3配对双样本t检验(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/a6dec915e82018a25cf6dc2b805a719e.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*6fim2gaSqmu0z-TPMrwEeQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图4假设方差相等的双样本t检验(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/a0538d1ca98c44093be5227f53948ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*ct1In5yFDqg1rnyuR9UKRg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图5假设方差不等的双样本t检验(图片由作者提供)</strong></p></figure><p id="0510" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">两种截然不同的学习模式，但两者对班级失衡的平均预测敏感度相同。将测试更多的模型类型，以确定类别不平衡是否是一种普遍的、预测不可知的现象。</p><p id="57f0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">ADASYN是否在一系列综合比率和学习模型中提供稳定的预测？</strong></p><p id="8a90" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ADASYN提供了更改合成样本比率的能力，从默认的50/50分布(具有最大数量的合成样本)降低到不生成合成样本的数据的自然类别不平衡。每个图表在顶部显示数据集的名称，并显示一系列使用ADASYN ratio函数的模型，并用y轴上的F1分数进行测量(标记为“准确性”)。选择F1评分是因为它是ADASYN作者(何、白、加西亚和李，2008)推荐的一般衡量标准。x轴包含多数/少数类的比率，表示为与50/50起点的偏差。阅读x轴刻度线的快速指南如下:</p><p id="23e7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">a.0 =五五比</p><p id="69f5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">b.10 = 55/45比率(50+5和50–5)</p><p id="54b0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">c.20 = 60/40比率(50+10和50–10)</p><p id="cf2a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">d.30 = 65/35比率(50+15和50–15)</p><p id="70e4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">e.40 = 70/30的比例(等等。)</p><p id="8a2f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">f.50 = 75/25的比例(等等。)</p><p id="67d3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">g.60 = 80/20的比例(等等。)</p><p id="c276" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">默认的50/50 ADASYN分布在最左侧，而自然不平衡出现在最右侧。定义这些线的每个序列模型代表了从50/50起点直到达到自然不平衡的2%的阶级差异增加(每个模型=多数+1和少数-1)。蓝色的点(在最左边)表示没有平衡的训练数据，而橙色的点(相同的区域)显示没有平衡的测试数据。水平的蓝色和橙色线分别显示了平衡的训练和测试数据，即序列模型。</p><p id="ad6e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每组有两个地块，数据集用随机森林拟合，然后用逻辑回归拟合(见图6-11)。我们希望了解在合成样本、数据集和模型的范围内，测试数据标绘线的干扰程度，从而了解标绘体积。</p><p id="921a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将在这里谈论它们，这样你就可以跳过情节，更快地到达ADASYN揭示。基本上，随机森林在所有数据集的比率范围内大多是稳定的，而逻辑回归可能会变得相当混乱，迷人的逐步函数导致稳定的量子水平。这些量子能级的数学描述，特别是它们的维度的确定，应该在未来的工作中探索。</p><p id="5495" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不管学习模型如何，在几乎所有情况下，默认的50/50 ADASYN处理都是稳定的，并在测试数据上提供了最佳性能。但是，也有一些例外(例如，使用两种模型的流失建模、RandomForest的信贷批准以及LogisticRegression的德国信贷)。请参考下面的图表，了解这个1，000+模型实验的图示。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/521c6b3f91187e5d73007431cdf6fcc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*i8Sj1RyF_zs008ozJoKryg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图6随机森林的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/83e8f7fe27650b15c64aaf8775ad9a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*UU37Zx6AnIOdB_z1ZT4kbg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图7逻辑回归的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><p id="967d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意:澳大利亚信用证明数据在没有综合调整的情况下接近平衡(训练集中的284/233类样本)。在随机森林中没有ADASYN改进，但尽管在训练数据中注入了有限数量的合成样本，但逻辑回归显示了更好的性能。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/8a255fd7e09e5ce1967e763d0a2f2f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*_rpu4Dg2u3oVosx1iytgoQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图8随机森林的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/80cd82a83734f04a9f1c6c337ba9f5ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*e2B0k7OGZJbZIXk9kShpcw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图9逻辑回归的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/e25de5b7c912ce869af94b61a68ade53.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*4t32Gx3v7p9ndFTkfZ7riQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图10随机森林的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/eb40e197dd60c6a2e9a8309574022bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*gfUUTU1Za9-iTAEoShBnyA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图11逻辑回归的ADASYN比率稳定性(图片由作者提供)</strong></p></figure><h1 id="8145" class="mr ms jg bd mt mu mv mw mx my mz na nb km nc kn nd kp ne kq nf ks ng kt nh ni bi translated"><strong class="ak">阿达辛被揭露</strong></h1><p id="777d" class="pw-post-body-paragraph kv kw jg kx b ky nj kh la lb nk kk ld le nl lg lh li nm lk ll lm nn lo lp lq ij bi translated">对于大多数数据集，ADASYN单独将测试样本从真阴性转换为假阳性(上侧)和从假阴性转换为真阳性(下侧)，分别在每个侧内一一对应。少量数据集沿相反方向行进，<strong class="kx jh">在每个横向内也是一对一的</strong>。更多详情请参考图12。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi no"><img src="../Images/c75279232e879f9380678d53654e8691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w0eQpw39ac0EH35vcqon_A.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图12混淆矩阵横向转移</strong></p></figure><p id="ed14" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下四个图表(图13-16)显示了真阴性(TN)、假阳性(FP)、假阴性(FN)和真阳性(TP)的增量，以应用ADASYN后测试数据的百分比变化进行测量。随机森林模型是前两个图表，逻辑回归紧随其后。每对图中的第一个(图13和15)显示了真阴性和假阳性之间的关系，每对图中的第二个(图14和16)显示了假阴性和真阳性之间的关系。</p><p id="f81e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">向左移动的条形表示测试数据减少了一定的百分比，向右移动的条形表示测试数据增加了一定的百分比——这是不平衡模型的增量。<strong class="kx jh">由于ADASYN* </strong>，相反方向的等长条“蝴蝶的翅膀”显示了混淆矩阵中从左侧象限到其横向关系的直接转移</p><p id="849f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">*完全由这些图表背后的数字数据支持。统计支持无关紧要，因为转让的绝对值是相同的。</em></p><p id="ab56" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">随机森林模型</strong></p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi np"><img src="../Images/122b575f3cfc5c56c072cea2cd309d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xe08OxksY2i-3jC4Pzn05Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图13随机森林模型的TN-FP上部横向混淆转移(图片由作者提供)</strong></p></figure><p id="b1e6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于随机森林模型，30个数据集中的26个显示了从真阴性到假阳性的数量完全相等的零或正值转移(8个为0，18个为正值)。这些结果不会导致分母发生变化，但会导致<strong class="kx jh">特异性(TN/(TN+FP)) </strong>的分子减少，从而导致捕获TN-FP转移的源和汇的指标总体减少。</p><p id="e95e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">绝对不应该使用Precision，因为它无法为假阳性接收器捕获真正的阴性源。此外，永远不要使用F1分数，因为它的分子和分母都很精确。</strong></p><p id="2be0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">四个数据集显示了与这种情况相反的情况，发生了从假阳性到真阴性的转移。这一现象将很快被探究。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/b426555653b731ed65a6138bee4f91dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3vbDYuwbdocSfKv0nNhRQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图14随机森林模型的FN-TP较低横向混淆转移(图片由作者提供)</strong></p></figure><p id="263a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">移动到FN-TP维度，30个数据集中的26个显示了从假阴性到真阳性的数量完全相等的零或正计数转移(4个为0，22个为正值)。这些结果不会改变分母，但会增加<strong class="kx jh">灵敏度(TP/(TP+FN)) </strong>的分子，从而总体增加捕获FN-TP传输的源和汇的度量。</p><p id="5b7f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">四个数据集显示了与这种情况相反的情况，从真阳性到假阴性发生转移，这也将很快被探究。</p><p id="d5a9" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">逻辑回归模型</strong></p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nr"><img src="../Images/ff854bccbcab15f81cd57d926ebf9a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7N0aQHgut-3Cosjlvj51iA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图15逻辑回归模型的TN-FP上横向混淆转移(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/72bf2644dab19fb3b6cece90dc8a8c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_mJBb4HiEm7Xi_GuSMbGNQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图16逻辑回归模型的FN-TP下侧混淆转移(图片由作者提供)</strong></p></figure><p id="5aa0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于逻辑回归模型，30个数据集中的26个显示了从真阴性到假阳性的完全等量的零或正值转移(4个为0，22个为正值)。此外，移动到FN-TP维度，30个数据集中的26个也显示了从假阴性到真阳性的完全等量的零值或正值转移(6个零值，20个正值)。</p><p id="c3c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如上所述，特异性和敏感性应用于分析，因为它们分别包括混淆转移的源和汇(更多信息见图17)。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/10cd19592dfd05f810d3861ee922a356.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*4c7oyEzfs-IA3ybJ0LiOUQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图17敏感性和特异性指标(从</strong> <a class="ae jd" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank">敏感性和特异性—维基百科</a> <strong class="bd ml"> ) </strong></p></figure><p id="be03" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">性能的一般测量可以从<strong class="kx jh">信息</strong>开始，它等于<strong class="kx jh">特异性+灵敏度1 </strong>。另一个度量可以是灵敏度和特异性的调和平均值，作为F1分数的适应[<strong class="kx jh">2 *(TPR * TNR)/(TPR+TNR))</strong>。然而，F1评分<strong class="kx jh"> </strong>受到了批评，因为它认为特异性与敏感性具有相同的值，但这种情况很少发生。有一个可调的F1分数，它使用β系数来引起两个基本度量之间的偏移(sklearn.metrics中的fbeta_score ),这可以进行调整，但选择该系数是有问题的。其他人提出将<strong class="kx jh">马修斯相关系数</strong>作为衡量二元变量的更好指标(Chicco &amp; Jurman，2020)。</p><p id="6740" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">反向转账</strong></p><p id="76de" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">反向转移是指假阳性变成真阴性，真阳性变成假阴性。有七个数据集导致反向转移，三个专用于随机森林模型，一个专用于逻辑回归，三个生成反向转移而不考虑学习模型(见表2)。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/67a07c17a8f89fa51185924e935d79d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*KxIE0RplGg8ZWN6K1bXumg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表2反向转移(图片由作者提供)</strong></p></figure><p id="494f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果TN和FN都增加(如<strong class="kx jh">粗体</strong>所示)，则发现一对匹配的横向混淆象限。该表以颜色编码，灰色表示未知，黄色表示样本量问题，绿色表示共享MissForest。</p><p id="681f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关注随机森林模型(见图18和19)，四个(从顶部数，第四个)中的两个较小的反向转移之一可能是由于样本大小的问题。在这种情况下，每个预测器的样本远少于12个(即p &gt;&gt; n ),并且观察到微小的反向转移。虽然这是轶事，但样本大小始终是机器学习中的一个问题，这些微小的反向转移可能是模型不稳定的结果。在这些潜在样本量问题的情况下，TN-FP和FN-TP转移维度之间缺乏匹配，进一步暗示了模型的不稳定性。BostonHousing是一个异常，因为尽管反向转移的影响可以忽略不计，但样本大小似乎不是一个问题——这将在以后的研究中进一步研究。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/000121f8ba229b5cfeeca1a79a41e324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IVDYrudICLHndbFl6RI4zA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图18随机森林模型的FP-TN反向转移(图片由作者提供)</strong></p></figure><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/8b9bd2d0c29de0fd6553ec720b55ef4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iLycEuZ9kLem3aoQS4ZTWA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">图19随机森林模型的TP-FN反向传输(图片由作者提供)</strong></p></figure><p id="1de4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，在两个数据集中发生了更大的反向迁移，而不管学习模型和样本大小是不是一个问题。这两个数据集(Lending Club和NBA新秀)具有匹配的反向转移(FP转换为TN <strong class="kx jh">和</strong> TP转换为FN ),除了通过逻辑回归显著增加TN% delta和FN% delta之外，几乎没有其他相似之处；例如，与不平衡模型相比，NBA新秀的真阴性增加了29.1%，假阴性增加了25.37%(以及相应的FP和TP减少)。NBA新秀都是数字，有大量浮点预测值，而Lending Club有八个分类变量，由于one-hot编码导致更大的稀疏化(见表3)。它们共有的一个属性是都使用了MissForest缺失值插补算法。事实上，在导致反向转移的七个数据集中，其中四个使用了MissForest算法，这是仅有的四个缺少值的数据集。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/239e92b4b459a9f869ac1d0e33bc9e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*sYBYrATWjskzmm5Yphe81w.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表3匹配大额反向转账的数据集(图片由作者提供)</strong></p></figure><p id="3315" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">ADASYN在内部使用k-最近邻(kNN)算法，并将缺失值插补算法更改为sklearn.impute库中的KNNImputer，从而实现了微小的改进，例如，乳房x光照片和Wisc Prog从不匹配的反向传输转换为小比例的匹配正向传输；基本上实现了正常运行。虽然测量了小的改善，但Lending Club和NBA新秀仍然存在反向转移的严重问题，这是一个值得进一步研究的无法解释的现象。</p><p id="8e46" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但这确实提出了一个有趣的应用点——在使用ADASYN时，我们应该考虑使用kNN缺失值插补，因为它在每种缺失值的情况下都能提供稍好的性能。</p><p id="dca0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">商业分析场景</strong></p><p id="7f0d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">特异性</strong>和<strong class="kx jh">敏感性</strong>虽然是很好的指标，但都无法捕捉到混淆矩阵中相对侧的信息。特异性定义了上侧，而敏感性衡量了下侧，但两者都无法“看到”等式的另一侧。衡量标准I<strong class="kx jh">inform ness</strong>有助于解决这个问题，但是更好的理解来自于经济分析，它包含了混淆矩阵的所有四个象限，并在成本/收益关系中将它们标准化。虽然假阴性和假阳性几乎总是有相关的成本，但真阴性和真阳性可能是成本或收益，这取决于场景，这限制了在业务设置中对性能的一般测量的有用性。</p><p id="3d96" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，如果TN-FP转移的负值大于FN-TP转移的正值，则ADASYN的表现将低于不平衡模型。相反，如果FN-TP转换产生的绝对值大于TN-FP维度，则ADASYN辅助模型将更优越。</p><p id="6871" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下四个场景探讨了经济绩效的概念，并通过简化的案例展示了几种可能的结果。</p><p id="2e31" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lr">场景1员工流失</em> </strong></p><p id="1f84" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，目标变量Gone表示已经离开组织的雇员。由于雇佣和培训新员工的成本，准确预测即将到来的辞职可能相当重要，即使没有大的辞职。</p><p id="e925" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据美国劳动局的数据，更换一名员工的成本可能高达高管年薪的200%，但全国平均水平为年薪的21%。防止辞职的干预成本是不可用的，因为它们通常是定制的，所以我们选择年薪的4%作为保留成本。应该注意的是，这种保持成本会随着时间和条件而变化。从劳动局也获得了按职业估算平均工资的数据。</p><p id="6b4d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TN =员工不受影响，这是中性的。</p><p id="b2c4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FN =员工将在没有干预的情况下离开；替换成本*计数为负</p><p id="799d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FP =员工不会离开，但无论如何都要干预；维护成本*计数为负</p><p id="40f1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TP =员工将离职，但干预被阻止；维护*计数的成本为负值，但更换*计数的成本为正值。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/02173fbd0552ac62ebae3c48e6017cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*F9qeGJVPMf4SJExxqmEx6w.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表5员工流失经济绩效分析(图片由作者提供)</strong></p></figure><p id="9068" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表4表明ADASYN辅助的随机森林优于该系列中的所有其他模型。</p><p id="30c5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lr">场景二信用审批</em> </strong></p><p id="687a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这种情况下，我们选择的平均信用值为10，000美元，该值的违约成本为25%。</p><p id="bc7c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TN =信用被批准，金额*计数被添加为正数</p><p id="5507" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FN =信用已批准，但金额*默认成本*数量为负值</p><p id="2957" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FP =信用被拒绝，金额*计数为负数</p><p id="7239" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TP =信用被拒绝，这导致节省违约成本*计数为正数</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/d1d5f6daccf276cd70b5abc1715b62ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*6a4yvKrg1ZHXRiDPwabXew.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表5信贷审批经济绩效分析(图片由作者提供)</strong></p></figure><p id="b1be" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表5表明，无辅助随机森林模型优于该系列中的所有其他模型。</p><p id="3324" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lr">场景3客户流失(电信客户流失)</em> </strong></p><p id="ba09" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们曾在电信行业使用预测模型，我们估计替换一个客户的成本为500美元，保留一个客户的成本为50美元，这是基于真实世界的信息，这些信息曾经是正确的，但现在可能已经过时了。</p><p id="1bf7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TN =客户不受影响，这是中性的。</p><p id="04a1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FN =客户将离开，无需干预；替换成本*计数为负</p><p id="41e1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FP =客户不会离开，但无论如何都要干预；维护成本*计数为负</p><p id="b105" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TP =客户将离开，但干预被阻止；维护成本*计数为负</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/d0bc99db0e5614fb77be62f1e81f87bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*F9FNOjg9aooKXzo1YDPa2w.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表6客户流失经济表现分析(图片由作者提供)</strong></p></figure><p id="d318" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表6表明ADASYN辅助的逻辑回归优于该系列中的所有其他模型。请记住，这是一个简化的场景，没有考虑客户收入，因此经济方面的更多细节可能会导致转向不同的模式。</p><p id="05ef" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh"> <em class="lr">场景4贷款审批(贷款俱乐部)</em> </strong></p><p id="3a4e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为它可能是反向转移的有害影响的来源，我们选择这个数据集来研究这些事件的影响。在本例中，我们选择的平均贷款批准额为25，000美元，违约成本为6，250美元。</p><p id="c544" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TN =贷款被批准，贷款金额*计数被添加为正数</p><p id="c59b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FN =贷款已批准，但贷款金额*违约成本*计数为负数</p><p id="4352" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">FP =贷款被拒绝，贷款金额*计数为负数</p><p id="a9b3" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">TP =贷款被拒绝，这节省了违约成本*计数为正数</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/2797bf782a4b2b11cb26a4d9b1ad1c6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*Fnts9EockKQYm6CaFkmfng.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd ml">表7贷款审批经济绩效分析(图片由作者提供)</strong></p></figure><p id="b028" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表7表明ADASYN辅助的逻辑回归优于该系列中的所有其他模型。这个场景展示了反向转移是如何提高业绩的，因为有更多的真负值，并且在这个场景中，TN象限有一个很大的正估值。尽管假阴性有所增加，但违约成本无法抵消贷款收益，但我们认为这种情况很少发生，因为TN象限通常不会有这么大的估值。</p><p id="4cb5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">结论</strong></p><p id="ee69" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的调查让我们对阶级不平衡和ADASYN的问题有了一些真正发人深省的见解。</p><p id="8889" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当我们研究阶级不平衡对我们学习模型的影响时，不平衡测试数据中的假阴性比例表明随机森林和逻辑回归预测对阶级不平衡具有相同的敏感性。有趣的是，ADASYN似乎对学习模型之间的结果有不同的影响，正如“蝴蝶”图显示的上侧和下侧。</p><p id="8c6b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当在两个模型上实现ADASYN时，数据显示随机森林通常具有稳定的预测，而不管使用的合成比率如何，而逻辑回归模型往往受各种比率的影响更大。这种现象超出了本研究的范围，但将在未来进行研究。</p><p id="1c0d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">也许我们最有意义的发现是在不平衡模型上原子水平上的ADASYN辅助转换。ADASYN创建的从FN-TP和TN-FP横向转移的概念在决定该算法是否应该用于平衡数据集时非常有利，并且还显示了ADASYN在应用于业务分析时的影响力。</p><p id="d153" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经证明了混乱矩阵的最终形成不是由于波函数的坍缩——我现在正在抚摸薛定谔的猫！虽然这是一种机械现象，但TN-FP和FN-TP转换的简单性和普遍性是非同寻常的。</p><p id="42cf" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在可以通过一个更清晰的镜头来看待ADASYN，从这个镜头中我们可以更好地分析我们的模型，并获得更有意义的结果。</p><p id="e2e1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">未来研究</strong></p><p id="1978" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">未来对类别不平衡的研究将进一步探索模型的敏感性，以发现具有抵抗性的模型。用不同的学习模型，如支持向量机和boosted树，以及不同的不平衡算法，如SMOTE、KMeansSMOTE、BorderlineSMOTE等，重复这个实验设计。可能会很有趣。此外，了解反向转移也提上了日程，尤其是两个具有极端效应的数据集。此外，我们将试图理解出现在比率图中的量化水平，以及它们是否与其他不平衡算法一起发展。</p><p id="f924" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">参考文献</strong></p><p id="c60b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Abu-Mostafa，Y. S .、Magdon-Ismail，m .、和Lin，H.-T. (2012年)。<em class="lr">学习资料</em>(第四卷)。美国纽约AMLBook</p><p id="3e75" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">奇科博士和朱尔曼博士(2020年)。马修斯相关系数(MCC)在二分类评估中相对于F1分数和准确性的优势。<em class="lr"> BMC基因组学</em>，<em class="lr"> 21 </em> (1)，6。<a class="ae jd" href="https://doi.org/10.1186/s12864-019-6413-7" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1186/s12864-019-6413-7</a></p><p id="8824" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Shmueli，g .，Bruce，P. C .，Gedeck，p .，&amp; Patel，N. R. (2019)。<em class="lr">商业分析的数据挖掘:Python中的概念、技术和应用</em>。约翰·威利的儿子们。</p><p id="cc86" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">何海辉，白，杨，贾亚东，李，等(2008年6月)。ADASYN:用于不平衡学习的自适应合成采样方法。在<em class="lr"> 2008年IEEE国际神经网络联合会议(IEEE世界计算智能大会)</em>(第1322-1328页)。IEEE。</p><p id="719c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">联系方式:</strong></p><p id="ab47" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">dguggen@gmail.com博士:领英简介:大卫·古根海姆博士</p><p id="87b1" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">斯里什·蒂鲁马莱:<a class="ae jd" href="https://www.linkedin.com/in/srish-tirumalai-616727167/" rel="noopener ugc nofollow" target="_blank">领英简介</a>，【stirumalai1@gmail.com】T2</p></div></div>    
</body>
</html>