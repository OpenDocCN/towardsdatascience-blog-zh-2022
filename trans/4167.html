<html>
<head>
<title>How to Convince Your Boss to Trust Your ML/DL Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何说服你的老板相信你的ML/DL模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-convince-your-boss-to-trust-your-ml-dl-models-671f707246a8#2022-09-15">https://towardsdatascience.com/how-to-convince-your-boss-to-trust-your-ml-dl-models-671f707246a8#2022-09-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8167" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用LIME的机器学习模型可解释性，或者如何解释为什么模型做出了特定的预测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fde4efa212c1a03548a204668da68847.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nN1yfOCpUOFu-jlSpWDKpA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">准确性与可解释性(图片由作者提供)</p></figure><h2 id="9b4d" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">简介</strong></h2><p id="1e52" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">一些公司经理或利益相关者对机器学习模型预测持悲观态度。因此，数据科学家有理由让他们相信模型预测是可信的，也是人类可以理解的。因此，我们不仅需要专注于创建强大的机器学习/深度学习模型，还需要使模型能够被人类解释。</p><p id="f288" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">可解释性在许多方面都有帮助，例如帮助我们理解模型如何做出决策，它证明模型预测是正确的并获得洞察力，建立对模型的信任，并且它帮助我们改进模型。有两种类型的ML模型解释——全局和局部。</p><ul class=""><li id="2c8e" class="ms mt it lw b lx mn ma mo lh mu ll mv lp mw mm mx my mz na bi translated"><strong class="lw iu">本地解读</strong>回答问题，为什么模型做出这个具体的预测？</li><li id="e44b" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated"><strong class="lw iu">全球解读</strong>回答了这个问题，预测最重要的特征是什么？</li></ul><blockquote class="ng nh ni"><p id="fa8d" class="lu lv nj lw b lx mn ju lz ma mo jx mc nk mp me mf nl mq mh mi nm mr mk ml mm im bi translated">可解释性是人类能够理解决策原因的程度[Miller，Tim 2017]</p></blockquote><p id="2598" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">在本文中，我们将关注本地可解释性，而<strong class="lw iu">我们将涉及:</strong></p><ol class=""><li id="b950" class="ms mt it lw b lx mn ma mo lh mu ll mv lp mw mm nn my mz na bi translated"><em class="nj">固有的可解释模型</em></li><li id="2b35" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm nn my mz na bi translated"><em class="nj">局部解释方法:石灰</em></li><li id="8b63" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm nn my mz na bi translated"><em class="nj">实际工作—解释玩具数据集上的XGBoost模型预测</em></li><li id="7f84" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm nn my mz na bi translated">石灰的利弊</li></ol><h2 id="85ab" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">1.固有的可解释模型</h2><p id="eab7" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">固有解释模型的好例子是线性回归和决策树。</p><p id="39f5" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu"> 1.1线性回归</strong></p><p id="386f" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">线性回归背后的直觉是，它将目标预测为输入特征的加权和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/c16364cd31871bd55863395188397ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CkcJFusOyKKm7KshtJzWVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">线性回归公式(图片作者提供)</p></figure><p id="5336" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">基于线性回归的假设函数，解释是如此容易。很清楚哪个特征贡献更大，哪个特征对预测最重要。但是任何事情都是有代价的——模型的正确性取决于训练数据中的关系是否满足某些假设，例如<a class="ae np" href="https://en.wikipedia.org/wiki/Linearity" rel="noopener ugc nofollow" target="_blank">线性</a>、<a class="ae np" href="https://en.wikipedia.org/wiki/Normalization_(statistics)" rel="noopener ugc nofollow" target="_blank">正态性</a>、<a class="ae np" href="https://en.wikipedia.org/wiki/Homoscedasticity_and_heteroscedasticity" rel="noopener ugc nofollow" target="_blank">同方差性</a>、<a class="ae np" href="https://en.wikipedia.org/wiki/Independence_(probability_theory)" rel="noopener ugc nofollow" target="_blank">独立性、</a>和无<a class="ae np" href="https://en.wikipedia.org/wiki/Multicollinearity" rel="noopener ugc nofollow" target="_blank">多重共线性</a>。</p><p id="5f8b" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">可以在<a class="ae np" rel="noopener" target="_blank" href="/fish-weight-prediction-regression-analysis-for-beginners-part-1-8e43b0cb07e"> <strong class="lw iu">上一篇</strong> </a>中看到线性回归算法的详细解释。</p><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/fish-weight-prediction-regression-analysis-for-beginners-part-1-8e43b0cb07e"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">鱼重预测(初学者回归分析)——第一部分</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">如何使用顶级线性ML算法(线性回归、套索回归和岭回归)构建ML回归模型</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh ks nt"/></div></div></a></div><p id="90f5" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu"> 1.2决策树</strong></p><p id="31da" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">决策树也很容易解释。此外，它还可以处理特征之间的非线性关系，这是线性回归算法所无法做到的。决策树是通过基于某些标准(即基尼指数)进行分割来构建的，其中数据集的不同子集是通过分割来创建的。我们可以遵循从根节点到叶节点的树的结构，并理解为什么模型做出特定的预测。下面是一个可视化决策树示例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/d850a69e8a659cf1ff048a202289ccd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wDGrDWicTGcaDq5cMxFNYg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决策树示例(图片由作者提供)</p></figure><p id="06cd" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">如果你想了解更多关于决策树是如何工作的，你可以访问我的<a class="ae np" rel="noopener" target="_blank" href="/regression-analysis-for-beginners-using-tree-based-methods-2b65bd193a7">上一篇文章</a>。</p><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/regression-analysis-for-beginners-using-tree-based-methods-2b65bd193a7"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">初学者回归分析—第二部分</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">使用基于树的算法(决策树、随机森林、XGboost)构建ML回归模型</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="oj l oe of og oc oh ks nt"/></div></div></a></div><p id="947e" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu"> 2。局部解释方法:石灰</strong></p><p id="b531" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">随着模型变得越来越复杂，预测能力越来越强，对预测的解释也变得复杂。复杂模型，也称为黑盒模型，如XGBoost、随机森林和神经网络，本质上是不可解释的，因此它们需要额外的方法来理解它们的预测性质。<strong class="lw iu"> LIME </strong>是一种局部解释方法，解释如何对黑盒ML模型进行单独预测。LIME背后的直觉是，它创建了代理模型(即线性回归、决策树)，该模型被训练为近似底层黑盒模型的预测。LIME不是训练一个全局代理模型，而是专注于训练局部代理模型，以解释个体预测。这是下图所示的石灰配方。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/3e67ec178242e5cae32d6bef0345c344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*DQ-6c2WmFTuexaLriqrmOQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">石灰配方(图片由作者提供)</p></figure><p id="d43e" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">局部代理模型的数学表达式是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/77ae0c09d71ea5504cad2447840da7b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*4h_5ku34tErpRaXjgSfZoQ.png"/></div></figure><p id="46f5" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">哪里…</p><ul class=""><li id="7dc3" class="ms mt it lw b lx mn ma mo lh mu ll mv lp mw mm mx my mz na bi translated">我们要解释的一个例子</li><li id="5c73" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">f-原始模型(即深度神经网络，XGBoost)</li><li id="65f0" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">g-代理模型(即线性回归、决策树)</li><li id="f820" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">π_x邻近度，它定义了新生成的数据集应该有多大。</li><li id="7e21" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">l损失(即均方误差、交叉熵)</li><li id="df47" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">ω(g)-模型复杂性</li><li id="9952" class="ms mt it lw b lx nb ma nc lh nd ll ne lp nf mm mx my mz na bi translated">G-一系列可能的解释(即所有可能的线性回归模型、线性回归、套索、岭)</li></ul><p id="35a9" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">在实践中，用户应该确定模型的复杂性，这意味着选择替代模型可以使用的最大数量的特征和样本。</p><p id="552d" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu"> 3。实际工作XGBoost模型的可解释性</strong></p><p id="fe2c" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">在这一节中，我们将讨论LIME的实际实现。我们将在来自<em class="nj"> sklearn </em>的玩具数据集<em class="nj"> load_breast_cancer </em>上做一个实验，这是一个带有标签的数据集，包含关于乳腺癌状况的信息，即它是良性还是恶性的。</p><p id="f4ae" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu">步骤1:导入库和数据集</strong></p><p id="b518" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">首先，我们需要使用<strong class="lw iu"> pip安装石灰</strong>来安装<em class="nj">石灰包</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/5e69a285c9a224f75a7ec8007f0a5e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GcL_hKlFxWEwkGExyoU8MQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据帧结果(作者照片)</p></figure><p id="7a45" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu">第二步:构建XGBoost模型</strong></p><p id="c060" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">加载数据集后，让我们将数据分为训练和测试部分，使用默认超参数创建一个简单的XGBoost模型，并计算混淆矩阵和预测精度。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/75dc0fc6803c91eda1d517fd11762e0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*0h4RFf2hlk9zfExB-OofQA.png"/></div></figure><p id="a8ad" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">结果表明，该模型的准确率为96%；现在是解释个别预测的时候了。</p><p id="2da5" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu">第三步:创建代理模型</strong></p><p id="cb77" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">现在我们创建一个lime表格解释器对象，它将尝试解释单个样本。将在新创建的包含5000个扰动样本的数据集上训练代理模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><p id="e7b2" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated"><strong class="lw iu">步骤4:解读单个样本。</strong></p><p id="95f8" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">在这种情况下，我将尝试对两个随机样本进行解释。一个样本被正确分类，而另一个被错误分类。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="om on l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/659f0caef119f5c532121b12da00e3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S1f0W-31KZkV8YCe8wSLdQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示例1(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/864703f798297804f051108cd4f31b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwSNKqAniP0B1mjSQlv2Nw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">示例2(图片由作者提供)</p></figure><p id="18c3" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">如可视化所示，颜色<strong class="lw iu"> <em class="nj">蓝色</em>和<em class="nj">橙色</em> </strong>分别代表<strong class="lw iu"> <em class="nj">消极</em>和<em class="nj">积极</em> </strong>联想。</p><p id="8b71" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">第一个样本是正确分类的示例，它被分类为良性类。让我们来回答这个问题— <em class="nj">为什么这个样本被归类为良性</em>？因为代理模型说如果特征<em class="nj">【最差纹理】</em> ≤21.05或者<em class="nj">【最差凹点】</em> &gt; 0.06或者<em class="nj">【最差凹点】</em> &gt; 0.12或者<em class="nj">【面积误差】</em> ≤ 18.17或者<em class="nj">【平均凹点】</em> &gt; 0.1那么他们倾向于预测为良性。该样本的所有特征值都满足这些条件，因此该示例被分类为良性。</p><p id="ad4d" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">第二个样本分类错误。问题— <em class="nj">为什么这个样本被错误地归类为良性，尽管它是恶性的？</em>因为从上面的可视化来看，代理模型说前五个特征中的三个特征满足良性属性，并且它们的特征的加权和大于满足恶性属性的特征的加权和。<em class="nj">这就是为什么这个特殊样本被错误分类的原因。</em></p><h2 id="c7b0" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak"> 4。石灰的利弊</strong></h2><p id="e745" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">石灰法的优点是它使解释更人性化。尽管我们讨论了使用表格数据的例子，但是LIME也可以用于文本和图像数据。LIME的缺点之一是采样的数据点来自高斯分布，忽略了特征之间的相关性。此外，有时解释可能不稳定。因为LIME是一个近似值，所以当法律要求您完全解释预测时，它不是一个充分的方法。</p><h2 id="889d" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">结论</strong></h2><p id="c030" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">综上所述，LIME是一个强有力的方法，它回答了我为什么要相信ML模型，以及为什么该模型做出了这个具体的预测？它创建了一个局部代理模型，与初始黑盒模型有很好的近似，这使得个体解释更容易。由于模型是可解释的，数据科学家也更容易让管理者和利益相关者相信预测是可信的。</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><blockquote class="ng nh ni"><p id="b7fb" class="lu lv nj lw b lx mn ju lz ma mo jx mc nk mp me mf nl mq mh mi nm mr mk ml mm im bi translated"><em class="it">希望你喜欢:)，这里也是我GitHub上的</em><strong class="lw iu"><em class="it"/></strong><a class="ae np" href="https://github.com/gurokeretcha/ML_interpretability/blob/main/LIME.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="lw iu"><em class="it">全代码</em> </strong> </a> <em class="it">。</em></p><p id="5295" class="lu lv nj lw b lx mn ju lz ma mo jx mc nk mp me mf nl mq mh mi nm mr mk ml mm im bi translated">下一篇文章将是关于任何ML/DL模型的全局可解释性。</p><p id="fd15" class="lu lv nj lw b lx mn ju lz ma mo jx mc nk mp me mf nl mq mh mi nm mr mk ml mm im bi translated"><em class="it">你可以</em> <strong class="lw iu"> <em class="it">关注我</em> </strong> <em class="it">上</em> <a class="ae np" href="https://medium.com/@gkeretchashvili" rel="noopener"> <em class="it">中</em> </a> <em class="it">保持通知。</em></p></blockquote></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="3780" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">如果你想了解更多关于应用数据科学的知识，这里有<a class="ae np" href="https://www.youtube.com/channel/UCvlF0PPaQ2GAuqYKJT4UpJQ" rel="noopener ugc nofollow" target="_blank"> <strong class="lw iu">我的YouTube频道</strong> </a> <strong class="lw iu">。</strong></p><div class="nq nr gp gr ns nt"><a href="https://www.youtube.com/channel/UCvlF0PPaQ2GAuqYKJT4UpJQ" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">和朋友一起的AI学院</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">与朋友、家人和全世界分享您的视频</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">www.youtube.com</p></div></div><div class="oc l"><div class="oz l oe of og oc oh ks nt"/></div></div></a></div><h2 id="712f" class="ky kz it bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">参考文献:</strong></h2><p id="8acb" class="pw-post-body-paragraph lu lv it lw b lx ly ju lz ma mb jx mc lh md me mf ll mg mh mi lp mj mk ml mm im bi translated">[1] Molnar，Christoph“可解释的机器学习。让黑盒模型变得可解释的指南”(2019)</p><p id="2588" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">[2]米勒，蒂姆“人工智能中的解释:来自社会科学的见解”(2017)</p><p id="410c" class="pw-post-body-paragraph lu lv it lw b lx mn ju lz ma mo jx mc lh mp me mf ll mq mh mi lp mr mk ml mm im bi translated">[3]马尔科·图利奥·里贝罗《机器学习的模型不可知可解释性》(2016)</p></div></div>    
</body>
</html>