<html>
<head>
<title>An Introduction to Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督学习导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/supervised-learning-61256f2aebeb#2022-02-26">https://towardsdatascience.com/supervised-learning-61256f2aebeb#2022-02-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c810" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">其中有一个朴素贝叶斯分类算法的例子</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/e79e65a5308036aea73a4df63e5e8eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BE9Q5-9elTlkQjgc-pi-6g.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片说明|照片由<a class="ae ku" href="https://www.pexels.com/@anniroenkae" rel="noopener ugc nofollow" target="_blank">安妮·伦凯</a>拍摄</p></figure><p id="0049" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这是以彼此为基础的系列文章的继续。请看我上一篇关于<a class="ae ku" rel="noopener" target="_blank" href="/time-series-analysis-7138ec68754a">时间序列分析</a>和<a class="ae ku" rel="noopener" target="_blank" href="/logistic-regression-cebee0728cbf">逻辑回归</a>的文章。</p><p id="9333" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">好吧，让我们从监督学习开始。我在以前的文章中提到了一些，但是让我回顾一下这篇文章的一些细节。</p><ul class=""><li id="e5df" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">监督学习:从已有数据中学习，这些数据被分类并标有预定义的类别。测试数据也被标记到这些类中</li></ul><p id="4979" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这适用于所有类型的学习。但是，具体来说，它有<strong class="kx iu">标记的预定义类</strong>。这是最重要的事情— <strong class="kx iu">监督学习有一个被称为专家标签的东西</strong>。这是一个有趣的词，意思是它被标记为一个结果；或者对于任何给定的情况，都有一个已知的、期望的结果。</p><p id="7e2c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">无监督学习(聚类)并不假设它知道答案。例如，群集将查看数据，并根据数据的状态对数据进行分区。</p><p id="c5b7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">监督学习将根据标签对数据进行分区。这是一个很大的区别。无监督学习的一个例子是聚类。监督学习的一个例子是回归，就像我之前写的一样。</p><p id="7026" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">例如，在回归模型中，我们有X和Y，我们通过它们画一条最佳拟合线。在这个例子中，X是我们的输入，Y是输出。我们可以说这是监督学习，因为Y是专家标签；给定这些专家标签，模型正在学习如何获取X并得出Y。</p><h1 id="e72a" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">示例:</h1><ul class=""><li id="14b3" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated">欺诈交易:我们知道训练数据中哪些交易是欺诈(1)，哪些不是(0)</li><li id="fc2c" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">再入院:我们知道哪些患者在出院后的某个时间窗内再次入院</li><li id="e271" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">推荐:我们知道哪些商品呈现给了客户，哪些商品被点击、添加到购物车或购买了</li><li id="08eb" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">一个典型的例子是垃圾邮件过滤器</li></ul><p id="26f8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">机器学习任务有多种用途。这里有一些经典的机器学习任务的例子:识别欺诈，识别病人的再次入院，识别推荐，就像你典型的网飞机器学习案例，当你去网飞时，你会得到你会喜欢的电影的推荐；这些电影是基于你以前看过的电影，并考虑到其他人在看过与你看过的电影相似的电影时喜欢什么，以及他们看过什么电影，除此之外。这就是所谓的推荐引擎。</p><blockquote class="nc nd ne"><p id="715e" class="kv kw nf kx b ky kz ju la lb lc jx ld ng lf lg lh nh lj lk ll ni ln lo lp lq im bi translated">作为一个题外话，这个推荐引擎是一种灰色区域，可能不总是被描述为监督学习，但我跑题了。</p></blockquote><p id="f7b8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">监督学习的一个经典例子是垃圾邮件过滤器。垃圾邮件过滤器是做什么的？它将你的电子邮件分为垃圾邮件和非垃圾邮件。该模型学习的方式是通过某人，一个“专家”——一个人，来将各种电子邮件标记为垃圾邮件或非垃圾邮件。然后，电子邮件和这些标签被交给一种算法，该算法预计会计算出如何自行从电子邮件到达该标签。这整个过程被称为监督学习。</p><h1 id="482e" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">典型的机器学习任务:</h1><ul class=""><li id="8d59" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated"><strong class="kx iu">分类:</strong>我们能给输入打上标签吗？</li><li id="0335" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated"><strong class="kx iu">回归</strong>:我们能做个预测吗？</li><li id="1be4" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated"><strong class="kx iu">建议</strong>:我们能根据用户偏好预测一些东西吗？</li></ul><p id="0fb2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">监督学习有两个重要步骤:首先，你训练一个模型，然后你测试这个模型。使用看不见的测试数据来测试你的模型是非常重要的。在以前的文章中，我写过监督学习，就像回归一样，我没有使用测试数据，而是使用训练数据来测试模型。这是不好的，不是一件好事。人们偶尔做这件事，做这件事有不同的原因。合法的理由很少，但是有一些。如果你用训练数据来确定你的模型的准确性，那么你充其量是在愚弄自己；最坏的情况是，你在撒谎。</p><p id="9fee" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所以为了测试这个模型，你需要使用所谓的“看不见的测试数据”现在，我们如何创建看不见的测试数据？嗯，这很简单。您只需将您的建模数据分成训练数据和测试数据:在模型已经在训练段上训练之后，测试数据用于模型的测试。</p><p id="468f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们所说的学习是什么意思？你使用数据和算法得出一个性能指标或最小化一个成本函数——这是另一种说法。当你这样做的时候，你将会用新的操作数据提出一个模型，你将会得到一个答案。</p><h1 id="bdbe" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">学习的基本假设</h1><p id="3306" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">学习的一个基本假设是训练样本的分布与测试样本的分布相同，包括未来未知的样本。更重要的是，训练样本的分布与未来的样本足够相似。鉴于它们是未来的例子，它们是看不见的。</p><p id="0823" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想要一个精确的度量，那么这个分布也应该类似于测试例子。这种假设不是必需的。一个要求是，为了让你相信你的准确性，你的测试例子必须和你未来的例子来自同一个分布。</p><p id="499f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果您创建了一个可用的模型，那么您的训练示例来自哪里并不重要。如果你的训练样本来自不同的发行版，那就更有力量了。要成为有效的衡量标准，测试示例必须足够类似于在实际操作数据时使用的示例——当涉及到可操作性时。现在，对上述假设的强烈违反将导致较差的分类准确度。</p><h2 id="cc62" class="nm mb it bd mc nn no dn mg np nq dp mk le nr ns mm li nt nu mo lm nv nw mq nx bi translated">机器学习框架</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi ny"><img src="../Images/fb66ce7ea3628dc2597eb1f42cabf845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSzY2JvbjdMIsVrkRxUZGQ.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="6805" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">训练:</strong>给定一个<em class="nf">训练</em>的标记样本集{(x_1，y_1，… (x_n，y_n)}，估计使训练集上的预测误差最小的预测函数(f)和参数(θ)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a29e5565d438101d0e967b323f4ca08a.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*h0CDa5x-LeQCen98-9meaA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">培训功能|作者图片</p></figure><p id="dcbc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">测试:</strong>将(f)应用于一个从未见过的<em class="nf">测试</em>例子(x)并输出预测值(y = f(x))</p><p id="b8ed" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在整个机器学习框架中，你给一个X，然后你得到一个y。这将会有一些误差，因为有一些随机噪声与一切相关。这意味着你得到的实际Y，并不完全是上面的函数。</p><h1 id="596e" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated"><strong class="ak">分类工作流程</strong></h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi oe"><img src="../Images/5ee8b7775e5a5a99dec111323187bf7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IAsxwJYW7GKp-LVpgksdmA.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">分类工作流程图|按作者分类的图片</p></figure><p id="f158" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最重要的是数据必须分成训练集和测试集。模型是在训练集中开发的，模型是在测试集上评估的。最后，您可以获得性能度量，也称为准确性度量。这里有三个性能度量:其中称为准确性的性能度量可能是最差的性能度量。准确率和召回率都相当不错。有一个更好的方法是精确度和召回率的混合，即F1分数。</p><p id="6340" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我更喜欢它的原因是它是召回率和精确度的混合体。你会希望有良好的回忆和准确性。如果你有非常好的回忆和非常糟糕的精确度，反之亦然，你的模型是没有价值的。对于二元分类，有一个更好的准确性衡量标准ROC AUC。</p><p id="aa69" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">所以ROC曲线的曲线下面积是用来分类的。它之所以优于以前的性能度量，是因为它对所有阈值都有效；而准确度或精确度假定一个阈值，通常假定阈值为0.5。同样，F1分数也假定阈值为0.5。你可以选择不同的阈值，但大多数人不会认为你会选择不同的阈值。</p><p id="aa64" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">之所以选择不同的阈值，是因为您可能有不同的目的，其中您的假阳性可能比假阴性更糟糕，反之亦然。通过调整你的阈值，你可以权衡这些。</p><h2 id="7905" class="nm mb it bd mc nn no dn mg np nq dp mk le nr ns mm li nt nu mo lm nv nw mq nx bi translated">许多分类器可供选择</h2><ul class=""><li id="a6c2" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated">线性回归</li><li id="f0b7" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">逻辑回归</li><li id="8492" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">支持向量机(SVM)</li><li id="96b5" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">神经网络(安，有线电视新闻网，RNN，DNN)</li><li id="e0ce" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">朴素贝叶斯</li><li id="2c49" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">贝叶斯网络</li><li id="ef6e" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">随机森林(随机森林)</li><li id="c4dc" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">提升决策树(梯度提升树)</li><li id="c129" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">k-最近邻(KNN)</li></ul><p id="d7d8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这里是所谓的分类器，监督学习中使用的算法。KNN通常被认为是你最简单的概念，并且经常在这样的课上教授，因为算法相对简单:你可以从头开始写算法。</p><p id="ed5d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">增强决策树和随机化森林曾经是你通常喜欢的机器学习分类算法。今天，“最新”类型的算法是神经网络。当我说最新的时候，我的陈述是大约5到10年前的，这取决于你如何看待它。但是直到大约五年前，Kaggle竞赛<a class="ae ku" href="https://www.kaggle.com/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/data?scriptVersionId=0" rel="noopener ugc nofollow" target="_blank">是由增强的决策树和随机森林赢得</a>。现在，深度神经网络正在赢得Kaggle比赛。所以不是神经网络，而是一种更复杂的神经网络，叫做深度神经网络(DNN)。</p><p id="b66b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">逻辑回归是每个人的最爱——每当你做一个分类，你首先做一个逻辑回归，总是这样！从这个意义上来说，朴素贝叶斯也是一个很好的例子。但是逻辑回归可能更进一步。所以你总是做逻辑回归。不是因为你想炫耀逻辑回归的结果。只是它是如此的强大，你知道如果你不能让逻辑回归起作用，你也不能让其他任何东西起作用。所以逻辑回归是你要做的第一件事。当这种方法奏效时，你就开始变得更加大胆，尝试上面列出的其他算法。</p><h1 id="ac7d" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">一般化</h1><p id="6733" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated"><strong class="kx iu">欠拟合</strong>:模型过于“简单”，无法表示所有相关的类特征——高训练误差和高验证误差。</p><p id="357f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">过拟合</strong>:模型过于“复杂”，拟合数据中不相关的特征(噪声)——训练误差低，验证误差高(训练和验证性能差距大)</p><p id="8dad" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">一般化意味着它工作得有多好。作为一个很好的启发<strong class="kx iu">每当你说一般化，你会想到正规化</strong>。为什么要这么做？因为你概括一个模型的方法是通过正则化这个模型。如果你有一个很好的正则化模型，它大概是广义的。泛化是什么意思？这意味着它不仅仅在最小的环境下也能工作。因此没有出现过拟合。欠拟合模型通常过于简单，需要做更多的工作来从中提取信息。但是过拟合模型不够一般化，需要正则化。</p><h1 id="6558" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">机器学习中的常见陷阱</h1><ul class=""><li id="d755" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated"><strong class="kx iu">过拟合</strong></li><li id="a447" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated"><strong class="kx iu">欠拟合</strong></li><li id="ef00" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated"><strong class="kx iu">数据泄露</strong>:在训练数据中产生意想不到的额外信息，产生不切实际的好预测。将测试数据泄露到训练数据中。包含模型操作环境中不存在的数据</li></ul><p id="808a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">很少有欠拟合的陷阱，可能是算法的使用过于原始，导致了某种程度的欠拟合，因为人们可能已经停止了逻辑回归，他们应该使用梯度提升树，如果你想认为这是一种欠拟合。如前所述，过度拟合是你的一个大问题。</p><p id="4978" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，下一个大问题是数据泄漏或任何类型的代理列或代理。这些问题经常发生。这个概念很难理解，很难解释，很难教为什么这样的事情会经常发生，除非你自己做过。</p><p id="2187" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">例如，你已经查看了一个月的数据，并对其进行了处理，只有当你的测试结果出来后，你才能看到你的机器学习算法的测试结果，比如你的准确率为. 97。这时你才意识到，“哦，我一定是数据泄露了。”简而言之——你很少能得到这么好的模型。然后你必须剖析你的模型，你必须找出为什么你的模型好得不真实。而你的模型好到不真实的原因，通常是因为数据泄露。</p><blockquote class="nc nd ne"><p id="a3dc" class="kv kw nf kx b ky kz ju la lb lc jx ld ng lf lg lh nh lj lk ll ni ln lo lp lq im bi translated">一个现实生活中的例子:前列腺癌模型包括一个变量，表明患者是否进行了前列腺癌手术。模型看不到未来，患者是否做过手术的数据应该已经从模型中删除以进行训练。</p></blockquote><h1 id="ba2d" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">混淆矩阵</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi of"><img src="../Images/713b0cbf3e44d4f5ee1f2e7d4524b88f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8ODG1d__f3IMLpJuFOjjw.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">混淆矩阵的编码</p></figure><p id="6f68" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这是一个混淆矩阵的例子。关于这些混淆矩阵的一个重要注意事项是，它们通常在左上角有真负值，在右下角有真正值。之所以会这样，现在看来，是因为零小于一。因为真正的否定通常被建模为零，所以首先列出它们在数字上是有意义的。当你把你的实际类和你的预测类简化成计算机最容易理解的形式时，你就把它们简化成了0和1。因为零比一小，所以零先去，一后去。因为0比1小，所以0在垂直方向上也是先走，然后是1。零通常与缺少某物联系在一起，通常与否定联系在一起。</p><p id="edba" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这里，阴性并不是一件坏事——如果我是新冠肺炎阴性，这意味着我没有COVID，或者至少我的测试结果是COVID阴性。如果我没有COVID，那么这就是我所说的真负值。同样，编码为1 1意味着我确实有COVID，并且我检测结果为阳性。</p><p id="59a1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这就是为什么真阴性和真阳性是这样排列的:真阴性在左上方，真阳性在右下方。情况并不总是这样——过去是相反的！但这是你最近大部分时间看到的。这和0和1的排序有关！</p><p id="a6b3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">精确度和召回率是需要理解的重要概念，但超出了本文的范围。正如我上面提到的，我更喜欢F1分数，精度和回忆的调和平均值(相对于算术平均值)作为我的“准确性”指标，而不是选择任何一个。但是分类的最佳性能测量是ROC曲线。</p><p id="19fd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">受试者工作特征(ROC)曲线对于分类非常有用。我相信这是最重要的准确性测量，但有时它不能使用。这是有原因的，但一般来说，ROC曲线是你想要使用的。之所以要用ROC曲线，是因为它考虑了所有的阈值。为了说明这一点为什么重要，考虑这个假设的面试问题:给人们假阳性、真阳性、假阴性和真阴性的数字——每种数字有10个。所以这可能会给你最差的准确度分数:0.5</p><blockquote class="nc nd ne"><p id="4aee" class="kv kw nf kx b ky kz ju la lb lc jx ld ng lf lg lh nh lj lk ll ni ln lo lp lq im bi translated">顺便说一下，如果你的模型精确到了0.01，那么只要把你的0类和1类的标签换一下，你的模型就会突然精确到0.99</p></blockquote><p id="15b2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是如果你看看概率，真阳性和真阴性的概率:都是0和1左右——意味着它们是好的。假阳性和假阴性的概率都在0.5左右，这意味着它们非常糟糕。这意味着错误是不可靠的，正确的结果是非常好的或非常安全的；因此，您将因此获得更高的ROC AUC分数！你将永远不会看到任何类似的其他准确性措施，因为<strong class="kx iu">他们不考虑概率。他们只考虑布尔结果</strong>:它是真的正还是不是真的正？</p><h1 id="8237" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">朴素贝叶斯</h1><p id="fd43" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">朴素贝叶斯模型的一些属性是</p><ul class=""><li id="990d" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">不需要先验知识</li><li id="f476" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">计算复杂度与参数/特征的数量成线性关系</li><li id="7ecc" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">需要最少的数据来生成概括良好的模型</li><li id="d4c4" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">具有简单和固有的正则化</li></ul><p id="0d93" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">一些应用:</p><ul class=""><li id="2871" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">文件分类</li><li id="53eb" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">垃圾邮件检测</li><li id="7378" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">图像分类</li></ul><p id="786e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">是的，朴素贝叶斯中的贝叶斯确实指的是贝叶斯定理，我之前<a class="ae ku" rel="noopener" target="_blank" href="/bayesian-statistics-11f225174d5a">写过</a>关于它。贝叶斯定理和朴素贝叶斯模型之间也有非常明确的联系。然而，朴素贝叶斯模型的假设是个体维度是独立的，或者说是朴素的。这意味着贝叶斯定理的重要部分，你可以把A的概率和B的概率联系起来，或者不需要交集。我们在这里天真地认为，我们说这些概率是相互独立的。因此条件概率基本上消失了。这就是朴素贝叶斯中的“天真”——表现得好像你的数据维度是独立的。</p><p id="f573" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果您的数据维度不是独立的，那么您的朴素贝叶斯将不会很好地工作。一个令人惊讶的结果，或者至少令人惊讶的是，如果你过于关注独立性的要求，朴素贝叶斯模型在你的维度不完全独立的情况下仍然可以很好地工作。不管怎样，我的观点是，在考虑贝叶斯定理时，一些最困难的部分因为朴素贝叶斯而变得非常简单；因为你假设概率是相互独立的——因此不需要计算或假设条件概率。维度独立性假设允许您将概率彼此相乘，这大大简化了训练和测试模型所需的计算。</p><p id="45d9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">就像逻辑回归是如何被用作分类器一样，你可以称之为逻辑分类器。因此，朴素贝叶斯的一个更好的名字可能是朴素概率模型，以远离贝叶斯定理中固有的条件概率。</p><h1 id="93f2" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">朴素贝叶斯的陷阱</h1><ul class=""><li id="13c7" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated">小概率相乘导致浮点下溢。这个问题可以通过计算对数概率ln(p)来解决</li><li id="a0fb" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">如果没有样本/数据，则p(xj | Ck) = 0，导致概率的乘积为0。拉普拉斯平滑器用于确保所有p(xj | Ck) &gt; 0</li><li id="5dd3" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">共线特征不显示独立性。理想情况下，应将此类要素从数据集中移除，以防止模型出现问题</li><li id="6165" class="lr ls it kx b ky mx lb my le mz li na lm nb lq lw lx ly lz bi translated">正则化通常是朴素贝叶斯模型的一个小问题，因为无信息特征趋向于均匀分布，这不会影响结果</li></ul><h1 id="258a" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">朴素贝叶斯模型的类型</h1><p id="fb2c" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">现在我们已经研究了朴素贝叶斯模型的基础，让我们看看一些具体的公式。重要的是要记住，每一类问题都需要一个特定的朴素贝叶斯模型。</p><p id="8e14" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">多项式朴素贝叶斯分类器</strong>是模型的一种广泛使用的形式。多项式分类器从多种可能性中找到最可能的类。为了防止数值下溢，我们编写这个分类器，取等式两边的对数如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/9faad2608cdae4fa62dcbf656460af21.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*171fccbPxHOTAbVCl6C5wA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="4c5f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">那么最有可能的𝑦̂班是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/541059895a7bc43821412c210beac9f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*vz2v52QqhxEBbIr9gwzEaw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="0064" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对于伯努利或二元情况，多项式分类器可以简化为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/0a9a6c58ff9c9ef660b3678e8f8297e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*0IUbUYpqpo7DFChelufGyQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="6367" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">文档分类示例</h1><ul class=""><li id="fe60" class="lr ls it kx b ky ms lb mt le mu li mv lm mw lq lw lx ly lz bi translated">朴素贝叶斯主题模型使用以下关系，基于单词{w1，w2，…，wn}的出现，计算文档D具有主题C的概率:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/493072e8f69e409439496078db2ac9b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*wQZOpv71IOiftu0rstEtew.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">信用:<a class="ae ku" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="9bfd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这个文档分类的例子中，你有各种各样的文档，一个所谓的文档语料库。这意味着您有一个文档集合，并且这些文档以某种方式被标记。首先，给一个文档一个“专家”标签(垃圾邮件或非垃圾邮件)。在应用标签之后，你要做的是为每个单词创建一个列，这意味着每个单词都变成了一个布尔列，就像一键编码一样。</p><p id="9f24" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">对文档中的每个单词重复这个过程。有很多方法可以减少列数，但我的观点是朴素贝叶斯对于文档分类非常有用。现在，有什么这样的例子吗？例如，这份文件是否抄袭？这份文件到底是不是假新闻？这到底是不是垃圾邮件？朴素贝叶斯之所以是一种受欢迎的方法，是因为该模型不介意巨大的维数。可能会有一些性能下降或保真度下降，导致分类器在大量数据维的情况下不具有良好的准确性。但是，有办法去除多余的输入。从计算上来说，这非常快，因此它是文档分类的首选。</p><h1 id="4e11" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">Python代码示例</h1><p id="6e0c" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">既然理论已经奠定，让我带你看一个实际的例子。下面是朴素贝叶斯模型的一个简单例子。想想1984年美国众议院435名议员的政党和16项重要法案的投票。</p><p id="0039" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我将使用这个数据集建立并测试一个分类器来预测国会议员的政党。让我们从进口开始:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="007c" class="nm mb it on b gy os ot l ou ov">import pandas<br/>import numpy<br/>import seaborn<br/>from matplotlib import pyplot</span><span id="79c9" class="nm mb it on b gy ow ot l ou ov">%matplotlib inline</span><span id="2799" class="nm mb it on b gy ow ot l ou ov">votes = pandas.read_csv('<a class="ae ku" href="https://archive.ics.uci.edu/ml/datasets/congressional+voting+records" rel="noopener ugc nofollow" target="_blank">https://library.startlearninglabs.uw.edu/DATASCI410/Datasets/house-votes-84.</a>csv', header=None, <br/>names=['class', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9','V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16'])<br/>print(votes.shape)<br/>votes.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/35ee59fdfc6344724d47d4c25821bdbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*TTuBaF1h8vfAJnvteSD9zQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">形状和数据集的前5行|作者的图像</p></figure><h1 id="8c75" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">分配主题</h1><p id="57a2" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">上述数据框中的每个投票列都对应于以下主题，因此让我们用更容易记住的名称来替换列名:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="c6de" class="nm mb it on b gy os ot l ou ov">vote_names = [<br/>    'handicapped_infants',<br/>    'water_project_cost_sharing',<br/>    'adoption_of_the_budget_resolution',<br/>    'physician_fee_freeze',<br/>    'el_salvador_aid',<br/>    'religious_groups_in_schools',<br/>    'anti_satellite_test_ban',<br/>    'aid_to_nicaraguan_contras',<br/>    'mx_missile',<br/>    'immigration',<br/>    'synfuels_corporation_cutback',<br/>    'education_spending',<br/>    'superfund_right_to_sue',<br/>    'crime',<br/>    'duty_free_exports',<br/>    'export_administration_act_south_africa']</span><span id="f64b" class="nm mb it on b gy ow ot l ou ov">votes.columns = ['class'] + vote_names<br/>votes.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi oy"><img src="../Images/8b91ecc163a949bf9b0d4ffd5b592dd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4RvalkAuwVwhrVFiYLpp4A.jpeg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">重新标记的列|作者图片</p></figure><h1 id="fdfb" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">视觉探索—条形图</h1><p id="eb98" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">为了进一步了解这个数据，我们来做一些前5票的剧情。下面单元格中的代码为<code class="fe ok ol om on b">Class</code>政党的这些投票创建了条形图。执行这段代码并检查结果:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="6233" class="nm mb it on b gy os ot l ou ov"># Convert dataframe columns to "category" type to take advantage<br/># categorical utilities like facet-based plotting in seaborn</span><span id="8bff" class="nm mb it on b gy ow ot l ou ov">votes['class'] = pandas.Categorical(votes['class'].astype('object')<br/>    , categories=['republican', 'democrat'])</span><span id="f345" class="nm mb it on b gy ow ot l ou ov">values = ['y', 'n', '?']<br/>vote_dtype = pandas.api.types.CategoricalDtype(categories=values)<br/>for c in votes.columns[1:]:<br/>    votes[c] = votes[c].astype('object').astype(<br/>        vote_dtype)<br/>democrats = votes[votes['class'] == 'democrat']<br/>republicans = votes[votes['class'] == 'republican']<br/>for vote_col in votes.columns[1:6]:<br/>    pyplot.subplot(1, 2, 1)<br/>    pyplot.hist([1 if x == 'y' else 0 for x in democrats[vote_col]])<br/>    pyplot.title('Democrats: \n' + vote_col)<br/>    pyplot.ylabel('count')<br/>    pyplot.subplot(1, 2, 2)<br/>    pyplot.hist([1 if x == 'y' else 0 for x in republicans[vote_col]])<br/>    pyplot.title('Republicans: \n' + vote_col)<br/>    pyplot.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/5f943cc1873d0b9f06eba816ea199516.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*-FpuJ4_lzZXF_wIYXz23ZA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/c70c2479f107a786bc393daf82d49c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*EKt7PlxgfScQCvJoCdqh0Q.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/1b6de93ebc9671d7f5ba485622b676ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*JfmughvF75cE88SSulrZSg.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="6433" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当检查这些图表时，请记住，在这个数据集中，民主党人比共和党人多——因此它不是完全平衡的。重要的是每个政党的成员投赞成票或反对票的概率。有些投票因党派关系而颇为偏颇，比如“通过预算决议”。然而，有些投票在政党中有相似的概率，例如“水项目成本分摊”。这些政党的投票概率用于训练朴素贝叶斯模型。</p><h1 id="c512" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">训练和测试模型</h1><p id="f8b9" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">现在我们已经了解了一些数据的特征，是时候训练和测试一个朴素贝叶斯模型了。python <code class="fe ok ol om on b">sklearn.naive_bayes</code>包提供了一个库，用于训练朴素贝叶斯模型，并生成一个可以对新实例进行预测的模型对象:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="ed3b" class="nm mb it on b gy os ot l ou ov">import sklearn.model_selection as m_s<br/>Votes_Train, Votes_Test = m_s.train_test_split(votes)<br/>votes = Votes_Test</span><span id="0107" class="nm mb it on b gy ow ot l ou ov">label_col = 'class'</span><span id="f21f" class="nm mb it on b gy ow ot l ou ov"># Convert our categorical values to numeric feature vectors<br/>feature_vecs = numpy.array([<br/>        votes[c].cat.codes <br/>        for c in votes.columns <br/>        if c != label_col]).T<br/>print(feature_vecs.shape)</span><span id="1c7d" class="nm mb it on b gy ow ot l ou ov">feature_Train = numpy.array([<br/>        Votes_Train[c].cat.codes <br/>        for c in Votes_Train.columns <br/>        if c != label_col]).T<br/>print(feature_Train.shape)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/0c87866d200118ae0d20b705e7abb125.png" data-original-src="https://miro.medium.com/v2/resize:fit:190/format:webp/1*wcD3gLKSnbFvQezKaV057Q.jpeg"/></div></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="0612" class="nm mb it on b gy os ot l ou ov">feature_vecs[:5]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/cce189aadbf282812f54620de6ed04e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*D5V7uWSDU8AfkRjQI2vHYQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="a77c" class="nm mb it on b gy os ot l ou ov"># Convert our label (democrat vs republican) to numeric values<br/>labels = votes[label_col].cat.codes<br/>labels_Train = Votes_Train[label_col].cat.codes<br/># Look at the mapping for the first 5 values<br/>list(zip(votes[label_col][:5], labels[:5]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/0874d233eb2ad613e619913f183f1588.png" data-original-src="https://miro.medium.com/v2/resize:fit:468/format:webp/1*C0qoyKQznqYqcEuAhIKnCg.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="52a5" class="nm mb it on b gy os ot l ou ov">import sklearn.naive_bayes</span><span id="cf69" class="nm mb it on b gy ow ot l ou ov"># Define model<br/>model = sklearn.naive_bayes.MultinomialNB(alpha=1e-7)<br/># Train model with votes dataset<br/>model.fit(feature_Train, labels_Train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/8b0b442caa9217455f5ddcea826e2405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*WpiX3DTzGWhCi9q9aZk4MA.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="576b" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">评估模型性能</h1><p id="34f8" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">计算出模型后，现在让我们来评估性能。通过打印结果的前10行，我们可以快速了解模型的有效性:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="48f5" class="nm mb it on b gy os ot l ou ov">predicted_party = model.predict(feature_vecs[:10])<br/>party_probabilities = model.predict_proba(feature_vecs[:10])</span><span id="8d7d" class="nm mb it on b gy ow ot l ou ov">results = pandas.DataFrame({<br/>        'party': votes['class'][:10],<br/>        'predicted': pandas.Categorical.from_codes(<br/>            predicted_party, votes['class'][:10].cat.categories),<br/>        'proba(Republican)': party_probabilities[:, 0],<br/>        'proba(Democrat)': party_probabilities[:, 1],<br/>    })<br/>results</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/59966fcb625eddee130f6ee6e5caa49a.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*z9t5CRo6jDNFC65UYTQVYg.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="cc0a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当您检查这些结果时，请注意:</p><ol class=""><li id="c09d" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq ph lx ly lz bi translated">有1例明确的分类错误，1例分类未定，8例分类正确。</li><li id="25c2" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">在大多数情况下，预测类的概率(得分)比其他类的概率大得多，包括分类错误的情况。</li><li id="9d34" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">一种情况下，这两类概率几乎相同。</li></ol><p id="d60a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下一步，我们计算该模型的混淆矩阵和性能指标:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="8dce" class="nm mb it on b gy os ot l ou ov">import sklearn.metrics</span><span id="8f64" class="nm mb it on b gy ow ot l ou ov">def confusion_matrix(labels, predicted_labels, label_classes):<br/>    return pandas.DataFrame(<br/>        sklearn.metrics.confusion_matrix(labels, predicted_labels),<br/>        index=[label_classes], <br/>        columns=label_classes)</span><span id="5165" class="nm mb it on b gy ow ot l ou ov">def performance(results):<br/>    accuracy = sklearn.metrics.accuracy_score(<br/>        results['party'].cat.codes, results['predicted'].cat.codes)<br/>    precision = sklearn.metrics.precision_score(<br/>            results['party'].cat.codes, results['predicted'].cat.codes)<br/>    recall = sklearn.metrics.recall_score(<br/>            results['party'].cat.codes, results['predicted'].cat.codes)</span><span id="38f7" class="nm mb it on b gy ow ot l ou ov">print('Accuracy = %.3f, Precision = %.3f, Recall = %.3f' % (accuracy, precision, recall))<br/>    <br/>    return confusion_matrix(<br/>        results['party'], <br/>        results['predicted'], <br/>        results.party.cat.categories)</span><span id="1218" class="nm mb it on b gy ow ot l ou ov">performance(results)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6acb987fd8f8bf9ba44644dd50ce61e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*oxj7rPlFQ4SGIk3bmaxYiw.jpeg"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="5543" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从435名国会议员中的前10名来看，结果相当不错。</p><p id="43ce" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">执行下面单元格中的代码，使用所有数据计算并打印模型评估，并将结果与第一个模型进行比较:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="4ae9" class="nm mb it on b gy os ot l ou ov">predicted_party = model.predict(feature_vecs)<br/>party_probabilities = model.predict_proba(feature_vecs)</span><span id="c6ab" class="nm mb it on b gy ow ot l ou ov">results_all = pandas.DataFrame({<br/>        'party': votes['class'],<br/>        'predicted': pandas.Categorical.from_codes(<br/>            predicted_party, votes['class'].cat.categories),<br/>        'proba(democrat)': party_probabilities[:, 0],<br/>        'proba(republican)': party_probabilities[:, 1],<br/>    })<br/>performance(results_all)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/60baee0d37c7fc3bf5e80523eba4f451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*aqCctXwBkNXvkEh3Q8M7dQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="3a48" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">拉普拉斯平滑</h1><p id="d54b" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">拉普拉斯平滑法是处理没有足够样本来计算概率的数据集的有效方法。这种方法避免了𝑝(𝑥𝑗|𝐶𝑘)=0p(xj|Ck)=0.</p><p id="9abf" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">下面单元格中的代码使用相同的国会投票数据计算一个朴素贝叶斯模型，但是使用了一个跨度为3个数据点的拉普拉斯平滑器。执行这段代码并检查结果:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="3d81" class="nm mb it on b gy os ot l ou ov">predicted_party = model.predict(feature_vecs)<br/>party_probabilities = model.predict_proba(feature_vecs)</span><span id="3b4d" class="nm mb it on b gy ow ot l ou ov">results_all = pandas.DataFrame({<br/>        'party': votes['class'],<br/>        'predicted': pandas.Categorical.from_codes(<br/>            predicted_party, votes['class'].cat.categories),<br/>        'proba(democrat)': party_probabilities[:, 0],<br/>        'proba(republican)': party_probabilities[:, 1],<br/>    })<br/>performance(results_all)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/80581088fd1228328afb04db48b29b93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*H86wGeXZNsgaFuFOshACqw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="7a26" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">结果类似于没有拉普拉斯平滑计算的模型。这一结果是意料之中的，因为数据集中的所有案例都有足够的数据。</p><h1 id="9661" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">另一个例子——人口普查收入</h1><p id="9dfd" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">现在我们可以尝试另一个二元分类的例子。下面单元格中的代码加载了一些美国人口普查数据样本。我们希望构建并评估一个朴素贝叶斯模型，以50，000美元为分界点，根据高收入和低收入对人们进行分类。执行此代码并检查数据集中的特征。</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="f233" class="nm mb it on b gy os ot l ou ov"># income is a pd read_csv function from a source URL that no longer works<br/>income.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi pl"><img src="../Images/a8981fe84f8107482bda577a058d4547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTGer3Ad6rDtrJzxCLgoAg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="8b0b" class="nm mb it on b gy os ot l ou ov">income.shape</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/acf7c722066d8a8ba718049e2cf8a74a.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*8gUw6f--u3HAFOHowaGhmQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="f4f0" class="nm mb it on b gy os ot l ou ov">income.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/29081dddfd1138b4e23c91b16e8246f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*O585feVqdF4HzdV-nuxs_Q.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="d571" class="nm mb it on b gy os ot l ou ov">income.describe()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/524a00ade4b06587dfa694a42add98c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*DHXqvtshLF6Wj85rE23PQQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="5e4d" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">减少特征</h1><p id="751c" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">我们可以看到一些可能是共线的特征。还有一个特征，<code class="fe ok ol om on b">fnlwgt</code>对这些人分类没什么用。下面单元格中的代码删除了这些列。执行此代码以创建一个具有简化功能的数据集:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="a628" class="nm mb it on b gy os ot l ou ov">income = income.drop(['workclass', 'fnlwgt', 'education-num', 'relationship'], axis=1)<br/>income.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi pp"><img src="../Images/b76b9b8e188307b2ad6bbcc32ad7a43b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeRSrgtAdpYtmtpLVs25fQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="a1c3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，我计算一个朴素贝叶斯模型，使用收入数据集中的特征对<code class="fe ok ol om on b">income</code>进行分类:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="f551" class="nm mb it on b gy os ot l ou ov">for c in income.columns:<br/>    if income[c].dtype == 'object':<br/>        income[c] = income[c].astype('category')</span><span id="92db" class="nm mb it on b gy ow ot l ou ov">income_label_col = 'income'</span><span id="cfcb" class="nm mb it on b gy ow ot l ou ov">income_labels = income[income_label_col].cat.codes</span><span id="3d25" class="nm mb it on b gy ow ot l ou ov">features = []<br/>for c in income.columns:<br/>    if c != income_label_col:<br/>        if str(income[c].dtype) == 'category':<br/>            features.append(income[c].cat.codes)<br/>        else:<br/>            features.append(income[c])<br/>income_feature_vecs = numpy.array(features).T</span><span id="c89a" class="nm mb it on b gy ow ot l ou ov"># Create model<br/>model = sklearn.naive_bayes.MultinomialNB(alpha=3)<br/>model.fit(income_feature_vecs, income_labels)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/b011236fa670dfbec5d4212727755df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*iYl0_I6A8YqlfsnZgxwo5g.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="5f70" class="nm mb it on b gy os ot l ou ov">features[8]</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/ab31e4d40b42b1a912d97e7ed5038a30.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*C8w1Po3-QSQXlT8SK0nw_w.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="f770" class="nm mb it on b gy os ot l ou ov">conditional_probas = pandas.DataFrame(model.feature_log_prob_, columns=income.columns[:-1])<br/>conditional_probas</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nz oa di ob bf oc"><div class="gh gi pr"><img src="../Images/5de5e16fc48ffea9f025f68c4d82040b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FwlIvbF2PgM1Q7LlsVkGlA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="49b8" class="nm mb it on b gy os ot l ou ov">(-conditional_probas).plot(kind='bar')<br/>pyplot.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/a9ea8e86d3f00fff9609dd8d1f9a99aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*b6SLYi3MJd_4kht57cCi4w.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="c021" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">改变特征的数量</h1><p id="294a" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">现在让我们研究一下向朴素贝叶斯模型添加更多数据样本的效果。下面单元格中的代码使用2、3、4、5和6票来计算和评估朴素贝叶斯模型。执行此代码，并将结果与使用完整数据集获得的结果进行比较:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="887a" class="nm mb it on b gy os ot l ou ov">label_col = 'class'</span><span id="b2ef" class="nm mb it on b gy ow ot l ou ov"># We need to convert our categorical values to numeric feature vectors<br/>feature_vecs = numpy.array([<br/>        votes[c].cat.codes <br/>        for c in votes.columns <br/>        if c != label_col]).T<br/>print(feature_vecs.shape)</span><span id="e02b" class="nm mb it on b gy ow ot l ou ov"># we also need to convert our label (democrat vs republican) to numeric values<br/>labels = votes[label_col].cat.codes<br/># take a look at the mapping for the first 5 values like so<br/>list(zip(votes[label_col][:5], labels[:5]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/30a4a552d07d94c17d64c92559c83a25.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*pO1WQUF7PNjqzi6tVrGbYA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="78f9" class="nm mb it on b gy os ot l ou ov">for num_features in [2, 3, 4, 5, 6]:<br/>    model = sklearn.naive_bayes.MultinomialNB()<br/>    model.fit(feature_vecs[:, :num_features], labels)</span><span id="c9ce" class="nm mb it on b gy ow ot l ou ov">predicted_votes = model.predict(feature_vecs[:, :num_features])</span><span id="a2b1" class="nm mb it on b gy ow ot l ou ov">print('Number of features = %d' % num_features)<br/>    accuracy = sklearn.metrics.accuracy_score(labels, predicted_votes)<br/>    precision = sklearn.metrics.precision_score(labels, predicted_votes)<br/>    recall = sklearn.metrics.recall_score(labels, predicted_votes)<br/>    print('Accuracy = %.3f, Precision = %.3f, Recall = %.3f' % (accuracy, precision, recall))<br/>    print('Confusion matrix:')<br/>    print(confusion_matrix(labels, predicted_votes, votes['class'].cat.categories))<br/>    print('')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/99dd6419a39504ef64b8356000fc5fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*1xwYpAXM5HFs3uo58YEHLw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="3bfb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从这些结果中可以看出，该模型仅用几个特征就能快速获得准确性。事实上，16个特征中的5或6个提供了相同的结果。</p><p id="8738" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">计算一个朴素贝叶斯模型，计算并打印100、500、1000、2000、8000和32561行<code class="fe ok ol om on b">income</code>数据集的性能统计数据:</p><pre class="kj kk kl km gt oo on op oq aw or bi"><span id="2f48" class="nm mb it on b gy os ot l ou ov">NumberOfRowsTests = [100, 500, 1000, 2000, 8000, 32561]<br/>for num_rows in (NumberOfRowsTests):<br/>    model = sklearn.naive_bayes.MultinomialNB()<br/>    model.fit(income_feature_vecs[:num_rows, :], income_labels[:num_rows])</span><span id="ee29" class="nm mb it on b gy ow ot l ou ov">predicted_income = model.predict(income_feature_vecs[:num_rows, :])<br/>    income_probabilities = model.predict_proba(income_feature_vecs[:num_rows, :])<br/>    <br/>    accuracy = sklearn.metrics.accuracy_score(income_labels[:num_rows], predicted_income)<br/>    precision = sklearn.metrics.precision_score(income_labels[:num_rows], predicted_income)<br/>    recall = sklearn.metrics.recall_score(income_labels[:num_rows], predicted_income)<br/>    print('%6.0f rows:  Accuracy = %.3f, Precision = %.3f, Recall = %.3f' % (num_rows, accuracy, precision, recall))<br/>    print('Confusion matrix:')<br/>    print(confusion_matrix(<br/>            income_labels[:num_rows], predicted_income, income.income.cat.categories), '\n')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/c9586dbfba6a1ee14d7515163dd5c6fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*UCv_msZPuDsABsFMYQx0Lw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><h1 id="886d" class="ma mb it bd mc md me mf mg mh mi mj mk jz ml ka mm kc mn kd mo kf mp kg mq mr bi translated">摘要</h1><p id="5109" class="pw-post-body-paragraph kv kw it kx b ky ms ju la lb mt jx ld le nj lg lh li nk lk ll lm nl lo lp lq im bi translated">在本笔记本中，我完成了以下工作:</p><ol class=""><li id="953b" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq ph lx ly lz bi translated">朴素贝叶斯模型理论</li><li id="34c1" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">朴素贝叶斯的陷阱</li><li id="4847" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">良好的正则化性质</li><li id="d95f" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">计算效率</li><li id="2683" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">计算和评估朴素贝叶斯模型的示例</li><li id="18f0" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">检查数据集大小对朴素贝叶斯模型结果的影响</li><li id="bf9d" class="lr ls it kx b ky mx lb my le mz li na lm nb lq ph lx ly lz bi translated">监督学习的解释</li></ol><p id="44c2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">请记住，虽然朴素贝叶斯是一个有用且强大的分类器——但这个模型应该总是与一个<a class="ae ku" rel="noopener" target="_blank" href="/logistic-regression-cebee0728cbf">逻辑回归</a>模型相比较。这种启发允许进行有用的健全性检查，并且为评估您的模型提供了重要的基础事实。</p><p id="592b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我希望你喜欢这篇文章！无论你是这个概念的新手，还是仅仅需要复习，我希望我的读者对数据科学和机器学习中这些复杂但非常重要的主题有深刻而完整的直觉和理解。</p><p id="9e79" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想让我继续写类似的主题，请订阅！</p><p id="6acc" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<a class="ae ku" href="https://www.linkedin.com/in/james-a-w-godwin/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上找到我</p><p id="ccc1" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="nf">物理学家兼数据科学家——可用于新机遇| SaaS |体育|初创企业|扩大规模</em></p></div></div>    
</body>
</html>