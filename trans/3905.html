<html>
<head>
<title>How to frame a regression problem as a classification problem to account for uncertainty</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将回归问题框架化为分类问题以解释不确定性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-frame-a-regression-problem-as-a-classification-problem-to-account-for-uncertainty-63fb8269486e#2022-08-30">https://towardsdatascience.com/how-to-frame-a-regression-problem-as-a-classification-problem-to-account-for-uncertainty-63fb8269486e#2022-08-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/2316804c3b5500b75cb8a34a19df1d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5H-4coVRx_Bm9iyLzSnPQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">foto de Vladislav Vasnetsov:<a class="ae jg" href="https://www.pexels.com/es-es/foto/cubos-de-basura-de-plastico-de-varios-colores-2682683/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/es-es/foto/cubos-de-basura-de-plastico-de-varios-colores-2682683/</a></p></figure><div class=""/><p id="65d2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk">利弊，以及一个工作实例</strong></p><p id="4ee6" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我敢打赌你去过那里:你有一些数据，你也有一个目标列，你需要使用一些ML技术来估计。你能想到的:给定一些财务数据估计价格，一些客户信息估计它的终身价值，一些机械信息估计磨损或使用。这是一个回归问题，目标是在给定一组特征的情况下精确定位连续变量的值。有趣的部分来了。你对这个价值有多大把握？</p><p id="da76" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用第一个例子。您正在向销售经理展示一个价格估算模型，在给定输入的情况下，它估计价格应该是$51.53。你有信心，因为评估RMSE是1.8美元；对于这个价格范围来说已经足够好了，但是对于$5到$10的价格范围来说是一个相当大的问题。这里的问题是，误差在价格范围之间不是均匀分布的。该模型在某些范围内会更准确，而在其他范围内就不那么准确了，RMSE不会让你知道它对某个估计有多准确。换句话说，你不知道模型的不确定性。</p><p id="4fb1" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">金融领域也有相似之处。你有100美元，想在3种可能的资产中决定投资方向。如果有人来告诉你把所有的钱都投资到一个单一的资产上，这将是很奇怪的，因为你会期望得到一些建议，比如“把60%倒过来，30%倒过来，最后10%倒过来”。</p><p id="9755" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我敢打赌，你可以看到问题的走向。在给定的回归问题中，您可以确定一个预测值，比如10.5美元，或者以“该值有20%的可能性在0到5之间，有70%的可能性在5到10之间，只有10%的可能性大于10”的形式提供分布。</p><p id="de03" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下图显示了这一点。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi le"><img src="../Images/5d99c7871987be13f6d62fdaa8cb0b7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*MjOiFlPCWG_hX-y4bkZ-1g.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">解决回归问题的传统方法是:确定预期的结果。图片由作者提供。</p></figure><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/e857c8dfacdaf42a90fc5b7e0a2b9488.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*plJFRCSMR1Zxjj-ZNPnhkQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">考虑到不确定性的另一种分布式解决方案。图片由作者提供。</p></figure><p id="2a73" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这两种方法各有利弊。</p><p id="f2f9" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk">精确定位一个值</strong></p><p id="81dd" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">赞成</p><ul class=""><li id="4a3e" class="lk ll jj ki b kj kk kn ko kr lm kv ln kz lo ld lp lq lr ls bi translated">告诉某人期望值是10.5美元，这意味着什么就不会有疑问了。优点是一个数字很容易理解。</li></ul><p id="3d26" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">欺骗</p><ul class=""><li id="31e0" class="lk ll jj ki b kj kk kn ko kr lm kv ln kz lo ld lp lq lr ls bi translated">如前所述。你对这个价值有多大把握？训练RMSE不会告诉你太多关于这个特殊的情况。缺点是你不知道一个特定的预测有多准确。</li></ul><p id="dd3e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki jk">显示一个分布图</strong></p><p id="e0ff" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">赞成</p><ul class=""><li id="daa9" class="lk ll jj ki b kj kk kn ko kr lm kv ln kz lo ld lp lq lr ls bi translated">你知道模型在预测中有多确定。例如，如果模型告诉您某个容器有90%的可能性，您可以确信它在相应的范围内。另一方面，如果模型给你的值接近30%,你肯定什么都不知道。甚至知道你什么都不知道也没用。这里的优点是模型考虑了不确定性。</li></ul><p id="f5f5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">欺骗</p><ul class=""><li id="955f" class="lk ll jj ki b kj kk kn ko kr lm kv ln kz lo ld lp lq lr ls bi translated">这种方法的主要问题可能是可解释性。任何知道概率分布概念的人都会很容易理解如何处理这个结果。如果你足够幸运，能与精明的股东打交道，那你就大功告成了。然而，如果他们不这么做，你将面临更大的挑战。</li></ul><p id="8f94" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">此时，您可能想知道分类部分在哪里。嗯，看上面的直方图。你明白了吗？如果你没有，就在这里。</p><blockquote class="lu lv lw"><p id="d5c2" class="kg kh lt ki b kj kk kl km kn ko kp kq lx ks kt ku ly kw kx ky lz la lb lc ld im bi translated">不要精确定位值，而是估计它的值属于某个箱的概率，这是:将每个样本分类到一个箱中。</p></blockquote><p id="7f01" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们用一些代码和一个真实的例子来阐明这个想法。首先，我们将训练一个回归变量来精确定位工资，然后进行修改以将回归问题构建为一个分类问题。</p><h2 id="e09f" class="ma mb jj bd mc md me dn mf mg mh dp mi kr mj mk ml kv mm mn mo kz mp mq mr ms bi translated">回归任务</h2><p id="b810" class="pw-post-body-paragraph kg kh jj ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">我们将使用Kaggle上提供的<a class="ae jg" href="https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries" rel="noopener ugc nofollow" target="_blank">数据科学职位工资</a> [1]。</p><p id="0f68" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集看起来像这样。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi my"><img src="../Images/65f4d3f049008f2f03e4e401b68d6585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aDaNewcoAiNSxaIcfKB3cA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">数据集预览。图片由作者提供。</p></figure><p id="4e81" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我不会深入讨论清理和准备数据的细节，但是一般来说，这些步骤包括删除未使用的列、处理分类数据和缩放数据集值。最后，我们将使用<a class="ae jg" href="https://xgboost.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">XGBoost</a>[2]来训练一个回归变量。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="443a" class="ma mb jj na b gy ne nf l ng nh"><em class="lt"># Prepare data</em></span><span id="db1b" class="ma mb jj na b gy ni nf l ng nh">X = df.drop(['Unnamed: 0','salary', 'salary_currency','salary_in_usd'], axis=1)<br/>X = pd.get_dummies(X)<br/><br/>y = df['salary_in_usd']</span><span id="41d5" class="ma mb jj na b gy ni nf l ng nh"><em class="lt"># Split into train test sets</em></span><span id="520b" class="ma mb jj na b gy ni nf l ng nh">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)<br/><em class="lt"># Scale data</em><br/>t = MinMaxScaler()<br/>t.fit(X_train)<br/>X_train = t.transform(X_train)<br/>X_test = t.transform(X_test)</span><span id="ebc7" class="ma mb jj na b gy ni nf l ng nh"><em class="lt"># Fit model no training data</em></span><span id="4736" class="ma mb jj na b gy ni nf l ng nh">from xgboost import XGBRegressor<br/>model = XGBRegressor()<br/>model.fit(X_train, y_train)</span><span id="0563" class="ma mb jj na b gy ni nf l ng nh"><em class="lt"># Make predictions for test data</em></span><span id="3a9d" class="ma mb jj na b gy ni nf l ng nh">y_pred = model.predict(X_test)<br/>predictions = [round(value) for value <strong class="na jk">in</strong> y_pred]</span><span id="f063" class="ma mb jj na b gy ni nf l ng nh">from sklearn.metrics import mean_squared_error<br/><br/>rms = mean_squared_error(y_test, y_pred, squared=False)<br/><br/><em class="lt"># Not quite good but doing this to compare to the distributive approach</em></span><span id="74bf" class="ma mb jj na b gy ni nf l ng nh"># Output: 41524.12746933382</span></pre><p id="6858" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们看一下前五个预测，它们看起来像这样。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="6159" class="ma mb jj na b gy ne nf l ng nh">[71284, 44957, 131146, 165507, 100765]</span></pre><p id="abc2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于每个元素，回归变量旨在精确定位相应薪金的数值。果然不出所料。我不知道是不是我，但当我看着这些数字时，我觉得缺乏一些背景。我有多确定这些数字是正确的？</p><p id="b833" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">回归变量实现了41，524的RMSE。我打赌我们可以做得更好，然而，目的不是训练一个超级精确的分类器，而是对比将问题框架化为回归问题或分类问题之间的差异。现在让我们来看分类部分。</p><h2 id="acc6" class="ma mb jj bd mc md me dn mf mg mh dp mi kr mj mk ml kv mm mn mo kz mp mq mr ms bi translated">分类问题</h2><p id="0390" class="pw-post-body-paragraph kg kh jj ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">前面我们说过，将回归问题构建为分类问题的核心思想是，不精确确定数值，而是估计样本属于一组固定箱的概率，即，将每个样本分类到一个箱中。</p><p id="b377" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，第一个显而易见的步骤是确定固定箱的集合。为了实现这一点，我们需要查看我们拥有的训练数据的直方图。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/4538f6699028afca9f5b905910477b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/0*ugD42Txt9plwuSCj.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">描述工资分布的直方图。图片由作者提供。</p></figure><p id="48e7" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是了。现在我们清楚地知道了大部分工资的位置，最低工资和最高工资。</p><p id="635b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们来定义箱子。为了做到这一点，我们将只考虑一个使分类问题更容易的原则:确保数据集不是非常不平衡。我们将通过仔细选择箱的数量来做到这一点，以便属于每个类的元素的计数大致相似。</p><p id="8f86" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们选择5个箱的计数来找到每个箱的极限和元素计数。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="bff6" class="ma mb jj na b gy ne nf l ng nh"><em class="lt"># Let’s calculate the numeric histogram from the actual test target</em><br/>hist, bin_edges = np.histogram(y_test, bins=5)<br/>hist, bin_edges</span></pre><p id="0d5d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="69ee" class="ma mb jj na b gy ne nf l ng nh">(array([33, 45, 28, 15,  1]),<br/> array([  4000.,  68000., 132000., 196000., 260000., 324000.]))</span></pre><p id="3f18" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个箱的数量相当平衡，但是，最后一个箱有一个问题，我们将通过聚合这些箱中的数据来解决。</p><p id="5bb0" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，此时我们在<em class="lt"> y </em>中的目标只是一堆浮动数字(工资)，不适合分类任务，因为这种任务需要一个样本和一个标签，表明样本属于哪个类别。所以接下来的任务是写一些代码来将一个浮点数映射成一个整数标签。</p><p id="7f14" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以看一下下面的代码。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/fe1efb4cd2fcb9090d8055efc6b1ae84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1iaXuDYzQSiY5DINcUBtlQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">一个简单的函数，将一个数字映射到一个类中。图片由作者提供。</p></figure><p id="3bc2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">简单吧？我们接收一个浮点数，并根据它的值返回一个标签。代码是不言自明的，只需注意最后的<em class="lt"> elif </em>语句:这是聚合发生的地方。该代码表示“大于196，000的所有内容都将被分配一个标签4”。</p><p id="504d" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我听到你问为什么这些值是硬编码的。答案是因为这只是一个例子。我敢打赌有更明智的方法来选择框的边界，但是，我只是想保持简单，以保持快速移动。</p><p id="fc0e" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在让我们再次使用XGBoost训练分类。但是首先，我们需要将<em class="lt">浮动y目标</em>转换成一组分布式y目标。这段代码就可以了。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="c9b7" class="ma mb jj na b gy ne nf l ng nh"># convert each y in training and test sets to a class</span><span id="7622" class="ma mb jj na b gy ni nf l ng nh">y_train_distributive = [map_float_to_class(y) for y in y_train]<br/>y_test_distributive = [map_float_to_class(y) for y in y_test]</span></pre><p id="4cb2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在训练真正的分类任务。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="2094" class="ma mb jj na b gy ne nf l ng nh"># Import the classifier</span><span id="ad0e" class="ma mb jj na b gy ni nf l ng nh">from xgboost import XGBClassifier<br/>from sklearn.metrics import accuracy_score</span><span id="3ee0" class="ma mb jj na b gy ni nf l ng nh">model = XGBClassifier()</span><span id="3515" class="ma mb jj na b gy ni nf l ng nh"># Train to get a label</span><span id="7f17" class="ma mb jj na b gy ni nf l ng nh">model.fit(X_train, y_train_distributive)</span><span id="0727" class="ma mb jj na b gy ni nf l ng nh"># Get the labels</span><span id="97e0" class="ma mb jj na b gy ni nf l ng nh">predictions = model.predict(X_test)</span><span id="dc65" class="ma mb jj na b gy ni nf l ng nh"># How good does it work</span><span id="ccc5" class="ma mb jj na b gy ni nf l ng nh">accuracy_score(y_test_distributive, predictions)</span><span id="eed8" class="ma mb jj na b gy ni nf l ng nh"># Output: 0.5327868852459017</span></pre><p id="ebd2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用默认参数，我们得到了0.53的精度，你打赌它可以得到改善。现在，让我们继续。</p><p id="b55b" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们看一下前五个预测，它们看起来像这样。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="7e4f" class="ma mb jj na b gy ne nf l ng nh">array([1, 1, 2, 3, 2])</span></pre><p id="b860" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它们只是标签…不太能说明问题。我们感兴趣的不是哪个标签被选中，而是被选中的标签是在哪个底层分布中被挑选出来的。</p><p id="c4a4" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这段代码将完成这个任务。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="87b5" class="ma mb jj na b gy ne nf l ng nh"># Instead of the labels get the probability distributions</span><span id="98b9" class="ma mb jj na b gy ni nf l ng nh">predictions = model.predict_proba(X_test)</span></pre><p id="40d3" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">前五个预测是这样的。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="f3df" class="ma mb jj na b gy ne nf l ng nh">array([[2.76227575e-03, 8.35917711e-01, 1.60156339e-01, 8.88690702e-04,<br/>        2.75029975e-04],<br/>       [2.02982640e-03, 7.47869253e-01, 2.40976274e-01, 8.92745517e-03,<br/>        1.97156842e-04],<br/>       [9.52042465e-04, 4.67287423e-03, 4.85075146e-01, 2.80507535e-01,<br/>        2.28792369e-01],<br/>       [7.99451722e-04, 8.09144005e-02, 1.74629122e-01, 7.32445538e-01,<br/>        1.12115145e-02],<br/>       [1.12233951e-03, 8.29923898e-02, 8.98771644e-01, 1.67797077e-02,<br/>        3.33951320e-04]], dtype=float32)</span></pre><p id="75c5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">嗯…我们有更多的信息！由于一幅图像胜过千言万语(在这种情况下是数组)，我们应该更好地制作一个图表。</p><pre class="lf lg lh li gt mz na nb nc aw nd bi"><span id="f100" class="ma mb jj na b gy ne nf l ng nh"># Plot some of the predicted salary distributions</span><span id="d472" class="ma mb jj na b gy ni nf l ng nh">fig, ax = plt.subplots(3, 3)<br/>fig.set_size_inches(16, 6)</span><span id="02ea" class="ma mb jj na b gy ni nf l ng nh"># Random indexes picked<br/>ax[0, 0].bar(labels, predictions[1])<br/>ax[0, 1].bar(labels, predictions[5])<br/>ax[0, 2].bar(labels, predictions[8])</span><span id="b741" class="ma mb jj na b gy ni nf l ng nh">ax[1, 0].bar(labels, predictions[10])<br/>ax[1, 1].bar(labels, predictions[15])<br/>ax[1, 2].bar(labels, predictions[20])</span><span id="4730" class="ma mb jj na b gy ni nf l ng nh">ax[2, 0].bar(labels, predictions[40])<br/>ax[2, 1].bar(labels, predictions[47])<br/>ax[2, 2].bar(labels, predictions[52])</span><span id="22ea" class="ma mb jj na b gy ni nf l ng nh">plt.tight_layout()<br/>fig.suptitle("Some calculated distributions samples")<br/>plt.show()</span></pre><p id="9d35" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是输出。我发现这种解决方案比没有上下文的简单浮点数更有表现力。对于一个样本，模型返回一个分布，从这个分布中，你可以获得很多信息。</p><figure class="lf lg lh li gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/143147be5ee951651b840fd06974146c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Dl1OzXoE4pRYSqCb.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">计算所得预测值的随机子集的预测工资分布。图片由作者提供。</p></figure><p id="b6c5" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看一下第1行和第0列。如果你刚刚使用了第一个分类器提供的标签，你可能会犯错误，因为特定样本属于这两个较大类别的概率之间的差异非常小。在这种情况下，也许你应该深入了解候选人的个人资料，然后再做决定。</p><p id="559c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相比之下，看看第2行和第1列。该模型非常确定在这个范围内的工资是正确的。</p><p id="cc60" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，看第0行和第2列。该模型对工资应该在第二个箱中的某个位置有3倍的信心，然而第三个箱是非常相关的。选哪个？你可以获取一些其他数据来做出最终决定:也许招聘部门的人员轮换率很高，更高的薪水可能有助于减少轮换，或者从另一方面来说，这种职位需求很大，因此，你可以在较低的范围内招聘。</p><p id="4d4c" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以对剩下的分布进行类似的分析，但底线是一样的:与单个值相比，分布提供了更多的数据来进行决策。自己判断。</p><h1 id="3994" class="nm mb jj bd mc nn no np mf nq nr ns mi nt nu nv ml nw nx ny mo nz oa ob mr oc bi translated">结论</h1><p id="853a" class="pw-post-body-paragraph kg kh jj ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">在这篇文章中，我讨论了通过一个自定义函数将一个回归问题转化为一个分类问题的好处，这个自定义函数将浮点值映射到一个由整数描述的类中。每一类代表一个值域，即一个固定的支持。因此，它提供了固定支持的一组概率，而不是有一个在给定样本的情况下精确定位值的模型。</p><p id="4d1a" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">分布式模型的优点是它提供了更多的决策环境，缺点是它不能提供单一的解决方案。一个人不可能拥有一切。</p><p id="3f84" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您是否有此解决方案可能有用的应用？</p></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><p id="7d47" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以在这里查看<a class="ae jg" href="https://www.kaggle.com/code/jonathan0001/medium-classification-and-regression" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本。如果你觉得这个帖子有趣，请关注我并分享！</a></p><h2 id="689c" class="ma mb jj bd mc md me dn mf mg mh dp mi kr mj mk ml kv mm mn mo kz mp mq mr ms bi translated">参考</h2><p id="40ef" class="pw-post-body-paragraph kg kh jj ki b kj mt kl km kn mu kp kq kr mv kt ku kv mw kx ky kz mx lb lc ld im bi translated">[1]数据科学岗位工资(2022年更新)。Kaggle数据集。<a class="ae jg" href="https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries/metadata" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/ruchi 798/data-science-job-sales/metadata</a></p><p id="88f2" class="pw-post-body-paragraph kg kh jj ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] XGBoost文档(2022年更新)。【https://xgboost.readthedocs.io/en/stable/index.html T4】</p></div></div>    
</body>
</html>