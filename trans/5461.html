<html>
<head>
<title>Tweaking a model for lower False Predictions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调整模型以降低错误预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tweaking-a-model-for-lower-false-predictions-37d3bf028a3f#2022-12-07">https://towardsdatascience.com/tweaking-a-model-for-lower-false-predictions-37d3bf028a3f#2022-12-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8c74" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">调整您的模型，仅进行更高确定度的分类</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d09eeda2f5b0e5300c40b3814caae742.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PDN3L9m4jQNKY_PbW3GEQg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@kajtek?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Kajetan Sumila </a>在<a class="ae ky" href="https://unsplash.com/s/photos/different?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="0152" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="8b83" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">当创建分类模型时，许多算法提供函数<code class="fe mu mv mw mx b">predict_proba()</code>来给我们观察值被分类到每个类别下的概率。因此，通常会看到这样的输出:</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="09ef" class="nc lh it mx b be nd ne l nf ng">[0.925, 0.075]</span></pre><blockquote class="nh"><p id="7098" class="ni nj it bd nk nl nm nn no np nq mt dk translated">在前面的例子中，模型有 92.5%的把握认为观察值属于类 0，而只有 7.5%的机会来自类 1。</p></blockquote><p id="28f2" class="pw-post-body-paragraph ly lz it ma b mb nr ju md me ns jx mg mh nt mj mk ml nu mn mo mp nv mr ms mt im bi translated">因此，如果我们请求同一个模型使用<code class="fe mu mv mw mx b">predict()</code>函数给我们一个二元预测，我们只会得到一个<code class="fe mu mv mw mx b">[0]</code>作为结果，对吗？</p><p id="14a5" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">在本例中，我们最有可能不希望模型预测观察值为<em class="ob">类 1 </em>，因为它只有很小的可能性。但是，假设我们对另一个观测值进行了预测，结果如下:</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="9411" class="nc lh it mx b be nd ne l nf ng">[0.480, 0.520]</span></pre><p id="cd9c" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">现在怎么办？</p><p id="174c" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">当然，来自许多模型的<em class="ob">粗略</em>预测会给我们结果<code class="fe mu mv mw mx b">[1]</code>。但这是最好的决定吗？有时候，是的。其他时候，没有那么多。</p><p id="a66e" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">在这篇文章中，我们将学习如何使用 Python 中的<code class="fe mu mv mw mx b">catboost</code>包，根据我们理解的用例可接受的假阳性【FPR】或假阴性率【FNR】的数量，为我们提供分类的最佳阈值。</p><h1 id="8022" class="lg lh it bd li lj oc ll lm ln od lp lq jz oe ka ls kc of kd lu kf og kg lw lx bi translated">数据科学背景</h1><p id="ee3d" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">为了将这篇文章放在上下文中，让我们理解为什么我们想要将阈值从默认的 50%削减更改为另一个数字。</p><p id="0ebf" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">我们最好的例子来自医疗保健行业。我们知道，许多实验室检查、诊断和医学测试依赖于机器学习来帮助专家得出最精确的答案。毕竟在这个行业，每一个百分点都关系到一个人的一生。</p><p id="938a" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">所以，假设我们正在利用数据来诊断乳腺癌。<em class="ob">与利益相关者</em>交谈后，我们达成一致，我们希望我们的模型最多给出 1%的假阴性。我们想非常确定一个人是健康的，说它是乳腺癌阴性。如果有疑问，我们会将其归类为阳性，并建议进行第二次检查或不同的确认测试。</p><p id="6afb" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">正如你可能已经得出的结论，这样做我们会降低模型的准确性，因为我们会增加假阳性的数量，但这是可以接受的，因为这个人总是可以再次检查并进行其他检查来确认这是不是真阳性。另一方面，我们不会遗漏任何患有该疾病并收到阴性结果的人。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/ee3bf2858ac08eca7d710006e226ddeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yt6WaCLVIo7AkqP5NoFkWA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@towfiqu999999?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Towfiqu barbhuiya </a>在<a class="ae ky" href="https://unsplash.com/s/photos/doubt?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="1ce2" class="lg lh it bd li lj oc ll lm ln od lp lq jz oe ka ls kc of kd lu kf og kg lw lx bi translated">编码</h1><p id="4de7" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">你可以在我的 GitHub 资源库中找到这个练习的完整代码，这里是<a class="ae ky" href="https://github.com/gurezende/Studying/tree/master/Python/CatBoost" rel="noopener ugc nofollow" target="_blank"/>。</p><div class="oi oj gp gr ok ol"><a href="https://github.com/gurezende/Studying/tree/master/Python/CatBoost" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">在 gurezende 大师学习/Python/CatBoost/学习</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><p id="760d" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">要安装<code class="fe mu mv mw mx b">catboost</code>，请使用<code class="fe mu mv mw mx b">pip install catboost</code>。下面列出了一些需要进口的产品。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="2bcb" class="nc lh it mx b be nd ne l nf ng"># Basics<br/>import pandas as pd<br/>import numpy as np<br/># Visualizations<br/>import plotly.express as px<br/># CatBoost<br/>from catboost import CatBoostClassifier<br/>from catboost import Pool<br/># Train test<br/>from sklearn.model_selection import train_test_split<br/># Metrics<br/>from sklearn.metrics import confusion_matrix, f1_score</span></pre><h2 id="1972" class="pa lh it bd li pb pc dn lm pd pe dp lq mh pf pg ls ml ph pi lu mp pj pk lw pl bi translated">资料组</h2><p id="46dc" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">要使用的数据是著名的玩具数据集<em class="ob">乳腺癌，</em>来自<code class="fe mu mv mw mx b">sklearn</code>。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="2e7c" class="nc lh it mx b be nd ne l nf ng"># Dataset<br/>from sklearn.datasets import load_breast_cancer<br/><br/># Load data<br/>data = load_breast_cancer()<br/><br/># X<br/>X = pd.DataFrame(data.data, columns=data.feature_names)<br/># y<br/>y = data.target</span></pre><p id="b251" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">您可能知道也可能不知道，这个数据集已经准备好了。在建模之前，没有太多需要探索或转换的地方。这不是我们的目的，所以我会继续讲代码。</p><h2 id="b365" class="pa lh it bd li pb pc dn lm pd pe dp lq mh pf pg ls ml ph pi lu mp pj pk lw pl bi translated">列车测试分离</h2><p id="f1e8" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">让我们把数据分开来进行训练和测试。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="a706" class="nc lh it mx b be nd ne l nf ng"># Train test split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br/><br/>print(f'Train shapes: {X_train.shape} | {y_train.shape}')<br/>print(f'Test shapes: {X_test.shape} | {y_test.shape}')<br/><br/>Train shapes: (455, 30) | (455,)<br/>Test shapes: (114, 30) | (114,)</span></pre><h2 id="b775" class="pa lh it bd li pb pc dn lm pd pe dp lq mh pf pg ls ml ph pi lu mp pj pk lw pl bi translated">第一个模型</h2><p id="2cc7" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">接下来我们用<code class="fe mu mv mw mx b">CatBoostClassifier</code>训练第一个模型。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="4d2f" class="nc lh it mx b be nd ne l nf ng"># Creating a Pool for training and validation sets<br/>train_pool = Pool( data=X_train, label=y_train)<br/>test_pool = Pool( data=X_test, label=y_test)<br/><br/># Fit<br/>model = CatBoostClassifier(iterations=500)<br/>model.fit(train_pool, eval_set=test_pool, verbose=100)</span></pre><p id="10a7" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">在序列中，这里是 F1 得分:<em class="ob"> 97% </em>。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="d44e" class="nc lh it mx b be nd ne l nf ng"># Predict<br/>preds = model.predict(X_test)<br/>f1_score(y_test, preds)<br/><br/>0.971830985915493</span></pre><p id="aba9" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">非常好。但是我们的模型有点复杂，因为它有 30 多个特性。让我们试着在不损失太多性能的情况下降低它。<strong class="ma iu"> Catboost </strong>具有<code class="fe mu mv mw mx b">feature_importances_</code>属性，可以帮助我们确定要选择的最佳属性。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="6edc" class="nc lh it mx b be nd ne l nf ng"># Feature importances to dataframe<br/>feature_importances = (<br/>    pd.DataFrame({'feature': data.feature_names, <br/>                  'importance': model.feature_importances_})<br/>    .sort_values(by='importance', ascending=False)<br/>)<br/># Plot<br/>px.bar(feature_importances,<br/>       x= data.feature_names, y=model.feature_importances_,<br/>       height=600, width=1000).update_layout(xaxis={'categoryorder':'total descending'})</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/79afe8d38bce23ef233c136ef2ef7b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*im4XEQQg2_MdQeAufKp7Lw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">减少 3 以下的重要性。图片由作者提供。</p></figure><p id="a258" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">没有使用任何花哨的技术，我只是任意选择保留任何重要性为 3+的特征。这使得他们中的 10 个人，在红线的左边。</p><h2 id="a343" class="pa lh it bd li pb pc dn lm pd pe dp lq mh pf pg ls ml ph pi lu mp pj pk lw pl bi translated">更简单的模型</h2><p id="3ff6" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">让我们训练更简单的模型，并评估分数。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="5a7a" class="nc lh it mx b be nd ne l nf ng"># Simpler model<br/>features = feature_importances.feature[:10]<br/># Creating a Pool for training and validation sets<br/>train_pool2 = Pool( data=X_train[features], label=y_train)<br/>test_pool2 = Pool( data=X_test[features], label=y_test)<br/><br/># Model <br/>model2 = CatBoostClassifier(iterations=600)<br/>model2.fit(train_pool2, eval_set=test_pool2, verbose=100)<br/><br/># Score<br/>preds2 = model2.predict(test_pool2)<br/>f1_score(y_test, preds2)<br/><br/>0.979020979020979</span></pre><p id="48ee" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">很好。同 F1 分:<em class="ob"> 97% </em>。</p><p id="e089" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">由于我们正在进行医学诊断，我们不应该对假阴性非常宽容。只有当我们非常确定病人确实健康时，我们才会希望我们的模型说他健康。</p><p id="0346" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">但是我们知道 CatBoost 算法使用标准的 50%阈值来预测结果。这意味着，如果阳性概率低于 50%，患者将被诊断为乳腺癌阴性。但是我们可以调整这个数字，让它给出一个更高确定性的负面预测。</p><p id="f2f6" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">让我们看看这是怎么做到的。以下是我们模型的一些预测。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="a8c0" class="nc lh it mx b be nd ne l nf ng"># Regular predictions<br/>default_preds = pd.DataFrame(model2.predict_proba(test_pool2).round(3))<br/>default_preds['classification'] = model2.predict(test_pool2)<br/>default_preds.sample(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/6b3a52b384a4d2c1666695c9b7cd475e.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*wUiyHp72RwRxL0qlAaMsNw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">50%阈值模型的预测概率。图片由作者提供。</p></figure><p id="d9f0" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">请注意，观察值 82 有 63.4%的几率为阴性，但也有 36%的几率为阳性，这对于医学标准来说是很高的。我们希望这个病例被归类为阳性，即使知道它可能是假的。所以我们可以在晚些时候送这个人去做另一个测试。因此，我们将假阴性率[FNR]容限设为 1%。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="1ab5" class="nc lh it mx b be nd ne l nf ng">from catboost.utils import select_threshold<br/># Finding the right threshold<br/>print(select_threshold(model2, test_pool2, FNR=0.01))<br/><br/>0.1420309044590601</span></pre><p id="93bb" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">太好了。既然 CatBoost 已经计算出了这个数字，那么被归类为负数的新阈值就是 1–0.142 = 0.858。<strong class="ma iu">简单来说，0 类的概率必须超过 85.8%才能被标记为 0，否则将被归类为 1。</strong></p><p id="4e57" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">好的。因此，我创建了一个自定义函数<code class="fe mu mv mw mx b">predict_threshold(df, threshold, rate_type)</code> ( <a class="ae ky" href="https://github.com/gurezende/Studying/tree/master/Python/CatBoost" rel="noopener ugc nofollow" target="_blank">访问我的 GitHub 查看代码</a>)，该函数将带有解释变量、所需阈值和汇率类型(FNR 或 FPR)的数据帧作为输入，并使用新的 cut 返回分类。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="e582" class="nc lh it mx b be nd ne l nf ng"># Predict<br/>new_predictions = predict_threshold(df= test_pool2, <br/>                                    threshold= 0.01, <br/>                                    rate_type= "FNR")<br/><br/># Standard predictions<br/>normal_predictions = model2.predict(test_pool2)</span></pre><p id="0029" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">对指数 82 的相同观察，先前以 63%的概率被分类为负(0)，现在被分类为正(1)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/4b0a07964440fb371ecb58c9da0b2a2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*QmHP8SI72HRIgSZAEd9bXQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">同样的观察#82 现在是积极的。图片由作者提供。</p></figure><p id="0cd9" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">这是标准 50%阈值的混淆矩阵。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="22b7" class="nc lh it mx b be nd ne l nf ng"># Confusion Matrix 50% standard threshold<br/>pd.DataFrame( confusion_matrix(y_true=y_test, y_pred=normal_predictions) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/9ceef7ee9e2cc15be5c6e196f47d3395.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*OlHVXFvgd9Ka-J52l5zeZQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类 50%阈值。图片由作者提供。</p></figure><p id="202a" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">这是具有更新阈值的新分类。</p><pre class="kj kk kl km gt my mx mz bn na nb bi"><span id="1b3a" class="nc lh it mx b be nd ne l nf ng"># Confusion Matrix 1% of false negatives allowed threshold<br/>pd.DataFrame( confusion_matrix(y_true=y_test, y_pred=new_predictions) )</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/ea87ea69e9b794f1604cf4a1e00752de.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*f6uRgI5AyvXijpHnas-dQQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分类 85.8%阈值。图片由作者提供。</p></figure><p id="e441" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">观察两个混淆矩阵的左下角单元格[true=1，pred=0，FN]。最上面的显示了一个假阴性。该人实际上患有癌症，并且该模型被分类为阴性。这个问题在新模型中得到了解决，没有假阴性。另一方面，我们也增加了一个假阳性。因此，就像数据科学中的许多事情一样，这都是关于权衡的问题。</p><blockquote class="nh"><p id="0482" class="ni nj it bd nk nl pr ps pt pu pv mt dk translated">FPR(I 型误差)和 FNR(II 型误差)是互补的。当你减少一个时，另一个必然会增加。</p></blockquote><p id="48c2" class="pw-post-body-paragraph ly lz it ma b mb nr ju md me ns jx mg mh nt mj mk ml nu mn mo mp nv mr ms mt im bi translated">如果您的项目需要非常低的误报率，那么可以使用相同的方法来降低 FPR。</p><h1 id="b21f" class="lg lh it bd li lj oc ll lm ln od lp lq jz oe ka ls kc of kd lu kf og kg lw lx bi translated">在你走之前</h1><p id="2e6c" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">总之，我们在这篇文章中学到的是:</p><ul class=""><li id="1238" class="pw px it ma b mb nw me nx mh py ml pz mp qa mt qb qc qd qe bi translated">分类的默认截止阈值是 50%的概率。</li><li id="019f" class="pw px it ma b mb qf me qg mh qh ml qi mp qj mt qb qc qd qe bi translated">这个数字可以调整，以减少假阳性或假阴性的数量。</li><li id="57c0" class="pw px it ma b mb qf me qg mh qh ml qi mp qj mt qb qc qd qe bi translated">FPR(I 型误差)和 FNR(II 型误差)是互补的。减少一个会增加另一个。</li><li id="d4c7" class="pw px it ma b mb qf me qg mh qh ml qi mp qj mt qb qc qd qe bi translated">使用<code class="fe mu mv mw mx b">catboost</code>包计算分类的概率截止阈值。</li><li id="f7a9" class="pw px it ma b mb qf me qg mh qh ml qi mp qj mt qb qc qd qe bi translated">例:<code class="fe mu mv mw mx b">predict_threshold(test_pool2, threshold= 0.01, rate_type=”FNR”)</code></li></ul><p id="88f5" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">如果你喜欢这个内容，关注我的博客或者在<a class="ae ky" href="https://www.linkedin.com/in/gurezende/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上找到我。</p><div class="oi oj gp gr ok ol"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="ou l"><div class="qk l ow ox oy ou oz ks ol"/></div></div></a></div><p id="8cc7" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">使用这个<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">推荐代码</a>成为一个媒体会员(你的订阅的一部分将会来到我这里，激励我继续创作内容)。</p><h1 id="2799" class="lg lh it bd li lj oc ll lm ln od lp lq jz oe ka ls kc of kd lu kf og kg lw lx bi translated">参考</h1><div class="oi oj gp gr ok ol"><a href="https://github.com/catboost/tutorials/blob/master/events/2019_pydata_london/pydata_london_2019.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">master catboost 上的 tutorials/pydata _ London _ 2019 . ipynb/tutorials</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="ql l ow ox oy ou oz ks ol"/></div></div></a></div><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="qm qn l"/></div></figure></div></div>    
</body>
</html>