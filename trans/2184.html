<html>
<head>
<title>Using Caching to Speed up Your Python Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用缓存加速Python代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-caching-to-speed-up-your-python-code-871e9c08aefd#2022-05-16">https://towardsdatascience.com/using-caching-to-speed-up-your-python-code-871e9c08aefd#2022-05-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ea80" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在Python中实现各种缓存策略</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c1d01f37c8566349dcd20cc44dc2d271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*juuBRaQxuQTWwd_x"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@veri_ivanova" rel="noopener ugc nofollow" target="_blank">维里·伊万诺娃</a>在<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="f070" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">在</span>上一篇文章中，我谈到了<a class="ae ky" rel="noopener" target="_blank" href="/how-to-find-out-the-bottleneck-of-my-python-code-46383d8ef9f">如何找出我的Python代码</a>的瓶颈。其中一个要点是分析程序并找到需要很长时间的代码段。作为后续，在本文中，我想介绍一种流行的架构模式来打破瓶颈并加速您的Python代码——缓存。除了讲述理论，我还将解释Python中的一些内置缓存解决方案，以及如何使用Python来实现流行的缓存策略(如LRU、LFU等)。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="586f" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">什么是缓存？</h2><p id="d5ee" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">缓存是一个通用术语，用于将一些数据临时存储在一个比从源(数据库、文件系统、服务等)读取数据更快的地方。存储层<em class="nj">缓存</em>要么是源的子集，要么是一些繁重计算的预计算结果。缓存中的数据通常存储在快速访问硬件中，如RAM和内存引擎。因此，缓存允许您提高系统的整体吞吐量，因为单位时间内可以处理更多的读取请求。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f52184e63bed99ed599cd7579b819e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*LZK1tR2UbHfLF-DsuLSihw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">缓存(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创建)</p></figure></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="a330" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">我们什么时候需要缓存？</h2><p id="44de" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">当涉及到性能问题时，我们通常会将问题归结为CPU限制或I/O限制。缓存在这两种情况下都很有用。</p><p id="9369" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">存储先前计算的数据</strong></p><p id="a1dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加速CPU受限程序的一个例子是缓存先前计算的结果以避免重复计算。我们可以用递归的方法用它来解决斐波那契问题。这是递归树。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/ba3c62de740d3351d620a58b24bd35e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nmdag-B0LqKfToez1jPZGg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">斐波那契递归树(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创建)</p></figure><p id="9843" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本算法要求您编写一个递归函数，根据需要多次调用自己。以这个图为例，计算<code class="fe no np nq nr b">f5</code>，函数要调用自己15次，其中<code class="fe no np nq nr b">f1</code>节点5次，<code class="fe no np nq nr b">f0</code>节点3次，<code class="fe no np nq nr b">f2</code>节点3次，等等。所需时间呈指数增长，因为该函数反复计算许多相同的子问题。</p><p id="43f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种使算法更有效的技术叫做记忆化。记忆通过将先前计算的结果存储在高速缓存中来加速算法。因此，该函数只需要查找节点的结果，而无需再次运行计算。如果你对斐波那契问题感兴趣，可以用Real Python查看这篇文章。</p><div class="ns nt gp gr nu nv"><a href="https://realpython.com/fibonacci-sequence-python/#generating-the-fibonacci-sequence-recursively-in-python" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">斐波纳契数列的Python指南-真正的Python</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">让我们开始吧！列奥纳多·斐波那契是一位意大利数学家，他能够很快给出这个问题的答案…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">realpython.com</p></div></div><div class="oe l"><div class="of l og oh oi oe oj ks nv"/></div></div></a></div><p id="a6d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">存储最常请求的数据</strong></p><p id="13c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多存储层，如数据库和文件系统，由于它们的低IOPS(每秒输入/输出操作数)，可能是对程序整体性能影响最大的因素。为了加快I/O绑定程序的速度，缓存在原始存储位置(数据库、文件系统等)前面创建了一个存储层，以便更快地进行数据检索。缓存可以通过不同的技术层来应用:</p><ul class=""><li id="ab2a" class="ok ol it lb b lc ld lf lg li om lm on lq oo lu op oq or os bi translated">操作系统—从较低层读取数据比从较高层读取数据要慢。操作系统中的缓存是为了确保最频繁请求的数据位于最高级别。</li><li id="4d43" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">数据库——大多数数据库，如<a class="ae ky" href="https://dev.mysql.com/doc/internals/en/caching.html" rel="noopener ugc nofollow" target="_blank"> MySQL </a>都采用内部缓存来保存内存中的热数据或昂贵查询的结果。如果数据已经在缓存中，它就响应数据库请求。这通过降低数据库引擎上的资源利用率极大地提高了性能。尽管它完全由数据库管理，但理解这些机制有助于调试性能问题。</li><li id="755c" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">应用程序—开发人员可以在由活动驱动的应用程序层中实现自定义缓存解决方案。如果您对数据库中内置的缓存解决方案不满意，您可以根据需要在您的数据库前面再设置一个缓存，用于存储<em class="nj">热</em> <em class="nj">数据</em>及其到期日期。</li><li id="cb6e" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">Web缓存—缓存在web应用程序中广泛使用。在服务器端和客户端都可以采用各种缓存策略。服务器通常使用web代理来保留web响应。客户端(例如浏览器)通常缓存图像、HTML页面、HTTP会话等web资产，以便在所有web服务器和设备上提供更好的用户体验。</li><li id="0246" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">CDN(内容交付网络)—当您的web流量分散在不同的地理位置时，将整个基础架构复制到每个新位置的成本很高。CDN能够将视频和网页等网络内容的缓存副本提供给各地的客户。</li></ul></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="bc8f" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated"><strong class="ak">有哪些缓存</strong>策略<strong class="ak">？</strong></h2><p id="3dc5" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">大多数缓存被设计成键值对，其中缓存键是缓存中每个对象的唯一标识符。当请求生成匹配的缓存密钥，并且对象将作为响应返回时，就会发生缓存命中。实现缓存时，我们应该了解一些常见的缓存特征和策略:</p><p id="6953" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">缓存是为读密集型应用而设计的</strong></p><p id="2d19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在应该很清楚，缓存是一种快速读取的解决方案。它主要有益于进行大量读取操作的程序。为达到最佳性能，读取操作应具有时间复杂性<strong class="lb iu"> O(1) </strong>。如果您熟悉基本的数据结构，您应该知道哈希映射——这是Python中的字典。字典中给定关键字的值可能被最新的设置操作覆盖，该操作的时间复杂度也是O(1)。</p><pre class="kj kk kl km gt oy nr oz pa aw pb bi"><span id="869c" class="ml mm it nr b gy pc pd l pe pf">cache = {}<br/>cache["user1"] = "res1"</span></pre><p id="d5d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，这种实现方式存在一些问题。在最坏的情况下(虽然非常罕见)，密钥冲突问题将导致读取操作的<a class="ae ky" href="https://wiki.python.org/moin/TimeComplexity" rel="noopener ugc nofollow" target="_blank"> O(n)时间复杂度</a>。另一个问题是，您不能将<em class="nj">所有的</em>都放在内存缓存中，因为它最终会爆炸内存，所以您应该决定缓存应该存储什么。</p><p id="48e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">根据内容的创建时间存储内容</strong></p><p id="6e84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">控制缓存大小的一种方法是拥有一种自动清理机制。将新的键值对插入缓存时，会为该键分配一个TTL(生存时间)值。它是一个整数值，指定密钥到期前的秒数。换句话说，该对将在TTL秒后被删除，以保持缓存在可管理的大小。它避免了用太多过时的数据来扰乱缓存。</p><p id="f02e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据对象的时间敏感性选择合适的TTL。一般来说，对于不常变化的数据或客户端对陈旧数据更宽容的数据，会设置较高的TTL。对于对时间敏感的数据，如股票市场和天气，通过强制缓存更频繁地重新验证内容，可以设置较低的TTL。</p><p id="d11c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要用TTL创建缓存，我们可以安装软件包<code class="fe no np nq nr b">cachetools</code>。在本例中，缓存存储从<a class="ae ky" href="https://openweathermap.org/" rel="noopener ugc nofollow" target="_blank"> OpenWeatherMap </a>中检索到的天气数据，每10分钟刷新一次。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pg ph l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">TTL缓存示例</p></figure><p id="9d1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在后台，第一个函数调用API并将响应存储在缓存中，TTL设置为10分钟。因此，第二个函数花费的时间要少得多，因为它直接从缓存中检索数据。第三个函数是在密钥已经过期时执行的，所以它再次调用API并刷新缓存中的阿姆斯特丹天气数据。</p><p id="9ba9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TTL广泛应用于CDNs环境中。它控制网站资源的刷新率，理想地确保客户端不会看到太陈旧的内容，同时提高页面加载速度。TTL也是一种DSN服务器设置，它告诉缓存在从名称服务器再次搜索之前存储DNS记录的时间。</p><p id="c318" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">根据访问模式存储内容——LRU&amp;LFU</strong></p><p id="410a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了时间之外，决定何时从缓存中清除对象的另一个重要因素是它的访问模式。当缓存已满时，使用两种常见策略:</p><ul class=""><li id="4d35" class="ok ol it lb b lc ld lf lg li om lm on lq oo lu op oq or os bi translated">LRU(最近最少使用)—首先丢弃最近最少使用的项目。它按照使用顺序对项目进行排序。每次访问一个对象时，算法都会将它移动到缓存的顶部。这样，算法可以快速识别哪个项目最长时间没有被访问。</li><li id="83a5" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">LFU(租赁常用)-首先丢弃最不常用的项目。它不是删除最近最少使用的数据，而是驱逐最少使用的数据。它可能会丢弃最近使用过但不像其他数据那样经常使用的数据。</li></ul><p id="3ecf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果您实现了一个缓存来存储浏览器历史，并且您对最近访问过的页面更感兴趣，那么LRU缓存就更有用。另一方面，如果你使用缓存来存储浏览器的书签，那么LFU更有用，因为用户可以快速打开他们最喜欢的页面。</p><p id="e066" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Python为LRU缓存提供了<a class="ae ky" href="https://docs.python.org/3/library/functools.html" rel="noopener ugc nofollow" target="_blank">内置库</a>。高速缓存最多保存最近的<code class="fe no np nq nr b">maxsize</code>次呼叫。在本例中，高速缓存的大小为1。通过查看日志，前3个函数实际上调用了API ,因为它们都请求来自前一个函数的不同数据。只有最后一个函数利用了缓存，因为它与前一个函数检索相同的对象。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pg ph l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">lru缓存的示例</p></figure><p id="e242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们看看LRU缓存的实现，以理解为什么它是如此受欢迎的缓存策略。作为一个缓存，它必须是时间高效的，即所有操作的时间复杂度应为O(1)。</p><p id="dd8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哈希映射是一种存储键值对的良好数据结构，具有较低的时间复杂度。在LRU缓存中，我们需要另一种数据结构来维护<strong class="lb iu">的使用顺序</strong>。整个过程包括以下步骤:</p><ul class=""><li id="32f8" class="ok ol it lb b lc ld lf lg li om lm on lq oo lu op oq or os bi translated">在哈希表中查找项目。哈希映射存储对象及其使用顺序。</li><li id="736b" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">将对象移动到行首，其他对象应该相应地向后移动。值得注意的是，这个机动的时间复杂度应该是O(1)。您可以在这里暂停一下，想想哪种数据结构最合适。</li><li id="3393" class="ok ol it lb b lc ot lf ou li ov lm ow lq ox lu op oq or os bi translated">如果该项不在哈希表中，它将被添加到行首。如果缓存已满，我们需要驱逐最近最少使用的项——行尾。时间复杂度也被认为是O(1)。</li></ul><p id="fe3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哪个数据结构在你的脑海里？数组？LinkedList？数组的一个问题是将一个项目移动或添加到数组的前面需要O(n)时间。然而，一个单链表只需要O(1)时间。但是删除尾节点需要O(n)时间，因为它需要遍历整个LinkedList。</p><p id="c208" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以最好的解决方案是使用双向链表。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6ddc98b932652ca360aaec347e022e62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*KzyxZgd_whT5CjsVtTYjlQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LRU缓存示例(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创建)</p></figure><p id="0b07" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哈希映射存储相应的链表节点。将一个节点移动到列表的头部的时间复杂度是O(1)。因为它是一个双向链表，删除尾部节点也需要O(1)时间。</p><p id="7016" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一种用Python实现LRU缓存的方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pg ph l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Lru缓存实现</p></figure><p id="eaf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LFU的工作方式与LRU缓存类似，但它根据数据的使用频率来驱逐数据。如果有多个项目具有相同的频率，它将驱逐最近最少使用的项目。与LRU缓存相比，它需要额外的哈希映射来存储频率信息。关键是频率，值是具有该频率的项目列表，并按访问时间排序。在实现中，我也使用了双向链表。但是这部分可以用Python中的<a class="ae ky" href="https://github.com/python/cpython/blob/3.10/Lib/collections/__init__.py#L78" rel="noopener ugc nofollow" target="_blank"> OrderedDict </a>来代替，它是使用相同的数据结构实现的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/f9a8b08e7eab6eba29a62b6cf9eb797e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ew4Qt-Mk7HA3v_UpwsS96A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Lfu缓存(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创建)</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pg ph l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Lfu cahce实施</p></figure><p id="1fa6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">根据内容的创建时间和访问模式存储内容</strong></p><p id="6fa9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">LRU/LFU缓存的一个问题是，如果数据被反复请求，它将永远不会从源获取更新。为了解决这个问题，我们可以添加TTL值。如果请求试图访问过期数据，该函数将从源获取更新并刷新缓存。我们可以通过在<code class="fe no np nq nr b">@lru_cache</code>之上创建一个装饰器来实现这一点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pg ph l"/></div></figure><p id="0b95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在最后一个函数中，虽然缓存还没有满，但是函数仍然调用API，因为数据已经过期。当时间和访问模式都相关时，这种策略很有用。例如，我想设计一个缓存来存储Twitter用户最近的推文。LFU缓存确保只有受欢迎的用户的推文存储在缓存中，TTL值确保缓存中不包含太陈旧的推文。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="2f19" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">如何将缓存集成到系统中？</h2><p id="5f48" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">到目前为止，我们已经讨论了缓存的内部设计和回收策略。最终，我们需要将缓存集成到应用程序中。根据应用程序的类型，可以应用一些模式。</p><p id="d14a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">通读</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/772246ef70bddba39f00699a61396400.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YvdbxCLEsXSoDlXYcLfEyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">通读(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创作)</p></figure><p id="601e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是最常用的模式。收到请求时，应用程序会尝试在缓存中查找匹配项。如果找到了数据，它会立即返回数据。否则，它会到底层数据库获取数据，并将其加载到缓存中。</p><p id="fe6c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种模式中，由于频繁的缓存未命中，初始请求的延迟会很高。</p><p id="0ec4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">写通</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/d0fe736fd18b3f7c63e8228d780e7969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8CDjqeEQMENltOc91zM29Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">直写(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创作)</p></figure><p id="9096" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">直写与填充缓存的顺序相反。每次写入都是先写入缓存，然后再写入源。这意味着缓存总是与源同步。应用程序从不需要从数据源读取数据。</p><p id="eb83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为缓存与源同步，所以很可能可以在缓存中找到数据。从而导致更好的性能。然而，缺点是包括不经常请求的数据在内的所有数据也存储在高速缓存中，导致高速缓存庞大而昂贵。缓存和源之间的同步是一个同步过程，可能会导致高延迟。</p><p id="2741" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用直写和通读模式是很常见的。例如，数据首先被写入缓存，并设置一个TTL值以保持其相关性和精简性。如果再次请求已删除的数据，它可以使用通读模式从源中检索回来。</p><p id="6244" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">写在</strong>后面</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/a5fcc3efe763e407b37e17c1fcefdbdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VpOFnPsj6e80GBtcVIb-gw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">写在后面(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创作)</p></figure><p id="ef23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这类似于直写模式。应用程序首先将数据写入缓存。但之后，应用程序会立即返回到主进程。另一个进程将定期运行，以同步缓存和源之间的数据。与直写不同，缓存和源之间的备份是一个异步过程。</p><p id="3c6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们不想承担每次写入源的高延迟成本，并且同步过程足够可靠，这种方法会更有效。但是，这种模式需要从缓存到源的可靠备份过程，以确保数据不会丢失。</p><p id="5171" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">提前刷新</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/dca456858c641579380474169cecdcf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sj1Qb1yai2_EgsZ7UmPdlQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提前刷新(由<a class="nl nm ep" href="https://medium.com/u/2adc5a07e772?source=post_page-----871e9c08aefd--------------------------------" rel="noopener" target="_blank">高</a>创作)</p></figure><p id="206d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种模式中，缓存被配置为在数据过期之前自动和异步地从数据源重新加载数据。因此，应用程序将总是从缓存中检索数据。万一出现罕见的缓存未命中，它将从源执行同步读取并刷新缓存。</p><p id="63eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">提前刷新对于大量读取的应用程序很有用。值在高速缓存中保持新鲜，并且避免了从源过度重载的问题。</p><p id="3820" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通常，预刷新和通读是为只读应用程序设计的。提前刷新在低延迟的情况下更有效，但是它需要缓存中的一种机制来决定何时从源加载什么。通读很容易实现，但是我们需要忍受初始请求中的高延迟，因为大多数请求将直接到达源。</p><p id="1dc2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于读/写应用程序，直写和后写都很有用。同样，直写相对容易实施，但由于缓存和源之间的同步备份，会导致高延迟。而后写具有低延迟，但需要确保在将缓存转储到源时不会丢失任何东西。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="35ca" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">结论</h2><p id="f822" class="pw-post-body-paragraph kz la it lb b lc ne ju le lf nf jx lh li ng lk ll lm nh lo lp lq ni ls lt lu im bi translated">在本文中，我们讨论了一些关于缓存的理论，包括什么是缓存，何时需要缓存，以及不同的缓存策略和模式。我们还看到了Python中TTL缓存、LRU缓存和LFU缓存的实现。希望你觉得有用。干杯！</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h2 id="f189" class="ml mm it bd mn mo mp dn mq mr ms dp mt li mu mv mw lm mx my mz lq na nb nc nd bi translated">参考</h2><div class="ns nt gp gr nu nv"><a href="https://aws.amazon.com/caching/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">什么是缓存及其工作原理| AWS</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">缓存是一个高速数据存储层，它存储数据的一个子集，通常是短暂的，以便将来…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">aws.amazon.com</p></div></div><div class="oe l"><div class="po l og oh oi oe oj ks nv"/></div></div></a></div><div class="ns nt gp gr nu nv"><a href="https://kislayverma.com/software-architecture/architecture-patterns-caching-part-1/" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd iu gy z fp oa fr fs ob fu fw is bi translated">架构模式:缓存(第1部分)|基斯利·维尔马</h2><div class="oc l"><h3 class="bd b gy z fp oa fr fs ob fu fw dk translated">性能一直是技术系统的关键特征。今天在互联网上，亚秒级的延迟是…</h3></div><div class="od l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">kislayverma.com</p></div></div><div class="oe l"><div class="pp l og oh oi oe oj ks nv"/></div></div></a></div></div></div>    
</body>
</html>