<html>
<head>
<title>Learnt Harmonic Mean Estimator for Bayesian Model Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯模型选择的学习调和均值估计</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learnt-harmonic-mean-estimator-for-bayesian-model-selection-47258bb0fc2e#2022-05-13">https://towardsdatascience.com/learnt-harmonic-mean-estimator-for-bayesian-model-selection-47258bb0fc2e#2022-05-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="631a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">机器学习辅助的边际可能性计算</h2></div><p id="abbc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">贝叶斯模型比较提供了一个原则性的统计框架，用于选择合适的模型来描述观察数据，自然地权衡模型复杂性和拟合优度。然而，它需要计算贝叶斯模型证据，也称为边际可能性，这在计算上具有挑战性。我们提出了学习调和均值估计器来计算模型证据，这是不可知的采样策略，提供了很大的灵活性。</em></p><p id="e26f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文由<a class="ae lc" href="https://www.ucl.ac.uk/astrophysics/people/dr-alessio-spurio-mancini" rel="noopener ugc nofollow" target="_blank">阿莱西奥·斯普尔里奥·曼奇尼</a>合著。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/f46d692b4636c5853b1a78f05e22deae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w6LXENTWSetqERkX-SZDFA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">贝叶斯定理。【<a class="ae lc" href="https://miro.medium.com/max/3200/1*as2DnWuAUVLSZpS6MvPZxw.png" rel="noopener">图片来源</a>。]</p></figure><p id="7f63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lt translated">选择一个合适的模型来描述观察到的数据，这在数据科学的许多领域都是一项重要的任务。贝叶斯形式主义为比较和选择模型提供了一个健壮和有原则的统计框架。然而，执行贝叶斯模型选择是高度计算要求的。</p><h1 id="8511" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">贝叶斯模型选择</h1><p id="b86f" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">贝叶斯形式主义是统计推断最常用的方法之一。对于参数推断，对于给定的模型<em class="lb"> M </em>，感兴趣的参数𝜽的后验概率分布可以通过贝叶斯定理与数据<em class="lb"> y </em>的似然相关</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mz"><img src="../Images/cf234f0764a7b4c7aa34b2c182a8cede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yMgkrIB3cK5VNUtlPISOhg.png"/></div></div></figure><p id="fca9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中先验分布<em class="lb"> p( </em> 𝜽 <em class="lb"> | M) </em>编码了我们在观察数据之前对参数的先验知识(关于贝叶斯推理的介绍，请参见<a class="ae lc" rel="noopener" target="_blank" href="/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348">这篇优秀的TDS文章</a>)。</p><p id="601c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由上述等式的分母给出的<em class="lb">贝叶斯模型证据</em>与参数估计无关，因为它独立于感兴趣的参数，并且可以简单地视为归一化常数。然而，对于模型比较来说，<em class="lb">贝叶斯模型证据</em>，也称为<em class="lb">边际可能性</em>，起着核心作用。</p><p id="84c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于模型选择，我们感兴趣的是模型的后验概率，通过贝叶斯定理的另一个应用，它可以写成</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi na"><img src="../Images/e4369426eae8ef3f460afbbf5e270c43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FdFv9Zpc8k4jIWckkJ8s0Q.png"/></div></div></figure><p id="7bcc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，为了比较模型，我们需要计算贝叶斯因子，这需要计算考虑中的模型的模型证据。这就是计算挑战的地方。</p><p id="7b59" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">贝叶斯模型证据</strong>由参数空间上的似然和先验的积分给出:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nb"><img src="../Images/479773ada5f617ff27f12487d6e071d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3qS7-jRy0REdS1tLym0ChA.png"/></div></div></figure><p id="715f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，证据的计算需要评估多维积分，这在计算上极具挑战性。我们将很快回到这一点，引入学习调和平均估计量来计算模型证据。</p><p id="5e0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得注意的是，模型证据自然地结合了<strong class="kh ir">奥卡姆剃刀</strong>，权衡了模型复杂性和拟合优度，如下图所示。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nc"><img src="../Images/a794940afa937bcdde78b200366b2a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zA4jsFQ0qUIm16vcDjMweQ.jpeg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">贝叶斯模型证据自然地结合了奥卡姆剃刀，权衡了模型的复杂性和拟合优度。【图表来自<a class="ae lc" href="https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0553" rel="noopener ugc nofollow" target="_blank">Ghahramani(2013)</a>【1】，经许可转载，其灵感来自<a class="ae lc" href="https://en.wikipedia.org/wiki/David_J._C._MacKay" rel="noopener ugc nofollow" target="_blank"> David MacKay </a>的类似图表。]</p></figure><p id="1fff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图[1]中的水平x轴代表所有可能的数据集。在贝叶斯形式主义中，模型被指定为数据集上的概率分布，并且由于概率分布的总和必须为1，所以每个模型都有有限的“<em class="lb">概率预算</em>来分配。虽然复杂模型可以很好地表示大范围的数据集，但它的预测概率分布很广。这样做，如果不需要这样的复杂性，复杂模型的模型证据将被扣分。</p><p id="3b6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，贝叶斯形式主义提供了一种原则性的统计方法来执行模型选择。但是，在实践中应用这种形式并不简单，并且在计算上极具挑战性。</p><p id="050b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">已经开发了各种计算模型证据的方法，这些方法被证明非常成功(例如[2，3，4，5])。然而，这些通常有一些限制，并且很难扩展到更高维度的设置。因此，模型证据的计算远不是一个已解决的问题。在本文中，我们将重点放在调和平均估计量来计算贝叶斯模型的证据。</p><h1 id="96f3" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">原始调和均值估计量</h1><p id="d5dd" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated"><em class="lb">原始调和平均值估计值</em>于1994年由牛顿&amp;拉夫特[6]引入，依赖于以下关系:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nd"><img src="../Images/ff60739314bfd7c0fe6a31e259b060f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2a1Jna3wlrDpfHxHIk0KwA.png"/></div></div></figure><p id="127b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这表明模型证据(倒数)的估计量如下:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ne"><img src="../Images/d21f465f44f12040d6e3d985aa76e063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qvqB0v0BYLt19HK7HbRbXA.png"/></div></div></figure><p id="aa9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，给定来自后验𝜽 <em class="lb"> ᵢ </em>的样本，可通过<a class="ae lc" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank">马尔可夫链蒙特卡罗(MCMC)采样</a>生成，从似然的调和平均值中估计模型证据。</p><p id="f5d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">调和平均值估计的一个非常好的特性是，它只需要来自后验的样本，这可以通过任何MCMC技术产生。相比之下，计算模型证据的替代方法通常与特定的采样方法紧密结合，这可能具有很大的限制性。</p><p id="c2bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，在调和平均值估计被提出后，人们立即意识到它可能会灾难性地失败[7]。事实上，最初的调和均值估计被称为<a class="ae lc" href="https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever/" rel="noopener ugc nofollow" target="_blank">有史以来最差的蒙特卡罗方法</a>！</p><p id="ba1a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了直观地了解为什么最初的估计会失败，可以从<a class="ae lc" href="https://en.wikipedia.org/wiki/Importance_sampling" rel="noopener ugc nofollow" target="_blank">重要性抽样</a>的角度来看。估计量可以看作是重要抽样，其中先验扮演重要抽样目标分布的角色，后验扮演抽样密度的角色。</p><p id="dee6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使重要性抽样有效，我们通常会考虑比目标更宽的抽样密度。然而，对于调和平均值估计量，我们有相反的情况，因为封装了我们对模型参数的初始知识的先验分布通常比封装了我们对数据观察后的模型参数的知识的后验分布更宽。因此，原始谐波平均值的方差可能变得非常大，并且可能不是有限的，使得估计器在实践中无效。</p><h1 id="84e6" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">重定目标调和均值估计量</h1><p id="e827" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">盖尔范德&amp;戴伊在1994年【8】引入了<em class="lb">重定目标调和平均值估计器</em>来解决这个问题。重定目标的谐波均值估计器引入了新的目标分布<em class="lb"> φ </em> (𝜽)，其可以被设计成避免上述有问题的配置，从而产生以下估计器:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nf"><img src="../Images/039dbabca14fc0b900efdd9d2bb14d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARXn9QT3FigCsY2fL8GUBg.png"/></div></div></figure><p id="5d83" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问题仍然是:应该如何选择新的目标分布<em class="lb"> φ </em> (𝜽)？</p><p id="09c9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">已经考虑了各种情况，例如一个<a class="ae lc" href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution" rel="noopener ugc nofollow" target="_blank">多元高斯函数</a>【9】和<a class="ae lc" href="https://en.wikipedia.org/wiki/Indicator_function" rel="noopener ugc nofollow" target="_blank">指示函数</a>【10，11】。高斯曲线通常具有太宽的尾部，这会增加估计量的方差。虽然指标函数已被证明是有效的[10]，但它们通常局限于参数空间的一个小区域，因此可能是低效的。</p><h1 id="c67b" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">学习调和均值估计器</h1><p id="dbb0" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">通过考虑最佳目标，人们可以更直观地了解如何设计有效的目标分布，这只不过是标准化后验本身(因为所得的估计量具有零方差)。然而，目标分布必须归一化，后验的归一化常数是模型证据…正是我们试图估计的术语！</p><p id="d51f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然最佳目标(标准化后验概率)在实践中不可及，但我们建议使用机器学习来估计近似值:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ng"><img src="../Images/5aa2c01143fa4f58071188f19f2ff883.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJPBIySgA8DcAoK1r3PZ0Q.png"/></div></div></figure><p id="855b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就产生了<em class="lb">学习谐波均值估计器</em>【12】。后验概率的学习近似值不需要非常精确。但是，至关重要的是，它的尾巴不能比屁股更肥。当从后验样本学习目标分布时，我们施加这个约束。此外，我们提出策略来估计学习调和平均估计量的方差，它自己的方差，和其他健全性检查。(进一步的细节可以在我们的相关文章中找到:<a class="ae lc" href="https://arxiv.org/abs/2111.12720" rel="noopener ugc nofollow" target="_blank">麦克尤恩等人2021</a>【12】。)</p><h1 id="48e8" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">数值实验</h1><p id="ba09" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">我们进行了大量的数值实验，通过与贝叶斯模型证据的基础真值进行比较来验证学习的调和均值估计量。</p><p id="27ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Rosenbrock函数为评估计算模型证据的方法提供了一个公共基准。在下面的图中，我们显示了学习谐波均值估计器对于这个问题是鲁棒的和高度准确的。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nh"><img src="../Images/942102f1713ad35c27f4d9c27d2077ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tv4O4sQiWRgCH96na1bHuQ.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">Rosenbrock例子中学习调和平均值估计量计算的模型证据。执行100次实验来恢复估计器的统计的经验估计。不仅估计量本身是准确的，而且估计量的方差估计也是准确的。【原创剧情由作者创作。]</p></figure><p id="4188" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个常见的基准问题是法线伽马模型，如下图所示。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ni"><img src="../Images/c269a8e819ed432a1662cd0140138b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCPCWE0Znir85lZ13bhEsg.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">正常伽马模型的图形表示。【原图由作者创作。]</p></figure><p id="55a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在一项审查用于计算模型证据的估计量的研究[13]中，该示例显示了原始调和平均值估计量的病理性故障。在下表中，我们给出了由原始调和平均值估计器和我们学习的调和平均值估计器为该问题计算的模型证据值。我们的学习估计器非常准确，比原始估计器提高了四个数量级。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nj"><img src="../Images/c7fba7d133620433d679673844263a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w8FFxJFkmBIyDwnYUiVegg.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">贝叶斯模型证据值由原始调和平均值估计器和我们学习的调和平均值估计器为正常伽马基准问题计算。我们的学习估计器是高度准确的，提供了比原始估计器高四个数量级的改进(在对数空间中)。</p></figure><h1 id="624a" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">谐波代码</h1><p id="640c" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">学习谐波均值估计器在<a class="ae lc" href="https://github.com/astro-informatics/harmonic" rel="noopener ugc nofollow" target="_blank"> <em class="lb">谐波</em> </a>软件包中实现，该软件包是开源的并可公开获得。遵循软件工程最佳实践，仔细考虑了代码的设计和实现。</p><p id="ef00" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为学习谐波均值估计器只需要来自后验分布的样本，所以<em class="lb">谐波</em>码对于用于生成后验样本的方法或码是不可知的。也就是说，<em class="lb"> harmonic </em>与MCMC采样技术配合得非常好，MCMC采样技术通过其系综特性自然地提供来自多个链的样本，例如仿射不变性系综采样器[14]。<a class="ae lc" href="https://emcee.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">主持人</em> </a>代码【15】提供了仿射不变性集合采样器的出色实现，因此<em class="lb">主持人</em>是与<em class="lb">谐波一起使用的自然选择。</em></p><h1 id="0302" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">摘要</h1><p id="54b7" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">贝叶斯模型比较为选择合适的模型来描述观察数据提供了一个强大的原则性统计框架，自然地权衡了模型的复杂性和拟合优度。然而，它需要计算贝叶斯模型证据，也称为边际可能性，这是一个具有计算挑战性的问题。</p><p id="82b2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们回顾了用于计算模型证据的调和均值估计器，包括我们最近提出的<em class="lb">学习调和均值估计器</em>。学习调和均值估计器对用于产生后验样本的方法是不可知的，这给它提供了很大的灵活性。我们还发布了一个开源代码，<a class="ae lc" href="https://github.com/astro-informatics/harmonic" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> harmonic </em> </a>，它实现了估算器，我们遵循软件工程的最佳实践，非常关注代码的设计和实现。</p><p id="accb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目前，我们采用非常简单的机器学习模型和我们学习的调和均值估计器。这些简单的模型将很难扩展到非常高维的环境。我们已经在探索使用更复杂的机器学习模型，这将允许我们扩展到更高维度的设置。</p><p id="560a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望学习调和均值估计已经可以为贝叶斯模型选择提供一个有用的工具。特别是，由于它是不可知的抽样方法，它允许一个人计算模型证据的大量不同的抽样方法，这在以前是不可能的。</p><h1 id="d119" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">参考</h1><p id="c98c" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">[1] <a class="ae lc" href="https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0553" rel="noopener ugc nofollow" target="_blank"> Ghahramani </a>，<em class="lb">贝叶斯非参数化和概率方法建模，</em> <a class="ae lc" href="https://doi.org/10.1098/rsta.2011.0553" rel="noopener ugc nofollow" target="_blank">菲尔。反式。R. Soc。</a> (2013年)</p><p id="a88d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Skilling，<em class="lb">一般贝叶斯计算的嵌套抽样。</em> <a class="ae lc" href="https://www.mrao.cam.ac.uk/~steve/maxent2009/images/skilling.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯分析</a> (2006)</p><p id="dd29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Feroz &amp; Hobson，<em class="lb"> MultiNest:一种用于宇宙学和粒子物理学的高效且健壮的贝叶斯推理工具，</em> MNRAS (2009)，<a class="ae lc" href="https://arxiv.org/abs/0809.3437" rel="noopener ugc nofollow" target="_blank"> arXiv:0809.3437 </a></p><p id="248b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4] Handley，Hobson &amp; Lasenby，<em class="lb"> PolyChord:宇宙学的嵌套采样，</em> MNRAS (2015)，<a class="ae lc" href="https://arxiv.org/abs/1502.01856" rel="noopener ugc nofollow" target="_blank"> arXiv:1502.01856 </a></p><p id="7361" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]蔡，McEwen，Pereyra，<em class="lb">高维贝叶斯模型选择的近似嵌套抽样</em>，<a class="ae lc" href="https://arxiv.org/abs/2106.03646" rel="noopener ugc nofollow" target="_blank"> arXiv:2106.03646 </a></p><p id="6290" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[6] Newton &amp; Raftery，<em class="lb">用加权似然bootstrap进行近似贝叶斯推断，</em><a class="ae lc" href="http://www.jstor.org/stable/2346025" rel="noopener ugc nofollow" target="_blank">J R Stat Soc Ser A</a>(1994)</p><p id="ac53" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[7] Neal，<a class="ae lc" href="https://radfordneal.files.wordpress.com/2008/08/newton-raftery-disc.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lb">对“用加权似然自助法近似贝叶斯推断”的讨论的贡献</em> </a> (1994)</p><p id="3011" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[8]盖尔范德&amp;戴伊，<em class="lb">贝叶斯模型选择:渐近和精确计算</em>。J R Stat Soc Ser B </p><p id="40a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[9] Chib，<em class="lb">来自吉布斯产出的边际可能性</em>，<a class="ae lc" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476635#:~:text=In%20the%20context%20of%20Bayes,draws%20from%20the%20posterior%20distribution." rel="noopener ugc nofollow" target="_blank">美国统计协会杂志</a> (1995)</p><p id="6dc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[10] Robert &amp; Wraith，贝叶斯模型选择的计算方法，美国物理学会会议论文集(2009)，<a class="ae lc" href="https://arxiv.org/abs/0907.5123" rel="noopener ugc nofollow" target="_blank"> <br/> arXiv:0907.5123 </a></p><p id="bc1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[11] van Haasteren，【MCMC方法的边际似然计算，载于<a class="ae lc" href="https://link.springer.com/book/10.1007/978-3-642-39599-4" rel="noopener ugc nofollow" target="_blank">引力波探测和脉冲星计时阵列数据分析</a> (2014)</p><p id="0bb1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[12]麦克尤恩，沃利斯，普莱斯，多切蒂，<em class="lb">机器学习辅助贝叶斯模型比较:已学习调和均值估计器</em> (2021)，<em class="lb"> </em> <a class="ae lc" href="https://arxiv.org/abs/2111.12720" rel="noopener ugc nofollow" target="_blank"> arXiv:2111.12720 </a></p><p id="74f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[13]弗列尔和怀斯，<em class="lb">评估证据——一项审查</em>，尼尔兰迪卡统计局(2012年)，<a class="ae lc" href="https://arxiv.org/abs/1111.1957" rel="noopener ugc nofollow" target="_blank"> arXiv:1111.1957 </a></p><p id="fc88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[14] Goodman &amp; Weare，<em class="lb">仿射不变性集合采样器，</em> <a class="ae lc" href="https://msp.org/camcos/2010/5-1/camcos-v5-n1-p04-p.pdf" rel="noopener ugc nofollow" target="_blank">应用数学与计算科学通讯</a> (2010)</p><p id="fd31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[15]福尔曼-麦基，霍格，郎，古德曼，<em class="lb">主持人:MCMC汉默，</em> PASP (2013)，<a class="ae lc" href="https://arxiv.org/abs/1202.3665" rel="noopener ugc nofollow" target="_blank"> arXiv:1202.3665 </a></p></div></div>    
</body>
</html>