<html>
<head>
<title>How to Increase Training Performance Through Memory Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何通过内存优化提高训练绩效</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-increase-training-performance-through-memory-optimization-1000d30351c8#2022-08-21">https://towardsdatascience.com/how-to-increase-training-performance-through-memory-optimization-1000d30351c8#2022-08-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fd6f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">充分利用GPU内存的技巧</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7eb7fa3958f79bf4f591e0a52edf0c0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qkEA9EJnZLECn_Tk"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@alevisionco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">alevision.co</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="b4f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">优化深度神经网络(DNN)训练工作负载的运行时性能的关键之一是最大限度地利用训练实例的资源。GPU或其他训练加速器的资源尤其如此，它们通常是训练设备中最昂贵的组件。在这篇文章中，我们将重点关注GPU(或替代训练加速器)的<strong class="ky ir">内存利用率</strong>。关于培训绩效优化的更多建议，请务必查看我们的其他博客帖子(例如<a class="ae kv" rel="noopener" target="_blank" href="/tensorflow-performance-analysis-314b56dceb59">此处</a>和<a class="ae kv" rel="noopener" target="_blank" href="/overcoming-data-preprocessing-bottlenecks-with-tensorflow-data-service-nvidia-dali-and-other-d6321917f851">此处</a>)。为了简单起见，每当我们提到GPU内存的时候，我们更泛指<em class="ls">任何</em>训练加速器的内存，包括GPU、<a class="ae kv" href="https://cloud.google.com/tpu" rel="noopener ugc nofollow" target="_blank">谷歌云TPU </a>、<a class="ae kv" href="https://habana.ai/training/gaudi/" rel="noopener ugc nofollow" target="_blank">哈瓦那高迪</a>等。</p><p id="0459" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GPU内存优化最基本的例子是增加批量大小，以尽可能将内存利用率提高到接近100%。一般来说(但不总是)，你的整体训练吞吐量会增加。这是因为存在与每个训练步骤相关联的<em class="ls">固定成本</em>操作，例如GPU内核加载和梯度共享。这些是<em class="ls">固定成本</em>，因为它们不依赖于批量大小。因此，这些操作的每个样品的<em class="ls">成本</em>会随着批量的增加而降低。</p><p id="fd22" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，还有其他因素，如内存对齐，可能会发挥作用，因此不能保证总吞吐量会增加。但绝对值得一试。还要记住，即使在调整训练批大小时吞吐量确实增加了，也不能保证收敛速度(作为历元数的函数)保持不变。通常，这可以通过适当调整一些优化器设置来控制(参见此处的<a class="ae kv" rel="noopener" target="_blank" href="/a-guide-to-highly-distributed-dnn-training-9e4814fb8bd3">在数据分布式培训的背景下对该主题的讨论】,但并非总是如此。作为一个极端的例子，考虑这样一种情况:批处理的大小等于整个数据集的大小。增加批量大小不会给每个训练步骤增加任何额外的信息，因此，整个训练步骤的数量不会减少。</a></p><p id="b555" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的重点是GPU内存已经被充分利用的情况，我们正在寻求在不改变模型的架构或收敛能力的情况下减少内存消耗<strong class="ky ir">，以便释放内存用于其他用途。有许多众所周知的降低内存消耗的技术。在本帖中，我们将回顾其中的一小部分，包括混合精度训练、激活检查点和基于零的分布式训练(使用FSDP)。我们有意省略了一些技术，因为它们的性能损失相对较高(例如CPU卸载)，或者缺乏通用性(例如float8量化——在撰写本文时)。</strong></p><p id="bccc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章将包括几个使用py torch(1.12版)和tensor flow(2.8版)的代码片段。这些实现示例不应以任何方式被视为任何官方API文档和/或教程的替代。特别是，我们将使用的一些API仍被认为是实验性的，可能会进行修订和优化。请务必了解最新最棒的内存优化API产品。</p><h1 id="2553" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">动机——为什么您应该关注内存优化</h1><p id="51f7" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在这一节中，我们提供了一些优化内存利用率的情况，这意味着可以显著提高训练的运行时性能。</p><h2 id="4bf0" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">训练大型模型</h2><p id="2bf3" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">需要优化内存利用率的一个最常见的情况是，训练模型过于庞大，以至于它们根本不适合单个GPU。深度学习的一些最新进展依赖于极大模型的使用，这些模型的大小有数十亿个参数。训练这样的模型不是一件简单的事情，通常需要先进的模型分发策略、大量的GPU和足够的创造力。在过去的几年中，已经创建了许多库来解决这个独特的挑战(包括<a class="ae kv" href="https://www.deepspeed.ai/" rel="noopener ugc nofollow" target="_blank"> deepspeed </a>、<a class="ae kv" href="https://fairscale.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> fairscale </a>、<a class="ae kv" href="https://arxiv.org/abs/2105.04663" rel="noopener ugc nofollow" target="_blank"> GSPMD </a>等等)。在这些解决方案中，内存优化是一个关键因素。</p><p id="726e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">值得注意的是，虽然内存优化的主题经常在大型模型训练的上下文中出现，但在其他场景中，内存优化可能非常有益。在我们看来，熟悉这篇文章中讨论的技术是很重要的<strong class="ky ir">，即使你不是在训练一个大型模型</strong>。</p><h2 id="fb28" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">增加批量</h2><p id="4171" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">您可以增加训练批次大小的程度受到GPU中可用内存量的限制。你越能优化你的内存使用，你就越能释放内存来增加你的批处理大小。虽然对于大多数模型来说，大批量是一种奢侈，因为它可以增加您的整体训练量，但对于一些模型来说，大批量是至关重要的。例如，使用<a class="ae kv" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">对比损失</a>的模型，一种结合了大量正面和负面例子的损失，已被证明从特别大的批量中受益匪浅。</p><h2 id="61cc" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">提高GPU性能</h2><p id="ee87" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">内存优化可以提高训练吞吐量的另一种方式是通过提高GPU性能。一般来说，当GPU在更少的内存上运行时，它需要更少的计算能力。这是优化内存使用影响GPU性能的最明显的方式。然而，内存优化还有其他方法可以提高GPU利用率。</p><p id="262b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">示例-内存对齐:</strong>你的模型映射到加速器内存的方式高度依赖于组成它的张量的具体大小，这并不奇怪。批量大小、线性图层中的要素数量或卷积图层中的过滤器数量的微小变化都会对张量的映射方式产生重大影响。在大多数情况下，当ML工程师构建他们的深度学习模型时，他们(理所当然地)主要关心这些变化如何影响模型收敛。它们不考虑这种内存对齐问题，而是严重依赖SW堆栈以最佳方式将张量映射到内存。然而，有时结果映射会导致加速器计算能力的次优使用。例如，未能遵循<a class="ae kv" href="https://cloud.google.com/tpu" rel="noopener ugc nofollow" target="_blank">谷歌云TPU </a>编程的<a class="ae kv" href="https://cloud.google.com/tpu/docs/performance-guide#tensor_dimensions" rel="noopener ugc nofollow" target="_blank">性能指南</a>可能会导致大量内存填充，这相当于TPU计算能力的巨大浪费。调整模型参数可以改善内存对齐，减少填充量，并提高吞吐量。我们在下面展示了一个详细的例子。</p><p id="3873" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">希望我们已经让你相信了优化你的GPU内存的价值。在下一节中，我们将回顾实现这一点的几种方法。</p><h1 id="2a56" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">内存优化方法</h1><p id="fc64" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">有很多技术都属于GPU内存优化的范畴。在这一节中，我们将重点介绍一些能够提供有意义的好处，同时又相对容易编程的工具。我们将使用流行的<a class="ae kv" href="https://pypi.org/project/timm/" rel="noopener ugc nofollow" target="_blank"> timm </a>库，基于PyTorch 1.12中大约13亿个参数的分类模型，演示我们在玩具<a class="ae kv" href="https://en.wikipedia.org/wiki/Vision_transformer" rel="noopener ugc nofollow" target="_blank">视觉转换器</a> (ViT)上讨论的方法的实现。</p><p id="459e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们使用标准PyTorch数据分布API，<a class="ae kv" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html" rel="noopener ugc nofollow" target="_blank">分布式数据并行</a> (DDP)在一个伪数据集上训练我们的模型。有关DDP的详细信息，请参考官方<a class="ae kv" href="https://pytorch.org/docs/stable/notes/ddp.html" rel="noopener ugc nofollow" target="_blank">文件</a>。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f6d4" class="mq lu iq nd b gy nh ni l nj nk">import time, os<br/>import torch<br/>import torch.distributed as dist<br/>import torch.multiprocessing as mp<br/>from torch.utils.data import Dataset<br/>from timm.models.vision_transformer import VisionTransformer</span><span id="bb56" class="mq lu iq nd b gy nl ni l nj nk"># A fake dataset<br/>class FakeDataset(Dataset):<br/>  def __len__(self):<br/>    return 1000000</span><span id="a687" class="mq lu iq nd b gy nl ni l nj nk">  def __getitem__(self, index):<br/>    rand_image = torch.randn([3, 224, 224], dtype=torch.float32)<br/>    label = torch.tensor(data=[index % 1000], dtype=torch.int64)<br/>    return rand_image, label</span><span id="9f19" class="mq lu iq nd b gy nl ni l nj nk"># build a ViT model using timm<br/>def build_model():<br/>  model_args ={<br/>            "img_size": 224,<br/>            "patch_size": 14,<br/>            "embed_dim": 2560,<br/>            "mlp_ratio": 4.0,<br/>            "num_heads": 16,<br/>            "depth": 16<br/>        }<br/>  return VisionTransformer(**model_args)</span><span id="15df" class="mq lu iq nd b gy nl ni l nj nk"># DDP setup<br/>def setup(rank, world_size):<br/>  os.environ['MASTER_ADDR'] = os.environ.get('MASTER_ADDR',<br/>                                             'localhost')<br/>  os.environ['MASTER_PORT'] = os.environ.get('MASTER_PORT',<br/>                                             str(2222))<br/>  dist.init_process_group('nccl', rank=rank,<br/>                          world_size=world_size)</span><span id="3ae7" class="mq lu iq nd b gy nl ni l nj nk"># wrap the model with DDP<br/>def wrap_model(model,local_rank):<br/>  from torch.nn.parallel import DistributedDataParallel as DDP<br/>  model.to(torch.cuda.current_device())<br/>  model = DDP(model,device_ids=[local_rank])<br/>  return model</span><span id="b95f" class="mq lu iq nd b gy nl ni l nj nk"># standard training loop<br/>def train(local_rank, world_size):<br/>  setup(local_rank, world_size)<br/>  torch.cuda.set_device(local_rank)</span><span id="f428" class="mq lu iq nd b gy nl ni l nj nk">  dataset = FakeDataset()<br/>  model = build_model()<br/>  model = wrap_model(model, local_rank)<br/>  <strong class="nd ir">batch_size = 10 # per GPU batch size</strong><br/>  optimizer = torch.optim.Adam(model.parameters())<br/>  data_loader = torch.utils.data.DataLoader(dataset,<br/>                          batch_size=batch_size, num_workers=16)<br/>  loss_function = torch.nn.CrossEntropyLoss()<br/>  t0 = time.perf_counter()<br/>  summ = 0<br/>  count =0<br/>  for idx, (inputs, target) in enumerate(data_loader, start=1):<br/>    inputs = inputs.to(torch.cuda.current_device())<br/>    targets = torch.squeeze(target.to(torch.cuda.current_device()),<br/>                            -1)<br/>    optimizer.zero_grad()<br/>    outputs = model(inputs)<br/>    loss = loss_function(outputs, targets)<br/>    loss.backward()<br/>    optimizer.step()</span><span id="2e1c" class="mq lu iq nd b gy nl ni l nj nk">    if torch.distributed.get_rank() == 0:<br/>      batch_time = time.perf_counter() - t0<br/>      print(f'step: {idx}: step time is {batch_time}')<br/>      if idx &gt; 1: # skip first step<br/>        summ += batch_time<br/>        count += 1<br/>      t0 = time.perf_counter()</span><span id="adeb" class="mq lu iq nd b gy nl ni l nj nk">  if torch.distributed.get_rank() == 0:<br/>    print(f'average step time: {summ/count}')<br/>  dist.destroy_process_group()</span><span id="5492" class="mq lu iq nd b gy nl ni l nj nk">if __name__ == '__main__':<br/>  gpus_per_machine = torch.cuda.device_count()<br/>  mp.spawn(fn=train,<br/>           args=(gpus_per_machine,),<br/>           nprocs=gpus_per_machine,<br/>           join=True)</span></pre><p id="1eda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在将回顾一些内存优化方法，并展示如何将它们应用到上面的脚本中。</p><h2 id="bf43" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">混合精度</h2><p id="9491" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在PyTorch和TensorFlow等流行的训练框架中使用的默认浮点类型是float32，它使用32位表示。许多平台支持1位精度浮点。使用这些较低精度的浮点可以将浮点张量的内存利用率减半。由于在训练期间执行的绝大多数操作都是浮点操作，因此对内存节省的影响可能是显著的。同时，出于精度或性能的考虑，有些操作最好留在float32中。PyTorch和TensorFlow都支持使用<em class="ls">混合精度</em>模式的选项，在这种模式下，16位和32位浮点数串联使用(细节取决于实现)。有两种低精度浮点格式，float16和<a class="ae kv" href="https://cloud.google.com/tpu/docs/bfloat16" rel="noopener ugc nofollow" target="_blank"> bfloat16 </a>。Bfloat16有许多属性使它成为机器学习的首选格式；然而，它只在相对较新的平台上受支持。</p><p id="c6f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们演示了训练循环所需的简单更改，以便将PyTorch的<a class="ae kv" href="https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html" rel="noopener ugc nofollow" target="_blank">自动混合精度</a> (AMP)支持与bfloat16一起使用。注意，使用float16时，需要一个额外的<a class="ae kv" href="https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler" rel="noopener ugc nofollow" target="_blank">梯度缩放</a>步骤。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="2809" class="mq lu iq nd b gy nh ni l nj nk">for idx, (inputs, target) in enumerate(data_loader, start=1):<br/>    inputs = inputs.to(torch.cuda.current_device())<br/>    targets = torch.squeeze(target.to(torch.cuda.current_device()),<br/>                            -1)<br/>    optimizer.zero_grad()<br/>    <strong class="nd ir">with torch.cuda.amp.autocast(dtype=torch.bfloat16)</strong>:<br/>      outputs = model(inputs)<br/>      loss = loss_function(outputs, targets)<br/>    loss.backward()<br/>    optimizer.step()</span></pre><p id="ad98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有关混合精度的更多信息，请务必查看<a class="ae kv" href="https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>和<a class="ae kv" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">tensor flow</a>API的文档，同时密切关注每个API的详细信息。另外，请看这篇强烈推荐的<a class="ae kv" href="https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch/" rel="noopener ugc nofollow" target="_blank">博文</a>。</p><h2 id="dbd2" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">激活检查点</h2><p id="fb80" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在标准训练步骤的正向传递期间，所有中间激活张量都存储在存储器中，并用于计算反向传递期间的梯度更新。使用激活检查点时，只有指定激活的张量输出存储在内存中。从存储的激活检查点重新计算所有其他激活(使用适当的转发段)。这种技术以重复部分正向传递为代价来减少内存，即增加GPU操作的数量。这意味着使用激活检查点可能会增加您的步骤时间，从而降低您的吞吐量。！).然而，在许多情况下，通过利用释放的内存来增加批处理大小，总体吞吐量(每秒采样数)实际上可能会增加。</p><p id="cdbb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们演示了使用<a class="ae kv" href="https://pytorch.org/docs/stable/checkpoint.html" rel="noopener ugc nofollow" target="_blank"> PyTorch检查点API </a>来包装具有激活检查点支持的timm转换器块。然后，我们使用专用的timm VisionTransformer构造函数参数传入增强的Transformer块。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="d682" class="mq lu iq nd b gy nh ni l nj nk">def build_model():<br/>  model_args ={<br/>            "img_size": 224,<br/>            "patch_size": 14,<br/>            "embed_dim": 2560,<br/>            "mlp_ratio": 4.0,<br/>            "num_heads": 16,<br/>            "depth": 16<br/>        }<br/>  from timm.models.vision_transformer import Block<br/>  import torch.nn as nn<br/>  from torch.utils.checkpoint import checkpoint<br/>  class CKPTBlock(nn.Module):<br/>    def __init__(self, dim, num_heads, mlp_ratio=4.,<br/>                 qkv_bias=False, drop=0., attn_drop=0.,<br/>                 init_values=None, drop_path=0.,<br/>                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):<br/>      super().__init__()<br/>      self.block = Block(dim, num_heads, mlp_ratio,<br/>                         qkv_bias, drop, attn_drop,<br/>                         init_values, drop_path,<br/>                         act_layer, norm_layer)</span><span id="3c42" class="mq lu iq nd b gy nl ni l nj nk">    def forward(self, x):<br/>      return checkpoint(self.block,x)</span><span id="9b61" class="mq lu iq nd b gy nl ni l nj nk">  model_args['block_fn'] = CKPTBlock<br/>  return VisionTransformer(**model_args)</span></pre><p id="9d52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如文档中所述，使用激活检查点可能会对依赖随机生成的变量的图层(例如，丢弃图层)和在正向传递过程中收集统计数据的图层(例如，批量规范化图层)产生影响。在采用激活检查点之前，应该仔细研究和解决这些问题。更多细节参见<a class="ae kv" href="https://fairscale.readthedocs.io/en/latest/deep_dive/activation_checkpointing.html" rel="noopener ugc nofollow" target="_blank"> FairScale关于激活检查点</a>的文档。</p><h2 id="9312" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">零冗余优化器(<a class="ae kv" href="https://arxiv.org/pdf/1910.02054.pdf" rel="noopener ugc nofollow" target="_blank">零</a>)</h2><p id="cbf1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">零冗余优化器(<a class="ae kv" href="https://arxiv.org/pdf/1910.02054.pdf" rel="noopener ugc nofollow" target="_blank"> ZeRO </a>)指的是<a class="ae kv" href="https://arxiv.org/pdf/1910.02054.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>中描述的技术集合，用于优化内存利用率，以支持超大型模型的训练。在本帖中，我们将演示一种技术，通常称为ZeRO3。</p><p id="7b61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> ZeRO3 </strong>是一种执行数据分布式训练的技术，它取代了标准的数据分布方案(如PyTorch中的<a class="ae kv" href="https://pytorch.org/docs/stable/notes/ddp.html" rel="noopener ugc nofollow" target="_blank"> DDP </a>和TensorFlow中的<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy" rel="noopener ugc nofollow" target="_blank"> MirroredStrategy </a>)。在标准的数据分发方案中，每个GPU都保留自己的模型副本。通过在所有GPU之间共享梯度来确保模型之间的一致性。这需要高度的冗余。ZeRO3建议通过在所有GPU上分割模型来消除这种冗余。因此，每个单独的参数将驻留在单个GPU上，并由单个GPU拥有和更新，而不是所有的GPU。与标准方案一样，完整的训练步骤将在独立的本地批处理中在每个GPU上执行。当GPU达到存储在<em class="ls"> gpu_j </em>上的<em class="ls">参数_i </em>时，它将需要从<em class="ls"> gpu_j </em>中提取其权重来执行所需的计算，但它随后会立即删除权重，以便它不会占用任何内存。这在向前和向后传球中都发生。一旦计算出梯度更新，GPU需要将它们传达给它们各自参数的所有者。</p><p id="78b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<em class="ls"> N </em>个GPU上使用ZeRO3时，每个型号只存储该型号的<em class="ls"> 1/N </em>分之一。潜在的内存节省与GPU的数量成线性关系，不受训练批次大小的影响。特别要注意的是，ZeRO3内存节省仅适用于多GPU场景。不利的一面是，ZeRO3需要GPU之间多50%的网络通信来更新参数。ZeRO3以相对较小的网络通信增加为代价，为内存节省提供了一个实质性的机会。关于这些计算的更多细节，参见<a class="ae kv" href="https://arxiv.org/pdf/1910.02054.pdf" rel="noopener ugc nofollow" target="_blank">零文件</a>。</p><p id="cd15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ZeRO3的实现:zero 3的实现有很多，包括在<a class="ae kv" href="https://www.deepspeed.ai/" rel="noopener ugc nofollow" target="_blank"> deepspeed </a>和<a class="ae kv" href="https://fairscale.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> fairscale </a>中。在1.11版本中，PyTorch发布了他们自己的ZeRO3实现，名为<a class="ae kv" href="https://pytorch.org/docs/1.11/fsdp.html" rel="noopener ugc nofollow" target="_blank">fullyshardeddata parallel</a>(FSDP)。有关分区和FSDP API的更多详细信息，请参见<a class="ae kv" href="https://pytorch.org/docs/1.11/fsdp.html" rel="noopener ugc nofollow" target="_blank">基础</a>和<a class="ae kv" href="https://pytorch.org/docs/1.11/fsdp.html" rel="noopener ugc nofollow" target="_blank">高级</a> FSDP教程，以及<a class="ae kv" href="https://medium.com/pytorch/training-a-1-trillion-parameter-model-with-pytorch-fully-sharded-data-parallel-on-aws-3ac13aa96cff" rel="noopener">本概述</a>。</p><p id="e354" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们演示了使用FSDP时如何包装我们的模型。该代码在很大程度上依赖于官方教程，详细内容请参考这些教程。该代码包括用于以混合精度和激活检查点配置FSDP的控件。(注意，在撰写本文时，激活检查点需要PyTorch 的<a class="ae kv" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">夜间版本。)</a></p><p id="0723" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我要感谢<a class="ae kv" href="https://www.linkedin.com/in/less-wright-22b59017/" rel="noopener ugc nofollow" target="_blank"> Less Wright </a>和<a class="ae kv" href="https://www.linkedin.com/in/hamid-nazeri/" rel="noopener ugc nofollow" target="_blank"> Hamid Shojanazeri </a>对使用FSDP API的指导。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="78ad" class="mq lu iq nd b gy nh ni l nj nk">def wrap_model(model, local_rank):<br/>  from functools import partial<br/>  from timm.models.vision_transformer import Block<br/>  from torch.distributed.fsdp import (<br/>      FullyShardedDataParallel as FSDP,<br/>      MixedPrecision,<br/>      ShardingStrategy<br/>  )<br/>  from torch.distributed.fsdp.wrap import (    <br/>      transformer_auto_wrap_policy<br/>  )</span><span id="ab06" class="mq lu iq nd b gy nl ni l nj nk"><strong class="nd ir">  mixed_prec = True<br/>  ckpt_act = True</strong></span><span id="a22c" class="mq lu iq nd b gy nl ni l nj nk">  bfSixteen = MixedPrecision(<br/>      param_dtype=torch.bfloat16,<br/>      reduce_dtype=torch.bfloat16,<br/>      buffer_dtype=torch.bfloat16,<br/>  )</span><span id="5edf" class="mq lu iq nd b gy nl ni l nj nk">  mp_policy = bfSixteen if mixed_prec else None</span><span id="6c02" class="mq lu iq nd b gy nl ni l nj nk">  my_auto_wrap_policy = partial(transformer_auto_wrap_policy,<br/>                                transformer_layer_cls={Block,})</span><span id="538b" class="mq lu iq nd b gy nl ni l nj nk">  model = FSDP(model,<br/>               auto_wrap_policy=my_auto_wrap_policy,<br/>               mixed_precision=mp_policy,<br/>               device_id=torch.cuda.current_device(),<br/>               sharding_strategy=ShardingStrategy.FULL_SHARD)</span><span id="5cfa" class="mq lu iq nd b gy nl ni l nj nk">  if ckpt_act: # requires pytorch nightly<br/>    from torch.distributed.algorithms.\<br/>        _checkpoint.checkpoint_wrapper import (<br/>      checkpoint_wrapper,<br/>      CheckpointImpl,<br/>      apply_activation_checkpointing_wrapper<br/>    )<br/>    check_fn = lambda submodule: isinstance(submodule, Block)<br/>    non_reentrant_wrapper = partial(<br/>        checkpoint_wrapper,<br/>        offload_to_cpu=False,<br/>        checkpoint_impl=CheckpointImpl.NO_REENTRANT)<br/>    apply_activation_checkpointing_wrapper(<br/>        model, checkpoint_wrapper_fn=non_reentrant_wrapper,<br/>        check_fn=check_fn)<br/>  return model</span></pre><p id="7c8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如上所述，ZeRO3只是众多<em class="ls">模型分片</em>技术中的一种。您可能会发现，对于您的特定目的，一种不同的模型分片方法，或者多种方法的某种组合，更加合适。其他此类方法包括<a class="ae kv" href="https://pytorch.org/docs/stable/pipeline.html" rel="noopener ugc nofollow" target="_blank">流水线并行</a>，其中一个模型被分割成连续的分片，每个分片在一个单独的GPU上运行；以及<a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-tensor-parallelism-how-it-works.html" rel="noopener ugc nofollow" target="_blank">张量并行</a>，其中特定的层/张量被分割到多个GPU上。查看<a class="ae kv" href="https://medium.com/pytorch/pytorch-data-parallel-best-practices-on-google-cloud-6c8da2be180d" rel="noopener">这篇概述</a>，它调查了一些技术并提出了一个选择最佳选项的标准。</p><h1 id="1526" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">实验</h1><h2 id="fa99" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">在GPU上增加批量大小(PyTorch)</h2><p id="bfb8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了展示我们所讨论的不同技术的价值，我们在一个<a class="ae kv" href="https://aws.amazon.com/ec2/instance-types/p4/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2 p4.24xlarge实例</a>(有8个GPU)上运行了上面分享的PyTorch脚本。在下表中，我们总结了每次试验能够达到的批量大小，以及由此产生的训练速度(每秒样本数)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/fafec9146de6c69e179c6300ea5a475f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pfiyCNu_kr1sjgZL1EkLew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GPU上的性能结果(按作者)</p></figure><p id="8c1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然使用混合精度只能适度增加批量大小，但它可以显著提高训练速度。另一方面，激活检查点可以大大增加批量大小，但对训练速度来说代价很小。当结合使用FSDP和混合精度时，接收到最大吞吐量。当结合所有三种技术时，得到最大的批量。</p><p id="8102" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请记住，根据项目的具体情况，比较结果可能会有很大差异。在得出任何结论之前，一定要进行自己的详细评估。</p><p id="b0e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">重要提示(承蒙</strong><a class="ae kv" href="https://www.linkedin.com/in/less-wright-22b59017/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">Less Wright</strong></a><strong class="ky ir">)</strong>:我们在这个实验中的目标是评估不同的内存优化方法对我们最大限度地增加批处理大小的能力的影响，而不会遇到内存不足(OOM)故障。但是，您应该知道，在PyTorch中以这种方式最大化内存利用率有时会产生负面影响，例如内存分配失败和重试，这反过来会降低您的训练吞吐量。不幸的是，在撰写本文时，这些重试是在后台执行的，不会通知用户。如果你怀疑这可能发生在你身上，一定要看看这个教程。</p><h2 id="cc9e" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">增加TPU (PyTorch/XLA)的批量</h2><p id="ae8a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在我们的下一个实验中，我们展示了如何应用我们讨论的方法来增加<a class="ae kv" href="https://cloud.google.com/tpu/docs/run-calculation-pytorch" rel="noopener ugc nofollow" target="_blank">云TPU v3–8 VM</a>上PyTorch模型的训练批量。在进入实验细节之前，先做一些介绍性的评论:</p><ol class=""><li id="ff8d" class="nn no iq ky b kz la lc ld lf np lj nq ln nr lr ns nt nu nv bi translated">在TPU的PyTorch训练需要对你的剧本做一些修改。最值得注意的是，它需要py torch/XLA python库。你可以查看TPU <a class="ae kv" href="https://cloud.google.com/tpu/docs/run-calculation-pytorch" rel="noopener ugc nofollow" target="_blank">文档</a>了解更多细节。</li><li id="85eb" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated">在撰写本文时，PyTorch/XLA支持低精度(16位)浮点，但不支持PyTorch支持的自动混合精度(AMP)。如果您需要混合使用低精度和全精度浮点，您将需要手动应用它。</li><li id="53e8" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated">FSDP对<a class="ae kv" href="https://pytorch.org/xla/release/1.12/index.html" rel="noopener ugc nofollow" target="_blank"> PyTorch/XLA </a>的支持在1.12版本中发布。尽管torch-xla版本提供了与PyTorch FSDP类似的特性集，但在撰写本文时，具体的API和使用流程是不同的。更多细节见<a class="ae kv" href="https://github.com/pytorch/xla" rel="noopener ugc nofollow" target="_blank"> API </a>。</li><li id="0290" class="nn no iq ky b kz nw lc nx lf ny lj nz ln oa lr ns nt nu nv bi translated">torch-xla中FSDP的使用在<a class="ae kv" href="https://github.com/ronghanghu/vit_10b_fsdp_example" rel="noopener ugc nofollow" target="_blank">这个了不起的github项目</a>(由<a class="ae kv" href="http://ronghanghu.com/" rel="noopener ugc nofollow" target="_blank"> Ronghang Hu </a>提供)中的视觉转换器上演示，我们在实验中使用了它。</li></ol><p id="5fdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们通过使用以下命令行参数运行上述项目中的<em class="ls"> run_vit_training.py </em>脚本，训练了一个大约8亿参数的视觉传递:</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="1edb" class="mq lu iq nd b gy nh ni l nj nk">python3 run_vit_training.py \<br/> --embed_dim 2048 \<br/> --num_heads 16 \<br/> --num_blocks 16 \<br/> --batch_size 256 \<br/> --log_step_interval 1\<br/> --fake_data\<br/>#--run_without_fsdp\<br/>#--no_grad_ckpt\</span></pre><p id="ddd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用<em class="ls"> run_without_fsdp </em>和<em class="ls"> no_grad_ckpt </em>标志来分别控制fsdp和激活检查点的使用。低浮点精度设置是通过XLA _使用_BF16环境变量控制的。</p><p id="a599" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果，包括我们能够达到的批量大小和由此产生的产量，可以在下表中找到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/f7970cbe7201499907c06324f0373e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fksn9d-dt-4XryXl8ORABw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TPU的绩效结果(按作者)</p></figure><p id="ea81" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们再次警告不要从这些结果中得出任何关于你自己项目的结论。如前所述，我们可以看到内存优化技术非常有效。使用bfloat16不仅可以增加批量大小，还可以提高训练吞吐量。ZeRO3和激活检查点为增加批量大小提供了进一步的机会，而总体吞吐量的成本适中。</p><p id="5ac8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非常感谢Vaibhav Singh关于在云TPU上使用FSDP的指导。</p><h2 id="1df1" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">改进TPU上的内存对齐(TensorFlow)</h2><p id="4ea5" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在这个基于TensorFlow的实验中，我们展示了使用混合精度对TPU记忆比对和模型训练速度的影响。</p><p id="c4e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们定义了一个简单的卷积模型，该模型被训练来对公共的<a class="ae kv" href="https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/03_Flower_pictures_to_TFRecords.ipynb" rel="noopener ugc nofollow" target="_blank"> flowers </a>数据集执行分类。关于在云TPU上构建和运行TensorFlow模型的详细信息，请查看<a class="ae kv" href="https://cloud.google.com/tpu/docs/tutorials" rel="noopener ugc nofollow" target="_blank">官方教程</a>以及<a class="ae kv" rel="noopener" target="_blank" href="/tpu-training-6eb84100d138">这篇博文</a>。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="b69b" class="mq lu iq nd b gy nh ni l nj nk">import tensorflow as tf<br/>from tensorflow import keras<br/>from tensorflow.keras import layers<br/>from tensorflow.keras import mixed_precision</span><span id="f408" class="mq lu iq nd b gy nl ni l nj nk"><strong class="nd ir">local_batch_size = 64 # 128<br/></strong>batch_size = 8*local_batch_size<strong class="nd ir"><br/></strong>image_size = 331<br/>n_layers = 7<br/><strong class="nd ir">n_filters = 64</strong></span><span id="1829" class="mq lu iq nd b gy nl ni l nj nk"><strong class="nd ir"># Uncomment to use mixed<br/>#mixed_precision.set_global_policy('mixed_bfloat16')</strong></span><span id="937c" class="mq lu iq nd b gy nl ni l nj nk">tpu = tf.distribute.cluster_resolver.TPUClusterResolver()<br/>tf.config.experimental_connect_to_cluster(tpu)<br/>tf.tpu.experimental.initialize_tpu_system(tpu)<br/>strategy = tf.distribute.TPUStrategy(tpu)</span><span id="c495" class="mq lu iq nd b gy nl ni l nj nk">with strategy.scope():<br/>  inputs = keras.Input(shape=(image_size,image_size,3), <br/>                       name='frame')<br/>  x = layers.Conv2D(n_filters, 3, activation='relu', <br/>                    padding='same', name=f'conv_0')(inputs)<br/>  for i in range(1,n_layers):<br/>    x = layers.Conv2D(n_filters, 3, activation='relu', <br/>                      padding='same', name=f'conv_{i}')(x)<br/>  x = layers.Flatten()(x)<br/>  x = layers.Dense(5, name='dense_logits')(x)<br/>  outputs = layers.Activation('softmax', dtype='float32', <br/>                              name='predictions')(x)<br/>  model = keras.Model(inputs=inputs, outputs=outputs)<br/>  model.compile(loss='categorical_crossentropy',<br/>                  optimizer='adam')</span><span id="e4ac" class="mq lu iq nd b gy nl ni l nj nk">def parse_tfrecord(example):<br/>  features = {<br/>    "image": tf.io.FixedLenFeature([], tf.string),<br/>    "class": tf.io.FixedLenFeature([], tf.int64),<br/>    "one_hot_class": tf.io.VarLenFeature(tf.float32),<br/>  }<br/>  example = tf.io.parse_single_example(example, features)<br/>  decoded = tf.image.decode_jpeg(example['image'], channels=3)<br/>  normalized = tf.cast(decoded, tf.float32) / 255.0<br/>  image_tensor = tf.reshape(normalized, [image_size,image_size, 3])<br/>  one_hot_class = tf.reshape(tf.sparse.to_dense(<br/>                                    example['one_hot_class']), [5])<br/>  return image_tensor, one_hot_class</span><span id="df38" class="mq lu iq nd b gy nl ni l nj nk">p = 'gs://flowers-public/tfrecords-jpeg-331x331/flowers00-230.tfrec'<br/>dataset = tf.data.TFRecordDataset([p],  <br/>  num_parallel_reads=tf.data.AUTOTUNE)\<br/>  .map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\<br/>  .batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)</span><span id="5d07" class="mq lu iq nd b gy nl ni l nj nk">model.fit(dataset)</span></pre><p id="a4a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，在上面显示的脚本中，我们将每层的过滤器(通道)数量设置为64，并将本地批处理大小设置为64。如<a class="ae kv" href="https://cloud.google.com/tpu/docs/performance-guide#tensor_dimensions" rel="noopener ugc nofollow" target="_blank">文档</a>中所述，TPU会将通道大小或批量大小填充为可被128整除的数字。因此，我们可以预期这些张量的分配会导致2倍的填充开销。</p><p id="1aac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了使用<a class="ae kv" href="https://cloud.google.com/tpu/docs/cloud-tpu-tools" rel="noopener ugc nofollow" target="_blank">云TPU分析器</a>捕获的填充(蓝色)和未填充(红色)TPU内存利用率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/f87860ee68f1555aa9e4a5aeddef1864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TiIhShJ6YYholq1tdRR7_Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TensorBoard中的TPU内存配置文件(作者)</p></figure><p id="76fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如所料，填充开销很大，大约是1.63倍，相当于近40%的计算浪费。这个问题最简单的解决方案是将本地批处理大小加倍到128。不幸的是，在TPUv3上运行时，这导致了TPU OOM异常。这就是混合精度来拯救。通过将脚本配置为使用混合精度，我们能够减少内存占用，从而允许增加批处理大小。这不仅减少了填充开销，还将训练吞吐量提高了3倍以上。</p><p id="2569" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了应用混合精度并将本地批处理大小加倍后的内存配置文件:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/1a7baeb5ab33abec6aeec16c48338eeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b49z9WNd2KjF2h-6E3ZHTw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TensorBoard中的TPU内存配置文件(作者)</p></figure><p id="73b1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实验结果总结在下表中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/c804c18ad60c05de6bfb963b9b49a5cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IKVS3KCzIxm7gzVrnyEcKg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">TPU的绩效结果(按作者)</p></figure><h1 id="f429" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">摘要</h1><p id="9fe8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">要在现代深度学习领域取得成功，需要熟练掌握各种工具，以应对与优化使用培训资源相关的各种挑战。在这篇文章中，我们回顾了几种强大的技术，用于优化你的训练工作负载的GPU内存利用率。我们表明，这些技术不仅能使你显著扩大批量，还能使你的训练量显著增加。</p></div></div>    
</body>
</html>