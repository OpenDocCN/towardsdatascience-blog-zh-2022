<html>
<head>
<title>Recommender Systems — A Complete Guide to Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐系统——机器学习模型完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recommender-systems-a-complete-guide-to-machine-learning-models-96d3f94ea748#2022-11-25">https://towardsdatascience.com/recommender-systems-a-complete-guide-to-machine-learning-models-96d3f94ea748#2022-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3cf7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用数据帮助用户发现新内容</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/32718690c4a38a6132153a2cac716cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HQQUHJDQVwlHkA7P"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Javier Allegue Barros 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="b10d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">推荐系统:为什么和如何？</h1><p id="a7a2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Recommender_system" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">推荐系统</strong> </a>是为每个用户最相关的项目提供个性化建议的算法。随着可用在线内容的大规模增长，用户已经被淹没在选择中。因此，为了提高用户满意度和参与度，网络平台向每个用户提供商品推荐是至关重要的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/12c605b93649102531881347e897aa37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MLr8crqbUC9MazNIGOZOzw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">YouTube 向用户推荐视频，帮助他们在大量可用内容中发现和观看与他们相关的内容。(图片由作者提供)</p></figure><p id="4307" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">下面的列表展示了拥有<strong class="lq ir">大量可用内容</strong>的知名网络平台的例子，这些平台需要高效的推荐系统来保持用户的兴趣。</p><ol class=""><li id="8291" class="mq mr iq lq b lr ml lu mm lx ms mb mt mf mu mj mv mw mx my bi translated"><a class="ae kv" href="https://www.youtube.com/" rel="noopener ugc nofollow" target="_blank">T11】Youtube</a>T14】。每分钟都有人上传<a class="ae kv" href="https://www.oberlo.com/blog/youtube-statistics" rel="noopener ugc nofollow" target="_blank"> 500 个小时的视频</a>，也就是说，一个用户要花 82 年才能看完上一个小时上传的所有视频。</li><li id="4bc6" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj mv mw mx my bi translated"><a class="ae kv" href="https://www.spotify.com/" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir"/></a><strong class="lq ir">。</strong>用户可以收听超过<a class="ae kv" href="https://newsroom.spotify.com/company-info/" rel="noopener ugc nofollow" target="_blank">8000 万首歌曲和播客</a>。</li><li id="6a47" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj mv mw mx my bi translated"><a class="ae kv" href="https://www.amazon.com/" rel="noopener ugc nofollow" target="_blank">T27】亚马逊 </a> <strong class="lq ir">。</strong>用户可以购买超过<a class="ae kv" href="https://www.retailtouchpoints.com/resources/how-many-products-does-amazon-carry" rel="noopener ugc nofollow" target="_blank">3.5 亿种不同的产品</a>。</li></ol><p id="2c2d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">所有这些平台都使用强大的机器学习模型，以便为每个用户生成相关的推荐。</p><h1 id="5d54" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">显性反馈与隐性反馈</h1><p id="769e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在推荐系统中，机器学习模型用于预测用户<em class="ne"> u </em>对某个项目<em class="ne">I</em>T7】t8】的<strong class="lq ir">评分<em class="ne"> rᵤᵢ </em>。在推理时，我们向每个用户<em class="ne"> u </em>推荐预测评分最高的<em class="ne"> l </em>项<em class="ne">rᵤ</em>t16】t17】ᵢt19】。</strong></p><p id="2a43" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">因此，我们需要收集用户反馈，这样我们就可以有一个训练和评估模型的基础事实。这里必须对<strong class="lq ir">显式反馈</strong>和<strong class="lq ir">隐式反馈</strong>进行重要区分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/b910558749cf46992bc7f86720cc2a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yPeDvQjUoFdLKb9CkxaFPA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">推荐系统中显式和隐式反馈的比较。(图片由作者提供)</p></figure><p id="6edd" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Rating_scale#Rating_scales_used_online" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">显性反馈</strong> </a> <strong class="lq ir"> </strong>是用户明确给出的一个评分，用以表达对某个项目的满意程度。例如:购买产品后给出的从 1 到 5 的星级数，观看视频后给出的拇指向上/向下等。这种反馈提供了<strong class="lq ir">用户喜欢某件商品的详细信息</strong>，但是<strong class="lq ir">很难收集</strong>，因为大多数用户通常不会为他们购买的每件商品写评论或给出明确的评级。</p><p id="75a0" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Implicit_data_collection" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir"/></a>另一方面，假设用户-项目交互是偏好的指示。例子是:用户的购买/浏览历史、用户播放的歌曲列表等。这种反馈是<strong class="lq ir">极其丰富的</strong>，但同时也是<strong class="lq ir">不太详细的</strong>和<strong class="lq ir">更嘈杂的</strong>(例如，某人可能会购买一件产品作为礼物送给别人)。然而，与这种可用数据的庞大规模相比，这种噪音变得可以忽略不计，并且大多数现代推荐系统倾向于依赖隐式反馈。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/b1071fad8e751f3114f52b80ce1a755e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4UGbxNRZwyqnFCl3lxXcA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">显性反馈和隐性反馈数据集的用户项目评分矩阵。(图片由作者提供)</p></figure><p id="898c" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">收集到显性或隐性反馈后，我们可以创建<strong class="lq ir">用户项评分矩阵<em class="ne"> rᵤᵢ </em> </strong>。对于明确的反馈，在<em class="ne"> rᵤᵢ </em>中的每个条目都是一个数值——例如<em class="ne"> rᵤᵢ = </em>“由<em class="ne"> u </em>给电影<em class="ne"> i </em>”的星星——或“？”如果用户<em class="ne"> u </em>没有对项目<em class="ne"> i </em>进行评分。对于隐式反馈，<em class="ne"> rᵤᵢ </em>中的值是表示存在或不存在交互的布尔值——例如,<em class="ne"> rᵤᵢ = </em>“用户<em class="ne"> u </em>看电影了吗。请注意，矩阵<em class="ne"> rᵤᵢ </em>非常稀疏，因为用户与所有可用内容中的很少项目交互，他们查看的项目更少！</p><h1 id="2556" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">基于内容的方法与协作过滤方法</h1><p id="1f47" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">推荐系统可以根据用来预测用户偏好的信息类型分为<strong class="lq ir">基于内容的</strong>或<strong class="lq ir">协同过滤。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/d299de9c73b8447b8f5a919152adcd75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L3RyKloSo-mTAezwlarVcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">推荐系统中基于内容和协作过滤的方法。(作者图片)</p></figure><h2 id="2c00" class="ni kx iq bd ky nj nk dn lc nl nm dp lg lx nn no li mb np nq lk mf nr ns lm nt bi translated">基于内容的方法</h2><p id="19ad" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Recommender_system#Content-based_filtering" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">基于内容的方法</strong> </a>通过 <strong class="lq ir">已知的元数据</strong>来描述<strong class="lq ir">用户和项目<em class="ne"> </em>。每一项<em class="ne"> i </em>都由一组相关的标签表示——例如<a class="ae kv" href="https://www.imdb.com/search/keyword/" rel="noopener ugc nofollow" target="_blank"> IMDb 平台的电影</a>可以被标记为<em class="ne">“动作”、“喜剧”、“T45】等。每个用户<em class="ne"> u </em>都由一个用户配置文件表示，该文件可以根据已知的用户信息(例如，性别和年龄)或用户过去的活动创建。</em></strong></p><p id="edfc" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">用这种方法训练机器学习模型，我们可以使用<a class="ae kv" href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> k-NN 模型</strong> </a> <strong class="lq ir">。</strong>例如:如果我们知道用户<em class="ne"> u </em>购买了一件<em class="ne"> i </em>的商品，我们可以向<em class="ne"> u </em>推荐那些与<em class="ne"> i </em>最相似的商品。</p><p id="a55e" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这种方法的<strong class="lq ir">优势</strong>是项目元数据是预先已知的，因此我们也可以将其应用于<a class="ae kv" href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)" rel="noopener ugc nofollow" target="_blank">冷启动场景</a>，其中新项目或用户被添加到平台，我们没有用户-项目交互来训练我们的模型。<strong class="lq ir">的缺点</strong>是我们没有使用所有已知的用户-项目交互(每个用户被单独对待)，并且我们需要知道每个项目和用户的元数据信息。</p><h2 id="cb3f" class="ni kx iq bd ky nj nk dn lc nl nm dp lg lx nn no li mb np nq lk mf nr ns lm nt bi translated">协同过滤方法</h2><p id="e952" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Recommender_system#Collaborative_filtering" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">协同过滤方法</strong> </a> <strong class="lq ir"> </strong>不使用项目或用户元数据，而是尝试<strong class="lq ir">利用所有用户的反馈或活动历史</strong>，以便通过从观察到的活动推断用户和项目之间的相互依赖性来预测用户对给定项目的评级。</p><p id="da6f" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">为了用这种方法训练机器学习模型，我们通常会尝试对评级矩阵<em class="ne"> rᵤᵢ </em>进行聚类或因式分解，以便对未观察到的对(<em class="ne"> u，i </em>)，即<em class="ne"> rᵤᵢ </em> = <em class="ne"> </em>"？进行预测。在本文的下文中，我们将介绍<a class="ae kv" href="https://en.wikipedia.org/wiki/Matrix_factorization_(recommender_systems)" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">矩阵分解算法</strong> </a>，这是这一类中最常用的方法。</p><p id="698f" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这种方法的<strong class="lq ir">优势</strong>在于使用了整套用户-项目交互(即矩阵<em class="ne"> rᵤᵢ </em>),这通常允许获得比使用基于内容的模型更高的准确性。这种方法的缺点是在模型拟合之前需要一些用户交互。</p><h2 id="ed51" class="ni kx iq bd ky nj nk dn lc nl nm dp lg lx nn no li mb np nq lk mf nr ns lm nt bi translated">混合方法</h2><p id="b2c5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">最后，还有<a class="ae kv" href="https://en.wikipedia.org/wiki/Recommender_system#Hybrid_recommendations_approaches" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">混合方法</strong> </a>尝试使用已知的元数据和观察到的用户-项目交互集。这种方法<strong class="lq ir">结合了基于内容和协作过滤方法的优点</strong>，并允许获得最佳结果。在本文的后面，我们将介绍<a class="ae kv" href="https://github.com/lyst/lightfm" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> LightFM </strong> </a>，它是这类方法中最流行的算法。</p><h1 id="e3cd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">协同过滤:矩阵分解</h1><p id="54f3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><a class="ae kv" href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">矩阵分解算法</strong> </a>可能是推荐系统中最流行、最有效的协同过滤方法。矩阵因式分解是一种<a class="ae kv" href="https://en.wikipedia.org/wiki/Latent_variable_model" rel="noopener ugc nofollow" target="_blank">潜在因子模型</a>假设对于每个用户<em class="ne"> u </em>和项目<em class="ne"> i </em>有<strong class="lq ir">个潜在向量表示<em class="ne"> pᵤ、qᵢ</em>t13】∈<strong class="lq ir">r</strong>ᶠs . t .<em class="ne">rᵤᵢ</em>可以用<em class="ne"> pᵤ </em>和<em class="ne"> qᵢ </em>来唯一地表示——即“因式分解”。Python 库<a class="ae kv" href="https://github.com/NicolasHug/Surprise" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">惊奇</strong> </a> <strong class="lq ir"> </strong>提供了这些方法的优秀实现。</strong></p><h2 id="b73a" class="ni kx iq bd ky nj nk dn lc nl nm dp lg lx nn no li mb np nq lk mf nr ns lm nt bi translated">显式反馈的矩阵分解</h2><p id="0f14" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">最简单的想法是通过一个<strong class="lq ir">线性模型</strong>对用户-项目交互进行建模。为了了解<em class="ne"> pᵤ </em>和<em class="ne"> qᵢ </em>的值，我们可以在已知<em class="ne"> rᵤᵢ </em>的组<em class="ne"> K </em>对(<em class="ne"> u </em>，<em class="ne"> i </em>)上最小化一个正则化的<a class="ae kv" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank"> MSE 损失</a>。这样得到的算法称为<a class="ae kv" href="https://proceedings.neurips.cc/paper/2007/hash/d7322ed717dedf1eb4e6e52a37ea7bcd-Abstract.html" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">【PMF】</strong></a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/f2f2e81ac3973a0f589989f062f47201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hczNETNp0H6BfgEk86k9EQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">概率矩阵分解:rᵤᵢ模型<em class="nv">和损失函数。</em></p></figure><p id="b978" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">损失函数可以通过两种不同的方式最小化。第一种方法是使用<a class="ae kv" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir"/>【SGD】</a><strong class="lq ir">。SGD 容易实现，但是可能会有一些问题，因为 pᵤ和 qᵢ都是未知的，因此损失函数不是凸的。为了解决这个问题，我们可以选择固定值<em class="ne"> pᵤ </em>和<em class="ne"> qᵢ </em>，得到一个凸线性回归问题，这个问题很容易用<a class="ae kv" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank">普通最小二乘法(OLS) </a>来解决。这第二种方法被称为<a class="ae kv" href="https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">【ALS】</strong></a>，允许显著的并行化和加速。</strong></p><p id="2b46" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">PMF 算法后来被推广为<a class="ae kv" href="https://sifter.org/simon/journal/20061211.html" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">【SVD】</strong></a>算法，在模型中引入了<strong class="lq ir">偏差项</strong>。更具体地说，<strong class="lq ir"><em class="ne"/></strong>和<strong class="lq ir"><em class="ne"/></strong>分别测量用户<em class="ne"> u </em>和项目<em class="ne"> i </em>的观察评分偏差，而<strong class="lq ir"> <em class="ne"> μ </em> </strong> <em class="ne"> </em>是总体平均评分。这些术语通常解释了大多数观察到的评级<em class="ne"> rᵤᵢ </em>，因为一些项目普遍获得更好/更差的评级，而一些用户对他们的评级一贯或多或少慷慨。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/4c58dfa9473a26588c1f7a1863737db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dopKPhNNW7PD63ci3My9_w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SVD 算法，概率矩阵分解的推广。</p></figure><h2 id="74cd" class="ni kx iq bd ky nj nk dn lc nl nm dp lg lx nn no li mb np nq lk mf nr ns lm nt bi translated">隐式反馈的矩阵分解</h2><p id="a38c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">将<strong class="lq ir"> SVD </strong> <strong class="lq ir">方法</strong> <strong class="lq ir">能</strong> <strong class="lq ir">被</strong> <a class="ae kv" href="https://ieeexplore.ieee.org/document/4781121" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir">适应于隐式反馈数据集</strong> </a>。这个想法是将隐性反馈视为信心的间接测量。假设隐式反馈<strong class="lq ir"> <em class="ne"> tᵤᵢ </em> </strong>测量用户<em class="ne"> u </em>看过电影<em class="ne"> i </em>的百分比——例如<em class="ne"> tᵤᵢ </em> = 0 表示<em class="ne"> u </em>从未看过<em class="ne"> i </em>，<em class="ne"> tᵤᵢ </em> = 0.1 表示他只看了其中的 10%，<em class="ne"> tᵤᵢ </em> = 2 表示直觉上，用户更可能对他们看过两次的电影感兴趣，而不是对他们从未看过的电影感兴趣。我们因此定义一个<strong class="lq ir">信心矩阵<em class="ne">cᵤᵢ</em>t35】和一个<strong class="lq ir">评级矩阵<em class="ne"> rᵤᵢ </em> </strong> <em class="ne"> </em>如下。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/6b51b43091f6ea486b03d702dcdb389e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YmkV1wS345TrVZnkzGvfbg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">隐式反馈的置信矩阵和评级矩阵。</p></figure><p id="62ed" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">然后，我们可以使用用于奇异值分解的相同线性模型对观察到的<em class="ne"> rᵤᵢ </em>进行建模，但损失函数略有不同。首先，我们计算所有(<em class="ne"> u </em>，<em class="ne"> i </em>)对的损失——与显式情况不同，如果用户<em class="ne"> u </em>从未与<em class="ne"> i </em>交互，我们就有了<em class="ne"> rᵤᵢ = </em> 0，而不是<em class="ne"> rᵤᵢ = </em>”。第二，我们通过<em class="ne"> cᵤᵢ </em>认为<em class="ne"> u </em>喜欢<em class="ne"> i. </em>来衡量每一项损失</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/4a83805145745506515d92892dd67ff5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jHIXoZJl5cHdO5VbJNOoDg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">隐式反馈奇异值分解的损失函数。</p></figure><p id="163a" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">最后，当我们可以访问显式和隐式反馈时，可以使用<a class="ae kv" href="https://dl.acm.org/doi/abs/10.1145/1401890.1401944" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir">svd++</strong></a><strong class="lq ir"/>算法。这可能非常有用，因为通常用户会与许多项目进行交互(=隐式反馈)，但只对其中的一小部分进行评级(=显式反馈)。让我们为每个用户<em class="ne"> u </em>表示<em class="ne"> N(u) </em>已经与<em class="ne"> u </em>交互的项目集合。然后，我们假设与项目<em class="ne"> j </em>的隐式交互与新的潜在向量<em class="ne">zⱼ</em>∈<strong class="lq ir">r</strong><em class="ne">ᶠ</em>相关联。SVD++算法通过将这些潜在因素的加权和包含到用户表示中来修改 SVD 的线性模型<em class="ne"> zⱼ.</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/f9b9e1d7e1086982f566be4f568cd978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PQfLB2JriOkJffpAqozjJw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SVD++用于混合(显式+隐式)反馈</p></figure><h1 id="7f2c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">混合方法:LightFM</h1><p id="cbbd" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">基于矩阵分解的协同过滤方法通常会产生出色的结果，但在<a class="ae kv" href="https://en.wikipedia.org/wiki/Cold_start_(recommender_systems)" rel="noopener ugc nofollow" target="_blank"><strong class="lq ir"/></a>冷启动场景中——其中很少或没有交互数据可用于新项目和用户——它们无法做出良好的预测，因为它们缺乏估计潜在因素的数据。<strong class="lq ir">混合方法</strong>通过利用已知项目或用户元数据来改进矩阵分解模型，从而解决了这个问题。Python 库<a class="ae kv" href="https://github.com/lyst/lightfm" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> LightFM </strong> </a>实现了最流行的混合算法之一。</p><p id="2db3" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">在 LightFM 中，我们假设为每个用户<em class="ne"> u </em>收集了一组标签注释<em class="ne">aᵁ(u】</em>—例如<em class="ne">“男性”</em>，<em class="ne">“年龄&lt;30”</em>，… —类似地，每个商品<em class="ne"> i </em>都有一组注释<em class="ne"> Aᴵ(i) </em> —例如<em class="ne">“价格&gt; 100 美元】【t22 …然后我们通过一个<strong class="lq ir">潜在因子<em class="ne"> xᵁₐ </em> ∈ </strong> <strong class="lq ir"> R </strong> ᶠ和一个<strong class="lq ir">偏差项<em class="ne">bᵁₐ</em>∈</strong>t36】r 对每个用户标签进行建模，并且我们假设用户向量表示<em class="ne"> pᵤ </em>及其相关偏差<em class="ne"> bᵤ </em>可以简单地表示为这些项<em class="ne"> xᵁₐ </em>和</em>之和 我们对物品标签采取同样的方法，使用潜在因素<em class="ne"> xᴵₐ </em> ∈ Rᶠ和偏差项<em class="ne"> bᴵₐ </em> ∈ R。一旦我们使用这些公式定义了<em class="ne"> pᵤ、qᵢ、bᵤ、bᵢ </em>，我们就可以使用相同的 SVD 线性模型来描述这些项和<em class="ne"> rᵤᵢ </em>之间的关系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/279c418c30505c269ed44eaa4dacd0f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dCTDYkocQfV1hQ-bhUo9Pg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">LightFM:用户/项目嵌入和偏差是与每个用户/项目相关的潜在向量的总和。</p></figure><p id="f55d" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">注意，LightFM 的这种混合方法有三个有趣的例子。</p><ol class=""><li id="1f6f" class="mq mr iq lq b lr ml lu mm lx ms mb mt mf mu mj mv mw mx my bi translated"><strong class="lq ir">冷启动。</strong>如果我们有一个带有已知标签<em class="ne">aᴵ(i</em>的新项目<em class="ne"> i </em>，那么我们可以使用潜在向量<em class="ne"> xᴵₐ </em>(通过对之前的数据拟合我们的模型获得)来计算它的嵌入<em class="ne"> qᵢ </em>，并因此为任何用户<em class="ne"> u </em>估计它的评级<em class="ne"> rᵤᵢ </em>。</li><li id="350a" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj mv mw mx my bi translated"><strong class="lq ir">没有可用的标签。</strong>如果我们没有任何已知的条目或用户的元数据，我们唯一可以使用的注释是一个指示器函数，即每个用户和每个条目有一个不同的注释<em class="ne"> a </em>。然后，用户和物品特征矩阵是单位矩阵，LightFM 简化为 SVD 等经典的协同过滤方法。</li><li id="8756" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj mv mw mx my bi translated"><strong class="lq ir">基于内容与混合。</strong>如果我们只使用没有指示器注释的用户或项目标签，LightFM 将几乎是一个基于内容的模型。因此，在实践中，为了利用用户-项目交互，我们还向已知标签添加了一个指示器注释<em class="ne">一个不同于每个用户和项目的</em>。</li></ol><h1 id="98ee" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">TL；DR–结论</h1><ul class=""><li id="7652" class="mq mr iq lq b lr ls lu lv lx nz mb oa mf ob mj oc mw mx my bi translated"><strong class="lq ir">推荐系统</strong>利用机器学习算法来帮助用户在发现相关内容时淹没在选择中。</li><li id="68c6" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><strong class="lq ir">显性与隐性反馈</strong>:前者更容易利用，但后者更丰富。</li><li id="1308" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><strong class="lq ir">基于内容的</strong>模型在冷启动场景中工作良好，但是需要知道用户和项目<strong class="lq ir">元数据</strong>。</li><li id="8a60" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><strong class="lq ir">协同过滤</strong>模型一般采用矩阵分解:<strong class="lq ir"> PMF，SVD，SVD 为隐式反馈，SVD++。</strong></li><li id="2dba" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><strong class="lq ir">混合模型</strong>充分利用了基于内容和协作过滤的优势。LightFM 是这种方法的一个很好的例子。</li></ul><h1 id="b950" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><ul class=""><li id="b7ae" class="mq mr iq lq b lr ls lu lv lx nz mb oa mf ob mj oc mw mx my bi translated"><a class="ae kv" href="https://en.wikipedia.org/wiki/Recommender_system" rel="noopener ugc nofollow" target="_blank">维基百科，<em class="ne">推荐系统</em> </a> <em class="ne">。</em></li><li id="944f" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><a class="ae kv" href="https://surprise.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank">《惊喜》、<em class="ne"> Python 包文档</em>。</a></li><li id="6b43" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated">网飞更新:在家里试试这个。 </li><li id="eb83" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><a class="ae kv" href="https://proceedings.neurips.cc/paper/2007/hash/d7322ed717dedf1eb4e6e52a37ea7bcd-Abstract.html" rel="noopener ugc nofollow" target="_blank"> (R. Salakhutdinov 2007)，<em class="ne">概率矩阵分解。</em> </a></li><li id="6f32" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated">(<a class="ae kv" href="https://ieeexplore.ieee.org/document/4781121" rel="noopener ugc nofollow" target="_blank">y . Hu 2008)<em class="ne">针对隐式反馈数据集的协同过滤</em> </a> <em class="ne">。</em></li><li id="0d9e" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><a class="ae kv" href="https://ieeexplore.ieee.org/document/5197422" rel="noopener ugc nofollow" target="_blank">(y . Koren 2009)<em class="ne">推荐系统的矩阵分解技术</em> </a> <em class="ne">。</em></li><li id="a999" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated"><a class="ae kv" href="https://dl.acm.org/doi/abs/10.1145/1401890.1401944" rel="noopener ugc nofollow" target="_blank"> (Y. Koren 2008) <em class="ne">因式分解遇上邻域:多面协同过滤模型。</em>T53】</a></li><li id="31c6" class="mq mr iq lq b lr mz lu na lx nb mb nc mf nd mj oc mw mx my bi translated">(<a class="ae kv" href="https://arxiv.org/pdf/1507.08439.pdf" rel="noopener ugc nofollow" target="_blank"> M .库拉 2015)，<em class="ne">用户和项目冷启动建议的元数据嵌入</em> </a> <em class="ne">。</em></li></ul></div></div>    
</body>
</html>