<html>
<head>
<title>Understanding Multiple Hyperplanes Of scikit-learn’s OVO SVC Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解scikit-learn的OVO SVC模型的多个超平面</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-multiple-hyperplanes-of-scikit-learns-ovo-svc-model-3c0d09c8b8e5#2022-06-20">https://towardsdatascience.com/understanding-multiple-hyperplanes-of-scikit-learns-ovo-svc-model-3c0d09c8b8e5#2022-06-20</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="68aa" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">如何解释scikit-learn中线性SVC的coef_ attribute以解决多类分类问题</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/31d0277cdd992648854e9ea889095758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CrpNN_0c89EdM-Gh"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com/@dannyboy4125?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Fr拍摄。丹尼尔·丘奇</a>开启<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="94be" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我最近的文章中，我向你展示了如何为一个<strong class="lc iv">二元分类问题</strong>解释一个拟合的SVC模型的<code class="fe lw lx ly lz b">coef_</code>和<code class="fe lw lx ly lz b">intercept_</code>属性，以及如何绘制决策平面。如果你还没有读过，我建议你在读这篇文章之前先看看。以下是它的链接:</p><div class="ma mb gq gs mc md"><a rel="noopener follow" target="_blank" href="/understanding-the-hyperplane-of-scikit-learns-svc-model-f8515a109222"><div class="me ab fp"><div class="mf ab mg cl cj mh"><h2 class="bd iv gz z fq mi fs ft mj fv fx it bi translated">理解scikit-learn的SVC模型的超平面</h2><div class="mk l"><h3 class="bd b gz z fq mi fs ft mj fv fx dk translated">如何解释scikit-learn中线性SVC的coef_ attribute以解决二元分类问题</h3></div><div class="ml l"><p class="bd b dl z fq mi fs ft mj fv fx dk translated">towardsdatascience.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr kt md"/></div></div></a></div><p id="8586" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">注意:</strong> <em class="ms">因为上一篇文章围绕着一个二元分类问题，所以它基本上是我们使用的一个SVM。在这篇文章中，我们实际上使用了一个SVC，我们将利用SVC的力量。SVM和支持向量机之间的主要区别在于，支持向量机本质上只是多个支持向量机的组合，因此允许我们使用多个超平面来分类多个类别。</em></p><p id="dea0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这篇文章的主题有点复杂，但是我会尽我所能让它容易理解。</p><p id="1bff" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">准备好了吗？我们走吧！</p></div><div class="ab cl mt mu hy mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="in io ip iq ir"><h2 id="38d2" class="na nb iu bd nc nd ne dn nf ng nh dp ni lj nj nk nl ln nm nn no lr np nq nr ns bi translated">创建一些虚拟数据</h2><p id="9cf0" class="pw-post-body-paragraph la lb iu lc b ld nt jv lf lg nu jy li lj nv ll lm ln nw lp lq lr nx lt lu lv in bi translated">首先，让我们创建一些数据来处理和可视化。下面的代码片段应该可以完成这个任务:</p><pre class="kk kl km kn gu ny lz nz oa aw ob bi"><span id="d0bb" class="na nb iu lz b gz oc od l oe of">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="a6b5" class="na nb iu lz b gz og od l oe of">X = np.array([</span><span id="ca18" class="na nb iu lz b gz og od l oe of">[1.5, 1  ], [1.5, 2  ], [ 2,  1  ], [ 2,  2  ], #upper right (Green)</span><span id="f466" class="na nb iu lz b gz og od l oe of">[1,  -1  ], [1,  -2  ], [ 2, -1  ], [ 2, -2  ], #lower right (Blue)</span><span id="51d0" class="na nb iu lz b gz og od l oe of">[-1, -1.5], [-1, -2.5], [-2, -1.5], [-2, -2.5], #lower left (Red)</span><span id="eac9" class="na nb iu lz b gz og od l oe of">[-1,  1  ], [-1,  2  ], [-2,  1  ], [-2,  2  ], #upper left (Yellow)</span><span id="d121" class="na nb iu lz b gz og od l oe of">])</span><span id="e0a2" class="na nb iu lz b gz og od l oe of">y = np.array([</span><span id="9f7c" class="na nb iu lz b gz og od l oe of">'green','green','green','green',</span><span id="8b99" class="na nb iu lz b gz og od l oe of">'blue','blue','blue','blue',</span><span id="75d3" class="na nb iu lz b gz og od l oe of">'red','red','red','red',</span><span id="a338" class="na nb iu lz b gz og od l oe of">'yellow','yellow','yellow','yellow',</span><span id="6247" class="na nb iu lz b gz og od l oe of">])</span><span id="9e57" class="na nb iu lz b gz og od l oe of">plt.scatter(X[:, 0], X[:, 1], c=y)<br/>plt.show()</span></pre><p id="a867" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这将产生以下情节:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oh"><img src="../Images/4478061a3497951af972624f16af9a95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*PxCfqR7CPdUnbHrL4Hp27w.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">散点图中的四个数据类-由作者创建</p></figure><p id="4f8d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">正如你所看到的，这个数据显然是线性可分的，所以线性SVC应该可以很好地处理它，因为有两个以上的类，我们需要一个以上的超平面，(这种直觉应该很容易理解。想象一下，必须画一条<strong class="lc iv"/><strong class="lc iv">单条</strong> <strong class="lc iv">直线</strong> <strong class="lc iv">来分隔四个不同的类。你根本不能</strong>。</p></div><div class="ab cl mt mu hy mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="in io ip iq ir"><h2 id="6bbe" class="na nb iu bd nc nd ne dn nf ng nh dp ni lj nj nk nl ln nm nn no lr np nq nr ns bi translated">在数据上拟合SVC</h2><p id="7c97" class="pw-post-body-paragraph la lb iu lc b ld nt jv lf lg nu jy li lj nv ll lm ln nw lp lq lr nx lt lu lv in bi translated">下一步是使用scikit-learn的库在我们的数据上安装一个SVC。这可以简单地这样做:</p><pre class="kk kl km kn gu ny lz nz oa aw ob bi"><span id="58d2" class="na nb iu lz b gz oc od l oe of">from sklearn.svm import SVC</span><span id="6baa" class="na nb iu lz b gz og od l oe of">clf = SVC(kernel='linear')<br/>clf.fit(X, y)</span></pre><p id="c5e2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">就SVCs而言，存在两种创建超平面的方法。一个叫<strong class="lc iv">一对一(OVO) </strong>一个叫<strong class="lc iv">一对一(OVR) </strong>。我现在不会深入讨论这个问题，因为这是另一篇文章的主题。现在，你只需要知道我们将创建一个<strong class="lc iv"> OVO </strong> SVC。简而言之，这意味着我们将每一个类与每一个其他类进行比较，并且这些比较中的每一个都有一个相应的超平面。</p><p id="44e7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们可以看看拟合的SVC的<code class="fe lw lx ly lz b">coef_</code>和<code class="fe lw lx ly lz b">intercept_</code>属性，就像我们在上一篇文章中所做的那样。</p><pre class="kk kl km kn gu ny lz nz oa aw ob bi"><span id="2111" class="na nb iu lz b gz oc od l oe of">print('coef_\n', clf.coef_)<br/>print('intercept_', clf.intercept_)</span><span id="0ccb" class="na nb iu lz b gz og od l oe of">&gt;&gt; coef_<br/>   [[ 0.00000000e+00 -1.00000000e+00]<br/>    [ 9.99532404e-01  2.22044605e-16]<br/>    [ 5.00000000e-01 -5.00000000e-01]<br/>    [ 4.00000000e-01  4.00000000e-01]<br/>    [ 8.00000000e-01  0.00000000e+00]<br/>    [ 0.00000000e+00 -8.00000000e-01]]</span><span id="ec97" class="na nb iu lz b gz og od l oe of">&gt;&gt; intercept_<br/>   [ 1.45716772e-16<br/>     4.30211422e-16<br/>     0.00000000e+00<br/>     0.00000000e+00<br/>    -2.00000000e-01<br/>    -2.00000000e-01]</span></pre><p id="66e4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">好的，显然我们为<code class="fe lw lx ly lz b">coef_</code>属性得到了6个向量，也为<code class="fe lw lx ly lz b">intercept_</code>属性得到了6个值。这些是我们将要用来绘制超平面的值，也是用来分类新数据点的值。</p><p id="0a4d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">你可能会问为什么是数字6？要回答这个问题，让我们看看SVC的<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn文档:</a></p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oi"><img src="../Images/38e45d341c00b81f10ddbb00cba23061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*XDmAl3ScH84_OE10McWLwA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">scikit-learn文档的屏幕截图(于2022年12月6日访问)-由作者创建</p></figure><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oj"><img src="../Images/08c647ddcdcb72efbed1685404841694.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*8wBAblyg5tTjTNl5W1SSeA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">scikit-learn文档的屏幕截图(于2022年12月6日访问)-由作者创建</p></figure><p id="8ce6" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们现在可以看到，值6来自以下等式:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ok"><img src="../Images/38eb1280caa752446c6761e0b6a0a94e.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*MORQ8E1e2reqP0gRKmQP2w.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">coef_中的向量数方程—作者创建</p></figure><p id="252d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们的例子中，我们有4个类，因此等式如下:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ol"><img src="../Images/77d3c6f244dea0026c1ec239387e7635.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*NnhK_Zyk-M9fxQzqKyiwXA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">具有实际值的等式—由作者创建</p></figure><p id="24c9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">希望这一点现在已经很清楚了。然而，这给我们留下了后续问题:哪个<code class="fe lw lx ly lz b">coef_</code>向量和<code class="fe lw lx ly lz b">intercept_</code>值对应于哪个标签？正如我在上面简要提到的，OVO方法将每一类进行比较。这意味着我们比较</p><p id="22ea" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">标签1对标签2 <br/>标签1对标签3 <br/>标签1对标签4 <br/>标签2对标签3</p><p id="22b0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">依此类推……直到所有的标签都相互比较完毕，<em class="ms">(我将在后面的文章中进一步详细介绍新数据点是如何分类的)</em></p><p id="d1e2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们的每个<code class="fe lw lx ly lz b">coef_</code>向量都代表了这样一种比较。但是，我们怎么知道哪个向量对应于哪个比较呢？</p><p id="fa59" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">为了弄清楚这一点，我们可以使用下面的代码来获得数据和超平面的可视化表示:</p><pre class="kk kl km kn gu ny lz nz oa aw ob bi"><span id="bc3b" class="na nb iu lz b gz oc od l oe of">line_colors = {0:'red', 1:'blue', 2:'green', 3:'yellow', 4:'black', 5:'gray'}</span><span id="d91b" class="na nb iu lz b gz og od l oe of">number_of_coefficients = len(clf.coef_)<br/>figure, axis = plt.subplots(3, 2)<br/>row = 0<br/>col = 0</span><span id="d833" class="na nb iu lz b gz og od l oe of">for j in range(number_of_coefficients):<br/>  for i in range(j+1):<br/>     w = clf.coef_[i]<br/>     w = [w[0], w[1] + 0.0001] #adding 0.0001 just to make sure we       <br/>                               #don't devide by 0<br/>     a = -w[0] / w[1]</span><span id="3484" class="na nb iu lz b gz og od l oe of">     xx = np.linspace(-4,4)<br/>     yy = a * xx - clf.intercept_[i] / w[1]<br/>     axis[row, col].plot(xx, yy, label=f'h{i}', c=line_colors[i])<br/>  <br/>  axis[row, col].set_xlim([-4, 4])<br/>  axis[row, col].set_ylim([-4, 4])<br/>  axis[row, col].scatter(X[:, 0], X[:, 1], c = y)</span><span id="432f" class="na nb iu lz b gz og od l oe of">  row = row + 1 if col == 1 else row<br/>  col = col + 1 if col != 1 else 0</span><span id="1df6" class="na nb iu lz b gz og od l oe of">plt.show()</span></pre><p id="1944" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><em class="ms">(为了避免文章篇幅过长，我没有对代码片段进行解释，只需注意它用于使用</em> <code class="fe lw lx ly lz b"><em class="ms">coef_</em></code> <em class="ms">和</em> <code class="fe lw lx ly lz b"><em class="ms">intercept_</em></code> <em class="ms">值创建情节)</em></p><p id="e52e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这会产生以下情节:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj om"><img src="../Images/c8e0ce78eda7b4856680537350b042fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omOxj-LGVRzVGOhC1au1cQ.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">绘制一个接一个的超平面—由作者创建</p></figure><p id="7838" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这里发生了相当多的事情，所以让我们仔细地浏览一下。</p><p id="ea40" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">每个子情节增加一个额外的超平面。这样，我们可以通过检查刚刚添加的超平面的位置来了解哪个超平面对应于哪个比较。以下是超平面的描述:</p><ol class=""><li id="f0c8" class="on oo iu lc b ld le lg lh lj op ln oq lr or lv os ot ou ov bi translated"><strong class="lc iv">红线</strong>比较<strong class="lc iv">蓝等级</strong>和<strong class="lc iv">绿等级。</strong></li><li id="1719" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">蓝线</strong>比较<strong class="lc iv">蓝等级</strong>和<strong class="lc iv">红等级。</strong></li><li id="aa37" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">绿线</strong>比较<strong class="lc iv">蓝色等级</strong>和<strong class="lc iv">黄色等级。</strong></li><li id="065f" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">黄线</strong>比较<strong class="lc iv">绿色等级</strong>和<strong class="lc iv">红色等级。</strong></li><li id="5f56" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">黑线</strong>比较<strong class="lc iv">绿色等级</strong>和<strong class="lc iv">黄色等级。</strong></li><li id="f30d" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">灰色线</strong>比较<strong class="lc iv">红色等级</strong>和<strong class="lc iv">黄色等级。</strong></li></ol><p id="92b1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当对新的数据点进行分类时，将针对这些超平面中的每一个来测量该点。每次比较后，我们记下它属于哪个标签，并将其添加到该标签的累积分数中。最后，新的数据点被简单地标记为具有最高分数的类。</p><p id="cd19" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">每个超平面以如下方式对新数据点进行分类:如果该点位于超平面的右侧，则该超平面将该点分类为其比较中的第一个标签。相反，如果点在平面的左边，那么它被标记为超平面比较的第二类。</p><blockquote class="pb pc pd"><p id="e141" class="la lb ms lc b ld le jv lf lg lh jy li pe lk ll lm pf lo lp lq pg ls lt lu lv in bi translated"><strong class="lc iv">快速举例:</strong>以<strong class="lc iv">红线</strong>为例，它的第一个标签是<strong class="lc iv">蓝色等级</strong>，第二个标签是<strong class="lc iv">绿色等级</strong>。如果一个给定的数据指向线的右边，那么这个超平面将其分类为<strong class="lc iv">蓝色</strong>。</p></blockquote><p id="21cf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">注意:</strong>T5】为了有一个“右”或“左”的超平面，它们需要有一个方向。本例中的 <strong class="lc iv"> <em class="ms">红色</em> </strong> <em class="ms">和</em> <strong class="lc iv"> <em class="ms">灰色线条</em> </strong> <em class="ms">指向右边，蓝色</em>  <em class="ms">和</em> <strong class="lc iv"> <em class="ms">黑色</em> </strong> <em class="ms"> </em> <strong class="lc iv"> <em class="ms">线条</em></strong><em class="ms"/><strong class="lc iv"/></p></div><div class="ab cl mt mu hy mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="in io ip iq ir"><h2 id="e257" class="na nb iu bd nc nd ne dn nf ng nh dp ni lj nj nk nl ln nm nn no lr np nq nr ns bi translated">具有新观点的示例</h2><p id="a374" class="pw-post-body-paragraph la lb iu lc b ld nt jv lf lg nu jy li lj nv ll lm ln nw lp lq lr nx lt lu lv in bi translated">让我们看一个例子。我们可以绘制一个新的点<code class="fe lw lx ly lz b">[1.5, -2.5]</code>(图中的棕色点)，我们预计该点将被归类为<strong class="lc iv">蓝色</strong>点。下面是一个让它更加明显的图:</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj oh"><img src="../Images/ce839407c2ba4ff8a66b634af6c4d2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*xPAocVLd-3-sKB0IkwTYRA.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">超平面和一个新的预测点—由作者创建</p></figure><p id="e57b" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">逐一进行比较(超平面):</p><ol class=""><li id="3479" class="on oo iu lc b ld le lg lh lj op ln oq lr or lv os ot ou ov bi translated">红线<strong class="lc iv">将其归类为蓝色</strong></li><li id="310f" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">蓝线</strong>将其归类为蓝色</li><li id="84fb" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">绿线</strong>将其归类为蓝色</li><li id="181a" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated">黄线<strong class="lc iv">将其归类为红色</strong></li><li id="ef87" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated"><strong class="lc iv">黑线</strong>将其归类为绿色</li><li id="8710" class="on oo iu lc b ld ow lg ox lj oy ln oz lr pa lv os ot ou ov bi translated">灰色线<strong class="lc iv">将其归类为红色</strong></li></ol><p id="d542" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">新点分为<strong class="lc iv">蓝色</strong> 3次，<strong class="lc iv">红色</strong> 2次，<strong class="lc iv">绿色</strong> 1次。因此，我们用<strong class="lc iv">蓝色</strong>标签对点进行分类。</p><p id="df93" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果我们使用拟合的模型进行预测，我们会得到同样的结果。可以通过以下方式完成:</p><pre class="kk kl km kn gu ny lz nz oa aw ob bi"><span id="6498" class="na nb iu lz b gz oc od l oe of">new_point = np.array([[1.5, -2.5]])<br/>print(clf.predict(new_point))</span><span id="5934" class="na nb iu lz b gz og od l oe of">&gt;&gt; <strong class="lz iv">['blue']</strong></span></pre><p id="01fb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们得到了预期的蓝色标签。</p></div><div class="ab cl mt mu hy mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="in io ip iq ir"><h2 id="9507" class="na nb iu bd nc nd ne dn nf ng nh dp ni lj nj nk nl ln nm nn no lr np nq nr ns bi translated">如何确定比较的顺序</h2><p id="151c" class="pw-post-body-paragraph la lb iu lc b ld nt jv lf lg nu jy li lj nv ll lm ln nw lp lq lr nx lt lu lv in bi translated">我希望上面的例子对你来说很容易理解，并且你明白我们是如何得出关于哪些超平面对应于哪些比较的结论的。然而，这是一个简单的实验，数据很容易分离。这允许我们通过视觉检查来确定超平面和<code class="fe lw lx ly lz b">coef_</code>属性之间的关系。然而，真实世界的数据很可能不那么容易处理。所以，你可能想知道是否有一个系统，来决定比较的顺序？</p><p id="72f3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">换句话说，我们能确定由<code class="fe lw lx ly lz b">coef_[0]</code>代表的超平面总是将<strong class="lc iv">蓝色</strong>类和<strong class="lc iv">绿色</strong>类分开的那个超平面吗？</p><p id="40ee" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我得出的结论是，排序是由标签排序决定的。在标签是单词的情况下，我注意到前三个超平面，<code class="fe lw lx ly lz b">coef_[0]</code>、<code class="fe lw lx ly lz b">coef_[1]</code>、<code class="fe lw lx ly lz b">coef_[2]</code>都与蓝色标签有关。这支持了我的理论，因为蓝色的<strong class="lc iv">将按字母顺序排列为第一个标签。以下两个标签<code class="fe lw lx ly lz b">coef_[3]</code>和<code class="fe lw lx ly lz b">coef_[4]</code>与<strong class="lc iv">绿色</strong>标签有关，因为<strong class="lc iv">‘g’</strong>排在<strong class="lc iv">‘b’</strong>之后，<strong class="lc iv">‘r’</strong>之前，<strong class="lc iv">‘y’</strong>之前。</strong></p><p id="860f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这可能有点难以理解，但是想一想，它可能会对你有意义。</p><p id="ae35" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">有了这个关于模型的超平面如何工作的信息，你将对幕后发生的事情有一个更好的理解。您还可以使用帖子中的代码片段来绘制超平面。</p></div><div class="ab cl mt mu hy mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="in io ip iq ir"><p id="a9a4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><strong class="lc iv">感谢</strong>花时间阅读这篇文章！我希望它对你有用。如果你有任何问题，意见或注意到代码或文本中的错误，我鼓励你联系我。</p><p id="b230" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果你是一个渴望更多的好奇的开发者，那么下面这些帖子可能也会让你感兴趣:</p><div class="ma mb gq gs mc md"><a href="https://betterprogramming.pub/what-is-up-with-the-numbers-in-python-26d8d36e129b" rel="noopener  ugc nofollow" target="_blank"><div class="me ab fp"><div class="mf ab mg cl cj mh"><h2 class="bd iv gz z fq mi fs ft mj fv fx it bi translated">Python中的数字是怎么回事</h2><div class="mk l"><h3 class="bd b gz z fq mi fs ft mj fv fx dk translated">让我们来揭开为什么Python中整数的大小至少是24字节</h3></div><div class="ml l"><p class="bd b dl z fq mi fs ft mj fv fx dk translated">better编程. pub</p></div></div><div class="mm l"><div class="ph l mo mp mq mm mr kt md"/></div></div></a></div><div class="ma mb gq gs mc md"><a rel="noopener follow" target="_blank" href="/how-to-use-an-autoregressive-ar-model-for-time-series-analysis-bb12b7831024"><div class="me ab fp"><div class="mf ab mg cl cj mh"><h2 class="bd iv gz z fq mi fs ft mj fv fx it bi translated">如何使用自回归(AR)模型进行时间序列分析</h2><div class="mk l"><h3 class="bd b gz z fq mi fs ft mj fv fx dk translated">python中使用自回归模型进行预测的初学者指南</h3></div><div class="ml l"><p class="bd b dl z fq mi fs ft mj fv fx dk translated">towardsdatascience.com</p></div></div><div class="mm l"><div class="pi l mo mp mq mm mr kt md"/></div></div></a></div></div></div>    
</body>
</html>