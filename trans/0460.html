<html>
<head>
<title>Graph Neural Networks in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的图形神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-neural-networks-in-python-c310c7c18c83#2022-02-18">https://towardsdatascience.com/graph-neural-networks-in-python-c310c7c18c83#2022-02-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9243" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">简介和逐步实施</h2></div><p id="f89b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated">最近，图机器学习领域发展迅速，该领域的大多数模型都是用Python实现的。本文将介绍图形的概念以及使用Python处理图形的一些基本方法。之后，我们将创建一个图卷积网络，并让它在PyTorch的帮助下在现实世界的关系网络上执行节点分类。这里描述的整个工作流程可以从<a class="ae ln" href="https://colab.research.google.com/drive/17eRoYIBxlgxAMKHV4qmXmBYL2-Wkl3Xx?usp=sharing" rel="noopener ugc nofollow" target="_blank">的Colab笔记本</a>中获得。</p><h1 id="0f27" class="lo lp it bd lq lr ls lt lu lv lw lx ly jz lz ka ma kc mb kd mc kf md kg me mf bi translated">什么是图？</h1><p id="7ea3" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">一个图，在其最一般的形式下，仅仅是节点以及节点之间的一组边的集合。形式上，一个图<em class="ml"> G </em>可以写成<em class="ml"> G = (V，E) </em>，其中<em class="ml"> V </em>表示节点，<em class="ml"> E </em>表示相应的边集。有两种主要类型的图，有向图和无向图。有向图的边从它们的原点<em class="ml"> u </em>节点指向目标节点<em class="ml"> v </em>，而无向图中的边是没有方向的，因此(<em class="ml"> u，v</em>)<em class="ml"/>∑<em class="ml">e</em>⇔<em class="ml"/>(<em class="ml">v，u</em>)<em class="ml"/>∑<em class="ml">e .</em>图可以用一个可以通过让每个节点索引特定的行和列来创建该矩阵。然后，边的存在可以被表示为邻接矩阵中的条目，意味着如果(<em class="ml"> u，v</em>)∈<em class="ml">E</em>和<strong class="kk iu"> A </strong> [ <em class="ml"> u </em>，<em class="ml"> v </em> ] = 0，则<strong class="kk iu"> A </strong> [ <em class="ml"> u </em>，<em class="ml"> v </em> ] = 1，否则。如果图仅由无向边组成，邻接矩阵将是对称的，但是如果图是有向的，就不一定是对称的。</p><p id="6d60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了在Python中操作图形，我们将使用非常流行的networkx库[1]。我们首先创建一个空的有向图<em class="ml"> H </em>:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="f8df" class="mv lp it mr b gy mw mx l my mz">import networkx as nx</span><span id="1e2f" class="mv lp it mr b gy na mx l my mz">H = nx.DiGraph()</span></pre><p id="e69d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，我们将向图中添加4个节点。每个节点有两个特征，颜色和大小。机器学习问题中的图通常具有带有特征的节点，例如社交网络中某个人的姓名或年龄，然后模型可以使用这些特征来推断复杂的关系并进行预测。Networkx附带了一个内置的实用函数，用于以列表形式填充带有节点的图形，此外还有以下特性:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="3ee3" class="mv lp it mr b gy mw mx l my mz">H.add_nodes_from([<br/>  (0, {"color": "gray", "size": 450}),<br/>  (1, {"color": "yellow", "size": 700}),<br/>  (2, {"color": "red", "size": 250}),<br/>  (3, {"color": "pink", "size": 500})<br/>])</span><span id="0d82" class="mv lp it mr b gy na mx l my mz">for node in H.nodes(data=True):<br/>  print(node)</span><span id="61a7" class="mv lp it mr b gy na mx l my mz">&gt; (0, {'color': 'gray', 'size': 450})<br/>&gt; (1, {'color': 'yellow', 'size': 700})<br/>&gt; (2, {'color': 'red', 'size': 250})<br/>&gt; (3, {'color': 'pink', 'size': 500})</span></pre><p id="ef9a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图中的边被定义为包含源节点和目标节点的元组，因此例如边<code class="fe nb nc nd mr b">(2, 3)</code>将节点2连接到节点3。因为我们有一个有向图，所以也可以有一条指向相反方向的边<code class="fe nb nc nd mr b">(3, 2)</code>。多条边可以作为列表的一部分添加到图表中，方式与节点相似:</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="7b12" class="mv lp it mr b gy mw mx l my mz">H.add_edges_from([<br/>  (0, 1),<br/>  (1, 2),<br/>  (2, 0),<br/>  (2, 3),<br/>  (3, 2)<br/>])</span><span id="9778" class="mv lp it mr b gy na mx l my mz">print(H.edges())</span><span id="4834" class="mv lp it mr b gy na mx l my mz">&gt; [(0, 1), (1, 2), (2, 0), (2, 3), (3, 2)]</span></pre><p id="49e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在我们已经创建了一个图表，让我们定义一个函数来显示关于它的一些信息。我们验证了该图确实是有向的，并且它具有正确的节点数和边数。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="b00a" class="mv lp it mr b gy mw mx l my mz">def print_graph_info(graph):<br/>  print("Directed graph:", graph.is_directed())<br/>  print("Number of nodes:", graph.number_of_nodes())<br/>  print("Number of edges:", graph.number_of_edges())</span><span id="6cea" class="mv lp it mr b gy na mx l my mz">print_graph_info(H)</span><span id="ea73" class="mv lp it mr b gy na mx l my mz">&gt; Directed graph: True<br/>&gt; Number of nodes: 4<br/>&gt; Number of edges: 5</span></pre><p id="a009" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">绘制您正在使用的图表也非常有帮助。这可以通过使用<code class="fe nb nc nd mr b">nx.draw</code>来实现。我们使用节点的特征来给每个节点着色，并在绘图中给每个节点指定它们自己的大小。因为节点属性是以字典的形式出现的，而且draw函数只接受列表，所以我们必须首先转换它们。生成的图看起来像是应该有4个节点、5条边和正确的节点特征。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="e082" class="mv lp it mr b gy mw mx l my mz">node_colors = nx.get_node_attributes(H, "color").values()<br/>colors = list(node_colors)</span><span id="8e1e" class="mv lp it mr b gy na mx l my mz">node_sizes = nx.get_node_attributes(H, "size").values()<br/>sizes = list(node_sizes)</span><span id="dabe" class="mv lp it mr b gy na mx l my mz">nx.draw(H, with_labels=True, node_color=colors, node_size=sizes)</span></pre><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/bef0cb7c3647af0dab1c733991188fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*neI19MpUho9ocn6zJneW6Q.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">有向图，作者的图像。</p></figure><p id="c6f1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们把有向图<em class="ml"> H </em>转换成无向图<em class="ml"> G </em>。之后，我们再次打印关于该图的信息，我们可以看到转换成功了，因为输出表明它不再是一个有向图。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="b5ed" class="mv lp it mr b gy mw mx l my mz">G = H.to_undirected()<br/>print_graph_info(G)</span><span id="210d" class="mv lp it mr b gy na mx l my mz">&gt; Directed graph: False<br/>&gt; Number of nodes: 4<br/>&gt; Number of edges: 4</span></pre><p id="f139" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">奇怪的是，边的数量减少了一个。如果我们仔细观察，我们可以看到边<code class="fe nb nc nd mr b">(3, 2)</code>已经消失了，这是合理的，因为一个无向边只能由一个元组来表示，在这种情况下是<code class="fe nb nc nd mr b">(2, 3)</code>。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="0b3d" class="mv lp it mr b gy mw mx l my mz">print(G.edges())</span><span id="d4f8" class="mv lp it mr b gy na mx l my mz">&gt; [(0, 1), (0, 2), (1, 2), (2, 3)]</span></pre><p id="8f60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们想象无向图时，我们可以看到边的方向消失了，而其他一切都保持不变。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="403b" class="mv lp it mr b gy mw mx l my mz">nx.draw(G, with_labels=True, node_color=colors, node_size=sizes)</span></pre><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/52baf3aa8c0e3f19e8f9b4a3ead736ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*7j86m-HBcxD2HlLxubMKrw.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">一个无向图，作者的图像。</p></figure><h1 id="7340" class="lo lp it bd lq lr ls lt lu lv lw lx ly jz lz ka ma kc mb kd mc kf md kg me mf bi translated">空手道俱乐部网络</h1><p id="d7f2" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">现在我们已经对如何在Python中处理图形有了一个高层次的理解，我们将看看一个真实世界的网络，我们可以使用它来定义一个机器学习任务。扎卡里的空手道俱乐部网络[2]就是为此而选择的。它代表了w .扎卡里在七十年代研究的空手道俱乐部成员之间的友谊关系。如果两个人在俱乐部之外进行社交，则图中的一条边将他们连接起来。</p><p id="b7c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">空手道俱乐部数据集可通过PyTorch Geometric (PyG ) [3]获得。PyG库包含了对图形和其他不规则结构进行深度学习的各种方法。我们首先检查数据集的一些属性。它似乎只包含一个图形，这是意料之中的，因为它描述了一个俱乐部。此外，数据集中的每个节点被分配一个唯一代表每个节点的34维特征向量。俱乐部的每个成员都是机器学习术语中4个派别或类别之一的一部分。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="5b83" class="mv lp it mr b gy mw mx l my mz">from torch_geometric.datasets import KarateClub</span><span id="62bd" class="mv lp it mr b gy na mx l my mz">dataset = KarateClub()<br/>print("Dataset:", dataset)<br/>print("# Graphs:", len(dataset))<br/>print("# Features:", dataset.num_features)<br/>print("# Classes:", dataset.num_classes)</span><span id="9970" class="mv lp it mr b gy na mx l my mz">&gt; Dataset: KarateClub()<br/>&gt; # Graphs: 1<br/>&gt; # Features: 34<br/>&gt; # Classes: 4</span></pre><p id="bc6f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以进一步探索数据集中唯一的图形。我们看到该图是无向的，它有34个节点，每个节点有34个特征，如前所述。边用元组表示，一共有156个。然而，在PyG中，无向边被表示为两个元组，每个方向一个，也称为双向，这意味着在空手道俱乐部图中有78个唯一的边。PyG只包括<strong class="kk iu"> A </strong>中非零的条目，这就是为什么边是这样表示的。这种类型的表示被称为<em class="ml">坐标格式</em>，通常用于稀疏矩阵。每个节点都有一个标签，<em class="ml"> y </em>，它保存了相应节点属于哪个类的信息。该数据还包含一个<code class="fe nb nc nd mr b">train_mask</code>,它具有我们在训练期间已知的基础事实标签的节点的索引。有4个真实节点，每个派系一个，现在的任务是推断其余节点的派系。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="e840" class="mv lp it mr b gy mw mx l my mz">data = dataset[0]</span><span id="31de" class="mv lp it mr b gy na mx l my mz">print(data)<br/>print("Training nodes:", data.train_mask.sum().item())<br/>print("Is directed:", data.is_directed())</span><span id="9ae9" class="mv lp it mr b gy na mx l my mz">&gt; Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])<br/>&gt; Training nodes: 4<br/>&gt; Is directed: False</span></pre><p id="bf9c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将空手道俱乐部网络转换为Networkx图，这允许我们使用<code class="fe nb nc nd mr b">nx.draw</code>函数来可视化它。节点根据它们所属的职业(或派别)进行着色。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="bd40" class="mv lp it mr b gy mw mx l my mz">from torch_geometric.utils import to_networkx</span><span id="8ff8" class="mv lp it mr b gy na mx l my mz">G = to_networkx(data, to_undirected=True)<br/>nx.draw(G, node_color=data.y, node_size=150)</span></pre><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/711e7b2e447bf46695cd58da7d3458a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*63JXNX-4ZFHACVO-nr41yw.png"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">扎卡里的空手道俱乐部网络，由作者图像。</p></figure><h1 id="19f6" class="lo lp it bd lq lr ls lt lu lv lw lx ly jz lz ka ma kc mb kd mc kf md kg me mf bi translated">半监督节点分类</h1><p id="c6c1" class="pw-post-body-paragraph ki kj it kk b kl mg ju kn ko mh jx kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">当训练模型来执行节点分类时，它可以被称为半监督机器学习，这是用于在训练期间组合有标签和无标签数据的模型的通用术语。在节点分类的情况下，我们可以访问图中的所有节点，甚至是那些属于测试集的节点。唯一缺少的信息是测试节点的标签。</p><p id="8478" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图卷积网络(GCNs)将用于对测试集中的节点进行分类。为了给出简单的理论介绍，图形神经网络中的层可以写成非线性函数<em class="ml"> f </em>:</p><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/09643590b52c87d971789d1fb933aa55.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*Kh9w4vXhm6lEE3ow0ANU4w.png"/></div></figure><p id="e5fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以图的邻接矩阵<strong class="kk iu"> <em class="ml"> A </em> </strong>和某层的(潜在)节点特征<strong class="kk iu"><em class="ml"/></strong><em class="ml">l</em>作为输入。图形神经网络的简单分层传播规则如下所示:</p><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/caae2e594c520d4b8f6781a9e91bb92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*iCNT1uj3y5RsVpHVPVBdSA.png"/></div></figure><p id="ee22" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<strong class="kk iu"> <em class="ml"> W </em> </strong>为第<em class="ml"> l </em>个神经网络层的权重矩阵，<em class="ml"> σ </em>为非线性激活函数。将权重与邻接矩阵相乘意味着对每个节点的所有(1跳)相邻节点的所有特征向量进行求和和聚合。但是，不包括节点本身的特征向量。</p><p id="7387" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决这个问题，Kipf和Welling [4]将单位矩阵添加到邻接矩阵中，并将这个新矩阵表示为<strong class="kk iu"><em class="ml">—</em></strong>=<strong class="kk iu"><em class="ml">A</em></strong>+<strong class="kk iu"><em class="ml">I</em></strong>。邻接矩阵的乘法也将改变特征向量的比例。为了抵消这个<strong class="kk iu"><em class="ml">—</em></strong>被对称地乘以其对角度矩阵，产生最终的GCN传播规则:</p><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi no"><img src="../Images/bdd4bb682b9b4f44f482175529417ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*5Fu3vrUQpksF7jLXgzEsRw.png"/></div></figure><p id="c036" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GCN层已经是what PyG的一部分，它可以很容易地作为<code class="fe nb nc nd mr b">GCNConv</code>类导入。与在普通神经网络中层叠层的方式相同，也可以层叠多个GCN层。具有3层GCN将导致三个连续的传播步骤，导致每个节点用来自3跳之外的信息进行更新。模型的第一层必须具有与每个节点的要素数量一样多的输入单元。与最初的GCN论文一致，除了最后一个维度被设置为2之外，潜在维度被设置为4。这允许我们稍后将所学习的潜在嵌入绘制为二维散点图，以查看该模型是否设法学习对于属于同一类的节点来说相似的嵌入。双曲正切激活函数在GCN层之间用作非线性函数。输出层将二维节点嵌入映射到4个类中的1个。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="5fbb" class="mv lp it mr b gy mw mx l my mz">from torch.nn import Linear<br/>from torch_geometric.nn import GCNConv</span><span id="98f9" class="mv lp it mr b gy na mx l my mz">class GCN(torch.nn.Module):<br/>  def __init__(self):<br/>    super(GCN, self).__init__()<br/>    torch.manual_seed(42)<br/>    self.conv1 = GCNConv(dataset.num_features, 4)<br/>    self.conv2 = GCNConv(4, 4)<br/>    self.conv3 = GCNConv(4, 2)<br/>    self.classifier = Linear(2, dataset.num_classes)</span><span id="2ea0" class="mv lp it mr b gy na mx l my mz">  def forward(self, x, edge_index):<br/>    h = self.conv1(x, edge_index)<br/>    h = h.tanh()<br/>    h = self.conv2(h, edge_index)<br/>    h = h.tanh()<br/>    h = self.conv3(h, edge_index)<br/>    h = h.tanh()<br/>    out = self.classifier(h)<br/>    return out, h</span><span id="5e4f" class="mv lp it mr b gy na mx l my mz">model = GCN()<br/>print(model)</span><span id="7ec4" class="mv lp it mr b gy na mx l my mz">&gt; GCN(<br/>&gt;   (conv1): GCNConv(34, 4)<br/>&gt;   (conv2): GCNConv(4, 4)<br/>&gt;   (conv3): GCNConv(4, 2)<br/>&gt;   (classifier): Linear(in_features=2, out_features=4, bias=True)<br/>&gt; )</span></pre><p id="ceaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们使用交叉熵作为损失函数，因为它非常适合于多类分类问题，并初始化Adam作为随机梯度优化器。我们创建一个标准的PyTorch训练循环，并让它运行300个周期。注意，虽然所有节点确实获得了对它们的节点嵌入的更新，但是仅针对训练集中的节点计算损失。在训练期间，损失急剧减少，这意味着分类效果良好。来自最后一个GCN层的二维嵌入被存储为一个列表，以便我们可以在训练期间动画化嵌入的演变，给出对模型的潜在空间的一些洞察。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="9d09" class="mv lp it mr b gy mw mx l my mz">criterion = torch.nn.CrossEntropyLoss()<br/>optimizer = torch.optim.Adam(model.parameters(), lr=0.01)</span><span id="1acd" class="mv lp it mr b gy na mx l my mz">def train(data):<br/>  optimizer.zero_grad()<br/>  out, h = model(data.x, data.edge_index)<br/>  loss = criterion(out[data.train_mask], data.y[data.train_mask])<br/>  loss.backward()<br/>  optimizer.step()<br/>  return loss, h</span><span id="bdd0" class="mv lp it mr b gy na mx l my mz">epochs = range(1, 301)<br/>losses = []<br/>embeddings = []</span><span id="ef1f" class="mv lp it mr b gy na mx l my mz">for epoch in epochs:<br/>  loss, h = train(data)<br/>  losses.append(loss)<br/>  embeddings.append(h)<br/>  print(f"Epoch: {epoch}\tLoss: {loss:.4f}")</span><span id="f294" class="mv lp it mr b gy na mx l my mz">&gt; Epoch: 1    Loss: 1.399590<br/>&gt; Epoch: 2    Loss: 1.374863<br/>&gt; Epoch: 3    Loss: 1.354475<br/>&gt; ...<br/>&gt; Epoch: 299  Loss: 0.038314<br/>&gt; Epoch: 300  Loss: 0.038117</span></pre><p id="6a2d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Matplotlib可以用来制作节点嵌入的散点图，其中每个点都根据它们所属的派系进行着色。对于每一帧，除了该时期的训练损失值之外，我们还显示该时期。最后，动画被转换成GIF格式，如下图所示。</p><pre class="mm mn mo mp gt mq mr ms mt aw mu bi"><span id="cd77" class="mv lp it mr b gy mw mx l my mz">import matplotlib.animation as animation</span><span id="51bc" class="mv lp it mr b gy na mx l my mz">def animate(i):<br/>  ax.clear()<br/>  h = embeddings[i]<br/>  h = h.detach().numpy()<br/>  ax.scatter(h[:, 0], h[:, 1], c=data.y, s=100)<br/>  ax.set_title(f'Epoch: {epochs[i]}, Loss: {losses[i].item():.4f}')<br/>  ax.set_xlim([-1.1, 1.1])<br/>  ax.set_ylim([-1.1, 1.1])</span><span id="f8f3" class="mv lp it mr b gy na mx l my mz">fig = plt.figure(figsize=(6, 6))<br/>ax = plt.axes()<br/>anim = animation.FuncAnimation(fig, animate, frames=epochs)<br/>plt.show()</span><span id="2d07" class="mv lp it mr b gy na mx l my mz">gif_writer = animation.PillowWriter(fps=20)<br/>anim.save('embeddings.gif', writer=gif_writer)</span></pre><figure class="mm mn mo mp gt nf gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2568a26e1c8fe64f56d6ff52e9f3befd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/1*TKutsPCJaeHZpqYyV5mLsQ.gif"/></div><p class="ni nj gj gh gi nk nl bd b be z dk translated">节点嵌入的演变，作者图片。</p></figure><p id="eb04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GCN模型设法线性分离不同类的几乎所有节点。这是令人印象深刻的考虑到它只给了每个派系一个标记的例子作为输入。</p><p id="7182" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望你对图形神经网络的介绍感兴趣。gnn是非常通用的算法，因为它们可以应用于复杂的数据和解决不同类型的问题。例如，通过在我们的神经网络末端使用一些置换不变池(如mean)来简单地聚集节点特征，它可以对整个图进行分类，而不是对单个节点进行分类！</p></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="dac4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1] A. Hagberg，D. Schult和P. Swart，“使用NetworkX探索网络结构、动力学和功能”，<em class="ml"> SciPy2008 </em>，2008，【networkx.org】T2</p><p id="fc60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] W .扎卡里，“小群体中冲突和裂变的信息流模型”，<em class="ml"> J. Anthropol .Res </em>。doi:10.1086/jar . 33 . 4 . 3629752</p><p id="81b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] M. Fey和J. Lenssen，“用PyTorch几何快速图形表示学习”，<em class="ml"> ICLR，</em> 2019，<a class="ae ln" href="https://www.pyg.org" rel="noopener ugc nofollow" target="_blank">pyg.org</a>，麻省理工学院许可</p><p id="2835" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] T. Kipf和M. Welling，“基于图卷积网络的半监督分类”，<em class="ml"> ICLR </em>，2016，<a class="ae ln" href="https://arxiv.org/abs/1609.02907" rel="noopener ugc nofollow" target="_blank"> arXiv: 1609.02907 </a></p></div></div>    
</body>
</html>