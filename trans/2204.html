<html>
<head>
<title>Walkable 360° Video</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可行走的360视频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/walkable-360-video-b77c11792d4d#2022-05-16">https://towardsdatascience.com/walkable-360-video-b77c11792d4d#2022-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b7fd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">几何人工智能可以让你进入360 VR照片和视频</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b7bd78bb1e2e8471c53ed0538066ec46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zTIZg5pfZPXjohzf1JWzCA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">可步行360视频。【原创图片由作者创作。]</p></figure><p id="27de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated">今天的虚拟现实体验与用户期望的现实主义相差甚远。当前的虚拟现实技术基本上分为两类:基于3D模型和计算机生成图像(CGI)的技术；以及基于全景360°图像的那些。</p><p id="cdf2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于CGI的体验是<em class="ma">交互式的</em>，支持新颖的视角，但是<em class="ma">远非照片般真实</em>，构建成本高昂，并且表现出高数据量和计算成本。</p><p id="2f4c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基于360°图像的虚拟现实体验<em class="ma">逼真</em>，易于获取，数据量和计算成本较低，但<em class="ma">不具备交互性</em>且不支持新颖的视图。</p><blockquote class="mb mc md"><p id="ea1d" class="kv kw ma kx b ky kz jr la lb lc ju ld me lf lg lh mf lj lk ll mg ln lo lp lq ij bi translated">理想情况下，我们希望两个世界都是最好的，虚拟现实体验既逼真又互动。</p></blockquote><h1 id="6650" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">360°摄像机仅捕捉单个视点</h1><p id="afea" class="pw-post-body-paragraph kv kw iq kx b ky mz jr la lb na ju ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">虽然360°内容，即全景照片和视频，本质上是照片级的，毕竟它们是基于摄影的，但它们是由相机在每个时间点在空间的给定点获取的。在每个时刻，相机只捕捉这个固定的视点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/ba8ef52b55476b4ab5e5af2eeb9347a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xjjf7Fwn1D3R9Finm6VHhA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">360°摄像机捕捉完整的360°全景，但仅从固定视点拍摄。【来源于<a class="ae nf" href="https://en.wikipedia.org/wiki/Ricoh_Theta#/media/File:Omnidirectional_camera_03.jpg" rel="noopener ugc nofollow" target="_blank">维基共享</a>。]</p></figure><p id="3ffb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，360°内容只能从原始摄像机视点在VR中观看。<em class="ma">不可能</em>在空间中移动来探索拍摄时未被摄像机捕捉到的新奇视角。</p><blockquote class="mb mc md"><p id="53fa" class="kv kw ma kx b ky kz jr la lb lc ju ld me lf lg lh mf lj lk ll mg ln lo lp lq ij bi translated">在360 VR中，无论你在真实的物理世界中如何移动，你都在虚拟世界中保持冻结状态。</p></blockquote><p id="ab11" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们希望从相机视点解锁用户的视图，从而提供基于360°图像的真实感VR体验，同时也是交互式的，允许用户在上面移动。人工智能(AI)技术可以帮助实现这一目标。</p><h1 id="8390" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">周正艾来救驾了</h1><p id="a026" class="pw-post-body-paragraph kv kw iq kx b ky mz jr la lb na ju ld le nb lg lh li nc lk ll lm nd lo lp lq ij bi translated">虽然人工智能在过去十年经历了一场革命，但大多数人工智能方法都是基于标准(欧几里得)数据，如常见的2D图像。但是，360°照片和视频具有几何结构，因为它们是在360°球面上定义的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/a594a9d227c37af8ac3a9bc6a5267448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*FVACWy3pMRwlYtqly3IC0g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">360照片和视频产生球体上定义的数据。【原创图片由作者创作。]</p></figure><p id="7774" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了将人工智能应用于360°照片和视频，我们需要专门在360°球体上定义的人工智能技术。几何人工智能的新兴领域恰恰解决了这一挑战(参见<a class="ae nf" rel="noopener" target="_blank" href="/geometric-deep-learning-for-spherical-data-55612742d05f">本文</a>介绍球面360°数据的几何人工智能，以及<a class="ae nf" rel="noopener" target="_blank" href="/what-einstein-can-teach-us-about-machine-learning-1661e26bef2c">本文</a>介绍一些底层概念)。</p><h1 id="5bd5" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">用几何人工智能合成运动</h1><blockquote class="mb mc md"><p id="fd25" class="kv kw ma kx b ky kz jr la lb lc ju ld me lf lg lh mf lj lk ll mg ln lo lp lq ij bi translated">利用360°数据的几何人工智能技术，有可能实现既逼真又互动的VR体验。</p></blockquote><p id="7bb0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在<a class="ae nf" href="https://www.kagenova.com/" rel="noopener ugc nofollow" target="_blank"> Kagenova </a>，一家致力于建设未来照片般逼真的元宇宙的初创公司，我们开发了<a class="ae nf" href="https://www.kagenova.com/products/copernic360/" rel="noopener ugc nofollow" target="_blank"> copernic360 </a>来提供可行走的360°视频。</p><p id="c9ce" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">copernic360利用Kagenova开发的<a class="ae nf" href="https://www.kagenova.com/research/" rel="noopener ugc nofollow" target="_blank">几何球形人工智能</a>技术，从单个360°图像(照片或视频帧)中估计代表场景的3D几何图形。</p><p id="5e34" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">copernic360查看器系统使用这种几何图形以及原始的360视频或照片来渲染场景的3D纹理表示。然后，用户能够在重建的场景中自由移动。这不仅大大增强了虚拟现实体验的真实性，还消除了网络晕动病的主要原因。</p><p id="7332" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面嵌入的视频演示了由copernic360实现的可行走的360°照片和视频。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nh ni l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">可步行360视频演示。【视频由作者创作。]</p></figure><h1 id="a2bb" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">逼真的元宇宙</h1><blockquote class="mb mc md"><p id="f100" class="kv kw ma kx b ky kz jr la lb lc ju ld me lf lg lh mf lj lk ll mg ln lo lp lq ij bi translated">通过将图像与强大的人工智能技术相结合，有可能实现既逼真又互动的虚拟体验。</p></blockquote><p id="6712" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">copernic360提供的可行走的360°视频体验只是朝着这个方向迈出的第一步。神经渲染领域正在快速发展，并有可能提供更真实的体验，为未来的照片级元宇宙提供动力——这是我们在Kagenova积极追求的目标！</p><p id="ee52" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与此同时，copernic360提供可行走的360照片和视频，可以在今天的生产中部署，以增强现有的360体验、应用程序和平台。</p></div></div>    
</body>
</html>