<html>
<head>
<title>Crafting Prompts for Text-to-Image Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为文本到图像模型制作提示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-future-of-crafting-prompts-for-text-to-image-models-fc7d9614cb65#2022-07-26">https://towardsdatascience.com/the-future-of-crafting-prompts-for-text-to-image-models-fc7d9614cb65#2022-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dbaf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">只要你知道正确的咒语，DALL E可以产生你想要的任何东西</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/dfcfe3064ead1f9ee9f22e75bd188500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*71VH5H30gIX3eVyv6SIDzg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过<a class="ae kv" href="http://midjourney.com" rel="noopener ugc nofollow" target="_blank">中途</a>生成的插图(生成式人工智能)。文字提示:“一个男孩绝望地在笔记本电脑键盘上打字，沮丧的脸，明显生气，卡通风格”。</p></figure><p id="cb23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像<a class="ae kv" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank"> DALL E </a>这样以文本为条件的图像生成模型的出现无疑将改变传统的创作过程。然而，艺术不一定是免费的:负担将简单地从绘画或使用复杂的图形设计软件转移到制作有效的文本提示，以控制文本到图像模型的突发奇想。本文讨论了用户和公司解决<strong class="ky ir">即时工程</strong>或<strong class="ky ir">即时设计</strong>挑战的潜在方法。</p><blockquote class="ls"><p id="9975" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">提示是迁移学习的最新和最极端的形式。对图像的每一次请求都可以被视为一个新的任务，由一个根据大量数据预先训练好的模型来完成。在某种程度上，提示已经使迁移学习民主化，但还没有使它变得毫不费力。写有效的提示可能需要和培养一个新爱好一样多的工作。</p></blockquote><h1 id="09b7" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">提示的起源</h1><p id="2a5c" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">有人可能会说，提示是迁移学习的最新和最极端的形式:一种允许先前训练的模型权重在新的环境中重用的机制。这些年来，我们找到了在构建特定任务模型时重用越来越多预训练权重的方法。2013年，<em class="mz"> word2vec </em> [1]将通用word <em class="mz"> </em>嵌入捆绑成静态库；人们用它们作为他们NLP模型的现成输入。在2010年代末，ELMo [2]和BERT [3]等模型引入了<em class="mz">微调</em>:它们允许预训练模型的<em class="mz">整个架构</em>被重用，并与每个任务的最小数量的额外权重连接。最后，GPT-3 [4]在2020年通过<em class="mz">提示</em>关闭了迁移学习章节:一个单独的预训练模型现在可以执行几乎任何特定的任务，无需额外的参数或重新训练；它只需要通过文本输入被引导到正确的方向。DALL E等文本到图像模型处于迁移学习光谱的同一端:对图像的每个请求都可以被视为模型要完成的新任务。</p><h1 id="3a30" class="mc md iq bd me mf mg mh mi mj mk ml mm jw na jx mo jz nb ka mq kc nc kd ms mt bi translated">当前的事态</h1><p id="f459" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">在某种程度上，提示已经使迁移学习民主化:用户不再需要ML工程技能或昂贵的微调数据集来利用大模型的力量。然而，利用生成性人工智能还不是轻而易举的。今天，在第一篇DALL E论文发表1.5年后，DALL E 2向少数人开放3个月后，写有效的提示可能需要像培养新的爱好一样的努力。有一个学习曲线在起作用:人们修补模型，通过反复实验，他们发现输入和模型行为之间的相关性。他们也让自己沉浸在文本到图像的社区中(例如<a class="ae kv" href="https://www.reddit.com/r/dalle2/" rel="noopener ugc nofollow" target="_blank"> Reddit </a>、<a class="ae kv" href="https://twitter.com/hashtag/dalle2?src=hashtag_click" rel="noopener ugc nofollow" target="_blank"> Twitter </a>等)。)来学习这一行业的诀窍并分享他们自己的发现。除此之外，他们还争论达尔E 2 <a class="ae kv" href="https://twitter.com/giannis_daras/status/1531693093040230402" rel="noopener ugc nofollow" target="_blank">是否有</a>或<a class="ae kv" href="https://twitter.com/benjamin_hilton/status/1531780892972175361" rel="noopener ugc nofollow" target="_blank">没有</a>秘密语言。</p><p id="e34b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一个数据驱动型的人，我想知道数据是否能提供一条捷径来获得快速工程这一难以捉摸的技能。我们与一位<a class="ae kv" href="https://twitter.com/gaurav_nemade15" rel="noopener ugc nofollow" target="_blank">朋友</a>一起，窃取了<a class="ae kv" href="https://www.midjourney.com" rel="noopener ugc nofollow" target="_blank"> Midjourney </a>的公共Discord服务器，用户在那里与一个机器人互动，发出提示，并获得人工智能生成的图像作为回报。我们在10个频道上收集了4个月的请求和响应，并在Kaggle上提供了数据集:<a class="ae kv" href="https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage" rel="noopener ugc nofollow" target="_blank">中途用户提示&amp;生成的图像(250k) </a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/d1e4c3f464a2e28e6913f6a578dc089b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yv1KfsN7anrS9x6s"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd ne">文本提示中最常用的短语</strong>由<a class="ae kv" href="http://midjourney.com" rel="noopener ugc nofollow" target="_blank">中途</a>用户发布。查看Kaggle上的完整数据集:<a class="ae kv" href="https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage" rel="noopener ugc nofollow" target="_blank">中途用户提示&amp;生成的图像(250k) </a>。作者制作的插图。</p></figure><p id="636f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的词云说明了Midjourney用户发出的文本提示中最常用的短语。其中一些是意想不到的，至少对于非鉴赏家来说是这样。取代动物、机器人或任何其他我们人类觉得可爱的实体(即<em class="mz">内容</em>)的是<em class="mz">修饰语</em>(即描述期望输出的风格或质量)。它们包括像<a class="ae kv" href="https://en.wikipedia.org/wiki/Octane_Render" rel="noopener ugc nofollow" target="_blank">辛烷渲染</a>或<a class="ae kv" href="https://www.unrealengine.com/en-US" rel="noopener ugc nofollow" target="_blank">虚幻引擎</a>这样的应用名称和像<a class="ae kv" href="https://en.wikipedia.org/wiki/Craig_Mullins" rel="noopener ugc nofollow" target="_blank">克雷格穆林斯</a>这样的艺术家名称。你可以在<a class="ae kv" href="https://www.kaggle.com/code/succinctlyai/midjourney-prompt-analysis" rel="noopener ugc nofollow" target="_blank">这本笔记本</a>里找到更详细的提示分析。免责声明:目前还不清楚这些发现有多普遍。它们可能只是反映了潜在的有偏见的用户群的口味，或者可能只是从中途模型中引出强烈的视觉反应。如果你有DALL E 2的权限，让我知道他们对它有没有影响！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/10ae366929fc3465b1d17704f7743849.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*XaaDJGYcJWrVojeoxjS00g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">中途用户在他们的文本提示中提到的顶级艺术家(y轴是每10k个提示的随机子样本的计数)。你可以在本笔记本中找到更多统计数据。</p></figure><p id="0ad4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">诚然，我们被观察到的提示的复杂性所淹没，我们决定在这些用户生成的文本提示上对大型语言模型GPT-2进行微调。我们现在可以依靠它来自动完成我们微薄的提示，并将其转化为创造性的和复杂的输入，而不是靠我们自己来学习交易的技巧。<strong class="ky ir">我们的模型在</strong> <a class="ae kv" href="https://huggingface.co/succinctly/text2image-prompt-generator" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">的HuggingFace上免费提供，简洁/text 2 image-prompt-generator</strong></a><strong class="ky ir">。请随意与演示互动！</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/6444d699061579633e98f612bafe1c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thtIAqjsyglSgzN4TZvNGw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">提示自动完成模型的示例用法，可在<a class="ae kv" href="https://huggingface.co/succinctly/text2image-prompt-generator" rel="noopener ugc nofollow" target="_blank">简洁地/text 2 image-prompt-generator</a>获得。这三幅图像是在<a class="ae kv" href="https://midjourney.com" rel="noopener ugc nofollow" target="_blank">中途</a>生成的。插图本身是作者画的。</p></figure><h1 id="6ad9" class="mc md iq bd me mf mg mh mi mj mk ml mm jw na jx mo jz nb ka mq kc nc kd ms mt bi translated">激励遇上资本主义</h1><blockquote class="ls"><p id="7441" class="lt lu iq bd lv lw lx ly lz ma mb lr dk translated">在商业中，时间就是金钱，文本提示也是如此。</p></blockquote><p id="beab" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf nj lh li lj nk ll lm ln nl lp lq lr ij bi translated">随着DALL E 2和Midjourney等竞争服务变得越来越普及(前者目前正在向其第一批一百万用户推出，而后者正在T2进行公开测试)，专业人士开始评估将生成性人工智能融入他们工作流程的潜力。例如，一位平面设计师在Twitter上发了一个帖子，探讨DALL E 2创建独特模型的能力:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="89c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着文本到图像模式进入资本主义(专业设计、内容营销、广告创意)，提示不再是一种娱乐爱好，而是一项需要有效完成的工作。在商业中，时间就是金钱，文本提示也是如此。<a class="ae kv" href="https://www.reddit.com/r/dalle2/comments/w5y162/comment/ihbgpoi/?utm_source=share&amp;utm_medium=web2x&amp;context=3" rel="noopener ugc nofollow" target="_blank">一些人</a>预测，与其他类型的体力工作类似，即时工程将被转移到低收入国家:工人将获得每小时10美元的报酬，以发布尽可能多的查询并选择最佳视觉输出。然而，随着OpenAI <a class="ae kv" href="https://jimclydemonge.medium.com/dall-e2s-new-pricing-is-making-people-upset-b55c853faaf7" rel="noopener">颇具争议的</a>宣布基于信用的定价模式(本质上是按使用量收费，而不是提供订阅)，用户被激励发出尽可能少的提示。因此，取代上面的暴力方法，我们可能会看到一个新的职业出现:<em class="mz">提示工程师</em>——一个精通生成人工智能的能力和奇思妙想的人，他可以在3次或更少的尝试中制作出你需要的插图。</p><h1 id="6e33" class="mc md iq bd me mf mg mh mi mj mk ml mm jw na jx mo jz nb ka mq kc nc kd ms mt bi translated">研究将如何介入</h1><p id="2cf2" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">提示不一定需要永远是人类的劳动。事实上，当提示实践首次出现在文本生成领域时，研究人员对其进行了广泛的研究。这本可能并不完整的文集提到了截至2022年7月底的86篇论文。许多文章提出了自动化，自动地<em class="mz">以一种更模型友好的方式重新表述</em>输入，包含冗余，<em class="mz">生成额外的令牌</em>以使模型的任务更加明确，产生<em class="mz">软提示</em>(即，修改原始输入提示的内部表示)，或者为<a class="ae kv" href="https://arxiv.org/abs/2201.06009" rel="noopener ugc nofollow" target="_blank"> <em class="mz">交互会话</em> </a> <em class="mz"> </em>设计一个框架，在这个框架中，模型记住用户的偏好和对更长请求序列的反馈。很可能同样数量的研究将用于驯服文本到图像的模型。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><h1 id="7b07" class="mc md iq bd me mf nv mh mi mj nw ml mm jw nx jx mo jz ny ka mq kc nz kd ms mt bi translated">承认</h1><p id="77d2" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">中途刮削项目是与<a class="ae kv" href="https://www.linkedin.com/in/gauravnemade/" rel="noopener ugc nofollow" target="_blank"> Gaurav Nemade </a>合作完成的。</p><h1 id="e6da" class="mc md iq bd me mf mg mh mi mj mk ml mm jw na jx mo jz nb ka mq kc nc kd ms mt bi translated">资源/链接</h1><ul class=""><li id="5245" class="oa ob iq ky b kz mu lc mv lf oc lj od ln oe lr of og oh oi bi translated">Kaggle数据集(Midjourney用户提示和生成的图像(250k):<a class="ae kv" href="https://www.kaggle.com/datasets/succinctlyai/midjourney-texttoimage" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/succictlyai/Midjourney-texttoimage</a></li><li id="beff" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr of og oh oi bi translated">仅带有文本提示的HuggingFace数据集:<a class="ae kv" href="https://huggingface.co/datasets/succinctly/midjourney-prompts" rel="noopener ugc nofollow" target="_blank">https://hugging face . co/datasets/essentially/mid journey-prompts</a></li><li id="a01c" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr of og oh oi bi translated">HuggingFace模型(提示生成器):<a class="ae kv" href="https://huggingface.co/succinctly/text2image-prompt-generator" rel="noopener ugc nofollow" target="_blank">https://hugging face . co/简洁地/text 2 image-prompt-generator</a></li></ul><h1 id="93d2" class="mc md iq bd me mf mg mh mi mj mk ml mm jw na jx mo jz nb ka mq kc nc kd ms mt bi translated">参考</h1><p id="11d1" class="pw-post-body-paragraph kw kx iq ky b kz mu jr lb lc mv ju le lf mw lh li lj mx ll lm ln my lp lq lr ij bi translated">[1] Mikolov等人(2013)，<a class="ae kv" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">向量空间中单词表示的有效估计</a></p><p id="4d55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] Peters等(2018)，<a class="ae kv" href="https://arxiv.org/abs/1802.05365" rel="noopener ugc nofollow" target="_blank">深度语境化的词语表征</a></p><p id="020b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] Devlin等人(2018)，<a class="ae kv" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT:用于语言理解的深度双向变换器的预训练</a></p><p id="6efa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] Brown等人(2020)，<a class="ae kv" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank">语言模型是很少出手的学习者</a></p></div></div>    
</body>
</html>