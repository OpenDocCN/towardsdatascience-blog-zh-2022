<html>
<head>
<title>Hidden Markov Models Simply Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">隐马尔可夫模型简单解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hidden-markov-models-simply-explained-d7b4a4494c50#2022-02-28">https://towardsdatascience.com/hidden-markov-models-simply-explained-d7b4a4494c50#2022-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1952" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">隐马尔可夫模型及其相关计算的简单解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fc9d01fe2c508411dd13159eff0df302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EEJ3w3eL3dS8S0Dp"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@pietrozj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pietro Jeng </a>拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="6824" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="4c7e" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在我的马尔可夫链系列的最后一篇文章中，我们将讨论<strong class="ma iu">隐马尔可夫模型(HMM)。</strong>这些出现在数据科学和机器学习的许多方面，特别是<strong class="ma iu">自然语言处理</strong>和<strong class="ma iu">强化学习</strong>，因此绝对值得了解。</p><p id="8490" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在本文中，我假设读者已经对<strong class="ma iu">马尔可夫性质</strong>和<strong class="ma iu">马尔可夫链、</strong>以及<strong class="ma iu">平稳分布背后的思想有了一些基本的了解。</strong>如果没有，请参考我之前关于这些主题的帖子:</p><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/markov-chains-simply-explained-dc77836b47e3"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">马尔可夫链简单地解释了</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">马尔可夫性和马尔可夫链的直观而简单的解释</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq ks nc"/></div></div></a></div><div class="mz na gp gr nb nc"><a rel="noopener follow" target="_blank" href="/markov-chains-stationary-distribution-bedd67140112"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd iu gy z fp nh fr fs ni fu fw is bi translated">马尔可夫链:平稳分布</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">用 Python 模拟解释和推导马尔可夫链的平稳分布</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq ks nc"/></div></div></a></div></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="efd6" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">直觉和范例模型</h1><p id="7202" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在一个规则的马尔可夫链中，我们能够看到状态和它们相关的转移概率。然而，在一个<strong class="ma iu">隐马尔可夫模型(HMM) </strong>中，马尔可夫链是<strong class="ma iu">隐<em class="ns"> </em> </strong>但是我们可以通过它给定的<strong class="ma iu">观察状态来推断它的性质。</strong></p><blockquote class="nt nu nv"><p id="3b02" class="ly lz ns ma b mb mu ju md me mv jx mg nw mw mj mk nx mx mn mo ny my mr ms mt im bi translated">注意:隐马尔可夫模型本身并不是马尔可夫链，它是马尔可夫过程/模型列表中的另一个模型。</p></blockquote><p id="4888" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们通过一个例子来获得一些理解:</p><ul class=""><li id="1d11" class="nz oa it ma b mb mu me mv mh ob ml oc mp od mt oe of og oh bi translated">如果天气晴朗，我有 90%的几率快乐，10%的几率悲伤。</li><li id="63ec" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated">如果天气<strong class="ma iu">下雨</strong>，我有<strong class="ma iu"> 30% </strong>的几率快乐，有<strong class="ma iu"> 70% </strong>的几率悲伤。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/e3a69c792ab6e03f0009cda58b6a51d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zoB-ln-iaE72aC8cJONmuw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者生成的图像。</p></figure><p id="94ef" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这些<strong class="ma iu">观察状态</strong>(快乐、悲伤)<strong class="ma iu"> </strong>的关联概率被称为<strong class="ma iu">发射概率。</strong></p><p id="e9cf" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在，假设我的朋友想从我的情绪中推断天气。所以，对于给定的一周，比方说，我:<strong class="ma iu"> <em class="ns">悲伤、快乐、表示快乐、悲伤、开心、难过。</em> </strong>因此，我的朋友会推断天气一直:<strong class="ma iu"> <em class="ns">下雨，晴天，下雨，晴天，下雨，晴天，下雨。</em> </strong>这是一种直观的方法，然而天气不太可能如此变化无常。因此，我们需要在我们的<strong class="ma iu">隐藏状态之间加上<strong class="ma iu">转移概率</strong>。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/4c334e26088c0aee59354f5890dea5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P9ppS83Ipq9ZCmPdOj9tZw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者生成的图像。</p></figure><p id="3975" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">上面的情节就是我们的<strong class="ma iu">隐马尔可夫模型！</strong>我们现在将使用我们的模型进行一些基本计算！</p><h1 id="f688" class="lg lh it bd li lj op ll lm ln oq lp lq jz or ka ls kc os kd lu kf ot kg lw lx bi translated">晴天的概率？</h1><p id="219a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">随机一天是晴天还是雨天的概率有多大？这个问题由马尔可夫链的<strong class="ma iu">平稳分布</strong>来回答。这告诉我们长期处于给定状态的概率，或者称为<strong class="ma iu">马尔可夫链的均衡。</strong></p><p id="261d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">平稳分布是一个给定的分布，如果你应用<strong class="ma iu">转移矩阵，<em class="ns"> P </em> </strong>，结果分布是和以前一样的<strong class="ma iu"/>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/ea70e27af25b50467d9d691cfde676f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:190/format:webp/1*jbGq6frLhOjKx5l-hI5CcQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX 中生成的方程。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/bc23ec9a9693d7a9c456068d70211eaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*KH_RrD09UsR3NFy6IKO5LA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX 中生成的方程。</p></figure><p id="ff04" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其中<strong class="ma iu"> <em class="ns"> π </em> </strong>为平稳分布。这个分布可以通过<strong class="ma iu">找到<em class="ns"> P </em>的特征值为 1 的特征向量来导出。</strong>在本文中，我不会推导整个特征值分解过程，因为它是详尽的，但是它在我之前关于平稳分布的<a class="ae ky" rel="noopener" target="_blank" href="/markov-chains-stationary-distribution-bedd67140112">文章中有所涉及。</a></p><p id="147d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">尽管如此，在对上述 HMM 应用特征值分解后，我们发现<strong class="ma iu">平稳分布为<em class="ns"> {0.5，0.5}。</em> </strong>换句话说，一个随机的日子是<strong class="ma iu">同样可能是晴天或雨天！</strong></p><h1 id="3ef1" class="lg lh it bd li lj op ll lm ln oq lp lq jz or ka ls kc os kd lu kf ot kg lw lx bi translated">评估序列可能性</h1><p id="87d4" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><em class="ns">我们如何计算一系列隐藏的和观察到的状态出现的概率？</em></p><p id="0464" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">例如，让我们说昨天我是<strong class="ma iu">快乐的</strong>并且它是<strong class="ma iu">晴朗的</strong>并且今天我是<strong class="ma iu">悲伤的</strong>并且它也是<strong class="ma iu">晴朗的。</strong>这个序列的概率是多少？</p><p id="7a67" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">数学上，我们想计算:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/e70649698f401639ee509e308cf11721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*K_X1qQjBvbvEh5f1OyrP9A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX 中生成的方程。</p></figure><p id="1cc5" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们可以使用上面的 HMM 图中显示和导出的<strong class="ma iu">发射、跃迁和稳态分布概率</strong>通过蛮力做到这一点。我们将其分解为以下概率:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/c94200340e53f4377d2e80c6ef15afe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5OOZtcTsO_5EqrkMNWRiBA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LaTeX 中生成的方程。</p></figure><p id="f573" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><strong class="ma iu">所以上面序列的概率是 0.056！</strong></p><blockquote class="nt nu nv"><p id="c6d9" class="ly lz ns ma b mb mu ju md me mv jx mg nw mw mj mk nx mx mn mo ny my mr ms mt im bi translated">眼尖的人可能已经注意到我们在上面的计算中间接使用了<strong class="ma iu">贝叶斯定理</strong>！</p></blockquote><h1 id="5ac8" class="lg lh it bd li lj op ll lm ln oq lp lq jz or ka ls kc os kd lu kf ot kg lw lx bi translated">解码最可能的序列</h1><p id="083c" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><em class="ns">产生一个可观测的(情绪)序列的最可能的隐藏状态(天气)序列是什么？</em></p><p id="8d9e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这个答案可以通过简单地<strong class="ma iu">计算所有可能的隐藏状态组合</strong>并选择具有最高概率的<strong class="ma iu">来实现。这被称为最大似然估计。</strong></p><p id="2594" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">然而，组合的数量可以很快变得非常大。对于<strong class="ma iu"><em class="ns"/></strong>n 个隐藏状态和一个观测序列的<strong class="ma iu"><em class="ns"/></strong>个观测值，我们有(<strong class="ma iu"><em class="ns">【n^t】)</em></strong>个可能的组合。在实践中，<strong class="ma iu"> <em class="ns"> N </em> </strong>和<strong class="ma iu"> <em class="ns"> T </em> </strong>会很大，因此<strong class="ma iu">计算每个隐藏状态组合在计算上是不可行的</strong>。</p><p id="45f3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">为了解决这个复杂性问题，我们使用<strong class="ma iu">维特比算法或前向算法</strong>，其使用按照<em class="ns"> O(N ) </em>的顺序工作的<strong class="ma iu">动态编程。我将把这些算法的解释留到以后的博客上，因为它相当密集。然而，请自行研究！</strong></p><h1 id="95af" class="lg lh it bd li lj op ll lm ln oq lp lq jz or ka ls kc os kd lu kf ot kg lw lx bi translated">结论</h1><p id="92ac" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">希望你喜欢这篇关于隐马尔可夫模型的文章！这个统计算法的领域相当大，所以这只是一个基本的介绍，以及一些你可以用它做的事情。</p><h1 id="c85a" class="lg lh it bd li lj op ll lm ln oq lp lq jz or ka ls kc os kd lu kf ot kg lw lx bi translated">和我联系！</h1><ul class=""><li id="ca40" class="nz oa it ma b mb mc me mf mh oy ml oz mp pa mt oe of og oh bi translated">要在媒体上阅读无限的故事，请务必在这里注册！  <em class="ns"> </em>💜</li><li id="9786" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated"><a class="ae ky" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank">T49<em class="ns">T51】😀</em></a></li><li id="b8dc" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated"><a class="ae ky" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"> <em class="ns">领英</em> </a> <em class="ns"> </em>👔</li><li id="a7a0" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated"><a class="ae ky" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="ns">推特</em> </a> <em class="ns"> </em> 🖊</li><li id="fb18" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated"><a class="ae ky" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="ns">github</em></a><em class="ns"/>🖥</li><li id="87b0" class="nz oa it ma b mb oi me oj mh ok ml ol mp om mt oe of og oh bi translated"><a class="ae ky" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="ns"/></a><em class="ns"/>🏅</li></ul><blockquote class="nt nu nv"><p id="72f1" class="ly lz ns ma b mb mu ju md me mv jx mg nw mw mj mk nx mx mn mo ny my mr ms mt im bi translated">(所有表情符号都是由<a class="ae ky" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计的——开源的表情符号和图标项目。执照:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>