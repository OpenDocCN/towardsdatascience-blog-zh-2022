<html>
<head>
<title>Data Distillation for Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于目标检测的数据提取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-distillation-for-object-detection-92a89fe5d996#2022-02-13">https://towardsdatascience.com/data-distillation-for-object-detection-92a89fe5d996#2022-02-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cddd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从不同的角度学习</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f3c82022456063dc46eb5fe84c6ad908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8Y3jCdkcLL-JU9-t"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Robina Weermeijer 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="7e2b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">知识的升华</h1><p id="e5e9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">知识提取(KD)，也称为模型提取(MD)，是深度学习之父杰弗里·辛顿(Geoffrey Hinton)提出的一种令人印象深刻的神经网络训练方法，以获得神经网络的性能。如果你从未听说过 KD，你可以通过这个<a class="ae kv" href="https://pub.towardsai.net/a-gentle-introduction-to-knowledge-distillation-6240bf8eb8ea" rel="noopener ugc nofollow" target="_blank">链接</a>到达我的帖子。</p><p id="0acd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">简而言之，知识发现的核心思想是从大型模型(教师)或神经网络模型集合中提取知识，并使用这些知识作为软标签来指导(训练)较小的神经网络(学生)，以便学生可以更有效地学习，从而提高其性能，这是通过从头开始训练学生无法实现的。</p><p id="75c8" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">尽管 KD 很有潜力，但它在训练阶段有局限性，因为它需要大量的硬件资源和长时间来训练大型教师模型或笨重的模型集合，以实现生成用于指导学生模型的良好伪标签(软标签)的目标。为此，来自 AI Research (FAIR)的 Ilija Radosavovic，He 等人提出了数据提取，该方法应用半监督学习，通过利用有限数量的标记数据和互联网规模数量的未标记数据来提高 CNN 在对象检测中的性能。你可以在<a class="ae kv" href="https://arxiv.org/abs/1712.04440" rel="noopener ugc nofollow" target="_blank"> arXiv </a>上轻松找到整篇论文。</p><h1 id="dc20" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据提炼</h1><h2 id="d200" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">数据提炼与知识提炼</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/58cec4a3bbb7ef98195dd1d3903e1daa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38S641PLy26eSTfxFOGHeQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><p id="8944" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">上图比较了数据提取和模型提取(知识蒸馏)的区别。模型提取利用模型 A、B、C 的集合来生成软标签，该软标签随后用于训练学生模型。集合中的每个模型可以大于或等于学生模型。部署模型提取的一种流行方式是独立地训练每个模型，这是耗时且计算效率低的。</p><p id="c496" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">或者，数据提取仅训练一个教师模型 A，然后应用多变换推理来合成伪标签。多变换推理可以被认为有点类似于测试时间增加过程，并且它可以被应用于改善神经网络的性能。多变换推理也是一种简单的方式，既不需要修改损失函数，也不需要改变模型结构。此外，根据单次变换图像上的预测重新训练模型通常不会带来太多的性能改进价值。因此，输入的多个几何变换可以帮助生成用于训练学生模型的良好伪标签。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/94fae0b923944e61ac25065f1c185235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZ1u8hElNg-EOeZjmanBiA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><h2 id="6d61" class="mp kx iq bd ky mq mr dn lc ms mt dp lg lx mu mv li mb mw mx lk mf my mz lm na bi translated">如何进行数据提炼</h2><p id="4881" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">数据提炼包括 4 个主要步骤:</p><ol class=""><li id="4d5b" class="nd ne iq lq b lr mk lu ml lx nf mb ng mf nh mj ni nj nk nl bi translated">根据标记数据训练模型(如监督学习)</li><li id="5f80" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">使用训练好的模型对未标记数据的多次转换进行预测</li><li id="4a2a" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">集合预测以生成未标记数据的伪标记</li><li id="249c" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">在真实标签和伪标签的并集上重新训练模型，直到收敛</li></ol><p id="3314" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">为了澄清，我给出了一个例子，说明如何使用 YOLOv4 为对象检测部署数据提取。</p><ul class=""><li id="abd6" class="nd ne iq lq b lr mk lu ml lx nf mb ng mf nh mj nr nj nk nl bi translated">首先，像常规的监督学习一样，在一组标签数据上训练 YOLOv4。</li><li id="3db5" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated">之后，使用经过训练的 YOLOv4 对未标记数据的多个几何变换进行预测，如下图所示，我应用了一个原始图像、一个翻转版本和一个升级版本，就像测试时增强过程一样。</li><li id="da88" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated">然后，输出将采用加权盒融合(WBF)方法进行处理，您可以在这里应用任何包围盒后处理方法，例如非最大值抑制。我们都知道输出总是包括真阳性、假阳性和假阴性；我们必须为伪标签选择“好的”预测。一种简单但有效的方式是挑选置信度得分高于某个阈值的预测。以及如何选择一个门槛？在这篇论文中，作者利用了一个阈值，使无标签图像中的平均对象数量等于真实标签图像中的平均对象数量。这可能不是在所有情况下都有效，但至少是有效的！</li><li id="0eb0" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated">最后，结合真实标记数据和生成的伪标记数据来重新训练(或微调)YOLOv4 模型。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/ff8483869fa30f541de38bd05638a318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6c_bs3li0EyIZIwM0ChycA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分列的数字</p></figure><h1 id="2a1e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">物体检测的结果</h1><p id="9554" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">文中给出了在基准数据集 COCO 上的数据提取性能。我想总结如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/d6152218b8e5459c4ae752e1a3246ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0GQ3rm66pKMvP9X1TQ9dGA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/32911e13a0f6b93af65e374ac6c747f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2vr2RV8CG1hYLOfyrqpO0A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/74a6d51255be115fbb779b131bd978d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wwef9z03qGkAR1xhr4VzFA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/5819d966caa4b539a9134a52aaa8b75f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W4I2tMorx-INqLBCzFZxFg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/cc2c911f13193863facb54206190d846.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QFPDr70Ve8OtvOMyjxy9rA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的数字</p></figure><p id="3660" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">详细内容可以看<a class="ae kv" href="https://arxiv.org/abs/1712.04440" rel="noopener ugc nofollow" target="_blank">全文</a>。</p><h1 id="f60d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="1533" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这篇文章中，我简要回顾了数据提取，这是一种提高 CNN 性能的半监督学习方法。通过利用未标记数据的多重几何变换，该方法生成可以与人工标记数据相结合的高质量伪标记，以提高神经网络模型的学习效率。数据提取的能力已经在人类关键点检测和物体检测任务的基准数据集上得到验证。</p><p id="ca2f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">欢迎读者访问我的脸书粉丝页面，分享关于机器学习的事情:<a class="ae kv" href="https://www.facebook.com/diveintomachinelearning" rel="noopener ugc nofollow" target="_blank">深入机器学习</a>。更多值得注意的帖子可以在这里找到:</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><ul class=""><li id="5e1d" class="nd ne iq lq b lr mk lu ml lx nf mb ng mf nh mj nr nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/yolov4-5d-an-enhancement-of-yolov4-for-autonomous-driving-2827a566be4a">约洛夫 4–5D 评论</a></li><li id="2b7a" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/darkeras-execute-yolov3-yolov4-object-detection-on-keras-with-darknet-pre-trained-weights-5e8428b959e2">达克拉斯</a></li><li id="58a9" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/efpn-extended-feature-pyramid-network-for-small-object-detection-980af794a093"> EFPN </a></li><li id="ac49" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/data-augmentation-compilation-with-python-and-opencv-b76b1cd500e0">数据增强</a></li><li id="e09e" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj nr nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/synthesize-hazy-foggy-image-using-monodepth-and-atmospheric-scattering-model-9850c721b74e">雾霾数据合成</a></li></ul></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><p id="80e9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">感谢您抽出时间！</p></div></div>    
</body>
</html>