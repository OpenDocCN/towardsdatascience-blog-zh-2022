<html>
<head>
<title>One Line of Code to Accelerate Your Sklearn Algorithms on Big Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一行代码加速您在大数据上的Sklearn算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/one-line-of-code-to-accelerate-your-sklearn-algorithms-on-big-data-9c26190a0dc5#2022-05-06">https://towardsdatascience.com/one-line-of-code-to-accelerate-your-sklearn-algorithms-on-big-data-9c26190a0dc5#2022-05-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a0e2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">英特尔sklearn扩展的推出。让你的随机森林比XGBoost还要快。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ad9c2ca9727d63b8447c2be55005037f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKuJSM0GmY2pW7jm3BvEyQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="99fd" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">介绍</h1><p id="21b7" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">Scikit-learn(又名Sklearn)无疑是当今数据科学中使用最多的Python库之一。然而，用sklearn算法训练一个大数据集有时会很昂贵。当我还在学校的时候，我记得我训练了一个SVC模型一天。我确信我不是唯一一个对这种情况感到沮丧的人。而今天，我要向大家介绍的是sklearnex，这是一个由英特尔AI团队在大约一年前开发的扩展，它最初是daal4py库的一部分。这个扩展有可能将您的sklearn代码加速10-100倍。</p><p id="bbcc" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">根据他们的文档，“Scikit-learn*的英特尔扩展动态修补Scikit-learn估算器，以使用英特尔(R) oneAPI数据分析库作为底层解算器，同时通过使用矢量指令、IA硬件专用内存优化等更快地获得相同的解决方案。在发射时。”他们的团队还声称，它可以将各种sklearn算法的速度提高10到100倍。你不觉得这很疯狂吗？一起来了解一下吧！</p><h1 id="ba65" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">履行</h1><p id="347c" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">要在您的sklearn应用程序上修补它而不更改代码，您可以使用以下命令行:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mo"><img src="../Images/5049c892f419fe1cc43759da7b6f6589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*alaDJJdxYnxZWQoe7eH9Mg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="792a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如果您想在笔记本中直接使用它，您可以执行以下操作:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="f75b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如果您想在特定算法或特定算法列表的基础上修补它，您可以像这样直接在函数中传递名称:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="aeb1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如果您想从您代码中删除它，您可以简单地解包它并重新导入您的sklearn模型，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><h1 id="4a37" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">Sklearn vs. Sklearnex</h1><ul class=""><li id="4b75" class="mr ms iq lp b lq lr lt lu lw mt ma mu me mv mi mw mx my mz bi translated"><em class="na"> RandomForestRegressor </em></li><li id="4c49" class="mr ms iq lp b lq nb lt nc lw nd ma ne me nf mi mw mx my mz bi translated"><em class="na"> SVC </em></li><li id="5818" class="mr ms iq lp b lq nb lt nc lw nd ma ne me nf mi mw mx my mz bi translated"><em class="na"> DBSCAN </em></li><li id="cf0f" class="mr ms iq lp b lq nb lt nc lw nd ma ne me nf mi mw mx my mz bi translated"><em class="na">RandomForestClassifier vs . xgb classifier</em></li></ul><p id="99b0" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">由于硬件的限制，很难复制他们的所有工作，我计划从三个主要的机器学习算法:回归，分类和聚类，将增强版本与原始版本进行比较。</p><p id="cfda" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在我们开始测试之前，让我们导入我们需要的所有包:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><h2 id="9e76" class="ng kw iq bd kx nh ni dn lb nj nk dp lf lw nl nm lh ma nn no lj me np nq ll nr bi translated">随机森林回归量</h2><p id="dd9a" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">第一步:培训</p><p id="0419" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">由于我使用google colab pro来进行这个演示，所以只分配了25G内存供使用。所以我会用10到100K的样本量来测试模型。对于更大的数据，如数百万条以上的记录，只需查看模式就足够了。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="bbf7" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">第二步:收集结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/25766b55319d8d6b1f25cf2c10053368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1vbHTyeJ5ai798wwVSBiOA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="21e4" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">基于输出，我们可以看到性能非常一致，而对于100K个样本，训练速度提高了大约6.5倍。我认为这是机器学习实践的显著增长。</p><p id="cc9c" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">第三步:策划</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/02fefb49178681efe3572b7b9c5ed91e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QYJun0WdbFSecaL3p6R8yg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="8ad0" class="ng kw iq bd kx nh ni dn lb nj nk dp lf lw nl nm lh ma nn no lj me np nq ll nr bi translated">交换虚拟电路</h2><p id="a5b6" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">第一步:培训:</p><p id="a859" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><em class="na">注意:请注意这一部分，最终迭代的培训时间大约需要1小时20分钟。</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="b157" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">由于代码与我用RandomForestRegressor所做的极其相似，我将省略第2步和第3步。结果如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/6d2f0e838b45349a9978f2df63985294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89F8ctC9xk_oJpOgroOs-g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/4010140b9fd40c03158c6871b11c4d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_86NRrDbz7oiDk5wC5-3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="776e" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">到目前为止，SVC在这个演示中表现出了最鲜明的对比。在sklearnex的基础上，我们可以在100K样本的数据集上观察到32倍的速度。由于SVC的耗时问题，我在大多数情况下都放弃了这种算法，尽管它具有独特的算法唯一性。然而，随着sklearnex的增强，我认为SVC将开始获得更多的关注。</p><h2 id="43ee" class="ng kw iq bd kx nh ni dn lb nj nk dp lf lw nl nm lh ma nn no lj me np nq ll nr bi translated">基于密度的噪声应用空间聚类</h2><p id="0181" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">第一步:培训:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="2558" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/2a70bf52e125a8e32afc55f3da397c90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZsxGvqtDY7mTuN98PIAoQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/d02bdda5978156db1615ed746e08dbea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unLOd2NStNkoAYFzmJodmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="6d25" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">根据英特尔的文档，他们的扩展可以帮助DBSCAN在具有50万个样本和50个特征的数据集上速度提高322倍。然而，我的google colab会因为DBSCAN的样本量大于80K而崩溃，所以我无法复制这个数字。根据我所能得到的，在sklearnex的帮助下，DBSCAN平均快了1.25倍。</p><h2 id="5d43" class="ng kw iq bd kx nh ni dn lb nj nk dp lf lw nl nm lh ma nn no lj me np nq ll nr bi translated">RandomForest vs. XGBoost</h2><p id="74a5" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">对于许多数据科学项目，我们已经看到人们选择XGBoost而不是Random Forest。这种决策涉及许多权衡，当然，在大型数据集上的训练时间就是其中之一。所以我要给你看一些真正令人兴奋的东西:</p><p id="9e1f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">第一步:培训</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/7f40c3f691e1435ee418a62c71d7280c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l48EyABd1Ueguu8z_y0Vgg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者代码</p></figure><p id="7e7b" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/20d0afb89a8692a743d961df1f4b2c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkBmh4T9KbMVbZj1Jc7t4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0bd9" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><em class="na">注:</em></p><p id="59d0" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><em class="na"> Spped_X_RR是原始随机森林与带扩展的随机森林的训练时间的比较</em></p><p id="e9ec" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><em class="na"> Spped_X_RX是XGBoost在扩展为</em>的随机森林上的训练时间比较</p><p id="7fe3" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><em class="na"> Spped_X_RR是原始随机森林的训练时间与XGBoost的比较</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/dbc009a068b0eb76ca64813afd22754b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ce7VaVbMBggC8R3ciYjUmw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="fb3a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">根据结果，我们可以看到，在10K和100K的给定数据集上，增强的随机森林分类器比xgb分类器分别快大约3.5倍。</p><p id="dd30" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">你可以在这里找到完整的代码:<a class="ae oa" href="https://github.com/jinhangjiang/Medium_Demo/blob/main/Intel_Sklearn/Intel_Extension_for_Sklearn.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/Jin hangjiang/Medium _ Demo/blob/main/Intel _ sk learn/Intel _ Extension _ for _ sk learn . ipynb</a></p><h1 id="092d" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">结论</h1><p id="62b7" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">鉴于这一英特尔扩展实现的简单性，我相信它可以应用于数据科学中非常大范围的项目。特别是，鉴于有限的测试结果，我们可以清楚地观察到这个扩展的可伸缩性。总结一下，就这么简单:数据越大，性能越好。您可以在这里找到英特尔进行的完整比较的详细信息:<a class="ae oa" href="https://intel.github.io/scikit-learn-intelex/acceleration.html" rel="noopener ugc nofollow" target="_blank">https://Intel . github . io/sci kit-learn-intelex/acceleration . html</a>。</p><p id="37b3" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">当然，目前这个扩展有一些限制。例如，扩展不支持随机森林和K近邻的多输出和稀疏数据。更多详情，请查看这里:<a class="ae oa" href="https://intel.github.io/scikit-learn-intelex/algorithms.html" rel="noopener ugc nofollow" target="_blank">https://Intel . github . io/sci kit-learn-intelex/algorithms . html</a>。</p><p id="d22d" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated"><strong class="lp ir"> <em class="na">请随时与我联系</em></strong><a class="ae oa" href="https://www.linkedin.com/in/jinhangjiang/" rel="noopener ugc nofollow" target="_blank"><strong class="lp ir"><em class="na">LinkedIn</em></strong></a><strong class="lp ir"><em class="na">。</em>T15】</strong></p><h1 id="468b" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">参考</h1><p id="3841" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">英特尔公司。(2021).Scikit-learn* 2021.5文档的英特尔扩展。<a class="ae oa" href="https://intel.github.io/scikit-learn-intelex/blogs.html" rel="noopener ugc nofollow" target="_blank">https://intel.github.io/scikit-learn-intelex/blogs.html</a></p><p id="d7d8" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">Smirnov，E. (2021)借助英特尔Scikit-learn扩展节省时间和资金。<a class="ae oa" href="https://medium.com/intel-analytics-software/save-time-and-money-with-intel-extension-for-scikit-learn-33627425ae4" rel="noopener">https://medium . com/Intel-analytics-software/save-time-and-money-with-Intel-extension-for-scikit-learn-33627425 ae4</a></p></div></div>    
</body>
</html>