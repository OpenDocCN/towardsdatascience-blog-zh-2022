<html>
<head>
<title>Learning to Rank: A Complete Guide to Ranking using Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习排序:使用机器学习的排序完全指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4#2022-02-28">https://towardsdatascience.com/learning-to-rank-a-complete-guide-to-ranking-using-machine-learning-4c9688d370d4#2022-02-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/3289e8411246fe5e4ede89ed189d47ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2oK2SifPRPRE4nFSA5FMA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/s/photos/library?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kc" href="https://unsplash.com/@jannerboy62?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">尼克·费因斯</a>拍摄</p></figure><h1 id="efd9" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">排名:什么和为什么？</h1><p id="82a2" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇文章中，通过“<strong class="ld ir">排名</strong>，我们指的是<strong class="ld ir">通过相关性</strong>对文档进行排序，以找到与查询相关的感兴趣的内容<strong class="ld ir">。这是<a class="ae kc" href="https://en.wikipedia.org/wiki/Information_retrieval" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">信息检索</strong> </a>的一个基本问题，但这个任务在许多其他应用中也会出现:</strong></p><ol class=""><li id="411b" class="lz ma iq ld b le mb li mc lm md lq me lu mf ly mg mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Search_engine" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">搜索引擎</strong> </a> <strong class="ld ir"> </strong> —给定一个用户简介(位置、年龄、性别……)一个文本查询，按相关性对网页结果进行排序。</li><li id="9444" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mg mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Recommender_system" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">推荐系统</strong></a>——给定一个用户简档和购买历史，对其他项目进行排序，为用户找到新的潜在感兴趣的产品。</li><li id="e0e9" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mg mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Travel_agency" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">旅行社</strong> </a> —给定一个用户配置文件和过滤器(入住/退房日期、旅行者的数量和年龄等)，根据相关性对可用房间进行排序。</li></ol><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/2d893f37eab4614373df04b286f06468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4MqXSXWyjCcjpdW9tD3Og.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">排名应用:1)搜索引擎；2)推荐系统；3)旅行社。(图片由作者提供)</p></figure><p id="68e4" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">排名模型通常通过为每个输入预测一个<strong class="ld ir">相关性分数<em class="mx">s = f</em>(<em class="mx">x</em>)</strong>x=(<em class="mx">q，d </em> ) 来工作，其中<strong class="ld ir"> <em class="mx"> q </em> </strong> <strong class="ld ir">是一个</strong> <strong class="ld ir">查询</strong>并且<em class="mx"> d </em>  <strong class="ld ir">是一个文档一旦我们有了每个文档的相关性，我们就可以根据这些分数对文档进行排序(即排名)。</strong></p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/0714545e429c76703a884c5dd9d3b23e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gX8d-0eerlTHEAv716QC8Q.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">排名模型依赖于评分函数。(图片由作者提供)</p></figure><p id="accf" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">可以使用各种方法实现评分模型。</p><ul class=""><li id="910c" class="lz ma iq ld b le mb li mc lm md lq me lu mf ly mz mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Vector_space_model" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">向量空间模型</strong></a>——为每个查询和文档计算一个向量嵌入(例如使用<a class="ae kc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> Tf-Idf </a>或<a class="ae kc" href="https://arxiv.org/abs/1908.10084" rel="noopener ugc nofollow" target="_blank"> BERT </a>，然后计算相关性得分<strong class="ld ir"><em class="mx">f</em>(<em class="mx">x</em>)<em class="mx">= f</em>(<em class="mx">q，d </em> ) </strong>作为<strong class="ld ir"> <em class="mx"> q </em>的向量嵌入之间的余弦相似度</strong></li><li id="1c54" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Learning_to_rank" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">学习排名</strong></a><strong class="ld ir"/>–评分模型是一种机器学习模型，它在某种排名损失最小化的训练阶段，在给定输入<strong class="ld ir"><em class="mx">×T38】=(<em class="mx">q，d </em> ) </em></strong>的情况下，学习预测得分<strong class="ld ir"> <em class="mx"> s </em> </strong>。</li></ul><p id="6b8b" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">在本文中，我们关注后一种方法，我们展示了如何实现用于学习排名的<strong class="ld ir">机器学习模型。</strong></p><h1 id="b404" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">评估指标排名</h1><p id="287f" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在分析学习排名的各种 ML 模型之前，我们需要定义使用哪些度量来评估排名模型。这些度量是对排名的<strong class="ld ir">预测文档进行计算的，即第<strong class="ld ir"> <em class="mx"> k- </em>个最高检索文档</strong>是具有最高预测分数<strong class="ld ir"> <em class="mx"> s </em> </strong>的第<em class="mx"> k </em>个文档。</strong></p><h2 id="8788" class="na ke iq bd kf nb nc dn kj nd ne dp kn lm nf ng kr lq nh ni kv lu nj nk kz nl bi translated">平均精度</h2><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/908d1172ce69a60ac946ca1d8cc2595b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I_Ab19M4GKj2PrtJaZ_Nuw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">地图-平均精度。(图片由作者提供)</p></figure><p id="8249" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Mean_average_precision" rel="noopener ugc nofollow" target="_blank">平均精度</a>用于<strong class="ld ir">二元相关</strong>的任务，即当一个文档<em class="mx"> d </em>的真实分数<em class="mx"> y </em>只能是<strong class="ld ir"> 0 ( <em class="mx">不相关</em>或 1 ( <em class="mx">相关</em> ) </strong>时。</p><p id="b2e1" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">对于给定的查询<em class="mx"> q </em>和相应的文档<em class="mx">d</em>=<em class="mx">t5】{<em class="mx">d</em>₁、…，<em class="mx"> dₙ </em> }，我们检查前<em class="mx"> k </em>个检索到的文档中有多少是相关的(<em class="mx"> y </em> =1)或不相关的(<em class="mx"> y= </em> 0)。为了计算<strong class="ld ir">精度</strong> P <em class="mx"> ₖ </em>和<strong class="ld ir">召回</strong> R <em class="mx"> ₖ </em>。对于<em class="mx"> k = </em> 1… <em class="mx"> n </em>，我们得到不同的 P <em class="mx"> ₖ </em>和</em> R <em class="mx"> ₖ </em>值，它们定义了<strong class="ld ir">精度-召回曲线</strong>:这条曲线下的面积就是<strong class="ld ir">平均精度(AP) </strong>。</p><p id="5b2a" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">最后，通过计算一组<em class="mx"> m </em>查询的 AP 值的平均值，我们获得了<strong class="ld ir">平均精度(MAP) </strong>。</p><h2 id="693b" class="na ke iq bd kf nb nc dn kj nd ne dp kn lm nf ng kr lq nh ni kv lu nj nk kz nl bi translated">贴现累计收益(DCG)</h2><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/95ac5bd375efc5d1246fcfd978542f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a8eRGOleBZYqehb-SNLCZw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">DCG——贴现累积收益。(图片由作者提供)</p></figure><p id="84ae" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain" rel="noopener ugc nofollow" target="_blank">折扣累积收益</a>用于<strong class="ld ir">分级相关</strong>的任务，即当文档<em class="mx"> d </em>的真实得分<em class="mx"> y </em>是衡量查询<em class="mx"> q </em>相关度的尺度中的离散值时。一个典型的尺度是<strong class="ld ir"> 0 ( <em class="mx">差</em>)、1 ( <em class="mx">一般</em>)、2 ( <em class="mx">好</em>)、3 ( <em class="mx">优秀</em>)、4 ( <em class="mx">完美</em> ) </strong>。</p><p id="4519" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">对于一个给定的查询<em class="mx"> q </em>和相应的文档<em class="mx">d</em>=<em class="mx"/>{<em class="mx">d</em>₁、…、<em class="mx"> dₙ </em> }，我们考虑第<em class="mx"> k </em>个顶部检索到的文档。增益 gₖ=2^<em class="mx">yₖ</em>–1 衡量这个文档有多有用(我们想要相关性高的文档！)，而<strong class="ld ir">折扣</strong>d<em class="mx">ₖ=</em>1/log(<em class="mx">k</em>+1)惩罚以较低等级检索的文档(我们希望相关文档在最高等级！).</p><p id="4503" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated"><strong class="ld ir">贴现收益</strong>项 g<em class="mx">ₖ</em>d<em class="mx">ₖ</em>for<em class="mx">k =</em>1…<em class="mx">n</em>之和就是<strong class="ld ir">贴现累计收益(DCG) </strong>。为了确保这个分数在 0 和 1 之间，我们可以用测量的 DCG 除以理想的分数 IDCG，如果我们用真实值<em class="mx"> yₖ </em>对文档进行排序，就会得到理想的分数 idcg。这给了我们<strong class="ld ir">归一化贴现累积收益(NDCG) </strong>，其中 NDCG = DCG/IDCG。</p><p id="c176" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">最后，对于 MAP，我们通常计算一组<em class="mx"> m </em>查询的 DCG 或 NDCG 值的平均值来获得一个平均值。</p><h1 id="76cc" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">用于学习排序的机器学习模型</h1><p id="e162" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了建立一个用于排名的机器学习模型，我们需要定义<strong class="ld ir">输入</strong>、<strong class="ld ir">输出</strong>和<strong class="ld ir">损失函数</strong>。</p><ul class=""><li id="b578" class="lz ma iq ld b le mb li mc lm md lq me lu mf ly mz mh mi mj bi translated"><strong class="ld ir">输入</strong>–对于一个查询<strong class="ld ir"> <em class="mx"> q </em> </strong>我们有<strong class="ld ir"> <em class="mx"> n </em> </strong>个文档<strong class="ld ir"><em class="mx">d</em>=<em class="mx"/>{<em class="mx">d</em></strong>₁、…、<strong class="ld ir"><em class="mx">d</em></strong><em class="mx">ₙ</em><strong class="ld ir">}</strong>按相关性进行排序。元素<strong class="ld ir"><em class="mx"/>=(<em class="mx">q</em>，<em class="mx"> dᵢ </em> ) </strong>是我们模型的输入。</li><li id="29a0" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><strong class="ld ir">输出</strong>–对于一个查询文档输入<em class="mx"> xᵢ </em> = ( <em class="mx"> q </em>，<em class="mx"> dᵢ </em>)，我们假设存在一个真实的<strong class="ld ir">相关性得分<em class="mx">yᵢ</em>t51】。我们的模型输出一个<strong class="ld ir">预测分数</strong><strong class="ld ir"><em class="mx">sᵢ= f</em>(<em class="mx">xᵢ</em>)</strong><em class="mx">。</em></strong></li></ul><p id="e6e4" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">所有的学习排序模型都使用一个基本的机器学习模型(例如<a class="ae kc" href="https://en.wikipedia.org/wiki/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">决策树</a>或<a class="ae kc" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank">神经网络</a>)来计算<em class="mx">s</em>=<em class="mx">f</em>(<em class="mx">x</em>)。选择<strong class="ld ir">损失函数</strong>是学习排列模型的独特元素。一般来说，我们有<strong class="ld ir"> 3 种方法</strong>，这取决于损失是如何计算的。</p><ol class=""><li id="f3ba" class="lz ma iq ld b le mb li mc lm md lq me lu mf ly mg mh mi mj bi translated"><strong class="ld ir">逐点法</strong>——总损失计算为各文件<strong class="ld ir">上定义的损失项之和<em class="mx">dᵢ</em>t81】(因此<strong class="ld ir">t83】逐点 t85)作为预测得分<strong class="ld ir"> <em class="mx"> sᵢ </em> </strong>和地面真实值<strong class="ld ir"> <em class="mx"> yᵢ </em> </strong>，对于<em class="mx"> i= </em> 1 通过这样做，我们将我们的任务转化为一个<strong class="ld ir">回归问题，</strong>其中我们训练一个模型来预测<em class="mx"> y. </em></strong></strong></li><li id="94fe" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mg mh mi mj bi translated"><strong class="ld ir">成对方法</strong>——总损失计算为每对单据<strong class="ld ir">上定义的损失条款之和<em class="mx"> dᵢ、</em> </strong> <em class="mx"> </em>(因此<strong class="ld ir"> <em class="mx">成对</em> </strong>)，对于<em class="mx"> i，j= </em> 1… <em class="mx"> n </em>。训练模型的目的是预测<strong class="ld ir"> <em class="mx"> yᵢ &gt; yⱼ </em> </strong>是否相关，即两个文档中哪一个更相关。通过这样做，我们将我们的任务转化为一个<strong class="ld ir">二元分类问题</strong>。</li><li id="1c41" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mg mh mi mj bi translated"><strong class="ld ir">列表方式</strong>——直接在整个文档列表上计算损失(因此<strong class="ld ir"> <em class="mx">列表方式</em> </strong>),具有相应的预测等级。这样，排名指标可以更直接地纳入损失。</li></ol><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/26cea9c7a4b8683e526a20bd4e08c623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s3CQuNRWcQNkQKd8Met-MA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">学习排序的机器学习方法:逐点，成对，列表。(图片由作者提供)</p></figure><h2 id="d3bd" class="na ke iq bd kf nb nc dn kj nd ne dp kn lm nf ng kr lq nh ni kv lu nj nk kz nl bi translated">逐点方法</h2><p id="0d08" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">逐点法是最容易实现的方法，也是第一个被提出来学习任务排序的方法。损失直接测量地面真实分数<strong class="ld ir"><em class="mx"/></strong>和预测的<strong class="ld ir"><em class="mx">【sᵢ】</em></strong>之间的距离，因此我们通过有效地解决回归问题来处理这个任务。例如，<a class="ae kc" href="https://link.springer.com/chapter/10.1007/11776420_44" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">子集排序</strong> </a>使用了<a class="ae kc" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差(MSE) </a>损失。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/ea4dc2e4b93fbf3d8b7d1d6ab6025524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h8zgsEZCktLerxfkY51bQA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">子集排序中逐点方法的 MSE 损失。(图片由作者提供)</p></figure><h2 id="726b" class="na ke iq bd kf nb nc dn kj nd ne dp kn lm nf ng kr lq nh ni kv lu nj nk kz nl bi translated">成对方法</h2><p id="4887" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">逐点模型的主要问题是需要真实的相关性分数来训练模型。但是在许多场景中，训练数据仅可用于<strong class="ld ir">的部分信息，例如，我们仅知道用户选择了文档列表中的哪个文档(因此<em class="mx">与</em>更相关)，但是我们不知道这些文档中的与<em class="mx">有多相关！</em></strong></p><p id="f8b0" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">由于这个原因，成对方法不能与绝对相关性一起工作。相反，他们使用<strong class="ld ir">相对偏好</strong>:给定两个文档，我们想要预测第一个文档是否比第二个更相关。这样，我们解决了一个<strong class="ld ir">二元分类任务</strong>，其中我们只需要基本事实<em class="mx"> yᵢⱼ </em> ( <em class="mx"> = </em> 1 如果<em class="mx"> yᵢ &gt; yⱼ </em>，否则为 0)，并且我们使用<a class="ae kc" href="https://en.wikipedia.org/wiki/Logistic_function" rel="noopener ugc nofollow" target="_blank">逻辑函数</a>:<em class="mx">sᵢⱼ</em>=σ(<em class="mx">sᵢ–sⱼ</em>)将模型输出映射到概率。这种方法最早由<a class="ae kc" href="https://icml.cc/Conferences/2015/wp-content/uploads/2015/06/icml_ranking.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> RankNet </strong> </a>使用，其中使用了<a class="ae kc" href="https://en.wikipedia.org/wiki/Cross_entropy" rel="noopener ugc nofollow" target="_blank">二进制交叉熵【BCE】</a>损失。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/b6c0167838edc48f4be383c528d24ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnqFlRq7aYN8szI52jS0MA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">RankNet 中成对方法的 BCE 损失。(图片由作者提供)</p></figure><p id="7e42" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">RankNet 是对逐点方法的改进，但在训练期间所有文档仍然被赋予相同的重要性，而我们希望给予排名更高的文档更多的重要性(正如 DCG 度量对折扣条款所做的那样)。</p><p id="93c6" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">不幸的是，排序信息只有在排序后才可用，而且排序是不可微的。然而，要运行<a class="ae kc" href="https://en.wikipedia.org/wiki/Gradient_descent" rel="noopener ugc nofollow" target="_blank">梯度下降</a>优化，我们不需要损失函数，我们只需要它的梯度！<a class="ae kc" href="https://www.microsoft.com/en-us/research/publication/learning-to-rank-with-non-smooth-cost-functions/" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">λrank</strong></a>定义了隐式损失函数的梯度，使得等级高的文档具有大得多的梯度:</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/bb7e231460890bb0e59ada4d270ad1a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BFTD0koJ-AbNNQd2TOd92w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">如 LambdaRank 中的隐式损失函数的梯度。(图片由作者提供)</p></figure><p id="e787" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">拥有渐变也足以构建一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">渐变提升</a>模型。这就是<a class="ae kc" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">λmart</strong></a><strong class="ld ir"/>使用的思想，产生了比用 than 更好的结果。</p><h2 id="3af3" class="na ke iq bd kf nb nc dn kj nd ne dp kn lm nf ng kr lq nh ni kv lu nj nk kz nl bi translated">列表式方法</h2><p id="8ef1" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">逐点和成对方法将排序问题转化为代理回归或分类任务。相反，列表式方法通过最大化评估指标更直接地解决问题<strong class="ld ir">。</strong></p><p id="a48a" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">直观上，这种方法<strong class="ld ir">应该给出最好的结果</strong>，因为关于排名的信息被充分利用并且 NDCG 被直接优化。但是设置<strong class="ld ir">loss = 1–ndcg</strong>的一个明显问题是，计算折扣 Dₖ所需的排名信息只有在根据预测分数对<strong class="ld ir"> </strong>文档进行<strong class="ld ir"> </strong>排序后才可用，而<strong class="ld ir">排序</strong> <strong class="ld ir">是不可微的</strong>。我们如何解决这个问题？</p><p id="60a7" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">第一种<strong class="ld ir">方法</strong>是使用迭代方法，其中<strong class="ld ir">排名度量用于在每次迭代中重新加权</strong>实例。这是由<a class="ae kc" href="https://www.microsoft.com/en-us/research/publication/learning-to-rank-with-non-smooth-cost-functions/" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">λrank</strong></a><strong class="ld ir"/>和<a class="ae kc" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">λmart</strong></a>使用的方法，它们确实介于成对方法和列表方法之间。</p><p id="2e0b" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated"><strong class="ld ir">第二种方法</strong>是逼近目标使其可微，这是<a class="ae kc" href="https://www.researchgate.net/publication/221520227_SoftRank_optimizing_non-smooth_rank_metrics" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> SoftRank </strong> </a>背后的思想。不是预测一个确定性的分数<em class="mx">s</em>=<em class="mx">f</em>(<em class="mx">x</em>)，而是预测一个<strong class="ld ir">平滑的概率分数</strong><em class="mx">s ~</em>𝒩(<em class="mx">f</em>(<em class="mx">x</em>)，<em class="mx"> σ </em>)。<strong class="ld ir">排名<em class="mx"> k </em> </strong> <em class="mx"> </em>是<strong class="ld ir">预测得分<em class="mx"> s </em> </strong>的非连续函数，但是由于平滑化，我们可以计算每个文档排名的<strong class="ld ir">概率分布。最后，我们优化<strong class="ld ir"> SoftNDCG </strong>，这是一个平滑函数，它是这个秩分布的期望 NDCG。</strong></p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/d2b2e578ef2c8d592393462620630573.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MqY4bnrcmOVhHKBg5LsBCA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">分数的不确定性导致了 SoftRank 的平滑损失。(图片由作者提供)</p></figure><p id="51a3" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">第三种方法被认为是每个排序列表对应于一个排列，并定义排列空间上的<strong class="ld ir">损失</strong>。在<a class="ae kc" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> ListNet </strong> </a>中，给定一个分数列表<em class="mx"> s </em>我们使用<a class="ae kc" href="https://en.wikipedia.org/wiki/Discrete_choice#J._Exploded_logit" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> Plackett-Luce 模型</strong> </a>定义任何排列的概率。<strong class="ld ir"> </strong>然后，我们的损失很容易计算为置换空间上真实和预测的<strong class="ld ir">概率分布之间的<strong class="ld ir">二元交叉熵距离</strong>。</strong></p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/861637b0705211505d7569318875bb7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulNdD-rW6OF0x46sPg5jqw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">ListNet 中 Plackett-Luce 模型各种排列的概率。(图片由作者提供)</p></figure><p id="4aa9" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">最后，<a class="ae kc" href="https://research.google/pubs/pub47258.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="ld ir">lambda loss</strong></a><strong class="ld ir"/>论文对这个问题引入了一个新的视角，并创建了一个<strong class="ld ir">广义框架</strong>来定义新的列表式损失函数并实现<strong class="ld ir">最先进的精度</strong>。其主要思想是以一种严格和通用的方式将问题框架化，作为一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Mixture_model" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">混合模型</strong> </a>，其中排序列表<em class="mx"> π </em>被视为一个隐藏变量。然后，损失被定义为该模型的负对数似然。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/f98c82fb18906cb1227b44c9ca59f302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zj5QvE_HkcKrkOrr96Mq4w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">loss 损失函数。(图片由作者提供)</p></figure><p id="f6c0" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">LambdaLoss 框架的作者证明了两个基本结果。</p><ol class=""><li id="48e9" class="lz ma iq ld b le mb li mc lm md lq me lu mf ly mg mh mi mj bi translated">所有其他列表式方法(RankNet、LambdaRank、SoftRank、ListNet、…)都是这个通用框架的<strong class="ld ir">特殊配置</strong>。的确，他们的损失是通过准确选择<strong class="ld ir">似然</strong> <strong class="ld ir"> <em class="mx"> p </em> ( <em class="mx"> y | s，π </em> ) </strong>和<strong class="ld ir">排序列表分布<em class="mx"> p </em> ( <em class="mx"> π | s </em> ) </strong>得到的。</li><li id="3759" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mg mh mi mj bi translated">这个框架允许我们定义度量驱动的损失函数，直接连接到我们想要优化的排名度量。这有助于<strong class="ld ir">显著提高任务排序的学习水平。</strong></li></ol><h1 id="ecd4" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="ffa0" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">从信息检索到推荐系统和旅游预订，排名问题无处不在。像 MAP 和 NDCG 这样的评估指标同时考虑了检索文档的排名和相关性，因此很难直接优化。</p><p id="e406" class="pw-post-body-paragraph lb lc iq ld b le mb lg lh li mc lk ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">学习排序方法使用机器学习模型来预测文档的相关性分数，并被分为 3 类:点方式、成对方式、列表方式。在大多数排序问题上，列表式方法如 LambdaRank 和广义框架 LambdaLoss 达到了最先进的水平。</p><h1 id="31ea" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h1><ul class=""><li id="383e" class="lz ma iq ld b le lf li lj lm np lq nq lu nr ly mz mh mi mj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Learning_to_rank" rel="noopener ugc nofollow" target="_blank">维基百科关于“学习排名”的页面</a></li><li id="f867" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated">【李，】号杭。“学习排名的简短介绍。” 2011 年</li><li id="3042" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="https://web.archive.org/web/20170808044438/http://wwwconference.org/www2009/pdf/T7A-LEARNING%20TO%20RANK%20TUTORIAL.pdf" rel="noopener ugc nofollow" target="_blank">铁岩。“学习信息检索排序”，2009 年</a></li><li id="57b0" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="http://didawiki.di.unipi.it/lib/exe/fetch.php/magistraleinformatica/ir/ir13/1_-_learning_to_rank.pdf" rel="noopener ugc nofollow" target="_blank">李铁岩《学会排名》，</a> 2009</li><li id="e324" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="https://research.google/pubs/pub47258/" rel="noopener ugc nofollow" target="_blank"> X .王《排名度量优化的 LambdaLoss 框架》，2018 </a></li><li id="18cb" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf" rel="noopener ugc nofollow" target="_blank">曹志，“学习排序:从两两法到列表法”，2007 </a></li><li id="f87a" class="lz ma iq ld b le mk li ml lm mm lq mn lu mo ly mz mh mi mj bi translated"><a class="ae kc" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/SoftRankWsdm08Submitted.pdf" rel="noopener ugc nofollow" target="_blank">M . Taylor，“软排名:优化非平滑排名指标”，2008 年</a></li></ul></div></div>    
</body>
</html>