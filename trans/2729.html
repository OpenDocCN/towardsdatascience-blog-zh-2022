<html>
<head>
<title>Deploy Your ML Model as a Web Service in Minutes Using GCP’s Cloud Run</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GCP的云在几分钟内将您的ML模型部署为Web服务</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-your-ml-model-as-a-web-service-in-minutes-using-gcps-cloud-run-ee9d433d8787#2022-06-13">https://towardsdatascience.com/deploy-your-ml-model-as-a-web-service-in-minutes-using-gcps-cloud-run-ee9d433d8787#2022-06-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7711" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用GCP全面管理的无服务器服务分享您的ML模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9f5fd3b875c0db24183f84466fe250bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BM181AvA8yspIVEA6_phyg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">约翰-马克·史密斯在<a class="ae kv" href="https://unsplash.com/backgrounds/colors?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="39f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型部署是ML项目生命周期中的关键步骤。有多种方式可以做到这一点，无论是在批处理或流处理管道或作为一个web服务。最后一个选项是本文的重点，我们将部署一个ML模型到Cloud run，这是Google Cloud提供的一个服务，用于以无服务器的方式部署应用程序。</p><p id="c39b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我们将分三步从一个项目想法到一个部署的服务:</p><ul class=""><li id="3120" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">建立一个预测模型。</li><li id="d42f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">将模型打包成dockerized服务。</li><li id="c62a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">部署到GCP。</li></ul><p id="0754" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的代码可以在这里找到:【https://github.com/CVxTz/gcp_model_deploy_example T4】</p><h1 id="1cbb" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">构建模型</h1><p id="98b0" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">首先，我们需要设置我们的Python开发环境。<br/>我更喜欢使用Anaconda来创建新的虚拟环境:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="3bb4" class="ni mh iq ne b gy nj nk l nl nm">conda create --name gcp_model_deploy python==3.8<br/>conda activate gcp_model_deploy</span></pre><p id="65e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，为了管理项目依赖，我使用了<strong class="ky ir">诗歌</strong>。你可以在这里找到如何在你的系统上安装它:<a class="ae kv" href="https://python-poetry.org/docs/" rel="noopener ugc nofollow" target="_blank">https://python-poetry.org/docs/</a>。这是一个非常酷的工具，它可以帮助我们定义python项目的依赖性，同时避免pip的一些缺点，例如有限的依赖性冲突解决方案。</p><p id="b040" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在克隆了上面链接的存储库并创建了虚拟环境之后，我们可以使用以下命令安装项目的所有依赖项:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="ab4c" class="ni mh iq ne b gy nj nk l nl nm">poetry install</span></pre><p id="3149" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，由于这个项目的重点不是集中在模型部分，我们将使用来自<strong class="ky ir"> SpaCy </strong>的预训练的<strong class="ky ir"> NER </strong>模型来检测句子中的实体。我们将SpaCy和“<strong class="ky ir"> en_core_web_md </strong>”模型添加到我们的诗歌依赖关系中，这样我们就可以将该模型应用于如下句子:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="9c40" class="ni mh iq ne b gy nj nk l nl nm">import spacy<br/><br/>NLP = spacy.load("en_core_web_md")<br/><br/><br/>def predict_entities(text):<br/><br/>    doc = NLP(text)<br/><br/>    entities = [<br/>        {<br/>            "text": entity.text,<br/>            "label": entity.label_,<br/>            "start_idx": entity.start_char,<br/>            "end_idx": entity.end_char,<br/>        }<br/>        for entity in doc.ents<br/>    ]<br/><br/>    return entities</span></pre><p id="ec03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，对于这句话:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="d2e8" class="ni mh iq ne b gy nj nk l nl nm">On Halloween, Gotham City mayor Don Mitchell Jr. is murdered by a masked psychopath calling himself the Riddler.</span></pre><p id="7f7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">预测函数</strong>将返回以下内容:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="305e" class="ni mh iq ne b gy nj nk l nl nm">[<br/>    {<br/>        "text": "Halloween",<br/>        "label": "<strong class="ne ir">DATE</strong>",<br/>        "start_idx": 3,<br/>        "end_idx": 12<br/>    },<br/>    {<br/>        "text": "Gotham City",<br/>        "label": "<strong class="ne ir">GPE</strong>",<br/>        "start_idx": 14,<br/>        "end_idx": 25<br/>    },<br/>    {<br/>        "text": "Don Mitchell Jr.",<br/>        "label": "<strong class="ne ir">PERSON</strong>",<br/>        "start_idx": 32,<br/>        "end_idx": 48<br/>    },<br/>    {<br/>        "text": "Riddler",<br/>        "label": "<strong class="ne ir">PERSON</strong>",<br/>        "start_idx": 104,<br/>        "end_idx": 111<br/>    }<br/>]</span></pre><p id="d869" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在已经完成了模型部分！</p><h1 id="3cd3" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">将模型打包成一个dockerized服务</h1><h2 id="71d3" class="ni mh iq bd mi nn no dn mm np nq dp mq lf nr ns ms lj nt nu mu ln nv nw mw nx bi translated">该服务:</h2><p id="8d79" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们将把预测函数包装成一个<strong class="ky ir"> FastApi </strong>端点。</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="d3c2" class="ni mh iq ne b gy nj nk l nl nm">@app.post("/predict/", response_model=Response)<br/>def create_item(in_query: Query):<br/>    entities = predict_entities(in_query.text)<br/><br/>    return Response(text=in_query.text, entities=[Entity(**x) for x in entities])</span></pre><p id="b9e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，要获得预测，我们只需要调用/predict/ endpoint。<br/>本地运行API可以从项目根目录使用以下命令来完成:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="84fd" class="ni mh iq ne b gy nj nk l nl nm">poetry run uvicorn --app-dir ner_app app:app --host 0.0.0.0 --port 8080 --workers 2</span></pre><p id="fa78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者运行“make run_app”</p><p id="4c8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以在<a class="ae kv" href="http://0.0.0.0:8080/docs" rel="noopener ugc nofollow" target="_blank"> http://0.0.0.0:8080/docs </a>访问API的swagger页面</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/423f847cfcc56ea2275c3fced9f8b6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vk3cuP-K3-WlaSJ0V9cGQw.png"/></div></div></figure><p id="b7fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步是将这个应用程序打包成docker映像，这样我们就可以在任何地方运行它。</p><h2 id="7f92" class="ni mh iq bd mi nn no dn mm np nq dp mq lf nr ns ms lj nt nu mu ln nv nw mw nx bi translated">码头工人:</h2><p id="7ec3" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们将使用<strong class="ky ir"> python:3.8-slim </strong>作为我们的基础映像，然后运行一个两阶段构建，以便最终得到一个更小的映像大小:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="3c59" class="ni mh iq ne b gy nj nk l nl nm">FROM python:3.8-slim as <em class="nz">builder<br/><br/></em>WORKDIR "/app"<br/><br/>ENV <em class="nz">PYTHONFAULTHANDLER</em>=1 \<br/>    <em class="nz">PYTHONHASHSEED</em>=random \<br/>    <em class="nz">PYTHONUNBUFFERED</em>=1<br/><br/>ENV <em class="nz">PIP_DEFAULT_TIMEOUT</em>=100 \<br/>    <em class="nz">PIP_DISABLE_PIP_VERSION_CHECK</em>=1 \<br/>    <em class="nz">PIP_NO_CACHE_DIR</em>=1 \<br/>    <em class="nz">POETRY_VERSION</em>=1.1.13<br/><br/><br/>RUN pip install "poetry==$<em class="nz">POETRY_VERSION</em>"<br/>RUN python -m venv /venv<br/><br/>COPY pyproject.toml poetry.lock ./<br/>COPY ner_app ner_app<br/><br/>RUN . /venv/bin/activate &amp;&amp; poetry install --no-dev --no-root<br/>RUN . /venv/bin/activate &amp;&amp; poetry build<br/><br/>FROM python:3.8-slim as <em class="nz">final<br/><br/></em>WORKDIR "/app"<br/><br/>COPY --from=<em class="nz">builder </em>/venv /venv<br/>COPY --from=<em class="nz">builder </em>/app/dist .<br/>COPY ner_app ner_app<br/><br/>RUN . /venv/bin/activate &amp;&amp; pip install *.whl<br/><br/>CMD ["/venv/bin/python", "-m", "uvicorn", "--app-dir", "ner_app", "app:app", "--host", "0.0.0.0", "--port", "5000", "--workers", "2"]</span></pre><p id="f6fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一阶段构建python虚拟环境，第二阶段只是复制它并使用它来运行API。</p><p id="f7ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以使用以下内容构建映像:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="fa0d" class="ni mh iq ne b gy nj nk l nl nm">docker build . -t ner_app:0.0.1</span></pre><p id="d7c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后使用以下命令运行它:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="73d1" class="ni mh iq ne b gy nj nk l nl nm">docker run -p 5000:5000 -i -t ner_app:0.0.1</span></pre><p id="2c25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该应用程序可在<a class="ae kv" href="http://0.0.0.0:5000/docs" rel="noopener ugc nofollow" target="_blank"> http://0.0.0.0:5000/docs </a>下载</p><h1 id="94df" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">部署到GCP</h1><h2 id="a3a6" class="ni mh iq bd mi nn no dn mm np nq dp mq lf nr ns ms lj nt nu mu ln nv nw mw nx bi translated">GCP设置:</h2><p id="7fea" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">这里，我假设您已经有了一个<strong class="ky ir"> GCP </strong>账户，您在那里创建了一个项目，并在您的开发环境中安装和验证了<strong class="ky ir"> gcloud </strong> CLI。</p><p id="17c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们需要激活<strong class="ky ir"> cloudbuild </strong>功能，这样我们就可以轻松地构建docker映像并将其推送到GCR (Google容器注册表)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/82edf594edf2250aa696cd5fa0da18d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YkU90sC1p9Lz3oyQhblsEw.png"/></div></div></figure><p id="1700" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在GCP控制台中查找并启用该功能。这允许我们远程构建docker映像，然后将其推送到GCR。</p><h2 id="1a34" class="ni mh iq bd mi nn no dn mm np nq dp mq lf nr ns ms lj nt nu mu ln nv nw mw nx bi translated">推送图像:</h2><p id="50c0" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">使用以下命令可以轻松构建映像并将其推送到GCR:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="7de8" class="ni mh iq ne b gy nj nk l nl nm">PROJECT_ID := $(shell gcloud config get-value project)<br/>HOSTNAME := eu.gcr.io<br/>GCR_TAG := ${HOSTNAME}/${PROJECT_ID}/${APP_NAME}:${VERSION}<br/>APP_NAME := ner_app</span><span id="f4c2" class="ni mh iq ne b gy ob nk l nl nm">run_grc_build:<br/>   echo "${GCR_TAG}"<br/>   gcloud builds submit --tag ${GCR_TAG} -q</span></pre><p id="6484" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以现在，我们可以运行“make run_grc_build”来构建并推送dockerized API到GCP。</p><p id="f8dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以在这里找到我们推送的图像:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/c44987facb7e06e3aa8af446389feb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jxl20ZkDKm5L3kxtu4BXiA.png"/></div></div></figure><h2 id="3426" class="ni mh iq bd mi nn no dn mm np nq dp mq lf nr ns ms lj nt nu mu ln nv nw mw nx bi translated">部署服务:</h2><p id="d298" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">将服务部署到云运行也可以通过一个命令来完成:</p><pre class="kg kh ki kj gt nd ne nf ng aw nh bi"><span id="d65f" class="ni mh iq ne b gy nj nk l nl nm">PROJECT_ID := $(shell gcloud config get-value project)<br/>HOSTNAME := eu.gcr.io<br/>GCR_TAG := ${HOSTNAME}/${PROJECT_ID}/${APP_NAME}:${VERSION}<br/>APP_NAME := ner_app</span><span id="6a9d" class="ni mh iq ne b gy ob nk l nl nm">cloud_run_deploy:<br/>   gcloud run deploy ner-app --image=${GCR_TAG} \<br/>--max-instances=2 --min-instances=0 --port=5000 \<br/>--allow-unauthenticated --region=europe-west1 \<br/>--memory=2Gi --cpu=4 -q</span></pre><p id="2493" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们只需运行“make cloud_run_deploy ”,即可在不到一分钟的时间内将应用部署到云上。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/e7ac4b83720bf3efd7b23ca93179cb9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EN8CkPh4rGnvDDilR3TKFw.png"/></div></div></figure><p id="b7a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Cloud run是一种无服务器服务，所以如果没有流量，它可以缩小到零，在这种情况下，我们不必支付任何费用。这就是为什么我们把<strong class="ky ir">最小实例=0 </strong>。<br/>该服务还可以根据CPU利用率自动扩展到<strong class="ky ir"> x </strong>个实例。<br/>我们还指定了一些其他参数，比如memory=2Gi，因为默认值512 Mib不够用。</p><p id="52fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在可以访问返回的URL来测试我们的API:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/d8f59fa9d0b664a60641ee4b05adbbb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pE7r9gmF5qhQzlDbcPwpA.png"/></div></div></figure><p id="e205" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Cloud run还提供了一些有用的指标来监控您的web服务的健康状况:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/3e977e3b88338d46d6b9dea3751d6635.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AitFYPrMAH9v5NQibeAJkg.png"/></div></div></figure><p id="b901" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:您可以使用locust+GitHub存储库中可用的locustfile对您部署的服务进行负载测试。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/5f80e81b577266a1e3f72e2f031e879c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUrI-Lu47smF_O8fCpxETQ.png"/></div></div></figure><p id="8b4b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以进一步调整部署配置，以改善NER应用程序的延迟和吞吐量。</p><h1 id="0407" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">结论</h1><p id="e4a3" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在这篇文章中，我们看到了如何使用Cloud run轻松地将机器学习模型部署到Google云平台。这项服务有助于降低模型部署的成本，因为我们只需为我们使用的服务付费，这对于负载变化很大的模型来说是一个很好的选择。</p><p id="de0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">遵循教程的代码可以在这里找到:<a class="ae kv" href="https://github.com/CVxTz/gcp_model_deploy_example" rel="noopener ugc nofollow" target="_blank">https://github.com/CVxTz/gcp_model_deploy_example</a></p><p id="5d3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有任何问题，欢迎在Github上发表评论或提出问题！</p></div></div>    
</body>
</html>