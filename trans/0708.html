<html>
<head>
<title>Implementing Neural Networks in 16 lines of raw Julia</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在16行raw Julia中实现神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-neural-networks-in-16-lines-of-raw-julia-aaa9512f007#2022-02-28">https://towardsdatascience.com/implementing-neural-networks-in-16-lines-of-raw-julia-aaa9512f007#2022-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7c6d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">再用一些来训练它</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d3a0d553eda348da69287aa270b2fa06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4QpdBM516FvHCha1B67-Yw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿丽娜·格鲁布尼亚</a>在<a class="ae ky" href="https://unsplash.com/s/photos/neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="f2c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在构建神经网络和深度学习模型时，Tensorflow和PyTorch是事实上的标准。虽然日常模型可以快速实现，但定制算法有时会导致代码看起来非常冗长。</p><p id="6b75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这在一定程度上是由于Tensorflow和PyTorch都只是将Python作为其低级API的“前端”。另一方面，Julia承诺用单一语言实现端到端的可区分机器学习。这无疑给更干净的代码库带来了希望！</p><p id="aa4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在准备Julia的介绍性演讲时，我试图用尽可能少的代码实现一个简单的前馈神经网络。如果没有空行，代码甚至可以减少到14行。然而，这会大大降低可读性。结果如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="c009" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们一步一步地检查每个组件。如果你不熟悉前馈神经网络的内部结构，你可能会发现这些<a class="ae ky" href="https://en.wikipedia.org/wiki/Feedforward_neural_network#References" rel="noopener ugc nofollow" target="_blank">维基百科参考文献</a>很有用。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="b851" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">将前馈层编写为Julia结构</h1><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="aa3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是前馈层的标准设置。我们需要一个权重矩阵，<strong class="lb iu"> W </strong>，一个偏置向量，<strong class="lb iu"> b </strong>，以及一个<strong class="lb iu">激活</strong>函数。接下来，我们定义前馈层的前馈通道:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="90a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Julia允许我们通过实例化的结构调用函数。在某种程度上，这使得层和网络实例的后续使用更加优雅。</p><p id="3b99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">和<strong class="lb iu">标识</strong>激活函数的实现应该是不言自明的。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="c898" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">将层聚集到全前馈神经网络中</h1><p id="4304" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">网络本身只不过是其各个层的集合:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="40b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们在构造函数中使用一个<code class="fe nb nc nd ne b">Vararg</code>参数来允许任意数量的层。虽然我们可以在构造函数调用中只使用一个<code class="fe nb nc nd ne b">Vector</code>，但是这种方法为我们节省了两个括号:)。</p><p id="9b9a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们要定义全局前馈通路。请记住，这可以表示为所有层的功能组合:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/fc8e4e7320a6d4db64807a77eaa56005.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*q99RZEn1in7pBTeMulmziQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="3266" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，<strong class="lb iu"> f </strong>表示总共<strong class="lb iu"> L </strong>个前馈层的层函数。我们可以在Julia中这样写:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="32ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们的函数组合是一个关联操作，我们可以使用<code class="fe nb nc nd ne b">reduce()</code>函数。这使得我们可以在Julia中把这个关键元素变成另一个俏皮话。</p><p id="472a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你仔细观察，你会注意到我们在<code class="fe nb nc nd ne b">reduce()</code>期间颠倒了<code class="fe nb nc nd ne b">layer::Vector{Layer}</code>的顺序。虽然从<strong class="lb iu">从左到右</strong>推理网络拓扑更容易，但是合成操作本身是从<strong class="lb iu">从右到左</strong>执行的。</p><p id="2d9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，请注意，如果我们想要优化网络，我们不能预先计算这个组成。让我们实际这样做，以便验证我们的实现是否如预期的那样工作。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="7428" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">在一个玩具例子上训练我们的Julia神经网络</h1><p id="eee3" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">由于梯度计算和优化器实现将是一个更大的任务，我们将使用两个Julia库来帮助完成这一步。对于玩具数据集，让我们在<code class="fe nb nc nd ne b">[-3.0,3.0]</code>中的插值线上使用正弦函数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="3e8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，上面的代码片段执行以下步骤:</p><ol class=""><li id="644e" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated">创建玩具数据并定义损失函数</li><li id="83f0" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">实例化神经网络</li><li id="87e2" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">从网络实例中提取目标参数(网络权重)</li><li id="c9d0" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">训练模型(即优化其参数)</li></ol></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="f531" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">检查输出</h1><p id="1a2e" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">最后，让我们验证我们迄今所做的一切确实是正确的。如果一切顺利，我们的模型应该已经学会近似正弦函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><p id="2524" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这会产生以下情节:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/5bac7562847dd0581e9c1c297134ba78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xVOSKJvn3-hi3Fju.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nv">输出证实了我们的实现确实是正确的。我们可以进一步利用这个例子，用Julia以紧凑的方式实现例如</em> <a class="ae ky" rel="noopener" target="_blank" href="/regularization-an-important-concept-in-machine-learning-5891628907ea"> <em class="nv">正则化</em> </a> <em class="nv">。(图片由作者提供)</em></p></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="6b78" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">太好了！现在我能放下Tensorflow和PyTorch吗？</h1><p id="fc2c" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">肯定看情况！一方面，Julia是一种以高效方式编写快速机器学习算法的优秀语言。另一方面，Julia还是一门比较年轻的语言。就我个人而言，我还不会在任何非个人的商业产品中使用朱莉娅。</p><p id="6e2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下两个我亲身经历或在网上讨论中看到的问题仍然阻止我向我的客户推荐Julia:</p><p id="17b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/FluxML/Zygote.jl/issues/796" rel="noopener ugc nofollow" target="_blank">当然，这个论点只有在涉及到可微分的机器学习模型时才有效。</a></p><p id="cd19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于JIT编译来说，可部署性是具有挑战性的——一般来说，Julia提供了成功部署模型甚至复杂应用程序所需的所有功能。然而，JIT编译器的预热时间使得很难有效地这样做。</p><p id="53e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每当您开始一个新的Julia会话时，您基本上必须等待一两分钟，直到您的代码可以使用为止。如果您需要您的应用程序快速伸缩以适应突然的使用高峰，这可能是一个令人望而却步的问题。</p><p id="15c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，对于做研究或创建新算法的原型来说，Julia是一种很棒的语言。一旦你的Julia神经网络或相关模型表现良好，你可以通过<a class="ae ky" href="https://github.com/FluxML/ONNX.jl" rel="noopener ugc nofollow" target="_blank"> ONNX </a>轻松将其转移到PyTorch或Tensorflow。从那里，您可以使用常用的、经过验证的工具集来部署它。</p><p id="aa26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你愿意尝试，并且能处理偶尔的怪癖，你绝对应该给朱莉娅一个机会。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="aa38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nw">原载于2022年2月28日https://sarem-seitz.com</em><a class="ae ky" href="https://sarem-seitz.com/blog/implementing-neural-networks-in-16-lines-of-raw-julia/" rel="noopener ugc nofollow" target="_blank"><em class="nw"/></a><em class="nw">。</em></p></div></div>    
</body>
</html>