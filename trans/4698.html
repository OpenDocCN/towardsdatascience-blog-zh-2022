<html>
<head>
<title>Unsupervised Keyphrase Extraction with PatternRank</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于模式排序的无监督关键词抽取</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-keyphrase-extraction-with-patternrank-28ec3ca737f0#2022-10-19">https://towardsdatascience.com/unsupervised-keyphrase-extraction-with-patternrank-28ec3ca737f0#2022-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fcaf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用预训练的变压器语言模型和词性进行最先进的关键短语提取</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d51575e45e30870f0f48bb426b473699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MShRfm9psSWz6GAaSs_Orw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="ac2a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">本帖基于我们的论文</em><a class="ae ls" href="https://arxiv.org/abs/2210.05245" rel="noopener ugc nofollow" target="_blank"><em class="lr">“pattern rank:利用预训练的语言模型和词性进行无监督的关键短语提取(2022)”</em></a><em class="lr">被KDIR22接受。您可以在那里阅读更多关于我们方法的详细信息。</em></p><p id="c892" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">📑为了快速获得文本内容的概述，我们可以使用简明反映其语义上下文的关键短语。关键短语描述了一篇文章最重要的方面。与简单的关键字不同，关键短语不仅仅由单个单词组成，而是由几个复合词组成。如<em class="lr">《足球》</em>vs<em class="lr">《青少年足球训练》</em>。关键短语比简单的关键字提供了更准确的描述，因此通常是首选的，不依赖于标记的数据选择。</p><p id="a4e3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇文章中，我们介绍了<strong class="kx ir"> PatternRank </strong>，它利用预先训练的语言模型和词性从单个文档中进行无监督的关键短语提取。我们的方法不依赖于标记数据，因此可以很容易地用于各种不同的领域。我们的实验表明，PatternRank比以前的方法具有更高的精度、召回率和F1值🏆。此外，我们还展示了<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">keyphrasevectors</a>Python包🐍，这允许容易地修改候选关键短语选择的词性模式，从而使我们的方法适用于任何领域。</p><h1 id="8d18" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">PatternRank是如何工作的？</h1><p id="7fcd" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">下图说明了PatternRank的一般关键短语提取过程👇。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/c3c67cb1a232e0430d2f3ca60004c4f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MBvaUT-MRXT3NZkuhAOseQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mr">无监督关键短语提取的模式排序</strong>方法。单个文本文档被用作初始过滤步骤的输入，在该步骤中，选择与定义的词性模式相匹配的候选关键短语。随后，基于候选关键短语与输入文本文档的语义相似性，通过预先训练的语言模型对候选关键短语进行排序。最后，提取前N个关键短语作为输入文本文档的简明反映。来源:<a class="ae ls" href="https://arxiv.org/abs/2210.05245" rel="noopener ugc nofollow" target="_blank">绍普夫等人</a></p></figure><p id="36b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了从文本中提取关键短语，<strong class="kx ir"> <em class="lr"> PatternRank执行以下步骤:</em> </strong></p><ol class=""><li id="7b1d" class="ms mt iq kx b ky kz lb lc le mu li mv lm mw lq mx my mz na bi translated">输入由正在进行单词标记的单个文本文档组成。</li><li id="9086" class="ms mt iq kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">然后用词性标签对单词标记进行标记。</li><li id="8c67" class="ms mt iq kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">其标签与先前定义的词性模式相匹配的记号被选为候选关键短语。</li><li id="6c50" class="ms mt iq kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">然后，预训练的语言模型将整个文本文档以及所有候选关键短语作为语义向量表示来嵌入。</li><li id="a6f0" class="ms mt iq kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">随后，计算文档表示和候选关键短语表示之间的余弦相似度，并基于所计算的相似度得分以降序排列候选关键短语。</li><li id="df7c" class="ms mt iq kx b ky nb lb nc le nd li ne lm nf lq mx my mz na bi translated">最后，提取最能代表输入文档的前N个排序的关键短语。</li></ol><p id="15de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的实验中，我们使用预先训练的<a class="ae ls" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank"> all-mpnet-base-v2 </a>语言模型。这是一个<a class="ae ls" href="https://aclanthology.org/D19-1410/" rel="noopener ugc nofollow" target="_blank"> SBERT </a>模型，已经被证明可以为语义相似性任务产生最先进的文本表示。对于这篇博文的范围，我们只使用简单的名词短语作为词性模式。尽管我们在<a class="ae ls" href="https://arxiv.org/abs/2210.05245" rel="noopener ugc nofollow" target="_blank">的论文</a>中表明，更复杂的词性模式可以带来更好的结果，但在模式排序中使用名词短语是一种简单而有效的方法，可以提取任何领域中有意义的关键短语🏅。</p><blockquote class="ng nh ni"><p id="54e3" class="kv kw lr kx b ky kz jr la lb lc ju ld nj lf lg lh nk lj lk ll nl ln lo lp lq ij bi translated">名词通常是指一件事或一个人。形容词是描述名词的词。名词短语是围绕一个名词构建的简单短语。它由零个或多个形容词后跟一个或多个名词组成。例如:一棵大树，一些五颜六色的糖果，巨大的皇家城堡。</p></blockquote><h1 id="3a15" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">模式排序与以前方法的比较</h1><h2 id="9de7" class="nm lu iq bd lv nn no dn lz np nq dp md le nr ns mf li nt nu mh lm nv nw mj nx bi translated">先前的关键短语提取方法</h2><p id="30a0" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">大多数流行的无监督关键短语提取方法可以被描述为基于统计、基于图或基于嵌入的方法，而<em class="lr"> Tf-Idf </em>是用于评估的常见基线。在这篇文章中，我们针对三种非常流行的关键短语提取方法来评估PatternRank。如果您对更多关键短语提取方法的详细比较感兴趣，请查看Papagiannopoulou和Tsoumakas的论文<a class="ae ls" href="https://arxiv.org/abs/1905.05044" rel="noopener ugc nofollow" target="_blank">(2019)</a>。</p><p id="9622" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👉YAKE 是一种快速、轻量级的方法，用于基于统计特征从单个文档中无监督地提取关键短语。</p><p id="35da" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👉<a class="ae ls" href="https://aclanthology.org/C08-1122/" rel="noopener ugc nofollow" target="_blank"> SingleRank </a>对单词共现图应用排序算法，从单个文档中进行无监督的关键短语提取。</p><p id="e353" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">👉<a class="ae ls" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank"> KeyBERT </a>使用类似于PatternRank的预训练语言模型对候选关键短语进行排名。然而，KeyBERT使用简单的单词n-grams作为候选关键短语，而不是像我们的PatternRank方法那样，使用匹配特定词性模式的单词标记。</p><blockquote class="ng nh ni"><p id="a590" class="kv kw lr kx b ky kz jr la lb lc ju ld nj lf lg lh nk lj lk ll nl ln lo lp lq ij bi translated"><em class="iq">单词n元语法范围让用户决定应该从给定文本中提取的连续单词序列的长度。假设我们定义了一个</em> <code class="fe ny nz oa ob b"><em class="iq">word n-gram range = (1,3)</em></code>。然后，我们将选择从文本中提取一元词(只有一个单词)、二元词(两个连续单词的组合)和三元词(三个连续单词的组合)。将单词n-gram range应用到 <code class="fe ny nz oa ob b"><em class="iq">"an apple a day keeps the doctor away"</em></code> <em class="iq">将得到</em> <code class="fe ny nz oa ob b"><em class="iq">["an", "apple", "a","day", "keeps", "the", "doctor", "away", "an apple", "apple a", "a day", "day keeps", "keeps the", "the doctor", "doctor away", "an apple", "apple a day", "a day keeps", "day keeps the", "keeps the doctor", "the doctor away"]</em></code> <em class="iq">。- </em> <a class="ae ls" href="https://www.quora.com/What-is-the-n-gram-range" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> <em class="iq">德维什帕马尔</em> </strong> </a></p></blockquote><p id="d052" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了评估，我们比较了YAKE、SingleRank、KeyBERT和PatternRank的性能。对于KeyBERT和PatternRank，我们使用相同的预训练的<a class="ae ls" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank"> all-mpnet-base-v2 </a>语言模型。</p><h2 id="5e38" class="nm lu iq bd lv nn no dn lz np nq dp md le nr ns mf li nt nu mh lm nv nw mj nx bi translated">数据</h2><p id="429c" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">💾我们在<a class="ae ls" href="https://github.com/LIAAD/KeywordExtractor-Datasets#Inspec" rel="noopener ugc nofollow" target="_blank"> Inspec数据集</a>上评估关键短语提取方法。它包括从1998年到2002年间的科学期刊文章中收集的2000篇英语计算机科学摘要。每个摘要都分配了两种不同类型的关键短语。首先，出现在Inspec数据集的词库中但不一定出现在摘要中的受控和手动分配的关键短语。第二，不受控制的关键短语，它们是由专业索引器自由分配的，并且不限于同义词库或摘要。在我们的实验中，我们认为这两种关键短语的联合就是黄金关键短语。</p><h2 id="0fa9" class="nm lu iq bd lv nn no dn lz np nq dp md le nr ns mf li nt nu mh lm nv nw mj nx bi translated">韵律学</h2><p id="a7d2" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们基于精确匹配方法进行评估，这意味着真正的肯定是提取的关键短语与黄金关键短语之一具有精确的字符串匹配。我们报告<em class="lr"> Precision@N </em>、<em class="lr"> Recall@N </em>和<em class="lr"> F1@N </em>得分，分别使用前N个提取的关键短语(<em class="lr"> N=5，10 </em>)。</p><h2 id="4c69" class="nm lu iq bd lv nn no dn lz np nq dp md le nr ns mf li nt nu mh lm nv nw mj nx bi translated">结果</h2><p id="198b" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们的评估结果如下图所示📊。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/b0ebcd6c1e1421a95b7c9d922f8b936e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pfj9vbnMRIoyGdTX9932hQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae ls" href="https://github.com/LIAAD/KeywordExtractor-Datasets#Inspec" rel="noopener ugc nofollow" target="_blank"> Inspec数据集</a>上比较KeyBERT、YAKE、SingleRank和PatternRank关键短语提取结果。</p></figure><p id="28e0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果显示，在所有基准测试中，PatternRank优于所有其他方法。KeyBERT使用与PatternRank相同的预训练语言模型对候选关键短语进行排序，但使用简单的n元语法来选择候选关键短语，而不是词性模式(在本例中为名词短语)。因此，KeyBERT在所有方法中表现最差。正如所料，YAKE是最快的关键短语提取方法，因为它是基于统计特征的轻量级方法。然而，提取的关键短语不是非常准确，并且与PatternRank相比，YAKE在所有评估中的表现明显更差。SingleRank是与PatternRank相比唯一能取得竞争结果的方法。然而，在所有评估中，它的表现始终比PatternRank差几个百分点。因此，我们得出结论，PatternRank实现了最先进的关键短语抽取结果🏆。</p><h1 id="7d80" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">如何使用PatternRank？</h1><p id="4cdf" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">我们开发了<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">keyphrasvectories</a>Python包🐍这使得<strong class="kx ir">模式等级</strong>易于使用。将<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">关键短语分解器</a>与KeyBERT一起用于关键短语提取产生了<a class="ae ls" href="https://arxiv.org/abs/2210.05245" rel="noopener ugc nofollow" target="_blank">模式排序</a>方法。其思想是使用KeyBERT的实现，通过预训练的语言模型对关键短语进行排序，并利用来自<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">关键短语分析器</a>的词性模式选择候选关键短语，从而产生<strong class="kx ir">模式排序</strong>方法。如何用Python实现这种方法在这篇博客文章中有详细的解释💡。</p><h1 id="7962" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">摘要</h1><p id="c907" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">PatternRank是最近开发的一种方法，可用于从文本文档中提取最先进的关键短语。评估显示，在所有基准测试中，PatternRank在精确度、召回率和F1值方面表现最佳。此外，我们还展示了<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">keyphrasevectors</a>Python包🐍，这使得PatternRank易于使用和定制。</p><p id="8709" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">也非常感谢<a class="ae ls" href="https://www.maartengrootendorst.com/" rel="noopener ugc nofollow" target="_blank">马腾·格罗腾多斯特</a>，他在我们编写<a class="ae ls" href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener ugc nofollow" target="_blank">keyphrasevectors</a>包时给了我们输入和灵感。</p><h1 id="e01b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">来源</h1><div class="od oe gp gr of og"><a href="https://arxiv.org/abs/2210.05245" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">PatternRank:利用预训练的语言模型和无监督关键短语的词性…</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">关键短语提取是从给定文本中自动选择一小组最相关短语的过程…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">arxiv.org</p></div></div><div class="op l"><div class="oq l or os ot op ou kp og"/></div></div></a></div><div class="od oe gp gr of og"><a href="https://github.com/TimSchopf/KeyphraseVectorizers" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">GitHub——TimSchopf/keyphrasevectorizer:一组向量器，使用…</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">一组向量器，从一组文本文档中提取带有词性模式的关键短语，并转换…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="ov l or os ot op ou kp og"/></div></div></a></div></div></div>    
</body>
</html>