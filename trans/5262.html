<html>
<head>
<title>Clustering on Mixed Data Types</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">混合数据类型上的聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-on-mixed-data-types-5fe226f9d9ca#2022-11-24">https://towardsdatascience.com/clustering-on-mixed-data-types-5fe226f9d9ca#2022-11-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3562" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用高尔相和 HDBSCAN</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5007d3c57e462c23c283c6436de42b16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AxEbdVBPeMQRX2hCevswsA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">资料来源:Unsplash。</p></figure><p id="19d1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">聚类是一种无监督的机器学习技术，旨在将相似的数据点分组到不同的子组中。通常，用于这种分组的距离度量对于数值数据是<em class="lu">欧几里德距离</em>，对于分类数据是<em class="lu">雅克卡距离</em>。大多数聚类算法也是为数字或分类数据显式设计的，但不是同时为两者设计的。在本文中，我将概述一种通过利用一种称为高尔相异度的距离度量来对混合数据进行聚类的方法。虽然各种聚类算法可以将预先计算的距离度量作为输入，但我将使用 HDBSCAN，因为它对异常值具有鲁棒性，并且能够识别有噪声的数据点。</p><h1 id="f82f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据集和预处理</h1><p id="7348" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">为了说明，我使用公开可用的<a class="ae ms" href="https://www.kaggle.com/competitions/titanic/data?select=test.csv" rel="noopener ugc nofollow" target="_blank">泰坦尼克号测试数据集</a>。高基数要素(主要是每个乘客独有的要素，如<em class="lu"> PassengerId </em>、<em class="lu"> Name </em>和<em class="lu"> Cabin </em>)以及任何包含 nan 的行和包含超过 50% nan 的列都已从数据集中移除。为了简单和更好的可视化，只使用了 30%数据的随机部分。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/032887077a67ac95177a3a45145f54bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*j8UiuoC1ua6mrYnYOZ9zYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预处理的 Titanic 测试数据集的随机样本。</p></figure><h1 id="738f" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">高尔不同</h1><p id="7b5f" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated"><a class="ae ms" href="https://www.jstor.org/stable/2528823" rel="noopener ugc nofollow" target="_blank">高尔相异度(<em class="lu"> GD </em> ) </a>是表示两个样本差异程度的度量。度量范围从 0 到 1，0 表示无差异，1 表示最大差异。它是基于任意两个样本的部分相似性来计算的。部分相似性(<em class="lu"> ps </em>)根据数据类型是数值型还是分类型进行不同的计算。对于分类数据，如果值相同，ps = 1，如果值不同，ps = 0。对于数值数据，<em class="lu"> ps </em>计算如下:</p><p id="b0c4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，确定特征列的范围。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/fe880964bc7a9db3bd6df2fa4eccdc30.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*QfOIOnYFEsD7lE59vPaiJQ.png"/></div></figure><p id="007c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二，<em class="lu"> ps </em>是对数据中任意两个样本计算的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/892dd0522b47080efdc32a8d3dc5f90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/1*acR3MIvckdvQ-BAKYyVqEQ.png"/></div></figure><p id="10ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第三，高尔相似度(<em class="lu"> GS </em>)是通过取所有部分相似度的算术平均值来计算的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/5c90746089cbf127fb00641c4e7fc7c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*LJlaDWLIFb-BVO-2QvT5VA.png"/></div></figure><p id="1a01" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，通过从 1 中减去相似性度量(<em class="lu"> GS </em>)来将其转换成距离度量(<em class="lu"> GD </em>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e518158bc1e46a86acd4a6848edc6a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:222/format:webp/1*HgVHuig4V38sbQthZvOwyg.png"/></div></figure><h2 id="ad90" class="my lw it bd lx mz na dn mb nb nc dp mf lh nd ne mh ll nf ng mj lp nh ni ml nj bi translated">视觉插图</h2><p id="931c" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">为了更好地说明，让我们再次查看预处理数据的前五行:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/032887077a67ac95177a3a45145f54bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*j8UiuoC1ua6mrYnYOZ9zYA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预处理的 Titanic 测试数据集的随机样本。</p></figure><p id="c681" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看第 0 行和第 3 行，人们会立即意识到这两行非常相似，只有在<em class="lu">年龄</em>和<em class="lu">费用</em>上略有不同。因此，我们预计<em class="lu"> GD </em>会非常低(接近于零)。其实准确的<em class="lu"> GD </em>是 0.0092(见下图)。更不相似的样本，如第 0 行和第 2 行，具有更大的距离值，在本例中为 0.24。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/f631f18f153827ffcab499446742c7d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*RVHuNjLC_M5psa3_VRXHRQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上面概述的样本的相应高尔距离矩阵。</p></figure><p id="0e8b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们整个预处理数据集的<em class="lu"> GD </em>矩阵如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3576eb2744acbf11935e343fca77f407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*wBiFxPwn-g1Y0Sv-sP5rTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">整个预处理测试数据集的高尔距离矩阵。</p></figure><h1 id="7f4b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使聚集</h1><p id="d70c" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">作为聚类算法，我选择了<a class="ae ms" href="https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html" rel="noopener ugc nofollow" target="_blank"> HDBSCAN </a>(针对有噪声的应用的基于层次密度的空间聚类)。HDBSCAN 擅长识别高密度集群，计算效率高，对异常值具有鲁棒性。</p><p id="34f6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">设置了两个参数来运行 HDBSCAN。影响聚类结果的主要参数是<em class="lu">最小聚类大小</em>。这是指被视为一个组或簇的最小数量的数据点。可以设置一个附加参数<em class="lu"> min_samples </em>来控制分类为噪声的数据。该值越低，归类为噪声的数据点就越少。在该示例中，<em class="lu">最小聚类大小</em>被设置为 6，而<em class="lu">最小样本数</em>被设置为 1。</p><p id="2714" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些参数可以使用集群质量度量进一步调整，例如<a class="ae ms" href="https://github.com/christopherjenness/DBCV" rel="noopener ugc nofollow" target="_blank">基于密度的集群验证(DBCV) </a>分数。然而，为了简洁起见，本文省略了这一点。</p><h1 id="f971" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">形象化</h1><p id="a363" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">为了可视化结果，应用了 2D <a class="ae ms" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank"> t 分布随机邻居嵌入</a> (t-SNE)投影。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/064964694bc025bb35f1adba37720439.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*kakYBqpBm4PYh8Ga0_fPZw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">HDBSCAN 输出 6 个不同的簇和一个被视为噪声的簇(暗红色)。</p></figure><p id="3208" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们通过可视化其中一些集群的值来看看这些分组的质量。</p><p id="f28b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">紫色集群</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/09dd9b7497e08cec64d0bc45a905079f.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*xND58qeL2a7jT5Kd68y8dQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">组成紫色集群的数据点样本。</p></figure><p id="7b7f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">黄色集群</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f6f07378ba8496e4bd2ef077a1275da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*8c703W_Za4trGx4NwdFpjQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">组成黄色聚类的数据点样本。</p></figure><p id="90de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">绿色集群</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/df519d111a6fc1e6e66b36b41612ac8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*Bv02bA9xfP1CPvQkrcEJHg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">组成绿色聚类的数据点样本。</p></figure><p id="9800" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">噪声集群</strong></p><p id="a280" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如所料，归类为噪声的样本彼此非常不同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2dfd3685804ce4bc364528eeda930ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*xqJikvuCsR98D5XYZRXq6w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">组成噪声群的数据点的样本。</p></figure><h1 id="1ec8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="e9c7" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">在本文中，我演示了如何对混合类型的数据进行聚类，方法是首先计算高尔距离矩阵，然后将其输入 HDBSCAN。结果表明，对于所使用的数据，该方法在将相似的数据点分组在一起方面表现得相当好。然而，这不是一个适用于所有混合数据类型的通用方法，最终使用的方法将取决于手头的数据。例如，HDBSCAN 要求集群内的密度一致，集群之间的密度下降。如果没有，就需要考虑其他方法。</p></div></div>    
</body>
</html>