<html>
<head>
<title>Polynomial Autoregression: Improve Your Forecasts in 2 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多项式自回归:在 2 分钟内改善你的预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/polynomial-autoregression-improve-your-forecasts-in-2-minutes-746d8b57d896#2022-12-15">https://towardsdatascience.com/polynomial-autoregression-improve-your-forecasts-in-2-minutes-746d8b57d896#2022-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6d96" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">完全初学者的非线性时间序列+代码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f3f8a48673425d146ec510e06c7ae15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S0kGqCleVsxOgCh8.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">by <a class="ae kv" href="https://pixabay.com/pl/photos/zabytek-czechy-czech-praga-rathaus-92861/" rel="noopener ugc nofollow" target="_blank"> sebo106 </a></p></figure><p id="639a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在人工智能和自动化解决方案的时代，人们相对容易忘记经常产生可比结果的简单技术。你还记得非线性回归吗？</p><p id="7be7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然它因其漂亮的分析公式而在学术界非常受欢迎，但自从机器学习爆发以来，它并没有获得太多的关注。尽管我 100%确定你不是真的喜欢数学，但我会告诉你一个非常简单的方法来提高你的时间序列预测的准确性，只需多花两分钟的时间。</p><p id="e5aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">有很多看起来很丑的总结，但是如果你对 r 过敏，你可以跳过其中的大部分。</strong></p><p id="5d42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对非线性时间序列完全陌生，我强烈建议你从对整个主题的直观介绍开始:</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/nonlinear-time-series-an-intuitive-introduction-7390aae8b446"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">非线性时间序列——直观介绍</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">为什么你的标准时间序列分析程序有时会失败？</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj kp lv"/></div></div></a></div></div><div class="ab cl mk ml hu mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="ij ik il im in"><h1 id="0885" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">多项式回归</h1><p id="9ec3" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">如果你熟悉多项式回归，你可以跳过这一部分。</p><p id="7a03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我简单介绍一下多项式回归背后的思想。<strong class="ky ir">线性</strong>回归之所以这样叫，是因为它反映了<strong class="ky ir">数据</strong>之间的线性关系。当数据<strong class="ky ir">之间的关系不是线性的</strong>时，使用多项式回归。让我们稍微想象一下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/1dbc971545575d2e7d0927d954372e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KLm3M9XWf2WIxhn0XpTptg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者，用 NumPy 生成</p></figure><p id="4569" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们想要对左边的数据建模，我们将使用标准线性回归:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="a3f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这显然是我们在学校都学过的经典<code class="fe nr ns nt nu b">f(x)=ax+b</code>函数。第二张图显示了二次关系。这意味着，我们的回归函数将扩展到:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="2cda" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个方程的参数α可以用简单的 OLS 很容易地估计出来——这正是我们下一步要做的！</p><h1 id="bb51" class="mr ms iq bd mt mu nv mw mx my nw na nb jw nx jx nd jz ny ka nf kc nz kd nh ni bi translated">认真工作</h1><p id="0e15" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">我认为用 R 来做是最舒服的，然而，我要用的所有工具在 Python、Julia 或其他什么语言中都很容易访问。在我们开始之前，有一个问题我们必须回答:</p><blockquote class="oa"><p id="1c1d" class="ob oc iq bd od oe of og oh oi oj lr dk translated"><strong class="ak">我们如何知道我们的时间序列是非线性的？</strong></p></blockquote><p id="16f4" class="pw-post-body-paragraph kw kx iq ky b kz ok jr lb lc ol ju le lf om lh li lj on ll lm ln oo lp lq lr ij bi translated">虽然我们可以做一些奇特的统计测试，但我保证这个故事是针对完全初学者的，所以我们保持简单。我希望你们使用的工具非常简单——这是一个滞后图:</p><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="601c" class="ot ms iq nu b be ou ov l ow ox">data &lt;- data.frame(y=log10(datasets::lynx))  #log10 for statistical reasons<br/><br/>{par(mfrow=c(2,2))<br/>  scatter.smooth(lag(train$y, 1), train$y, span = 2/3, degree = 1,<br/>                 family = c("symmetric", "gaussian"), evaluation = 50, xlab = "t-1", ylab = "t")<br/>  scatter.smooth(lag(train$y, 2), train$y, span = 2/3, degree = 1,<br/>                 family = c("symmetric", "gaussian"), evaluation = 50, xlab = "t-2", ylab = "t")<br/>  scatter.smooth(lag(train$y, 3), train$y, span = 2/3, degree = 1,<br/>                 family = c("symmetric", "gaussian"), evaluation = 50, xlab = "t-3", ylab = "t")<br/>  scatter.smooth(lag(train$y, 4), train$y, span = 2/3, degree = 1,<br/>                 family = c("symmetric", "gaussian"), evaluation = 50, xlab = "t-4", ylab = "t")<br/>}</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/bf8f26a588074ebf93c3d68016822f85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lWqeiM1DI_DYOOffuy26wA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者</p></figure><p id="e771" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然第一个滞后看起来是线性的，但从第二个滞后开始，我们可以清楚地看到非线性关系正在发生。这是使用非线性模型的充分理由。记住——不要在没有看到滞后图的情况下进行时间序列分析！忽略这一点，你可能会被错误地识别。</p><p id="cfa7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从正确的数据准备开始建模。为了包含非线性项，我们需要添加多项式特征，然后确保它们都具有相似的方差。我们将通过标准化来实现:</p><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="5fa7" class="ot ms iq nu b be ou ov l ow ox">th &lt;- 81<br/>for (i in 1:4){ <br/>  data[paste0("L", i)] &lt;- Hmisc::Lag(data1$y, i) #here we are adding lags<br/>  data[paste0("L.2.", i)] &lt;- Hmisc::Lag(data1$y, i)^2 #from here on we are adding polynomial lags<br/>  data[paste0("L.3.", i)] &lt;- Hmisc::Lag(data1$y, i)^3<br/>  data[paste0("L.4.", i)] &lt;- Hmisc::Lag(data1$y, i)^4<br/>}<br/><br/>data &lt;- data %&gt;% mutate_at(names(data), ~(scale(.) %&gt;% as.vector))  #standarization<br/>data &lt;- na.omit(data)  #get rid of the NAs<br/>boxplot(data)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/2ad7878c1320ba3dede51053bf9de8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6gbEJBUhuCX3EBvfqP5ig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者</p></figure><p id="eadb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看起来效果不错。现在，我们将数据集分为训练集和测试集，我们将训练 ARIMA 模型:</p><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="e40d" class="ot ms iq nu b be ou ov l ow ox">train &lt;- data[1:80,]<br/>test &lt;- data[th:110,]<br/><br/>ar &lt;- forecast::auto.arima(train$y)<br/>summary(ar)</span></pre><pre class="pa op nu oq bn or os bi"><span id="6776" class="ot ms iq nu b be ou ov l pb ox">Series: train$y <br/>ARIMA(4,0,1) with zero mean <br/><br/>Coefficients:<br/>         ar1     ar2      ar3      ar4     ma1<br/>      0.3917  0.4609  -0.4490  -0.2687  0.9339<br/>s.e.  0.1164  0.1346   0.1244   0.1102  0.0619<br/><br/>sigma^2 = 0.1606:  log likelihood = -39.59<br/>AIC=91.18   AICc=92.33   BIC=105.47<br/><br/>Training set error measures:<br/>                      ME      RMSE       MAE     MPE     MAPE      MASE        ACF1<br/>Training set -0.03339086 0.3880593 0.3254522 3.37014 107.7749 0.5795365 -0.01482778</span></pre><p id="fb64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ARIMA 模型的最大滞后是 4(为了简单起见，我将它作为最大滞后)。现在让我们训练我们的多项式模型。我们正在做的是:</p><ol class=""><li id="cc0c" class="pc pd iq ky b kz la lc ld lf pe lj pf ln pg lr ph pi pj pk bi translated">创建一个包含所有变量+截距的线性回归模型</li><li id="c878" class="pc pd iq ky b kz pl lc pm lf pn lj po ln pp lr ph pi pj pk bi translated">使用 AIC 网格搜索选择，以找出哪些变量要删除。这也可以通过其他功能选择来完成，但 AIC 是最受欢迎的一个，所以我现在不把它搞得太复杂了。</li></ol><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="9f53" class="ot ms iq nu b be ou ov l ow ox">model &lt;- lm(y ~ ., train)<br/><br/>model2 &lt;- stepAIC(model, k=2) # k=log(nrow(train)) - if you want to use BIC<br/>summary(model2)</span></pre><pre class="pa op nu oq bn or os bi"><span id="0601" class="ot ms iq nu b be ou ov l pb ox">Call:<br/>lm(formula = y ~ L1 + L.2.1 + L.3.1 + L.3.2 + L.4.2 + L.2.3 + <br/>    L.3.3 + L.4.3 + L.3.4, data = train)<br/><br/>Residuals:<br/>     Min       1Q   Median       3Q      Max <br/>-0.89423 -0.19751 -0.01561  0.24469  0.70938 <br/><br/>Coefficients:<br/>             Estimate Std. Error t value Pr(&gt;|t|)   <br/>(Intercept)  -0.04549    0.03999  -1.137  0.25921   <br/>L1            5.97418    2.63906   2.264  0.02669 * <br/>L.2.1       -11.85976    5.75545  -2.061  0.04306 * <br/>L.3.1         7.11220    3.13333   2.270  0.02630 * <br/>L.3.2         1.39683    0.87505   1.596  0.11493   <br/>L.4.2        -1.95094    0.79889  -2.442  0.01713 * <br/>L.2.3         7.10425    2.95244   2.406  0.01876 * <br/>L.3.3       -16.10242    6.24565  -2.578  0.01204 * <br/>L.4.3         9.00962    3.36456   2.678  0.00923 **<br/>L.3.4        -0.17323    0.11475  -1.510  0.13564   <br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1<br/><br/>Residual standard error: 0.3505 on 70 degrees of freedom<br/>Multiple R-squared:  0.8973, Adjusted R-squared:  0.8841 <br/>F-statistic: 67.97 on 9 and 70 DF,  p-value: &lt; 2.2e-16</span></pre><p id="7ce7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你很容易注意到的有趣细节是，第一个<strong class="ky ir">延迟是唯一一个被认为是线性的</strong>——回到延迟图，你会明白为什么会发生这种情况。</p><p id="1955" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，哪种模式更好？我们来做预测吧！</p><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="6088" class="ot ms iq nu b be ou ov l ow ox">refit &lt;- forecast::Arima(data$y, model=ar)<br/>fcast &lt;- predict(model2, test)<br/><br/>plot(test$y, type='l')<br/>lines(refit$fitted[th:110], col='purple')<br/>lines(fcast, col='red')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/56c7e3d8ee5e5683a5700c2214ee5ebd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5Uw8RtwzfsFtJzhYfN5Hw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者</p></figure><p id="ef92" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以很容易地看到，多项式 AR 只是更好地拟合数据集——它不像 ARIMA 的预测那样跳跃，特别是在第 15 次观察之后。它的<em class="pq"> MSE </em>怎么样？</p><pre class="kg kh ki kj gt op nu oq bn or os bi"><span id="538e" class="ot ms iq nu b be ou ov l ow ox">mean(sum((test$y - refit$fitted[th:110])^2))  #for ARIMA<br/>mean(sum((test$y - fcast)^2))  #for Polynomial AR</span></pre><pre class="pa op nu oq bn or os bi"><span id="a708" class="ot ms iq nu b be ou ov l ow ox">ARIMA: 5.749183<br/>Polynomial AR: 5.119633</span></pre><p id="618c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，我们已经显著改进了样本外预测<strong class="ky ir">，而没有向数据集添加任何额外信息</strong>！</p><h1 id="98b0" class="mr ms iq bd mt mu nv mw mx my nw na nb jw nx jx nd jz ny ka nf kc nz kd nh ni bi translated">摘要</h1><p id="20ff" class="pw-post-body-paragraph kw kx iq ky b kz nj jr lb lc nk ju le lf nl lh li lj nm ll lm ln nn lp lq lr ij bi translated">我刚刚展示给你的是<em class="pq">可能是</em>最简单同时也是最强大的非线性时间序列技术，你可以在两分钟内完成。然而，实际上，非线性有不同的类型——不幸的是，多项式无法涵盖所有类型，因为我相信你已经想到了。举例？没问题:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/d6c256ff946e194b758b00a556c0b992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qDgM5XKRrZOpHLDEM7snBA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者，用 NumPy 生成</p></figure><p id="f663" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有人会认为这是撒旦的创造。其中一个可能是对的。即使一开始看起来无法解决，但还是有模型可以处理这种非线性。如果你对此感到好奇，请查看:</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/threshold-autoregressive-models-beyond-arima-r-code-6af3331e2755"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">门限自回归模型——超越 ARIMA + R 码</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">满足 TAR——自回归模型的非线性扩展。</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="pr l mg mh mi me mj kp lv"/></div></div></a></div><p id="cc34" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有任何问题，请在评论中提问！你也可以通过 LinkedIn 联系我。</p><p id="4af5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.picostat.com/dataset/r-dataset-package-datasets-lynx" rel="noopener ugc nofollow" target="_blank">将</a>链接到数据(GNU)。</p></div></div>    
</body>
</html>