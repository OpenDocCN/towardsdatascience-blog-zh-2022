<html>
<head>
<title>Natural Language Process for Judicial Sentences with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现司法判决的自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-process-for-judicial-sentences-with-python-part-2-964b0e12dd4a#2022-10-31">https://towardsdatascience.com/natural-language-process-for-judicial-sentences-with-python-part-2-964b0e12dd4a#2022-10-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/273a81a62db10df78d427d649c3febad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jrAhtRi-5LqgkieR.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">https://pixabay.com/</a></p></figure><div class=""/><div class=""><h2 id="32f0" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">第2部分:描述性统计</h2></div><p id="c9c0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这一系列文章中，我将对司法判决进行一系列的NLP分析，目的是解决两个研究问题:</p><ul class=""><li id="19b7" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated">如果您需要检索详细信息，拥有一个标签良好的知识库是至关重要的。新闻档案每天都在更新，手动标注每篇文章可能会非常耗时。我的问题是:有没有可能实现一个预测算法，自动将新文章分类到现有类别中？</li><li id="a91d" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated">能否推断出文章的情绪，并将其与所属的类别联系起来？为此，我将对我的文章进行无监督的情感分析，对于每个类别，显示有多少文章被归类为正面或负面。</li></ul><p id="65b6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本系列的<a class="ae jg" href="https://valentinaalto.medium.com/natural-language-process-for-judicial-sentences-with-python-part-1-bdc01a4d7f04" rel="noopener">第1部分</a>中，我们介绍了数据集和一些预处理活动，如标记化、词干化和词汇化。</p><p id="e22f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们开始从我们的数据中获得一些有意义的见解和可视化表示。</p><h2 id="088e" class="mi mj jj bd mk ml mm dn mn mo mp dp mq lh mr ms mt ll mu mv mw lp mx my mz na bi translated"><strong class="ak">类别的频率</strong></h2><p id="a1f1" class="pw-post-body-paragraph ky kz jj la b lb nb kk ld le nc kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">现在我感兴趣的是调查哪个是类别出现的频率。在预测任务中也需要这些信息:事实上，在测试预测模型时，有一个评估基准是很有用的，它可以被设置为最频繁的基线预测，也就是说，将最频繁的类别分配给所有记录作为标签。</p><p id="d6e0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们用类别频率创建一个熊猫数据框架:</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="0bd4" class="mi mj jj nl b gy np nq l nr ns">#retrieving data</span><span id="e980" class="mi mj jj nl b gy nt nq l nr ns">df = pd.read_pickle('data/df.pkl')<br/>df=df.rename(columns={'topic':'category'})</span><span id="d058" class="mi mj jj nl b gy nt nq l nr ns">#creating a list of categories from the available ones<br/>categories = list(set([i for  l in df['category'].to_list() for i in l]))</span><span id="5e21" class="mi mj jj nl b gy nt nq l nr ns">#creating a df </span><span id="9851" class="mi mj jj nl b gy nt nq l nr ns">categories_list=[]<br/>count_list=[]<br/>for k in range(len(categories)):<br/>    counter=0<br/>    categories_list.append(categories[k])<br/>    for i in range(len(df)):<br/>        if categories[k] in df['category'][i]:<br/>            counter+=1<br/>    count_list.append(counter) <br/>    <br/>counts = pd.DataFrame({"Category": categories_list, "Count": count_list}).sort_values(by = "Count", ascending = False).reset_index(drop=True)<br/>counts.head(5)</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/de5ffd06281e83f8ebdf540a19106996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*PKN1_-hrFOxuNG6MsDoBCg.png"/></div></figure><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="f2fa" class="mi mj jj nl b gy np nq l nr ns">import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>sns.set_context("paper")</span><span id="7b7e" class="mi mj jj nl b gy nt nq l nr ns">fig, axis = plt.subplots(figsize = (16, 8))<br/>sns.barplot(counts.Category, counts.Count, ax = axis)<br/>axis.set_title("Category counts")</span><span id="ef0c" class="mi mj jj nl b gy nt nq l nr ns">for item in axis.get_xticklabels():<br/>    item.set_rotation(90)<br/>    item.set_fontsize(10)<br/>    item</span><span id="97fb" class="mi mj jj nl b gy nt nq l nr ns">fig.show()</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nv"><img src="../Images/e96e5c3c6ea4ed6db85b41cb3770e3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5R8chQdMOIpWj-ChxRYEeA.png"/></div></div></figure><p id="61d9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到，到目前为止，最常见的类别是税收:它几乎是第二常见类别的两倍。</p><p id="1da9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我最初想放弃那些少于20条记录的类别。然而，鉴于我分析的目标，我决定保留它们。事实上，我的最终目标是创建一个自动系统，能够在新文章插入数据库时对其进行标记，这样搜索它们就更容易了(在研究问题部分有更好的解释)。因此，我更喜欢保留所有已经提到的类别，由于数据库的不断输入，过一会儿记录会越来越多。</p><h2 id="bb90" class="mi mj jj bd mk ml mm dn mn mo mp dp mq lh mr ms mt ll mu mv mw lp mx my mz na bi translated">文章长度的分布</h2><p id="c393" class="pw-post-body-paragraph ky kz jj la b lb nb kk ld le nc kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在这一节中，我分析了文章长度在类别中的分布。我很想知道是否有些类别会比其他类别导致更长的文章。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="8c11" class="mi mj jj nl b gy np nq l nr ns">sns.set_context("talk")<br/>fig, axis = plt.subplots(nrows = 1, ncols = 1, figsize = (11, 6))</span><span id="bac1" class="mi mj jj nl b gy nt nq l nr ns">for category in categories_list:<br/>    mask = [category in df['category'][i] for i in range(len(df))]<br/>    x = [len(df[mask].reset_index(drop=True)['text'][i]) for i in range(len(df[mask]))]<br/>    sns.distplot(x, label = category, hist = False, ax = axis)</span><span id="9242" class="mi mj jj nl b gy nt nq l nr ns">plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')<br/>plt.title("Distributions of articles' lengths across various categories")</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/9a25d85bcb042eec57872a76c61de58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btkCz5K6pYZQ_dsaAn7fdQ.png"/></div></div></figure><p id="a8b1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">似乎所有的分布都趋向于在3k和5k字长之间达到它们的最大值，加上几乎所有的分布都非常窄。只有少数种类，如类足类动物，相对于其他种类，其分布范围要广得多。</p><h2 id="7849" class="mi mj jj bd mk ml mm dn mn mo mp dp mq lh mr ms mt ll mu mv mw lp mx my mz na bi translated">地理分析</h2><p id="e3f4" class="pw-post-body-paragraph ky kz jj la b lb nb kk ld le nc kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在这里，我将从文本中提取地缘政治实体，并查看哪些是美国“最热”的地区。我说的“热门”是指他们参与犯罪活动的次数。为了这个分析，我决定检查那些参与贩毒的人，但同样的推理适用于任何其他类别。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="bdd9" class="mi mj jj nl b gy np nq l nr ns">#let's create a list of geopolitical named entities. This will take a while. Skip to the next cell to directly download the results<br/>import pickle<br/>sites = [entity.text for i in range(len(df)) for entity in nlp(df['text'][i]).ents if (entity.label_=='GPE') &amp; <br/>     ('Drug Trafficking' in df['category'][i]) &amp; (entity.text!='U.S.')]</span><span id="3eb4" class="mi mj jj nl b gy nt nq l nr ns">with open("data/sites.txt", "wb") as fp:   #Pickling<br/>    pickle.dump(sites, fp)</span><span id="583b" class="mi mj jj nl b gy nt nq l nr ns">#investigate most common locations<br/>from collections import Counter<br/>c = Counter(sites)<br/>c.most_common(6)</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f4dba3289b506d58d7ed00e030b77d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*tbrrs5NuJ7hkcOH4heTf-A.png"/></div></figure><p id="7d3c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意:位置“美国”被解析为一个地理政治实体，但是为了本节的目的，我们应该只考虑单个州。</p><p id="71f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们绘制这些数据:</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="317b" class="mi mj jj nl b gy np nq l nr ns">#downloading necessary packages<br/>#! pip install --user basemap<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from mpl_toolkits.basemap import Basemap</span><span id="2332" class="mi mj jj nl b gy nt nq l nr ns">import os<br/>#os.environ['PROJ_LIB'] = r"C:\Users\valen\Anaconda3\pkgs\proj4-5.2.0-ha925a31_1\Library\share"</span><span id="a0cc" class="mi mj jj nl b gy nt nq l nr ns">os.environ['PROJ_LIB'] = r"...\Anaconda3\pkgs\proj4-5.2.0-ha925a31_1\Library\share"</span><span id="5024" class="mi mj jj nl b gy nt nq l nr ns">plt.figure(figsize=(20,10))<br/>m = Basemap(projection='robin',lon_0=0,resolution='c')<br/>m.fillcontinents(color='white',lake_color='#85A6D9')<br/>m.drawcoastlines(color='#6D5F47', linewidth=.4)<br/>m.drawcountries(color='#6D5F47', linewidth=.4)</span><span id="5d52" class="mi mj jj nl b gy nt nq l nr ns">#the following information have been seached on google, they are not present in the dataset</span><span id="6a18" class="mi mj jj nl b gy nt nq l nr ns">lats = [23.634501,31, 36.778259,  27.994402]<br/>lngs = [-102.552784,-100, -119.417931, -81.760254]<br/>populations = [93,76, 75, 67]<br/>x,y = m(lngs,lats)</span><span id="6a48" class="mi mj jj nl b gy nt nq l nr ns">s_populations = [p*5 for p in populations]</span><span id="3851" class="mi mj jj nl b gy nt nq l nr ns">m.scatter(<br/>    x,<br/>    y,<br/>    s=s_populations, #size<br/>    c='red', #color<br/>    marker='o', #symbol<br/>    alpha=0.25, #transparency<br/>    zorder = 2, #plotting order<br/>    )</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/93d11dfb2c91df8932b138ab2eeb0df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-gp4D2WcUBEoF0_k7BFdA.png"/></div></div></figure><h2 id="f3eb" class="mi mj jj bd mk ml mm dn mn mo mp dp mq lh mr ms mt ll mu mv mw lp mx my mz na bi translated">趋势类别随时间的演变</h2><p id="f608" class="pw-post-body-paragraph ky kz jj la b lb nb kk ld le nc kn lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">最后，在这一节中，我想考察一段时间内最常见的类别。为了做到这一点，我按年份汇总了我的数据集，并简单地计算了每个类别出现的次数。</p><pre class="ng nh ni nj gt nk nl nm nn aw no bi"><span id="132b" class="mi mj jj nl b gy np nq l nr ns">sns.set_context("paper")<br/>fig, axis = plt.subplots(nrows = 1, ncols = 1, figsize = (11, 6))</span><span id="670b" class="mi mj jj nl b gy nt nq l nr ns">for category in categories_list:<br/>    mask = [category in df['category'][i] for i in range(len(df))]<br/>    new_df=df[mask].reset_index(drop=True)<br/>    gap_df=new_df.resample('Y', on='date').count()['category']<br/>    <br/>    sns.lineplot(x=gap_df.index, y=gap_df, label=category)<br/>    <br/>plt.xticks(rotation=15)<br/>plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')<br/>plt.title('Evolution of trending categories across time')</span></pre><figure class="ng nh ni nj gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/c20e13abfd7d4f71e278cbf391cbf0b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F3N5YG5hC2eOsb0zErVKQg.png"/></div></div></figure><p id="05e3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上面的图表中我们可以看到一些标签是从某一年开始使用的。即民权或身份盗窃从2016年才开始使用。</p><p id="88f9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，在2015年之前，最常见的标签(税)只有1条。</p><p id="67ef" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下一篇文章中，我们将讨论TF-IDF分析:术语频率(TF)和逆文档频率(IDF)。</p><p id="1ce9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请继续关注第3部分！</p><h1 id="3f5f" class="oa mj jj bd mk ob oc od mn oe of og mq kp oh kq mt ks oi kt mw kv oj kw mz ok bi translated">参考</h1><ul class=""><li id="9da3" class="lu lv jj la b lb nb le nc lh ol ll om lp on lt lz ma mb mc bi translated">自然语言工具包</li><li id="031d" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">Python中的spaCy工业级自然语言处理</a></li><li id="a518" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://www.justice.gov/news" rel="noopener ugc nofollow" target="_blank">司法新闻| DOJ |司法部</a></li><li id="33ce" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://www.kaggle.com/datasets/jbencina/department-of-justice-20092018-press-releases" rel="noopener ugc nofollow" target="_blank">司法部2009-2018年新闻发布| Kaggle </a></li><li id="2528" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/publicdomain/zero/1.0/</a></li></ul></div></div>    
</body>
</html>