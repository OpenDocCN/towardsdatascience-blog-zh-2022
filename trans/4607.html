<html>
<head>
<title>Building a Convolutional Neural Network from Scratch using Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Numpy从头构建卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-convolutional-neural-network-from-scratch-using-numpy-a22808a00a40#2022-10-13">https://towardsdatascience.com/building-a-convolutional-neural-network-from-scratch-using-numpy-a22808a00a40#2022-10-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="12c2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">随着计算机视觉应用在我们的生活中变得无处不在，理解卷积神经网络的工作原理对于每个数据科学从业者来说都是至关重要的</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/995c49c0e27577be507dd46fff736493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgc-SpdAdyTkhimxHlpKuA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:canva.com</p></figure><p id="4948" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<a class="ae kv" rel="noopener" target="_blank" href="/building-a-deep-neural-network-from-scratch-using-numpy-4f28a1df157a">我之前的文章</a>中，我在没有使用Tensorflow、Pytorch、Keras等流行的现代深度学习库的情况下，构建了一个深度神经网络。我后来用那个网络来分类手写数字。所获得的结果不是最先进的水平，但它们仍然是令人满意的。现在我想更进一步，我的目标是只用Numpy开发一个卷积神经网络(CNN)。</p><p id="d093" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这项任务背后的动机与创建完全连接的网络的动机相同:Python深度学习库尽管是强大的工具，但却阻止了从业者理解底层正在发生的事情。对于CNN来说尤其如此，因为这个过程比经典深度网络进行的过程更不直观。唯一的解决办法就是亲自动手，尝试自己实现这些网络。</p><p id="242d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我打算把这篇文章作为一个实用的实践指南，而不是一个关于CNN运作原理的全面指南。因此，理论部分是狭窄的，主要服务于实践部分的理解。对于需要更好地理解卷积网络工作原理的读者，我留下了一些很好的参考资料。查看<a class="ae kv" href="https://www.youtube.com/watch?v=Lakz2MoHy6o&amp;t=1273s&amp;ab_channel=TheIndependentCode" rel="noopener ugc nofollow" target="_blank">本视频</a>来自<a class="ae kv" href="https://www.youtube.com/channel/UC1OLIHvAKBQy3o5LcbbxUSg" rel="noopener ugc nofollow" target="_blank">的独立代码</a>和<a class="ae kv" rel="noopener" target="_blank" href="/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53">本完整指南</a>。</p><h1 id="05e3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是卷积神经网络？</h1><p id="7eef" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">卷积神经网络使用特定的架构和操作，这使它们非常适合于图像相关的任务，如图像分类、对象定位、图像分割和许多其他任务。它们大致模拟了人类的视觉皮层，其中每个生物神经元只对视野的一小部分做出反应。此外，高级神经元对其他低级神经元的输出做出反应<a class="ae kv" href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" rel="noopener ugc nofollow" target="_blank">【1】</a>。</p><p id="697c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我在之前的<a class="ae kv" rel="noopener" target="_blank" href="/building-a-deep-neural-network-from-scratch-using-numpy-4f28a1df157a">文章</a>中所展示的，即使是经典的神经网络也可以用于像图像分类这样的任务。问题是，它们只适用于小尺寸的图像，当应用于中等或大尺寸的图像时，它们变得非常低效。原因是经典神经网络需要大量的参数。例如，一个200x200像素的图像有40000个像素，如果网络的第一层有1000个单元，那么仅第一层就有4000万个权重。由于CNN实现了部分连接的层和重量共享，这个问题得到了极大的缓解。</p><p id="ece4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积神经网络的主要组件包括:</p><ul class=""><li id="e1b9" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">卷积层</li><li id="4f14" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">池层</li></ul><h2 id="5e29" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">卷积层</h2><p id="ac13" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">卷积层由一组过滤器(也称为内核)组成，当应用于该层的输入时，会对原始图像进行某种修改。滤镜是一个矩阵，其元素值定义了对原始图像执行的修改类型。如下所示的3x3内核具有突出显示图像垂直边缘的效果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a0868098605b12edd190dfc1ded41756.png" data-original-src="https://miro.medium.com/v2/resize:fit:172/1*2V5YIujyr_f9k7RrQqeqqw.gif"/></div></figure><p id="d70c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不同的是，这个内核强调水平边缘:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/0c3b04fd74cc0bb3ae9d77807704c000.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/1*CVIbKfPNMTRu8FKJgdXMYg.gif"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8b3b72118a555d0ca9d6f4729ed22bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*vd0x7loCpzE68xZYBG0Mew.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卷积的效果。来源:<a class="ae kv" href="https://en.wikipedia.org/wiki/Kernel_(image_processing)" rel="noopener ugc nofollow" target="_blank">维基百科</a>。</p></figure><p id="9e40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">核中元素的值不是手动选择的，而是网络在训练期间学习的参数。</p><p id="f0e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">卷积的作用是隔离图像中存在的不同特征。密集层稍后会使用这些功能。</p><h2 id="1bbd" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">池层</h2><p id="39c9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">池层非常简单。池层的任务是缩小输入图像，以减少网络的计算负载和内存消耗。减少图像尺寸，实际上意味着减少参数的数量。</p><p id="1e49" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">池层所做的是使用一个内核(通常是2x2的维度)并将输入图像的一部分聚合成一个值。例如，一个2x2 max池内核取输入图像的4个像素，并只返回具有最大值的像素。</p><h1 id="747b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Python实现</h1><p id="2c83" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">所有的代码都可以在<a class="ae kv" href="https://github.com/andreoniriccardo/CNN-from-scratch" rel="noopener ugc nofollow" target="_blank">这个GitHub资源库</a>中找到。</p><div class="ns nt gp gr nu nv"><a href="https://github.com/andreoniriccardo/CNN-from-scratch" rel="noopener  ugc nofollow" target="_blank"><div class="nw ab fo"><div class="nx ab ny cl cj nz"><h2 class="bd ir gy z fp oa fr fs ob fu fw ip bi translated">GitHub-andreoniriccardo/CNN-从零开始:从零开始的卷积神经网络</h2><div class="oc l"><p class="bd b dl z fp oa fr fs ob fu fw dk translated">github.com</p></div></div><div class="od l"><div class="oe l of og oh od oi kp nv"/></div></div></a></div><p id="a13f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个实现背后的想法是创建Python类来表示卷积和最大池层。此外，由于这段代码后来被应用于MNIST分类问题，我为softmax层创建了一个类。</p><p id="384c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个类都包含实现正向传播和反向传播的方法。</p><p id="e41b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些层随后被连接成一个列表，以生成实际的CNN。</p><h2 id="c1fb" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">卷积层实现</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="0ffb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">构造器将卷积层的核的数量及其大小作为输入。我假设只使用大小为<code class="fe ol om on oo b"><strong class="ky ir">kernel_size</strong></code> <strong class="ky ir"> </strong>乘<code class="fe ol om on oo b"><strong class="ky ir">kernel_size</strong></code> <strong class="ky ir">的平方核。</strong></p><p id="2235" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第5行，我生成了形状为<code class="fe ol om on oo b"><strong class="ky ir">(kernel_num, kernel_size, kernel_size)</strong></code> <strong class="ky ir"> </strong>的随机过滤器，并将每个元素除以内核大小的平方进行归一化。</p><p id="7fd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ol om on oo b"><strong class="ky ir">patches_generator()</strong></code> <strong class="ky ir"> </strong>方法是一个生成器。它产生执行每个卷积步骤的图像部分。</p><p id="669c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ol om on oo b"><strong class="ky ir">forward_prop()</strong></code> <strong class="ky ir"> </strong>方法对上述方法生成的每个面片进行卷积。</p><p id="90c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，<code class="fe ol om on oo b"><strong class="ky ir">back_prop()</strong></code> <strong class="ky ir"> </strong>方法负责计算损失函数相对于层的每个权重的梯度，并相应地更新权重值。注意，这里所说的损失函数并不是网络的全局损失。取而代之的是由最大池层传递给前一卷积层的损失函数。</p><p id="3726" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了展示这个类的实际效果，我用32个3x3滤镜实例化了一个<code class="fe ol om on oo b"><strong class="ky ir">ConvolutionLayer</strong></code> <strong class="ky ir"> </strong>对象，并对一个图像应用了正向传播方法。输出由32个稍小的图像组成。</p><p id="11ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原始输入图像的大小为28x28像素，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/0fedd603be651acabe2c0dae7a5d709b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1M_tqJbBH3CtSN0YhLOlfg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者。</p></figure><p id="1d2d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在应用卷积层的前向传播方法之后，我获得了32个大小为26×26的图像。这里我画了其中一个:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/5b034b87f7d37dac4dbf8b69c5c13d46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rPz_TAsHqBwdfJI60wySw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者。</p></figure><p id="c3da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的，图像稍微变小了，手写数字也变得不那么清晰了。考虑到这个操作是由一个填充了随机值的过滤器执行的，所以它不代表一个经过训练的CNN实际执行的操作。尽管如此，你可以得到这样的想法，这些卷积提供了更小的图像，其中对象特征是孤立的。</p><h2 id="d427" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">最大池层实施</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="f982" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">构造函数方法只分配内核大小值。以下方法与卷积层的方法类似，主要区别在于反向传播函数不更新任何权重。事实上，池层并不依赖于权重来执行聚合。</p><h2 id="97c5" class="nd lt iq bd lu ne nf dn ly ng nh dp mc lf ni nj me lj nk nl mg ln nm nn mi no bi translated">Sigmoid层实现</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="65fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">softmax层使由max池提供的输出体积变平，并输出10个值。它们可以被解释为对应于数字0-9的图像的概率。</p><h1 id="60dc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="d7c0" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">你可以克隆包含代码的<a class="ae kv" href="https://github.com/andreoniriccardo/CNN-from-scratch" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>，用<code class="fe ol om on oo b"><strong class="ky ir">main.py</strong></code> <strong class="ky ir"> </strong>脚本玩。该网络当然没有达到最先进的性能，但在几个时期后达到96%的准确率。</p><h1 id="ee65" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><p id="5ba8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">[1]: <a class="ae kv" href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" rel="noopener ugc nofollow" target="_blank">使用Scikit-Learn、Keras和TensorFlow进行机器实践学习，第二版——aurélien géRon</a></p><p id="1a1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]: <a class="ae kv" href="https://www.youtube.com/watch?v=0zbhg79i_Bs&amp;t=1800s&amp;ab_channel=AhladKumar" rel="noopener ugc nofollow" target="_blank">深度学习54: CNN_6 —用Python从零开始实现CNN</a></p><p id="b620" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3]: <a class="ae kv" href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank">卷积神经网络，深度学习。艾</a></p></div></div>    
</body>
</html>