<html>
<head>
<title>Fundamental EDA Techniques for NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理的基本EDA技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fundamental-eda-techniques-for-nlp-f81a93696a75#2022-08-31">https://towardsdatascience.com/fundamental-eda-techniques-for-nlp-f81a93696a75#2022-08-31</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d681" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">从数量、长度、词频到为什么不需要词云</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/55e3fdb9d22bffd398cf0cc843f53b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tGvdQakIzad56nQTmac2uQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供。</p></figure><p id="fd96" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">探索性数据分析(EDA)是任何数据科学项目工作流程中的一个重要步骤。然而，当在自然语言处理(NLP)项目中处理文本数据时，您需要应用与处理表格数据不同的技术。</p><blockquote class="lu"><p id="7127" class="lv lw it bd lx ly lz ma mb mc md lt dk translated">处理文本数据[…]时，您需要应用与处理表格数据等不同的技术。</p></blockquote><p id="c9d1" class="pw-post-body-paragraph ky kz it la b lb me ju ld le mf jx lg lh mg lj lk ll mh ln lo lp mi lr ls lt im bi translated">因此，在本文中，我们将研究一些针对文本数据的基本EDA技术:</p><ol class=""><li id="357b" class="mj mk it la b lb lc le lf lh ml ll mm lp mn lt mo mp mq mr bi translated"><a class="ae ms" href="#74ea" rel="noopener ugc nofollow"> <strong class="la iu">计数和长度</strong> </a> <strong class="la iu"> : </strong>我们将看看字符计数、单词计数、句子计数和字符串计数，以及单词和句子的平均长度。</li><li id="62c6" class="mj mk it la b lb mt le mu lh mv ll mw lp mx lt mo mp mq mr bi translated"><a class="ae ms" href="#b757" rel="noopener ugc nofollow"> <strong class="la iu">词频分析</strong> </a> <strong class="la iu"> : </strong>我们来看看最常用的词和n元词，讨论一下为什么不需要词云。</li></ol></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="e741" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于本文，我们将使用来自Kaggle的<a class="ae ms" href="https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank">女装电子商务服装评论</a>数据集。</p><p id="f7a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了简化示例，我们将使用450条正面评论(<code class="fe nf ng nh ni b">rating == 5</code>)和450条负面评论(<code class="fe nf ng nh ni b">rating == 1</code>)。这将数据点的数量减少到900行，将评级类别的数量减少到两个，并平衡正面和负面的评论。</p><p id="0561" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，我们将只使用两列:评论文本和评级。</p><p id="c6cb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">精简数据集的数据帧头如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/acc5bf94b9c42ae5e775c875b6708302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aS_fAX_WkGZkUNegK7EB4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">简化的<a class="ae ms" href="https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank">女性电子商务服装评论</a>数据集负责人(图片由作者提供)</p></figure></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="74ea" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">计数和长度</h1><p id="e719" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">先说一些基本的计数和长度。我们将通过一个简单的示例回顾文本来介绍每个功能:</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="7c25" class="ol nl it ni b gy om on l oo op">text = "Very #comfortable and #versatile. Got lots of compliments."</span></pre><h2 id="2f11" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">字符计数</h2><p id="718b" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">你可以从计算一篇文章中的所有字符开始。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="0c73" class="ol nl it ni b gy om on l oo op">char_count = len(text)</span></pre><p id="a79f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们复习课文的例子，<code class="fe nf ng nh ni b">char_count = 58</code>。</p><h2 id="7c2a" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">字数</h2><p id="966f" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">接下来，你可以统计一篇课文中的所有单词。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="984e" class="ol nl it ni b gy om on l oo op">word_count = len(text.split())</span></pre><p id="7fd9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们的示例复习文本，<code class="fe nf ng nh ni b">word_count = 8</code>。</p><h2 id="d373" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">句子计数</h2><p id="1015" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">如果你有较长的文本，你也可以计算句子的数量。为此，您需要从NLTK导入<code class="fe nf ng nh ni b">sent_tokenize</code>函数。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="c48b" class="ol nl it ni b gy om on l oo op">import nltk<br/>from nltk.tokenize import sent_tokenize</span><span id="cc28" class="ol nl it ni b gy pb on l oo op">sent_count = len(sent_tokenize(text))</span></pre><p id="eaaf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们的示例复习文本，<code class="fe nf ng nh ni b">sent_count = 2</code>。</p><h2 id="a75b" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">字符串计数</h2><p id="38ee" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">您还可以计算特定的字符或字符串。例如，你可以通过计算字符“#”来计算标签的数量。你也可以计算提及次数(“@”)或网站(“http”)等等。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="e818" class="ol nl it ni b gy om on l oo op">hashtag_count = text.count("#")</span></pre><p id="f5a1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们的示例复习文本，<code class="fe nf ng nh ni b">hashtag_count = 2</code>。</p><h2 id="2211" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">平均单词长度</h2><p id="5154" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">你也可以计算一个单词的平均长度。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="4507" class="ol nl it ni b gy om on l oo op">import numpy as np</span><span id="c360" class="ol nl it ni b gy pb on l oo op">avg_word_len = np.mean([len(w) for w in str(text).split()])</span></pre><p id="6224" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们的示例复习文本，<code class="fe nf ng nh ni b">avg_word_len = 6.375</code>。</p><h2 id="c82a" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">平均句子长度</h2><p id="fc40" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">如果你有较长的文本，你也可以计算一个句子的平均长度。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="04aa" class="ol nl it ni b gy om on l oo op">avg_sent_len = np.mean([len(w.split()) for w in sent_tokenize(text)])</span></pre><p id="4d49" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于我们复习课文的例子，<code class="fe nf ng nh ni b">avg_sent_len = 4.0</code>。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="76b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<code class="fe nf ng nh ni b">map()</code>功能，您可以将上述所有技术应用到pandas数据框架中的文本列:</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="dda7" class="ol nl it ni b gy om on l oo op">import numpy as np<br/>import nltk<br/>from nltk.tokenize import sent_tokenize</span><span id="90d4" class="ol nl it ni b gy pb on l oo op"># Character counts<br/>df["char_count"] = df["text"].map(lambda x: len(x))</span><span id="36e1" class="ol nl it ni b gy pb on l oo op"># Word counts<br/>df["word_count"] = df["text"].map(lambda x: len(x.split()))</span><span id="30b8" class="ol nl it ni b gy pb on l oo op"># Sentence counts<br/>df["sent_count"] = df["text"].map(lambda x: len(sent_tokenize(x)))</span><span id="2fc0" class="ol nl it ni b gy pb on l oo op"># String counts<br/>df["hashtag_count"] = df["text"].map(lambda x: x.count("#"))</span><span id="1e3d" class="ol nl it ni b gy pb on l oo op"># Average word length<br/>df["avg_word_len"] = df["text"].map(lambda x: np.mean([len(w) for w in str(x).split()]))</span><span id="fe6a" class="ol nl it ni b gy pb on l oo op"># Average sentence length<br/>df["avg_sent_len"] = df["text"].map(lambda x: np.mean([len(w.split()) for w in sent_tokenize(x)]))</span></pre><p id="c259" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在此之后，您的初始数据帧可能如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/fe89f48221a658928fcea46a31ae874e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IYSvJcHOJ_zx2T5Jpr0diQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从文本创建新特征后的DataFrame的头部(图片由作者提供)</p></figure></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="6397" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，您可以使用直方图、KDE图或箱线图来探索这些新功能。如果您正在处理文本分类问题，当您可视化数据时，也可以按类进行区分。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="7029" class="ol nl it ni b gy om on l oo op">import seaborn as sns</span><span id="6b8c" class="ol nl it ni b gy pb on l oo op"># Histogram<br/>sns.histplot(data = df, x = feature, hue = class)</span><span id="1cfb" class="ol nl it ni b gy pb on l oo op"># KDE plot<br/>sns.kdeplot(data = df, x = feature, hue = class)</span><span id="61e6" class="ol nl it ni b gy pb on l oo op"># Boxplot<br/>sns.boxplot(data = df, x = class, y = feature)</span></pre><p id="275d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面你可以看到我们的例子KDE图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/3b772b92b37696e022bc7d5c9c19763c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TTBfmSDOW8mauNCCPsNLuw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由“评级”类分隔的新创建功能的KDE图(图片由作者提供)</p></figure><h1 id="b757" class="nk nl it bd nm nn pe np nq nr pf nt nu jz pg ka nw kc ph kd ny kf pi kg oa ob bi translated">词频分析</h1><p id="9007" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">这是你可能想使用单词cloud的地方。不要。</p><p id="641a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我专门用了一整节的篇幅来讲述为什么我会在这篇文章之后避免使用单词云。但我们先来说说如何探索和可视化最常用的术语。</p></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><p id="bec3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在开始之前，我们需要对文本进行预处理，将所有内容都改为小写，并删除所有标点符号和非罗马字符。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="38e3" class="ol nl it ni b gy om on l oo op">import re<br/>import string</span><span id="cff4" class="ol nl it ni b gy pb on l oo op">def clean_text(text):<br/>    # Convert text to lowercase<br/>    text = text.lower()</span><span id="6ced" class="ol nl it ni b gy pb on l oo op">    # Remove punctuation<br/>    text = re.sub("[%s]" % re.escape(string.punctuation), "", text)</span><span id="13a6" class="ol nl it ni b gy pb on l oo op">    # Remove non-Roman characters<br/>    text = re.sub("([^\x00-\x7F])+", " ", text)<br/>    <br/>    return text</span><span id="0a88" class="ol nl it ni b gy pb on l oo op">df["text_clean"] = df["text"].map(lambda x: clean_text(x))</span></pre><p id="4d81" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">清理后的评论文本如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/df54986a7e6c1f9d31097f0803a472c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*28F-P8_kG4aUGrEUFZZv_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">左边是原始评论文本，上面是经过清理的评论文本(图片由作者提供)</p></figure><h2 id="fbd5" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">最常用的词</h2><p id="9d94" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">要得到最常用的词，首先需要创建一个所谓的“语料库”。这意味着我们创建了一个列表，其中包含所有来自已清理评论文本的相关单词。我说的“相关”词是指不是停用词的词，比如“是”、“for”、“a”、“and”。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="b37f" class="ol nl it ni b gy om on l oo op">from nltk.corpus import stopwords</span><span id="b688" class="ol nl it ni b gy pb on l oo op">stop = set(stopwords.words("english"))</span><span id="df3d" class="ol nl it ni b gy pb on l oo op">corpus = [word for i in df["text_clean"].str.split().values.tolist() for word in i if (word not in stop)]</span></pre><p id="ec41" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nf ng nh ni b">corpus</code>看起来是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/ff56aed775a6d01c78cbdd39f1bf3d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ybP37YApvyWcnEsc-nHLhg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文集的开头(图片由作者提供)</p></figure><p id="8119" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，要从语料库中获取最常见的单词，您有两种选择:</p><p id="67e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用<code class="fe nf ng nh ni b">FreqDist</code>类:</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="aada" class="ol nl it ni b gy om on l oo op">from nltk.probability import FreqDist<br/>most_common = FreqDist(corpus).most_common(10)</span></pre><p id="acb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">或者你可以使用<code class="fe nf ng nh ni b">Counter</code>类:</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="e1f7" class="ol nl it ni b gy om on l oo op">from collections import Counter<br/>most_common = Counter(corpus).most_common(10)</span></pre><p id="52b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<code class="fe nf ng nh ni b">most_common(10)</code>函数，将返回前10个最常用的单词及其频率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/72613f26fbb063f3d939f096b9291df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*HdqnS8CFp-mvqzGZfWOiMQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最常用的单词(图片由作者提供)</p></figure><p id="72ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了这个，你可以很容易地创建一个最常见的单词的柱状图:</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="13c7" class="ol nl it ni b gy om on l oo op">words, frequency = [], []<br/>for word, count in most_common:<br/>    words.append(word)<br/>    frequency.append(count)<br/>    <br/>sns.barplot(x = frequency, y = words)</span></pre><p id="5952" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面，你可以看到负面和正面评论中最常见的10个词:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/0ef078256c447d1f61ed50e1599d6a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLM1ADd4PlbnfHhd8Nj0ww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由“评级”类分隔的最常用词(图片由作者提供)。</p></figure><p id="d328" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这个技巧中，我们可以看到在正面和负面的评论中,“连衣裙”和“上衣”是最常被提及的。然而，在积极的评论中，像“伟大”和“完美”这样的形容词被提到了很多，而在消极的评论中却不是这样。</p><h2 id="37b9" class="ol nl it bd nm oq or dn nq os ot dp nu lh ou ov nw ll ow ox ny lp oy oz oa pa bi translated">最常见的N-gram</h2><p id="4293" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">让我们对n-grams做同样的事情。什么是n-gram？它是文本中n个单词的序列。</p><p id="68e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，句子“你今天好吗？”的二元语法(n = 2)会是:“你好吗”、“你好吗”和“今天的你”。三元组(n =3)将是“你好吗”和“你今天好吗”。</p><p id="e409" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要将文本分成n元语法，可以使用如下所示的<code class="fe nf ng nh ni b">CountVectorizer</code>类。</p><p id="a060" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在<code class="fe nf ng nh ni b">ngram_range</code>中，您可以定义要考虑的n-grams。比如<code class="fe nf ng nh ni b">ngram_range = (2, 2)</code>只考虑二元，<code class="fe nf ng nh ni b">ngram_range = (3, 3)</code>只考虑三元，<code class="fe nf ng nh ni b">ngram_range = (2, 3)</code>考虑二元和三元。</p><pre class="kj kk kl km gt oh ni oi oj aw ok bi"><span id="8a88" class="ol nl it ni b gy om on l oo op">from sklearn.feature_extraction.text import CountVectorizer</span><span id="1672" class="ol nl it ni b gy pb on l oo op"># Initialize CountVectorizer<br/>vec = CountVectorizer(stop_words = stop, ngram_range = (2, 2))</span><span id="b75e" class="ol nl it ni b gy pb on l oo op"># Matrix of ngrams<br/>bow = vec.fit_transform(df["text_clean"])</span><span id="0d6f" class="ol nl it ni b gy pb on l oo op"># Count frequency of ngrams<br/>count_values = bow.toarray().sum(axis=0)</span><span id="cae3" class="ol nl it ni b gy pb on l oo op"># Create DataFrame from ngram frequencies<br/>ngram_freq = pd.DataFrame(sorted([(count_values[i], k) for k, i in vec.vocabulary_.items()], reverse = True))<br/>ngram_freq.columns = ["frequency", "ngram"]</span></pre><p id="9b31" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">得到的数据帧<code class="fe nf ng nh ni b">ngram_freq</code>如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pn"><img src="../Images/7a19c7494cac995554fc259f7c1067d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FiamVjPxU15bF0Tom__EWw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">包含二元模型的数据帧头(图片由作者提供)</p></figure><p id="a368" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面你可以看到由正面和负面评论分开的二元和三元词汇:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/5ca931dc1e6af68c8f48943dd6ff1ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_r25vTP0MKrEO8UEeYPiSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按“评级”分类最常见的双字母组合(图片由作者提供)。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/a0a130d4027bd38fc4a9bab2df51412b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mUAHzG0_JrLFl3rI0mhFcw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按“评级”分类最常见的三元组(图片由作者提供)。</p></figure><p id="c161" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，这种EDA技术有助于你理解评论的不同基调。</p><h1 id="4b78" class="nk nl it bd nm nn pe np nq nr pf nt nu jz pg ka nw kc ph kd ny kf pi kg oa ob bi translated">用那些文字云想念我</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pp"><img src="../Images/e42f367f9f8a6af77a1159dea43b70b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*Ngsb4Xh9OTkbvohs3bROkg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由作者提供。</p></figure><p id="9126" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，我们怎么没有谈到单词云？是的—您可以在不使用词云的情况下对文本数据执行EDA。</p><p id="6e06" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">字云何惑</strong>。虽然较频繁的术语比不太频繁的术语以更大的字体显示，但是很难掌握相似的频繁词之间的顺序。</p><p id="58bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一个简单的<strong class="la iu">条形图</strong>可能不像单词云那样华丽，但它在可视化精确排名和术语频率方面做得更好。</p><p id="0550" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，除非你的管理层真的想看到一个词云，否则我会推荐用条形图来代替。</p><blockquote class="lu"><p id="5bbb" class="lv lw it bd lx ly lz ma mb mc md lt dk translated">除非你的管理层真的想看到一个词云，否则我会推荐用条形图来代替。</p></blockquote><h1 id="c15e" class="nk nl it bd nm nn pe np nq nr pf nt nu jz pq ka nw kc pr kd ny kf ps kg oa ob bi translated">结论</h1><p id="13a3" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">在本文中，我们研究了一些针对文本数据的基本EDA技术:</p><ol class=""><li id="d8ae" class="mj mk it la b lb lc le lf lh ml ll mm lp mn lt mo mp mq mr bi translated"><strong class="la iu">计数和长度:</strong>我们查看了字符数、字数、句子数和字符串数，以及平均单词和句子长度。</li><li id="1a5c" class="mj mk it la b lb mt le mu lh mv ll mw lp mx lt mo mp mq mr bi translated"><strong class="la iu">词频分析:</strong>我们看了最常用的词和n-gram，讨论了为什么不需要词云。</li></ol><p id="fb1b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是所有可快速复制的代码片段:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pt pu l"/></div></figure><p id="4563" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在这篇关于<a class="ae ms" rel="noopener" target="_blank" href="/intermediate-eda-techniques-for-nlp-2c898cc96d1d">“NLP的中级EDA技术”</a>的文章中找到这篇文章的续篇:</p><div class="pv pw gp gr px py"><a rel="noopener follow" target="_blank" href="/intermediate-eda-techniques-for-nlp-2c898cc96d1d"><div class="pz ab fo"><div class="qa ab qb cl cj qc"><h2 class="bd iu gy z fp qd fr fs qe fu fw is bi translated">面向自然语言处理的中级EDA技术</h2><div class="qf l"><h3 class="bd b gy z fp qd fr fs qe fu fw dk translated">如何对自然语言处理的文本数据进行探索性数据分析</h3></div><div class="qg l"><p class="bd b dl z fp qd fr fs qe fu fw dk translated">towardsdatascience.com</p></div></div><div class="qh l"><div class="qi l qj qk ql qh qm ks py"/></div></div></a></div></div><div class="ab cl my mz hx na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="im in io ip iq"><h1 id="ed51" class="nk nl it bd nm nn no np nq nr ns nt nu jz nv ka nw kc nx kd ny kf nz kg oa ob bi translated">喜欢这个故事吗？</h1><p id="ae97" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated"><em class="pm">这里收集了我的其他自然语言处理文章:</em></p><div class="pv pw gp gr px"><div role="button" tabindex="0" class="ab bv gv cb fp qn qo bn qp ks ex"><div class="qq l"><div class="ab q"><div class="l di"><img alt="Leonie Monigatti" class="l de bw qr qs fe" src="../Images/61f354281722566e5c755e2cf181514f.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*TTIl4oynrJyfIkLbC6fumA.png"/><div class="fb bw l qr qs fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated">莉奥妮·莫尼加蒂</p></div></div><div class="qv qw gw l"><h2 class="bd iu vy mj fp vz fr fs qe fu fw is bi translated">自然语言处理</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wa au wb wc wd sp we an eh ei wf wg wh el em eo de bk ep" href="https://medium.com/@iamleonie/list/natural-language-processing-nlp-52815a8f7361?source=post_page-----f81a93696a75--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wi l fo"><span class="bd b dl z dk">3 stories</span></div></div></div><div class="ri dh rj fp ab rk fo di"><div class="di ra bv rb rc"><div class="dh l"><img alt="Found the words “EDA” (Exploratory Data Analysis), “NLP” (Natural language processing), “ngram”, “sentiment”, “word”, “character” in a word search." class="dh" src="../Images/114e99636fcb2dad2d15788cc72ecedf.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*Qe1OSC3jvRzu3FQM1IEjNQ.png"/></div></div><div class="di ra bv rd re rf"><div class="dh l"><img alt="Found the words “EDA” (Exploratory Data Analysis), “NLP” (Natural language processing), “ngram”, “sentiment”, “word”, “character” in a word search." class="dh" src="../Images/63431c479bb6e1c393d1680e38ba5a20.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*tGvdQakIzad56nQTmac2uQ.png"/></div></div><div class="di bv rg rh rf"><div class="dh l"><img alt="The tokens of the sentence “Visualizing Part-of-Speech Tags with NLTK and Spacy” are highlighted in color according to their POS tag" class="dh" src="../Images/e0eb295e480ffb6ba504d17ebf32966f.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*m2qeNjOSiDZzTFhdHpORqw.png"/></div></div></div></div></div><p id="b6ed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="pm">如果你想把我的新故事直接发到你的收件箱，请务必</em> <a class="ae ms" href="https://medium.com/subscribe/@iamleonie" rel="noopener"> <em class="pm">订阅</em> </a> <em class="pm">！</em></p><p id="e677" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="pm">成为媒介会员，阅读更多来自我和其他作家的故事。报名时可以用我的</em> <a class="ae ms" href="https://medium.com/@iamleonie/membership" rel="noopener"> <em class="pm">推荐链接</em> </a> <em class="pm">支持我。我将收取佣金，不需要你额外付费。</em></p><div class="pv pw gp gr px py"><a href="https://medium.com/@iamleonie/membership" rel="noopener follow" target="_blank"><div class="pz ab fo"><div class="qa ab qb cl cj qc"><h2 class="bd iu gy z fp qd fr fs qe fu fw is bi translated">通过我的推荐链接加入Medium—Leonie Monigatti</h2><div class="qf l"><h3 class="bd b gy z fp qd fr fs qe fu fw dk translated">阅读Leonie Monigatti(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接…</h3></div><div class="qg l"><p class="bd b dl z fp qd fr fs qe fu fw dk translated">medium.com</p></div></div><div class="qh l"><div class="ro l qj qk ql qh qm ks py"/></div></div></a></div><p id="c115" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="pm">在</em> <a class="ae ms" href="https://twitter.com/helloiamleonie" rel="noopener ugc nofollow" target="_blank"> <em class="pm">上找我</em></a><em class="pm"/><a class="ae ms" href="https://www.linkedin.com/in/804250ab/" rel="noopener ugc nofollow" target="_blank"><em class="pm">LinkedIn</em></a><em class="pm"/><a class="ae ms" href="https://www.kaggle.com/iamleonie" rel="noopener ugc nofollow" target="_blank"><em class="pm">ka ggle</em></a><em class="pm">！</em></p><h1 id="3d9a" class="nk nl it bd nm nn pe np nq nr pf nt nu jz pg ka nw kc ph kd ny kf pi kg oa ob bi translated">资料组</h1><p id="a4b5" class="pw-post-body-paragraph ky kz it la b lb oc ju ld le od jx lg lh oe lj lk ll of ln lo lp og lr ls lt im bi translated">《nicapotato》《女装电商服装评论》。(License:CC0:Public Domain)<a class="ae ms" href="https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/nica potato/women-ecommerce-clothing-reviews</a>(2022年8月30日访问)。</p></div></div>    
</body>
</html>