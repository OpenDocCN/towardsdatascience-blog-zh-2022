<html>
<head>
<title>Part Of Speech (POS) tagging in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理中的词性标注</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/part-of-speech-pos-tagging-in-nlp-e067a1c5e06c#2022-03-04">https://towardsdatascience.com/part-of-speech-pos-tagging-in-nlp-e067a1c5e06c#2022-03-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fca9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何为 NLP 选择模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e58717a83cf3e3af28bef1bf5e2cdb0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kojtyr8_ihyMvi1cNN5-vA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="8c99" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所有语言的基础是单词。单词根据它们在句子中的功能被分为词类。重要的是要认识到，一个单词属于多个词类并不罕见，这取决于该单词的使用方式。理解这种基本的分类需要大量的训练。</p><p id="0562" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在自然语言处理(NLP)中，有一个类似的任务叫做<strong class="kx ir">词性标注</strong>，目的是将句子中的每个单词标注到正确的<strong class="kx ir">词性</strong>(词性)。<strong class="kx ir"> </strong>词性标注是一项消歧任务。一个单词可以有多个词性标签；目标是在给定当前上下文的情况下找到正确的标签<strong class="kx ir">。例如,<em class="lr"> left </em>在用作“他<em class="lr">离开</em>房间”时可以是动词，在用作“<em class="lr">离开</em>房间”时可以是名词。</strong></p><p id="9251" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">词性标注是自然语言处理中的一个基本问题。有许多基于 POS 标签的 NLP 任务。大多数好的词性标注者报告的准确率都在 97%以上。然而，一些学者<a class="ae ls" href="https://nlp.stanford.edu/pubs/CICLing2011-manning-tagging.pdf" rel="noopener ugc nofollow" target="_blank">认为</a>每个令牌的准确性不是估计 POS 引擎准确性的最佳方式。在他们看来，在句子层面，准确率远低于声称的 97%。</p><h1 id="7e42" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">使用空间的词性标注</h1><p id="819a" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">SpaCy 提供了四种英语词性标注模型-</p><ul class=""><li id="12b4" class="mq mr iq kx b ky kz lb lc le ms li mt lm mu lq mv mw mx my bi translated">'核心网'</li><li id="d6e8" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">en_core_web_md '</li><li id="c2c9" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">en_core_web_lg '</li><li id="70cb" class="mq mr iq kx b ky mz lb na le nb li nc lm nd lq mv mw mx my bi translated">en_core_web_trf '</li></ul><p id="980b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我的合作伙伴<a class="ae ls" href="https://www.behance.net/abridged_story" rel="noopener ugc nofollow" target="_blank">玛姆塔·查克拉沃蒂</a>创造了<a class="ae ls" href="https://sauravc.online/?p=614" rel="noopener ugc nofollow" target="_blank">一个可视化效果</a>来识别马丁·路德·金著名的“我有一个梦想”每一段的位置演讲。</p><p id="26a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">她用的是 SpaCy 的‘en _ core _ web _ LG’语言模型。</p><p id="df4b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">语言模型的质量取决于两个构件——模型架构和训练数据。</p><p id="1339" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">' en_core_web_lg '的代码不是公开的，所以我们无法确认模型架构。然而，我们知道 SpaCy 已经在来源于 notes 5.0 版、<a class="ae ls" href="https://github.com/clir/clearnlp-guidelines/blob/master/md/components/dependency_conversion.md" rel="noopener ugc nofollow" target="_blank"> ClearNLP 成分到依赖转换</a>和<a class="ae ls" href="https://wordnet.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> Wordnet 3.0 </a>的数据上训练了这个语言模型，并报告了这个模型的 POS <a class="ae ls" href="https://spacy.io/models/en#en_core_web_lg-accuracy" rel="noopener ugc nofollow" target="_blank">准确率为 97%。</a></p><p id="2a73" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">SpaCy 的'<a class="ae ls" href="https://spacy.io/models/en#en_core_web_trf" rel="noopener ugc nofollow" target="_blank"> en_core_web_trf </a>'模型基于变压器架构。Transformer 是最新的 NLP 技术之一，它已经变得非常流行，因为这些模型显示了对上一代语言模型的重大改进。SpaCy 的“en_core_web_trf”报告的准确率为 98%。</p><p id="d38c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“en_core_web_sm”和“en_core_web_md”是轻型型号。他们的准确性不如另外两个。</p><h1 id="1f8c" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">“en_core_web_lg”和“en_core_web_trf”结果比较</h1><p id="192b" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">让我们参考 MLK 的演讲。它有 23 个段落和 84 个句子。下面的代码将语音存储为数据帧，并输出“lg”和“trf”模型的 POS 标签之间的差异。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="2512" class="nj lu iq nf b gy nk nl l nm nn">import spacy<br/>texts = speech['Para_txt'].to_list()<br/>nlp_trf = spacy.load('en_core_web_trf')<br/>nlp_lg = spacy.load('en_core_web_lg')<br/>pos_trf = [(tok.text, tok.pos_) for t in texts for tok in nlp_trf(t)]<br/>pos_lg = [(tok.text, tok.pos_) for t in texts for tok in nlp_lg(t)]<br/>assert len(pos_lg) == len(pos_trf)<br/>diff = [(a, b, d) for ((a, b), (c, d)) in zip(pos_lg, pos_trf) if b != d]<br/>print(diff)<br/>-------------------------------------------------------------------</span><span id="19a1" class="nj lu iq nf b gy no nl l nm nn">[('Negro', 'ADJ', 'PROPN'),<br/> ('crippled', 'ADJ', 'VERB'),<br/> ('material', 'NOUN', 'ADJ'),<br/> ('â\x80\x94', 'ADJ', 'PUNCT'),<br/> ('Negro', 'PROPN', 'ADJ'),<br/> ('bank', 'PROPN', 'NOUN'),<br/> ('justice', 'PROPN', 'NOUN'),<br/> ('demand', 'VERB', 'NOUN'),<br/> ('invigorating', 'ADJ', 'VERB'),<br/> ('Those', 'DET', 'PRON'),<br/> ('content', 'NOUN', 'ADJ'),<br/> ('until', 'ADP', 'SCONJ'), ...<br/>]</span></pre><p id="4670" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有 45 个单词在两个模型之间被标记为不同。在上表中，我只展示了前几个例子。在上述所有差异中，突出的差异(“需求”)最为突出。虽然模型混淆名词和形容词是常见的，但是模型混淆动词和名词是不常见的。动词表示动作，因此很容易与名词区分开来。</p><blockquote class="np nq nr"><p id="957c" class="kv kw lr kx b ky kz jr la lb lc ju ld ns lf lg lh nt lj lk ll nu ln lo lp lq ij bi translated">因此，我们来兑现这张支票，这张支票将在我们要求时给予我们自由的财富和正义的保障。</p><p id="41ad" class="kv kw lr kx b ky kz jr la lb lc ju ld ns lf lg lh nt lj lk ll nu ln lo lp lq ij bi translated">-马丁·路德·金</p></blockquote><p id="49fd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面的句子中,' demand '一词用作名词。Riches 是动词 give 的宾语。因此基于变压器的“trf”模型是准确的。当我们使用这两种模型检查 SpaCy 中的依赖图时，这变得更加清楚。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/f3bdfb54d8ca13f37368fa98a4ac18d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b0HFyS3DCYKzOi9H.jpg"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/08cdec8075d47b2066bb1fa99a100ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CivI-KtkaH1_yliv.jpg"/></div></div></figure><h1 id="175f" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论——这重要吗</h1><p id="2b29" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">这个帖子不是关于变形金刚的；你可以在<a class="ae ls" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">这篇伟大的文章</a>中阅读变形金刚的介绍。这篇文章的目的是展示我们做出的选择是如何改变我们的 NLP 结果的。</p><p id="275b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">NLP 任务逐步建立在上游任务的基础上。我们将 POS 标签用于其他任务，例如实体检测。POS 标签中的一个小错误会完全改变这些下游任务的结果。在 MLK 演讲的例子中，根据我们将单词<em class="lr"> demand </em>视为名词还是动词，这个句子呈现出完全不同的含义。</p><p id="3761" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">模型的质量只是我们决策的一个参数。在为我们的应用选择模型之前，我们还需要考虑成本、延迟和其他工程因素。基于 Transformer 的模型比上一代模型需要更多的计算资源。因此,“trf”模型很可能比“lg”模型贵很多个数量级。直到时间变压器模型变得像旧模型一样便宜，旧模型仍将在许多 NLP 应用中使用。</p><p id="f390" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我也写在<a class="ae ls" href="https://sauravc.online/" rel="noopener ugc nofollow" target="_blank"> sauravc.online </a></p></div></div>    
</body>
</html>