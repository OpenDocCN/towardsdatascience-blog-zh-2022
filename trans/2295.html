<html>
<head>
<title>The wrong and right way to approximate Area Under Precision-Recall Curve (AUPRC)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">精确召回曲线下面积近似的正确与错误</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-wrong-and-right-way-to-approximate-area-under-precision-recall-curve-auprc-8fd9ca409064#2022-05-20">https://towardsdatascience.com/the-wrong-and-right-way-to-approximate-area-under-precision-recall-curve-auprc-8fd9ca409064#2022-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c09d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">总结AUPRC的方法有很多，但并不是所有的方法都有相同的优点</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0bf292b3fa2d0aab591af563b35015e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EX2_Ix4gWr69o1vv"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@raimondklavins?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">雷蒙·克拉文斯</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0fec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精确召回(PR)曲线下的面积(AUPRC)是一个总结PR曲线信息的单一数字。有许多方法可以估算它的封闭面积，但并不是所有的方法都有同样的优点。本文试图分析近似AUPRC的两种常见方法:使用梯形规则或使用平均精度分数，以及为什么一种方法比另一种方法更正确。</p><h2 id="18d3" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated"><strong class="ak">通过PR曲线的梯形近似获得的AUC与平均精密度分数不同:例如</strong></h2><p id="9868" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我看到人们经常犯的一个错误是，假设通过PR曲线的梯形插值获得的AUC(在scikit-learn中用<code class="fe mq mr ms mt b">auc(precision, recall)</code>表示)与平均精度分数(在scikit-learn中用<code class="fe mq mr ms mt b">average_precision_score(y_true, y_score)</code>表示)完全相同。虽然这两种度量在许多情况下产生非常相似的估计，但它们是根本不同的。梯形方法使用了过于乐观的线性插值。当数据高度偏斜时，更有可能观察到这种不正确插值的影响(<a class="ae kv" rel="noopener" target="_blank" href="/precision-recall-curve-is-more-informative-than-roc-in-imbalanced-data-4c95250242f6">，这正是PR曲线优于ROC曲线</a>的情况)。</p><p id="07dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了说明这一点，我在从UPenn机器学习基准(PMLB)套件中选择的不平衡数据集上训练了一个虚拟分类器。这个名为“spambase”的数据集有4，601个观察值，57个特征，以及0.04个阳性率的二进制目标。虚拟分类器根据80%的训练数据进行训练，并根据20%的排除数据进行评估。当比较梯形规则产生的AUPRC估计值与平均精度得分时，前者明显更高(0.53比0.41)。下面提供了您自己实验的代码片段——由于虚拟分类器和训练/测试分割的随机性，您可能看不到完全相同的估计值。然而，与平均精度分数相比，梯形规则计算的AUPRC过于乐观，这一观点应该是明确和一致的。</p><div class="mu mv gp gr mw mx"><a href="https://replit.com/@TamTran26/AUPRC-different-estimations#main.py" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">AUPRC不同估计</h2><div class="ne l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">与平均精度分数相比，使用梯形规则获得的AUPRC过于乐观。使用repl.it生成的交互式代码。</p></div></div><div class="nf l"><div class="ng l nh ni nj nf nk kp mx"/></div></div></a></div><h2 id="d213" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">为什么梯形近似适用于ROC空间…</h2><p id="946d" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">给定ROC空间中的一组点，其x坐标表示假阳性率(FPR)，y坐标表示真阳性率(TPR)，梯形近似使用线性插值来连接相邻的点以形成ROC曲线。简单来说，我们画一条连接两点的直线。该曲线下的面积(AUC)是所有梯形面积的总和。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/c6590d9bde36bbe7af49f7405461bd06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNrisIbyiGEk3VHLP7x_Uw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">连接4个ROC点的ROC曲线。曲线下面积(AUC)分数可以通过梯形规则计算，该规则将曲线下的所有梯形1、2和3相加。图片作者。</p></figure><p id="2d8f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">已经证明，通过投掷加权硬币来决定两个端点所代表的分类器，可以在连接两个现有ROC点的这条线上实现任何级别的性能。假设点a(在上图中)代表模型a，它在fₐ的FPR下实现了tₐ的TPR，而模型b(由点b代表)同样在fᵦ.实现了tᵦ的TPR在分类器a和分类器b之间，通过以概率pᵦ = (f-fₐ)/(fᵦ-fₐ)选择b的输出和以概率pₐ=1-pᵦ.选择a的输出，可以产生具有FPR f的新分类器</p><blockquote class="nm nn no"><p id="7cfc" class="kw kx np ky b kz la jr lb lc ld ju le nq lg lh li nr lk ll lm ns lo lp lq lr ij bi translated">线性插值实际上是ROC空间中凸包的关键思想所要求的主要标准之一。</p></blockquote><h2 id="7cfe" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">…但不是在公关领域？</h2><p id="c7f9" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在ROC空间中，TPR(或召回)相对于FPR绘制，而在PR空间中，召回相对于精确度绘制。随着召回水平的变化，精确度不一定线性变化。召回被定义为TP/(TP+FN)，其中TP+FN =实际阳性的数量不依赖于分类器阈值。这意味着降低分类器阈值可以通过增加真阳性结果的数量来提高召回率。也有可能降低阈值会使召回率保持不变，而精确度会波动。另一方面，Precision=TP/(TP+FP)的定义表明，通过增加返回的肯定预测结果的数量，降低分类器的阈值可以增加分母。如果阈值先前设置得太高，新的结果可能都是真阳性，这将提高精确度。如果先前的阈值大约合适或太低，进一步降低阈值将引入假阳性，降低精度。例如，PR空间中的基线曲线是一条水平线，其高度等于正类的流行度，这意味着对于每个召回值，对应的精度值保持不变，并且等于流行度。</p><p id="41e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以在PR空间中，点与点之间的线性插值是不正确的。线性插值是一个错误，它对PR空间的性能估计过于乐观。当要插值的点之间的距离非常大时，不正确插值的影响尤其明显。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/34e900c7186f6e486e4b158660ff32e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*wK4YNNgzYQuGjAu0Vo9RWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">考虑从具有433个阳性和56，164个阴性的数据集由单个点(0.02，1)构建并延伸到端点(0，1)和(1，0.008)的曲线。正确的插值将产生0.031的AUPRC，而线性插值将严重高估0.50的AUPRC。图片来自Davis和Goadrich (2006)的论文“精确召回和ROC曲线的关系”。</p></figure><h2 id="d6c5" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">对于AUPRC，什么是更好的近似？</h2><p id="3b1f" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">希望到现在为止，我们都同意非线性插值是PR空间的发展方向。有多种不同的方法和变体可用于构建该PR曲线。Davis和Goadrich (2006)根据对应于每个PR点的真阳性(TP)和假阳性(FP)的数量来检查插值。假设我们有一个包含20个阳性和2000个阴性的数据集。让TPₐ=5、FPₐ=5、TPᵦ=10和FBᵦ=30.为了找到一些中间值，Davis和Goadrich (2006)建议首先找出多少个负数等于一个正数，或者局部偏差，由(FBᵦ-FPₐ)/(TPᵦ-TPₐ).)定义在本例中，局部偏斜=(30–5)/(10–5)= 5，这意味着每5个负值就有1个正值。现在，我们可以为x的所有整数值创建新点TPₐ+x，使得1≤x≤TPᵦ-TPₐ，并通过由局部偏斜线性增加每个新点的假阳性来计算相应的FP。具体来说:</p><pre class="kg kh ki kj gt nu mt nv nw aw nx bi"><span id="0734" class="ls lt iq mt b gy ny nz l oa ob">+-------+----+----+--------+-----------+<br/>| Point | TP | FP | Recall | Precision |<br/>+-------+----+----+--------+-----------+<br/>| A     | 5  | 5  | 0.25   | 0.5       |<br/>| .     | 6  | 10 | 0.30   | 0.375     |<br/>| .     | 7  | 15 | 0.35   | 0.318     |<br/>| .     | 8  | 20 | 0.40   | 0.286     |<br/>| .     | 9  | 25 | 0.45   | 0.265     |<br/>| B     | 10 | 30 | 0.5    | 0.25      |<br/>+-------+----+----+--------+-----------+</span></pre><p id="9c57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，结果精度插值在0.5和0.25之间不是线性的。</p><p id="dad4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个较好的估计是平均精度(AP)。AP方法完全避免了经验曲线的构建，这意味着我们不需要担心使用什么插值方法。AP计算为每个阈值达到的精度的加权平均值，其中权重是从上一个阈值开始的召回增加:</p><blockquote class="oc"><p id="9aab" class="od oe iq bd of og oh oi oj ok ol lr dk translated">ap=σ(rₙ-rₙ₋₁)pₙ</p></blockquote><p id="989e" class="pw-post-body-paragraph kw kx iq ky b kz om jr lb lc on ju le lf oo lh li lj op ll lm ln oq lp lq lr ij bi translated">其中Pₙ和Rₙ是第n个阈值的精度和召回率。</p><p id="f697" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">AP和工作点下的梯形面积都是概括精度-召回曲线的常用方法。但是，它们可能会导致不同的结果，尤其是当数据高度倾斜时。在这些情况下，AP是更合适的估计值。</p><p id="d83f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="np">参考文献</em></p><p id="2b53" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] J.Davis和M.Goadrich，<a class="ae kv" href="https://dl.acm.org/doi/10.1145/1143844.1143874" rel="noopener ugc nofollow" target="_blank"/>(2006)，ICML 2006年第23届机器学习国际会议论文集</p></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><p id="841d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如果你喜欢这篇文章，你可能也会喜欢:</strong></p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/precision-recall-curve-is-more-informative-than-roc-in-imbalanced-data-4c95250242f6"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">在不平衡数据中，精确召回曲线比ROC更能提供信息</h2><div class="oy l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">当负类更普遍，真-负预测值低时，精确-回忆曲线…</h3></div><div class="ne l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="oz l nh ni nj nf nk kp mx"/></div></div></a></div><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/performance-curve-more-intuitive-than-roc-prc-and-less-assumptive-than-threshold-metrics-391e777da566"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd ir gy z fp nc fr fs nd fu fw ip bi translated">性能曲线:比ROC/PRC更直观，比阈值指标更少假设</h2><div class="oy l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">一种结合两者优点的二元分类器评价方法</h3></div><div class="ne l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="nf l"><div class="pa l nh ni nj nf nk kp mx"/></div></div></a></div></div></div>    
</body>
</html>