<html>
<head>
<title>AWS SageMaker X HuggingFace X AWS QuickSight</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS SageMaker X hugging face X AWS quick sight</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/aws-sagemaker-x-huggingface-x-aws-quicksight-7f4bd53dc484#2022-05-26">https://towardsdatascience.com/aws-sagemaker-x-huggingface-x-aws-quicksight-7f4bd53dc484#2022-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2f86" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何通过机器学习解决医疗成绩单的分类问题，并为以下内容发布模型和数据监控仪表板</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a376710b4524809b3ee1f3cb1043baa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9X2R0RTPIrz_S25Sd4uLQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:丹尼尔·科尔派在<a class="ae kv" href="https://unsplash.com/s/photos/monitor?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="552e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated"><strong class="ak">简介</strong></h1><p id="2699" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是一个解决方案，演示了如何在<strong class="lq ir"> AWS SageMaker </strong>上训练和部署预训练的<strong class="lq ir"> Huggingface </strong>模型，并发布一个<strong class="lq ir"> AWS QuickSight </strong>仪表板，该仪表板可视化模型在验证数据集上的性能，并对预处理的训练数据集进行探索性数据分析。以此作为提出的解决方案的架构，我们尝试通过机器学习来解决医疗记录的分类，这基本上是解决一个<strong class="lq ir">生物医学NLP </strong>问题。在本解决方案中，我们还讨论了通过PyTorch编写自定义Huggingface训练器进行训练时的特征工程和通过类权重处理不平衡数据集。</p><p id="d3d5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">将Huggingface与SageMaker一起使用的意义在于简化SageMaker上基于transformer的模型的训练，并使它们易于部署用于生产。此外，使用QuickSight Dashboard将数据和模型分析集中在一个平台上，使监控和配置变得更加容易。当项目需要一个服务器端仪表板来由管理员或开发团队监控模型和数据时，建议的dashboard管道非常方便。</p><h1 id="2c4e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">体系结构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/2ed32c902f548baae3f5bbbec8fb69be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MhS_dacqufq4nP9ImOX3Ig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><h1 id="45fd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">视频演示</h1><p id="14d3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">下面是建议的架构的演示视频。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><h1 id="ca4e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">问题陈述</h1><p id="6b3a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><strong class="lq ir">诊断预测</strong>旨在自动预测具有特定既往病史的患者所需的诊断。</p><p id="ff73" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">病历由一个原始文本文件表示，其中包含医生对患者的记录，包括他/她的年龄、在高速公路上描述的主诉、患者的病史等等。它是非结构化的——一个病人病历的不同部分可能在另一个病人的病历中不存在。</p><p id="6f35" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">目标标签由所需诊断程序的名称表示。</p><p id="a92f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">解决方案的价值</strong>可以帮助医生找到诊断订单的最佳解决方案。患者可以节省时间和金钱，医生可以通过节省时间进行不必要的诊断来更有效地为患者服务。此外，在困难的情况下，该算法可以帮助医生更快地找到诊断结果，这在某些情况下可能非常有价值，甚至可以挽救生命。</p><p id="7062" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从理论上讲，算法发现的一些规律可能有助于医学研究人员根据某些疾病与某些症状之间的不明显联系，找到治疗某些疾病的思路。</p><h1 id="9e91" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集和存储</h1><p id="24e8" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">所有的数据集都存储在<strong class="lq ir"> <em class="ms">数据集</em> </strong>目录下的<strong class="lq ir"> S3桶(</strong> <em class="ms">医学-转录-回购</em> <strong class="lq ir"> ) </strong>中。该数据集包含各种医学专业的样本<strong class="lq ir">医学转录</strong>。</p><p id="6e34" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">预处理和特征工程数据集存储在不同目录下的相同S3桶中(<em class="ms">S3://medical-transcription-repo/preprocess/</em>)。模型存储也是如此(<em class="ms">S3://medical-transcription-repo/models/</em>)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/a846c0bdff531cc1f7892c07bd0ea138.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CiqNvEcsqlRyVxJcZIWsaA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><p id="118d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">类似地，在<em class="ms">预处理</em> s3存储桶目录中，我们存储训练数据和验证数据集以备将来使用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/b067ad02e15227b1438bb69de3ef47f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_yHvR4WU5EBr1PU1J9RqNg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="6bca" class="na kx iq mw b gy nb nc l nd ne">- dataset</span><span id="ff4d" class="na kx iq mw b gy nf nc l nd ne">     - dataset.csv</span><span id="b7c2" class="na kx iq mw b gy nf nc l nd ne">- preprocess</span><span id="9723" class="na kx iq mw b gy nf nc l nd ne">     - pre-processed</span><span id="2a15" class="na kx iq mw b gy nf nc l nd ne">           - eval</span><span id="3a00" class="na kx iq mw b gy nf nc l nd ne">              - validation.csv</span><span id="3e07" class="na kx iq mw b gy nf nc l nd ne">           -pre-processed.csv</span><span id="c133" class="na kx iq mw b gy nf nc l nd ne">     - train</span><span id="6357" class="na kx iq mw b gy nf nc l nd ne">           - dataset-info.json</span><span id="1090" class="na kx iq mw b gy nf nc l nd ne">     -test</span><span id="f4c0" class="na kx iq mw b gy nf nc l nd ne">           - dataset-infor.json</span><span id="da8d" class="na kx iq mw b gy nf nc l nd ne">- models</span><span id="9265" class="na kx iq mw b gy nf nc l nd ne">      - huggingface-dd-mm-yyyy:hh-mm-ss</span><span id="5895" class="na kx iq mw b gy nf nc l nd ne">           - output</span><span id="3ba9" class="na kx iq mw b gy nf nc l nd ne">              - model.tar.gz</span><span id="b339" class="na kx iq mw b gy nf nc l nd ne">              - output.tar.gz</span></pre><h2 id="efe7" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">数据集源</h2><p id="e057" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">从mtsamples.com刮来的数据。这个数据集通过提供医学转录样本提供了一个解决方案。</p><h1 id="baa6" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">ML模型训练、部署和推理</h1><h2 id="ba98" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">AWS SageMaker</h2><p id="a221" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了在SageMaker上训练和部署模型，使用了以下服务:</p><ul class=""><li id="642e" class="nr ns iq lq b lr mk lu ml lx nt mb nu mf nv mj nw nx ny nz bi translated"><strong class="lq ir">笔记本实例(</strong><em class="ms">ml . T2 . medium</em><strong class="lq ir">)</strong></li><li id="e283" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated"><strong class="lq ir">培训岗位(</strong><em class="ms">ml . p 3.2x large</em><strong class="lq ir">)</strong></li><li id="c014" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated"><strong class="lq ir">推断终点(</strong><em class="ms">ml . T2 . medium</em><strong class="lq ir"><em class="ms">)</em></strong></li></ul><h2 id="bf76" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">预处理和特征工程</h2><p id="6181" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">原始数据集由40个要分类的类组成，但是由于缺乏关于这些类的足够的训练样本，一些类集合被移除，最终以23个类的分类问题结束。然后，预处理后的数据集被上传到s3存储桶，以便在<strong class="lq ir"> AWS QuickSight </strong>中进一步创建EDA仪表盘。</p><p id="516e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来，数据集被分成训练集和验证集，并对文本数据进行标记。预训练的<em class="ms">无壳</em>分词器用于对输入数据进行分词。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="da27" class="na kx iq mw b gy nb nc l nd ne">from transformers import AutoTokenizer</span><span id="2087" class="na kx iq mw b gy nf nc l nd ne"># tokenizer used in preprocessing<br/>tokenizer_name = 'distilbert-base-uncased'<br/># download tokenizer<br/>tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)</span><span id="08ff" class="na kx iq mw b gy nf nc l nd ne"># tokenizer helper function<br/>def tokenize(batch):<br/>    return tokenizer(batch['text'],padding=True, truncation=True)</span><span id="e73c" class="na kx iq mw b gy nf nc l nd ne"># tokenize dataset<br/>train_dataset = dataset['train'].map(tokenize, batched=True)<br/>test_dataset = dataset['test'].map(tokenize, batched=True)</span><span id="dd06" class="na kx iq mw b gy nf nc l nd ne"># set format for pytorch<br/>train_dataset =  train_dataset.rename_column("target", "labels")<br/>train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])<br/>test_dataset = test_dataset.rename_column("target", "labels")<br/>test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])</span></pre><p id="b349" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">令牌化的训练和验证集被上传到s3存储桶。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="c6e0" class="na kx iq mw b gy nb nc l nd ne">import botocore<br/>from datasets.filesystems import S3FileSystem</span><span id="9c5d" class="na kx iq mw b gy nf nc l nd ne">s3 = S3FileSystem()  <br/>prefix = 'preprocess'</span><span id="466e" class="na kx iq mw b gy nf nc l nd ne"># save train_dataset to s3<br/>training_input_path = f's3://{bucket}/{prefix}/train'<br/>train_dataset.save_to_disk(training_input_path,fs=s3)</span><span id="aea6" class="na kx iq mw b gy nf nc l nd ne"># save test_dataset to s3<br/>test_input_path = f's3://{bucket}/{prefix}/test'<br/>test_dataset.save_to_disk(test_input_path,fs=s3)</span></pre><h2 id="80c0" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">估计类别权重</h2><p id="f310" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对于类别不平衡，要考虑的一个方面是每个批次都有足够的信号来覆盖所有类别，甚至不平衡的类别。否则可能会在训练中退化。</p><p id="fc3b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在这种情况下，我们使用类权重来处理不平衡的数据集。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="d136" class="na kx iq mw b gy nb nc l nd ne">from sklearn.utils import class_weight<br/>class_weights = dict(enumerate(class_weight.compute_class_weight(‘balanced’,<br/>               classes=np.unique(df[‘target’]),<br/>               y=df[‘target’])))</span></pre><h2 id="fc7d" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">拥抱脸定制训练器</h2><p id="fb05" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">预训练的<em class="ms">无壳</em>模型和用于处理不平衡数据集的自定义损失函数用于模型训练。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="1750" class="na kx iq mw b gy nb nc l nd ne">from transformers import Trainer, TrainingArguments, AutoTokenizer</span><span id="ed8f" class="na kx iq mw b gy nf nc l nd ne"># create Trainer instance<br/># Subclass Trainer and override the compute_loss method<br/>class MedModelTrainer(Trainer):<br/>    def compute_loss(self, model, inputs, return_outputs=False):<br/>        labels = inputs.get("labels")<br/>        # forward pass<br/>        outputs = model(**inputs)<br/>        logits = outputs.get("logits")<br/>        # compute custom loss<br/>        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor(list(class_weights.values())))<br/>        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))<br/>        return (loss, outputs) if return_outputs else loss</span><span id="1f65" class="na kx iq mw b gy nf nc l nd ne">trainer = MedModelTrainer(<br/>    model=model,<br/>    args=training_args,<br/>    compute_metrics=compute_metrics,<br/>    train_dataset=train_dataset,<br/>    eval_dataset=test_dataset,<br/>    tokenizer=tokenizer,<br/>)</span><span id="8321" class="na kx iq mw b gy nf nc l nd ne"># train model<br/>trainer.train()</span></pre><h2 id="3efc" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">创建评估员并开始培训工作</h2><p id="8421" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">拥抱脸深度DLCs(深度学习容器)让在SageMaker中训练变形金刚模型变得前所未有的简单。以下是您应该使用拥抱脸DLCs来训练和部署您的下一个机器学习模型的一些原因:<br/> *您只需要一个命令。<br/> *加速机器学习从研究到生产的转变。<br/> *内置性能。</p><p id="3ae2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在SageMaker训练环境中，该估计器执行拥抱面部训练脚本。</p><p id="aa37" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">使用预构建的拥抱面部Docker容器，估计器启动SageMaker管理的拥抱面部环境，并执行用户通过<code class="fe of og oh mw b"><strong class="lq ir">entry_point</strong></code>参数提供的拥抱面部训练脚本。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="bf4f" class="na kx iq mw b gy nb nc l nd ne">from sagemaker.huggingface import HuggingFace, TrainingCompilerConfig<br/># initialize the Amazon Training Compiler<br/>compiler_config=TrainingCompilerConfig()</span><span id="38b8" class="na kx iq mw b gy nf nc l nd ne"># hyperparameters, which are passed into the training job<br/>hyperparameters={'epochs': 10,<br/>                 'train_batch_size': 64,<br/>                 'eval_batch_size': 32,<br/>                 'learning_rate': 3e-5, <br/>                 'model_name':'distilbert-base-uncased'<br/>                 }</span><span id="5f8d" class="na kx iq mw b gy nf nc l nd ne">huggingface_estimator = HuggingFace(entry_point='train.py',<br/>                            source_dir='./scripts',<br/>                            instance_type='ml.p3.2xlarge',<br/>                            instance_count=1,<br/>                            role=role,<br/>                            transformers_version='4.11.0',<br/>                            pytorch_version='1.9.0',<br/>                            py_version='py38', output_path='s3://{}/models'.format(bucket),<br/>                            hyperparameters = hyperparameters,<br/>                            compiler_config = compiler_config<br/>                                   )</span></pre><p id="0c90" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">以我们上传的数据集作为输入开始训练工作。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="d253" class="na kx iq mw b gy nb nc l nd ne">huggingface_estimator.fit({'train': training_input_path, 'test': test_input_path})</span></pre><h2 id="95bd" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">部署端点</h2><p id="893e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">为了部署我们的端点，我们在HuggingFace estimator对象上调用<em class="ms"> deploy() </em>，传入我们想要的实例数量和实例类型。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="7c1f" class="na kx iq mw b gy nb nc l nd ne">predictor = huggingface_estimator.deploy(1,"ml.t2.medium")</span></pre><p id="968b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于推理，您可以使用您训练的拥抱人脸模型或预训练的拥抱人脸模型之一来部署SageMaker的推理作业。通过这种协作，您只需要一行代码就可以使用SageMaker部署您的已训练模型和预训练模型。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="af34" class="na kx iq mw b gy nb nc l nd ne">eval_df = pd.read_csv('test.csv')<br/>eval_df['pred'] = 0<br/>eval_df['score'] = 0.0<br/>max_length = 512<br/>for i in range(len(eval_df)):<br/>    sentiment_input= {"inputs": eval_df['text'].iloc[i][:max_length]}<br/>    eval_df['pred'][i] = int(predictor.predict(sentiment_input)[0]['label'].split('_')[1])<br/>    eval_df['score'][i] = float(predictor.predict(sentiment_input)[0]['score'])</span></pre><p id="d58e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">带有模型预测的验证集存储在s3存储桶中，以开发AWS QuickSight上的模型性能仪表板。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="dc86" class="na kx iq mw b gy nb nc l nd ne">eval_df.to_csv("model-performance.csv", index=False)<br/>s3 = boto3.resource('s3')<br/>s3.meta.client.upload_file('model-performance.csv', bucket, 'preprocess/pre-processed/eval/model-performance.csv')</span></pre><h2 id="e3c0" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">源代码</h2><p id="4b23" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">下面给出了以下建议体系结构的源代码:</p><p id="ad39" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" href="https://github.com/victor369basu/SagemakerHuggingfaceDashboard" rel="noopener ugc nofollow" target="_blank">托管QuickSight仪表盘的架构，用于SageMaker上部署的拥抱面部模型监控以及数据EDA </a></p><h1 id="86de" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">AWS QuickSight</h1><p id="6e7c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">Quicksight是AWS提供的云原生、无服务器BI服务。</p><p id="df2a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">EDA仪表板显示在预处理的医疗记录数据上。分析的重点是医学专业的分布、医学专业的子群、医学专业之间的关系、转录上下文的词云等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/2217d7fc02a31e643d38656167313b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rltGn3xQCLKZI7H1Yx0Ipw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><p id="5a23" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">模型性能仪表板是可视化的，用于验证医学转录数据集的模型预测。分析的重点是模型预测的正确性；目标类与预测类分布的差异；模型在验证集上的准确度、精确度、召回率和f1分数等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/d3d5cd3e6bc648cf1bfe4ed1463000b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uRvvJcaRiLw2Nd8TApxSw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来源:作者</p></figure><h2 id="16b3" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">正确性图的计算字段</h2><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="0c30" class="na kx iq mw b gy nb nc l nd ne">ifelse(pred=target, "Correct", "Wrong")</span></pre><h2 id="25be" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">准确度(%)的计算字段</h2><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="7846" class="na kx iq mw b gy nb nc l nd ne">(countIf(Correctness, Correctness="Correct")/ count(Correctness)) * 100</span></pre><h2 id="f01b" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">精度的计算字段(%)</h2><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="8397" class="na kx iq mw b gy nb nc l nd ne">((countIf(pred, pred=0 AND target=0)/countIf(pred, pred=0) +</span><span id="7eb8" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=1 AND target=1)/countIf(pred, pred=1) +</span><span id="92b4" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=2 AND target=2)/countIf(pred, pred=2) +</span><span id="3556" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=3 AND target=3)/countIf(pred, pred=3) +</span><span id="de10" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=4 AND target=4)/countIf(pred, pred=4) +</span><span id="f026" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=5 AND target=5)/countIf(pred, pred=5) +</span><span id="810e" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=6 AND target=6)/countIf(pred, pred=6) +</span><span id="9972" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=7 AND target=7)/countIf(pred, pred=7) +</span><span id="e76d" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=8 AND target=8)/countIf(pred, pred=8) +</span><span id="c613" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=9 AND target=9)/countIf(pred, pred=9) +</span><span id="8e6f" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=10 AND target=10)/countIf(pred, pred=10) +</span><span id="881c" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=11 AND target=11)/countIf(pred, pred=11) +</span><span id="40e9" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=11 AND target=11)/countIf(pred, pred=11) +</span><span id="f1f0" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=12 AND target=12)/countIf(pred, pred=12) +</span><span id="7ba3" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=13 AND target=13)/countIf(pred, pred=13) +</span><span id="9951" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=14 AND target=14)/countIf(pred, pred=14) +</span><span id="884f" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=15 AND target=15)/countIf(pred, pred=15) +</span><span id="1a61" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=16 AND target=16)/countIf(pred, pred=16) +</span><span id="0830" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=17 AND target=17)/countIf(pred, pred=17) +</span><span id="442e" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=18 AND target=18)/countIf(pred, pred=18) +</span><span id="c01b" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=19 AND target=19)/countIf(pred, pred=19) +</span><span id="fea5" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=20 AND target=20)/countIf(pred, pred=20) +</span><span id="e2c3" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=21 AND target=21)/countIf(pred, pred=21) +</span><span id="d7ff" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=22 AND target=22)/countIf(pred, pred=22)) /23) *100</span></pre><h2 id="2bfc" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">召回的计算字段(%)</h2><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="c407" class="na kx iq mw b gy nb nc l nd ne">((countIf(pred, pred=0 AND target=0)/countIf(target, target=0) +</span><span id="f0af" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=1 AND target=1)/countIf(target, target=1) +</span><span id="b495" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=2 AND target=2)/countIf(target, target=2) +</span><span id="21e5" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=3 AND target=3)/countIf(target, target=3) +</span><span id="ba53" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=4 AND target=4)/countIf(target, target=4) +</span><span id="0070" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=5 AND target=5)/countIf(target, target=5) +</span><span id="24c9" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=6 AND target=6)/countIf(target, target=6) +</span><span id="ccaf" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=7 AND target=7)/countIf(target, target=7) +</span><span id="7300" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=8 AND target=8)/countIf(target, target=8) +</span><span id="a7ba" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=9 AND target=9)/countIf(target, target=9) +</span><span id="050e" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=10 AND target=10)/countIf(target, target=10) +</span><span id="0383" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=11 AND target=11)/countIf(target, target=11) +</span><span id="589e" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=11 AND target=11)/countIf(target, target=11) +</span><span id="1b05" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=12 AND target=12)/countIf(target, target=12) +</span><span id="6920" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=13 AND target=13)/countIf(target, target=13) +</span><span id="a879" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=14 AND target=14)/countIf(target, target=14) +</span><span id="aad2" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=15 AND target=15)/countIf(target, target=15) +</span><span id="35fe" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=16 AND target=16)/countIf(target, target=16) +</span><span id="8c50" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=17 AND target=17)/countIf(target, target=17) +</span><span id="3d32" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=18 AND target=18)/countIf(target, target=18) +</span><span id="1e4c" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=19 AND target=19)/countIf(target, target=19) +</span><span id="88cc" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=20 AND target=20)/countIf(target, target=20) +</span><span id="8ff6" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=21 AND target=21)/countIf(target, target=21) +</span><span id="59cf" class="na kx iq mw b gy nf nc l nd ne">countIf(pred, pred=22 AND target=22)/countIf(target, target=22)) /23) *100</span></pre><h2 id="5492" class="na kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">f1的计算字段-得分(%)</h2><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="1809" class="na kx iq mw b gy nb nc l nd ne">2 * (Precision*Recall ) / (Precision + Recall)</span></pre><h1 id="2a90" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="95e2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">提议的AWS云架构提供了一种解决方案，用于训练和部署基于transformer的NLP预训练模型，这些模型可在Huggingface通过AWS SageMaker进行生产。AWS QuickSight用于发布仪表板，以可视化基本数据集的EDA和验证集上的ML模型性能，这成功地将数据和模型分析集中在一个屋檐下。</p><h1 id="aab5" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">改进的范围</h1><ul class=""><li id="0126" class="nr ns iq lq b lr ls lu lv lx oj mb ok mf ol mj nw nx ny nz bi translated">可以改进模型性能仪表板，以增加每个类的精确度和召回分数。</li><li id="536f" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">向模型性能仪表板添加混淆矩阵。</li><li id="95dc" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">为更高的时期训练模型以更好地收敛。</li><li id="2f06" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">尝试不同的预训练模型，如<strong class="lq ir">伯特</strong>和<strong class="lq ir">罗伯塔</strong>，以获得更好的模型性能。</li><li id="a972" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated">改进特征工程技术，如减少目标类或使用<strong class="lq ir">少数过采样</strong>技术以获得更好的性能。</li></ul><h1 id="bef3" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><ul class=""><li id="5ab7" class="nr ns iq lq b lr ls lu lv lx oj mb ok mf ol mj nw nx ny nz bi translated"><a class="ae kv" href="https://huggingface.co/docs/sagemaker/main" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker上的拥抱脸</a></li><li id="99ca" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated"><a class="ae kv" href="https://docs.aws.amazon.com/sagemaker/latest/dg/hugging-face.html" rel="noopener ugc nofollow" target="_blank">使用亚马逊SageMaker的拥抱脸</a></li><li id="fd81" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated"><a class="ae kv" href="https://www.kaggle.com/code/ruzarx/oversampling-smote-and-adasyn" rel="noopener ugc nofollow" target="_blank">过采样SMOTE和ADASYN </a></li><li id="b5e5" class="nr ns iq lq b lr oa lu ob lx oc mb od mf oe mj nw nx ny nz bi translated"><a class="ae kv" href="https://www.kaggle.com/code/ritheshsreenivasan/clinical-text-classification" rel="noopener ugc nofollow" target="_blank">临床文本分类</a></li></ul></div></div>    
</body>
</html>