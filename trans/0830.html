<html>
<head>
<title>Straightforward Stratification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单分层</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/straightforward-stratification-bb0dcfcaf9ef#2022-03-07">https://towardsdatascience.com/straightforward-stratification-bb0dcfcaf9ef#2022-03-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d0ec" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">处理数字、无监督和多维数据</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/43b4d47e062ae160d82861d1367e97b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEMKacsW_bK7Zb6b2FmRfA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://www.pexels.com/@edward-jenner" rel="noopener ugc nofollow" target="_blank">爱德华·詹纳</a>在<a class="ae kv" href="https://www.pexels.com/photo/glass-blur-bubble-health-4033022/" rel="noopener ugc nofollow" target="_blank">像素</a>上拍摄</p></figure><blockquote class="kw kx ky"><p id="6296" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">用于分层的常用数据科学工具非常适合处理监督分类数据集。但是，它们不是为开箱即用地处理数值、无监督和多维数据集而设计的。这就是<a class="ae kv" href="https://github.com/aiqc/aiqc" rel="noopener ugc nofollow" target="_blank"> AIQC </a>擅长的地方。</p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="1c88" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">分层导致一般化</h2><p id="72af" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">在以前的博客文章中，我们广泛地讨论了用验证和测试分割/折叠来评估模型的重要性:</p><ul class=""><li id="c9b9" class="ne nf iq lc b ld le lg lh mm ng mq nh mu ni lv nj nk nl nm bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/evaluation-bias-are-you-inadvertently-training-on-your-entire-dataset-b3961aea8283"> <strong class="lc ir">评估偏差</strong> </a></li><li id="19c7" class="ne nf iq lc b ld nn lg no mm np mq nq mu nr lv nj nk nl nm bi translated"><a class="ae kv" href="https://aiqc.medium.com/memorization-isnt-learning-it-s-overfitting-b3163fe6a8b4" rel="noopener"> <strong class="lc ir">识记过拟合</strong> </a></li><li id="cfb1" class="ne nf iq lc b ld nn lg no mm np mq nq mu nr lv nj nk nl nm bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/data-leakage-5dfc2e0127d4"> <strong class="lc ir">数据泄露</strong> </a></li></ul><p id="13d0" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi ns translated"><span class="l nt nu nv bm nw nx ny nz oa di"> T </span>预测分析的目的是训练一个可以应用于其他地方的模型——能够对模型从未见过的外部样本做出预测。为了实现这一点，模型被训练的数据<em class="lb">分布</em>必须是更广泛的<em class="lb">群体</em>的<em class="lb">代表</em>。</p><p id="5344" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">在本帖中，我们将介绍如何对不同类型的数据进行分层，以及在此过程中需要注意的陷阱</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="fd2a" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">类别分层</h2><p id="0b2e" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">让我们尝试对虹膜数据集进行分层。首先，我们导入数据:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="b599" class="md me iq oc b gy og oh l oi oj">from sklearn import datasets<br/>iris = datasets.load_iris()<br/>features, labels = iris['data'], iris['target']</span></pre><p id="a664" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">然后，我们使用<em class="lb"> sklearn 的</em> <code class="fe ok ol om oc b">train_test_split</code>函数将数据分割成训练、验证和测试分割。注意<code class="fe ok ol om oc b">stratify</code>参数的使用。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="5d93" class="md me iq oc b gy og oh l oi oj">from sklearn.model_selection import train_test_split</span><span id="a576" class="md me iq oc b gy on oh l oi oj">train_features, eval_features, train_labels, eval_labels = <strong class="oc ir">train_test_split</strong>(<br/>    features, labels, test_size=0.32, <strong class="oc ir">stratify</strong>=labels<br/>)</span><span id="d58c" class="md me iq oc b gy on oh l oi oj"># `eval_*` is further divided into validation &amp; test.<br/>val_features, test_features, val_labels, test_labels = <strong class="oc ir">train_test_split</strong>(<br/>    eval_features, eval_labels, test_size=0.32, <strong class="oc ir">stratify</strong>=eval_labels<br/>)</span></pre><p id="1c73" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">稍微争论一下，我们就可以画出新拆分的分布图。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="44a3" class="md me iq oc b gy og oh l oi oj">import numpy as np<br/>_, train_counts = np.<strong class="oc ir">unique</strong>(train_labels, return_counts=True)<br/>_, val_counts = np.<strong class="oc ir">unique</strong>(val_labels, return_counts=True)<br/>_, test_counts = np.<strong class="oc ir">unique</strong>(test_labels, return_counts=True)</span><span id="f91a" class="md me iq oc b gy on oh l oi oj">from itertools import chain<br/>counts = list(chain(train_counts,val_counts,test_counts))<br/>labels = ['Setosa', 'Versicolor', 'Virginica']<br/>labels = labels + labels + labels<br/>splits = ['Train', 'Train', 'Train', 'Validation','Validation','Validation','Test','Test','Test']</span><span id="c2b3" class="md me iq oc b gy on oh l oi oj">import pandas as pd<br/>df = pd.<strong class="oc ir">DataFrame</strong>()<br/>df['Count'], df['Label'], df['Split'] = counts, labels, splits</span><span id="2f82" class="md me iq oc b gy on oh l oi oj">import plotly.express as px<br/>px.<strong class="oc ir">histogram</strong>(<br/>    df, x='Split', y='Count', color='Label',<br/>    barmode='group', height=400, title='Stratification'<br/>).update_layout(yaxis_title='Count')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/0e79eaf39f5e8a4165d2687f090f37ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsB2Tm4yOeNnfs8rV1XcLw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a5c2" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi ns translated">请注意，随着我们对数据进行越来越多的划分，分布将很难保持均匀。当数据集中有一个<em class="lb">少数</em>类时，很容易在后面的子集中用完这个代表性不足的类的样本。这很容易导致少数类的零表示分离，特别是在像 10 重交叉验证这样的场景中。这种代表性不足不仅是<em class="lb">偏差</em>的来源，还会在计算绩效指标时导致错误。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/de9290f8d45f9a9bcde750eb35613282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNB9sqq7MFsUS92tAjIpVw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="929e" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">如果我们在不使用<code class="fe ok ol om oc b">stratify</code>参数的情况下运行相同的代码，那么我们会看到我们的分布变得倾斜。尽管在数据集中类被平等地表示，当我们让分层随机进行时，<em class="lb">测试</em>分裂变得偏斜。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="9366" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">数字分层</h2><p id="60d4" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">然而，当试图将<code class="fe ok ol om oc b">stratify</code>与具有许多唯一值的数字(整数或浮点数)标签一起使用时，很可能会立即遇到下面的错误:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="d354" class="md me iq oc b gy og oh l oi oj">from aiqc import datum<br/>df = datum.to_pandas('houses.csv')<br/>labels = df['price'].to_numpy()<br/>features = df.drop(columns=['price']).to_numpy()</span><span id="0cf8" class="md me iq oc b gy on oh l oi oj">train_features, eval_features, train_labels, eval_labels = <strong class="oc ir">train_test_split</strong>(<br/>    features, labels, test_size=0.32, <strong class="oc ir">stratify</strong>=labels<br/>)</span><span id="6bce" class="md me iq oc b gy on oh l oi oj"><strong class="oc ir">"""<br/>ValueError</strong>: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.<br/>"""</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/65fd37266ca13399db22a2b9f412f392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U-Xb9e5vzeBd9oYQ8Y5LSQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">里克·巴雷特在<a class="ae kv" href="https://unsplash.com/photos/uwk8IS-HfJ8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="4637" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">垃圾箱来了</h2><p id="6fcd" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">我们可以通过将唯一标签值放入<em class="lb">装箱范围</em>来减少它们的数量。然后，我们可以将它们各自的<em class="lb">箱号</em>视为<em class="lb">离散化的</em>分类数据。</p><p id="c066" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">首先用<a class="ae kv" href="https://pandas.pydata.org/docs/reference/api/pandas.qcut.html" rel="noopener ugc nofollow" target="_blank">熊猫分位数切割</a>分割数值数据:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="8d8a" class="md me iq oc b gy og oh l oi oj">bin_count = 5<br/>bin_numbers = pd.<strong class="oc ir">qcut</strong>(<br/>    x=labels, q=bin_count, labels=False, duplicates='drop'<br/>)</span><span id="5f06" class="md me iq oc b gy on oh l oi oj">train_features, eval_features, train_labels, eval_labels = <strong class="oc ir">train_test_split</strong>(<br/>    features, labels, test_size=0.32, <strong class="oc ir">stratify</strong>=bin_numbers<br/>)</span><span id="f12b" class="md me iq oc b gy on oh l oi oj"># 2nd round<br/>bin_numbers = pd.<strong class="oc ir">qcut</strong>(<br/>    x=eval_labels, q=bin_count, labels=False, duplicates='drop'<br/>)</span><span id="fc71" class="md me iq oc b gy on oh l oi oj">val_features, test_features, val_labels, test_labels = <strong class="oc ir">train_test_split</strong>(<br/>    eval_features, eval_labels, test_size=0.32, <strong class="oc ir">stratify</strong>=bin_numbers<br/>)</span></pre><p id="488f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">然后绘制它们以验证分布:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="27f8" class="md me iq oc b gy og oh l oi oj">train_df = pd.<strong class="oc ir">DataFrame</strong>(train_labels, columns=['price'])<br/>val_df = pd.<strong class="oc ir">DataFrame</strong>(val_labels, columns=['price'])<br/>test_df = pd.<strong class="oc ir">DataFrame</strong>(test_labels, columns=['price'])</span><span id="4d3c" class="md me iq oc b gy on oh l oi oj">px.<strong class="oc ir">histogram</strong>(train_df, x='price', height=400, title='Train Labels', nbins=30)<br/>px.<strong class="oc ir">histogram</strong>(val_df, x='price', height=400, title='Validation Labels', nbins=30)<br/>px.<strong class="oc ir">histogram</strong>(test_df, x='price', height=400, title='Test Labels', nbins=30)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/2dd7138883746584aa1ff56607b0ef9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pM1meIH140debC8BKb0EFQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/6b5a864847b5a91f0cb74f19faf67cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wa2T4mkHEXtN_IgsefZcLw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/c7110321a7a06e2bfcd7cb007c917c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eU3O_Z8aqRl45Gccn6qXAA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><blockquote class="kw kx ky"><p id="7b28" class="kz la lb lc b ld le jr lf lg lh ju li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">看着这些图表真的让我质疑来自广泛交叉验证(5-10 倍)的指标是如何可信的。</p></blockquote></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi os"><img src="../Images/0405c3072dc4c025049ec8a24aa4a0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSbc3yJSqUpknTVpizU1OQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="b38a" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">多维和无监督数据</h2><p id="d846" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">让我们更进一步。如果我们没有<em class="lb">标签</em>怎么办？如果我们的数据不是表格形式的呢？</p><p id="bb00" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">下面的摄取脚本会生成一个 3D 数组。有 1000 个病人的 178 个脑电图读数。每一组阅读材料都被格式化为挑战的 2D。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="f9db" class="md me iq oc b gy og oh l oi oj">df = datum.to_pandas('epilepsy.parquet')<br/>features = df.drop(columns=['seizure']).to_numpy().reshape(1000, 178, 1)</span></pre><p id="6da1" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">您可能会惊讶，标签实际上并不需要执行分层。该函数不关心<em class="lb">分层</em>数组来自哪里，它只需要与我们的特征具有相同的样本顺序。但是，如果我们尝试使用 3D 要素进行分层，则会出现错误:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="9d9f" class="md me iq oc b gy og oh l oi oj">train_features, eval_features, = <strong class="oc ir">train_test_split</strong>(<br/>    features, test_size=0.32, <strong class="oc ir">stratify</strong>=features<br/>)</span><span id="f22c" class="md me iq oc b gy on oh l oi oj">"""<br/>ValueError: Found array with dim 3. Estimator expected &lt;= 2.<br/>"""</span></pre><p id="d396" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">花点时间想一想，数组中每个样本有 178 个读数。那么它到底是通过什么来分层的呢？让我们取每组读数的中间值<em class="lb">作为分层数组。</em></p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="5512" class="md me iq oc b gy og oh l oi oj">medians = [np.<strong class="oc ir">median</strong>(arr) for arr in features]</span><span id="7e57" class="md me iq oc b gy on oh l oi oj">bin_count = 5<br/>bin_numbers = pd.<strong class="oc ir">qcut</strong>(x=medians, q=bin_count, labels=False, duplicates='drop')</span><span id="a787" class="md me iq oc b gy on oh l oi oj">train_features, eval_features, = train_test_split(<br/>    features, test_size=0.32, stratify=bin_numbers<br/>)</span><span id="5b52" class="md me iq oc b gy on oh l oi oj"># 2nd round<br/>medians = [np.<strong class="oc ir">median</strong>(arr) for arr in eval_features]</span><span id="2cf0" class="md me iq oc b gy on oh l oi oj">bin_numbers = pd.<strong class="oc ir">qcut</strong>(<br/>    x=medians, q=bin_count, labels=False, duplicates='drop'<br/>)<br/>val_features, test_features = <strong class="oc ir">train_test_split</strong>(<br/>    eval_features, test_size=0.32, stratify=bin_numbers<br/>)</span></pre></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="0ba0" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">和 AIQC 在一起更容易</h2><p id="56be" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">如果你对这一切感到有点不知所措，可以看看 AIQC——一个端到端 MLops 的开源库。它为预处理/后处理、实验跟踪和模型评估提供了高级 API。</p><p id="dd69" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">例如，当使用<code class="fe ok ol om oc b">aiqc.Pipeline</code>摄取数据时，从业者可以使用分层参数来<em class="lb">声明</em>他们希望如何处理他们的数据:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="6288" class="md me iq oc b gy og oh l oi oj">size_test       = 0.22<br/>size_validation = 0.12<br/>fold_count      = 5<br/>bin_count       = 15</span></pre><p id="ba32" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">由于 AIQC 是<a class="ae kv" href="https://aiqc.readthedocs.io/en/latest/compare.html" rel="noopener ugc nofollow" target="_blank">数据感知型</a>，知道如何处理数据集的数据类型和监管。</p><p id="51e8" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated">AIQC 是本帖作者创建的一个开源库。</p><p id="6b7f" class="pw-post-body-paragraph kz la iq lc b ld le jr lf lg lh ju li mm lk ll lm mq lo lp lq mu ls lt lu lv ij bi translated"><em class="lb">别忘了 github.com/aiqc/aiqc</em><a class="ae kv" href="https://github.com/aiqc/aiqc" rel="noopener ugc nofollow" target="_blank"><em class="lb"/></a></p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h2 id="f576" class="md me iq bd mf mg mh dn mi mj mk dp ml mm mn mo mp mq mr ms mt mu mv mw mx my bi translated">摘要</h2><p id="8bd2" class="pw-post-body-paragraph kz la iq lc b ld mz jr lf lg na ju li mm nb ll lm mq nc lp lq mu nd lt lu lv ij bi translated">让我们回顾一下我们所学的内容:</p><ul class=""><li id="86b6" class="ne nf iq lc b ld le lg lh mm ng mq nh mu ni lv nj nk nl nm bi translated">分层确保训练和评估数据是在更广泛的<em class="lb">人群</em>中发现的分布的<em class="lb">代表</em>，这有助于我们训练<em class="lb">可概括的</em>模型。</li><li id="bfeb" class="ne nf iq lc b ld nn lg no mm np mq nq mu nr lv nj nk nl nm bi translated"><em class="lb">宁滨离散化</em>数值数据用作分层数组。</li><li id="0d0b" class="ne nf iq lc b ld nn lg no mm np mq nq mu nr lv nj nk nl nm bi translated">分层数组<em class="lb">不一定是标签/目标</em>！</li><li id="fc0b" class="ne nf iq lc b ld nn lg no mm np mq nq mu nr lv nj nk nl nm bi translated"><em class="lb">汇总统计</em>如均值和中值帮助我们减少特征的<em class="lb">维度</em>以用作分层数组。</li></ul></div></div>    
</body>
</html>