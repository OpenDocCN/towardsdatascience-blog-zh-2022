<html>
<head>
<title>Data Augmentations in Torchvision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火炬视觉中的数据增强</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-augmentations-in-torchvision-5d56d70c372e#2022-05-17">https://towardsdatascience.com/data-augmentations-in-torchvision-5d56d70c372e#2022-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7c4d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">这个博客旨在比较和熟悉研究团体使用的不同数据转换技术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e09e2385c80fb9929853f6d1fd1f5af0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NSTUJF0IQuVvWP3DinxYzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="5b23" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">介绍</h1><blockquote class="lx"><p id="52ed" class="ly lz it bd ma mb mc md me mf mg mh dk translated">为什么我们需要数据增强？</p></blockquote><p id="0b1f" class="pw-post-body-paragraph mi mj it mk b ml mm ju mn mo mp jx mq mr ms mt mu mv mw mx my mz na nb nc mh im bi translated">数据扩充是深度学习项目的关键要素之一。证明了它在对抗<strong class="mk iu"> <em class="nd">过拟合</em> </strong>和使模型<strong class="mk iu"> <em class="nd">更好地泛化</em> </strong>方面的有效性。除了正则化特征之外，变换可以通过添加已经存在的图像的稍微修改的副本来人为地<strong class="mk iu"> <em class="nd">放大</em> </strong>数据集。</p><blockquote class="lx"><p id="8bcb" class="ly lz it bd ma mb mc md me mf mg mh dk translated">如何选择正确的增强？</p></blockquote><p id="c008" class="pw-post-body-paragraph mi mj it mk b ml mm ju mn mo mp jx mq mr ms mt mu mv mw mx my mz na nb nc mh im bi translated">选择增强有两种方式:<strong class="mk iu"> <em class="nd">手动</em> </strong>或使用<em class="nd"/><strong class="mk iu"><em class="nd">优化</em> </strong> <em class="nd">策略。正如</em>你可能认为的那样，如果没有数据集领域的广泛背景研究，手动设计只能产生<em class="nd">次优解决方案</em>。</p><p id="359d" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">另一方面，<em class="nd">自动化策略</em>经过优化，可以在没有人工干预的情况下获得特定任务的最高验证准确性。</p><p id="6500" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">在这篇博客中，我们将详细介绍这两种<em class="nd">方法</em>，以及<code class="fe nj nk nl nm b">torchvision</code>代码。最后，我们将在<a class="ae nn" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>数据集上比较使用<em class="nd">无增强</em>、<em class="nd">手动</em>和<em class="nd">自动</em>策略的三个设置的性能。</p><p id="7939" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">事不宜迟，让我们深入探讨一下吧！</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="b5f7" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated"><strong class="ak">手动增强</strong></h1><p id="9d97" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated"><code class="fe nj nk nl nm b">torchvision.transforms</code>模块中有30多种不同的增强功能。在这一部分中，我们将重点介绍计算机视觉任务中最常用的五种技术。为了将它们结合在一起，我们将使用<code class="fe nj nk nl nm b">transforms.Compose()</code>函数。在我们应用任何转换之前，我们需要使用<code class="fe nj nk nl nm b">transforms.Normalize()</code>将<strong class="mk iu"> <em class="nd">规范化</em> </strong>输入。该方案减少了模型的不稳定性，加快了收敛速度。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="2ed0" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">使用整个数据集的<em class="nd">平均值</em>和<em class="nd">标准偏差</em>对输入进行归一化。这些值是为每个通道(RGB)单独计算的。在这种情况下，我们使用特定于<strong class="mk iu"> CIFAR-10 </strong>的值。如果你想了解更多关于正常化的知识，你可以看看我的<a class="ae nn" href="https://medium.com/nerd-for-tech/overview-of-normalization-techniques-in-deep-learning-e12a79060daf" rel="noopener">文章</a>。</p><p id="d030" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><code class="fe nj nk nl nm b">transforms.ToTensor()</code>命令将PIL图像格式转换为torch <code class="fe nj nk nl nm b">Tensor</code>,这样就可以将它传递给PyTorch模型。</p><p id="0f2f" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">现在我们来看看如何添加转换:</p><h2 id="087e" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><em class="oh"> 1。随机翻转</em></h2><p id="1a0b" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated">—水平</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/09d840821571f7c986ac975a9ea8ac40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4RiIea4ta_80vYK8pQMVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd oj">左</strong>:原稿，<strong class="bd oj">右</strong>:放大。图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="7eb2" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">—垂直</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/e35d0c7995d7079715a2ee56710a3cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMGxKStmO8MXwHpL2N2FAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6b99" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">水平和垂直翻转是最简单的和最强大的T21变换之一。参数<code class="fe nj nk nl nm b"><em class="nd">p</em></code>表示反射发生的概率。</p><h2 id="1576" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><em class="oh"> 2。填充</em></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/03c12428870e3f03ddf8885ed0478571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dceuuu0R3ysH4QCtCd03HA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="2545" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">参数<code class="fe nj nk nl nm b">pad</code>定义了输出的<em class="nd">高度</em>和<em class="nd">宽度</em>的额外像素。</p><h2 id="0f84" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><em class="oh"> 3。随机裁剪</em></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/90939fcf961cb7964efcd11bc5984fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuukqpqHjYK0deftHy0R3Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="86d4" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">这个功能是将新图像裁剪成想要的<code class="fe nj nk nl nm b">size</code>。<code class="fe nj nk nl nm b">Padding</code>有助于保持输入的精确尺寸。</p><h2 id="a2da" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><em class="oh"> 4。颜色抖动</em></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/f7f07b721db33dfb17bdc9f83c3c5ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WXgCEtAd2nsbAWsFagywA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="b1c2" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">该功能随机操作<code class="fe nj nk nl nm b">brightness</code>、<code class="fe nj nk nl nm b">contrast</code>和<code class="fe nj nk nl nm b">saturation</code>。这样，我们可以模拟白天和夜晚的情况，这有助于泛化。</p><h2 id="b83d" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><em class="oh"> 5。随机擦除</em></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/94f7e728acea86b2545ab5289c62419a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ry4z7mxXsaX9gLHkE_yCHw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="65ac" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">该功能随机选择矩形区域，'<em class="nd">'删除其像素值为0的像素。再次，<code class="fe nj nk nl nm b"><em class="nd">p</em></code>表示发生的概率。与其他变换不同的是<code class="fe nj nk nl nm b">RandomErasing()</code>直接应用于张量；因此它在<code class="fe nj nk nl nm b">toTensor()</code>之后。</em></p><h2 id="86c1" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated">手工设计</h2><p id="e9a5" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated"><code class="fe nj nk nl nm b">transforms.Compose()</code>功能允许我们链接多个扩展并创建一个<em class="nd">策略</em>。有一点需要记住，有些技术可能是无用的，甚至会降低性能。</p><p id="64ac" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">最简单的例子就是<em class="nd">横向</em>翻转数字<em class="nd">‘6’</em>，变成<em class="nd">‘9’</em>。可惜标签做不到这一点。因此，只考虑数据集的相关扩充是值得的。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="4234" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">自动增强</h1><h2 id="388f" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated">自动增强</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/de4709c32d7e885b1fccf141780cda2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GOS6C4_UAyruf9PwGwZXiQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">包含5个子策略的自动增强策略。每个子策略由2个转换以及这些操作的概率和大小组成。图片来自<a class="ae nn" href="https://arxiv.org/pdf/1805.09501.pdf" rel="noopener ugc nofollow" target="_blank">自动增强:从数据中学习增强策略</a>。</p></figure><p id="1dc6" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">2017年，谷歌开发了第一个算法，<strong class="mk iu"> <em class="nd">自动搜索</em> </strong>以改进数据扩充政策。手工设计的主要问题是耗时的<em class="nd">背景</em>研究和<em class="nd">次优</em>结果。新的解决方案建立在两个组件上，<em class="nd">搜索算法</em>和<em class="nd">搜索空间</em>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/fa473898dc411e6bc15ec943b1b0ecd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-JCrMRhj1nKbozAfNQD9Qg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">搜索算法框架。图片作者。</p></figure><p id="1e3c" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">在每一步中，<em class="nd">控制器</em>生成<strong class="mk iu"> <em class="nd"> 5 </em> </strong> <strong class="mk iu"> <em class="nd">子策略</em> </strong>和<strong class="mk iu"> <em class="nd"> 2 </em> <em class="nd">采样</em> <em class="nd">操作</em> </strong>。它按顺序进行，首先选择<em class="nd">变换</em>，然后选择其<strong class="mk iu"> <em class="nd">大小</em> </strong>和<strong class="mk iu"> <em class="nd">概率</em> </strong>。扩充应用于数据集，并传递给原始网络的<strong class="mk iu">较小版本(<em class="nd">子版本</em>)</strong>。产生的<strong class="mk iu"> <em class="nd">验证精度</em> </strong>使用PPO算法(奖励)进行修改，以更新控制器的权重。这个过程重复15 000次，根据结果选择最佳政策。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c92c468867eb5d23ef14292ac425b691.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eMtW8zESTwHfGrx3cYnjuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">控制器生成的单个子策略。图片作者。</p></figure><p id="a7df" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">自动增强</em>击败了当时所有最先进的结果，但有一个警告:<em class="nd">计算成本</em>。有16种<em class="nd">可能的</em> <em class="nd">增强(如旋转、均衡</em> <a class="ae nn" href="https://arxiv.org/pdf/1805.09501.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nd">等</em> </a> <em class="nd">)。)</em>、10个<em class="nd">量级</em>值、11个概率，这就产生了巨大的<em class="nd">(16 * 11 * 10)⁰</em><strong class="mk iu"><em class="nd">5个子策略的搜索空间</em> </strong>。寻找最优的是一项计算量很大的重要任务。</p><p id="81b4" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">幸运的是，<code class="fe nj nk nl nm b">torchvision</code>为我们提供了针对CIFAR-10、ImageNet或SVHN等数据集的预训练策略。所有这些都在<code class="fe nj nk nl nm b">AutoAugemntPolicy</code>封装中提供。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="307c" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><code class="fe nj nk nl nm b">Torchvision</code>只接受已经培训过的政策，不支持<em class="nd">学习</em>程序。假设您想要为数据集找到最佳扩充。在这种情况下，你需要一个带有<em class="nd">自动增强</em>的外部库或者重新实现算法。但是在考虑这个选项之前，先看看下面的方法，它不需要任何额外的包，计算量也更小。</p><h2 id="3399" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated">随机扩增</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/53e0eedee70f457d27407a200aab11f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lAdjP9SBr_9JXx_VrYVVA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae nn" href="https://arxiv.org/pdf/1909.13719.pdf" rel="noopener ugc nofollow" target="_blank"> RandAugment:搜索空间缩小的实用自动数据扩充</a>。</p></figure><p id="7094" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">除了<em class="nd">自动增强</em>的计算负担之外，它在大型数据集上的表现也更差。子(<em class="nd">代理</em>)网络仅近似于原始模型性能；因此，它只能生成近似(<em class="nd">次优</em>)策略。</p><p id="00da" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd"> RandAugment </em> <strong class="mk iu">删除</strong>任何<em class="nd">学习</em>技术和代理任务，以找到最佳的扩充。</p><blockquote class="lx"><p id="7d73" class="ly lz it bd ma mb mc md me mf mg mh dk translated">等等，他们是怎么做到的？</p></blockquote><p id="a7b0" class="pw-post-body-paragraph mi mj it mk b ml mm ju mn mo mp jx mq mr ms mt mu mv mw mx my mz na nb nc mh im bi translated">首先，RandAugment只接受两个参数，<em class="nd"> N </em>和<em class="nd"> M </em>。<em class="nd"> N </em>是14个可用的增强的<strong class="mk iu">数(<a class="ae nn" href="https://sh-tsang.medium.com/review-randaugment-9a392e6911e9#:~:text=Given%20N%20transformations%20for%20a,%2Dx%2C%20translate%2Dy." rel="noopener">整个列表</a>)。<em class="nd"> M </em>是这些操作的<strong class="mk iu">量级</strong>，范围为1-10，定义图像旋转、平移等的程度。</strong></p><p id="fa6d" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">我们可以通过执行简单的<strong class="mk iu">网格搜索</strong>来找到这些参数，网格搜索依赖于<em class="nd">数据集</em>和<em class="nd">主</em> <em class="nd">模型</em>，而不是自动增强中的“<em class="nd">子</em>”网络。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/0dd9f015dfed42c238cfa75dea25d1e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lfOkOG2-7Ujc2p5qh5cDBQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">简单的网格搜索，验证精度为N={1，2}和M{2，6，10，14}。图片作者。</p></figure><p id="6d3f" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">本质上，我们根据N和M的不同组合来训练网络，并选择一个具有最佳验证准确性的组合。听起来很简单，结果本身就说明了产生比<em class="nd">自动增强</em>更好或相等的<em class="nd">验证准确性</em>。</p><p id="4baf" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">这是<em class="nd">随机增加</em>的<code class="fe nj nk nl nm b">torchvision</code>代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="94c8" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">比较</h1><p id="7e4a" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated">在这一部分中，我们将最终看到三种增强系统的性能:</p><ul class=""><li id="2190" class="os ot it mk b ml ne mo nf mr ou mv ov mz ow mh ox oy oz pa bi translated"><strong class="mk iu">普通</strong> —仅应用<code class="fe nj nk nl nm b">Normalize()</code>操作。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><ul class=""><li id="4c76" class="os ot it mk b ml ne mo nf mr ou mv ov mz ow mh ox oy oz pa bi translated"><strong class="mk iu">基线</strong>—<code class="fe nj nk nl nm b">HorizontalFlip()</code>、<code class="fe nj nk nl nm b">RandomCrop()</code>、<code class="fe nj nk nl nm b">RandomErasing()</code>的组合。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><ul class=""><li id="ebec" class="os ot it mk b ml ne mo nf mr ou mv ov mz ow mh ox oy oz pa bi translated"><strong class="mk iu">自动增强</strong> — <strong class="mk iu"> </strong>策略，其中<code class="fe nj nk nl nm b">AutoAugment</code>是基线配置的附加转换。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="7693" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><strong class="ak">数据集</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/e329a0f84fc0b4a296c06eb91d131364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6551nCZ3eeRrWYqp1QXKRQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="9905" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><strong class="mk iu"> CIFAR-10 </strong>由10类60 000幅32x32彩色图像组成，每类60 00幅图像。数据集分为50 000幅训练图像、2500幅验证图像和7500幅测试图像。</p><p id="9b99" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">*仅增强训练图像。</em></p><p id="c474" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">对数据集应用转换的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="bf07" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><strong class="ak">型号</strong></h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/bfadae5178e0ecd5876f442ee5f4cf6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lfwX3s9RcdBSOXe3kqyzww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">d —表示阶段{1，2，3}。图片作者。</p></figure><p id="e426" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><strong class="mk iu"> ResNet-20 </strong>是为<a class="ae nn" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="mk iu">图像识别深度残差学习</strong> </a>论文中提出的CIFAR-10数据集特别定制的ResNet版本。</p><p id="be35" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">第一层<code class="fe nj nk nl nm b"><strong class="mk iu">Conv1</strong></code>是具有3x3内核大小的卷积。接下来是3个<strong class="mk iu">阶段</strong>，其中每个阶段包含{16，32，64}个<em class="nd">过滤器</em>。参数<strong class="mk iu"> <em class="nd"> n </em> </strong>通过操纵每一阶段的 <strong class="mk iu"> <em class="nd">残差块</em> </strong>的数量<em class="nd">来控制网络的深度。在我们的例子中，它等于3，这产生9个残差块和18个卷积层。</em></p><p id="ae7c" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">使用步长2对阶段之间的特征图</em>进行下采样，这分别给出了输出尺寸{32，16，8}。<strong class="mk iu">残差投影</strong>在这里使用1x1卷积来匹配下一阶段的通道。</p><p id="6bd3" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">网络以<strong class="mk iu"> <em class="nd">全局平均池</em> </strong>和<strong class="mk iu">完全连接的</strong>层结束，导致<strong class="mk iu"> <em class="nd"> 20 </em> </strong> <strong class="mk iu">可训练</strong> <strong class="mk iu">层</strong>。</p><p id="343a" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">下面是PyTorch中的实现:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6e1e" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">如果你想了解更多关于T42的事情，可以看看我在YouTube上的视频。</p><h2 id="a956" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><strong class="ak">超参数</strong></h2><p id="5d62" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated">这些是用于训练的一组<em class="nd">参数</em>:</p><pre class="kj kk kl km gt pd nm pe pf aw pg bi"><span id="e099" class="nv lg it nm b gy ph pi l pj pk">learning_rate = 0.001<br/>batch = 256<br/>optimizer = Adam<br/>loss = CrossEntropyLoss<br/>epochs = 40<br/>n = 3<br/>weight initialization = Kaiming He</span></pre><p id="8483" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">我还在模型中添加了<em class="nd">学习率调度器</em>。当验证损失<em class="nd">超过</em>时，它降低了学习率，这有助于防止<em class="nd">过拟合</em>。</p><p id="e0e4" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">我没有包括所有的训练、验证和测试循环，因为它们有点长，而且对理解主题并不重要。然而，你可以很容易地在我的Github上找到它们，并有一些直观的解释。</p><h2 id="fb1f" class="nv lg it bd lh nw nx dn ll ny nz dp lp mr oa ob lr mv oc od lt mz oe of lv og bi translated"><strong class="ak">结果</strong></h2><p id="c95f" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated">现在是时候在训练3个不同的模型40个时期后比较结果了。要评估的主要指标是<em class="nd">精度</em>和<em class="nd">损失</em>函数，所以让我们看看它们是什么样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/566f014d51522a3d13ba791aabe25c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1guPQoIWR6FJOXUYjp1ruA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">虚线表示验证准确性。图片作者。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/700d7c1e25aae123e31d111196817dec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R8fCAWMZa3LZX-vZLds4KQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">虚线代表验证损失。图片作者。</p></figure><p id="d523" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">在<em class="nd">‘Plain’</em>模型中，训练准确度趋向100%，而验证饱和并降低。此外，验证损失正在增加，这表明<strong class="mk iu">过拟合</strong>问题。</p><p id="24e2" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">基线</em>配置似乎<strong class="mk iu">处理</strong>过拟合很好。令人惊讶的是，学习率一次也没有下降。验证准确度稳步向更高的值发展，没有显著下降。可能该模型可以被训练更长时间以用更低的学习率获得更好的结果。</p><p id="4f09" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">最后但同样重要的是，<em class="nd"> AutoAugment </em>有趣地保持了验证精度高于测试精度。指出了<strong class="mk iu">欠拟合</strong>的问题，使模型过于泛化，不能很好地拟合数据。同样，该模型可以通过学习率时间表进行更长时间的训练，并可能获得更好的结果。</p><p id="0ea7" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">最终结果可能会令人惊讶，基线<em class="nd">增强给出了大约87%测试准确度的最佳结果，而自动增强给出了大约84%的测试准确度。它证明了随机翻转、裁剪和擦除是多么强大。</em></p><p id="595c" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">为自动增强辩护，我个人认为对于这样一个小网络有太多的转换。像<em class="nd"> ResNet50 </em>这样的大型模型将具有额外的学习能力，以覆盖更复杂的情况，并更好地进行归纳。</p></div><div class="ab cl ky kz hx la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="im in io ip iq"><h1 id="8d4c" class="lf lg it bd lh li lj lk ll lm ln lo lp jz lq ka lr kc ls kd lt kf lu kg lv lw bi translated">结论</h1><p id="f84f" class="pw-post-body-paragraph mi mj it mk b ml no ju mn mo np jx mq mr nq mt mu mv nr mx my mz ns nb nc mh im bi translated">如果你设法到达那里，祝贺你。在这篇文章中，我们经历了深度学习中使用的大量不同的数据增强技术。我们比较了三种不同设置的性能。</p><p id="ef98" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">简单的</em>配置证明了数据扩充对于提高模型的准确性至关重要。</p><p id="50f2" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated"><em class="nd">手动</em>挑选转换似乎需要更多数据集背后的直觉，并且经常产生次优结果。尽管如此，即使是标准政策也能产生令人印象深刻的结果。</p><p id="0eed" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">另一方面，<em class="nd">自动化增强</em>无疑是未来的变革，理论上应该在<em class="nd">最优</em>解决方案下表现更好。在我们的案例中,<em class="nd">学到的</em>策略实际上并没有改善手工设计的结果。然而，这是一个活跃的研究领域，只是最近才开始得到更多的关注，仍然有很大的潜力。</p><p id="a680" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">我希望这篇文章给你一个坚实的介绍，让你探索和试验更多的torchvision和测试一些其他的技术。欢迎在评论中提问。</p><p id="3fc9" class="pw-post-body-paragraph mi mj it mk b ml ne ju mn mo nf jx mq mr ng mt mu mv nh mx my mz ni nb nc mh im bi translated">如果你喜欢这篇文章，你应该看看我的<a class="ae nn" href="https://medium.com/@maciejbalawejder" rel="noopener"> <strong class="mk iu">中的</strong> </a>和<a class="ae nn" href="https://github.com/maciejbalawejder" rel="noopener ugc nofollow" target="_blank"> <strong class="mk iu"> Github </strong> </a>看看我正在做的其他项目。</p></div></div>    
</body>
</html>