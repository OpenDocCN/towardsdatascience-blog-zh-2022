<html>
<head>
<title>Using Whisper and BERTopic to model Kurzgesagt’s videos</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Whisper 和 BERTopic 对 Kurzgesagt 的视频进行建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-whisper-and-bertopic-to-model-kurzgesagts-videos-7d8a63139bdf#2022-11-21">https://towardsdatascience.com/using-whisper-and-bertopic-to-model-kurzgesagts-videos-7d8a63139bdf#2022-11-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3176" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们可以在 Kurzgesagt 的视频中找到哪些主题？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/512eeee527598f92d12a96eb22c0ccec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlPTB5bNcbyyH-RmOhqpdA.png"/></div></div></figure><p id="4f9d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一个多月前，OpenAI 发布了一个名为<a class="ae lq" href="https://openai.com/blog/whisper/" rel="noopener ugc nofollow" target="_blank"> Whisper </a>的英语语音识别神经网络。由于它的准确性、易用性，最重要的是因为他们开源了它，它在过去的几周里变得相当受欢迎！</p><p id="5bdc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有了这些版本，我迫不及待地想要得到这样一个模型，并尝试一下。然而，我喜欢有一个有趣的用例来实际使用它。</p><p id="8a78" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">所以我想，为什么不用它来制作一个我一直喜欢看的频道，Kurzgesagt！</p><p id="915f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一个令人惊叹的频道，有着令人难以置信的精心解释的视频，侧重于动画教育内容，从气候变化和恐龙到黑洞和地球工程。</p><p id="3b16" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我决定不仅仅做一些文字记录。相反，让我们使用 BERTopic 来看看我们是否可以提取 Kurzgesagt 视频中的主要主题。</p><p id="32db" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，本文是一篇关于使用 Whisper 和 BERTopic 从 Youtube 视频中提取脚本并在其上使用主题建模的教程。</p><h1 id="8fc3" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">1.装置</h1><p id="20ef" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在进入实际代码之前，我们首先需要安装几个包，分别是<a class="ae lq" href="https://github.com/openai/whisper" rel="noopener ugc nofollow" target="_blank">耳语</a>、<a class="ae lq" href="https://github.com/MaartenGr/BERTopic" rel="noopener ugc nofollow" target="_blank"> BERTopic </a>和<a class="ae lq" href="https://github.com/pytube/pytube" rel="noopener ugc nofollow" target="_blank"> Pytube </a>。</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="16d9" class="mt ls it mp b be mu mv l mw mx">pip install --upgrade git+https://github.com/openai/whisper.git <br/>pip install git+https://github.com/pytube/pytube.git@refs/pull/1409/merge<br/>pip install bertopic</span></pre><p id="c7dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们有目的地在 Pytube 中选择一个特定的 pull 请求，因为它修复了空通道的问题。</p><p id="becd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在最后一步，我将简要介绍 BERTopic 的一个即将推出的特性，您已经可以安装该特性了:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="ec6b" class="mt ls it mp b be mu mv l mw mx">pip install git+https://github.com/MaartenGr/BERTopic.git@refs/pull/840/merge</span></pre><h1 id="06be" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">2.Pytube</h1><p id="c8c9" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">我们需要从 Kurzgesagt 的 YouTube 频道中提取我们需要的每一个元数据。使用 Pytube，我们可以创建一个<code class="fe my mz na mp b">Channel</code>对象，允许我们提取他们视频的 URL 和标题。</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="fb1e" class="mt ls it mp b be mu mv l mw mx"># Extract all video_urls<br/>from pytube import YouTube, Channel<br/>c = Channel('https://www.youtube.com/c/inanutshell/videos/')<br/>video_urls = c.video_urls<br/>video_titles = [video.title for video in c.videos]</span></pre><p id="0aeb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还提取了标题，因为当我们稍后可视化主题时，它们可能会派上用场。</p><h1 id="9c47" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">3.低语</h1><p id="ffbe" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">当我们有了我们的网址，我们就可以开始下载视频和提取文字记录。为了创建这些抄本，我们使用了最近发布的 Whisper。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/58d7b2cb134ea08f00143ed26f1b2314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeOGVVn7IA5ZFJFAuw0-CA.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">耳语的管道。更多信息，请看他们的博客。</p></figure><p id="3663" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于新用户来说，该模型可能会令人望而生畏，但它本质上是一个序列到序列转换器模型，已经在几个不同的语音处理任务上进行了训练。这些任务被输入到 Transformer 模型的编码器-解码器结构中，这使得 Whisper 可以取代传统语音处理管道的几个阶段。</p><p id="4b4b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">换句话说，因为它专注于联合表示多个任务，所以它可以在一个模型中学习各种不同的处理步骤！</p><p id="047d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这很好，因为我们现在可以使用一个模型来完成所有必要的处理。下面，我们将导入我们的 Whisper 模型:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="4605" class="mt ls it mp b be mu mv l mw mx"># Just two lines of code to load in a Whisper model!<br/>import whisper<br/>whisper_model = whisper.load_model("tiny")</span></pre><p id="03e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，我们迭代我们的 YouTube URLs，下载音频，最后通过我们的 Whisper 模型传递它们，以便生成转录:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="0bb4" class="mt ls it mp b be mu mv l mw mx"># Infer all texts<br/>texts = []<br/>for url in video_urls[:100]:<br/>    path = YouTube(url).streams.filter(only_audio=True)[0].download(filename="audio.mp4")<br/>    transcription = whisper_model.transcribe(path)<br/>    texts.append(transcription["text"])</span></pre><p id="7117" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">就是这样！我们现在有 Kurzgesagt 的 100 个视频的转录本。</p><p id="5f4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">注意</strong>:我选择了<code class="fe my mz na mp b">tiny</code>型号，因为它的速度和准确性，但是还有<a class="ae lq" href="https://github.com/openai/whisper#available-models-and-languages" rel="noopener ugc nofollow" target="_blank">更准确的型号</a>，你可以在 Whisper 中使用，值得一试。</p><h1 id="9daa" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">4.抄本处理</h1><p id="582a" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">BERTopic 将主题建模作为一项集群任务，结果是将单个文档分配给单个主题。为了避免这一点，我们可以将我们的抄本分成句子，并在这些句子上运行 BERTopic:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="6914" class="mt ls it mp b be mu mv l mw mx">from nltk.tokenize import sent_tokenize<br/><br/># Sentencize the transcripts and track their titles<br/>docs = []<br/>titles = []<br/>for text, title in zip(texts, video_titles):<br/>    sentences = sent_tokenize(text)<br/>    docs.extend(sentences)<br/>    titles.extend([title] * len(sentences))</span></pre><p id="d39e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们不仅有更多的数据来训练，而且还可以创建更精确的主题表示。</p><p id="118f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">注意</strong>:在 BERTopic 中可能会有也可能没有主题发布的特性…</p><h1 id="0b09" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">5.贝尔托皮奇</h1><p id="4324" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">BERTopic 是一种主题建模技术，它专注于模块化、透明性和人工评估。它是一个框架，允许用户在一定范围内构建自己的定制主题模型。</p><p id="a4c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">BERTopic 的工作原理是遵循聚类和主题提取的线性管道:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/1b74f6f0ee606ddfedbd0dafe10ce768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlDZcj7xBoIX-5Ge17wgtA.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">SBERT -&gt; UMAP -&gt; HDBSCAN -&gt;计数矢量器-&gt; c-TF-IDF--&gt;(可选)MMR</p></figure><p id="d61a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在流水线的每一步，它对之前的所有步骤几乎不做任何假设。例如，c-TF-IDF 表示不关心使用哪个输入嵌入。BERTopic 的这一指导思想允许子组件被轻松地替换掉。因此，您可以随心所欲地构建您的模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/0c83c1aae10a7b9346733eea5df3c367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UAASA2YVnBGah8nWjv6m_g.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">通过定义嵌入模型、降维算法、聚类模型以及 c-TF-IDF 提取，构建您自己的主题模型。</p></figure><p id="cec1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尽管我们只需要几行代码就可以使用 BERTopic，但生成我们的嵌入是值得的，这样我们就可以在以后需要重新生成它们时多次使用它们:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="4cdb" class="mt ls it mp b be mu mv l mw mx">from sentence_transformers import SentenceTransformer<br/><br/># Create embeddings from the documents<br/>sentence_model = SentenceTransformer("paraphrase-multilingual-mpnet-base-v2")<br/>embeddings = sentence_model.encode(docs)</span></pre><p id="76da" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然 Kurzgesagt 的内容是英文的，但可能会有一些非英文术语，所以我选择了多语言句子转换器模型。</p><p id="9925" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成嵌入后，我想稍微调整一下子模型，以便更好地适应我们的数据:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="8c69" class="mt ls it mp b be mu mv l mw mx">from bertopic import BERTopic<br/>from umap import UMAP<br/>from hdbscan import HDBSCAN<br/>from sklearn.feature_extraction.text import CountVectorizer<br/><br/># Define sub-models<br/>vectorizer = CountVectorizer(stop_words="english")<br/>umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)<br/>hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=2, metric='euclidean', cluster_selection_method='eom')<br/><br/># Train our topic model with BERTopic<br/>topic_model = BERTopic(<br/>    embedding_model=sentence_model,<br/>    umap_model=umap_model,<br/>    hdbscan_model=hdbscan_model,<br/>    vectorizer_model=vectorizer<br/>).fit(docs, embeddings)</span></pre><p id="2771" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经拟合了 BERTopic 模型，让我们来看看它的一些主题。为此，我们运行<code class="fe my mz na mp b">topic_model.get_topic_info().head(10)</code>来获得最常见主题的数据框架:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/3cd236843ac27f2723e7027a98208ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xzLEy3vSO4UDI0vi5AjJ1A.png"/></div></div></figure><p id="f75f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以看到关于食物、细胞、星系和更多的话题！</p><h1 id="0fde" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">6.可视化主题</h1><p id="b7ad" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">尽管该模型发现了一些有趣的主题，但手动浏览这些主题似乎需要大量的工作。相反，我们可以使用一些可视化技术，使它变得简单一些。</p><p id="1a1a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，生成一些更好看的标签可能是值得的。为此，我们将使用<code class="fe my mz na mp b">generate_topic_labels</code>生成我们的主题标签。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/84b571fdd61c22477de4fcbb9ca570fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aGrXTG7ir87qAA1mgWGDNw.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">使用“generate_topic_labels ”,你可以为你的用例生成更好看的标签。</p></figure><p id="58e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们想要的是前 3 个单词，带一个<code class="fe my mz na mp b">,</code>分隔符，我们对主题前缀不太感兴趣。</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="f146" class="mt ls it mp b be mu mv l mw mx"># Generate nicer looking labels and set them in our model<br/>topic_labels = topic_model.generate_topic_labels(nr_words=3,<br/>                                                 topic_prefix=False,<br/>                                                 word_length=15,<br/>                                                 separator=", ")<br/>topic_model.set_topic_labels(topic_labels)</span></pre><p id="fd47" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们准备执行一些有趣的可视化。第一关，<code class="fe my mz na mp b">.visualize_documents</code>！该方法旨在在 2D 空间中交互地可视化文档及其对应的文档:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="21b2" class="mt ls it mp b be mu mv l mw mx"># Manually selected some interesting topics to prevent information overload<br/>topics_of_interest = [33, 1, 8, 9, 0, 30, 27, 19, 16, <br/>                      28, 44, 11, 21, 23, 26, 2, 37, 34, 3, 4, 5,<br/>                      15, 17, 22, 38]<br/><br/># I added the title to the documents themselves for easier interactivity<br/>adjusted_docs = ["&lt;b&gt;" + title + "&lt;/b&gt;&lt;br&gt;" + doc[:100] + "..." <br/>                 for doc, title in zip(docs, titles)]<br/><br/># Visualize documents<br/>topic_model.visualize_documents(<br/>    adjusted_docs, <br/>    embeddings=embeddings, <br/>    hide_annotations=False, <br/>    topics=topics_of_interest,<br/>    custom_labels=True<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/2784aa617fa926bc469146c34018cecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wKEXqiCNnnj8_KNd-PQ-nA.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">我们可以在 Kurzgesagt 的视频中找到一些主题。</p></figure><p id="e962" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从上面的图像中可以看出，我们有很多不同的话题，从恐龙和气候变化到细菌甚至蚂蚁！</p><h1 id="4f13" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">7.每个视频的主题</h1><p id="43e9" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">因为我们已经将每个视频分成句子，所以我们可以对每个视频的主题分布进行建模。我最近看到一个视频，叫做</p><p id="7e66" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">“如果超级火山爆发会发生什么？”</strong></p><p id="17d8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们来看看视频中有哪些主题:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="cf31" class="mt ls it mp b be mu mv l mw mx"># Topic frequency in ""What Happens if a Supervolcano Blows Up?""<br/>video_topics = [topic_model.custom_labels_[topic+1] <br/>                for topic, title in zip(topic_model.topics_, titles) <br/>                if title == "What Happens if a Supervolcano Blows Up?" <br/>                and topic != -1]<br/>counts = pd.DataFrame({"Topic": video_topics}).value_counts(); countstopics_per_class = topic_model.topics_per_class(docs, classes=classes)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/bed38b42045834df92c5aa7219670b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EkBbiAtG26_ty-piKQetNw.png"/></div></div></figure><p id="1c2b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如所料，它似乎主要与火山爆发有关，但也涉及一般的爆炸。</p><h1 id="8670" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">8.主题分布</h1><p id="45a0" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在即将到来的<a class="ae lq" href="https://github.com/MaartenGr/BERTopic/pull/840" rel="noopener ugc nofollow" target="_blank"> BERTopic v0.13 版本</a>中，有可能近似任何文档的主题分布，而不管其大小如何。</p><p id="4e3e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">该方法的工作原理是在文档上创建一个滑动窗口，并计算每个主题的窗口相似度:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/cd9a5a4cfc40bdf14c45f682770edcde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dRujAcu8QNy7RzqwX_j7mQ.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">在令牌级别生成多主题分配的过程。</p></figure><p id="5805" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以为所有文档生成这些分布，方法是运行以下代码，并确保我们在令牌级别上计算分布:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="4020" class="mt ls it mp b be mu mv l mw mx"># We need to calculate the topic distributions on a token level<br/>(topic_distr, <br/>topic_token_distr) = topic_model.approximate_distribution(<br/>                                      docs, calculate_tokens=True<br/>)</span></pre><p id="3f80" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们需要选择一段文本来为主题建模。为此，我认为探索模型如何处理 Kurzgesagt 结尾的 Brilliant 广告会很有趣:</p><blockquote class="nn no np"><p id="0d86" class="ku kv nq kw b kx ky ju kz la lb jx lc nr le lf lg ns li lj lk nt lm ln lo lp im bi translated">通过免费试用 brilliant premium，您可以探索 brilliant 提供的一切。</p></blockquote><p id="2e76" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们输入文档并运行我们可视化:</p><pre class="kj kk kl km gt mo mp mq bn mr ms bi"><span id="d163" class="mt ls it mp b be mu mv l mw mx"># Create a visualization using a styled dataframe if Jinja2 is installed<br/>df = topic_model.visualize_approximate_distribution(docs[100], topic_token_distr[100]); df</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/d996b17c2cbf40428dfc4fb3928e470d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSNp-FVf6bFVbWPMTHhTzg.png"/></div></div></figure><p id="4909" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们所看到的，它似乎选择了关于<a class="ae lq" href="https://brilliant.org/s/partners/nutshell/" rel="noopener ugc nofollow" target="_blank">辉煌</a>和会员资格的话题，这在这种情况下似乎是有意义的。</p><p id="a4d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有趣的是，使用这种方法，我们可以考虑到不仅每个文档有多个主题，甚至每个标记有多个主题！</p><h1 id="154b" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">感谢您的阅读！</h1><p id="aa17" class="pw-post-body-paragraph ku kv it kw b kx mj ju kz la mk jx lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">如果你和我一样，对人工智能、数据科学或心理学充满热情，请随时在<a class="ae lq" href="https://www.linkedin.com/in/mgrootendorst/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> LinkedIn </strong> </a> <strong class="kw iu"> </strong>上添加我，或者在<a class="ae lq" href="https://twitter.com/MaartenGr" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> Twitter </strong> </a>上关注我。你也可以在我的<a class="ae lq" href="https://maartengrootendorst.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">个人网站</strong> </a>上找到我的一些内容。这几天在试<a class="ae lq" href="https://fosstodon.org/@maartengr" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu">乳齿象</strong> </a>如果有兴趣转行。</p><p id="5a53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="nq">所有未注明出处的图片均由作者</em>创作</p></div></div>    
</body>
</html>