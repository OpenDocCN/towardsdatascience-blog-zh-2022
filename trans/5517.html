<html>
<head>
<title>Artificial Intelligence for Geospatial Analysis with Pytorch’s TorchGeo (Part 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Pytorch 的 TorchGeo 进行地理空间分析的人工智能(第 3 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-3-7521131f30b1#2022-12-13">https://towardsdatascience.com/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-3-7521131f30b1#2022-12-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="78ad" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Pytorch 和 TorchGeo 包的端到端深度学习地理空间分割项目</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f299e1cf7c416f0ea98e543694b61da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vm3VRhTtsjgUTJWF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@nasa?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> NASA </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><h1 id="3a70" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="0ef2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在之前的故事(<a class="ae ky" href="https://medium.com/towards-data-science/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-1-52d17e409f09" rel="noopener">第 1 部分</a>和<a class="ae ky" rel="noopener" target="_blank" href="/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-2-ec3785fae284">第 2 部分</a>)中，我们看到了如何准备一个光栅(多光谱)图像数据集，并使用 TorchGeo 提供的<code class="fe mn mo mp mq b">IntersectionDataset </code>将它们与相应的标签(地面真实遮罩)结合起来。为了从中抽取样本(训练所需的较小的固定大小的补丁)，将<code class="fe mn mo mp mq b">RandomGeoSampler</code>与<code class="fe mn mo mp mq b">DataLoader</code>对象一起使用(负责向训练过程提供批次——样本组)。</p><p id="3124" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">此外，我们使用<code class="fe mn mo mp mq b">nn.Sequential</code>类为每个批次添加了光谱指数和归一化。现在，在这最后一部分，我们将看到如何创建一个能够“学习”正确分割我们的图像的模型，以及如何将所有东西放在一起形成一个训练循环。</p><p id="cf46" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">所以让我们开始吧！</p><h1 id="1c5f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">基线</h1><p id="9129" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们需要从停下来的地方赶上来，为任务准备数据集和数据加载器。基本上，我们需要创建两个数据加载器，一个用于训练，一个用于验证，遵循与前面相同的步骤，如下所示。</p><h2 id="a20f" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">数据集和数据加载器</h2><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="fbf5" class="nm la it mq b be nn no l np nq">train_imgs = RasterDataset(root=(root/'tra_scene').as_posix(), crs='epsg:3395', res=10, transforms=scale)<br/>train_msks = RasterDataset(root=(root/'tra_truth').as_posix(), crs='epsg:3395', res=10)<br/><br/>valid_imgs = RasterDataset(root=(root/'val_scene').as_posix(), crs='epsg:3395', res=10, transforms=scale)<br/>valid_msks = RasterDataset(root=(root/'val_truth').as_posix(), crs='epsg:3395', res=10)<br/><br/># IMPORTANT<br/>train_msks.is_image = False<br/>valid_msks.is_image = False<br/><br/>train_dset = train_imgs &amp; train_msks<br/>valid_dset = valid_imgs &amp; valid_msks<br/><br/>train_sampler = RandomGeoSampler(train_imgs, size=512, length=260, units=Units.PIXELS)<br/>valid_sampler = RandomGeoSampler(valid_imgs, size=512, length=128, units=Units.PIXELS)</span></pre><p id="c301" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">采样器中指定的长度是一次“通过”(也称为一个时期)中提供的样本数。这通常是数据集中的面片数，一个历元应该遍历所有样本。然而，由于我们使用的是随机抽样，我们不能保证覆盖所有地区。在这种情况下，我将长度定义为每个数据集中图像数量的四倍(训练和验证)。</p><p id="6e2a" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">现在，让我们创建数据加载器并检查它们是否按预期工作。</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="5c30" class="nm la it mq b be nn no l np nq">train_dataloader = DataLoader(train_dset, sampler=train_sampler, batch_size=8, collate_fn=stack_samples)<br/>valid_dataloader = DataLoader(valid_dset, sampler=valid_sampler, batch_size=8, collate_fn=stack_samples)<br/><br/>train_batch = next(iter(train_dataloader))<br/>valid_batch = next(iter(valid_dataloader))<br/>train_batch.keys(), valid_batch.keys()<br/><br/>code output: <br/>(dict_keys(['image', 'crs', 'bbox', 'mask']),<br/> dict_keys(['image', 'crs', 'bbox', 'mask']))</span></pre><h2 id="14b9" class="mw la it bd lb mx my dn lf mz na dp lj ma nb nc ll me nd ne ln mi nf ng lp nh bi translated">标准化和光谱指数</h2><p id="8fc8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于标准化和光谱指数，程序与第 1 部分和第 2 部分已经介绍过的相同。可视化例程也是如此。以下笔记本中的所有内容都已更新至正确的批次创建。</p><p id="686d" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">最后一个单元格显示了一个验证数据集批次的样本和带有 9 个通道(6 个通道+ 3 个索引)的验证图像的形状，如预期的那样。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/8a2d1427e08c8991537f8cd10842b87c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1FnNm1pbO9eYou6uwEhTdA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:代码输出。图片作者。</p></figure></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><h1 id="9b59" class="kz la it bd lb lc ob le lf lg oc li lj jz od ka ll kc oe kd ln kf of kg lp lq bi translated">细分模型</h1><p id="f430" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于语义分割模型，我们将使用 Pytorch 中提供的预定义架构。查看官方文档(<a class="ae ky" href="https://pytorch.org/vision/stable/models.html#semantic-segmentation" rel="noopener ugc nofollow" target="_blank">https://py torch . org/vision/stable/models . html # semantic-segmentation</a>)可能会注意到 3 种模型可用于语义分割，但其中一种(LRASPP)是针对移动应用的。在我们的教程中，我们将使用 DeepLabV3 模型。</p><p id="5113" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">所以，让我们为 2 个类创建一个 DeepLabV3 模型。在这种情况下，我将跳过预训练的权重，因为权重代表另一个域(不是多光谱影像中的水体分割)。</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="09e3" class="nm la it mq b be nn no l np nq">from torchvision.models.segmentation import deeplabv3_resnet50<br/>model = deeplabv3_resnet50(weights=None, num_classes=2)<br/><br/>model<br/><br/>code output: <br/>DeepLabV3(<br/>  (backbone): IntermediateLayerGetter(<br/>    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)<br/>    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)<br/>    (relu): ReLU(inplace=True)<br/>    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)<br/>...</span></pre><p id="4c56" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">在模型架构中，我们首先要注意的是第一次卷积(Conv2d)中预期的通道数，定义为 3。这是因为该模型已准备好处理 RGB 图像。在第一次卷积之后，3 个通道将以较低的分辨率产生 64 个通道，依此类推。由于我们现在有 9 个通道，我们将改变这个第一处理层，以正确适应我们的模型。我们可以按照命令，用新的卷积层替换第一个卷积层。最后，我们检查模拟批处理是否可以通过模型，并根据需要提供带有 2 个通道(水/无水)的输出。</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="e746" class="nm la it mq b be nn no l np nq">backbone = model.get_submodule('backbone')<br/><br/>conv = nn.modules.conv.Conv2d(<br/>    in_channels=9, <br/>    out_channels=64, <br/>    kernel_size=(7, 7),<br/>    stride=(2, 2),<br/>    padding=(3, 3),<br/>    bias=False<br/>)<br/>backbone.register_module('conv1', conv)<br/><br/>pred = model(torch.randn(3, 9, 512, 512))<br/>pred['out'].shape<br/><br/>code output: <br/>torch.Size([3, 2, 512, 512])</span></pre><p id="653c" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">我们的架构似乎在按预期工作。下一步是训练它。所以让我们为它创建一个训练循环。</p><h1 id="2921" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">训练循环</h1><p id="c700" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">训练函数应该接收历元数、模型、数据加载器、损失函数(待优化)、精度函数(评估结果)、优化器(将在正确的方向上调整模型的参数)以及要应用于每批的变换。</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="a03a" class="nm la it mq b be nn no l np nq">def train_loop(<br/>    epochs: int, <br/>    train_dl: DataLoader, <br/>    val_dl: Optional[DataLoader], <br/>    model: nn.Module, <br/>    loss_fn: Callable, <br/>    optimizer: torch.optim.Optimizer, <br/>    acc_fns: Optional[List]=None, <br/>    batch_tfms: Optional[Callable]=None<br/>):<br/>    # size = len(dataloader.dataset)<br/>    cuda_model = model.cuda()<br/><br/>    for epoch in range(epochs):<br/>        accum_loss = 0<br/>        for batch in train_dl:<br/><br/>            if batch_tfms is not None:<br/>                batch = batch_tfms(batch)<br/><br/>            X = batch['image'].cuda()<br/>            y = batch['mask'].type(torch.long).cuda()<br/>            pred = cuda_model(X)['out']<br/>            loss = loss_fn(pred, y)<br/><br/>            # BackProp<br/>            optimizer.zero_grad()<br/>            loss.backward()<br/>            optimizer.step()<br/><br/>            # update the accum loss<br/>            accum_loss += float(loss) / len(train_dl)<br/><br/>        # Testing against the validation dataset<br/>        if acc_fns is not None and val_dl is not None:<br/>            # reset the accuracies metrics<br/>            acc = [0.] * len(acc_fns)<br/><br/>            with torch.no_grad():<br/>                for batch in val_dl:<br/><br/>                    if batch_tfms is not None:<br/>                        batch = batch_tfms(batch)                    <br/><br/>                    X = batch['image'].type(torch.float32).cuda()<br/>                    y = batch['mask'].type(torch.long).cuda()<br/><br/>                    pred = cuda_model(X)['out']<br/><br/>                    for i, acc_fn in enumerate(acc_fns):<br/>                        acc[i] = float(acc[i] + acc_fn(pred, y)/len(val_dl))<br/><br/>            # at the end of the epoch, print the errors, etc.<br/>            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f} - Accs={[round(a, 3) for a in acc]}')<br/>        else:<br/><br/>            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f}')</span></pre><h1 id="3737" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">损失和精度函数</h1><p id="7146" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在调用训练函数之前，让我们创建损失函数和准确度函数。在我们的具体例子中，我们将有形状为(N，C，d1，d2)的预测，并且我们有形状为(N，1，d1，d2)的掩码。对于损失函数，通常交叉熵损失应该起作用，但是它要求掩模具有形状(N，d1，d2)。在这种情况下，我们将需要手动挤压我们的第二维。</p><p id="5741" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">此外，我们将创建两个精度函数。总精度，用于原始论文和交集并集。通常当我们在每个类中有不平衡数量像素的遮罩时，就像水遮罩的情况一样(有时我们有只有陆地和很少水体的场景)，整体精度将导致不切实际的值。在这种情况下，应该避免 OA，但它留在这里是为了与原始论文进行比较。</p><p id="d398" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">通过将所有匹配相加并除以批次中的元素数量，手动计算整体精度。IoU 也称为 Jaccard Index，在 Sklearn 包中提供。Pytorch 的交叉熵用于损失，对目标的形状做了微小的调整。经过所有必要的调整后，功能定义如下:</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="a58d" class="nm la it mq b be nn no l np nq">from sklearn.metrics import jaccard_score<br/><br/>def oa(pred, y):<br/>    flat_y = y.squeeze()<br/>    flat_pred = pred.argmax(dim=1)<br/>    acc = torch.count_nonzero(flat_y == flat_pred) / torch.numel(flat_y)<br/>    return acc<br/><br/>def iou(pred, y):<br/>    flat_y = y.cpu().numpy().squeeze()<br/>    flat_pred = pred.argmax(dim=1).detach().cpu().numpy()<br/>    return jaccard_score(flat_y.reshape(-1), flat_pred.reshape(-1), zero_division=1.)<br/><br/><br/>def loss(p, t):    <br/>    return torch.nn.functional.cross_entropy(p, t.squeeze())</span></pre><h1 id="c89b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">培养</h1><p id="1327" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">训练函数现在可以这样调用:</p><pre class="kj kk kl km gt ni mq nj bn nk nl bi"><span id="0f2a" class="nm la it mq b be nn no l np nq">optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)<br/>train_loop(5, train_dataloader, valid_dataloader, model, loss, optimizer, <br/>           acc_fns=[oa, iou], batch_tfms=tfms)<br/><br/>code output: <br/>Epoch 0: Train Loss=0.37275 - Accs=[0.921, 0.631]<br/>Epoch 1: Train Loss=0.22578 - Accs=[0.94, 0.689]<br/>Epoch 2: Train Loss=0.22280 - Accs=[0.906, 0.576]<br/>Epoch 3: Train Loss=0.19370 - Accs=[0.944, 0.706]<br/>Epoch 4: Train Loss=0.18241 - Accs=[0.92, 0.619]<br/>Epoch 5: Train Loss=0.21393 - Accs=[0.956, 0.748]</span></pre><p id="7fc6" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">从结果可以看出，损耗在下降，精度在提高。所以我们的训练正在如预期的那样进行。第一个精度是总精度，第二个是 IoU。将 10 个时期后的结果与研究论文(Luo 等人，2021 年)中测试的 DeepLabV3 的结果进行比较，我们分别得到 OA=95.6%和 OA = 95.7%(从论文中考虑的 3 个不同区域获得的平均值)。考虑到我们从任意权重开始，并且没有对超参数进行任何微调，例如正则化或学习率等。，我们可以说我们的结果非常好。将该数据集与其他水分割算法进行比较将是令人感兴趣的，例如单指标阈值化(MNDWI、AWEI 等。)不提供最佳结果，尽管它们很简单(Cordeiro 等人，2021)。</p><h1 id="4932" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">笔记本</h1><p id="c08e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这里有完整的笔记本，可以直接在 google Colab 打开。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nr ns l"/></div></figure><h1 id="b301" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="2a95" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在第 3 部分中，我们已经完成了我们的项目，提供了一个训练循环来优化 DL 模型(DeepLab V3 ),以便使用卫星图像进行水体分割。结果很有希望，但可以通过一些微调来改善。除了超参数和更多的训练之外，数据增强也可以用于提高准确性，以及不同的架构，如 U-Net。直观地检查输出的质量，了解模型在哪里表现良好，在哪里没有达到目标，这也是很有趣的。这些话题并没有包含在这个故事中，但是如果你想看到更多这样的故事，不要犹豫，在评论中留下你的要求(和想法)。</p><h1 id="798f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">保持联系</h1><p id="5d49" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="og">如果你喜欢这篇文章，想支持我当作家，可以考虑成为</em> <a class="ae ky" href="https://cordmaur.medium.com/membership" rel="noopener"> <em class="og">中等会员</em> </a> <em class="og">。每月只需 5 美元，我会从你的会员费中收取一小笔佣金，不需要你额外付费。或者你可以随时给我买杯咖啡。</em></p><div class="oh oi gp gr oj ok"><a href="https://cordmaur.medium.com/membership" rel="noopener follow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">通过我的推荐链接加入媒体-毛里西奥·科代罗</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">阅读毛里西奥·科代罗的每一个故事(以及媒体上成千上万的其他作家)。您的会员费直接…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">cordmaur.medium.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><h1 id="8430" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">以前的零件</h1><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-1-52d17e409f09"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">使用 Pytorch 的 TorchGeo 进行地理空间分析的人工智能(第 1 部分)</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">使用 Pytorch 和 TorchGeo 包的端到端深度学习地理空间分割项目</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="oz l ov ow ox ot oy ks ok"/></div></div></a></div><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/artificial-intelligence-for-geospatial-analysis-with-pytorchs-torchgeo-part-2-ec3785fae284"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">使用 Pytorch 的 TorchGeo 进行地理空间分析的人工智能(第 2 部分)</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">使用 Pytorch 和 TorchGeo 包的端到端深度学习地理空间分割项目</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="pa l ov ow ox ot oy ks ok"/></div></div></a></div><h1 id="a097" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考资料:</h1><p id="9eba" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Cordeiro，M.C.R .，Martinez，j-m .，pea-Luque，s .，2021。Sentinel-2 图像多维分级聚类的自动水探测和与水平 2A 处理器的比较。环境遥感 253，112209。<a class="ae ky" href="https://doi.org/10.1016/j.rse.2020.112209" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.rse.2020.112209</a></p><p id="c3da" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mt mc md me mu mg mh mi mv mk ml mm im bi translated">罗，童小华，胡。基于多光谱图像的地表水体自动制图方法。国际应用地球观测和地理信息杂志，2021，103，102472。【<a class="ae ky" href="https://www.sciencedirect.com/science/article/pii/S0303243421001793" rel="noopener ugc nofollow" target="_blank">链接</a></p></div></div>    
</body>
</html>