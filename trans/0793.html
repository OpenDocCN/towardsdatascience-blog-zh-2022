<html>
<head>
<title>Creating Regression Models to Predict Data Responses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">创建回归模型以预测数据响应</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-regression-models-to-predict-data-responses-120b0e3f6e90#2022-03-05">https://towardsdatascience.com/creating-regression-models-to-predict-data-responses-120b0e3f6e90#2022-03-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3787" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习从头开始创建和编写回归模型，以预测结果</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bab2723f11830fdd45be088692c4d920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wn-eZop6eK1L3yWL"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">凯利·西克玛在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="bcdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回归分析可以描述为一种统计技术，用于在给定一个或多个自变量(预测因子或特征)值的情况下，预测/预报因变量(响应)的值。回归被认为是监督机器学习的一种形式；这是一种建立数学模型以确定输入和期望输出之间关系的算法。可以生成的回归模型数不胜数，所以让我们先介绍一下回归数学，然后跳到三个常见的模型。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="ee5e" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">回归数学</h2><p id="f806" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在我们看任何代码之前，我们应该了解一点回归模型背后的数学。如前所述，回归模型可以有多个输入变量或特征，但是对于本文，为了简单起见，我们将使用单个特征。回归分析包括猜测哪种类型的函数最适合您的数据集，是直线函数、n 次多项式函数还是对数函数等。回归模型假设数据集遵循以下形式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/9877e95a21cd4a156da7c57714150711.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/1*jAW2V3KLppnhQWmlDL6LHg.gif"/></div></figure><p id="0aa3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，<em class="nb"> x </em>和<em class="nb"> y </em>是我们在观察点<em class="nb"> i </em>的特征和响应，<em class="nb"> e </em>是误差项。回归模型的目标是估计函数<em class="nb"> f </em>，使其最接近数据集(忽略误差项)。函数<em class="nb"> f </em>是我们对哪种类型的函数最适合数据集的猜测。当我们看到例子时，这将变得更加清楚。为了估计函数，我们需要估计<em class="nb"> β </em>系数。最常见的方法是普通最小二乘法，它可以最小化数据集和函数之间的误差平方和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d1241ef718ca6b084951021dd454e55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/1*JuCwe88wUdEGQLjTCngRIQ.gif"/></div></figure><p id="9acd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最小化平方误差将导致我们的<em class="nb"> β </em>系数的估计，标记为<em class="nb"> β </em> -hat。可以使用由普通最小二乘法得出的正规方程来获得估计值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d9b64d7aad2b1ecd18245716a35d2bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/1*6XDGqYxdFZKGTD8byn_RVw.gif"/></div></figure><p id="d129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">反过来，我们可以使用这些估计的<em class="nb"> β </em>系数来创建我们的响应变量<em class="nb"> y </em>的估计值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/f69937485d761f56c2b3441bbfe375b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:192/1*M-eK1a6DT4O6XbVIdynMIw.gif"/></div></figure><p id="cd73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的<em class="nb"> y </em> -hat 值是一个观察值<em class="nb"> i </em>的预测值。通过使用我们估计的<em class="nb"> β </em>系数和特征值<em class="nb"> x </em>来生成预测。</p><p id="e557" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确定我们的回归模型表现如何，我们可以计算 R 平方系数。此系数评估回归模型预测周围数据集的分散程度。换句话说，这是回归模型与原始数据集的拟合程度。通常，该值越接近 1.0，拟合度越好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/77ebefba24b7a742dc28f7ea95a548ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/1*CuvEeEhM8dB-GhxF1eesRg.gif"/></div></figure><p id="dec0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了正确评估您的回归模型，您应该比较多个模型(函数，<em class="nb"> f </em>)的 R 平方值，然后决定使用哪个模型来预测未来值。让我们开始编码，以便更好地理解回归模型的概念。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="38ea" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">导入库</h2><p id="8ced" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">对于这些示例，我们将需要以下库和包:</p><ul class=""><li id="4b94" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><em class="nb"> NumPy </em>用于创建数值数组(为方便调用，定义为<em class="nb"> np </em></li><li id="eb34" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated"><em class="nb"> NumPy </em>中的<em class="nb"> random </em>用于在函数中创建噪声，以模拟真实世界的数据集</li><li id="ba15" class="ng nh it lb b lc np lf nq li nr lm ns lq nt lu nl nm nn no bi translated">来自<em class="nb"> matplotlib </em>的<em class="nb"> pyplot </em>用于显示我们的数据和趋势线</li></ul><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="c42a" class="mc md it nv b gy nz oa l ob oc"># Importing Libraries and Packages<br/>import numpy as np<br/>from numpy import random<br/>import matplotlib.pyplot as plt</span></pre><h2 id="cf49" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">创建和显示测试数据集</h2><p id="4c11" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">为了创建数据集，我们可以创建一个作为我们的特征的<code class="fe od oe of nv b">x</code>数组和一个作为我们的响应的<code class="fe od oe of nv b">y</code>数组。<code class="fe od oe of nv b">y</code>数组是一个任意指数函数。使用<em class="nb">随机</em>包，我们将在我们的数据中引入噪声来模拟某种真实世界的数据。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="a08f" class="mc md it nv b gy nz oa l ob oc"># Creating Data<br/>x = np.linspace(0, 4, 500)  # n = 500 observations<br/>random.seed(10)  # For consistent results run-to-run<br/>noise = np.random.normal(0, 1, x.shape)<br/>y = 0.25 * np.exp(x) + noise<br/><br/># Displaying Data<br/>fig = plt.figure()<br/>plt.scatter(x, y, s=3)<br/>plt.title("Test Data")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.show()</span></pre><p id="9489" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我们应用回归分析的数据集:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/6f361d26a7d7d2d51807f846b4f9d10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*kOG0s4wawYoPHkalfGqy4g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据[由作者创建]</p></figure><p id="135f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们花点时间来看看这个情节。我们知道使用了一个指数方程来创建该数据，但是如果我们不知道该信息(如果您正在执行回归分析，您就不会知道)，我们可能会查看该数据并认为二次多项式最适合数据集。然而，作为最佳实践，您应该评估几个不同的模型，看看哪一个性能最好。然后，您将使用最佳模型来创建您的预测。现在让我们分别来看几个回归模型，看看它们的结果如何比较。</p><h2 id="c186" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">线性回归</h2><p id="d205" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">正如在数学部分提到的，对于回归分析，你猜测一个模型，或函数。对于线性模型，我们的函数采用以下形式，<em class="nb"> f </em>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/9f29cc07a1b60f4fa406924868b27d02.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/1*4Jj0cUmqXKo8H6xNXrzdRA.gif"/></div></figure><p id="584d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是为估计我们的<em class="nb"> β </em>系数的正规方程(在数学部分)创建矩阵。它们应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/3a090dde1c4d5825affd217994e5a39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/1*mgWK0_TyQZkwvbLFuCDRvQ.gif"/></div></figure><p id="160d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用我们的数据集，我们估计的<em class="nb"> β </em>系数以及线性回归模型将为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/62debc5ac7b8917a88a5edae25c5e998.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/1*aKQEpHZ_lKgFhXQuQYB13A.gif"/></div></figure><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="e0ab" class="mc md it nv b gy nz oa l ob oc"># Linear Regression<br/>X = np.array([np.ones(x.shape), x]).T<br/>X = np.reshape(X, [500, 2])<br/><br/># Normal Equation: Beta coefficient estimate<br/>b = np.linalg.inv(X.T @ X) @ X.T @ np.array(y)<br/>print(b)<br/><br/># Predicted y values and R-squared<br/>y_pred = b[0] + b[1] * x<br/>r2 = 1 - sum((y - y_pred) ** 2)/sum((y - np.mean(y)) ** 2)<br/><br/># Displaying Data<br/>fig = plt.figure()<br/>plt.scatter(x, y, s=3)<br/>plt.plot(x, y_pred, c='red')<br/>plt.title("Linear Model (R$^2$ = " + str(r2) + ")")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.legend(["Data", "Predicted"])<br/>plt.show()</span></pre><p id="cac7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">生成的回归模型如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/188993c5fa9f3299d9d2721d5f833c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*IueIbzVznl3C0w7VMnCmxQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据[由作者创建]</p></figure><p id="64a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如图的标题所示，线性回归模型的 R 平方值约为 0.75。这意味着线性模型符合数据，但如果我们收集更多的数据，我们可能会看到 R 平方的值大幅下降。</p><h2 id="8458" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">多项式回归</h2><p id="a09b" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">多项式回归的一般形式如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/2f243deed2e429c2b13d1e2718de3c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/1*bXjTgfhOEKZHzWCvGImpcg.gif"/></div></figure><p id="1976" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将函数<em class="nb"> f </em>的形式显示为二阶多项式。您可以以类似的方式添加更多的多项式项来满足您的需求；但是，要警惕过度拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d5430ae6d6ad47aa5fda3c5b2e101926.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/1*LygkbjBoY7rn1aah8BE7Eg.gif"/></div></figure><p id="2dab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建正规方程的矩阵给出如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/e907048b31ab7487e69dc8a1c7ed0c02.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/1*1z7v62cT9vCLoeU_hFOoMg.gif"/></div></figure><p id="6255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这些矩阵，估计的<em class="nb"> β </em>系数和多项式回归模型将为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3942d89e3daf3fcb7b1c0190a28e9324.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/1*ov-r97FlVpo4R0U6Q07MfQ.gif"/></div></figure><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="26b3" class="mc md it nv b gy nz oa l ob oc"># Polynomial Regression<br/>X = np.array([np.ones(x.shape), x, x ** 2]).T<br/>X = np.reshape(X, [500, 3])<br/><br/># Normal Equation: Beta coefficient estimate<br/>b = np.linalg.inv(X.T @ X) @ X.T @ np.array(y)<br/>print(b)<br/><br/># Predicted y values and R-squared<br/>y_pred = b[0] + b[1] * x + b[2] * x ** 2<br/>r2 = 1 - sum((y - y_pred) ** 2)/sum((y - np.mean(y)) ** 2)<br/><br/># Displaying Data<br/>fig = plt.figure()<br/>plt.scatter(x, y, s=3)<br/>plt.plot(x, y_pred, c='red')<br/>plt.title("2$^{nd}$ Degree Poly. Model (R$^2$ = " + str(r2) + ")")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.legend(["Data", "Predicted"])<br/>plt.show()</span></pre><p id="6c77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由此产生的情节:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7b8e8258b1d0549acc37377a6563db76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ezH2Ku3yqezFDlWD75PH8w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据[由作者创建]</p></figure><p id="e6ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，二次多项式在匹配数据集方面做得更好，其 R 平方值约为 0.91。然而，如果我们看数据集的末尾，我们会注意到模型低估了这些数据点。这应该鼓励我们研究其他模型。</p><h2 id="cc93" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">指数回归</h2><p id="3db4" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">如果我们决定不采用多项式模型，我们的下一个选择可能是以下形式的指数模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/cc36e190814016ba54d212cf4aa44e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/1*Jjj_HU1ESgV1weriW3UkYA.gif"/></div></figure><p id="28c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，创建法线方程的矩阵给出如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/6344438ee550bb84f4ff77d718f44e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/1*c6MNZVwqmASKcRqUHc54UQ.gif"/></div></figure><p id="de7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，有了估计的<em class="nb"> β </em>系数，回归模型将是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b422ecbd4f10b19934aae1303b48c495.png" data-original-src="https://miro.medium.com/v2/resize:fit:498/1*s6rqokM_Uhudfl4KMpYilA.gif"/></div></figure><p id="a203" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，指数项的领先系数与模拟数据领先系数非常匹配。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="e18b" class="mc md it nv b gy nz oa l ob oc"># Exponential Regression<br/>X = np.array([np.ones(x.shape), np.exp(x)]).T<br/>X = np.reshape(X, [500, 2])<br/><br/># Normal Equation: Beta coefficient estimate<br/>b = np.linalg.inv(X.T @ X) @ X.T @ np.array(y)<br/>print(b)<br/><br/># Predicted y values and R-squared<br/>y_pred = b[0] + b[1]*np.exp(x)<br/>r2 = 1 - sum((y - y_pred) ** 2)/sum((y - np.mean(y)) ** 2)<br/><br/># Displaying Data<br/>fig = plt.figure()<br/>plt.scatter(x, y, s=3)<br/>plt.plot(x, y_pred, c='red')<br/>plt.title("Exponential Model (R$^2$ = " + str(r2) + ")")<br/>plt.xlabel("x")<br/>plt.ylabel("y")<br/>plt.legend(["Data", "Predicted"])<br/>plt.show()</span></pre><p id="c21b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最终的数字:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/8f083c2796b6520a03c4f34cef970d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*v2N7clreOwm39UAFQjeiSA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据[由作者创建]</p></figure><p id="d1f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，与二次多项式模型相比，R 平方值有所提高。更有希望的是，数据集的末端比二次多项式更适合此模型。给定这些信息，我们应该使用指数模型来预测未来的<em class="nb"> y </em>值，以获得尽可能精确的结果。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="24be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文章到此结束。希望这能让您了解如何在 Python 中执行回归分析，以及如何在现实场景中正确使用它。如果你学到了什么，给我一个关注，看看我关于空间、数学和 Python 的其他文章！谢谢大家！</p></div></div>    
</body>
</html>