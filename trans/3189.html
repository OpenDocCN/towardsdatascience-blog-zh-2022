<html>
<head>
<title>Feature Selection: Choosing the Right Features for Your Machine Learning Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征选择:为你的机器学习算法选择正确的特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-selection-choosing-the-right-features-for-your-machine-learning-algorithm-379bda9f3e05#2022-07-13">https://towardsdatascience.com/feature-selection-choosing-the-right-features-for-your-machine-learning-algorithm-379bda9f3e05#2022-07-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="072d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">有时候，少即是多</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c0e593edc50f6a77c2a57dccb188554e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9q9Wr6rz5Li6IZcgLD7_Ig.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">选择，还是不选择…照片由<a class="ae ky" href="https://unsplash.com/@edgr?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">edu·格兰德</a>在<a class="ae ky" href="https://unsplash.com/s/photos/selection?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="9b61" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">为什么我们要选择一些特征而忽略其余的呢？拥有更多的特征不是对我们模型的准确性有好处吗？</h2><p id="5236" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">选择正确的特征，忽略不合适的特征，是任何机器学习项目中至关重要的一步。这可以产生良好的模型性能，并节省您的时间。它还可以帮助您更容易地解释模型的输出。但是拥有更多的特征将意味着模型有更多的数据来训练，并且应该意味着模型将更加准确，对吗？不完全是。</p><p id="32b2" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">拥有太多的特征会导致算法容易陷入<strong class="lx iu">过度拟合。</strong>过度拟合是指模型推广到不相关的数据或异常值。另一个仔细选择特性的好理由是所谓的维度诅咒。通常每个特征都存储在一个维度中。<strong class="lx iu"> </strong>算法在高维情况下变得更难设计，因为运行时间往往随着维数呈指数增长。因此，当我们选择最合适的特征而忽略其他特征时，这是有意义的，并且提供了好处。</p><h1 id="f978" class="mt la it bd lb mu mv mw le mx my mz lh jz na ka ll kc nb kd lp kf nc kg lt nd bi translated">我们如何选择最佳特征进行训练？</h1><p id="b68d" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">有两种选择特征的方法。首先，人们可以通过直方图等用图形表示来人工观察特征。第二种方式是通过自动选择最佳特征。</p><h2 id="f2b9" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">手动做事…</h2><p id="4e10" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我们可以通过直方图等图形表示来手动观察特征。然后，通过识别可以相互区分的特征和相互重叠的特征，我们可以决定哪一个将是最好的。让我们看一个例子。</p><p id="eddf" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们将看看<a class="ae ky" href="https://www.kaggle.com/datasets/uciml/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>。它有150朵鸢尾花的数据，包括3个品种(鸢尾、海滨鸢尾和杂色鸢尾)。花的四个特征在数据集中可用(花的萼片和花瓣的宽度和长度)。数据集的摘录如下所示。</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="bfe3" class="kz la it nf b gy nj nk l nl nm">Here, you can see the <strong class="nf iu">four available features </strong>in the iris dataset for the iris flower species known as Setosa. <br/>(the first 5 rows of the dataset are shown)</span><span id="83da" class="kz la it nf b gy nn nk l nl nm">  <strong class="nf iu">Sepal.Length  Sepal.Width  Petal.Length  Petal.Width   </strong>Species <br/>1          5.1          3.5           1.4          0.2    setosa<br/>2          4.9          3.0           1.4          0.2    setosa<br/>3          4.7          3.2           1.3          0.2    setosa<br/>4          4.6          3.1           1.5          0.2    setosa<br/>5          5.0          3.6           1.4          0.2    setosa</span><span id="9e04" class="kz la it nf b gy nn nk l nl nm">Note: When we set <strong class="nf iu">dim = 0</strong> in the below code, we are selecting the feature: <strong class="nf iu">Sepal.Length</strong></span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="no np l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码加载虹膜数据集和绘制直方图的基础上，我们想要的功能。</p></figure><p id="696d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">使用上面的代码，我们为虹膜数据集的三个种类中的每一个绘制了直方图，为使用变量'<strong class="lx iu"> dim' </strong>选择的特定特征绘制了直方图。</p><p id="aed5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们可以使用<strong class="lx iu"> 'iris.target' </strong>来选择特定的物种，例如，在上面的代码中:<strong class="lx iu"> iris.data[iris.target == 0，dim] </strong>给出了鸢尾物种<strong class="lx iu">和</strong>的数据特征:萼片长度。</p><p id="0ff9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">通过查看生成的直方图，我们意识到特征重叠。这意味着我们选择的特征(萼片长度)，由<strong class="lx iu"> dim = 0 </strong>给出，可能不足以区分不同类型的鸢尾花(Setosa，Versicolor和Virginica)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/77ebbb70ed2462d82c98c6552739a3a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*r4WOWP2cLcTALD-P6kFsMQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">上面代码的结果，功能是重叠的。</p></figure><p id="ea75" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">现在，让我们选择一个不同的特性。我们将使用<strong class="lx iu"> dim=3 </strong>选择特征4(花瓣宽度)。下图显示了生成的直方图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0581c0fbe2373a489e5ebd3e08a0b847.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*_ePHQEd0IZO-KXPDWRlAcw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从上面的代码中获得的特性3的直方图。</p></figure><p id="e613" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">如你所见，与我们观察到的另一个特征相比，这个特征在三种类型的花之间提供了足够好的分离。以这种方式观察直方图可以帮助我们对正在处理的数据获得更好的感觉或直觉，并识别合适的特征以及不太有用的特征。</p><p id="b32e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">当我们处理更多的功能时，手工的方法可能不合适。在这种情况下，我们可以利用自动特征选择方法。</p><p id="c3f4" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="ns">注意:在我们使用的数据集中，长度用于特征。每个要素都有相同的单位(厘米)。但是一些数据集可能具有互不相同的要素。例如，一个要素可能以米为单位，而另一个要素可能是颜色。这可以引入它自己的一套复杂功能，我们将需要</em> <strong class="lx iu"> <em class="ns">标度</em> </strong> <em class="ns">特性，这些我们将在本文的最后讨论。</em></p><h2 id="a243" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">自动特征选择</h2><p id="7d53" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">特征选择的一般程序是:</p><ul class=""><li id="0b94" class="nt nu it lx b ly mo mb mp li nv lm nw lq nx mn ny nz oa ob bi translated">通过与地面实况进行比较或通过比较每个要素的类之间的方差来计算每个要素的质量。</li><li id="4903" class="nt nu it lx b ly oc mb od li oe lm of lq og mn ny nz oa ob bi translated">接下来，根据计算出的质量对特征进行排序，只保留最好的。可以通过使用质量阈值或者通过简单地选择最佳<em class="ns"> n </em>个特征来选择最佳特征。</li></ul><p id="ecf8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">为了选择特征子集，我们可以执行<strong class="lx iu"> <em class="ns">正向特征选择、</em> </strong>逐步添加最佳尺寸或特征，或者执行<strong class="lx iu"> <em class="ns">反向特征选择、</em> </strong>从所有特征开始，继续删除质量最差的特征。</p><p id="8e5c" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">我们如何计算一个特性的<em class="ns">质量</em>？</strong></p><p id="92a3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们要看的第一个质量指数叫做<em class="ns">相关系数</em>(又名<em class="ns">皮尔逊相关</em>)。相关系数是两个变量之间的<strong class="lx iu">协方差</strong>和<strong class="lx iu">标准差</strong>之比。作为比值的结果，我们得到一个介于-1和1之间的结果。</p><p id="03cc" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="ns">什么是</em> <strong class="lx iu"> <em class="ns">协方差</em> </strong> <em class="ns">？</em></p><blockquote class="oh oi oj"><p id="3552" class="lv lw ns lx b ly mo ju ma mb mp jx md ok mq mf mg ol mr mi mj om ms ml mm mn im bi translated">如果一个变量的较大值主要与另一个变量的较大值相对应，并且较小值也是如此(即变量往往表现出相似的行为)，则协方差为正。</p><p id="acdb" class="lv lw ns lx b ly mo ju ma mb mp jx md ok mq mf mg ol mr mi mj om ms ml mm mn im bi translated">在相反的情况下，当一个变量的较大值主要对应于另一个变量的较小值时，协方差为负。</p><p id="31c8" class="lv lw ns lx b ly mo ju ma mb mp jx md ok mq mf mg ol mr mi mj om ms ml mm mn im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Eric_W._Weisstein" rel="noopener ugc nofollow" target="_blank">——魏斯斯坦，埃里克W. </a> <a class="ae ky" href="https://mathworld.wolfram.com/Covariance.html" rel="noopener ugc nofollow" target="_blank">【协方差】</a>。<a class="ae ky" href="https://en.wikipedia.org/wiki/MathWorld" rel="noopener ugc nofollow" target="_blank"> <em class="it">数学世界</em> </a>。</p></blockquote><p id="07f5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这一点通过观察下图可以看得很清楚。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/393d4d737149674d5812e4c7204e4226.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*8jws5-3rAmaRyNyN01MzDg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Covariance" rel="noopener ugc nofollow" target="_blank">两个随机变量的协方差的符号<em class="oo"> X </em>和<em class="oo">Y</em>T29】</a></p></figure><p id="cd1c" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">协方差可通过以下等式计算，其中x̄和ȳ分别代表x和y的平均值:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/0cf1d247e2771e489ee92303d66a91d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*-ygvCd43psJPIa96m3B3-g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算协方差的方程。来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Covariance" rel="noopener ugc nofollow" target="_blank">协方差</a></p></figure><p id="dc1d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">因此，相关系数可以计算如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/1173322d5237f09c743b5d24216ee3a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*SkpdLmY6z6HYpR3qvpp4rQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算<a class="ae ky" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">相关系数</a>的方程式</p></figure><p id="77b9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">如果这两个特征是随机独立的，它们的相关性将为0。然而，请记住，即使相关性为0，也不一定意味着变量是独立的。可能存在相关性未捕捉到的潜在依赖关系。</p><p id="53d6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">还要注意，相关性并不意味着因果关系。看下面的图表。由于两起事件相似，关联度极高。但这是否意味着如果你吃了更多的奶酪，你很可能会被你的床单勒死？这里的数据纯属巧合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/0c47dabd2b76b91e31ac3a11165c295f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9gsV2GMkUzncyrVH.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.freecodecamp.org/news/why-correlation-does-not-imply-causation-the-meaning-of-this-common-saying-in-statistics/" rel="noopener ugc nofollow" target="_blank">食用奶酪与床单纠缠致死之间的关系。</a>作者:<a class="ae ky" href="http://tylervigen.com/spurious-correlations" rel="noopener ugc nofollow" target="_blank">泰勒·维根</a></p></figure><p id="c443" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">特征选择相关性的缺点:</strong></p><ul class=""><li id="7a61" class="nt nu it lx b ly mo mb mp li nv lm nw lq nx mn ny nz oa ob bi translated">相关性只查找线性关系</li><li id="b78b" class="nt nu it lx b ly oc mb od li oe lm of lq og mn ny nz oa ob bi translated">这也只适用于两个类的问题</li></ul><p id="e9b3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">另一个可以使用的质量指标是<em class="ns">费希尔比率</em>。它测量变量的线性辨别能力，并具有以下公式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/affedec117a230d39d84b92ce624fe20.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*Ulp7tv7sWOEETsP4IDKyDw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="http://www.statistics4u.com/fundstat_eng/cc_fisher_ratio.html#:~:text=Fisher's%20ratio%20is%20a%20measure,and%20v2%20the%20variances." rel="noopener ugc nofollow" target="_blank">计算费雪比的方程式。</a></p></figure><p id="d217" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这里，x̄和ȳ分别代表第1类和第2类的平均值，两类的方差以分母表示。这种方法的好处是，它为更复杂的标准提供了更快的计算速度。</p><p id="aee0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">还有许多其他可用的质量测量工具，如Kullback-Leibler散度、ANOVA等，这里不做讨论。</p><h1 id="5a7d" class="mt la it bd lb mu mv mw le mx my mz lh jz na ka ll kc nb kd lp kf nc kg lt nd bi translated">特征选择可能存在的问题</h1><p id="1831" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">尽管大多数算法相对简单和容易，但它们并不总是适用的。当试图确定使用哪种质量度量时，以及当试图在单个维度不产生任何结果的情况下初始化贪婪算法时，会出现困难。</p><p id="4a29" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">此外，即使特性被看作是独立的，相互独立的，它们也常常相互依赖。结果，基于质量测量的特征选择将永远不会提供当两个特征被组合时可以观察到的相同信息。因此，利用不同维度之间共享的信息是有好处的。这可以通过变换特征空间(也称为压缩)来实现。为了实现这一点，可以使用<em class="ns">主成分分析(PCA) </em>。我们将在另一篇文章中讨论PCA。</p><h1 id="b8bc" class="mt la it bd lb mu mv mw le mx my mz lh jz na ka ll kc nb kd lp kf nc kg lt nd bi translated">具有非常不同的特征的问题</h1><p id="81e7" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">上面，我们讨论了拥有彼此不同的特性会带来问题。例如，一个特征的长度以厘米为单位，另一个特征是颜色。为了减轻这种情况，我们可以使用特征缩放。</p><h2 id="1406" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">缩放比例</h2><ul class=""><li id="a5b6" class="nt nu it lx b ly lz mb mc li ot lm ou lq ov mn ny nz oa ob bi translated">在Iris和Digits数据集中，所有要素的比例相等(单位为厘米)</li><li id="128b" class="nt nu it lx b ly oc mb od li oe lm of lq og mn ny nz oa ob bi translated">如果不是这样，单个特征可能会使结果产生偏差。</li><li id="1187" class="nt nu it lx b ly oc mb od li oe lm of lq og mn ny nz oa ob bi translated">例如，具有高方差的特征支配距离测量。</li></ul><h2 id="745a" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">解决方案:</h2><ul class=""><li id="35bf" class="nt nu it lx b ly lz mb mc li ot lm ou lq ov mn ny nz oa ob bi translated">将要素缩放至平均值为0，方差为1</li></ul><p id="872e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">如果已知总体平均值和总体标准偏差，则通过以下公式将原始分数<em class="ns"> x </em>转换为标准分数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/4be6d1dc49d60468b0204bb8735f1070.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*aggt80D_wZdsa8l0-TxX1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Standard_score" rel="noopener ugc nofollow" target="_blank">用方程式计算标准分数。</a></p></figure><p id="0fbc" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">其中:<em class="ns"> μ </em>为总体的<a class="ae ky" href="https://en.wikipedia.org/wiki/Mean" rel="noopener ugc nofollow" target="_blank">均值</a>，<em class="ns"> σ </em>为总体的<a class="ae ky" href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener ugc nofollow" target="_blank">标准差</a>。</p><h1 id="fb98" class="mt la it bd lb mu mv mw le mx my mz lh jz na ka ll kc nb kd lp kf nc kg lt nd bi translated">结论</h1><p id="abd6" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">拥有大量特征会在训练机器学习模型时引入复杂性，例如使算法易于过度拟合并增加训练次数。因此，选择运行良好的特性，忽略不能提供足够好处的特性是非常重要的。这可以通过可视化数据并观察要素如何相互作用来手动完成。此外，当可用的特征太大时，可以使用自动技术来完成。这两种方法都有好处和优点，选择合适的方法取决于手头的问题。</p></div></div>    
</body>
</html>