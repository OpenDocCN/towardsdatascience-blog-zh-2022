<html>
<head>
<title>Classifying Music Genres with LightGBM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LightGBM对音乐流派进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-music-genres-with-lightgbm-17662035cf4e#2022-06-28">https://towardsdatascience.com/classifying-music-genres-with-lightgbm-17662035cf4e#2022-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d1a8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Optuna超参数优化和降维</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/4649c73fd3a7fb8b0736c68aa898c308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*74iRQr3c1-zBnN3QVYIGkQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://www.pexels.com/@tima-miroshnichenko/" rel="noopener ugc nofollow" target="_blank">马体·米罗什尼琴科</a>从<a class="ae kv" href="https://www.pexels.com/photo/a-man-and-woman-browsing-through-vinyl-music-records-6827191/" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄</p></figure><p id="4a63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated">他的文章概述了使用tuned LightGBM模型根据歌曲的音频和歌词特征将歌曲分类的过程。它从一个<a class="ae kv" href="https://www.kaggle.com/datasets/imuhammad/audio-features-and-lyrics-of-spotify-songs" rel="noopener ugc nofollow" target="_blank"> Kaggle音乐数据集</a>中提取公开的音乐数据(通过Spotify API和一个授权开发者账户提取)。LightGBM是一个基于决策树算法的梯度推进框架，被认为是当今可用的最佳开箱即用模型之一。它带有大量的<a class="ae kv" href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html" rel="noopener ugc nofollow" target="_blank">可调参数</a>，我们将尝试使用超参数优化框架<a class="ae kv" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank"> Optuna </a>对其进行优化。</p><p id="8a5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">文章大纲如下:</strong></p><ul class=""><li id="0313" class="mb mc iq ky b kz la lc ld lf md lj me ln mf lr mg mh mi mj bi translated">数据概述和预处理</li><li id="99b4" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">探索性分析</li><li id="9a38" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">歌词特征的探索性降维</li><li id="f138" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">建模和超参数优化</li><li id="1d81" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">结果</li><li id="2789" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">带回家的点数</li></ul></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="1b38" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">数据概述和预处理</h1><p id="0129" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">Kaggle数据集包含超过18，000首歌曲的信息，以及关于其音频特征的信息(例如，它有多活跃或充满语音，或者它以什么速度或基调播放等。)，以及歌曲的歌词。在<a class="ae kv" href="https://www.kaggle.com/datasets/imuhammad/audio-features-and-lyrics-of-spotify-songs" rel="noopener ugc nofollow" target="_blank">地图</a>上可以看到更详细的可用列概览。</p><p id="33de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在最初的形式下，数据有点难以处理，所以在使用之前需要一些过滤和整理。可以在<a class="ae kv" href="https://github.com/louismagowan/lgbm-music_classifier/blob/master/prep_kaggle_data.py" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中查看所采取的预处理步骤的完整概要。<code class="fe nt nu nv nw b">prep_kaggle_data.py</code>脚本可用于处理来自Kaggle的数据，或者，处理后的数据也可作为repo中的压缩CSV文件。</p><p id="2f1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预处理步骤是这个项目中最不有趣的部分，所以我们将在总结中忽略它们:</p><ol class=""><li id="77f6" class="mb mc iq ky b kz la lc ld lf md lj me ln mf lr nx mh mi mj bi translated">过滤数据，只包括英语歌曲，并删除“拉丁”风格的歌曲(因为这些歌曲几乎全部是西班牙语，所以会造成严重的类别不平衡)。</li><li id="e869" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated">整理歌词，使它们小写，删除标点符号和停用词。统计剩余单词在歌曲歌词中出现的次数，然后过滤掉所有歌曲中出现频率最低的单词(杂乱数据/噪音)。</li><li id="e96c" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated">转换剩余的单词计数，使每首歌曲都包含计算某个单词在该歌曲的歌词中出现的次数的列。</li></ol></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="a12f" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">探索性分析</h1><p id="0ad4" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">本节和下一节的所有代码都可以在repo中的eda.ipynb笔记本中找到。</p><p id="c605" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们检查一下标签(流派)的<strong class="ky ir">等级平衡</strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/4a2b0356edff6223aadffb0d4c24b8d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jTOR4eU0_BKE2rR9P3N0Iw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0fa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">似乎有一点<strong class="ky ir"><em class="nz"/></strong>的类不平衡，所以交叉验证和训练测试拆分大概应该是<strong class="ky ir"> <em class="nz">分层</em> </strong>。</p><p id="ead4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">音频和歌词特征的<strong class="ky ir"> <em class="nz">稀疏性</em> </strong>呢？下面的数据框架显示了它们各自的百分比稀疏度。<strong class="ky ir">相比之下，<strong class="ky ir"> <em class="nz">的抒情特色却极其稀疏</em> </strong>。这是有意义的，因为歌词中的大多数非停用词不会在不同的歌曲中一致出现。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/a1a491f485550cfab3f34e93123c560a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*KBBIO7Q0XI1U_VKcMUzWAw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><blockquote class="ob"><p id="8dc7" class="oc od iq bd oe of og oh oi oj ok lr dk translated">歌词特征的稀疏性可以很好地表明它们非常适合于降维。</p></blockquote></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="a331" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">歌词特征的探索性降维</h1><p id="02d3" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">如果许多机器学习算法处理具有大量特征(维度)的数据，它们的性能会更差。如果这些特征中的许多非常稀疏，情况尤其如此。这就是降维有用的地方。</p><blockquote class="ol om on"><p id="50dd" class="kw kx nz ky b kz la jr lb lc ld ju le oo lg lh li op lk ll lm oq lo lp lq lr ij bi translated">其思想是将高维数据投影到低维子空间中，同时尽可能多地保留数据中存在的差异。</p></blockquote><p id="f3e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将首先使用两种方法(主成分分析和t-SNE)来探索对我们的歌词数据使用降维是否合适，以及获得降维的良好范围的早期指示。建模过程中使用的实际降维将略有不同(用户选择截断SVD、PCA和Keras autoencoder)，我们将在后面看到。</p><h2 id="a996" class="or mx iq bd my os ot dn nc ou ov dp ng lf ow ox ni lj oy oz nk ln pa pb nm pc bi translated">主成分分析</h2><p id="ba02" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">一种常用的降维方法是主成分分析或PCA(关于它的很好的入门可以在<a class="ae kv" href="https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/" rel="noopener ugc nofollow" target="_blank">这里</a>找到)。我们可以用它来看看，相对于我们减少的维数，我们可以解释歌词列中的多少变化。例如，我们可以看到，通过<strong class="ky ir"> <em class="nz">将歌词缩减到大约400维</em> </strong>(在这种情况下是主分量)我们仍然<strong class="ky ir"> <em class="nz">保留了歌词</em> </strong>中60%的方差。大约800个维度，我们可以覆盖80%的差异。减少维度的另一个好处是，它消除了歌词特征的稀疏性，使它们更容易建模。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/8575a3b205e47f735be27f8338706cbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ey7kaodjDfBWuHaUvSu-0Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d812" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的图和PCA的代码可以在下面找到。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><h2 id="97f6" class="or mx iq bd my os ot dn nc ou ov dp ng lf ow ox ni lj oy oz nk ln pa pb nm pc bi translated">SNE视觉化</h2><p id="521c" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">我们还可以更进一步，想象我们的数据在一系列维度缩减中是如何分离的。t-SNE算法可以用于进一步将我们的歌词主成分减少到二维，即人脑可以感知的图形。想了解更多关于t-SNE的信息，这里有一篇好文章。本质上，该图向我们展示了当我们使用例如所有1806个特征，或者将其缩减为1000、500、100个主分量等时，如果将其投影到2-D空间，我们的歌词数据将会是什么样子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/80be7de2dc77dc17fb45473926faed3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vK0JuKWWLSf0u7zyuv3OjA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0b9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理想情况下，我们希望看到在某个特定的缩减维数(例如截止值= 1000)时，类型变得更加可分。</p><p id="d029" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，根据t-SNE图的结果，似乎任何特定数量的维度/主成分都不会产生更容易分离的数据。所有的体裁在抒情特征上似乎都相当混杂。<em class="nz">因此，对所有类型进行准确分类可能很困难</em>。</p><p id="a7dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">t-SNE图的代码如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="f2a8" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">建模和超参数优化</h1><p id="5d8c" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">我们可以使用下面的代码得到最终形式的数据。我们这样做，以便我们可以很容易地改变我们想要在歌词特征上使用的降维方法，以及要降维的维数。我们将在一系列输出维度上试验PCA、截断SVD和Keras欠完整自动编码器。</p><p id="18bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了简洁起见，省略了自动编码器的代码，但是可以在<a class="ae kv" href="https://github.com/louismagowan/lgbm-music_classifier/blob/master/custom_functions.py" rel="noopener ugc nofollow" target="_blank"> repo </a>的<code class="fe nt nu nv nw b">custom_functions.py</code>文件中的<code class="fe nt nu nv nw b">autoencode</code>函数中找到。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><p id="dcd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在<strong class="ky ir"> <em class="nz">我们已经按照我们想要的方式对数据进行了标准化、转换和简化</em> </strong>，我们可以开始用它建模了。</p><h2 id="87b5" class="or mx iq bd my os ot dn nc ou ov dp ng lf ow ox ni lj oy oz nk ln pa pb nm pc bi translated">构建模型</h2><p id="8772" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">首先，让我们<strong class="ky ir"> <em class="nz">定义一个评估指标</em> </strong>来评估我们的模型的性能并进行优化。由于我们数据中的流派/类别略有不平衡，宏F1分数<strong class="ky ir"><em class="nz"/></strong>可能是一个很好的选择，因为它平等地评估了类别的贡献。下面定义了它，以及一些我们将应用于所有LightGBM模型的固定参数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><p id="cf0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们必须<strong class="ky ir"> <em class="nz">为Optuna定义一个目标函数</em> </strong>进行优化。这是一个返回性能指标的函数，在我们的例子中，这将是一个分层的5重交叉验证，超级法拉利(jk jk，但它肯定是一个拗口的)，宏观F1分数。</p><p id="3c98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">LightGBM带有大量可调参数，所以这段代码中有很多内容。如果你想了解更多关于他们的信息，那么<a class="ae kv" href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html" rel="noopener ugc nofollow" target="_blank">文档</a>很好，还有<a class="ae kv" rel="noopener" target="_blank" href="/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5">这篇</a>和<a class="ae kv" rel="noopener" target="_blank" href="/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997">这篇</a>文章。</p><blockquote class="ol om on"><p id="536b" class="kw kx nz ky b kz la jr lb lc ld ju le oo lg lh li op lk ll lm oq lo lp lq lr ij bi translated">然而，关键的一点是，在<code class="fe nt nu nv nw b">param</code>论证中，我们<strong class="ky ir">定义了一个可能的超参数的搜索空间</strong>(最初是一个相当广泛的搜索空间)，Optuna将用它来测试我们的模型。</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><h2 id="279e" class="or mx iq bd my os ot dn nc ou ov dp ng lf ow ox ni lj oy oz nk ln pa pb nm pc bi translated">超参数优化</h2><p id="f663" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">现在我们有了目标函数，我们可以使用Optuna来调整模型的超参数。</p><p id="2a0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们<strong class="ky ir"> <em class="nz">创建一个“研究”，用不同的超参数值运行我们的目标函数</em> </strong>，模型的每次运行被称为“试验”该研究记录了特定试验中使用的超参数值/组合，以及该试验中模型的表现(根据5倍分层CV宏F1)。</p><p id="9608" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以<strong class="ky ir"> <em class="nz">为研究</em> </strong>分配一个修剪程序，以减少训练次数。如果很早就清楚当前选择的超参数将导致较差的性能，则<code class="fe nt nu nv nw b">HyperbandPruner</code>将提前结束或“修剪”试验。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><p id="d182" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以使用<a class="ae kv" href="https://optuna.readthedocs.io/en/stable/reference/visualization/index.html" rel="noopener ugc nofollow" target="_blank"> Optuna的可视化模块</a>来<strong class="ky ir"> <em class="nz">可视化不同超参数组合</em> </strong>的性能。例如，我们可以使用<code class="fe nt nu nv nw b">plot_param_importances(study)</code>来查看哪些超参数对模型性能最重要/对优化影响最大。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pg pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分类的图表</p></figure><p id="dc99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以使用<code class="fe nt nu nv nw b">plot_parallel_coordinate(study)</code>来查看尝试了哪些超参数组合/范围，从而产生了较高的目标值(良好的性能)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/fe1848ad98cc41037122b79978dea145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ikwiHtMNew5MgP05ZDODA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="ab7c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以使用<code class="fe nt nu nv nw b">plot_optimization_history</code>来查看最佳目标值/最强模型性能与运行的试验数量之间的关系。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pg pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按作者分类的图表</p></figure><p id="72a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">最后，我们可以这样选择</strong></p><ul class=""><li id="7f43" class="mb mc iq ky b kz la lc ld lf md lj me ln mf lr mg mh mi mj bi translated">使用研究确定的最佳超参数运行我们的最终模型。最佳超参数存储在<code class="fe nt nu nv nw b">study.best_params</code>属性中。最终模型中的<code class="fe nt nu nv nw b">params</code>参数需要更新为<code class="fe nt nu nv nw b">params = {**fixed_params, **study.best_params}</code>，如下面的代码所示。</li><li id="6798" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">或者，运行更多轮次的超参数调整/研究，缩小搜索空间/超参数范围，以更接近之前确定的每一轮次的最佳超参数值。然后使用<code class="fe nt nu nv nw b">study.best_params</code>运行你的最终模型。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="c71f" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">结果</h1><p id="ebf0" class="pw-post-body-paragraph kw kx iq ky b kz no jr lb lc np ju le lf nq lh li lj nr ll lm ln ns lp lq lr ij bi translated">好了，现在我们有了最终的模型，让我们来评估它！我们将考察<strong class="ky ir"> <em class="nz">列车，交叉验证并测试F1成绩。</em> </strong>我们还可以将我们的结果与使用的降维方法、使用的降维数量以及我们进行研究的试验数量一起存储在一个数据框架中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd pe l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者要点</p></figure><p id="b906" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过将上述所有代码的结果保存到一个CSV中，我们可以比较一系列缩减方法、试验和缩减的维度，以查看哪一个给出了总体上最好的模型。在所试验的值中，<strong class="ky ir"> <em class="nz">具有400个缩减维度和1000次试验</em> </strong>的PCA似乎已经产生了最佳模型- <strong class="ky ir"> <em class="nz">，实现了66.48% </em>的测试宏F1分数。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/921ca75aff4ff216867799f0b7d8614c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSR9olE4OrzOdFfjj6pg3A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7d91" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以使用更小尺寸的更多值和更大量的试验，但是这很快在计算上变得昂贵(运行数小时)。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="47c9" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">带回家的点数</h1><ol class=""><li id="362c" class="mb mc iq ky b kz no lc np lf pj lj pk ln pl lr nx mh mi mj bi translated"><strong class="ky ir">预处理音乐数据，将歌词整理成列，统计歌曲中非停用词的出现次数。</strong></li><li id="aa24" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">探索性数据分析:考虑类别平衡和特征稀疏性。其他EDA也可以在</strong> <code class="fe nt nu nv nw b"><a class="ae kv" href="https://github.com/louismagowan/lgbm-music_classifier/blob/master/eda.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">eda.ipynb</strong></a></code> <strong class="ky ir">笔记本中找到。</strong></li><li id="cfcb" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">探索性地对高度稀疏的歌词特征进行降维:使用主成分分析，然后使用t-SNE，在一系列降维选项/截止点上将音乐流派可视化(投影到2-D空间)。</strong></li><li id="05ae" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">将数据分成测试集和训练集，然后使用您选择的降维方法(截断SVD、PCA或Keras欠完整编码器)对其进行处理。</strong></li><li id="28e8" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">定义您的目标函数/构建LightGBM模型。使用Optuna研究为其尝试一系列超参数值(搜索空间)。</strong></li><li id="396f" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated">* * *可选:重复5，但缩小超参数值的范围，使其更接近第一轮超参数调整研究确定的最佳值。</li><li id="c4d8" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">使用Optuna研究发现的最佳超参数值运行您的最终模型。</strong></li><li id="37f0" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr nx mh mi mj bi translated"><strong class="ky ir">在测试集上评估模型。</strong></li></ol></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="0879" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">链接</h1><ul class=""><li id="5e10" class="mb mc iq ky b kz no lc np lf pj lj pk ln pl lr mg mh mi mj bi translated">LinkedIn : <a class="ae kv" href="https://www.linkedin.com/in/louismagowan/" rel="noopener ugc nofollow" target="_blank">路易斯·马戈万</a></li><li id="5d59" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">GitHub:<a class="ae kv" href="https://github.com/louismagowan/lgbm-music_classifier" rel="noopener ugc nofollow" target="_blank">lgbm-music _ classifier</a></li></ul><h1 id="1c89" class="mw mx iq bd my mz pm nb nc nd pn nf ng jw po jx ni jz pp ka nk kc pq kd nm nn bi translated">参考</h1><ul class=""><li id="0d92" class="mb mc iq ky b kz no lc np lf pj lj pk ln pl lr mg mh mi mj bi translated">t .秋叶，s .佐野，t .柳濑，t .太田，t .，&amp; Koyama，M. (2019，7月)。Optuna:下一代超参数优化框架。在<em class="nz">第25届ACM SIGKDD知识发现国际会议论文集&amp;数据挖掘</em>(第2623–2631页)。</li><li id="fcb0" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated"><a class="ae kv" href="https://machinelearningmastery.com/autoencoder-for-classification/" rel="noopener ugc nofollow" target="_blank">自动编码器特征提取</a>，机器学习掌握</li><li id="2dda" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated">数据集:<a class="ae kv" href="https://www.kaggle.com/datasets/imuhammad/audio-features-and-lyrics-of-spotify-songs" rel="noopener ugc nofollow" target="_blank">音乐数据的Kaggle数据集</a>，Muhammad Nakhaee。最初是从Spotify API刮来的，<a class="ae kv" href="https://developer.spotify.com/policy/#iv-streaming-and-commercial-use" rel="noopener ugc nofollow" target="_blank">被授权用于非流媒体SDAs的有限商业用途</a>。</li><li id="ade6" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5">kag gler 2021年使用Optuna进行LightGBM超参数调优指南</a>，Bex T。</li><li id="022e" class="mb mc iq ky b kz mk lc ml lf mm lj mn ln mo lr mg mh mi mj bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/how-to-beat-the-heck-out-of-xgboost-with-lightgbm-comprehensive-tutorial-5eba52195997">你错过了LightGBM。它在各方面碾压XGBoost</a>，Bex T。</li></ul></div></div>    
</body>
</html>