<html>
<head>
<title>Explain Machine Learning Models using SHAP library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SHAP图书馆解释机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explain-machine-learning-models-using-shap-library-e05a1583c34f#2022-10-05">https://towardsdatascience.com/explain-machine-learning-models-using-shap-library-e05a1583c34f#2022-10-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b431" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python的Shapley附加解释可以帮助您轻松解释模型如何预测结果</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/46bcfafb6d05d5b796bb47676eef4b39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fugSRJLOV4n8SEOOI0SY4Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">萨姆·莫格达姆·卡姆西在<a class="ae ky" href="https://unsplash.com/s/photos/black-box?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="34ec" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="fe67" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">复杂的机器学习模型经常被称为“<em class="mu">黑盒</em>”。这里有一个很好的概念解释。</p><blockquote class="mv"><p id="49ff" class="mw mx it bd my mz na nb nc nd ne mt dk translated">在科学、计算和工程中，黑匣子是一种设备、系统或物体，它产生有用的信息，但不透露任何关于其内部工作的信息。对其结论的解释仍然模糊不清，或者说是“黑的”。(<a class="ae ky" href="https://www.investopedia.com/terms/b/blackbox.asp#:~:text=book%20of%20business.-,What%20Is%20a%20Black%20Box%20Model%3F,remain%20opaque%20or%20%E2%80%9Cblack.%E2%80%9D" rel="noopener ugc nofollow" target="_blank"> Investopedia </a>)</p></blockquote><p id="4362" class="pw-post-body-paragraph ly lz it ma b mb nf ju md me ng jx mg mh nh mj mk ml ni mn mo mp nj mr ms mt im bi translated">因此，简单地说，就是当你创建一个ML模型，它工作得很好，但是如果有人问你是如何得到那个答案的，你不知道如何解释。“它就这样发生了”。</p><p id="b2bc" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">然而，作为数据科学家，我们与企业和高管一起工作，他们会经常要求解释，以确保他们做出正确的决定。或者，至少，他们想知道模型在做什么，它是如何得出结论的，什么有助于理解结果。</p><p id="2282" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">在这篇文章中，我们将学习如何使用Python中的SHAP模块来使“黑盒”模型更易于解释。这不仅有利于展示数据科学领域的领域，也有利于向客户推销您的模型，方法是演示数据如何进入以及如何出来、转换为预测。</p><h1 id="c5fe" class="lg lh it bd li lj np ll lm ln nq lp lq jz nr ka ls kc ns kd lu kf nt kg lw lx bi translated">沙普利值</h1><p id="b830" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Shapley_value" rel="noopener ugc nofollow" target="_blank">沙普利价值观</a>以<em class="mu">劳埃德·沙普利</em>命名，他因此获得了2012年诺贝尔奖。这个概念是基于博弈论，提出了一个解决方案，以确定每个球员的重要性，整体合作，游戏。</p><blockquote class="mv"><p id="b332" class="mw mx it bd my mz na nb nc nd ne mt dk translated">将这个概念转用到机器学习上，我们可以<strong class="ak">说Shapley值将告诉我们每个数据点对模型决策的重要性。</strong></p></blockquote><p id="61d7" class="pw-post-body-paragraph ly lz it ma b mb nf ju md me ng jx mg mh nh mj mk ml ni mn mo mp nj mr ms mt im bi translated">打个比方，我们来想象一个银行账户，最后的余额是怎么确定的。</p><p id="2ec2" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">有些钱进来(工资、股票收益)，有些钱出去(账单、食物、交通、房租)。每一笔交易都会增加或减少最终余额，对吗？有些收入会很高，有些不会很高。同样，有些费用会很大，有些会很小…</p><p id="2947" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">月底，余额将是所有收支的总和。所以，这些数字中的每一个都像Shapley值，它们更容易告诉我们每个交易在一个月中对余额的贡献是积极的还是消极的。</p><p id="aba9" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">例如，工资支票有很大的积极影响，而租金是最大的下降影响。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/fd8f36d7167ec8c8167fe79fae7c1bb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*el-yUQ-035NOQnveSzQq8Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个值对最终结果都有积极或消极的影响。图片由作者提供。</p></figure><h1 id="21bb" class="lg lh it bd li lj np ll lm ln nq lp lq jz nr ka ls kc ns kd lu kf nt kg lw lx bi translated">如何使用SHAP模块</h1><p id="d250" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">好了，现在我们知道了什么是Shapley值，我们如何实际使用它们呢？这是我们将在序列中看到的。</p><p id="8702" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">我们将安装并导入名为<code class="fe nv nw nx ny b">shap</code>的Python模块。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="de42" class="od lh it ny b gy oe of l og oh"># Install<br/>pip install shap</span><span id="fcac" class="od lh it ny b gy oi of l og oh">#import<br/>import shap</span></pre><p id="6c33" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">我们应该为这个练习导入一些其他的需求。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="4da1" class="od lh it ny b gy oe of l og oh">import pandas as pd<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.datasets import make_classification</span></pre><p id="91b7" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">接下来，让我们创建一个用于训练目的的分类数据集，并将其分为训练集和测试集。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="bde6" class="od lh it ny b gy oe of l og oh"># Create dataset<br/>X, y = make_classification(n_samples=1000, n_features=5, n_informative=3,n_redundant=2, n_repeated=0, n_classes=2,scale=10, shuffle=True, random_state=12)</span><span id="4631" class="od lh it ny b gy oi of l og oh"># Train Test Split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)</span></pre><p id="0de2" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">好的。我们有自己的一套。现在让我们训练一个随机森林分类器。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="cadc" class="od lh it ny b gy oe of l og oh"># Model<br/>rf = RandomForestClassifier().fit(X_train, y_train)</span></pre><p id="551b" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">接下来，我们可以创建一个<code class="fe nv nw nx ny b">X_test</code>的副本，并添加一些列名，以帮助SHAP的可解释性。我们可以假设数据集中的随机数是对给定产品的测试分数。要预测的标签是二进制的(0或1)，这可能意味着0=失败，1 =通过。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="c7be" class="od lh it ny b gy oe of l og oh">X_test_df = pd.DataFrame(X_test, columns=['Test1', 'Test2', 'Test3', 'Test4', 'Test5'])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f9111d4e810f7f602736b90a45073425.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*BYlmunPYcc_r9erNJrLkJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试数据集。图片由作者提供。</p></figure><h2 id="6b5d" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">解释者和SHAP价值观</h2><p id="bf2b" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">下一步是为基于树的模型创建一个解释器。为此，我们将输入训练好的模型。在序列中，我们用最近创建的带有特性名称的测试集来计算<code class="fe nv nw nx ny b">shap_values()</code>。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="27e4" class="od lh it ny b gy oe of l og oh"># Create Tree Explainer object that can calculate shap values<br/>explainer = shap.explainers.Tree(rf)</span><span id="5f14" class="od lh it ny b gy oi of l og oh"># Calculate shap values<br/>shap_values = explainer.shap_values(X_test_df)</span></pre><p id="d44c" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">现在让我们来看看这个数据集的Shapley值。注意代码中有切片符号<code class="fe nv nw nx ny b">[1]</code>，因为<code class="fe nv nw nx ny b">.shap_values()</code>函数返回一个张量，每个类有一个数组。片<code class="fe nv nw nx ny b">[0]</code>中的一个将类0的预测视为参考，片<code class="fe nv nw nx ny b">[1]</code>将1的预测视为参考。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="3864" class="od lh it ny b gy oe of l og oh"># SHAP values for predictions with (1 = passed) as reference<br/>pd.DataFrame(shap_values[1])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/664b3f3b2d23f7ae0b23c075b06f2053.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*LbuQ8ybhLbG46c2It-f-Lw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集的Shapley值。图片由作者提供。</p></figure><p id="9c36" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">好吧，酷，但这是什么意思？这些数字中的每一个都意味着该数据点对预测结果<strong class="ma iu"> 1 </strong>的贡献有多大。因此，例如，第一行的<em class="mu">变量0 </em>贡献更多，增加了它成为1的机会，而<em class="mu">变量3 </em>具有最大的负面影响，减少了它被分类为1的机会。</p><h2 id="9f93" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">力图</h2><p id="28fc" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们可以在这个很酷的力图中直观地看到贡献。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="b6fc" class="od lh it ny b gy oe of l og oh"># Check Single Prediction</span><span id="58ff" class="od lh it ny b gy oi of l og oh"># Choose observation<br/>observation = X_test_df.loc[[0]]</span><span id="e44c" class="od lh it ny b gy oi of l og oh"># Calculate Shapley values<br/>shap_values2 = explainer.shap_values(observation)</span><span id="c0c7" class="od lh it ny b gy oi of l og oh"># Initiate Java script for plotting<br/>shap.initjs()</span><span id="4b60" class="od lh it ny b gy oi of l og oh"># Plot<br/>shap.force_plot(explainer.expected_value[1], shap_values2[1], observation)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/140dd9347081d7905cbd1d884b63dde0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ItuRTRjkZhoVCtJoJZM6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">第一个条目的预测组成。图片由作者提供。</p></figure><p id="82d0" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">让我们一点一点地理解这个图形。</p><ul class=""><li id="07c4" class="ox oy it ma b mb nk me nl mh oz ml pa mp pb mt pc pd pe pf bi translated">SHAP从一个基础值开始，即目标变量的平均值。<code class="fe nv nw nx ny b">y.mean()</code>为0.505。因此，如果类0的基值是这样，则类1的基值将是1–0.505，大约是0.495。</li><li id="0ed3" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">由此，算法计算出是什么增加或减少了类为0或1的机会。粉色使机会增加，蓝色使机会减少。</li><li id="de5b" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">测试4和5将分类推回到0类，而测试1、2和3将分类推回到1类。</li><li id="39ea" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">我们看到，在每个贡献之后，最终结果是0.48，低于0.5，因此它使该观察的预测为0类(在我们的示例中，<em class="mu">失败</em>)。</li></ul><h2 id="325f" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">决策图</h2><p id="a2b4" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">与力图类似的一个选项是决策图，它显示了算法决策的相同步骤，但以不同的可视化方式显示。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="a876" class="od lh it ny b gy oe of l og oh"># Choose observation<br/>observation = X_test_df.loc[[195]]</span><span id="c5e0" class="od lh it ny b gy oi of l og oh"># Calculate Shapley values<br/>shap_values2 = explainer.shap_values(observation)</span><span id="ad17" class="od lh it ny b gy oi of l og oh"># Decision Plot<br/>shap.decision_plot(explainer.expected_value[1], shap_values2[1], observation)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/d69eeff70548b9fb78815e54af1e2015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*iwtLIvRy39l2KHQdEjf_nQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自SHAP的决策图。图片由作者提供。</p></figure><h2 id="6ef5" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">力图(特征重要性)</h2><p id="0991" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">为了有一个总体的观点，非常类似于随机森林中的<em class="mu">特性重要性</em>图，我们可以绘制一个摘要条形图。下面是代码，后面是生成的图像。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="afe9" class="od lh it ny b gy oe of l og oh"># Summary bar plot<br/>shap.summary_plot(shap_values[1], x_test_df, plot_type='bar')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/4c6ec955157fca958ca8f73b2c412c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*ZzNzmlze1tlyhZx6kXYCnA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汇总条形图。图片由作者提供。</p></figure><p id="01e5" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">变量<em class="mu"> Test1 </em>对预测最重要，其次是测试号3、4、5和2。</p><h2 id="83b7" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">数据点汇总图</h2><p id="4246" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">另一个有趣的情节是摘要散点图。它显示了每个数据点如何影响分类的摘要。代码很简单:只需调用<code class="fe nv nw nx ny b">summary_plot()</code>并用SHAP值和要绘制的数据来填充它。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="a03d" class="od lh it ny b gy oe of l og oh"># Summary scatterplot<br/>shap.summary_plot(shap_values[1], x_test_df)</span></pre><p id="dff2" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">这个结果起初看起来很可怕，但是很容易解释。首先，观察颜色是数据点的值。所以，值越高，越红，值越低，越蓝。</p><p id="849b" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">第二个注意点，X轴是SHAP值出现的地方。向右为正值意味着对分类为1的影响更大，因为我们使用的是带切片的数组<code class="fe nv nw nx ny b">shap_values[1]</code>。Y轴显示变量名。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/8fcfe2813a301def186624f5d04ab304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*3PsQrBrhnGit703clMYO6Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">汇总散点图。图片由作者提供。</p></figure><p id="d44e" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">所以，解释一下:</p><ul class=""><li id="6b61" class="ox oy it ma b mb nk me nl mh oz ml pa mp pb mt pc pd pe pf bi translated"><em class="mu"> Test1 </em>值越高，对分类的负面影响就越大，越倾向于0类。</li><li id="7c33" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">对于<em class="mu">测试3 </em>，该值越高，对1级分类的影响越大。</li><li id="aae3" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">Test4和<em class="mu"> Test2 </em>也显示了与SHAP负面影响更相关的较高值，这意味着它们将分类推至0级。</li><li id="7769" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated"><em class="mu">测试5 </em>看起来更加混合，但是较低的值影响分类为1。</li></ul><h2 id="21d5" class="od lh it bd li ok ol dn lm om on dp lq mh oo op ls ml oq or lu mp os ot lw ou bi translated">依赖图</h2><p id="eeae" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">最后，我们来看依赖情节。这种可视化可以帮助我们在算法对观察结果进行分类时确定哪些变量关系更密切。</p><p id="e906" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">下面是创建它的代码。使用<code class="fe nv nw nx ny b">shap.dependence_plot()</code>并输入特征索引号、SHAP值和绘图数据集。</p><pre class="kj kk kl km gt nz ny oa ob aw oc bi"><span id="18f9" class="od lh it ny b gy oe of l og oh"># Dependence plot<br/>shap.dependence_plot(0, shap_values[1], x_test_df)</span></pre><p id="a134" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">结果是这样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi po"><img src="../Images/82db984cde49f9e1d280f47e4fe400ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*gG7qPC72Zmy1XWYF-8LAIQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自SHAP模块的依赖图。图片由作者提供。</p></figure><p id="47df" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">它带来的有趣之处是:</p><ul class=""><li id="48eb" class="ox oy it ma b mb nk me nl mh oz ml pa mp pb mt pc pd pe pf bi translated">该图显示了预测时关系更密切的两个变量。在我们的例子中，<em class="mu">测试1 </em>与<em class="mu">测试4 </em>有很大关系。</li><li id="9cbf" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">X上的值是数据点。y为同一变量带来SHAP值。</li><li id="c303" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">颜色取决于第二个变量<em class="mu"> Test4 </em>。</li><li id="8060" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">这里，它表明对于高值的<em class="mu">测试1和测试4 </em>，在分类中的影响是负面的(SHAP值低)。因此，在<em class="mu">测试1 </em>上具有高值的观察值，在<em class="mu">测试4 </em>上具有高值的观察值更有可能被分类为0级。</li><li id="05df" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">请参见下图，这两个变量都是分类值的主要减损因素。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/c33f20054c812ce4da642dac15397137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rwrux-3hTWlS1cXTHtSYzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Test1和Test4的高值对SHAP有负面影响，将分类推到0类。图片由作者提供。</p></figure><h1 id="d6ba" class="lg lh it bd li lj np ll lm ln nq lp lq jz nr ka ls kc ns kd lu kf nt kg lw lx bi translated">在你走之前</h1><p id="d9de" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我一直在研究这个包，我知道还有很多东西要学。我强烈建议你阅读下面这些来自<a class="ae ky" href="https://medium.com/@dataman-ai" rel="noopener">data man</a>博士的参考资料，它们对我了解这个令人敬畏的图书馆和创建这个帖子帮助很大。</p><p id="558f" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">促使我这样做的是来自<a class="ae ky" href="https://medium.com/@aayushmnit" rel="noopener"> Aayush Agrawal </a>的一篇很棒的文章，我也附上这篇文章作为关于微软研究院<code class="fe nv nw nx ny b">interpret</code>模块的参考。他们也将这个概念包装在一个很好的Python模块中。我鼓励你去看ML可解释性的“艺术”部分<strong class="ma iu"/>，那真是太棒了！</p><p id="44c8" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">概述:</p><ul class=""><li id="e16a" class="ox oy it ma b mb nk me nl mh oz ml pa mp pb mt pc pd pe pf bi translated">SHAP值计算每个数据点对给定分类的影响。</li><li id="e92f" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">SHAP是一种加法方法，因此重要性的总和将决定最终结果</li><li id="4df0" class="ox oy it ma b mb pg me ph mh pi ml pj mp pk mt pc pd pe pf bi translated">探索图并解释每个观察的分类。</li></ul><p id="5a65" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">如果你喜欢这个内容，关注我的博客或者考虑使用这个<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">推荐链接</a>加入Medium(部分资源归作者所有)。</p><div class="pq pr gp gr ps pt"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="qc l"><div class="qd l qe qf qg qc qh ks pt"/></div></div></a></div><p id="c941" class="pw-post-body-paragraph ly lz it ma b mb nk ju md me nl jx mg mh nm mj mk ml nn mn mo mp no mr ms mt im bi translated">上<a class="ae ky" href="https://www.linkedin.com/in/gurezende/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>找我。</p><h1 id="b48e" class="lg lh it bd li lj np ll lm ln nq lp lq jz nr ka ls kc ns kd lu kf nt kg lw lx bi translated">参考</h1><div class="pq pr gp gr ps pt"><a rel="noopener follow" target="_blank" href="/mixing-art-into-the-science-of-model-explainability-312b8216fa95"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">将艺术融入模型解释的科学中</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">可解释Boosting机概述和一种将ML解释转换为更人性化的方法…</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">towardsdatascience.com</p></div></div><div class="qc l"><div class="qi l qe qf qg qc qh ks pt"/></div></div></a></div><div class="pq pr gp gr ps pt"><a href="https://medium.com/dataman-in-ai/explain-your-model-with-the-shap-values-bc36aac4de3d" rel="noopener follow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">用SHAP价值观解释你的模型</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">使用SHAP值来解释任何复杂的ML模型</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">medium.com</p></div></div><div class="qc l"><div class="qj l qe qf qg qc qh ks pt"/></div></div></a></div><div class="pq pr gp gr ps pt"><a rel="noopener follow" target="_blank" href="/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">解释任何具有SHAP值的模型—使用内核解释器</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">对SHAP值使用KernelExplainer</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">towardsdatascience.com</p></div></div><div class="qc l"><div class="qk l qe qf qg qc qh ks pt"/></div></div></a></div><div class="pq pr gp gr ps pt"><a href="https://www.kaggle.com/code/vikumsw/explaining-random-forest-model-with-shapely-values" rel="noopener  ugc nofollow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">用Shapely值解释随机森林模型</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自Titanic的数据-灾难中的机器学习</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">www.kaggle.com</p></div></div><div class="qc l"><div class="ql l qe qf qg qc qh ks pt"/></div></div></a></div><div class="pq pr gp gr ps pt"><a href="https://shap.readthedocs.io/en/latest/api.html#explainers" rel="noopener  ugc nofollow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">API参考- SHAP最新文件</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">本页包含SHAP公共对象和函数的API参考。还有示例笔记本…</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">shap.readthedocs.io</p></div></div><div class="qc l"><div class="qm l qe qf qg qc qh ks pt"/></div></div></a></div><div class="pq pr gp gr ps pt"><a href="https://interpret-community.readthedocs.io/en/latest/visualizations.html" rel="noopener  ugc nofollow" target="_blank"><div class="pu ab fo"><div class="pv ab pw cl cj px"><h2 class="bd iu gy z fp py fr fs pz fu fw is bi translated">可视化-解释-社区0.27.0文档</h2><div class="qa l"><h3 class="bd b gy z fp py fr fs pz fu fw dk translated">单击特性重要性图中的任何特性条，查看所选…的值之间的关系</h3></div><div class="qb l"><p class="bd b dl z fp py fr fs pz fu fw dk translated">interpret-community . readthedocs . io</p></div></div></div></a></div></div></div>    
</body>
</html>