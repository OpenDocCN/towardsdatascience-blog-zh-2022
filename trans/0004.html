<html>
<head>
<title>A Big Problem with Linear Regression and How to Solve It</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归的一个大问题以及如何解决</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/robust-regression-23b633e5d6a5#2022-02-01">https://towardsdatascience.com/robust-regression-23b633e5d6a5#2022-02-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="be66" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习中的稳健回归简介</h2></div></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><p id="27e0" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">经典线性回归背后的想法很简单:在数据点上画一条<strong class="kr iu">“最佳拟合”线</strong>，使均方误差最小化:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/6aa668ef33f208bc9384534177f2661b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TGUadCRpzu-dr45V6v8gFA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">普通最小二乘法的经典线性回归。(图片由作者提供)</p></figure><p id="052e" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">看起来不错。但是在现实生活中，我们并不总是得到如此干净、良好的数据。相反，我们可能会得到这样的结果:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/f12ccba9fb9a9e2551b42d26edbd2fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*STRvvNaGyvz4JRfZHU8XoA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">与上面相同的算法，但是现在由于异常值而表现不佳。(图片由作者提供)</p></figure><p id="cf18" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">现在这是一场灾难——只有几个<strong class="kr iu">错误，外围点</strong>破坏了线性模型，即使人眼很清楚如何画出“最佳”线。</p><p id="fc5c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">你可能会认为我们所要做的就是剔除那些异常值，我们就完成了，但是当你有一个 4096 维的数据集和一百万个样本时，祝你好运！事情会很快失控。相反，我们需要一个通用的方法，使我们能够执行回归<strong class="kr iu">，尽管</strong>离群值或严重噪声。</p><p id="c7d3" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">由此出现了<strong class="kr iu">稳健回归</strong>的概念。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mb"><img src="../Images/4ad99fbc7574d9c9bebe37c02b9cfd88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vnSgw_cGmFGpCOqaDO3ViQ.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">正常回归比稳健回归表现差。(图片由作者提供)</p></figure><p id="9556" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这种离群点的出现是错误测量、噪声、人为错误或错误假设的常见结果，尤其是在(非常)高维自然数据(图像、音频等)普遍存在的机器学习中。</p><p id="dc6d" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">在本文中，您将知道如何正确地将模型拟合到遭受这种问题的数据，如上图所示。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="f232" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">预赛</h1><p id="c5a7" class="pw-post-body-paragraph kp kq it kr b ks mu ju ku kv mv jx kx ky mw la lb lc mx le lf lg my li lj lk im bi translated">要解决问题，我们必须知道问题的确切原因。</p><p id="124a" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">回想一下线性回归是如何工作的:由于直线(<em class="mz"> y=mx+b </em>)完全由两个参数<em class="mz"> m </em>和<em class="mz"> b </em>描述，我们必须找到<em class="mz"> m </em>和<em class="mz"> b </em>的值，使得直线和实际数据点之间的<strong class="kr iu">均方误差</strong> (MSE)最小化<strong class="kr iu"/>:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi na"><img src="../Images/7f34813cad201dd8db7376265879640f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Ayxh4XumKB5fST8CI1BVTg.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">MSE =(虚线长度的平方之和)÷(虚线的数量)。(作者制作的动画)</p></figure><p id="43b9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">您可以将虚线(代表地面实况数据点和直线之间的误差)视为金属弹簧，将蓝线视为刚性杆。弹簧以正比于其长度平方的力将杆拉向它们的红点，直到达到平衡。</p><p id="d407" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">然而，这种方法的问题是，一旦你得到一个外围点…</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi na"><img src="../Images/17608ebdd39debfd15a77ddcf19e4189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*H4IC28ajJAfs7WoAH0Lu5g.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">离群值破坏了模型的运行。(作者制作的动画)</p></figure><p id="bafc" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">…该点和线<strong class="kr iu">之间的误差将计入总误差</strong>，算法将尝试将其最小化。换句话说，异常值的“弹簧”会把线拉向他们。</p><p id="2127" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">但这激发了一个想法:</p><blockquote class="nb nc nd"><p id="6bda" class="kp kq mz kr b ks kt ju ku kv kw jx kx ne kz la lb nf ld le lf ng lh li lj lk im bi translated"><strong class="kr iu"> <em class="it">忽略或减少离群点的误差，使其不会影响总 MSE。</em> </strong></p></blockquote><p id="06be" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">那么，我们如何识别外围点的错误呢？</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="0da6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">胡伯损失回归</h1><p id="d70b" class="pw-post-body-paragraph kp kq it kr b ks mu ju ku kv mv jx kx ky mw la lb lc mx le lf lg my li lj lk im bi translated">回想一下 MSE 损失的定义:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/af650ae93fce020a08e2f19e4228f500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8GK3bRGkpt6ggPncgT0CsA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">均方误差图。(图片由作者提供)</p></figure><p id="64d8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">虚线的长度(即误差或残差)被平方、相加，然后除以点数(<em class="mz"> n </em>)以获得需要最小化的均方误差损失。</p><p id="25b7" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">Huber loss 的想法是<strong class="kr iu">不平方橙色虚线</strong>(代表异常值的误差)的长度，而只平方红色虚线，这样异常值就不会对损失造成太大影响。</p><p id="84b9" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">为了知道哪些误差不平方，我们定义了一个准则:<strong class="kr iu">如果绝对误差大于某个阈值(δ)，就不平方。</strong>由于异常值通常“远离”原始点(因此它们具有较大的误差)，它们<em class="mz">希望</em>不会被平方，因此对整体损失的影响较小。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/ea5aba95da6270806e5904235ce894ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Si0YuLvf1BsI1Kyf2yEgLw.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">Huber 损失与 MSE 损失的比较。x 轴是数据点和直线之间的误差(残差)。指出了 Huber 损耗的线性部分，其中误差没有平方。(图片由作者提供)</p></figure><p id="5fb5" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">要实现 Huber 损耗，只需用您最喜欢的最小化算法中的 Huber 损耗替换 MSE 损耗:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/283040031b55319b43b427dc804a89d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*LUfF3yAvixXGToHwELhIZQ.png"/></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">用误差表示 MSE 损失和 Huber 损失的数学表达式。(图片由作者提供)</p></figure><p id="d003" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">让我们看看它是如何工作的:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi na"><img src="../Images/c0340affa1d3c15dda0a4f1a2ecadab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*_Soi4QGC9GIGa102pMOBug.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">Huber 回归在行动。红色虚线是方形的，而橙色虚线不是。(作者制作的动画)</p></figure><p id="cfa3" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">不错！现在，异常值对算法的影响没有以前那么大，因为它们相应的损失被衰减了。使用弹簧类比，橙色弹簧现在比红色弹簧弱，拉力也没有红色弹簧大。</p><p id="3c8c" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">然而，这种方法存在一些问题。一个是选择δ的值。它应该是什么并不总是很清楚，所以要不断试错(δ=1.35 是一个典型的开始)。另一个问题是，如果离群值太远…</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/21eadaea08ef2a845f2249e61772d1e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_jkKhOZsl3FsawbWocJkhg.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">胡伯回归遭到破坏。(图片由作者提供)</p></figure><p id="2567" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">…事情可能会变得不可收拾——它们的误差变得如此之大，以至于即使没有平方，它们也会超过损失。然而，我们仍然很清楚什么是“最佳拟合”线，所以必须有另一种方法来解决这个问题。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="e1fe" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">泰尔-森回归</h1><p id="4e79" class="pw-post-body-paragraph kp kq it kr b ks mu ju ku kv mv jx kx ky mw la lb lc mx le lf lg my li lj lk im bi translated">统计学家中有一句名言:</p><blockquote class="ni"><p id="2c1e" class="nj nk it bd nl nm nn no np nq nr lk dk translated">中位数比平均数更能抵抗异常值。</p></blockquote><p id="b436" class="pw-post-body-paragraph kp kq it kr b ks ns ju ku kv nt jx kx ky nu la lb lc nv le lf lg nw li lj lk im bi translated">原因显而易见:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mb"><img src="../Images/a5a4c4094414767bc089817f70b4ed45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*GLDlwSbht2DsitC5l0RaJw.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">与数轴上五个数的中值相比的算术平均值。(作者制作的动画)</p></figure><p id="28a8" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">中值的概念也可以扩展到任意数量的维度(在所谓的<a class="ae nx" href="https://en.wikipedia.org/wiki/Geometric_median" rel="noopener ugc nofollow" target="_blank"> <strong class="kr iu">空间中值</strong> </a>中)，同时仍然保留其抗异常值的属性:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mb"><img src="../Images/39640e0683a3f45598dbfcd99a275185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*RQL-etF8R9k7PFZSzymUmA.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">与四个 2D 点的分量平均值相比的空间中值。(作者制作的动画)</p></figure><p id="e2f4" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">于是产生了<strong class="kr iu">泰尔森回归</strong>的想法:</p><blockquote class="nb nc nd"><p id="024d" class="kp kq mz kr b ks kt ju ku kv kw jx kx ne kz la lb nf ld le lf ng lh li lj lk im bi translated"><em class="it">用一条直线将每一对点连接起来(</em>y<em class="it">=</em>m<strong class="kr iu">ᵢ</strong>x<em class="it">+</em>b<strong class="kr iu">ᵢ</strong><em class="it">)得到斜率截距对列表(</em> m <strong class="kr iu"> ᵢ，</strong> b <strong class="kr iu"> ᵢ </strong> <em class="it">)。这些对的空间中值将给出最佳拟合线的斜率和截距。</em></p></blockquote><p id="a323" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">让我们来看看这个爆炸的案例是如何运作的:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/b1c3cdc17bb6b47b1a8db86c9898cb89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AMy8MeFC-OCNjaivpsU3jA.png"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">泰尔森回归在行动。(图片由作者提供)</p></figure><p id="5ab1" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">太棒了。</p><p id="6969" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">你可能已经注意到，我们需要连接每一对点，这给了我们(<em class="mz"> n </em>选择 2)=<em class="mz">n</em>(<em class="mz">n</em>—1)<strong class="kr iu"/>2 对(如果<em class="mz"> n </em>是点数)。对于大型数据集，这可能导致难以处理的长计算时间(例如，仅 1000 个点就产生 50 万个(<em class="mz">m</em><strong class="kr iu"><em class="mz">ᵢ</em>，</strong><em class="mz">b</em><strong class="kr iu"><em class="mz">ᵢ</em></strong>)对来寻找的空间中值)。</p><p id="ba59" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">一种解决方案是只对这些点对的随机子集进行处理，或者不是连接每一对点来得到一条线，而是将一条线拟合到每一个<em class="mz"> k </em>点元组。这牺牲了速度的鲁棒性。另一个解决方案是使用 RANSAC。</p><h1 id="9e83" class="mc md it bd me mf ny mh mi mj nz ml mm jz oa ka mo kc ob kd mq kf oc kg ms mt bi translated">兰萨克</h1><p id="df23" class="pw-post-body-paragraph kp kq it kr b ks mu ju ku kv mv jx kx ky mw la lb lc mx le lf lg my li lj lk im bi translated">随机样本一致性(RANSAC)算法基于这样一种想法，即数据的随机子集具有一定的无异常值概率，因此将模型拟合到该子集可能会产生最佳拟合模型。因此，重复挑选一个随机子集并对其拟合模型的过程足够多次，将有希望产生最佳拟合模型。该算法的典型版本如下:</p><ol class=""><li id="6eef" class="od oe it kr b ks kt kv kw ky of lc og lg oh lk oi oj ok ol bi translated">从数据中随机抽取点的子集。</li><li id="4e62" class="od oe it kr b ks om kv on ky oo lc op lg oq lk oi oj ok ol bi translated">将线性(或其他)模型拟合到随机样本。</li><li id="a5ab" class="od oe it kr b ks om kv on ky oo lc op lg oq lk oi oj ok ol bi translated">计算所有点和模型之间的误差(即残差)。误差小于预定阈值的点被分类为内点，其余的被分类为外点。</li><li id="7ff9" class="od oe it kr b ks om kv on ky oo lc op lg oq lk oi oj ok ol bi translated">重复上述步骤特定次数，选择<strong class="kr iu">得分最高的型号</strong>作为最适合的型号。</li></ol><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi na"><img src="../Images/f325d1a291f2e066e9f3321eb2f7c529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dZu4Uax7NF_IGHgepKObYg.gif"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">RANSAC 插图:将线性模型拟合到两个随机选取的点，计算得分，并重复该过程。得到的模型是得分最高的模型。(作者制作的动画)</p></figure><p id="9522" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">分数通常被定义为内球的数量。如果两个模型的内层数相等，选择 MSE 最小或 R 最大的一个。</p><p id="1534" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">这种方法的一个直接缺点是它是不确定的。也就是说，它并不总是保证产生我们正在寻找的最佳拟合模型，因为我们在有限的迭代次数中处理随机子集。此外，超参数(子集大小、迭代次数、停止标准)是特定于问题的，需要手动调整。然而，RANSAC 是一种强大且广泛使用的算法，尤其是在计算机视觉中，这是由于其鲁棒性和扩展到非线性模型和更高维数据集的能力。</p></div><div class="ab cl ki kj hx kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="im in io ip iq"><h1 id="35bc" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="d919" class="pw-post-body-paragraph kp kq it kr b ks mu ju ku kv mv jx kx ky mw la lb lc mx le lf lg my li lj lk im bi translated">现在，您知道了如何使模型稳健地适应被异常值破坏的数据。上面的每种方法都有自己的优点和缺点，所以在选择哪种方法来解决给定的问题时要小心。此外，应进行适当的分析，以确保异常值是真正由不必要的误差和噪声引起的，还是由数据中尚未考虑的重要潜在模式引起的。</p><p id="f077" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">上述三种算法都可以从<a class="ae nx" href="https://scikit-learn.org/stable/auto_examples/linear_model/plot_robust_fit.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn 库</a>中获得。</p><p id="4f68" class="pw-post-body-paragraph kp kq it kr b ks kt ju ku kv kw jx kx ky kz la lb lc ld le lf lg lh li lj lk im bi translated">保持强壮。</p></div></div>    
</body>
</html>