<html>
<head>
<title>Document Parsing with Python &amp; OCR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python和OCR进行文档解析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/document-parsing-with-python-ocr-75543448e581#2022-07-13">https://towardsdatascience.com/document-parsing-with-python-ocr-75543448e581#2022-07-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bf7a59d41b19f964ce71b34753c515bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LgqxDMP5qD1HE_uM33zZrg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><div class=""/><div class=""><h2 id="d988" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">使用计算机视觉从任何类型的文档中检测和提取文本、图形、表格</h2></div><h2 id="e0bd" class="kx ky ji bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">摘要</h2><p id="ab8f" class="pw-post-body-paragraph lt lu ji lv b lw lx kj ly lz ma km mb lg mc md me lk mf mg mh lo mi mj mk ml im bi translated">在本文中，我将使用Python和计算机视觉展示如何解析文档，比如<em class="mm">pdf、</em>并提取信息。</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mn"><img src="../Images/7207360645e210691d24907b77dc106c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*whpadRMvhQIUefFf"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae ms" href="https://unsplash.com/@gtomassetti?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">乔治·托马塞蒂</a>在<a class="ae ms" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="bbdc" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated"><a class="ae ms" href="https://en.wikipedia.org/wiki/Parsing" rel="noopener ugc nofollow" target="_blank"> <strong class="lv jj">文档解析</strong> </a>涉及检查文档中的数据，提取有用的信息。这对公司来说是必不可少的，因为它减少了大量的手工工作。想象一下，必须手动搜索100页的表格，然后将它复制并粘贴到其他地方……如果有一个程序可以在1秒钟内完成，那该有多酷？</p><p id="3bda" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">一种流行的解析策略是将文档转换成图像并使用计算机视觉。<a class="ae ms" href="https://en.wikipedia.org/wiki/Document_layout_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="lv jj">文档图像分析</strong> </a>是指应用于文档图像以从像素数据中获取信息的技术。这可能很棘手，因为在一些情况下，对于预期的结果应该是什么样子(文本、图像、图表、数字、表格、公式……)没有明确的答案。最常用的技术是OCR。</p><p id="921d" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated"><a class="ae ms" href="https://en.wikipedia.org/wiki/Optical_character_recognition" rel="noopener ugc nofollow" target="_blank"><strong class="lv jj">【OCR(光学字符识别)</strong> </a> <strong class="lv jj"> </strong>是通过计算机视觉检测并提取图像中文字的过程。它是在第一次世界大战期间发明的，当时以色列科学家伊曼纽尔·戈德堡创造了一种可以阅读字符并将其转换成电报代码的机器。今天，该领域已经达到了非常高的复杂程度，混合了图像处理、文本定位、字符分割和字符识别。基本上是一种文本对象检测。</p><p id="9ea1" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">在本教程中，我将展示如何使用OCR进行文档解析。我将展示一些有用的Python代码，这些代码可以很容易地用于其他类似的情况(只需复制、粘贴、运行)，并通过注释遍历每一行代码，这样您就可以很容易地复制这个示例(下面是完整代码的链接)。</p><div class="is it gp gr iu my"><a href="https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils/blob/master/computer_vision/example_ocr_parsing.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jj gy z fp nd fr fs ne fu fw jh bi translated">data science _ artificial intelligence _ Utils/example _ ocr _ parsing . ipynb at master…</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">数据科学项目和人工智能用例的示例…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">github.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm ja my"/></div></div></a></div><p id="7513" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">我将用一家上市公司的<em class="mm"> PDF </em>格式的财务报表作为例子(下面的链接)。</p><figure class="mo mp mq mr gt iv"><div class="bz fp l di"><div class="nn no l"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae ms" href="https://s2.q4cdn.com/470004039/files/doc_financials/2021/q4/_10-K-2021-(As-Filed).pdf" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="4735" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">特别是，我将经历:</p><ul class=""><li id="6c8b" class="np nq ji lv b lw mt lz mu lg nr lk ns lo nt ml nu nv nw nx bi translated">环境设置:导入包、读取数据、预处理</li><li id="b9c7" class="np nq ji lv b lw ny lz nz lg oa lk ob lo oc ml nu nv nw nx bi translated">检测(文本、图形、表格)</li><li id="f6a6" class="np nq ji lv b lw ny lz nz lg oa lk ob lo oc ml nu nv nw nx bi translated">摘录(文本、图表、表格)</li></ul></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><h2 id="a469" class="kx ky ji bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">设置</h2><p id="a8ef" class="pw-post-body-paragraph lt lu ji lv b lw lx kj ly lz ma km mb lg mc md me lk mf mg mh lo mi mj mk ml im bi translated">文档解析令人烦恼的地方在于，有如此多的工具可以处理不同类型的数据(文本、图形、表格),但没有一个能够完美地工作。以下是基于人们想要遵循的策略的最流行的包的当前框架:</p><ul class=""><li id="da89" class="np nq ji lv b lw mt lz mu lg nr lk ns lo nt ml nu nv nw nx bi translated"><strong class="lv jj">将文档处理为文本</strong>:用<a class="ae ms" href="https://pypdf2.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> PyPDF2 </em> </a>提取文本，用<a class="ae ms" href="https://github.com/camelot-dev/camelot" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> Camelot </em> </a>或<a class="ae ms" href="https://github.com/chezou/tabula-py" rel="noopener ugc nofollow" target="_blank"><em class="mm">tabulopy</em></a>提取表格，用<a class="ae ms" href="https://pymupdf.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> PyMuPDF </em> </a>提取数字。</li><li id="fedf" class="np nq ji lv b lw ny lz nz lg oa lk ob lo oc ml nu nv nw nx bi translated"><strong class="lv jj">将文档转换为图像(OCR) </strong>:用<a class="ae ms" href="https://github.com/Belval/pdf2image" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> pdf2image </em> </a>进行转换，用<a class="ae ms" href="https://github.com/madmaze/pytesseract" rel="noopener ugc nofollow" target="_blank"><em class="mm">pytesserac</em></a><em class="mm"/>加上其他很多支持库，<em class="mm"> </em>或者只是<a class="ae ms" href="https://github.com/Layout-Parser/layout-parser" rel="noopener ugc nofollow" target="_blank"> <em class="mm"> LayoutParser </em> </a>提取数据。</li></ul><p id="4ef5" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">也许你会问自己:“<em class="mm">为什么要麻烦地将页面转换成图像，而不是直接处理PDF文件？”。你可以这么做<em class="mm">。</em>这种策略的主要缺点是编码方案:文档可以有多种编码(如UTF 8、ASCII、Unicode)，因此转换成文本可能会导致数据丢失。因此，为了避免任何问题，我将使用OCR并用<strong class="lv jj"> <em class="mm"> pdf2image </em> </strong>将页面转换成图像。请注意，<em class="mm"> PDF </em>渲染库<a class="ae ms" href="https://poppler.freedesktop.org/" rel="noopener ugc nofollow" target="_blank"><strong class="lv jj"><em class="mm">Poppler</em></strong></a><strong class="lv jj"><em class="mm"/></strong>需要运行。</em></p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="11b9" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj"># with pip</strong><br/>pip install python-poppler<br/><strong class="ol jj"># with conda<br/></strong>conda install -c conda-forge poppler</span></pre><p id="1126" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">您可以轻松阅读该文档:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="d1ed" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj"># READ AS IMAGE</strong><br/>import <strong class="ol jj">pdf2image</strong></span><span id="c589" class="kx ky ji ol b gy ot oq l or os">doc = pdf2image.convert_from_path("doc_apple.pdf")<br/>len(doc) <strong class="ol jj">#&lt;-- check num pages<br/></strong>doc[0]   <strong class="ol jj">#&lt;-- visualize a page</strong></span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ou"><img src="../Images/b2f44b7ba1aabd5888352902d34dc802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TKi0ra1qLrFQKqBNs-2DJw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="6052" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">如果要在计算机上保存页面图像，可以使用下面的代码:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="cd0b" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj"># Save imgs<br/></strong>import <strong class="ol jj">os</strong></span><span id="735d" class="kx ky ji ol b gy ot oq l or os">folder = "doc"<br/>if folder not in os.listdir():<br/>    os.makedirs(folder)</span><span id="6bb1" class="kx ky ji ol b gy ot oq l or os">p = 1<br/>for page in doc:<br/>    image_name = "page_"+str(p)+".jpg"  <br/>    page.save(os.path.join(folder, image_name), "JPEG")<br/>    p = p+1</span></pre><p id="2522" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">最后，我们需要设置我们将使用的CV引擎。<strong class="lv jj"> <em class="mm"> LayoutParser </em> </strong>似乎是第一个针对OCR的通用包，基于深度学习。它使用两个著名的任务模型:</p><ul class=""><li id="e8e6" class="np nq ji lv b lw mt lz mu lg nr lk ns lo nt ml nu nv nw nx bi translated">检测:<a class="ae ms" href="https://github.com/facebookresearch/detectron2" rel="noopener ugc nofollow" target="_blank"><strong class="lv jj"><em class="mm">Detectron</em></strong></a>，脸书最先进的物体检测库(我们将使用第二版<em class="mm"> Detectron2 </em>)。</li></ul><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="7cec" class="kx ky ji ol b gy op oq l or os">pip install layoutparser torchvision &amp;&amp; pip install "git+https://github.com/facebookresearch/detectron2.git@v0.5#egg=detectron2"</span></pre><ul class=""><li id="caeb" class="np nq ji lv b lw mt lz mu lg nr lk ns lo nt ml nu nv nw nx bi translated">提取:<a class="ae ms" href="https://github.com/tesseract-ocr/tesseract" rel="noopener ugc nofollow" target="_blank"> <strong class="lv jj"> <em class="mm">宇宙魔方</em> </strong> </a>，主要的OCR系统，由惠普于1985年创建，目前由谷歌开发。我们还必须下载软件，StackOverflow上的这个<a class="ae ms" href="https://stackoverflow.com/questions/50951955/pytesseract-tesseractnotfound-error-tesseract-is-not-installed-or-its-not-i" rel="noopener ugc nofollow" target="_blank">帖子</a>解释了如何为不同的操作系统下载软件。</li></ul><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="a77c" class="kx ky ji ol b gy op oq l or os">pip install "layoutparser[ocr]"</span></pre><p id="a319" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">现在，我们已经准备好开始信息检测和提取的OCR过程。</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="e8d5" class="kx ky ji ol b gy op oq l or os">import <strong class="ol jj">layoutparser</strong> as lp<br/>import <strong class="ol jj">cv2<br/></strong>import<strong class="ol jj"> numpy </strong>as np<br/>import <strong class="ol jj">io</strong><br/>import <strong class="ol jj">pandas </strong>as pd<br/>import <strong class="ol jj">matplotlib</strong>.pyplot as plt</span></pre><h2 id="db88" class="kx ky ji bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">侦查</h2><p id="b3d0" class="pw-post-body-paragraph lt lu ji lv b lw lx kj ly lz ma km mb lg mc md me lk mf mg mh lo mi mj mk ml im bi translated"><a class="ae ms" href="https://en.wikipedia.org/wiki/Object_detection" rel="noopener ugc nofollow" target="_blank">(物体)检测</a>是在一张图片中寻找多条信息，然后用一个长方形的包围盒将其包围起来的过程。对于文档解析，这些信息是标题、文本、图表、表格…</p><p id="a650" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">因此，让我们来看一个包含所有内容的复杂页面:</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ov"><img src="../Images/a17783e2e0dc88494f1216b6a4465804.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xsGFXxp8itODBp5J0S2E9w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">第22页(作者图片)</p></figure><p id="65ce" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">这个页面以一个标题开始，有一个文本块，后面是一个图和一个表，所以我们需要一个经过训练的模型来识别这些对象。幸运的是<em class="mm"> Detectron </em>能够胜任这项任务，你只需要从<a class="ae ms" href="https://layout-parser.readthedocs.io/en/latest/notes/modelzoo.html#example-usage" rel="noopener ugc nofollow" target="_blank">这里</a>选择一个模型，并在代码中指定它的路径。</p><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ow"><img src="../Images/2b55df22752085a7af0e3cd2e8bd8ca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ItyANyIy7645ePVnqI6c7A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="e30a" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">我将要使用的模型只能检测这4个对象(文本、标题、列表、表格、图形)。因此，如果你需要识别其他东西(比如方程式)，你必须改变模型。</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="51be" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj">## load pre-trained model</strong><br/>model = lp.Detectron2LayoutModel(<br/>   <strong class="ol jj">"lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config",</strong><br/>   extra_config=["MODEL.ROI_HEADS.SCORE_THRESH_TEST", 0.8],<br/>   label_map={0:"Text", 1:"Title", 2:"List", 3:"Table", 4:"Figure"})</span><span id="9dd5" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj">## turn img into array<br/></strong>i = 21<br/>img = np.asarray(doc[i])</span><span id="ac9a" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj">## predict<br/></strong>detected = model.detect(img)</span><span id="65e9" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj">## plot<br/></strong>lp.draw_box(img, detected, box_width=5, box_alpha=0.2, <br/>            show_element_type=True)</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/e7267ac3481ea7505fe1d25f0911976c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RYi3j657KOB44oItXO0TQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="dd7b" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">预测对象“<em class="mm">检测到”</em>包含每个检测到的布局的细节，如边界框的坐标。根据输出在页面上出现的顺序对其进行排序非常有用:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="4741" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj">## sort</strong><br/>new_detected = detected.sort(key=lambda x: x.coordinates[1])</span><span id="f03d" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj">## assign ids</strong><br/>detected = lp.Layout([block.set(id=idx) for idx,block in <br/>                      enumerate(new_detected)])</span><span id="3660" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj">## check<br/></strong>for block in detected:<br/>    print("---", str(block.id)+":", block.type, "---")<br/>    print(block, end='\n\n')</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/b5b83efcd824df5cfa37b70b36ad4335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDTqKtr9oSVZeG59NDgvkg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="1a6d" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">完成OCR的下一步是正确提取边界框内的信息。</p><h2 id="0a7d" class="kx ky ji bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">提取，血统</h2><p id="90b3" class="pw-post-body-paragraph lt lu ji lv b lw lx kj ly lz ma km mb lg mc md me lk mf mg mh lo mi mj mk ml im bi translated">为了帮助OCR模型，通常使用边界框分割图像，然后使用模型处理分割的图像。最后，我将把提取的输出保存到一个字典中。</p><p id="9cb1" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">由于我们看到不同类型的输出(文本、标题、图形、表格)，我将准备一个函数来显示结果。</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="2d18" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj">'''<br/>{'0-Title': '...',<br/> '1-Text':  '...', <br/> '2-Figure': array([[ [0,0,0], ...]]),<br/> '3-Table': pd.DataFrame,<br/>}<br/>'''</strong><br/>def <strong class="ol jj">parse_doc</strong>(dic):<br/>    for k,v in dic.items():<br/>        if "Title" in k:<br/>            print('\x1b[1;31m'+ v +'\x1b[0m')<br/>        elif "Figure" in k:<br/>            plt.figure(figsize=(10,5))<br/>            plt.imshow(v)<br/>            plt.show()<br/>        else:<br/>            print(v)<br/>        print(" ")</span></pre><p id="7d16" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">让我们用<strong class="lv jj">文本</strong>来试试:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="3501" class="kx ky ji ol b gy op oq l or os"><strong class="ol jj"># load model</strong><br/>model = lp.TesseractAgent(languages='eng')</span><span id="5a4d" class="kx ky ji ol b gy ot oq l or os">dic_predicted = {}</span><span id="364a" class="kx ky ji ol b gy ot oq l or os">for block in [block for block in detected if block.type in [<strong class="ol jj">"Title","Text"</strong>]]:<br/>    <strong class="ol jj"><em class="mm">## segmentation</em></strong><br/>    segmented = block.pad(left=15, right=15, top=5, <br/>                bottom=5).crop_image(img)<br/>    <strong class="ol jj"><em class="mm">## extraction</em></strong><br/>    extracted = model.detect(segmented)<br/>    <strong class="ol jj"><em class="mm">## save</em></strong><br/>    dic_predicted[str(block.id)+"-"+block.type] = <br/>                  extracted.replace('\n',' ').strip()</span><span id="8a9a" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj"># check</strong><br/>parse_doc(dic_predicted)</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/b14f2de120aaef8ef9a7c6be9fe57819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LatRosqLeqfXTx7kNRpEGg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="ea25" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">继续关注<strong class="lv jj">人物</strong>:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="8a3a" class="kx ky ji ol b gy op oq l or os">for block in [block for block in detected if block.type == "<strong class="ol jj">Figure</strong>"]:<br/>    <strong class="ol jj"><em class="mm">## segmentation</em></strong><br/>    segmented = block.pad(left=15, right=15, top=5, <br/>                          bottom=5).crop_image(img)<br/>    <strong class="ol jj"><em class="mm">## save</em></strong><br/>    dic_predicted[str(block.id)+"-"+block.type] = segmented</span><span id="c206" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj"># check</strong><br/>parse_doc(dic_predicted)</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/628a4dad5bd139bd97325d918249a0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6LfxbPev1qJ4NvuCwbM2w.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="9b61" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">很好，但是那相对容易，<strong class="lv jj">桌子</strong>就难多了。尤其是示例中的这个，因为它没有垂直线来分隔列，而列名在单独的行上。</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="d3a7" class="kx ky ji ol b gy op oq l or os">for block in [block for block in detected if block.type == "<strong class="ol jj">Table</strong>"]:<br/>    <strong class="ol jj"><em class="mm">## segmentation</em></strong><br/>    segmented = block.pad(left=15, right=15, top=5, <br/>                bottom=5).crop_image(img)<br/>    <strong class="ol jj"><em class="mm">## extraction</em></strong><br/>    extracted = model.detect(segmented)<br/>    <strong class="ol jj"><em class="mm">## save</em></strong><br/>    dic_predicted[str(block.id)+"-"+block.type] = pd.read_csv( <br/>                 io.StringIO(extracted) )</span><span id="6a2f" class="kx ky ji ol b gy ot oq l or os"><strong class="ol jj"># check</strong><br/>parse_doc(dic_predicted)</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/9c761d0c46c8a016b4960b0792e92545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQyp9qJXtO8-Y5Y1wXEbdQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="0918" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">如您所见，提取出的表格并不好。没有OCR会不会不一样？让我们尝试在不将文档转换成图像的情况下处理它。我将使用<strong class="lv jj"> <em class="mm"> TabulaPy </em> </strong>包:</p><pre class="mo mp mq mr gt ok ol om on aw oo bi"><span id="8177" class="kx ky ji ol b gy op oq l or os">import <strong class="ol jj">tabula</strong><br/>tables = tabula.read_pdf("doc_apple.pdf", pages=i+1)<br/>tables[0]</span></pre><figure class="mo mp mq mr gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pc"><img src="../Images/2c5d3a62d03a27724c301585cd6591c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*balgSAqTADF7dYVwogtPiA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="5471" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">结果稍微好一点，因为现在表有列了，即使名称仍然是错误的。</p><h2 id="74d8" class="kx ky ji bd kz la lb dn lc ld le dp lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">结论</h2><p id="a4b3" class="pw-post-body-paragraph lt lu ji lv b lw lx kj ly lz ma km mb lg mc md me lk mf mg mh lo mi mj mk ml im bi translated">这篇文章是演示如何用OCR执行文档解析的教程。我用<em class="mm"> LayoutParser </em>包走了一遍检测和提取的全过程。我展示了如何处理<em class="mm"> PDF </em>文档中的文本、图表和表格。</p><p id="832d" class="pw-post-body-paragraph lt lu ji lv b lw mt kj ly lz mu km mb lg mv md me lk mw mg mh lo mx mj mk ml im bi translated">我希望你喜欢它！如有问题和反馈，或者只是分享您感兴趣的项目，请随时联系我。</p><blockquote class="pd"><p id="b77d" class="pe pf ji bd pg ph pi pj pk pl pm ml dk translated">👉<a class="ae ms" href="https://linktr.ee/maurodp" rel="noopener ugc nofollow" target="_blank">我们来连线</a>👈</p></blockquote></div><div class="ab cl od oe hx of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="im in io ip iq"><blockquote class="pn po pp"><p id="0689" class="lt lu mm lv b lw mt kj ly lz mu km mb pq mv md me pr mw mg mh ps mx mj mk ml im bi translated">本文是Python 系列<strong class="lv jj"> CV的一部分，参见:</strong></p></blockquote><div class="is it gp gr iu my"><a rel="noopener follow" target="_blank" href="/how-to-detect-objects-with-your-webcam-82693c47bd8"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jj gy z fp nd fr fs ne fu fw jh bi translated">用Python和YOLO进行对象检测</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">使用网络摄像头的计算机视觉</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">towardsdatascience.com</p></div></div><div class="nh l"><div class="pt l nj nk nl nh nm ja my"/></div></div></a></div><div class="is it gp gr iu my"><a href="https://pub.towardsai.net/image-classification-with-python-cnn-vs-transformers-fe509cbbc2d0" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jj gy z fp nd fr fs ne fu fw jh bi translated">用Python进行图像分类:CNN与变形金刚</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">计算机视觉&amp;用卷积神经网络、迁移学习、ViT、TensorFlow和HuggingFace进行解释</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">pub.towardsai.net</p></div></div><div class="nh l"><div class="pu l nj nk nl nh nm ja my"/></div></div></a></div></div></div>    
</body>
</html>