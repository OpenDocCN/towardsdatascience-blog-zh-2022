<html>
<head>
<title>Pick Your Deep Learning Tool</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">挑选你的深度学习工具</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pick-your-deep-learning-tool-d01fcfb86845#2022-04-25">https://towardsdatascience.com/pick-your-deep-learning-tool-d01fcfb86845#2022-04-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7407" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为什么您的工具可以依赖于您组织的团队结构</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ec29e660799fae0a26b8fbf1aea8f51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8lMC8go_iTQy-vud"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">塞萨尔·卡利瓦里诺·阿拉贡在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="8a52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">免责声明:本文的观点是我自己的，并不一定反映我的组织或使用或开发所述代码库的其他人的观点。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="4300" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">介绍</h1><p id="df2f" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">机器学习模型的生命周期漫长、复杂且容易出错。ML和数据科学家需要使用工具来轻松准备数据、定义模型、执行他们想要的训练循环并为模型服务。与此同时，一切都应该是可复制的，以便在它们的生命周期中追踪模型问题是可行的。</p><p id="2ec9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Jupiter笔记本是数据和ml从业者学习的第一批工具之一，用于管理整个生命周期，同时保留支持理解的周围文本。因为它们提供了快速的反馈回路，所以它们是一个很好的学习工具。然而，当从学习/原型环境转移到将机器学习模型部署到生产的需求时，它们变得越来越不有用。</p><p id="bc3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当谈到生产ML模型时，控制数据和模型的版本非常重要，以便知道我们运行的模型来自哪里，以及控制实验运行以防止在相同的实验上浪费更多的计算。此外，有用的ML模型是在大量数据上训练的，需要以一致和自动化的方式在集群或云上训练，而Jupiter笔记本不是实现这一目标的最佳工具。</p><p id="58bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当科学家处于探索阶段时，可以在他们的笔记本电脑中进行原型化的训练运行，但随后需要将它们移动到支持长时间高计算资源工作的环境中。在转移培训时，需要远程复制本地执行环境，以确保一切正常，这通常是使用docker容器和python环境来完成的，因此不需要进一步的返工。</p><p id="6460" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">科学家需要实验，然后他们需要工具，这些工具包括他们任务的领域逻辑，并且容易扩展他们的实验，同时遵循良好的工程实践。</p><h2 id="a393" class="mz md it bd me na nb dn mi nc nd dp mm li ne nf mo lm ng nh mq lq ni nj ms nk bi translated">特定领域的DL工具</h2><p id="4a19" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">大多数从业者使用ML的方式是为他们的深度学习分支使用特定领域的工具。这种工具包括用于数据准备、训练和评估模型、在新数据上使用它们(推断)、后处理它们的结果以及在某些情况下部署它们的代码。这种方法非常普遍，因为它非常方便:</p><ul class=""><li id="d85b" class="nl nm it lb b lc ld lf lg li nn lm no lq np lu nq nr ns nt bi translated">在模型生命周期中执行不同的步骤只需要执行一个CLI命令</li><li id="b35c" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu nq nr ns nt bi translated">该领域的最新研究改进了代码，所有团队成员都从中受益</li><li id="ec04" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu nq nr ns nt bi translated">由于代码是特定于领域的，对于一个拥有领域知识的科学家来说，几乎没有额外的认知负担，他可以很容易地将概念映射到代码。</li><li id="e121" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu nq nr ns nt bi translated">团队的最佳实践通常被编码在工具中。想想数据清理、训练超参数和缺省值。</li></ul><p id="6cc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我攻读机器翻译博士学位期间，这也是我最喜欢的解决方案，也是我所知道的唯一解决方案。我用的是<a class="ae ky" href="https://github.com/EdinburghNLP/nematus" rel="noopener ugc nofollow" target="_blank"> Nematus </a>(当时还是基于Theano！)、<a class="ae ky" href="https://github.com/OpenNMT/OpenNMT-py" rel="noopener ugc nofollow" target="_blank"> OpenNMT-py </a>和<a class="ae ky" href="https://github.com/pytorch/fairseq" rel="noopener ugc nofollow" target="_blank"> Fairseq </a>，以此顺序，在<a class="ae ky" href="https://github.com/mattiadg/FBK-Fairseq-ST" rel="noopener ugc nofollow" target="_blank">分叉</a> Fairseq之前进行语音翻译支持。</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/getting-started-with-end-to-end-speech-translation-3634c35a6561"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">开始使用端到端语音翻译</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">使用Pytorch，您只需几个步骤就可以翻译英语演讲</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ks oc"/></div></div></a></div><p id="e5ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对我来说，主要的优势是使用基于社区的工具，快速实现最新的研究成果，从而更快地产生研究成果。</p><p id="379a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，与任何工具类似，使用这种平台也有缺点。</p><p id="e647" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，这种代码库的目标是正确快速地实现最新的研究成果，而不总是为未来提供稳定的基础。<br/>当底层深度学习框架出现版本跳转，打破追溯兼容性时，问题就出现了。从Tensorflow切换到Tensorflow 2时发生了这种情况，Pytorch APIs长时间不稳定，Theano被放弃，迫使依赖它的项目做出艰难的决定。在这种情况下，如果维护人员不想使用废弃的软件，他们必须用更新的API重写(大部分)代码库，切换框架，如从Theano迁移到Tensorflow的Nematus，甚至获得废弃软件的所有权，但这肯定是最昂贵的选择，因为它还需要数据/ML科学家不具备的技能。</p><p id="d5ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，快速变化的框架问题的唯一解决方案是自己编写所有的深度学习操作。Marian-nmt是我所知道的唯一一个这样做的工具，它的结果非常好，因为它可以优化代码的任何方面。缺点是它需要C++技能，这在科学家中也不是很常见，并且可能需要更高的开发工作，而该工具是特定于一个应用领域(机器翻译)的。</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/how-fast-is-c-compared-to-python-978f18f474c7"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">C++相比Python有多快？</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">相信自己不需要了解C++的数据科学家的一个例子</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="or l on oo op ol oq ks oc"/></div></div></a></div><p id="e82a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个问题:<strong class="lb iu">所有权。</strong>小型研究小组可以选择实用的方法，使用最适合他们需求的开源工具。我在读博士期间就是这么做的，这让我可以专注于我的研究，而不是软件开发。另一方面，无法控制主要工作工具的开发会隐藏巨大的成本。</p><p id="efcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有很多这样的例子，这些项目用一个巨大的公关和没有通知打破了它们的追溯兼容性。当这种情况发生时，如果你的研究分支偏离了主分支，并且与新的设计不再兼容，你就有大麻烦了。举个例子，我的分支<a class="ae ky" href="https://github.com/mattiadg/FBK-Fairseq-ST" rel="noopener ugc nofollow" target="_blank"> FBK-Fairseq-ST </a>(不再维护)与<a class="ae ky" href="https://github.com/mgaido91/FBK-fairseq-ST" rel="noopener ugc nofollow" target="_blank">当前的主分支</a>不兼容，主要是因为在此期间对Fairseq进行了重大重写，当前的维护者必须跟上它。</p><p id="4f46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决方案是开发你自己的独立项目，但是这会增加开发成本，而且世界上其他开发最新特性的人不会给你免费的午餐。对于小团队来说，这可能很难实现，但是减少我们自己对其他项目的依赖是值得的，特别是当它们处于活跃的开发阶段并且不稳定的时候。</p><p id="a144" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特定领域工具的另一个缺点是，组织中有多个团队在为不同的任务进行深度学习。不同的团队将最终为他们的深度学习生命周期使用不同的代码库。这样的代码库是独立的，但不是完全不相关的，因为它们主要是关于训练和测试DL模型的。这种情况导致工作重复，一方很少或没有分享最佳做法；当一个团队的成员被要求使用另一个团队的工具时，会有很大的认知负荷。</p><p id="4616" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重复的工作出现在训练循环中，最近的优化器仍然不是框架的一部分，还有transformer层的实现。认知负荷来自理解代码的深度学习部分，但对特定领域了解甚少。项目之间不同的代码结构和架构，以及个人对代码的期望，都放大了这种混乱。</p><p id="650e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当谈到让团队通过共享平台进行交流时，一个可能的解决方案是使用公共的机器学习引擎。</p><h2 id="4953" class="mz md it bd me na nb dn mi nc nd dp mm li ne nf mo lm ng nh mq lq ni nj ms nk bi translated">机器学习引擎</h2><p id="07f3" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">机器学习引擎的主要思想是，它支持数据加载和批处理、模型定义、训练和推理的广泛通用操作，以便它可以被从事不同任务的多个团队使用和优化。每个团队将只需要关注数据处理的代码，这取决于任务，并且不够通用，不能在引擎代码中完成。</p><p id="4848" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这类软件的唯一例子是<a class="ae ky" href="https://github.com/rwth-i6/returnn" rel="noopener ugc nofollow" target="_blank"> Returnn </a>，这是一个考虑到序列间问题而开发的机器学习引擎。Returnn基于Tensorflow，但在兼容模式下使用其低级API，不太依赖于开发趋势。</p><p id="848f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，通过使用低级API，它生成包含自己的搜索算法的模型图，这些算法也在Returnn中定义，因此不需要额外的代码来服务它们。</p><p id="1b5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其工作方式是，引擎将定义训练和验证数据、模型定义和训练超参数的配置文件作为输入。然后，团队的责任是准备他们需要的特定任务处理的数据，并维护模型。数据加载、训练和推理都由任务无关引擎管理。</p><p id="9142" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型被定义在一个由引擎解释的高级抽象中，但并不真正需要它作为一个依赖。在版本控制下，配置文件可以很容易地存储在团队拥有的存储库中，也许最重要的是，它们可以很容易地在团队之间共享，因为底层平台是完全相同的。</p><p id="6bc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个相关的优点在于可维护性。团队不需要维护他们自己的机器学习工具。这种方法可以防止一些工具被放弃，然后最终使用旧的tensorflow或pytorch版本，使它们难以更新。使用Returnn，配置文件很难变旧，而且当它们变旧时，更新它们的工作量比更新整个平台要少得多，而所有的维护工作都是保持Returnn最新。</p><p id="c36c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主要的问题是，由于所有的训练周期和从配置中创建的模型都需要返回，所以在不修改代码的情况下做一些高度实验性的事情会变得很困难。</p><p id="8b27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，为了维护团队之间的公共平台，它的维护应该是团队之间的共同努力，或者委托给专门的团队。在这两种情况下，所有涉众之间都需要强有力的沟通，以保持工具的相关性和对每个人都有用。如果做不到这一点，软件就不再对每个人都有用，但当它成功完成时，它可以从团队中释放出很多能量，因为他们可以专注于解决他们的问题，而不是开发通用的深度学习代码。</p><p id="80cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，需要将它与Keras这样的高级工具进行比较。Keras为整个深度学习生命周期提供了许多功能，也包括Returnn的优点。它们的设计是不同的，因为Returnn是一个独立的软件，而Keras是一个开发深度学习工具的框架。然后，Keras将被用于构建特定任务的工具，回到我们上面提到的同样的问题，但是维护工作要少得多，因为它是由Google支持的开源软件。</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/getting-started-with-end-to-end-speech-translation-3634c35a6561"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">开始使用端到端语音翻译</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">使用Pytorch，您只需几个步骤就可以翻译英语演讲</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ks oc"/></div></div></a></div><h1 id="cb32" class="mc md it bd me mf os mh mi mj ot ml mm jz ou ka mo kc ov kd mq kf ow kg ms mt bi translated">综合</h1><p id="8cd2" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">总的来说，这是一个团队组织和优先事项的问题。如果有可能在团队间共享单一工具，那么共同工作的中央引擎可以让科学家们更多地关注他们的问题。它允许轻松地共享代码和最佳实践，但它需要团队之间的高度沟通。另一方面，如果团队差异太大而不能使用共享代码，或者不可能有专门的人来开发引擎，那么特定于任务的工具将确保更大的灵活性。</p><h1 id="ec31" class="mc md it bd me mf os mh mi mj ot ml mm jz ou ka mo kc ov kd mq kf ow kg ms mt bi translated">我的经历</h1><p id="a968" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">直到两年前，我只知道特定于任务的工具。我在三年内换了三次工具，试图通过寻找更快的模型训练或更容易的开发来最大化我的生产力。与旧的Nematus相比，OpenNMT-py在质量上是一个巨大的飞跃，首先是因为pytorch是一个比Theano更快(就模型训练而言)的框架，还因为代码的结构更好，更灵活。Fairseq实现了比OpenNMT-py更多的特性(值得注意的是，它是Transformer的一个工作实现，OpenNMT-py仍然缺乏它),并且训练速度也更快。然而，我认为开发者在一年内做了两个大的突破性的改变。这真的令人沮丧。</p><p id="0323" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我获得博士学位后开始目前的工作时，我接触了Returnn。最初，很难理解这种不同的哲学，但我开始越来越欣赏它，原因有几个:</p><ol class=""><li id="12ab" class="nl nm it lb b lc ld lf lg li nn lm no lq np lu ox nr ns nt bi translated">你的模型可以作为另一个团队发现的直接结果而改进</li><li id="56ae" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu ox nr ns nt bi translated">次要任务的工具可以留在开发中，而Returnn中的代码不能</li><li id="3852" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu ox nr ns nt bi translated">模型网络可以作为人工制品存储，并且完全独立于运行它的代码</li><li id="dde6" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu ox nr ns nt bi translated">我在不同任务和团队的交叉点上工作，对每种任务使用一个工具真的很好，不需要上下文切换</li><li id="cec1" class="nl nm it lb b lc nu lf nv li nw lm nx lq ny lu ox nr ns nt bi translated">得到的模型仍然是Tensorflow模型，没有深奥的格式，仍然可以很容易地集成到不同的应用程序中。</li></ol><h1 id="c857" class="mc md it bd me mf os mh mi mj ot ml mm jz ou ka mo kc ov kd mq kf ow kg ms mt bi translated">结论</h1><p id="c8db" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">当前可应用的深度学习前景由围绕深度学习框架构建的工具统治，这些工具专门用于单个或几个任务。它们在实现框架、一些设计选择和对外部依赖的依赖上有所不同。但是，它们在主要的设计思想上都是相似的。</p><p id="a31f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我想分享另一种构建深度学习工具的选择，使用Returnn的例子，这是我所知道的唯一一个深度学习引擎。它展示了开发深度学习工具的另一种方式，这种方式在多个团队从事不同任务但在同一代码库上协作的环境中更有意义。</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/tips-for-reading-and-writing-an-ml-research-paper-a505863055cf"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">阅读和撰写ML研究论文的技巧</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">从几十次同行评审中获得的经验教训</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="oy l on oo op ol oq ks oc"/></div></div></a></div><h1 id="4ae2" class="mc md it bd me mf os mh mi mj ot ml mm jz ou ka mo kc ov kd mq kf ow kg ms mt bi translated">中等会员</h1><p id="3d3d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">你喜欢我的文章吗？你是否正在考虑申请一个中级会员来无限制地阅读我的文章？</p><p id="116b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您决定通过此链接订阅，您将通过您的订阅支持我，无需为您支付额外费用<a class="ae ky" href="https://medium.com/@mattiadigangi/membership" rel="noopener">https://medium.com/@mattiadigangi/membership</a></p></div></div>    
</body>
</html>