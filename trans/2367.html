<html>
<head>
<title>XGBoost: Cardinality, the crucial HyperParameter that is always under-considered</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">XGBoost:基数，总是被忽视的关键超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/xgboost-cardinality-the-crucial-hyperparameter-that-is-always-under-considered-31973126bc43#2022-05-24">https://towardsdatascience.com/xgboost-cardinality-the-crucial-hyperparameter-that-is-always-under-considered-31973126bc43#2022-05-24</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><figure class="gl gn jt ju jv jw gh gi paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="gh gi js"><img src="../Images/40a6b48d3d3801a357298b8853d70cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GaZUNWIBxDf4wAXw"/></div></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">照片由<a class="ae kh" href="https://unsplash.com/@patriceb?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">帕特里斯·布沙尔</a>在<a class="ae kh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><blockquote class="ki kj kk"><p id="9c3f" class="kl km kn ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj io bi translated"><strong class="ko iw">更新</strong>:发现我关于渐变提升的新书，<a class="ae kh" href="https://www.amazon.fr/dp/B0BJ82S916" rel="noopener ugc nofollow" target="_blank">实用渐变提升</a>。这是用python中的许多例子对渐变增强的深入探究。</p></blockquote><div class="lk ll gp gr lm ln"><a href="https://www.amazon.com/dp/B0BJ82S916" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab fo"><div class="lp ab lq cl cj lr"><h2 class="bd iw gy z fp ls fr fs lt fu fw iu bi translated">实用的渐变增强:深入探究Python中的渐变增强</h2><div class="lu l"><h3 class="bd b gy z fp ls fr fs lt fu fw dk translated">这本书的梯度推进方法是为学生，学者，工程师和数据科学家谁希望…</h3></div><div class="lv l"><p class="bd b dl z fp ls fr fs lt fu fw dk translated">www.amazon.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb kb ln"/></div></div></a></div><p id="13dd" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在处理超参数调整时，大多数注意力都集中在过度拟合和使用正确的正则化参数上，以确保模型不会过度学习。</p><p id="3347" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">然而，还有一个非常重要的问题要问:预测空间的基数是多少？换句话说，XGBoost和更一般的决策树可以预测多少不同的值？</p></div><div class="ab cl mf mg hz mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="io ip iq ir is"><h1 id="42f5" class="mm mn iv bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">XGBoost和boosted树是离散模型</h1><p id="6281" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">当使用XGBoost、CatBoost或LightGBM时，记住所有这些库都依赖决策树是绝对重要的，决策树的叶子只包含常量值(除非您已经为LightGBM启用了线性树。参见我关于主题的另一篇文章<a class="ae kh" href="https://medium.com/p/197864013e88" rel="noopener">。)</a></p><p id="2cab" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">简单地说，这意味着给定的模型只能预测离散数量的值。其他模型，例如高斯过程或基本线性模型，可以预测无限数量的值。</p><p id="9145" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">下面的代码和图表说明了:</p><figure class="np nq nr ns gt jw"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">显示梯度增强树的离散性质。作者代码。</p></figure><p id="1002" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">梯度推进树的离散性质是明确的，如上面代码生成的图所示:</p><figure class="np nq nr ns gt jw gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/b096e747ff756999bca8a36f1410af26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*R3UjAaG8CoaXEjyuiRKxcw.png"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">梯度增强树的离散性质。剧情作者。</p></figure><p id="8a56" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">梯度推进树只能预测一组有限的离散值。</p><h1 id="9351" class="mm mn iv bd mo mp nw mr ms mt nx mv mw mx ny mz na nb nz nd ne nf oa nh ni nj bi translated">为什么要关心基数？</h1><p id="31b7" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">基数很重要，原因有二:</p><ul class=""><li id="8abb" class="ob oc iv ko b kp kq kt ku mc od md oe me of lj og oh oi oj bi translated">它与你的预测集的基数直接相关。比方说，你需要预测<code class="fe ok ol om on b">n</code>种工作和<code class="fe ok ol om on b">m</code>个国家的收入。如果你的模型预测小于<code class="fe ok ol om on b">n*m</code>值，你的模型很可能无法正确预测收入。可能的预测集不够大，不足以捕捉现实的复杂性。</li><li id="2eee" class="ob oc iv ko b kp oo kt op mc oq md or me os lj og oh oi oj bi translated">这是过度拟合的一个很好的指标。如果您的模型基数比您的预测集的基数高得多，那么您的模型可能会过度拟合。</li></ul><h1 id="0e3b" class="mm mn iv bd mo mp nw mr ms mt nx mv mw mx ny mz na nb nz nd ne nf oa nh ni nj bi translated">计算梯度提升树的基数</h1><p id="dfe3" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">计算梯度增强树模型可以生成的预测基数并不容易。这取决于每棵树的结构，以及每个决策节点做出的决策。</p><p id="c7cc" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">在只有一个估计器的简单树集合的情况下，计算是简单的。有多少树叶，就有多少种可能的预测。如果树是完整的，即如果每个分支都达到了最大深度，则叶子的数量等于<code class="fe ok ol om on b">2^max_depth</code>。</p><p id="3874" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">当有<code class="fe ok ol om on b">n</code>个估计器时，理论上讲，第一棵树的每个可能的预测可以被第二棵树带来的任何校正更新，第二棵树又可以被第三棵树带来的任何校正更新，等等。因此，从理论上讲，梯度助推器树可以产生高达</p><figure class="np nq nr ns gt jw gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/e1feba40a71db0fa8a783fc81afd6f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*SgC7Md8gt9LKwf5mfNE9Ng.png"/></div><p class="kd ke gj gh gi kf kg bd b be z dk translated">作者的公式</p></figure><p id="fae7" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">实际上，这个值是一个上限，因为对于一组特征来说，每棵树相对于其他树都不是独立的。</p><p id="6683" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">实际上，考虑第一棵树的一片叶子，特征区间的笛卡儿积允许到达这些叶子。因此，当特征在这些间隔中变化时，第一个树的响应总是相同的值。</p><p id="468f" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">当在这些范围内改变特征时，可以到达其他树的每片叶子的几率很低。这解释了为什么上面的公式显然是一个最大值，因为只有叶子的子集是可达的。</p><h1 id="d9bb" class="mm mn iv bd mo mp nw mr ms mt nx mv mw mx ny mz na nb nz nd ne nf oa nh ni nj bi translated">驱动梯度提高了树基数</h1><p id="57d0" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">为了控制模型基数而调整的超参数与导致过度拟合的参数相同。基于上一节的解释，我们看到基本的<code class="fe ok ol om on b">n_estimators</code>和<code class="fe ok ol om on b">max_depth</code>可以用于引导基数。</p><p id="21cb" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated"><code class="fe ok ol om on b">gamma</code>和<code class="fe ok ol om on b">lamda</code>，因为它们控制节点分裂也可以使用。如果您使用的是LightGBM，那就更简单了，因为有一个参数<code class="fe ok ol om on b">num_leaves</code>，它定义了给定估计器的最大叶子数，而不管深度如何。</p></div><div class="ab cl mf mg hz mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="io ip iq ir is"><h1 id="a903" class="mm mn iv bd mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh ni nj bi translated">结论</h1><p id="f07a" class="pw-post-body-paragraph kl km iv ko b kp nk kr ks kt nl kv kw mc nm kz la md nn ld le me no lh li lj io bi translated">基数是基于梯度提升树的模型的基本特征，必须根据要预测的值的基数进行分析。</p><p id="1512" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">这是梯度增强树的离散性质的直接结果。</p><p id="4db7" class="pw-post-body-paragraph kl km iv ko b kp kq kr ks kt ku kv kw mc ky kz la md lc ld le me lg lh li lj io bi translated">重要的是要确保生成的模型有足够的自由度来为预测过程中考虑的每个不同情况生成不同的值。</p></div></div>    
</body>
</html>