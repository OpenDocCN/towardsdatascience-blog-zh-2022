<html>
<head>
<title>Speech Recognition for Analytics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于分析的语音识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speech-recognition-for-analytics-e98c1e496873#2022-02-12">https://towardsdatascience.com/speech-recognition-for-analytics-e98c1e496873#2022-02-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0e1097272214b2a62083912ac583b19d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SZspFdk_4FHrHaaU"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梁杰森</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="e05b" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">利用语音到文本处理充分利用您的音频数据</h2></div><p id="94db" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了在竞争中占据优势，企业正在收集比以往更多的数据。大数据架构使这种增长成为可能，促进了海量和多种数据的快速捕获。除了常规的表格数字事务，我们还可以看到事件日志、文本消息，甚至是<strong class="la jk">多媒体内容</strong>。</p><p id="5a54" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果适当利用这些多媒体内容，可以为你所在的企业带来<strong class="la jk">额外的关键洞察力</strong>。想象一下，如果您可以从客户服务电话中分析客户的主要问题和最常用的解决方案，或者在您的电子商务平台上消除垃圾/无关的文本/图像/视频评论。在本文中，我们将重点关注<strong class="la jk">音频分析</strong>，特别是<strong class="la jk">处理/转录它们</strong>，以便使用文本自然语言处理(NLP)工具进行进一步分析。</p><p id="ac99" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">本次分析使用的完整代码共享在</em><a class="ae jg" href="https://github.com/oliviatan29/speech-recognition-analysis/tree/main" rel="noopener ugc nofollow" target="_blank"><em class="lu">this Github project</em></a><em class="lu">下。</em></p><p id="95b8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文旨在使用Python中的语音识别库。如果你有兴趣了解更多关于音频数据内在的、与波形相关的特性，你可以查看<a class="ae jg" href="https://medium.com/towards-data-science/get-to-know-audio-feature-extraction-in-python-a499fdaefe42" rel="noopener">这篇文章</a>。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="2a01" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">音频文件的预处理</h1><p id="edf7" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">Python中的大多数音频处理库要求音频文件为<strong class="la jk">波形(。wav)格式</strong>进行处理。WAV本身是最受欢迎的数字音频格式之一，因为它具有无损文件特性，不同于已经被压缩的mp3/m4a。因此，如果您的音频文件不是WAV格式，建议您在继续分析之前先将其转换为WAV格式。</p><p id="6e4c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在Python中，我们可以使用<a class="ae jg" href="https://github.com/jiaaro/pydub" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> pydub </strong> </a>包进行音频文件的转换。从输入文件创建AudioSegment实例并使用“导出”功能导出所需的输出文件非常简单。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="04e7" class="ni md jj ne b gy nj nk l nl nm">from pydub import AudioSegment</span><span id="1d32" class="ni md jj ne b gy nn nk l nl nm">AudioSegment.converter = "Downloads/ffmpeg"<br/>AudioSegment.ffmpeg = "Downloads/ffmpeg"<br/>AudioSegment.ffprobe ="Downloads/ffprobe"</span><span id="ed2f" class="ni md jj ne b gy nn nk l nl nm">from pydub.playback import play</span><span id="4fdd" class="ni md jj ne b gy nn nk l nl nm"># Create an AudioSegment instance<br/>raw_file = AudioSegment.from_file(file="Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.ogg", format="ogg")</span><span id="9a56" class="ni md jj ne b gy nn nk l nl nm"># Check the type<br/>print(type(raw_file))</span><span id="ed7e" class="ni md jj ne b gy nn nk l nl nm"># Export the .ogg file as wav<br/>raw_file.export(out_f="Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.wav",<br/>                format="wav")</span></pre><p id="b083" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除了转换文件格式，pydub包还可以用于其他音频文件操作，如扩展/附加音频文件，分割音频文件，增加音量，或设置淡出过渡。</p><h1 id="6224" class="mc md jj bd me mf no mh mi mj np ml mm kp nq kq mo ks nr kt mq kv ns kw ms mt bi translated">通用音频功能探索</h1><p id="fb26" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">现在我们有了正确的输入文件格式，我们可以通过查看音频文件的一般属性来开始我们的音频分析，如音频文件本身的<strong class="la jk"><em class="lu"/></strong>(声压的强度或级别)<strong class="la jk"><em class="lu"/></strong>(单位时间的振动)，或<strong class="la jk"> <em class="lu">长度</em> </strong>。</p><p id="ec07" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个分析中，我使用了来自Wikimedia的两个开放许可的音频文件:</p><ul class=""><li id="cccb" class="nt nu jj la b lb lc le lf lh nv ll nw lp nx lt ny nz oa ob bi translated"><a class="ae jg" href="https://commons.wikimedia.org/wiki/File:2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.ogg" rel="noopener ugc nofollow" target="_blank">美国之音新闻报道——国际足联将重新审查世界杯裁判失误后的录像回放。ogg </a>归<a class="ae jg" href="https://www.voanews.com/" rel="noopener ugc nofollow" target="_blank">美国之音新闻</a>公有领域</li><li id="2713" class="nt nu jj la b lb oc le od lh oe ll of lp og lt ny nz oa ob bi translated"><a class="ae jg" href="https://commons.wikimedia.org/wiki/File:Aldi_-_Indonesian_language_-_Bible_Verse_John_3-16.ogg" rel="noopener ugc nofollow" target="_blank"> Aldi —印度尼西亚语—圣经·约翰福音3–16 . ogg</a>可在<a class="ae jg" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">知识共享</a> <a class="ae jg" href="https://creativecommons.org/publicdomain/zero/1.0/deed.en" rel="noopener ugc nofollow" target="_blank"> CC0 1.0通用公共领域专用</a>下获得</li></ul><p id="85d0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些文件源的详细信息可以在本文末尾找到(参考资料部分)。</p><p id="f04d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以使用Python中的<a class="ae jg" href="https://librosa.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="la jk"> librosa </strong> </a>包来提取音频文件特征。Librosa是一个扩展包，允许我们提取各种音频文件属性，从振幅/频率等直接属性到更高级的导数属性，如<a class="ae jg" href="https://en.wikipedia.org/wiki/Zero-crossing_rate" rel="noopener ugc nofollow" target="_blank">过零率</a>和<a class="ae jg" href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum" rel="noopener ugc nofollow" target="_blank">梅尔频率倒谱系数(MFCCs) </a>。它还允许各种可视化，从常规的线形图到<a class="ae jg" href="https://en.wikipedia.org/wiki/Spectrogram" rel="noopener ugc nofollow" target="_blank">光谱图</a>格式。</p><p id="c62d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是在librosa中生成振幅可视化的代码。从可视化中，我们可以看到从文件的开始到大约2.30分钟的整个过程中相当一致的信号。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="efc5" class="ni md jj ne b gy nj nk l nl nm">import librosa<br/>import librosa.display</span><span id="0b99" class="ni md jj ne b gy nn nk l nl nm">y, sr = librosa.load('Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.wav', mono=False)</span><span id="8861" class="ni md jj ne b gy nn nk l nl nm">fig, ax = plt.subplots(figsize=(15, 3))<br/>img = librosa.display.waveshow(y, sr=sr, ax=ax)</span><span id="e43c" class="ni md jj ne b gy nn nk l nl nm">ax.set(title='Envelope view, stereo')<br/>ax.label_outer()</span><span id="56af" class="ni md jj ne b gy nn nk l nl nm">plt.show()</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oh"><img src="../Images/7d73e6b2ce295f8ad64f729b42299932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiKKcN8hPzTPdxaxutWITw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">美国之音新闻文件的振幅图</p></figure><p id="0faa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是在librosa中生成频谱图的代码。从这个图像中，我们可以看到音频文件的5个大片段。有一个是从0:00到0:08，然后从0:08到0:25，然后从0:25到1:17，然后从1:17到1:30，然后1:30到文件结尾。如果我们听音频文件，这些片段<strong class="la jk">代表文件</strong>的变化设置——在清晰的录音室录音和轻微嘈杂的现场采访之间。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="c142" class="ni md jj ne b gy nj nk l nl nm"># Load audio file to Librosa<br/>y, sr = librosa.load('Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.wav')</span><span id="e7b8" class="ni md jj ne b gy nn nk l nl nm"># Converts data into short term Fourier transform. <br/># STFT converts signals such that we can know the amplitude of the given frequency at a given time<br/>D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)</span><span id="f688" class="ni md jj ne b gy nn nk l nl nm"># Display spectogram<br/>fig, ax = plt.subplots(figsize=(15, 3))<br/>img = librosa.display.specshow(D, y_axis='log', x_axis='time', sr=sr)<br/>ax.set(title='Logarithmic-frequency power spectrogram')<br/>ax.label_outer()</span><span id="3882" class="ni md jj ne b gy nn nk l nl nm">plt.colorbar()</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oi"><img src="../Images/b602323ceeccf7e5bf69d560e151b251.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wpDyXsRAwg9rIpTzWPIRTQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">美国之音新闻音频的对数频率频谱图</p></figure><h1 id="1bb3" class="mc md jj bd me mf no mh mi mj np ml mm kp nq kq mo ks nr kt mq kv ns kw ms mt bi translated">语音识别</h1><p id="bd64" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">在探索了一般的音频功能之后，是时候进入这个项目令人兴奋的亮点了——<em class="lu">语音识别部分</em>！</p><p id="1e10" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很简单，你可以<strong class="la jk"> <em class="lu">将你的音频文件运行到一个预先确定的引擎中，以获得文本转录</em> </strong>。我们在这个转录过程中使用Python中的<a class="ae jg" href="https://github.com/Uberi/speech_recognition" rel="noopener ugc nofollow" target="_blank">语音识别</a>库。它支持多种语音识别引擎，如<a class="ae jg" href="https://cmusphinx.github.io/wiki/" rel="noopener ugc nofollow" target="_blank"> CMU斯芬克斯</a>、<a class="ae jg" href="https://cloud.google.com/speech-to-text" rel="noopener ugc nofollow" target="_blank">谷歌云语音API </a>、<a class="ae jg" href="https://www.microsoft.com/cognitive-services/en-us/speech-api" rel="noopener ugc nofollow" target="_blank">微软必应语音识别</a>和<a class="ae jg" href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/speech-to-text.html" rel="noopener ugc nofollow" target="_blank"> IBM语音转文本</a>。请注意，其中一些引擎需要使用API令牌。对于这个项目，我们使用<strong class="la jk">谷歌语音识别和默认的API键</strong>。</p><h2 id="0a51" class="ni md jj bd me oj ok dn mi ol om dp mm lh on oo mo ll op oq mq lp or os ms ot bi translated">语音识别功能</h2><p id="f3b5" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">语音识别库有一个<strong class="la jk">识别器</strong>类，它有一组用于语音识别设置和功能的内置函数。</p><p id="5afa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们导入库并设置识别器。然后，我们导入要转录的音频文件。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="19df" class="ni md jj ne b gy nj nk l nl nm">import speech_recognition as sr</span><span id="c4ff" class="ni md jj ne b gy nn nk l nl nm"># Set up recognizer<br/>r = sr.Recognizer()</span><span id="8b87" class="ni md jj ne b gy nn nk l nl nm"># Import Audio data<br/>test_audio = sr.AudioFile('Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.wav')</span></pre><p id="b18f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从这里开始，我们可以使用<code class="fe ou ov ow ne b">recognize_google</code>函数直接进行转录，该函数接受音频文件输入并给出转录作为输出。然而，根据您的音频文件的<strong class="la jk">质量，其他一些功能可以用来增强您的音频文件，从而提供更好的转录。</strong></p><p id="de26" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">如果您的音频文件包含一些您不需要转录的不必要内容</strong>，您可以使用<code class="fe ou ov ow ne b">record </code>功能中的“持续时间”和“偏移量”变量来选择要转录的音频文件的特定部分。</p><p id="6698" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">如果您的音频文件有噪音</strong>，您可以使用<code class="fe ou ov ow ne b">adjust_for_ambient_noise</code>功能校准环境噪音水平的能量阈值。校准允许识别器忽略噪声并专注于实际语音。</p><p id="ebba" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是VOA新闻音频文件的语音识别代码。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="433d" class="ni md jj ne b gy nj nk l nl nm"># Set up recognizer<br/>r = sr.Recognizer()</span><span id="d567" class="ni md jj ne b gy nn nk l nl nm"># Import Audio data<br/>test_audio2 = sr.AudioFile('Downloads/2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.wav')</span><span id="6d1d" class="ni md jj ne b gy nn nk l nl nm"># Covert the AudioFile to AudioData, adjust for noise, cut by duration<br/>with test_audio2 as source2:<br/>    r.adjust_for_ambient_noise(source)<br/>    audio2 = r.record(source2, duration=60)<br/>    audio3 = r.record(source2, duration=60)<br/>    audio4 = r.record(source2)</span><span id="4507" class="ni md jj ne b gy nn nk l nl nm"># Generate transcription<br/>text_audio = r.recognize_google(audio2) + " " + r.recognize_google(audio3) + " " + r.recognize_google(audio4)<br/>text_audio</span></pre><p id="0814" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">它将生成如下转录文本。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ox"><img src="../Images/95835b459f8f245d65d3e86e0f6beb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VEu69jKK79jP3T8su9cmlA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">美国之音新闻音频的语音识别转录</p></figure><p id="af87" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">语音识别引擎可能有几种来自不同识别技术的转录结果。识别器类自动地<strong class="la jk">挑选具有最高置信度得分的一个</strong>。如果你想检查其他的转录结果，你可以在<code class="fe ou ov ow ne b">recognize_google</code>函数中添加<code class="fe ou ov ow ne b">show_all=True</code>变量。</p><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oy"><img src="../Images/4431796099c6ec0297d3f80865c8514e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jj1_vUT58DzwF4tmv2Iicw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">有各种转录结果可用</p></figure><p id="6960" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">关于语音识别库的更多细节，你可以在这里浏览他们的文档<a class="ae jg" href="https://pypi.org/project/SpeechRecognition/" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="c67e" class="ni md jj bd me oj ok dn mi ol om dp mm lh on oo mo ll op oq mq lp or os ms ot bi translated">非英语语言的语音识别</h2><p id="96d0" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">语音识别也允许识别一些非英语语言。在这种情况下，你只需要在<code class="fe ou ov ow ne b">recognize_google</code>函数中添加<code class="fe ou ov ow ne b">language="id-ID"</code>变量。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="3d16" class="ni md jj ne b gy nj nk l nl nm"># Set up recognizer<br/>r = sr.Recognizer()</span><span id="3ff0" class="ni md jj ne b gy nn nk l nl nm"># Import Audio data<br/>test_audio = sr.AudioFile('Downloads/Aldi_-_Indonesian_language_-_Bible_Verse_John_3-16.wav')<br/>with test_audio as source:<br/>    r.adjust_for_ambient_noise(source)<br/>    audio = r.record(source)<br/>    <br/>r.recognize_google(audio, language="id-ID", show_all=True)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oz"><img src="../Images/417c7c19b4f5ad41fa5e1d0f57bf0337.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6nQNj4SLH1ZFHPYYFRLNTQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">非英语(印度尼西亚语)语言的转录结果</p></figure><p id="99f3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此处列出了可用语言的列表<a class="ae jg" href="https://stackoverflow.com/questions/14257598/what-are-language-codes-in-chromes-implementation-of-the-html5-speech-recogniti/14302134#14302134" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="2961" class="ni md jj bd me oj ok dn mi ol om dp mm lh on oo mo ll op oq mq lp or os ms ot bi translated">使用标点符号</h2><p id="b48b" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">从上面的结果可以看出，语音转录是以纯文本的形式交付的，没有任何格式。如果你在抄写一篇冗长的演讲或对话，这可能会令人困惑。</p><p id="0445" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我偶然发现了<a class="ae jg" href="https://pypi.org/project/punctuator/" rel="noopener ugc nofollow" target="_blank">标点符号</a>库，可以用来在文本文件上标注标点符号，提高转录的可读性。使用起来非常简单，你只需要运行<code class="fe ou ov ow ne b">punctuate</code>函数，就可以得到带注释的文本。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="00cb" class="ni md jj ne b gy nj nk l nl nm">from punctuator import Punctuator</span><span id="3ac3" class="ni md jj ne b gy nn nk l nl nm">p = Punctuator('Downloads/INTERSPEECH-T-BRNN.pcl')<br/>text_audio_punc = p.punctuate(text_audio)<br/>text_audio_punc</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pa"><img src="../Images/7940f7203c39422f7853d933660ca1f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOB_nqC69F46OUZVwb8dMg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">标点转录结果</p></figure><p id="8fe2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在某些情况下，注释可能无法完美地工作，但它确实有助于提高可读性。</p><h1 id="1b4e" class="mc md jj bd me mf no mh mi mj np ml mm kp nq kq mo ks nr kt mq kv ns kw ms mt bi translated">语言分析</h1><p id="52ba" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">现在以文本格式的形式，你可以<strong class="la jk">将各种自然语言处理技术</strong>应用到你的音频转录中。可能性是无穷的，从做情感分析，话题抽取，分类等等。</p><p id="a792" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在这个项目中，我只是使用<a class="ae jg" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">空间</a>提供了一个简单的<a class="ae jg" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank">命名实体识别</a>的例子，这对主题/对象分析和分类很有用。</p><pre class="mz na nb nc gt nd ne nf ng aw nh bi"><span id="f99c" class="ni md jj ne b gy nj nk l nl nm">import spacy</span><span id="8cb9" class="ni md jj ne b gy nn nk l nl nm"># Load spaCy language model<br/>nlp = spacy.load("en_core_web_sm")</span><span id="361a" class="ni md jj ne b gy nn nk l nl nm"># Set up the transcribed text as doc<br/>doc = nlp(text_audio_punc)</span><span id="770c" class="ni md jj ne b gy nn nk l nl nm"># Find named entities in doc<br/>for entity in doc.ents:<br/>    print(entity.text, entity.label_)</span></pre><figure class="mz na nb nc gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pb"><img src="../Images/610e0fb932522f78729b8c2fb62171ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FvSjS5E-5Jz0BRrMs0F-4A.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">命名实体识别结果空间</p></figure><p id="25c5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看该结果，我们可以确定音频文件正在谈论世界杯事件(来自国际足球协会和世界杯实体)，其中提到了国家之间的一些比赛(来自国家名称和一些球员姓名实体)。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="2de6" class="mc md jj bd me mf mg mh mi mj mk ml mm kp mn kq mo ks mp kt mq kv mr kw ms mt bi translated">结束语</h1><p id="3058" class="pw-post-body-paragraph ky kz jj la b lb mu kk ld le mv kn lg lh mw lj lk ll mx ln lo lp my lr ls lt im bi translated">包括音频数据在内的多媒体数据虽然已经被收集，但还没有被普遍用于产品和商业分析。有一些Python库包可以用来从这些音频数据中提取特征，包括使用语音识别技术的内容；允许我们<strong class="la jk">从这些音频数据</strong>中获得最大收益。一旦转录成文本，这些数据就可以利用自然语言处理技术用于各种目的。可用性各不相同，从通过情感分析了解客户满意度，从客户服务电话评估关注的话题，到从平台删除垃圾/辱骂内容，等等。如果您已经有了数据(或者在收集和存储它们方面没有任何困难)，为什么不充分利用这些数据来进行产品分析呢？</p><p id="5a7e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">本分析中使用的完整代码共享在</em><a class="ae jg" href="https://github.com/oliviatan29/speech-recognition-analysis/tree/main" rel="noopener ugc nofollow" target="_blank"><em class="lu">this Github project</em></a><em class="lu">下。</em></p><p id="de29" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">使用的音频参考</strong></p><p id="dc19" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[1] <a class="ae jg" href="https://commons.wikimedia.org/wiki/File:2010-06-29_VOA_News_report_-_FIFA_to_Re-Examine_Video_Replays_After_World_Cup_Referee_Mistakes.ogg" rel="noopener ugc nofollow" target="_blank">美国之音新闻报道——国际足联重新审查世界杯裁判失误后的录像回放。该媒体在美国属于公共领域，因为它完全由美国联邦政府官方对外广播机构美国之音制作和提供的材料组成。</a></p><p id="d494" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2] <a class="ae jg" href="https://commons.wikimedia.org/wiki/File:Aldi_-_Indonesian_language_-_Bible_Verse_John_3-16.ogg" rel="noopener ugc nofollow" target="_blank">阿尔迪语——印尼语——圣经约翰福音3–16节. ogg</a>；根据<a class="ae jg" href="https://en.wikipedia.org/wiki/en:Creative_Commons" rel="noopener ugc nofollow" target="_blank">知识共享协议</a>许可<a class="ae jg" href="https://creativecommons.org/publicdomain/zero/1.0/deed.en" rel="noopener ugc nofollow" target="_blank"> CC0 1.0通用公共领域专用</a></p></div></div>    
</body>
</html>