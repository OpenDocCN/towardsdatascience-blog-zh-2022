<html>
<head>
<title>5 Sneaky Ways Bias Can Affect Your Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">偏见会影响你的机器学习模型的5种偷偷摸摸的方式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-sources-of-bias-in-ai-ml-729acbec3215#2022-09-16">https://towardsdatascience.com/5-sources-of-bias-in-ai-ml-729acbec3215#2022-09-16</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="d0e9" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">发现你的模型中隐藏的偏见并修正它们</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/9c1d1dca2c6a221fec227231098de6a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xFS17j6Wumn-jlct"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">由<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kz" href="https://unsplash.com/@vackground?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">真空背景</a>拍摄</p></figure><p id="03cf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们现在应该使用更多的人工智能解决方案。但是有这个偏见问题要考虑！</p><p id="298f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们已经看到人工智能模型对代表性不足的群体表现不同。近年来，这些问题引起了激烈的辩论。在寻找产生偏见的原因时，我们发现，除了人类训练员的意图之外，还有更多方式可以导致偏见。</p><p id="6ea2" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">然而，当涉及到其他人的生活和工作时，造物主的清白是不可原谅的。顾客的反对、公众舆论和诽谤可能会损害你的声誉，而且可能很难恢复。</p><p id="f15d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">因此，理解人工智能偏见至关重要。你不能管理你不懂的东西。</p><p id="e924" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这里有五种情况，偏见可能会潜入你的模型。</p><h1 id="6e83" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">改变旧型号的用途是有用的，但也是危险的。</h1><p id="1305" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">可重用性是开发人员和组织的首要任务。机器学习模型的好处甚至更高。</p><p id="08b7" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">培训时间和资源消耗是公司采用人工智能实践的主要关注点。因此，重新利用旧模型或重用为不同目的构建的模型更有意义。</p><p id="d9bc" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当然，云计算和<a class="ae kz" href="https://www.techtarget.com/searchcloudcomputing/definition/Platform-as-a-Service-PaaS" rel="noopener ugc nofollow" target="_blank">平台即服务</a> (PAAS)解决方案已经彻底改变了数据科学。然而，我们训练的模型近年来也变大了。</p><p id="713d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">语言模型<a class="ae kz" href="https://openai.com/blog/gpt-3-apps/" rel="noopener ugc nofollow" target="_blank"> GPT3 </a>有1750亿个参数。训练这个模型大约需要460万美元。嗯，那不是每个人都能负担得起的。</p><p id="3499" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但是你可以花0.0004美元使用开放的AI API。那更实惠。更好的是，您可以针对您的特定用例对这些模型进行微调。</p><p id="2dbf" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">然而，你不知道这些模型被训练的原始数据集。盲目重用会在应用程序中引入偏见。</p><h2 id="764c" class="mt lx iu bd ly mu mv dn mc mw mx dp mg lj my mz mi ln na nb mk lr nc nd mm ne bi translated">现有模型的直接重用可能会引入偏差</h2><p id="9d9a" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">像Open AI的GPT-3一样，你可以在很多其他地方找到预训练的模型。<a class="ae kz" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank"> Keras文档</a>列出了一系列此类车型。您可以抓住一个并在类似的用例上使用它。</p><p id="0f0e" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">例如，您可以抓起VGG16，开始对图像进行分类。但它可能会将一个人标记为动物，因为模型没有看到足够多具有某些特征(例如，肤色)的人的例子。</p><p id="f6ea" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在不同的环境中使用它可能会产生偏见，即使这是你自己的模型。例如，你用美国输入训练的聊天机器人可能在澳大利亚用户身上表现更差。</p><p id="9d4d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">因此，最好不要在不同的上下文中重用模型，除非你100%确定它的所有后果。必要的时候，如果你能让<strong class="lc iv">人参与其中，</strong>就去做。在预测开始产生影响之前，你可以让所有的预测或者可信度较低的预测得到人类的验证。</p><p id="c28f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当然，并不是所有的应用程序都有人参与。如果是这样，使用迁移学习技术或集成方法更新模型是明智的。</p><h2 id="10cc" class="mt lx iu bd ly mu mv dn mc mw mx dp mg lj my mz mi ln na nb mk lr nc nd mm ne bi translated">使用迁移学习来更新模型，并为其提供上下文信息。</h2><p id="51ac" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">迁移学习是ML工程师重用现有模型的一种普遍做法。你可以在深度神经网络(DNN)上使用这种技术。</p><p id="20f1" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">本质上，如果你有一个识别图像中的狗的模型，转移学习就会训练它识别猫。毕竟，猫和狗有很多相似之处——四条腿、耳朵、尾巴等等。</p><p id="0ae3" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">您可以向DNN添加新图层，也可以解冻最后一个图层。然后用您的特定领域示例训练模型。</p><p id="7da8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">迁移学习是一种节省成本和时间的技术，可以产生更好的结果。在你将它们应用到新的环境之前，先在你的模型上使用它将会减少偏见的机会。</p><p id="cd74" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">你可以在我之前的文章中读到更多。</p><div class="nf ng gq gs nh ni"><a rel="noopener follow" target="_blank" href="/transfer-learning-in-deep-learning-641089950f5d"><div class="nj ab fp"><div class="nk ab nl cl cj nm"><h2 class="bd iv gz z fq nn fs ft no fv fx it bi translated">迁移学习:你能学到的最有效的深度学习技能。</h2><div class="np l"><h3 class="bd b gz z fq nn fs ft no fv fx dk translated">迁移学习是一种加速深度学习训练的惊人方法。它有助于解决复杂的问题…</h3></div><div class="nq l"><p class="bd b dl z fq nn fs ft no fv fx dk translated">towardsdatascience.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw kt ni"/></div></div></a></div><h2 id="871f" class="mt lx iu bd ly mu mv dn mc mw mx dp mg lj my mz mi ln na nb mk lr nc nd mm ne bi translated">使用集合来移除模型中不必要的偏差。</h2><p id="0f09" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">集合意味着一组模型。如果已经有了预测猫的模型，可以附加一个额外的模型，增加一个新的职责——找狗。</p><p id="544a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果您使用的是为类似目的而训练的模型，则可以使用另一个模型并用新数据准备它，以最大限度地减少偏差。</p><h1 id="6edc" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">当你的模型从相互作用中学习时，偏见就产生了</h1><p id="fc54" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">当你的模型向你的用户学习时，你应该更加小心。</p><p id="34a0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><a class="ae kz" href="https://spectrum.ieee.org/in-2016-microsofts-racist-chatbot-revealed-the-dangers-of-online-conversation" rel="noopener ugc nofollow" target="_blank">微软的Twitter聊天机器人Tay </a>就是一个很好的案例研究。Tay一直在从Twitter与其他用户的对话中学习。但是这个机器人仅仅在几个小时后就被关闭了，因为Tay从其他用户那里选择了攻击性的语言，并开始像他们一样说话。</p><p id="6980" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果你的模型是从用户那里学习的，它就暴露在偏见的风险中。在主动学习中避免偏见仍处于研究阶段，我们还没有可靠的解决方法。因此，当你选择这个的时候，你应该更加小心。</p><p id="f7e5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果学习是分批进行的，你就可以控制它。在将新数据输入模型之前，您可以检查它们是否存在任何已知的偏差。此外，您可以在发布新版本的模型之前进行更多的检查。</p><p id="f9c9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">拥有一个<a class="ae kz" href="https://neptune.ai/blog/ml-model-registry" rel="noopener ugc nofollow" target="_blank">模型注册中心</a>是一个很好的实践。模型注册中心可以帮助您试验几种模型来解决同一个问题。当您在生产环境中发现一个模型有问题时，您可以很容易地切换到一个旧的模型，并将影响最小化。</p><p id="f493" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">但是，在主动学习模型中，比如进化的<a class="ae kz" href="https://ai.googleblog.com/2021/04/evolving-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">强化算法</a>，你把控制权留给了机器。</p><h1 id="ef0e" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">合成数据的使用可能会导致偏差。</h1><p id="f8d7" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">有时，合成或人工创建的数据被用于训练机器学习。虽然听起来可能违反直觉，但合成数据有很多用处。</p><p id="2e52" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当收集新数据很困难或成本很高时，工程师使用合成数据来训练ML模型。此外，当匿名很重要时，合成数据是有益的。</p><p id="a11a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">通常，合成数据生成会对变量的潜在概率分布进行建模，并从中提取新样本。</p><p id="69e6" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">随着合成数据对分布进行概化，它<strong class="lc iv">失去了数据集的原始上下文</strong>。因此，在偏见产生后果之前发现任何偏见的机会很小。</p><p id="24c9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这也是近年来大多数图像生成算法备受争议的原因之一。使用图像增强来训练神经网络是一种普遍的做法。避免过度合身是必要的。</p><p id="5f0c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">除了隐藏细节，合成数据增强还可以放大差异。有了更多的人工数据，你现在有更多的数据来代表你的主导类。</p><h1 id="1758" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">偏见可能隐藏在抽象的维度中。</h1><p id="9545" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">像合成数据一样，PCA等降维技术也掩埋了上下文，产生了抽象变量。这并不意味着我们应该避免这样的做法。但是要注意风险。</p><p id="5fc4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">它们使得在早期阶段很难理解输入变量和检测偏差。追溯抽象变量偏差的来源将是一个挑战。</p><p id="7325" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">想象一个场景，你建立一个模型来预测信用评分。您的输入数据集包含收入变量。PCA之后，您有PC1和PC2，…而不是标签。</p><p id="7f9c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">也许你会抽样调查低收入人群最有可能违约的人群。但是你永远不会知道这是一个抽样问题，因为变量是抽象的。</p><h1 id="0960" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">无法解释的模型导致无法解释的偏见。</h1><p id="69cd" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">偏见并不总是有偏见的数据集的产物。它还取决于模型从数据集中选择要素的方式。</p><p id="43fb" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">深度神经网络(DNN)最大的前景是自动特征选择。它非常有益，但也有缺点。你对你的DNN型号的特征选择没有多少控制力。</p><p id="0846" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">从A市开车到B市，只要安全准时到达B市，可能不太在乎路径。但在机器学习中，这很重要！</p><p id="8411" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">可解释的人工智能(XAI)近年来受到了很多关注，因为<a class="ae kz" href="https://levity.ai/blog/ai-bias-how-to-avoid" rel="noopener ugc nofollow" target="_blank">对人工智能模型对代表性不足群体的预测提出了</a>的担忧。</p><p id="6a5a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">话虽如此，我们不能忽视和回避DNN的好处。合理的基准是人的水平的表现。确保人类也能以同样的方式表演。当预测置信度较低时，过滤它们并尝试手动进行。</p><h1 id="5d16" class="lw lx iu bd ly lz ma mb mc md me mf mg ka mh kb mi kd mj ke mk kg ml kh mm mn bi translated">最后的想法</h1><p id="8b1e" class="pw-post-body-paragraph la lb iu lc b ld mo jv lf lg mp jy li lj mq ll lm ln mr lp lq lr ms lt lu lv in bi translated">将人工智能偏见的影响降至最低是数据科学界面临的一项挑战。</p><p id="ee5d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">至此，世界已经清楚地明白了AI的好处，想要前进。然而，我们已经看到了机器预测的几个问题，我们知道还有更多要学习的。</p><p id="fbc4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">算法天生没有偏见。但是他们从中学习的例子可以改变他们的行为。在这篇文章中，我们讨论了偏见进入你的模型的一些间接方式。</p></div><div class="ab cl nx ny hy nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="in io ip iq ir"><blockquote class="oe of og"><p id="9eb2" class="la lb oh lc b ld le jv lf lg lh jy li oi lk ll lm oj lo lp lq ok ls lt lu lv in bi translated">感谢阅读，朋友！在<a class="ae kz" href="https://www.linkedin.com/in/thuwarakesh/" rel="noopener ugc nofollow" target="_blank"><strong class="lc iv">LinkedIn</strong></a><a class="ae kz" href="https://twitter.com/Thuwarakesh" rel="noopener ugc nofollow" target="_blank"><strong class="lc iv">Twitter</strong></a><a class="ae kz" href="https://thuwarakesh.medium.com/" rel="noopener"><strong class="lc iv">Medium</strong></a>上跟我打招呼。</p><p id="5ec2" class="la lb oh lc b ld le jv lf lg lh jy li oi lk ll lm oj lo lp lq ok ls lt lu lv in bi translated">还不是中等会员？请使用此链接<a class="ae kz" href="https://thuwarakesh.medium.com/membership" rel="noopener"> <strong class="lc iv">成为会员</strong> </a>因为，在没有额外费用的情况下，我赚取了一点佣金。</p></blockquote></div></div>    
</body>
</html>