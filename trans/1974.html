<html>
<head>
<title>Hands on Climate Time Series Clustering using Machine Learning, with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习和Python进行气候时间序列聚类实践</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-climate-time-series-clustering-using-machine-learning-with-python-6a12ce1607f9#2022-05-05">https://towardsdatascience.com/hands-on-climate-time-series-clustering-using-machine-learning-with-python-6a12ce1607f9#2022-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1cd1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">下面介绍如何用很少几行代码使用机器学习对无标签的时间序列进行分类。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d5860d261939569d94f2c477efd06e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3P2yaPBWNZP8HsY0oUNw7A.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">乔纳森·鲍尔斯在<a class="ae kv" href="https://unsplash.com/s/photos/weather?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2f37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> T </span>何的第一堂机器学习课是这样开始的:</p><blockquote class="mb"><p id="f4f8" class="mc md iq bd me mf mg mh mi mj mk lr dk translated">在机器学习场景中有两种任务:分类和回归。</p></blockquote><p id="e4a0" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">假设你有一张图片，用数学术语来说就是一个矩阵，你想说这是一只猫还是一只狗的图片。这是一个<strong class="ky ir">分类</strong>问题，因为你当然是在对一个输入对象进行分类。</p><p id="03d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，给定一个输入对象，您可能想要获得一个<strong class="ky ir">实值</strong>。例如，给定一所房子某些特征，你可能想猜测它的价格。</p><p id="d6d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个非常简单的介绍，理解机器学习是关于什么的是有效和有见地的。隐藏的是，当我们考虑所谓的<strong class="ky ir">监督机器学习时，这种区别是真实的。</strong></p><p id="73ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管如此，机器学习算法的一个可能不太著名的应用是<strong class="ky ir">无监督的</strong>和对应的<strong class="ky ir">分类</strong>操作，对于<strong class="ky ir">未被标记为</strong>的数据，该操作被称为<strong class="ky ir">聚类。</strong></p><p id="e8cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">给定一个对象，你想对它进行分类，却不知道它可能有什么标签。让我们说得更清楚些。</p><p id="dbc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想象一下，你是一个<strong class="ky ir">外星人</strong>，你在一家杂货店里。<br/>即使你是<strong class="ky ir">外星人</strong>(我不知道是不是真的:)，你也可能会认出<strong class="ky ir">剃须刀片</strong>和<strong class="ky ir">苹果是不同的。这意味着你在对物品进行“分类”,即使你对它们的标签一无所知。<br/>这就是<strong class="ky ir">集群</strong>的作用。</strong></p><p id="febd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们有多种机器学习算法来完成聚类工作。最广为人知的叫做<strong class="ky ir"> </strong> <a class="ae kv" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> K的意思是</strong> </a> <strong class="ky ir">。</strong>我们来看看吧。</p><h1 id="3713" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">1.k-均值算法</h1><p id="9c21" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">好的，首先，我要说的是，有人非常详细地解释了K的意思，这不是我在这篇博文中打算做的。尽管如此，让我来介绍一下K均值算法的步骤。</p><p id="2873" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">看下面这张GIF:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/68e8b2771b55a98cab1478fdb9446e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/1*Nx6IyGfRAV1ly6uDGnVCxQ.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学分:Chire-Own work，CC BY-SA 4.0，<a class="ae kv" href="https://commons.wikimedia.org/w/index.php?curid=59409335" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=59409335</a></p></figure><p id="c82a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想象一下，就像我们说的，我们一开始没有任何标签。所以我们只有N个数据点。每个数据点由两个值组成:x和y。</p><p id="e54a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在(<strong class="ky ir">第一步</strong>)我们在这个二维空间内随机定义三个(一般为k个)点。我们称这k个数据点为“<strong class="ky ir">质心</strong>”。<br/><strong class="ky ir">第二步</strong>是根据数据点和三个(一般也是k)质心之间的距离对每个数据点进行“分类”。假设这个新的点<strong class="ky ir"> x </strong>，我们有三个质心之间的距离值。让我们称这个距离值为D1，D2和D3。我们根据d_1，d_2，d_3的argmin把这个点分为1，2，3。比如如果d_1 &lt; d_2 &lt; d_3 或者<strong class="ky ir"> d_1 &lt; d_2 &gt; d_3就会归类为<strong class="ky ir"> 1。<br/> </strong>接下来我们要做的(<strong class="ky ir">第三步</strong>)是通过考虑分类为1、2或3的所有点的平均值来更新这个质心的值。<br/>第<strong class="ky ir">第四步</strong>是返回到<strong class="ky ir">第二步</strong>L次，其中L为迭代次数。</strong></p><h1 id="e277" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">2.时间序列聚类</h1><p id="0787" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">当然，K均值算法也可以应用于<strong class="ky ir">时间序列</strong>。我们唯一要考虑的是数据集的维数是M，其中M是时间序列的长度。不管怎样，我们可以做得更好。:)</p><p id="5c41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，Python中有一个库叫做<a class="ae kv" href="https://tslearn.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> tslearn </strong> </a> <strong class="ky ir">。</strong>他们所做的是将预处理步骤应用于时间序列，并将众所周知的算法应用于时间序列。其中一个算法是我们到目前为止讨论过的<strong class="ky ir">聚类</strong>算法。</p><p id="7711" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么不能直接应用K均值呢？有一个问题。如果两个时间序列相同，但其中一个移动了一个单位，则使用传统方法(如均方误差或平均绝对误差)计算的<strong class="ky ir">距离</strong>仍然很大，即使两个时间序列之间的差异基本上为0。</p><p id="4f33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们希望计算“最短路径”并将其称为两个时间序列之间的距离，而不是以传统方式计算距离。<br/>这种操作被称为<a class="ae kv" href="https://en.wikipedia.org/wiki/Dynamic_time_warping" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">距离时间扭曲</strong> </a>，其工作原理的实际演示可在下图或这里的<a class="ae kv" href="https://tslearn.readthedocs.io/en/stable/auto_examples/metrics/plot_dtw.html" rel="noopener ugc nofollow" target="_blank"> tslearn文档</a>中找到:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d8fd20d6b98923b8e880649cd01cd4c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*kMa9rjXxmUxPOuA-fsXccg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者制作，使用的代码可以在<a class="ae kv" href="https://tslearn.readthedocs.io/en/stable/auto_examples/metrics/plot_dtw.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p></figure><h1 id="ee51" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">3.气候时间序列聚类</h1><p id="1297" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">在这篇博文中，我们将使用上文解释过的距离时间弯曲算法对气候时间序列进行聚类。特别是，我们将有世界上一些主要城市的平均温度。我们希望对所有时间序列(2012–2017)中天气相似的城市进行聚类。</p><p id="bc8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集可以在<a class="ae kv" href="https://www.kaggle.com/datasets/selfishgene/historical-hourly-weather-data" rel="noopener ugc nofollow" target="_blank">这里</a>找到。可以免费下载并用于商业目的(更多信息<a class="ae kv" href="https://opendatacommons.org/licenses/odbl/" rel="noopener ugc nofollow" target="_blank">请点击</a>)。</p><p id="a255" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们开始玩吧！</p><h2 id="7bb9" class="np mr iq bd ms nq nr dn mw ns nt dp na lf nu nv nc lj nw nx ne ln ny nz ng oa bi translated">3.0导入库</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><h2 id="1857" class="np mr iq bd ms nq nr dn mw ns nt dp na lf nu nv nc lj nw nx ne ln ny nz ng oa bi translated">3.1数据预处理</h2><p id="e6e8" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">让我们导入数据集并查看一下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="ed1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们绘制一个时间序列:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="3207" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于我们正在使用的算法来说，时间序列当然太混乱了:这需要很长时间。出于我们的目的，让我们对数据集进行欠采样:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="e7e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">很好看，都准备好了:)</p><h2 id="354a" class="np mr iq bd ms nq nr dn mw ns nt dp na lf nu nv nc lj nw nx ne ln ny nz ng oa bi translated">3.2集群</h2><p id="debb" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">现在，预处理可能有点漫长和无聊，但一如既往，应用模型需要两行代码。</p><p id="9970" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="8244" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们决定用k=3。<br/>让我们将拟合的模型应用于我们的数据集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="b4b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们定义我们的时间步长数组:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="1687" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太好了。让我们画出结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="2c87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这实际上是信息丰富的:</p><ul class=""><li id="2fc6" class="od oe iq ky b kz la lc ld lf of lj og ln oh lr oi oj ok ol bi translated"><strong class="ky ir">第一</strong>级范围很广，但好像总是小于等于310。一般来说，最低值似乎在260左右(250左右的值似乎是异常值)。</li><li id="a613" class="od oe iq ky b kz om lc on lf oo lj op ln oq lr oi oj ok ol bi translated"><strong class="ky ir">第二类</strong>量程较小，但数值明显较大；较低和较大的数值均大于第一类对应的数值</li><li id="0c16" class="od oe iq ky b kz om lc on lf oo lj op ln oq lr oi oj ok ol bi translated">第三个类恰好和第一个类似，但是我们在高温下的值比在低温下的值多。</li></ul><p id="abe0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我同意这些结论可能不明显。其实我作弊了一点点:)。在查看了三个类别的直方图后，我找到了这些解释:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="9f85" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为什么我们说这个信息量大，不明显？嗯，因为这些城市在趋势和范围上看起来很相似，但在位置上并不接近。<br/>另一方面，如果你只是在位置上做一个K的意思(像这样):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="3e47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们看到相应的直方图:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="d5ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没什么意义吧？<br/>这是因为在地理位置上以某种方式“聚集”在一起的城市在气候上并不一定具有相同的行为。我们都知道气候远比这复杂。</p><h1 id="645c" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">6.结论</h1><p id="d40c" class="pw-post-body-paragraph kw kx iq ky b kz ni jr lb lc nj ju le lf nk lh li lj nl ll lm ln nm lp lq lr ij bi translated">如果你喜欢这篇文章，你想知道更多关于机器学习的知识，或者你只是想问我一些你可以问的问题:</p><p id="f6ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">A.在<a class="ae kv" href="https://www.linkedin.com/in/pieropaialunga/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Linkedin </strong> </a>上关注我，在那里我发布我所有的故事<br/> B .订阅我的<a class="ae kv" href="https://piero-paialunga.medium.com/subscribe" rel="noopener"> <strong class="ky ir">简讯</strong> </a>。这会让你了解新的故事，并给你机会发短信给我，让我收到你所有的更正或疑问。<br/> C .成为<a class="ae kv" href="https://piero-paialunga.medium.com/membership" rel="noopener"> <strong class="ky ir">推荐会员</strong> </a>，这样你就不会有任何“本月最大数量的故事”，你可以阅读我(以及成千上万其他机器学习和数据科学顶级作家)写的任何关于最新可用技术的文章。</p></div></div>    
</body>
</html>