<html>
<head>
<title>Paper Review: Reconstruction by inpainting for visual anomaly detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文综述:视觉异常检测的修复重建</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-review-reconstruction-by-inpainting-for-visual-anomaly-detection-70dcf3063c07#2022-08-08">https://towardsdatascience.com/paper-review-reconstruction-by-inpainting-for-visual-anomaly-detection-70dcf3063c07#2022-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="62d1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用5分钟时间解释如何通过将带有随机图案的图像传送到自动编码器来改进异常检测</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/649af6c5514eff66ac0bad59a5e0b62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YB5-Mp0yyCwKXu-j"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com/photos/HWbxSLvmSww" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@nevenkrcmarek" rel="noopener ugc nofollow" target="_blank"> Neven Krcmarek </a>拍摄的照片</p></figure><p id="f3ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个故事中，我将回顾由卢布尔雅那大学介绍的<strong class="ky ir">修复异常检测</strong> (RIAD)方法【1】。本文中有两个主要概念:</p><ul class=""><li id="5e99" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">RIAD是一种方法，<strong class="ky ir">去除图像</strong>中的部分局部区域，并重建由受损图像开始的图像</li><li id="2a2e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">RIAD基于一个编码器-解码器网络，该网络学习区分<strong class="ky ir">无异常图像</strong>和<strong class="ky ir">有缺陷图像</strong>。</li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="1e68" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">概述</h2><ol class=""><li id="e6f2" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr nl ly lz ma bi translated"><a class="ae kv" href="#1a16" rel="noopener ugc nofollow"> <strong class="ky ir">先决条件</strong> </a></li><li id="5d02" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nl ly lz ma bi translated"><a class="ae kv" href="#34fa" rel="noopener ugc nofollow"> <strong class="ky ir"> MVTec数据集</strong> </a></li><li id="2239" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nl ly lz ma bi translated"><a class="ae kv" href="#563c" rel="noopener ugc nofollow"> <strong class="ky ir"> RIAD算法</strong> </a></li><li id="ebc8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr nl ly lz ma bi translated"><a class="ae kv" href="#d1a1" rel="noopener ugc nofollow"> <strong class="ky ir">结果</strong> </a></li></ol></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="1a16" class="nm mo iq bd mp nn no np ms nq nr ns mv jw nt jx my jz nu ka nb kc nv kd ne nw bi translated"><strong class="ak"> 1。先决条件</strong></h1><p id="33a9" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nx lh li lj ny ll lm ln nz lp lq lr ij bi translated">在深入解释本文之前，有一些概念需要了解。由于论文使用了自动编码器，你需要了解它是什么。查看我的文章来了解它是如何工作的。</p><ul class=""><li id="65c0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> U-net </strong></li><li id="9e79" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">auto encoder如何应用于异常检测？</strong></li><li id="ac10" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">自动编码器在异常检测中的局限性</strong></li><li id="0676" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">自动编码器的重建损失</strong></li><li id="25bc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">结构相似度</strong></li><li id="5a15" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">梯度幅度相似度</strong></li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="1d0a" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">优信网</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/052bd5a6d891c80cc42d57e8ed9f358b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mJVVUTMEELfAcY1zpot9Ag.png"/></div></div></figure><p id="2523" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> U-net </a>是Ronneberger在2015年推出的卷积编解码网络[4]。它由两个网络组成:压缩数据模式的编码器和解压缩并重建原始数据的解码器。这个网络的主要特点是它的架构。在编码器架构中，每个卷积层中的特征通道数量加倍，而在解码器架构中，通道数量减半。此外，U-net使用<strong class="ky ir">跳过连接</strong>来通过网络的不同层传输功能。这是导致精确重建的一个重要方面。</p><p id="01d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了更好的了解细节，有一篇@ <a class="ob oc ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----70dcf3063c07--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a>写的<a class="ae kv" rel="noopener" target="_blank" href="/review-u-net-biomedical-image-segmentation-d02bf06ca760">评论</a>解释了U-net的架构。</p><h2 id="a74c" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">autoencoder如何应用于异常检测？</h2><ul class=""><li id="88bd" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated">对于银行、保险和制造业等众多领域而言，异常检测是一项至关重要的挑战。在这种情况下，自动编码器可以很好地解决这类问题，因为它们可以处理无人监督的问题。</li><li id="e9be" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">在训练期间，您只将正常数据传递给自动编码器</strong>。这样，模型将从提供的训练数据中学习潜在的表示。我们还将假设在训练期间没有观察到的<strong class="ky ir">异常数据</strong>、<strong class="ky ir">不应该被自动编码器</strong>很好地重建，因此<strong class="ky ir">与正常数据相比应该具有高重建误差</strong>。</li><li id="35b3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">例如，可以应用自动编码器来解决欺诈检测问题。在训练期间，我们只将正常的交易传递给模型。当我们评估测试集中的模型时，大多数欺诈性交易可能具有高于正常交易的均方误差。</li></ul><h2 id="1c50" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">自动编码器在异常检测中的局限性</h2><ul class=""><li id="9f30" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated">自动编码器倾向于学习“<strong class="ky ir">身份</strong>”<strong class="ky ir">功能</strong></li><li id="23e2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">然后，它能够重新创建异常数据，即使它从未被训练过。</li></ul><h2 id="b50f" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">自动编码器的重构损耗</h2><p id="ffc1" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nx lh li lj ny ll lm ln nz lp lq lr ij bi translated">训练自动编码器的损失函数被命名为重建损失。最流行的重建损失是<strong class="ky ir">均方误差</strong> (MSE) <strong class="ky ir"> </strong>损失函数。它<strong class="ky ir"> </strong>计算原始输入和网络输出之间的平方差的平均值。如果应用于图像，MSE测量我们正在比较的图像的平均像素差异。MSE越高，图像越不相似。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/41582ea41fb553157b84901036918b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*jPEXMLgrLI1F7q3KVnD15Q.png"/></div></figure><p id="9689" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MSE的替代方案是<strong class="ky ir"> L1 </strong> <strong class="ky ir">函数</strong>，其<strong class="ky ir"> </strong>测量输入和输出之间的<strong class="ky ir">绝对差值</strong>的<strong class="ky ir"> </strong>和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/df96ef95d16cc3ba735c208582a1e894.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*gzbAduUuZe4L2iwx0jQHDw.png"/></div></figure><p id="5589" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然这些重建损失是常用的，但它们有一些局限性。它们假设相邻像素之间的独立性，这通常是不被尊重的，并且不足以定量地测量原始样本和网络输出之间的相似性。</p><h2 id="2ca5" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">结构相似性</h2><p id="58a5" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nx lh li lj ny ll lm ln nz lp lq lr ij bi translated">为了考虑局部相关性，而不是单个像素值的差异，许多论文中提出了<strong class="ky ir"> SSIM </strong>(结构相似性)损失【2】。SSIM测量一对图像补片p和q之间的距离，其特征在于三个不同的方面:</p><ul class=""><li id="a9d9" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">亮度</strong>，通过计算补丁的平均值来考虑。</li><li id="e82f" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">对比度</strong>是补丁方差的函数。</li><li id="facd" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">结构</strong>通过计算两个面片的协方差来考虑。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/40baac1015ece939352cf0639f34dff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k08sCuy5KHKaR7ZS01l43w.png"/></div></div></figure><p id="0166" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其取值范围介于-1和1之间。当分数接近1时，这意味着两个被比较的图像是相似的，而分数为-1表示它们非常不同。</p><h2 id="752b" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">梯度震级相似性</h2><p id="8f60" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nx lh li lj ny ll lm ln nz lp lq lr ij bi translated">像SSIM，梯度幅度相似性是一个补丁相似性度量。它考虑了比较图像之间的局部相似性[3]。不是比较图像像素，而是考虑两幅图像I和I_{R}上的局部梯度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/505f6a4c4fd5871e8fe8e342cb3356fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*cD6mnYewO-HUur8HjBkIMw.png"/></div></figure><p id="2413" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中g(I)是图像I的梯度幅值图，c是常数以确保数值稳定性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7bcfbfdaaf16ce391c3e238bef51351c.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*1yudPExFEuPXDoQTJTkUxg.png"/></div></figure><p id="4ec5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">沿原始图像的x(或水平)和y(或垂直)方向卷积3x3 <a class="ae kv" href="https://en.wikipedia.org/wiki/Prewitt_operator" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Prewitt滤波器</strong> </a>得到原始图像的梯度幅值图。</p><h1 id="34fa" class="nm mo iq bd mp nn oi np ms nq oj ns mv jw ok jx my jz ol ka nb kc om kd ne nw bi translated">2.MVTEc广告数据集</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/687fb95ea0a29d1f75fa5c803550d877.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LvzebkIGR39dZYNsPIzffA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MVTEc广告数据集[5]</p></figure><p id="687a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MVTec AD是一个新颖而全面的工业数据集<br/>，由5354幅高分辨率图像组成，分为15类:5种纹理和10种物体【5】。训练集仅由正常的<br/>图像组成，而测试集包含有缺陷和无缺陷的图像。<br/>图像分辨率在700x700和1024x1024像素之间变化</p><h1 id="563c" class="nm mo iq bd mp nn oi np ms nq oj ns mv jw ok jx my jz ol ka nb kc om kd ne nw bi translated">3.里亚德<strong class="ak">算法</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/1c8771646d195817849817e57412a174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KgKc0tmtDG_uDdhkSqMPyA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">RIAD方法概述[1]</p></figure><p id="40b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在无异常的图像上训练自动编码器，其中随机选择的区域被设置为0。如前所述，使用的编码器-解码器架构是U-net。但是这些图像是如何被掩盖的呢？这些是以下步骤:</p><ul class=""><li id="f7ff" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">我们通过输入<strong class="ky ir">区域大小参数k </strong>从每幅图像中随机选择一组像素。</li><li id="fd38" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">每个图像可以被认为是一个尺寸为高度/k *宽度/k 的<strong class="ky ir">网格。</strong></li><li id="ed5a" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们的图像/网格被随机分成n个<strong class="ky ir">不相交的</strong>(或不重叠的)<strong class="ky ir">集合Si </strong>。</li><li id="2357" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们生成一个<strong class="ky ir">二进制掩码</strong>，M_{Si}，如果局部区域属于集合Si，它包含0，否则包含1。</li><li id="1659" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">最终图像是二进制掩模和原始图像</strong>的乘积。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/0009fbb7a54f3e6a83e8db0c9b410788.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdOzs8NNI_6R8DODlSwi8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从图像中随机移除像素的算法[1]。</p></figure><p id="e77b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在U-网的训练过程中，大小K是从一组K值中随机选取的。在本文中，他们使用K = {2，4，8，18}作为一组区域大小。在将掩模应用于原始图像之后，通过将修补的图像提供给模型来获得重建，然后通过考虑三种类型的损失来计算总损失:</p><ul class=""><li id="4ae4" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> MSGMS </strong>损失，即<em class="oq">几个尺度下的平均GMS距离:</em></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bdaf4656bad43a5ed41abea5e1353f0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*qS9M_8hp9V2L2TTPpslbkA.png"/></div></figure><p id="3e74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中Hl和Wl分别是被比较图像的高度和宽度，Nl是比例l下的像素数</p><ul class=""><li id="8491" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir"> SSIM损失</strong>是所有本地SSIM值的<em class="oq">平均值:</em></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/1927ef1dad25d0d47025c0540bed2fab.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*HTYONkYVWmKiXRSrzY9SuQ.png"/></div></figure><ul class=""><li id="ab19" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">逐像素L2损失</strong>(或<em class="oq">均方误差损失)</em></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/8f2fc32367a47641460e46aea5fd5576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Q_Y2uDOPxuOKI4OlVLZ0A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">U-net的训练[1]。</p></figure><p id="6f36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们可以获得在每个k值下为每个图像重建I_{R}产生的异常图<strong class="ky ir"> G_A(I，I_{R}) </strong>的平均值。随后，我们计算图像级异常分数，其本质上是异常图平均值的最大值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e6d1173bd8d6232df6d218416d630215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*dBrQfyCWiDM2yJJWPlBjqg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对U-net的评价[1]。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/2568b7d94a11e4c0c47dd9a78d3c52ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*WL0UHfyuB-MbBvJPkDb3dQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">评估期间获得的异常图示例说明[1]。</p></figure><p id="5fc7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">比如我们假设K = {2，4，8，16}。我们计算属于{2，4，8，16}的每个k值处的每个图像重建的异常图，然后，我们计算这些异常图的平均值，如最后一列所示。</p><h1 id="d1a1" class="nm mo iq bd mp nn oi np ms nq oj ns mv jw ok jx my jz ol ka nb kc om kd ne nw bi translated">4.结果</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/58427bb2ec52e52bd9824e6b909dd20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*l-s3-FTAWiuppPm69_TqPA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">异常检测的图像水平ROC-AUC评分[1]。</p></figure><ul class=""><li id="8155" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">与其他最先进的模型相比，RIAD在对象类别上表现更好，如瓶子、金属螺母和牙刷，它们呈现出较高的平均ROC-AUC，并且在一些纹理类别上也取得了不错的结果，如<strong class="ky ir">网格</strong>和<strong class="ky ir">皮革</strong>。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/40ea9a984dda7f771873d919406782c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*fyD5JZb5L8-z_TamKryxMQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">异常定位的每像素水平ROC-AUC得分[1]。</p></figure><ul class=""><li id="a1d5" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">此表显示了MVTec AD数据集类别的异常定位结果。</li><li id="1dc6" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">与其他最先进的方法相比，它在异常定位方面获得了更高的总体ROC-AUC分数。</li></ul><h2 id="9f4a" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">参考</h2><p id="e1d4" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nx lh li lj ny ll lm ln nz lp lq lr ij bi translated">[1] <a class="ae kv" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320305094" rel="noopener ugc nofollow" target="_blank">视觉异常检测修复重建</a>，Vitjan Zavrtanik，Matej Kristan，Danijel Skocaj，(2021)</p><p id="43f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="https://arxiv.org/abs/1807.02011" rel="noopener ugc nofollow" target="_blank">通过将结构相似性应用于自动编码器来改进无监督缺陷分割</a>，保罗·博格曼，辛迪·洛，迈克尔·福瑟，大卫·萨特勒格，卡斯滕·斯泰格</p><p id="cba7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] <a class="ae kv" href="https://www.arxiv-vanity.com/papers/1708.02237/" rel="noopener ugc nofollow" target="_blank">图像质量评估技术显示了自动编码器生成对抗网络的改进的训练和评估</a>，迈克尔·o·弗托利，<strong class="ky ir"> </strong>吉姆·戴维斯，卡尔顿大学，(2017)</p><p id="6bf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] <a class="ae kv" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net:用于生物医学图像分割的卷积网络</a>，Olaf Ronneberger，Philipp Fischer，Thomas Brox，(2015)</p><p id="09be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5]<a class="ae kv" href="https://link.springer.com/content/pdf/10.1007/s11263-020-01400-4.pdf" rel="noopener ugc nofollow" target="_blank">MVTec异常检测数据集:用于无监督异常检测的综合真实数据集</a>，保罗·博格曼、基利安·巴茨纳、迈克尔·福瑟(2021)</p><h2 id="ce4d" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">Github知识库</h2><ul class=""><li id="f586" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/plutoyuxie/Reconstruction-by-inpainting-for-visual-anomaly-detection" rel="noopener ugc nofollow" target="_blank">https://github . com/plutoyuxie/用于视觉异常检测的修复重建</a></li></ul><h2 id="3c9d" class="mn mo iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">其他相关文章:</h2><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/ganomaly-paper-review-semi-supervised-anomaly-detection-via-adversarial-training-a6f7a64a265f"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd ir gy z fp pg fr fs ph fu fw ip bi translated">GANomaly论文综述:通过对抗训练的半监督异常检测</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">一种结合自动编码器和生成式对抗网络的异常检测模型</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp kp pb"/></div></div></a></div></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="9234" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你喜欢我的文章吗？<a class="ae kv" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="oq">成为会员</em> </a> <em class="oq">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae kv" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="oq">订阅</em> </a> <em class="oq">每当我发布新的数据科学和python指南时，您都可以收到电子邮件！</em></p></div></div>    
</body>
</html>