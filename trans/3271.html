<html>
<head>
<title>Building classifiers with biased classes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用有偏向的类构建分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-classifiers-with-biased-classes-adasampling-comes-to-the-rescue-8212814264e3#2022-07-20">https://towardsdatascience.com/building-classifiers-with-biased-classes-adasampling-comes-to-the-rescue-8212814264e3#2022-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b148" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">AdaSampling来拯救我们</h2></div><p id="6bbf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">离开Kaggle的世界，进入现实世界，数据科学家经常(<em class="lb"> read: always </em>)面临脏数据的问题。除了缺失值、不同单位、重复等等，分类任务的一个相当常见的挑战是数据标签中的噪声。虽然有些噪声问题可以由分析师来解决，但其他问题本质上是有噪声的或不精确的。</p><p id="3e31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">考虑以下任务:预测特定蛋白质是否与特定DNA序列结合。或者另一个:预测是什么导致了普通感冒。这两个任务有一个共同点，那就是关于负类的知识很少。有数不清的DNA序列，只有那些碰巧被分析并作为特定蛋白质的目标发表的序列被认为是阳性的。但其他未发表的序列不一定是否定的。它们可能没有被分析过。普通感冒也是如此:许多病例未被发现，因为只有少数人报告患了感冒。然而，有一种技术可以帮助你应对这一挑战:<a class="ae lc" href="https://ieeexplore.ieee.org/document/8329462" rel="noopener ugc nofollow" target="_blank">杨</a>等人(2019)提出的自适应采样(AdaSampling)。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/46d6397a910eb99cd3db4bf501377a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*apyMD6bkh--T_mMG2T4lsw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">AdaSampling算法，示意性示例。图片作者。</p></figure><p id="7cf2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简而言之，AdaSampling算法执行以下步骤:<br/> 1 .从数据集中抽取一个子样本。给定的正/负样本被选择的概率等于它是正/负类成员的概率。<em class="lb">(在图中，突出显示的样本最有可能是任一类别的成员，因此被选择用于建模。)</em> <br/> 2。使用任何底层分类算法(例如SVM、kNN、ld a等)构建分类器。).<br/> 3。基于该分类模型，预测样本(在完整数据集内)在正/负类中的概率。<br/> 4。重复1-3，直到类别概率没有变化。</p><p id="0f02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基本上，你会得到一张你的类的清晰的图片，并得到关于你的负样本中哪些可能不是负样本的第一个线索。在训练阶段省略这些可以大大提高模型的准确性。</p><p id="c56f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用r中的AdaSampling包来尝试一下。示例数据集是关于良性和恶性乳腺癌的。</p><pre class="le lf lg lh gt lt lu lv lw aw lx bi"><span id="8f87" class="ly lz iq lu b gy ma mb l mc md">#install.packages("AdaSampling")<br/>library(tidyverse)<br/>library(AdaSampling)<br/>library(caret)</span><span id="02c6" class="ly lz iq lu b gy me mb l mc md"># load the example dataset<br/>data(brca)<br/># some cleanup of the dataset<br/>brca$cla &lt;- as.factor(unlist(brca$cla)) <br/>brca$nuc &lt;- as.numeric(as.character((brca$nuc))) </span><span id="9426" class="ly lz iq lu b gy me mb l mc md">#run a PCA<br/>brca.pca &lt;- prcomp(brca[,c(1:9)], center = TRUE,scale. = TRUE)<br/># append PCA components to dataset<br/>brca_withPCA &lt;- cbind(brca, brca.pca$x)<br/># plot<br/>ggplot(brca_withPCA, aes(x=PC1, y=PC2, color=cla)) +<br/>  geom_point() + <br/>  ggtitle("PCA of Breast Cancer Dataset") +<br/>  theme_classic()</span></pre><p id="89ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">原始数据集上的主成分分析如下所示:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mf"><img src="../Images/53152f0f28901a036e6e415f6dc2678c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hJKCpECqgKHRAykABA0xxA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片作者。</p></figure><p id="a78e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们实际上看到两个很好的分离的类。我们可以在此基础上建立一个“基础事实”分类器。我选择了一个SVM，得到了0.96的精确度和0.91的灵敏度(代码如下)。</p><pre class="le lf lg lh gt lt lu lv lw aw lx bi"><span id="fa72" class="ly lz iq lu b gy ma mb l mc md">#Separate test set<br/>set.seed(107)<br/>inTrain &lt;- createDataPartition(y = brca$cla,  p = 0.75)<br/>train &lt;- brca[ inTrain$Resample1,]<br/>test  &lt;- brca[-inTrain$Resample1,]</span><span id="6cae" class="ly lz iq lu b gy me mb l mc md">ctrl &lt;- trainControl(<br/>  method = "repeatedcv", <br/>  repeats = 3,<br/>  classProbs = TRUE, <br/>  summaryFunction = twoClassSummary<br/>)<br/>model_groundTruth &lt;- train(<br/>  cla ~ .,<br/>  data = train,<br/>  method = "svmLinear", # Support Vector Machines with Linear Kernel<br/>  ## Center and scale the predictors for the training<br/>  preProc = c("center", "scale"),<br/>  trControl = ctrl,<br/>  metric = "ROC"<br/>)</span><span id="3563" class="ly lz iq lu b gy me mb l mc md">#predict<br/>predicted_groundTruth &lt;- predict(model_groundTruth, newdata = test)<br/>confusionMatrix(data = predicted_groundTruth, test$cla, positive="malignant")</span></pre><p id="dfd9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很好。这是一个相当精确的分类器。现在让我们看看AdaSampling的实际应用。我们假装时光倒流，回到了某些恶性肿瘤被诊断为良性的时间点。这是一个更真实的场景，因为并非所有被诊断为良性的癌症都会永远如此。</p><pre class="le lf lg lh gt lt lu lv lw aw lx bi"><span id="6497" class="ly lz iq lu b gy ma mb l mc md">#get the classes<br/>pos &lt;- which(brca$cla == "malignant")<br/>neg &lt;- which(brca$cla == "benign")<br/>#introduce 40% noise to malignant class<br/>brca.cls &lt;- sapply(X = brca$cla, FUN = function(x) {ifelse(x == "benign", 0, 1)})<br/>brca.cls.noisy &lt;- brca.cls<br/>set.seed(1)<br/>brca.cls.noisy[sample(pos, floor(length(neg) * 0.4))] &lt;- 0</span><span id="d932" class="ly lz iq lu b gy me mb l mc md">brca$noisy_class &lt;- as.factor(brca.cls.noisy)<br/>brca %&gt;% group_by(cla, noisy_class) %&gt;% tally()</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/856465694796c4dcae70a7cc54466d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*medhCaMOaS9bzEzHpUQi8g.png"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片作者。</p></figure><p id="41d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们引入了一个测量误差:95%的癌症会变成恶性的(基本事实),现在被标记为良性的。PCA看起来极具破坏性:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mf"><img src="../Images/a359c523d40fc31745f1b280ac38fe5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mRBFLsvmghoYSO6gL3-rrA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片作者。</p></figure><p id="6f1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用此数据构建分类器会得到一个准确度为0.81、灵敏度为0.47、特异性为0.99的模型。正如所料，这个分类器漏掉了许多潜在的恶性肿瘤。</p><p id="2200" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是采样的时候了。下面的代码显示了细节。程序如下:需要告诉算法哪个是正样本，哪个是负样本。然后，它充当分类算法的包装器(我选择了kNN，但是这个包提供了许多其他算法)并重新分配类。完成后，我检查了使用主成分分析的样本分布情况，使用与之前相同的特性:</p><pre class="le lf lg lh gt lt lu lv lw aw lx bi"><span id="02fd" class="ly lz iq lu b gy ma mb l mc md"># identify positive and negative examples from the noisy dataset<br/>Ps &lt;- rownames(brca)[which(brca$noisy_class == 1)]<br/>Ns &lt;- rownames(brca)[which(brca$noisy_class == 0)]</span><span id="bc79" class="ly lz iq lu b gy me mb l mc md"># apply AdaSampling method on the noisy data. I pick kNN, but other classification methods are available<br/>brca.preds &lt;- adaSample(Ps, Ns, train.mat=brca[,1:9], test.mat=brca[,1:9], classifier = "knn")<br/>brca.preds &lt;- as.data.frame(brca.preds)<br/>head(brca.preds)<br/>brca.preds$Adaclass &lt;- as.factor(ifelse(brca.preds$P &gt; brca.preds$N, "malignant", "benign"))<br/>brca &lt;- cbind(brca, brca.preds["Adaclass"])</span><span id="5748" class="ly lz iq lu b gy me mb l mc md">#check the result with PCA first:<br/>brca.pca_Ada &lt;- prcomp(brca[,c(1:9)], center = TRUE,scale. = TRUE)<br/># append PCA components to dataset<br/>brca_withPCA_Ada &lt;- cbind(brca, brca.pca_Ada$x)<br/># plot<br/>ggplot(brca_withPCA_Ada, aes(x=PC1, y=PC2, color=Adaclass)) +<br/>  geom_point() + <br/>  ggtitle("PCA of Breast Cancer Dataset with Noise removed by AdaSampling")+<br/>  theme_classic()</span></pre><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mf"><img src="../Images/bc7d0bc999798b99a5f39cafd3d2454e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32Hb-zZlnT4fFvLmuM5cAA.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片作者。</p></figure><p id="e240" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几乎和地面真相一模一样！为了完整起见，我还使用清理后的数据构建了一个分类器，结果得到一个准确度为0.96、敏感度为0.92、特异性为0.99的模型。</p><p id="1689" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该分类器与我们在没有噪声的数据集上构建的分类器一样好。我猜这是由于数据集和恶性肿瘤很容易通过提供的特征识别。在真实世界的场景中，它可能看起来不同，并且您永远无法确定您的模型实际执行得有多好，直到您收集了更多真实的正面和负面示例。在此之前，AdaSampling是您工具箱中增强模型的又一个工具。</p><p id="ed46" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="lb">参考文献</em> </strong> <em class="lb"> : P .杨，J. T. Ormerod，W. Liu，C. Ma，A. Y. Zomaya和J. Y. H. Yang，“正-未标记和标记噪声学习的自适应采样及其在生物信息学中的应用”，载于《IEEE控制论汇刊》，第49卷，第5期，第1932–1943页，2019年5月，doi:10.11109/tcyb . 20000005</em></p></div></div>    
</body>
</html>