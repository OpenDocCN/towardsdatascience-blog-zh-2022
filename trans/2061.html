<html>
<head>
<title>Random Forest and Decision Trees from scratch— no coding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的随机森林和决策树—无需编码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/random-forest-and-decision-trees-by-hand-no-coding-a209f2bbb1c9#2022-05-09">https://towardsdatascience.com/random-forest-and-decision-trees-by-hand-no-coding-a209f2bbb1c9#2022-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/71bbf7cd6437866c1270f27a611341b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikT4bplBcxKAznfiHHTmWQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">一棵粉红色的樱花树</p></figure><h1 id="c758" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">介绍</h1><p id="1c2c" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在本文中，我们将讨论决策树和随机森林，这是机器学习中用于分类和回归任务的两种算法。</p><p id="6db3" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我将展示如何使用纸笔从头开始构建决策树，以及如何对其进行归纳并构建一个随机森林模型。</p><h2 id="1ab6" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">资料组</h2><p id="f49c" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">让我们用一个简单数据集来看看这在实践中是如何工作的。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mt"><img src="../Images/c95593597034b18edb3638094b669f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lG6L7mPmmOcL_ksQgihlBg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">数据集(作者提供的图片)</p></figure><p id="2513" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这里，我们试图预测一个人是否有大学学位。我们有两个数字变量，那个人的年龄和工资(以千美元计)。</p><h2 id="f216" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">关于数据集的初始假设</h2><p id="0af2" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当你查看一个新的数据集时，我总是建议你想出关于它的<strong class="lg iu">假设</strong>，看看它们是否是真的。</p><p id="1b64" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我个人在这里有两个假设:</p><ul class=""><li id="584e" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated"><strong class="lg iu">高薪人士更有可能拥有大学文凭。我这么说是基于这样一个事实:很多高薪职业(医学、法律、科技、咨询、金融等)都需要大学学位。</strong></li><li id="8749" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">年轻人比他们的长辈更有可能上大学。我是基于皮尤研究中心的研究和个人经验(我经常听我周围的老年人说，他们觉得我这一代人比他们过去上大学多得多——现在，我知道这是真的)。</li></ul><p id="a16d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我快速计算了一些平均值，发现数据集中上过大学的人的平均年龄是34岁，而没有上过大学的人是43岁。关于工资，上过大学的人平均工资为63K，相比之下，没上过大学的人平均工资为37K。因此，我们的两个假设都是正确的。</p><p id="76f2" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这样做不是强制性的，但总是有用的，可以让您更好地理解您正在处理的数据集。</p><h1 id="55e0" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">决策图表</h1><p id="a968" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，让我们看看如何在这个数据集上训练决策树并进行预测。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/d59914fce870171b130fd6ff701d2067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dhf2HM4ou90MSarugySKpw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">根节点(作者图片)</p></figure><p id="e5e1" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一开始，我们有<strong class="lg iu"> 6是</strong>和<strong class="lg iu"> 4否</strong>。这将成为我们的根节点。</p><p id="42eb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在任何时候，我们<strong class="lg iu">总是</strong>能够访问真正的标签(也就是说，我们总是知道整个决策树中的一个例子是“是”还是“否”)。记住这一点，这对接下来的事情很重要。</p><p id="955c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在决策树的每个节点，我们可以预测其中一个类别。这里，我们既可以预测<strong class="lg iu">是</strong>也可以预测<strong class="lg iu">否</strong>。</p><ul class=""><li id="2d05" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">如果我们预测<strong class="lg iu">是</strong>，我们将正确分类10个数据点中的6个数据点，错误分类4个数据点。因此，我们将有4/10 = <strong class="lg iu"> 0.4的错误率</strong>。</li><li id="d790" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">如果我们预测<strong class="lg iu">没有</strong>，我们将正确分类10个数据点中的4个数据点，错误分类6个数据点。因此，我们将有6/10 = <strong class="lg iu"> 0.6的错误率</strong>。</li></ul><p id="f1f0" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">因此在这里，我们应该预测<strong class="lg iu">是</strong>以获得最低的错误率。</p><p id="5cad" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，让我们看看如何改进这一点。请记住，我们在这里仍然没有使用任何功能，只有数据集的真实标签。</p><h2 id="2038" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">分裂</h2><p id="a565" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在的问题是，我们如何利用我们的特征来改善我们的预测，并做得比0.4的错误率更好。我们将为此使用一个阈值:如果某人的工资高于X，那么我们预测是。如果他们的工资低于X，我们预测是否定的。让我们看一个例子:</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/aa580cd9916a51dfc65ed090e674f20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wp3IVkItkAU2UzSyfH4dsw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">工资分割(图片由作者提供)</p></figure><p id="35aa" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这里，我们仍然有我们的根节点，但我们没有直接预测，而是首先以32.5K的拆分值拆分薪水(剧透:这是这里的最佳拆分)，然后进行预测—同样，我们有真正的标签。我们的错误率现在是0.2(我们只对右边方框中的两个黄色点进行了错误分类，它显示为6 | 2 -我们预测这些点是，而我们应该预测不是)。</p><p id="aefb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">所以，有两个问题:为什么我们决定先按<strong class="lg iu">薪水</strong>分(而不是按<strong class="lg iu">年龄</strong>或其他特征，如果我们有更多的话)以及为什么我们按<strong class="lg iu"> 32.5K </strong>分而不是按另一个值分？</p><h2 id="22a7" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">如何找到最佳阈值？</h2><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/53878705ccd0721dc33cd8b85c2f792f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a_PTYGa2rkY7egRs4hjljw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">薪水从最小到最大排序，绿色表示是，黄色表示否(图片由作者提供)</p></figure><p id="ce3a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这里，我将工资从最小到最大排序。寻找给定特征的最佳阈值的想法如下:</p><ul class=""><li id="95f8" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">对特性的值进行排序(如上)</li><li id="a04a" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">取两点之间的中间值</li><li id="d703" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">像前面一样，将此作为阈值，并计算损耗</li><li id="6993" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">对所有中间值(即所有分割)进行此操作</li><li id="4d41" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">为给定特征选择最佳分割</li></ul><p id="5012" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们看一个例子。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/0cb1b0b6c7ec153d19346419536f26ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_T2Rf2ZtPmK4cL_2zp_bAg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">以4.2万英镑的薪水分割(图片由作者提供)</p></figure><p id="825d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这里我们取42作为阈值，是40到44之间的中间值。这将我们的数字列表一分为二。</p><p id="5074" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">对于每一部分，我们可以预测是或不是。</p><ul class=""><li id="b0a9" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">如果我们在左边预测是，在右边预测不是(与我们在图片上所做的相反)，我们将有6个错误= 0.6错误率。</li><li id="67b4" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">如果我们反过来做，如图所示，我们会得到4个错误= 0.4个错误率。</li></ul><p id="d2df" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">所以我们这里能达到的最低错误率是0.4(图片上是什么)。</p><p id="af4a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在的想法是计算所有可能的分割值的损失。让我们看看这是什么样子。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/ff2502a576d5fb618a9d3ceca863144b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Y_TSKCQFmMcxTmQ1HYG1Q.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">工资的所有可能分割(图片由作者提供)</p></figure><p id="a36f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这里，我们有各种可能的方法来平分薪水。我们看到32.5K是分割的最佳值，因为它的错误率最低。</p><p id="35ed" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">请记住，你是在42还是42.005上拆分并不重要，只要你在两个值之间选择一个阈值。我的意思是:</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/51518ffd5e8a192c4b0827363233dcec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Spxi3MEsj2cVN8K8W-gsxw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">分割区域(作者图片)</p></figure><p id="dc0c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在这里，您可以在红色区域中选取任何值，只要它大于40并且小于44(因此40.1有效，43.9也有效)。原因是这些值仍然会导致相同的错误率。因此，你选择哪一个并不重要。我们只是选择中点作为惯例。</p><h2 id="4785" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">决定分割哪个变量</h2><p id="fa1a" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，我们知道，在我们可以分割薪水的所有方式中，32.5K的门槛是最好的分割方式。</p><p id="2f18" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，我们如何决定我们是应该在年龄和薪水上平分呢？简单。计算年龄的误差率，就像我们计算工资的误差率一样，从两者中选择最低的误差率，并将其作为我们的分割值。就这么办吧。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/5638fc39986659cbd8b1204ded814a15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkVLOJ7775-eFreTPgidMA.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">所有可能的根分裂的总结(图片由作者提供)</p></figure><p id="e1b7" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我们用<strong class="lg iu">年龄</strong>能达到的最低错误率是<strong class="lg iu"> 0.3 </strong>，而用<strong class="lg iu">工资</strong>能达到的最低错误率是<strong class="lg iu"> 0.2 </strong>。因此，我们在<strong class="lg iu"> 32.5K </strong>上对<strong class="lg iu">工资</strong>进行分割，并选择此作为我们的第一次分割。</p><p id="8654" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，我们递归:只要我们在一个给定的节点中没有0错误或者没有特征，我们就继续分裂。这是我们的树目前的样子:</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/aa580cd9916a51dfc65ed090e674f20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wp3IVkItkAU2UzSyfH4dsw.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">当前树(作者图片)</p></figure><ul class=""><li id="790b" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">在<strong class="lg iu">左侧</strong>，您可以看到我们无法做得更好(我们已经将这2点完美分类)。因此，我们不需要进一步分裂。</li><li id="8db6" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">在<strong class="lg iu">右侧</strong>，我们仍然可以在年龄上分裂，并有可能做得更好。</li></ul><p id="18eb" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">让我们计算一下年龄的所有可能的分裂。这里，我们有8个数据点，而不是10个，因为我们只处理树右侧的数据点。</p><p id="5e6c" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我们像前面一样，首先对数据点进行排序。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/2626b1b4c0e2dc3d77a6a0600cad7392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VgKkLrAUQsbWEzaG1CzKBg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">对剩下的8个数据点进行排序(图片由作者提供)</p></figure><p id="2ff6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">现在，我们得到下面的分裂列表。</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/a3f72f21c9fd6c25b551777ef6558a91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*et526UUGjXnNkkn6Db8GEQ.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">年龄差异(作者图片)</p></figure><p id="8afd" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">因此，我们在<strong class="lg iu"> 52.5 </strong>的<strong class="lg iu">年龄</strong>上分开，如果年龄低于52.5则预测是，如果高于52.5则预测否。这给了我们下面的树:</p><figure class="mu mv mw mx gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/a0653965d5e5930ef5ca7023fb046f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dwh8DFcvx3HD4ier5DjR5Q.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">该数据集的最终树(图片由作者提供)</p></figure><p id="f199" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我们得到最终树的错误率为0.1，因为它只将1个点错误分类为是而不是否。我们不能进一步分割，因为我们没有可分割的特征。</p><h2 id="98ce" class="mh kh it bd ki mi mj dn km mk ml dp kq lp mm mn ku lt mo mp ky lx mq mr lc ms bi translated">分类特征</h2><p id="0019" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">如果你有<strong class="lg iu">分类</strong>而不是<strong class="lg iu">数值</strong>特征，过程同上。您只需对现有的值进行拆分。</p><p id="1dbc" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">例如，如果你有一个<strong class="lg iu">分类特征</strong>来表示某人是住在农村还是住在城市，你就可以分开来看它的表现如何。然后，您将与其他功能进行比较。基本相同的过程。这就是为什么我首先讨论了数字特征，因为分类特征基本上是相同的，但是你已经有了分裂。</p><h1 id="d7be" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">什么时候停止种树？</h1><p id="051a" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">早些时候，我们没有其他可以拆分的功能(我们有两个功能，年龄和工资，并且拆分了两次)。因此，这个问题没有提出来。</p><p id="9545" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><strong class="lg iu">在实践中</strong>，你会有更多的功能，你将能够分裂更多，让你的树长得更大，</p><p id="0686" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">正如我在以前的<a class="ae kf" rel="noopener" target="_blank" href="/lasso-and-ridge-regression-an-intuitive-comparison-3ee415487d18">文章</a>中提到的，这里你将有一个<strong class="lg iu">偏差-方差</strong>的权衡。树越深，它就越适合数据集，但是过度适合的风险就越高。你的树将开始捕捉数据的噪音。因此，何时停止生长一棵树的问题出现了。</p><p id="bf3d" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">有两个主要的技巧:提前停止和修剪。</p><p id="aff4" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在<strong class="lg iu">提前停止</strong>，<strong class="lg iu"> </strong>中，你基于给定的条件停止在树的给定节点上的分裂。以下是早期拆分条件的示例:</p><ul class=""><li id="add0" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">设置叶节点所需的最小样本数</li><li id="a10c" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">设置树的最大深度</li></ul><p id="b60b" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">在<strong class="lg iu">修剪</strong>中，你只需像我们之前做的那样构建树，然后构建一个比你之前停止时更复杂的树。然后，根据给定的条件删除一些节点。</p><p id="5209" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">两者各有利弊，都在实践中使用。为此，我建议查看一下<a class="ae kf" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>文档。我所涉及的参数称为<em class="nw">修剪</em>、<em class="nw">最大深度</em>和<em class="nw">最小样本叶。</em>还有很多，我建议尽可能多地研究这些文档。</p><h1 id="72cc" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">随机森林</h1><p id="d217" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">现在，如何构建一个随机森林分类器？简单。</p><p id="303a" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">首先，创建一定数量的决策树。然后，从数据集中统一采样(<strong class="lg iu">替换</strong>)，采样次数与数据集中的样本数相同。因此，如果您的数据集中有100个示例，您将从中抽取100个点作为样本。替换意味着一旦你采样了一个给定点，你就不能把它从数据集中去掉(<strong class="lg iu">你基本上可以对同一个点采样两次</strong>)。</p><p id="3125" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">这为我们提供了构建随机森林分类器的以下过程:</p><ul class=""><li id="5809" class="my mz it lg b lh mc ll md lp na lt nb lx nc mb nd ne nf ng bi translated">数据集中替换的样本</li><li id="0364" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">在这个子数据集上训练一个决策树</li><li id="b090" class="my mz it lg b lh nh ll ni lp nj lt nk lx nl mb nd ne nf ng bi translated">重复所需的树数</li></ul><p id="7544" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">一旦你有了自己的决策树，你只需要进行多数投票。在我们之前的例子中，假设您已经训练了100棵决策树。对于一个给定的例子，如果64棵树预测是，36棵树预测否，那么你会预测是。</p><h1 id="c6b1" class="kg kh it bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">更进一步</h1><p id="890d" class="pw-post-body-paragraph le lf it lg b lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在这篇文章中，我停留在相对较高的层次，没有涉及一些事情，比如可以用于分割的不同度量，以及树如何解决回归问题。在Scikit-learn文档中还可以找到更多的参数。</p><p id="85ff" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">然而，对于以前没有使用过这种算法的人来说，这应该是一个坚实的基础。我建议在一张纸上重新计算，看看你是否得到同样的结果。这确实有助于理解算法。</p><p id="21a8" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated">我最近写了一篇关于<a class="ae kf" rel="noopener" target="_blank" href="/lasso-and-ridge-regression-an-intuitive-comparison-3ee415487d18"> Ridge和Lasso </a>的文章，这是回归问题的两种正则化算法。虽然它们不能用于分类，但本文将帮助您理解偏差-方差权衡。这在决策树的上下文中很有用，可以理解为什么你应该在训练你的树或者修剪它们的时候早点停止。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><p id="4ae6" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nw">我希望你喜欢这个教程！让我知道你对它的看法。</em></p><p id="c04f" class="pw-post-body-paragraph le lf it lg b lh mc lj lk ll md ln lo lp me lr ls lt mf lv lw lx mg lz ma mb im bi translated"><em class="nw">随时连接上</em><a class="ae kf" href="https://www.linkedin.com/in/thomas-le-menestrel/" rel="noopener ugc nofollow" target="_blank"><em class="nw">LinkedIn</em></a><em class="nw">和</em><a class="ae kf" href="https://github.com/tlemenestrel" rel="noopener ugc nofollow" target="_blank"><em class="nw">GitHub</em></a><em class="nw">谈论更多关于数据科学和机器学习的话题并关注我上</em> <a class="ae kf" href="https://tlemenestrel.medium.com/" rel="noopener"> <em class="nw">中</em> </a> <em class="nw">！</em></p></div></div>    
</body>
</html>