<html>
<head>
<title>7 real-world applications of reinforcement learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习的7个实际应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/7-real-world-applications-of-reinforcement-learning-f80955cefcd5#2022-02-17">https://towardsdatascience.com/7-real-world-applications-of-reinforcement-learning-f80955cefcd5#2022-02-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5fa0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们离日常生活中的强化学习有多近？以下是强化学习的真实使用案例——从机器人到个性化你的网飞建议。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a889d5674e019442868db782797eea75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2UOXmYMPcPoeYn1l-3dphw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">迈克尔·泽兹奇在<a class="ae ky" href="https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="11b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">强化学习是机器学习的一个子域，其中代理通过与他们的环境交互来学习做出决策。最近，它通过在围棋、象棋、Dota和星际争霸2等游戏中实现超人水平的能力而广受欢迎。</p><p id="cd9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我列出了强化学习在现实世界用例中应用的7个例子。</p><h1 id="2f8e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1.使用Wayve的自动驾驶</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/71e078299259bffbd08efeadbc89d8ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WuqIxNf03T0F1-i9fvKH-Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@ev25?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">叶夫根尼·切博塔列夫</a>在<a class="ae ky" href="https://unsplash.com/s/photos/car?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="66c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">历史上，自动驾驶汽车的方法包括定义逻辑规则。这可能很难扩展到无人驾驶汽车在公共道路上可能遇到的无数情况。这就是<a class="ae ky" href="https://arxiv.org/pdf/2002.00444.pdf" rel="noopener ugc nofollow" target="_blank">深度强化学习可能有前途的地方</a>。</p><p id="7a7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://wayve.ai/" rel="noopener ugc nofollow" target="_blank"> Wayve </a>是一家总部位于英国的公司，自2018年以来一直在公共道路上测试自动驾驶汽车。在他们的论文“<a class="ae ky" href="https://arxiv.org/pdf/1807.00412.pdf" rel="noopener ugc nofollow" target="_blank">在一天内学会驾驶</a>”中，他们描述了他们如何使用深度强化学习来训练一个使用单目图像作为输入的模型。奖励是车辆在没有安全驾驶员控制的情况下行驶的距离。该模型在驾驶模拟中进行训练，然后在现实世界中部署在250米的路段上。</p><p id="e905" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然他们的自动驾驶汽车技术继续发展，但他们声称强化学习继续在<strong class="lb iu">运动规划</strong>中发挥作用(确保目标点和目的点之间存在可行的路径)。</p><h1 id="b5d5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2.个性化您的网飞推荐</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/fa62f7c2e81c0e92c89f8d97853f0829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uoch3wbZGe-HjsUpu0mpIQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@freestocks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">自由股票</a>在<a class="ae ky" href="https://unsplash.com/s/photos/netflix?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="14e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网飞在190多个国家拥有2亿用户。对于这些用户，网飞的目标是呈现最具娱乐性和相关性的视频。在贾斯汀·巴西利科(网飞大学机器学习和推荐系统主任)的演讲“<a class="ae ky" href="https://scale.com/blog/Netflix-Recommendation-Personalization-TransformX-Scale-AI-Insights" rel="noopener ugc nofollow" target="_blank">网飞解释了推荐和个性化</a>”中，他描述了他们如何通过结合四种关键方法来实现这一点:深度学习、因果关系、强化学习和目标。</p><p id="2198" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">面临的挑战是训练一个模型，优化用户的长期满意度，而不是即时满意度。强化学习可以通过引入探索来提供帮助，探索可以让模型随着时间的推移学习新的兴趣。</p><p id="eacb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Justin指出，由于高维数和大问题空间，强化学习在这种情况下很难应用。为了帮助这一点，该团队开发了<a class="ae ky" href="https://dl.acm.org/doi/abs/10.1145/3460231.3474259" rel="noopener ugc nofollow" target="_blank">手风琴</a>——一种用于长期训练的模拟器。</p><h1 id="f397" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3.优化沃尔玛的库存水平</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/b47646c926ea0a06038806b86420f8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmFJlPyyIIs9Q5pIAIwreQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@querysprout?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Marques Thomas @ querysprout . com</a>在<a class="ae ky" href="https://unsplash.com/s/photos/walmart?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="c9d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">沃尔玛是世界上最大的零售商和杂货商，拥有超过4650家店铺。沃尔玛必须不断转移未售出的库存，为新的更畅销的商品腾出空间。转移多余库存的通常策略是实施降价。这是一项费时费力的工作，需要逐个商店多次对打折商品重新贴标签。</p><p id="029f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了降低运营成本，<a class="ae ky" href="https://www.youtube.com/watch?v=pxWkg2N0l9c" rel="noopener ugc nofollow" target="_blank">沃尔玛创造了一种优化降价的算法</a>。该算法接收数据，包括销售数据、运营成本、商品的数量和类型，以及商品必须销售的动态时间框架。</p><p id="d5de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该方法应用数据分析、强化学习和动态优化来为每个产品做出自动化决策，并为每个商店量身定制。其结果是降低了运营成本，增加了销售额，一些商店的待搬迁库存销售额增加了15%。</p><h1 id="9b4b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4.使用search.io改进搜索引擎结果</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/cc3fa540711109aa0f7444efbc74e114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWd3ERvOabG7k-2dDddHFQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">诺德伍德主题公司在<a class="ae ky" href="https://unsplash.com/s/photos/search-engine?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="d631" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="http://search.io/" rel="noopener ugc nofollow" target="_blank"> Search.io </a>是一款用于站内搜索查询的AI搜索引擎。他们使用“按等级学习”和强化学习技术来改进他们的搜索等级算法。</p><p id="1bf8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">学习排名涉及使用机器学习模型，该模型在基于相关性评分的查询-结果对的数据集上训练。这种技术的一个缺点是输入(查询结果对得分)保持静态。</p><p id="fca1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">强化学习使用点击、销售、注册等形式的反馈，随着时间的推移帮助改进搜索算法。在这种情况下应用强化学习的挑战在于，搜索结果的质量通常从低开始，并且在开始满足客户期望之前需要时间和数据。</p><h1 id="22dd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">5.用OpenAI的WebGPT改进语言模型</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/2f1562cf95db76730ee6707381230b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ce6qoJZQHoBpFJb_6S52iQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@leecampbell?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">李·坎贝尔</a>在<a class="ae ky" href="https://unsplash.com/s/photos/web-browser?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2067" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">GPT-3是一种用于生成类人文本的语言模型。这些语言模型的缺点是，在执行需要模糊的现实世界知识的任务时，倾向于“幻觉”信息。为了改善这一点，OpenAI教GPT-3使用基于文本的网络浏览器。该模型能够从网页中搜索和收集信息，并使用这些信息来撰写开放式问题的答案。</p><p id="b569" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型最初使用人类演示来训练。在此基础上，通过训练一个奖励模型来预测人类的偏好，可以提高模型的有用性和准确性。然后，使用强化学习或拒绝采样，针对该奖励模型对系统进行优化。结果是该系统被发现比GPT-3更“真实”。</p><h1 id="cfde" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">6.利用IBM的DSX平台在金融市场上进行交易</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/ddfb245f7b1e5b3592ab6383cef535c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4f_CROOkgXWgq3Evj2N_Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com/s/photos/stock-market?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@austindistel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Austin Distel </a>拍摄的照片</p></figure><p id="8c65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于高货币风险，金融行业一直不愿意应用机器学习。<a class="ae ky" href="https://medium.com/ibm-data-ai/reinforcement-learning-the-business-use-case-part-2-c175740999" rel="noopener">在这篇文章</a>中，IBM描述了一个用强化学习训练的交易系统。</p><p id="88da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，强化学习的优势在于能够学习做出预测，以解释算法的行为对市场状态产生的任何影响。这种反馈循环允许算法随着时间的推移自动调整，不断使其更加强大和适应性更强。回报函数是基于每笔交易的盈利或亏损。</p><p id="5ff0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型根据买入并持有策略和ARIMA-GARCH(一种预测模型)进行评估。他们发现该模型能够捕捉头肩顶模式，这是一个不平凡的壮举。</p><h1 id="130d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">7.加州大学伯克利分校的机器人技术</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/ee1728a1c93a120f082fd4b382fdd8d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gC-pHMacu7xJXhf6Wy9k7Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@patriciodavalos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">帕特里西奥·达瓦洛斯</a>在<a class="ae ky" href="https://unsplash.com/s/photos/robot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="3bc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开发机器人控制器是一项具有挑战性的任务。典型的方法包括仔细的建模，但是当暴露在意外的情况和环境中时容易失败。</p><p id="5f46" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">加州大学伯克利分校的一个团队试图通过使用强化学习训练一个真正的双足机器人来解决这个问题。该团队能够开发出一种模型，从而对名为Cassie的机器人进行更加多样化和鲁棒的行走控制。</p><p id="88fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">部署的模型能够执行各种行为，例如在现实世界中改变行走高度、快速行走、侧向行走和转弯。它对机器人本身(例如部分损坏的电机)和环境(例如地面摩擦力的变化和从不同方向被推动)的变化也很鲁棒。你可以在这个视频中观看凯西的行动。</p><h1 id="227b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="150a" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">虽然强化学习在现实世界中的应用仍处于早期阶段，但我希望这个列表突出了该技术的潜力以及迄今为止已经发生的令人兴奋的进展。随着数据收集、模拟、处理能力和研究的不断发展，谁知道我们在未来几年还会看到什么？</p><p id="3a58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果强化学习领域让你兴奋，这里有一些我的其他文章，你可能会觉得有用:</p><ul class=""><li id="525b" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated"><a class="ae ky" href="https://medium.com/coder-one/creating-your-first-game-playing-bot-2fb176a0b469" rel="noopener">open ai健身房出租车强化学习介绍</a></li><li id="f07f" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><a class="ae ky" href="https://medium.com/coder-one/a-hands-on-introduction-to-deep-reinforcement-learning-using-unity-ml-agents-e339dcb5b954" rel="noopener">深度强化学习的实践介绍</a></li><li id="558b" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/8-reinforcement-learning-project-ideas-3521e0ccd313"> 8+强化学习项目创意</a></li></ul><p id="9c6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读！</p></div></div>    
</body>
</html>