<html>
<head>
<title>Boosting Forecast Performance with Nixtla’s StatsForecast</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助Nixtla的StatsForecast提升预测性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boosting-forecast-performance-with-nixtlas-statsforecast-2282fae91850#2022-08-25">https://towardsdatascience.com/boosting-forecast-performance-with-nixtlas-statsforecast-2282fae91850#2022-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0148" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提高百里香的效率</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4ebb381bed09ba1fec41a7618d285d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xJknqmZzptRvuQRZp_nFCg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Marc-Olivier Jodoin 在<a class="ae ky" href="https://unsplash.com/s/photos/speed?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="805e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">百里香增强框架，在其核心，只是一个简单的梯度增强算法包装在标准的时间序列方法。这意味着框架严重依赖<em class="lv">底层方法的效率和速度。正如我们将在本文中看到的，增强和附加逻辑增加了准确性，但也增加了计算量。这种繁重的工作大部分以前是通过ETS和ARIMA等统计模型实现的，但利用Nixtla的统计预测包:<a class="ae ky" href="https://github.com/Nixtla/statsforecast" rel="noopener ugc nofollow" target="_blank"> StatsForecast，</a>可以提高<strong class="lb iu">速度和准确性。使ThymeBoost和StatsForecast成为时间序列预测的完美结合。</strong></em></p><p id="ac4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的好<strong class="lb iu"> TLDR </strong>是:</p><p id="cd74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">stats forecast<strong class="lb iu">比stats models</strong>快，ThymeBoost带来<strong class="lb iu">精度</strong>增益。</p><p id="32e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://github.com/tblume1992/ThymeBoost" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Github for百里香增强</strong> </a></p><h2 id="fd7c" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">介绍</h2><p id="87c7" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">首先，如果你没有听说过百里香，那么我鼓励你看看我之前的文章给出了一个不错的概述。在最新版本中，我添加了StatsForecast作为可选的依赖项。为了运行这些示例，您需要安装它:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="7357" class="lw lx it mv b gy mz na l nb nc">pip install StatsForecast</span></pre><p id="04ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了安全起见，请继续更新百里香增强:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="445a" class="lw lx it mv b gy mz na l nb nc">pip install ThymeBoost --upgrade</span></pre><p id="1eb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们已经解决了这个问题，那么本文的主要内容将是在每周M4数据集上进行基准测试，以了解所有这些模型在准确性和速度方面的表现。这些数据集都是开源的，并且在M-competitions <a class="ae ky" href="https://github.com/Mcompetitions/M4-methods/tree/master/Dataset" rel="noopener ugc nofollow" target="_blank"> github </a>上直播。它被标准训练和测试分割，因此我们将使用训练csv进行拟合，而测试csv仅用于使用SMAPE进行评估。</p><p id="59e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请随意用其他数据集测试，并让我知道他们的表现如何！</p><p id="e21a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这样做的主要目的是回顾新方法在boosting框架中的作用，并最终了解将它们添加到ThymeBoost框架中如何提高准确性。</p><h2 id="c0eb" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">对方法进行基准测试</h2><p id="223f" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">首先，我们将尝试一下ThymeBoost中计算量最大的方法:AutoArima。以前是用PmdArima完成的，现在我们可以用StatsForecast进行测试，只需在与ThymeBoost配合时通过<code class="fe nd ne nf mv b">trend_estimator=‘fast_arima’</code>即可。让我们来看看一些代码，在这些代码中，我们首先构建数据集，然后我们可以运行百里香增强:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ee73" class="lw lx it mv b gy mz na l nb nc">from tqdm import tqdm<br/>from statsforecast.models import ETS, AutoARIMA<br/>from ThymeBoost import ThymeBoost as tb<br/>tqdm.pandas()<br/>train_df = pd.read_csv(r'm4-weekly-train.csv')<br/>test_df = pd.read_csv(r'm4-weekly-test.csv')<br/>forecast_horizon = len(test_df.columns) - 1<br/>train_df = train_df.rename({'V1': 'ID'}, axis=1)<br/>train_long = pd.wide_to_long(train_df, ['V'], 'ID', 'Date')<br/>test_df = test_df.rename({'V1': 'ID'}, axis=1)<br/>test_df = pd.wide_to_long(test_df, ['V'], 'ID', 'Date')<br/>train_long = train_long.dropna()<br/>train_df = train_long.reset_index()<br/>train_df.index = train_df['ID']<br/>train_df = train_df.drop('ID', axis = 1)<br/>X = train_long<br/>X = X.reset_index()</span></pre><ul class=""><li id="cd6b" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nl nm nn no bi translated"><em class="lv">注意:这段代码在数据操作方面可能效率很低，我确信有更好的方法来做这件事，这只是我为基准测试做的一些工作。时间不包括运行这段代码的时间。</em></li></ul><p id="8175" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不管怎样，现在我们有了要拟合的训练数据，让我们来看看拟合函数:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="fe74" class="lw lx it mv b gy mz na l nb nc">def grouped_forecast(df):<br/>    y = df['V'].values<br/>    boosted_model = tb.ThymeBoost(verbose=0)<br/>    output = boosted_model.fit(y,<br/>                               seasonal_period=None,<br/>                               trend_estimator=['fast_arima'])<br/>    predicted_output = boosted_model.predict(output,<br/>                                              forecast_horizon,<br/>                                              trend_penalty=True)<br/>    predictions = predicted_output['predictions']<br/>    return predictions</span></pre><p id="16ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们只是创建一个函数，当我们执行groupby并应用时，该函数将被传递:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="ca04" class="lw lx it mv b gy mz na l nb nc">def counter(df):<br/>    df['counter'] = np.arange(2, len(df) + 2)<br/>    return df<br/>predictions = X.groupby('ID').progress_apply(grouped_forecast)<br/>predictions = predictions.reset_index()<br/>predictions = predictions.groupby('ID').apply(counter)<br/>test_df = test_df.reset_index()<br/>benchmark_df = predictions.merge(test_df, left_on=['ID', 'counter'],<br/>                                 right_on=['ID', 'Date'])</span><span id="d444" class="lw lx it mv b gy np na l nb nc">def smape(A, F):<br/>    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))<br/>tqdm.pandas()<br/>def grouped_smape(df):<br/>    return smape(df['V'], df['predictions'])<br/>test = benchmark_df.groupby('ID').progress_apply(grouped_smape)<br/>print(np.mean(test))</span></pre><p id="00df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我们得到给定输出的平均SMAPE，这里的一切都应该是好的，但如果有任何错误会混淆基准，请让我知道。</p><p id="fdd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行这个程序会得到平均SMAPE值<strong class="lb iu"> 8.61 </strong>，大概需要10分钟。</p><p id="4ea0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们单独运行Nixtla的Auto Arima，看看它的表现如何。</p><p id="ce88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将把groupby预测函数改为:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="e3df" class="lw lx it mv b gy mz na l nb nc">def grouped_forecast(df):<br/>    y = df['V'].values<br/>    ar_model = AutoARIMA().fit(y)<br/>    predictions = pd.DataFrame(ar_model.predict(forecast_horizon)['mean'],<br/>                                columns=['predictions'])<br/>    return predictions</span></pre><p id="a913" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重新运行上面的SMAPE计算块将得到一个8.93的SMAPE和大约4分钟的时间。</p><p id="501a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好的，很好，我们已经通过提高Auto-Arima过程展示了一些精度增益。这应该不足为奇，因为我在一篇文章《深度潜水<a class="ae ky" href="https://medium.com/p/e093f80772f6" rel="noopener">梯度提升Arima </a>中展示了非常相似的结果。但是我想提醒一下，boosting并不是万能的，也不总是比Arima好，但是它仍然是一个有趣的观察。</p><p id="9073" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步应该很明显。我们已经看了“快速”自动Arimain百里香增压以及StatsForecast的无增压自动Arimain。接下来，我们应该看看如何使用PmdArima的Auto-Arimain百里香增强。</p><p id="5b8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您一直在运行这段代码，请系好安全带。</p><p id="b0c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步需要一些时间…</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="dfa3" class="lw lx it mv b gy mz na l nb nc">def grouped_forecast(df):<br/>    y = df['V'].values<br/>    boosted_model = tb.ThymeBoost(verbose=0, n_rounds=None)<br/>    output = boosted_model.fit(y,<br/>                               seasonal_period=None,<br/>                               trend_estimator=['arima'],<br/>                               arima_order='auto')<br/>    predicted_output = boosted_model.predict(output,<br/>                                              forecast_horizon,<br/>                                              trend_penalty=True)<br/>    predictions = predicted_output['predictions']<br/>    return predictions</span></pre><p id="3bd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果呢？</p><p id="67f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个SMAPE的<strong class="lb iu"> 8.78 </strong>，但是用了90分钟。看起来提升Pmd Arima优于Nixtla的StatsForecast开箱即用，但它需要相当长的时间。</p><p id="20ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Arima不是StatsForecast中的所有产品，另一个实现是ETS方法。有了这些新方法，我们实际上可以在ThymeBoost的<code class="fe nd ne nf mv b">autofit</code>方法中利用这些更快的实现。为此，我们只需要在调用autofit时传递<code class="fe nd ne nf mv b">fast=True</code>。新的预测函数将如下所示:</p><pre class="kj kk kl km gt mu mv mw mx aw my bi"><span id="a086" class="lw lx it mv b gy mz na l nb nc">def grouped_forecast(df):<br/>    y = df['V'].values<br/>    boosted_model = tb.ThymeBoost(verbose=0, n_rounds=None)<br/>    output = boosted_model.autofit(y,<br/>                                    seasonal_period=[52],<br/>                                    optimization_type='grid_search',<br/>                                    optimization_strategy='holdout',<br/>                                    lag=26,<br/>                                    optimization_metric='smape',<br/>                                    verbose=False,<br/>                                    fast=False<br/>                                )</span><span id="3fbe" class="lw lx it mv b gy np na l nb nc">    predicted_output = boosted_model.predict(output,<br/>                                              forecast_horizon,<br/>                                              trend_penalty=True)<br/>    predictions = predicted_output['predictions']<br/>    return predictions</span></pre><p id="7ee1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这导致SMAPE为7.88，并且需要大约80分钟。绝对是所有测试中最好的即插即用精度，但我们选择型号有点作弊。</p><p id="3c59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要注意的一点是，将季节长度52传递给StatsForecast的方法并不是一个好主意。对于ETS it错误和Auto-Arima来说，时间太长了。这是一个利用百里香实际上如何工作的领域<em class="lv">提高</em>的速度，因为在ARIMA设置中长的季节周期需要明显更长的时间。</p><p id="9605" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们测试了其他几种方法，您可以在下面查看基准测试结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/d1da82e049eeb5d16ac86e4c2b0aa95f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d6kvWVN-agUxj7Ih_HUfrA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="b1cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就首字母缩略词而言:</p><ol class=""><li id="1442" class="ng nh it lb b lc ld lf lg li ni lm nj lq nk lu nr nm nn no bi translated">结核病:百里香增强</li><li id="fa64" class="ng nh it lb b lc ns lf nt li nu lm nv lq nw lu nr nm nn no bi translated">SF:统计预测</li><li id="43ac" class="ng nh it lb b lc ns lf nt li nu lm nv lq nw lu nr nm nn no bi translated">NS:非季节性</li><li id="ddea" class="ng nh it lb b lc ns lf nt li nu lm nv lq nw lu nr nm nn no bi translated">倍增:倍增的季节性</li><li id="9a53" class="ng nh it lb b lc ns lf nt li nu lm nv lq nw lu nr nm nn no bi translated">快速:百里香利用统计预测引擎盖下</li></ol><p id="5911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在高层次上，性能最好的是来自百里香增强的快速自动拟合方法。出于某些奇怪的原因，用季节性和快速Arima拟合百里香增强并没有表现得太好，事实上它比使用PmdArima的Auto-Arima要差得多。另一个观察结果是，从StatsForecast提升普通ETS方法可能会损害非提升方法正常拟合的准确性。如果我们改变拟合函数中的<code class="fe nd ne nf mv b">global_cost</code>参数，这种情况可能会改变，因为默认情况可能并不总是最佳的。</p><h2 id="244b" class="lw lx it bd ly lz ma dn mb mc md dp me li mf mg mh lm mi mj mk lq ml mm mn mo bi translated">结论</h2><p id="9cef" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">最新版本的ThymeBoost增加了一些引入StatsForecast方法的功能。与之前的实现相比，我们可以看到速度的提高和潜在的准确性。</p><p id="a4ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">百里香和一个好蛋糕一样，需要有好的面糊作为底料。StatsForecast可能是优于StatsModels。梯度推进只是顶部的点缀。</p><p id="1a8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你喜欢这篇文章，你可以看看我写的其他一些与时间序列相关的帖子:</p><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/lazyprophet-time-series-forecasting-with-lightgbm-3745bafe5ce5"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">LazyProphet:用LightGBM进行时间序列预测</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">都是关于功能的</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo ks oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/handling-trends-in-tree-based-time-series-forecasting-fea5e4c066fb"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">基于树的时间序列预测中的趋势处理</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">事实是——没有趋势</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="op l ol om on oj oo ks oa"/></div></div></a></div><div class="nx ny gp gr nz oa"><a rel="noopener follow" target="_blank" href="/online-time-series-forecasting-in-python-12bada43b8bd"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd iu gy z fp of fr fs og fu fw is bi translated">Python中基于流数据的时间序列预测</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">百里香增强剂的例子</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">towardsdatascience.com</p></div></div><div class="oj l"><div class="oq l ol om on oj oo ks oa"/></div></div></a></div></div></div>    
</body>
</html>