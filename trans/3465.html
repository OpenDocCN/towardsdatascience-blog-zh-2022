<html>
<head>
<title>Understand the Workings of SHAP and Shapley Values Used in Explainable AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解可解释人工智能中使用的SHAP和沙普利值的工作原理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e#2022-08-01">https://towardsdatascience.com/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e#2022-08-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f588" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">你还对SHAP和沙普利价值观的运作感到困惑吗？让我在本文中对SHAP值和沙普利值提供最简单直观的解释。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fc3b3afc89ce715d65f6b16f6835780a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hyFk6Diav7cnirMDS5Fesw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源—<a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">https://github.com/slundberg/shap</a></p></figure><p id="1673" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">【沙普利附加解释】</strong> </a>，这是另一个流行的<a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">可解释AI</strong>(<strong class="lb iu">【XAI)</strong></a><strong class="lb iu"/>框架，可以为表格、图像和文本数据集提供模型不可知的局部可解释性。</p><p id="07d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> SHAP </strong>基于沙普利值，沙普利值是<a class="ae ky" href="https://c3.ai/glossary/data-science/shapley-values/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">博弈论</strong> </a>中普遍使用的概念。尽管对Shapley值的数学理解可能很复杂，但我将提供对<strong class="lb iu"> Shapley值</strong>和<strong class="lb iu"> SHAP </strong>的简单、直观的理解，并更多地关注该框架的实际方面。在本文中，我将参考SHAP在《应用机器学习可解释技术》一书中提供的非常简单的解释，并推荐浏览GitHub库https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques/tree/main/chapter 06，以获得在Python中应用SHAP的实用代码示例<a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank">。</a></p><div class="lv lw gp gr lx ly"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.amazon.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="27ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想得到关于这本书的详细反馈，这个视频可能对你有用:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="6545" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对XAI概念不太熟悉，我强烈推荐你观看过去在2021年APAC人工智能加速器节上发表的关于XAI的演讲:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="f1f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们现在就开始吧，不要耽搁！</p><h1 id="dee7" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">SHAP值和沙普利值简介</h1><p id="ee68" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated"><strong class="lb iu"> SHAP框架</strong>是由<strong class="lb iu"> Scott Lundberg </strong>和<strong class="lb iu"> Su-In Lee </strong>在他们的研究工作中提出的，<a class="ae ky" href="https://arxiv.org/abs/1705.07874" rel="noopener ugc nofollow" target="_blank"> <em class="nm">解释模型预测</em> </a>的统一方法。这是2017年发表的。SHAP是基于合作博弈论中Shapley值的概念，它考虑了附加特征的重要性。</p><p id="89a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据定义，Shapley值是每个特征值对特征空间中所有可能值的平均<em class="nm">边际贡献。Shapley值的数学理解很复杂，可能会让大多数读者感到困惑。也就是说，如果你有兴趣深入了解沙普利值的数学知识，我们建议你看看名为<em class="nm">“n人游戏的价值”的研究论文《博弈论》投稿2.28</em><strong class="lb iu">(1953)</strong><strong class="lb iu">罗伊德·S·沙普利</strong>。在下一节中，我们将通过一个非常简单的例子来直观地了解Shapley值。</em></p><h1 id="96d8" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">什么是沙普利价值观？</h1><p id="5261" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在这一节中，我将用一个非常简单易懂的例子来解释Shapley值。让我们假设Alice、Bob和Charlie是三个朋友，他们作为一个团队参加了一场Kaggle比赛，以解决给定的ML问题，并获得一定的现金奖励。他们的共同目标是赢得比赛，获得奖金。他们三个在ML的所有领域都同样不好，因此以不同的方式做出了贡献。现在，如果他们赢得了比赛并赢得了奖金，考虑到他们个人的贡献，他们将如何确保奖金的公平分配？他们将如何衡量自己对同一目标的贡献？这些问题的答案可以由Shapley值给出，Shapley值是由Lloyd Shapley于1951年在T21提出的。</p><p id="0082" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图直观地展示了这种情况:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/e28c564ab50cb316ffbe1c6402d5a709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C044NoeaOH3nV__Zw1JRVg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank">作者图片</a></p></figure><p id="b6bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在这个场景中，Alice、Bob和Charlie属于同一个团队，玩同一个游戏(即Kaggle竞赛)。在博弈论中，这被称为联盟博弈。比赛的奖金是他们的支出。因此，Shapley值告诉我们每个玩家对确保公平分配的支出的平均贡献。但是为什么不在所有玩家之间平均分配奖金呢？嗯，既然贡献不对等，那么把钱平均分配就不公平了。</p><h1 id="fb0d" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">决定支出</h1><p id="f803" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">现在，我们如何决定最公平的分配方式呢？一种方法是假设Alice、Bob和Charlie按顺序加入游戏，Alice先开始，Bob接着，Charlie接着。让我们假设，如果爱丽丝、鲍勃和查理单独参与，他们将分别获得10分、20分和25分。但如果爱丽丝和鲍勃联手，他们可能会得到40分。爱丽丝和查理一起可以得到30分，鲍勃和查理一起可以得到50分。当他们三个一起合作时，只有这样他们才能得到90分，这足以让他们赢得比赛。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ccdc84489f6a83c3cfe68115a35cb52d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*dsz1aX0McfYbTxqmWZ9f6A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">该表说明了用于计算每个玩家的平均边际贡献的每个条件的分值</p></figure><p id="fc47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数学上，如果我们假设有n个玩家，其中s是玩家的联盟子集，𝑣(𝑆)是s个玩家的总价值，那么通过Shapley值的公式，玩家I的边际贡献给出如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/c19ef8d4d3a2b41c05b864b329fa1373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*bcmLTb6tXyvJwK54GcfBrw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">参与人I的边际贡献等式</p></figure><p id="b99a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Shapley值的等式可能看起来很复杂，但是让我们用我们的例子来简化它。请注意，每个玩家开始游戏的顺序很重要，因为Shapley值试图考虑每个玩家计算边际贡献的顺序。</p><p id="f486" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，对于我们的示例，可以通过计算爱丽丝对最终得分可能造成的差异来计算爱丽丝的贡献。因此，贡献是通过计算爱丽丝在游戏中和不在游戏中得分的差异来计算的。</p><p id="3856" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有，当爱丽丝在玩的时候，她既可以独自玩，也可以和别人组队玩。当爱丽丝在玩的时候，她能创造的价值可以表示为𝑣(𝐴).同样，𝑣(𝐵)和𝑣(𝐶)表示鲍勃和查理创造的个人价值。现在，当Alice和Bob合作时，我们可以通过从总贡献中移除Bob的贡献来计算Alice的贡献。这可以用𝑣(𝐴、𝐵)–𝑣(𝐵来代表)。如果三个人一起玩，爱丽丝的贡献是𝑣(𝐴，𝐵，𝐶)–𝑣(𝐵，𝐶).</p><p id="d911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到爱丽丝、鲍勃和查理玩游戏的序列的所有可能排列，爱丽丝的边际贡献是她在所有可能场景中个人贡献的平均值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/f0eb099b42cb9c6fa2d8ad27625596cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KK1o7DFrZYn_eevIXBvmGA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">爱丽丝的沙普利值是考虑到所有可能的情况下她的边际贡献</p></figure><p id="5a3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，爱丽丝的总贡献将是她在所有可能情况下的边际贡献，这也恰好是沙普利值。对于爱丽丝来说，沙普利值是<strong class="lb iu"> 20.83 </strong>。同样，我们可以计算Bob和Charlie的边际贡献，如下表所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/36c96af72a41b66f3a7638fc1c0da58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wE926Hn1ZxeYbVqIUUO15g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">爱丽丝、鲍勃和查理的边际贡献</p></figure><p id="4fe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这不会太难理解！需要注意的一点是，Alice、Bob和Charlie的边际贡献之和应该等于他们三个加在一起的总贡献。现在，让我们试着在ML的背景下理解Shapley值。</p><div class="lv lw gp gr lx ly"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.amazon.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="bff5" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">沙普利值(ML)</h1><p id="a170" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">为了理解ML中Shapley值对解释模型预测的重要性，我们将尝试修改我们用于理解Shapley值的关于Alice、Bob和Charlie的示例。我们可以将Alice、Bob和Charlie视为用于训练模型的数据集中存在的三个不同特征。因此，在这种情况下，玩家的贡献将是每个特性的贡献。游戏或Kaggle竞争将是黑盒ML模型，支出将是预测。因此，如果我们想知道每个特征对模型预测的贡献，我们将使用Shapley值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/736ae7f328dc03c13989b6fc897ab3fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7peMAm-Ndqoq7h-XJpnAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在ML环境下理解Shapley值(<a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank">图片作者</a></p></figure><p id="6870" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，Shapley值帮助我们理解每个特征对黑盒ML模型预测的结果的集体贡献。通过使用Shapley值，我们可以通过估计特征贡献来解释黑盒模型的工作。</p><h1 id="1e06" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">摘要</h1><p id="92c7" class="pw-post-body-paragraph kz la it lb b lc nh ju le lf ni jx lh li nj lk ll lm nk lo lp lq nl ls lt lu im bi translated">在本文中，我们关注于理解SHAP框架对于模型可解释性的重要性。至此，您已经对沙普利价值观和SHAP有了很好的了解。如果你喜欢这篇文章，并想了解更多关于如何应用SHAP来解释ML模型的信息，我推荐阅读这本书:<a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">【应用机器学习可解释技术】</strong> </a> <strong class="lb iu"> </strong>并探索GitHub资源库:<a class="ae ky" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/tree/main/Chapter06" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques/tree/main/chapter 06</a>以获得实际操作的代码示例。</p><div class="lv lw gp gr lx ly"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.amazon.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="96ff" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">作者关于TDS的其他XAI相关文章:</h1><ol class=""><li id="bbc4" class="nt nu it lb b lc nh lf ni li nv lm nw lq nx lu ny nz oa ob bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/explainable-machine-learning-for-models-trained-on-text-data-combining-shap-with-transformer-5095ea7f3a8">用于在文本数据上训练的模型的可解释机器学习:将SHAP与变压器模型相结合</a></li><li id="b9e7" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/euca-an-effective-xai-framework-to-bring-artificial-intelligence-closer-to-end-users-74bb0136ffb1">EUCA——一个有效的XAI框架，让人工智能更贴近终端用户</a></li></ol><div class="lv lw gp gr lx ly"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.amazon.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><h1 id="7e6f" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">参考</h1><ol class=""><li id="761f" class="nt nu it lb b lc nh lf ni li nv lm nw lq nx lu ny nz oa ob bi translated">Python SHAP框架的GitHub repo—【https://github.com/slundberg/shap T2】</li><li id="d823" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">应用机器学习解释技术—【https://amzn.to/3cY4c2h T4】</li><li id="4940" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">GitHub repo自《应用机器学习可解释技术》——<a class="ae ky" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques/</a></li></ol></div></div>    
</body>
</html>