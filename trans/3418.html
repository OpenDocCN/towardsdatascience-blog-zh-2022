<html>
<head>
<title>Beware of the Hidden Error in Your Test Score</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当心你考试分数中隐藏的错误</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beware-of-the-hidden-error-in-your-test-score-c88c6a3b9b1b#2022-07-28">https://towardsdatascience.com/beware-of-the-hidden-error-in-your-test-score-c88c6a3b9b1b#2022-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7532" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">为什么应该报告测试集的置信区间</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/be4dc83a98a648fb42848e56664ba615.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gr-e9wlfwGahOwnJC1gRWA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:你的机器学习模型的测试分数受统计波动的影响。图片作者。</p></figure><p id="4033" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在实验科学中，我们习惯于用误差线和有效数字来报告估计值。例如，当您在实验室中称量样品时，您可以读出其质量，比如说，三位数。在机器学习中，这是不同的。当您评估模型的准确性时，您会得到一个数值误差达到机器精度的值。这就好像你的模型得出的精确估计是可靠的，精确到小数点后七位。不幸的是，外表可能具有欺骗性。你的考试分数中有一个隐藏的错误。数据的随机本质所固有的不可克服的变化。一个潜在的大误差，它完全决定了你的模型的性能分数的可靠性。</p><p id="901e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我说的是<strong class="kx ir">统计波动</strong>。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="2e63" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">情况</h1><p id="0cf4" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">假设你刚被一家新的生物技术公司聘为数据科学家。你的任务？使用他们的尖端测量设备来预测患者是否需要挽救生命的手术。首席执行官对你非常有信心，并为你的项目拨款10万欧元给€。由于这项技术仍处于起步阶段，每次测量仍然相当昂贵，每个样本要花费€2500英镑。您决定将全部预算用于数据获取，并着手收集20个训练样本和20个测试样本。</p><p id="b108" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(您可以通过执行Python代码块来理解叙述。)</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="c644" class="na lz iq mw b gy nb nc l nd ne"><strong class="mw ir">from</strong> sklearn.datasets <strong class="mw ir">import</strong> make_blobs</span><span id="6322" class="na lz iq mw b gy nf nc l nd ne">centers = [[0, 0], [1, 1]]<br/>X_train, y_train = make_blobs(<br/>    centers=centers, cluster_std=1, n_samples=20, random_state=5<br/>)<br/>X_test, y_test = make_blobs(<br/>    centers=centers, cluster_std=1, n_samples=20, random_state=1005<br/>)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/9ab542bfb2f7b484e3857ecac1fd18a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*0Wx7p0MOn_6m4LyGeKolFQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:阳性标签(红叉)和阴性标签(蓝圈)的训练数据。图片作者。</p></figure><p id="c51e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">完成测量后，您可以看到训练数据集(图2)。考虑到这一点点数据，还是很难辨认出不同的模式。因此，您首先要使用一个简单的线性模型:逻辑回归来建立一个基线性能。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="9c5f" class="na lz iq mw b gy nb nc l nd ne"><strong class="mw ir">from</strong> sklearn.linear_model <strong class="mw ir">import</strong> LogisticRegression</span><span id="023a" class="na lz iq mw b gy nf nc l nd ne">baseline_model = LogisticRegression(random_state=5).fit(X_train, y_train)<br/>baseline_model.score(X_test, y_test)  # Output: 0.85.</span></pre><p id="01d3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">实际上，这还不错:在测试集上有85 %的准确率。建立了一个强大的基线后，你开始尝试一个更复杂的模型。经过一番深思熟虑后，你决定尝试一下梯度增强树，因为它们在Kaggle上很成功。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="8511" class="na lz iq mw b gy nb nc l nd ne"><strong class="mw ir">from</strong> sklearn.ensemble <strong class="mw ir">import</strong> GradientBoostingClassifier</span><span id="6e40" class="na lz iq mw b gy nf nc l nd ne">tree_model = GradientBoostingClassifier(random_state=5).fit(X_train, y_train)<br/>tree_model.score(X_test, y_test)  # Output: 0.90.</span></pre><p id="fe6b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">哇！90 %的准确率。满怀兴奋，你向首席执行官汇报了你的发现。她似乎对你的巨大成功感到高兴。你们一起决定将更复杂的分类器部署到生产中。</p><p id="54a2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">模型投入生产后不久，您就开始收到客户的投诉。看起来你的模型可能没有你的测试集精度所建议的那样好。</p><p id="4c3d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是怎么回事？你应该怎么做？回滚到更简单但性能更差的基线模型？</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="d7a8" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">统计波动</h1><p id="e02f" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">为了理解统计波动，我们必须看看抽样过程。当我们收集数据时，我们从未知的分布中抽取样本。我们说未知，因为如果我们知道数据生成分布，那么我们的任务就完成了:我们可以完美地对样本进行分类(达到不可约误差)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/4b6d13c01546b8e42c9a4d4f005652c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R3WlEVIo24eqYE6C_McDyw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:假设您从包含简单案例(可正确分类，蓝色)和困难案例(不可正确分类，红色)的分布中收集样本。在小型数据集中，您有相当大的机会获得最简单或最困难的案例。图片作者。</p></figure><p id="25f1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，将你的模型能够正确预测的简单案例涂成蓝色，将分类不正确的困难案例涂成红色(图3，左侧)。通过构建数据集，您实际上是在绘制一组红色和蓝色的球(图3，中间)。在这种情况下，精确度是所有球中蓝色球的数量(图3，右)。每次你构建一个数据集，蓝球的数量——你的模型的精确度——<em class="ni">围绕它的“真实”值波动</em>。</p><p id="a1ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">正如你所看到的，通过抽一把球，你有相当大的机会得到大部分是红色或蓝色的球:统计波动很大！随着你收集的数据越来越多，波动的幅度会越来越小，所以平均颜色会收敛到它的“真实”值。</p><p id="39cf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">另一种思考方式是，统计波动是你估计的误差。在实验科学中，我们通常会报告平均值、<em class="ni">、标准差、<em class="ni">、σ </em>。我们这样说的意思是，如果<em class="ni"> </em>和<em class="ni"/>是正确的，我们预计<em class="ni">高斯波动</em>在[ <em class="ni"> -2σ，+2σ] </em>之间大约95 %的时间<em class="ni">。</em>在机器学习和统计中，我们经常处理比高斯分布更奇特的分布。因此，更常见的是报告95 %置信区间(CI):95%情况下的波动范围，不考虑分布情况。</em></p><p id="caf9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们把这个理论付诸实践。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h1 id="0566" class="ly lz iq bd ma mb mc md me mf mg mh mi jw mj jx mk jz ml ka mm kc mn kd mo mp bi translated">分辨率:带误差线的估计值</h1><p id="94c6" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">回到你在生物技术创业公司的任务，预测病人是否需要挽救生命的手术。了解了统计波动后，你开始怀疑这些波动可能是你问题的核心。如果我的测试集很小，那么统计波动一定很大。因此，你开始量化你可能合理期望的精度范围。</p><p id="5b41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">量化模型分数统计波动的一种方法是使用一种叫做<a class="ae nj" href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)" rel="noopener ugc nofollow" target="_blank"> bootstrapping </a>的统计技术。Bootstrapping意味着你随机抽取数据集，并用它们来估计不确定性。一个有用的Python包是<a class="ae nj" href="https://gitlab.com/hylkedonker/statkit" rel="noopener ugc nofollow" target="_blank"> statkit </a> ( <code class="fe nk nl nm mw b"><strong class="kx ir">pip3</strong> install statkit</code>)，它是我们专门设计来与sci-kit learn集成的。</p><p id="14c1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从计算基线模型的置信区间开始。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="77b9" class="na lz iq mw b gy nb nc l nd ne"><strong class="mw ir">from</strong> sklearn.metrics <strong class="mw ir">import</strong> accuracy_score<br/><strong class="mw ir">from</strong> statkit.non_parametric <strong class="mw ir">import</strong> bootstrap_score</span><span id="f075" class="na lz iq mw b gy nf nc l nd ne">y_pred_simple = baseline_model.predict(X_test)<br/>baseline_accuracy = bootstrap_score(<br/>    y_test, y_pred_simple, metric=accuracy_score, random_state=5<br/>)<br/><strong class="mw ir">print</strong>(baseline_accuracy)  <em class="ni"># Output: 0.85 (95 % CI: 0.65-1.0)</em></span></pre><p id="6ab7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，虽然您的基线模型在测试集上的准确性为85 %，但我们可以预计，在大多数时间，准确性在65 % — 100 %的范围内。评估更复杂模型的精度范围，</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="82f7" class="na lz iq mw b gy nb nc l nd ne">y_pred_tree = tree_model.predict(X_test)<br/>tree_accuracy = bootstrap_score(y_test, y_pred_tree, metric=accuracy_score, random_state=5)<br/><strong class="mw ir">print</strong>(tree_accuracy)  <em class="ni"># Output: 0.90 (95 % CI: 0.75–1.0)</em></span></pre><p id="fd73" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们发现差不多(75 %到100 %之间)。因此，与你和CEO最初的想法相反，越复杂并不是越好。</p><p id="f28a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从错误中吸取教训后，你决定退回到更简单的基线模型。不愿意让更多愤怒的客户，你清楚地传达你的模型的性能的带宽，并保持密切联系，以尽早获得反馈。经过一段时间的努力监控，您设法收集到了更多的数据。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="4dca" class="na lz iq mw b gy nb nc l nd ne">X_large, y_large = make_blobs(centers=centers, cluster_std=1, n_samples=10000, random_state=0)</span></pre><p id="9c51" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些额外的测量允许您更准确地评估性能。</p><pre class="kg kh ki kj gt mv mw mx my aw mz bi"><span id="9bfc" class="na lz iq mw b gy nb nc l nd ne">baseline_accuracy_large = bootstrap_score(<br/>    y_large,<br/>    baseline_model.predict(X_large),<br/>    metric=accuracy_score,<br/>    random_state=5<br/>)<br/><strong class="mw ir">print</strong>('Logistic regression:', baseline_accuracy_large)<br/><em class="ni"># Output: 0.762 (95 % CI: 0.753-0.771)</em></span><span id="2212" class="na lz iq mw b gy nf nc l nd ne">tree_accuracy_large = bootstrap_score(<br/>    y_large, <br/>    tree_model.predict(X_large), <br/>    metric=accuracy_score, <br/>    random_state=5<br/>)<br/><strong class="mw ir">print</strong>('Gradient boosted trees:', tree_accuracy_large)<br/><em class="ni"># Output: 0.704 (95 % CI: 0.694-0.713)</em></span></pre><p id="ddb9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">更大的数据集证实:你更简单的基线模型确实更好。</p><h1 id="83a6" class="ly lz iq bd ma mb nn md me mf no mh mi jw np jx mk jz nq ka mm kc nr kd mo mp bi translated">结论</h1><p id="7022" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">不要被你的考试成绩所欺骗:它们可能是统计学上的侥幸。特别是对于小数据集，由于统计波动导致的误差可能很大。我们的建议是:拥抱未知，用95 %的置信区间量化你估计中的不确定性。这将防止您在真实世界的性能低于测试集的点估计值时措手不及。</p></div><div class="ab cl lr ls hu lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="ij ik il im in"><h2 id="ddd1" class="na lz iq bd ma ns nt dn me nu nv dp mi le nw nx mk li ny nz mm lm oa ob mo oc bi translated">承认</h2><p id="0784" class="pw-post-body-paragraph kv kw iq kx b ky mq jr la lb mr ju ld le ms lg lh li mt lk ll lm mu lo lp lq ij bi translated">感谢<a class="ae nj" href="https://huijzer.xyz/" rel="noopener ugc nofollow" target="_blank"> Rik Huijzer </a>的校对。</p></div></div>    
</body>
</html>