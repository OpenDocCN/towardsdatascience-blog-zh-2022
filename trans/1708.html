<html>
<head>
<title>How to Interpret Any Machine Learning Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何解读任何机器学习预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-interpret-any-machine-learning-prediction-64ff43020214#2022-04-22">https://towardsdatascience.com/how-to-interpret-any-machine-learning-prediction-64ff43020214#2022-04-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="c9e4" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">人工智能|可解释性|数据科学</h2><div class=""/><div class=""><h2 id="5375" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">将黑盒模型转换成玻璃盒子</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6a2fa16e0b50245b16156a85bb694b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AX0Odxv-WjwxOpYo"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">威廉·冈克尔在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="f741" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">局部可解释模型不可知解释(LIME)是Ribeiro等人[1]开发的Python项目，用于解释任何监督机器学习(ML)模型的预测。</p><p id="5346" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">大多数ML算法是黑盒；我们无法正确理解它们是如何进行特定预测的。这是人工智能的一个巨大缺点，随着人工智能(AI)变得越来越普遍，理解“<em class="me">的重要性这是为什么？</em>'是不断增加的。</p><p id="50a6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本帖中，我们将讨论LIME项目如何工作以及为什么工作。我们还将通过一个使用真实数据集的示例来进一步理解LIME的结果。</p><h1 id="8b91" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">理解机器学习的基础</h1><p id="fee2" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">在我们能够理解并真正欣赏LIME的牛逼之前，我们必须先了解ML的基本直觉。</p><p id="5b53" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">任何被监督的问题都可以归结为两个主要特征:𝒙(我们的特征)和𝑦(我们的目标)。我们想建立一个模型ƒ(𝒙)来生成一个预测𝑦'每当我们提供一些样本𝒙'.</p><p id="e97c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在训练期间，ML模型不断地调整映射函数ƒ(𝒙的权重)，这使得该模型成为一个黑箱，因为理解这些权重如何变化并不容易。</p><blockquote class="nc nd ne"><p id="4977" class="li lj me lk b ll lm kd ln lo lp kg lq nf ls lt lu ng lw lx ly nh ma mb mc md im bi translated">理解任何ML模型的预测归结为理解所述模型背后的映射函数。</p></blockquote><h1 id="779d" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">理解模型可解释性类型</h1><p id="139d" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">模型可解释性有两种主要类型:</p><h1 id="2a6f" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">1.全球解释</h1><p id="6265" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">给定一个模型，使用整个训练数据集生成全局解释。全局解释显示了整体特征对模型的重要性。对于每个特性，全局解释通常会回答这个问题:<em class="me">“总的来说，这个特性对有多重要？”</em></p><h1 id="b3a8" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">2.当地解释</h1><p id="d9ed" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">当地的解释直接基于单一的观察。利用局部解释，我们试图理解为什么会对特定样本产生特定的预测。对于任何给定的样本，本地解释通常会回答这个问题:<em class="me">“哪个特征对这个特定的预测影响最大？”</em></p><p id="d7a1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章的其余部分，我们将集中讨论当地的解释。</p><h1 id="cf6a" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">石灰的直觉</h1><p id="8a07" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">LIME试图通过采样实例来近似模型的映射函数ƒ(𝒙) <strong class="lk jd"> </strong>(称为输入扰动)。通俗地说，LIME生成了一堆合成样本𝒙'，这些样本与原始实例𝒙.非常接近然后，LIME将𝒙'传递给原始模型，并记录各自的预测。这个过程使LIME能够确定不同的输入波动是如何影响的。在过程的最后，对于给定的样本𝒙，LIME将能够通过确定每个特征的单独影响来近似预测。因此，LIME能够通过了解哪些要素对预测的贡献最大来解释特定的预测。</p><h1 id="b4f7" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">概括起来</h1><ul class=""><li id="4e10" class="ni nj it lk b ll mx lo my lr nk lv nl lz nm md nn no np nq bi translated">𝒙'石灰样品实例</li><li id="1b2c" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">LIME使用𝒙'生成一组预测𝑦'使用ƒ(𝒙)</li><li id="a2af" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">LIME比较预测与原始预测的接近程度，并对它们进行加权。</li><li id="8258" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nn no np nq bi translated">LIME使用权重来确定哪些特征对单个预测最有影响。</li></ul><h1 id="b2ac" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">潜得更深</h1><p id="f17b" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">如前所述，莱姆的整个想法是试图解释ƒ(𝒙).LIME通过代理模型实现了这一点。替代模型g是用于解释另一种预测算法的结果的任何模型。一般来说，g会是一个更简单、更易解释的模型(比如决策树或线性模型)。我们可以正式定义代理模型集合为G，使得G∈<strong class="lk jd">T3】G</strong></p><p id="7c0f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，LIME如何选择使用哪个g来解释原始模型呢？</p><p id="f905" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LIME考虑了两个主要的决定因素:</p><p id="8db8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd"><em class="me">*警告:好听的话传入* </em> </strong></p><ol class=""><li id="ea1e" class="ni nj it lk b ll lm lo lp lr nw lv nx lz ny md nz no np nq bi translated">局部保真度，用<em class="me"> L(f，g，π)表示——也称为保真度函数</em></li><li id="7bcf" class="ni nj it lk b ll nr lo ns lr nt lv nu lz nv md nz no np nq bi translated">复杂度，用<em class="me">ω(g)</em>表示</li></ol><p id="e612" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">什么是地方忠信？</p><p id="9f7f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们有两个部分:</p><ul class=""><li id="a216" class="ni nj it lk b ll lm lo lp lr nw lv nx lz ny md nn no np nq bi translated"><strong class="lk jd">本地</strong></li></ul><p id="d48c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们已经讨论过了。局部简单意味着我们一次只关注一个特定的预测，而不是整体考虑。</p><ul class=""><li id="5441" class="ni nj it lk b ll lm lo lp lr nw lv nx lz ny md nn no np nq bi translated"><strong class="lk jd">忠诚</strong></li></ul><p id="a1ee" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">就像暗示的那样，这是对我们选择的g能够多精确地跟随原始模型的度量。g的预测越接近于，g被认为越忠实于。我们把两个预测的‘接近’称为接近度，数学上定义为π。</p><p id="146f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">简单吧？</p><h1 id="6858" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">什么是复杂性？</h1><p id="b4e9" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">向一个5岁的孩子解释2+2比解释∫ tan(𝒙).容易为什么？因为2+2背后的‘映射函数’比积分简单多了。</p><p id="0f22" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">g背后的主要动机是解读。因此，g必须是可解释的。g越简单，它就变得越容易解释。</p><p id="9ef0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">根据被评估模型的类型，复杂性有不同的度量方法。例如，在决策树中，复杂性可以直接由树的深度给出(树越深，越复杂，越难解释)。在线性模型中，复杂性可以用非零权重的数量来衡量。</p><blockquote class="nc nd ne"><p id="53f4" class="li lj me lk b ll lm kd ln lo lp kg lq nf ls lt lu ng lw lx ly nh ma mb mc md im bi translated">LIME试图最小化复杂性，最大化忠实性。</p></blockquote><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/4f3013c4d3551a82e1e29dc5ea1e9ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eZZsFufjSpgK15Ao.png"/></div></div></figure><p id="9670" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">保真度函数<em class="me"> L(f，g，π) </em>可以由任何损失函数定义。LIME使用平方损失距离函数。损失函数也根据要解释的模型的类型而变化(图像分类器将需要与表格不同的损失函数)。</p><p id="9e5c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这主要是石灰项目的要点。还有更多的内容，所以如果你喜欢这篇文章，我强烈推荐阅读[1]。</p><p id="2fd1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在，让我们用一些Python例子来体验一下吧！</p><h1 id="19d5" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">Python中的工作时间示例</h1><p id="f10f" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">首先，我们需要使用pip安装LIME。你可以在[2]中找到LIME的源代码。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="d835" class="og mg it oc b gy oh oi l oj ok">pip install lime</span></pre><p id="c371" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们将使用Scikit-learn [3]提供给我们的iris数据集作为示例来演示软件包的用法。</p><p id="7a99" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">首先，我们需要导入我们需要的不同的包。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="ebf6" class="og mg it oc b gy oh oi l oj ok"># imports<br/>import numpy as np<br/>from sklearn.datasets import load_iris<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import train_test_split</span></pre><p id="69eb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们也可以进口石灰如下:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="2cb4" class="og mg it oc b gy oh oi l oj ok">from lime.lime_tabular import LimeTabularExplainer</span></pre><p id="cddc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们的问题有一个监督的表格结构。因此，我们需要导入LimeTabularExplainer。此外，当使用石灰时，设置NumPy的随机种子可能是个好主意。LIME利用NumPy作为其后端；因此，将随机种子设置为我们选择的数量将确保我们可以获得可重复的实验。我们可以使用以下方式设置随机种子:</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="bc0d" class="og mg it oc b gy oh oi l oj ok">np.random.seed(1)</span></pre><p id="6921" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我们创建一个助手函数，它接受我们的训练和测试集，训练一个基本的RandomForestClassifier，并计算出它的准确度分数。这里的目标不是构建最健壮的模型，而是为我们的解释获得一个基础模型。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="4f21" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们从Scikit-learn获取数据集，对其进行分割，并按如下方式训练我们的模型:</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="13c0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">接下来，我们需要生成我们的LIME explainer函数。这里我们需要指定训练数据、特征名、类标签，以及是否离散化连续变量。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="393f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">现在我们可以为任何我们想要的预测生成一个解释。在这一步，我们开始控制要显示的最有影响力的特征的数量。这可以是介于1和数据集中要素数量之间的任意整数值。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="ol om l"/></div></figure><p id="7422" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">针对三种不同的预测运行最后这段代码，我们得到:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/b2bd93bf40d9cfbc750cc46e25041c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Rh_4Tgrr_-IB4ywE.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/521e57bcf6eb1eb6a85bfd5cfbe9ee6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0ECJndai-ywpJLtw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/e18ce3d390430199045ce8ad726417db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tLmqWypp8Nepgcp-.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="2200" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在可视化的左侧，我们得到了每一类的预测概率分布。在右边，我们得到了对该预测最有影响的前2个(我们在初始化上面的explainer函数时指定的)特征以及它们各自的值。在图的中心，我们得到每个有影响的特征的条件(基于扰动的输入)及其强度(即，对模型的贡献/影响)。</p><p id="c17b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">例如，在第一次预测中，模型以99%的置信度预测样本为杂色。这个分数的24%是因为花瓣长度大于1.58厘米，另外14%的影响是因为花瓣宽度大于0.3厘米</p><h1 id="66a4" class="mf mg it bd mh mi mj mk ml mm mn mo mp ki mq kj mr kl ms km mt ko mu kp mv mw bi translated">结论</h1><p id="e415" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">而且真的是这样！这个包的美妙之处在于它严格遵循了我们刚刚讨论过的“代码模板”。即使在解释图像或文本分类器时。唯一不同的部分是导入所需的解释器(在我们的例子中，我们使用LimeTabularExplainer，因为我们想要解释表格数据)。</p><p id="f3e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">要记住的一个重要方面是，解释器函数只能和它试图逼近的原始模型一样好。因此，当在野外时，一定要确保使用交叉验证对模型进行稳健的训练，并进行适当的验证。此外，LIME还可用于评估任何给定ML模型的稳健性。</p><p id="f555" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">LIME是对可解释人工智能世界的惊人介绍。LIME和领域都在不断成长和成熟，这使得现在是开始将XAI纳入数据建模管道的最佳时机。</p></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><p id="38e3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">你喜欢这篇文章吗？如果是的话，也许你可以考虑成为会员来支持我和你其他喜欢的作家。</p><div class="ou ov gp gr ow ox"><a href="https://david-farrugia.medium.com/membership" rel="noopener follow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd jd gy z fp pc fr fs pd fu fw jc bi translated">加入我的介绍链接媒体-大卫法鲁吉亚</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">david-farrugia.medium.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl lb ox"/></div></div></a></div></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><h1 id="b764" class="mf mg it bd mh mi pm mk ml mm pn mo mp ki po kj mr kl pp km mt ko pq kp mv mw bi translated">参考</h1><p id="2265" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">[1]里贝罗，M.T .，辛格，s .和盖斯特林，c .，2016年8月。“我为什么要相信你？”解释任何分类器的预测。第22届ACM SIGKDD知识发现和数据挖掘国际会议论文集(第1135-1144页)。</p><p id="fc36" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[2]https://github.com/marcotcr/lime<a class="ae lh" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank"/></p><p id="05ac" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">[3]<a class="ae lh" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/datasets/plot _ iris _ dataset . html</a></p></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><p id="efa1" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想给我买杯咖啡吗？</p><div class="ou ov gp gr ow ox"><a href="https://paypal.me/itsdavidfarrugia?country.x=MT&amp;locale.x=en_US" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd jd gy z fp pc fr fs pd fu fw jc bi translated">使用贝宝支付大卫法鲁吉亚。我</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">如果您接受cookies，我们将使用它们来改善和定制您的体验，并使我们的合作伙伴能够向您展示…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">paypal.me</p></div></div><div class="pg l"><div class="pr l pi pj pk pg pl lb ox"/></div></div></a></div></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><h1 id="bc7b" class="mf mg it bd mh mi pm mk ml mm pn mo mp ki po kj mr kl pp km mt ko pq kp mv mw bi translated">想联系吗？</h1><p id="12a0" class="pw-post-body-paragraph li lj it lk b ll mx kd ln lo my kg lq lr mz lt lu lv na lx ly lz nb mb mc md im bi translated">我很想听听你对这个话题的想法，或者其他什么。如果你想联系我，请给我发电子邮件到davidfarrugia53@gmail.com。</p><p id="7f61" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><a class="ae lh" href="https://www.linkedin.com/in/david-farrugia/" rel="noopener ugc nofollow" target="_blank">Linkedin</a>——<a class="ae lh" href="https://twitter.com/davidfarrugia53" rel="noopener ugc nofollow" target="_blank">Twitter</a></p></div></div>    
</body>
</html>