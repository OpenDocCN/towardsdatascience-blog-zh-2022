<html>
<head>
<title>Synthetic data could change everything</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">合成数据可以改变一切</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/synthetic-data-could-change-everything-fde91c470a5b#2022-05-18">https://towardsdatascience.com/synthetic-data-could-change-everything-fde91c470a5b#2022-05-18</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="68b9" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank">播客</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">Alex Watson谈合成数据的隐私和性能优势</h2></div><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="kv kw l"/></div><p class="kx ky gj gh gi kz la bd b be z dk translated"><a class="ae lb" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae lb" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae lb" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae lb" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></p></figure><p id="a1ba" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated"><em class="ly">编者按:TDS播客由杰雷米·哈里斯主持，他是人工智能安全初创公司墨丘利的联合创始人。每周，Jeremie都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。</em></p></div><div class="ab cl lz ma hw mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="il im in io ip"><p id="7060" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">有一个叫<a class="ae lb" href="http://thispersondoesnotexist.com" rel="noopener ugc nofollow" target="_blank">thispersondoesnotexist.com</a>的网站。当你参观它时，你会看到一张高分辨率、逼真的人工智能生成的人脸照片。正如该网站的名字所暗示的那样，地球上没有一个人看起来很像页面上回瞪着你的那个人。</p><p id="b5a3" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">每一张生成的图片都是一段数据，它捕捉了看起来像人类的本质。然而，他们这样做却没有告诉你任何关于某个人的任何事情。从这个意义上说，这是完全匿名的人脸数据。</p><p id="12c0" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">这已经足够令人印象深刻了，它说明了生成图像模型在过去十年中已经走了多远。但是如果我们可以对任何类型的数据做同样的事情呢？</p><p id="59c3" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">如果我可以生成一组匿名的医疗记录或金融交易数据，捕捉隐藏在私人数据集中的所有潜在关系，而没有泄露真实人物敏感信息的风险，会怎么样？这是Gretel AI的首席产品官兼联合创始人亚历克斯·沃森(Alex Watson)的使命，他致力于以保护隐私的方式释放隐藏在敏感数据集中的价值。</p><p id="0a6a" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">与亚历克斯交谈后，我意识到合成数据不仅仅是确保隐私。正如您将在对话过程中看到的那样，我们很可能会走向一个大多数数据都可以通过数据合成受益于增强的世界，在这个世界中，合成数据带来了隐私价值，这几乎是用从更广阔的世界导入的上下文丰富地面真实数据的副作用。</p><p id="4a3b" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">在这一集的TDS播客中，Alex和我一起讨论了数据隐私、数据合成，以及数据生命周期的奇怪未来。以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="7f86" class="mg mh is le b lf lg li lj ll mi lp mj lt mk lx ml mm mn mo bi translated">数据综合是创建新的数据样本。一个好的合成数据集保留了原始“基础事实”数据集中存在的要素之间的所有关系，甚至可能是信息更加密集的(稍后将详细介绍)。</li><li id="3cd6" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">生成合成样本的一种老派方法是插值。这种策略包括生成新的样本，使它们落在特征空间的真实样本之间。但最近几个月，出现了一个新趋势:公司正在使用大型语言模型(LLM)来生成新样本。这是通过微调LLM来实现的，根据用户提供的提示，在CSV文件中生成新的行或新的JSON对象。</li><li id="ace9" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">这种LLM策略有一个主要优势。在大量文本上训练的语言模型最终学习了世界的强大表示。这是因为他们基本上接受了自动完成的训练——自动完成得非常好意味着能够完成这样的句子，“将决定2022年美国经济增长轨迹的主要因素是……”。这样做需要大量的世界知识，以及对逻辑关系的充分理解。当这些LLM在诸如生成医疗保健数据的新样本等任务上进行微调时，他们能够将他们的丰富世界模型用于新任务，从而将他们从阅读数十亿高质量文本单词中获得的知识注入到他们生成的数据中。</li><li id="ee48" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">最终结果是，合成数据可以更加私密，但也更具信息性和价值。它不仅结合了包含在初始地面真实数据中的信息，还结合了用于生成它的LLM的大量世界知识。</li><li id="7b7e" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">合成数据可能带来的一个挑战是记忆。LLM有时会过度训练，这可能会导致他们记住训练数据中包含的敏感信息，如姓名、信用卡号等。因为这是一个过拟合问题，所以通常最好通过正则化来解决:像梯度裁剪、设计学习率和向随机梯度下降过程添加噪声这样的技术对此很有价值。</li></ul><p id="9e7e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">你可以<a class="ae lb" href="https://twitter.com/AlexWatson405" rel="noopener ugc nofollow" target="_blank">在Twitter上关注阿历克斯</a>，或者<a class="ae lb" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">我在这里</a>。如果你觉得这个对话很有趣，你也可以在下面找到一些链接。</p><ul class=""><li id="61bf" class="mg mh is le b lf lg li lj ll mi lp mj lt mk lx ml mm mn mo bi translated"><a class="ae lb" href="https://www.youtube.com/watch?v=1jmIVplIJxQ" rel="noopener ugc nofollow" target="_blank">Gretel AI今年在Nvidia GTC的演讲视频</a>，主题是使用合成数据来平衡和改善ML数据集。</li><li id="ca75" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated"><a class="ae lb" href="https://gretel.ai/blog/advanced-data-privacy-gretel-privacy-filters-and-ml-accuracy" rel="noopener ugc nofollow" target="_blank">一个关于隐私和合成数据准确性的帖子</a>。</li><li id="d503" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/create-a-location-generator-gan-33680d81289f">一个关于图像合成的早期博客</a>。</li><li id="c24d" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">Gretel AI核心合成数据引擎的<a class="ae lb" href="https://github.com/gretelai/gretel-synthetics" rel="noopener ugc nofollow" target="_blank">开源代码</a>。</li></ul><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/7097023825520465a74aecdd23458388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1p806yhC4XZt51YPeBy8A.png"/></div></div></figure><h2 id="181a" class="nb nc is bd nd ne nf dn ng nh ni dp nj ll nk nl nm lp nn no np lt nq nr ns iy bi translated">章节:</h2><ul class=""><li id="b9e9" class="mg mh is le b lf nt li nu ll nv lp nw lt nx lx ml mm mn mo bi translated">0:00介绍</li><li id="346e" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">2:40什么是合成数据？</li><li id="620e" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">6:45大型语言模型</li><li id="1383" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">11:30防止数据泄露</li><li id="fe6d" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">18:00生成型与下游型</li><li id="acd0" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">24:10去偏置和公平性</li><li id="5a15" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">30:45使用合成数据</li><li id="fec4" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">35:00人消费数据</li><li id="3f38" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">41:00发现数据中的相关性</li><li id="c7f6" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">47:45不同ML算法的概括</li><li id="d73c" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">51:15总结</li></ul></div></div>    
</body>
</html>