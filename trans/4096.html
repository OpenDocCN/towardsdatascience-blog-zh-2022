<html>
<head>
<title>A Comprehensive Guide on Model Calibration: What, When, and How</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型校准综合指南:什么，何时，如何</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-comprehensive-guide-on-model-calibration-part-1-of-4-73466eb5e09a#2022-09-12">https://towardsdatascience.com/a-comprehensive-guide-on-model-calibration-part-1-of-4-73466eb5e09a#2022-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6f6c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">第1部分:了解如何校准机器学习模型，以获得合理且可解释的概率作为输出</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/5c1cce2646a371468e680fae40a22bf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y2VoeGF9NGks4f0j"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@adigold1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿迪·戈尔茨坦</a>在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="b581" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">尽管今天人们可以找到太多的博客谈论奇特的机器学习和深度学习模型，但我找不到多少关于模型校准及其重要性的资源。我发现更令人惊讶的是，模型校准对于某些用例来说可能是至关重要的，但却没有得到足够的重视。因此，我将写一个4部分的系列来深入研究校准模型。一旦你完成了这个系列，你将会学到一些东西。</p><h2 id="9a8e" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">学习成果</h2><ul class=""><li id="6211" class="mm mn iq kz b la mo ld mp lg mq lk mr lo ms ls mt mu mv mw bi translated"><strong class="kz ir">什么是模型校准，为什么它很重要</strong></li><li id="764f" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated"><strong class="kz ir">何时校准模型，何时不校准模型</strong></li><li id="980a" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated"><strong class="kz ir">如何评估模型是否校准(可靠性曲线)</strong></li><li id="750a" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated"><strong class="kz ir">校准机器学习模型的不同技术</strong></li><li id="b7e3" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">低数据设置中的模型校准</li><li id="1cad" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">校准多类分类器</li><li id="528b" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">在PyTorch中校准现代深度学习网络</li><li id="e5b5" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">校准回归变量</li></ul><p id="b094" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在今天的博客中，我们将关注前四个重点。</p><h1 id="7d28" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">什么是模型校准？</h1><p id="488e" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">让我们考虑一个二元分类任务和一个在这个任务上训练的模型。没有任何校准，模型的输出不能被解释为真实的概率。例如，对于猫/狗分类器，如果模型输出对于作为狗的例子的预测值是0.4，则该值不能被解释为概率。为了用概率来解释这种模型的输出，我们需要校准模型。 </p><p id="76ac" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">令人惊讶的是，大多数开箱即用的模型都没有经过校准，它们的预测值往往过于自信或过于自信。这意味着，在很多情况下，他们预测的值接近0和1，而他们不应该这样做。</p><h2 id="2fe6" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">解释未校准和校准模型的输出</h2><p id="ef24" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">为了更好地理解为什么我们需要模型校准，让我们看看前面的输出值为0.4的例子。<strong class="kz ir">理想情况下，我们希望该值代表的是这样一个事实，即如果我们拍摄10张这样的照片，并且模型以大约0.4的概率将它们分类为狗，那么在现实中，这10张照片中的4张实际上是狗的照片。这正是我们应该如何解释来自<strong class="kz ir"> <em class="nq">校准</em> </strong>模型的输出。</strong></p><p id="7d94" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然而，如果模型没有被校准，那么我们不应该期望这个分数将意味着10张图片中的4张将实际上是狗图片。</p><h1 id="711b" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">何时不校准模型</h1><p id="85b9" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">我们校准模型的全部原因是，我们希望输出在解释为独立概率时有意义。然而，对于某些情况，例如根据质量对新闻文章标题进行排序的模型，如果我们的策略是选择最佳标题，我们只需要知道哪个标题得分最高。在这种情况下，校准模型没有多大意义。</p><h1 id="e3bf" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">何时校准模型以及为什么校准至关重要</h1><p id="d5c2" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">假设我们想要对火警是否正确触发进行分类。(我们今天将通过代码来讨论这一点。)这样的任务是至关重要的，因为我们希望彻底了解我们的模型的预测，并改进模型，使其对真实的火灾敏感。假设我们对两个例子进行测试，将火灾的可能性分为0.3和0.9。<strong class="kz ir">对于一个未校准的模型，这并不意味着第二个例子可能导致实际火灾的次数是第一个例子的三倍。</strong></p><p id="bddf" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">此外，在部署该模型并收到一些反馈后，我们现在考虑改进我们的烟雾探测器和传感器。使用我们的新模型运行一些模拟，我们看到以前的示例现在得分为0.35和0.7。</p><p id="8a34" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">比方说，改进我们的系统需要20万美元。我们想知道我们是否应该为每个示例分别0.05和0.2的得分变化投资这笔钱。<strong class="kz ir">对于一个未校准的模型，比较这些数字没有任何意义，因此我们无法正确估计一项投资是否会带来实实在在的收益。但是如果我们的模型被校准，我们可以通过专家指导的基于概率的调查来解决这个难题。</strong></p><p id="3d87" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> <em class="nq">通常，模型校准对于生产中的模型至关重要，这些模型通过不断的学习和反馈得到改进。</em>T9】</strong></p><h1 id="88c6" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">评估模型校准</h1><p id="c043" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">现在我们知道了为什么我们应该校准我们的模型(如果需要的话),让我们看看如何识别我们的模型是否被校准。</p><p id="356e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">那些想直接跳到代码的人可以在这里访问它。</p><h2 id="3754" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">数据集</h2><p id="83cc" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">今天，我们将看看来自<a class="ae kw" href="https://www.kaggle.com/datasets/rjmanoj/telecom-customer-churn-prediction" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的电信客户流失预测数据集。你可以阅读更多关于协变量和烟雾探测器类型的信息，查看Kaggle数据集的描述页面。<strong class="kz ir">我们将尝试在此数据上校准LightGBM模型，因为XGBoost通常是未校准的。</strong></p><p id="5deb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">数据集官方来自IBM，可以在这里</strong>  <strong class="kz ir">免费下载</strong> <a class="ae kw" href="https://community.ibm.com/accelerators/catalog/content/Telco-customer-churn" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">。它是在Apache License 2.0下授权的，如这里的</strong> </a> <strong class="kz ir">中的</strong> <a class="ae kw" href="https://github.com/IBM/telco-customer-churn-on-icp4d/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">。</strong></a></p><h2 id="45ca" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">可靠性曲线</h2><p id="96a6" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">可靠性曲线是一种很好的可视化方法，可以用来识别我们的模型是否经过校准。首先，我们创建从0到1的容器。然后，我们根据预测的输出划分数据，并将它们放入这些箱中。例如，如果我们以0.1的间隔收集数据，我们将有10个介于0和1之间的箱。假设我们在第一箱中有5个数据点，即我们有5个点<strong class="kz ir"> (0.05，0.05，0.02，0.01，0.02) </strong>，其模型预测范围位于0和0.1之间。现在，我们在X轴上绘制了这些预测的平均值，即<strong class="kz ir"> 0.03，在Y轴上绘制了经验概率，即基本事实等于1的数据点的分数。说出来我们的5分，1分有地面真值1。在这种情况下，我们的y值将是1/5 = 0.2。因此，我们的第一个点的坐标是[0.03，0.2]。</strong>我们对所有的箱都这样做，并将这些点连接起来形成一条线。然后我们将这条线与这条线进行比较</p><p id="2be4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir"> y = x </strong>并评估校准。<strong class="kz ir">当圆点在这条线以上时，模型低估了真实概率，如果圆点在这条线以下，模型高估了真实概率。</strong></p><p id="54d9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们可以使用Sklearn构建这个图，它看起来像下面的图。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/c64a816c3bfbf521264b24968ea238ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*ptp4mjN8PneLqJhuP07FBg.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">Sklearn的校准曲线(图片由作者提供)</p></figure><p id="2113" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如你所见，该模型在0.6之前过于自信，然后在0.8左右低估</p><p id="6fba" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然而，Sklearn的情节有一些缺陷，因此<strong class="kz ir">我更喜欢使用布莱恩·卢切纳博士的ML-insights </strong> <a class="ae kw" href="https://ml-insights.readthedocs.io/en/latest/#" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">包</strong> </a>中的情节。</p><p id="b68f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">该软件包显示了数据点周围的置信区间，还显示了每个区间(每个bin中)有多少数据点，因此您可以相应地创建自定义bin区间。正如我们还将看到的，有时模型过于自信，预测值非常接近0或1，在这种情况下，软件包有一个方便的logit-scaling功能来显示在非常接近0或1的概率周围发生的事情。</p><p id="7643" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是与上面使用Ml-insights创建的图相同的图。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ns"><img src="../Images/b39927cada77347ea672130c1e3d16cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sdCMqexzz1lEnyzGg9f37A.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">Ml-insight的可靠性曲线(图片由作者提供)</p></figure><p id="70d6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如您所见，我们还可以看到每个条柱中数据点的直方图分布以及置信区间。</p><h2 id="3d1d" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">定量评估模型校准</h2><p id="b574" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">根据我在阅读该领域的一些文献时收集的信息，捕捉模型校准误差没有完美的方法。文献中经常使用预期校准误差等指标，但我发现(正如你在我的笔记本和代码中看到的)，ECE会随着你选择的频段数量而大幅变化，因此并不总是可靠的。我将在以后更高级的校准博客中更详细地讨论这一指标。<strong class="kz ir">你可以在这个博客</strong> <a class="ae kw" href="https://medium.com/@wolframalphav1.0/evaluate-the-performance-of-a-model-in-high-risk-applications-using-expected-calibration-error-and-dbc392c68318" rel="noopener"> <strong class="kz ir"> <em class="nq">这里</em> </strong> </a> <strong class="kz ir">阅读更多关于ECE的内容。我强烈建议你通过它。</strong></p><p id="bc4b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我在这里使用的一个基于卢切纳博士博客的指标是传统的对数损失。这里简单的直觉是，对数损失(或交叉熵)惩罚了在做出错误预测或做出与其真实概率显著不同的预测时过于自信的模型。你可以在这本<a class="ae kw" href="https://github.com/numeristical/resources/blob/master/CalibrationWorkshop/Calibration_Workshop_1.ipynb" rel="noopener ugc nofollow" target="_blank"> n </a>笔记本中了解更多关于定量模型校准的信息。</p><p id="3ec5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">T15】</strong></p><h1 id="cc2b" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">校准模型的方法</h1><h2 id="db97" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">拆分数据</h2><p id="5b8b" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">在我们进行任何校准之前，重要的是理解我们不能校准我们的模型，然后在相同的数据集上测试校准。因此，为了避免数据泄露，我们首先将数据分成三组——训练、验证和测试。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="2389" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">未校准性能</h2><p id="5d06" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">首先，这是我们的未校准LightGBM模型在我们的数据上的表现。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="67ae" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">普拉特标度</h2><p id="1c50" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">普拉特标度假设模型预测和真实概率之间存在逻辑关系。</p><p id="3956" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">剧透——这在很多情况下并不成立。</strong></p><p id="5f77" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们简单地使用逻辑回归来拟合验证集的模型预测，并将验证集的真实概率作为输出。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="6ed4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下面是它的表现。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="65f2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如我们所见，我们的原木损失在这里明显减少了。由于我们有许多模型预测接近0的数据点，我们可以在这里看到使用Ml-insights包(及其logit缩放功能)的好处。</p><h2 id="f998" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">保序回归</h2><p id="96c6" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">这种方法结合了贝叶斯分类器和决策树来校准模型，当我们有足够的数据来拟合时，它比Platt scaling更好。详细算法可以在这里找到<a class="ae kw" href="https://cseweb.ucsd.edu/~elkan/calibrated.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="fafd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我使用ml-insights包来实现保序回归。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="ae8e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">对于我们的数据，这似乎比普拉特缩放更有效。<strong class="kz ir">尽管在对不同数据分割和随机种子的实验结果进行平均或使用交叉验证(我们将在未来的博客中看到)后得出这样的结论会更明智。</strong></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h2 id="a1da" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">样条校准</h2><p id="4eed" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">这个算法是由Ml-insights软件包的作者(布莱恩·卢切纳)给出的，可以在这篇<a class="ae kw" href="https://arxiv.org/pdf/1809.07751.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中找到。</p><p id="5ab6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本质上，该算法使用平滑的三次多项式(选择该多项式是为了最小化某个损失，如本文中为那些对技术细节感兴趣的人所详述的那样),并且适合验证集及其真实概率上的模型预测。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="0066" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">样条线校准在我们的数据中表现最好(至少对于这种分割来说)。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="ccde" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这是他们在一个情节中的表现</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h1 id="ae49" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">预期校准误差及其缺陷</h1><p id="2c22" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">许多当代文献都提到ECE是衡量模型校准程度的一个指标。</p><p id="ba82" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">以下是ECE的正式计算方法。</p><ol class=""><li id="e6a4" class="mm mn iq kz b la lb ld le lg nv lk nw lo nx ls ny mu mv mw bi translated">像我们之前做的那样选择n个箱</li><li id="17e2" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated">对于每个条柱，计算属于该条柱的数据点的模型预测的平均值，并根据该条柱中的数据点数对其进行归一化。</li><li id="04bd" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated">对于每个箱，还要计算真阳性的比例。</li><li id="060c" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated">现在，对于每个箱，计算步骤3和步骤4中计算的值之间的绝对差，并将该绝对差乘以该箱中的数据点数。</li><li id="189f" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated">将步骤4中计算的所有箱的结果相加，并通过所有箱中的样本总数对该相加和进行归一化。</li></ol><p id="d3b6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">计算ECE的代码可以在这个<a class="ae kw" href="https://medium.com/@wolframalphav1.0/evaluate-the-performance-of-a-model-in-high-risk-applications-using-expected-calibration-error-and-dbc392c68318" rel="noopener">博客</a>中找到，并且已经在我的实验中使用。</p><p id="0119" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然而，在我的案例中，数据点在所有箱中的分布并不均匀(因为大多数数据点属于第一个箱)，因此必须相应地为ECE选择箱。我们可以看到仓的数量如何直接影响算法中的ECE。</p><p id="ce89" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">例如，仅对于5个箱，未校准的模型似乎比所有其他方法具有更小的校准误差。</p><p id="25ea" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然而，当我们增加仓的数量时，我们可以看到模型校准实际上对我们的情况有所帮助。</p><p id="20e7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在下面的代码片段中，可以验证这种效果。请忽略OE(过度自信误差度量),因为它在文献中没有广泛使用。</p><p id="55f9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">对于5个箱子，我们有</strong></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="b1c9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">对于50个箱子，我们有</strong></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="cade" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">对于500个箱子，我们有</strong></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><p id="2693" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">对于5000个箱子，我们有</strong></p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="nt nu l"/></div></figure><h1 id="d26f" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">结论</h1><p id="6134" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">在今天的博客中，我们看到了什么是模型校准，如何评估模型的校准以及这样做的一些指标，探讨了ml-insights包以及校准模型的一些方法，最后探讨了ECE的谬误。</p><p id="a31c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">下一次，我们将研究低数据设置的稳健校准，校准深度学习模型，并最终校准回归变量。</p><p id="7bbd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">查看我的<a class="ae kw" href="https://github.com/rajlm10" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir"> GitHub </strong> </a>的其他一些项目。可以联系我<a class="ae kw" href="https://rajsangani.me/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir"> <em class="nq">这里</em> </strong> </a> <strong class="kz ir"> <em class="nq">。</em> </strong>感谢您的宝贵时间！</p><p id="095a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果你喜欢这个，这里还有一些！</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/interpreting-an-lstm-through-lime-e294e6ed3a03"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd ir gy z fp oh fr fs oi fu fw ip bi translated">透过莱姆解读LSTM</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">了解如何通过LIME解释一个Keras LSTM，并深入到文本LIME库的内部工作…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq kq oc"/></div></div></a></div><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/adding-custom-layers-on-top-of-a-hugging-face-model-f1ccdfc257bd"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd ir gy z fp oh fr fs oi fu fw ip bi translated">在拥抱脸模型上添加自定义层</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">了解如何提取隐藏的状态从一个拥抱脸模型机构，修改/添加任务特定的层上，它和…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="or l on oo op ol oq kq oc"/></div></div></a></div><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/dealing-with-features-that-have-high-cardinality-1c9212d7ff1b"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd ir gy z fp oh fr fs oi fu fw ip bi translated">处理具有高基数的要素</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">一个简单的实用程序，我用来处理具有许多唯一值的分类特征</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="os l on oo op ol oq kq oc"/></div></div></a></div><h1 id="f31c" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">承认</h1><p id="73f4" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nn li lj lk no lm ln lo np lq lr ls ij bi translated">我感谢布莱恩·卢切纳博士对与本博客相关的各种话题的帮助和建议。我还发现他在YouTube上关于模型校准的播放列表非常详细和有用，我的大部分实验都是基于他的视频。</p><h1 id="2872" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">参考</h1><ol class=""><li id="119c" class="mm mn iq kz b la mo ld mp lg mq lk mr lo ms ls ny mu mv mw bi translated"><a class="ae kw" href="https://www.youtube.com/playlist?list=PLeVfk5xTWHYBw22D52etymvcpxey4QFIk" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/playlist?list = plevfk 5 xtwhybw 22d 52 etymvcpxe 4 qfik</a></li><li id="892c" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated"><a class="ae kw" href="https://cseweb.ucsd.edu/~elkan/calibrated.pdf" rel="noopener ugc nofollow" target="_blank">https://cseweb.ucsd.edu/~elkan/calibrated.pdf</a></li><li id="dff3" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated"><a class="ae kw" href="https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html" rel="noopener ugc nofollow" target="_blank">https://www . unofficialgogledatascience . com/2021/04/why-model-calibration-matters-and-how . html</a></li><li id="265f" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated"><a class="ae kw" rel="noopener" target="_blank" href="/classifier-calibration-7d0be1e05452">https://towards data science . com/classifier-calibration-7d 0 be 1e 05452</a></li><li id="18ad" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated"><a class="ae kw" href="https://medium.com/@wolframalphav1.0/evaluate-the-performance-of-a-model-in-high-risk-applications-using-expected-calibration-error-and-dbc392c68318" rel="noopener">https://medium . com/@ wolfram alpha 1.0/evaluate-the-performance-of-a-model-in-high-risk-applications-using-expected-calibration-error-and-DBC 392 c 68318</a></li><li id="724c" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls ny mu mv mw bi translated">https://arxiv.org/pdf/1809.07751.pdf<a class="ae kw" href="https://arxiv.org/pdf/1809.07751.pdf" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>