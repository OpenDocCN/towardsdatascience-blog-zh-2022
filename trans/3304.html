<html>
<head>
<title>Understand Vectorization for Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解深度学习的矢量化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understand-vectorization-for-deep-learning-d712d260ab0f#2022-07-22">https://towardsdatascience.com/understand-vectorization-for-deep-learning-d712d260ab0f#2022-07-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="5abe" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">深度学习</h2><div class=""/><div class=""><h2 id="f4f3" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">与“for”循环相比，Python中的NumPy在处理十亿次乘法时要快10，000%以上。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/a520f5acc88153dea75ddf52cfb59aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZqfklMguHoO1XKvz"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">马库斯·克里斯蒂亚在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="afeb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇文章将向你介绍矢量化，以及它在机器学习(尤其是深度学习)中的重要性。您还将学习如何使用NumPy在Python中实现它，以及它带来了多大的不同。</p><p id="314a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这篇文章假设了线性代数的最低背景。你应该知道什么是向量，什么是矩阵，我们怎么把向量和矩阵相乘。除了这些，我会在我们进行的过程中介绍其他的东西。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="90af" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">为什么矢量化很重要？</h1><p id="2bf0" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">当谈到将机器学习应用于给定的问题时，通常没有确定性的公式可以告诉你将做得很好的精确架构或超参数。不管任何人声称什么，这个过程都是通过反复试验来实现的。它本质上是经验主义的。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ni"><img src="../Images/8f8cf493f518e5c96913861a770cd6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wAcMikg8JhD7a17QvM2cA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">改编自吴恩达的深度学习课程(图片由作者提供)</p></figure><p id="a095" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这就是为什么我们需要将数据集分成不同的部分，训练集、开发集(有时也称为验证集)和测试集。我们使用开发集来选择正确的超参数和架构集，如果结果不够好，就进行迭代。</p><h2 id="8b97" class="nj mm it bd mn nk nl dn mr nm nn dp mv lr no np mx lv nq nr mz lz ns nt nb iz bi translated"><strong class="ak"> <em class="nu">我们需要速度更快的迭代，找到好的解决方案</em> </strong></h2><p id="ad42" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">随着你获得更多的经验，你会发展出某些直觉来帮助你更快地获得更好的结果。然而，这种方法仍然是经验性的。因此，速度不仅很好，而且绝对重要。如果你的算法训练得非常慢，那么迭代的可能性就会降低，从而找到“足够好”的结果的可能性也会降低。</p><h2 id="fdae" class="nj mm it bd mn nk nl dn mr nm nn dp mv lr no np mx lv nq nr mz lz ns nt nb iz bi translated">引擎盖下的神经网络</h2><p id="3e21" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">在我继续举例说明之前，先简单介绍一下神经网络(深度学习算法的基本单元)。神经网络的单层由一些输入(<strong class="lk jd"> <em class="nv"> x </em> </strong>)、偏差项(<strong class="lk jd"> <em class="nv"> b </em> </strong>)、权重(<strong class="lk jd"> <em class="nv"> w </em> </strong>)和非线性函数(称为激活函数)组成。从数学上讲，这是一个简单的数学运算，包含线性和非线性部分。</p><p id="a8cf" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习算法由这种堆叠在一起的神经网络层组成。训练神经网络包括向前传递和向后传递。在向前传递的过程中，我们进行预测。在反向传递过程中，我们将预测结果与实际结果进行比较，并使用误差来更新神经网络的权重。然后我们重复这个过程。</p><p id="2c54" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">让我们绘制一个简单网络的单层来说明矢量化的思想。在这里，我只展示了一个神经元作为说明，用一个数字，<em class="nv"> x，</em>作为输入，另一个数字，b(称为偏差)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nw"><img src="../Images/995fe646e74280672de6b525778cc51a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7ugpsO0ENsUVyDkTXsknQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">单个神经元具有单个一维输入x、偏置项和非线性激活函数f(图片由作者提供)</p></figure><p id="b8c6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在现实世界的应用中，输入<em class="nv"> x </em>将会有多个维度。此外，我们将拥有多个神经元，而不是每层只有一个神经元。由于矩阵和向量，我们仍然可以用多维输入(用一个涉及矩阵的方程)来表示和计算给定层中多个神经元的数学方程。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/999ae71ca7128a001441f370ed2da365.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*myLF2fuM0q7pSLjcITWLbA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">单层的数学运算(图片由作者提供)</p></figure><p id="376c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于上面的等式，矩阵<strong class="lk jd"><em class="nv">W’</em></strong>将具有尺寸为<em class="nv"> m </em>乘<em class="nv"> k </em> ( <em class="nv"> m </em>行，每行对应一个神经元，以及<em class="nv"> k </em>列，其中每列对应给定样本中的每个特征)，<strong class="lk jd"><em class="nv">【X’</em></strong>将是一个<em class="nv"> k </em>乘<em class="nv"> </em> 1 <em class="nv"> 【T25)</em></p><p id="3ca8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">以上是单个数据样本的单层神经网络的前向传递方程，<strong class="lk jd"><em class="nv">X’</em></strong>。如果我们要对每个数据样本重复这个操作，那就太麻烦了。想象一下当训练数据集有超过一百万个数据点时这样做。</p><p id="4ed3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">幸运的是，我们不需要对每个数据样本重复上述过程。相反，我们可以传递整个训练数据集，并在一个步骤中计算输出。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4b593601d53daa5b30be449ae2665486.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*pmwxQj2BhD67DV2OXbgz1Q.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">使用所有训练数据时单个图层的数学运算(图片由作者提供)</p></figure><p id="0e2a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">除了量纲不同之外，这个方程看起来与前面的方程非常相似。<strong class="lk jd"> <em class="nv"> X </em> </strong>不再是单个<em class="nv"> k </em>维数据点，而是整个数据集的矩阵，其维数为<em class="nv"> k </em>乘<em class="nv"> s </em>，其中s是样本总数(一百万以上并不罕见)。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/c3f6bfe723b99d2fe1405812e94e638b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8dzCRswsCXKLpYzkWdqGVQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">整个训练数据排列成一个大矩阵X，其中每一列是k维样本，总共有s个样本(图片由作者提供)</p></figure><h2 id="85ba" class="nj mm it bd mn nk nl dn mr nm nn dp mv lr no np mx lv nq nr mz lz ns nt nb iz bi translated">深度学习只有在我们拥有大型数据集的情况下才有意义</h2><p id="c682" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">深度学习在许多情况下超过传统算法的一个主要原因是大型数据集的可用性。事实上，如果数据集很小，使用传统的学习算法会更好。</p><p id="ddfe" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">想象一下，如果我们有一百万个数据样本可以用来训练。如果没有任何矢量化，我们将不得不依次对每个示例进行乘法和加法运算。我们需要一个“for”循环，从每个矩阵中挑选相应的项，并将它们相乘。矢量化使我们能够避免这种“for”循环，并在一个步骤中使用所有数据。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/cc12ba8599ff4ee77ef2e00df74e02ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pz1s8VvaQqlMWaDrwKiqww.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">实现神经网络前向传播部分的矢量化版本的矩阵乘法的图示</p></figure><h2 id="fc6f" class="nj mm it bd mn nk nl dn mr nm nn dp mv lr no np mx lv nq nr mz lz ns nt nb iz bi translated">在Python中是如何实现的？</h2><p id="e495" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">在python中，我们可以使用Numpy来帮助我们实现神经网络。Numpy代表数字Python。这是一个开源项目，它提供了线性代数和矩阵的函数。在基本Python中，列表可以用作数组。然而，Numpy提供的数组对象(ndarray)比Python列表快几个数量级。</p><p id="f66c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在内部，NumPy将数组存储在一个连续的内存位置。此外，NumPy经过优化，可与最新的CPU架构配合使用。因此，NumPy被广泛用于数据科学并不奇怪。</p><p id="b712" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果没有矢量化，我们将被迫使用“for”循环进行矩阵/向量乘法。让我们看看用for循环和矢量化(从而避免for循环)将两个向量相乘时执行时间的差异。</p><p id="518c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">下面我将生成两个大小为“array_size”的随机NumPy数组。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="1dca" class="nj mm it oc b gy og oh l oi oj">import numpy as np<br/>import time<br/>array_size = 1000000<br/>x1_numpy = np.random.rand(1,array_size)<br/>x2_numpy = np.random.rand(1,array_size)</span></pre><p id="09cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我将使用“for”循环计算这两个向量的乘积，并估计所需的时间。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="fcb8" class="nj mm it oc b gy og oh l oi oj">tic = time.process_time()<br/>dot_product = 0<br/>for i in range(x1_numpy.shape[1]):<br/>    dot_product +=x1_numpy[0,i]*x2_numpy[0,i]<br/>toc = time.process_time()<br/>print("dot product = " + str(dot_product))<br/>print ("Computation time = " + str(1000 * (toc - tic)) + "ms")</span></pre><p id="7e02" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然后，我将使用内置的NumPy函数估计使用矢量化版本所需的时间。</p><pre class="ks kt ku kv gt ob oc od oe aw of bi"><span id="ae10" class="nj mm it oc b gy og oh l oi oj">tic = time.process_time()<br/>dot_product = np.dot(x1_numpy,x2_numpy.T)<br/>toc = time.process_time()<br/>print("dot product = " + str(dot_product))<br/>print ("Computation time = " + str(1000 * (toc - tic)) + "ms")</span></pre><p id="66e9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于一个大小为10亿的数组，For循环需要1，330，437毫秒(约22分钟)。矢量化方法仅用了7，421毫秒(约7秒)。这相当于快了179倍以上(17，900%！).</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ok"><img src="../Images/dbf11a4030552b4007d99e27dc0de300.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AixjkeQRXI2J8DfwGq75gw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">进行10亿次乘法运算时，比较矢量化版本和非矢量化版本</p></figure><p id="76d9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">毫不奇怪，随着数组大小的增加，这两种方法之间的差异变得很明显。我针对不同的数组大小(从10到10亿)重复了上述步骤，并计算了计算所需的总时间。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/892cbf08d9283c3e6be736eb5acb34cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DC6d8Um_FCfMnbVIZGeGrQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">对于从10到10亿的不同向量大小，比较使用“for”循环和矢量化版本的处理时间。(图片由作者提供)</p></figure><h1 id="98bb" class="ml mm it bd mn mo om mq mr ms on mu mv ki oo kj mx kl op km mz ko oq kp nb nc bi translated">最后的想法</h1><p id="4767" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">我在这个领域已经工作了十多年了。我认为深度学习现在起飞的三个关键原因是大量数据的可用性、可用的计算能力和算法的创新。矢量化是一项惊人的算法创新。我不相信没有矢量化，深度学习就不会起飞。</p><div class="or os gp gr ot ou"><a href="https://ahmarshah.medium.com/membership" rel="noopener follow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd jd gy z fp oz fr fs pa fu fw jc bi translated">通过我的推荐链接加入Medium-Ahmar Shah博士(牛津)</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">阅读艾哈迈尔·沙阿博士(牛津)的每一个故事(以及媒体上成千上万的其他作家)。您的会员费直接…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">ahmarshah.medium.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi lb ou"/></div></div></a></div></div></div>    
</body>
</html>