<html>
<head>
<title>Shap’s partition explainer for language models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语言模型的Shap划分解释器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shaps-partition-explainer-for-language-models-ec2e7a6c1b77#2022-05-20">https://towardsdatascience.com/shaps-partition-explainer-for-language-models-ec2e7a6c1b77#2022-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e922" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Shapley值，Owen值和shap中的分割解释器:它们是如何联系在一起的</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b094b868dcedac4d4bd393a9e843dfdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5yCqq_yJUjjzZDJC"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@redcharlie?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">雷德查理</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="cdd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">理解模型预测的能力通常对铺平生产道路至关重要。虽然简单、可解释的模型在某些应用中取得了足够好的结果，但在其他应用中，使用复杂建模技术的好处超过了对易处理性的追求，如自然语言处理或计算机视觉。然而，我们希望了解哪些特征对模型的预测最重要。</p><p id="1d12" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Shapley值是一个理论上合理且广泛用于解释黑盒机器学习模型的概念。作为一种与模型无关的方法，它可以用于任何预测模型。它的吸引力在于其直白的解释:Shapley值是一个特征对实际预测的贡献，所有特征的Shapley值加起来就是预测。不幸的是，它有一个不可忽视的缺点:在其纯形式中，它很快变得难以计算。因此，我们必须求助于替代的、近似的方法。T4图书馆提供了一套不同的方法。对于自然语言处理和图像分类任务，它默认使用<em class="ls">分区解释器</em>计算<em class="ls"> Owen值</em>。本文的目的是演示它是如何工作的。</p><p id="abdc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我在一个文本模型设置中演示了什么是欧文价值观，它们如何与Shapley价值观相关，它们有多好，以及它们如何在shap中实现。在描述欧文价值观之前，我先快速回顾一下沙普利价值观。</p><h2 id="19cd" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">文本语境中的Shapley值述评</h2><p id="d34e" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">关于Shapley值、它的内部工作方式、优点和缺点已经写了很多，我不打算在这里赘述。感兴趣的读者可以在网上找到大量容易获取的资料(例如这里的<a class="ae kv" href="https://christophm.github.io/interpretable-ml-book/shapley.html" rel="noopener ugc nofollow" target="_blank">或者这里的</a>或者<a class="ae kv" rel="noopener" target="_blank" href="/the-shapley-value-for-ml-models-f1100bff78d1">和</a>)。相反，我限制自己在一个特定的环境中回顾它的本质，即基于文本的模型。</p><p id="1904" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在较高层次上，Shapley值是特征值或文本设置中的标记对模型结果的贡献。代币被解释为合作游戏中的玩家，他们合作产生收益或损失，即结果减去参考值。每个玩家贡献了多少？Shapley值试图将公平份额分配给每个参与者。单个玩家也可能对群体的得失做出相反的贡献。</p><p id="fe15" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了说明，让我们看一些随机的句子:“令人惊讶的曲折”，在一些监督学习文本模型中，它产生0.9886的预测。对于作为引用的空字符串，模型输出0.6431。每个单词对这0.3455的差异贡献了多少？</p><p id="6609" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们把句子想象成一组玩家<strong class="ky ir"> F </strong>，令牌。对于参与人<strong class="ky ir"> i </strong>，我们计算I在<strong class="ky ir"> F </strong>中排除I的所有子集<strong class="ky ir"> S </strong>上的加权边际贡献，边际贡献指的是I的存在引起的结果函数<strong class="ky ir"> v </strong>的变化。接近初始联盟或空集的子集被赋予更大的权重。在正式符号中，令牌I的Shapley值是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b3f3bfed8414dedf2ea8a6966f4097aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*p6rBZc7gObzmLNUrR04kSA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">参与人I的Shapley值的正式定义。</p></figure><p id="904f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有子集<strong class="ky ir"> S </strong>，也称为联合，都尊重原句子的顺序。下表展示了在示例文本中，对于某些假设模型，如何计算“令人惊讶”的Shapley值:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="43a6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将加权差值相加得到沙普利值0.1218。这就是“令人惊讶的”对0.3455的预测增长的贡献。为了计算这个小句子中一个单词的Shapley值，我们需要计算16个预测，8个子集各两个。总的来说，这个数字相当于</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/743aae09f1451ae5872b64231eba2827.png" data-original-src="https://miro.medium.com/v2/resize:fit:54/format:webp/1*PGPvDOAYohajIzLdd2h24g.png"/></div></figure><p id="b020" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算。</p><h2 id="fc95" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">欧文值:Shapley值的一个易于计算的近似值</h2><p id="807b" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">欧文值是沙普利值的联合版本。最初，欧文的意图是考虑到球员可能属于群体。在ML设置中，这转化为相关的特征值。尽管这是一个很好的副作用，但据我理解，shap的分区解释器使用Owen值的主要原因是为了让计算更容易处理。</p><p id="e6fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欧文值通过减少需要计算边际贡献的子集数量来逼近沙普利值。选择基于初始划分，即联合结构，它指定如何将令牌分组到联合中。从玩家的角度来看，联盟既可以在联盟内部形成，也可以在联盟层面形成。外部联合保持完整，不会分裂。在这两个层次上组合联盟的初始次序是选择联盟。</p><p id="0b19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们回到我们的例子，使这一点更清楚。句子“令人惊讶的曲折”可以被分割成联合结构B={{0，1}，{2，3}}。因此，形成的联合是{0，1}和{2，3}。对于索引0处的令牌“令人惊讶”，要组合的联盟是:</p><ul class=""><li id="caf0" class="mv mw iq ky b kz la lc ld lf mx lj my ln mz lr na nb nc nd bi translated">内部级别的{}和{1}</li><li id="2f72" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated">{}和{2，3}在联合级别。</li></ul><p id="a18b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">组合后的联合是{}、{2，3}、{1}、{1，2，3}。</p><p id="f53f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就像之前一样，我们然后计算I在排除I的所有已识别联盟上的加权边际贡献。正式定义是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/2824667080794ac6293c5e8a5318b51b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*-fEjzwTtEm9ZGAjw-q3nFg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">参与人I的欧文值的正式定义。</p></figure><p id="c07e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">诚然，这看起来有点复杂，但实际上与Shapley方程没有太大区别。<strong class="ky ir"> R </strong>都是<strong class="ky ir"> M\{k} </strong>的子集，其中<strong class="ky ir"> M={1，2，…，m} </strong>，其中<strong class="ky ir"> k </strong>是指其中有I的并集。<strong class="ky ir"> Q </strong>是r中的并的对应并(就集合论而言)即Q是并层次上的并。<strong class="ky ir"> T </strong>则是内部级别的联合，不包含I，小写字母<strong class="ky ir"> r </strong>和<strong class="ky ir"> t </strong>代表各自集合的大小。</p><p id="7786" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，下面是如何计算“令人惊讶”的欧文值，略有滥用符号:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="2a68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于Shapley值，我们需要计算8*2=16次预测，而对于Owen值，我们只需要4*2=8次！根据分区，所需的计算量可以大大减少。</p><p id="88dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是一个更长的例子:一个有七个标记的句子被分割成B={{0，1，2}，{3}，{4，5，6}}。对于索引为0的令牌，要考虑的联盟有</p><ul class=""><li id="503d" class="mv mw iq ky b kz la lc ld lf mx lj my ln mz lr na nb nc nd bi translated">在内部级别:{}、{1}、{2}、{1，2}</li><li id="a29c" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated">在外层:{}、{3}、{4，5，6}、{3，4，5，6}</li></ul><p id="2ff0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个例子中，计算了4*4*2 = 32个预测。不可忽略，但比最初的128个预测要少得多。更一般地，单个令牌所需的计算次数总计为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/35b1daf07b90e8809a852a97f4a6ee65.png" data-original-src="https://miro.medium.com/v2/resize:fit:128/format:webp/1*PifPmqhcl6j2M4SXMPcdbw.png"/></div></figure><p id="2ad3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欧文值方法潜在地节省了大量的计算资源。注意，如果形成个体联盟(每个集合一个令牌，b_k = 1)或大联盟(一个集合中的所有令牌，m = 1)，欧文值与沙普利值完全相同。</p><p id="7bd6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算Shapley值的计算成本极高。因此，采用更便宜的选择不仅是可取的，而且往往是必要的。不利的一面是，欧文值不是沙普利值，而沙普利值长期以来被认为是满足许多理想性质的唯一值。在ML环境中，它们是:</p><ul class=""><li id="14ed" class="mv mw iq ky b kz la lc ld lf mx lj my ln mz lr na nb nc nd bi translated"><em class="ls">对称性</em>:如果两个令牌对所有可能的联盟贡献相等，那么它们的贡献值是相同的。</li><li id="a066" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated"><em class="ls">效率</em>:所有Shapley值之和充分说明了得失。</li><li id="bdc7" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated"><em class="ls">虚拟</em>:其值不影响模型结果的特征贡献值为零。</li><li id="3637" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated"><em class="ls">可加性</em>:当一个模型的输出是两个中间输出的相加结果时，新的Shapley值是两个中间Shapley值之和。</li></ul><p id="a20a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不出所料，对称性被放弃了，或者至少放松了，因为它仍然适用于同一联盟中的令牌。贡献值取决于初始分区，因此现在是不明确的。</p><p id="9bcb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欧文值和沙普利值有多接近？在我们上面举例说明的例子中，欧文对“惊奇”的贡献是0.1175，所以只比沙普利值0.1218小一点点。更一般地说，<a class="ae kv" href="https://www.researchgate.net/publication/46510645_The_shapley_value_the_owen_value_and_the_veil_of_ignorance" rel="noopener ugc nofollow" target="_blank">本文在这里</a>论证了Shapley值是所有可能分区上所有对称分布的期望Owen值，但它没有对方差作出陈述。</p><h2 id="8f83" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">在shap中实施</h2><p id="159e" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在shap中，Owen值由partition explainer实现，缺省情况下文本模型会调用它。</p><p id="011a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码片段中，我给出了一个例子。解释器需要一些模型函数来从给定的字符串列表中产生输出。在这里，我使用了一个经过微调的distilbert情绪分析模型，它碰巧输出了上面示例中列出的预测。掩码很可能不同于原始模型的记号赋予器，它定义了计算Owen值的基础。我想获得“不可否认”的贡献值，而不是计算“un”、“deni”、“able”的贡献值。我发现transformers库中的BasicTokenizer通常是处理标点使用不当的好选择，但是空格标记化可能就足够了。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="4966" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，我使用空字符串作为引用字符串。如果标记化器没有属性mask_token，shap.maskers.Text()则使用“…”。对Shapley值的一个常见批评是引用不可信的特征值组合，这些组合不太可能甚至不可能在野外找到。虽然简单地丢弃标记肯定是有问题的，但在我看来，用一些随机的字符串替换它们更有问题，并且会创建特别奇怪的句子。我不知道作者为什么选择这样做。</p><p id="786a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了计算样本文本的Owen值，我们简单地调用explainer，<code class="fe nl nm nn no b">explainer(['surprising twists and turns']).</code>这样就实现了上面给出的划分，B = { { ' surprising '，' twists'}，{'and '，' turns'}}。</p><p id="e312" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要查看不同样本字符串上实现的分区，我们可以绘制一个树状图，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ms mt l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7b3229a13355b225f5ef606c27b5c915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*IDANwAZGQunuRtva73dC4g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">sample_text的树形图</p></figure><p id="3d1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，划分树有多个层次，B={{{0，1}，{2，3}}，{{4，5}，{6}}}。在我的理解中，绿色分支内的所有令牌都将红色分支视为一个整体，反之亦然。除此之外，程序没有改变。在所描绘的树中，使用分区B={{0，1}、{2，3}、{4，5，6}}来计算前四个令牌的Owen值，而红色分支令牌考虑B={{0，1，2，3}、{4，5}、{6}}。此外，权重不是根据上面描述的公式计算的，而是被均匀地分割。</p><h2 id="e4bc" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lf mc md me lj mf mg mh ln mi mj mk ml bi translated">Owen values:一种计算效率更高的近似值，易于在shap中实现</h2><p id="87ea" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">Shapley值是一个强大的ML解释工具，具有吸引人的解释:它对应于一个特征对模型预测的贡献。接近Shapley值的Owen值继承了这种直接的可解释性。此外，Shapley值长期以来被认为是满足许多期望属性的唯一概念，这些属性被认为共同定义了公平分享回报的含义。幸运的是，欧文价值观分享了其中的大部分。</p><p id="2aa7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">欧文最初的动机是扩展Shapley值，以考虑到球员可能属于群体。因此，同一个组的成员在彼此之间分享其收益之前形成一个协商子联盟。在ML上下文中，如果划分被相应地定义，这可能会重新平衡相关特性的问题。据我所知，这并不是shap库计算Owen值作为自然语言处理模型默认值的主要原因。相反，它利用了欧文值的计算更容易处理的事实，这是由于减少了所考虑的联盟的数量。</p></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="0717" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我试图在一个文本分类模型上计算Shapley值时，我无意中发现了shap的分区解释器。我花了一些时间来弄清楚它的内部工作原理，由于很难找到对欧文价值观的通俗易懂的解释，我决定撰写这篇文章。我所写的是我所能理解的，希望对某人有所帮助！</p><p id="3365" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考资料/进一步阅读</strong></p><p id="1d1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] <em class="ls"> J. M. Giménez，M. A .普恩特:</em> <a class="ae kv" href="https://upcommons.upc.edu/bitstream/handle/2117/131879/ICORES_2019_9_CR.pdf;jsessionid=1265EA4B2DB8C82F48ECBAA87BA249B7?sequence=1" rel="noopener ugc nofollow" target="_blank"> <em class="ls">欧文和欧文-班扎夫价值观应用于立法机构2015–2019</em></a><em class="ls">马德里议会和安达卢西亚议会的研究。ICORES 2019:45–52</em></p><p id="c7be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <em class="ls"> C. Molnar:可解释的机器学习:使黑盒模型可解释的指南(第二版。).</em><a class="ae kv" href="http://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank"><em class="ls">christophm.github.io/interpretable-ml-book/</em></a></p></div></div>    
</body>
</html>