<html>
<head>
<title>I ran 80,000 simulations to investigate different p-value adjustments</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我运行了80，000次模拟来研究不同的p值调整</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-ran-80-000-simulations-to-investigate-different-p-value-adjustments-5ff36fe4e0e6#2022-04-17">https://towardsdatascience.com/i-ran-80-000-simulations-to-investigate-different-p-value-adjustments-5ff36fe4e0e6#2022-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0173" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">多重比较很难。哪种校正最能处理假阳性和假阴性？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e1330e89ab5fdc71509425dd81775111.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YAgXK40SQXx1ShWn"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@edge2edgemedia?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Edge2Edge媒体</a>拍摄</p></figure><h1 id="e77e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">TL；博士:</h1><ul class=""><li id="4e42" class="lo lp iq lq b lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">在现实环境中，一次进行许多显著性测试是很常见的。然而，这意味着找到假阳性关系的可能性更大。有许多p值调整试图控制这一点，但它们往往过于保守，假阴性率非常高——尤其是在进行数百或数千次测试时。</li><li id="70e8" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">我使用80，000次模拟来研究四种不同的调整程序在准确性、假阳性率和假阴性率方面的比较。这些模拟在比较次数、具有真实(即非空)效应的比较比例以及效应大小的平均显著性方面有所不同。</li><li id="5fe1" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">我发现，在反映社会科学设置中最常见的数据类型的情况下，调整后的p值比未调整的p值更准确。然而，在其他情况下，未经调整的值具有更高的准确性。</li><li id="5279" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">最好的方法是在体面的<em class="ml">先验</em>信息和理论的基础上进行测试。当这不可能时，该分析表明基于错误发现率调整p值是大多数现实社会科学案例的最佳策略。继续使用未经调整的p值应该基于对被测事物相关性的坚定信念。</li></ul></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><h2 id="138a" class="mt kx iq bd ky mu mv dn lc mw mx dp lg lv my mz li lx na nb lk lz nc nd lm ne bi translated">在理想的世界中，所有的显著性检验都是为理论服务的。</h2><p id="a7da" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">然而，令几乎所有专业从事数据工作的人惊讶的是，我们并不是生活在一个理想的世界中。各种压力迫使许多从业者对同一数据集进行数十、数百甚至数千次显著性检验。这样做的一些原因比其他的更好，但是，独立于最好的动机:这种做法基本上打破了日常统计。p值变小的保证——仅这种可能性就能刺激零差异出现的几率仅为5%、1%或0.1%——在你进行数百次、数千次或数万次博弈时是没有意义的。(总有一个<a class="ae kv" href="https://xkcd.com/882/" rel="noopener ugc nofollow" target="_blank">相关的XKCD </a>)。正如我的微积分老师在向我们阐述极限的概念时所说的:</p><blockquote class="ns nt nu"><p id="8bde" class="nf ng ml lq b lr nv jr nh lt nw ju ni nx ny nk nl nz oa nn no ob oc nq nr mb ij bi translated">一个非常非常大的数除以一个大的数[或者，等价地，乘以一个小的比例]仍然是一个非常非常大的数。</p></blockquote><p id="0e79" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">最常见的方法是用一种程序来解释这种膨胀的假阳性率，这种程序伴随着膨胀大部分(如果不是全部)p值，使显著性阈值更难达到[1，2]。我们进行的测试越多，新的门槛就越严格。但是，虽然这有助于确保人们不太可能在某样东西不在的时候断定它“在那里”，但这意味着他们不可避免地更有可能在它在的时候断定它不在“那里”。换句话说，我们优先考虑避免假阳性而不是假阴性[3]。虽然这种偏好在许多情况下是有意义的，但它不是(也不应该是)普遍偏好的。在某些情况下，在假阳性上浪费时间的成本很高——但是，在其他情况下，抑制潜在的洞察力比避免走进死胡同的成本更高。幸运的是，有替代的调整程序承诺不那么严格。不幸的是，(或者，也许，<em class="ml">也幸运的是</em>，这取决于你的观点)，有几个重合的考虑因素在起作用，这意味着在何时使用哪种方法上根本缺乏严格的规则。</p><p id="3cfe" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">在我工作的地方，我们与大型跨国公司、新闻机构、政府机构和各种规模的非营利组织合作，收集和分析来自各种受众的意见数据。他们构建的调查种类<strong class="lq ir">多得令人难以置信</strong>；假设同一个解决方案能满足每个项目的所有需求是没有意义的。说某种方法绝对“更好”也是没有意义的。</p><blockquote class="od"><p id="7ef0" class="oe of iq bd og oh oi oj ok ol om mb dk translated">“更好”总是与某个目标、某个基准相关，而每个目标或基准都涉及到权衡。我宁愿通过向我们的客户和合作伙伴提供每种方法的成本和收益来授权他们做出这些决定，而不是自以为知道什么对他们“最好”。</p></blockquote><p id="216f" class="pw-post-body-paragraph nf ng iq lq b lr on jr nh lt oo ju ni lv op nk nl lx oq nn no lz or nq nr mb ij bi translated">为此，本文对80，000个模拟进行了分析，根据3个主要考虑因素调查了不同p值调整策略的假阳性和假阴性率:</p><ol class=""><li id="d4d5" class="lo lp iq lq b lr nv lt nw lv os lx ot lz ou mb ov md me mf bi translated">正在运行的测试的数量。</li><li id="6292" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb ov md me mf bi translated">测试集中“真实”关系的数量。</li><li id="6644" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb ov md me mf bi translated">我们对那些“真实的”关系有多确定。</li></ol><p id="f609" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated"><em class="ml">(“真”是指来自不同于空值的分布；其中非零差的经典“替代”假设是正确的。在这篇文章中，我将使用“真实”,这既是为了语义简单，也是为了让外行读者也能理解——这两个概念经常互换使用。</em></p><p id="5767" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">我发现，在最有可能在社会科学数据中看到的背景下，p值调整提高了我们准确分类效果是否“真实”的能力。然而，这主要来自于这样一个事实，即<em class="ml"> un </em>调整后的p值<strong class="lq ir">可靠地夸大了假阳性率。</strong>在处理数据时，如果您预计测试集的低比例确实是显著的(比如1%或5%)，这种夸大的假阳性率超过了调整后的p值具有非常高的假阴性率的强烈趋势(这种趋势只会随着测试数量的增加而加剧)。在处理数据时，如果您预计适度到更高比例的关系被测试为真正显著(例如，10%、20%或40%)，<strong class="lq ir">传统的、未调整的p值在分类准确性方面开始持续优于调整后的p值。</strong></p><p id="0e05" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">在深入研究结果之前，我想先了解一下模拟是如何设置的。这种讨论主要是概念性的；我把代码块留给那些有兴趣了解我如何在R语言中分析这些代码的人，这些代码块在我的个人博客上更具技术性。(也欢迎大家来参观这个项目的<a class="ae kv" href="https://github.com/prlitics/Research-Projects/tree/main/P-Value-Corrections-2022/p_value_corrections" rel="noopener ugc nofollow" target="_blank"> GitHub </a>资源库)。</p><h1 id="bbcd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">模拟设置</h1><p id="8e48" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">这个模拟的主要工具是<a class="ae kv" href="https://en.wikipedia.org/wiki/T-statistic" rel="noopener ugc nofollow" target="_blank">谦逊t统计</a>。由于在原始的模拟数据集之间进行比较只是用额外的(计算上昂贵的)步骤生成t统计量，所以我直接生成它们，然后将它们转换成p值。我假设空关系是正态分布的，平均t值为0。这意味着大约5%的真空值将大到足以被错误分类为“显著的”(即，触发假阳性)。你可能知道，这是传统的零假设显著性检验的要点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/a317e7ffc79a5bee68e3bc58a256e7cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TjdaUIrZJTQLjpWTCxcebw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1: 10，000个模拟t值，其中所有值都来自零分布。图片作者。</p></figure><p id="7f6f" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">为了模拟“真正的”显著差异，我生成了一个单独的t统计系列，其中第20个分位数位于传统的显著性临界值(1.96)的中心。这相当于80%功率的测试；也就是说，由于偶然性，假阴性将发生20%。我还假设这些t统计量遵循正态分布。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/2ab1879837ebf8e50f8629d22d56f039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3X3Wv0G-zofBxA2p5SoSxQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2: 10，000个图，其中90%为空，10%来自“真实”分布。注意较粗的尾部，因为更多的值在极端区域，比我们预期的要多。图片由作者提供。</p></figure><p id="0e5f" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">标题中的80，000个模拟由80个条件组成，每个条件执行1，000次。每种方法都试图比较5种不同p值的假阳性和假阴性率:<a class="ae kv" href="https://en.wikipedia.org/wiki/Bonferroni_correction" rel="noopener ugc nofollow" target="_blank"> Bonferroni调整的p值</a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method" rel="noopener ugc nofollow" target="_blank"> Holm调整的p值</a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method" rel="noopener ugc nofollow" target="_blank">Benjamin和Hochberg调整的p值</a>、<a class="ae kv" href="https://en.wikipedia.org/wiki/False_discovery_rate#Benjamini%E2%80%93Yekutieli_procedure" rel="noopener ugc nofollow" target="_blank">Benjamin和Yekutieli调整的p值，以及未调整的p值</a>。前两个针对家庭错误率(FWER)进行调整，旨在控制出现一个<strong class="lq ir"><em class="ml"/></strong>假阳性的可能性，而第三个和第四个调整基于假发现率(FDR)，将受控数量的假阳性视为降低假阴性率的可接受代价[4]。这使我们能够相互比较两种调整的性能，以及与标准的、未调整的p值进行比较。</p><p id="68db" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">这80个条件由3个研究问题驱动:</p><ul class=""><li id="cf08" class="lo lp iq lq b lr nv lt nw lv os lx ot lz ou mb mc md me mf bi translated"><em class="ml">假阳性/假阴性率将如何随着测试数量的增加而变化？</em>我考虑了4种不同测试次数的情况:10、100、1000和10000次。</li><li id="ea45" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated"><em class="ml">随着“真实效应”比例的变化，假阳性/假阴性率将如何变化？我考虑了5种情况，其中真实效果占测试的不同预期百分比:1%、5%、10%、20%和40%。</em></li><li id="880f" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated"><em class="ml">随着“真实效应”大小分布的变化，假阳性/假阴性率将如何变化？</em>我研究了当真正分布有4个不同的标准差时会发生什么:0.1、0.5、1.0和2.0。这也转化为真实效应的不同平均p值:0.04、0.02、0.005和0.0003。这反过来又告诉我们，我们有多“确定”这些差异不等于零。实际上，这是由效果大小和估计噪声的某种组合决定的。</li></ul><p id="8786" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">4个大小条件x 5个比例条件x 4个分布条件x 1，000个重复，每个重复给我们80，000个模拟。</p><p id="122b" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">在这些成千上万的模拟中，我将关注3个主要的指标:分类准确率、假阳性率和假阴性率。所讨论的“分类”反映了使用p值阈值(通常为0.05)来确定两个观察值之间的差异是否“真实”的常见频率主义实践——其中“真实”是指被比较的组实际上在感兴趣的度量上存在可测量的差异。虽然我(和许多许多其他人)不一定认为这是好的统计实践[5]，但它在学术和商业研究领域都非常突出:在某些时候，你必须遇到他们所在的地方。</p><p id="ffd9" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">由于模拟确定了差异在这个意义上是否是“真实的”,所以这可以转化为一系列(非常大的)2×2混淆矩阵，查看该值是否被生成为真，以及该过程是否确定其为真。(即(未)调整的p值是否低于0.05)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/3eae5b8f6d814911006a42a63b8bbe32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YCEsnUDJD2goNs79egTkew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:混淆矩阵示例。这是对100次比较进行BH调整的结果，其中40%的比较实际上是显著的，真实分布的平均p值为0.0003。</p></figure><p id="4abb" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">然后，我计算了分类准确度(正确识别的(非)重要关系的数量除以该模拟运行中的测试总数)、假阳性率(错误识别为重要的真正非重要关系的数量除以该运行中非重要关系的总数)和假阴性率(错误识别为非重要的真正肯定关系的数量除以该运行中重要关系的总数)。<a class="ae kv" href="https://en.wikipedia.org/wiki/Confusion_matrix#Table_of_confusion" rel="noopener ugc nofollow" target="_blank">维基百科对这些措施进行了细分</a>，但是，请注意，描述性的表格有点粗糙。</p><p id="6852" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">我应该注意的是，并不是我测试的所有值都特别现实——尤其是与其他值结合起来考虑的时候。很少有人做10，000次比较(或者，至少很少有人<em class="ml">应该</em>做那么多比较)；更少的测试有10，000次，其中<strong class="lq ir"> 40% </strong>的<strong class="lq ir"> </strong>比较是真正不同的，有很大一部分t值延伸到5-6 sigma。如果我曾经看到有人声称拥有这样的数据，我会问他们是否也打算向我出售一座桥梁，或者他们是否来自经销商服务部，就我的汽车的延长保修问题打电话。但是我把它们包括进来是为了测试边界条件:看看这些因素在最极端的情况下如何影响我感兴趣的东西。</p><h1 id="3ae1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结果</h1><h2 id="82b2" class="mt kx iq bd ky mu mv dn lc mw mx dp lg lv my mz li lx na nb lk lz nc nd lm ne bi translated">分类准确度</h2><p id="6521" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">下面一组图表显示了关于分类准确性的模拟结果。图表从左到右从最少(10)到最大(10，000)的比较次数进行排序，并从最低(1%)到最高(40%)的真实效果百分比进行排序。因此，更右边的图表显示了具有大量比较的模拟结果，而更靠近底部的图表显示了更大比例的所述比较实际上具有真实结果的结果。每个图表在其Y轴上按所查看的p值类型排序:未调整的p值、Bonferroni调整的p值、Holm调整的p值、Benjamini和Hochberg (BH)调整的p值以及Benjamini和Yekutieli (BY)调整的p值。每个图表的X轴反映了分类的准确性，范围从0到1。不同的形状反映了较高/较低的平均p值，线条代表了内部95%模拟值的范围。圆形是平均p值0.04，三角形是0.02，正方形是0.005，十字形是0.0003。然后，在每个图表中，每个形状的位置反映了通过该方法获得的精度，形状本身表达了在真实关系中看到的平均p值。(点击放大图)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/9d02adb3442a0e3f3f60e602437a3118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLID8D_qt64tHUrsUYBaUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:精度上的P值调整性能。点反映平均值，线显示95%模拟的分布。在小于10%真值的情况下，BH调整是最好的。在超过10%真值的情况下，未经调整的p值是最好的。</p></figure><p id="2589" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">如果看起来有很多事情发生，那就是有。类似于那些图片，你看得越多，你就发现越多，这里有大量的信息编码。这些图表最终揭示了p值类型及其分类准确性之间的高度上下文驱动关系。</p><ul class=""><li id="d5c2" class="lo lp iq lq b lr nv lt nw lv os lx ot lz ou mb mc md me mf bi translated">对于具有5%或更少真实效应的比较集，真实效应的平均p值对分类准确性没有特别大的影响。形状都是相互成一直线的；如果有什么突出的，那就是十字架——但这只在几个面板中有争议。在每种情况下，调整后的p值的精度都高于未调整的p值，尽管当比较次数较少时，精度等级会分散得多。当你达到10000点时，价差已经缩小到非常有限的范围。无论你采用哪种p值方法，这些组的平均分类排名都非常高:在所有条件下，所有方法的平均得分为0.97，满分为1.0。然而，尽管利润极其微薄，但BH的调整优于其他公司。</li><li id="44a7" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">对于10%的效应为真的对比组，故事变得更加复杂。在比较次数较少时，这些值仍然分散，随着比较次数的增加，这些值变得更加集中，但现在我们看到了十字形和其他形状之间的明显区别——至少在调整值的情况下是如此。最有趣的是，这个条件(真实关系的平均p值为0.0003)是唯一一个可以可信地声称表现与未经调整的p值一样好或更好的条件——实际上这只是两个错误发现率调整(BH和BY)中的一个。</li><li id="e022" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">在20%或40%的影响为真的情况下，调整后的平均p值的影响变得更加相关。当平均真实p值为0.04或0.02时，分类准确度与未调整的p值显著不同(当40%为真实效应时，差异显著)。当平均真实p值为0.0003时，这一点得到了很大的改善，但它没有接近除BH之外的所有校正方法的未校正p值的分类精度。(即便如此，也比未经调整的p值略差)。</li></ul><p id="86b0" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">对于大多数日常社会科学数据集，你很难让20-40%的随机测试关系证明是真正重要的。我能想到的唯一例外是，如果这组比较已经通过至少不完整的理论考虑进行了筛选，或者如果所有可用的变量都已经过筛选。在大多数情况下，这些结果表明p值调整是最谨慎的，BH FDR调整表现最好。但如果你有充分的理由认为你测试的比较中有相当多的事实上是显著不同的，那么使用调整后的p值通常比使用未调整的p值更差(尽管前者的表现随着平均真实p值的下降而改善)。</p><h2 id="8b93" class="mt kx iq bd ky mu mv dn lc mw mx dp lg lv my mz li lx na nb lk lz nc nd lm ne bi translated">假阳性和假阴性率</h2><p id="bd36" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">虽然分类准确性很重要，但人们使用调整后的p值的主要原因是为了减少假阳性的数量，而人们经常拒绝调整的原因是因为假阴性的增加。那么这些策略是如何影响这些利率的呢？</p><p id="aee2" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">下面这组图表研究了这个问题。和以前一样，图表从左到右按比较次数组织，从上到下按与真实关系的比较比例组织。图表上的点的形状标识了“真实”关系的平均显著性，X轴编码了度量的分数，范围在0-1之间。不过，在这里，我们看到的是两个指标，而不是一个。Y轴上列出的每个过程分为两种颜色:红色是该指标在该条件下的假阳性率，绿色是其假阴性率。(点击可缩放)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/fcbcab9cae74e3fa13baf81a685b5e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdP4A0jjQreD6nNRkrmaaA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:假阳性(红色)和假阴性(绿色)率的P值调整。点反映平均值，线显示95%模拟的分布。调整往往会导致较低的假阳性率，但通常会导致较高的假阴性率——尤其是当样本增加时。在这种情况下，未经调整的值更好，但平均“真实”p值与阈值相差很大的比较集可能会更接近。</p></figure><p id="e758" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">这里，各种面板再次揭示了一种高度上下文相关的关系。然而，有几个总体趋势是可以确定的。</p><ul class=""><li id="6443" class="lo lp iq lq b lr nv lt nw lv os lx ot lz ou mb mc md me mf bi translated">关于假阳性率，调整程序普遍优于未调整的p值。按照设计，未经调整的p值将有5%的假阳性率；调整后的测试倾向于低一个数量级或多一个数量级，其中BY调整在该组中具有最佳性能。</li><li id="77ce" class="lo lp iq lq b lr mg lt mh lv mi lx mj lz mk mb mc md me mf bi translated">然而，关于假阴性率，调整程序普遍比未调整的p值差。总的来说，大量的测试倾向于提高调整后p值的假阴性率，而对未调整的p值没有影响。这是有意义的，因为调整后的度量标准的显著性阈值是随着您使用越来越多的测试而变得越来越严格的标准的比较次数的函数。相比之下，未调整的p值与测试的功效相关。对于与显著性临界值没有太大差别的真实关系，这意味着有效地将所有真正显著的关系错误分类为不显著。当平均真实p值变小时，所有调整程序的性能都有所提高，但性能最好的是那些通过FDR(即BH和by)而不是FWER(即Bonferroni和Holm)进行调整的程序，其中BH是性能最好的调整程序。</li></ul><h2 id="ee09" class="mt kx iq bd ky mu mv dn lc mw mx dp lg lv my mz li lx na nb lk lz nc nd lm ne bi translated">总而言之</h2><p id="f665" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">对于社会科学数据中最常见的数据和比较类型，调整后的p值将提供更高的分类精度。这些方法中表现最好的往往是BH和BY调整。但是，除非您预期真正显著的比较具有比显著性阈值更小的平均p值(即0.005或更低)，否则随着测试次数的增加，这些方法往往会出现越来越多的假阴性。</p><h1 id="0d81" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">调整还是不调整？</h1><p id="ec8f" class="pw-post-body-paragraph nf ng iq lq b lr ls jr nh lt lu ju ni lv nj nk nl lx nm nn no lz np nq nr mb ij bi translated">那么，你应该选择调整后的还是未调整的p值呢？事实上，在数据科学和统计学领域，一切都要视情况而定。在真正有意义的比较比例在1–5%之间的情况下，调整后的p值比未调整的p值具有更高的准确率。10%或更高，取决于你真实关系的平均强度。如果您有一堆值徘徊在您的显著性阈值附近，调整后的方法将导致几乎所有的值(如果不是全部的话)被错误分类为非显著性。当平均显著性值明显好于截止值时，这种趋势得到改善。这反映在不同情况下的假阳性和假阴性率上:调整程序的假阳性率极低，但假阴性率很高，除非大多数真值大大低于显著性阈值。当比较的数量不是过多时，调整程序做得最好，我们期望只有少量的比较是真正有意义的。在其他情况下，未经调整的p值可能更为谨慎。</p><p id="54c0" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">这可能会鼓励一些读者认为未经调整的p值是正确的选择。从个人经验来看，如果有一条路是你被迫走的，你总是很容易说服自己你的数据符合某些标准。然而，犯错的代价相当高昂:假阳性的噪音比真阳性的信号要大得多。如果只有5%的关系最终有真实的信号，模拟显示超过一半的标记为重要的关系实际上没有。如果真正重要的关系只占关系的1%,你可以预期只有15-20%的“重要”结果是正确的。最糟糕的是，在这两种情况下，你都不知道哪个是真实的，哪个是冒名顶替的。虽然在某些情况下，追求新创新失败的成本可能比走进死胡同更高，但很难证明在走向“真实”之前走进4-5个死胡同的成本是合理的，尤其是在无法保证“真实”有足够的杠杆来支付这些成本的情况下。同样，在某些情况下，接受5次失误是完全合理的(例如，天使投资者的相对成功率通常比这低)，但这不是应该假设的事情。</p><p id="293e" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">如果有一些关系在p值调整后变得无关紧要，这让你感到惊讶，你总是可以用一个独立的样本单独重试这个关系:那种认为某个东西<em class="ml">应该</em>在那里的琐碎感觉可能是由某种理论预设或其他因素决定的。只有将你的期望建立在基础上，使它们变得清晰，并自己测试它们，研究才能得到改进。</p><p id="f851" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">也就是说，这项研究确实强烈表明，在某些情况下，即使进行多重比较，未经调整的p值也将是更谨慎的选择。这种情况包括当你测试大量的比较时，非常大的比例实际上反映了真实的关系。我必须强调，这样的数据很少。如何确定一个人的数据是否符合这条路线的标准超出了这个项目的范围(毕竟，当<em class="ml">您控制关系</em>的重要性时，很容易做出这个决定；在现实世界中，我们不直接拉动杠杆或输入真实值，这有点困难)。然而，我认为一个卓有成效的方法是从比较中的p值直方图开始。因为p值是均匀分布的，所以在小于0.05或0.10的值处看到大的峰值会让您感觉到您的数据实际上具有显著的关系。这个峰值相对于其他值的大小(以及峰值是否集中在更接近于0.05的值，比如说0.001)可以帮助查明调整实际上是否是正确的策略。有多种方法可以估计p值直方图中“真零”的比例[6]。我目前正计划在未来几个月的某个时候对这个话题进行另一次调查，敬请关注！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/065527374292dd2893e21e5480d1264c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mdXdbSHz0JM91_hPdLrDoA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6:p值直方图，其中所有值均为空，正态分布(上图)，10%的值来自平均p值为0.005的“真实”效应分布(下图)。后者比0.05的值集中得多。</p></figure><p id="a7b6" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">总的来说，如果从这项模拟研究中有什么收获的话，那应该是:处理多重比较是很棘手的，而且取决于具体情况。应根据分析的目标和数据的性质来决定是否使用校正。在进行数十次、数百次或数千次比较时，简单地不调整p值并不是一个好主意——最好的解决方案也不是让所有东西都通过p值调整的“过滤器”。依我拙见，最好的解决办法是，尽可能地关注最重要的关系。只测试那些你真正感兴趣的和/或对你的用例有帮助的。权衡是做研究不可避免的一部分，但多重比较测试中的假阳性与假阴性问题大多来自于在没有设计的地方应用熟悉的测试范例。统计是神奇的，但不是字面上的神奇。如果我们把它的机制推到远远超出其预期的程度，当它崩溃时，我们不应感到惊讶。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="7697" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">Peter Licari是一名专门研究美国政治行为的社会数据科学家。他在佛罗里达大学获得了美国政治和政治方法论的博士学位，目前是Morning Consult的商业数据科学总监。这里表达的观点是他自己的。也可以在 <a class="ae kv" href="https://www.youtube.com/channel/UCuCCVkVbWmYmgg7W9x2Y30g" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> YouTube </em> </a> <em class="ml">和推特(</em><a class="ae kv" href="https://twitter.com/PRLPoliSci" rel="noopener ugc nofollow" target="_blank"><em class="ml">@ PRLPoliSci</em></a><em class="ml">)上找到他。剩下的一点点业余时间都花在了长跑、与妻子斯蒂芬妮(Stephanie)畅玩游戏和媒体、与女儿罗莎琳娜(Rosalina)玩耍、遛狗杜德(Dude)以及与他的猫亚洲(Asia)进行奇怪的、富有成效的单边对话上。</em></p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="8650" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[1]j . p .罗马诺、A. M .谢赫和m .沃尔夫(未注明日期)。<em class="ml">多重检测。</em></p><p id="9803" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[2]f . Bretz、t . hot horn和p . Westfall(2016年)。<em class="ml">使用R的多重比较</em>。查普曼和霍尔/CRC。</p><p id="f81a" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[3]罗斯曼，K. J. (1990年)。多重比较不需要调整。<em class="ml">流行病学</em>，43–46。</p><p id="b1d0" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[4]诺布尔，W. S. (2009年)。多重测试校正是如何工作的？。<em class="ml">《自然生物技术》</em>，<em class="ml"> 27 </em> (12)，1135–1137。</p><p id="e410" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[5]盖尔曼(2013年)。评论:P值和统计实践。<em class="ml">流行病学</em>，<em class="ml"> 24 </em> (1)，69–72。http://www.jstor.org/stable/41739720</p><p id="f251" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">[6]姜，h .，，R. W. (2008年).估计多重比较的真零假设的比例。<em class="ml">癌症信息学</em>，<em class="ml"> 6 </em>，25–32。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="e860" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated"><em class="ml">这是本分析的版本</em><strong class="lq ir"><em class="ml">1 . 1 . 0</em></strong><em class="ml">。</em></p><p id="0fc9" class="pw-post-body-paragraph nf ng iq lq b lr nv jr nh lt nw ju ni lv ny nk nl lx oa nn no lz oc nq nr mb ij bi translated">我相信所有的作品都得益于读者的建设性反馈以及作者自己的重新审视和思考。但是并不是所有的作品都适合学术出版。为此，为了透明起见，我决定在我的非学术项目上线时，以一种其他人(希望)会接触到它的方式，对它们的要点进行可视化索引。小的修改(如语法或小的图像格式问题)会导致第三位数增加。由我自己的重访启发的大修改和由读者的建议启发的小修改导致第二位数的增加。由读者的建议或未来的反思和对项目的重新审视所驱动的主要修改会导致第一个数字的增加。在6个月没有更新之后，一个版本应该被认为是“最终版本”当前版本于2012年4月17日发布。本帖的changelog维护在 <a class="ae kv" href="https://github.com/prlitics/Research-Projects/tree/main/P-Value-Corrections-2022/p_value_corrections" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> Github </em> </a> <em class="ml">上。</em></p></div></div>    
</body>
</html>