<html>
<head>
<title>Navigating MLOps in 2022</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">2022年导航MLOps</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/navigating-mlops-dc2a242ef7ed#2022-07-06">https://towardsdatascience.com/navigating-mlops-dc2a242ef7ed#2022-07-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cbdd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">生产中的数据科学:经验、工具和框架</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/95cf2d3e4430b01c8795f7d911bed615.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BbmzDkJMotBh2WZBtA-ozg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">劳拉·奥克尔在<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="3819" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://ml-ops.org/" rel="noopener ugc nofollow" target="_blank"> MLOps </a>已经在机器学习、数据科学、软件工程和(云)基础设施的交叉领域确立了自己的独立地位。在这篇文章中，我想看看机器学习/数据科学在生产中的现代方法、经验教训和实践经验。</p><h1 id="cbfd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据环境变化很快</h1><p id="721e" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我刚开始做机器学习的时候，2014年我还是大数据工程师的时候，大部分是在大数据的背景下应用的。机器学习或数据科学并不新鲜，但随着Hadoop中的MapReduce和后来的内存引擎(如Apache Spark)将机器学习的能力与分布式计算和海量(web)数据的能力联系起来。我们已经看到了许多重大转变，从(本地)Hadoop生态系统的兴衰开始(并非最后是因为巨大的管理成本),以及云中数据处理的持续趋势，我们可以肯定只有一件事是一致的:变化。</p><p id="93d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不仅基础设施变了，框架和方法也变了。从TensorFlow到Pytorch，从CRISP-DM到Agile，从SOAP到无服务器。很难跟上潮流。</p><h1 id="bb3e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">MLOps Buzz</h1><p id="99bf" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你看看人工智能初创公司和咨询公司做出的承诺，以及真正适用的承诺，两者之间存在很大差距。虽然他们中的一些人几乎没有应用任何人工智能，但他们中的大多数人都因为坏的、丢失的或无用的数据而失败。然而，近年来许多公司已经开始成功地应用数据科学，并且有许多模型等待投入生产。这带来了新一波的MLOps创业公司，他们现在再次承诺提供一个适合所有人的解决方案。</p><h1 id="48fe" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">没有人能统治他们所有人</h1><p id="29b1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当从定制的MySQL数据仓库迁移到云并评估许多不同的产品时，只有一个结论:没有适用于所有东西的平台，其中大多数都在为非常狭窄的用例工作。对于MLOps也是如此。因此，不要认为没有ML基础设施团队就可以将模型投入生产。</p><p id="91e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是当然，有一些优秀的工具可以解决特定的用例。而且你不需要在投产前建立完整的基础设施，你也不应该。但是您需要相应地扩展您的基础架构。</p><p id="7df8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我将在这里详细说明，并直接说出供应商或开源框架的名称，而不涉及其中任何一个。</p><h1 id="7b11" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">语言</h1><p id="fe9d" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">只是一个简短的提醒，每一个代码都应该遵循软件工程的原则。这意味着测试CI/CD、项目结构和编码最佳实践。我在这里不关注这个，因为它与软件工程没有什么不同。</p><h2 id="df48" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">计算机编程语言</h2><p id="e3f3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">当然，我推荐使用pandas、scikit-learn、seaborn、tensorflow、pytorch、<a class="ae ky" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank"> huggingface </a>、jupyter的Python堆栈——凡是你能想到的。然而，从MLOps的角度来看，更重要的是该堆栈的部署。如果你有轻量级的脚本，我建议使用AWS Lambda，如果它变得更高级，我更喜欢运行云服务器(如AWS EC2)并在<a class="ae ky" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>中隔离一切。将<a class="ae ky" href="https://www.terraform.io/" rel="noopener ugc nofollow" target="_blank">地形</a>用于基础设施是明智之举。我也推荐使用anaconda，因为他们的库是有管理的，对于专业人员来说非常便宜。</p><h2 id="9086" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">稀有</h2><p id="6a93" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有时你可能需要生产R脚本。在这种情况下，要么选择托管服务，要么使用Docker来隔离环境。不要在裸机服务器上安装R并试图在那里运行生产脚本，你会经历地狱，因为R肯定不是生产级语言。并了解R库的安全含义。</p><h2 id="fcda" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">Java 语言(一种计算机语言，尤用于创建网站)</h2><p id="0632" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你身边有Java，就像许多公司一样，使用java ml框架可能更容易。在许多情况下，将您的模型直接集成到您的软件环境中是非常有意义的。但是你需要会用Java编码的人，或者需要会“移植”代码的工程师。虽然我个人不喜欢<a class="ae ky" href="https://www.cs.waikato.ac.nz/ml/weka/" rel="noopener ugc nofollow" target="_blank"> WEKA </a>并会避免<a class="ae ky" href="https://github.com/eclipse/deeplearning4j" rel="noopener ugc nofollow" target="_blank"> deeplearning4j </a>，但我真的很喜欢使用<a class="ae ky" href="https://haifengl.github.io/" rel="noopener ugc nofollow" target="_blank"> Smile-ML </a>。</p><h1 id="4827" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">框架和产品</h1><h2 id="6c58" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">实验跟踪</h2><p id="b1c2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">周围有很多不同的工具，但我个人喜欢<a class="ae ky" href="https://neptune.ai/" rel="noopener ugc nofollow" target="_blank"> Neptune.ai </a>。他们称自己为ML-Ops的元数据存储库，这相当准确。你可以免费使用它们，甚至在一个小团队中，并跟踪你的实验和保存你的模型，支持许多不同的框架，如scikit-learn，TensorFlow，Pytorch，R…</p><h2 id="30a2" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">部署脚本与部署深度学习模型</h2><p id="928f" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你部署深度学习模型，我真的会建议你使用模型服务器。可以是<a class="ae ky" href="https://developer.nvidia.com/nvidia-triton-inference-server" rel="noopener ugc nofollow" target="_blank"> Triton </a>，<a class="ae ky" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> tensorflow serve </a>，或者你喜欢的任何东西，但是要用模型服务器！如果你没有定制层，使用<a class="ae ky" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> ONNX </a>作为格式，如果你有定制层，使用框架的模型服务器来避免不必要的工作。<a class="ae ky" rel="noopener" target="_blank" href="/how-to-not-deploy-keras-tensorflow-models-4fa60b487682">这里</a>我写的更详细，重点是TensorFlow。</p><p id="f401" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您为批量预测部署脚本，那么简单的方法就是在Docker中运行它们。对于API，你可以像之前说的那样在Docker容器中运行无服务器产品，如<a class="ae ky" href="https://aws.amazon.com/de/lambda/" rel="noopener ugc nofollow" target="_blank"> AWS Lambda </a>或<a class="ae ky" href="https://fastapi.tiangolo.com/" rel="noopener ugc nofollow" target="_blank"> FastAPI </a>。</p><h2 id="2549" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">模特培训</h2><p id="06b8" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">有了terraform，你还可以在GPU实例(AWS、GCP、Azure)上的云中自动进行模型训练。然而，我个人喜欢在我的开发机器上有一个强大的GPU来快速试验东西和评估模型。在本地有一个GPU，这对于原型来说要快得多。还要注意，有特定的GPU实例用于推理。</p><h2 id="ab26" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">管弦乐编曲</h2><p id="f906" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于编排来说，<a class="ae ky" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"> AirFlow </a>或<a class="ae ky" href="https://www.prefect.io/" rel="noopener ugc nofollow" target="_blank"> Prefect </a>似乎是不错的选择，但是Prefect要求你在每台服务器上安装一个代理(管理员通常不喜欢这样)，在AirFlow中你可以使用SSH。</p><h2 id="f2e8" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">监视</h2><p id="ee07" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">根据我的经验，监控是高度定制的，但我个人喜欢的是用于时间序列监控的<a class="ae ky" href="https://www.elastic.co/de/kibana/" rel="noopener ugc nofollow" target="_blank"> Kibana </a>，它在付费版本中提供了开箱即用的异常检测。一般来说，监控模型预测(计数、分布)、训练结果和特征特性之类的东西是明智的。NeptuneAI还涵盖了与模型训练相关的指标。</p><h2 id="9a2b" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">SQL和矢量数据库</h2><p id="de79" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我很喜欢使用MySQL或PostgeSQL这样的纯SQL数据库。然而，在某种程度上，使用数据仓库是明智的，因为在2022年没有人会构建Hadoop集群，所以你最好看看像<a class="ae ky" href="https://www.snowflake.com/" rel="noopener ugc nofollow" target="_blank"> Snowflake </a>这样的云数据仓库，它提供了很多高级功能，特别是针对ML和DS ( <a class="ae ky" href="https://www.snowflake.com/snowpark" rel="noopener ugc nofollow" target="_blank"> Snowpark </a>)。</p><p id="c245" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但还有更多，如果你使用一些相似性搜索引擎(如视觉相似性)，你可能要调查向量数据库。直截了当的方法是使用<a class="ae ky" href="https://github.com/nmslib/hnswlib" rel="noopener ugc nofollow" target="_blank"> HNSWlib </a>(支持包括Java在内的许多语言)或<a class="ae ky" href="https://github.com/spotify/annoy" rel="noopener ugc nofollow" target="_blank">惹恼来自Spotify的</a>，其中的索引只是一个文件。但是还有更高级的选项，比如<a class="ae ky" href="https://milvus.io/" rel="noopener ugc nofollow" target="_blank"> Milvus.io </a>。</p><h2 id="6e9a" class="ms lw it bd lx mt mu dn mb mv mw dp mf li mx my mh lm mz na mj lq nb nc ml nd bi translated">项目管理</h2><p id="a0e1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">不要用Scrum，用看板，但这是我的看法。详见<a class="ae ky" href="https://medium.com/towards-data-science/machine-learning-projects-and-scrum-a-major-mismatch-c155ad8e2eee" rel="noopener">此处</a>。</p><h1 id="43d5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">推理设置</h1><p id="e726" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最后，让我们快速讨论一下推理设置。通常，很多模型不需要提供实时预测。如果不需要，引入额外的堆栈是没有意义的。以我的经验来看，有三种推理模式。<strong class="lb iu">批量预测</strong>、<strong class="lb iu">实时预测</strong>和<strong class="lb iu">在线学习系统</strong>，其中最后一个是一个例外。我从未真正将在线学习系统投入生产，所以我不能真正谈论它，但至少我可以说这是最复杂的场景，因为它是完全自主的，你需要大量的监控来确保模型不会失败，就像<a class="ae ky" href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist" rel="noopener ugc nofollow" target="_blank">微软向我们展示的</a>。</p><p id="4260" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与批处理相比，实时推理增加了许多复杂性。您需要确保应用所有的软件工程实践来构建一个可靠的、可伸缩的系统。这就是为什么我建议使用模型服务器，因为它们是为这种用例而设计的。</p><p id="de4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">批处理要简单得多，因为如果它失败了，可以很容易地重复，你不需要考虑延迟，通常你只需要输入-&gt;输出，不需要太多的网络参与。</p><p id="698a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这能给你一些启发，帮助你理解MLOps是什么。一如既往，这里有很多观点，有其他经历也没关系，但我很高兴在评论中听到你的。</p></div></div>    
</body>
</html>