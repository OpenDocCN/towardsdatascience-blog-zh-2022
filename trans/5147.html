<html>
<head>
<title>How to Serve and Deploy Machine Learning Models Easily</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何轻松地服务和部署机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d#2022-11-17">https://towardsdatascience.com/10-ways-bentoml-can-help-you-serve-and-scale-machine-learning-models-4060f1e59d0d#2022-11-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fb1f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><code class="fe ki kj kk kl b">Moving from Jupyter notebooks to production is not that difficult</code>毕竟</h2></div><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/99eeeac9ec933e73821acbe0dac1de79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jbVzJZozg6u_X12l"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">弗兰·雅克耶在 Unsplash<a class="ae lc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">上的照片</a></p></figure><p id="2512" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果您是一名数据科学家，您可能会花大量时间开发复杂的 Jupyter 笔记本来执行数据分析、构建复杂的培训管道或计算统计数据。</p><p id="525b" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">Jupyter 笔记本在这方面非常棒，它让我们可以立刻构建出想法的原型。</p><p id="7dac" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf iu">但是，一旦您完成了这项工作，并且对保存的 ML 模型感到满意，会发生什么呢？🤔</strong></p><p id="e979" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是您开始考虑将它们部署到生产中的地方。你开始工作的时候有没有想清楚这一点？</p><p id="d1af" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">大概不会。这不怪你，因为这不是数据科学家的核心专长。(尽管行业目前正朝着这个方向发展)</p><blockquote class="lz ma mb"><p id="e622" class="ld le mc lf b lg lh ju li lj lk jx ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">在本教程中，我将展示如何使用一个名为 BentoML 的 Python 库来打包您的机器学习模型并轻松部署它们。 </p><p id="083a" class="ld le mc lf b lg lh ju li lj lk jx ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated"><strong class="lf iu"> <em class="it">我先给大家介绍一下制作 ML 的概念。然后，我将向您介绍该工具，并涵盖 BentoML 可以让您的生活变得更轻松的 10 种方式。</em> </strong></p></blockquote><p id="705e" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="mc"> PS:这不是一篇 clickbait 的文章:所有这些理由都是有效的、有据可查的理由。对于每一个，我将分享代码，解释和我的印象。</em></p><p id="640e" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">事不宜迟，我们来看看🔍</p></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="9873" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">一旦你的模型被训练后会发生什么？</h1><p id="abe2" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">一旦你训练了一个模型，你需要开始考虑与其他团队分享它。</p><p id="3157" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果您团队中的其他开发人员(例如后端或前端开发人员)想要使用它，他们需要与包装它的某种 API 进行交互。这个 API 必须清晰并有文档记录，有明确的错误记录和数据验证。</p><p id="ab4e" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果 DevOps 团队想要管理您的模型的部署，它需要处理它的依赖关系。它通常期望至少有一个运行并服务于您的模型的 Docker 映像。</p><p id="a72e" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">如果产品团队想要对您的模型进行压力测试或者向客户展示，那么 API 必须能够适应许多并发请求。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nk"><img src="../Images/a4cd4f27f7ad861d53cff364507d1a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxEWE9EMT-QBpCHB4nIBEw.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">接下来会发生什么？作者图片</p></figure><p id="d104" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这里总结一下。</p><p id="8ce7" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">将一个 ML 模型带入生活(即生产)会有很多限制:</p><ul class=""><li id="cdd6" class="nl nm it lf b lg lh lj lk lm nn lq no lu np ly nq nr ns nt bi translated">多 ML 框架的使用和支持(咄！)</li><li id="42bc" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">创建 API 并以最低的性能水平为其服务</li><li id="76a7" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">再现性和依赖性管理</li><li id="836b" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">API 文档</li><li id="1875" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">监控、日志记录、指标等。</li></ul><p id="7ee2" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">势不可挡不是吗？</p><p id="aed2" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在接下来的 10 节中，我们将通过概念、有用的命令和 ML 相关的特性来探索 BentoML 是如何实现这一点的。</p><h1 id="68a5" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated">1— BentoML🍱:分发您的 ML 模型的标准化格式</h1><p id="13fb" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated"><a class="ae lc" href="https://www.bentoml.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu"> BentoML </strong> </a>是模型服务和部署的端到端解决方案。它旨在帮助数据科学家利用通用 MLOps 最佳实践构建生产就绪型终端。</p><blockquote class="lz ma mb"><p id="92ff" class="ld le mc lf b lg lh ju li lj lk jx ll md ln lo lp me lr ls lt mf lv lw lx ly im bi translated">它是另一个 web 框架吗？</p></blockquote><p id="b977" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">不完全是。BentoML 将 ML 项目中需要的所有东西打包成一个名为<strong class="lf iu"> <em class="mc">的分发格式🍱<strong class="lf iu"/></em></strong></p><p id="c822" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">更准确地说，便当是一个文件档案，包含您的模型训练的所有<strong class="lf iu">源代码</strong>和您定义的用于服务的<strong class="lf iu">API</strong>，保存的<strong class="lf iu">二进制模型</strong>，<strong class="lf iu">数据文件</strong>，<strong class="lf iu">docker 文件</strong>，<strong class="lf iu">依赖关系</strong>，以及附加的<strong class="lf iu">配置</strong>。</p><p id="6db0" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">所有的东西都组合成一个单元，并打包成一种标准化的格式。</p><p id="39ac" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你可以把便当想象成 Docker 图像，但是对于 ML。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oe"><img src="../Images/8073127282f9321820e391db6837d49d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jLmbRuiSJWQTESwkTJnNWA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">BentoML —作者图片</p></figure><p id="f6b8" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一份盒饭也是自带的。这简化了任何云基础架构的模型服务和部署。</p><p id="fd44" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当你的便当被构建时(我们将在下一节看到这意味着什么)，你可以把它变成一个 Docker 镜像，你可以部署在云上，或者使用<code class="fe ki kj kk kl b"><a class="ae lc" href="https://github.com/bentoml/bentoctl" rel="noopener ugc nofollow" target="_blank"><strong class="lf iu">bentoctl</strong></a></code> <strong class="lf iu"> </strong>，它依赖于幕后的 Terraform，并把你的便当部署到任何云服务和基础设施(AWS Lambda 或 EC2，GCP 云运行，Azure 函数，等等)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi of"><img src="../Images/e4b8d0713efbb0249407558966b88191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B9n1mPHhja4WP_72TPSzQQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">如何部署便当—作者图片</p></figure><h1 id="d75b" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated">2-将模型保存到本地存储并进行版本控制💾</h1><p id="c462" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">首先，你需要运行:<code class="fe ki kj kk kl b"><strong class="lf iu">pip install bentoml</strong></code></p><p id="ae1f" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><em class="mc">一旦安装完毕，</em> <code class="fe ki kj kk kl b"><em class="mc">bentoml</em></code> <em class="mc">命令就会被添加到您的 shell 中:这在接下来的章节中会很有用。</em></p><p id="775b" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当您的模型完成训练时，您通常会开始使用 BentoML(这一部分不受影响)</p><p id="67ac" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">事实上，您可以使用 BentoML 将模型保存在特定的文件夹中(称为模型存储)，而不是保存在文件系统的某个地方。这有助于为模型的每个版本提供唯一的标签，并确保可再现性。</p><p id="e24a" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在下面的例子中，我们保存了一个在 iris 数据集上训练的 SVC 模型。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="b0ad" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这将生成一个惟一的模型标记，允许您稍后获取相应的模型。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oi"><img src="../Images/18960d8b08f6cad244e1a3aebf8556b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0T5-O8AFt-FBHqGg.png"/></div></div></figure><p id="9a07" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">它还会创建一个以模型标记命名的文件夹。如果查看这个文件夹，我们会发现二进制文件和一个名为<code class="fe ki kj kk kl b">model.yaml</code>的 Yaml 文件，它描述了模型元数据。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oj"><img src="../Images/40d07de2eb113334dfafba15a007e208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6-feJYq-b9v7Uif1.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><h1 id="cac1" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak"> 3—创建推理服务，将模型公开为 API⚙️</strong></h1><p id="dd46" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">一旦模型被创建并保存在模型存储中，您就可以将它转换成您可以请求的 API 端点。要做到这一点，首先必须创建一个调用模型运行器的服务，然后用它来修饰一个函数。</p><p id="aadf" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在下面的例子中，当有效负载数据(NumpyNdarray 类型)通过 HTTP POST 请求发送到<code class="fe ki kj kk kl b">/classify</code>端点路径时，用<code class="fe ki kj kk kl b">api</code>方法修饰的<strong class="lf iu"> <em class="mc"> classify </em> </strong>函数运行代码。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="e4d9" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">然后，通过使用以下命令运行服务，您可以在本地为模型提供服务:</p><pre class="kn ko kp kq gt ok kl ol bn om on bi"><span id="ae22" class="oo mo it kl b be op oq l or os">bentoml serve service:svc --reload</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ot"><img src="../Images/3b10f7c2e3c27c665b4ab41d2e631c30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*53MFn6S8BQWm0bgq.png"/></div></div></figure><p id="58a0" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这将打开一个 HTTP 本地服务器，您可以使用 Python 请求它</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="1d94" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">或界面(直接访问<a class="ae lc" href="http://localhost:3000)" rel="noopener ugc nofollow" target="_blank"> http://localhost:3000) </a></p><div class="kn ko kp kq gt ab cb"><figure class="ou kr ov ow ox oy oz paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><img src="../Images/1553fc0868f2ab24fb799e56a57db122.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/0*JNeaoom0qsFMfsY-.png"/></div></figure><figure class="ou kr pa ow ox oy oz paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><img src="../Images/f4a5b0d07e1bdd6e4ad54099248aa860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*1JB-o304DEbuvoSw.png"/></div><p class="ky kz gj gh gi la lb bd b be z dk pb di pc pd translated">通过 Swagger UI 请求—作者提供的图片</p></figure></div><h1 id="80aa" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak">4—制作并定制您的便当🏗</strong></h1><p id="74b2" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">在这里你可以构建一个便当，看看里面有什么文件。这为您的所有项目提供了一个独立于底层工具的标准化结构。</p><p id="34e8" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要构建您的便当，您首先需要创建一个名为<code class="fe ki kj kk kl b">bentofile.yaml</code>的文件</p><p id="f638" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个文件配置如何构建便当:它包括元数据，列出有用的源代码，并定义包列表。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="b124" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要构建便当，在包含<code class="fe ki kj kk kl b">bentofile.yaml</code>的文件夹中运行下面的命令。</p><pre class="kn ko kp kq gt ok kl ol bn om on bi"><span id="5668" class="oo mo it kl b be op oq l or os">bentoml build</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pe"><img src="../Images/28138f12cc277884ad5c46fbc03ad0f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J8Gg3gP1zt1Axb_f.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><p id="eb80" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">现在，如果我们查看便当并检查里面有什么，我们将看到以下文件夹结构，其中包含以下内容:</p><ul class=""><li id="b261" class="nl nm it lf b lg lh lj lk lm nn lq no lu np ly nq nr ns nt bi translated">API 的描述和模式</li><li id="2b20" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">构建 Docker 映像所需的 Docker 文件</li><li id="2dee" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">Python 需求</li><li id="5f43" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">经过训练的模型及其元数据</li><li id="711d" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">负责训练模型和定义 API 路线的源代码</li><li id="3dbe" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">指定便当构建选项的配置(<code class="fe ki kj kk kl b"><strong class="lf iu">bentoml.yaml</strong></code>)</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pf"><img src="../Images/d368b7f3fd1acc5a7639c6996068b9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lc-rpFlF0nacFKMl.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><h1 id="30dd" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak"> 5—将便当装入 Docker 图像中🐳</strong></h1><p id="fd7d" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">一旦创建了便当，您可以使用<code class="fe ki kj kk kl b">dockerize</code>命令来构建一个健壮的 Docker 映像。这是 bentoml 提供的一个非常有用的特性。如果您使用的是 FastAPI，那么您必须手动完成这项工作。</p><p id="d887" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">BentoML 提供了这个简单的命令来为您构建图像。</p><pre class="kn ko kp kq gt ok kl ol bn om on bi"><span id="0a49" class="oo mo it kl b be op oq l or os"> bentoml containerize iris_classifier:latest</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pg"><img src="../Images/c690ff02d40fbab7949e99362a661844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AKbVrTukenA2rY3A.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">将便当容器化——作者的形象</p></figure><p id="c95e" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一旦构建了映像，您就可以在您的系统上检查它:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ph"><img src="../Images/25fa5ccbe4537dd1a479e5b860a4be4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3e-O2RpONDLVo9kN.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者图片</p></figure><p id="12cc" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这个 Docker 映像是自包含的，用于在本地提供便当或将其部署到云中。</p><pre class="kn ko kp kq gt ok kl ol bn om on bi"><span id="9825" class="oo mo it kl b be op oq l or os">docker run -it --rm -p 3000:3000 iris_classifier:jclapisz2s6qyhqa serve --production</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pg"><img src="../Images/efc894ff8bf6860a42a97d1a35963fa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3Lxm_IPjxzHz0p_H.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">从容器到主人端上便当——图片由作者提供</p></figure><h1 id="6b44" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak">6——使用跑步者独立于 web 请求扩展推理🚀</strong></h1><p id="7288" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">Runners 是特定于 ML 的计算单元，它允许推理过程独立于 web 服务器进行扩展。</p><p id="b8ba" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这意味着推理和 web 请求处理运行在两个独立的进程上。</p><p id="baa4" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这也意味着您的推理管道可以有任意数量的运行器，并且可以垂直伸缩(通过分配更多的 CPU)。每个运行器也可以有特定的配置(RAM、CPU 与 GPU 等。)</p><p id="fc70" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">例如，这种架构允许你拥有一个依赖于三个独立的运行者来处理不同事情的服务。</p><p id="0986" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在下面的例子中，两个运行器(一个执行 OCR 任务，另一个执行文本分类)在输入图像上顺序运行。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="f933" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你可以在这里了解更多关于跑步者的信息<a class="ae lc" href="https://docs.bentoml.org/en/latest/concepts/runner.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="a779" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak"> 7 —支持自适应批处理</strong></h1><p id="72b9" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">批处理是对一组 N 个输入运行预测而不是启动 N 个顺序预测的术语。<br/>这具有优势:它<strong class="lf iu">提高了性能</strong>和<strong class="lf iu">吞吐量</strong>和<strong class="lf iu">利用加速硬件</strong>(GPU 因加速矢量化运算而闻名)</p><p id="20d2" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">FastAPI、Flask 或 Django 等 Web 框架没有处理批处理的机制。</p><p id="15b7" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">另一方面，BentoML 为此提供了一个很好的解决方案。</p><p id="9d6a" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">事情是这样的:</p><ul class=""><li id="803c" class="nl nm it lf b lg lh lj lk lm nn lq no lu np ly nq nr ns nt bi translated">多个输入请求并行运行</li><li id="b86b" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">代理(即负载平衡器)在工作器之间分发请求(工作器是 API 服务器的运行实例)</li><li id="b027" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">每个工作人员将请求分发给负责推理的模型运行人员</li><li id="5253" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">每个运行器通过在延迟和吞吐量之间找到一个折衷，动态地将请求分批分组</li><li id="d4d3" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">跑步者对每一批进行预测</li><li id="152f" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">然后，批量预测被拆分并作为单独的响应发布</li></ul><p id="c824" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这一点的美妙之处在于，对于发送多个并行请求的客户机来说，这是完全透明的。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pi"><img src="../Images/8b925447a71b77fa9e73ee4cb90bf560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lPxib4_Z0hCfeDzp"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">图片由作者修改</p></figure><p id="2100" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要启用批处理，您需要将<code class="fe ki kj kk kl b">batchable</code>参数设置为 True。示例:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="a112" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">点击   <strong class="lf iu"> <em class="mc">了解更多配料<a class="ae lc" href="https://docs.bentoml.org/en/latest/guides/batching.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lf iu"> <em class="mc">。</em>T25】</strong></a></em></strong></p><h1 id="308f" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated">8 —平行推理</h1><p id="d269" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">跑步者有一种优雅的气质。您可以根据需要组合它们，以创建可定制的推理图。在前面的例子中，我们看了两个跑步者依次跑步。(OCR -&gt;文本分类)。</p><p id="7786" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">在这个例子中，我们展示了通过利用异步请求，运行者也可以并发运行。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="og oh l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pj"><img src="../Images/04a4dd7c198a5a9464eb0c2d00acb843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xq2kKz9QCmMilleQ98-QWA.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">平行推理——作者图片</p></figure><p id="2d88" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">想想有多少次你不得不将 ML 模型合并到一个预测管道中。使用 BentoML，您可以同时运行这些模型，并在最后收集结果。</p><h1 id="9f17" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated">9—部署到任何云基础架构</h1><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi of"><img src="../Images/e4b8d0713efbb0249407558966b88191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B9n1mPHhja4WP_72TPSzQQ.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">如何部署便当—作者图片</p></figure><p id="fae1" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">便当的好处在于，当它被构建时，你可以用两种方式部署它:</p><ol class=""><li id="d502" class="nl nm it lf b lg lh lj lk lm nn lq no lu np ly pk nr ns nt bi translated">通过将 Docker 映像推送到注册表并将其部署到云中</li><li id="8a01" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly pk nr ns nt bi translated">通过使用 BentoML 团队开发的实用程序库<a class="ae lc" href="https://github.com/bentoml/bentoctl" rel="noopener ugc nofollow" target="_blank">bento TL</a>来加速部署过程</li></ol><p id="b62f" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">强烈推荐使用 bentoctl。它有助于将任何构建好的便当作为生产就绪的 API 端点部署在云上。它支持许多云提供商(AWS、GCS、Azure、Heroku)以及同一云中的多个服务(AWS Lambda、EC2 等)。)</p><p id="8f7f" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">我最近用 spaCy 模型为 AWS Lambda 部署了一个(无服务器)API 端点。它非常管用，我只需要一个现成的便当。</p><p id="2480" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">你可以通过<a class="ae lc" href="https://github.com/bentoml/bentoctl/blob/main/docs/quickstart.md" rel="noopener ugc nofollow" target="_blank">文档</a>来让它工作，但是简单来说你需要做的就是下面这些:</p><ul class=""><li id="75fa" class="nl nm it lf b lg lh lj lk lm nn lq no lu np ly nq nr ns nt bi translated">安装 bentoml</li><li id="a4e8" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">安装 terraform(检查此<a class="ae lc" href="https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli" rel="noopener ugc nofollow" target="_blank">链接</a></li><li id="5b0a" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">设置 AWS CLI 并配置您的凭证(参见<a class="ae lc" href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html" rel="noopener ugc nofollow" target="_blank">安装指南</a>)</li><li id="5b2e" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">安装 bentoctl ( <code class="fe ki kj kk kl b">pip install bentoctl</code>)</li><li id="469a" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">做了你的便当</li><li id="c2a7" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">安装允许在 AWS Lambda 上部署的 aws-lambda 操作符(bentoctl 也支持其他操作符):<code class="fe ki kj kk kl b">bentoctl operator install aws-lambda</code></li><li id="8954" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">运行<code class="fe ki kj kk kl b">bentoctl init</code>生成部署文件。这一步交互地要求您配置 Lambda 函数的部署(设置区域、内存、超时等)</li><li id="84f1" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">通过运行<code class="fe ki kj kk kl b">bentoctl build</code> <br/>构建部署所需的映像这一步准备一个 Docker 映像并将其推送到部署注册中心。</li><li id="54d0" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated">通过运行以下命令部署到 Lambda🚀<code class="fe ki kj kk kl b">bentoctl apply -f deployment_config.yaml</code>。配置部署后，这一步依赖于 Terraform 来应用更改</li></ul><p id="fc47" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">部署完成后，会提示您一个 API URL，您可以请求它与您的模型进行交互。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pl"><img src="../Images/a078fc438a2a6ec97284f9def30fb1c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZYYKn0eqCiqjXCt2ElE4A.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者截图</p></figure><p id="7e33" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">要删除 Lambda 函数，只需运行<code class="fe ki kj kk kl b">bentoctl destroy -f deployment_config.yaml</code>即可。</p><h1 id="40b5" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated"><strong class="ak"> 10 —API 文档和交互 UI </strong></h1><p id="7294" class="pw-post-body-paragraph ld le it lf b lg nf ju li lj ng jx ll lm nh lo lp lq ni ls lt lu nj lw lx ly im bi translated">当您部署 BentoML 服务或在本地为其提供服务时，您可以访问一个<a class="ae lc" href="https://swagger.io/tools/swagger-ui/" rel="noopener ugc nofollow" target="_blank"> Swagger </a> UI，该 UI 允许您在没有任何实现逻辑的情况下可视化 API 资源并与之交互。</p><p id="93d0" class="pw-post-body-paragraph ld le it lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">这是由带有可视化文档的 OpenAPI 规范生成的，便于后端实现和客户端使用。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi pg"><img src="../Images/a3610ae3315ceeea6f35c13bf3e9fd38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JNeaoom0qsFMfsY-.png"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">大摇大摆的用户界面示例——作者的图片</p></figure><h1 id="2508" class="mn mo it bd mp mq nz ms mt mu oa mw mx jz ob ka mz kc oc kd nb kf od kg nd ne bi translated">资源:</h1><ul class=""><li id="47bb" class="nl nm it lf b lg nf lj ng lm pm lq pn lu po ly nq nr ns nt bi translated"><a class="ae lc" rel="noopener" target="_blank" href="/comprehensive-guide-to-deploying-any-ml-model-as-apis-with-python-and-aws-lambda-b441d257f1ec">https://towards data science . com/comprehensive-guide-to-deploying-any-ml-model-as-APIs-with-python-and-AWS-lambda-b441d 257 f1 EC</a></li><li id="af21" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" rel="noopener" target="_blank" href="/bentoml-create-an-ml-powered-prediction-service-in-minutes-23d135d6ca76">https://towards data science . com/bento ml-create-an-ml-powered-prediction-service-in-minutes-23d 135 D6 ca 76</a></li><li id="d4ec" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" href="https://neptune.ai/blog/ml-model-serving-best-tools" rel="noopener ugc nofollow" target="_blank">https://neptune.ai/blog/ml-model-serving-best-tools</a></li><li id="038b" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" href="https://www.reddit.com/r/mlops/comments/w4vl6r/hello_from_bentoml/" rel="noopener ugc nofollow" target="_blank">https://www . Reddit . com/r/mlops/comments/w4v l6 r/hello _ from _ bentoml</a></li><li id="14ca" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" href="https://docs.bentoml.org/en/latest/concepts/service.html#runners" rel="noopener ugc nofollow" target="_blank">https://docs . bentoml . org/en/latest/concepts/service . html # runners</a></li><li id="6909" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" href="https://github.com/bentoml/BentoML/tree/main/examples" rel="noopener ugc nofollow" target="_blank">https://github.com/bentoml/BentoML/tree/main/examples</a></li><li id="8385" class="nl nm it lf b lg nu lj nv lm nw lq nx lu ny ly nq nr ns nt bi translated"><a class="ae lc" href="https://modelserving.com/blog/breaking-up-with-flask-amp-fastapi-why-ml-model-serving-requires-a-specialized-framework" rel="noopener ugc nofollow" target="_blank">https://model serving . com/blog/breaking-with-flask-amp-fastapi-why-ml-model-serving-requires-a-specialized-framework</a></li></ul></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><h1 id="92d0" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">新到中？你可以每月订阅 5 美元，并解锁各种主题的无限文章(技术、设计、创业……)你可以通过点击我的推荐链接<a class="ae lc" href="https://ahmedbesbes.medium.com/membership" rel="noopener">来支持我</a></h1><div class="pp pq gp gr pr ps"><a href="https://ahmedbesbes.medium.com/membership" rel="noopener follow" target="_blank"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd iu gy z fp px fr fs py fu fw is bi translated">加入我的介绍链接媒体-艾哈迈德贝斯</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">阅读 Ahmed Besbes 的每一个故事(以及媒体上成千上万的其他作家)。您的会员费直接支持…</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">ahmedbesbes.medium.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg kw ps"/></div></div></a></div></div></div>    
</body>
</html>