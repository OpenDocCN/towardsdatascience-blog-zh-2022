<html>
<head>
<title>GANomaly Paper Review: Semi-Supervised Anomaly Detection via Adversarial Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GANomaly论文综述:通过对抗训练的半监督异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ganomaly-paper-review-semi-supervised-anomaly-detection-via-adversarial-training-a6f7a64a265f#2022-08-22">https://towardsdatascience.com/ganomaly-paper-review-semi-supervised-anomaly-detection-via-adversarial-training-a6f7a64a265f#2022-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5dcd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种结合自动编码器和生成式对抗网络的异常检测模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8836496925ac911a84150b1ac9052f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ejaB_8GxDSyvhj3b"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://unsplash.com/photos/DdVCpBoHlv0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@ineka" rel="noopener ugc nofollow" target="_blank"> Ine Carriquiry </a>拍摄</p></figure><p id="9308" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">本文是</em> <a class="ae kv" rel="noopener" target="_blank" href="/paper-review-reconstruction-by-inpainting-for-visual-anomaly-detection-70dcf3063c07"> <em class="ls">论文综述:视觉异常检测的修复重建</em> </a> <em class="ls">的续篇。在上一篇文章中，我回顾了一种新颖的方法，它通过将带有随机块的图像传递到U-net来提高异常检测性能。本教程有助于您理解如何使用自动编码器进行异常检测。我还对撰写专门研究视觉异常检测的论文的评论感兴趣，这是我在研究奖学金期间发现的。很少有帖子涉及异常检测和计算机视觉之间的交叉，因此，我想以某种方式填补这一空白。</em></p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="15a0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">异常检测是一个众所周知的问题，包括从正常样本中识别异常样本。这个问题很有挑战性，因为正常类的样本量大于异常类。在计算机视觉中，由于数据量小，图像种类有限，这就更难了。</p><p id="197f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在文献中，很少有模型是为这种类型的任务提出的。在自动编码器方面有相当多的工作，但是当数据集包含具有复杂模式的图像时，例如CIFAR10，它们被证明是过于简单的模型。为此，GANomaly被提议作为通用异常检测架构，其:</p><ul class=""><li id="7b69" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">利用<strong class="ky ir">对抗训练</strong>，典型的GANs，学习数据分布</li><li id="1621" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">使用<strong class="ky ir">编码器-解码器架构</strong>作为发生器网络</li></ul><p id="493e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将回顾介绍这种新颖的异常检测模型的文章。</p><h2 id="d930" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">概述</h2><ol class=""><li id="93bb" class="ma mb iq ky b kz nh lc ni lf nj lj nk ln nl lr nm mg mh mi bi translated"><strong class="ky ir">要求</strong></li><li id="7135" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr nm mg mh mi bi translated"><a class="ae kv" href="#cc2c" rel="noopener ugc nofollow"> <strong class="ky ir">加诺马利</strong> </a></li><li id="c6ba" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr nm mg mh mi bi translated"><a class="ae kv" href="#d936" rel="noopener ugc nofollow"> <strong class="ky ir">数据集</strong> </a></li><li id="8e39" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr nm mg mh mi bi translated"><a class="ae kv" href="#57b0" rel="noopener ugc nofollow"> <strong class="ky ir">结果</strong> </a></li></ol><h1 id="13f3" class="nn mp iq bd mq no np nq mt nr ns nt mw jw nu jx mz jz nv ka nc kc nw kd nf nx bi translated">1.要求</h1><p id="0dae" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">当你阅读一篇论文时，有些概念是理所当然的。为了不迷失在这篇评论中，我建议您快速浏览这一部分。</p><ul class=""><li id="7ec1" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><a class="ae kv" href="#7d49" rel="noopener ugc nofollow"> <strong class="ky ir">自动编码器</strong> </a></li><li id="b0c8" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><a class="ae kv" href="#b31f" rel="noopener ugc nofollow"><strong class="ky ir"/></a></li><li id="7248" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><a class="ae kv" href="#285d" rel="noopener ugc nofollow"> <strong class="ky ir">对抗性自动编码器</strong> </a></li></ul><h2 id="7d49" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">自动编码器</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/acccd61f5224cf788de0e7d9c82ff318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m6VXY8SR3Lon2BSrjLFf8A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">自动编码器的体系结构。作者插图。</p></figure><p id="c63e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自动编码器是一种以无监督方式训练的神经网络结构。目标是将输入的最相关特征提取到输入的编码表示中，称为潜在空间表示，然后将其解压缩以获得原始输入。自动编码器由两个神经网络组成:</p><ul class=""><li id="7652" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">编码器</strong>，将输入的信息压缩成低维的<strong class="ky ir">潜码</strong>。</li><li id="8d7d" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">解码器</strong>从解压缩的潜在代码开始重建原始输入。</li></ul><h2 id="b31f" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">生成对抗网络</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/863537acfb197ee3a5be799c7bef5378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FrjVFs2CtFI_TcOQynaUyQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">甘斯的建筑。作者插图。</p></figure><p id="a8fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成式对抗网络是强大的算法，由以生成真实图像而闻名的Ian Goodfellow首次引入。它们以无人监督的方式进行训练，由两种神经网络结构组成:</p><ul class=""><li id="c182" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">发生器</strong>接收随机输入并产生类似真实数据的样本。</li><li id="5488" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">鉴别器</strong>试图将生成器生成的假样本与数据集的真实样本区分开来。</li></ul><p id="256e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用来解释这些生成模型的常见类比是艺术伪造者和艺术研究者的例子。艺术伪造者(创造者)试图创作写实主义绘画，这些绘画类似于真实绘画的特征，而艺术调查员检查哪些绘画是真的，哪些绘画是假的。</p><p id="5762" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要思想是这<strong class="ky ir">两个神经网络互相竞争</strong>。在训练开始时，鉴别器比生成器工作得更好，生成器产生的数据明显是假的。随着历元数量的增加，发生器提高了其生成逼真图像的能力，可以欺骗鉴别器。主要目标是在生成器生成数据时达到<strong class="ky ir">平衡点</strong>，该数据与训练数据无法区分，在这种情况下，鉴别器将无法解决其任务。</p><h2 id="285d" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">对抗自动编码器</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/f32aabc950ddb4dd110a76274204ec62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yws78ZAR_-WWjqM7uxXmlQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对抗性自动编码器的体系结构。作者插图。</p></figure><p id="6d6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对抗性自动编码器(AAE)是一种概率性自动编码器，它利用了GANs的思想，<strong class="ky ir">对抗性训练</strong>，将特定的先验分布(例如高斯分布)强加到自动编码器的潜在代码分布上。</p><p id="3ff3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对抗性自动编码器中有不同的组件:</p><ul class=""><li id="089b" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">通过最小化重构误差来训练自动编码器</strong>,以从潜在代码z开始重构原始输入x。</li><li id="0632" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">发生器</strong>是自动编码器的编码器。</li><li id="d79b" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">鉴别器</strong>将利用先验产生的<strong class="ky ir">真样本</strong>与<strong class="ky ir">产生的样本</strong>(或假样本)区分开来，这些样本对应于自动编码器获得的隐藏代码。</li></ul><p id="97e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练对抗性自动编码器有两个主要阶段:</p><ul class=""><li id="e32f" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">重建阶段</strong>:自动编码器学习从潜在代码重建原始图像x</li><li id="9b11" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">正则化阶段:</strong>第一步是训练鉴别器对隐藏码z和使用先验z’生成的样本进行分类。之后，生成器(也是自动编码器的编码器)被更新以欺骗鉴别模型d。主要目标是使鉴别器认为<strong class="ky ir">隐藏代码来自真实的先验分布</strong>。</li></ul><h1 id="cc2c" class="nn mp iq bd mq no np nq mt nr ns nt mw jw nu jx mz jz nv ka nc kc nw kd nf nx bi translated">2.加诺马利</h1><p id="eb4f" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">GANomaly是一种异常检测模型，它采用对抗性训练来捕获数据分布。在某些方面，它与对抗性自动编码器非常相似，因为它将传统的自动编码器与GANs相结合，但在AAE方面也有差异，这将在下面的段落中探讨。</p><ul class=""><li id="b88f" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">如何应用于异常检测？</strong></li><li id="3e0d" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir"> GANomaly的主要部件</strong></li><li id="3f28" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">目标函数</strong></li><li id="c981" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">模型测试</strong></li></ul></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h2 id="c405" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">它是如何应用于异常检测的？</h2><p id="b3ec" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">异常检测有一个正式的问题定义:</p><ul class=""><li id="9a81" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated">训练数据集仅包含正常图像，而测试数据集包括正常和异常样本。</li><li id="2351" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">在训练期间，模型仅学习正态数据分布。</li><li id="3cf0" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">在训练阶段完成后，我们希望在测试样本上评估模型。假设在训练期间没有通过的异常样本应该比正常图像输出更高的异常分数。</li></ul><h2 id="6db1" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">GANomaly的主要组件</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/172c1770679fa6b658e2c44b3a9b8b10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kpZKFb8l-TIRC9SVB2ET_w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加诺马利的建筑[1]。</p></figure><p id="ae69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与对抗性自动编码器类似，GANomaly由不同的组件组成。该方法包括两个编码器、一个解码器和一个判别模型。</p><ul class=""><li id="0590" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir"> Autoencoder </strong>，其<strong class="ky ir"> </strong>也是模型的生成器，通过使用编码器和解码器网络学习重构原始输入。</li><li id="5df3" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated"><strong class="ky ir">鉴别器</strong>被训练来区分输入(真样本)和重建(假样本)。</li><li id="7d15" class="ma mb iq ky b kz mj lc mk lf ml lj mm ln mn lr mf mg mh mi bi translated">第二<strong class="ky ir">编码器</strong>包括重构为潜在代码z’。</li></ul><h2 id="b2d6" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">目标函数</h2><p id="10f8" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">在模型的训练期间，目标函数组合了三个不同的损失函数，这些损失函数中的每一个都是通过不同的子网络获得的:</p><ul class=""><li id="728e" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">对抗损失</strong>是原始图像x的特征表示和生成图像G(x)的特征表示之间的L2距离。在这个损失函数中，f(x)被定义为对于给定的输入x输出鉴别器D的中间层的函数。对抗性损失用于用生成的图像欺骗鉴别模型D。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/383289719b059b5521718fc72b6c6233.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*G-JGWle8RAI7V-OoHx75gA.png"/></div></figure><ul class=""><li id="90f0" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">上下文损失</strong>是原始输入x和生成图像G(x)之间的L1距离。这种损失对于添加关于输入的上下文信息很重要。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/ca14eb3a03eb939a9291169ddee85cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*kzx3FjiXHQyNb1XfMvA6ww.png"/></div></figure><ul class=""><li id="296e" class="ma mb iq ky b kz la lc ld lf mc lj md ln me lr mf mg mh mi bi translated"><strong class="ky ir">编码器损耗</strong>是输入的瓶颈特征z和生成图像的编码特征z’之间的L2距离。以这种方式，生成器学习如何对正常样本的生成图像的特征进行编码。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ae07281de3c740c383998cb29f927079.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*-wSUSC8mEBnB70_mUHwaLg.png"/></div></figure><p id="8161" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，目标函数考虑了这三种类型的损失:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/a4a16dd72a8d19eca00fb764bc91adeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdFJmyAKXrUho2hauIJxWg.png"/></div></div></figure><p id="4e41" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中w_{adv}、w_{con}和w_{enc}分别是对抗损失、上下文损失和编码器损失的权重参数。</p><h2 id="04fd" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">模型检验</h2><p id="86ef" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">在评估期间，模型使用<strong class="ky ir">编码器损耗</strong>来输出每个测试图像的异常分数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/955e4bd517c0054693412b92eb9a002d.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*x2-GnytPAWKIVfMCRO4A4g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">每个测试图像的异常分数[1]。</p></figure><p id="0a63" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算异常分数之后，它们被归一化到0和1之间的范围内:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e21aebf45fc5bde961a7008131212d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*0DPIeBXimmbb7p7tQhxRUA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">异常分数的最小-最大归一化[1]。</p></figure><h1 id="d936" class="nn mp iq bd mq no np nq mt nr ns nt mw jw nu jx mz jz nv ka nc kc nw kd nf nx bi translated">3.数据集</h1><p id="7e6b" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">有四个数据集被认为是评估异常检测框架的基准。前两个数据集是众所周知的玩具数据集<a class="ae kv" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"/></a>和<a class="ae kv" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> CIFAR10 </strong> </a>，其中一个类被视为异常，其余被视为正常。剩下的数据集是<strong class="ky ir">大学行李异常数据集</strong> (UBA)和<strong class="ky ir">全枪对操作良性</strong> (FFOB)。</p><p id="7b7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> UBA </strong>是一个行李x光数据集，包含230，275个图像补片。目标是自动检测来自安全X射线扫描的威胁。在样本中，有三个异常类，刀、枪和枪组件，如下例所示。</p><p id="3597" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> FFOB </strong>是英国政府的数据集，提供了4，680件火器全武器为异常类，67，672件操作良性为正常类。</p><p id="a6f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了尊重问题的正式表述，所有这些数据集的正常样本被分成80%用于训练，20%用于测试。只有在评估期间，模型才会看到异常样本。</p><h1 id="57b0" class="nn mp iq bd mq no np nq mt nr ns nt mw jw nu jx mz jz nv ka nc kc nw kd nf nx bi translated">4.结果</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/23f1169b169a009951e6e72cbe77505c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z88KPAQ4nGmzlScuijsgOA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:MNIST(a)和CIFAR10 (b)数据集的AUC结果。他们还使用3种不同的随机种子来考虑变异[1]。</p></figure><p id="1c4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图1比较了MNIST和CIFAR10数据集的AUC结果。在这两种情况下，GANomaly的AUC都高于EGBAD、AnoGAN和VAE。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/5de569d8bc6588948e2583b625c24d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*CXJAdZuvTX6GKiQd1EBNLw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表1:UBA和FFOB数据集的AUC结果[1]。</p></figure><p id="2857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从表1中，值得注意的是，在UBA数据集上，除了刀之外，GANomaly在所有异常类上都表现得更好。此外，异常检测方法优于其他模型，在UBA和FFOB数据集上分别达到0.643和0.882</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/91299025f3a1189c708f178babb43e00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3VHElftFtfEWy_wOuot5hQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:MNIST数据集上的结果，其中2是异常类。(a)通过改变潜在向量z的大小来分析模型性能；(b)加权损失对整体模型性能的影响[1]。</p></figure><p id="083c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图2显示了超参数的变化，如潜在向量的大小和损失的权重，如何影响MNIST数据集上GANomaly的性能。z等于100时获得最高AUC，而在右侧，w_{bce}=1、w_{rec}=50和w_{enc}=1时获得最佳性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/6a4ea9e30194e0cff4f820037436f58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sgss2PqX2pc5xSEh2xBwFg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3: (a)正常和异常测试实例的<strong class="bd op">异常分数</strong>直方图。(b)使用<strong class="bd op">t-SNE</strong>【1】从鉴别器的最后一个卷积层提取的特征的3d可视化。</p></figure><p id="cd72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图3突出显示了正常样品和异常样品之间的明显区别。</p><h1 id="462a" class="nn mp iq bd mq no np nq mt nr ns nt mw jw nu jx mz jz nv ka nc kc nw kd nf nx bi translated">外卖食品</h1><p id="d080" class="pw-post-body-paragraph kw kx iq ky b kz nh jr lb lc ni ju le lf ny lh li lj nz ll lm ln oa lp lq lr ij bi translated">我希望你喜欢这篇关于GANomaly的评论。图像中的异常检测具有挑战性，简单的技术不足以识别异常。此外，缺乏专门用于异常检测的图像数据集，当数据集中没有足够的信息时，无监督方法最适合。</p><p id="cc79" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">几个月前，我发现了一个适合异常检测的图像数据集，称为<strong class="ky ir"> MVTec AD数据集</strong>。这是一个新颖而全面的工业数据集，由15个类别的5354幅高分辨率图像组成。训练集仅由正常图像组成，而测试集包含缺陷和无缺陷图像。我试图用这个数据集实现GANomaly。这里的GitHub代码是<a class="ae kv" href="https://github.com/eugeniaring/ganomaly-MVTec-AD" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><p id="cdf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想探索异常检测的其他技术，建议你去看看其他解释<a class="ae kv" href="https://arxiv.org/abs/1901.08954" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> Skip-GANomaly </strong> </a>和<a class="ae kv" href="https://arxiv.org/abs/1703.05921" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> AnoGAN </strong> </a>的论文。如果你有其他关于阅读的建议，请告诉我，分享知识是提高的最好方法。感谢阅读。祝您愉快！</p><p id="3302" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考文献:</strong></p><p id="a8d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] <a class="ae kv" href="https://arxiv.org/abs/1805.06725" rel="noopener ugc nofollow" target="_blank">加诺玛利:通过对抗训练进行半监督异常检测</a>，S. Akcay，A. Atapour-Abarghouei和T. P. Breckon，(2018)</p><p id="bab0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="https://arxiv.org/abs/1511.05644" rel="noopener ugc nofollow" target="_blank">对抗性自动编码器</a>，a .马克扎尼，j .施伦斯&amp; N .贾伊特利，I .古德费勒，b .弗雷，(2016)</p><h2 id="c2a0" class="mo mp iq bd mq mr ms dn mt mu mv dp mw lf mx my mz lj na nb nc ln nd ne nf ng bi translated">Github知识库</h2><div class="oq or gp gr os ot"><a href="https://github.com/samet-akcay/ganomaly" rel="noopener  ugc nofollow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd ir gy z fp oy fr fs oz fu fw ip bi translated">GitHub-samet-akcay/gano maly:gano maly:通过对抗训练的半监督异常检测</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">此回购不再维护。GANomaly实现已经被添加到anomalib中，它是…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">github.com</p></div></div></div></a></div></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><p id="3fe5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你喜欢我的文章吗？<a class="ae kv" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="ls">成为会员</em> </a> <em class="ls">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae kv" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="ls">订阅</em> </a> <em class="ls">每当我发布新的数据科学和python指南时，您都会收到电子邮件！</em></p></div></div>    
</body>
</html>