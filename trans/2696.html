<html>
<head>
<title>A new computational fabric for Graph Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种新的图形神经网络计算结构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-computational-fabric-for-graph-neural-networks-280ea7e3ed1a#2022-06-10">https://towardsdatascience.com/a-new-computational-fabric-for-graph-neural-networks-280ea7e3ed1a#2022-06-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d12b" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">拓扑空间上的学习</h2><div class=""/><div class=""><h2 id="1a05" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><strong class="ak">图形神经网络(gnn)通常将它们的计算图与输入图的结构对齐。但是图是GNNs的合适的计算结构吗？最近的一系列论文通过用来自代数拓扑领域的更一般的对象代替图来挑战这一假设，这提供了多种理论和计算优势。</strong></h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/6a60e39436b1c4b3cf67710d972e96ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YzCX9DhZ8SeD30Bf5heMMg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">图片:基于维基百科。</em></p></figure><p id="5fca" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><em class="mb">本文由克里斯蒂安·博德纳尔和法布里齐奥·弗拉斯卡合著，基于c·博德纳尔、f·弗拉斯卡等人的论文</em> <a class="ae mc" href="http://proceedings.mlr.press/v139/bodnar21a/bodnar21a.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Weisfeiler和Lehman Go topology:Message Passing simplical Networks</em></a><em class="mb">(2021)ICML和c·博德纳尔、f·弗拉斯卡等人的论文</em> <a class="ae mc" href="https://arxiv.org/pdf/2106.12575.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Weisfeiler和Lehman Go Cellular:CW Networks</em></a><em class="mb">(2021)neur IPS。它是从微分几何和代数拓扑</em>  <em class="mb">的角度看</em> <a class="ae mc" rel="noopener" target="_blank" href="/graph-neural-networks-through-the-lens-of-differential-geometry-and-algebraic-topology-3a7c3c22d5f?source=your_stories_page----------------------------------------"> <em class="mb">图神经网络系列的一部分。另请参见讨论</em> </a><a class="ae mc" rel="noopener" target="_blank" href="/graph-neural-networks-as-neural-diffusion-pdes-8571b8c0c774?sk=cf541fa43f94587bfa81454a98533e00"> <em class="mb">神经扩散偏微分方程</em> </a>、<a class="ae mc" rel="noopener" target="_blank" href="/over-squashing-bottlenecks-and-graph-ricci-curvature-c238b7169e16?sk=f5cf01cbd57b4fee8fb3a89d447e56a9"> <em class="mb">图重布线与瑞奇流</em> </a>、<em class="mb">和</em> <a class="ae mc" rel="noopener" target="_blank" href="/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6?sk=0b2f814a1180a64460699f6a3277053a"> <em class="mb">细胞束</em> </a> <em class="mb">系列的其他帖子。</em></p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><blockquote class="mk"><p id="09aa" class="ml mm iq bd mn mo mp mq mr ms mt ma dk translated">“拓扑！人类思想的顶峰！在24世纪，它可能对某人有用。”——亚历山大·索尔仁尼琴，在第一圈<em class="le"> (1968) </em></p></blockquote><p id="24ff" class="pw-post-body-paragraph lf lg iq lh b li mu ka lk ll mv kd ln lo mw lq lr ls mx lu lv lw my ly lz ma ij bi mz translated">raphs被用来模拟从计算机网络到大型强子对撞机中的粒子相互作用的任何事物。使图形如此普遍的是它们的离散和组合性质，允许它们表达抽象的关系，同时仍然服从于计算。它们受欢迎的原因之一是图形抽象出了几何图形，即节点在空间中的位置或边是如何弯曲的，只留下节点如何连接的表示。图论的起源源于1741年莱昂哈德·欧拉在他关于<em class="mb">几何位置</em>(“位置几何”)【1】的工作中所做的观察，在该工作中，他表明了著名的柯尼斯堡<a class="ae mc" href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg" rel="noopener ugc nofollow" target="_blank">七桥</a>问题无解。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ni"><img src="../Images/1c0ec006c9ba76135b6349b6bd6c196f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oLl1C_6L047C499K"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">七座桥问题要求寻找一条穿过柯尼斯堡城的自行车道，且不要穿过任何一座桥超过一次。正如欧拉所说，柯尼斯堡的确切形状并不重要。重要的是不同的陆地(图的节点)如何相互连接(边)。欧拉证明了当且仅当所有节点的度数都是偶数时，这种循环才存在。只有五座最初的桥保存到了现代。图片:维基百科。</em></p></figure><p id="4cd2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">有趣的是，欧拉的发现不仅标志着图论的开始，而且通常被视为拓扑学的诞生。和图一样，拓扑学家感兴趣的是独立于特定形状或几何的空间属性。这些观点的现代表现出现在1895年亨利·庞加莱的开创性论文“分析情境”<em class="mb">。他的工作激发了人们对流形的组合描述的兴趣，从这种描述中可以更容易地找到和计算拓扑不变量。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/dbeedd1419b7f720e4e00f7fff0a1490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QPUUXtNIYqVkO0cWIBoo4g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">莱昂哈德·欧拉(1707-1783，左)和亨利·庞加莱(1854-1912，右)。肖像:伊霍尔·高斯基。</em></p></figure><p id="b9ab" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">这些组合描述今天被称为<em class="mb">细胞复合体</em>【8】，可以被认为是图形的更高维度概括。与由节点和边组成的图不同，细胞复合体还可以包含更高维的结构或“细胞”:顶点是0-细胞，边是1-细胞，2D表面是2-细胞，等等。为了构建细胞复合体，可以通过将一个细胞的边界粘合到其他低维细胞上来进行分层。在特定情况下，当单元由单形(例如边、三角形、四面体等)形成时，这些空间也被称为<em class="mb">单形复形</em>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/d78e2db3e59b40fa3db300ad757e33c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vJ3OyrJlZGyyhhlI"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">图可以被看作是一组顶点，我们在这些顶点上附加边(单胞)。类似地，单纯复形和细胞复形可以被看作是我们附加2-细胞(显示为蓝色)、3-细胞(绿色)等等的图。</p></figure><h1 id="ee2f" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated"><strong class="ak">机器学习和数据科学中的拓扑</strong></h1><p id="9745" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated">我们选择引用索尔仁尼琴的话来开始这篇文章[9]，与他的怀疑性格相反，人们不必等待四百年才能将拓扑学变成一种实用的工具。在<a class="ae mc" href="https://en.wikipedia.org/wiki/Topological_data_analysis" rel="noopener ugc nofollow" target="_blank">拓扑数据分析</a> (TDA)的保护下，单纯复形等拓扑结构已被用于机器学习和数据科学，这是一类出现于20世纪90年代的方法，试图以一种对度量不敏感且对噪声鲁棒的方式来分析“数据的形状”[4–7]。TDA的起源可以追溯到20世纪20年代末，20世纪最多产的拓扑学家之一Leopold Vietoris [43]的工作。然而，这些技术必须等到现代计算的诞生才能大规模应用。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/af04e3943204d5b57561cb6e451bac8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p-L3Yd0mgGq5jVFg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">给定一个点云，围绕每个点的固定半径的闭球之间的交点产生一个单纯复形。通过逐渐增加球的半径，我们得到了一个嵌套的单纯复形序列。图片:巴斯蒂安·里克。</p></figure><p id="bbd5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">TDA的主力是<a class="ae mc" href="https://en.wikipedia.org/wiki/Persistent_homology" rel="noopener ugc nofollow" target="_blank">持久同调</a>(PH)【7】，一种从点云中提取拓扑特征的方法。给定一个点的数据集，PH创建一个嵌套的单纯复形序列，其中每个复形对应于一个特定的尺度，在该尺度下分析潜在的点云。然后，它会跟踪各种拓扑特征(例如，连接的组件、循环或空隙)，这些拓扑特征会随着比例的逐渐增加以及从序列中的一个复合体到下一个复合体的过渡而出现和消失。在深度学习时代，持续同源有了“第二次生命”，因为人们可以通过它反向传播，从而将已经建立的TDA装置整合到深度学习框架中[10–17]。</p><p id="1032" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi mz translated"><span class="l na nb nc bm nd ne nf ng nh di">最近的一系列工作提出了几何深度学习中单纯和细胞复合体的不同用途，作为更丰富的底层拓扑空间来支持数据和在其上执行的计算。利用这一观点的最初几部作品[18–22]提出了卷积模型以及在单纯复形上操作的随机行走方法[42]。如我们的论文[24，25]所示，卷积模型可以理解为在单纯和细胞复合体上传递消息的具体实例[23–25]。因为计算是由这些空间的拓扑结构(即邻域结构)驱动的，我们将这组方法称为<em class="mb">拓扑消息传递。</em>在此框架中，相邻单元(可能具有不同维度)正在交换消息，如下所示。</span></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oj"><img src="../Images/a501ef47ba7069b92863c5c2975eff3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*crWtSYQvjUyv7lBzks7aAg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">拓扑消息传递示意图。蓝色箭头表示上相邻单元之间的“水平”信息传播，即同一高维单元边界中的单元。红色箭头表示“垂直”信息传播，细胞从其边界内的低维细胞接收信息。将来自边界单元的信息汇总到一个粗略的表示中，这种计算可以被解释为一种形式的(可区分的)池。</em></p></figure><p id="45e5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">超越GNNs中的图形</strong></p><p id="2c82" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">尽管细胞复合体提供了丰富的结构，但我们不能忽视的是，图是迄今为止机器学习中最常见的拓扑对象，很少有数据集超越它们。尽管如此，我们表明人们仍然可以通过变换输入图来利用这些有趣的拓扑空间。我们将图到更高维度拓扑空间的转换称为“提升”，类似于范畴理论中的同名概念。它是一种通过遵循特定规则将高维单元附加到输入图的转换。例如，通过将一个更高维的单元附加到图的每个团或圈，可以将图提升为单元复合体。通过这样做，该图被替换为具有更多结构的不同空间，并且可以为GNNs提供比原始图更好的计算结构。在下文中，我们将讨论这种方法的具体优势。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/4391babdd609bbe94677cf7158299907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RhqVeEP2DpGCu_hNRKFMng.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">通过(例如)将2D封闭圆盘的边界粘合到图中的诱导循环，可以从图中构建更高维的细胞复合体。</em></p></figure><p id="ad9c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">高阶特征和结构。gnn通常采用以节点为中心的观点，其中驻留在边上的数据仅被视为增强顶点之间通信的辅助信息。在拓扑信息传递中，<em class="mb">所有的</em>细胞都是一等公民。不管它们的维度如何，它们都被分配了一个特定的表示法，这个表示法是通过与相邻的细胞交换信息而演化出来的。这为明确地模拟某些高阶结构和它们之间的相互作用提供了一个方法。特别是，它提供了一种原则性的方法来演化输入图的边缘(即1个单元)特征，这是一大类GNN模型没有考虑的。</strong></p><p id="ec05" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">高阶相互作用。</strong>根据定义<em class="mb">图是二元的</em>(成对的)，不能表示涉及两个以上对象的关系和交互【26】。当对以高阶相互作用为特征的复杂系统建模时，这可能是一个问题:例如，一个化学反应中的三种反应物可能同时相互作用。在细胞复合体中，这种情况可以通过由2-细胞(即“填充”三角形)连接反应物来编码。因此，模型的计算流程适应高阶相互作用的存在。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/c25af354c7381d35ed1e5ef27931823a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fU0SriZwCMkz89pR"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le">细胞Weisfeiler-Lehman (CWL)试验[24，25]将经典的WL试验[27]扩展至细胞复合体。该算法的每一步都完美地散列了相邻单元的颜色(可能具有不同的维度)。</em></p></figure><p id="ecad" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">表现力。</strong>消息传递GNNs的表达能力受到魏斯费勒-莱曼(WL)图同构测试的限制【27–29】。众所周知，WL不能检测某些图的子结构，如三角形或圈，甚至不能区分非常简单的非同构图。在我们的论文[24，25]中，我们介绍了WL检验(CWL)的细胞版本，可用于检验细胞复合体的同构。当这种新测试与如上所述的图提升过程配对时，我们表明它可以区分比WL测试更大的图类。在某些条件下，我们提出的拓扑消息传递程序继承了这种测试的优点，与标准GNNs [24，25，30]相比，提高了表达能力。</p><p id="e389" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">不足、过度和瓶颈。</strong>消息传递GNNs需要<em class="mb"> n </em>层使<em class="mb"> n- </em>跳远的节点进行通信。因此，当只使用几层时，相距很远的节点不能交换消息，这种现象被称为<em class="mb">欠到达</em> [31，32]。相比之下，使用过多的层可能会导致<em class="mb">过度平滑</em>【33，34】并且消息可能会在图的结构性<em class="mb">瓶颈</em>【32】中丢失。细胞复合体可以缓解这些问题，因为由高维细胞诱导的更丰富的邻近结构在可能相距很远的节点之间创建了捷径。因此，信息以有限的计算步骤有效地传播。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/a28724628f53c01e29719efd88a025ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6hc0nHRF5jqBNHO_"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated"><em class="le"> GNNs需要很多层才能让距离较远的节点进行通信(左图)。更高维度的细胞通过创建捷径来改变空间的底层拓扑结构(右图)。这使得距离较远的节点只需几个消息传递步骤就可以交换信息。</em></p></figure><p id="46de" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">层次造型。</strong>拓扑消息传递执行的计算自然是分层的，信息从低维单元流向高维单元，然后返回。这可以被视为一种“垂直”(和可区分的)池形式，与标准图形神经网络中的“水平”池相反。这保持了“压缩”图区域的归纳偏差，而没有忽略输入图的细粒度信息，这通常会损害基于池的GNNs的性能。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oi"><img src="../Images/fc380099ecdefa2954de9b91422b4754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mOVbbopgjSTqEyRW"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">拓扑消息传递允许信息在不同维度的单元之间分层传递。</p></figure><p id="18e0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">结构域比对。</strong>某些应用自然与细胞复合体的结构一致。例如，分子的原子、键和化学环可以表示为0-细胞、1-细胞和2-细胞。分子的物理结构和细胞复合体表示之间的直接对应自然地允许拓扑消息传递利用前述特性。使用这些表示，我们表明拓扑消息传递在分子性质预测任务中实现了最先进的结果[25]。其他排列良好的应用程序可以包括计算机图形应用程序中的离散流形(网格)、社交网络(其中派系尤为重要)或空间图形，如谷歌地图(其中街道之间的街区可以自然地表示为“立方体”单元)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/e0917dc1b32142f56cd68767b1ecfb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*j3jni21kNgfnBEmj"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">咖啡因分子被模拟成二维细胞复合体。</p></figure><h1 id="a692" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated"><strong class="ak">拓扑和微分几何相遇的地方</strong></h1><p id="68ad" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated">拓扑消息传递保留了许多与代数拓扑和微分几何的有趣联系，允许利用迄今为止在图形和几何深度学习中尚未开发的数学工具。</p><p id="e36a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">洞代数与方向等方差。</strong>在代数拓扑中，人们通常使用面向<em class="mb">的</em>单形复形，其中每个单形都有一个任意的“方向”。例如，对于每条边，我们选择一个源节点和一个目标节点，对于每个三角形，我们选择一个顺序来遍历它的节点。一旦选择了一个方向，我们就可以在复形上进行有趣的代数运算，例如通过“边界算子”计算某些单形的边界。这些代数操作也可以用来寻找单纯复形中的“洞”——没有边界的区域，它们不在其他东西的边界上。在引擎盖下，持续同源依赖于这些计算来检测拓扑特征。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/0d9cb1a953745592361b6cf1fed62d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jHgHupJJ333C8qxy"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">应用于2-单纯形的边界算子产生一个三角形。再次将运算符应用于三角形，会得到零，因为三角形是一个循环，因此它没有边界。</p></figure><p id="99e4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">拓扑消息传递可以被视为代数运算符(如边界运算符)的(非线性)推广。因此，拓扑消息传递必须有类似的行为:我们希望各层的输出“一致地”响应输入复合体方向的变化。换句话说，我们希望我们的层是<em class="mb">方向等变的</em>。在我们的工作[24]中，我们研究了拓扑消息传递如何通过选择正确的非线性和消息传递函数来满足这一特性。同时，这也在纯卷积环境中进行了检验[20]。</p><p id="e6d8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">区分拓扑空间。</strong>第一批已知的拓扑不变量之一，欧拉特征[8，41]，最初用于柏拉图立体的分类。我们可以把它定义为每个维度上细胞数量的交替总和。令人惊讶的是，如果两个细胞复合体是同胚的，这些和将是相同的，即使它们是同一空间的非常不同的离散。</p><p id="1f45" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">一个有趣的事实是，拓扑消息传递模型的读出操作可以很容易地计算这个拓扑不变量，因为它在每个维度的单元上应用了置换不变量归约。因此，这种类型的模型通过构造来区分某些<em class="mb">非</em>同胚的空间(即具有不同的欧拉特征)。从计算的角度来看，这可以被视为WL测试的一般化，其中我们不只是对确定两个细胞复合体是否严格相同感兴趣，而是对它们是否彼此同胚感兴趣。</p><p id="2997" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated"><strong class="lh ja">离散Hodge理论</strong>为细胞复合体的拓扑性质提供了更具几何意义的解释。当与<em class="mb"> k </em>细胞相关的特征符号取决于k细胞的方向时，这些特征在数学上可以被视为微分几何中微分k形式的离散版本(即可以被积分的k维体积元素)[45]。对图拉普拉斯进行一般化的拉普拉斯算子，称为<a class="ae mc" href="https://en.wikipedia.org/wiki/Laplace_operators_in_differential_geometry#Hodge_Laplacian" rel="noopener ugc nofollow" target="_blank"> <em class="mb">霍奇拉普拉斯</em></a>【21，44】，可以作用于这些微分形式。可以看出，基于该拉普拉斯算子的扩散PDE在极限下收敛于与复合体的空穴相关的信号[44]。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/1cef5690369d8e18d551860d182b296a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DjppDfJnDx4hdxablg_cSg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">基于Hodge Laplacian的扩散PDE收敛于初始微分形式到Laplacian的核上的投影的极限。这张图片显示了霍奇拉普拉斯的零特征向量如何在复杂的洞周围取高值。图片:安德烈·波佩斯库。</p></figure><p id="fe60" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">第一个单纯神经网络模型[18–20]实际上是基于Hodge Laplacian的卷积模型，它反过来受到拓扑信号处理的启发[21，22]。最近，基于该算子版本的卷积模型被用于解决计算代数拓扑中的NP-hard问题[35]。</p><h1 id="75d7" class="nl nm iq bd nn no np nq nr ns nt nu nv kf nw kg nx ki ny kj nz kl oa km ob oc bi translated"><strong class="ak">最终想法</strong></h1><p id="4e5a" class="pw-post-body-paragraph lf lg iq lh b li od ka lk ll oe kd ln lo of lq lr ls og lu lv lw oh ly lz ma ij bi translated"><strong class="lh ja">这些只是伪装的图形吗？</strong>最近的论文【36，37】认为，其中，拓扑消息传递方法只不过是对编码细胞复合体结构的修改图进行操作的消息传递GNN。这对于卷积模型来说当然是正确的，其消息传递计算涉及成对的信元。然而，在其最一般的形式中，消息函数允许较高维度的细胞在它们的边界上调制在较低维度的细胞之间传递的消息。这(通常)不再可能通过图中的常规消息传递来实现，因为一条边恰好连接两个节点，而2-cell可以连接任意多条边。</p><p id="1754" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">在这两种情况下，计算都是由数据附加到的底层空间的拓扑驱动的。我们认为，在消息传递中采用这种拓扑观点的好处远远超出了纯粹的计算考虑。除了有价值的数学联系之外，它还为其他数学和计算学科开启了研究话语，并有利于我们往往过于单一的社区之间的积极交叉授粉。</p><p id="ec5a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">拓扑消息传递的下一步是什么？我们预测拓扑消息传递方法的两个主要未来方向。首先，GNNs多年来开发的许多架构(如注意机制[38，39])将很可能在这些新的拓扑空间中采用，同时利用它们的具体特征。第二，来自代数拓扑领域的其他数学对象和工具(包括像细胞束[40]这样的结构，即使对最精通数学的ML研究人员来说也可能听起来很奇怪)将被图形和几何深度学习社区采用。这种方法既能为老问题提供答案，也能帮助解决新问题，或者，正如<a class="ae mc" href="https://www.maa.org/meetings/calendar-events/putting-topology-to-work" rel="noopener ugc nofollow" target="_blank">罗伯特·格里斯特所说的</a>:“新的挑战需要新的数学”。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="308e" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[1] L .欧拉，solution problematis ad geometriam situs pertinentis(1741)，ene strm 53，<a class="ae mc" href="https://scholarlycommons.pacific.edu/euler-works/53/" rel="noopener ugc nofollow" target="_blank">欧拉档案</a>。</p><p id="7901" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[2]粗略地说，拓扑学使用邻域的概念，而不是距离或角度的概念，它们是几何构造。</p><p id="a687" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[3] H .庞加莱，分析现状(1895年)，《综合技术学院学报》。</p><p id="6b1a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[4] P. Frosini，欧几里得空间的子流形的相似类的距离(1990)，澳大利亚数学学会通报42(3):407–415。</p><p id="4cd4" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[5] H. Edelsbrunner等人，拓扑持续性和简化(2002)，离散和计算几何28(4):511–533。</p><p id="4a33" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[6] G. Carlsson,《拓扑与数据》( 2009年),《美国数学学会公报》46:255–308。</p><p id="c00d" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[7] H. Edelsbrunner和J. Harer。计算拓扑:导论(2010)，美国数学学会。</p><p id="3bc1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[8] A. Hatcher，代数拓扑(2002)，剑桥大学出版社。</p><p id="e5f3" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[9]原文为俄文:“топология！Стратосфера человеческой мысли!В двадцать четвёртом столетии она, может быть, и понадобится кому-нибудь."在小说中，这一判断是由半自传体人物格莱布·涅尔津(Gleb Nerzhin)宣布的，他是一位数学家，正在努力解决浮士德式的问题，即是否要从事有助于斯大林政权的应用研究。作者亚历山大·索尔仁尼琴本身就是一名训练有素的数学家，参见罗伯特·格里斯特讲座的注释，我们从其中剽窃了这段引文。</p><p id="8813" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[10] M. Horn，E. De Brouwer等人<a class="ae mc" href="https://arxiv.org/abs/2102.07835" rel="noopener ugc nofollow" target="_blank">拓扑图神经网络</a> (2022)，ICLR。</p><p id="d44f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[11] R. Gabrielsson等人，<a class="ae mc" href="https://arxiv.org/abs/1905.12200" rel="noopener ugc nofollow" target="_blank">一个用于机器学习的拓扑层</a> (2020)，AISTATS。</p><p id="62b1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[12] M. Moor等人，<a class="ae mc" href="https://arxiv.org/abs/1906.00722" rel="noopener ugc nofollow" target="_blank">拓扑自动编码器</a> (2020)，ICML。</p><p id="3578" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[13] C. Hofer等人，<a class="ae mc" href="https://arxiv.org/abs/1707.04041" rel="noopener ugc nofollow" target="_blank">具有拓扑签名的深度学习</a> (2017)，NIPS。</p><p id="8e2f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[14] C. Hofer等人，<a class="ae mc" href="https://proceedings.mlr.press/v97/hofer19a.html" rel="noopener ugc nofollow" target="_blank">通过持续同源进行连通性优化的表征学习</a> (2019)，ICML。</p><p id="d836" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[15] C. Hofer等人，<a class="ae mc" href="https://jmlr.org/papers/v20/18-358.html" rel="noopener ugc nofollow" target="_blank">持久性条形码的学习表征</a> (2019)，JMLR 20(126):145，2019。</p><p id="b2ba" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[16] C. Hofer等人，<a class="ae mc" href="https://arxiv.org/abs/1905.10996" rel="noopener ugc nofollow" target="_blank">图过滤学习</a> (2020)，ICML</p><p id="c630" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[17] C. Hofer等人，<a class="ae mc" href="https://arxiv.org/abs/2002.04805" rel="noopener ugc nofollow" target="_blank">拓扑增密分布</a> (2020)，ICML</p><p id="3b90" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[18] E. Bunch等人<a class="ae mc" href="https://arxiv.org/abs/2012.06010" rel="noopener ugc nofollow" target="_blank"> Simplicial 2-complex卷积神经网络</a> (2020)，NeurIPS拓扑数据分析及其他研讨会。</p><p id="b424" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[19] S. Ebli等人<a class="ae mc" href="https://arxiv.org/abs/2010.03633" rel="noopener ugc nofollow" target="_blank">单纯神经网络</a> (2020)，NeurIPS拓扑数据分析研讨会及其他。</p><p id="86c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[20] M. T. Roddenberry，N. Glaze和S. Segarra，<a class="ae mc" href="http://proceedings.mlr.press/v139/roddenberry21a/roddenberry21a.pdf" rel="noopener ugc nofollow" target="_blank">用于轨迹预测的原则性单纯神经网络</a> (2021)，ICML。</p><p id="14c2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[21] S .巴巴罗萨等人<a class="ae mc" href="https://arxiv.org/abs/1907.11577" rel="noopener ugc nofollow" target="_blank">单纯复形上的拓扑信号处理</a> (2020)，IEEE信号处理汇刊68:2992–3007。</p><p id="0cb8" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[22] S. Sardellitti等人<a class="ae mc" href="https://arxiv.org/pdf/2112.06709" rel="noopener ugc nofollow" target="_blank">细胞复合体上的拓扑信号处理</a> (2021)，Asilomar信号、系统和计算机会议。</p><p id="58d9" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[23] M. Hajij等人<a class="ae mc" href="https://arxiv.org/abs/2010.00743" rel="noopener ugc nofollow" target="_blank">细胞复杂神经网络</a> (2020)，NeurIPS拓扑数据分析及其他研讨会。</p><p id="3bee" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[24] C .，f .，Y. G .王，g .蒙图法尔等<a class="ae mc" href="https://arxiv.org/abs/2103.03212" rel="noopener ugc nofollow" target="_blank">魏斯费勒和雷曼go拓扑:消息传递单纯网络</a> (2021)著。</p><p id="5ffd" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[25] C .博德纳尔、f .弗拉斯卡等人<a class="ae mc" href="https://arxiv.org/abs/2106.12575" rel="noopener ugc nofollow" target="_blank">魏斯费勒和雷曼go Cellular: CW Networks </a> (2021)，NeurIPS。</p><p id="c3c0" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[26] F .巴蒂斯顿等人，<a class="ae mc" href="https://www.nature.com/articles/s41567-021-01371-4" rel="noopener ugc nofollow" target="_blank">复杂系统中高阶相互作用的物理学</a> (2021)，自然物理学17:1093–1098。</p><p id="7659" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[27] B. Weisfeiler和A. Leman，<a class="ae mc" href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf" rel="noopener ugc nofollow" target="_blank">将一个图简化为标准形式以及其中出现的代数</a> (1968)，Nauchno-Technicheskaya informatisia 2(9):12–16。关于WL测试和GNNs的关系，见<a class="ae mc" rel="noopener" target="_blank" href="/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49?sk=5c2a28ccd38db3a7b6f80f161e825a5a">帖子</a>。有关深入的评论(和历史笔记)，请参见C. Morris等人的文章，<a class="ae mc" href="https://arxiv.org/abs/2112.09992" rel="noopener ugc nofollow" target="_blank"> Weisfeiler和Leman go Machine Learning:the story迄今为止</a> (2021) arXiv:2112.09992。</p><p id="4c96" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[28] K. Xu等，<a class="ae mc" href="https://arxiv.org/abs/1810.00826" rel="noopener ugc nofollow" target="_blank">图神经网络到底有多强大？</a> (2019)，ICLR。</p><p id="5c1c" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[29] C. Morris等人，<a class="ae mc" href="https://arxiv.org/abs/1810.02244" rel="noopener ugc nofollow" target="_blank"> Weisfeiler和Leman Go Neural:高阶图神经网络</a> (2019)，AAAI。</p><p id="0797" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[30]我们注意到，与我们的方法正交的是WL测试的持久版本，由B. Rieck等人提出，<a class="ae mc" href="https://proceedings.mlr.press/v97/rieck19a.html" rel="noopener ugc nofollow" target="_blank">图分类的持久Weisfeiler-Lehman程序</a> (2019)，ICML。同时，持续的同源性也被用来使GNNs比WL测试更有表达力[10]。</p><p id="393a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[31] P. Barceló等人，图形神经网络的逻辑表达能力(2020年)，ICLR。</p><p id="d061" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[32] U. Alon和E. Yahav，<a class="ae mc" href="https://openreview.net/forum?id=i80OPhOCVH2" rel="noopener ugc nofollow" target="_blank">关于图神经网络的瓶颈及其实际意义</a> (2021)，ICLR。</p><p id="48e1" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[33] K. Oono和t .铃木，<a class="ae mc" href="https://openreview.net/pdf?id=S1ldO2EFPr" rel="noopener ugc nofollow" target="_blank">图形神经网络对节点分类的表达能力指数性丧失</a> (2020)，ICLR。</p><p id="2756" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[34]蔡春华，王永元，<a class="ae mc" href="https://arxiv.org/abs/2006.13318" rel="noopener ugc nofollow" target="_blank">关于图神经网络过光滑问题的一个注记</a> (2020)，arXiv:2006.13318 .</p><p id="b91a" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[35] A. D. Keros等人，<a class="ae mc" href="https://arxiv.org/abs/2110.15182" rel="noopener ugc nofollow" target="_blank"> Dist2Cycle:用于同源定位的单纯神经网络</a> (2021)，AAAI。</p><p id="5b0f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[36]p .<a class="ae mc" href="https://openreview.net/profile?id=~Petar_Veli%C4%8Dkovi%C4%871" rel="noopener ugc nofollow" target="_blank">veli kovi</a>，<a class="ae mc" href="https://openreview.net/forum?id=Bc8GiEZkTe5" rel="noopener ugc nofollow" target="_blank">消息一路向上传递</a> (2022)，ICLR几何与拓扑表征学习研讨会。</p><p id="fa56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[37] F. Jogl等人<a class="ae mc" href="https://openreview.net/forum?id=HKUxAE-J6lq" rel="noopener ugc nofollow" target="_blank">将细胞复合体的学习简化为图形</a> (2022)，ICLR几何和拓扑表示学习研讨会。</p><p id="53be" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[38] C. W. J. Goh等人<a class="ae mc" href="https://openreview.net/forum?id=ScfRNWkpec" rel="noopener ugc nofollow" target="_blank">单纯注意力网络</a> (2022)，ICLR几何和拓扑表示学习研讨会。</p><p id="a3bf" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[39] L. Giusti等人，<a class="ae mc" href="https://arxiv.org/abs/2203.07485" rel="noopener ugc nofollow" target="_blank">单纯注意神经网络</a> (2022)，arXiv:2203.07485。</p><p id="7be5" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[40] C .博德纳尔，f .迪·乔瓦尼等人，<a class="ae mc" href="https://arxiv.org/abs/2202.04579" rel="noopener ugc nofollow" target="_blank">神经束扩散:GNNs中异嗜性和过度光滑的拓扑透视</a> (2022) arXiv:2202.04579。另请参见随附的<a class="ae mc" rel="noopener" target="_blank" href="/neural-sheaf-diffusion-for-deep-learning-on-graphs-bfa200e6afa6">帖子</a>。</p><p id="1a82" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[41] L. Euler,《团结的理论基础》( 1758年),《石油政治科学院新评论》: 109-140页。</p><p id="3fa2" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[42] C. Hacker，k-simplex 2 vec:node 2 vec的单纯扩展(2020年)，NeurIPS拓扑数据分析研讨会及其他。</p><p id="5e56" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[43] L. Vietoris，1927年，《数学年鉴》97:454-472。</p><p id="2b20" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[44] A. Muhammad和M. Egerstedt，在网络拓扑中使用高阶拉普拉斯算子的控制(2006)，网络和系统数学理论国际研讨会。</p><p id="8688" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">[45]当局限于边缘时，这些信号可以很好地解释为通过网络的流动。例如，参见T. Gebhart等人的《随波逐流？使用Hodge理论 (2021)对美国医疗保健服务网络进行大规模分析，IEEE大数据2021，作为拓扑数据分析应用于大数据研讨会的一部分。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="a99f" class="pw-post-body-paragraph lf lg iq lh b li lj ka lk ll lm kd ln lo lp lq lr ls lt lu lv lw lx ly lz ma ij bi translated">我们非常感谢Ben Chamberlain和Bastian Rieck对这篇文章的校对。关于图形深度学习的其他文章，请参见我在《走向数据科学》中的 <a class="ae mc" rel="noopener" target="_blank" href="https://towardsdatascience.com/graph-deep-learning/home"> <em class="mb">其他帖子</em> </a> <em class="mb">，</em> <a class="ae mc" href="https://michael-bronstein.medium.com/subscribe" rel="noopener"> <em class="mb">订阅我的帖子</em> </a> <em class="mb">和</em> <a class="ae mc" href="https://www.youtube.com/c/MichaelBronsteinGDL" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> YouTube频道</em> </a> <em class="mb">，获取</em> <a class="ae mc" href="https://michael-bronstein.medium.com/membership" rel="noopener"> <em class="mb">中等会员</em> </a> <em class="mb">，或者关注我的</em> <a class="ae mc" href="https://twitter.com/mmbronstein" rel="noopener ugc nofollow" target="_blank"> <em class="mb"> Twitter </em> </a></p></div></div>    
</body>
</html>