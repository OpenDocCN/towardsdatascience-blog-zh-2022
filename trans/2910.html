<html>
<head>
<title>Getting Started with Text/NLP Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本/自然语言处理可视化入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-text-nlp-visualization-9dcb54bc91dd#2022-06-24">https://towardsdatascience.com/getting-started-with-text-nlp-visualization-9dcb54bc91dd#2022-06-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8b61" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何可视化文本数据来传达您的故事</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7db3eba9db61285304beb811f2bc3dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2M3IxDv8Gk4Xkqju"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://www.pexels.com/ko-kr/photo/1714208/" rel="noopener ugc nofollow" target="_blank">像素</a>的免费使用照片</p></figure><h1 id="4e62" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="c6d4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">自然语言处理(NLP)有多种定义，但我经常引用的一个定义如下:</p><blockquote class="mn mo mp"><p id="671d" class="lr ls mq lt b lu mr ju lw lx ms jx lz mt mu mc md mv mw mg mh mx my mk ml mm im bi translated"><em class="it"> NLP致力于建造能够理解和响应文本或语音数据的机器，并用它们自己的文本或语音做出响应，就像人类做的一样。[1] </em></p></blockquote><p id="4c58" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">由于在众多应用程序、平台和机构中生成的文本数据量不断增加，NLP市场正在快速增长。因此，知道如何从文本数据中传达有意义和有趣的故事是至关重要的。为此，你需要视觉化。在这篇文章中，让我们学习如何开始可视化文本数据。更先进的预处理和可视化文本数据的方法将在另一篇文章中介绍！</p><h1 id="fefa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文本基本概要统计的可视化分布</h1><p id="4a36" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">表格数据的“汇总统计”概念同样适用于文本数据。汇总统计帮助我们描述数据的特征。在文本数据的上下文中，此类统计数据可以是组成每个文本的字数，以及统计数据在整个语料库中的分布情况。为了观察分布，我们可以使用可视化方法，包括核密度估计(KDE)图和直方图等。但是为了介绍哪些统计数据可以被可视化。hist()函数用在所有的代码片段中。</p><p id="3afd" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">假设我们有一个评论数据集，其中包含一个名为“description”的变量，该变量中有文本描述。</p><h2 id="8954" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak">【1】每段文字的长度</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="478b" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].str.len().hist()</span></pre><h2 id="b3fd" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak">【2】</strong><strong class="ak">每篇文字字数</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="7157" class="mz la it nm b gy nq nr l ns nt"># .str.split( ) returns a list of words split by the specified delimiter<br/># .map(lambda x: len(x)) applied on .str.split( ) will return the number of split words in each text</span><span id="0ff8" class="mz la it nm b gy nu nr l ns nt">reviews[‘description’].str.split().map(lambda x: len(x)).hist()</span></pre><p id="b738" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">另一种方法是:</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="09b9" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: len(str(x).split())).hist()</span></pre><h2 id="2780" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak"> [3]每个文本中唯一的字数</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="1a02" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: len(set(str(x).split()))).hist()</span></pre><h2 id="5f06" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak"> [4]每个文本中的平均单词长度</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="bbe4" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].str.split().apply(lambda x : [len(i) for i in x]).map(lambda x: np.mean(x)).hist()</span></pre><p id="203e" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">另一种方法是:</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="8133" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: np.mean([len(w) for w in str(x).split()])).hist()</span></pre><h2 id="e317" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak"> [5]每个文本中的中值单词长度(分布)</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="49d2" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: np.median([len(w) for w in str(x).split()])).hist()</span></pre><h2 id="244a" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak">【6】停止字数统计</strong></h2><p id="eb96" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">NLP上下文中的停用词指的是频繁出现在语料库中但对理解文本的各个方面(包括情感和极性)没有添加太多意义的一组词。例如代词(例如他、她)和冠词(例如the)。</p><p id="e1c0" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">检索停用词主要有两种方法。一种方法是使用NLTK包，另一种方法是使用wordcloud包。在这里，我使用wordcloud包，因为它已经在一个名为“停用词”的子模块中预定义了一整套英语停用词。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="e4ec" class="mz la it nm b gy nq nr l ns nt">from wordcloud import STOPWORDS</span><span id="6879" class="mz la it nm b gy nu nr l ns nt">### Other way to retrieve stopwords</span><span id="58e0" class="mz la it nm b gy nu nr l ns nt"># import nltk</span><span id="53d3" class="mz la it nm b gy nu nr l ns nt"># nltk.download(‘stopwords’)</span><span id="f5f5" class="mz la it nm b gy nu nr l ns nt"># stopwords =set(stopwords.words(‘english’))<br/></span><span id="4363" class="mz la it nm b gy nu nr l ns nt">reviews[‘description’].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS])).hist()</span></pre><h2 id="f315" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak">【7】字符数</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="e140" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: len(str(x))).hist()</span></pre><h2 id="0ec5" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated"><strong class="ak">【8】标点数</strong></h2><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="7b30" class="mz la it nm b gy nq nr l ns nt">reviews[‘description’].apply(lambda x: len([c for c in str(x) if c in string.punctuation])).hist()</span></pre><h2 id="eb9f" class="mz la it bd lb na nb dn lf nc nd dp lj ma ne nf ll me ng nh ln mi ni nj lp nk bi translated">额外收获:检查常态</h2><p id="2565" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于新创建的统计变量(如平均单词长度)，您可能希望检查它们是否满足某些条件，例如，某些模型或回归算法要求变量符合某些分布。一种这样的检查是通过查看概率图来检查变量的分布是否足够接近正态分布。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="b36e" class="mz la it nm b gy nq nr l ns nt"><strong class="nm iu">from </strong>scipy <strong class="nm iu">import</strong> stats<br/><strong class="nm iu">import </strong>statsmodels.api <strong class="nm iu">as </strong>sm</span><span id="3765" class="mz la it nm b gy nu nr l ns nt">stats.probplot(reviews['char_length'], plot=plt)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/a571fb90dc5fe39c5ffa45d376fe932f.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*LWHfT8et6an2u_uZuMTD7g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">接近正态分布的分布示例</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/980d798988c27e3730dd5c38cb97bfff.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*YgUw7P0ePzshkhGIOVabGQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不接近正态分布的分布示例。</p></figure><h1 id="f143" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated"><strong class="ak">可视化顶部N-Grams </strong></h1><p id="61f0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">什么是n-gram？根据斯坦福大学的语音和语言处理课程材料，一个“n-gram是一个文本句子中n个单词的序列n-gram。”[2]</p><p id="b5db" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">例如，句子“我很酷”的二元模型(n-gram，n=2)将是:</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="0491" class="mz la it nm b gy nq nr l ns nt">[ (‘I’, ‘am”), (‘am’, ‘cool’)]</span></pre><p id="6b83" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">为了可视化最频繁出现的顶部N元文法，我们需要首先将我们的词汇表表示成某种数字矩阵形式。为此，我们使用了<em class="mq">计数矢量器。</em>根据Python的scikit-learn包文档，“Countvectorizer是一种将文本文档集合转换为令牌计数矩阵的方法。”[3]</p><p id="92f7" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">下面的函数首先将文本矢量化成某种适当的矩阵形式，其中包含记号(这里是n元文法)的计数。请注意，可以指定参数stop_words，以便在进行计数时忽略指定语言的停用词。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="b497" class="mz la it nm b gy nq nr l ns nt"><strong class="nm iu">def </strong>ngrams_top(corpus, ngram_range, n=None):</span><span id="2581" class="mz la it nm b gy nu nr l ns nt"><em class="mq">    ### What this function does: List the top n words in a vocabulary according to occurrence in a text corpus.</em></span><span id="3e62" class="mz la it nm b gy nu nr l ns nt">    vec = CountVectorizer(stop_words = ‘english’, ngram_range=ngram_range).fit(corpus)</span><span id="35ac" class="mz la it nm b gy nu nr l ns nt">   bag_of_words = vec.transform(corpus)</span><span id="7212" class="mz la it nm b gy nu nr l ns nt">   sum_words = bag_of_words.sum(axis=0)</span><span id="ebbd" class="mz la it nm b gy nu nr l ns nt">   words_freq = [(word, sum_words[0, idx]) for word, idx <strong class="nm iu">in</strong> vec.vocabulary_.items()]</span><span id="6c21" class="mz la it nm b gy nu nr l ns nt">   words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)</span><span id="2bac" class="mz la it nm b gy nu nr l ns nt">   total_list=words_freq[:n]</span><span id="df97" class="mz la it nm b gy nu nr l ns nt">   df = pd.DataFrame(total_list, columns=[‘text’,’count’])</span><span id="53fc" class="mz la it nm b gy nu nr l ns nt">   <strong class="nm iu">return </strong>df</span></pre><p id="4c06" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">下面的函数将ngram_range指定为(1，1)，所以我们只对基本上只是单个单词的单字元感兴趣。这里n=10意味着我们有兴趣查看描述语料库中的前10个单字。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="2262" class="mz la it nm b gy nq nr l ns nt">unigram_df = ngrams_top(reviews[‘description’], (1,1), n=10)</span></pre><p id="4c3c" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">然后，我们可以使用seaborn将其可视化为一个水平条形图。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="4aa2" class="mz la it nm b gy nq nr l ns nt"># seaborn barplot</span><span id="644e" class="mz la it nm b gy nu nr l ns nt">sns.barplot(x=’count’, y=’text’) #horizontal barplot</span></pre><p id="1ad5" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">如果你想使用稍微花哨一点的交互式可视化形式，我推荐plotly express，它的语法非常简单，但能让你用几行代码创建交互式可视化。</p><pre class="kj kk kl km gt nl nm nn no aw np bi"><span id="faa0" class="mz la it nm b gy nq nr l ns nt"># fancier interactive plot using plotly express</span><span id="467b" class="mz la it nm b gy nu nr l ns nt"><strong class="nm iu">import </strong>plotly.express <strong class="nm iu">as </strong>px</span><span id="8ecc" class="mz la it nm b gy nu nr l ns nt">fig = px.bar(unigram_df, x='unigram', y='count', title=’Counts of top unigrams', template='plotly_white', labels={'ngram;: ‘Unigram’, ‘count’: ‘Count’})</span><span id="245d" class="mz la it nm b gy nu nr l ns nt">fig.show()</span></pre><p id="eaae" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">更先进的预处理和可视化文本数据的方法将在另一篇文章中介绍！</p><h1 id="2ffd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">关于作者</h1><p id="85a0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><em class="mq">数据科学家。加州大学欧文分校信息学博士生。</em></p><p id="4509" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated"><em class="mq">密歇根大学刑事司法行政记录系统(CJARS)经济学实验室的前研究领域专家，致力于统计报告生成、自动化数据质量审查、构建数据管道和数据标准化&amp;协调。Spotify前数据科学实习生。Inc .(纽约市)。</em></p><p id="15fb" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">他喜欢运动、健身、烹饪美味的亚洲食物、看kdramas和制作/表演音乐，最重要的是崇拜我们的主耶稣基督。结账他的 <a class="ae ky" href="http://seungjun-data-science.github.io" rel="noopener ugc nofollow" target="_blank"> <em class="mq">网站</em> </a> <em class="mq">！</em></p><h1 id="063d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="1deb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">【1】什么是自然语言处理？、IBM云、<a class="ae ky" href="https://www.ibm.com/cloud/learn/natural-language-processing" rel="noopener ugc nofollow" target="_blank">https://realpython.com/python-assert-statement/</a></p><p id="08c6" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">[2]朱拉夫斯基和马丁。语音和语言处理(2021年12月最后更新)。https://web.stanford.edu/~jurafsky/slp3/3.pdf<a class="ae ky" href="https://web.stanford.edu/~jurafsky/slp3/3.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="6dcc" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma mu mc md me mw mg mh mi my mk ml mm im bi translated">[3] Scikit学习文档。<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . feature _ extraction . text . count vectorizer . html</a></p></div></div>    
</body>
</html>