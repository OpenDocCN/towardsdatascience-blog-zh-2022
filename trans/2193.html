<html>
<head>
<title>Model Prediction and Distribution with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用火花进行模型预测和分配</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/model-prediction-and-distribution-with-spark-9710c3065e62#2022-05-16">https://towardsdatascience.com/model-prediction-and-distribution-with-spark-9710c3065e62#2022-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3796" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何用Spark实现和分发机器学习模型——py Spark实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e81c23ea92a83e267375725749462a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_90g6USMw-8VJAcZuAq0ww.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/big-data-binary-code-background-7134400/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd kw">来源</strong> </a></p></figure><p id="3950" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">由于Apache Spark，任务处理可能是分散的。通过将内存中的属性与Spark SQL功能结合使用，它增强了这一过程。Spark的分布式数据记录和处理方法是通过包括分布式脚本、数据处理、数据工作流的创建和具有MLlib函数的机器学习技术在内的功能实现的。</p><p id="1a2d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Spark可以根据平台以不同的方式安装。在本节中，我们将重点关注本地安装。</p><p id="1428" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Apache Spark可以在任何安装了Python、Scala或Java的环境中运行。本文将关注Python语言。紧凑快速地安装所需的Python包和Jupyter Notebook的最简单方法是使用<a class="ae kv" href="https://www.anaconda.com/products/individual#Downloads" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>。</p><h2 id="9453" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated">探索性数据分析</h2><p id="1984" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated"><em class="mr">“ny T2”</em>数据集将在整篇文章中使用。你可以通过Kaggle网站从<a class="ae kv" href="https://www.kaggle.com/cmenca/new-york-times-hardcover-fiction-best-sellers" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载。</p><p id="c1cd" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">数据集的格式具有使用“JSON”函数的基本要求。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="07a2" class="lt lu iq mt b gy mx my l mz na">tr_df = spark.read<strong class="mt ir">.</strong>json('dataset/nyt2.json')</span><span id="3187" class="lt lu iq mt b gy nb my l mz na">ts_df = spark.read<strong class="mt ir">.</strong>json('dataset/nyt2.json')</span></pre><h1 id="b40d" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">新特征生成:特征工程</h1><p id="a187" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">通过使用特征工程，可以从数据集的当前变量中收集更多的信息数据。</p><p id="09a0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">个人的头衔也包含在Titanic数据集的“<em class="mr">姓名</em>”列中。该模型可以从该信息中受益。然后创建一个新的变量。可以使用'<em class="mr"> withColumn </em>'方法添加新的标题列。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="7289" class="lt lu iq mt b gy mx my l mz na">tr_data = tr_df.withColumn("writer",   regexp_extract(col("author"),"([A-Za-z]+)\.", 1))</span></pre><p id="c993" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">可能有一些重复的作者姓名。“替换”功能可用于替换它们。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="8502" class="lt lu iq mt b gy mx my l mz na">feature_dataframe =   tr_data.\<br/>   replace(["Jane Greenn", <br/>            "Stepheniei Meyer",<br/>            "Jimmy Buffett"],<br/>           ["Jane Green", <br/>            "Stephenie Meyer",<br/>            "Jimmy Buffett"])<br/>  </span></pre><p id="5824" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">标题的分布看起来比先前遵循替换过程更精确。</p><h1 id="b3db" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">用Spark MLlib建模</h1><p id="d111" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">最终的建模数据集必须将所有字符串格式的列转换为正确的数字类型，因为预测算法需要数字变量。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="a056" class="lt lu iq mt b gy mx my l mz na">from pyspark.ml.feature import StringIndexer</span><span id="0dbb" class="lt lu iq mt b gy nb my l mz na">writerIndexer = StringIndexer(inputCol="writer", outputCol="writer_Ind").fit(feature_dataframe)</span><span id="3d6d" class="lt lu iq mt b gy nb my l mz na">descriptionIndexer = StringIndexer(inputCol="published_date", outputCol="published_ind").fit(feature_dataframe)</span></pre><p id="83d4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">数据帧中包含所有数字变量，因为以前的字符串格式操作已被删除并编入索引。我们可以使用数据帧中的列来创建特征向量，因为每一列都具有非字符串格式。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="84af" class="lt lu iq mt b gy mx my l mz na">from pyspark.ml.feature import VectorAssembler</span><span id="5a13" class="lt lu iq mt b gy nb my l mz na">assembler = VectorAssembler(<br/>   inputCols = ["writer","price","published_ind"],<br/>   outputCol = "features")</span></pre><p id="9c1b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当创建流水线时，分类器的参数可以在`<em class="mr"> ParamGridBuilder </em>的帮助下进行优化。网格搜索后将创建相应的参数。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="af91" class="lt lu iq mt b gy mx my l mz na">from pyspark.ml.tuning import ParamGridBuilder<br/> <br/> pg = ParamGridBuilder().build()</span></pre><h1 id="dd8e" class="nc lu iq bd lv nd ne nf ly ng nh ni mb jw nj jx me jz nk ka mh kc nl kd mk nm bi translated">评估指标</h1><p id="bda7" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">精确度可用作模型评估的统计数据。“精确度”数学公式。</p><h2 id="30ca" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated"><strong class="ak">带MLFlow的MLOps】</strong></h2><p id="3411" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">对于PySpark模型，MLFlow可用作模型服务库。根据官方文档中的说明，可以为PySpark编程安装该库。</p><pre class="kg kh ki kj gt ms mt mu mv aw mw bi"><span id="72dc" class="lt lu iq mt b gy mx my l mz na">pip install mlflow</span></pre><p id="e775" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">“mlflow.pyfunc”函数可用于填充相关的模型推断。为此，独立分配模型和数据集路径至关重要。然后，模型路线可用于创建火花UDF。接下来是读取它们并将其注册到数据帧中。先前建立的火花UDF在最后阶段用于构造新特征。</p><p id="8761" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在<a class="ae kv" href="https://github.com/pinarersoy/PySpark_SparkSQL_MLib/blob/master/RDD%20Basics%20and%20PySpark%20ML%20Model%20Serving.ipynb" rel="noopener ugc nofollow" target="_blank">我的GitHub repo </a>中可以找到这个模型预测和分发脚本的完整实现示例版本！</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><p id="73d7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">非常感谢您的提问和评论！</p></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><h1 id="97c0" class="nc lu iq bd lv nd nu nf ly ng nv ni mb jw nw jx me jz nx ka mh kc ny kd mk nm bi translated">参考</h1><ol class=""><li id="369d" class="nz oa iq kz b la mm ld mn lg ob lk oc lo od ls oe of og oh bi translated"><a class="ae kv" href="https://spark.apache.org/mllib/" rel="noopener ugc nofollow" target="_blank">火花MLlib </a></li><li id="c57f" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank">阿帕奇火花</a></li><li id="da96" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://www.python.org/" rel="noopener ugc nofollow" target="_blank"> Python API文档</a></li><li id="849b" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://www.scala-lang.org/" rel="noopener ugc nofollow" target="_blank"> Scala API文档</a></li><li id="bdb5" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://www.java.com/" rel="noopener ugc nofollow" target="_blank"> Java API文档</a></li><li id="dc07" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://mlflow.org/" rel="noopener ugc nofollow" target="_blank"> MLFlow文档</a></li><li id="b457" class="nz oa iq kz b la oi ld oj lg ok lk ol lo om ls oe of og oh bi translated"><a class="ae kv" href="https://pypi.org/project/mlflow/" rel="noopener ugc nofollow" target="_blank"> MLFlow安装</a></li></ol></div></div>    
</body>
</html>