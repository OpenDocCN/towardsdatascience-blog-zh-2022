<html>
<head>
<title>NLP: Building a Grammatical Error Correction Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理:建立一个语法纠错模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-building-a-grammatical-error-correction-model-deep-learning-analytics-c914c3a8331b#2022-04-01">https://towardsdatascience.com/nlp-building-a-grammatical-error-correction-model-deep-learning-analytics-c914c3a8331b#2022-04-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="831b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用数据做很酷的事情</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c81a767e539122ad3d0e606d82b4fe44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eD1vWl8gqwxnvqX6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@ninjason?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">梁杰森</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="168d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="944f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">语法纠错(GEC)系统旨在纠正文本中的语法错误。<a class="ae ky" href="https://www.grammarly.com/" rel="noopener ugc nofollow" target="_blank">语法上</a>就是这样一个语法修正产品的例子。纠错可以提高电子邮件、博客文章和聊天中文字的质量。</p><p id="ab82" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">GEC 任务可以被认为是一个序列对序列的任务，其中一个转换器模型被训练成以一个不合语法的句子作为输入，并返回一个语法正确的句子。在本帖中，我们将展示如何训练这样一个模型，并在训练时使用权重和偏差来监控模型的性能。我们还在 Spaces <a class="ae ky" href="https://huggingface.co/spaces/deep-learning-analytics/GrammarCorrector" rel="noopener ugc nofollow" target="_blank">这里</a>发布了我们训练过的模型用于实验。代码也在 Colab <a class="ae ky" href="https://colab.research.google.com/drive/1KVB7TcDQraDw-B-NB9NzvZk2zGlv2PH-?authuser=5" rel="noopener ugc nofollow" target="_blank">这里</a>和 Github <a class="ae ky" href="https://github.com/priya-dwivedi/Deep-Learning/blob/master/GrammarCorrector/T5_Grammar.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>公开。</p><p id="bf0a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在书面语言中遇到的错误可能有不同的类型，如下图所示。</p><div class="kj kk kl km gt ab cb"><figure class="ms kn mt mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5168a1258a949d1229ae966d0b82cab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*Voez5hEn5MU8Knde3fIZfw.png"/></div></figure><figure class="ms kn my mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1ed81db69cc645ee2c6d0310c81349f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*-PjJLo30cr-E2_3tHYZwyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk mz di na nb translated">书面语言中遇到的错误。来源:作者提供的数据</p></figure></div><h1 id="7742" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">资料组</h1><p id="1d19" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于我们的语法校正器的训练，我们使用谷歌最近发布的<a class="ae ky" href="https://github.com/google-research-datasets/C4_200M-synthetic-dataset-for-grammatical-error-correction" rel="noopener ugc nofollow" target="_blank"> C4_200M 数据集</a>。这个数据集由 200 毫米合成生成的语法错误以及正确的文本组成。</p><p id="4a82" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在 GEC，最大的挑战之一是获得各种各样的数据来模拟通常在书面语言中犯的错误。如果损坏是随机的，那么它们不能代表真实用例中遇到的错误的分布。</p><p id="4abc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了生成讹误，首先训练标记讹误模型。通过将干净文本作为输入并生成损坏的文本，在现有数据集上训练该模型。例如，输入句子将是<em class="nc">“有</em><strong class="lt iu"><em class="nc"/></strong><em class="nc">很多羊”</em>，腐败模型将把它改为<em class="nc">“有很多羊”</em>。所以它会生成语法错误的输出。</p><p id="9cab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于 C4_2OOM 数据集，作者首先确定了书面语中遇到的相对错误类型的分布。当产生讹误时，它们取决于错误的类型。例如，一个名词变化错误会把一个正确的句子作为输入。</p><p id="b80f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">正确的句子— <em class="nc">“有</em><strong class="lt iu"><em class="nc"/></strong><em class="nc">很多羊”</em></p><p id="28da" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">带有名词屈折错误的不正确句子-</p><ol class=""><li id="b278" class="nd ne it lt b lu mn lx mo ma nf me ng mi nh mm ni nj nk nl bi translated"><em class="nc">“有很多</em><strong class="lt iu"><em class="nc"/></strong><em class="nc"/></li><li id="8fee" class="nd ne it lt b lu nm lx nn ma no me np mi nq mm ni nj nk nl bi translated"><em class="nc">“有很多羊”</em></li></ol><p id="7612" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这使得 C4_200M 数据集具有一组不同的误差，反映了它们在现实应用中的相对频率。要了解更多关于生成综合破坏的过程，请在此处参考原始论文<a class="ae ky" href="https://aclanthology.org/2021.bea-1.4.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="3731" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了这篇博文的目的，我们从 C4_200M 中提取了 55 万个句子。C4_200M 数据集在 TF 数据集上可用。我们提取了我们需要的句子，并保存为 CSV 格式。此处的数据准备代码被推送到 Colab <a class="ae ky" href="https://colab.research.google.com/drive/1qwf8l3UshZt2WKsb9xPCuWcfMJWelDou?authuser=5#scrollTo=vGIOWlz7u355" rel="noopener ugc nofollow" target="_blank">这里</a>。如果您有兴趣下载准备好的数据集，可以在此访问<a class="ae ky" href="https://drive.google.com/drive/folders/1kKlGcinD_FhGXC0LztN4Ts605YXzMEVA?usp=sharing" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="601f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面是 C4_200M 数据集的截图。输入是不正确的句子，输出是语法正确的句子。这些随机例子表明，数据集涵盖了来自不同领域和各种写作风格的输入。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nr"><img src="../Images/5c7362d4d1125bd0dbea5018e1194676.png" data-original-src="https://miro.medium.com/v2/format:webp/1*b2CfZQUH8zGdR2Q0K7cZ2Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">C4_200M 数据集截图</p></figure><h1 id="bcd6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模特培训</h1><p id="af23" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这次培训中，我们将使用 Google 的通用 T5 模型。</p><p id="554c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">T5 是文本到文本模型，这意味着它可以被训练成从一种格式的输入文本到一种格式的输出文本。我个人使用这个模型有很多不同的目的，比如摘要(见博客<a class="ae ky" href="https://deeplearninganalytics.org/fine-tuning-a-t5-transformer-for-any-summarization-task/" rel="noopener ugc nofollow" target="_blank">这里</a>)和文本分类(见博客<a class="ae ky" href="https://deeplearninganalytics.org/detect-fake-news-using-transformers/" rel="noopener ugc nofollow" target="_blank">这里</a>)。还用它构建了一个琐事机器人，它可以在没有任何上下文的情况下从内存中检索答案。点击查看这篇博客<a class="ae ky" href="https://medium.com/analytics-vidhya/build-a-trivia-bot-using-t5-transformer-345ff83205b6" rel="noopener">。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nr"><img src="../Images/6b4ea7384dcc471ade53f945e0addad9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ax8c9rvc75i8wtCvCbox5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">T5 —文本到文本转换转换器。图片来自<a class="ae ky" href="https://arxiv.org/pdf/1910.10683.pdf" rel="noopener ugc nofollow" target="_blank"> T5 纸。</a></p></figure><p id="15c0" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于很多任务，我更喜欢 T5，原因有几个——1 .可用于任何文本到文本的任务，2。微调后对下游任务的准确性好，3 .使用 Huggingface 易于训练</p><p id="f38f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在来自 C4_200M 的 550K 样本上训练 T5 模型的完整代码可从 Colab 上的<a class="ae ky" href="https://colab.research.google.com/drive/1KVB7TcDQraDw-B-NB9NzvZk2zGlv2PH-?authuser=5" rel="noopener ugc nofollow" target="_blank">这里</a>获得。也分享在我的 Github 上<a class="ae ky" href="https://github.com/priya-dwivedi/Deep-Learning/blob/master/GrammarCorrector/T5_Grammar.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="c70f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">培训的高级步骤包括:</p><p id="f25a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们将不正确的句子设置为输入，将正确的文本设置为标签。输入和目标都使用 T5 记号化器进行记号化。最大长度设置为 64，因为 C4_200M 中的大多数输入是句子，并且假设该模型也将用于句子。完成标记化的代码片段如下。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">语法纠错模型的标记器</p></figure><p id="d81f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">2.<strong class="lt iu">使用 seq2seq 训练器类训练模型</strong></p><p id="2022" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们使用 Huggingface 中的 Seq2Seq trainer 类来实例化模型，并实例化对 wandb 的日志记录。对 HuggingFace 使用权重和偏差非常简单。所有需要做的就是在训练参数中设置<code class="fe nu nv nw nx b">report_to = "wandb"</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">T5 模型的定型参数和定型</p></figure><p id="3294" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu"> 3。监测和评估模型</strong></p><p id="b52c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们使用了 Rouge 评分作为评估模型的标准。正如在 W&amp;B 下面的图中所看到的，该模型在一个时期的训练后获得了 72 的胭脂分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nr"><img src="../Images/f55029b3c077d6215d6100c0e5dbec6c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wFxf0l23GZh5_p-zIcPKEw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一轮训练后的准确度</p></figure><p id="44fe" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><a class="ae ky" href="https://wandb.ai/deep-learning-analytics/huggingface?workspace=user-deep-learning-analytics" rel="noopener ugc nofollow" target="_blank"> T </a>此处可通过权重和偏差<a class="ae ky" href="https://wandb.ai/deep-learning-analytics/GrammarErrorCorrector?workspace=user-deep-learning-analytics" rel="noopener ugc nofollow" target="_blank">访问他的项目。</a></p><h1 id="a928" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">在空间上发布模型</h1><p id="e8e0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们已经将训练好的模型推送到 Spaces <a class="ae ky" href="https://huggingface.co/spaces/deep-learning-analytics/GrammarCorrector" rel="noopener ugc nofollow" target="_blank">这里</a>，这样它就可以被测试了。如下面的截图所示，它可以被编程为返回最多 2 个正确的序列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl nr"><img src="../Images/857f8978ac20152ad00bc75a34216023.png" data-original-src="https://miro.medium.com/v2/format:webp/1*HS7BMWgG4VhDrvHscNGsFQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在空格上测试语法修正器</p></figure><p id="c46d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我已经在许多不正确的序列上测试了这个模型，并且对它的性能很满意。</p><p id="dc25" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">该型号在 hugginface.co<a class="ae ky" href="https://huggingface.co/deep-learning-analytics/GrammarCorrector" rel="noopener ugc nofollow" target="_blank">这里</a>也有售，也可以直接使用。模型文档显示了使用模型所涉及的步骤。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用训练好的模型进行推理</p></figure><h1 id="9404" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="95f3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这篇博文展示了利用 HuggingFace 和 WandB 为不同用例训练 NLP 模型是多么容易。我希望你尝试一下 HuggingFace Spaces，并在下面分享你的经历。</p><p id="9c7c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在<a class="ae ky" href="https://deeplearninganalytics.org/" rel="noopener ugc nofollow" target="_blank">深度学习分析</a>，我们专门为各种用例构建定制的机器学习模型。我们与世界各地的客户合作，为他们的特定需求构建解决方案。我们的专家团队拥有文本分类、翻译、摘要、神经搜索等方面的经验。如果你看到合作的机会，请发邮件到 info@deeplearninganalytics.org 给我们。</p></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><p id="8e6f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="nc">原载于 2022 年 4 月 1 日 https://deeplearninganalytics.org</em><a class="ae ky" href="https://deeplearninganalytics.org/nlp-building-a-grammatical-error-correction-model/" rel="noopener ugc nofollow" target="_blank"><em class="nc"/></a><em class="nc">。</em></p></div></div>    
</body>
</html>