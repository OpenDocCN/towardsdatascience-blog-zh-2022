<html>
<head>
<title>3 Fundamental Processes in Feature Engineering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征工程的3个基本过程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-fundamental-processes-in-feature-engineering-d6b84983754#2022-10-28">https://towardsdatascience.com/3-fundamental-processes-in-feature-engineering-d6b84983754#2022-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3d7d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以正确的方式向模型呈现数据模式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d943064ea5e4ef80f251e52a8e340fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uSQ2oOyt92R0z9Jk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阿克顿·克劳福德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="5260" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">介绍</h2><p id="ca6c" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">这篇文章解释了特征工程(FE)中的三个关键过程，你需要知道这三个过程才能正确地将数据模式呈现给机器学习(ML)模型。</p><p id="91bb" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">特征工程是修改现有特征以增强模型从数据中学习的能力的过程。</p><blockquote class="mt"><p id="ebc0" class="mu mv it bd mw mx my mz na nb nc mn dk translated">有限元在不显著增加计算时间和成本的情况下，显著提高了模型精度。</p></blockquote><p id="653b" class="pw-post-body-paragraph lv lw it lx b ly nd ju ma mb ne jx md li nf mf mg lm ng mi mj lq nh ml mm mn im bi translated">FE是数据转换的子集，是数据预处理的关键元素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/53abd35bcda378243439aaf755d4eaa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*9AR2GMCxpI_NMYHyeO8FbQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据预处理的层次(图片由作者提供)</p></figure><p id="168f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在最近的一篇文章中，我详细讨论了数据转换。然而，FE作为一个子领域很突出。文章的链接如下所示:</p><div class="nj nk gp gr nl nm"><a rel="noopener follow" target="_blank" href="/three-critical-elements-of-data-preprocessing-part-3-6a7da681ae16"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">数据预处理的三个关键要素—第3部分</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">数据科学中建模的主干。</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">towardsdatascience.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa ks nm"/></div></div></a></div><p id="7aaa" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">本文的主要目的是讨论数据转换的组件。这有助于更好地理解数据科学项目生命周期中的数据预处理步骤。</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="378a" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">特征工程的3个基本过程</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b567ab22091035c7e33c0aece1239ea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*kpDsMJNPjF3ZhRNPiELPVA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征工程的基本过程(图片由作者提供)</p></figure><p id="ba86" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">现在，让我们深入研究FE中的主要过程:</p><p id="38df" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">1.<strong class="lx iu">特征提取</strong></p><p id="d967" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是从现有要素生成新要素的过程。它是高度特定于领域的，并且很大程度上依赖于你对主题领域的知识。主要思想是创建新的特征，使ML模型能够更好地从数据中学习。例如，当预测风力涡轮机的功率输出时，根据原始X和Y方向风速创建风速大小特征可提供更高的模型精度。</p><p id="69b8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">此外，许多ML模型处理数字数据，即由整数或小数组成的数据。因此，我们需要对原始的分类数据(由字符串组成的数据)进行编码，以使它们可用于模型。例如，状态变量可以有“开”和“关”类别。</p><p id="77f5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">基于特征学习技术，有更高级的特征提取方法。这种方法更加数据驱动、通用和可伸缩。一些例子包括<a class="ae ky" href="https://machinelearningmastery.com/autoencoder-for-classification/" rel="noopener ugc nofollow" target="_blank">自动编码器</a>和<a class="ae ky" rel="noopener" target="_blank" href="/how-to-create-new-features-using-clustering-4ae772387290">集群</a>。</p><p id="f1f3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">2.<strong class="lx iu">功能选择</strong></p><p id="bfb3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是为训练过程选择最相关特征的过程。特征选择方法分为三个主要类别，即包装器、过滤器和嵌入式方法。关于特性选择的深入讨论可以在<a class="ae ky" href="https://neptune.ai/blog/feature-selection-methods" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e6ca" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">功能相关性的一些衡量标准包括:</p><p id="6c34" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="oj">相关分析:</em>相关系数衡量两个变量之间的关系，取值在-1和+1之间。正相关意味着两个变量同向变动(即一个变量增加，另一个变量增加，反之亦然)。此外，系数越大，变量之间的相关性越强。在特征选择中，选择与目标变量具有更高相关性的特征，因为它们具有更高的预测能力。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/591dfdbe8252db59b1960178a09a8c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7OqijQUPStilxp9S.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">样本相关图。<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Correlation_examples.png" rel="noopener ugc nofollow" target="_blank">原始照片</a>被<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Correlation_examples_1.png" rel="noopener ugc nofollow" target="_blank">裁剪w:用户:Imagecreator </a>，<a class="ae ky" href="https://creativecommons.org/publicdomain/zero/1.0/deed.en" rel="noopener ugc nofollow" target="_blank"> CC0 </a>，via Wikimedia</p></figure><p id="e6f5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="oj">特征重要性:</em>一些树方法，例如随机森林和梯度提升算法，提供特征重要性分数，其显示每个特征对目标预测的影响。这些分数可以用来选择最相关的特征。更多详情可在<a class="ae ky" rel="noopener" target="_blank" href="/understanding-feature-importance-and-how-to-implement-it-in-python-ff0287b20285">这里</a>找到。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/074353044818916485cf5ee556250044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/0*nZc5HSG5co8A8uO1"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特征重要性排序示例。照片由<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Wikireliability_original-research_feature-importance.png" rel="noopener ugc nofollow" target="_blank"> 0xkaywong </a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>通过维基媒体提供</p></figure><p id="f348" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="oj">互信息:</em>基于对一个变量的了解，测量另一个变量的不确定性的减少。不确定性的减少是因为掌握了更多的变量信息。具有高互信息分数的特征被认为更相关，并被选择用于ML建模。更多细节可以在找到<a class="ae ky" href="https://guhanesvar.medium.com/feature-selection-based-on-mutual-information-gain-for-classification-and-regression-d0f86ea5262a" rel="noopener">。</a></p><p id="4e9b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">3.<strong class="lx iu">特征投影</strong></p><p id="b0a0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是将高维数据映射到低维空间的过程。它通常包括减少馈送给ML算法的特征的数量。这是有益的，原因有很多。一个是降低最终模型的复杂性，从而减少过度拟合的机会。另一个目的是减少计算时间和工作量，同时不显著影响模型的准确性。</p><p id="48c9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">有两类主要的特征投影技术:</p><p id="a291" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="oj">线性投影:</em>这些方法采用特征的线性组合，并且不捕捉两个或更多特征之间的相互作用。一些例子包括线性判别分析(LDA)和主成分分析(PCA)。更多细节可以在<a class="ae ky" href="https://bitsandbrains.io/2018/09/25/linear-dimensionality-reduction.html" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="f7fd" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="oj">非线性投影:</em>这些方法比较复杂，用非线性方程描述。一些例子包括核主成分分析(KPCA)和主曲线。更多细节可以在这里找到<a class="ae ky" href="https://golden.com/wiki/Nonlinear_dimensionality_reduction_(NDR_or_NLDR)-6834P" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><h2 id="7e77" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h2><p id="a9e6" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在本文中，我们讨论了特征工程中的三个基本过程，特征工程是数据转换的一个子领域。这些过程是特征提取、选择和投影。提供了在这些过程中使用的不同方法的例子，包括一些资源链接。</p><p id="aa7d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我希望你觉得这篇文章很有见地，下次再见。干杯！</p></div><div class="ab cl ob oc hx od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="im in io ip iq"><p id="a6f1" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">你可以通过下面我的推荐链接订阅Medium来获得更多我和其他作者的启发性文章，这也支持我的写作。谢谢大家！</p><div class="nj nk gp gr nl nm"><a href="https://aolaoye.medium.com/membership" rel="noopener follow" target="_blank"><div class="nn ab fo"><div class="no ab np cl cj nq"><h2 class="bd iu gy z fp nr fr fs ns fu fw is bi translated">通过我的推荐链接加入媒体</h2><div class="nt l"><h3 class="bd b gy z fp nr fr fs ns fu fw dk translated">阅读Abiodun Olaoye(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="nu l"><p class="bd b dl z fp nr fr fs ns fu fw dk translated">aolaoye.medium.com</p></div></div><div class="nv l"><div class="om l nx ny nz nv oa ks nm"/></div></div></a></div></div></div>    
</body>
</html>