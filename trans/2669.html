<html>
<head>
<title>Explaining negative R-squared</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释负R平方</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explaining-negative-r-squared-17894ca26321#2022-06-09">https://towardsdatascience.com/explaining-negative-r-squared-17894ca26321#2022-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="414a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我第一次开始做机器学习时，我了解到:</p><ul class=""><li id="272a" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">r是决定系数，是对拟合模型解释数据的程度的度量，</li><li id="cf7c" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">R是相关系数的平方，</li><li id="839a" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">r是一个范围从0到1的量</li></ul><p id="c244" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，R也应该在0到1的范围内。</p><p id="2d06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当sklearn 中的“r2_score` <a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html" rel="noopener ugc nofollow" target="_blank">”实现返回负数时，我感到很惊讶。怎么回事？</a></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi la"><img src="../Images/40f7c3906e20ff1319e3d61b45810e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1CgRyoAG8IGoHaIb311nhA.jpeg"/></div><p class="li lj gj gh gi lk ll bd b be z dk translated">如果你本能地忽略了数学，这个迷因就是给你的。</p></figure><blockquote class="lm ln lo"><p id="a793" class="jn jo lp jp b jq jr js jt ju jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj kk ij bi translated">本文改编自我的<a class="ae kz" href="https://tnwei.github.io/posts/negative-r2/" rel="noopener ugc nofollow" target="_blank">原创博文这里</a></p></blockquote><h2 id="89d2" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">答案在于定义</h2><p id="61c1" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">r的定义基于拟合模型的平方和等于解释的平方和加上残差平方和；</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/e94ea4063f1649fa2177f4ac12349a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*dArha-uzww1dnV8QRtFoBw.jpeg"/></div></figure><p id="969d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中:</p><ul class=""><li id="526f" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">总平方和(SS_tot)表示数据的总变化，用预期值和实际值之差的平方和来衡量。</li><li id="f219" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">解释平方和(SS_exp)代表由拟合模型解释的数据变化，以及</li><li id="b081" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">残差平方和(SS_res)表示拟合模型无法解释的数据变化。</li></ul><p id="6896" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">r本身定义如下:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/16782baf30b75d92639ccb88c976154a.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*8icqaOJd9lQGmrdZmLeqoA.jpeg"/></div></figure><p id="f01b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据这些定义，请注意，只有当残差平方和(SS_res)超过总平方和(SS_tot)时，负R才是可能的。由于这在数学上是不可能的，这只能意味着所解释的平方和以及残差平方和不再等于总平方和。换句话说，等式1中的等式似乎[1]不成立。</p><p id="8bd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">怎么会这样呢？</p><h2 id="1578" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">因为我们在训练和测试数据上分别评估模型</h2><p id="122a" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">根据上述定义，SS_tot可以仅使用数据本身来计算，而SS_res取决于模型预测和数据。虽然我们可以使用任何任意模型来生成评分预测，但我们需要认识到，上述等式是为基于相同数据训练的<em class="lp">模型定义的。因此，当我们使用测试数据来评估基于列车数据构建的模型时，它不一定成立！不能保证外国模型的预测和数据之间的差异小于数据本身的变化。</em></p><p id="36f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以从经验上证明这一点。下面的代码对随机生成的数据拟合了几个线性回归模型:</p><pre class="lb lc ld le gt mt mu mv mw aw mx bi"><span id="00f8" class="lt lu iq mu b gy my mz l na nb">from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import r2_score<br/>import numpy as np</span><span id="3dbf" class="lt lu iq mu b gy nc mz l na nb">for _ in range(20):<br/>    data = np.random.normal(size=(200, 10))</span><span id="f697" class="lt lu iq mu b gy nc mz l na nb">    X_train = data[:160, :-1]<br/>    X_test = data[160:, :-1]<br/>    y_train = data[:160, -1]<br/>    y_test = data[160:, -1]</span><span id="fe4e" class="lt lu iq mu b gy nc mz l na nb">    lr = LinearRegression()<br/>    lr.fit(X_train, y_train)</span><span id="4ba5" class="lt lu iq mu b gy nc mz l na nb">    y_train_pred = lr.predict(X_train)<br/>    y_test_pred = lr.predict(X_test)</span><span id="3963" class="lt lu iq mu b gy nc mz l na nb">    train_score = r2_score(y_train, y_train_pred)<br/>    test_score = r2_score(y_test, y_test_pred)<br/>    print(f"Train R2: {train_score:.3f}, Test R2: {test_score:.3f}")</span></pre><p id="8806" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管我们可能会尝试，但是当根据训练数据评估模型时，R永远不会降到零以下。下面是我在STDOUT中得到的内容:</p><pre class="lb lc ld le gt mt mu mv mw aw mx bi"><span id="31fe" class="lt lu iq mu b gy my mz l na nb">Train R2: 0.079, Test R2: -0.059<br/>Train R2: 0.019, Test R2: -0.046<br/>Train R2: 0.084, Test R2: -0.060<br/>Train R2: 0.020, Test R2: -0.083<br/>Train R2: 0.065, Test R2: -0.145<br/>Train R2: 0.022, Test R2: 0.032<br/>Train R2: 0.048, Test R2: 0.107<br/>Train R2: 0.076, Test R2: -0.031<br/>Train R2: 0.029, Test R2: 0.006<br/>Train R2: 0.069, Test R2: -0.150<br/>Train R2: 0.064, Test R2: -0.150<br/>Train R2: 0.053, Test R2: 0.096<br/>Train R2: 0.062, Test R2: 0.022<br/>Train R2: 0.063, Test R2: 0.008<br/>Train R2: 0.059, Test R2: -0.061<br/>Train R2: 0.076, Test R2: -0.191<br/>Train R2: 0.049, Test R2: 0.099<br/>Train R2: 0.040, Test R2: -0.012<br/>Train R2: 0.096, Test R2: -0.373<br/>Train R2: 0.073, Test R2: 0.088</span></pre><h2 id="9219" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">那么……R是相关的平方呢？</h2><p id="4dd8" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">似乎R = R * R只是在有限的情况下。引用下面来自维基百科相关页面的段落:</p><blockquote class="lm ln lo"><p id="d587" class="jn jo lp jp b jq jr js jt ju jv jw jx lq jz ka kb lr kd ke kf ls kh ki kj kk ij bi translated">R有几种定义，只是有时是等价的。一类这样的情况包括简单线性回归，其中使用R而不是R。当仅包括截距时，则R简单地是观察到的结果和观察到的预测值之间的样本相关系数(即R)的平方。如果包括额外的回归量，R是多重相关系数的平方。在这两种情况下，决定系数通常在0到1之间。</p></blockquote><p id="4f43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，如果我们碰巧(1)使用线性回归模型，并且(2)对它们所拟合的相同数据进行评估(如前面所建立的)，R只是相关性的平方。</p><h2 id="a8c8" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">线性回归背景之外R的自由使用</h2><p id="4807" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">引用的维基百科段落与我翻阅统计文本时的观察一致:R几乎总是在线性回归的上下文中引入。也就是说，R的公式使得它对于任何任意的预测模型都是通用定义的，而不考虑统计基础。数据科学家在回归任务中大量使用它，它甚至是sklearn中回归模型的默认度量。我们在R的原始语境之外如此自由地使用R，对吗？</p><p id="7a25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">老实说，我不知道。一方面，它作为一种度量标准显然有很多用处，这首先导致了它被数据科学家广泛采用。另一方面，你可以在网上找到<a class="ae kz" href="https://stats.stackexchange.com/questions/547863/heres-why-you-can-hopefully-use-r2-for-non-linear-models-why-not" rel="noopener ugc nofollow" target="_blank">讨论</a> <a class="ae kz" href="https://blog.minitab.com/en/adventures-in-statistics-2/why-is-there-no-r-squared-for-nonlinear-regression" rel="noopener ugc nofollow" target="_blank">像</a> <a class="ae kz" href="https://statisticsbyjim.com/regression/r-squared-invalid-nonlinear-regression/" rel="noopener ugc nofollow" target="_blank">这些</a>告诫不要使用R进行非线性回归。在我看来，从统计学的角度来看，在正确的条件下计算R是很重要的，这样它的性质就可以用于进一步的分析。我观察到在数据科学圈子里相对缺乏关于R的讨论，这意味着从数据科学的角度来看，R不仅仅是像MSE或MAE那样的性能指标。</p><p id="50e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就个人而言，我认为我们可以很好地使用R，只要我们足够了解它，知道用它做什么。</p><h2 id="3360" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">包扎</h2><p id="c940" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">总的来说，只有当线性回归模型是合适的，并且对拟合的相同数据进行评估时，我们才应该期望R在零和一之间有界。否则，R的定义会导致负值。</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="2f09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[1]具体到我在这里选择的词语:)</p></div></div>    
</body>
</html>