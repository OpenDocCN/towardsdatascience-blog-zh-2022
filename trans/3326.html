<html>
<head>
<title>Using Python UDF’s and Snowflake’s Snowpark to build and deploy Machine Learning Models, Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python UDF和Snowflake的Snowpark构建和部署机器学习模型，第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-python-udfs-and-snowflake-s-snowpark-to-build-and-deploy-machine-learning-models-a3c160c06d85#2022-07-25">https://towardsdatascience.com/using-python-udfs-and-snowflake-s-snowpark-to-build-and-deploy-machine-learning-models-a3c160c06d85#2022-07-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/68248e0d7c14d68e70a8ab1cc6a82bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NMd5MBMRkdeBZ638HG8HXQ.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">照片来自<a class="ae kc" href="https://unsplash.com/@asoggetti" rel="noopener ugc nofollow" target="_blank">阿莱西奥·索格蒂</a>通过<a class="ae kc" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="18cf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本指南将向您展示如何将雪花的Snowpark与Python UDF的结合使用，以利用雪花的计算能力来运行使用Python的机器学习模型。</p><p id="3782" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">导入库</strong></p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="66ae" class="lk ll iq lg b gy lm ln l lo lp">import snowflake.connector<br/>import pandas as pd<br/>import numpy as np<br/>from sqlalchemy import create_engine<br/>from snowflake.sqlalchemy import URL</span><span id="1960" class="lk ll iq lg b gy lq ln l lo lp">from snowflake.connector.pandas_tools import write_pandas<br/>from snowflake.snowpark.functions import udf<br/>from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType<br/>from snowflake.snowpark.session import Session<br/>from snowflake.snowpark import Session<br/>import snowflake.snowpark.functions as F<br/>from snowflake.snowpark import types as T<br/>from snowflake.snowpark import Window<br/>from snowflake.snowpark.functions import udf, max, min, count, avg, sum, col, lit, listagg<br/>import mlxtend<br/>from mlxtend.feature_selection import ColumnSelector</span><span id="e4af" class="lk ll iq lg b gy lq ln l lo lp">import lightgbm as lgb<br/>from sklearn.model_selection import GridSearchCV, train_test_split<br/>from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, FunctionTransformer<br/>from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier<br/>from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer<br/>from sklearn.metrics import balanced_accuracy_score<br/>from sklearn import datasets</span></pre><p id="8c86" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">数据</strong></p><p id="29c8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用来自sklearn数据集(Alpaydin，E. &amp; Kaynak，C)的<a class="ae kc" href="https://archive-beta.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits" rel="noopener ugc nofollow" target="_blank">数字</a>数据集。这个数据集是在<a class="ae kc" href="https://creativecommons.org/licenses/by/4.0/legalcode" rel="noopener ugc nofollow" target="_blank">知识共享署名4.0国际</a> (CC BY 4.0)许可下许可的。</p><p id="49c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这允许为任何目的共享和改编数据集，只要给予适当的信任。</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="2fe3" class="lk ll iq lg b gy lm ln l lo lp">digits = pd.DataFrame(datasets.load_digits().data)<br/>digits['target'] = datasets.load_digits().target<br/>digits.head()</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lr"><img src="../Images/538588673748895df2b445575fd63557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jQIktuGTYJzUzSgbzn7xIQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="abf5" class="lk ll iq lg b gy lm ln l lo lp">print(datasets.load_digits().DESCR)</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ls"><img src="../Images/2b2808c42a9fa0e9390b717f04faac6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*njBd8f97UCmN9u2q0VjsQQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="ae57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们将数字数据分成训练和测试，并将它们作为单独的表保存在雪花中。我们稍后可以使用Snowpark连接到这些:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="c4b8" class="lk ll iq lg b gy lm ln l lo lp">#Set up the snowflake connection<br/>ctx = snowflake.connector.connect(<br/>    user='&lt;user&gt;',<br/>    password='&lt;password&gt;',<br/>    account='&lt;account-identifier&gt;',<br/>    database='&lt;database&gt;',<br/>    warehouse='&lt;warehouse&gt;',<br/>    role='&lt;role&gt;',<br/>    schema='&lt;schema&gt;'<br/>    )</span><span id="a3d4" class="lk ll iq lg b gy lq ln l lo lp">#Create column names for the tables <br/>cols1=['X' + str(x) for x in range(0,64)]<br/>cols1.append('TARGET')</span><span id="e334" class="lk ll iq lg b gy lq ln l lo lp">digits.columns=cols1<br/>X=digits.drop(columns='TARGET')<br/>y=digits['TARGET']<br/>X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1234, test_size=.33)</span><span id="61f7" class="lk ll iq lg b gy lq ln l lo lp">#Create the DataFrame with the features and target for the validation data set<br/>train=pd.concat([X_train,y_train], axis=1)<br/>valid=pd.concat([X_valid,y_valid], axis=1)</span><span id="c7a4" class="lk ll iq lg b gy lq ln l lo lp">#Match the snowflake table column names to the Digits data column names<br/>snowflake_cols=['X' + str(x) + ' integer' for x in range(0,64)]<br/>s = ', '.join(snowflake_cols)</span><span id="0f65" class="lk ll iq lg b gy lq ln l lo lp">#Create the training table in snowflake from the csv<br/>ctx.cursor().execute(<br/>"""CREATE OR REPLACE TABLE<br/>DIGITS_TRAINING_DATA(""" + s + """, target integer)""")</span><span id="0af1" class="lk ll iq lg b gy lq ln l lo lp">#Copy the table into snowflake<br/>write_pandas(ctx, train, 'DIGITS_TRAINING_DATA')</span><span id="c1ec" class="lk ll iq lg b gy lq ln l lo lp">#Create the validation table in snowflake from the csv<br/>ctx.cursor().execute(<br/>"""CREATE OR REPLACE TABLE<br/>DIGITS_VALIDATION_DATA(""" + s + """, target integer)""")</span><span id="10db" class="lk ll iq lg b gy lq ln l lo lp">#Copy the table into snowflake<br/>write_pandas(ctx, valid, 'DIGITS_VALIDATION_DATA')</span></pre><p id="8abf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">建模</strong></p><p id="742f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">连接到Snowpark中的数据:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="f881" class="lk ll iq lg b gy lm ln l lo lp">#Create snowpark session to connect to saved tables. <br/>def create_session_object():<br/>   connection_parameters = {<br/>      "account": "&lt;account-identifier&gt;",<br/>      "user": "&lt;user&gt;",<br/>      "password": "&lt;password&gt;",<br/>      "role": "&lt;role&gt;",<br/>      "warehouse": "&lt;warehouse&gt;",<br/>      "database": "&lt;database&gt;",<br/>      "schema": "&lt;schema&gt;"<br/>   }<br/>   session = Session.builder.configs(connection_parameters).create()<br/>   print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())<br/>   return session</span><span id="e8f2" class="lk ll iq lg b gy lq ln l lo lp">#Create two sessions, one for pulling the initial data, and one for pushing the udf to snowpark. I've found it tends to fail if I use just one session<br/>session=create_session_object()<br/>session2=create_session_object()</span><span id="9ac4" class="lk ll iq lg b gy lq ln l lo lp">cols=session.table('DIGITS_TRAINING_DATA')<br/>cols.schema.fields</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lt"><img src="../Images/2e8b8c95fa340b68b15d0eea9da6b8ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0Iw1jDMkhYFL3GC41F95w.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="c985" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将数据从雪花带到我们的本地环境:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="cbcb" class="lk ll iq lg b gy lm ln l lo lp">tbl=pd.DataFrame(cols.collect())</span></pre><p id="e9f3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查缺少的值:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="45ca" class="lk ll iq lg b gy lm ln l lo lp">count_nas=pd.DataFrame(tbl.isna().sum())<br/>count_nas[count_nas[0]&gt;0]</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/59d21f2e0de4c4e2931f44da85873f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*u2KjqfmWRqdYmHk7-P_BKQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="927c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果有缺失值，我们可以用以下内容来填充它们:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="afa9" class="lk ll iq lg b gy lm ln l lo lp">tbl=tbl.fillna(0)</span></pre><p id="843e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">分为特征和响应变量:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="6666" class="lk ll iq lg b gy lm ln l lo lp">#This is already our training set so no need to use train_test_split here. <br/>X=tbl.drop(columns='TARGET')<br/>y=tbl['TARGET']</span></pre><p id="2f42" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为所有功能构建一个管道预处理器:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="aa50" class="lk ll iq lg b gy lm ln l lo lp">numeric_features=['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10',<br/>       'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',<br/>       'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30',<br/>       'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40',<br/>       'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50',<br/>       'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60',<br/>       'X61', 'X62', 'X63']</span><span id="652d" class="lk ll iq lg b gy lq ln l lo lp">numeric_cols = Pipeline(steps=[<br/>    ('selector', ColumnSelector(numeric_features))])</span><span id="8ca3" class="lk ll iq lg b gy lq ln l lo lp"># Combine categorical and numerical pipeline with FeatureUnion<br/>preprocessor = FeatureUnion([<br/>    ('select_numeric_cols',numeric_cols)<br/>])</span><span id="7229" class="lk ll iq lg b gy lq ln l lo lp">pipe_feat_un = Pipeline(steps=[('preprocessor', preprocessor)])</span></pre><p id="c0aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您在建模之前有一些变量转换要做，那么您可以使用管道来实现它们，它们将与udf中的模型一起打包。</p><p id="e837" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将轻型gbm模型添加到管线中:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="6181" class="lk ll iq lg b gy lm ln l lo lp">clf = make_pipeline(lgb.LGBMClassifier())<br/>model = make_pipeline(pipe_feat_un, clf)</span></pre><p id="0337" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据训练数据拟合模型:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="c1c2" class="lk ll iq lg b gy lm ln l lo lp">model.fit(X,y)</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lv"><img src="../Images/0fc5bb607e696de7002af448c38798f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kv0_Si8Ms16HYvVe7-x3tg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="0704" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在雪花中将模型保存为udf</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="0daa" class="lk ll iq lg b gy lm ln l lo lp">session2.clear_packages() #Clear out all existing packages</span><span id="31bb" class="lk ll iq lg b gy lq ln l lo lp">session2.clear_imports() #Clear out all existing imports</span><span id="d6f5" class="lk ll iq lg b gy lq ln l lo lp">session2.add_import('/opt/anaconda3/lib/python3.8/site-packages/mlxtend') #Add mlxtend as an import, since it is not available within Snowpark</span><span id="6ec3" class="lk ll iq lg b gy lq ln l lo lp">session2.add_packages('scikit-learn','lightgbm','pandas') #Add these packages to the udf, which exist in Snowpark </span><span id="c06a" class="lk ll iq lg b gy lq ln l lo lp">session2.sql('create stage if not exists MODELSTAGE').collect() #Create a model stage if it does not already exist. </span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/6651548790466e1dde8541d55d58ec72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7TT-ExQ3nENQpvYohiLaiQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="57bf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想调用add_import函数。如果Snowpark中没有您需要的库，您可以很容易地添加它们。这增加了使用Snowpark的灵活性。</p><p id="fb3a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建Python udf:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="e8cc" class="lk ll iq lg b gy lm ln l lo lp"><a class="ae kc" href="http://twitter.com/udf" rel="noopener ugc nofollow" target="_blank">@udf</a>(name='lightgbm_snowpark_digits',is_permanent = True, stage_location = '<a class="ae kc" href="http://twitter.com/MODELSTAGE" rel="noopener ugc nofollow" target="_blank">@MODELSTAGE</a>', replace=True, session=session2)</span><span id="2642" class="lk ll iq lg b gy lq ln l lo lp">def predict_digits(args: list) -&gt; float:<br/>    row = pd.DataFrame([args], columns=['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10',<br/>       'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',<br/>       'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30',<br/>       'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40',<br/>       'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50',<br/>       'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60',<br/>       'X61', 'X62', 'X63'])<br/>    return model.predict(row)</span></pre><p id="b98e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预测的三个选项:</p><ol class=""><li id="69f6" class="lx ly iq kf b kg kh kk kl ko lz ks ma kw mb la mc md me mf bi translated">使用Snowpark使用我们保存的udf进行预测，并将数据带回本地环境:</li></ol><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="535e" class="lk ll iq lg b gy lm ln l lo lp">session2.table('DIGITS_VALIDATION_DATA').select(F.call_udf("lightgbm_snowpark_digits",\<br/>    F.array_construct('X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10',<br/>   'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',<br/>   'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30',<br/>   'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40',<br/>   'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50',<br/>   'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60',<br/>   'X61', 'X62', 'X63')).alias('DIGITS_VALIDATION_DATA_PREDICTION')).collect()</span></pre><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/5a9dac6b36a85653aae594dd4e3a2b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x4Ktoj1hMeYXPAkeUbx1Mw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="7009" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.使用Snowpark使用我们保存的udf进行预测，并将输出保存为雪花中的一个表:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="beb3" class="lk ll iq lg b gy lm ln l lo lp">session2.table('DIGITS_VALIDATION_DATA').select(F.call_udf("lightgbm_snowpark_digits",\<br/>    F.array_construct('X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10',<br/>   'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20',<br/>   'X21', 'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30',<br/>   'X31', 'X32', 'X33', 'X34', 'X35', 'X36', 'X37', 'X38', 'X39', 'X40',<br/>   'X41', 'X42', 'X43', 'X44', 'X45', 'X46', 'X47', 'X48', 'X49', 'X50',<br/>   'X51', 'X52', 'X53', 'X54', 'X55', 'X56', 'X57', 'X58', 'X59', 'X60',<br/>   'X61', 'X62', 'X63')).alias('DIGITS_VALIDATION_DATA_PREDICTION')).write.mode('overwrite').saveAsTable('light_gbm_snowpark_digits_validation')</span><span id="340e" class="lk ll iq lg b gy lq ln l lo lp">#The array construct is how Snowflake passes in the data to the udf as a single column array of all the data, similar to Spark's feature vector format.  </span></pre><p id="b5da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Snowpark中连接到的仓库、数据库和模式中，您现在可以在Snowflake中看到保存的表。</p><p id="48ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.在雪花中使用sql代码调用udf，然后在雪花中对表中的数据进行预测:</p><pre class="lb lc ld le gt lf lg lh li aw lj bi"><span id="db12" class="lk ll iq lg b gy lm ln l lo lp">select lightgbm_snowpark_digits(array_construct(X0, X1, X2, X3, X4, X5, X6, X7, X8, X9, X10,<br/> X11, X12, X13, X14, X15, X16, X17, X18, X19, X20,<br/> X21, X22, X23, X24, X25, X26, X27, X28, X29, X30,<br/> X31, X32, X33, X34, X35, X36, X37, X38, X39, X40,<br/> X41, X42, X43, X44, X45, X46, X47, X48, X49, X50,<br/> X51, X52, X53, X54, X55, X56, X57, X58, X59, X60,<br/> X61, X62, X63)) from ”DIGITS_VALIDATION_DATA”;</span></pre><p id="1a66" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望您喜欢这篇快速指南，它讲述了如何训练一个本地模型，将其打包成一个udf，使用Snowpark将该udf上传到Snowflake，然后使用Snowpark或Snowflake对该数据进行预测。</p><p id="d5d4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考文献:</strong></p><p id="ad79" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">阿尔帕丁和凯纳克..(1998).手写数字的光学识别。UCI机器学习知识库。</p></div></div>    
</body>
</html>