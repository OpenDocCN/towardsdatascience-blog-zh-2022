<html>
<head>
<title>Why Not Use CNN to Extract Features?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么不用CNN提取特征？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-not-use-cnn-to-extract-features-1f18341bee8#2022-06-14">https://towardsdatascience.com/why-not-use-cnn-to-extract-features-1f18341bee8#2022-06-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b06b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何发现数据中的意外模式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3f6572ce41c66dc12f6a3b6ac06d640b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sgtGLhZ68VCIzAkTELJ6kg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">潜在空间图示例(图片由作者提供)</p></figure><p id="c957" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">意外中有美。</p><p id="5d07" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">就在你认为你已经想通了所有事情的时候，一些新的事情突然出现，让你大吃一惊。数据分析也是如此。当你查看数据集，试图找到模式和趋势时，有时你会遇到一些不太有意义的东西。这就是异常检测的用武之地。</p><p id="b62f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">异常检测是识别数据中异常模式的过程。这些异常模式可能是不符合正常趋势或行为的任何东西，它们可能是由各种各样的事情引起的，例如数据收集中的错误、异常值，甚至是恶意活动。异常检测非常重要，因为它可以帮助您发现数据中的问题，否则您将无法发现这些问题。</p><p id="a903" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">异常检测的方法有很多种，但是在这篇博文中，我们将关注一种特殊的方法:流形学习。流形学习是一种寻找高维数据的低维表示的技术。</p><h1 id="0d7c" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">自动编码器</h1><p id="72ea" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">自动编码器是一种人工神经网络，分为两个主要部分:编码器网络和解码器网络。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/c1a2e95095e6764b80d1b48a1acaf529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YgiZaTACxLe8zYKXqBB5ow.png"/></div></div></figure><p id="c964" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个部分执行以下操作:</p><ol class=""><li id="ef45" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt mx my mz na bi translated"><strong class="la iu">编码器</strong> <strong class="la iu">网络:</strong>在一个叫做潜在空间的低维空间中减少一个高维输入。</li><li id="181e" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt mx my mz na bi translated"><strong class="la iu">解码器网络:</strong>将潜在空间映射成输入图像的表示。</li></ol><p id="df14" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自动编码器属于非监督学习技术的范畴，因为数据不需要有标签。编码器减少输入数据的维数，解码器从潜在空间再现输入，并且两个网络被优化以减少输入和输出数据之间的差异。</p><p id="98aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">编码器和解码器网络可以被设计为服务于特定的任务。在图像的情况下，我们通常使用我们训练的卷积神经网络(CNN ),以便减少输入X和其重构输出X '之间的均方误差(MSE ),即</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/fe1a3761a7e7553b796592c27747f52a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CCS7GaVNEwPy_Ege1YR_xA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输入X与其重构输出X '之间的均方误差</p></figure><p id="1946" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自动编码器的常见使用案例有:</p><ul class=""><li id="4d1e" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt nh my mz na bi translated">维度缩减</li><li id="61ba" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated">图像压缩</li><li id="36ef" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated">数据去噪</li><li id="67d5" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated">异常检测</li></ul><p id="2b0b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于后者，经典方法侧重于通过查看输入与其重建版本之间的差异来发现异常。假设当输入类似于训练数据集时，自动编码器表现良好，但是在异常周围产生高重建误差。为了使用这种方法，我们用无异常数据训练自动编码器，并观察自动编码器的输入和输出之间的差异。</p><p id="93e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一种可能性是确保模型学习潜在空间的有意义的表示，并直接在这个低维空间中发现异常。这就是拉普拉斯自动编码器的用武之地。</p><blockquote class="ni nj nk"><p id="4f32" class="ky kz nl la b lb lc ju ld le lf jx lg nm li lj lk nn lm ln lo no lq lr ls lt im bi translated">但是首先，我们必须建立一个K-最近邻图来训练拉普拉斯自动编码器。</p></blockquote><h1 id="6a0a" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">k-最近邻图</h1><p id="0d47" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">k-最近邻图(k-NNG)是每个节点与其最近邻相连的图。例如，在下图中，每个节点都连接到其三个最近的点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/72d0bf46563201745aa74a1f8cd05fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vGu0qWjyWg57xQyB2g3dPg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">k-NN图形草图(图片由作者提供)</p></figure><p id="9fc7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欧几里德范数可能是最直观的接近度度量，因为它给出了两点之间的最短距离。可以根据应用选择其他流行的距离度量，如<a class="ae nq" rel="noopener" target="_blank" href="/9-distance-measures-in-data-science-918109d069fa">闵可夫斯基、曼哈顿、汉明或余弦</a>。</p><p id="2d4a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于高维输入，如图片，我们需要选择一个距离度量来衡量图像之间的相似性，如结构相似性指数(SSIM)或基于梯度方向直方图(HOG)。</p><p id="b6ab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，我们可以使用HOG描述符，并用Wasserstein度量或卡方距离计算两个直方图之间的距离。</p><p id="ad01" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">选择度量标准时，我们需要记住，一个好的距离度量标准应该是:</p><ul class=""><li id="27a8" class="ms mt it la b lb lc le lf lh mu ll mv lp mw lt nh my mz na bi translated"><strong class="la iu">信息量</strong>:距离可以直接翻译为相似程度</li><li id="9c9e" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated"><strong class="la iu">反身</strong>:从“A到B”和“B到A”的距离相等</li><li id="4dda" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated"><strong class="la iu">灵敏</strong>:距离变化时变化平滑</li><li id="6203" class="ms mt it la b lb nb le nc lh nd ll ne lp nf lt nh my mz na bi translated"><strong class="la iu">有界</strong>:指标落在受限范围内</li></ul><h1 id="9994" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">拉普拉斯自动编码器</h1><blockquote class="ni nj nk"><p id="382c" class="ky kz nl la b lb lc ju ld le lf jx lg nm li lj lk nn lm ln lo no lq lr ls lt im bi translated">使用自动编码器时，最大的挑战是确保模型实际学习潜在空间的有意义的表示。</p></blockquote><p id="7d6b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">拉普拉斯自动编码器也使用编码器-解码器结构，但是区别在于用于训练两个网络的损失函数。</p><p id="b484" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">仍然训练自动编码器，以便减少输入和其重构输出之间的误差，但是在损失函数中增加了正则化项，以便在高维和低维之间保持相同的邻居。这意味着输入空间中的接近数据点将在潜在空间中保持接近。</p><p id="cb0e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了构建拉普拉斯自动编码器，我们首先必须在输入数据上构建KNN图，并且在损失函数上添加正则化项，一旦相同的邻居被映射到潜在空间中，该正则化项鼓励保持相同的邻居。</p><p id="371c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从KNN图中，我们导出了一个权重矩阵(W ),当Xi和Xj之间的距离很大时，它具有小的W(i，j ),而当Xi和Xj之间的距离很小时，它具有大的W(I，j)。正则化函数定义如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/63518c74708492a23e0fbf57248c2739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*osuEvTwgDQ8bmTNPeEl7CQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉普拉斯自动编码器的正则化函数</p></figure><p id="ccdc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中Zi和Zj分别表征来自输入Xi和Xj的潜在空间中的映射点。第一个参数(λ)是正则化权重，我们可以将其作为模型的超参数进行调整。</p><p id="35d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">拉普拉斯自动编码器旨在优化的全损失函数定义如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/ac75b1c4d345ef9c9b5cb2317f0ec7b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MExkNw2ItzeGBdO2Ch797w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉普拉斯自动编码器的损失函数</p></figure><h1 id="6539" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">最后的话</h1><p id="2cd7" class="pw-post-body-paragraph ky kz it la b lb mm ju ld le mn jx lg lh mo lj lk ll mp ln lo lp mq lr ls lt im bi translated">那么，当你的数据不太符合模型的时候，你能做什么呢？</p><p id="4dc5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用卷积神经网络(CNN)来查找数据中的意外模式。CNN非常适合从图像中提取特征，并已被证明在发现传统方法难以检测的模式方面非常有效。</p><p id="6f9d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用非监督方法相对于监督等效方法的主要优势在于，我们不需要标记任何数据，这是一项非常昂贵的任务。权衡的结果是，我们可能检测到不是异常的模式，而是数据集固有的模式。</p><p id="024a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你喜欢这个教程，并发现它很有用。如果你有任何问题或意见，欢迎在下面发表。</p></div><div class="ab cl nt nu hx nv" role="separator"><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny nz"/><span class="nw bw bk nx ny"/></div><div class="im in io ip iq"><p id="8bbb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">好奇想了解更多关于Anthony的工作和项目吗？在<a class="ae nq" href="https://medium.com/@anthonycvn" rel="noopener">媒体</a>、<a class="ae nq" href="https://www.linkedin.com/in/anthonycavin/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae nq" href="https://twitter.com/Anthony66333223" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注他。</p><p id="828a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="nl">需要技术写手？将您的请求发送到</em><a class="ae nq" href="https://amigocci.io/blog/mlops-at-medium-scale/" rel="noopener ugc nofollow" target="_blank"><em class="nl">https://amigo CCI . io</em></a><em class="nl">。</em></p></div></div>    
</body>
</html>