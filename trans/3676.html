<html>
<head>
<title>Machine Learning and Rust (Part 4): Neural Networks in Torch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习与Rust(第四部分):Torch中的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-and-rust-part-4-neural-networks-in-torch-85ee623f87a#2022-08-16">https://towardsdatascience.com/machine-learning-and-rust-part-4-neural-networks-in-torch-85ee623f87a#2022-08-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6841" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们可以在Rust中使用PyTorch吗？什么是锈绑定？tch-rs是什么？Rust中的神经网络研究</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5f227f81592faeedc4780988cf7ae457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cqFevxUiYHk0zJD9IXtu4Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">乔尔·菲利普在<a class="ae ky" href="https://unsplash.com/photos/RFDP7_80v5A" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的图片</p></figure><p id="101e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自从我们上次看到Rust及其在机器学习中的应用已经有一段时间了——请向下滚动到底部，查看以前关于ML和Rust的教程。今天我将向大家介绍Rust中的神经网络。存在一个铁锈火炬，它允许我们创建任何我们想要的神经网络。捆绑是焊炬落地的关键。绑定允许创建<em class="lv">外部函数接口</em>或FFI，这在Rust和用语言编写的函数/代码之间建立了一座桥梁。<a class="ae ky" href="https://doc.rust-lang.org/nomicon/ffi.html#calling-rust-code-from-c" rel="noopener ugc nofollow" target="_blank">在Rust nomicon </a>中可以找到很好的例子</p><p id="5292" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要用C和C++创建绑定，我们可以使用bindgen，一个由<a class="ae ky" href="https://github.com/rust-lang/rust-bindgen" rel="noopener ugc nofollow" target="_blank">自动生成Rust FFI </a>的库。从绑定到PyTorch的C++ api，<a class="ae ky" href="https://github.com/LaurentMazare/tch-rs" rel="noopener ugc nofollow" target="_blank"> Laurent Mazare </a>已经帮助Rust社区拥有了一个Rustacean版本的PyTorch。正如GitHub页面所说，tch在C++ libtorch周围提供了薄薄的包装。最大的好处是，这个库和原来的严格相似，所以没有学习障碍需要克服。<a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/main/src/nn/linear.rs" rel="noopener ugc nofollow" target="_blank">核心代码相当易读。</a></p><h1 id="65f9" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">初始化和线性:让我们学习巨人肩膀上的铁锈</h1><p id="aeaf" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">首先，我们来看一下代码。这是进一步了解Rust基础设施的最佳起点。</p><p id="13ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，为了对Rust FFI有所了解，我们可以查看这些文件。其中大部分是自动生成的，而Laurent和他的同事们已经编写了大量代码，将c++ Torch API与Rust连接起来。</p><p id="64f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面，我们就可以开始阅读<code class="fe mt mu mv mw b">src</code>中的核心代码了，具体来看一下<code class="fe mt mu mv mw b"><a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/main/src/nn/init.rs:" rel="noopener ugc nofollow" target="_blank">init.rs</a></code>。在定义了一个<code class="fe mt mu mv mw b">enum Init </code>之后，有一个公共函数<code class="fe mt mu mv mw b">pub fn f_init </code>，它匹配输入初始化方法并返回一个权重张量和一个偏差张量。我们可以学习C中反映<code class="fe mt mu mv mw b">switch</code>的<code class="fe mt mu mv mw b">match</code>和Python 3.10中的<code class="fe mt mu mv mw b">match</code>的用法。权重和偏差张量通过随机、统一、明凯或正交方法初始化(图1)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图Rust中的匹配大小写，它反映了C中的switch和Python 3.10中的match</p></figure><p id="2406" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，对于类型<code class="fe mt mu mv mw b">enum Init</code>，我们有了<a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/a022da9861efbe66a4920d318166341c3a60be9e/src/nn/init.rs#L82" rel="noopener ugc nofollow" target="_blank">方法实现</a> <code class="fe mt mu mv mw b"><a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/a022da9861efbe66a4920d318166341c3a60be9e/src/nn/init.rs#L82" rel="noopener ugc nofollow" target="_blank">impl Init</a></code> <a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/a022da9861efbe66a4920d318166341c3a60be9e/src/nn/init.rs#L82" rel="noopener ugc nofollow" target="_blank">。</a>实现的方法是一个setter <code class="fe mt mu mv mw b">pub fn set(self, tensor: &amp;mut Tensor)</code>，这是一个很好的例子来进一步理解Rust中所有权和借用的概念:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图init的实现。注意&amp;mut张量，这是解释Rust中借力的一个很好的例子。</p></figure><p id="ce99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://levelup.gitconnected.com/machine-learning-and-rust-part-1-getting-started-745885771bc2" rel="noopener ugc nofollow" target="_blank">我们在第一个教程</a>中谈到了借贷。现在是更好地理解这个概念的时候了。假设我们可以有一个类似的<code class="fe mt mu mv mw b">set</code>函数:</p><pre class="kj kk kl km gt mz mw na nb aw nc bi"><span id="a47d" class="nd lx it mw b gy ne nf l ng nh">pub fn set(self, tensor: Tensor){}</span></pre><p id="717e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在主代码中，我们可以调用这个函数，传递一个张量<code class="fe mt mu mv mw b">Tensor</code>。<code class="fe mt mu mv mw b">Tensor</code>会被设定，我们会很开心。但是，如果我们再次在<code class="fe mt mu mv mw b">Tensor</code>上呼叫<code class="fe mt mu mv mw b">set</code>呢？嗯，我们会遇到错误<code class="fe mt mu mv mw b">value used here after move</code>。这是什么意思？这个错误告诉你你把<code class="fe mt mu mv mw b">Tensor</code>移到了<code class="fe mt mu mv mw b">set</code>。<em class="lv"> A </em> <code class="fe mt mu mv mw b"><em class="lv">move</em></code> <em class="lv">表示您已经将所有权</em>转让给了<code class="fe mt mu mv mw b">set</code>中的<code class="fe mt mu mv mw b">self</code>，当您再次调用<code class="fe mt mu mv mw b">set(self, tensor: Tensor)</code>时，您希望将所有权归还给<code class="fe mt mu mv mw b">Tensor</code>以便再次设置。幸运的是，在Rust中这是不可能的，而在C++中则不同。在Rust中，<em class="lv">一旦一个</em> <code class="fe mt mu mv mw b"><em class="lv">move</em></code> <em class="lv">已经完成，分配给该进程的内存将被释放</em>。因此，我们在这里要做的是<em class="lv">将<code class="fe mt mu mv mw b">Tensor</code>的值借用给<code class="fe mt mu mv mw b">set</code>，这样我们就可以保留所有权。为此，我们需要通过引用调用<code class="fe mt mu mv mw b">Tensor</code>，因此<code class="fe mt mu mv mw b">tensor: &amp;Tensor</code>。因为我们预计<code class="fe mt mu mv mw b">Tensor</code>会发生变异，所以我们必须添加<code class="fe mt mu mv mw b">mut</code>以便:<code class="fe mt mu mv mw b">tensor: &amp;mut Tensor</code></em></p><p id="3a0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们可以看到另一个重要的元素，它很简单，使用了<code class="fe mt mu mv mw b">Init</code>类:<code class="fe mt mu mv mw b"><a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/main/src/nn/linear.rs" rel="noopener ugc nofollow" target="_blank">Linear</a></code>，即一个完全连接的神经网络层:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:定义线性结构并为其实现默认配置</p></figure><p id="14c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图3显示了建立一个完全连接的层是多么容易，它由一个权重矩阵<code class="fe mt mu mv mw b">ws_init</code>和偏置矩阵<code class="fe mt mu mv mw b">bs_init</code>组成。重量的默认初始化是通过<code class="fe mt mu mv mw b">super::Init::KaimingUniform</code>完成的，这是我们在上面看到的功能。</p><p id="c1e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后可以使用功能<code class="fe mt mu mv mw b">linear</code>创建主全连接层。正如您在函数签名中看到的，也就是在<code class="fe mt mu mv mw b">&lt;...&gt;</code>之间，有一些有趣的事情(图4)。其一，<a class="ae ky" href="https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html" rel="noopener ugc nofollow" target="_blank"> <em class="lv">一生注释</em> </a> <code class="fe mt mu mv mw b"><a class="ae ky" href="https://doc.rust-lang.org/book/ch10-03-lifetime-syntax.html" rel="noopener ugc nofollow" target="_blank">'a</a></code>。如上所述，Rust会自动识别变量何时超出范围并被释放。<em class="lv">我们可以注释一些变量，让它们有一个特定的生命周期</em>，这样我们就可以决定它们能活多久。标准注释是<code class="fe mt mu mv mw b">'a</code>，其中<code class="fe mt mu mv mw b">'</code>表示寿命参数。需要记住的一件重要事情是，这个签名不会修改函数中的任何内容，但是它告诉函数借用者识别所有那些其生存期可以满足我们所施加的约束的变量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:实现完全连接的神经网络层的功能。在函数签名中，您可以注意到一个生存期注释和一个通用变量T，它从nn::Path借用了一个值</p></figure><p id="c4e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二个参数是<code class="fe mt mu mv mw b">T: Borrow&lt;super::Path&lt;'a&gt;</code>这个注释的意思是:取 <code class="fe mt mu mv mw b"><a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/2c2b4545966be04e8377ffa7f34fe01b9a20acd0/src/nn/var_store.rs#L40" rel="noopener ugc nofollow" target="_blank">var_store.rs</a></code>中指定的<code class="fe mt mu mv mw b">nn::Path</code> <a class="ae ky" href="https://github.com/LaurentMazare/tch-rs/blob/2c2b4545966be04e8377ffa7f34fe01b9a20acd0/src/nn/var_store.rs#L40" rel="noopener ugc nofollow" target="_blank">，把这个类型借用到<code class="fe mt mu mv mw b">T</code>。Rust中的任何类型都可以自由借用为几种不同的类型。该类型将用于定义输入硬件(如GPU)，如您在<code class="fe mt mu mv mw b">vs:T</code>中所见。最后，网络的输入和输出维度与<code class="fe mt mu mv mw b">LinearConfig</code>一起被指定为整数<code class="fe mt mu mv mw b">in_dim: i64, out_dim: i64</code>，用于初始化权重和偏差<code class="fe mt mu mv mw b">c: LinearConfig.</code></a></p><h1 id="146a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">让我们与巨人同行:你在Rust的第一个神经网络</h1><p id="e3db" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">是时候弄脏我们的手玩火炬锈了。让我们使用MNIST数据集建立一个简单的线性神经网络，然后是序列网络，最后是卷积神经网络。一如既往，你可以在我的ML ❤生锈回购上找到所有的材料。 <a class="ae ky" href="https://keras.io/api/datasets/mnist/" rel="noopener ugc nofollow" target="_blank"> Yann LeCun和Corinna Cortes拥有MNIST数据集</a>的版权，并已根据<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/3.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名-类似共享3.0许可证的条款提供。</a></p><h2 id="c8e7" class="nd lx it bd ly ni nj dn mc nk nl dp mg li nm nn mi lm no np mk lq nq nr mm ns bi translated">Rust中的一个简单神经网络</h2><p id="4951" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">和往常一样，新Rust项目的第一步是<code class="fe mt mu mv mw b">cargo new NAME_OF_THE_PROJECT</code>，在这里是<code class="fe mt mu mv mw b">simple_neural_networks</code>。然后，我们可以开始用我们需要的所有包设置<code class="fe mt mu mv mw b">Cargo.toml</code>:我们将使用<code class="fe mt mu mv mw b">mnist</code>、<code class="fe mt mu mv mw b">ndarry</code>，显然还有<code class="fe mt mu mv mw b">tch</code>——图5。我决定使用<code class="fe mt mu mv mw b">mnist</code>提取原始的MNIST数据，这样我们可以看到如何转换和处理数组和张量。请随意使用<code class="fe mt mu mv mw b">tch.</code>中已经存在的<code class="fe mt mu mv mw b">vision</code>资源</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5: Cargo.toml用于建立一个简单的线性神经网络。</p></figure><p id="b157" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用<code class="fe mt mu mv mw b">mnist</code>下载MNIST数据集，使用<code class="fe mt mu mv mw b">ndarray</code>对图像向量执行一些转换，并将它们转换成<code class="fe mt mu mv mw b">tch::Tensor</code>。</p><p id="5051" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们跳到<code class="fe mt mu mv mw b">main.rs</code>代码。简而言之，我们需要:</p><ol class=""><li id="d1ef" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated">下载并提取MNIST图像，并返回用于训练、验证和测试数据的向量。</li><li id="e58b" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">从这些向量中，我们必须执行一些到<code class="fe mt mu mv mw b">Tensor</code>的转换，这样我们就可以使用<code class="fe mt mu mv mw b">tch</code>。</li><li id="b1ec" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated">最后，我们将实现一系列时段，在每个时段中，我们将输入数据乘以神经网络权重矩阵，并执行反向传播来更新权重值。</li></ol><p id="e0e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mt mu mv mw b">mnist</code>自动从<a class="ae ky" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">下载输入文件到</a>这里。我们需要在<code class="fe mt mu mv mw b">Cargo.toml</code>中添加<code class="fe mt mu mv mw b">features = ['download']</code>来激活下载功能。下载文件后，提取原始数据<code class="fe mt mu mv mw b">download_and_extract()</code>，并细分为训练集、验证集和测试集。注意，主函数不会返回任何东西，所以您需要在代码末尾指定<code class="fe mt mu mv mw b">-&gt; Results&lt;(), Box&lt;dyn, Error&gt;&gt;</code>和<code class="fe mt mu mv mw b">Ok(())</code>(图6)</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6:从mnist::MnistBuilder下载、提取和创建训练、验证和测试集。</p></figure><p id="ea2d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，代码的第一件事:将一个数组转换成<code class="fe mt mu mv mw b">Tensor.</code>，<code class="fe mt mu mv mw b">mnist</code>的输出数据是<code class="fe mt mu mv mw b">Vec&lt;u8&gt;</code>。训练向量结构具有<code class="fe mt mu mv mw b">TRAIN_SIZE</code>个图像，其尺寸是<code class="fe mt mu mv mw b">HEIGHT</code>乘以<code class="fe mt mu mv mw b">WIDTH</code>。这三个参数可以指定为<code class="fe mt mu mv mw b">usize</code>类型，与输入数据向量一起，可以传递给<code class="fe mt mu mv mw b">image_to_tensor</code>函数，如图7所示，返回<code class="fe mt mu mv mw b">Tensor</code></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7: image_to_tensor函数，给定输入数据向量、图像数量、高度和宽度，我们将返回tch::Tensor</p></figure><p id="136b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输入的<code class="fe mt mu mv mw b">Vec&lt;u8&gt;</code>数据可以用<code class="fe mt mu mv mw b">from_shape_vec</code>整形到<code class="fe mt mu mv mw b">Array3</code>，数值被归一化并转换到<code class="fe mt mu mv mw b">f32</code>，即<code class="fe mt mu mv mw b">.map(|x| *x as f32/256.0)</code>。从一个数组很容易建立一个火炬张量，如第14行所示。对于我们的训练数据，输出张量大小为<code class="fe mt mu mv mw b">dim1 x (dim2*dim3)</code>，设置<code class="fe mt mu mv mw b">TRAIN_SIZE=50'000</code>、<code class="fe mt mu mv mw b">HEIGHT=28</code>和<code class="fe mt mu mv mw b">WIDTH=28</code>，输出训练张量大小为<code class="fe mt mu mv mw b">50'000 x 784</code>。</p><p id="f911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似地，我们将标签转换为张量，其大小将为<code class="fe mt mu mv mw b">dim1</code> —因此对于训练标签，我们将有一个<code class="fe mt mu mv mw b">50'000</code>长张量<a class="ae ky" href="https://github.com/Steboss/ML_and_Rust/blob/aa7d495c4a2c7a416d0b03fe62e522b6225180ab/tutorial_3/simple_neural_networks/src/main.rs#L42" rel="noopener ugc nofollow" target="_blank">https://github . com/ste boss/ML _ and _ Rust/blob/aa7d 495 C4 a2 C7 a 416d 0b 03 Fe 62 e 522 b 6225180 ab/tutorial _ 3/simple _ neural _ networks/src/main . RS # L42</a></p><p id="9405" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在准备开始处理线性神经网络。在权重和偏差矩阵的零初始化之后:</p><pre class="kj kk kl km gt mz mw na nb aw nc bi"><span id="6745" class="nd lx it mw b gy ne nf l ng nh">let mut ws = Tensor::zeros(&amp;[(HEIGHT*WIDTH) as i64, LABELS], kind::FLOAT_CPU).set_requires_grad(true);</span><span id="bbc4" class="nd lx it mw b gy oh nf l ng nh">let mut bs = Tensor::zeros(&amp;[LABELS], kind::FLOAT_CPU).set_requires_grad(true);</span></pre><p id="e49b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类似于PyTorch实现，我们可以开始计算神经网络权重。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8:主要训练功能。对于N _ EPOCHS，我们在输入数据和权重及偏差之间执行matmul。计算每个历元的精确度和损失。如果两个连续损失之间的差异小于三，我们停止学习迭代。</p></figure><p id="8187" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图8示出了运行线性神经网络训练的主例程。首先，我们可以用<code class="fe mt mu mv mw b">'train</code>给最外层的for循环命名，在这种情况下，撇号不是生命期的指示器，而是循环名的指示器。我们正在监控每个时期的损失。如果两个连续的损失差小于<code class="fe mt mu mv mw b">THRES</code>，当我们达到收敛时，我们可以停止最外面的循环——你可以不同意，但目前让我们保持它:)整个实现非常容易阅读，只是在从计算的<code class="fe mt mu mv mw b">logits</code>中提取精度时需要注意一点，工作就完成了:)</p><p id="93cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当你准备好了，你可以直接在我的2019年MacBook Pro上用<code class="fe mt mu mv mw b">cargo run</code>运行整个<code class="fe mt mu mv mw b">main.rs</code>代码，2.6GHZ，6核英特尔酷睿i7，16GB RAM，计算时间不到一分钟，在65个周期后达到90.45%的测试准确率</p><h2 id="666e" class="nd lx it bd ly ni nj dn mc nk nl dp mg li nm nn mi lm no np mk lq nq nr mm ns bi translated">顺序神经网络</h2><p id="7b23" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在我们来看顺序神经网络实现<a class="ae ky" href="https://github.com/Steboss/ML_and_Rust/tree/master/tutorial_3/custom_nnet" rel="noopener ugc nofollow" target="_blank">https://github . com/ste boss/ML _ and _ Rust/tree/master/tutorial _ 3/custom _ nnet</a></p><p id="d158" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图9解释了顺序网络是如何建立的。首先，我们需要导入<code class="fe mt mu mv mw b">tch::nn::Module</code>。然后我们可以为神经网络<code class="fe mt mu mv mw b">fn net(vs: &amp;nn::Path) -&gt; impl Module</code>创建一个函数。该函数返回<code class="fe mt mu mv mw b">Module</code>的实现，并接收作为输入的<code class="fe mt mu mv mw b">nn::Path</code>，该输入是关于用于运行网络的硬件的结构信息(例如CPU或GPU)。然后，时序网络被实现为输入大小为<code class="fe mt mu mv mw b">IMAGE_DIM</code>和<code class="fe mt mu mv mw b">HIDDEN_NODES</code>节点的线性层、<code class="fe mt mu mv mw b">relu</code>和具有<code class="fe mt mu mv mw b">HIDDEN_NODES</code>输入和<code class="fe mt mu mv mw b">LABELS</code>输出的最终线性层的组合。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9:顺序神经网络的实现</p></figure><p id="ece1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在主代码中，我们将神经网络创建称为:</p><pre class="kj kk kl km gt mz mw na nb aw nc bi"><span id="e344" class="nd lx it mw b gy ne nf l ng nh">// set up variable store to check if cuda is available<br/>let vs = nn::VarStore::new(Device::cuda_if_available());</span><span id="e4cb" class="nd lx it mw b gy oh nf l ng nh">// set up the seq net<br/>let net = net(&amp;vs.root());</span><span id="ef77" class="nd lx it mw b gy oh nf l ng nh">// set up optimizer<br/>let mut opt = nn::Adam::default().build(&amp;vs, 1e-4)?;</span></pre><p id="49ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">还有一个Adam优化器— <a class="ae ky" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=question+mark+in+Rust&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank">记住</a> <code class="fe mt mu mv mw b"><a class="ae ky" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=question+mark+in+Rust&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank">opt</a></code> <a class="ae ky" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=question+mark+in+Rust&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank"> </a>末尾的 <code class="fe mt mu mv mw b"><a class="ae ky" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=question+mark+in+Rust&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank">?</a></code> <a class="ae ky" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=question+mark+in+Rust&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank">，否则你会返回一个<code class="fe mt mu mv mw b">Result&lt;&gt;</code>类型，它没有我们需要的功能。在这一点上，我们可以简单地按照PyTorch的过程来做，所以我们将设置一些epochs，并用优化器的<code class="fe mt mu mv mw b">backward_step</code>方法和给定的<code class="fe mt mu mv mw b">loss</code>来执行反向传播</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10:针对给定的历元数N_EPOCHS训练序列神经网络，并使用opt.backward_step(&amp;loss)设置反向推进；</p></figure><h2 id="bb5b" class="nd lx it bd ly ni nj dn mc nk nl dp mg li nm nn mi lm no np mk lq nq nr mm ns bi translated">卷积神经网络</h2><p id="367d" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我们今天的最后一步是处理卷积神经网络:<a class="ae ky" href="https://github.com/Steboss/ML_and_Rust/tree/master/tutorial_3/conv_nnet/src" rel="noopener ugc nofollow" target="_blank">https://github . com/ste boss/ML _ and _ Rust/tree/master/tutorial _ 3/conv _ nnet/src</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图11:卷积神经网络结构</p></figure><p id="417e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，你可以注意到我们现在使用的是<code class="fe mt mu mv mw b">nn::ModuleT</code>。这个模块特征是附加训练参数。这通常用于区分训练和评估之间的网络行为。然后，我们可以开始定义网络<code class="fe mt mu mv mw b">Net</code>的结构，它由两个conv2d层和两个线性层组成。<code class="fe mt mu mv mw b">Net</code>的实现陈述了网络是如何构成的，两个卷积层的步幅分别为1和32，填充为32和64，膨胀分别为5和5。线性层接收1024的输入，最后一层返回10个元素的输出。最后，我们需要为<code class="fe mt mu mv mw b">Net</code>定义<code class="fe mt mu mv mw b">ModuleT</code>实现。这里，前进步骤<code class="fe mt mu mv mw b">forward_t</code>接收一个额外的布尔参数<code class="fe mt mu mv mw b">train</code>，它将返回一个<code class="fe mt mu mv mw b">Tensor</code>。前一步应用卷积层，以及<code class="fe mt mu mv mw b">max_pool_2d</code>和<code class="fe mt mu mv mw b">dropout</code>。dropout步骤只是出于训练目的，所以它与布尔值<code class="fe mt mu mv mw b">train</code>绑定在一起。</p><p id="6e59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了提高训练性能，我们将从输入张量中分批训练conv层。为此，您需要实现一个函数来将输入张量分成随机批次:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图12:为从图像输入池创建批次生成随机索引</p></figure><p id="5d62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mt mu mv mw b">generate_random_index</code>获取输入图像数组和我们想要分割的批次大小。它创建一个随机整数的输出张量<code class="fe mt mu mv mw b">::randint</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图13:卷积神经网络的训练时期。对于每个时期，我们通过输入数据集进行批处理，并训练计算交叉熵的模型。</p></figure><p id="4bdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图13显示了训练步骤。输入数据集被分成<code class="fe mt mu mv mw b">n_it</code>批，其中<code class="fe mt mu mv mw b">let n_it = (TRAIN_SIZE as i64)/BATCH_SIZE;</code>。对于每一批，我们计算网络损耗并用<code class="fe mt mu mv mw b">backward_step</code>反向传播误差。</p><p id="2461" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我的本地笔记本电脑上运行卷积网络需要几分钟，实现了97.60%的验证准确率。</p><h1 id="7e96" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">结论</h1><p id="293a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">你成功了！我为你骄傲！今天我们来了解一下<code class="fe mt mu mv mw b">tch</code>以及如何设置一些计算机视觉实验。我们看到了初始化和线性层代码的内部结构。我们回顾了Rust中关于借用的一些重要概念，并了解了什么是终生注释。然后，我们开始实现一个简单的线性神经网络、一个顺序神经网络和一个卷积神经网络。在这里，我们学习了如何处理如何输入图像并将其转换为<code class="fe mt mu mv mw b">tch::Tensor.</code>，我们看到了如何使用模块<code class="fe mt mu mv mw b">nn:Module</code>作为一个简单的神经网络，来实现一个向前的步骤，我们还看到了它的扩展<code class="fe mt mu mv mw b">nn:ModuleT</code>。对于所有这些实验，我们看到了两种执行反向传播的方法，要么使用<code class="fe mt mu mv mw b">zero_grad</code>和<code class="fe mt mu mv mw b">backward</code>，要么直接将<code class="fe mt mu mv mw b">backward_step</code>应用于优化器。</p><p id="3e9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望你喜欢我的教程:)敬请期待下一集。</p></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><h1 id="6a40" class="lw lx it bd ly lz op mb mc md oq mf mg jz or ka mi kc os kd mk kf ot kg mm mn bi translated">支持我的写作:</h1><p id="d513" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><em class="lv">通过我的推荐链接加入Medium来支持我的写作和项目:</em></p><div class="ou ov gp gr ow ox"><a href="https://stefanobosisio1.medium.com/membership" rel="noopener follow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">通过我的推荐链接加入Medium—Stefano Bosisio</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">阅读Stefano Bosisio(以及媒体上成千上万的其他作家)的每一个故事。为什么支持我？1)关于人工智能的文章…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">stefanobosisio1.medium.com</p></div></div><div class="pg l"><div class="ph l pi pj pk pg pl ks ox"/></div></div></a></div><p id="e316" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有任何问题或意见，请随时给我发电子邮件，地址是:stefanobosisio1@gmail.com，或者直接在Medium这里。</p><h1 id="498e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">以前关于Rust和ML的教程</h1><div class="ou ov gp gr ow ox"><a href="https://levelup.gitconnected.com/machine-learning-and-rust-part-1-getting-started-745885771bc2" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">机器学习与Rust(第1部分):入门！</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">这是Rust和ML系列教程的第一部分。今天，让我们来了解关于生锈的5个基本问题！</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pg l"><div class="pm l pi pj pk pg pl ks ox"/></div></div></a></div><div class="ou ov gp gr ow ox"><a href="https://levelup.gitconnected.com/machine-learning-and-rust-part-2-linear-regression-d3b820ed28f9" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">机器学习与Rust(第二部分):线性回归</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">在本教程中:如何在Rust中阅读一个csv？如何实现线性回归？让我们把手弄脏，学习…</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pg l"><div class="pn l pi pj pk pg pl ks ox"/></div></div></a></div><div class="ou ov gp gr ow ox"><a href="https://levelup.gitconnected.com/machine-learning-and-rust-part-3-smartcore-dataframe-and-linear-regression-10451fdc2e60" rel="noopener  ugc nofollow" target="_blank"><div class="oy ab fo"><div class="oz ab pa cl cj pb"><h2 class="bd iu gy z fp pc fr fs pd fu fw is bi translated">机器学习和Rust(第三部分):智能核心、数据框架和线性回归</h2><div class="pe l"><h3 class="bd b gy z fp pc fr fs pd fu fw dk translated">在本教程中:我们能拥有铁锈中的熊猫吗？什么是smartcore？</h3></div><div class="pf l"><p class="bd b dl z fp pc fr fs pd fu fw dk translated">levelup.gitconnected.com</p></div></div><div class="pg l"><div class="po l pi pj pk pg pl ks ox"/></div></div></a></div></div></div>    
</body>
</html>