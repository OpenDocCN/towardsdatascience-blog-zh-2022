<html>
<head>
<title>Training RL agents in stable-baselines3 is easy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在稳定基线 3 中培训 RL 代理很容易</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-rl-agents-in-stable-baselines3-is-easy-9d01be04c9db#2022-02-03">https://towardsdatascience.com/training-rl-agents-in-stable-baselines3-is-easy-9d01be04c9db#2022-02-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/99781f77b09e22fa53eb7a50e156f3e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*D229BGsHHYFEpryeJ00Pkg.gif"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者 GIF)</p></figure><h1 id="6c1b" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">动机</h1><p id="e834" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">大约 2 年以来，强化学习成了我的一个爱好。我特别喜欢在游戏上训练代理人。这些年来，我面临的一个大问题是缺乏一个可靠的 python 强化学习库，我不得不自己编写最先进的算法，或者在 github 上找到一个好的资源。对我来说，在我发现稳定基线 3 库的那一天，一切都变了。</p><h1 id="aa35" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">你能期待什么</h1><p id="7998" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我将带你了解 stable-baselines3 和 openai gym 的整个安装过程。然后，我将向您展示如何在横拉杆环境中训练一个代理，并在屏幕上显示一些经过训练的代理的运行情况。我还想让你知道保存和加载模型。稳定基线 3 还支持同时在多个环境中进行培训。最后，我将向您展示如何在更复杂的 LunarLander-v2 环境中训练一个近似策略优化(PPO)代理，以及如何在 atari 突破环境中训练一个 A2C 代理。</p><h1 id="8ba0" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">装置</h1><p id="3aa1" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated"><strong class="lb iu">稳定基线 3 </strong>库提供了最重要的强化学习算法。它可以使用 python 包管理器“pip”来安装。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="e19f" class="mg kc it mc b gy mh mi l mj mk">pip install stable-baselines3</span></pre><p id="f944" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">我将使用 openai gym 环境演示这些算法。安装它来跟随。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="b7c9" class="mg kc it mc b gy mh mi l mj mk">pip install gym</span></pre><h1 id="60c1" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">用 cartpole 环境测试算法</h1><h2 id="27e3" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">培训 PPO 代理人</h2><p id="d137" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">稳定基线库包含许多不同的强化学习算法。在下面的代码中，我将展示如何使用近似策略优化算法训练一个可以击败 openai cartpole 环境的代理。</p><figure class="lx ly lz ma gt ju"><div class="bz fp l di"><div class="nb nc l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者代码)</p></figure><p id="b510" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">你可以很容易地将我使用的算法与<a class="ae nd" href="https://stable-baselines3.readthedocs.io/en/master/modules/base.html#" rel="noopener ugc nofollow" target="_blank">稳定基线 3 库</a>提供的任何其他强化学习算法进行交换。你只需要改变第 1 行和第 7 行，用你选择的算法替换 PPO。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/4173791d3ad684b40c0a2da34068a16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XntciyIhCHeW3tcNXliRRQ.png"/></div></div></figure><p id="70a3" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">将策略设置为“<strong class="lb iu"> MlpPolicy </strong>”意味着我们将给出一个<strong class="lb iu">状态向量</strong>作为模型的输入。这里只有两个其他的政策选择。如果您提供<strong class="lb iu">图像</strong>作为输入，请使用“<strong class="lb iu"> CnnPolicy </strong>”。还有用于处理多输入的“多输入策略”。由于 cartpole 环境不能输出图像，稍后我将展示一个“CnnPolicy”在其他体育馆环境中的用例。</p><h2 id="1c20" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">保存和加载模型</h2><p id="413f" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">要保存模型，请使用下面的代码行。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nj"><img src="../Images/5cbb99d50d725f8f79e97dbea4a23674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lSenY2yL37YDIPY8AcMLkA.png"/></div></div></figure><p id="80d4" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">您可以将保存的模型加载回 python 中</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nk"><img src="../Images/2bb994728341da9466ace23c13c91862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uxmHTksJHjYpiY8mGCIWMA.png"/></div></div></figure><p id="2dcc" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">下面的代码展示了为 cartpole 环境训练、保存和加载 PPO 模型的整个过程。请确保仅在训练模型后保存它。</p><figure class="lx ly lz ma gt ju"><div class="bz fp l di"><div class="nb nc l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者代码)</p></figure><h2 id="3d8b" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">多种环境下的平行培训</h2><p id="d67e" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">您还可以非常容易地同时在多个环境中训练一个代理(即使是在 cpu 上训练)。这加快了代理的培训过程。</p><p id="e702" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">我们可以使用 stablebaselines3 库的 make_vec_env 函数创建并行环境。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nl"><img src="../Images/9d75e574e50ace9eb4fb560f487ed810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vNF1Xr1BFVGnEJ3gaVxMcQ.png"/></div></div></figure><p id="2302" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">我们以同样的方式使用它，我们使用了 openai 健身房功能来创建一个新的环境。但是我们告诉函数我们想要创建多少个并行环境。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nm"><img src="../Images/23d0c1b7bece9cfb5dd5a0086f3baf91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N0EYj1dh1g5khy1gD-5HzQ.png"/></div></div></figure><p id="8b64" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">因为您只训练了一个代理，所以您可以像以前一样保存模型。</p><p id="ad51" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">但是与前一个案例的一个重要区别是，当我们测试我们训练有素的代理时，对终端状态的处理。如果 epsiode 在其中一个环境中结束，它会自动重置。在测试之前，代理看起来像这样:</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nn"><img src="../Images/4c6ec627818db80fcbbc3ec06b114b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NZvHBL68oYFgxZb_ombwLA.png"/></div></div></figure><p id="c8f1" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">现在，它变短了:</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi no"><img src="../Images/c5be3350fa48577c40557e77c7fd2ebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qYT3SkrnqhCC8arPnsgTlA.png"/></div></div></figure><p id="61ab" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">以下代码同时在 4 个环境中训练 PPO 代理:</p><figure class="lx ly lz ma gt ju"><div class="bz fp l di"><div class="nb nc l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者代码)</p></figure><h1 id="d801" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用其他健身房环境</h1><p id="3410" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">为了运行大多数其他健身房环境，您必须安装 python 的 Box2D 库。这在 mac 和 linux 上非常容易，但在 windows 上却非常困难。</p><h2 id="cf13" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">安装 Box2D</h2><p id="5887" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">Box2D 是 2D 物理学的开源物理引擎，许多体育馆环境用它来处理物体的碰撞。</p><p id="db53" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated"><strong class="lb iu"><em class="np">Linux/OSX</em>T3】</strong></p><p id="7cba" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">据我所知，在 linux 和 mac 电脑上直接安装 Box2D 没有任何问题。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="c681" class="mg kc it mc b gy mh mi l mj mk">pip install box2d-py</span></pre><p id="5664" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated"><strong class="lb iu"> <em class="np">视窗</em> </strong></p><p id="8bbc" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">在 windows 上，Box2D 环境的安装过程经常会出现问题。然而，我们可以使用 swig 单独安装它。这解决了问题。使用 anaconda 安装 swig 非常简单</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="5863" class="mg kc it mc b gy mh mi l mj mk">conda install swig</span></pre><p id="3289" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">如果不使用 anaconda，可以在这里下载 swig <a class="ae nd" href="http://www.swig.org/Doc1.3/Windows.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="7de7" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">还需要 Microsoft Visual C++ 14.0 或更高版本。如果没有安装，Box2d 安装会失败。因此，请到这里下载最新的 microsoft C++构建工具。</p><div class="nq nr gp gr ns nt"><a href="https://visualstudio.microsoft.com/visual-cpp-build-tools/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">Microsoft C++构建工具- Visual Studio</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">Microsoft C++构建工具通过可脚本化的独立安装程序提供 MSVC 工具集，无需 Visual Studio…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">visualstudio.microsoft.com</p></div></div><div class="oc l"><div class="od l oe of og oc oh jv nt"/></div></div></a></div><p id="c77d" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">您可以在这里安装构建工具。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oi"><img src="../Images/8ecb3ae5101f6216e424b3eedbf8f59c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNyDQRSVrXlNZBrn4P4zvg.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(图片由作者提供)</p></figure><p id="e6de" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">安装完“buildtools”后，打开 visual studio 安装程序(它可能在安装“buildtools”后已经打开)。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi oj"><img src="../Images/0af8649b08dd195e06b4f5103287ca4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RTSrtuEpjhuXbFWzdFxARQ.png"/></div></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(图片由作者提供)</p></figure><p id="dc0b" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">然后可以使用 pip 为 python 安装 Box2D。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="5ef8" class="mg kc it mc b gy mh mi l mj mk">pip install box2d-py</span></pre><h2 id="4152" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">击败 LunarLander-v2</h2><p id="5bae" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我现在将向您展示如何使用 stable_baselines3 库击败 lunarLander-v2 环境。代理人的任务是将着陆舱降落在两个黄色球门柱之间。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/39b6fc83fe5748f504ab01825454d389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*siKXcrO4YqRcDHJSQCA8ew.gif"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者 GIF)</p></figure><p id="3d2e" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">这是一个比 cartpole 环境更复杂的任务。以向量的形式给代理以下信息。</p><ul class=""><li id="7965" class="ol om it lb b lc ml lg mm lk on lo oo ls op lw oq or os ot bi translated">(连续):距离目标位置 X 距离</li><li id="630c" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(连续):距目标位置的 Y 距离</li><li id="c0ce" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(连续):X 速度</li><li id="5fdf" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(连续):Y 速度</li><li id="202b" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(连续):船的角度</li><li id="a0b7" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(连续):船的角速度</li><li id="4293" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(二进制):左腿接地</li><li id="120e" class="ol om it lb b lc ou lg ov lk ow lo ox ls oy lw oq or os ot bi translated">(二进制):右腿接地</li></ul><p id="5ae3" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">所以我们也必须使用<strong class="lb iu"> MlpPolicy </strong>。</p><p id="632a" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">我选择 PPO 算法来训练代理，因为我发现它在 LunarLander 环境中学习速度非常快。代理人花了 200 万步训练才达到平均分数<strong class="lb iu"> 233 </strong>。这场比赛的平均分数为 200 分就被认为失败了。</p><figure class="lx ly lz ma gt ju"><div class="bz fp l di"><div class="nb nc l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者代码)</p></figure><h2 id="190c" class="mg kc it bd kd mq mr dn kh ms mt dp kl lk mu mv kp lo mw mx kt ls my mz kx na bi translated">雅达利突破像素</h2><p id="c9a6" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">现在是时候让我们的代理仅使用屏幕上的像素来解决“雅达利突破”了。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/64b84ff63a20fb28abe0fd920ddb6996.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/1*RNb9OGv8ETh-TYPxOeqDdg.gif"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者 GIF)</p></figure><p id="ea36" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">gym 的标准安装中不包含 breakout 环境，因此您必须安装一个 gym 版本，其中包含 atari 集合。</p><pre class="lx ly lz ma gt mb mc md me aw mf bi"><span id="d6a6" class="mg kc it mc b gy mh mi l mj mk">pip install gym[atari]</span></pre><p id="8b6a" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">仅给定一张图片，代理人无法判断球的速度和方向。使用 VecFrameStack 包装器，我们同时给代理一些帧作为输入，这样他就可以学习球的移动。</p><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi pa"><img src="../Images/02aadcbf7d88d4497a4f86bb9e7c58d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZCiZpXLaiUDAZ90GVyJaxg.png"/></div></div></figure><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi pb"><img src="../Images/67814ac95a35a4571ce45f989770ea20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JhhE_SIZ7rVYVixr3scsdg.png"/></div></div></figure><p id="482c" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">也要意识到一个事实，那就是你现在必须知道使用“<strong class="lb iu"> CnnPolicy </strong>”。我用<strong class="lb iu"> A2C </strong>算法为<strong class="lb iu">500 万时间步长</strong>训练代理，并使用<strong class="lb iu"> 16 个并行环境</strong>。</p><figure class="lx ly lz ma gt ju"><div class="bz fp l di"><div class="nb nc l"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者代码)</p></figure><figure class="lx ly lz ma gt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/99781f77b09e22fa53eb7a50e156f3e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*D229BGsHHYFEpryeJ00Pkg.gif"/></div><p class="jx jy gj gh gi jz ka bd b be z dk translated">(作者 GIF)</p></figure><p id="590f" class="pw-post-body-paragraph kz la it lb b lc ml le lf lg mm li lj lk mn lm ln lo mo lq lr ls mp lu lv lw im bi translated">正如你所看到的，代理人已经学会了在砖块上打洞并在墙后投篮的技巧。然而，它很难射击最后几块砖，因此无法完成游戏。这很可能是因为代理没有在砖块较少的情况下接受过足够的培训。通过增加培训持续时间，代理应该能够战胜环境。</p><h1 id="7a74" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">结论</h1><p id="715a" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">我想花一点时间介绍一下关于稳定基线 3 库的最重要的信息。当您的环境向代理提供一个带有信息的向量时，则使用<strong class="lb iu"> MlpPolicy </strong>。如果它给出完整的图像，则使用<strong class="lb iu"> CnnPolicy </strong>。您可以并行使用多个环境来加速训练。但是他们都训练同样的<strong class="lb iu">一个特工</strong>。有了几千个时间步长的数据，cartpole 环境很容易被击败。LunarLander-v2 环境更加复杂，需要 200 万个时间步才能超越 PPO。雅达利突破将通过像素来解决，这使得它变得更加困难。有了 500 万个时间步长，我几乎可以击败使用 A2C 的环境。</p><h1 id="532e" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">想联系支持我？</h1><p id="24cb" class="pw-post-body-paragraph kz la it lb b lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw im bi translated">LinkedIn<br/><a class="ae nd" href="https://www.linkedin.com/in/vincent-m%C3%BCller-6b3542214/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/vincent-m%C3%BCller-6b3542214/</a><br/>脸书<br/><a class="ae nd" href="https://www.facebook.com/profile.php?id=100072095823739" rel="noopener ugc nofollow" target="_blank">https://www.facebook.com/profile.php?id=100072095823739</a><br/>Twitter<br/><a class="ae nd" href="https://twitter.com/Vincent02770108" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Vincent02770108</a><br/>中型<br/><a class="ae nd" href="https://medium.com/@Vincent.Mueller" rel="noopener">https://medium.com/@Vincent.Mueller</a><br/>成为中型会员并支持我(你的部分会员费直接归我)</p><div class="nq nr gp gr ns nt"><a href="https://medium.com/@Vincent.Mueller/membership" rel="noopener follow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">通过我的推荐链接加入媒体-文森特·米勒</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">medium.com</p></div></div><div class="oc l"><div class="pc l oe of og oc oh jv nt"/></div></div></a></div><h1 id="1c72" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">相关故事</h1><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/deep-q-learning-is-no-rocket-science-e34912f1864"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">深度 Q 学习不是火箭科学</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">用 pytorch 解释和编码的深度 Q 和双 Q 学习</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="pd l oe of og oc oh jv nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/snake-with-policy-gradients-deep-reinforcement-learning-5e6e921db054"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">具有策略梯度的 Snake 深度强化学习</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">策略梯度深度强化学习在蛇游戏中的应用</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="pe l oe of og oc oh jv nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/backpropagation-in-neural-networks-6561e1268da8"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">神经网络中的反向传播</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">从零开始的神经网络，包括数学和 python 代码</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="pf l oe of og oc oh jv nt"/></div></div></a></div><h1 id="5e08" class="kb kc it bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">其他故事</h1><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/how-you-can-use-gpt-j-9c4299dd8526"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">如何使用 GPT J</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">GPT J 解释了 3 种简单的方法，你可以如何访问它</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="pg l oe of og oc oh jv nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/eigenvalues-and-eigenvectors-378e851bf372"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">主成分分析中的特征值和特征向量</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">关于我们的数据，他们告诉了我们什么？</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="ph l oe of og oc oh jv nt"/></div></div></a></div><div class="nq nr gp gr ns nt"><a rel="noopener follow" target="_blank" href="/support-vector-machines-illustrated-b48a32c56388"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd iu gy z fp ny fr fs nz fu fw is bi translated">支持向量机，图解</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">支持向量机背后的直觉和数学</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="pi l oe of og oc oh jv nt"/></div></div></a></div></div></div>    
</body>
</html>