<html>
<head>
<title>Getting Started with PyTorch Image Models (timm): A Practitioner’s Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch图像模型(timm)入门:实践者指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055#2022-02-01">https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055#2022-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c4f0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在自己的培训脚本中使用这个神奇的库</h2></div><p id="9d0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">PyTorch Image Models (timm) 是一个用于最先进的图像分类的库，包含图像模型、优化器、调度器、增强器等等的集合；最近，它被命名为<a class="ae lb" href="https://medium.com/paperswithcode/papers-with-code-2021-a-year-in-review-de75d5a77b8b" rel="noopener">2021年</a>最热门的图书馆！</p><p id="65a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然越来越多的低代码和无代码解决方案使得开始将深度学习应用于计算机视觉问题变得容易，但在我目前作为微软CSE的一部分的角色中，我们经常与希望寻求针对其特定问题定制解决方案的客户接触；利用最新和最大的创新超越这些服务提供的性能水平。由于新的架构和培训技术被引入这个快速发展的领域的速度，无论您是初学者还是专家，都很难跟上最新的实践，并且在处理新的愿景任务时很难知道从哪里开始，以便重现与学术基准中呈现的结果类似的结果。</p><p id="731c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">无论我是从头开始训练，还是对现有模型进行微调以适应新任务，以及希望利用现有组件来加快我的工作流程，timm都是PyTorch中我最喜欢的计算机视觉库之一。然而，尽管timm包含参考<a class="ae lb" href="https://github.com/rwightman/pytorch-image-models/blob/master/train.py" rel="noopener ugc nofollow" target="_blank">培训</a>和<a class="ae lb" href="https://github.com/rwightman/pytorch-image-models/blob/master/validate.py" rel="noopener ugc nofollow" target="_blank">验证</a>脚本，用于再现<a class="ae lb" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>培训结果，并且在官方文档和<a class="ae lb" href="https://fastai.github.io/timmdocs/" rel="noopener ugc nofollow" target="_blank">timm docs项目</a>中包含涵盖核心组件<a class="ae lb" href="https://rwightman.github.io/pytorch-image-models/" rel="noopener ugc nofollow" target="_blank">的文档，但是由于该库提供的特性数量庞大，在定制用例中应用这些特性时，可能很难知道从哪里开始。</a></p><p id="1809" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本指南的目的是从从业者的角度探索timm，重点是如何在定制培训脚本中使用timm中包含的一些功能和组件。重点不是探究这些概念是如何或为什么工作的，或者它们是如何在timm中实现的；为此，在适当的地方会提供原始论文的链接，我会推荐<a class="ae lb" href="https://fastai.github.io/timmdocs/" rel="noopener ugc nofollow" target="_blank"> timmdocs </a>去了解更多关于timm的内部情况。此外，本文决不是详尽的，所选择的领域是基于我使用这个库的个人经验。</p><p id="513d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的所有信息都是基于撰写本文时最近发布的<code class="fe lc ld le lf b">timm==0.5.4</code>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/c604e4b4e5dd0e6c78051cd26a1c65bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*334fgb_3C80Raxrp"/></div></div><p class="ls lt gj gh gi lu lv bd b be z dk translated">图片由<a class="ae lb" href="https://unsplash.com/@cgower" rel="noopener ugc nofollow" target="_blank">克里斯托弗·高尔</a>在<a class="ae lb" href="https://unsplash.com/photos/m_HRfLhgABo" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="d421" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">目录</h1><p id="467b" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">虽然这篇文章可以按顺序阅读，但它也可以作为图书馆特定部分的参考。为了便于导航，下面提供了一个目录。</p><ul class=""><li id="26d1" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><a class="ae lb" href="#b83b" rel="noopener ugc nofollow"> <strong class="kh ir">模型</strong> </a> <a class="ae lb" href="#983b" rel="noopener ugc nofollow"> <br/> </a> - <a class="ae lb" href="#9388" rel="noopener ugc nofollow">定制模型</a>-<br/>-<a class="ae lb" href="#0583" rel="noopener ugc nofollow">特征提取</a>-<br/>-<a class="ae lb" href="#c193" rel="noopener ugc nofollow">导出不同格式</a></li><li id="fa8f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#4cc7" rel="noopener ugc nofollow"> <strong class="kh ir">数据增强</strong></a><strong class="kh ir"><br/></strong>-<a class="ae lb" href="#8549" rel="noopener ugc nofollow">rand augment</a><br/>-<a class="ae lb" href="#e618" rel="noopener ugc nofollow">cut mix和MixUp </a></li><li id="a33e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#c725" rel="noopener ugc nofollow"> <strong class="kh ir">数据集</strong> </a> <br/> - <a class="ae lb" href="#2c65" rel="noopener ugc nofollow">从TorchVision加载数据集</a> <br/> - <a class="ae lb" href="#96e0" rel="noopener ugc nofollow">从TensorFlow数据集加载数据集</a> <br/> - <a class="ae lb" href="#03bd" rel="noopener ugc nofollow">从本地文件夹加载数据集</a><br/>-<a class="ae lb" href="#a4d1" rel="noopener ugc nofollow">image dataset类</a></li><li id="7f9d" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#18f9" rel="noopener ugc nofollow"> <strong class="kh ir">优化器</strong> </a> <br/> - <a class="ae lb" href="#5e2d" rel="noopener ugc nofollow">用法举例</a>-<br/>-<a class="ae lb" href="#0afa" rel="noopener ugc nofollow">前瞻</a></li><li id="323a" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#50f2" rel="noopener ugc nofollow"> <strong class="kh ir">调度器</strong> </a> <strong class="kh ir"> <br/> </strong> - <a class="ae lb" href="#9ad3" rel="noopener ugc nofollow">使用示例</a> <br/> - <a class="ae lb" href="#65e2" rel="noopener ugc nofollow">调整学习率调度器</a></li><li id="7c47" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#429c" rel="noopener ugc nofollow"> <strong class="kh ir">指数移动平均模型</strong> </a></li><li id="232b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="#901e" rel="noopener ugc nofollow"> <strong class="kh ir">把这一切联系在一起！</strong> </a></li></ul><p id="82a2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"><em class="nh">Tl；dr: </em> </strong> <em class="nh">如果你只是想看一些可以直接使用的工作代码，复制这篇文章所需的所有代码都可以在这里</em><a class="ae lb" href="https://gist.github.com/Chris-hughes10/a9e5ec2cd7e7736c651bf89b5484b4a9" rel="noopener ugc nofollow" target="_blank"><em class="nh">GitHub gist</em></a><em class="nh">中找到。</em></p><h1 id="b83b" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">模型</h1><p id="67b6" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm最受欢迎的特性之一是其庞大且不断增长的模型架构集合。这些模型中的许多都包含预先训练的权重——要么在PyTorch中进行本机训练，要么从Jax和TensorFlow等其他库移植而来——可以轻松下载和使用。</p><p id="8111" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以列出并查询可用模型集合，如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ni"><img src="../Images/c47d970e73a800e911cc8d6ec9cd7417.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HKyEoZdAdDvlGbilvX5Aow.png"/></div></div></figure><p id="6d4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以使用<em class="nh">预训练</em>参数将此选择过滤到具有预训练权重的模型:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nj"><img src="../Images/5b8baf22f03eb417f695ff3b8fe6e674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdS-oCEkCgE_VWNovrYONQ.png"/></div></div></figure><p id="d672" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这仍然是一个令人印象深刻的数字！如果此时你正经历一点点选项麻痹，不要绝望！一个有用的资源可用于探索一些可用的模型，并了解它们的性能，这是由代码为的<a class="ae lb" href="https://paperswithcode.com/" rel="noopener ugc nofollow" target="_blank">论文的</a><a class="ae lb" href="https://paperswithcode.com/lib/timm" rel="noopener ugc nofollow" target="_blank">摘要页</a>，其中包含timm中许多模型的基准和原始论文的链接。</p><p id="a7a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了简单起见，让我们继续使用熟悉的、经过测试的ResNet模型系列。我们可以通过提供一个通配符字符串来列出不同的ResNet变体，该字符串将用作基于模型名称的过滤器:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nk"><img src="../Images/71b073229ca4008f09980d5fc86cdd8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3kfG37XTWLIRoPKol00q1Q.png"/></div></div></figure><p id="38b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所看到的，还有很多选择！现在，让我们探索如何从这个列表中创建一个模型。</p><h2 id="9614" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">一般用法</h2><p id="d0fd" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">创建模型最简单的方法是使用<code class="fe lc ld le lf b">create_model</code>；可用于在timm库中创建任何模型的工厂函数。</p><p id="1f4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过创建一个Resnet-D模型来演示这一点，如<a class="ae lb" href="https://arxiv.org/abs/1812.01187" rel="noopener ugc nofollow" target="_blank"> <em class="nh">卷积神经网络图像分类锦囊</em>论文</a>中所介绍的；这是对ResNet体系结构的一个修改，它利用一个平均池来进行下采样。这在很大程度上是一个任意的选择，这里演示的特性应该可以在timm中包含的大多数模型上工作。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nx"><img src="../Images/33ddabfc16b8dfd182a3b774302ddd30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A_fSf_tg_K081jMifEOg-A.png"/></div></div></figure><p id="d469" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所见，这只是一个普通的PyTorch模型。</p><p id="0f38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了帮助我们更好地了解如何使用该模型，我们可以访问其配置，其中包含的信息包括用于归一化输入数据的统计数据、输出类的数量以及网络分类部分的名称。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ny"><img src="../Images/8d3c0773e1ff4cfc95013b0b2d331767.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-aSMcp58_NvVVbULM1cGw.png"/></div></div></figure><p id="8b39" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">具有不同数量输入通道的图像的预训练模型</strong></p><p id="0300" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">timm模型的一个不太为人所知但非常有用的特性是，它们能够处理具有不同数量通道的输入图像，这对大多数其他库来说是个问题；在这里有一个关于这是如何工作的精彩解释<a class="ae lb" href="https://fastai.github.io/timmdocs/models#So-how-is-timm-able-to-load-these-weights?" rel="noopener ugc nofollow" target="_blank">。直观上，timm通过对小于3的信道的初始卷积层的权重求和，或者智能地将这些权重复制到期望数量的信道来实现这一点。</a></p><p id="8ef5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过将<em class="nh"> in_chans </em>参数传递给<code class="fe lc ld le lf b">create_model</code>来指定输入图像的通道数。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nz"><img src="../Images/123ce085939ba0e77f9c0bcbbd02b4c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9cUO2VYIG_bxmH_zqCHp1w.png"/></div></div></figure><p id="f1ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下，使用随机张量来表示单通道图像，我们可以看到模型已经处理了图像并返回了预期的输出形状。</p><p id="f7fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得注意的是，虽然这使我们能够使用预训练的模型，但输入与模型训练的图像明显不同。因此，我们不应该期望相同级别的性能，并在将模型用于任务之前对新数据集进行微调！</p><h2 id="9388" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated"><strong class="ak">定制模型</strong></h2><p id="d643" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">除了用股票架构创建模型之外，<code class="fe lc ld le lf b">create_model</code>还支持许多参数，使我们能够为我们的任务定制一个模型。</p><p id="bb16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">受支持的参数可能取决于底层模型架构，其中一些参数如下:</p><ul class=""><li id="9353" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> global_pool </strong>:确定最终分类层之前要使用的全局池的类型</li></ul><p id="7b9a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因型号而异。在这种情况下，它取决于架构是否采用全局池层。因此，虽然我们可以在类似ResNet的模型中使用它，但是在不使用平均池的<a class="ae lb" href="https://arxiv.org/abs/2010.11929v2" rel="noopener ugc nofollow" target="_blank"> ViT </a>中使用它就没有意义了。</p><p id="b3d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然有些论点是特定于模型的，但诸如以下论点:</p><ul class=""><li id="f1d3" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> drop_rate </strong>:设置训练的辍学率(默认为‘0 ’)</li><li id="c5b3" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> num_classes </strong>:类别对应的输出神经元的数量</li></ul><p id="1454" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几乎可用于所有型号。</p><p id="7790" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们探索实现这一点的一些方法之前，让我们检查一下当前模型的默认架构。</p><p id="2cd8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">改变班级数量</strong></p><p id="4953" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查我们之前看到的模型配置，我们可以看到我们网络的分类头的名称是<em class="nh"> fc </em>。我们可以用它来直接访问相应的模块。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oa"><img src="../Images/456f36085f2eb90ab411aa542d142c7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EoboWE_oxMjIgy3R2_51wQ.png"/></div></div></figure><p id="7f11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，这个名称可能会根据所使用的模型架构而改变。为了给不同的模型提供一致的接口，timm模型有<code class="fe lc ld le lf b">get_classifier </code>方法，我们可以用它来检索分类头，而不必查找模块名。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ob"><img src="../Images/cd19dc99aa662ea4aa7e80671e48afa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wNATQx5RhXDiabiVM0WcA.png"/></div></div></figure><p id="9a14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如所料，这将返回与之前相同的线性图层。</p><p id="b6eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这个模型是在ImageNet上预训练的，我们可以看到最终的层输出了1000个类。我们可以用<em class="nh"> num_classes </em>参数来改变这一点:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oc"><img src="../Images/8d0d295f53363cca3b515d206074e34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A7C4anUZjD7dsvyC0nAvXA.png"/></div></div></figure><p id="7a96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查分类器，我们可以看到，timm已经用一个新的、未经训练的、具有所需类别数的线性层替换了最后一层；准备好微调我们的数据集！</p><p id="e831" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们想完全避免创建最后一层，我们可以设置类的数量等于0，这将创建一个具有身份函数的模型作为最后一层；这对于检查倒数第二层的输出非常有用。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi od"><img src="../Images/5fd66f3a06e1ebc80d706b2aa5c112e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mz0g0grAgNhT6btZODNxmQ.png"/></div></div></figure><p id="637e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">全局池选项</strong></p><p id="eb8a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从我们模型的配置中，我们还可以看到设置了<em class="nh"> pool_size </em>，通知我们在分类器之前使用了一个全局池层。我们可以按如下方式对此进行检查:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oe"><img src="../Images/c47b74a10f6caa22ca41719f94a1d6a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lTifgXysBhIeoxBsox2l8g.png"/></div></div></figure><p id="47ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们可以看到这返回了一个<code class="fe lc ld le lf b">SelectAdaptivePool2d</code>的实例，它是timm提供的自定义层，支持不同的池化和扁平化配置。在撰写本文时，支持的池选项有:</p><ul class=""><li id="4bd7" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><em class="nh">平均值</em>:平均池</li><li id="b738" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh">最大</em>:最大池</li><li id="2b3e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> avgmax: </em>平均池和最大池之和，按0.5重新调整</li><li id="13b3" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> catavgmax: </em>沿特征维度的平均和最大池输出的串联。请注意，这将使特征尺寸加倍。</li><li id="fbc9" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh">“”:</em>不使用池，池层被一个标识操作替换</li></ul><p id="35e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到不同池选项的输出形状，如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi of"><img src="../Images/07fa7c712d42ee57572c0e174e5549f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lWmnW0pwzu7rbW5J8dIFGA.png"/></div></div></figure><p id="24a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">修改现有模型</strong></p><p id="303e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以使用<code class="fe lc ld le lf b">reset_classifier </code>方法修改现有模型的分类器和池层:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi og"><img src="../Images/6656a5fec98744d77df8503afa038538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DRS8lStpPeHSoATWtYP0fw.png"/></div></div></figure><p id="a771" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">创建新的分类头</strong></p><p id="1bac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然已经证明使用单一线性层作为我们的分类器足以获得良好的结果，但当在下游任务上微调模型时，我经常发现使用稍大的头部可以提高性能。让我们探索如何进一步修改我们的ResNet模型。</p><p id="7232" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们像以前一样创建我们的ResNet模型，指定我们想要10个类。因为我们使用了一个更大的头，所以让我们使用<em class="nh"> catavgmax </em>进行池化，这样我们就可以提供更多的信息作为分类器的输入。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oh"><img src="../Images/f37f0eb9bb16f7dc9e1b22b2bf388ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3eKkMiNjV7qq7yULgNx0iQ.png"/></div></div></figure><p id="7507" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从现有的分类器中，我们可以得到输入特征的数量:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oi"><img src="../Images/aef977558e3ef1cd59b948379a2304d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ohurTFsSYuxGkNWcL7rzmg.png"/></div></div></figure><p id="c705" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以通过直接访问分类器，用修改后的分类头替换最后一层。这里，分类标题的选择有些随意。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oj"><img src="../Images/9147e5a234316280216c93d5df8d45bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzMMtqWEZbi2hoE6NKoASA.png"/></div></div></figure><p id="0d92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用虚拟输入测试模型，我们得到预期形状的输出。现在，我们的改装模型可以开始训练了！</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ok"><img src="../Images/8a0d11986c5557424f16cf1c4d20623e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6o83d8cI9GcD0p0Qog7CRw.png"/></div></div></figure><h2 id="0583" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">特征抽出</h2><p id="b5bf" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm模型还具有用于获得各种类型的中间特征的一致机制，这对于将架构用作下游任务的特征提取器是有用的；比如在物体检测中创建<a class="ae lb" href="https://ieeexplore.ieee.org/document/8099589" rel="noopener ugc nofollow" target="_blank">特征金字塔</a>。</p><p id="2719" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过使用来自<a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津宠物数据集</a>的图像来想象这是如何工作的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ol"><img src="../Images/eba64af21bd6c35a3df55c49e06078a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9c6_XT1zcF0w4fMJu5cj5w.png"/></div></div></figure><p id="de88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以将其转换为张量，并将通道转换为PyTorch预期的格式:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi om"><img src="../Images/179bae90f0c046412831dc2ffb3502b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q_N_wf5BvZlmd-Z8OC5PuQ.png"/></div></div></figure><p id="521b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们再次创建我们的ResNet-D模型:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi on"><img src="../Images/78eab6afb078f7f19ce4dbf9c259d2cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aOt5YfrShNMqVTk1soNwLw.png"/></div></div></figure><p id="b383" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们只对最终的特征图感兴趣——在这种情况下，这是合并之前最终卷积层的输出——我们可以使用<code class="fe lc ld le lf b">forward_features </code>方法绕过全局合并和分类层。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oo"><img src="../Images/7276210765fed0bd94ecbc66d25ae586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fB37Ww6Ijdclt6udGnBHUQ.png"/></div></div></figure><p id="c699" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以将它形象化如下:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi op"><img src="../Images/4aa3ffa024270dc63c472ccb63e82fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-JbQoq1SbKBCAfodBO3-qg.png"/></div></div></figure><p id="ba0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">多特征输出</strong></p><p id="b720" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然正向特征方法可以方便地检索最终特征图，但timm还提供了使我们能够将模型用作输出选定级别的特征图的特征主干的功能。</p><p id="0b61" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当创建一个模型时，我们可以通过使用参数<em class="nh"> features_only=True </em>来指定我们想要使用一个模型作为特征主干。默认情况下，大多数模型将输出5步(并非所有模型都有这么多)，第一步从2开始(但有些从1或4开始)。</p><p id="f20e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以使用`<em class="nh">out _ indexes</em>和`<em class="nh"> output_stride </em>参数修改特征级别的指数和步数，如文档中的<a class="ae lb" href="https://rwightman.github.io/pytorch-image-models/feature_extraction/#multi-scale-feature-maps-feature-pyramid" rel="noopener ugc nofollow" target="_blank">所示。</a></p><p id="e27a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看这是如何与我们的ResNet-D模型一起工作的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oq"><img src="../Images/00a533680f984fb6cfc4d0b6953fa03c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9VCKHUr8y0bo6_X_AVRMw.png"/></div></div></figure><p id="5506" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如下所示，我们可以获得关于返回的特性的更多信息，例如特定的模块名称、特性的减少和通道的数量:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi or"><img src="../Images/f4519acaae1913f939c2a6c4907d32bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*doV4WO0yG3p1Lgw1ZPzzww.png"/></div></div></figure><p id="5107" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们通过我们的特征提取器传递一个图像，并研究输出。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi os"><img src="../Images/778f1f424739f92cf1bb58626fcfd3aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*nz5AXBVYPH0rDnUPc8pmvA.png"/></div></figure><p id="89db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如所料，已返回5个特征地图。检查形状，我们可以看到通道的数量与我们预期的一致:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/f5963382ea3653e377ba0cfd11170bb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*e0095ij9ukgm1f-FAR-w6A.png"/></div></figure><p id="9a48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可视化每个特征图，我们可以看到，图像是逐步下降采样，正如我们所期望的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ou"><img src="../Images/22182c0697fe98b38144068d31b22466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ex0Iui0X4u3IBP4M5HGbg.png"/></div></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ov"><img src="../Images/1788b677e96f14f4775bc23e267a8375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUlFKHhzvh9YrAQ75DRfOQ.png"/></div></div></figure><p id="4ac5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用火炬特效</strong></p><p id="3365" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://pytorch.org/vision/stable/index.html" rel="noopener ugc nofollow" target="_blank"> TorchVision </a>最近发布了一个名为FX的新工具，它使得在PyTorch模块向前传递期间访问输入的中间转换变得更加容易。这是通过象征性地跟踪forward方法来产生一个图来完成的，其中每个节点代表一个操作。由于节点被赋予了人类可读的名称，因此很容易准确地指定我们想要访问的节点。FX在文件和博客中<a class="ae lb" href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" rel="noopener ugc nofollow" target="_blank">有更详细的描述。</a></p><p id="2a14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注</strong>:在撰写本文时，使用FX时，动态控制流还不能用静态图来表示。</p><p id="5aad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于timm中几乎所有的模型都是象征性可追溯的，我们可以使用FX来操纵它们。让我们探索一下如何使用FX从timm模型中提取特征。</p><p id="52c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们从TorchVision导入一些helper方法:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ow"><img src="../Images/9cb578f3bee55577557ec2a907a796a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YkJRAosO0LA2goqGfJFlGQ.png"/></div></div></figure><p id="591c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们重新创建我们的ResNet-D模型，使用分类头，并使用<em class="nh"> exportable </em>参数来确保模型是可跟踪的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ox"><img src="../Images/57ba8fa27b4f7b07ec1a4e911263d986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mta2qvCaI3Ay1eWo97rM3Q.png"/></div></div></figure><p id="87b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以使用<code class="fe lc ld le lf b">get_graph_nodes</code>方法按照执行顺序返回节点名称。由于模型被跟踪了两次，在train和eval模式下，两组节点名都被返回。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oy"><img src="../Images/a05e7c8bb48a5a848286786535ec9ce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGtMAPNYf__litJhlMdb7w.png"/></div></div></figure><p id="bb33" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用FX，可以很容易地从任何节点访问输出。让我们在<em class="nh">层1 </em>中选择第二次激活。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oz"><img src="../Images/6bd24a8151b88ed6fc494590884dbfbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*bH2uePISLMIAeIya-9J2DQ.png"/></div></div></figure><p id="c1a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<code class="fe lc ld le lf b">create_feature_extractor</code>，我们可以在该点“切割”模型，如下图所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pa"><img src="../Images/f81f5371fa56f8bb16ca6a4922f414ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wvs-z917Uewb1upeC1Uccg.png"/></div></div></figure><p id="d392" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，通过我们的特征提取器传递一个图像，这将返回一个张量字典。我们可以像以前一样想象这个:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pb"><img src="../Images/8d5181f5ea0ed020122e79476b928f51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKJxgzcp3iDrhOMswBOdFg.png"/></div></div></figure><h2 id="c193" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">导出到不同的格式</h2><p id="e5f5" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">训练之后，通常建议将您的模型导出到一个优化的格式，以便进行推理；PyTorch有多种方法可以做到这一点。由于几乎所有的timm模型都是可脚本化和可追踪的，我们可以利用这些格式。</p><p id="1180" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们检查一些可用的选项。</p><p id="4a9a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">导出到TorchScript </strong></p><p id="4e1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TorchScript是一种从PyTorch代码创建可序列化和可优化模型的方法；任何TorchScript程序都可以从Python进程中保存，并在没有Python依赖的进程中加载。</p><p id="b454" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过两种不同的方式将模型转换为TorchScript:</p><ul class=""><li id="7c4e" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><em class="nh">跟踪</em>:运行代码，记录发生的操作，构建包含这些操作的ScriptModule。控制流或动态行为(如if/else语句)被删除。</li><li id="464b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh">脚本</em>:使用脚本编译器对Python源代码进行直接分析，将其转换成TorchScript。这保留了动态控制流，并且对不同大小的输入有效。</li></ul><p id="c7ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于TorchScript的更多信息可以在文档中的<a class="ae lb" href="https://pytorch.org/docs/stable/jit.html" rel="noopener ugc nofollow" target="_blank">和本教程</a>中的<a class="ae lb" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" rel="noopener ugc nofollow" target="_blank">中看到。</a></p><p id="8329" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于大多数timm模型都是可脚本化的，所以让我们使用脚本来导出我们的ResNet-D模型。我们可以设置层配置，以便在创建模型时使用<em class="nh">可脚本化的</em>参数使模型是jit可脚本化的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pc"><img src="../Images/b839572ad5f4493bc9fb580dc476dfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jK1iGFdOeTI29sdGSMekbQ.png"/></div></div></figure><p id="053a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在导出模型之前调用<code class="fe lc ld le lf b">model.eval()</code>将模型置于推理模式是很重要的，因为像dropout和batchnorm这样的操作符根据模式的不同会有不同的行为。</p><p id="a209" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以验证我们能够编写脚本并使用我们的模型。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pd"><img src="../Images/8c1b849e6685570e80660f0857ce86ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHAz0M7sNzqfxCTyzqjr1g.png"/></div></div></figure><p id="bd1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">导出到ONNX </strong></p><p id="f8a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">开放神经网络交换(ONNX) </a>是一种用于表示机器学习模型的开放标准格式。</p><p id="f748" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用<code class="fe lc ld le lf b">torch.onnx</code>模块将timm模型导出到ONNX使它们能够被支持ONNX的许多运行时所使用。如果用一个还不是ScriptModule的模块调用<code class="fe lc ld le lf b">torch.onnx.export()</code>，它首先执行与<code class="fe lc ld le lf b">torch.jit.trace()</code>等效的操作；它使用给定的参数执行模型一次，并记录执行过程中发生的所有操作。这意味着，如果模型是动态的，例如，根据输入数据改变行为，则导出的模型将不会捕捉这种动态行为。类似地，跟踪可能只对特定的输入大小有效。</p><p id="a7ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于ONNX的更多细节可以在文档中找到<a class="ae lb" href="https://pytorch.org/docs/master/onnx.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a6a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了能够以ONNX格式导出timm模型，我们可以在创建模型时使用<em class="nh"> exportable </em>参数，以确保模型是可追踪的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pe"><img src="../Images/ef3c87e7bcb65744d912d6dc1be773dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dfc4vzccOt4LaIWdBI00FQ.png"/></div></div></figure><p id="a985" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用<code class="fe lc ld le lf b">torch.onnx.export</code>来跟踪和导出我们的模型:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pf"><img src="../Images/d85d7b811a4c36b49a9b2c6238ccea21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4AnUVK2fpLDR-cYCDdi8yQ.png"/></div></div></figure><p id="c743" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用<code class="fe lc ld le lf b">check_model</code>函数来验证我们的模型是有效的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/c2bf0773882aac05d3e2bc2f719dad85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*KQs2JaI46oWJkBjLhVZnnQ.png"/></div></figure><p id="e83c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们指定了我们的模型应该是可追踪的，我们也可以手动执行追踪，如下所示。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ph"><img src="../Images/c88e1a2088a8887aa07b66605b15a647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hV7NzCa_NmFavb-R0QvtQ.png"/></div></div></figure><h1 id="4cc7" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">数据扩充</h1><p id="c99b" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm包括许多数据扩充转换，它们可以链接在一起形成扩充管道；与火炬视觉类似，这些管道期望PIL图像作为输入。</p><p id="0ee8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最简单的开始方式是使用<code class="fe lc ld le lf b">create_transform</code>工厂函数，让我们在下面探索如何使用它。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pi"><img src="../Images/13c200ea6d18334001156b2614e5ff81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtzsOTPiFcdiVUCOs7Q3Vw.png"/></div></div></figure><p id="6e81" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到这已经创建了一些基本的增强管道，包括调整大小，规范化和转换图像为张量。正如我们所料，我们可以看到，当我们设置<em class="nh"> is_training=True </em>时，包括了额外的变换，如水平翻转和颜色抖动。这些增强的幅度可以用诸如<em class="nh"> hflip </em>、<em class="nh">v lip</em>和<em class="nh"> color_jitter </em>之类的参数来控制。</p><p id="a01a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以看到，根据我们是否在训练，用于调整图像大小的方法也有所不同。虽然在验证过程中使用了标准的<em class="nh"> Resize </em>和<em class="nh"> CenterCrop </em>，但是在训练过程中，使用了<em class="nh">RandomResizedCropAndInterpolation</em>，让我们看看它在下面做了什么。因为在timm中实现这种变换使我们能够设置不同的图像插值方法；这里我们选择插值是随机选择的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pj"><img src="../Images/cb442bfc3a07a26387127f2200dbb267.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k-9F_sfb2afuVmGWwmaDHQ.png"/></div></div></figure><p id="e25b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行几次转换，我们可以观察到不同的作物已采取的形象。虽然这在培训期间是有益的，但在评估期间可能会使任务变得更加困难。</p><p id="31f2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">取决于图像的类型，这种类型的变换可能导致图片的主题从图像中被裁剪掉；如果我们看第一行的第二张图片，我们可以看到这样的例子！虽然如果不经常发生，这应该不是一个大问题，但我们可以通过调整比例参数来避免这种情况:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pk"><img src="../Images/b692765be99bbc4c180cf343f92b57ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-iBN_Dwy3UD67YEJ-G_Fw.png"/></div></div></figure><h2 id="8549" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated"><strong class="ak"> RandAugment </strong></h2><p id="5284" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">当开始一项新任务时，可能很难知道使用哪些增强，以及以何种顺序使用；随着现在可用的增强数量的增加，组合的数量是巨大的！</p><p id="97f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通常，一个好的起点是使用在其他任务中表现良好的增强管道。一种这样的策略是RandAugment，这是一种自动化的数据增强方法，它从一组增强中统一采样操作，如均衡、旋转、曝光、颜色抖动、色调分离、改变对比度、改变亮度、改变锐度、剪切和平移，并顺序应用其中的一些操作；更多信息，请参见<a class="ae lb" href="https://arxiv.org/abs/1909.13719" rel="noopener ugc nofollow" target="_blank">原始文件</a>。</p><p id="e78d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，在timm中提供的实现中有几个关键的差异，timm的创建者Ross Wightman在<a class="ae lb" href="https://arxiv.org/pdf/2110.00476v1.pdf" rel="noopener ugc nofollow" target="_blank">ResNets Strike Back paper</a>的附录中对此进行了最好的描述，我在下面解释了这些差异:</p><blockquote class="pl pm pn"><p id="0956" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">原始RandAugment规范有两个超参数，M和N；其中M是失真幅度，N是每幅图像均匀采样和应用的失真数量。RandAugment的目标是M和N都是人类可以解释的。</p><p id="2a91" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">然而，对于M[在最初的实现中]来说，情况并非如此。几个增强的尺度在该范围内是向后的或者不是单调增加的，因此增加M不会增加所有增强的强度。</p></blockquote><p id="f3bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在最初的实现中，虽然随着M的增加，一些增强的强度上升，但是其他增强的强度下降或者被完全移除，使得每个M本质上代表其自己的策略。</p><blockquote class="pl pm pn"><p id="eb40" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">timm中的实现试图通过添加“增加”模式(默认启用)来改善这种情况，在该模式中，所有增强强度都随着幅度增加。</p></blockquote><p id="40ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这使得增加M更直观，因为所有的强化现在应该随着M的相应减少/增加而减少/增加强度。</p><blockquote class="pl pm pn"><p id="e980" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">[此外，] timm添加了一个MSTD参数，该参数将具有指定标准偏差的高斯噪声添加到每个失真应用的M值中。如果MSTD设置为'-inf '，则对于每个失真，M从0-M均匀采样。</p><p id="2937" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">在timm的RandAugment中，为了减少对图像均值的影响，归一化参数可以作为一个参数传递，以便所有可能引入边界像素的增强都可以使用指定的均值，而不是像在其他实现中那样默认为0或硬编码元组。</p><p id="d711" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">[最后，]默认情况下不包括剪切，以支持单独使用timm的随机擦除实施*，这对增强图像的平均值和标准偏差的<br/>影响较小。</p></blockquote><p id="8dca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">* timm中随机擦除的实现在<a class="ae lb" href="https://fastai.github.io/timmdocs/RandomErase" rel="noopener ugc nofollow" target="_blank">这里</a>详细探讨。</p><p id="9ed6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经了解了什么是RandAugment，让我们看看如何在增强管道中使用它！</p><p id="176c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在timm中，我们通过使用一个配置字符串来定义RandAugment策略的参数；它由用破折号(<code class="fe lc ld le lf b">-</code>)分隔的多个部分组成</p><p id="cea9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一部分定义了rand augment的具体变体(目前只支持<code class="fe lc ld le lf b">rand</code>)。其余部分可以按任意顺序排列，它们是:</p><ul class=""><li id="363e" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> m </strong> ( <em class="nh">整数</em>):rand增大的幅度</li><li id="1882" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> n </strong> ( <em class="nh"> integer </em>):每个图像选择的变换操作数，这是可选的，默认设置为2</li><li id="da5b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> mstd ( </strong> <em class="nh"> float </em>):应用的噪声幅度的标准偏差</li><li id="f378" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> mmax </strong> ( <em class="nh"> integer </em>):将幅度的上限设置为默认值10以外的值</li><li id="b258" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> w </strong> ( <em class="nh"> integer </em>):概率权重指数(影响操作选择的一组权重的指数)</li><li id="0b63" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> inc </strong> ( <em class="nh"> bool — {0，1} </em>):使用严重性随幅度增加的增强，这是可选的，默认值为0 <br/> <br/>例如:</li><li id="377e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><code class="fe lc ld le lf b">rand-m9-n3-mstd0.5</code>:产生9级随机增强，每幅图像3次增强，mstd 0.5</li><li id="b4b5" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><code class="fe lc ld le lf b">rand-mstd1-w0</code>:mstd 1.0，权重0，默认m值10，每幅图像放大2倍</li></ul><p id="8d1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">向<code class="fe lc ld le lf b">create_transform</code>传递一个配置字符串，我们可以看到这是由<code class="fe lc ld le lf b">RandAugment</code>对象处理的，我们可以看到所有可用操作的名称:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pr"><img src="../Images/247f1dda8a6ce9f6c05f0aaef5b00b5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6JHTt4H5ZPQN7Ck4TBrgPw.png"/></div></div></figure><p id="3512" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以通过使用<code class="fe lc ld le lf b">rand_augment_transform</code>函数来创建这个对象，以便在自定义管道中使用，如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ps"><img src="../Images/ba9def0463b8044764fe0fb9f5849d7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yE2AgJ7ePAhDsgA2zvpmTw.png"/></div></div></figure><p id="8282" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们将这个策略应用到一个图像上，来可视化一些转换。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pd"><img src="../Images/a6aa8675d30add4c80178e8886bdb19c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cTd9VQU_YOZGezpbg-IdOQ.png"/></div></div></figure><p id="06a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此，我们可以看到使用RandAugment给了我们很多不同的图像！</p><h2 id="e618" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated"><strong class="ak">剪切和混合</strong></h2><p id="bf05" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm使用<code class="fe lc ld le lf b">Mixup</code>类提供了<a class="ae lb" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank">剪切混合</a>和<a class="ae lb" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank">混合</a>增强的灵活实现；它处理这两种扩充并提供在它们之间切换的选项。</p><p id="d9f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<code class="fe lc ld le lf b">Mixup,</code>,我们可以从各种不同的混音策略中进行选择:</p><ul class=""><li id="bdb5" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><em class="nh">批次</em>:每批次执行切割混合与混合选择、λ和切割混合区域采样</li><li id="3721" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> pair </em>:对一个批次内的采样对进行混合、lambda和区域采样</li><li id="3bbe" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> elem </em>:对批次内的每幅图像进行混合、λ和区域采样</li><li id="a4bc" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> half </em>:与元素方面相同，但是每个混合对中的一个被丢弃，以便每个样本在每个时期被看到一次</li></ul><p id="d592" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们想象一下这是如何工作的。要做到这一点，我们需要创建一个数据加载器，遍历它并将扩充应用到批处理中。我们将再次使用来自Pets数据集的图像。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pt"><img src="../Images/c586e4d6db6ff5101166905f4e70e539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gI45Frx88hVgGRGHGUgBuw.png"/></div></div></figure><p id="f931" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用TorchVision和<a class="ae lb" href="https://fastai.github.io/timmdocs/mixup_cutmix" rel="noopener ugc nofollow" target="_blank"> timmdocs </a>的帮助函数，我们可以在没有应用增强的情况下可视化我们批次中的图像:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pu"><img src="../Images/6d989941feb6968958078dc23cdbd504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9IXbebORhnSgc3KRvFKrg.png"/></div></div></figure><p id="6bda" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们创建我们的混音转换！<code class="fe lc ld le lf b">Mixup</code>支持以下参数:</p><ul class=""><li id="192c" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir">mixup _ alpha</strong>(<em class="nh">float</em>):mix up alpha值，如果&gt;为0，则mix up有效。，(默认值:1)</li><li id="f487" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">cutmix _ alpha</strong>(<em class="nh">float</em>):cut mix alpha值，如果&gt;为0，则cut mix有效。(默认值:0)</li><li id="9ee6" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">cutmix _ minmax</strong>(<em class="nh">List【float】</em>):cut mix最小/最大图像比率，cut mix处于活动状态，如果不是无，则使用此vs alpha。</li><li id="947b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> prob </strong> ( <em class="nh"> float </em>):每个批次或元素应用mix或cutmix的概率(默认值:1)</li><li id="4e69" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">switch _ prob</strong>(<em class="nh">float</em>):当两者都激活时，切换到cutmix而不是mix的概率(默认值:0.5)</li><li id="4fc4" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">模式</strong> ( <em class="nh"> str </em>):如何应用mixup/cutmix参数(默认:<em class="nh">批次</em>)</li><li id="d427" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">label _ smoothing</strong>(<em class="nh">float</em>):应用于混合目标张量的标签平滑量(默认值:0.1)</li><li id="b5d0" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">num _ classes</strong>(<em class="nh">int</em>):目标变量的类的数量</li></ul><p id="d5c3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们定义一组参数，以便我们将mixup或cutmix应用于一批图像，并且以概率1交替，并且使用这些来创建我们的“Mixup”变换:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pv"><img src="../Images/b4a30608c61cb4dfe03ec6a64f39549c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HLjr8tke-hDnMu8hv_O-nw.png"/></div></div></figure><p id="8b09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于mixup和cutmix发生在一批图像上，所以我们可以在应用增强来加速之前将该批图像放在GPU上！在这里，我们可以看到mixup已经应用于这批图像。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pw"><img src="../Images/41e919b798d66832eaa7229c4b1c0144.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bYFYrubbnAdhasjv6N5u2Q.png"/></div></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi px"><img src="../Images/a0b67fa9d2257bc3df382e75e68d7891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65mo4FfhDOwdLIgQkd5s-A.png"/></div></div></figure><p id="d138" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再次运行增强，我们可以看到，这一次，应用了CutMix。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi py"><img src="../Images/02492ca4ea3e923fefebca23571d52d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8srxbk0SHNGhKvnjGiRfQ.png"/></div></div></figure><p id="9470" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从彼此上面打印的标签可以观察到，我们也可以使用<code class="fe lc ld le lf b">Mixup</code>进行标签平滑！</p><h1 id="c725" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">数据集</h1><p id="0949" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm为处理不同类型的数据集提供了许多有用的工具。最简单的开始方式是使用<code class="fe lc ld le lf b">create_dataset</code>函数，它将为我们创建一个合适的数据集。</p><p id="e309" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lc ld le lf b">create_dataset</code>总是期望两种说法:</p><ul class=""><li id="5fc6" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><em class="nh">名称</em>:我们要加载的数据集的名称</li><li id="37d6" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> root: </em>本地文件系统上数据集的根文件夹</li></ul><p id="891c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是有额外的关键字参数，可用于指定选项，如我们是否希望加载定型集或验证集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi pz"><img src="../Images/73a64142008d7d996d4d2fcc98b9e77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*gKA1fFZYF6k5sdfTIhRErw.png"/></div></figure><p id="1ab4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以使用<code class="fe lc ld le lf b">create_dataset</code>，从几个不同的地方加载数据:</p><ul class=""><li id="b214" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/vision/0.11/datasets.html" rel="noopener ugc nofollow" target="_blank">火炬视觉中可用的数据集</a></li><li id="d92c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.tensorflow.org/datasets" rel="noopener ugc nofollow" target="_blank">张量流数据集中可用的数据集</a></li><li id="9d10" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">存储在本地文件夹中的数据集</li></ul><p id="017e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们探索其中的一些选项。</p><h2 id="2c65" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">从TorchVision加载数据集</h2><p id="49d7" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">要加载TorchVision包含的数据集，我们只需在希望加载的数据集名称前指定前缀<code class="fe lc ld le lf b">torch/</code>。如果文件系统上不存在这些数据，我们可以通过设置<em class="nh"> download=True </em>来下载这些数据。此外，我们在这里指定我们希望加载带有<em class="nh"> split </em>参数的训练数据集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qa"><img src="../Images/1ac8c95babefaaec5f0d4894ba9a666d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y_YlfmnVhfpVy1g432hcbQ.png"/></div></div></figure><p id="b17f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查类型，我们可以看到这是一个TorchVision数据集。我们可以像往常一样通过索引来访问它:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pb"><img src="../Images/e2be273d0ec1cca60c07d5434d51400f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nb4mVhgAjWurT2o4qaS5HA.png"/></div></div></figure><h2 id="96e0" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">从TensorFlow数据集加载数据集</h2><p id="20f6" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">除了通过TorchVision使用PyTorch时通常可用的数据集，timm还使我们能够从TensorFlow数据集下载和使用数据集；为我们包装底层的<code class="fe lc ld le lf b">tfds</code>对象。</p><p id="9305" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从TensorFlow数据集加载时，建议我们设置几个额外的参数，本地或TorchVision数据集不需要这些参数:</p><ul class=""><li id="2400" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> batch_size </strong>:用于保证分布式训练时，批量大小除以所有节点的样本总数</li><li id="0673" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> is_training </strong>:如果设置，数据集将被混洗。注意，这不同于设置<em class="nh">分割</em></li></ul><p id="2fcd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这个包装器从TFDS数据集中返回解压缩的图像示例，但是我们需要的任何扩充和批处理仍然由PyTorch处理。</p><p id="8ae6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下，我们用<code class="fe lc ld le lf b">tfds/</code>作为数据集名称的前缀。可用于图像分类的数据集列表可在<a class="ae lb" href="https://www.tensorflow.org/datasets/catalog/overview#image_classification" rel="noopener ugc nofollow" target="_blank">这里</a>找到。对于这个例子，我们将任意选择<em class="nh">bean</em>数据集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qb"><img src="../Images/7db166411f7d173e19de0e3f6b39d8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaRuMnOwpnyIXFxOtn0d6A.png"/></div></div></figure><p id="869c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以看到，对于<em class="nh">拆分</em>参数，我们指定了一个<code class="fe lc ld le lf b">tfds </code>拆分字符串，如这里的<a class="ae lb" href="https://www.tensorflow.org/datasets/splits" rel="noopener ugc nofollow" target="_blank">所述</a>。</p><p id="d11e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查我们的数据集，我们可以看到底层的TensorFlow数据集已经被包装在一个<code class="fe lc ld le lf b">IterableImageDataset</code>对象中。作为一个可迭代的数据集，它不支持索引——参见这里的差异<a class="ae lb" href="https://pytorch.org/docs/stable/data.html#dataset-types" rel="noopener ugc nofollow" target="_blank">和</a>——所以为了查看来自这个数据集的图像，我们必须首先创建一个迭代器。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qc"><img src="../Images/95655babe1e7aab3568b80a3a2a2bdd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXsCpr1VnpVbW5-hEUgCgw.png"/></div></div></figure><p id="e2db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用这个迭代器来依次检查图像和标签，如下所示。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qd"><img src="../Images/b1f313489b7f715ed630bddb4b51ca2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CWrg2qBkH5dQBLZKzUza8Q.png"/></div></div></figure><p id="2455" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到我们的图像已经正确加载！</p><h2 id="0ebd" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">从本地文件夹加载数据</h2><p id="f71c" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">我们还可以从本地文件夹加载数据，在这种情况下，我们只需使用空字符串(`''`)作为数据集名称。</p><p id="0775" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了能够从ImageNet风格的文件夹层次结构中加载之外，<code class="fe lc ld le lf b">create_dataset</code>还允许我们从一个或多个tar文档中提取；我们可以利用这一点来避免必须解压缩存档！作为一个例子，我们可以在<a class="ae lb" href="https://github.com/fastai/imagenette" rel="noopener ugc nofollow" target="_blank"> Imagenette数据集</a>上进行试验。</p><p id="5925" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，到目前为止，我们一直在加载原始图像，所以让我们也使用<em class="nh"> transform </em>参数来应用一些转换；这里，我们可以使用前面看到的<code class="fe lc ld le lf b">create_transform</code>函数快速创建一些合适的转换！</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qe"><img src="../Images/23ac1324d30fea85871bfae3d745abd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XksN70_HLwl9FLdzEhuSJQ.png"/></div></div></figure><p id="3a23" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过检查图像的羞耻，我们可以看到我们的变换已经被应用。</p><h2 id="a4d1" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">ImageDataset类</h2><p id="d16c" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">正如我们所见，<code class="fe lc ld le lf b">create_dataset</code>函数为处理不同类型的数据提供了许多选项。timm能够提供这种灵活性的原因是通过尽可能使用TorchVision中提供的现有数据集类，以及提供一些额外的实现— <code class="fe lc ld le lf b">ImageDataset</code>和<code class="fe lc ld le lf b">IterableImageDataset</code>，它们可以在广泛的场景中使用。</p><p id="a687" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本质上，<code class="fe lc ld le lf b">create_dataset</code>通过选择一个合适的类为我们简化了这个过程，但是有时我们可能希望直接使用底层组件。</p><p id="4ed4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我最常使用的实现是<code class="fe lc ld le lf b">ImageDataset</code>，它类似于<a class="ae lb" href="https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html" rel="noopener ugc nofollow" target="_blank"><em class="nh">torch vision . datasets . image folder</em></a>，但是增加了一些额外的功能。让我们探索一下如何使用它来加载解压缩的imagenette数据集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qf"><img src="../Images/d40f4bce52cc8c7caec55d3b3f52d9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAAjMGiE4b0AeRJy234zVg.png"/></div></div></figure><p id="850c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lc ld le lf b">ImageDataset</code>灵活性的关键在于它索引和加载样本的方式被抽象成了一个<code class="fe lc ld le lf b">Parser</code>对象。</p><p id="4c7e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">timm包含了几个解析器，包括从文件夹、tar文件和TensorFlow数据集读取图像解析器。解析器可以作为参数传递给数据集，我们可以直接访问解析器。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qg"><img src="../Images/6f09f5e1013b9ab6da95d65e145619ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3DP5q4Kvf-JYVcs4DW-1lA.png"/></div></div></figure><p id="9b50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们可以看到默认解析器是<code class="fe lc ld le lf b">ParserImageFolder</code>的一个实例。解析器还包含有用的信息，比如类查找，我们可以像下面这样访问它。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div class="gh gi qh"><img src="../Images/2abf88c1c06b1f5c2e87cbc588e6ddbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*j1Rn4g9GQa18jshlvQvvpg.png"/></div></figure><p id="c4c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，这个解析器已经将原始标签转换成整数，可以输入到我们的模型中。</p><p id="76ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">手动选择解析器— tar示例</strong></p><p id="c213" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，除了选择合适的类，<code class="fe lc ld le lf b">create_dataset</code>还负责选择正确的解析器。再次考虑压缩的Imagenette数据集，我们可以通过手动选择<code class="fe lc ld le lf b">ParserImageInTar</code>解析器并覆盖<code class="fe lc ld le lf b">ImageDataset</code>的默认解析器来获得相同的结果。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pk"><img src="../Images/a8c59100ba5cd6fdaa2a1710775478b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vAkTIQIqUFB1LpfNAiBEGA.png"/></div></div></figure><p id="dbbf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查第一个样本，我们可以验证这已经正确加载。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qi"><img src="../Images/ad68c187c8e7c3a761fac10e93e17db7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLuI3pbXvR8atdbmCYZtCg.png"/></div></div></figure><p id="4bc5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">创建自定义解析器</strong></p><p id="2e86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不幸的是，数据集并不总是像ImageNet那样结构化；也就是说，具有以下结构:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="8e61" class="nl lx iq lf b gy qn qo l qp qq">root/class_1/xx1.jpg<br/>root/class_1/xx2.jpg<br/>root/class_2/xx1.jpg<br/>root/class_2/xx2.jpg</span></pre><p id="2086" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这些数据集，<code class="fe lc ld le lf b">ImageDataset</code>不能开箱即用。虽然我们总是可以实现一个自定义数据集来处理这一点，但这可能是一个挑战，取决于数据是如何存储的。另一种选择是编写一个定制的解析器来使用<code class="fe lc ld le lf b">ImageDataset</code>。</p><p id="234b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为一个例子，让我们考虑一下<a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津宠物数据集</a>，其中所有图像都位于一个文件夹中，文件名中包含类名——在本例中是每个品种的名称。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qr"><img src="../Images/54d298808e35756d2409578f97fa9f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDrabvtmM5KU8SpyhSfbEA.png"/></div></div></figure><p id="371c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下，由于我们仍然从本地文件系统加载图像，所以对<code class="fe lc ld le lf b">ParserImageFolder</code>只做了一点小小的调整。让我们看看这是如何实现的灵感。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qs"><img src="../Images/bcd0a6832e154a8f027d1fc78fee0e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yf4fq1m3rJ-_8zrpTpUg0g.png"/></div></div></figure><p id="9309" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此，我们可以看到“ParserImageFolder”做了几件事:</p><ul class=""><li id="ddfd" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">为类创建映射</li><li id="35db" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">执行<code class="fe lc ld le lf b">__len__</code>返回样品数量</li><li id="2598" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">实现<code class="fe lc ld le lf b">_filename</code>来返回样本的文件名，并带有选项来确定它应该是绝对路径还是相对路径</li><li id="1874" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">执行<code class="fe lc ld le lf b">__getitem__</code>返回样品和目标。</li></ul><p id="f280" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经了解了我们必须实现的方法，我们可以在此基础上创建我们自己的实现！这里，我使用了<a class="ae lb" href="https://docs.python.org/3/library/pathlib.html" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> pathlib </em> </a>，从标准库中提取类名并处理我们的路径；因为我发现它比<code class="fe lc ld le lf b">os</code>更容易使用。</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="qt qu l"/></div></figure><p id="3084" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以将解析器的一个实例传递给<code class="fe lc ld le lf b">ImageDataset</code>，这将使它能够正确加载pets数据集！</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qv"><img src="../Images/f5e3c80cc8e7acf4394556cfb3d8df4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJXYMXZnfGEGnIV4yO7SQg.png"/></div></div></figure><p id="357f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过检查第一个样本来验证我们的解析器已经工作。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qw"><img src="../Images/e4fa7f2af6ea0088b7648bd58914ce84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yw8wNrl3hT_u9zQ6jTuIUQ.png"/></div></div></figure><p id="6100" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此看来，我们的解析器起作用了！此外，与默认解析器一样，我们可以检查已经执行的类映射。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qx"><img src="../Images/1d53ffa184c658be1dc5420f74ec0e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GX6lD5FuX2ouwXGjsbI9cA.png"/></div></div></figure><p id="b3ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个简单的例子中，创建一个自定义数据集实现只需要稍微多做一点工作。然而，希望这有助于说明编写自定义解析器并使其与<code class="fe lc ld le lf b">ImageDataset</code>一起工作是多么容易！</p><h1 id="18f9" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">优化者</h1><p id="0963" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm具有大量的优化器，其中一些不是PyTorch的一部分。除了方便访问熟悉的优化器，如<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html" rel="noopener ugc nofollow" target="_blank"> SGD </a>、<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" rel="noopener ugc nofollow" target="_blank">亚当</a>和<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html#torch.optim.AdamW" rel="noopener ugc nofollow" target="_blank"> AdamW </a>，一些值得注意的内容包括:</p><ul class=""><li id="9334" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> AdamP </strong>:本文所述<a class="ae lb" href="https://arxiv.org/abs/2006.08217" rel="noopener ugc nofollow" target="_blank"/></li><li id="0572" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">rms propf</strong>:基于原始TensorFlow实现的<a class="ae lb" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" rel="noopener ugc nofollow" target="_blank"> RMSProp </a>的实现，此处讨论其他<a class="ae lb" href="https://github.com/pytorch/pytorch/issues/23796" rel="noopener ugc nofollow" target="_blank">小调整</a>。根据我的经验，这通常会比PyTorch版本带来更稳定的训练</li><li id="3df2" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">LAMB</strong>:Apex的<a class="ae lb" href="https://nvidia.github.io/apex/optimizers.html#apex.optimizers.FusedLAMB" rel="noopener ugc nofollow" target="_blank"> FusedLAMB优化器的纯pytorch变体，在使用PyTorch XLA时与TPU兼容</a></li><li id="c7bf" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">adabelieve</strong>:本文所述<a class="ae lb" href="https://arxiv.org/abs/2010.07468" rel="noopener ugc nofollow" target="_blank"/>。关于设置超参数的指南可在<a class="ae lb" href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide" rel="noopener ugc nofollow" target="_blank">此处</a>获得</li><li id="6804" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">马德格拉德</strong>:本文所述<a class="ae lb" href="https://arxiv.org/abs/2101.11075" rel="noopener ugc nofollow" target="_blank"/></li><li id="e79f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> AdaHessian </strong>:自适应二阶优化器，在本文中描述<a class="ae lb" href="https://arxiv.org/abs/2006.00719" rel="noopener ugc nofollow" target="_blank"/></li></ul><p id="597b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">timm中的优化器支持与<a class="ae lb" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank"> <em class="nh"> torch.optim </em> </a>中相同的接口，并且在大多数情况下可以简单地放入一个训练脚本中，而无需进行任何更改。</p><p id="1752" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看timm实现的所有优化器，我们可以检查timm.optim模块。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qs"><img src="../Images/1aa1dea2b99296f4259ba254d5838241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUEk-ISaXODPmbduLlW1Ng.png"/></div></div></figure><p id="6b26" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建优化器最简单的方法是使用<code class="fe lc ld le lf b">create_optimizer_v2</code>工厂函数，该函数需要:</p><ul class=""><li id="d95d" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">一个模型或一组参数</li><li id="0725" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">优化程序的名称</li><li id="dfbc" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">要传递给优化器的任何参数</li></ul><p id="35fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用这个函数来创建timm中包含的任何优化器实现，以及torch.optim中流行的优化器和<a class="ae lb" href="https://nvidia.github.io/apex/index.html" rel="noopener ugc nofollow" target="_blank"> Apex </a>中的<a class="ae lb" href="https://nvidia.github.io/apex/optimizers.html" rel="noopener ugc nofollow" target="_blank">融合优化器</a>(如果安装的话)。</p><p id="1dee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看一些例子。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qy"><img src="../Images/a467237b7ec7f4da17eee5887b184108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VrJP_ULww_u93oFb5l8Lmw.png"/></div></div></figure><p id="78d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到，由于timm不包含SGD的实现，它已经使用“torch.optim”中的实现创建了我们的优化器。</p><p id="ae0f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们尝试创建一个在timm中实现的优化器。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qz"><img src="../Images/aee97ef53172408cd73da787d897a758.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LmcSG0hIqsJWuvcFyOdrA.png"/></div></div></figure><p id="8e2b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以验证已经使用了timm的<code class="fe lc ld le lf b">Lamb</code>实现，并且我们的权重衰减已经应用于参数组1。</p><p id="2359" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">手动创建优化器</strong></p><p id="1db9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，如果我们不想使用<code class="fe lc ld le lf b">create_optimizer_v2</code>，所有这些优化器都可以用通常的方式创建。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="2875" class="nl lx iq lf b gy qn qo l qp qq">optimizer = timm.optim.RMSpropTF(model.parameters(), lr=0.01)</span></pre><h2 id="5e2d" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">用法示例</h2><p id="621a" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">现在，我们可以使用大多数优化器，如下所示:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="f44c" class="nl lx iq lf b gy qn qo l qp qq"><em class="nh"># replace<br/># optimizer = torch.optim.Adam(model.parameters(), lr=0.01)<br/><br/># with<br/></em>optimizer = timm.optim.AdamP(model.parameters(), lr=0.01)<br/><br/>for epoch in num_epochs:<br/>    for batch in training_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        loss = loss_function(outputs, targets)<br/><br/>        loss.backward()<br/>        optimizer.step()<br/>        optimizer.zero_grad()</span></pre><p id="43a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在撰写本文时，唯一的例外是二阶<code class="fe lc ld le lf b">Adahessian</code>优化器，它在执行<code class="fe lc ld le lf b">backward</code>步骤时需要一个小的调整；类似的调整可能需要额外的二阶优化器，它们可能会在未来添加。</p><p id="3cfa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将在下面演示。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="66a9" class="nl lx iq lf b gy qn qo l qp qq">optimizer = timm.optim.Adahessian(model.parameters(), lr=0.01)<br/><br/>is_second_order = (<br/>    hasattr(optimizer, <strong class="lf ir">"is_second_order"</strong>) and optimizer.is_second_order<br/>)  <em class="nh"># True<br/><br/></em>for epoch in num_epochs:<br/>    for batch in training_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        loss = loss_function(outputs, targets)<br/><br/>        loss.backward(create_graph=second_order)<br/>        optimizer.step()<br/>        optimizer.zero_grad()</span></pre><h2 id="0afa" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">向前看</h2><p id="31a7" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">timm还使我们能够将前瞻算法应用于优化器；<a class="ae lb" href="https://arxiv.org/abs/1907.08610" rel="noopener ugc nofollow" target="_blank">此处介绍</a>和<a class="ae lb" href="https://www.youtube.com/watch?v=TxGxiDK0Ccc" rel="noopener ugc nofollow" target="_blank">此处精彩讲解</a>。前瞻可以提高学习的稳定性，降低内部优化器的方差，而计算和存储开销可以忽略不计。</p><p id="b8ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过在优化器名称前面加上<code class="fe lc ld le lf b">lookahead_</code>来对优化器应用前瞻。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="0bad" class="nl lx iq lf b gy qn qo l qp qq">optimizer = timm.optim.create_optimizer_v2(model.parameters(), opt='lookahead_adam', lr=0.01)</span></pre><p id="3c4c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">或者由timm的Lookahead类中的优化器实例进行包装:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="4f16" class="nl lx iq lf b gy qn qo l qp qq">timm.optim.Lookahead(optimizer, alpha=0.5, k=6)</span></pre><p id="5545" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当使用Lookahead时，我们需要更新我们的训练脚本以包括下面的行，来更新慢速权重。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="d231" class="nl lx iq lf b gy qn qo l qp qq">optimizer.sync_lookahead()</span></pre><p id="72c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是如何使用它的一个例子:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="14e9" class="nl lx iq lf b gy qn qo l qp qq">optimizer = timm.optim.AdamP(model.parameters(), lr=0.01)<br/>optimizer = timm.optim.Lookahead(optimizer)<br/><br/>for epoch in num_epochs:<br/>    for batch in training_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        loss = loss_function(outputs, targets)<br/><br/>        loss.backward()<br/><br/>        optimizer.step()<br/>        optimizer.zero_grad()<br/><br/>    optimizer.sync_lookahead()</span></pre><h1 id="50f2" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">调度程序</h1><p id="9778" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">在撰写本文时，timm包含以下调度程序:</p><ul class=""><li id="a5f4" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> StepLRScheduler </strong>:学习率每n步衰减一次；类似于<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR" rel="noopener ugc nofollow" target="_blank"> torch.optim.lr_scheduler。StepLR </a></li><li id="ba5c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">multi step scheduler</strong>:一个步骤调度器，支持多个里程碑，在这些里程碑上降低学习速率；类似<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR" rel="noopener ugc nofollow" target="_blank"> torch.optim.lr_scheduler。多步</a></li><li id="a504" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> PlateauLRScheduler </strong>:每次指定的指标达到稳定状态时，以指定的因子降低学习率；类似于<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau" rel="noopener ugc nofollow" target="_blank"> torch.optim.lr_scheduler。ReduceLROnPlateau </a></li><li id="3453" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">余弦调度器</strong>:带重启的余弦衰减调度，如本文<a class="ae lb" href="https://arxiv.org/abs/1608.03983" rel="noopener ugc nofollow" target="_blank">所述</a>；类似于<a class="ae lb" href="https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts" rel="noopener ugc nofollow" target="_blank"> torch.optim.lr_scheduler。CosineAnnealingWarmRestarts】</a></li><li id="c10c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">tanhlr scheduler</strong>:hyberbolic-tangent衰变纲图，重启，如本文<a class="ae lb" href="https://arxiv.org/abs/1806.01593" rel="noopener ugc nofollow" target="_blank">所述</a></li><li id="61c4" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> PolyLRScheduler </strong>:多项式衰减时间表，如<a class="ae lb" href="https://arxiv.org/abs/2004.05909" rel="noopener ugc nofollow" target="_blank">本文</a>所述</li></ul><p id="3264" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然在timm中实现的许多调度程序在PyTorch中都有对应的程序，但timm版本通常有不同的默认超参数，并提供额外的选项和灵活性；所有timm调度程序都有预热时期，并且可以选择向调度添加随机噪声。此外，<code class="fe lc ld le lf b">CosineLRScheduler</code>和<code class="fe lc ld le lf b">PolyLRScheduler</code>支持称为<em class="nh"> k-decay </em>的衰减选项，如这里的<a class="ae lb" href="https://arxiv.org/abs/2004.05909" rel="noopener ugc nofollow" target="_blank">所介绍的</a>。</p><p id="4e2f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在研究这些调度器提供的一些选项之前，让我们首先探索如何在定制的训练脚本中使用来自timm的调度器。</p><h2 id="9ad3" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">用法示例</h2><p id="9763" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">与PyTorch中包含的调度程序不同，每个时期更新两次timm调度程序是一种很好的做法:</p><ul class=""><li id="5c7e" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">在每次优化器更新之后，应该调用<code class="fe lc ld le lf b">.step_update</code>方法<strong class="kh ir">，使用下一次更新的I<em class="nh">index；在这里，我们将为PyTorch调度程序调用<code class="fe lc ld le lf b">.step</code></em></strong></li><li id="7306" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">在每个时段的末尾，应该调用<code class="fe lc ld le lf b">.step </code>方法<strong class="kh ir">，并使用下一个时段的<em class="nh">索引</em></strong></li></ul><p id="4e00" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过明确地提供更新的数量和时期索引，这使得timm调度器能够消除在PyTorch调度器中观察到的混淆的“最后时期”和“1”行为。</p><p id="6763" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我们如何使用timm调度程序的一个例子:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="4f94" class="nl lx iq lf b gy qn qo l qp qq">training_epochs = 300<br/>cooldown_epochs = 10<br/>num_epochs = training_epochs + cooldown_epochs<br/><br/>optimizer = timm.optim.AdamP(my_model.parameters(), lr=0.01)<br/>scheduler = timm.scheduler.CosineLRScheduler(optimizer, t_initial=training_epochs)<br/><br/>for epoch in range(num_epochs):<br/><br/>    num_steps_per_epoch = len(train_dataloader)<br/>    num_updates = epoch * num_steps_per_epoch<br/><br/>    for batch in training_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        loss = loss_function(outputs, targets)<br/><br/>        loss.backward()<br/>        optimizer.step()<br/>        scheduler.step_update(num_updates=num_updates)<br/><br/>        optimizer.zero_grad()<br/><br/>    scheduler.step(epoch + 1)</span></pre><h2 id="65e2" class="nl lx iq bd ly nm nn dn mc no np dp mg ko nq nr mi ks ns nt mk kw nu nv mm nw bi translated">调整学习率计划</h2><p id="f5bf" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">为了演示timm提供的一些选项，让我们探讨一些可用的超参数，以及修改这些参数对学习率计划的影响。</p><p id="03f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们将重点关注<code class="fe lc ld le lf b">CosineLRScheduler</code>，因为这是timm的培训脚本中默认使用的调度程序。然而，如上所述，在上面列出的所有调度器中都存在诸如添加预热和噪声之类的特性。</p><p id="1771" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了让我们能够可视化学习率计划，让我们定义一个函数来创建一个模型和优化器，以便与我们的计划程序一起使用。注意，由于我们将只更新调度程序，模型实际上并没有被优化，但是我们需要一个优化器实例来与我们的调度程序一起工作，而优化器需要一个模型。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="bdcf" class="nl lx iq lf b gy qn qo l qp qq">def create_model_and_optimizer():<br/>    model = torch.nn.Linear(2, 1)<br/>    optimizer = torch.optim.SGD(model.parameters(), lr=0.05)<br/>    return model, optimizer</span></pre><p id="f70f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用PyTorch中的“CosineAnnealingWarmRestarts”调度程序</strong></p><p id="6bcc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了说明timm的余弦调度器不同于PyTorch中包含的调度器，我们先来看看如何使用<code class="fe lc ld le lf b">ConsineAnnealingWarmRestarts</code>的Torch实现。</p><p id="0f9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该类支持以下参数:</p><ul class=""><li id="abed" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> T_0 </strong> ( <em class="nh"> int </em>):第一次重启的迭代次数。</li><li id="19f6" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> T_mult </strong> ( <em class="nh"> int </em>):重启后增加<em class="nh"> T_{i} </em>的因子。(默认值:` 1 `)</li><li id="155e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">eta _ min</strong>(<em class="nh">float</em>):最小学习率。(默认值:` 0 .`)</li><li id="0fc6" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">last _ epoch</strong>(<em class="nh">int</em>)—最后一个epoch的索引。(默认值:`-1 `)</li></ul><p id="8a39" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了设置我们的时间表，我们需要定义以下内容:时期的数量、每个时期发生的更新的数量，以及——如果我们想要允许重新启动——学习速率应该返回到其初始值的步骤的数量。因为我们在这里没有使用任何数据，所以我们可以任意设置这些数据。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="c0b3" class="nl lx iq lf b gy qn qo l qp qq">num_epochs=300<br/>num_epoch_repeat = num_epochs//2<br/>num_steps_per_epoch = 10</span></pre><p id="7363" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注意</strong>:在这里，我们已经指定我们希望学习率在训练运行的中途“重启”。这主要是出于可视化的目的而选择的，这样我们可以了解该调度程序的重启情况，而不是在实际训练运行中使用该调度程序的推荐方式。</p><p id="06b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们创建我们的学习率调度程序。由于<em class="nh"> T_0 </em>需要根据迭代次数来指定直到第一次重启的时间——其中每次迭代是一批——我们通过将我们希望重启发生的时期的索引乘以每个时期的步数来计算。这里，我们还指定学习率永远不应该低于“1e-6”。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ra"><img src="../Images/311a1d7caa96f5ff567f659c65c63174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o7af_y3S4Vfi5-2bbX6AzQ.png"/></div></div></figure><p id="8a29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以在训练循环中模拟使用这个调度程序。因为我们使用PyTorch实现，所以我们只需要在每次优化器更新后调用<code class="fe lc ld le lf b">step</code>，这是每批一次。在这里，我们记录每一步后的学习率值，这样我们可以直观地看到学习率值在整个训练过程中是如何调整的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rb"><img src="../Images/2bfc31468640a4879063ee36d3bdb93d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0efpG4C8LxeL7KNN797GNg.png"/></div></div></figure><p id="c302" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从该图中，我们可以看到，学习率衰减到第150个时期，在第150个时期，学习率在再次衰减之前被重置为初始值；正如我们所料。</p><p id="e4eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用timm中的“CosineLRScheduler”调度程序</strong></p><p id="110c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经了解了如何使用PyTorch的余弦调度器，让我们来看看它与timm中包含的实现以及提供的其他选项有何不同。首先，让我们使用timm实现的余弦学习率调度器— <code class="fe lc ld le lf b">CosineLRScheduler</code>来复制前面的图。</p><p id="7307" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要这样做的一些论据与我们之前看到的相似:</p><ul class=""><li id="e026" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir"> t_initial </strong> ( <em class="nh"> int </em>):第一次重启的迭代次数，相当于torch实现中的‘t _ 0’</li><li id="4c7f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir"> lr_min </strong> ( <em class="nh"> float </em>):最小学习率，相当于torch实现中的<strong class="kh ir"> eta_min </strong>(默认:` 0 .`)</li><li id="a45c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">cycle _ mul</strong>(<em class="nh">float</em>):重启后增加<em class="nh"> T_{i} </em>的因子，相当于torch实现中的<strong class="kh ir"> T_mult </strong>(默认:` 1 `)</li></ul><p id="5b33" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，为了观察与Torch一致的行为，我们还需要设置:</p><ul class=""><li id="4394" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir">cycle _ Limit</strong>(<em class="nh">int</em>):限制一个周期内的重启次数(默认:` 1 `)</li><li id="6ec4" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">t _ in _ epochs</strong>(<em class="nh">bool</em>):迭代次数是否按照epoch而不是批量更新的次数给出(默认:` True `)</li></ul><p id="79b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们像以前一样定义相同的时间表。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="eeab" class="nl lx iq lf b gy qn qo l qp qq">num_epochs=300<br/>num_epoch_repeat = num_epochs/2<br/>num_steps_per_epoch = 10</span></pre><p id="b335" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以创建调度程序实例了。这里，我们用更新步骤的数量来表示迭代的次数，并将周期限制增加到超过我们期望的重新启动次数；以便参数与我们之前在torch实现中使用的参数相同。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rc"><img src="../Images/df95697057f2eb2954a2f8295a4e1a62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4uRi6Sd_mEH0w17OMasvRw.png"/></div></div></figure><p id="7e3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们定义一个新函数来模拟在训练运行中使用timm调度程序，并记录学习率的更新。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="5eb4" class="nl lx iq lf b gy qn qo l qp qq">def plot_lrs_for_timm_scheduler(scheduler):<br/>    lrs = []<br/><br/>    for epoch in range(num_epochs):<br/>        num_updates = epoch * num_steps_per_epoch<br/><br/>        for i in range(num_steps_per_epoch):<br/>            num_updates += 1<br/>            scheduler.step_update(num_updates=num_updates)<br/><br/>        scheduler.step(epoch + 1)<br/><br/>        lrs.append(optimizer.param_groups[0][<strong class="lf ir">"lr"</strong>])<br/><br/>    plt.plot(lrs)</span></pre><p id="1044" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以用它来绘制我们的学习进度计划！</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rd"><img src="../Images/442ed1a5adde54e40c184220d78f4e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-2FQhKdgS0pij1h3Qj4CA.png"/></div></div></figure><p id="c742" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如所料，我们的图表看起来与我们之前看到的一模一样。</p><p id="be8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经复制了我们在torch中看到的行为，让我们更详细地看看timm提供的一些附加功能。</p><p id="132c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">到目前为止，我们已经用优化器更新来表示迭代次数；这需要我们使用<code class="fe lc ld le lf b">num_epoch_repeat * num_steps_per_epoch</code>来计算第一次重复的迭代次数，但是，通过根据历元指定迭代次数(这是timm中的默认设置),我们可以避免进行这种计算。使用默认设置，我们可以简单地传递我们希望第一次重启发生的时期的索引，如下所示。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi re"><img src="../Images/111faee9831ca5882b66faab155d28c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*akbY2EbFTNS8xU5hrlTmwg.png"/></div></div></figure><p id="4637" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，我们的时间表没有改变，我们只是稍微不同地表达了我们的论点。</p><p id="d3ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">添加预热和噪音</strong></p><p id="d974" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有timm优化器的另一个特点是，它们支持在学习率计划中增加热身和噪音。我们可以使用<em class="nh"> warmup_t </em>和<em class="nh"> warmup_lr_init </em>参数指定预热时期的数量以及预热期间使用的初始学习率。如果我们指定想要20个预热时期，让我们看看我们的时间表是如何变化的。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rf"><img src="../Images/c5b6392d01fa61268930de0338003504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dGsCc7w0xtkQQt-Ay042IA.png"/></div></div></figure><p id="31ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到，这导致了我们的最低学习率的逐渐增加，而不是像我们之前看到的那样从那个点开始。</p><p id="9b34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以使用<em class="nh"> noise_range_t </em>和<em class="nh"> noise_pct </em>参数向一系列时期添加噪声。让我们给前150个纪元添加少量噪声:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rg"><img src="../Images/26818cc072fb38b2a22e49ae7f5df43a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fu4bGpYeu3P6YKztQnAkRQ.png"/></div></div></figure><p id="5de7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，直到纪元150，添加的噪声影响我们的时间表，因此学习率不会以平滑的曲线下降。我们可以通过增加<em class="nh"> noise_pct </em>来使其更加极端。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rh"><img src="../Images/efa260179e22c6af127883fc31295e65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WjaptVoHQAr9Xugx3hUqJA.png"/></div></div></figure><p id="e086" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">“cosinelrscheduler”的附加选项</strong></p><p id="c7ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然预热和噪声可用于任何调度程序，但还有一些附加功能是<code class="fe lc ld le lf b">CosineLRScheduler</code>特有的。让我们探讨一下这些是如何影响我们的学习率周期的。</p><p id="7907" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用<em class="nh"> cycle_mul </em>，增加到下一次重启的时间，如下图所示。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ri"><img src="../Images/6373bb83d10971b644db03a6e0b3fa59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cV8kAvIyHtJT1NbFSAdjaw.png"/></div></div></figure><p id="7a14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，timm提供了使用<em class="nh"> cycle_limit </em>限制重启次数的选项。默认情况下，该值设置为“1 ”,这将产生以下计划。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi oi"><img src="../Images/a4564ced8fa822ada14c384b4e3ef5a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D663ME_xt8oZpRzlR7_hoA.png"/></div></div></figure><p id="e5d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lc ld le lf b">CosineLRScheduler</code>还支持不同类型的衰变。我们可以使用<em class="nh"> cycle_decay </em>来减少(或增加)将在每次连续重启期间设置的学习率值。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi op"><img src="../Images/02ea6d7eda03fffd235424f0dbb7e932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z4ZJX5KxHI0nVW9PhSRPpQ.png"/></div></div></figure><p id="0440" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注意</strong>:这里我们增加了重启次数的频率，以更好地说明衰减。</p><p id="a9a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了控制曲线本身，我们可以使用<em class="nh"> k_decay </em>参数，学习率的变化率由其k阶导数改变，如本文<a class="ae lb" href="https://arxiv.org/abs/2004.05909" rel="noopener ugc nofollow" target="_blank">所述</a>。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rj"><img src="../Images/8ce5b0d806484de35a0dafc785a0a828.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FpC43d5k31Mc4RIMVz-e8g.png"/></div></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi pc"><img src="../Images/196a708b0694d5e580addeaa98b3ae93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*98AG-v4omTQDJDov2Rk7TA.png"/></div></div></figure><p id="f364" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该选项提供了对该调度程序执行的退火的更多控制！</p><p id="527b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">timm培训脚本中的默认设置</strong></p><p id="0274" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们使用timm培训脚本中的默认设置来设置这个调度程序，我们会看到下面的调度程序。</p><p id="771c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注</strong>:在训练脚本中，训练将继续额外的10个周期，而不会进一步修改学习率作为“冷却”。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rk"><img src="../Images/9f93ab12d1a584026b0d4ea4294a2d81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7GhwmrXB6kEApERVroSeow.png"/></div></div></figure><p id="bb6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所看到的，在默认设置下根本没有重启！</p><p id="8945" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">其他学习率计划</strong></p><p id="dfa0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然timm中我最喜欢的调度器是<code class="fe lc ld le lf b">CosineLRScheduler</code>，但是可视化一些其他调度器的调度可能会有帮助，这些调度器在PyTorch中没有对应的调度器。这两种调度器都类似于余弦调度器，即学习率在指定数量的时期后重置(假设没有设置周期限制)，但退火的方式略有不同。</p><p id="711b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于<code class="fe lc ld le lf b">TanhLRScheduler</code>，使用双曲正切函数进行退火，如下所示。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rl"><img src="../Images/8b7acb9a955061db7fcbf58c131bf4c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04VbGetPJiiY-asooj4dGQ.png"/></div></div></figure><p id="3e98" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">timm还提供了<code class="fe lc ld le lf b">PolyLRScheduler</code>，它使用多项式衰减:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi qa"><img src="../Images/4d94d3eae01b7d64561b96c2c3032d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V3UC30cENUdXBSa82OOVRQ.png"/></div></div></figure><p id="1d02" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与<code class="fe lc ld le lf b">CosineLRScheduler</code>类似，<code class="fe lc ld le lf b">PolyLRScheduler</code>调度器也支持<em class="nh"> k_decay </em>参数，如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rm"><img src="../Images/9692c2970e0fd016c698ac58e3ff8bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*liPDk6ZAhAh4MPHVIu2RMQ.png"/></div></div></figure><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi rn"><img src="../Images/b68fda321858b96881e15a9d07116b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j6QLEP1syt2cUGA2dU6xtQ.png"/></div></div></figure><h1 id="429c" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">指数移动平均模型</h1><p id="50f7" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">在训练模型时，通过对在整个训练运行中观察到的参数进行移动平均来设置模型权重值可能是有益的，这与使用在最后一次增量更新之后获得的参数相反。实际上，这通常是通过维护一个<em class="nh"> EMA模型</em>来实现的，它是我们正在训练的模型的副本。然而，不是在每个更新步骤之后更新该模型的所有参数，而是使用现有参数值和更新值的线性组合来设置这些参数。这是使用以下公式完成的:</p><blockquote class="pl pm pn"><p id="d8bb" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">已更新_EMA_model_weights =</p><p id="f484" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">衰变* EMA_model_weights + (1。—衰变)*更新_模型_权重</p></blockquote><p id="fd73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中_decay_是我们设置的参数。例如，如果我们设置<em class="nh">衰变=0.99 </em>，我们有:</p><blockquote class="pl pm pn"><p id="76cb" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">已更新_EMA_model_weights =</p><p id="0037" class="kf kg nh kh b ki kj jr kk kl km ju kn po kp kq kr pp kt ku kv pq kx ky kz la ij bi translated">0.99 * EMA_model_weights + 0.01 *更新的_model_weights</p></blockquote><p id="7443" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到它保留了99%的现有状态，只保留了1%的新状态！</p><p id="11fb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了理解为什么这可能是有益的，让我们考虑这样的情况，我们的模型在训练的早期阶段，在一批数据上表现得非常差。这可能导致对我们的参数进行大量更新，过度补偿所获得的高损失，这对即将到来的批次是不利的。通过仅并入最新参数的一小部分，大的更新将被“平滑”，并且对模型的权重具有较小的整体影响。</p><p id="a04e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时，这些平均参数有时可以在评估期间产生明显更好的结果，并且这种技术已经在流行模型的几个训练方案中使用，例如训练<a class="ae lb" href="https://arxiv.org/abs/1807.11626v3" rel="noopener ugc nofollow" target="_blank"> MNASNet </a>、<a class="ae lb" href="https://arxiv.org/abs/1905.02244v5" rel="noopener ugc nofollow" target="_blank"> MobileNet-V3 </a>和<a class="ae lb" href="https://arxiv.org/abs/1905.11946v5" rel="noopener ugc nofollow" target="_blank">efficient net</a>；使用TensorFlow 中包含的<a class="ae lb" href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage" rel="noopener ugc nofollow" target="_blank">实现。使用timm中实现的<code class="fe lc ld le lf b">ModelEmaV2</code>模块，我们可以复制这种行为，并将相同的实践应用到我们自己的训练脚本中。</a></p><p id="2972" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe lc ld le lf b">ModelEmaV2</code>的实现需要以下参数:</p><ul class=""><li id="2c4f" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><strong class="kh ir">模型</strong>:nn<em class="nh">的子类。我们正在培训的模块</em>。这是将在我们的训练循环中正常更新的模型</li><li id="300c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">衰减</strong> : ( <em class="nh"> float </em>)要使用的衰减量，它决定了之前的状态会保持多少。TensorFlow文档建议衰减的合理值接近1.0，通常在多个9的范围内:0.999、0.9999等。(默认值:` 0.9999 `)</li><li id="c912" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><strong class="kh ir">设备</strong>:应该用来评估EMA模型的设备。如果未设置此项，EMA模型将在用于该模型的同一设备上创建。</li></ul><p id="9c71" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们探索一下如何将这一点融入到培训循环中。</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="b1bb" class="nl lx iq lf b gy qn qo l qp qq">model = create_model().to(gpu_device)<br/>ema_model = ModelEmaV2(model, decay=0.9998)<br/><br/>for epoch in num_epochs:<br/>    for batch in training_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        loss = loss_function(outputs, targets)<br/><br/>        loss.backward()<br/>        optimizer.step()<br/>        optimizer.zero_grad()<br/><br/>        model_ema.update(model)<br/><br/>    for batch in validation_dataloader:<br/>        inputs, targets = batch<br/>        outputs = model(inputs)<br/>        validation_loss = loss_function(outputs, targets)<br/><br/>        ema_model_outputs = model_ema.module(inputs)<br/>        ema_model_validation_loss = loss_function(ema_model_outputs, targets)</span></pre><p id="f3fc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们看到的，要更新EMA模型的参数，我们需要在每次参数更新后调用<code class="fe lc ld le lf b">.update</code>。由于EMA模型和被训练的模型有不同的参数，我们必须单独评估。</p><p id="02ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">值得注意的是，这个类对它的初始化位置很敏感。在分布式训练期间，应该在转换到<em class="nh"> SyncBatchNorm </em>之前和使用<em class="nh">分布式数据并行</em>包装器之前应用它！</p><p id="04a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，当保存EMA模型时，<em class="nh"> state_dict </em>中的键将与被训练模型的键相同，所以应该使用不同的检查点！</p><h1 id="901e" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">把所有的东西放在一起！</h1><p id="0ae9" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">虽然整篇文章中的伪代码片段说明了如何在训练循环中单独使用每个组件，但是让我们探索一下一次使用许多不同组件的示例！</p><p id="b152" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们将看看如何在Imagenette上训练一个模型。注意，由于Imagenette是Imagenet的子集，如果我们使用预训练的模型，我们会稍微作弊，因为只有新的分类头会用随机权重初始化；因此，在本例中，我们将从头开始训练。</p><p id="1ea7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注意:</strong>这个例子的目的是演示如何一起使用timm的多个组件。因此，所选择的特征以及所使用的超参数在某种程度上是任意选择的；因此，通过一些仔细的调整，性能可能会得到提高！</p><p id="c334" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了去除我们通常在PyTorch训练循环中看到的样板文件，比如遍历数据加载器和在设备之间移动数据，我们将使用PyTorch-accelerated来处理我们的训练；这使我们能够只关注使用timm组件时所需的差异。</p><p id="3585" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nh">如果您对PyTorch-accelerated不熟悉，并且希望在阅读本文之前了解更多相关信息，请查看</em> <a class="ae lb" href="https://medium.com/@chris.p.hughes10/introducing-pytorch-accelerated-6ba99530608c?source=friends_link&amp;sk=868c2d2ec5229fdea42877c0bf82b968" rel="noopener"> <em class="nh">介绍性博客文章</em> </a> <em class="nh">或</em> <a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/index.html#" rel="noopener ugc nofollow" target="_blank"> <em class="nh">文档</em></a><em class="nh">；或者，这很简单，缺乏这方面的知识不会影响您对本文所探讨内容的理解！</em></p><p id="d286" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在PyTorch-accelerated中，训练循环由“训练者”类处理；我们可以覆盖特定的方法来改变特定步骤的行为。在伪代码中，PyTorch加速训练器中训练运行的执行可以描述为:</p><pre class="lh li lj lk gt qj lf qk ql aw qm bi"><span id="c431" class="nl lx iq lf b gy qn qo l qp qq">train_dl = create_train_dataloader()<br/>eval_dl = create_eval_dataloader()<br/>scheduler = create_scheduler()<br/><br/>training_run_start()<br/>on_training_run_start()<br/><br/><strong class="lf ir">for</strong> epoch <strong class="lf ir">in</strong> num_epochs:<br/>    train_epoch_start()<br/>    on_train_epoch_start()<br/>    <strong class="lf ir">for</strong> batch <strong class="lf ir">in</strong> train_dl:<br/>        on_train_step_start()<br/>        batch_output = calculate_train_batch_loss(batch)<br/>        on_train_step_end(batch, batch_output)<br/>        backward_step(batch_output["loss"])<br/>        optimizer_step()<br/>        scheduler_step()<br/>        optimizer_zero_grad()<br/>    train_epoch_end()<br/>    on_train_epoch_end()<br/><br/>    eval_epoch_start()<br/>    on_eval_epoch_start()<br/>    <strong class="lf ir">for</strong> batch <strong class="lf ir">in</strong> eval_dl:<br/>        on_eval_step_start()<br/>        batch_output = calculate_eval_batch_loss(batch)<br/>        on_eval_step_end(batch, batch_output)<br/>    eval_epoch_end()<br/>    on_eval_epoch_end()<br/><br/>    training_run_epoch_end()<br/>    on_training_run_epoch_end()<br/><br/>training_run_end()<br/>on_training_run_end()</span></pre><p id="5d66" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于训练器如何工作的更多细节可以在文档中找到<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/trainer.html#" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0587" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以对默认教练进行子类化，并在培训脚本中使用，如下所示:</p><figure class="lh li lj lk gt ll"><div class="bz fp l di"><div class="qt qu l"/></div></figure><p id="195d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在使用2个GPU的Imagenette上使用此培训脚本，<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank">按照此处的说明</a>，我获得了以下指标:</p><ul class=""><li id="1f4f" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated"><em class="nh">精度</em> : 0.89</li><li id="be8f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><em class="nh"> ema_model_accuracy </em> : 0.85</li></ul><p id="e757" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">34个纪元后；考虑到超参数还没有调优，这并不坏！</p><h1 id="02af" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">结论</h1><p id="8af7" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">希望这已经提供了timm中包含的一些特性的全面概述，以及如何将这些特性应用到定制的培训脚本中。</p><p id="fbf4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我想花点时间感谢timm的创造者Ross Wightman为创建这个令人敬畏的图书馆所付出的巨大努力。Ross致力于为整个数据科学界提供易于访问的最先进的计算机视觉模型的实现，这是首屈一指的。如果你还没有，那就去加星星吧！</p><p id="0fd9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">复制这篇文章所需的所有代码都可以在GitHub gist <a class="ae lb" href="https://gist.github.com/Chris-hughes10/a9e5ec2cd7e7736c651bf89b5484b4a9" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">这里</strong> </a>找到。</p><p id="b81d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nh">克里斯·休斯正在上</em><a class="ae lb" href="http://www.linkedin.com/in/chris-hughes1/" rel="noopener ugc nofollow" target="_blank"><em class="nh">LinkedIn</em></a><em class="nh">。</em></p><h1 id="83f5" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">参考</h1><ul class=""><li id="a61d" class="mt mu iq kh b ki mo kl mp ko ro ks rp kw rq la my mz na nb bi translated"><a class="ae lb" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank">rwightman/py torch-image-models:py torch图像模型、脚本、预训练权重— ResNet、ResNeXT、EfficientNet、EfficientNetV2、NFNet、Vision Transformer、MixNet、MobileNet-V3/V2、RegNet、DPN、CSPNet等等(github.com)</a></li><li id="c937" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://medium.com/paperswithcode/papers-with-code-2021-a-year-in-review-de75d5a77b8b" rel="noopener">代码为2021的论文:一年回顾|作者Elvis | Papers with Code | 2021年12月| Medium </a></li><li id="107f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">ImageNet(image-net.org)</a></li><li id="52bc" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://rwightman.github.io/pytorch-image-models/" rel="noopener ugc nofollow" target="_blank"> Pytorch图像模型(rwightman.github.io) </a></li><li id="647d" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://fastai.github.io/timmdocs/" rel="noopener ugc nofollow" target="_blank"> Pytorch图像模型(timm)| timm docs(fastai . github . io)</a></li><li id="c03a" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://paperswithcode.com/lib/timm" rel="noopener ugc nofollow" target="_blank"> PyTorch图像模型|论文代码</a></li><li id="1c60" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1812.01187" rel="noopener ugc nofollow" target="_blank">【1812.01187】卷积神经网络图像分类的锦囊妙计(arxiv.org)</a></li><li id="08ed" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2010.11929v2" rel="noopener ugc nofollow" target="_blank">【2010.11929 v2】一张图像抵得上16x16字:大规模图像识别的变形金刚(arxiv.org)</a></li><li id="acfd" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://ieeexplore.ieee.org/document/8099589" rel="noopener ugc nofollow" target="_blank">用于目标检测的特征金字塔网络| IEEE会议出版物| IEEE Xplore </a></li><li id="915d" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津大学视觉几何组</a></li><li id="06f9" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/vision/stable/index.html" rel="noopener ugc nofollow" target="_blank">火炬视觉—火炬视觉0.11.0文档(pytorch.org)</a></li><li id="484a" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/fx.html#module-torch.fx" rel="noopener ugc nofollow" target="_blank"> torch.fx — PyTorch 1.10.1文档</a></li><li id="e474" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/blog/FX-feature-extraction-torchvision/" rel="noopener ugc nofollow" target="_blank">火炬视觉中使用火炬FX | PyTorch的特征提取</a></li><li id="f82b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/jit.html" rel="noopener ugc nofollow" target="_blank"> TorchScript — PyTorch 1.10.1文档</a></li><li id="429e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html" rel="noopener ugc nofollow" target="_blank">torch script简介— PyTorch教程1.10.1+cu102文档</a></li><li id="5ba9" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank"> ONNX | Home </a></li><li id="9098" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/master/onnx.html" rel="noopener ugc nofollow" target="_blank"> torch.onnx — PyTorch主文档</a></li><li id="64bb" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1909.13719" rel="noopener ugc nofollow" target="_blank">【1909.13719】rand augment:缩小搜索空间的实用自动数据扩充(arxiv.org)</a></li><li id="372e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2110.00476v1#:~:text=ResNet%20strikes%20back%3A%20An%20improved%20training%20procedure%20in,or%20as%20baselines%20when%20new%20architectures%20are%20proposed." rel="noopener ugc nofollow" target="_blank">【2110.00476 v1】雷斯内特反击:蒂姆(arxiv.org)的改进训练程序</a></li><li id="ab3b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1905.04899" rel="noopener ugc nofollow" target="_blank">【1905.04899】cut mix:训练具有可本地化特征的强分类器的正则化策略(arxiv.org)</a></li><li id="cfc9" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1710.09412" rel="noopener ugc nofollow" target="_blank">【1710.09412】混乱:超越经验风险最小化(arxiv.org)</a></li><li id="ae8a" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/vision/0.11/datasets.html" rel="noopener ugc nofollow" target="_blank">torch vision . datasets—torch vision 0 . 11 . 0文档(pytorch.org)</a></li><li id="7990" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.tensorflow.org/datasets" rel="noopener ugc nofollow" target="_blank">张量流数据集</a></li><li id="87a2" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/data.html#dataset-types" rel="noopener ugc nofollow" target="_blank">torch . utils . data—py torch 1 . 10 . 1文档</a></li><li id="0c40" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://docs.python.org/3/library/pathlib.html" rel="noopener ugc nofollow" target="_blank">path lib——面向对象的文件系统路径——Python 3 . 10 . 2文档</a></li><li id="aab0" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/optim.html" rel="noopener ugc nofollow" target="_blank"> torch.optim — PyTorch 1.10.1文档</a></li><li id="3037" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2006.08217" rel="noopener ugc nofollow" target="_blank">【2006.08217】AdamP:在尺度不变权重上减缓动量优化器的减速(arxiv.org)</a></li><li id="cdb8" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" rel="noopener ugc nofollow" target="_blank">讲座_幻灯片_ LEC 6 . pdf(toronto.edu)</a></li><li id="8bc8" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://nvidia.github.io/apex/index.html" rel="noopener ugc nofollow" target="_blank">Apex(py torch扩展)— Apex 0.1.0文档(nvidia.github.io) </a></li><li id="bd6b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2010.07468" rel="noopener ugc nofollow" target="_blank">【2010.07468】AdaBelief优化器:根据观测梯度的置信度调整步长(arxiv.org)</a></li><li id="ff3c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://github.com/juntang-zhuang/Adabelief-Optimizer#quick-guide" rel="noopener ugc nofollow" target="_blank">庄/Adabelief-Optimizer:neur IPS 2020聚焦“AdaBelief Optimizer:通过对观测梯度的信念来调整步长”(github.com)</a></li><li id="0450" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2101.11075" rel="noopener ugc nofollow" target="_blank">【2101.11075】不妥协的适应性:随机优化的动量化、适应性、双平均梯度法(arxiv.org)</a></li><li id="b544" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2006.00719" rel="noopener ugc nofollow" target="_blank">【2006.00719】ADAHESSIAN:用于机器学习的自适应二阶优化器(arxiv.org)</a></li><li id="818d" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1907.08610" rel="noopener ugc nofollow" target="_blank">【1907.08610】前瞻优化器:向前k步，向后1步(arxiv.org)</a></li><li id="9c6c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.youtube.com/watch?v=TxGxiDK0Ccc" rel="noopener ugc nofollow" target="_blank">前瞻优化器:向前k步，向后1步| Michael Zhang — YouTube </a></li><li id="8484" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="noopener ugc nofollow" target="_blank"> torch.optim — PyTorch 1.10.1文档</a></li><li id="809c" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1806.01593" rel="noopener ugc nofollow" target="_blank">【1806.01593】分类上具有双曲正切衰减的随机梯度下降(arxiv.org)</a></li><li id="9b53" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/2004.05909" rel="noopener ugc nofollow" target="_blank">【2004.05909】k-decay:一种学习速率表的新方法(arxiv.org)</a></li><li id="8363" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://arxiv.org/abs/1807.11626v3" rel="noopener ugc nofollow" target="_blank">【1807.11626 v3】mnas net:面向移动的平台感知神经架构搜索(arxiv.org)</a></li><li id="acc8" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">【arxiv.org T2】【1905.11946 V5】efficient net:卷积神经网络模型缩放的再思考</li><li id="7280" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">【arxiv.org T4】【1905.02244 V5】搜索MobileNetV3</li><li id="6984" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage" rel="noopener ugc nofollow" target="_blank"> tf.train .指数移动平均| TensorFlow Core v2.7.0 </a></li><li id="02b0" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/introducing-pytorch-accelerated-6ba99530608c">介绍PyTorch加速|克里斯·休斯| 2021年11月|迈向数据科学</a></li><li id="8a8f" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated"><a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">欢迎阅读pytorch-accelerated的文档！— pytorch加速0.1.3文档</a></li></ul></div></div>    
</body>
</html>