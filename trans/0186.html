<html>
<head>
<title>TensorFlow/Keras cheat sheet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow/Keras 备忘单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-keras-cheat-sheet-5ec99d9a1ccf#2022-02-08">https://towardsdatascience.com/tensorflow-keras-cheat-sheet-5ec99d9a1ccf#2022-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fc59" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们经常使用的所有标准模式都集中在一个地方</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4791c6116898490d7cb1dfafa32ca685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KrH_SEq-SsR0-p5tqwrtzA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预览。作者图片</p></figure><p id="e3ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，您将找到使用 TensorFlow/Keras 构建神经网络的完整备忘单。我在准备<a class="ae lu" href="https://www.tensorflow.org/certificate" rel="noopener ugc nofollow" target="_blank"> TensorFlow 开发者认证考试</a>时准备了这张小抄，它给了我很大的帮助。阅读以下文章，了解更多我的考试经历。</p><div class="lv lw gp gr lx ly"><a href="https://medium.com/@andimid/dont-be-afraid-to-take-the-tensorflow-developer-exam-by-google-e083fb26eecf" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">不要害怕参加 Google 的 TensorFlow 开发者考试</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">通过考试你需要知道什么，为什么现在是开始的最佳时机</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">medium.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="2afd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以在下面的<a class="ae lu" href="https://gitlab.com/Winston-90/tf_cheat_sheet" rel="noopener ugc nofollow" target="_blank"> GitLab 资源库</a>中访问该备忘单。</p><div class="lv lw gp gr lx ly"><a href="https://gitlab.com/Winston-90/tf_cheat_sheet" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">Dmytro Nikolaiev / tf_cheat_sheet</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">TensorFlow/Keras 备忘单</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">gitlab.com</p></div></div><div class="mh l"><div class="mn l mj mk ml mh mm ks ly"/></div></div></a></div><p id="c662" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事不宜迟，我们开始工作吧。</p><h1 id="bb6e" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">备忘单结构</h1><p id="586a" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">为了与我的叙述保持一致，首先，我们将看一些具有<em class="nl">顺序 API </em>的<em class="nl">典型神经网络架构</em>，并且还将<em class="nl">视为具有<em class="nl">功能 API </em>的非顺序架构</em>的示例。然后我们再考虑<code class="fe nm nn no np b">tf.keras.Model</code>对象的主要方法:<em class="nl">编译</em>、<em class="nl">拟合</em>(使用<em class="nl">回调</em>)、<em class="nl">求值</em>、<em class="nl">保存</em>和<em class="nl">加载</em>。</p><p id="c29d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们还将看看用于计算机视觉的<em class="nl">图像数据生成器</em><em class="nl"/>和用于 NLP 任务的<em class="nl">标记/填充句子</em>。在存储库中，这段代码位于代码文件的开头，但在这里我决定把它放在最后，因为它更专业，但同时又被广泛使用。</p><h2 id="6b74" class="nq mp it bd mq nr ns dn mu nt nu dp my lh nv nw na ll nx ny nc lp nz oa ne ob bi translated">进口</h2><p id="bd79" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">为了以后不被进口分散注意力，我马上列出来。我发现单独导入每一层不太方便，所以我使用了<code class="fe nm nn no np b">tf.keras.layers.layer</code>或<code class="fe nm nn no np b">layers.layer</code>结构。是个人口味，所以你的进口可能会略有不同。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="6d5c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">一些变量也是事先指定的，没有列在下面的列表中。基本上，这些都是用大写字母打印的常量，或者只是帮助变量和函数，比如到一些目录或数据集准备的路径。<strong class="la iu">请注意，当你按顺序运行这段代码时，你会得到一些错误:这是一个备忘单，不是脚本或程序。</strong></p><h1 id="4db3" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">具有顺序 API 的典型神经网络架构</h1><p id="d864" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">神经网络的三个主要架构是深度前馈(通常称为深度)、卷积和递归网络:DNN、CNN 和 RNN。</p><ul class=""><li id="640b" class="oe of it la b lb lc le lf lh og ll oh lp oi lt oj ok ol om bi translated">DNN 广泛用于一般用途的任务。<br/>通常是一个简单的全连接(<em class="nl">密集</em>)层序列，增加了一些内容:<em class="nl">脱落</em>、<em class="nl">批量正常化</em>，跳过连接等等。</li><li id="132d" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">CNN 用于图像处理:图像分类、对象检测、语义分割和其他计算机视觉任务。<br/>通常，简单的 CNN 架构是一系列<em class="nl">卷积池模块</em>和一个小的全连接网络。</li></ul><p id="8f92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">RNN 适用于顺序数据处理，即 NLP 任务和时序预测。</p><ul class=""><li id="65ec" class="oe of it la b lb lc le lf lh og ll oh lp oi lt oj ok ol om bi translated">NLP 架构的典型 RNN 是一个<em class="nl">嵌入</em>层(预训练或未训练)和一系列<em class="nl">双向 LSTM </em>层，因为所有文本对模型都是立即可见的。</li><li id="c7f3" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">时间序列预测的 RNN 通常是单向的，尽管使用双向层也可以提高质量。<em class="nl"> 1D 卷积</em>等技巧和窍门在这里也被广泛运用。</li></ul><p id="5fcc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">顺序 API 的官方文档是<a class="ae lu" href="https://www.tensorflow.org/guide/keras/sequential_model" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="cb25" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">具有功能 API 的更复杂的神经网络架构</h1><p id="d6be" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">Functional API 允许您在网络中添加非顺序连接，并指定多个输入和输出。下面是一个相当繁琐，但是演示性的网络描述，它采用文本、图像和几个数字作为输入特征。</p><p id="1bf0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">功能 API 的官方文档在这里是<a class="ae lu" href="https://www.tensorflow.org/guide/keras/functional" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="b923" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当<code class="fe nm nn no np b">model.summary()</code>方法不能很好地显示网络结构时，您可以可视化您的模型，以便更清楚地探索它。我在本文的<a class="ae lu" rel="noopener" target="_blank" href="/predicting-the-number-of-dislikes-on-youtube-videos-part-2-model-aa981a69a8b2">中描述了不同的可视化技术(参见<strong class="la iu">可视化神经网络架构</strong>部分)。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/8e9963fb107c77ee13a697c7733d0247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jHtjUXlODH6FZjI6aluuqQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ot">上图网络的可视化 plot _ model()函数的输出。作者图片</em></p></figure><h1 id="04c2" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">编译模型</h1><p id="b676" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">使用<code class="fe nm nn no np b">model.compile()</code>方法，我们设置了三个主要参数:优化器、损失函数和要观察的指标。优化器的标准选择是<em class="nl"> Adam </em>或<em class="nl"> RMSProp、</em>，标准度量是分类的<em class="nl">准确性</em>和回归的<em class="nl"> MSE 或 MAE </em>。</p><p id="de66" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">损失函数的选择很大程度上取决于任务，但通常情况下，这些是标准值:</p><ul class=""><li id="39f1" class="oe of it la b lb lc le lf lh og ll oh lp oi lt oj ok ol om bi translated"><em class="nl"> MSE </em>，<em class="nl"> MAE </em>或<em class="nl"> Huber </em>回归损失，</li><li id="186f" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated"><em class="nl">二进制交叉熵</em>二进制分类的损失，以及</li><li id="2caa" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated"><em class="nl">稀疏分类交叉熵</em>如果您的标签是整数(即 3 类分类为 1，2，3)，则多类分类任务的损失。<br/> <em class="nl">分类交叉熵</em>损失通常在你的标签被表示为一个热编码向量(即[1，0，0]，[0，1，0]和[0，0，1]用于 3 类分类)时使用。</li></ul><p id="5362" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nm nn no np b">compile</code>方法的官方文件是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile" rel="noopener ugc nofollow" target="_blank">这里是</a>。<br/>这里的<a class="ae lu" href="https://keras.io/api/optimizers/#available-optimizers" rel="noopener ugc nofollow" target="_blank">是可用优化器的列表</a>。<br/>这里的<a class="ae lu" href="https://keras.io/api/losses/" rel="noopener ugc nofollow" target="_blank">是可用损失清单</a>。<br/>可用指标列表在这里是<a class="ae lu" href="https://keras.io/api/metrics/" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="a46d" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">训练模型</h1><p id="82f3" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">当我们定义并编译了模型后，我们就可以开始学习过程了。<code class="fe nm nn no np b">model.fit()</code>是模型的主要方法，执行该方法，网络从数据中学习。您可以通过指定不同的数据源来训练网络，但最典型的是数组或张量形式的<em class="nl">常规数据</em>，计算机视觉的<em class="nl"> ImageDataGenerator </em>，NLP 的<em class="nl">填充序列</em>，以及<code class="fe nm nn no np b">tf.data.Dataset</code>对象。验证数据可以明确指定，也可以通过设置<code class="fe nm nn no np b">validation_split</code>参数来指定。</p><p id="e060" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">应该特别注意<em class="nl">回调</em>，因为它们现在就被指定。这些是在训练期间执行的特定功能。在我看来，其中最典型的是<em class="nl">模型检查点</em>(在其训练期间保存您的模型)和<em class="nl">提前停止</em>(如果损失停止改善，则停止训练过程)。</p><p id="c3c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nm nn no np b">fit</code>方法的官方文件在这里是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit" rel="noopener ugc nofollow" target="_blank"/>。<br/>可用回调列表在这里是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks" rel="noopener ugc nofollow" target="_blank"/>。<br/>model check point 的官方文档在这里是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="noopener ugc nofollow" target="_blank"/>。<br/>提前停止的官方文件是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="38b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意，上面的每个方法调用都是不同的，您必须正确指定模型结构和模型编译。有关更多详细信息，请参见 repo 中的完整代码文件。</p><h1 id="d9e5" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated"><strong class="ak">探索学习曲线</strong></h1><p id="9691" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">不要忘记将你的培训结果保存到一个<code class="fe nm nn no np b">history</code>变量中，以探索学习曲线——它们可以告诉你很多关于学习的信息。以下功能是<a class="ae lu" href="https://github.com/https-deeplearning-ai/tensorflow-1-public" rel="noopener ugc nofollow" target="_blank">官方 TensorFlow 开发者专业认证库</a>的一部分。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="1fe5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">此外，请记住，使用 Jupyter Notebook 或 Google Collab，您可以使用特殊的<code class="fe nm nn no np b">_</code>变量来保存学习过程，该变量会记住最后返回的函数/语句的值。更多详情请浏览回购中的<a class="ae lu" href="https://gitlab.com/Winston-90/tf_cheat_sheet/-/blob/main/special_variable_example.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">special _ variable _ example . ipynb</strong></a><strong class="la iu"/>笔记本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/2cef810da330382b34e03abaeaaaf25c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-Eh3lEVIz8M49-x_pz4QQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">特殊变量的例子。作者图片</p></figure><h1 id="ca2a" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">评估模型</h1><p id="ac3c" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated"><code class="fe nm nn no np b">model.evaluate()</code>方法可以让你看到你的模型在以前看不到的数据上的表现——通常，这是一个在你的研究开始时被搁置的测试集。</p><p id="2e8d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nm nn no np b">evaluate</code>方法的官方文件是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="742f" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated"><strong class="ak">保存并加载模型</strong></h1><p id="a696" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">保存模型以便加载和以后使用是非常重要的。我还为您提供了一个代码来保存您的模型，在文件名中使用<em class="nl">当前日期和时间</em>，这样您就可以运行多个训练过程，并确保您的所有结果都将被保存。</p><p id="1d60" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nm nn no np b">save</code>法的官方文件是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#save" rel="noopener ugc nofollow" target="_blank">这里是</a>。<br/>关于<code class="fe nm nn no np b">load_model</code>功能的官方文档在这里是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="0a7b" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">为计算机视觉和 NLP 任务准备数据</h1><p id="18ad" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">至此，小抄的总论部分(关于神经网络)告一段落。最后，让我为 ImageDataGenerator 和文本数据准备提供一些有用的代码片段。</p><h2 id="1b8b" class="nq mp it bd mq nr ns dn mu nt nu dp my lh nv nw na ll nx ny nc lp nz oa ne ob bi translated">使用 ImageDataGenerator</h2><p id="514c" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">ImageDataGenerator 将在计算机视觉任务中为你提供很大帮助——它会根据目录结构自动标记你的图像，或者为你执行内存中的数据扩充。</p><p id="6f77" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ImageDataGenerator 的官方文档是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h2 id="8c5b" class="nq mp it bd mq nr ns dn mu nt nu dp my lh nv nw na ll nx ny nc lp nz oa ne ob bi translated">自然语言处理任务中句子的标记和填充</h2><p id="8cfe" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">标记化和填充句子是 NLP 任务的常见做法。首先，你把句子转换成向量，然后你确保所有这些向量有一个固定的长度来输入你的模型。</p><p id="4b43" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你也可以像我在<a class="ae lu" rel="noopener" target="_blank" href="/predicting-the-number-of-dislikes-on-youtube-videos-part-2-model-aa981a69a8b2">这篇文章</a>中所做的那样使用文本矢量化层(参见<strong class="la iu">使用预训练的单词嵌入将文本转换为矢量</strong>部分)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/df7801bfa2fcde3797af303ae8fd4e8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-0XLjc7fiO2DnE-Bn2LlGA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 TensorFlow 的文本数据预处理选项。作者图片</p></figure><p id="462e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Tokenizer 的官方文档是这里的<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer" rel="noopener ugc nofollow" target="_blank"/>。<br/><code class="fe nm nn no np b">pad_sequences</code>方法的官方文档在这里是<a class="ae lu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="442e" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">结论</h1><p id="171b" class="pw-post-body-paragraph ky kz it la b lb ng ju ld le nh jx lg lh ni lj lk ll nj ln lo lp nk lr ls lt im bi translated">当然，不可能在一个备忘单中收集所有潜在的 TensorFlow/Keras 模式，但我认为我成功地以方便的形式收集了这里的主要模式。</p><p id="ace7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当你使用小抄的时候，它会带来很多好处，但是当你创建小抄的时候，好处会更多。读完这篇文章后，试着为自己创建一个类似的备忘单，纠正错误或不准确之处，并根据你的特定任务进行调整——这可能是一个很好的练习。之后，别忘了分享你的结果，并与我的进行比较(见<a class="ae lu" href="https://gitlab.com/Winston-90/tf_cheat_sheet" rel="noopener ugc nofollow" target="_blank">本资源库</a>)。祝你好运！</p></div><div class="ab cl ow ox hx oy" role="separator"><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb pc"/><span class="oz bw bk pa pb"/></div><div class="im in io ip iq"><h1 id="ea7c" class="mo mp it bd mq mr pd mt mu mv pe mx my jz pf ka na kc pg kd nc kf ph kg ne nf bi translated">感谢您的阅读！</h1><ul class=""><li id="3bf5" class="oe of it la b lb ng le nh lh pi ll pj lp pk lt oj ok ol om bi translated">我希望这些材料对你有用。<a class="ae lu" href="https://medium.com/@andimid" rel="noopener">在 Medium 上关注我</a>获取更多类似的文章。</li><li id="fa07" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">如果您有任何问题或意见，我将很高兴得到任何反馈。在评论中问我，或者通过<a class="ae lu" href="https://www.linkedin.com/in/andimid/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae lu" href="https://twitter.com/dimid_ml" rel="noopener ugc nofollow" target="_blank"> Twitter </a>联系。</li><li id="499f" class="oe of it la b lb on le oo lh op ll oq lp or lt oj ok ol om bi translated">为了支持我作为一名作家，并获得数以千计的其他媒体文章，使用<a class="ae lu" href="https://medium.com/@andimid/membership" rel="noopener">我的推荐链接</a>获得媒体会员资格(不收取额外费用)。</li></ul><h1 id="0499" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated"><strong class="ak">参考文献</strong></h1><div class="lv lw gp gr lx ly"><a href="https://keras.io/api/" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">Keras 文档 Keras API 参考</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">Keras 文档</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">Keras API 参考 Keras 文档 keras.io</p></div></div><div class="mh l"><div class="pl l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a href="https://www.tensorflow.org/api_docs/python/tf" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">模块:tf | TensorFlow Core v2.7.0</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">张量流</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">核心版本 2 . 7 . 0 TensorFlowwww.tensorflow.org</p></div></div><div class="mh l"><div class="pm l mj mk ml mh mm ks ly"/></div></div></a></div></div></div>    
</body>
</html>