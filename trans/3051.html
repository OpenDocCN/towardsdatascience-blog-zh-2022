<html>
<head>
<title>YOLOv6: next-generation object detection — review and comparison</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv6:下一代物体探测—回顾与比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f#2022-07-05">https://towardsdatascience.com/yolov6-next-generation-object-detection-review-and-comparison-c02e515dc45f#2022-07-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7d4a67ed1a8aea9891d8900cfef8ebd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ntuxZniu-76-7ODdQmaemA.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://unsplash.com/photos/jXd2FSvcRr8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><p id="eb73" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">近年来，计算机视觉领域发展迅速，并取得了几年前看起来像科幻小说一样的成果。从<a class="ae jd" href="https://dagshub.com/nirbarazida/pneumonia-Classification" rel="noopener ugc nofollow" target="_blank">分析x光图像</a>和诊断病人到(半)自动驾驶汽车，我们正在见证一场革命。这些突破有很多原因——构建更好、更易访问的计算资源，但事实上它们是我们最接近<a class="ae jd" href="https://dagshub.com/blog/a-case-for-open-source-data-science/" rel="noopener ugc nofollow" target="_blank">开源数据科学</a> (OSDS)的东西。向社区公开源代码可以释放“群众的智慧”,实现大规模创新和解决问题。</p><p id="6d86" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算机视觉领域最受欢迎的操作系统项目之一是YOLO(你只需看一次)。YOLO是一种高效的实时对象检测算法，由Joseph Redmon等人在2015年的开创性论文<a class="ae jd" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">中首次描述。YOLO将图像划分为一个网格系统，每个网格检测自身内部的对象。它可以用于实时推理，并且需要很少的计算资源。</a></p><p id="3fed" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">今天，在第一版YOLO发布7年后，美团的研究小组发布了新的YOLOv6型号——它是来踢一脚的！</p><h1 id="41c0" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLO的历史</h1><h1 id="06a6" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLO之前的目标检测</h1><p id="7f11" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在YOLO之前，两阶段对象检测架构主导了该领域。它使用基于区域的分类器来定位区域，然后将它们传递给更健壮的分类器。虽然这种方法给出了具有高平均精度(mAP)的精确结果，但是它是非常资源密集的，在其操作中需要多次迭代。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/10e7385278489238acc44e5a39db9f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*spAlDl0Jv11zBLMQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">两阶段对象检测，来自纸张的图像</p></figure><h1 id="24d6" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLO是如何工作的？</h1><p id="217b" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">YOLO提出了一种不同的方法，其中两个阶段都在同一个神经网络中进行。首先，图像被分成单元，每个单元具有SxS的等维区域。然后，每个单元用边界框坐标(相对于其坐标)和对象标签以及该事物出现在单元中的概率来检测和定位它所包含的对象。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mj"><img src="../Images/4d13577065972d3c31421a12f4b0ea93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Lg8T0ghKhK9XAeW4.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">YOLOv1，图像来自原纸</p></figure><p id="ec0a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为每个单元“独立工作”，所以它可以同时处理网格，减少了训练和推断所需的计算能力和时间。事实上，YOLO实现了最先进的结果，击败了其他实时对象检测算法。</p><h1 id="3838" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLO有哪些版本？</h1><ul class=""><li id="643b" class="mk ml jg kf b kg lz kk ma ko mm ks mn kw mo la mp mq mr ms bi translated">yolov 1(2015年6月):<a class="ae jd" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次:统一的、实时的物体检测</a></li><li id="d223" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">yolo v2(2016年12月):<a class="ae jd" href="https://arxiv.org/abs/1612.08242v1" rel="noopener ugc nofollow" target="_blank"> YOLO9000:更好、更快、更强</a></li><li id="8e7d" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">yolo v3(2018年4月):<a class="ae jd" href="https://arxiv.org/abs/1804.02767v1" rel="noopener ugc nofollow" target="_blank"> YOLOv3:增量改进</a></li><li id="5b35" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">yolov 4(2020年4月):<a class="ae jd" href="https://arxiv.org/abs/2004.10934v1" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体检测的最佳速度和精度</a></li><li id="83f9" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">yolov 5(2020年5月):<a class="ae jd" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> Github repo </a>(尚未发布论文)</li></ul><h1 id="41db" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLOv6是来踢**和取名字的</h1><p id="027b" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">MT-YOLOv6的灵感来自最初的一级YOLO建筑，因此<a class="ae jd" href="https://github.com/meituan/YOLOv6/blob/main/docs/About_naming_yolov6.md" rel="noopener ugc nofollow" target="_blank">被其作者(勇敢地)命名为</a> YOLOv6。虽然它提供了出色的结果，但值得注意的是MT-YOLOv6不是官方YOLO系列的一部分。</p><p id="d290" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">YOLOv6是一个专用于工业应用的单级对象检测框架，具有硬件友好的高效设计和高性能。它在检测准确性和推理速度方面优于YOLOv5，是生产应用中YOLO架构的最佳OS版本。</p><h1 id="6f1e" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLOv6成就</h1><ul class=""><li id="d242" class="mk ml jg kf b kg lz kk ma ko mm ks mn kw mo la mp mq mr ms bi translated">yolov 6-nano-在COCO val2017数据集上实现35.0地图，在T4上使用TensorRT FP16进行bs32推理，每秒1242帧</li><li id="1162" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">yolov 6-s-在COCO val2017数据集上实现43.1地图，在T4上使用TensorRT FP16进行bs32推理，每秒520帧。</li></ul><h1 id="dd34" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">单一图像推理</h1><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/8dcb89d8cdaca3bdfe8c7a51fc107abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EuLMAXmwMpE2bvIP.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来自YOLOv6存储库的图像</p></figure><p id="6c1a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">YOLOv6s (red)提供了比所有以前版本的YOLOv5更好的平均精度(mAP ),推理时间大约快2倍。我们还可以看到基于YOLO的架构和基于两阶段对象检测的EfficientDet之间的巨大性能差距。</p><h1 id="4609" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">视频推理</h1><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/23509be6a7804ae8710bd922a965fc51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gITL6C_55cQHNpgk.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">来自YOLOv6存储库的图像</p></figure><p id="0d20" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与单个图像推断相同，YOLOv6在所有FPS频谱上为视频提供了更好的结果。有趣的是注意到了大约550–620 FPS的曲线变化。我想知道这是否与硬件性能有关，以及维护人员在进行实验时是否减少了硬件的偏差。</p><h1 id="6c65" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">基准</h1><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/9d5434f06b5badb5f1d8646402155265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f7MwkX8WmUOz-YPe.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><ul class=""><li id="e63d" class="mk ml jg kf b kg kh kk kl ko mz ks na kw nb la mp mq mr ms bi translated">在<a class="ae jd" href="https://cocodataset.org/#download" rel="noopener ugc nofollow" target="_blank"> COCO val2017 </a>数据集上测试了不同物体探测器的地图和速度的比较。</li><li id="0bab" class="mk ml jg kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">其他方法的速度结果在维护者的环境中使用官方代码库和模型进行了测试，如果在相应的官方版本中没有找到的话。</li></ul><p id="ead1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">免责声明:上述评论是基于作者的说法，我们还有待核实。</p><h1 id="9df3" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLOv5与YOLOv6</h1><h1 id="97b0" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLOv5和YOLOv6的性能指标评测比较</h1><p id="067f" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在研究这两种型号的基准时，我发现很难对苹果进行比较。YOLOv6的型号较少(缺少m/l/x)，并且没有任何大于640像素的图像信息。对于两个项目报告的基准，我们可以清楚地看到YOLOv6在mAP方面的改进。然而，v6的参数和失败次数是v5的两倍，这让我想亲自深入训练过程，仔细检查下面的结果。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/186f45a038f35f5aeb0950f6d3acbc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OddcR-Ad89dBkq0i.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">作者图片</p></figure><h1 id="2909" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">YOLOv5和YOLOv6之间的定性比较</h1><p id="ccb2" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我使用两种型号的s版本来检测以下图像中的对象:</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/90fe965d0982beab6280e52f4fc85b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iOyM8lhQzj7Apohi.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">YOLOv6性能，图像来自YOLOv5存储库</p></figure><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/f0a05b03c42ef9d72a222039b25510a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fyxmnTPGhbGHN-Wg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">YOLOv5表演，图片来自YOLOv5知识库</p></figure><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/3d405c4084e77cc4d9ab796b61817a5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a5lXCtv-j0Vny_PG.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">YOLOv6性能，图像来自YOLOv5存储库</p></figure><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/8861b5346c0dda1f12728b30da65849d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-xQ9gB8n-ZEdqH_G.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">YOLOv5表演，图片来自YOLOv5知识库</p></figure><p id="1db7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以清楚地看到YOLOv6s在图像中检测到更多的物体，并且对它们的标签有更高的信心。</p><h1 id="f154" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">灵活性</h1><p id="2a26" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">两个项目都有相似的方法来创建不同的模型大小。最大的区别是<a class="ae jd" href="https://github.com/ultralytics/yolov5/tree/master/models" rel="noopener ugc nofollow" target="_blank"> YOLOv5使用YAML </a>，而<a class="ae jd" href="https://dagshub.com/nirbarazida/YOLOv6/src/main/configs" rel="noopener ugc nofollow" target="_blank"> YOLOv6直接在Python </a>中定义模型参数。预示性的一瞥也表明YOLOv5可能在一定程度上更具可定制性。</p><p id="2614" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，YOLOv6如此灵活的事实意味着我们可以在未来看到更大版本的YOLOv6，甚至更高精度的预测！</p><p id="fca7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你创造了一个更大的YOLOv6模型，<a class="ae jd" href="https://discord.com/invite/9gU36Y6" rel="noopener ugc nofollow" target="_blank">让我们知道不和谐</a>！我们很想看看！</p><h1 id="3ccc" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用</h1><p id="eb1f" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><a class="ae jd" href="https://yolov6.dagshubusercontent.com/" rel="noopener ugc nofollow" target="_blank">你可以使用DagsHub的应用</a>与YOLOv6的最新版本进行交互。如果您想在本地计算机上使用它，请按照下列步骤操作:</p><p id="3ea2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">安装</strong></p><pre class="mf mg mh mi gt ne nf ng nh aw ni bi"><span id="373f" class="nj lc jg nf b gy nk nl l nm nn">git clone https://dagshub.com/nirbarazida/YOLOv6 cd<br/>YOLOv6 pip install -r requirements.txt <br/>dvc pull</span></pre><p id="efa0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">推论</strong></p><p id="cb58" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用YOLOv6s: <code class="fe no np nq nf b">python tools/infer.py --weights yolov6s.pt --source &lt;path to image/directory&gt;</code></p><p id="eb78" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用YOLOv6n: <code class="fe no np nq nf b">python tools/infer.py --weights yolov6n.pt --source &lt;path to image/directory&gt;</code></p><h1 id="743c" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="4fc9" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">YOLOv6是最近发布的最令人兴奋的OSDS项目之一。与以前的YOLO版本相比，它提供了最先进的结果和各方面的显著改进。维护人员目前专注于丰富模型类型、部署选项和量化工具。尽管如此，与任何开源项目一样，社区可以极大地影响其路线图和进度曲线。</p><p id="2d42" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管该项目仍处于早期阶段，但它看起来非常有前途，我很想知道它将来会打破哪些基准。</p></div></div>    
</body>
</html>