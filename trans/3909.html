<html>
<head>
<title>Introduction to Instrumental Variables Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">工具变量估计导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-instrumental-variables-estimation-3eba75a04418#2022-08-30">https://towardsdatascience.com/introduction-to-instrumental-variables-estimation-3eba75a04418#2022-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/32a02699369edc3fd088aad6153eb579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SHheJzofZZreEbrkWYMPIQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由<a class="ae jd" href="https://pixabay.com/users/clker-free-vector-images-3736/" rel="noopener ugc nofollow" target="_blank"> Alexa </a>发自<a class="ae jd" href="https://pixabay.com/photos/different-nationalities-children-1124478/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a> ( <a class="ae jd" href="https://pixabay.com/service/license/" rel="noopener ugc nofollow" target="_blank"> Pixabay授权</a>)</p></figure><div class=""/><div class=""><h2 id="75d4" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">我们将学习工具变量，以及如何使用它们来估计线性回归模型</h2></div><p id="68ea" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我们将了解一种使用称为<strong class="kx jh">工具变量</strong>的工件来估计线性回归模型的巧妙技术。</p><p id="4c2b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx jh">基于工具变量(IV)的估计</strong>允许回归建模者处理困扰大部分回归模型的严重情况，即一个或多个回归变量与模型的误差项相关。换句话说，<a class="ae jd" rel="noopener" target="_blank" href="/what-are-exogenous-and-endogenous-regression-variables-c0ea1ba03ce8"> <strong class="kx jh">回归变量是内生的</strong> </a>。</p><p id="ada5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于一种被称为<a class="ae jd" rel="noopener" target="_blank" href="/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53"> <strong class="kx jh">省略变量偏差</strong> </a>的现象，对包含内生变量的模型的普通最小二乘估计会产生回归系数的有偏估计。从功能上讲，系数的这种偏差给实验者带来了一大堆实际问题，并可能使整个实验的有用性受到质疑。</p><p id="e2e4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在IV估计中，我们使用一个或多个<strong class="kx jh">工具变量</strong> ( <strong class="kx jh">工具</strong> ) <em class="lr">代替</em>可疑内生变量，并且我们使用被称为<strong class="kx jh">二阶段最小二乘法</strong>(简称<strong class="kx jh"> 2SLS </strong>的最小二乘法的修正形式来估计最终模型。</p><p id="f59d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文的其余部分，我们将展示如何使用工具变量来减轻内生性的影响，并且我们将通过一个例子来说明工具变量的使用。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="6ce3" class="lz ma jg bd mb mc md me mf mg mh mi mj km mk kn ml kp mm kq mn ks mo kt mp mq bi translated">内生性及其后果</h1><p id="d3ed" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">在上一篇文章中，我们学习了<a class="ae jd" rel="noopener" target="_blank" href="/what-are-exogenous-and-endogenous-regression-variables-c0ea1ba03ce8"> <strong class="kx jh">外生变量和内生变量</strong> </a>。让我们快速回顾一下这些概念。</p><p id="85ae" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑以下线性模型:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/d38abcb584f15fd0dfe69fdd0fc27d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8p2NYHdKP0vr_qebcwLr2g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">两个变量的线性模型<strong class="bd nb"> x </strong> _2和<strong class="bd nb"> x </strong> _3(图片由作者提供)</p></figure><p id="ae35" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上式中，<strong class="kx jh"> <em class="lr"> y </em> </strong>为因变量，<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _2 </em>和<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>为解释变量，<strong class="kx jh"><em class="lr">【ϵ</em></strong>为误差项，捕捉到了<strong class="kx jh"><em class="lr"/></strong>y<strong class="kx jh"><em class="lr">x</em></strong>对于包含<em class="lr"> n </em>行的数据集，<strong class="kx jh"> <em class="lr"> 1，y </em> </strong>，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>，<strong class="kx jh"><em class="lr">【ϵ</em></strong>都是大小为<em class="lr">【n×1】—</em>的列向量为了简洁起见，我们将从后面的等式中去掉<strong class="kx jh"> <em class="lr"> 1 </em> </strong>(它是1的向量)。</p><p id="a725" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果一个或多个回归变量，比如说<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>，是内生的，即它与误差项相关，则OLS估计量是<strong class="kx jh">而不是</strong> <a class="ae jd" rel="noopener" target="_blank" href="/the-consistent-estimator-913fab06f4f3"> <strong class="kx jh">一致的</strong> </a>。由于一种被称为<a class="ae jd" rel="noopener" target="_blank" href="/what-happens-when-you-omit-important-variables-from-your-regression-model-966830590d53"> <strong class="kx jh">省略变量偏差</strong> </a>的现象，所有<em class="lr">变量</em>的系数估计值，而不仅仅是<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _3、</em>的系数估计值都偏离真实值。</p><blockquote class="nc nd ne"><p id="9596" class="kv kw lr kx b ky kz kh la lb lc kk ld nf lf lg lh ng lj lk ll nh ln lo lp lq ij bi translated">面对内生性，无论你的数据集有多大或者有多平衡，这种估计偏差都不会消失。</p></blockquote><p id="38c0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当面临模型的内生性时，您有以下选择:</p><ol class=""><li id="19d1" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">如果内生性被怀疑很小，你可以简单地接受它和随之而来的系数估计偏差。</li><li id="2aae" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">对于隐藏在您怀疑与内生变量相关的误差项中的不可观察因素，您可以选择合适的<a class="ae jd" rel="noopener" target="_blank" href="/how-to-use-proxy-variables-in-a-regression-model-539f723ab587"> <strong class="kx jh">代理变量</strong> </a>。</li><li id="7777" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">如果可疑的内生变量是时间不变的，即它们的值不随时间变化，那么对模型进行一次时间差分，就会将它们减去。这是一种主要在<a class="ae jd" rel="noopener" target="_blank" href="/understanding-the-fixed-effects-regression-model-d2fccc2cc27e"> <strong class="kx jh">面板数据模型</strong> </a>中起作用的策略。</li><li id="419a" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">您可以使用<strong class="kx jh">工具变量(IV)</strong><em class="lr">代替</em>可疑内生变量，并使用IV估计技术(如<strong class="kx jh"> 2阶段最小二乘法</strong>)估计“工具化”模型。</li></ol><p id="b4a2" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们进一步了解如何使用IVs。</p><h1 id="7fce" class="lz ma jg bd mb mc nw me mf mg nx mi mj km ny kn ml kp nz kq mn ks oa kt mp mq bi translated">开发工具变量的动机</h1><p id="1881" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">再次考虑等式(1)中的模型:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/a1cf00b3c96d0a1103e3388dc0b34314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_BmQdkfW6tSpKSiQBR99w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">二元线性模型<strong class="bd nb"> x </strong> _2和<strong class="bd nb"> x </strong> _3(图片由作者提供)</p></figure><p id="6ad8" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们开始之前，让我们注意以下几点:</p><p id="43ec" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>和<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>都是外生的，则OLS估计量是<a class="ae jd" rel="noopener" target="_blank" href="/the-consistent-estimator-913fab06f4f3"><strong class="kx jh"/></a>一致的，它产生的所有系数估计都是无偏的。不需要基于IV的估计。</p><p id="02f5" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是现在假设<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>是内生的。我们将概念性地将<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>的方差视为由两部分组成:</p><ol class=""><li id="95d1" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">与<strong class="kx jh"> <em class="lr"> ϵ </em> </strong>不相关的一大块。这是<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>的部分，其实就是外生的。</li><li id="fb79" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">与<strong class="kx jh"> <em class="lr"> ϵ.相关的第二个块</em> </strong>这是<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>内生的部分。</li></ol><h2 id="e589" class="oc ma jg bd mb od oe dn mf of og dp mj le oh oi ml li oj ok mn lm ol om mp on bi translated">工具变量背后的关键直觉</h2><p id="d16d" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">如果我们能够以某种方式分离出<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>的外生部分，并用这个外生块替换<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>，同时从模型中省去<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>的内生部分，则得到模型<strong class="kx jh">这是在线性模型中使用工具变量背后的关键直觉。</strong></p><p id="1304" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为此，假设我们能够识别一个回归变量<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>，使得<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>具有以下两个属性:</p><ol class=""><li id="284e" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated"><strong class="kx jh"> <em class="lr"> z </em> </strong> <em class="lr"> _3 </em>与<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _3 </em>相关。记数法:<em class="lr">Cov(</em><strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3，</em><strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3)！= 0.</em>这就是所谓的<strong class="kx jh">关联条件</strong>，用于包含<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>。简单来说，<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>应该和<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _3相关。</em></li><li id="d947" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated"><strong class="kx jh"><em class="lr"/></strong><em class="lr">_ 3</em>与误差项不相关，<em class="lr">即e(</em><strong class="kx jh"><em class="lr">【ϵ|x】</em></strong><em class="lr">_ 3)= 0</em>或常数，<em class="lr">e(</em><strong class="kx jh"><em class="lr">【ϵ】</em></strong><em class="lr">*</em><strong class="kx jh"><em class="lr">x<em class="lr">这就是使用<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>的<strong class="kx jh">外生条件</strong>。</em></em></strong></li></ol><blockquote class="nc nd ne"><p id="506a" class="kv kw lr kx b ky kz kh la lb lc kk ld nf lf lg lh ng lj lk ll nh ln lo lp lq ij bi translated">如果<strong class="kx jh"> z </strong> _3满足<strong class="kx jh">相关条件</strong>和<strong class="kx jh">外生条件，则z </strong> _3称为<strong class="kx jh">仪器变量</strong>或<strong class="kx jh">仪器</strong>为<strong class="kx jh"> x </strong> _2。</p></blockquote><p id="2911" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不过先来考察一下关于<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>的一个微妙点。</p><p id="f7c7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>与<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>，我们可以将<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>表示为<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>和一个误差的线性组合</p><figure class="mx my mz na gt is gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a069657c6563a4572747b5894756ebb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*mjE-jbFiq4bgNMT70TcRXg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd nb"> x </strong> _3对<strong class="bd nb"> z </strong> _3的回归(图片由作者提供)</p></figure><p id="5eda" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，<strong class="kx jh"> <em class="lr"> z </em> </strong> <em class="lr"> _3 </em>也可以与<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _2 </em>相关联。回归变量之间的这种共线性在现实环境中非常普遍。由于这种共线性，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>可能会通过<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>影响<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>并且在上面的等式中，<em class="lr"> γ_3 </em>捕捉的不仅仅是<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3<em class="lr"/></em></p><p id="d454" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可能要隔离出<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>对<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>的影响，这样<a class="ae jd" rel="noopener" target="_blank" href="/understanding-partial-effects-main-effects-and-interaction-effects-in-a-regression-model-54e8a127c62d"> <strong class="kx jh">的主要影响</strong> </a>对<strong class="kx jh"><em class="lr"/></strong><em class="lr">_ 3</em>的影响为此，我们必须回归<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>不仅仅是在<strong class="kx jh"> <em class="lr"> z </em> </strong> <em class="lr"> _3、</em>上，还要在<strong class="kx jh"><em class="lr">×x</em><em class="lr">_ 2</em>上:</strong></p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi op"><img src="../Images/e77c540157f160a62f6a1ec3e39494e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jIOSYhuhWt-oeLvru3XIZg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><strong class="bd nb"> x </strong> _3表示为<strong class="bd nb"> x </strong> _2和<strong class="bd nb"> z </strong> _3的线性组合，以及一个常数(图片由作者提供)</p></figure><p id="fb7a" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">和前面一样，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2，</em><strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3，</em>和误差项<strong class="kx jh"> <em class="lr"> ν </em> </strong>都是大小为<em class="lr">的列向量同样，在等式(1a)中，<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>和<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>是外生的，即它们与<strong class="kx jh"> <em class="lr"> ν </em> </strong>不相关。</em></p><p id="101c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">将等式(1a)代入等式(1):</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oq"><img src="../Images/e8a943d4473cdbf820e876a0215a13d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qYG8c--9mEItmY58COuMFA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">将等式(1a)代入等式(1)(图片由作者提供)</p></figure><p id="5c59" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">绿色位可以被吸收到新的截距<em class="lr"> β*_1 </em>中。同样，我们将把(<em class="lr"> β_2+β_3* γ_2) </em>替换为新的系数<em class="lr"> β*_2 </em>，将<em class="lr"> (β_3* γ_3) </em>替换为<em class="lr"> β*_3 </em>，并将复合误差项<em class="lr">(β_ 3 *</em><strong class="kx jh"><em class="lr">ν</em></strong><em class="lr">)+</em><strong class="kx jh"><em class="lr">ϵ</em></strong></p><p id="ab2e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过这些替换，等式(1)中的回归模型被转换成以下模型:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/45760333dc77ddb23c410c1d57d34ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XF-odKnQAUpeyqygXsXlgA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">内生变量<strong class="bd nb"> x </strong> _3替换为变量<strong class="bd nb"> z </strong> _3的线性模型(图片由作者提供)</p></figure><p id="0cd4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">回想一下<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 2</em>和<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>都是假设不相关的<strong class="kx jh"><em class="lr"/></strong>和<strong class="kx jh"> <em class="lr"> ϵ </em> </strong>。因此，它们也与合成误差<strong class="kx jh"> <em class="lr">、ϵ* </em> </strong>不相关。因此，在等式(1b)中，R.H.S .上的所有变量都是外生的，等式(1b)可以使用OLS一致地估计。</p><h1 id="202a" class="lz ma jg bd mb mc nw me mf mg nx mi mj km ny kn ml kp nz kq mn ks oa kt mp mq bi translated">一个例子</h1><p id="fb85" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">考虑以下终生收入的治疗效果模型，该模型根据一个人是否上过常春藤盟校而回归:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi os"><img src="../Images/1a2ae979d9cbe534bac246673e848550.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsC89coPON3IfMP5vVfWtw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">终生收入随着这个人是否上过常春藤盟校而递减</p></figure><p id="547c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">布尔变量<strong class="kx jh"><em class="lr">Attended _ Ivy _ League</em></strong>显然是内生的。一个人是否上过常春藤盟校取决于社会经济因素和个人特定因素，如能力和追求成功的动力，这些因素无法衡量，但也会直接影响一生的收入。因此，这些不可观察的变量隐藏在误差项中，并且它们还与<strong class="kx jh"><em class="lr">Attended _ Ivy _ League</em>，</strong>相关，使得<strong class="kx jh"><em class="lr">Attended _ Ivy _ League</em></strong>内生。使用OLS估计会导致对<em class="lr"> β_1 </em>和<em class="lr"> β_2的有偏估计。</em></p><p id="4260" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很难想象更大的成功欲望会导致常春藤盟校的系统性下降。能力等其他因素也是如此。因此，我们假设<strong class="kx jh"><em class="lr">【ϵ】</em></strong>和<strong class="kx jh"> <em class="lr">中的隐藏因素之间存在正相关，从而导致对β_1 </em>和<em class="lr">β_ 2</em>的正偏差<em class="lr">，进而导致实验者的<em class="lr">高估了常春藤盟校出勤率对终生收入的影响。</em></em></strong></p><p id="440e" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">显然，这个问题需要一个解决方案。让我们试着找出一个与<strong class="kx jh"><em class="lr">Attended _ Ivy _ League</em></strong>相关但与误差项不相关的变量。其中一个变量是<strong class="kx jh">遗产</strong>，即这个人的父母或祖父母是否曾就读于常春藤联盟学校。数据显示，一个人的遗产状况和这个人是否被同一所常春藤盟校录取之间存在相关性。这满足了<strong class="kx jh">关联条件</strong>。此外，此人的父母或祖父母是否曾就读于常春藤联盟学校似乎与此人的能力和动机等因素没有直接关联，从而满足了<strong class="kx jh">外生性条件</strong>。因此，我们有:</p><p id="746c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr"> Cov( </em> <strong class="kx jh"> <em class="lr">遗留</em> </strong> <em class="lr">，</em> <strong class="kx jh"> <em class="lr">出席_常春藤</em> </strong> <em class="lr">)！= 0 </em></p><p id="dd34" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr"> Cov( </em> <strong class="kx jh"> <em class="lr">遗留</em> </strong> <em class="lr">，</em><strong class="kx jh"><em class="lr">ϵ</em></strong><em class="lr">)= 0</em></p><p id="2b70" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们指定<strong class="kx jh"> <em class="lr">遗产</em> </strong>为<strong class="kx jh"> <em class="lr">就读_常春藤</em> </strong>的乐器。我们将评估以下测量模型，而不是原始模型:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/e76a5a4b6a07f747b11231c55cfcd23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31_jlL4EBA-6XQ4nou4x7g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">回归模型的工具化版本(图片由作者提供)</p></figure><p id="92da" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用OLS可以一致地估计这个仪器模型，并且可以得到<em class="lr"> β*_1 </em>和<em class="lr"> β*_2的无偏估计。</em>注意<em class="lr"> β*_2 </em>是<strong class="kx jh"> <em class="lr">遗留</em> </strong>的效果，而不是<strong class="kx jh"><em class="lr">Attended _ Ivy _ League</em></strong>on<strong class="kx jh"><em class="lr">Lifetime _ income。</em> </strong>但是我们已经看到<em class="lr"> β_2 </em>无论如何都无法可靠估计。所以我们必须接受<em class="lr"> β*_2 </em>作为<em class="lr"> β_2的代表。</em>顺带一提，估算软件会将<em class="lr"> β*_2 </em>报为原内生变量<strong class="kx jh">的系数<em class="lr"> Attended_Ivy_League </em>和<em class="lr">的系数<em class="lr">遗留</em> </em></strong>这是好事。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="7c53" class="lz ma jg bd mb mc md me mf mg mh mi mj km mk kn ml kp mm kq mn ks mo kt mp mq bi translated">工具变量估计的优点和缺点</h1><p id="0687" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">通过检查等式(1b)中的仪表化模型，有一点变得很明显:</p><figure class="mx my mz na gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/45760333dc77ddb23c410c1d57d34ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XF-odKnQAUpeyqygXsXlgA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">内生变量<strong class="bd nb"> x </strong> _3替换为变量<strong class="bd nb"> z </strong> _3的线性模型(图片由作者提供)</p></figure><p id="314f" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">仪表化变量(<strong class="kx jh"> <em class="lr"> z </em> </strong> <em class="lr"> _3 </em>)与内生变量<strong class="kx jh"> <em class="lr"> x </em> </strong> <em class="lr"> _3 </em>并不完全相关。通过使用<strong class="kx jh"><em class="lr">z</em></strong><em class="lr">_ 3</em>代替<strong class="kx jh"><em class="lr"/></strong><em class="lr">_ 3</em>，我们正在丢失包含在<strong class="kx jh"><em class="lr">x</em></strong><em class="lr">_ 3</em>中的一些信息。这种信息损失使得仪表化模型具有更大的误差项和更不精确的系数估计，即它们的标准误差大于原始模型中相应系数的标准误差。较大的标准误差转化为较宽的置信区间。</p><blockquote class="nc nd ne"><p id="6104" class="kv kw lr kx b ky kz kh la lb lc kk ld nf lf lg lh ng lj lk ll nh ln lo lp lq ij bi translated">当我们使用工具变量进行估计时，我们是在用精度换取系数估计的无偏性——这是我们从模型中去除内生性所必须付出的代价。</p></blockquote><p id="487b" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总的来说，IV估计模型不如内生模型精确。除非选择的变量与内生变量具有中等至强相关性，并且变量也或多或少与误差不相关，否则最好使用包含内生变量的原始模型，并接受其估计系数中的偏差。</p><blockquote class="nc nd ne"><p id="b16b" class="kv kw lr kx b ky kz kh la lb lc kk ld nf lf lg lh ng lj lk ll nh ln lo lp lq ij bi translated">对于回归建模者来说，虽然内生性的幽灵可能会令人困扰，但不得不与<strong class="kx jh">弱工具</strong>一起工作的前景也可能是同样糟糕的困境。</p></blockquote><h2 id="4af1" class="oc ma jg bd mb od oe dn mf of og dp mj le oh oi ml li oj ok mn lm ol om mp on bi translated">一种实用的IV估计方法</h2><p id="f231" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">在现实生活中，人们可能希望采用以下方法:</p><ol class=""><li id="2944" class="ni nj jg kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">使用OLS估计原始模型，使用2SLS等技术估计仪表化模型。</li><li id="95e5" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">比较两个模型的估计系数值，并比较它们各自的置信区间。如果OLS估计模型的配置项完全位于IV估计模型的相应配置项内，这是使用OLS估计模型的一个强烈信号。</li><li id="5b6c" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">还要在人们正在研究的真实世界环境中检查来自两个模型的估计系数。根据上下文，选择产生较低(或较高)估计值的模型会有所帮助。</li></ol></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="fe8a" class="lz ma jg bd mb mc md me mf mg mh mi mj km mk kn ml kp mm kq mn ks mo kt mp mq bi translated">总结和关键要点</h1><ul class=""><li id="912f" class="ni nj jg kx b ky mr lb ms le ou li ov lm ow lq ox no np nq bi translated">当一个回归模型包含一个或多个内生变量时，不能使用OLS进行一致的估计。如果使用OLS估计，估计的系数偏离它们的真实值。</li><li id="ed56" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq ox no np nq bi translated">当面临内生性时，人们可以要么接受由此产生的估计偏差，要么尝试使用诸如<strong class="kx jh">代理变量</strong>，或<strong class="kx jh">差分</strong>(在面板数据模型中)，或通过<strong class="kx jh">工具变量</strong> (IVs)等技术来修正它。</li><li id="377f" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq ox no np nq bi translated">在IV方法中，我们确定与内生变量相关但与误差项不相关的合适变量，然后用IV替换内生变量。由此产生的模型是免费的内生解释变量，它可以估计使用OLS。在实践中，我们使用特定于IV的技术，如<strong class="kx jh"> 2阶段最小二乘法</strong> (2SLS)。</li><li id="639c" class="ni nj jg kx b ky nr lb ns le nt li nu lm nv lq ox no np nq bi translated">IV估计模型不如包含内生变量的原始模型精确，但与后者不同，它们产生无偏的系数估计。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="3c82" class="lz ma jg bd mb mc md me mf mg mh mi mj km mk kn ml kp mm kq mn ks mo kt mp mq bi translated">参考文献、引文和版权</h1><h2 id="4896" class="oc ma jg bd mb od oe dn mf of og dp mj le oh oi ml li oj ok mn lm ol om mp on bi translated">形象</h2><p id="54cc" class="pw-post-body-paragraph kv kw jg kx b ky mr kh la lb ms kk ld le mt lg lh li mu lk ll lm mv lo lp lq ij bi translated">本文中的所有图片版权归<a class="ae jd" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY-NC-SA </a>下的<a class="ae jd" href="https://www.linkedin.com/in/sachindate/" rel="noopener ugc nofollow" target="_blank"> Sachin Date </a>所有，除非图片下面提到了不同的来源和版权。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="7fb0" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">如果您喜欢这篇文章，请关注我的</em><a class="ae jd" href="https://timeseriesreasoning.medium.com" rel="noopener"><strong class="kx jh"><em class="lr">Sachin Date</em></strong></a><em class="lr">以获得关于回归、时间序列分析和预测主题的提示、操作方法和编程建议。</em></p></div></div>    
</body>
</html>