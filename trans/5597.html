<html>
<head>
<title>4 Techniques for Scaling Pandas to Large Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将熊猫扩展到大型数据集的 4 种技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/4-techniques-for-scaling-pandas-to-large-datasets-acf8805d30eb#2022-12-19">https://towardsdatascience.com/4-techniques-for-scaling-pandas-to-large-datasets-acf8805d30eb#2022-12-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="27f2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">提高效率的技巧</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/aa5c89f0dcdc32b879542dc608dc8f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTyn5BubgREJLP8S5qp_Ig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">S. Tsuchiya 在<a class="ae ky" href="https://unsplash.com/s/photos/large?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="88d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Pandas 是数据科学生态系统中最常用的工具之一。它通过提供大量具有易于理解的语法的函数，使得操纵和分析表格数据变得非常容易。</p><p id="89e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然 Pandas 在数据分析和操作方面处于领先地位，但当数据变得非常大时，它的性能开始下降。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="edc9" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">是什么让熊猫跑得更慢</h1><p id="d9d3" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">主要原因是 Pandas 做内存分析，所以如果数据集大于内存，使用 Pandas 就变得非常困难，或者不可能。</p><p id="bad2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，即使数据集有足够的内存，使用 Pandas 也是一个挑战，因为一些操作会产生中间副本。为了对熊猫有流畅的体验，数据集应该相对小于内存。</p><p id="36b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们在谈论性能，就不可避免地提到熊猫使用单个 CPU 核心来执行操作。在非常大的数据集上，这使得 Pandas 比提供分布式计算的工具要慢。</p><p id="bf71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将介绍 4 种技术，它们有助于 Pandas 在处理非常大的数据集时更加高效。</p><p id="fb9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，对于 Dask、Vaex、Modin 和 Datatable 等非常大的数据集，还有其他工具和库是更好的选择。</p><p id="287c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们不会在本文中讨论这些工具。相反，我们的重点是如何让熊猫更适用，表现更好。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="22c8" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">1.你真的需要所有的数据集吗？</h1><p id="ce9d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">数据是数据科学中最有价值的资产，因此我们倾向于收集尽可能多的数据。然而，我们并不需要所有任务的所有数据。</p><p id="5a1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据集可能包含冗余的列，或者对于特定的任务，我们可能只需要几列。</p><p id="9791" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与其读取整个数据集，然后过滤所需的列，不如只读取我们需要的列。</p><p id="04e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先生成一个数据集。下面的代码片段创建了一个有 51 列和 1000 万行的 Pandas DataFrame。50 列用 0 到 10 之间的随机整数填充，另一列包含 A、B、C 和 d 的字符串值。我的计算机花了大约 1 分钟来生成这个数据集。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="b403" class="ne md it na b be nf ng l nh ni">import pandas as pd<br/>import numpy as np<br/><br/>df = pd.DataFrame(np.random.randint(0, 100, size=(10000000, 50)))<br/>df = df.rename(columns={i:f"x_{i}" for i in range(50)})<br/>df["category"] = ["A", "B", "C", "D"] * 2500000</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/be09178210d4b6a02d2339b176d6176f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yI3XPlllkhc_zruS9E6reg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df 的前 5 行(图片由作者提供)</p></figure><p id="b916" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据帧的内存使用量约为 4 GB。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="7069" class="ne md it na b be nf ng l nh ni">np.round(df.memory_usage().sum() / 10**9, 2)<br/><br/># output<br/>4.08</span></pre><p id="9f68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在现实生活中，我们可能有比这个大得多的数据集，但这足以证明我们的情况。</p><p id="2d4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我想做一个简单的过滤操作，并衡量它需要多长时间。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="1066" class="ne md it na b be nf ng l nh ni">%time df[df["category"]=="A"]<br/><br/># output<br/>CPU times: user 519 ms, sys: 911 ms, total: 1.43 s<br/>Wall time: 2.43 s</span></pre><p id="f894" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大概花了半秒钟。我们还可以测量根据一列或多列中的值对行进行排序需要多长时间。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="9cdf" class="ne md it na b be nf ng l nh ni">%time df.sort_values(by=["x_0", "x_1"])<br/><br/># output<br/>CPU times: user 2.84 s, sys: 1.19 s, total: 4.03 s<br/>Wall time: 4.52 s</span></pre><p id="0744" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">按 x_0 和 x_1 列对行进行排序用了 2.84 秒。</p><p id="a15c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们将这个数据帧保存为 CSV 文件。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="9fca" class="ne md it na b be nf ng l nh ni">df.to_csv("very_large_dataset.csv", index=False)</span></pre><p id="6a26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑这样一种情况，我们只需要这个数据集中的前 10 列。我们可以使用 read_csv 函数的 usecols 参数选择要读取的列列表。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="03d7" class="ne md it na b be nf ng l nh ni">cols = ["category", "x_0", "x_1", "x_2", "x_3", "x_4", "x_5", "x_6", "x_7", "x_8"]<br/><br/>df = pd.read_csv("very_large_dataset.csv", usecols=cols)<br/><br/>df.head()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/0fe3bfb6f7ea7309aa18828b20bf18d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ivXgFFu6CBNlK0QtamXIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">df 的前 5 行(图片由作者提供)</p></figure><p id="4789" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">内存使用量从 4 GB 下降到 0.8 GB。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="b12b" class="ne md it na b be nf ng l nh ni">np.round(df.memory_usage().sum() / 10**9, 2)<br/><br/># output<br/>0.8</span></pre><p id="4cab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们进行与整个数据集相同的过滤操作。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="abdc" class="ne md it na b be nf ng l nh ni">%time df[df["category"]=="A"]<br/><br/># output<br/>CPU times: user 389 ms, sys: 147 ms, total: 535 ms<br/>Wall time: 629 ms</span></pre><p id="eb4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">耗时 389 毫秒，这意味着与处理整个数据集相比，速度快了 25%。排序操作的速度增益更大。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="c46a" class="ne md it na b be nf ng l nh ni">%time df.sort_values(by=["x_0", "x_1"])<br/><br/># output<br/>CPU times: user 919 ms, sys: 298 ms, total: 1.22 s<br/>Wall time: 1.33 s</span></pre><p id="c34d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">耗时 919 毫秒，这意味着与整个数据集的 2.84 秒相比，速度快了 67%。</p><p id="0806" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仅仅节省 1 秒钟可能看起来不是一个显著的改进，但是当你对一个典型的数据清理或数据分析任务进行大量操作时，它会累加起来。更重要的一点是，内存使用量从 4.8 GB 降至 0.8 GB。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="545c" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">2.分类数据的更有效的数据类型</h1><p id="7a53" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">DataFrame 中的每一列都有一种数据类型。有效地选择数据类型可能会减少内存消耗，从而有助于将 Pandas 扩展到更大的数据集。</p><p id="d529" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们有一个基数较低的分类特性，那么使用 category 数据类型而不是 object 或 string 可以节省大量内存。</p><p id="c1f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">低基数意味着与值的总数相比，不同的值非常少。例如，我们的数据框架中的 category 列只有 4 个不同的值，而总共有 1000 万个值。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="f621" class="ne md it na b be nf ng l nh ni">df["category"].unique()<br/># output<br/>array(['A', 'B', 'C', 'D'], dtype=object)<br/><br/>len(df["category"])<br/># output<br/>10000000</span></pre><p id="33b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它当前以对象数据类型存储。让我们检查一下它的内存使用情况。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="9443" class="ne md it na b be nf ng l nh ni">df["category"].dtypes<br/># output<br/>dtype('O')<br/><br/>np.round(df["category"].memory_usage() / 10**6, 2)<br/># output<br/>80.0</span></pre><p id="536e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">类别列的内存使用量是 80 MB。让我们将它的数据类型改为 category，并再次检查内存使用情况。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="a79b" class="ne md it na b be nf ng l nh ni">df["category"] = df["category"].astype("category")<br/><br/>np.round(df["category"].memory_usage() / 10**6, 2)<br/># output<br/>10.0</span></pre><p id="944c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它从 80 MB 降到了 10 MB，这意味着内存使用量减少了 87.5%。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="a2d2" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">3.向下转换数字列</h1><p id="602b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">数字列的数据类型可能会导致不必要的内存使用。例如，Pandas 中默认的整数数据类型是“int64”，它可以存储介于-9，223，372，036，854，775，808 和 9，223，372，036，854，775，807 之间的数字。在大多数情况下，我们不需要如此大范围的整数值。</p><p id="6b16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将整数列向下转换为 int16 或 int8，以减少内存使用。更实际的方法是使用 to_numeric 函数，它可以为我们进行适当的向下转换。</p><p id="7ccb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先检查一个整数列的内存消耗。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="b39d" class="ne md it na b be nf ng l nh ni">df["x_0"].dtypes<br/># output<br/>dtype('int64')<br/><br/>np.round(df["x_0"].memory_usage() / 10**6, 2)<br/># output<br/>80.0</span></pre><p id="4656" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是 80 MB。让我们向下转换该列的数据类型，并再次检查内存使用情况。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="903b" class="ne md it na b be nf ng l nh ni">df["x_0"] = pd.to_numeric(df["x_0"], downcast="unsigned")<br/><br/>df["x_0"].dtypes<br/># output<br/>dtype('uint8')<br/><br/>np.round(df["x_0"].memory_usage() / 10**6, 2)<br/># output<br/>10.0</span></pre><p id="85ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">新的数据类型是无符号整数 8，这导致 10 MB 的内存使用量。这也意味着内存使用减少了 87.5%。</p><p id="a5e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在任何数字列上这样做，无论是整型还是浮点型。在使用 float 的情况下，我们可以将向下转换参数的值设置为“float”。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="949f" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">4.对稀疏数据使用特殊的数据结构</h1><p id="b620" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们可以使用稀疏对象来有效地存储稀疏数据。假设我们有主要包含零的数字列。通过将这些列转换为稀疏数据类型，可以大大减少内存消耗。</p><p id="f415" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它不一定是“大部分为零”。它可以是 NaN 或任何其他值。稀疏对象可以被视为被“压缩”，其中任何匹配特定值(0、NaN 或任何其他值)的数据都被忽略。压缩后的值实际上并不存储在数组中。</p><p id="2d92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看一个例子来说明这个情况。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="997c" class="ne md it na b be nf ng l nh ni">df_new = df[["x_6", "x_7", "x_8"]].replace(<br/>  {2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}<br/>)<br/><br/>df_new["x_6"].value_counts()<br/># output<br/>0    8999426<br/>1    1000574<br/>Name: x_6, dtype: int64</span></pre><p id="1735" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的数据帧(df_new)包含 3 列，主要由零组成(大约。90%).其他值为 1。让我们检查每一列的数据类型和内存消耗。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="14d7" class="ne md it na b be nf ng l nh ni">df_new.dtypes<br/># output<br/>x_6    int64<br/>x_7    int64<br/>x_8    int64<br/>dtype: object<br/><br/>np.round(df_new.memory_usage() / 10**6, 2)<br/># output<br/>Index     0.0<br/>x_6      80.0<br/>x_7      80.0<br/>x_8      80.0</span></pre><p id="1f8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据类型是 int64，每列消耗 80 MB 内存。如果我们将数据类型转换为 unsigned int8，每列将占用 10 MB 的内存。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="940d" class="ne md it na b be nf ng l nh ni">df_new = df_new.astype("uint8")<br/><br/>np.round(df_new.memory_usage() / 10**6, 2)<br/># output<br/>Index     0.0<br/>x_6      10.0<br/>x_7      10.0<br/>x_8      10.0</span></pre><p id="7905" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们使用稀疏数据类型来进一步提高内存使用率。</p><pre class="kj kk kl km gt mz na nb bn nc nd bi"><span id="29ab" class="ne md it na b be nf ng l nh ni">sdf = df_new.astype(pd.SparseDtype("uint8", 0))<br/><br/>np.round(sdf.memory_usage() / 10**6, 2)<br/># output<br/>Index    0.00<br/>x_6      5.00<br/>x_7      4.99<br/>x_8      5.00</span></pre><p id="d77b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它降到了 5 MB，这也是一个显著的改进。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="80d9" class="nl md it bd me nm nn dn mi no np dp mm li nq nr mo lm ns nt mq lq nu nv ms nw bi translated">结论</h2><p id="4046" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们已经介绍了 4 种不同的技术，使熊猫更适合处理大型数据集。重要的是要注意，有其他的选择，但如果你想继续与熊猫合作，你可以使用这些技术来提高效率。</p><p id="7b11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nx">你可以成为</em> <a class="ae ky" href="https://sonery.medium.com/membership" rel="noopener"> <em class="nx">媒介会员</em> </a> <em class="nx">解锁我的全部写作权限，外加其余媒介。如果你已经是了，别忘了订阅</em><a class="ae ky" href="https://sonery.medium.com/subscribe" rel="noopener"><em class="nx"/></a><em class="nx">如果你想在我发表新文章时收到电子邮件。</em></p><p id="2b37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢您的阅读。如果您有任何反馈，请告诉我。</p></div></div>    
</body>
</html>