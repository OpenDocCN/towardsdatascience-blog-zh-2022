<html>
<head>
<title>8 Tips To Build Powerful Deep Learning Models for Visual Similarity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为视觉相似性建立强大的深度学习模型的8个技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/8-tips-to-build-powerful-deep-learning-models-for-visual-similarity-738eb6f69275#2022-05-09">https://towardsdatascience.com/8-tips-to-build-powerful-deep-learning-models-for-visual-similarity-738eb6f69275#2022-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2381" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">3个月浓缩的一般最佳实践，使您的暹罗网络表现良好，并产生高质量的嵌入</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6b51858b62ce5339ab0b2b53acd27f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MtQUnkqyF1WPVfxU"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">哈维·卡夫雷拉在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1483" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di">答</span>不久前，我参加了前公司举办的数据科学挑战赛。目的是帮助海洋研究人员更好地根据鲸鱼的吸虫外观来识别鲸鱼。</p><p id="92b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更具体地说，我们被要求为测试集的每个图像预测来自完整数据库(训练+测试)的前20个最相似的图像。</p><p id="b26d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这不是一个标准的分类任务。</p><p id="2b79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我花了3个月的时间做原型，最终在最终(私人)排行榜的300名参与者中名列第三。</p><p id="fc2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">对于这个故事，宙斯是我家的GPU驱动的服务器。没错，它有名字。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mf"><img src="../Images/34fe0f88e7d5003754d7d49d1b76c89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWbG5WMK3KFPMI8FdUvFvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决赛(私人)排行榜</p></figure><p id="5bb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是让我们不要进入这个挑战的细节。</p><blockquote class="mg mh mi"><p id="ab47" class="kz la me lb b lc ld ju le lf lg jx lh mj lj lk ll mk ln lo lp ml lr ls lt lu im bi translated"><em class="it">这篇帖子的目的是和大家分享</em> <strong class="lb iu"> <em class="it">我的关于构建视觉相似性任务强嵌入模型的小技巧</em> </strong> <em class="it">。这次挑战是一次极好的学习机会，我尝试了许多不同的技术。因此，我将在这里与大家分享什么是最有效的，什么是无效的，我将详细说明我在这个过程中采取的不同步骤。</em></p></blockquote><p id="beaf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事不宜迟，让我们来看看🔍</p><p id="6540" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me"> PS:以下实验的代码在我的Github</em><a class="ae ky" href="https://github.com/ahmedbesbes/whales-classification" rel="noopener ugc nofollow" target="_blank"><em class="me">repo</em></a><em class="me">上。</em></p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="c154" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">1 —将问题形式化，选择正确的损失？</h1><p id="3992" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我首先问自己的潜在问题是:<strong class="lb iu">我如何构建一个可以有效嵌入其特征并用于相似性任务的鲸鱼爪的数字表示？</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/f0dadadeb915b3066f42ad940502e9ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yAj_C9JMKwgV7XF7xP4ylQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们的目标是构建一个模型，生成输入图像的“良好”表示:作者的一张鲸鱼的图片</p></figure><h2 id="b4de" class="nr mu it bd mv ns nt dn mz nu nv dp nd li nw nx nf lm ny nz nh lq oa ob nj oc bi translated">第一种方法:分类</h2><p id="db3a" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我最初采用的天真方法是训练一个卷积神经网络(CNN ),使用标准的softmax交叉熵损失对图像的标签集(鲸鱼id)进行分类，然后将最后一个完全连接的层的输出作为嵌入。<strong class="lb iu">不幸的是，训练网络来优化交叉熵并不能产生良好的相似性嵌入向量。<br/> </strong>在这个问题中效率不是很高的原因是交叉熵只学习如何将图像映射到标签，而不学习输入之间的相对距离(或相似度)。</p><p id="9835" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">当你需要嵌入视觉相似性任务时，你的网络应该在训练时明确地学习如何在彼此之间比较和排列项目。</strong>如果你想了解更多，我推荐这篇<a class="ae ky" href="https://omoindrot.github.io/triplet-loss" rel="noopener ugc nofollow" target="_blank">帖子</a>。</p><h2 id="97e9" class="nr mu it bd mv ns nt dn mz nu nv dp nd li nw nx nf lm ny nz nh lq oa ob nj oc bi translated">从分类到度量学习</h2><p id="8061" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">学习相互比较和排列输入的有效嵌入的任务被称为<a class="ae ky" href="http://researchers.lille.inria.fr/abellet/talks/metric_learning_tutorial_CIL.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">度量学习</strong> </a> <strong class="lb iu">。<br/> </strong>这是一个经过充分研究的课题，已经应用于人脸识别或图像检索等热门应用中。<br/>我不会在这篇文章中讨论什么是度量学习。有很好的教程解释的很好<a class="ae ky" href="https://gombru.github.io/2019/04/03/ranking_loss/" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae ky" href="https://omoindrot.github.io/triplet-loss" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="3946" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将介绍我在这次挑战中试验的两个损失函数。</p><ul class=""><li id="e0e4" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">三重损失</li><li id="7903" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">弧面损失</li></ul><h2 id="df31" class="nr mu it bd mv ns nt dn mz nu nv dp nd li nw nx nf lm ny nz nh lq oa ob nj oc bi translated">1.三重损失</h2><p id="b75c" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">2015年，谷歌在FaceNet <a class="ae ky" href="https://arxiv.org/pdf/1503.03832.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中介绍了三重态损失。<br/>作者通过设计一个系统来探索人脸嵌入的新技术，该系统学习从人脸图像到紧致欧氏空间的映射，其中距离直接对应于人脸相似性的度量。<br/>提出的方法<strong class="lb iu">优化了嵌入本身</strong>，而不是没有明确解决问题的中间损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/a85148aef84500e90210686141843fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*G9HrHYbmC02jDeD9.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://omoindrot.github.io/triplet-loss" rel="noopener ugc nofollow" target="_blank">https://omoindrot.github.io/triplet-loss</a></p></figure><p id="0dee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种损失由三组数据定义:</p><ul class=""><li id="f18e" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">代表引用的<strong class="lb iu">锚图像</strong></li><li id="00a5" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">与主播同级的<strong class="lb iu">正面形象</strong></li><li id="5e7d" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">不同类别的<strong class="lb iu">负像</strong></li></ul><p id="e339" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并且以这样的方式优化模型的权重:</p><ul class=""><li id="f0c2" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">锚的嵌入和正图像的嵌入之间的欧几里德距离，即d(a，p)很低</li><li id="af69" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">锚的嵌入和负像的嵌入之间的欧几里德距离，即d(a，n)很高</li></ul><p id="2c97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">三重态损失可以形式化为:</p><blockquote class="mg mh mi"><p id="717a" class="kz la me lb b lc ld ju le lf lg jx lh mj lj lk ll mk ln lo lp ml lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it"> L = max(d(a，p) — d(a，n) + margin，0) </em> </strong></p></blockquote><p id="ad5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据定义，这种损失的下限为0。所以优化网络会尽可能把它推向0。培训完成后:</p><ul class=""><li id="566f" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">d(a，p)变得很小~0</li><li id="5b23" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">d(a，n)大于d(a，p) +余量</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/967099866db34532923aa2446f73e725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLFGI7wSLEHRxQFhr_VZ8A.png"/></div></div></figure><p id="b4c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我用了一些训练技巧来提高三连音缺失训练:</p><ul class=""><li id="a229" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated"><strong class="lb iu">硬采样</strong>:我使用硬三连音只是为了优化损失。<br/>一个硬三元组(A，p，n)满足这个不等式:d(a，n) &lt; d(a，p)</li><li id="6fcd" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu"> PK采样</strong>:我在我的PyTorch数据加载器中使用了一个采样器来确保每一批都是PK大小的，由P个不同的类组成，每个类有K个图像。</li><li id="b1c6" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">在线生成</strong>三胞胎</li></ul><p id="7aa5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在我的Github <a class="ae ky" href="https://github.com/ahmedbesbes/whales-classification/tree/master" rel="noopener ugc nofollow" target="_blank"> repo </a>上找到这些技巧的实现细节，如果你想了解更多这些技术，我推荐你阅读这篇<a class="ae ky" href="https://arxiv.org/pdf/1703.07737.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><h2 id="5a13" class="nr mu it bd mv ns nt dn mz nu nv dp nd li nw nx nf lm ny nz nh lq oa ob nj oc bi translated">2.弧形面</h2><p id="8454" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我在挑战结束前三周遇到了这种失败，在我尝试的那一刻，我就被它的有效性震惊了。</p><p id="177d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ArcFace loss已于2019年(CVPR)推出，其主要目标是通过学习用于人脸识别的高区分度特征来最大化人脸类别的可分性。根据该论文的作者，该方法在最常见的人脸识别基准上优于三重损失、内损失和间损失。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/7caaf14758b970908c601ef3159b0141.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*12Lit8VCaDGMJIG0gJc0PA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:ArcFace <a class="ae ky" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="89f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当给定从网络中提取的特征向量和相应的地面真实值(在本例中为鲸鱼id)时，arcface会学习一个权重矩阵来将计算映射到一个新的空间，在该空间中计算特征和目标之间的角度。因此，这个空间有一个几何解释。<br/>然后给这个角度增加一个余量，回复到原来的空间，应用交叉熵softmax loss。这种损失的主要好处是过渡到一个新的空间，在那里分离性被最大化。尽管如此，ArcFace与softmax交叉熵损失并无不同，因此训练开销很小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/6fb13b3579568f262d06b651794c4b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mI74Z1_1v5NEsANJREc7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:ArcFace <a class="ae ky" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="825c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我用ArcFace做实验时，我注意到三重态损失的一些好处:</p><ul class=""><li id="5e2d" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">ArcFace可以很好地适应大量的类</li><li id="f351" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">它减轻了在训练三重损失时遇到的硬样本挖掘的问题(因为它不需要一个)。它需要的只是数据和相应的标签。</li><li id="a084" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">它提供了一个很好的几何解释</li><li id="5108" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">它提供了稳定的训练</li><li id="7fca" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">它收敛得更快</li><li id="5e1e" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">最重要的是，用这种损失训练的单个模型比用三重损失训练的五个模型的混合模型表现得更好。</li></ul><p id="ec3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是为什么我在最终提交的作品中使用了它。</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="1674" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ArcFace是我的解决方案的基石。现在，让我们来看看帮助我有效设置培训的不同步骤。</p><h1 id="81d1" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">2-成为数据🗂的一员</h1><p id="d6de" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">这是不言而喻的，但我还是要说:花尽可能多的时间检查你的数据。无论你是在计算机视觉还是NLP领域工作，<strong class="lb iu">深度学习模型，就像任何其他模型一样，都是垃圾进垃圾出</strong>。不管它有多少深层。如果你给它提供质量差的数据，你就不要指望有好的结果。</p><p id="b3bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我对这个挑战的数据做了几件事(这个过程显然适用于度量学习任务中的任何数据集):</p><ul class=""><li id="2354" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">我去掉了那些分辨率很低或者根本看不到鲸爪的嘈杂和混乱的图像</li><li id="4e1b" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">我丢弃了只有一个图像的类:这被证明是非常有效的。这背后的原因是度量学习任务需要一点关于每个类的上下文:每个类一个图像显然是不够的。</li><li id="0d9b" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">我提取了鲸鱼尾巴的包围盒，以便丢弃任何周围的噪音(水溅声、海浪声)并放大相关信息。这后来作为一个<strong class="lb iu">注意机制</strong>。<br/>为了做到这一点，我在makesense.ai上标注了大约300头福禄克鲸后，从头开始训练了Yolo-V3福禄克探测器，make sense . ai是由<a class="pa pb ep" href="https://medium.com/u/11b65705ec0?source=post_page-----738eb6f69275--------------------------------" rel="noopener" target="_blank"> Piotr Skalski </a>构建的图像标记工具。<br/>我还用这个优秀的<a class="ae ky" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank"> repo </a>训练了Yolo-V3模型。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/db66deceec7d681b5241f5dc81a8bd71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bx5A5rafsrZb2SRv.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者截图</p></figure><p id="829e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">按键学习</strong>👨‍🏫<strong class="lb iu"> : </strong>与复杂的建模相比，适当清理数据可能会让你赢得更多分数。</p><h1 id="6bf4" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">3 —不要低估迁移学习的力量🔄</h1><p id="8a11" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">在比赛的前几周，我使用了ImageNet预训练模型(renset34、densenet121等。)作为骨干。还好，我的模型在一段时间后收敛了。</p><p id="aad9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后我调查了Kaggle座头鲸识别<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification" rel="noopener ugc nofollow" target="_blank">比赛</a>数据。</p><ul class=""><li id="ea43" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">尽管有排行榜指标，但这场比赛与我们的挑战非常相似</li><li id="4fae" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">这些数据和我们的结构一样，有着同样的阶级不平衡问题</li><li id="f6b6" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">这些吸虫和我们的竞争对手看起来不太一样。他们来自另一个物种——但这没什么。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/ffbf62912c22338eb42bc87376d932cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fiHp1bWH11XLJzb-.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卡格尔鲸的侥幸——来源:<a class="ae ky" href="https://www.kaggle.com/c/humpback-whale-identification" rel="noopener ugc nofollow" target="_blank">卡格尔</a></p></figure><p id="c6ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我立即决定使用三重损失对ImageNet预训练模型进行微调。</p><p id="bbc0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事情的发展很有趣:</p><ul class=""><li id="0af3" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">这产生了巨大的影响！我在排行榜上跳了起来</li><li id="cc0a" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">网络能够更快地聚合(在30%的时间内)</li></ul><p id="afb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">主要收获</strong>👨‍🏫<strong class="lb iu"> : </strong></p><ul class=""><li id="fb07" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">迁移学习很少会有伤害。如果你从预先训练了1000个普通物体(动物、汽车等)的ImageNet模型开始。)，更有可能的是，在你的类似数据集上的预训练网络更好。</li><li id="6852" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">迁移学习是一种间接的方式，可以给你的培训带来更多的数据</li></ul><h1 id="22d9" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">4-输入形状非常重要📏📐 🔍</h1><p id="cabb" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">关于这项挑战的数据，有一个重要的细节值得一提:它的<strong class="lb iu">高分辨率</strong>。由于专业设备，部分图像达到3000x1200像素甚至更高。</p><p id="59f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我开始比赛时，我将我的网络的输入大小设置为224x224像素，就像我在大多数图像分类问题中通常做的那样。</p><p id="2543" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，当我开始改变输入大小时，我的性能得到了提升。480x480是最适合我的输入图形。</p><p id="45b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">主要学习内容</strong>👨‍🏫<strong class="lb iu"> : </strong></p><ul class=""><li id="93f0" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">如果您正在处理高分辨率图像，请尝试增加网络的输入大小。ImageNet推荐的默认224x224输入形状并不总是最佳选择。<strong class="lb iu">有了更大的输入形状，你的网络可以学习具体的小细节</strong>来区分不同的鲸鱼。</li><li id="e8cf" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">越大不一定越好</strong>。如果您将输入形状增加到1000像素左右，您很可能会遇到以下两个问题:</li></ul><ol class=""><li id="8e02" class="od oe it lb b lc ld lf lg li of lm og lq oh lu pe oj ok ol bi translated">慢速训练:随着输入形状的增加，你的网络有更多的参数，这显然需要更多的计算能力，并且由于过度拟合也不能保证收敛。</li><li id="49e5" class="od oe it lb b lc om lf on li oo lm op lq oq lu pe oj ok ol bi translated">小图像性能差:当微小图像被上采样到1000x1000px分辨率时，原始信号被破坏。</li></ol><h1 id="fe42" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">5 —复杂的架构不一定是最佳选择🤹</h1><p id="6263" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">如果你对计算机视觉生态系统有点熟悉，你可能听说过一些流行的架构，如VGG或ResNet，或者不太可能听说过最近的复杂架构，如ResNet-Inception-V4或NASNet。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/da857c6e82de96658e05557251abb79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*C-dPyM2Ts1Fof9kA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代表性深度神经网络架构的基准分析:<a class="ae ky" href="https://arxiv.org/pdf/1810.00736.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="d23d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是<strong class="lb iu">项重要学习</strong>👨‍🏫经过三个月的实验，我终于明白了:</p><ul class=""><li id="122f" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">大而深的最先进的主干并不总是最佳的选择:如果你的数据集很小(就像这次挑战中的那个)，它们很快就会过度适应，如果你的计算资源很少，你就无法训练它们</li><li id="b53e" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">好的方法是从简单的网络开始，逐步增加复杂性，同时监控验证数据集的性能</li><li id="035a" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">如果您计划在web应用程序中发布您的解决方案，您必须考虑模型大小、内存消耗、推理时间等。</li></ul><h1 id="f79d" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">6 —设计稳健的管道⚙</h1><p id="13e3" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我制定的培训计划包括5个主要步骤:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/55fc92334daf48b5557838bb5ea5415c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3tJFOSDz7dySoSUS.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">培训管道—来源:我的Github <a class="ae ky" href="https://github.com/ahmedbesbes/whales-classification" rel="noopener ugc nofollow" target="_blank">回购</a></p></figure><ul class=""><li id="780e" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated"><strong class="lb iu">第一步:</strong>dataloder连接到数据库，批量向网络提供图像和相应的标签。它还负责在不同时期之间调整数据，并应用动态数据增强。<br/> <strong class="lb iu">重度增强</strong>已作为正则化效果应用于更好的泛化。变换包括:高斯噪声和模糊、运动模糊、随机雨(模拟飞溅效果)、颜色偏移、亮度、色调和饱和度的随机变化、锐化、透视的随机变化、弹性变换、随机旋转、仿射变换(平移和剪切)和随机遮挡(增加概括能力)</li><li id="e68a" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">第二步:</strong>向前传球。该模型将图像作为输入并生成特征。</li><li id="76f2" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">步骤3 </strong>:计算特征和目标之间的弧面损失</li><li id="f3ce" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">第四步:</strong>反向传播。计算损耗w.r.t .模型参数的梯度</li><li id="5ae5" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">步骤5:</strong>Adam优化器使用损失的梯度更新权重。该操作在每个批次上执行。</li></ul><h1 id="b2ae" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">7 —顶级教练的一般训练技巧👨‍🏫</h1><p id="6499" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">在这次比赛中，我做了很多实验。以下是我列出的让训练安全、可重复、稳健的建议。</p><ul class=""><li id="1372" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">固定种子以确保<strong class="lb iu">再现性</strong>。您很可能必须在脚本的开头编写这几行代码</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="3945" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更多详情<a class="ae ky" href="https://pytorch.org/docs/stable/notes/randomness.html" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><ul class=""><li id="b8ba" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">亚当是一个安全的优化器。但是，您不应该忘记<strong class="lb iu">将重量衰减设置为非零值</strong>。这起到了规则化的作用，防止了损耗波动。使用值:1e-3</li><li id="d541" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">大幅增强确实提高了结果。我从简单的旋转和平移开始，但是当我添加上面提到的转换时，我得到了更好的结果。扩充缓解了数据缺乏的问题，提高了模型的稳定性和泛化能力。为了建立一个有效的增强管道，我强烈推荐<a class="ae ky" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">白蛋白</a>库。</li><li id="0248" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">使用学习率计划程序来降低整个培训过程中的学习率。这防止损失停留在局部最小值。<br/>我最终选择的是一个<strong class="lb iu">预热调度程序，后面是余弦退火</strong>。<br/>它基本上从一个小的学习速率开始，在几个时期内达到目标值(开始学习速率)(这被称为预热阶段),然后按照余弦退火法降低学习速率，直到结束学习速率。<br/>预热阶段起到了调整作用，以防止早期过度拟合。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/d4a01d7314c872a996ffb2f7de891d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*gT5O_EfPlUr0TGdw2jDQQQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:researchgate.ne</p></figure><ul class=""><li id="26f0" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">在每个时期结束时监控损失值和其他指标。我用Tensorbaord画的。</li><li id="4640" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">伪标签可以给你一个优势:这种技术常用于Kaggle比赛。它包括根据您的训练数据训练一个模型，使用它对测试数据进行预测，获得最有信心的预测(&gt; 0.9的概率)，将它们添加到原始训练数据中，然后再次重新训练。</li><li id="fecd" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">确保你有合适的硬件。我可以使用一台11Gb GPU内存和64GB RAM的GPU服务器。在软件方面，我使用的是带有PyTorch 1.1.0和torchvision 0.3.0的conda虚拟环境。<br/>在480px分辨率的图像上用ArcFace loss训练Densenet121主干每个历元大约需要1分钟。收敛大约是90个纪元。</li><li id="e82a" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">通过记录您的模型来记录您的体验，并在培训结束时或培训期间保存它们。你会在我的Github <a class="ae ky" href="https://github.com/ahmedbesbes/whales-classification" rel="noopener ugc nofollow" target="_blank"> repo </a>中发现这是如何做到的。</li></ul><h1 id="3ca3" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">8-分而治之:将多个模型组合成一个最终提交⚡</h1><p id="3451" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我使用之前的管道和以下参数训练了两个模型:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/e47daa816592ef2c39efad6da951f04c.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*L6RNZ24r4Lhj-HoRrUfpMA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Github <a class="ae ky" href="https://github.com/ahmedbesbes/whales-classification" rel="noopener ugc nofollow" target="_blank">回购</a></p></figure><p id="0975" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我在最终得分中占据优势的是我将它们组合在一起的方式。这是一个简单的<strong class="lb iu">元嵌入技术</strong>，在自然语言处理中非常常用。</p><p id="8797" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">它包括在所有样本上生成每个模型的嵌入，然后连接它们。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/28b87513545e4b32e8a0af4c6a942893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80W5-pcLD02AbSdmFt1wXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">元嵌入模型——作者的图像</p></figure><p id="d34a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该方法用于生成训练和测试数据集的元嵌入。然后，使用相同的计算来生成提交。</p><p id="c0c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">按键学习</strong>👨‍🏫：</p><ul class=""><li id="d025" class="od oe it lb b lc ld lf lg li of lm og lq oh lu oi oj ok ol bi translated">当基础模型在主干架构(resnet34与densenet121)、图像输入大小(480与620)、正则化方案(丢失与不丢失)方面不同时，元嵌入级联技术提供了有趣的嵌入</li><li id="55ad" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated">每个单独的基础模型“看到”不同的东西:组合它们的嵌入产生一个新的混合模型，具有增强的表示能力。</li></ul><h1 id="4f42" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">最后的话🙏</h1><p id="443c" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我要感谢整个GDSC团队，感谢他们把这次挑战变成了一次很好的学习机会，感谢Lisa Steiner给了我们把知识应用到新领域的机会。</p><p id="624b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你能在这里找到可以在其他计算机视觉和深度学习项目中使用的资源。</p><h1 id="af66" class="mt mu it bd mv mw ov my mz na ow nc nd jz ox ka nf kc oy kd nh kf oz kg nj nk bi translated">参考📜</h1><ul class=""><li id="fd9c" class="od oe it lb b lc nl lf nm li pm lm pn lq po lu oi oj ok ol bi translated"><strong class="lb iu">face net</strong>:【https://arxiv.org/pdf/1503.03832.pdf】T4</li><li id="cdea" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">为三重失认人辩护:</strong><a class="ae ky" href="https://arxiv.org/pdf/1703.07737.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1703.07737.pdf</a></li><li id="28bd" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">排名损失、对比损失、差额损失、三联损失、铰链损失:</strong>T12】https://gombru.github.io/2019/04/03/ranking_loss/</li><li id="fb9c" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">三重缺失:</strong><a class="ae ky" href="https://omoindrot.github.io/triplet-loss" rel="noopener ugc nofollow" target="_blank">https://omoindrot.github.io/triplet-loss</a></li><li id="73c1" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu"> ArcFace论文:</strong><a class="ae ky" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1801.07698.pdf</a></li><li id="4a8e" class="od oe it lb b lc om lf on li oo lm op lq oq lu oi oj ok ol bi translated"><strong class="lb iu">解释arc face loss:</strong><a class="ae ky" href="https://medium.com/1-minute-papers/arcface-additive-angular-margin-loss-for-deep-face-recognition-d02297605f8d" rel="noopener">https://medium . com/1-minute-papers/arc face-additive-angular-margin-loss-for-deep-face-recognition-d 02297605 f8d</a></li></ul></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="8a4d" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">新到中？你可以每月订阅5美元，并解锁各种主题的无限文章(技术、设计、创业……)你可以通过点击我的推荐链接<a class="ae ky" href="https://ahmedbesbes.medium.com/membership" rel="noopener">来支持我</a></h1><div class="pp pq gp gr pr ps"><a href="https://ahmedbesbes.medium.com/membership" rel="noopener follow" target="_blank"><div class="pt ab fo"><div class="pu ab pv cl cj pw"><h2 class="bd iu gy z fp px fr fs py fu fw is bi translated">通过我的推荐链接加入Medium—Ahmed bes bes</h2><div class="pz l"><h3 class="bd b gy z fp px fr fs py fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qa l"><p class="bd b dl z fp px fr fs py fu fw dk translated">ahmedbesbes.medium.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg ks ps"/></div></div></a></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/164520bc1b75737b14e758fdbc350204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VYgDGOemcS-aMV2t"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@karsten116?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Karsten Winegeart </a>拍摄</p></figure></div></div>    
</body>
</html>