<html>
<head>
<title>Topic Modeling With Latent Dirichlet Allocation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于潜在狄利克雷分配的主题建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-ea3ebb2be9f4#2022-04-12">https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-ea3ebb2be9f4#2022-04-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a02c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">自然语言处理中一种流行建模技术的综述与实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/523c2e59033121a7aa288c9da162c837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dCQfXLMxQyr53Bom"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">布雷特·乔丹在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="b808" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">介绍</h2><p id="33ee" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">随着大量数据以文档的形式出现，例如文章、电子邮件和简历，对组织、总结、访问和解释这些数据的方法有了新的需求。</p><p id="25ef" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这就是主题建模发挥作用的地方。</p><p id="52d7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题建模是一种无监督的学习技术，在给定的文档集合中挖掘潜在的“主题”。它能够根据主题对文档进行分组或划分，这使它成为企业非常宝贵的资产。主题建模存在于许多应用中，例如推荐系统和搜索引擎。</p><p id="055e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题建模最流行的方法之一是潜在狄利克雷分配(LDA)。</p><p id="3dcd" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在这里，我们提供了一个关于LDA的快速概要，并演示了如何使用Python来执行它。</p><h2 id="bb4e" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">皱胃向左移</h2><p id="4579" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">执行LDA需要用概率模型捕获给定文档集合中的信息。</p><p id="d7b4" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这项技术基于以下两个假设:</p><ol class=""><li id="9851" class="mt mu it lx b ly mo mb mp li mv lm mw lq mx mn my mz na nb bi translated">每个文档都包含多个主题</li><li id="0086" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">每一个主题都由单词组合而成</li></ol><p id="3cbc" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">LDA用主题概率表示文档，用词概率表示主题。</p><p id="bcb4" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">由于LDA背后的算法，使用这种主题建模方法需要大量的计算。</p><p id="877c" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">幸运的是，有了Python的NLP模块(我们将很快介绍)，所有繁重的工作都为您完成了。任何给定文档集合的实际LDA模型都可以用最少的代码构建！</p><p id="77aa" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在这种情况下，我们可以坐视引用栈溢出，让我们的程序为我们做所有的工作，对吗？</p><p id="2cc7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">不完全是。</p><h2 id="0c64" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">挑战</h2><p id="1137" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">虽然由于Python强大的模块，LDA中的计算并不难执行，但在进行LDA时，用户需要做出一些关键决定。</p><p id="71b7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">首先，一个给定的数据集应该有多少个主题？这是用户定义的参数。如果分配的主题数量不适合给定的文档集，任何从文档中获取主题的努力都将失败。</p><p id="2927" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">此外，在建立LDA模型之后，你将会得到每个主题的单词概率。请记住，LDA是一种无监督的学习技术，因此用户的工作是根据每个主题所关联的单词来决定每个主题代表什么。即使LDA模型是健壮的，如果它的结果是不可理解的，它也没有用。</p><h2 id="1876" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">个案研究</h2><p id="f4cf" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">为了巩固对这种主题建模方法的理解，使用真实数据来应用它是有益的。</p><p id="0c51" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">LDA可用于汇总大量数据。人们可以利用这种主题建模方法来识别文档中陈述的要点，而不是解析每个文档中的每个细节。</p><p id="b6c8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">让我们使用LDA从评论集中挖掘话题。</p><p id="714d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在这个演示中，我们使用了亚马逊食品评论(无版权)的数据集，可以在这里访问。这是一个很大的数据集，所以我们将研究范围限制在前100，000条记录。</p><p id="982d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这是数据集的预览。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e24caa06c41e3a26450fc3d7048f9fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*fq3kV9tYukBNAetBB7VgDQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><ol class=""><li id="7359" class="mt mu it lx b ly mo mb mp li mv lm mw lq mx mn my mz na nb bi translated"><strong class="lx iu">预处理</strong></li></ol><p id="5d43" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">当然，在执行LDA之前，需要对评论进行预处理，以便成功地进行分析。</p><p id="c1a8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">首先，我们使用<a class="ae ky" href="https://radimrehurek.com/gensim/" rel="noopener ugc nofollow" target="_blank"> Gensim </a>模块对评论进行标记。此外，我们小写所有字符，并删除任何标点符号。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="f266" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">接下来，我们将二元模型添加到标记化文档中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="f7a8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">最后，我们删除所有出现的停用词或短词，并使用<a class="ae ky" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>模块对剩余的标记执行词汇化。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="5002" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">为了查看预处理后数据是如何被修改的，我们可以将其添加到数据框中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/5af36d1a9d74dba099d6212842eba771.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*q0H-e6xmJhP39FWxdQtdiA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="9943" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 2。创建文档术语矩阵和字典</strong></p><p id="ab1f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">像大多数NLP模型一样，LDA模型需要一个文档术语矩阵作为输入。它还需要语料库中所有单词的字典。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="20a0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 3。确定主题数量</strong></p><p id="f26d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在构建LDA模型之前，我们需要决定食品评论集合中的主题数量。</p><p id="8340" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">这可能很难确定，因为在任何给定的文档集合中没有多少主题的经验法则。因此，有不同的方法可以用来确定这个数字。</p><p id="aa48" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">第一种方法是用不同数量的主题创建多个LDA模型，看看哪一个最容易解释。另一种方法是利用领域知识来确定这个值。</p><p id="db44" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在这种情况下，我们将使用coherence score度量作为食品评论集合中有多少主题的指标。连贯性分数本质上是对分配给每个主题的单词在语义值方面有多相似的度量。分数越高越好。</p><p id="da25" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">让我们计算具有2到10个主题的LDA模型的一致性分数，并查看哪个数量的主题导致最高的一致性分数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/2be553fcf8b2f3d0cd88dc737165fb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*kl3XQ7YJslxY5wFLDmkCfQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="822d" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">根据一致性得分指标，亚马逊食品评论中应该有9个潜在主题。</p><p id="23ed" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 4。构建LDA模型</strong></p><p id="2659" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">既然我们已经确定了主题的最佳数量，我们就可以构建LDA模型了。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="5574" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 5。解读结果</strong></p><p id="0c37" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">一旦建立了模型，我们就可以根据概率得分来查看哪些单词与每个主题的亲和力最强。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/e4951ee63e90f2b4bcdebed0f8d5ea2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nGHq55U15FbiKVa62x7b6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="6bee" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们可以使用与每个主题相关的单词来解释主题，并找出它们所代表的内容:</p><p id="229f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题0:茶相关产品的评论</p><p id="1581" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">话题1:美味小吃评论</p><p id="0df5" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题2:对产品质量的总体正面评价</p><p id="55df" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">话题3:对含糖饮料的评论</p><p id="fcde" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">议题4:对咖啡相关产品的评论</p><p id="7ca7" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题5:对产品口味的总体评价</p><p id="cdcd" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题6:宠物食品评论</p><p id="e852" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题7:关于产品包装的评论</p><p id="5ae9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">主题8:巧克力相关产品的评论</p><p id="5ba3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">就这样，我们能够以9个主题的形式总结10万条食品评论中的数据。这些主题提供了客户谈论内容的大致概念。</p><p id="d2fb" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们还可以使用该模型来确定每个文档中的主题混合。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/498f416c0df5c0bb0926bd01e93e661c.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*-pG11qXuNdweVZyNMYFU7w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="bfc0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我们以第一篇美食评论为例。</p><p id="7d4f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">评论:“我已经购买了几个活力罐装狗粮产品，发现它们的质量都很好。这种产品看起来更像炖肉，而不是加工过的肉，而且闻起来更香。我的拉布拉多很挑剔，她比大多数人都更喜欢这个产品。”</p><p id="d800" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">根据LDA模型，本综述包含主题2和主题6。与主题2和主题6相关的单词证实了这次复习的主题任务。</p><p id="27bf" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 6。可视化结果(可选)</strong></p><p id="fd2e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">虽然我们可以用已经提供给我们的信息来解释文档中的每个主题，但是可视化LDA的结果将增强后续的分析。</p><p id="c008" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" href="https://pyldavis.readthedocs.io/en/latest/readme.html" rel="noopener ugc nofollow" target="_blank"> pyLDAvis </a>模块允许我们通过交互式可视化更好地解释LDA模型的结果。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/319054570d357b0170cf780a71241419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XmGV_nIHZgm-t8rPmliY8g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="abda" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">交互式可视化以图表(左)和水平条形图(右)的形式出现。</p><p id="8a1a" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">图中的每个气泡代表一个主题。气泡的大小代表包含该主题的评论的比例，气泡越大，比例越高。气泡之间的距离代表主题之间的相似度；距离越短，话题越相似。</p><p id="d1c4" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">条形图中的条代表每个单词的词频。蓝色条显示了文档集合中的总术语频率，而红色条显示了所选主题的术语频率。</p><p id="9fdc" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">当然，在执行LDA时，创建这样一个工具并不是一个强制性的步骤，但是任何漂亮而实用的视觉辅助工具总是一个受欢迎的补充，因为它可以更容易地从研究中获得发现并向他人展示。</p><p id="79ac" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">毕竟，谁不喜欢好的视觉效果呢？</p><h2 id="d3f1" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/287ca096495519da345668ec242a8465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SjeFJB40d6OYBjzG"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@prateekkatyal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Prateek Katyal </a>拍摄</p></figure><p id="4a82" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">到目前为止，您已经对LDA的功能以及如何使用Python强大的模块来执行它有了大致的了解。</p><p id="01c8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">也就是说，这只是LDA作为主题建模方法的一个概述。如果你有兴趣了解更多关于LDA的内部运作，我强烈建议你从查看这篇<a class="ae ky" href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>开始。</p><p id="5f69" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">我祝你在数据科学的努力中好运！</p><h2 id="7ead" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">参考</h2><ol class=""><li id="44f6" class="mt mu it lx b ly lz mb mc li nq lm nr lq ns mn my mz na nb bi translated">J.麦考利和j .莱斯科维奇。从业余爱好者到行家:通过在线评论模拟用户专业知识的演变。WWW，2013。</li><li id="4483" class="mt mu it lx b ly nc mb nd li ne lm nf lq ng mn my mz na nb bi translated">布莱，大卫和吴，安德鲁和乔丹，迈克尔。(2001).潜在狄利克雷分配。机器学习研究杂志。3.601–608.</li></ol></div></div>    
</body>
</html>