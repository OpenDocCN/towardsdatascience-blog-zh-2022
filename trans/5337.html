<html>
<head>
<title>A Step-by-Step Guide to Feature Engineering for Multivariate Time Series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元时间序列特征工程分步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-step-by-step-guide-to-feature-engineering-for-multivariate-time-series-162ccf232e2f#2022-11-30">https://towardsdatascience.com/a-step-by-step-guide-to-feature-engineering-for-multivariate-time-series-162ccf232e2f#2022-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="02e4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用 Python 添加基于汇总统计数据的新要素</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a84f6da9b4938f6cff2dcd55311cb4bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TzJg4WZIvGBxx1Ez"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Artem Maltsev 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5a9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个分步指南，介绍<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-for-forecasting-supervised-learning-with-multivariate-time-series-b5b5044fe068">多元时间序列预测</a>的特征工程。您将学习如何计算几个滚动统计数据。将这些添加到解释变量中通常会导致更好的预测性能。</p><h1 id="1995" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">介绍</h1><h2 id="43b6" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">自动回归</h2><p id="ce00" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">多元时间序列包含两个或多个变量。下面是一个例子。通常，研究这些数据集的目的是预测这些变量中的一个或多个。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/2571dfabcafe92b3cc5800c5e803dc3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-LC-NJMB2fCyf_bMT8zYA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:包含 9 个变量的多元时间序列。这些代表了智能浮标捕捉到的海洋状况。<a class="ae ky" href="https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork.html" rel="noopener ugc nofollow" target="_blank">数据公开可用【1】(CC BY 4.0 License)</a>。图片作者。</p></figure><p id="84da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数预测模型是基于自回归的。这相当于解决监督学习回归任务。<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-for-forecasting-supervised-learning-with-multivariate-time-series-b5b5044fe068">序列的未来值是目标变量。输入解释变量是每个变量最近的过去值。</a></p><p id="9082" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自动回归在一个主要假设下工作。最近的过去值包含了足够的关于未来的信息。但这可能不是真的。</p><p id="3997" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以试着从最近的数据中提取更多的信息。例如，滚动汇总统计有助于描述最近的动态。</p><h2 id="aa2c" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">自动化特征工程</h2><p id="194f" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">特征工程包括提取和管理解释变量。这是任何数据科学项目的关键阶段。特征的质量是模型性能的一个重要方面。正因为如此，数据科学家在这个过程中花费了大量的时间。</p><p id="bc4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，特征工程通常是一个特别的过程。数据科学家根据他们的领域知识和专业技能创建要素。因此，这个过程的自动化部分是从业者所希望的。</p><p id="5511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看如何对多元时间序列进行这种处理。</p></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="9391" class="lv lw it bd lx ly nm ma mb mc nn me mf jz no ka mh kc np kd mj kf nq kg ml mm bi translated">多元时间序列的特征工程</h1><h2 id="4845" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">读取数据</h2><p id="8559" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">我们将使用从智能浮标收集的多元时间序列<a class="ae ky" href="https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork.html" rel="noopener ugc nofollow" target="_blank">作为案例研究【1】。这个浮标位于爱尔兰海岸。它捕捉了与海洋条件相关的 9 个变量。这些包括</a><a class="ae ky" href="https://erddap.marine.ie/erddap/info/IWaveBNetwork/index.html" rel="noopener ugc nofollow" target="_blank">海水温度、海浪高度、海水流速</a>等等。上面的图 1 显示了 2022 年第一个月的情况。</p><p id="d062" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是如何使用 pandas 读取这些数据的方法:</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="2a36" class="nw lw it ns b be nx ny l nz oa">import pandas as pd<br/><br/># skipping second row, setting time column as a datetime column<br/># dataset available here: https://github.com/vcerqueira/blog/tree/main/data<br/>buoy = pd.read_csv('data/smart_buoy.csv', <br/>                   skiprows=[1], <br/>                   parse_dates=['time'])<br/><br/># setting time as index<br/>buoy.set_index('time', inplace=True)<br/># resampling to hourly data<br/>buoy = buoy.resample('H').mean()<br/># simplifying column names<br/>buoy.columns = [<br/>    'PeakP', 'PeakD', 'Upcross',<br/>    'SWH', 'SeaTemp', 'Hmax', 'THmax',<br/>    'MCurDir', 'MCurSpd'<br/>]</span></pre><p id="be59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的图 1 显示了 2022 年第一个月的情况。</p><p id="d8b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标是预测 SWH(有效波高)变量的未来值。这个变量通常用于量化海浪的高度。<a class="ae ky" href="https://medium.com/towards-data-science/an-introduction-to-exceedance-probability-forecasting-4c96c0e7772c" rel="noopener">这个问题的一个用例是估算海浪产生的能量</a>。这种能源是不可再生能源越来越受欢迎的替代品。</p><h2 id="825f" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">自回归模型</h2><p id="58ef" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">时间序列是多元的。因此，您可以使用 ARDL(自回归分布滞后)方法来解决这个任务。这个方法你可以在<a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-for-forecasting-supervised-learning-with-multivariate-time-series-b5b5044fe068">我之前的帖子</a>里了解更多。</p><p id="145a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是实现这个方法的方法。</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="c1f1" class="nw lw it ns b be nx ny l nz oa">import pandas as pd<br/><br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import mean_absolute_percentage_error as mape<br/>from sklearn.multioutput import MultiOutputRegressor<br/>from lightgbm import LGBMRegressor<br/><br/># https://github.com/vcerqueira/blog/blob/main/src/tde.py<br/>from src.tde import time_delay_embedding<br/><br/>target_var = 'SWH'<br/><br/>colnames = buoy.columns.tolist()<br/><br/># create data set with lagged features using time delay embedding<br/>buoy_ds = []<br/>for col in buoy:<br/>    col_df = time_delay_embedding(buoy[col], n_lags=24, horizon=12)<br/>    buoy_ds.append(col_df)<br/><br/># concatenating all variables<br/>buoy_df = pd.concat(buoy_ds, axis=1).dropna()<br/><br/># defining target (Y) and explanatory variables (X)<br/>predictor_variables = buoy_df.columns.str.contains('\(t\-')<br/>target_variables = buoy_df.columns.str.contains(f'{target_var}\(t\+')<br/>X = buoy_df.iloc[:, predictor_variables]<br/>Y = buoy_df.iloc[:, target_variables]<br/><br/># train/test split<br/>X_tr, X_ts, Y_tr, Y_ts = train_test_split(X, Y, test_size=0.3, shuffle=False)<br/><br/># fitting a lgbm model without feature engineering<br/>model_wo_fe = MultiOutputRegressor(LGBMRegressor())<br/>model_wo_fe.fit(X_tr, Y_tr)<br/><br/># getting forecasts for the test set<br/>preds_wo_fe = model_wo_fe.predict(X_ts)<br/><br/># computing the MAPE error<br/>mape(Y_ts, preds_wo_fe)<br/># 0.238</span></pre><p id="d325" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，将时间序列转化为自回归问题。这是通过函数<em class="ob"> time_delay_embedding </em>完成的。预测目标是预测 SWH 接下来的 12 个值(<em class="ob"> horizon=12 </em>)。解释变量是序列中每个变量过去的 24 个值(<em class="ob"> n_lags=24 </em>)。</p><p id="02de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用直接方法为每个预测范围训练 LightGBM。<a class="ae ky" href="https://medium.com/towards-data-science/6-methods-for-multi-step-forecasting-823cbde4127a" rel="noopener"><em class="ob">直接</em>方法是一种多步提前预测</a>的常用方法。它在 scikit-learn 中实现，名为<em class="ob"> MultiOutputRegressor。</em></p><p id="71df" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码构建并测试了一个自回归模型。解释变量仅包括每个变量最近的过去值。这导致平均绝对百分比误差为<em class="ob"> 0.238 </em>。让我们看看这个分数是否可以用特征工程来提高。</p><p id="fea3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本指南包括两种从多元时间序列中提取特征的方法:</p><ul class=""><li id="fbda" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated"><strong class="lb iu">单变量特征提取。</strong>计算每个变量的滚动统计量。例如，滚动平均可用于消除虚假观察；</li><li id="ac28" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated"><strong class="lb iu">二元特征提取。</strong>计算变量对的滚动统计量，以总结它们的相互作用。例如，两个变量之间的滚动协方差。</li></ul><h2 id="b836" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">单变量特征提取</h2><p id="c685" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">你可以总结每个变量最近的值。例如，计算滚动平均值来总结最近的水平。或滚动离差，以了解最近的离差程度。</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="4552" class="nw lw it ns b be nx ny l nz oa">import numpy as np<br/><br/>SUMMARY_STATS = {<br/>    'mean': np.mean,<br/>    'sdev': np.std,<br/>}<br/><br/>univariate_features = {}<br/># for each column in the data<br/>for col in colnames:<br/>    # get lags for that column<br/>    X_col = X.iloc[:, X.columns.str.startswith(col)]<br/><br/>    # for each summary stat<br/>    for feat, func in SUMMARY_STATS.items():<br/>        # compute that stat along the rows<br/>        univariate_features[f'{col}_{feat}'] = X_col.apply(func, axis=1)<br/><br/># concatenate features into a pd.DF<br/>univariate_features_df = pd.concat(univariate_features, axis=1)</span></pre><p id="8ef2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能想再添加一些统计数据。您可以通过向 SUMMARY_STATS 字典添加函数来实现这一点。将这些函数放在一个字典中可以保持代码整洁。</p><h2 id="1198" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">二元特征提取</h2><p id="6970" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">单变量统计遗漏了不同变量之间的潜在相互作用。您可以使用二元特征提取过程来获取这些信息。</p><p id="a7e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个想法是计算不同变量对的特征。所以，你用二元统计总结这些对的联合动力学。</p><p id="34b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两种方法可以做到这一点:</p><ul class=""><li id="abd7" class="oc od it lb b lc ld lf lg li oe lm of lq og lu oh oi oj ok bi translated"><strong class="lb iu">滚动二元统计。</strong>计算以变量对为输入的统计数据。例如，滚动协方差或滚动相关；</li><li id="28a8" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated"><strong class="lb iu">滚动二元变换后跟单变量统计。</strong>将一对变量转化为一个变量，并对这个变量进行汇总。例如，计算元素间的互相关，然后取其平均值。</li></ul><p id="e70d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">滚动二元统计的例子包括协方差、相关性或相对熵。</p><p id="78b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有许多二进制转换的可能性。例如，变量对之间的百分比差、互相关或线性卷积。然后，这些转换用统计数据进行总结，如平均值或标准偏差。</p><p id="3571" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是用于一次性完成这两个提取过程的脚本。</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="35a7" class="nw lw it ns b be nx ny l nz oa">import itertools<br/><br/>import pandas as pd<br/><br/>from scipy.spatial.distance import jensenshannon<br/>from scipy import signal<br/>from scipy.special import rel_entr<br/><br/>from src.feature_extraction import covariance, co_integration<br/><br/>BIVARIATE_STATS = {<br/>    'covariance': covariance,<br/>    'co_integration': co_integration,<br/>    'js_div': jensenshannon,<br/>}<br/><br/>BIVARIATE_TRANSFORMATIONS = {<br/>    'corr': signal.correlate,<br/>    'conv': signal.convolve,<br/>    'rel_entr': rel_entr,<br/>}<br/><br/># get all pairs of variables<br/>col_combs = list(itertools.combinations(colnames, 2))<br/><br/>bivariate_features = []<br/># for each row<br/>for i, _ in X.iterrows():<br/>    # feature set in the i-th time-step<br/>    feature_set_i = {}<br/>    for col1, col2 in col_combs:<br/>        # features for pair of columns col1, col2<br/><br/>        # getting the i-th instance for each column<br/>        x1 = X.loc[i, X.columns.str.startswith(col1)]<br/>        x2 = X.loc[i, X.columns.str.startswith(col2)]<br/><br/>        # compute each summary stat<br/>        for feat, func in BIVARIATE_SUMMARY_STATS.items():<br/>            feature_set_i[f'{col1}|{col2}_{feat}'] = func(x1, x2)<br/><br/>        # for each transformation<br/>        for trans_f, t_func in BIVARIATE_TRANSFORMATIONS.items():<br/><br/>            # apply transformation<br/>            xt = t_func(x1, x2)<br/><br/>            # compute summary stat<br/>            for feat, s_func in SUMMARY_STATS.items():<br/>                feature_set_i[f'{col1}|{col2}_{trans_f}_{feat}'] = s_func(xt)<br/><br/>    bivariate_features.append(feature_set_i)<br/><br/>bivariate_features_df = pd.DataFrame(bivariate_features, index=X.index)</span></pre><p id="12b5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，您可以添加额外的转换或统计。这是通过将它们包含在字典 BIVARIATE_TRANSFORMATIONS 或 BIVARIATE_STATS 中来实现的。</p><p id="c878" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">提取所有特征后，将它们连接到原始解释变量。然后，培训和测试周期就像你之前做的一样。</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="2670" class="nw lw it ns b be nx ny l nz oa"># concatenating all features with lags<br/>X_with_features = pd.concat([X, univariate_features_df, bivariate_features_df], axis=1)<br/><br/># train/test split<br/>X_tr, X_ts, Y_tr, Y_ts = train_test_split(X_with_features, Y, test_size=0.3, shuffle=False)<br/><br/># fitting a lgbm model with feature engineering<br/>model_w_fe = MultiOutputRegressor(LGBMRegressor())<br/>model_w_fe.fit(X_tr, Y_tr)<br/><br/># getting forecasts for the test set<br/>preds_w_fe = model_w_fe.predict(X_ts)<br/><br/># computing MAPE error<br/>print(mape(Y_ts, preds_w_fe))<br/># 0.227</span></pre><p id="f5b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这导致平均绝对百分比误差为<em class="ob"> 0.227 </em>，这是一个改进。不使用特征工程的方法损失更大(<em class="ob"> 0.238 </em>)。</p><h2 id="05fb" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">特征选择</h2><p id="6b2a" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">上述提取过程总共产生 558 个解释变量。</p><p id="9e37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据变量和汇总统计的数量，这可能会导致一个高维问题。因此，从数据集中移除不良或冗余的特征非常重要。</p><p id="9517" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以这样做的一个方法是抓住最重要的特征，用这些特征重复训练过程。</p><pre class="kj kk kl km gt nr ns nt bn nu nv bi"><span id="7372" class="nw lw it ns b be nx ny l nz oa"># getting the importance of each feature in each horizon<br/>avg_imp = pd.DataFrame([x.feature_importances_<br/>                        for x in model_w_fe.estimators_]).mean()<br/><br/># getting the top 100 features<br/>n_top_features = 100<br/><br/>importance_scores = pd.Series(dict(zip(X_tr.columns, avg_imp)))<br/>top_features = importance_scores.sort_values(ascending=False)[:n_top_features]<br/>top_features_nm = top_features.index<br/><br/># subsetting training and testing sets by those features<br/>X_tr_top = X_tr[top_features_nm]<br/>X_ts_top = X_ts[top_features_nm]<br/><br/># re-fitting the lgbm model<br/>model_top_features = MultiOutputRegressor(LGBMRegressor())<br/>model_top_features.fit(X_tr_top, Y_tr)<br/><br/># getting forecasts for the test set<br/>preds_top_feats = model_top_features.predict(X_ts_top)<br/><br/># computing MAE error<br/>mape(Y_ts, preds_top_feats)<br/># 0.229</span></pre><p id="0800" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前 100 个功能与完整的 558 个功能具有相似的性能。</p><p id="0f59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是 15 大特征的重要性(为简明起见，省略了其他特征):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/39eead315ff53bc9068d00011c986a6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7veqySMrq3DfswqObscYYA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2:根据预测模型的前 15 个特性。图片作者。</p></figure><p id="47ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最重要的特征是目标变量的第一个滞后。但是，一些提取的特征出现在这前 15 名中。比如 SWH 第三好的功能|Hmax_js_div。这表示目标变量的滞后和 Hmax 的滞后之间的 Jensen-Shannon 散度。第五个最好的特性是 SeaTemp_sdev:标准偏差海水温度滞后。协方差也是不同变量对的相关统计量。</p><p id="ebcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一种去除冗余特征的方法是应用相关滤波器。您删除高度相关的要素以降低数据的维度。</p><h1 id="1724" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">总结整个时间序列</h1><p id="69e1" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">本指南主要关注多变量时间序列的预测问题。因此，特征提取过程适用于一个时间序列的许多子序列。在每个时间步，您用一组统计数据总结了过去 24 小时的数据。</p><p id="ae96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，您也可以一次性应用这些统计数据来描述整个时间序列的特征。如果您的目标是对一组时间序列进行聚类，这可能会很有用。首先，你用特征提取总结每个时间序列。然后，对生成的要素应用聚类算法。</p><h1 id="876a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">关键要点</h1><ul class=""><li id="d360" class="oc od it lb b lc mz lf na li or lm os lq ot lu oh oi oj ok bi translated">多元时间序列预测通常是一个自回归过程</li><li id="82a6" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">特征工程是数据科学项目中的关键步骤。</li><li id="e8c4" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">您可以使用特征工程改进多元时间序列数据集。这包括计算单变量和双变量转换以及汇总统计数据。</li><li id="063f" class="oc od it lb b lc ol lf om li on lm oo lq op lu oh oi oj ok bi translated">提取太多特征会导致高维问题。您可以使用要素选择方法移除不需要的要素。</li></ul><p id="0146" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读，下一个故事再见！</p><h2 id="5bbf" class="mn lw it bd lx mo mp dn mb mq mr dp mf li ms mt mh lm mu mv mj lq mw mx ml my bi translated">参考</h2><p id="f3f2" class="pw-post-body-paragraph kz la it lb b lc mz ju le lf na jx lh li nb lk ll lm nc lo lp lq nd ls lt lu im bi translated">[1]数据来源:<a class="ae ky" href="https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork.html" rel="noopener ugc nofollow" target="_blank">https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork.html</a>。许可证:知识共享署名 4.0(<a class="ae ky" href="https://erddap.marine.ie/erddap/info/IWaveBNetwork/index.html" rel="noopener ugc nofollow" target="_blank">https://erd DAP . marine . ie/erd DAP/info/IWaveBNetwork/index . html</a>)</p><p id="d650" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2]塞尔奎拉、熊伟、努诺·莫尼斯和卡洛斯·苏亚雷斯。"背心:用于预测的自动特征工程."<em class="ob">机器学习</em>(2021):1–23。</p></div></div>    
</body>
</html>