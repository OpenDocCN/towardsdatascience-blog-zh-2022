<html>
<head>
<title>Hadoop vs Spark: Overview and Comparison</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hadoop与Spark:概述和比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hadoop-vs-spark-overview-and-comparison-f62c99d0ee15#2022-03-01">https://towardsdatascience.com/hadoop-vs-spark-overview-and-comparison-f62c99d0ee15#2022-03-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b131" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Spark和Hadoop的总结与比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/866b68441d25fbf426d92ff54df6febc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xaFsHMPIyRTYVo6aeTIsyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Wolfgang Hasselmann 在<a class="ae ky" href="https://unsplash.com/s/photos/elephant?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="849d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Hadoop和Spark都是开源软件的集合，由Apache软件基金会维护，用于大规模数据处理。Hadoop是两者中较老的一个，曾经是处理大数据的首选。然而，自从Spark推出以来，它的增长速度远远超过了Hadoop，后者不再是该领域无可争议的领导者。</p><p id="cf0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着Spark越来越受欢迎，在Spark和Hadoop之间做出选择是现实世界中许多公司面临的问题。不幸的是，这个问题的答案并不简单。两种系统都有优点和缺点，正确的选择将取决于所讨论的用例的复杂性。</p><p id="f475" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本次讨论中，我们将简要介绍Spark和Hadoop，讨论两者之间的主要技术差异，并比较它们的优势和劣势，以确定在哪些情况下应该选择其中之一。</p><h1 id="306b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Hadoop概述</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mn"><img src="../Images/4bea491ab403af14f4e43434cc64f899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1I9JdwrHyDL137pom4S__g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@wolfgang_hasselmann?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Wolfgang Hasselmann </a>在<a class="ae ky" href="https://unsplash.com/s/photos/elephant?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄——由作者编辑</p></figure><p id="e969" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Hadoop允许其用户利用由许多计算机组成的网络，目的是利用它们的综合计算能力来处理涉及大量数据的问题。Hadoop框架有两个主要元素，即分布式存储和处理。分布式存储使用Hadoop分布式文件系统(<strong class="lb iu"> HDFS </strong>)，而处理使用另一个资源协商器(<strong class="lb iu"> YARN </strong>)来调度任务和分配资源，从而实现MapReduce编程模型。</p><p id="2a47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">HDFS的建立有许多目标。首先，由于一个HDFS实例可能包含数千台机器，硬件故障被视为常态而非例外。因此，通过确保快速检测到故障，并且恢复过程平稳且自动，可以对这种故障进行规划。其次，HDFS的设计考虑的是批处理，而不是用户的交互使用。因此，HDFS优先考虑高吞吐量，而不是对数据的低延迟访问，从而实现对数据的流式访问。第三，HDFS确保包含巨大数据集(例如许多TB)的用例被容纳。最后，HDFS的另一个优势是易用性，这源于它与许多操作系统的兼容性以及跨硬件平台的可移植性。</p><p id="99a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Hadoop最初发布时没有YARN，仅仅依赖于MapReduce框架。YARN的加入意味着Hadoops的潜在用例扩展到了MapReduce之外。YARN的关键添加是将集群资源管理和调度从MapReduce的数据处理组件中分离出来。这导致Hadoop集群比MapReduce更严格的方法更好地分配资源(在内存和CPU负载方面)。YARN在HDFS和运行应用的处理引擎(如Spark)之间提供了更高效的链接，使Hadoop能够运行更广泛的应用，如流数据和交互式查询。</p><p id="65eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Hadoop的真正基础是<strong class="lb iu"> MapReduce </strong>，它的关键特征是批处理、对数据传递没有限制、没有时间或内存限制。有许多想法可以实现这些特性并定义Hadoop MapReduce。首先，设计是这样的，硬件故障是预料之中的，并且将被快速处理，不会丢失或损坏数据。第二，优先考虑横向扩展而不是纵向扩展，这意味着增加更多的商用机器比减少高端机器更可取。因此，Hadoop中的可伸缩性相对便宜且无缝。此外，Hadoop按顺序处理数据，避免了随机访问，还提高了数据位置意识。这些属性确保处理速度提高几个数量级，并尽可能避免移动大量数据的昂贵过程。</p><h1 id="b668" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Spark概述</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/e0c7985963e1816d6273f224f180e023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zaSSCvvfqhCELRTWIn931Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@cristian1?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">克里斯蒂安·埃斯科瓦尔</a>在<a class="ae ky" href="https://unsplash.com/s/photos/sparks?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="e59f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Hadoop的简单MapReduce编程模型很有吸引力，并在行业中得到广泛应用，但是，某些任务的性能仍然不是最佳的。这导致了Spark的出现，Spark的引入是为了提供对Hadoop的加速。需要注意的是，Spark不依赖于Hadoop，但可以利用它。在比较和对比这两种技术之前，我们将简要介绍一下Spark。</p><p id="bb9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Spark是一个用于大数据集的数据处理引擎，也是开源的，由Apache基金会维护。称为弹性分布式数据集(RDDs)的抽象概念的引入是Spark在某些任务上超越Hadoop并获得巨大加速的基础。</p><p id="662e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">rdd是容错的元素集合，通过分布在集群中的多个节点上，可以并行处理这些元素。Spark速度的关键在于，在RDD上执行的任何操作都是在内存中完成的，而不是在磁盘上。Spark允许对rdd进行两种类型的操作，即转换和操作。动作用于应用计算并获得结果，而变换导致新RDD的创建。这些操作的分配由Spark完成，不需要用户的指导。</p><p id="df22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">通过使用有向无环图(DAG)来管理在RDD上执行的操作。在Spark DAG中，每个RDD被表示为一个节点，而操作形成边。RDDs的容错特性来自于这样一个事实，即RDD的一部分丢失了，那么可以通过使用存储在图中的操作谱系从原始数据集中重新计算它。</p><h1 id="3ae4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">Spark和Hadoop的主要技术差异和选择</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/d93e80fd163f6613298d2a2e8d3e4b58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jEczFgfDZhqW0Utb1JtZCg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="c2eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，Spark为某些任务带来了巨大的加速。这种情况的主要技术原因是由于Spark在RAM(随机存取存储器)中处理数据，而Hadoop在磁盘上向HDFS读写文件(我们在这里注意到Spark可以使用HDFS作为数据源，但仍然会在RAM中处理数据，而不是像Hadoop那样在磁盘上处理数据)。RAM比磁盘快得多有两个原因。首先，RAM使用固态技术来存储信息，而磁盘通过磁性来存储。其次，RAM比存储在磁盘上的信息更接近CPU，并且具有更快的连接，因此RAM中的数据被更快地访问。</p><p id="ed34" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种技术上的差异导致应用程序的速度提高了许多个数量级，在这些应用程序中，同一个数据集被多次重用。Hadoop导致这些任务的显著延迟(等待时间),因为每次查询都需要单独的MapReduce作业，这涉及到每次从磁盘重新加载数据。然而，使用Spark，数据保留在RAM中，因此从那里而不是从磁盘读取。这导致在我们多次重用相同数据的某些情况下，Spark的速度比Hadoop快100倍。因此，在这种情况下，我会选择Spark而不是Hadoop。这种情况的常见例子是迭代作业和交互式分析。</p><p id="4a97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">重复使用相同数据集的迭代任务的一个具体且非常常见的示例是机器学习(ML)模型的训练。ML模型通常通过迭代地经过相同的训练数据集来训练，以便通过使用诸如梯度下降的优化算法来尝试并达到误差函数的全局最小值。数据被查询的次数越多，Spark在此类任务中实现的性能提升水平就越显著。例如，如果您在Hadoop和Spark上仅使用一次数据传递(epoch)来训练ML模型，将不会有明显的加速，因为Spark上的第一次迭代需要将数据从磁盘加载到RAM中。然而，Spark上的每个后续迭代将在一小部分时间内运行，而每个后续Hadoop迭代将花费与第一次迭代相同的时间，因为每次都从磁盘检索数据。因此，在处理ML应用程序时，Spark通常优于Hadoop。</p><p id="3589" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管在许多应用程序中这是一个巨大的优势，但值得注意的是，在有些情况下，内存中的Spark计算并不尽如人意。例如，如果我们处理的数据集非常大，超过了可用的RAM，那么Hadoop就是首选。此外，同样由于内存和磁盘的差异，与Spark相比，Hadoop的扩展相对容易且便宜。因此，尽管Spark可能最适合时间有限的企业，但Hadoop更便宜的设置和可扩展性可能更适合资金有限的企业。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="bf57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你从这些文章中获得了价值，考虑使用下面的链接注册medium！👇</p><div class="mx my gp gr mz na"><a href="https://medium.com/@riandolphin/membership" rel="noopener follow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd iu gy z fp nf fr fs ng fu fw is bi translated">加入我的推荐链接-海豚</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">medium.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no ks na"/></div></div></a></div></div></div>    
</body>
</html>