<html>
<head>
<title>Can You Code a Neural Network Using Only High School Mathematics?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你能只用高中数学编写一个神经网络吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-you-code-a-neural-network-using-only-high-school-mathematics-ac9ad80f52f7#2022-08-22">https://towardsdatascience.com/can-you-code-a-neural-network-using-only-high-school-mathematics-ac9ad80f52f7#2022-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="468f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">回到基础——仅使用NumPy编码神经网络</h2></div><p id="d0ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最近，我在向母亲解释神经网络的概念；我无法超越通常的输入、隐藏层、输出等比喻。我不认为我在这方面做得很好，这让我思考——我自己理解他们吗，还是我只是假装理解他们？</p><p id="21af" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我拿了一张纸，画了几张相连网络的图表，在一个jupyter笔记本上用Keras层对整个网络进行了编码。我用了不到10行代码编写了一个多层网络，并且运行良好。</p><p id="a2a8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然我不满意，但感觉我只是在假装我理解这个概念，如果我继续深入下去，我肯定会犹豫。我已经无数次地阅读了神经网络的工作原理，并且可以肤浅地解释它们是如何工作的，还可以快速得出一些数学公式，但是我真的理解它们以便我可以清晰地向任何人解释吗？这个问题在那天晚上成了众矢之的。我决定回到基本原则，只用高中数学来编码整个自然网络。没有瞎忙活，没有使用PyTorch、TensorFlow或Keras的任何花哨框架。</p><p id="cd80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这应该是可行的！</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/f1f5122ededb4824980695bab35af6b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RSq_8gUNZwx-SRLu"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">埃利斯·陈嘉炜在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="655c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">潜在的想法对我来说很清楚，但我不清楚我将如何从基础开始编码。</p><p id="e96c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，首先，让我们在一张纸上涂鸦，首先是想法，然后把想法转化成数学方程，然后尽可能简洁地把数学编码成程序。</p><p id="8096" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好吧，我已经想出了一个粗略的计划来解决这个问题。</p><h1 id="ce57" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">基本想法</h1><p id="10e3" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我相信你们都曾经见过类似的事情。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ms"><img src="../Images/c295093c4b90f13878dc0293c8995f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*accu4RqM17RInEICQ49K_g.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="9340" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在最简单的神经网络中，有一个输入层、一个隐藏层和一个输出层</p><p id="1124" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果没有隐藏层，这种排列将被称为感知器，类似于弗兰克·罗森布拉特在1943年设计的Mark 1。</p><p id="8738" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用一句话来解释，神经网络背后的思想是，给定一个输入X，我们能否做一些数学计算来正确识别X或将X分类到预定义的类别之一？就像我们的大脑一样。</p><h1 id="a04a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">简单看一下算法</h1><p id="940f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">让我们以一个单层网络为例，输入X1，X2；隐层神经元H1，H2；和输出Y1、Y2。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/94c92211c33ed4aa29ac0169bacbee3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZaWIHayGZxC_h2fnHGpaQw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">图1(作者图片)</p></figure><p id="6b2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mu">您估计权重w1、w2、w3等，计算每个节点的输出，并最终根据Y的真实值测量最终输出Y*。Y和Y*之间的差异是您用来重新调整权重和计算新Y *的误差；继续这样做，直到你得到一个接近Y或者令你满意的Y*值。</em></p><p id="72bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是所发生事情的淡化版本；实际上，还有更多的步骤。一个更复杂的算法:</p><ol class=""><li id="c843" class="mv mw it kk b kl km ko kp kr mx kv my kz mz ld na nb nc nd bi translated">获取输入X</li><li id="6c91" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">估计重量——这是一个完全不知情的过程，人们可以随机初始化重量。</li><li id="4f8e" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">估计偏差项的值。</li><li id="f691" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">前向传递(前馈)—在初始化权重的帮助下，估计每个节点的输出。</li><li id="3ebb" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">计算最终输出(y值)。</li><li id="5d0b" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">找出误差-网络的估计值减去您想要观察的实际值。</li><li id="32f0" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">反向传递(反向传播)—借助计算出的误差，重新调整权重。</li><li id="0c85" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">不断重复步骤3至6，直到达到所需的值。</li></ol><h1 id="c0a7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">从线性到非线性</h1><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/0fb2501c1be1fc4bc365505b4011818c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/1*sf0oFwk7x4qKgjldbSBgLA.gif"/></div></figure><p id="a4bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个回归方程，是输入和不同权重(betas)的线性组合。</p><p id="5129" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于图1，可以看到H1的输出是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/a405c71e9d3982682c682740b6f4564b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/1*swJx_MLP4M0hRqkPn8qB2g.gif"/></div></figure><p id="c1c5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">H2的输出是:x1*w3 + x2*w4 + b1等等。</p><p id="d8d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在任何时候，它都是权重和输入的线性组合。如果我们只在神经网络的不同节点获取输出，它将只不过是一组复杂的线性回归。为了避免这种情况，我们需要引入非线性，这就是激活函数的作用。有许多流行的函数，如sigmoid、tanh、softmax、ReLu等。</p><p id="60f5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在神经网络中引入激活函数有助于:</p><ol class=""><li id="7836" class="mv mw it kk b kl km ko kp kr mx kv my kz mz ld na nb nc nd bi translated">使模型非线性化。</li><li id="4c97" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">模仿大脑中的神经元；当满足某些阈值条件时，大脑中的神经元就会激活；激活函数给神经网络的功能带来了类似的阈值。</li><li id="acc4" class="mv mw it kk b kl ne ko nf kr ng kv nh kz ni ld na nb nc nd bi translated">在0和1之间映射输出。</li></ol><p id="0b1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们应用激活函数，例如sigmoid，节点处的输出将是:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nk"><img src="../Images/88693a21f168e31222a3e9d6335d526b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*UuULfihtwr4jw_zERsS6jA.gif"/></div></div></figure><p id="fb69" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦计算了所有节点的所有这些值，网络将估计最终输出，并计算期望值和观察值之间的误差。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nl"><img src="../Images/54aaee8be65a4378f65966ca607493ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HWPHGU7pcibULKkwZ_jHXQ.png"/></div></div></figure><h1 id="32fe" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数据</h1><p id="6cb0" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">数据集:MNIST手写数字。</p><p id="2cbd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来源:http://yann.lecun.com/exdb/mnist/<a class="ae lu" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"/></p><p id="c523" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">http://www.pymvpa.org/datadb/mnist.html MNIST手写数据集的许可——知识共享许可<a class="ae lu" href="http://www.pymvpa.org/datadb/mnist.html" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="f0c0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">正向传播</h1><p id="00f4" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">有42，000张图像，每张图像的尺寸为28 x 28 = 784像素，需要将它们分为10类——0、1、2、3、……9。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nm"><img src="../Images/64c3597b19147b3da9e6f8a8627a276b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*twS3nOo6sobKg_l-86LXeQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="125f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">各层的大小很重要，需要预先计算。</p><h2 id="ac4a" class="nn lw it bd lx no np dn mb nq nr dp mf kr ns nt mh kv nu nv mj kz nw nx ml ny bi translated">转化为数学</h2><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi nz"><img src="../Images/b1f905e2b9e415aa6613d71cd3122311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQuymuz094S5SHW9t4Kmmg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">方程组1(图片由作者提供)</p></figure><p id="d7a3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">网络的第一层是输入层X，向其添加权重和偏差的线性组合，以获得线性输出z。</p><p id="74c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在激活函数的帮助下，第一层的输出Z是非线性的，这里使用ReLU。</p><p id="b764" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">ReLU的非线性输出被馈送到网络的第二隐藏层，在第二隐藏层中添加了softmax非线性，并且最终产生输出A2。</p><p id="ae0d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Softmax会将输出向量转换为概率向量。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oa"><img src="../Images/0a22b26ce989ed18525a047c650c3080.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftAQPoXRs7a1uLqsyeMg7g.png"/></div></div></figure><p id="73e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mu">一个旁注，在</em><a class="ae lu" href="https://latexeditor.lagrida.com/" rel="noopener ugc nofollow" target="_blank"><em class="mu">【https://latexeditor.lagrida.com/】</em></a>上写乳胶很容易</p><h1 id="248c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">反向传播</h1><p id="7a90" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">到目前为止，我们一直在前进。</p><p id="cc2e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦我们得到了输出，我们将测量误差并进行反向传播。</p><h2 id="5662" class="nn lw it bd lx no np dn mb nq nr dp mf kr ns nt mh kv nu nv mj kz nw nx ml ny bi translated">为什么要反向传播？</h2><p id="e824" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">最初随机选择的权重在反向传播期间被调整。权重决定了特征的重要性:权重的数值越高，特征就越重要。</p><p id="ad04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最初，我们并不真正知道分配什么权重，所以我们从随机权重开始，但反向传播作为一种校准机制，有助于更新权重，并使网络和整个系统达到平衡。</p><p id="1183" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">计算以下偏导数，它们有助于确定Z、b或W等特征的微小变化如何影响误差函数。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ob"><img src="../Images/b7b57cf7da8e72958761f547b4e119db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k3D2MZWNnzKn5wt39dEcsQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="be1b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上是为了计算权重和偏差的误差，从而更新它们。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi oc"><img src="../Images/07d13dc6a1370da6de722df5bd2a2eee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqhrOBHPyo3GgaRIV31iUg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">方程组3(图片由作者提供)</p></figure><p id="52be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这看起来像是一大堆数学。简而言之，我们将使用以下等式更新权重和偏差:</p><p id="e210" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mu">新权重=旧权重—学习率*总误差相对于该权重的偏导数</em></p><p id="4176" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，在图1中，如果我们想要更新权重5，那么</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi od"><img src="../Images/d1274125de0f104ed3b4643a15d40196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GG5Mrbhww7bJucWOE-jZeA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">方程组4(图片由作者提供)</p></figure><blockquote class="oe"><p id="2e3f" class="of og it bd oh oi oj ok ol om on ld dk translated">我们知道总误差，我们只需要对误差函数进行w5的部分微分，但是因为误差函数中没有任何w5项，我们将使用<strong class="ak">导数链规则</strong>来找到各个偏导数，并将它们相乘以获得相关值(正如我们在上面的方程组4中所做的)</p></blockquote><p id="962d" class="pw-post-body-paragraph ki kj it kk b kl oo ju kn ko op jx kq kr oq kt ku kv or kx ky kz os lb lc ld im bi translated">观看<a class="ae lu" href="https://www.youtube.com/watch?v=tIeHLnjs5U8" rel="noopener ugc nofollow" target="_blank"> 3B1B视频</a>更多了解反向传播微积分如何工作。</p><h1 id="9397" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">数学够了，我们来编码吧！</h1><p id="4dc5" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">从回购中读取数据后，让我们将其分为训练集和测试集</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="5b3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个非常重要的步骤是使训练和测试集正常化，否则训练将会很慢或者根本无效。</p><pre class="lf lg lh li gt ov ow ox oy aw oz bi"><span id="7814" class="nn lw it ow b gy pa pb l pc pd">X_train = X_train/255.<br/>X_test = X_test/255.</span></pre><p id="8c95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据上面的方程组1，让我们初始化参数并为正向传递定义一个函数</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="5692" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">至此，已经定义了正向传递的一次迭代，让我们定义反向传播的方法，并根据方程组2和3更新参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="cb3d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们定义一个梯度下降方法，该方法将调用其中的向前传递和向后传递方法，并最终更新参数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="88e4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一次运行达到了88%的准确率</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi pe"><img src="../Images/8c2e7a9ff95b2900746f2a3131dbeeec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-tqeaAN-P_xzxH1JUhvEg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">各种迭代的准确性</p></figure><p id="8388" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在测试集上使用训练过的学习者显示了一些错误的分类，但大部分是正确的。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/09f9534374c5b764db47ba3f5f95da86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*TPUV8wu8YVVQPv71GGSosA.png"/></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">输出</p></figure><p id="f6df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在PyTorch、Keras或TensorFlow的帮助下，通过一些调整可以达到95%的精度，而在这里，通过基本的数学知识，我们可以达到88%。没那么糟糕！</p><p id="0ea9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更重要的是，我们能够计算出正向传播和反向传播数学，正确地将它们编码，并将其应用于真实世界的示例数据集。</p><p id="fa35" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码库在我的<a class="ae lu" href="https://github.com/Prashantmdgl9/NN_scratch" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>上。</p><p id="a7a5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你知道一些更简单的反向传播方法(或更直接的解释)，那么请留言或联系。</p></div></div>    
</body>
</html>