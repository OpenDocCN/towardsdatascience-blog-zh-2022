<html>
<head>
<title>Natural Language Inference: An Overview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言推理综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-inference-an-overview-57c0eecf6517#2022-06-09">https://towardsdatascience.com/natural-language-inference-an-overview-57c0eecf6517#2022-06-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a54f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基准和模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a75ce66e26ff0d6863cad478516ea0db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_kDohpQgN7Qw24g1Dgdsw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">瓦伦丁·维萨摄于Pexels</p></figure><h1 id="9eb9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">什么和为什么？</h1><p id="4e2d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">自然语言推理(NLI)的任务是确定是否给定的“假设”逻辑上遵循“前提”。通俗地说，你需要了解假设是否成立，而前提是你对该学科的唯一了解。</p><p id="6a32" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">你为什么要读这个？</strong>我假设你对NLI一无所知，并承诺让你了解该领域的最新发展(2022年4月)。对于一篇文章来说，这是一个相当大胆的承诺，不是吗？</p><h1 id="7487" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">问题陈述</h1><blockquote class="mp mq mr"><p id="161b" class="lo lp ms lq b lr mk jr lt lu ml ju lw mt mm lz ma mu mn md me mv mo mh mi mj ij bi translated"><a class="ae kv" href="https://affine.ai/natural-language-inferencing-nli-task-demonstration-using-kaggle-dataset/" rel="noopener ugc nofollow" target="_blank">自然语言推理</a>也被称为识别文本蕴涵(RTE ),是确定给定的“假设”和“前提”在逻辑上是否相互遵循(蕴涵)或不遵循(矛盾)或不确定(中性)的任务。</p></blockquote><p id="6c85" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你可以认为NLI根据前提将假设分为三类:蕴涵，矛盾，或中性。还有一个相关的问题:事实核查。事实核查问题与NLI非常相似。唯一不同的是，你没有前提。因此，事实核查包括两个问题:搜索问题和NLI。在这篇文章中，我将集中讨论NLI问题。</p><h1 id="00e8" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">基准</h1><p id="f39a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">当开始一个新游戏时，第一步是学习游戏规则。在机器学习中，基准是研究人员遵循的事实规则。</p><h2 id="67fb" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">SNLI</h2><ul class=""><li id="e3ca" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://nlp.stanford.edu/projects/snli/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="8ea4" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://nlp.stanford.edu/pubs/snli_paper.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="e05b" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/sota/natural-language-inference-on-snli" rel="noopener ugc nofollow" target="_blank">基准</a></li><li id="cbc0" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:570k</li><li id="9493" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:句子。</li><li id="037d" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:蕴涵，中立，矛盾。</li></ul><p id="49db" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是NLI标杆管理的经典之作，所以这个标杆被广泛使用，被尊重，坦白地说，已经过时了。<br/>SNLI数据集基于来自Flickr30k语料库的图像标题，其中图像标题被用作前提。该假设由土耳其机械工人按照以下说明手动创建:</p><ol class=""><li id="6890" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">蕴涵:写一个替代的标题，这个标题绝对是对照片的准确描述；</li><li id="2a9f" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">中性:写一个可能是照片的准确描述的备选标题；</li><li id="0bfe" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">矛盾:写一个替代说明，这是对照片的错误描述。</li></ol><p id="d7a6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">SNLI有两个明显的缺点:</p><ul class=""><li id="3214" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nn no np nq bi translated">前提是限于简短的照片描述，因此不包含时间推理，信仰，或模态。</li><li id="2116" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">简单而简短的前提要求简单而简短的假设，因此在模型可以轻松达到人类准确性水平的情况下，基准测试不够具有挑战性。</li></ul><h2 id="05ca" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">MultiNLI</h2><ul class=""><li id="de20" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="e112" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://cims.nyu.edu/~sbowman/multinli/paper.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="3745" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/sota/natural-language-inference-on-multinli" rel="noopener ugc nofollow" target="_blank">基准</a></li><li id="e40e" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:433k</li><li id="a8bf" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:句子</li><li id="1638" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:蕴涵，中立，矛盾。</li></ul><p id="ae43" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">MultiNLI (MNLI)模仿SNLI数据集模式，但涵盖了一系列口语和书面语文本。因此，MNLI可以与SNLI结合使用，并提供十种不同风格的文本。</p><p id="b7b4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">MNLI的前提来源于十个来源或体裁(基于开放的美国国家语料库):</p><ol class=""><li id="8ef3" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">面对面:两人对话的夏洛特叙事和对话集的转录；</li><li id="63cd" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">政府:来自公共领域政府网站的报告、演讲、信件和新闻稿；</li><li id="6e12" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">信件:来自印第安纳跨文化交流中心<br/>慈善募捐演讲的信件；</li><li id="cca2" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">9/11:美国国家恐怖袭击委员会的公开报告；</li><li id="6869" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">OUP:由牛津大学出版社出版的关于纺织业和儿童发展的五部非虚构作品；</li><li id="9869" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">石板:来自石板杂志档案的流行文化文章；</li><li id="a48c" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">电话:从宾夕法尼亚大学语言数据联盟总机语料库中转录的双方电话对话；</li><li id="806b" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">旅行:Berlitz出版社出版的旅行指南；</li><li id="820d" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">逐字记录:逐字记录档案中为非专业人员提供的关于语言学的帖子；</li><li id="62c9" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">小说:几部1912年至2010年间创作的免费当代小说作品。</li></ol><p id="d534" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">假设创建过程如下:向一名众包工作人员展示前提，并要求他写出三个新句子:</p><ol class=""><li id="531d" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">蕴涵:前提为真时必然为真或适当的事物；</li><li id="5e55" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">矛盾:前提为真时必然为假或不恰当的矛盾；</li><li id="26f6" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">中立:两种情况都不适用。</li></ol><p id="ca4d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">该数据集的一个重要特征是，十个流派中只有五个出现在训练集中，使得其他五个流派对于模型来说是不可见的。这些看不见的体裁可以用来评估模型对看不见的文本来源的概括程度。</p><h2 id="26dd" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">超强力胶水</h2><ul class=""><li id="0029" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://super.gluebenchmark.com/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="c99f" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://arxiv.org/abs/1905.00537" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="abe7" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/sota/natural-language-inference-on-rte" rel="noopener ugc nofollow" target="_blank">基准</a></li><li id="1090" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">基准</li><li id="fa69" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:RTE: 3k，CB: &lt;1k</li><li id="ef57" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:句子</li><li id="6508" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:RTE:蕴涵，not _蕴涵；CB:包含，不确定，未知</li></ul><p id="9f7b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">SuperGLUE是衡量NLP模型在三个任务中的性能的十个基准的集合:</p><ol class=""><li id="e030" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">自然语言推理</li><li id="a3f5" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">问题回答</li><li id="7291" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">共指消解</li></ol><p id="9e1a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">基于在这些任务中的表现，SuperGLUE旨在提供一个单一的分数，该分数概括了模型在自然语言理解方面的能力。SuperGLUE是一个非常流行的GLUE基准的扩展，具有更复杂的任务。</p><p id="e970" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">强力胶有两个NLI基准:RTE和CB。</p><p id="c422" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">RTE，即识别文本蕴涵，来自于每年的文本蕴涵比赛。RTE包含RTE1、RTE2、RTE3和RTE5数据集。数据本身来自维基百科和新闻文章。RTE的一个显著特点是标注的是二类分类而不是三类分类，所以没有中性标签。</p><p id="6282" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">CB，或CommitmentBank，是一个短文本的语料库，其中至少有一个句子包含嵌入子句。每一个嵌入的条款都有注释，说明撰写该文本的人对该条款真实性的承诺程度。由此产生的任务是从华尔街日报、英国国家语料库的小说和Switchboard中抽取的例子的三类文本蕴涵。每个例子由一个包含嵌入子句的前提组成，相应的假设是该子句的提取。</p><h2 id="b5df" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">发热</h2><ul class=""><li id="ca4f" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://aclanthology.org/W18-5501/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="74e2" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://aclanthology.org/W18-5501v3.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="1835" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/sota/fact-verification-on-fever" rel="noopener ugc nofollow" target="_blank">基准</a></li><li id="15a6" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:185k</li><li id="cdb5" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:维基百科网址+句子编号</li><li id="75db" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:支持、反驳、NotEnoughInfo</li></ul><p id="e52c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">注意:这个数据集称假设为“主张”。</p><p id="9846" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这个数据集不同于SNLI和MNLI，因为它支持NLI和事实检查问题。数据集提供的不是前提，而是维基百科页面的URL，可以从中提取前提。该数据集还提供了页面上的前提句数量，以支持纯NLI用例。</p><p id="24e3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些声明是人工生成的，根据维基百科页面的介绍部分进行人工验证，并标记为支持、反驳或无信息。</p><p id="dc0f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些说法是通过转述维基百科的事实，并以各种方式对其进行变异而产生的，其中一些方式是改变意思。对于每一个主张，在不知道该主张是从哪里产生的情况下，注释者从维基百科中选择句子形式的证据来证明该主张的标注。</p><p id="3772" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">数据集的一个警告是，它没有为NotEnoughInfo标签提供前提的维基百科URL。因此，如果您想将数据集用于NLI用例，您将需要自己搜索前提。</p><h2 id="e235" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">维基-事实核查</h2><ul class=""><li id="7201" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://aclanthology.org/2020.lrec-1.849/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="bfe6" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://aclanthology.org/2020.lrec-1.849.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="6bfb" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">基准:在有代码的论文上没有基准</li><li id="f861" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:160k</li><li id="735f" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:证据文档</li><li id="d572" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:蕴涵、矛盾、中性</li></ul><p id="e8df" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">与SNLI、MNLI和FEVER不同，该数据集由从维基百科引文中提取的真实说法组成。这些前提或证据文件是索赔中引用的文件。此外，数据集为每个索赔提供了上下文，这在不明确的情况下会有所帮助。对真实世界主张的强调确实给NLI提出了一个更具挑战性的任务。</p><p id="9d8f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这个数据集的缺点是质量:主张和前提是从维基百科自动提取的，有时毫无意义。</p><h2 id="af10" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">安利</h2><ul class=""><li id="2ba9" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://ai.facebook.com/research/publications/adversarial-nli-a-new-benchmark-for-natural-language-understanding/" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="f9b0" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://scontent.fdnk6-1.fna.fbcdn.net/v/t39.8562-6/106008535_712002762933999_6704813911278641056_n.pdf?_nc_cat=100&amp;ccb=1-5&amp;_nc_sid=ae5e01&amp;_nc_ohc=g5vmzERZnDYAX_iPF8n&amp;_nc_ht=scontent.fdnk6-1.fna&amp;oh=00_AT_4-DztcLXRjMoKxV18bJ14vWfbQdPeWmU7tNkmky22AA&amp;oe=6200E66E" rel="noopener ugc nofollow" target="_blank">论文</a></li><li id="c286" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/sota/natural-language-inference-on-anli-test" rel="noopener ugc nofollow" target="_blank">基准测试</a></li><li id="4412" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">示例:第1轮— 19k，第2轮— 47k，第3轮— 103k</li><li id="dd22" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">前提类型:句子</li><li id="0d7b" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">标签:蕴涵、矛盾、中性</li></ul><p id="8c12" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><em class="ms">安立是迄今为止最先进的NLI基准</em>。ANLI的收集过程与其他数据集非常不同，因为它采用了一种称为“人与模型在回路中的蕴涵训练”(HAMLET)的技术。</p><p id="44dd" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">HAMLET将数据收集过程分成几轮，每轮包括以下步骤:</p><ol class=""><li id="94db" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">训练一个SOTA模型。</li><li id="4e58" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">人类注释者被给予上下文(前提)和期望的目标标签，并被要求生成<strong class="lq ir">一个假设，该假设将欺骗模型对标签进行错误分类</strong>。</li><li id="e86d" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">如果模型对示例进行了错误分类，则该示例将被展示给两个人类验证者以确保它是正确的。如果他们不同意，第三个人验证打破平局。</li><li id="4329" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">该示例被添加到这一轮的训练集中，并将用于为下一轮训练模型。</li></ol><p id="55f5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">每一轮，模型和数据集的复杂性都在增加:</p><ol class=""><li id="3286" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">第一轮。型号:BERT-大号。数据集:SNLI + MNLI。上下文:维基百科+ HotpotQA。</li><li id="e1b7" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">第二轮。模特:罗伯塔模特的集合。数据集:SNLI+ MNLI +发烧+第1轮数据。上下文:新的来自维基百科+ HotpotQA。</li><li id="2857" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">第三轮。模特:罗伯塔模特的集合。数据集:SNLI + MNLI +发烧+第一轮数据+第二轮数据。上下文:各种来源，包括口语文本和更长的上下文。</li></ol><p id="b26c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在每一轮中，使用的NLI模型更强，背景更长，更难理解。因此，对手注释者必须在每一轮都拿出更多的例子，才能设法欺骗模型。例如，在第一轮中，注释者在模型被愚弄之前平均做了3.4次尝试，而在第三轮中，他们平均需要6.4次尝试。</p><p id="50f2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">ANLI数据集被设计为比其他数据集更难收集，并提供更长的真实环境。此外，ANLI通过增加新的回合提供了一种扩展机制，以便基准可以与SOTA模型一起发展。</p><h1 id="2279" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">SOTA模型</h1><p id="1a52" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是你们期待已久的部分——模特！不出所料，源自BERT的架构在列表中名列前茅。</p><h2 id="39e1" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">德伯塔</h2><ul class=""><li id="8a0d" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/paper/deberta-decoding-enhanced-bert-with" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="f510" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://arxiv.org/pdf/2006.03654v6.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li></ul><p id="90eb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是一个基于Transformer的架构，也是目前大多数强力胶任务上的SOTA模型:NLI (RTE，CommitmentBank)，常识推理(ReCoRD)，问题回答(COPA，MultiRC)。</p><p id="a5cb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">德伯塔:</p><ol class=""><li id="ae24" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">引入分散注意力机制，其中每个单词使用两个向量来表示，这两个向量对单词的内容和位置进行编码。单词间的注意力权重是使用关于单词内容和相对位置的解纠缠矩阵来计算的。</li><li id="4453" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">使用增强的屏蔽解码器将绝对位置结合到解码层中，以在模型预训练中预测屏蔽的记号。</li><li id="f9db" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">采用一种新的虚拟对抗训练方法进行微调，以提高模型的泛化能力。</li></ol><h2 id="9ca2" class="mw kx iq bd ky mx my dn lc mz na dp lg lx nb nc li mb nd ne lk mf nf ng lm nh bi translated">罗伯塔</h2><ul class=""><li id="5262" class="ni nj iq lq b lr ls lu lv lx nk mb nl mf nm mj nn no np nq bi translated"><a class="ae kv" href="https://paperswithcode.com/paper/roberta-a-robustly-optimized-bert-pretraining" rel="noopener ugc nofollow" target="_blank">网站</a></li><li id="2486" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated"><a class="ae kv" href="https://arxiv.org/pdf/1907.11692v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></li></ul><p id="cd0d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是一个基于变压器的架构。有趣的是，它只是调整了BERT训练过程的几个超参数，并实现了一个新的SOTA模型，击败了许多BERT修改。这项工作对BERT之后发布的模型所展示的性能改进的来源提出了质疑。</p><p id="9664" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">罗伯塔:</p><ol class=""><li id="a6ae" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">用更多数据的更大批量来训练模型更长时间</li><li id="4136" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">移除下一句预测目标</li><li id="a6d2" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">较长序列的训练</li><li id="871f" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">动态改变应用于训练数据的掩蔽模式</li></ol><h1 id="1a71" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">和德伯塔一起玩</h1><p id="6c97" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我决定在MNLI数据集上重现DeBERTa结果。由于计算限制，选择了DeBERTa基础模型。MNLI有两部分测试数据集:匹配和不匹配的流派。简而言之，匹配的流派出现在列车分裂，而不匹配的流派没有。根据DeBERTa的论文，DeBERTa基本模型应该在匹配的MNLI-m测试数据集上产生88.8%的准确度，在不匹配的MNLI-mm测试数据集上产生88.5%的准确度:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/19baa40d5eb0b4f6a9d5f7f0042c5f0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FPuKifnJB9fW7C2KufoRGw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">罗伯塔和德贝塔的表现比较。</p></figure><p id="60e2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">获得DeBERTa预训练权重的最简单方法是使用HuggingFace库。我用过微软的基于deberta的型号(T1 ),但也有更新的基于T2的型号(T3)。为了使用这些预先训练好的权重，你需要使用<a class="ae kv" href="https://www.sbert.net/examples/applications/cross-encoder/README.html" rel="noopener ugc nofollow" target="_blank">来自句子转换库</a>的CrossEncoder类来加载它们。</p><p id="a65a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" href="https://huggingface.co/datasets/multi_nli" rel="noopener ugc nofollow" target="_blank"> MNLI数据集可从HuggingFace数据集库</a>获得，我们应该对MNLI-m使用<em class="ms"> validation_matched </em>拆分，对MNLI-mm使用<em class="ms"> validation_mismatched </em>拆分。</p><p id="fc75" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">在MNLI上再现DeBERTa性能时，有两个注意事项</strong>:</p><ol class=""><li id="704b" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nz no np nq bi translated">首先，数据集和训练模型中的标签编码不同。这就是为什么如果你马上在MNLI-m上给模型打分，你只会得到31%左右的准确率。</li><li id="560d" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nz no np nq bi translated">第二，训练好的模型对句序比较敏感:前提先行，假设次之。</li></ol><p id="1548" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">数据集的标签编码:</p><ul class=""><li id="6f5a" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nn no np nq bi translated">0 —蕴涵</li><li id="8680" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">1-中性</li><li id="260f" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">2 —矛盾</li></ul><p id="74fc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">已训练模型的标签编码:</p><ul class=""><li id="076d" class="ni nj iq lq b lr mk lu ml lx nw mb nx mf ny mj nn no np nq bi translated">0 —矛盾</li><li id="74d0" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">1-蕴涵</li><li id="1ed7" class="ni nj iq lq b lr nr lu ns lx nt mb nu mf nv mj nn no np nq bi translated">2-中性</li></ul><p id="6787" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当应用上述修复时，该模型在MNLI-m数据集上产生了<strong class="lq ir"> 88.29%的准确度</strong>分数。我认为其原因是<strong class="lq ir">来自HuggingFace的deberta-base权重根本没有在MNLI数据集上训练过</strong>。这也解释了为什么在我的测试中，匹配和不匹配的体裁之间的差异如此之小:88.29%匹配和88.11%不匹配，而论文报告的匹配和不匹配比例分别为88.8%和88.5%。该模型应该在匹配的流派上进行训练，并在这些流派上表现得更好。然而，该模型没有在任何流派上进行训练，因此它以相同的方式在匹配和不匹配的情况下执行，并且在这两种情况下，性能都比论文中报道的差。</p><p id="aafb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">让我们来看看重现结果的工作流程。我假设实验是在配有GPU的Colab笔记本上运行的。</p><p id="8fae" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">首先，我们需要安装所需的软件包:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="8282" class="mw kx iq oc b gy og oh l oi oj">!pip install transformers sentence-transformers datasets sentencepiece</span></pre><p id="c479" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来，我们加载数据集:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/a8e48d88ba7c7d466d1967b538afc25d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6e1cZxteJfhUz0_YW8VKgQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用HuggingFace数据集库加载MNLI数据集</p></figure><p id="5e72" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">请记住，模型和数据集中的标签编码是不兼容的，我们需要定义一个映射函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/589c0b07a76dffa002f0b5af569ecbfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*Id6VYgXweu5w0w4fC_7eYg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">定义一个将模型标签转换为数据集标签的函数</p></figure><p id="553c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">并使用CrossEncoder加载模型:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/90c7098eef5449c53a9138ae47296a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5N1DNb3fN1rMMS39EOIAcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用sentence_transformers库加载预训练的模型权重</p></figure><p id="82ef" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">最后，我们可以在<em class="ms"> validation_matched </em> split上对模型进行评分，以实现88.29%的匹配流派:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/04d4598ee4785e7e4e0fb262603ab699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IUD9W-n_MpYJ0BO-d1Q7Aw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在validation_matched上对模型评分</p></figure><p id="4517" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">并在<em class="ms">validation _ mismatched</em>split上对模型进行评分，在不匹配流派上达到88.11%；</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/dfb8611f3778fefabdfcfcb40ad5229c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s7T5NR4pGf1fsQ4-my_YMA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对模型进行评分验证_不匹配</p></figure><p id="dd69" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你可以在这里找到<a class="ae kv" href="https://colab.research.google.com/drive/1317xbFEPrQkFT7m_uMjwDOqynAXAbZ3o?usp=sharing" rel="noopener ugc nofollow" target="_blank">一个完整的Colab笔记本</a>。</p><h1 id="9d65" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="9ce5" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们回顾了NLI最常用的数据集和模型。我们还在MNLI上复制了DeBERTa base的结果。</p><p id="0243" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果你需要快速解决一个NLI任务，使用德伯塔模型。这是SOTA，可以通过HuggingFace获得。如果你需要一个基准，我更喜欢使用ANLI或MNLI。</p><p id="9aef" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这几天我特别喜欢ML的一点就是变形金刚无处不在。因此，我们审查的模型也适用于NLI以外的许多应用任务。反过来也可以——许多基于transformer的模型在NLI任务上进行了基准测试，以显示与以前的架构相比的性能提升。</p><p id="15f6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">自然语言推理是一项重要的任务，它使我们开发出能够实际理解句子之间依赖关系的模型。到目前为止，我们已经介绍了太多关于NLI的内容，但是您已经有足够的基础来探索其他模型并理解基准之间的差异。</p><p id="0620" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">祝你在ML的道路上好运，记得和社区分享你的旅程！</p></div></div>    
</body>
</html>