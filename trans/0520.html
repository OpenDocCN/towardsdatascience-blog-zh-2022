<html>
<head>
<title>Forward and Backward propagation of Max Pooling Layer in Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络中最大池层数的前向和后向传播</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/forward-and-backward-propagation-of-pooling-layers-in-convolutional-neural-networks-11e36d169bec#2022-02-21">https://towardsdatascience.com/forward-and-backward-propagation-of-pooling-layers-in-convolutional-neural-networks-11e36d169bec#2022-02-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e505" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">理论与代码</h2></div><h2 id="034b" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h2><p id="bb39" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">在上一篇文章中，我们看到了如何在CNN中进行卷积运算的前向和后向传播。发现在卷积层之后应用汇集层提高了性能，有助于网络更好地概括并减少过拟合。这是因为，给定一个特定的网格(池高x池宽),我们只从中采样一个值，忽略特定的元素并抑制噪声。此外，因为池化减少了来自前一层的特征图的空间维度，并且它不添加任何要学习的参数，所以它有助于降低模型复杂性、计算成本并导致更快的训练。</p><h2 id="f951" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">正向传播</h2><p id="e115" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们假设在卷积运算之后，我们得到形状为<strong class="ld ir"> 4x4的输出。</strong>然后我们要做最大汇集，使<strong class="ld ir">汇集高度</strong>、<strong class="ld ir">汇集宽度</strong>和<strong class="ld ir">步幅</strong>都等于<strong class="ld ir"> 2。</strong>池化类似于卷积，但不是在权重和输入中的区域之间进行元素级乘法，然后对它们求和以获得输出矩阵中某个单元的元素，而是简单地从该区域中选择最大元素。以下可视化将阐明:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/171c2ec62fd2db13431d5361e471ba08.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/1*9kMkohwhU2SvtbMtc4vr_Q.gif"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像-正向传播</p></figure><p id="f4d2" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">池化操作后的<strong class="ld ir">输出形状</strong>使用以下公式获得:<br/><em class="mm">H _ out = floor(1+(H-pool _ height)/stride)<br/>W _ out = floor(1+(W-pool _ width)/stride)</em><br/>其中<em class="mm"> H </em>是输入的高度，<em class="mm"> pool_height </em>是池化区域的高度<br/> <em class="mm"> W </em>是输入的宽度，<em class="mm"/></p><p id="6668" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">在我们的例子中我们得到:<br/><em class="mm">H _ out</em>= floor(1+(4–2)/2)= 2<br/><em class="mm">W _ out</em>= floor(1+(4–2)/2)= 2</p><p id="0a7d" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">这是它在代码中的实现方式:</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="mn mo l"/></div></figure><h2 id="d673" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">反向传播</h2><p id="e7fd" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">与卷积运算不同，我们不必在这里计算权重和偏差导数，因为合并运算中没有参数。因此，我们需要计算的唯一导数是关于输入的，<strong class="ld ir">∂<em class="mm">y/</em></strong><em class="mm"/><strong class="ld ir">∂<em class="mm"><br/></em></strong>我们知道，关于输入的导数将具有与输入相同的形状。再来看第一个元素<strong class="ld ir">∂<em class="mm">y/</em></strong><em class="mm"/><strong class="ld ir">∂<em class="mm">x—</em></strong>∂<em class="mm">y/</em>∂<em class="mm">x</em>₁₁.</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/f9b0d8f9403ff31082952e8b7d93c388.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*wzrnpOCydh7QcMIF_ZaO3w.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像-汇集第一个元素</p></figure><p id="5ce4" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">很明显，只有当<em class="mm"> x </em> ₁₁是关于第一区域的第一汇集操作中的最大元素时，∂<em class="mm">y/</em>∂<em class="mm">x</em>₁₁=∂y₁₁/∂<em class="mm">x</em>₁₁的导数才不为零。假设第一区域中的最大元素是<em class="mm"> x </em> ₁₂，∂y₁₁/∂<em class="mm">x</em>₁₂=∂x₁₁/∂<em class="mm">x</em>₁₂= 1，并且在第一池区域中相对于其他x <em class="mm"> ᵢ </em> ⱼ的导数为零。同样，因为我们有一个来自下一层的引入导数，我们需要按照链式法则将局部梯度乘以引入梯度。因此，假设dy₁₁to是引入的导数，对于第一个区域，除了∂x₁₁/∂x₁₂= 1 *dy₁₁= dy₁₁.，所有的梯度都为零</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/6ddc50978b840007647f558bd2781c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/1*kvJtYeTgNDrO85jvUdYHKw.gif"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像—反向传播</p></figure><p id="5294" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">在代码中:</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="mn mo l"/></div></figure><p id="4c14" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">因此，假设以下输入和输入导数:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/0c282a762d74df8570face38415be6f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*ZDaikxNQVgOWtZY-_bC0jg.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像—输入</p></figure><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b08040c56b1c7bb343e5458a238b7fab.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*82zsJyHSJhTNGtzA508iWw.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图片—即将推出的衍生产品</p></figure><p id="ebc4" class="pw-post-body-paragraph lb lc iq ld b le mh jr lg lh mi ju lj ko mj ll lm ks mk lo lp kw ml lr ls lt ij bi translated">输出和相对于输入的梯度将是:</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/ceb69521d0754b8e372dd5379bdeaa4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*sV3o8B7D0pZKKuqmFkvAOw.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像-输出</p></figure><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/76f339174202d8b123d95ef156057aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*YC8L8CDulXSdCebloKqu1w.png"/></div><p class="md me gj gh gi mf mg bd b be z dk translated">按作者分类的图像—输入渐变</p></figure><h2 id="f45b" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h2><p id="3222" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">如果您阅读了我的前一篇关于卷积运算的前向和后向传播的文章，我相信这篇文章对您来说是小菜一碟！<br/>池化操作对于更好的模型泛化、降低复杂度和提高训练速度非常重要。然而，有人声称这在某些情况下可能是不好的，因为通过下采样特征，我们可能会丢失一些重要的信息，这些信息对于正确地分类对象是至关重要的。然而，在构建CNN模型时，池层的优势足够大。</p><h2 id="8a8f" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h2><p id="06ce" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">【http://cs231n.stanford.edu/】</p></div></div>    
</body>
</html>