<html>
<head>
<title>5–10x Faster Hyperparameter Tuning with HalvingGridSearch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HalvingGridSearch 将超参数调谐速度提高了 5-10 倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-10x-faster-hyperparameter-tuning-with-halvinggridsearch-1a874c1994d#2022-03-05">https://towardsdatascience.com/5-10x-faster-hyperparameter-tuning-with-halvinggridsearch-1a874c1994d#2022-03-05</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="2931" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">如何优化机器学习模型的超参数以及如何加速该过程</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/7a4cc8053c25de5d1aa8d019de8cb0e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L56JGRP2fCibQbJk"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">照片由<a class="ae kz" href="https://unsplash.com/@drewpatrickmiller?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">德鲁·帕特里克·米勒</a>在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="66d4" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">什么是超参数调谐？</h1><p id="79ec" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><strong class="lu iv">超参数调整</strong>是一种微调机器学习模型的方法。超参数<strong class="lu iv">不是在训练过程中专门学习的</strong>，但是可以调整以优化模型的性能。以下是我在进行超参数调整时喜欢考虑的一些技巧:</p><ol class=""><li id="0f3a" class="mo mp iu lu b lv mq ly mr mb ms mf mt mj mu mn mv mw mx my bi translated">超参数调整通常是构建模型时的最后一步<strong class="lu iv"/>，就在最终评估之前。</li><li id="7814" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">您不会从调整参数中得到明显不同的结果。对模型性能影响最大的是特征选择和模型选择。</li><li id="afab" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated">超参数调整可以帮助模型的<strong class="lu iv">一般化，减少过度拟合。</strong></li></ol><p id="79f1" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">也就是说，调整您的模型是工作流程中的一个重要步骤。这里有一个快速的视觉效果，可以帮助你理解这个过程。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj nh"><img src="../Images/8835b8d36a23e8377aa7f9fa7f4d6e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a1t2xtxOSiJE3YXA.png"/></div></div></figure><ol class=""><li id="d185" class="mo mp iu lu b lv mq ly mr mb ms mf mt mj mu mn mv mw mx my bi translated"><strong class="lu iv">数据准备</strong>:即<a class="ae kz" rel="noopener" target="_blank" href="/text-cleaning-for-nlp-in-python-2716be301d5d">清理</a>你的数据并为机器学习做准备的过程。</li><li id="1ff8" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated"><strong class="lu iv">探索性数据分析</strong>:这是你应该经常执行的一个步骤。探索新数据集和理解数据分布、相关性等的过程。见<a class="ae kz" rel="noopener" target="_blank" href="/exploratory-data-analysis-with-python-1b8ae98a61c5">这篇文章</a>一步一步的指导。</li><li id="aa14" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated"><strong class="lu iv">特性工程和选择</strong>:从您的数据中创建<em class="ni">新特性</em>(列)并根据它们对模型性能的贡献选择<em class="ni">最佳特性</em>的过程。</li><li id="9385" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated"><strong class="lu iv">模型选择</strong>:利用交叉验证来选择基于评估度量的最佳算法。</li><li id="a4f2" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated"><strong class="lu iv"> Hyper Parameter Tuning </strong>:本帖描述的过程。</li><li id="5f09" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn mv mw mx my bi translated"><strong class="lu iv">模型评估</strong>:选择正确的<a class="ae kz" rel="noopener" target="_blank" href="/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd">性能指标</a>并评估结果。</li></ol><h1 id="17c6" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">超参数示例</h1><p id="d7c4" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">超参数的一些例子有:</p><ul class=""><li id="e61e" class="mo mp iu lu b lv mq ly mr mb ms mf mt mj mu mn nj mw mx my bi translated">在逻辑回归模型中，我应该使用哪个<strong class="lu iv">解算器</strong>？</li><li id="2fdf" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn nj mw mx my bi translated"><strong class="lu iv"> C </strong>或正则化常数的最佳值是什么？</li><li id="164f" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn nj mw mx my bi translated">应该用什么正则化<strong class="lu iv">罚</strong>？</li><li id="7277" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn nj mw mx my bi translated">我的决策树允许的最大深度<strong class="lu iv">应该是多少？</strong></li><li id="5de6" class="mo mp iu lu b lv mz ly na mb nb mf nc mj nd mn nj mw mx my bi translated">我应该在我的随机森林中包含多少棵树？</li></ul><p id="0427" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">你自己很难搞清楚其中的大部分内容。好消息是，您可以应用各种技术来搜索最佳的参数集。现在，您已经对它们是什么以及它们如何适应流程有了基本的了解，让我们看看它是如何工作的。</p><h1 id="4ba7" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">型号选择</h1><p id="0e42" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">为简洁起见，我们将跳过初始清理和功能选择。GitHub 上的这个<a class="ae kz" href="https://github.com/broepke/Tuning/blob/main/Tuning.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>里有这个代码。我们将获取特征选择的结果，并创建我们的<code class="fe nk nl nm nn b">X</code>和<code class="fe nk nl nm nn b">y</code>变量。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="b0f0" class="ns lb iu nn b be nt nu l nv nw">X = df[['categories', 'postal_code', 'text_len', 'review_count', 'text_clean']]<br/>y = df['target']</span></pre><p id="6661" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">接下来，我们有一个函数允许我们重复地创建一个<a class="ae kz" rel="noopener" target="_blank" href="/using-pipelines-in-sci-kit-learn-516aa431dcc5">管道</a>以及一个分类器的实例。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="6e8a" class="ns lb iu nn b be nt nu l nv nw">def create_pipe(clf, ngrams=(1,1)):<br/><br/>    column_trans = ColumnTransformer(<br/>        [('Text', TfidfVectorizer(stop_words='english', ngram_range=ngrams), 'text_clean'),<br/>         ('Categories', TfidfVectorizer(), 'categories'), <br/>         ('OHE', OneHotEncoder(dtype='int', handle_unknown='ignore'),['postal_code']),<br/>         ('Numbers', MinMaxScaler(), ['review_count', 'text_len'])],<br/>        remainder='drop') <br/><br/>    pipeline = Pipeline([('prep',column_trans),<br/>                         ('over', SMOTE(random_state=42)),<br/>                         ('under', RandomUnderSampler(random_state=42)),<br/>                         ('clf', clf)])<br/><br/>    return pipeline</span></pre><p id="de4b" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/using-pipelines-in-sci-kit-learn-516aa431dcc5">管道</a>包含所有需要的预处理步骤。接下来，我们可以执行经典的<strong class="lu iv">交叉验证</strong>来找到最佳模型。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="5623" class="ns lb iu nn b be nt nu l nv nw">models = {'RandForest' : RandomForestClassifier(random_state=42),<br/>          'LogReg' : LogisticRegression(random_state=42)<br/>          }<br/><br/>for name, model, in models.items():<br/>    clf = model<br/>    pipeline = create_pipe(clf)<br/>    scores = cross_val_score(pipeline, <br/>                             X, <br/>                             y, <br/>                             scoring='f1_macro', <br/>                             cv=3, <br/>                             n_jobs=1, <br/>                             error_score='raise')<br/>    print(name, ': Mean f1 Macro: %.3f and Standard Deviation: (%.3f)' % (np.mean(scores), np.std(scores)))</span></pre><pre class="nx no nn np bn nq nr bi"><span id="b65d" class="ns lb iu nn b be nt nu l nv nw">[OUT]<br/>RandForest : Mean f1 Macro: 0.785 and Standard Deviation: (0.003)<br/>LogReg : Mean f1 Macro: 0.854 and Standard Deviation: (0.001)</span></pre><p id="bc6a" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">总的来说，我们可以看到<code class="fe nk nl nm nn b">LogisticRegression</code>分类器在这个数据上比<code class="fe nk nl nm nn b">RandomForestClassifier</code>表现得更好。如上所述，<em class="ni">特征工程</em>、<em class="ni">特征选择</em>、<em class="ni">模型选择</em>在训练你的模型时会给你最大的收获，所以我们总是从这里开始。</p><h1 id="78c1" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">访问管线中的模型参数</h1><p id="c69f" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我想指出的第一件事是如何在<a class="ae kz" rel="noopener" target="_blank" href="/using-pipelines-in-sci-kit-learn-516aa431dcc5">管道</a>中访问模型的参数。通常，当你有一个评估者(模型)实例时，你调用<code class="fe nk nl nm nn b">estimator.get_params()</code>，你可以看到它们。管道中的过程是相同的；但是，最终的输出略有不同。</p><p id="3d57" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">当直接从估算器访问参数时，输出将是一个值，如<code class="fe nk nl nm nn b">C</code>。相比之下，在管道中，输出将首先具有您给估算器的名称以及<em class="ni">双下划线</em>，最后是类似<code class="fe nk nl nm nn b">clf__C</code>的参数名称；知道如何访问参数很重要，因为您需要这些名称来构建参数网格进行搜索。</p><p id="a5fd" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">以下是我的管道的输出，为了简洁起见被截断了。您可以在列表的末尾看到分类器参数，所有这些参数都是当前的默认值。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="1445" class="ns lb iu nn b be nt nu l nv nw">pipeline.get_params()</span></pre><pre class="nx no nn np bn nq nr bi"><span id="6635" class="ns lb iu nn b be nt nu l nv nw">{'memory': None,<br/> 'steps': [('prep',<br/>   ColumnTransformer(transformers=[('Text', TfidfVectorizer(stop_words='english'),<br/>                                    'text_clean'),<br/>                                   ('Categories', TfidfVectorizer(), 'categories'),<br/>                                   ('OHE',<br/>                                    OneHotEncoder(dtype='int',<br/>                                                  handle_unknown='ignore'),<br/>                                    ['postal_code']),<br/>                                   ('Numbers', MinMaxScaler(),<br/>                                    ['review_count', 'text_len'])])),<br/><br/>... truncated for brevity ...<br/><br/> 'clf__C': 1.0,<br/> 'clf__class_weight': None,<br/> 'clf__dual': False,<br/> 'clf__fit_intercept': True,<br/> 'clf__intercept_scaling': 1,<br/> 'clf__l1_ratio': None,<br/> 'clf__max_iter': 500,<br/> 'clf__multi_class': 'auto',<br/> 'clf__n_jobs': None,<br/> 'clf__penalty': 'l2',<br/> 'clf__random_state': 42,<br/> 'clf__solver': 'lbfgs',<br/> 'clf__tol': 0.0001,<br/> 'clf__verbose': 0,<br/> 'clf__warm_start': False}</span></pre><h1 id="6731" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">网格搜索</h1><p id="9306" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们将探索的第一种方法是<a class="ae kz" href="https://scikit-learn.org/stable/modules/grid_search.html#grid-search" rel="noopener ugc nofollow" target="_blank">网格搜索交叉验证</a> n，它采用了与我们用于模型选择的常规交叉验证相同的逻辑。然而，网格搜索遍历每个参数组合，执行交叉验证，并返回最佳模型。这里的第一步是创建一个参数网格，我们通过为 GridSearch 构建一个字典列表来迭代完成。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="0a30" class="ns lb iu nn b be nt nu l nv nw">parameters = [{'clf__solver' : ['newton-cg', 'lbfgs', 'sag', 'liblinear'],'clf__C' : [.1, 1, 10, 100, 1000], 'prep__Text__ngram_range': [(1, 1), (2, 2), (1, 2)]}]</span></pre><p id="65a7" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">或者，您可以向列表中添加多个词典。它将独立地遍历每个字典的<em class="ni">组合；如果您有一些与其他参数不兼容的参数，这很有用。例如，在<code class="fe nk nl nm nn b">LogisticRegression</code>中，某些惩罚值只对某些解算器有效。</em></p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="3512" class="ns lb iu nn b be nt nu l nv nw">parameters = [<br/>  {'clf__penalty': ['l1', 'l2'], 'clf__solver' : ['liblinear']},<br/>  {'clf__penalty': ['l1', 'none'], 'clf__solver' : ['newton-cg']},<br/>  ]</span></pre><p id="7cae" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">现在我们有了参数网格，我们可以首先创建一个基本分类器的实例，并将其传递给管道函数。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="9dea" class="ns lb iu nn b be nt nu l nv nw">clf = LogisticRegression(random_state=42, max_iter=500)<br/>pipeline = create_pipe(clf)</span></pre><p id="0f60" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">接下来，我们将使用<code class="fe nk nl nm nn b">GridSearchCV</code>运行网格搜索。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="6a36" class="ns lb iu nn b be nt nu l nv nw">%time grid = GridSearchCV(pipeline, <br/>                          parameters, <br/>                          scoring='f1_macro', <br/>                          cv=3,<br/>                          random_state=0).fit(X_train, y_train)<br/><br/>print("Best cross-validation accuracy: {:.3f}".format(grid.best_score_))<br/>print("Test set score: {:.3f}".format(grid.score(X_test, y_test))) <br/>print("Best parameters: {}".format(grid.best_params_))<br/><br/>log_C = grid.best_params_['clf__C']<br/>log_solver = grid.best_params_['clf__solver']<br/>log_ngram = grid.best_params_['prep__Text__ngram_range']</span></pre><pre class="nx no nn np bn nq nr bi"><span id="9db0" class="ns lb iu nn b be nt nu l nv nw">58m 3s<br/><br/>Best cross-validation accuracy: 0.867<br/>Test set score: 0.872<br/>Best parameters: {'clf__C': 100, 'clf__solver': 'newton-cg', <br/>'prep__Text__ngram_range': (1, 2)}</span></pre><p id="30e6" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">我们的网格搜索用<code class="fe nk nl nm nn b">58m 3s</code>来运行，为每一个产生最佳参数。</p><p id="60f5" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">在查看上面的列表时，您可能会想到的一件事是，在我们的参数网格中有相当多的潜在组合。上例中有<strong class="lu iv">4x</strong>T3、<strong class="lu iv">5x</strong>T4、<strong class="lu iv">3x</strong>T5，合计为<code class="fe nk nl nm nn b">4 x 5 x 3 = 60</code>。因为训练我们的模型需要大约一分钟，所以遍历一次网格需要大约一个小时。</p><p id="21f5" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated"><strong class="lu iv">注意</strong>:可以用参数<code class="fe nk nl nm nn b">n_jobs=-1</code>并行化网格搜索；然而，我没有展示这个例子的相对性能。</p><p id="4907" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">接下来，我们来看一个提高整体性能的方法。</p><h1 id="0ec8" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">减半搜索</h1><p id="dc6d" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">然而，有一种方法可以加快网格搜索的速度，并在更短的时间内返回非常相似的结果。这种方法被称为<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html" rel="noopener ugc nofollow" target="_blank">连续减半</a>。它将在过程的早期利用数据的子集来找到一些性能最佳的参数组合，并随着最佳组合的缩小而逐渐增加所使用的数据量。</p><p id="3d94" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">您可以将<code class="fe nk nl nm nn b">GridSearchCV</code>调用与 HalvingGridSearchCV `调用交换，以利用对半网格搜索。就这么简单。让我们用这个新方法重新运行上面的搜索，看看它的表现如何。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="ffcd" class="ns lb iu nn b be nt nu l nv nw">%time grid = HalvingGridSearchCV(pipeline, <br/>                                 parameters, <br/>                                 scoring='f1_macro', <br/>                                 cv=3, <br/>                                 random_state=0).fit(X_train, y_train)<br/><br/><br/>print("Best cross-validation accuracy: {:.3f}".format(grid.best_score_))<br/>print("Test set score: {:.3f}".format(grid.score(X_test, y_test))) <br/>print("Best parameters: {}".format(grid.best_params_))<br/><br/>log_C_b = grid.best_params_['clf__C']<br/>log_solver_b = grid.best_params_['clf__solver']<br/>log_ngram_b = grid.best_params_['prep__Text__ngram_range']</span></pre><pre class="nx no nn np bn nq nr bi"><span id="9e50" class="ns lb iu nn b be nt nu l nv nw">14m 28s<br/><br/>Best cross-validation accuracy: 0.867<br/>Test set score: 0.872<br/>Best parameters: {'clf__C': 100, 'clf__solver': 'lbfgs', <br/>'prep__Text__ngram_range': (1, 2)}</span></pre><p id="3983" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">相当可观！从一小时缩短到 15 分钟！在某些情况下，我看到它的表现甚至更快。我们也可以看到结果相当相似。这次选择的解决方案是<code class="fe nk nl nm nn b">lbfgs</code>对<code class="fe nk nl nm nn b">newton-cg</code>。我们现在可以对比一下两者的表现。</p><h1 id="f4ba" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">评估结果</h1><p id="8a93" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们有一个简单的函数，它将采用一个管道，将数据拟合到一个训练和测试集，并使用一个<em class="ni">分类报告</em>和一个<em class="ni">混淆矩阵</em>评估结果。让我们依次经历<strong class="lu iv">未调模型</strong>、<strong class="lu iv">网格搜索调模型</strong>，最后是<strong class="lu iv">减半网格搜索调模型</strong>。首先是原始模型。</p><p id="de85" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated"><strong class="lu iv">注意</strong>:我们这里使用的评估指标是<strong class="lu iv">F1-宏</strong>；我们正在寻找平衡<em class="ni">精度</em>和<em class="ni">召回</em>。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="7a1e" class="ns lb iu nn b be nt nu l nv nw">def fit_and_print(pipeline, name):<br/><br/>    pipeline.fit(X_train, y_train)<br/>    y_pred = pipeline.predict(X_test)<br/>    score = metrics.f1_score(y_test, y_pred, average='macro')<br/><br/>    print(metrics.classification_report(y_test, y_pred, digits=3))<br/><br/>    ConfusionMatrixDisplay.from_predictions(y_test, <br/>                                            y_pred, <br/>                                            cmap=plt.cm.Greys)<br/><br/>    plt.tight_layout()<br/>    plt.title(name)<br/>    plt.ylabel('True Label')<br/>    plt.xlabel('Predicted Label')<br/>    plt.tight_layout()<br/>    plt.savefig(name + '.png', dpi=300) <br/>    plt.show;</span></pre><pre class="nx no nn np bn nq nr bi"><span id="c54b" class="ns lb iu nn b be nt nu l nv nw">clf = LogisticRegression(random_state=42, max_iter=500)<br/>pipeline = create_pipe(clf)<br/>fit_and_print(pipeline, 'Default Parameters')</span></pre><pre class="nx no nn np bn nq nr bi"><span id="6331" class="ns lb iu nn b be nt nu l nv nw">precision    recall  f1-score   support<br/><br/>           0      0.789     0.845     0.816      9545<br/>           1      0.925     0.894     0.909     20370<br/><br/>    accuracy                          0.879     29915<br/>   macro avg      0.857     0.869     0.863     29915<br/>weighted avg      0.882     0.879     0.880     29915</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ny"><img src="../Images/64826816257324d28eee0c3cd0a2730d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Ri2RnQ46jttDNqU27LYkA.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="9e6b" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">我们这里的<strong class="lu iv"> F1-Macro </strong>分数是<code class="fe nk nl nm nn b">0.863</code>。接下来，让我们尝试一下网格搜索调优模型。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="34da" class="ns lb iu nn b be nt nu l nv nw">clf = LogisticRegression(C=log_C, solver=log_solver, random_state=42, max_iter=500)<br/>pipeline = create_pipe(clf, log_ngram)<br/>fit_and_print(pipeline, 'GridSearch Parameters')</span></pre><pre class="nx no nn np bn nq nr bi"><span id="6c91" class="ns lb iu nn b be nt nu l nv nw">precision    recall  f1-score   support<br/><br/>           0      0.839     0.810     0.824      9545<br/>           1      0.913     0.927     0.920     20370<br/><br/>    accuracy                          0.890     29915<br/>   macro avg      0.876     0.869     0.872     29915<br/>weighted avg      0.889     0.890     0.889     29915</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ny"><img src="../Images/61a0651ce107ec424bd63ba8b513b17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-JqFsdlwESPjv8tjB7l6w.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="9876" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">我们这里的<strong class="lu iv"> F1-Macro </strong>分数是<code class="fe nk nl nm nn b">0.872</code>。我们的调优过程改进了该模式的整体结果，并且我们将 F1 宏分数增加了<code class="fe nk nl nm nn b">0.09</code>。接下来，让我们尝试一下减半网格搜索调优模型。</p><pre class="kk kl km kn gu no nn np bn nq nr bi"><span id="d5cc" class="ns lb iu nn b be nt nu l nv nw">clf = LogisticRegression(C=log_C_b, solver=log_solver_b, random_state=42, max_iter=500)<br/>pipeline = create_pipe(clf, log_ngram_b)<br/>fit_and_print(pipeline, 'HalvingGridSearch Parameters')</span></pre><pre class="nx no nn np bn nq nr bi"><span id="4e90" class="ns lb iu nn b be nt nu l nv nw">precision    recall  f1-score   support<br/><br/>           0      0.839     0.811     0.824      9545<br/>           1      0.913     0.927     0.920     20370<br/><br/>    accuracy                          0.890     29915<br/>   macro avg      0.876     0.869     0.872     29915<br/>weighted avg      0.889     0.890     0.889     29915</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj ny"><img src="../Images/e335af485fd1d719038f6b2ef3db2ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uo_aTIHptpWssR-0XRX9hw.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="25d8" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">最后，我们看到了减半网格搜索模型的结果。<strong class="lu iv">F1-宏</strong>分数与网格搜索模型相同。我们在不牺牲调优结果的情况下，将调优时间从 60 分钟缩短到 15 分钟。每次使用这些方法时，您的结果可能会有所不同，但这是一种无需花费大量时间就能调优模型的极好方法。</p><h1 id="fba3" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">结论</h1><p id="aeec" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">超参数调整是一种在精细执行特征选择和模型选择后调整模型的方法。超参数不是在训练过程中学习到的参数，而是经过调整以提高模型整体性能的参数。我们看到了如何访问管道中的参数，并执行网格搜索来选择最佳参数。最后，您看到了如何利用对半网格搜索方法来减少搜索最佳参数所需的时间。我希望你喜欢这篇文章。快乐模型建筑！</p><p id="4cda" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">如果你想重新创建它，所有这些代码都可以在 GitHub 上的<a class="ae kz" href="https://github.com/broepke/Tuning/blob/main/Tuning.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>中找到。</p><p id="7a75" class="pw-post-body-paragraph ls lt iu lu b lv mq jv lx ly mr jy ma mb ne md me mf nf mh mi mj ng ml mm mn in bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，考虑注册成为一名媒体会员。一个月 5 美元，让你可以无限制地访问成千上万篇文章。如果您使用 <a class="ae kz" href="https://medium.com/@broepke/membership" rel="noopener"> <em class="ni">【我的链接】</em> </a> <em class="ni">注册，我会为您赚取一小笔佣金，无需额外费用。</em></p></div></div>    
</body>
</html>