<html>
<head>
<title>E-DALL-E: Creating Digital Art with Varying Aspect Ratios</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">E-DALL-E:用不同的纵横比创建数字艺术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/e-dall-e-creating-digital-art-with-varying-aspect-ratios-5de260f4713d#2022-07-07">https://towardsdatascience.com/e-dall-e-creating-digital-art-with-varying-aspect-ratios-5de260f4713d#2022-07-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e2e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用VQGAN和CLIP修复侧面来扩展DALL-E Mini生成的图像</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/081bc66bc712e495711dd6b4a33ee79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPQ9iES-JHOqDOUHPfrOJA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">图片来自DALL-E Mini </strong>(左)<strong class="bd ky">，放大到16:9，边缘像素重复</strong>(中)<strong class="bd ky">和E-DALL-E </strong>(右)，图片由作者提供</p></figure><p id="ec63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能见过一些使用OpenAI的DALL-E 2 [1]从文本生成的图像。尽管该系统令人印象深刻，结果令人难以置信，但它目前只在封闭测试版中提供<a class="ae lv" href="https://labs.openai.com/waitlist" rel="noopener ugc nofollow" target="_blank">等候名单</a>。然而，你可以访问和运行一个独立的文本到图像系统，名为DALL-E Mini [2]，由开发者Boris Dayma和Pedro Cuenca领导。虽然结果没有DALL-E 2生成的图像那么壮观，但仍然非常优秀，源代码和训练好的模型都是免费开源的。你可以在他们广告支持的<a class="ae lv" href="https://www.craiyon.com/" rel="noopener ugc nofollow" target="_blank">演示</a>中尝试一下。</p><p id="ec97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可能已经注意到，两种DALL-E型号生成的图像都使用1:1的纵横比；图像总是死方的。该系统不能产生横向或纵向格式的图像，限制了它们的实用性。</p><p id="364a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，我注意到DALL-E Mini的图像生成器使用了VQGAN模型[3]，这一点我从我写的几篇关于图像生成的文章<a class="ae lv" href="https://robgon.medium.com/list/creating-fine-art-with-ai-73476c209de3" rel="noopener">中非常了解。我还知道VQGAN可以渲染不同纵横比的图像。所以我写了一点代码来获取DALL-E模型的输出，或者任何图像，并使用OpenAI [4]的CLIP引导的VQGAN来扩展纵横比。我称这个系统为Expand-DALL-E，简称E-DALL-E。你可以在这里运行它。请务必查看附录中的图片集。</a></p><h1 id="c684" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">系统概况</h1><p id="16bb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是E-DALL-E系统的示意图，其中简要描述了流程。系统组件的完整描述如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/273a12e54f70113f36916e62337f9f1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-RGP2Bh9qz2Aa01CPM38Bw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> E-Dall-E组件，</strong>作者提供的图表</p></figure><p id="b9b3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该系统有两个主要组成部分:用于图像生成的DALL-E Mini和用于扩展纵横比的E-DALL-E。</p><p id="9182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像创建过程从用户的文本提示开始，就像“在海滩上戴着太阳镜的哈巴狗的砖块上涂鸦墙”DALL-E Mini系统经过1500万对图像/字幕的训练，可以将文本转换为内部表示。然后，它将结果解码并采样为潜在向量，用作VQGAN图像生成器的输入，作者使用ImageNet数据集对其进行了训练[6]。VQGAN为每个样本渲染256x256的图像，用户选择一个。</p><p id="5455" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，用户向E-DALL-E提供所需的纵横比，如16:9。然后，它通过重复原始边缘像素来填充所选图像，作为进一步迭代的初始图像。系统将文本提示输入剪辑文本编码器，用作指导。然后，它开始在生成过程中迭代N步，比如100步。系统使用Adam优化器[7]来改变VQGAN向量，以创建与文本提示最匹配的图像。然而，在每一步之后，系统将原始图像中心部分的矢量复制回来，因此它将只更新图像的边缘。</p><p id="cdf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在完成迭代之后，系统显示扩展的图像，在侧面具有新添加的细节。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn mv mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/9af0e3e91ac9f0ea67ecd6b97f853f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*4B_ktPnDSVpe1o_OKml5UQ.png"/></div></figure><figure class="mu kn na mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5ed0c0816b96d87b8460e534b4629cec.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*cIpvYUHjbbHFjXIh27ij0g.png"/></div></figure><figure class="mu kn na mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/def904d52562dea31f404a53e8a882f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*jcJBgFkgpeFeFvnCVx6gtA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk nb di nc nd translated"><strong class="bd ky">DALL-E Mini的原始1:1图像，具有重复边缘像素的初始16:9图像，使用E-DALL-E扩展的16:9图像，</strong>作者提供的图像</p></figure></div><p id="3ab1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">仔细观察，您会发现右侧扩展图像的中心部分与左侧的原始图像略有不同。这是VQGAN渲染图像的一个有意的方面。我将在下面的图像拼接部分描述这种效果。</p><h1 id="3b01" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">组件详细信息</h1><h2 id="e524" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated"><strong class="ak">达尔-E </strong></h2><p id="7039" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">2021年1月，OpenAI发布了一篇论文和他们的DALL-E文本到图像系统的演示[8]。这个名字是一种文字游戏。这是画家萨尔瓦多·达利的姓氏和迪士尼动画电影《瓦力》的结合</p><p id="2dab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DALL-E模型是一个巨大的变压器。它有120亿个参数，并使用来自互联网的2.5亿对图像/字幕进行训练。以下是查询结果，“一只手风琴做的貘。有手风琴纹理的貘。”以及“一只穿着圣诞毛衣的小刺猬遛狗的插图。”</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/03453d164d42c4e90791ec4487306b2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDo-G0hWaTx1i4QpObpRlg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">来自DALL-E的输出</strong>来自OpenAI的论文<a class="ae lv" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">零镜头文本到图像生成</a></p></figure><p id="a1a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DALL-E的结果非常好。该系统在解释文本和渲染图像方面做得很好，既有创造性又很逼真。一个限制是输出相对较小，为256x256像素。OpenAI没有提供DALL-E源代码或训练模型的访问权限。但14个月后，情况发生了变化。</p><h2 id="89ac" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">达尔-E 2</h2><p id="d1fb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">2022年4月13日，OpenAI发布了名为DALL-E 2的更新版本[1]。它为文本编码器使用了他们的剪辑模型的变体，并使用了他们的GLIDE [9]图像解码器模型的变体，具有35亿个参数。OpenAI使用6.5亿张图像训练了DALL-E 2系统。该系统以1024x1024像素的高分辨率渲染图像。这是他们论文中的一些样本图片。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/ebb839a0d60a565e60cad4889c0d5cb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0hkneN1tcZtBudN5v-UrfQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">OpenAI论文中DALL-E 2的输出，<a class="ae lv" href="https://arxiv.org/pdf/2204.06125.pdf" rel="noopener ugc nofollow" target="_blank">带剪辑潜在时间的分层文本条件图像生成</a></p></figure><p id="ce41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些成绩都很优秀！正如我在本文开头提到的，DALL-E 2只提供封闭测试版。</p><h2 id="071c" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">达尔-E迷你</h2><p id="19ee" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">开发人员Boris Dayma和Pedro Cuenca带领一个团队创建了一个免费的开源文本到图像生成器，名为DALL-E Mini [2]。该系统使用一对经过训练的BERT变换器[10]将文本转换为潜在向量，这些潜在向量可以使用VQGAN渲染图像。顾名思义，DALL-E Mini型号比较小。它“只”有4亿个参数，并且“只”在1500万张图像上进行训练。</p><p id="b261" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是DALL-E Mini的推理管道图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/7136484d1ddca510644232180b486fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIGCVt0rSzd6-6Kpaef42w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">DALL-E Mini的推理管道</strong>，来源:<a class="ae lv" href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mini-Explained--Vmlldzo4NjIxODA" rel="noopener ugc nofollow" target="_blank"> DALL-E Mini解释</a></p></figure><p id="a011" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本提示被输入BART，然后被解码以产生VQGAN的潜在向量样本，从而呈现候选图像。请注意，系统不会迭代生成图像。它转换成VQGAN用来直接渲染图像的矢量。DALL-E Mini如何工作的完整解释是<a class="ae lv" href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-Mini-Explained--Vmlldzo4NjIxODA" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="8011" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一些提示的示例图像，“一幅起伏的农田的画”、“一幅带有橙色三角形的抽象画”和“一碗水果的静物画”</p><div class="kj kk kl km gt ab cb"><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f8db1fc6a6d783e0d0debd2e869ca327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8FQivywGuOlsodLLMrROqw.png"/></div></figure><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/d86f80b9fda7d3982ffc184dd3baf57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*LIbBJ1qfCZCbXb0YMHBcHQ.png"/></div></figure></div><div class="ab cb"><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5955f43a37241572ec5519c970e7d902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*cTzCxaT8dCoFXhFsT1Zifg.png"/></div></figure><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/27f51dfb1b0b63db476b6ed0df09a4cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6Ibu3k-1avftIJK0BMgXsw.png"/></div></figure></div><div class="ab cb"><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/157dc279838b6ea4fb674a4e09ce5ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*iQdbCAw_0uZt6O3gqOlpAg.png"/></div></figure><figure class="mu kn nt mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/4f31b4fef0731bbe4a46c1b06031e1da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*WOaWCksI-EBDf-aWqxm00Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk nu di nv nd translated"><strong class="bd ky">DALL-E Mini</strong>的输出样本，图片由作者提供</p></figure></div><p id="39d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然它们不如DALL-E 2的图像好，但DALL-E Mini的输出还不错。这些图像有很大的变化，虽然缺乏细节，但每幅作品总体来说都很好。</p><p id="7c1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我将向您展示如何扩展输出以获得不同的纵横比。</p><h2 id="5da4" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">伊达尔伊</h2><p id="7485" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">E-DALL-E系统从用户指定的纵横比开始。例如，如果我们有一个256x256的图像，并想将其拉伸到比如说16:9，我们需要在左侧添加96个像素，在右侧添加96个像素。这将产生大约为16:9的合成图像448x256。</p><p id="9c38" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，系统用重复的像素填充图像的边缘。这将有助于VQGAN模型在生成扩展图像的侧面时领先一步。重复像素是一个简单的编程技巧，不需要任何机器学习。</p><p id="5bb7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于图像中的每一行，系统计算最后8个像素的平均值，并复制它们以制作水平颜色恒定的子图像。它还对原始图像执行32像素的线性混合以掩盖过渡，因此左右子图像的宽度必须为96+32像素。</p><p id="f072" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是三幅图像在16:9格式下的样子，有重复的边缘像素。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/c7235855b38ebd99d52844f76427f9a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*Mb0FJ2ZdTsXvrVtUxLSTyw.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/fa1196ffcd9e36c065ad53c5a0591e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*XYVNFIqMaKsIAWPeHP0O6Q.png"/></figure></div><div class="ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/a573b347b99cbcb7a4bff1a71b3be60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*ucbqQN10p7lckY45ho_4rg.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/d3cb8cc5864882eee08c2e095f40f3a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*D-WzV1h4n6usg61ej_PpTA.png"/></figure></div><div class="ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/8d0e7aea6b4546e3a3b563101ec519c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*G-1eGK4JtPgvyoqPZoQImQ.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/bf791d4df8ea8404bfa56f37f3cfd7bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*8aXr8qoxmNm1Ss3SIIPHQA.png"/><p class="ku kv gj gh gi kw kx bd b be z dk ny di nz nd translated"><strong class="bd ky">具有重复边缘像素的DALL-E Mini的输出，</strong>作者的图像</p></figure></div><p id="11f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，它们不能作为成品图像，但它们是下一步过程的良好起点。重复边缘像素的源代码在这里是<a class="ae lv" href="https://gist.github.com/robgon-art/2576ac7f3850b20b09e2f29c807997fd" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="0022" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">使用VQGAN拼接图像</h2><p id="a655" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在我开始渲染扩展图像的侧面之前，我将讨论VQGAN的一个有趣的方面，据我所知，它还没有被写出来。)虽然VQGAN的作者创建它是为了生成新图像，但它在将相似图像拼接在一起方面做得非常好。</p><p id="0ec4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">VQGAN本质上是一个编解码器。编码器获取图像并生成潜在向量。解码器获取潜在向量并生成图像。在训练期间，系统更新模型的参数，以使输出图像尽可能接近地匹配输入图像。</p><p id="af98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与大多数GANs中的潜在向量不同，VQGAN使用的潜在向量有一个空间方面。对于输入中每16x16块RGB像素，解码器会创建256个浮点数。因此，256x256 RGB图像的潜在尺寸为16x16x256。在VQGAN论文[4]中，256个数字的组被称为“码本”。</p><p id="6edb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我在潜在向量空间中编辑图像时，系统会在解码结果图像时平滑结果。</p><p id="2560" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，这里有两幅来自艺术家古斯塔夫·克里姆特和阿美迪欧·莫蒂里安尼的肖像。最上面一行显示了从中间开始拼接RGB图像的结果。左半部分来自克里姆特，右半部分来自莫迪利阿尼。底部一行显示了拼接VQGAN潜在向量和解码结果图像的结果。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/a4332e42479550803477d0054bf29847.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*E5O_vaw2VamTBubOnkI8DA.png"/></div></figure><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/971dd626b28f78f93d88abd1d7317c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*VjBcuKQnkJUiICEKpFH19g.png"/></div></figure><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/acbe00a1f57710aacb9584be495f74ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*u0JpK-s_M_L95aWr8TIWNw.png"/></div></figure></div><div class="ab cb"><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/1040d2d0ecff6774f0488f52b899364c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*IQE5bNL28Frevd6DECiqCA.png"/></div></figure><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/b0485b91fa9aa93cc4301ae94fd5dc0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qzv9xj-HNYY78UR-4mj0RA.png"/></div></figure><figure class="mu kn oa mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/374cc6a0ae86b0c92a23930b1d77ad1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*J4CI9r3aYm3EP5FM4fG_eQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ob di oc nd translated">顶行:<a class="ae lv" href="https://www.wikiart.org/en/gustav-klimt/amalie-zuckerkandl-1918" rel="noopener ugc nofollow" target="_blank"> WikiArt </a>的古斯塔夫·克里姆特的<strong class="bd ky"> Amalie Zuckerkandl </strong>，作者的<strong class="bd ky">混合像素拼接</strong>，<a class="ae lv" href="https://www.wikiart.org/en/amedeo-modigliani/marie-daughter-of-the-people-1918" rel="noopener ugc nofollow" target="_blank"> WikiArt </a>的阿美迪欧·莫蒂里安尼的<strong class="bd ky"> Marie，人民的女儿</strong>，底行:<strong class="bd ky"> Amalie Zuckerkland“通过VQGAN，混合矢量拼接”，“通过VQGAN的Marie，人民的女儿</strong>，作者的图片</p></figure></div><p id="364e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有几件事需要注意。首先，VQGAN模型不是一个完美的编解码器。通过模型传递的图像与原始图像并不完全匹配。例如，左上和左下肖像中的眼睛看起来不同。但是，您可以看到在潜在向量空间中拼接图像是如何非常自然地混合图像部分的。尽管中下方的这张脸显然是由不同的两半组成的，但很难找到两者之间的接缝。这是因为每个VQGAN码本条目在解码时不仅会呈现其空间区域，还会影响其邻居基于训练数据创建内聚图像。</p><p id="4167" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当渲染扩展图像的侧面时，我使用VQGAN的这个特性。</p><h2 id="3108" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">使用E-DALL-E扩展图像</h2><p id="c429" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这是组件图，只显示了用于扩展图像的过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/fc0600625218b6fd83a9982db0cf4ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a2znoDoLBH0Qp67pKUfT0A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky"> E-DALL-E组件细节</strong>，作者提供的图表</p></figure><p id="4a9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该过程从输入图像和指定的纵横比开始。如上所述，系统重复边缘像素以拉伸图像。然后，它使用CLIP对提示进行编码，以指导优化过程。对于每次迭代，系统用CLIP对图像进行编码。它使用文本编码和图像编码之间的差异，通过Adam优化器来修改VQGAN潜在向量。在每次迭代之后，修改的图像向量的中心部分被来自输入图像的向量的中心替换，以保持中间部分相对恒定。只是侧面会有很大的变化。在N次迭代之后，系统显示具有新纵横比的最终图像。</p><p id="fec3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是使用E-DALL-E的一些结果。</p><div class="kj kk kl km gt ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/c7235855b38ebd99d52844f76427f9a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*Mb0FJ2ZdTsXvrVtUxLSTyw.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/f9bbe6b6a6329b2ba53e502b2f9a319b.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*2kvoOjXpeBiBfmF41cg5Iw.png"/></figure></div><div class="ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/8d0e7aea6b4546e3a3b563101ec519c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*G-1eGK4JtPgvyoqPZoQImQ.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/090bb122d80e098d3dd4ffc93a7946be.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*YrbqWFG0c1HuUIOlCRaGyw.png"/></figure></div><div class="ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/a573b347b99cbcb7a4bff1a71b3be60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*ucbqQN10p7lckY45ho_4rg.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/bda1aa4e813528fe86be2a92579be71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*QFXO89TK9KcUY_YYJVbTTA.png"/><p class="ku kv gj gh gi kw kx bd b be z dk ny di nz nd translated"><strong class="bd ky">来自E-DALL-E的结果，</strong>作者提供的图片</p></figure></div><p id="fb03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相当不错！该系统似乎在扩展区域中很好地弥补了新的细节。而且很难看到原始图像和新生成的部分之间的接缝。但你也可以看到VQGAN有时如何改变图像的中心部分，以使新的部分更好地适应。例如，在右上角的图像中，天空的色调似乎在中心部分变成了更深的蓝色。右下角图像中心的橙色三角形的纹理似乎与边上新生成的三角形的表面相匹配。</p><h1 id="2738" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">文化偏见</h1><p id="a6f4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">像大多数基于互联网上发现的大量数据进行训练的神经网络模型一样，该项目中使用的模型具有内在的文化偏见，这些偏见会在数据中得到体现。</p><p id="3fc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">视频作者研究了他们系统中存在的文化偏见。</p><blockquote class="oe of og"><p id="4c32" class="kz la oh lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">CLIP是在互联网上与图像配对的文本上训练的。这些图像-文本对未经过滤和切割，导致剪辑模型学习许多社会偏见。…例如，我们发现…‘保姆’和‘管家’等标签开始出现在女性身上，而‘囚犯’和‘暴徒’等标签开始出现在男性身上。…此外，CLIP还贴上了一些标签，这些标签更多地描述了男性的高地位职业，如“高管”和“医生”。<em class="it">——亚历克·拉德福德等人</em></p></blockquote><p id="b299" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DALL-E Mini的作者发现了以下情况。</p><blockquote class="oe of og"><p id="c718" class="kz la oh lb b lc ld ju le lf lg jx lh oi lj lk ll oj ln lo lp ok lr ls lt lu im bi translated">总的来说，由于生成的人和脸的质量低，很难详细调查模型偏差，但很明显，偏差是存在的。表现出较高教育水平的职业(如工程师、医生或科学家)或高体力劳动(如建筑业)大多由白人男性代表。相比之下，护士、秘书或助理通常是女性，通常也是白人。生成的人大部分是白人。只有在具体的例子中，比如运动员，我们才会看到不同的种族，尽管他们中的大多数仍然没有得到充分的代表。该数据集仅限于带有英语描述的图片，这使得来自非英语文化的文本和图像无法呈现。<em class="it"> - Boris Dayma和Pedro Cuenca等人</em></p></blockquote><p id="5ed0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">E-DALL-E在渲染扩展图像的新部分时可能会延续这些偏见。</p><h1 id="bfb0" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">最后的想法和未来的步骤</h1><p id="12ea" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">DALL-E迷你文本到图像模型的结果看起来非常好。VQGAN是一种多功能的图像渲染模型，有许多意想不到的用途，如扩展图像以改变纵横比。</p><p id="e311" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在未来的项目中，我可能会尝试使用VQGAN作为一个通用的修复工具。尽管系统将被掩蔽的区域量化为16×16的像素块，但是有可能混合回原始潜在向量和被掩蔽区域之外的原始像素。并且使用CLIP作为一个指导性的文本编码器，有可能执行类似于“在哈巴狗上画一顶派对帽”的功能。😀</p><h1 id="98e5" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">源代码</h1><p id="d687" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">这个项目的源代码可以在<a class="ae lv" href="https://github.com/robgon-art/e-dall-e" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。我在CC BY-SA许可下发布源代码。你可以使用谷歌眼镜<a class="ae lv" href="https://colab.research.google.com/github/robgon-art/e-dall-e/blob/main/DALL_E_Mini_Image_Generator.ipynb" rel="noopener ugc nofollow" target="_blank">创建</a>和<a class="ae lv" href="https://colab.research.google.com/github/robgon-art/e-dall-e/blob/main/E_DALL_E_Image_Expander.ipynb" rel="noopener ugc nofollow" target="_blank">扩展</a>你自己的图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/b2a3fdf8ce2482366e7c891537e8afcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/0*WErH15DsvR_rJhpZ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ky">知识共享署名共享</strong></p></figure><h1 id="26fd" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感谢</h1><p id="ccc4" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我要感谢詹尼弗·林对这篇文章的帮助。</p><h1 id="d9c4" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">参考</h1><p id="7833" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">[1] A. Ramesh等人，<a class="ae lv" href="https://arxiv.org/pdf/2204.06125.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> DALL-E 2 </strong>带剪辑潜在时间的分层文本条件图像生成</a> (2022)</p><p id="e0e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] B. Dayma和P. Cuenca，<a class="ae lv" href="https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini-Generate-Images-from-Any-Text-Prompt--VmlldzoyMDE4NDAy" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> DALL E mini </strong> —从任何文本提示生成图像</a> (2021)</p><p id="d8ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] <strong class="lb iu"> VQGAN </strong>作者:P. Esser、R. Rombach和B. Ommer，<a class="ae lv" href="https://arxiv.org/pdf/2012.09841.pdf" rel="noopener ugc nofollow" target="_blank">驯服变压器实现高分辨率图像合成</a> (2020)</p><p id="1b89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5] <strong class="lb iu">剪辑</strong>由a .拉德福德等著，<a class="ae lv" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf" rel="noopener ugc nofollow" target="_blank">从自然语言监督中学习可转移的视觉模型</a> (2021)</p><p id="4501" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6] J .邓等，<a class="ae lv" href="https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> ImageNet </strong>:一个大规模的层次化图像数据库</a> (2009)</p><p id="067c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[7] D. P .金马和j .巴雷，<strong class="lb iu">亚当</strong> : <a class="ae lv" href="https://arxiv.org/pdf/1412.6980.pdf" rel="noopener ugc nofollow" target="_blank">随机优化的一种方法</a> (2015)，国际学习表征会议<strong class="lb iu"> </strong> 2015</p><p id="77f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[8]<strong class="lb iu">a . Ramesh等人的DALL-E </strong>，<a class="ae lv" href="https://arxiv.org/pdf/2102.12092.pdf" rel="noopener ugc nofollow" target="_blank">零镜头文本到图像生成</a> (2021)</p><p id="85c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[9] A. Nichol等人，<a class="ae lv" href="https://arxiv.org/pdf/2112.10741.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> GLIDE </strong>:利用文本引导扩散模型实现照片级真实感图像生成和编辑</a> (2022)</p><p id="01bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[10] J. Devlin，M.W. Chang，K. Lee，K. Toutanova，<a class="ae lv" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> BERT </strong>:语言理解的深度双向转换器的预训练</a> (2018)</p><h1 id="d9cf" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">附录</h1><p id="5596" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">左边是DALL-E Mini的结果，右边是E-DALL-E的结果。</p><h2 id="5d8d" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">一幅带有蓝色、绿色和紫色漩涡的彩色抽象画</h2><div class="kj kk kl km gt ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/cd680ae4d452e93544debd9650d90ef7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*DCSJljHZOtnBbbCp8tnvSg.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/34c153359fbdc4108d32380e5c4b5ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*2as0xuex52lku_l5pYvuaQ.png"/><p class="ku kv gj gh gi kw kx bd b be z dk ny di nz nd translated"><strong class="bd ky">“蓝色、绿色和紫色漩涡的彩色抽象画，”</strong>作者图片</p></figure></div><h2 id="6594" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">一幅吉娃娃冲浪的画</h2><div class="kj kk kl km gt ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/a8f70a16c11fddbe824fea1f16ba38e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*-VpZ3F9ZyKe7T2_EhgvWCg.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/5e1404e70197c548ac5790e77819b9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*8jutHR6KS8KO2XRrpABjnQ.png"/><p class="ku kv gj gh gi kw kx bd b be z dk ny di nz nd translated"><strong class="bd ky">“一只吉娃娃在冲浪”，作者</strong>图片</p></figure></div><h2 id="1c81" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated"><strong class="ak">一幅梵高《星夜》风格的埃菲尔铁塔画</strong></h2><div class="kj kk kl km gt ab cb"><figure class="mu kn om mw mx my mz paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/9feaf7adabd0970eddf01d1117977a1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*Z5dIvuYyqBWNGAgyn7tbaw.png"/></div></figure><figure class="mu kn on mw mx my mz paragraph-image"><img src="../Images/132f6508f3ab608efca57ecdc9182ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*Cmwdy783XqZx8lXkMgsINw.png"/></figure><figure class="mu kn oo mw mx my mz paragraph-image"><img src="../Images/78a8a347cc9788ff36d61e5e7fb7807e.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*6XpFrlyoXbwl4uYPzXObhw.png"/><p class="ku kv gj gh gi kw kx bd b be z dk op di oq nd translated"><strong class="bd ky">“梵高《星夜》风格的埃菲尔铁塔画”，</strong>作者图片</p></figure></div><h2 id="9d27" class="ne lx it bd ly nf ng dn mc nh ni dp mg li nj nk mi lm nl nm mk lq nn no mm np bi translated">一幅色彩缤纷的新英格兰风景画</h2><div class="kj kk kl km gt ab cb"><figure class="mu kn nw mw mx my mz paragraph-image"><img src="../Images/bbf7e5d92bf2427d29fe4821acd6ae57.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*Hm9_wTHGdT8TkR7yXd7EPg.png"/></figure><figure class="mu kn nx mw mx my mz paragraph-image"><img src="../Images/cf3dcff25b9764aaba627ed388da0f13.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*1piqNm_t-126EvNIg2espg.png"/><p class="ku kv gj gh gi kw kx bd b be z dk ny di nz nd translated"><strong class="bd ky">“色彩缤纷的新英格兰风景画”，</strong>作者图片</p></figure></div></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="2183" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae lv" href="https://robgon.medium.com/membership" rel="noopener">成为会员</a>，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>