<html>
<head>
<title>Mixed Precision Training — Less RAM, More Speed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">混合精确训练—内存更少，速度更快</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mixed-precision-training-less-ram-more-speed-e0d5ebd0c1d1#2022-09-26">https://towardsdatascience.com/mixed-precision-training-less-ram-more-speed-e0d5ebd0c1d1#2022-09-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="dd0f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">最佳化</h2><div class=""/><div class=""><h2 id="88d5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">用两行代码加速你的模型</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/084ae95474ad292a98f3d07397e79ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x6FsM9GQbEpcBd6Czw6sKg.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="https://thetestspecimen.com" rel="noopener ugc nofollow" target="_blank">作者</a></p></figure><p id="b7bb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">对于大型复杂模型，尽可能减少模型训练时间并有效利用可用硬件至关重要。即使每个批次或时期的小增益也是非常重要的。</strong></p><p id="5e3f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">混合精度训练既可以显著降低GPU RAM的使用，也可以加快训练过程本身，而不会损失结果的精度。</strong></p><p id="cf20" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">本文将展示(通过代码示例)实际可以获得的收益，同时还将介绍在您自己的模型中使用混合精度训练的要求。</strong></p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><h1 id="5518" class="ml mm it bd mn mo mp mq mr ms mt mu mv ki mw kj mx kl my km mz ko na kp nb nc bi translated">介绍</h1><p id="e0ba" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">本文的前半部分旨在概述什么是混合精度，以及何时、为什么以及如何使用它。</p><p id="47b9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">第二部分是对一组虚拟图像进行“正常”和混合精度训练的比较结果。这些图像通过TensorFlow中的多层Conv2D神经网络进行训练，RAM使用和执行速度都受到全程监控。</p><p id="8711" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><strong class="lk jd">与比较相关的所有代码都可以在colab笔记本上找到</strong></p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/mixed_precision_training.ipynb"><div class="gh gi ni"><img src="../Images/e3c494d78254a53189d50acf0675d635.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*0cSi95lq5JxmVAlk4PCpug.jpeg"/></div></a></figure><h1 id="8630" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">混合精度到底是什么？</h1><p id="cf31" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">在我们深入什么是混合精度之前，在这个特定的上下文中，当我们说“精度”时，概述一下我们指的是什么可能是一个好主意。</p><p id="0956" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这种情况下，精度基本上是指浮点数如何存储，即它在内存中占用多少空间。内存占用越小，数字越不准确。基本上有三种选择:</p><ol class=""><li id="41f7" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md nt nu nv nw bi translated">半精度— 16位(float16) —用于表示数字的低级存储，低精度</li><li id="0efe" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">单精度— 32位(float32) —用于表示数字的中等存储水平，中等精度</li><li id="a774" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">双精度— 64位(float64) —用于表示数字的高级存储，高精度</li></ol><p id="1a73" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">通常使用机器学习/深度学习和神经网络，您将处理单精度32位浮点数。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oc"><img src="../Images/93a525ca7dd7bfefeb32da365cb2b463.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dqMuSU3rkrXzi4beoEZpZQ.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">来自<a class="ae lh" href="https://pixabay.com//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=6223513" rel="noopener ugc nofollow" target="_blank">像素库</a>的<a class="ae lh" href="https://pixabay.com/users/inspiredimages-57296/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=6223513" rel="noopener ugc nofollow" target="_blank">灵感图像</a></p></figure><p id="78b3" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，在几乎所有情况下，<strong class="lk jd">计算</strong>都可以使用16位浮点数而不是32位浮点数来运行，<strong class="lk jd">不会降低模型的精度。</strong></p><h2 id="9942" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">混合精度</h2><p id="9295" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">理想且最简单的解决方案是混合使用16位和32位浮点数。使用较低精度的16位浮点数可以尽可能快地运行计算，然后输入和输出可以存储为32位浮点变量，以确保保持较高的精度，并且输出没有兼容性问题。</p><p id="7325" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这种组合被称为“混合精度”。</p><h1 id="a7e9" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">为什么我应该使用混合精度？</h1><p id="963a" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">有两个主要原因:</p><ol class=""><li id="fc66" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md nt nu nv nw bi translated">GPU RAM的使用会有很大的提升。差别可能是GPU RAM利用率降低50%</li><li id="ca46" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">运行模型所需的时间可能会显著加快</li></ol><p id="c2e6" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在TensorFlow中使用混合精度可以:</p><blockquote class="oo op oq"><p id="e036" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">在现代GPU上性能提高3倍以上，在TPU上性能提高60%</p><p id="5dcf" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> -tensorflow.org </a></p></blockquote><p id="c2b4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">单单RAM使用量的减少就是一件大事。这将允许利用更大的批量，或者为在相同的硬件上实现更大和更密集的模型打开大门。</p><p id="8956" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在本文后面的比较中，我们当然会看到这两个因素的实际结果。</p><h1 id="c2e2" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">使用混合精度有什么要求？</h1><p id="403e" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">要使混合精度训练成为一项优势，您需要具备以下条件之一:</p><ol class=""><li id="55c0" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md nt nu nv nw bi translated">计算兼容性为7.0或更高的Nvidia GPU(你可以在我的上一篇文章<a class="ae lh" rel="noopener" target="_blank" href="/how-to-pick-the-best-graphics-card-for-machine-learning-32ce9679e23b">这里</a>中获得更多关于“计算兼容性”以及为什么选择Nvidia的详细信息。)</li><li id="6973" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md nt nu nv nw bi translated">TPU(张量处理单元)</li></ol><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ov"><img src="../Images/15b4857c82bda568716a29a827e4dc30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-_fQn1kqmzH9BDVfb7wrw.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@nanadua11?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">娜娜杜瓦</a>在<a class="ae lh" href="https://unsplash.com/s/photos/nvidia?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="2a04" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然你可以使用其他GPU的混合精度，它会运行。如果没有上面详述的项目，你将不会获得任何真正的速度提高。然而，如果你只是想增加内存的使用，那么还是值得的。</p><blockquote class="oo op oq"><p id="992e" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">旧的GPU使用混合精度不会带来数学性能优势，但是节省内存和带宽可以实现一些加速。</p><p id="af56" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">-张量流或</a> g</p></blockquote><h1 id="60ef" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">什么时候应该使用混合精度？</h1><p id="e92d" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">这个问题的简单答案是几乎所有的时间，因为在大多数情况下优点大大超过缺点。</p><p id="947b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">唯一要注意的是，如果你的模型相对简单和小，你可能不会意识到差异。模型越大越复杂，混合精度的优势就越显著。</p><h1 id="5fb6" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">如何使用混合精度？</h1><p id="0146" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">在TensorFlow中，这非常容易，我对PyTorch不太熟悉，但我无法想象实现起来会有多难。</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="7a20" class="od mm it ox b gy pb pc l pd pe">from tensorflow.keras import mixed_precision<br/>mixed_precision.set_global_policy('mixed_float16')</span></pre><p id="861c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">…就是这样。</p><p id="0ca8" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对上述内容的唯一警告是，您应该确保模型的输入和输出总是浮动的32。无论如何，输入都可能在float32中，但是为了确保您可以隐式地应用dtype。例如:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="be62" class="od mm it ox b gy pb pc l pd pe">images = tf.random.uniform(input_shape, minval=0.0, maxval=1.0, seed=SEED, dtype=tf.float32)</span></pre><p id="f0e4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了确保模型的输出在float32中，您可以将模型最后一层的激活分离出来。例如:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="5093" class="od mm it ox b gy pb pc l pd pe"># Simple layer stack using the funcitonal API with separated activation layer as output<br/>​<br/>layer1 = tf.keras.layers.Conv2D(128,2)(inputs)<br/>layer2 = tf.keras.layers.Conv2D(128,1)(layer1)<br/>layer3 = tf.keras.layers.Conv2D(128,1)(layer2)<br/>layer4 = tf.keras.layers.Flatten()(layer3)<br/>layer5 = tf.keras.layers.Dense(1)(layer4)<br/>output_layer = tf.keras.layers.Activation('sigmoid', dtype=tf.float32)(layer5)</span></pre><h2 id="1488" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">自定义训练循环</h2><p id="f1c0" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">将混合精度应用到您的模型真的很简单，如前一节所述。</p><p id="1a29" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">但是，如果您因为正在实施自己的训练循环而没有使用“model.fit ”,那么还需要注意几个步骤，因为您必须手动处理损失比例。</p><blockquote class="oo op oq"><p id="d3ea" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">如果您使用<code class="fe pf pg ph ox b"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit" rel="noopener ugc nofollow" target="_blank">tf.keras.Model.fit</a></code>，损失缩放已经为您完成，因此您不必做任何额外的工作。如果您使用定制的训练循环，您必须显式地使用特殊的优化器包装器<code class="fe pf pg ph ox b"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/LossScaleOptimizer" rel="noopener ugc nofollow" target="_blank">tf.keras.mixed_precision.LossScaleOptimizer</a></code>，以便使用损失缩放。</p><p id="b907" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> -tensorflow.org </a></p></blockquote><p id="9142" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这一点很重要，因为与float32相比，float16的可用存储空间更小，因此其值容易“下溢”和“上溢”。所有这一切的基本意思是:</p><blockquote class="oo op oq"><p id="fd65" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">高于65504的值将溢出到无穷大，低于6.0×108的值将下溢到零。</p><p id="c7f1" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> -tensorflow.org </a></p></blockquote><p id="7762" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">为了避免这种情况，一种称为损失比例的策略被用来缓解这一问题。为了更深入的了解，我建议看一看tensorflow.org上的<a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank">混合精度指南</a>。</p><h2 id="7e94" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">TPUs</h2><p id="a230" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">如果你足够幸运，能够使用专用的TPU(张量处理单元)，那么值得注意的是，你应该使用数据类型“bfloat16”而不是“float16”。</p><p id="766c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">实现起来并不困难，也不会遇到上一节提到的损失比例问题。</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="74e8" class="od mm it ox b gy pb pc l pd pe">from tensorflow.keras import mixed_precision<br/>mixed_precision.set_global_policy('mixed_bfloat16')</span></pre><h1 id="ef8f" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">实际例子</h1><p id="862a" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">作为潜在收益的一个例子，我提供了一个colab笔记本:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><a href="https://colab.research.google.com/github/thetestspecimen/notebooks/blob/main/mixed_precision_training.ipynb"><div class="gh gi ni"><img src="../Images/e3c494d78254a53189d50acf0675d635.png" data-original-src="https://miro.medium.com/v2/resize:fit:234/format:webp/1*0cSi95lq5JxmVAlk4PCpug.jpeg"/></div></a></figure><p id="e28a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这样你就能看到它的好处。笔记本的开头有一些与您必须使用的GPU相关的注意事项，因此请确保您阅读了这些内容，以充分利用笔记本。</p><p id="44dc" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在下面的小节中，我将回顾笔记本中的结果。</p><h2 id="9150" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">数据</h2><p id="b2ed" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">数据是被格式化成一批图像形状的随机均匀噪声。</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="800e" class="od mm it ox b gy pb pc l pd pe"># create dummy images based on random data<br/>SEED = 12<br/>tf.random.set_seed(SEED);<br/>total_images = 800<br/>input_shape = (total_images, 256, 256, 3) # (batch, height, width, channels)<br/>images = tf.random.uniform(input_shape, minval=0.0, maxval=1.0, seed=SEED, dtype=tf.float32)</span></pre><p id="92a4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">需要注意的是，我已经显式地将数据类型设置为float32。在这种情况下，这没有什么区别，因为这是该函数的默认值。然而，根据数据的来源，情况可能并不总是如此。</p><p id="f5e9" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">一个示例图像如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6edc704513a3fc01ff1e564dceb87c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*SxuUpw9OImBvMAjNIZZMEw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">图片作者<a class="ae lh" href="https://thetestspecimen.com" rel="noopener ugc nofollow" target="_blank">作者</a></p></figure><p id="d290" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我还创建了随机的二进制标签，以便模型可以是二进制分类模型。</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="5140" class="od mm it ox b gy pb pc l pd pe">labels = np.random.choice([0, 1], size=(total_images,), p=[0.5,0.5])</span></pre><h2 id="94f4" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">模型</h2><p id="45db" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">该模型被选择为简单，但足够复杂，以使用合理数量的RAM，并有一个体面的批处理运行时间。这确保了混合精度和“正常”运行之间的任何差异都是可区分的。模型的层次如下:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="e808" class="od mm it ox b gy pb pc l pd pe">layer1 = tf.keras.layers.Conv2D(128,2)<br/>layer2 = tf.keras.layers.Conv2D(128,1)<br/>layer3 = tf.keras.layers.Conv2D(128,1)<br/>layer4 = tf.keras.layers.Flatten()<br/>layer5 = tf.keras.layers.Dense(1)<br/>output_layer = tf.keras.layers.Activation('sigmoid',dtype=tf.float32)</span></pre><p id="beb4" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">再次注意，输出激活层被转换为float32。这对“正常”运行没有影响，但对混合精度运行至关重要。</p><h2 id="2be3" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">测试</h2><p id="993b" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">上一节提到的模型使用以下参数运行:</p><ul class=""><li id="358a" class="no np it lk b ll lm lo lp lr nq lv nr lz ns md pj nu nv nw bi translated">图像总数= 800</li><li id="75a5" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md pj nu nv nw bi translated">图像尺寸= 256 x 256</li><li id="3a26" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md pj nu nv nw bi translated">批量= 50</li><li id="46c1" class="no np it lk b ll nx lo ny lr nz lv oa lz ob md pj nu nv nw bi translated">纪元= 10</li></ul><h2 id="d09c" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">总运行时间和纪元运行时间</h2><p id="b6e5" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">然后使用timeit模块运行一次图像，以获得总的运行时间。</p><p id="cc3b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">还会打印纪元运行时间。</p><h2 id="b0a0" class="od mm it bd mn oe of dn mr og oh dp mv lr oi oj mx lv ok ol mz lz om on nb iz bi translated">GPU RAM使用情况</h2><p id="8696" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">要获取GPU RAM使用信息，使用以下函数:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="306f" class="od mm it ox b gy pb pc l pd pe">tf.config.experimental.get_memory_info('GPU:0')</span></pre><p id="b554" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这将输出当前和峰值GPU RAM使用情况。在每次运行之前，峰值使用被重置并与当前GPU RAM使用进行比较(因此它们应该是相同的)。然后在运行结束时，进行相同的比较。这允许计算运行期间实际使用的GPU RAM。</p><h1 id="74e3" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">结果呢</h1><p id="cc02" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">单精度(float32)型号:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="e453" class="od mm it ox b gy pb pc l pd pe">Epoch 1/10<br/>16/16 [==============================] - 10s 463ms/step - loss: 90.4716 - accuracy: 0.5038<br/>Epoch 2/10<br/>16/16 [==============================] - 8s 475ms/step - loss: 9.1019 - accuracy: 0.6625<br/>Epoch 3/10<br/>16/16 [==============================] - 8s 477ms/step - loss: 1.6142 - accuracy: 0.8737<br/>Epoch 4/10<br/>16/16 [==============================] - 8s 475ms/step - loss: 0.2461 - accuracy: 0.9488<br/>Epoch 5/10<br/>16/16 [==============================] - 8s 482ms/step - loss: 0.0486 - accuracy: 0.9800<br/>Epoch 6/10<br/>16/16 [==============================] - 8s 489ms/step - loss: 0.0044 - accuracy: 0.9975<br/>Epoch 7/10<br/>16/16 [==============================] - 8s 494ms/step - loss: 7.3721e-05 - accuracy: 1.0000<br/>Epoch 8/10<br/>16/16 [==============================] - 8s 497ms/step - loss: 1.4208e-05 - accuracy: 1.0000<br/>Epoch 9/10<br/>16/16 [==============================] - 8s 496ms/step - loss: 1.2936e-05 - accuracy: 1.0000<br/>Epoch 10/10<br/>16/16 [==============================] - 8s 490ms/step - loss: 1.1361e-05 - accuracy: 1.0000<br/>​<br/>RAM INFO:<br/>​<br/>Current: 0.63 GB, Peak: 9.18 GB, USED MEMORY FOR RUN: 8.55 GB<br/>​<br/>TIME TO COMPLETE RUN: 79.73</span></pre><p id="5242" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">混合精度(mixed_float16)模型:</p><pre class="ks kt ku kv gt ow ox oy oz aw pa bi"><span id="eee9" class="od mm it ox b gy pb pc l pd pe">Epoch 1/10<br/>16/16 [==============================] - 15s 186ms/step - loss: 71.8095 - accuracy: 0.5025<br/>Epoch 2/10<br/>16/16 [==============================] - 3s 184ms/step - loss: 15.2121 - accuracy: 0.6000<br/>Epoch 3/10<br/>16/16 [==============================] - 3s 182ms/step - loss: 4.4640 - accuracy: 0.7900<br/>Epoch 4/10<br/>16/16 [==============================] - 3s 183ms/step - loss: 1.1157 - accuracy: 0.9187<br/>Epoch 5/10<br/>16/16 [==============================] - 3s 183ms/step - loss: 0.2525 - accuracy: 0.9600<br/>Epoch 6/10<br/>16/16 [==============================] - 3s 181ms/step - loss: 0.0284 - accuracy: 0.9925<br/>Epoch 7/10<br/>16/16 [==============================] - 3s 182ms/step - loss: 0.0043 - accuracy: 0.9962<br/>Epoch 8/10<br/>16/16 [==============================] - 3s 182ms/step - loss: 7.3278e-06 - accuracy: 1.0000<br/>Epoch 9/10<br/>16/16 [==============================] - 3s 182ms/step - loss: 2.4797e-06 - accuracy: 1.0000<br/>Epoch 10/10<br/>16/16 [==============================] - 3s 182ms/step - loss: 2.5154e-06 - accuracy: 1.0000<br/>​<br/>RAM INFO:<br/>​<br/>Current: 0.63 GB, Peak: 4.19 GB, USED MEMORY FOR RUN: 3.57 GB<br/>​<br/>TIME TO COMPLETE RUN: 42.16</span></pre><p id="bb2e" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我认为这是相当确凿的:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pk"><img src="../Images/eaae87f1654d17153a04c33ad1a2403a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-YRgVSXpPaj7YVcu8bCo5w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">表作者<a class="ae lh" href="https://thetestspecimen.com" rel="noopener ugc nofollow" target="_blank">作者</a></p></figure><p id="caba" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在上述结果中，您可能会注意到，混合精度运行的初始历元比后续历元要长5倍，甚至比float32运行还要长。这是正常的，这是由于TensorFlow在学习过程开始时进行了优化。然而，即使有这个初始赤字，混合精度模型也不需要很长时间就可以赶上并超过float32模型。</p><p id="1ecb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">混合精度的较长初始历元也有助于说明为什么较小的模型可能看不到好处，因为需要克服初始开销才能实现混合精度的优势。</p><p id="4bf0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这也恰好是过度拟合的一个很好的例子。这两种方法都成功地在带有完全随机标签的完全随机数据上实现了100%的准确率！</p><h1 id="de45" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">今后</h1><p id="0e07" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">较低精度计算的趋势似乎越来越明显，随着Nvidia最新一代GPU的出现，现在已经有了诸如<a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_tensor_float_32_execution" rel="noopener ugc nofollow" target="_blank"> TensorFloat-32 </a>这样的实现，它们:</p><blockquote class="oo op oq"><p id="0e09" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">在某些float32操作中自动使用较低精度的数学运算，如<code class="fe pf pg ph ox b"><a class="ae lh" href="https://www.tensorflow.org/api_docs/python/tf/linalg/matmul" rel="noopener ugc nofollow" target="_blank">tf.linalg.matmul</a></code>。</p><p id="0f3d" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> -tensorflow.org </a></p></blockquote><p id="9461" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">还有一种情况是:</p><blockquote class="oo op oq"><p id="4a23" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated">即使默认的数据类型策略为float32，TPU也会在bfloat16中执行某些操作</p><p id="e31b" class="li lj or lk b ll lm kd ln lo lp kg lq os ls lt lu ot lw lx ly ou ma mb mc md im bi translated"><a class="ae lh" href="https://www.tensorflow.org/guide/mixed_precision" rel="noopener ugc nofollow" target="_blank"> -tensorflow.org </a></p></blockquote><p id="50fb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">因此，随着时间的推移，实际上可能没有必要直接实现混合精度，因为这一切都将得到妥善处理。</p><p id="3edb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">然而，我们还没有到那一步，所以现在仍然值得努力考虑利用混合精确训练。</p><h1 id="8d71" class="ml mm it bd mn mo nj mq mr ms nk mu mv ki nl kj mx kl nm km mz ko nn kp nb nc bi translated">结论</h1><p id="7de7" class="pw-post-body-paragraph li lj it lk b ll nd kd ln lo ne kg lq lr nf lt lu lv ng lx ly lz nh mb mc md im bi translated">得出的唯一结论是，混合精度是一个加速训练的优秀工具，但更重要的是释放GPU RAM。</p><p id="b692" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">希望本文能帮助您理解混合精度的含义，我鼓励您试用一下colab笔记本，看看它是否符合您的特定要求，并感受一下它可能带来的好处。</p></div><div class="ab cl me mf hx mg" role="separator"><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj mk"/><span class="mh bw bk mi mj"/></div><div class="im in io ip iq"><p id="532b" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你觉得这篇文章有趣或有用，记得关注我，或者<a class="ae lh" href="https://medium.com/@maclayton/subscribe" rel="noopener">注册我的时事通讯</a>获取更多类似的内容。</p><p id="d62f" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你还没有，你也可以考虑<a class="ae lh" href="https://medium.com/@maclayton/membership" rel="noopener">订阅媒体</a>。你的会员费不仅直接支持我，也支持你所阅读的其他作家。你还可以完全不受限制地访问媒体上的每个故事。</p><p id="b4cb" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">使用我的推荐链接注册会给我一点回扣，对你的会员资格没有影响，所以如果你选择这样做，谢谢你。</p><div class="pl pm gp gr pn po"><a href="https://medium.com/@maclayton/membership" rel="noopener follow" target="_blank"><div class="pp ab fo"><div class="pq ab pr cl cj ps"><h2 class="bd jd gy z fp pt fr fs pu fu fw jc bi translated">加入我的介绍链接媒体-迈克克莱顿</h2><div class="pv l"><h3 class="bd b gy z fp pt fr fs pu fu fw dk translated">阅读迈克·克莱顿(以及媒体上成千上万的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="pw l"><p class="bd b dl z fp pt fr fs pu fu fw dk translated">medium.com</p></div></div><div class="px l"><div class="py l pz qa qb px qc lb po"/></div></div></a></div></div></div>    
</body>
</html>