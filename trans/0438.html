<html>
<head>
<title>MLOps for Batch Processing: Running Airflow on GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于批处理的MLOps:在GPU上运行气流</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mlops-for-batch-processing-running-airflow-on-gpus-dc94367869c6#2022-02-17">https://towardsdatascience.com/mlops-for-batch-processing-running-airflow-on-gpus-dc94367869c6#2022-02-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1748" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">阿帕奇气流限制的简单变通方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f14b07da2237dad3aea0a33927b88ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0abk6CVBpJsx1CG_TRXGEQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://www.pexels.com/photo/aerial-view-of-cargo-ship-1554646/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae kv" href="https://www.pexels.com/@tomfisk?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">汤姆·菲斯克</a>的照片。</p></figure><p id="a8a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">有很多MLOps平台本身就处理GPU访问，但我们喜欢我们的一些任务的简单性。本文着眼于一种允许同时使用PyTorch和Tensorflow堆栈的方法。</em></p><p id="b7ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">已经有一些关于这种类型的实现的文章，但是</em> <a class="ae kv" href="https://medium.com/fandom-engineering/gpu-based-workloads-as-a-part-of-airflow-dags-1d856418b529" rel="noopener"> <em class="ls">为Batch </em> </a> <em class="ls">创建自己的AWS AMI或者使用其他依赖于特定于云的平台的方法并不是解决这个看似简单的问题的最佳方式。</em></p><h1 id="a2fd" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">背景和动机</h1><p id="406c" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">如果你已经花了很多时间将你的模型打包到一个漂亮的小容器中，并将它们绑定到你的CI/CD管道，那么偶尔你的模型会需要原始的GPU能力。对于大批量作业来说尤其如此，这是我们在<a class="ae kv" href="http://auditmap.ai" rel="noopener ugc nofollow" target="_blank"> AuditMap </a>内部审计和企业风险客户中经常看到的情况。此外，<a class="ae kv" href="https://lemay.ai" rel="noopener ugc nofollow" target="_blank">我们</a>在大多数NLP项目中使用大量基于BERT的模型进行数据预处理和清理，因此在GPU上进行批处理推理工作很有意义。</p><p id="6b95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，有一些现成的限制，我们将在本文中讨论和解决。</p><h2 id="e564" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">气流</h2><p id="4c1b" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated"><a class="ae kv" href="https://airflow.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Airflow </a>是一个开源的任务调度器和工作流管理器。与端到端MLOps解决方案相反，它只做一件事，即运行良好的作业。Airflow自带多种任务类型，包括<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html" rel="noopener ugc nofollow" target="_blank"> PythonOperator </a>和<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/_api/airflow/providers/docker/operators/docker/index.html" rel="noopener ugc nofollow" target="_blank"> DockerOperator </a>。这些特定的操作符意味着您可以分别运行Python函数或旋转容器。</p><p id="7918" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这些条件下，相信DockerOperator能够提供所有本机Docker功能(包括目标设备分配)是明智的。然而，截至2021年10月，<a class="ae kv" href="https://github.com/apache/airflow/pull/13541" rel="noopener ugc nofollow" target="_blank">仍没有关于该特定能力的重大开发活动</a>。现在，关于<a class="ae kv" href="https://github.com/apache/airflow" rel="noopener ugc nofollow" target="_blank"> Airflow Github页面</a>上的<a class="ae kv" href="https://github.com/apache/airflow/pull/13541#issuecomment-935688549" rel="noopener ugc nofollow" target="_blank"> <em class="ls"> device_request </em>参数</a>已经有了很多讨论，但是无论是他们的<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/_api/airflow/providers/docker/operators/docker/index.html" rel="noopener ugc nofollow" target="_blank">文档</a>还是他们的<a class="ae kv" href="https://github.com/apache/airflow/blob/d87762b3cc8170b78b0dac5c1ff932df913346fe/airflow/providers/docker/operators/docker.py#L47" rel="noopener ugc nofollow" target="_blank">源代码</a>都没有启用这个特定的参数。</p><p id="8c74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我仍然希望我的团队在GPU上运行气流Dag，所以我们在这里。</p><h2 id="f79b" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">变通办法</h2><p id="4ebe" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">虽然Airflow已经在内部使用了<a class="ae kv" href="https://github.com/apache/airflow/issues/9492#issuecomment-648765141" rel="noopener ugc nofollow" target="_blank">docker-py</a>，但是我们将把它作为一个外部依赖项来安装，并通过Python以编程方式调用Docker守护进程。从那里，外部容器将在目标GPU上以单次运行脚本的形式执行它们的代码。</p><p id="e88a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这需要一个包含python脚本的外部容器，该容器可以访问目标数据(下面将详细介绍)。然而，考虑到一些结构上的最佳实践，我们现在有了一个可以作为气流任务运行的容器。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/c4aff1710633067f51862a1be91058ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AlxKFXgcMKkxz6HjC_6TJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">呼叫逻辑的图表视图。</p></figure><p id="9583" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我们正在做的是<strong class="ky ir">在一个外部容器中运行一个Python脚本，这个脚本本身被一个Airflow Python任务</strong>调用。这避开了Airflow的DockerOperator限制，并从本机Docker引擎进行调用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自<a class="ae kv" href="https://giphy.com/gifs/spotify-play-streaming-SbtWGvMSmJIaV8faS8" rel="noopener ugc nofollow" target="_blank"> Giphy </a>的<a class="ae kv" href="https://giphy.com/spotify/" rel="noopener ugc nofollow" target="_blank"> Spotify </a>拍摄的《侏罗纪公园心灵爆炸》GIF。</p></figure><h1 id="bf57" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">示例:基本DAG</h1><p id="e7db" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">为了让我们熟悉一下，下面是一个简单的<em class="ls"> nvidia-smi </em>测试，它将在一个外部容器中运行(在本例中，<a class="ae kv" href="https://hub.docker.com/layers/tensorflow/tensorflow/2.7.0-gpu/images/sha256-fc5eb0604722c7bef7b499bb007b3050c4beec5859c2e0d4409d2cca5c14d442?context=explore" rel="noopener ugc nofollow" target="_blank"><em class="ls">tensor flow:2 . 7 . 0-GPU</em></a>):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h2 id="e8ef" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">让它工作</h2><p id="2e51" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">假设您的起点是Airflow的<a class="ae kv" href="https://github.com/apache/airflow/blob/main/docs/apache-airflow/start/docker-compose.yaml" rel="noopener ugc nofollow" target="_blank"><em class="ls">docker-compose . YAML</em></a>文件，下面是要做的更改:</p><ul class=""><li id="30dd" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">添加docker-py作为PIP要求:</li></ul><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="2e60" class="mq lu iq np b gy nt nu l nv nw">x-airflow-common:<br/>...<br/>  environment:<br/>  ...<br/>    _PIP_ADDITIONAL_REQUIREMENTS: <br/>    ${_PIP_ADDITIONAL_REQUIREMENTS:-<strong class="np ir">docker==5.0.3</strong>}</span></pre><ul class=""><li id="554e" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">安装包含Docker插座的卷:</li></ul><pre class="kg kh ki kj gt no np nq nr aw ns bi"><span id="40d4" class="mq lu iq np b gy nt nu l nv nw">x-airflow-common:<br/>...<br/>  volumes:<br/>  ...<br/><strong class="np ir">    - /var/run/docker.sock:/var/run/docker.sock</strong></span></pre><p id="fe85" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">(注意:如果您最终使用DockerOperator，那么它可以作为一个参数包含进来。)</em></p><ul class=""><li id="1fa9" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr nk nl nm nn bi translated">确保设置您的<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user" rel="noopener ugc nofollow" target="_blank"> AIRFLOW_UID </a>。</li></ul><p id="6969" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从那里开始，假设有适当的隧道并且没有端口冲突，您可以运行<code class="fe nx ny nz np b">docker-compose up</code>来让<em class="ls">气流</em>运行。主web服务器现在运行在端口8080上。如果您从我们的<a class="ae kv" href="https://github.com/lemay-ai/airflow_gpu" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中获取了代码，那么将会出现两个新的Dag:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/c49320a9fb57cd908b17f0b04b41e559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*NN24iFeKBDANMGakFkDdig.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作为我们回购的一部分。</p></figure><p id="14d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">运行<code class="fe nx ny nz np b">gpu_test</code> DAG给了我们很多信心。</p><h2 id="bee8" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">结果</h2><p id="27f4" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">正如所料，我们有一个不错的DAG运行成功和一个完成日志与一个<em class="ls"> nvidia-smi </em>打印输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/f5799b780d93bd371f7bc5d74fe511ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fjr09Z0ta-KlyJmlSJA1DA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">成功的DAG运行图。太美了。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/1eac77855ee833d3ef390f0773a3ac4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*35fhi4Lwz0ldMDQQXM_DYQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">nvidia-smi从check_gpu()调用中记录。</p></figure><h1 id="db0c" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">高级脚本</h1><p id="4239" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">下一步是创建一个容器，它可以:</p><ol class=""><li id="d9c4" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr od nl nm nn bi translated">持有生产模型；</li><li id="d44a" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr od nl nm nn bi translated">运行推理代码；和</li><li id="4a3f" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr od nl nm nn bi translated">加载目标数据并保存结果。</li></ol><p id="62dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您从容器化设计开始，那么将所有推理任务分配给一个脚本会变得更容易。让我们创建一个简单的多任务推理脚本，它可以接受参数。我们将从<a class="ae kv" href="https://huggingface.co/Helsinki-NLP" rel="noopener ugc nofollow" target="_blank"> Helsinki-NLP </a>创建一个简单的翻译管道。我们还将使用来自<a class="ae kv" href="https://www.kaggle.com/ldorigo/full-sentences-only" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>的一些样本数据来启动测试过程。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="75c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个脚本现在可以执行一个带有参数的推理任务。让我们更新我们的DAG来进行呼叫:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h2 id="56a9" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">结果</h2><p id="2fdd" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">成功！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/efdee7d28beecf18e7962965cf65fec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AH4GQmMESkT6Gx-wrpAYMw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">又一次成功的气流运行。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/bee0293e79a5894f31fba78106837db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wM7BsuCzn5uBpqUAfXkabg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">确认成功运行的日志。</p></figure><p id="bce2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个操作过程中，GPU确实受到了影响:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8de8a8c95670f5cc45371c9d650fe3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*N2m2Ey9dPqxymNqWMU05bQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">nvidia-smi打印输出。</p></figure><h1 id="dfa6" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">后续步骤</h1><p id="04d0" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">在成功运行之前，您需要清理一些基础设施项目:</p><ol class=""><li id="9446" class="nf ng iq ky b kz la lc ld lf nh lj ni ln nj lr od nl nm nn bi translated">映射数据文件夹和数据源。</li><li id="85a6" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr od nl nm nn bi translated">加载正确的模型。</li><li id="6869" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr od nl nm nn bi translated">确保nvidia-docker 和GPU访问在你的目标机器上可用。</li></ol><p id="efad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还应该使用MLFlow、PMML或<a class="ae kv" href="https://arxiv.org/abs/2201.00162" rel="noopener ugc nofollow" target="_blank">任何其他高质量工具</a>以编程方式添加模型，作为您的CI/CD管道的一部分。</p><h1 id="cd51" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">讨论</h1><p id="ee28" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">虽然有点复杂，但这种设计模式允许各种推理活动之间的大量可互换性。它还允许将模型作为CI/CD/MLOps管道的一部分进行分离，因为容器在启动时将始终采用最新的模型(如果模型是从外部卷加载的)。</p><p id="a987" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">防止GPU资源争用需要一点警惕，但我们在BERT模型上的经验告诉我们，您可以在每个模型6–8gb的内存预算下轻松运行多个模型。(但是，确保为Tensorflow 设置<a class="ae kv" href="https://www.tensorflow.org/guide/gpu" rel="noopener ugc nofollow" target="_blank">增量内存增长。)</a></p><h1 id="64c1" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">笔记</h1><ul class=""><li id="5576" class="nf ng iq ky b kz ml lc mm lf om lj on ln oo lr nk nl nm nn bi translated">我们确实在一个<a class="ae kv" href="https://hub.docker.com/layers/tensorflow/tensorflow/2.7.0-gpu/images/sha256-fc5eb0604722c7bef7b499bb007b3050c4beec5859c2e0d4409d2cca5c14d442?context=explore" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>容器中运行了一个Torch示例。这是因为Tensorflow容器倾向于非常整洁地预安装CUDA库。</li><li id="45c3" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated">确保根据<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html" rel="noopener ugc nofollow" target="_blank">气流安装说明</a>设置您的<a class="ae kv" href="https://airflow.apache.org/docs/apache-airflow/stable/start/docker.html#setting-the-right-airflow-user" rel="noopener ugc nofollow" target="_blank">气流_流体参数</a>。</li><li id="0497" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated">Github资源库可从这里获得:<a class="ae kv" href="https://github.com/lemay-ai/airflow_gpu" rel="noopener ugc nofollow" target="_blank">https://github.com/lemay-ai/airflow_gpu</a></li></ul><p id="d9c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">这篇文章的灵感来源于</em><a class="ae kv" href="https://stackoverflow.com/users/7091333/aquater" rel="noopener ugc nofollow" target="_blank"><em class="ls">Aquater</em></a><em class="ls">上的</em><a class="ae kv" href="https://stackoverflow.com/questions/69572705/how-to-create-an-airflow-task-where-i-start-a-docker-container-with-gpu-support" rel="noopener ugc nofollow" target="_blank"><em class="ls">stack overflow</em></a><em class="ls">。干得好阿奎特。</em></p><p id="a25b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">流水线作业快乐！</p><p id="d78f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">马特。</p><p id="9713" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">如果您对本文或我们的AI咨询框架有其他问题，请通过</em><a class="ae kv" href="https://www.linkedin.com/in/mnlemay/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="ls">LinkedIn</em></strong></a><strong class="ky ir"><em class="ls"/></strong><em class="ls">或通过</em> <a class="ae kv" href="mailto:matt@lemay.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> <em class="ls">电子邮件</em> </strong> </a> <em class="ls">联系。</em></p><h1 id="5cce" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">你可能喜欢的其他文章</h1><ul class=""><li id="21ab" class="nf ng iq ky b kz ml lc mm lf om lj on ln oo lr nk nl nm nn bi translated">数据集偏差:制度化的歧视还是足够的透明度？</li><li id="044b" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated"><a class="ae kv" href="https://medium.com/@lsci/how-does-artificial-intelligence-create-value-bec14c785b40" rel="noopener">人工智能如何创造价值？</a></li><li id="f50e" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/implementing-a-corporate-ai-strategy-a64e641384c8">实施企业人工智能战略</a></li><li id="fb02" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/outlier-aware-clustering-beyond-k-means-76f7bf8b4899">离群点感知聚类:超越K均值</a></li><li id="d898" class="nf ng iq ky b kz oe lc of lf og lj oh ln oi lr nk nl nm nn bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/rorschach-tests-for-deep-learning-image-classifiers-68c019fcc9a9">深度学习图像分类器的罗夏测试</a></li></ul></div></div>    
</body>
</html>