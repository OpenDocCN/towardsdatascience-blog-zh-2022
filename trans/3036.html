<html>
<head>
<title>ML Model Deployment Strategies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML模型部署策略</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-model-deployment-strategies-72044b3c1410#2022-07-04">https://towardsdatascience.com/ml-model-deployment-strategies-72044b3c1410#2022-07-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/18f7a98731e8116b8bf1fb7b3df178f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pKqERamABx17nwfSGeReQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">让我们制定战略(图片由作者提供)</p></figure><div class=""/><div class=""><h2 id="04d0" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">ML工程师部署策略图解指南</h2></div><p id="4f6d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">你好。</p><p id="1b6e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这篇文章是为那些想了解ML模型在生产中是如何部署的，以及在部署这些模型时可以使用什么策略的人准备的。</p><p id="e913" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我将举例说明部署ML模型的一般方法，部署时可以采用的不同策略，以及这些策略通常在哪里实现。每个数据科学团队都有不同的需求，所以要有所保留。</p><p id="77f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们开始吧。</p><h2 id="4f2a" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">了解ML模型部署</h2><p id="6efd" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">与软件或应用程序部署不同，模型部署是一种不同的野兽。一个简单的ML模型生命周期有几个阶段，如范围界定、数据收集、数据工程、模型训练、模型验证、部署和监控。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mo"><img src="../Images/a167052a6ce4bd5da48704c5cfc7b306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3KN_-nb0DXEEvE0jOLMV3w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">ML生命周期(图片由作者提供)</p></figure><p id="8a9f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当我们部署ML模型时，我们需要考虑一些因素，如:</p><p id="e6a8" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> 1。模型尺寸和包装— </strong>模型尺寸在我们计划如何包装中扮演着重要角色。较小的模型通常可以包装在FastAPI服务器中，并装入Docker容器中。然而，较大的模型可能需要在部署期间加载——它们可能从远程存储中取出，并通过模型服务器(如TFServing或TorchServer)运行。</p><p id="1733" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> 2。模型再培训和版本化— </strong>您再培训模型的频率会影响您的部署策略。你经常需要比较你的模特表演吗？您在生产中多久更新一次模型？您会在生产中维护不同版本的模型吗？</p><p id="a9f3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> 3。流量和请求路由— </strong>根据流量和模型类型，您必须决定是实时推理还是批量模型部署。您希望每个版本的模型分流多少流量？有多少用户可以访问特定的模型版本？</p><p id="955f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> 4。数据和概念漂移— </strong>在一段时间内，真实世界的数据不断变化，可能不会反映在模型中。比如说，购买力与工资的关系，工资可能每年或每月都在变化。或者消费者购买模式在新冠肺炎疫情期间如何变化，但模型大多依赖于历史数据。这影响了我们必须如何设计部署架构:我们应该重新培训和重新部署吗？我们现在应该只重新培训和展示模型吗？这个因素在数据科学团队的长期部署战略中发挥作用。</p><p id="cfc4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">记住这些因素，我们有大约六种模型部署的通用策略。这些方法大多借鉴自DevOps和UX的方法，在ML场景中非常适用。</p><p id="2a73" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">通常，在技术层面上在生产中部署模型涉及API端点网关、负载平衡器、虚拟机集群、服务层、某种形式的持久数据存储和模型本身。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/7df124ca5e933b0dfec000ed4e41c569.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hw6MkKbwstNM0filBOF73w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">通用模型部署(按作者列出的图像)</p></figure><p id="9503" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">部署策略通常在负载平衡器和服务级别进行配置，主要是配置路由和接收规则。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><p id="78c7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">让我们以动物识别和分类系统为例。<strong class="kw jg"> <em class="nb">我们从一个简单的猫-狗分类器开始。这将是我们的第一版模型。</em> </strong>假设我们已经训练了一个模型的副本来识别考拉，那么<strong class="kw jg"> <em class="nb">我们的版本2是一个猫-狗-考拉分类器</em> </strong>。我们将如何部署我们模型的新版本？</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/117eae8cf1d90db6af3cb7ab24efaf83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NcuAoTL8J4eF9_0eMmLAuw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">型号版本(按作者列出的图像)</p></figure><h1 id="32f1" class="nd lr jf bd ls ne nf ng lv nh ni nj ly kl nk km mb ko nl kp me kr nm ks mh nn bi translated">模型部署策略</h1><h2 id="595d" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated"><strong class="ak">大爆炸——重现</strong></h2><p id="075a" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">什么— </strong>这种部署形式是一种“从头开始”的部署方式。您必须为要部署的新部署拆除现有部署。</p><p id="1a2e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> WHERE — </strong>在开发环境中通常是可以接受的—您可以使用不同的配置根据需要多次重新创建部署。通常，部署管道会分解现有资源，并在其位置创建新的更新。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi no"><img src="../Images/417c01916e35fbe8c88e71ca7870b9ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4AQa9GlUlUvBKhp61zE96g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">重新创建部署(按作者创建映像)</p></figure><p id="e5f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种部署会导致一定程度的停机。在我们目前的组织ML开发速度下，这是不可接受的。</p><p id="ba40" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在我们的例子中，我们将用版本2替换版本1；这包括替换所有相关的基础设施和库设置。</p><h2 id="975c" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">滚动更新</h2><blockquote class="np nq nr"><p id="9d36" class="ku kv nb kw b kx ky kg kz la lb kj lc ns le lf lg nt li lj lk nu lm ln lo lp ij bi translated">他们看到我滚…他们讨厌…🎵</p></blockquote><p id="e428" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">什么— </strong>滚动更新包括逐个更新模型/应用程序的所有实例。假设你有4个吊舱的应用程序目前正在运行，你用一个新版本的模型激活了一个滚动更新。旧的豆荚一个接一个地被新的豆荚取代。这种方法没有停机时间。</p><p id="162e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> WHERE — </strong>当您希望用新版本快速更新整个产品线时，此选项非常有用。还允许您在需要时回滚到旧版本。主要用于团队需要测试新版本模型的测试或准备环境。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/7037d264654b2026e2b1c9e5e12d5e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5LJo9RVLn9QHxCBeW-PRNA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">滚动更新(按作者列出图像)</p></figure><p id="2bb7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">它通常不会是生产系统中的唯一实现，除非您只需要全面部署模型的特定版本。在我们的示例中，我们将只替换模型应用程序窗格，保持基础架构的其余部分不变。</p><h2 id="7737" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">🔵Blue/Green🟢</h2><p id="1812" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">什么— </strong>这种部署形式本质上是一种服务器交换。有两个相同的系统可用。用户请求被路由到其中一个系统，较新的更改和更新在另一个系统上完成。一旦更新经过测试和验证，用户的请求就会被发送到新的系统，从本质上来说，就是用新的系统替换旧的系统。</p><p id="384c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">其中— </strong>多用于应用或web app场景。也可以应用于模型部署，包括批处理和实时推理部署。基本上没有停机时间，因为我们只是将负载平衡器指向一组不同的机器。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/23294bc549bfc70852e84a2fb10af613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tyedoBVAujJzATYQq5IcKA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">蓝绿色部署(图片由作者提供)</p></figure><p id="4081" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">正如您在这里看到的，我们使用模型的更新版本创建了一个新的相同系统，然后将流量切换到新系统。</p><p id="0fdd" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">但是，我们必须考虑维护两个相同基础设施系统的成本。根据基础设施的规模和承受能力选择这种方法。</p><h2 id="d64e" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated"><strong class="ak">金丝雀</strong>🐦</h2><p id="bd35" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">什么— </strong>在Canary部署中，我们将更新部署到现有系统，并向用户部分展示新版本。这意味着我们的一小部分用户将能够访问更新的模型，其余的将仍然使用旧版本。</p><p id="0802" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种类型的部署主要用于测试新版本的工作情况，或者是否工作正常。通常，一小部分用户(大约5%-30%)会接触到更新，因为这有助于ML工程师和开发人员理解哪些特性可能需要推出，哪些需要重构。</p><p id="d19c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">其中— </strong> Canary部署通常在试运行和生产阶段进行，此时团队需要了解新更新型号的性能。这可以通过两种方式实现:</p><ol class=""><li id="80b7" class="nx ny jf kw b kx ky la lb ld nz lh oa ll ob lp oc od oe of bi translated">金丝雀滚动部署</li><li id="19fa" class="nx ny jf kw b kx og la oh ld oi lh oj ll ok lp oc od oe of bi translated">金丝雀并行部署</li></ol><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ol"><img src="../Images/9a334d7d95fda1072bd8bcf33fe75e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QXIoEcR9-DclBRLCxScioQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">金丝雀部署(图片由作者提供)</p></figure><p id="e9b0" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="nb">滚动部署</em> </strong>补丁更新到同一集群内的少量实例，一组用户请求被发送到这些pod。</p><p id="7ce4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="nb">并行部署</em> </strong>在现有设置的基础上创建一个较小的新实例集，并将一定比例的用户请求发送到这些pod。</p><p id="34d4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">根据流量负载和基础设施可用性，您可以选择希望设置哪个Canary实现。</p><p id="3cb3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="nb">用户请求通常通过标头进行标记，然后负载平衡器设置被配置为将它们发送到适当的目的地。</em>含义<strong class="kw jg"> <em class="nb">选择一组用户</em> </strong>查看更新，<strong class="kw jg"> <em class="nb">同一组用户每次都会看到更新。用户请求不会被随机发送到新的pod。Canary部署具有会话关联性。</em></strong></p><p id="48e3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在我们的示例中，假设10%的精选用户可以将他们的图像提交给模型，模型会使用考拉选项对他们进行分类，其余的用户只能使用二元分类器。</p><h2 id="5d44" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">A/B测试</h2><p id="fafd" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg"> WHAT — </strong>这种方法最常用于用户体验研究，用来评估用户的偏好。在ML场景中，我们可以使用这种部署风格来了解用户喜欢什么，以及哪种模型可能更适合他们。</p><p id="a3d3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">其中— </strong>主要用于全球推荐系统的部署。根据人口统计数据，假设一个在线市场网站使用两种不同类型的推荐引擎，一种可能服务于一组普通用户，另一种服务于特定的地理位置——提供更多的本地语言支持。工程师可以在一段时间后确定哪个引擎为用户提供更流畅的体验。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/adcc17269ef80aa085ed597ccf5b0edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kXo6a0OBL08EHkuQ2P7hEg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">为什么我们需要A/B测试(图片由作者提供)</p></figure><p id="413d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在我们的例子中，假设我们在全球部署了猫狗分类器，但是我们在澳大利亚—太平洋岛屿地区部署了版本1和版本2，在那里用户请求被随机发送到版本2。想象一下重新训练版本2来识别更多的本地动物品种并部署它，你认为澳大利亚的人民会更喜欢哪个版本？</p><pre class="mp mq mr ms gt on oo op oq aw or bi"><span id="733c" class="lq lr jf oo b gy os ot l ou ov"><strong class="oo jg">NOTE:</strong><br/>You might wonder what's the <strong class="oo jg">difference between Canary and A/B Testing</strong>. The main differences are:</span><span id="f90d" class="lq lr jf oo b gy ow ot l ou ov">- Canary is session affinity-based, mostly the same set of users will see the updated model whereas, in A/B Testing, the users are randomly sent to different versions.</span><span id="0160" class="lq lr jf oo b gy ow ot l ou ov">- Canary is specifically to test if the app or model is working as expected, A/B is more to understanding user experience.</span><span id="62c1" class="lq lr jf oo b gy ow ot l ou ov">- The Canary user ratio never goes beyond 50, a very small percentage of the user request (less than 35% ideally) is sent to the newer testing version.</span></pre><h2 id="87d2" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">阴影👻</h2><p id="5321" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">什么— </strong>影子部署在生产系统中使用，用生产数据测试新版本的模型。用户请求的副本被制作并发送到您的更新模型，但是现有系统给出了响应。</p><p id="7abc" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">其中— </strong>假设您有一个高流量的生产系统，为了验证更新后的模型如何处理生产数据和流量负载，我们以影子模式部署更新后的模型。每次向模型发送请求时，都会向更新的版本发送一个副本。响应仅由现有模型发回，而不是更新后的模型。</p><figure class="mp mq mr ms gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/c5c84624d923dcc412cc94097803f434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7--ohCyWfY_mQLVH252b9Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">影子部署(图片由作者提供)</p></figure><p id="9c6b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这种类型的部署用于了解生产负载、流量和模型性能。主要用于大量预测服务。这种部署增加了体系结构和设计的复杂性。我们必须包括服务网格、请求路由和基于用例的复杂数据库设计。</p><p id="f8d6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在我们的示例中，我们可能将版本2部署为影子部署，以了解版本2如何处理生产负载，也了解我们从哪里获得更多的考拉分类请求😉或者任何特定类型的模型请求模式。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><p id="0ad1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">现在，我们对如何在各种用例中部署模型有了很好的基本理解。根据需求，数据科学团队可能会结合使用这些方法。各有所好。</p><p id="46c3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">目前就这些。保重。再见！😇</p></div></div>    
</body>
</html>