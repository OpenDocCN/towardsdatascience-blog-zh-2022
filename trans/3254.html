<html>
<head>
<title>Paper Explained — Instant Neural Graphics Primitives with a Multiresolution Hash Encoding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释——具有多分辨率散列编码的即时神经图形图元</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-explained-instant-neural-graphics-primitives-with-a-multiresolution-hash-encoding-8e5a05865378#2022-07-20">https://towardsdatascience.com/paper-explained-instant-neural-graphics-primitives-with-a-multiresolution-hash-encoding-8e5a05865378#2022-07-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d9e2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">开创性的NeRF论文在计算机视觉界掀起了风暴，但提出的方法需要对每个新场景进行数小时的训练。NVIDIA的一种新方法将这一时间缩短到了几秒钟</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/d757fbc2758e702446bfd317853ce37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*t61FdNL9scLwv3AQa8mUrg.gif"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/" rel="noopener ugc nofollow" target="_blank">项目网站</a>上的视频生成的GIF，经许可拍摄。<em class="kv">戴珍珠耳环的女孩</em>翻新Koorosh Orooj ( <a class="ae ku" href="http://profoundism.com/free_licenses.html" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>)。<em class="kv">迪士尼云</em>模型华特迪士尼动画工作室(<a class="ae ku" href="https://media.disneyanimation.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 3.0 </a>)。</p></figure><h1 id="a671" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">介绍</h1><p id="a8ad" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">临近2020年底，注意到今年人工智能的主要趋势之一，教授兼研究员Frank Dellaert将他的一篇博客文章命名为“<a class="ae ku" href="https://dellaert.github.io/NeRF/" rel="noopener ugc nofollow" target="_blank"><strong class="lq iu">NeRF Explosion 2020</strong></a>”。Mildenhall等人在他们的论文<a class="ae ku" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank"> NeRF:将场景表示为用于视图合成的神经辐射场</a>中提出的惊人结果开辟了一条新的研究路线，该研究仍然是计算机视觉中最热门的主题之一，并可能代表许多应用程序的未来，如<a class="ae ku" href="https://neuralfields.cs.brown.edu/eg22.html" rel="noopener ugc nofollow" target="_blank">3D形状和图像的合成、人体动画、3D重建和姿态估计</a>。</p><p id="64dc" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">最初的<strong class="lq iu"> NeRF很棒，但是……非常慢</strong>！为单个场景训练模型可能需要几个小时，甚至几天。由NVIDIA 研究人员托马斯·穆勒、亚历克斯·埃文斯、克里斯托夫·席德和亚历山大·凯勒撰写的论文<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">即时神经图形图元与多分辨率哈希编码</a> ( <strong class="lq iu">即时NGP </strong>)提出了一种新的方法，即<strong class="lq iu">将这一时间从几个小时缩短到几秒钟</strong>。</p><p id="6e30" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">这是一个高级话题，你可能从未听说过NeRF或者需要复习一下。那样的话，别担心，我会掩护你的！下面你会发现我的文章，这一切都是从这张纸上开始的；我建议您在继续之前阅读它，因为我不打算重复解释已经讨论过的内容。</p><div class="mp mq gp gr mr ms"><a href="https://blog.devgenius.io/paper-explained-nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-e16567180531" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">论文解释——NeRF:将场景表示为用于视图合成的神经辐射场</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">介绍</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">blog.devgenius.io</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng ko ms"/></div></div></a></div><blockquote class="nh ni nj"><p id="1e8c" class="lo lp nk lq b lr mk ju lt lu ml jx lw nl mm lz ma nm mn md me nn mo mh mi mj im bi translated"><strong class="lq iu">免责声明</strong>:大部分图片和内容来源于即时NGP <a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">论文</a> / <a class="ae ku" href="https://nvlabs.github.io/instant-ngp/" rel="noopener ugc nofollow" target="_blank">项目网站</a>，在本文中我尽量报道了对其理解至关重要的部分，必要时补充细节。所有图片都是在作者许可下拍摄的，必要时还列出了额外的许可。</p></blockquote><h1 id="50dd" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">计算机图形图元</h1><p id="0737" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在解释即时NGP引入的新功能之前，有必要介绍四个任务，或者如论文中所称的<strong class="lq iu">计算机图形图元</strong>，作者将他们的方法与以前的方法进行了比较。</p><p id="43e0" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">对于即时NGP的部分解释，与NeRF一样，首先根据一些逻辑对输入进行编码，然后使用多层感知器(MLP)来学习它们与给定输出之间的映射。在这一节中，我们将看到本文中考虑的所有任务的输入和输出是什么。</p><h2 id="a55e" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">千兆像素图像近似</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/847f74754159570af58e8385e791b025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tWlFKTN1PTVOMCGqhCh0Sw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。<em class="kv">戴珍珠耳环的女孩</em>翻新Koorosh Orooj(<a class="ae ku" href="http://profoundism.com/free_licenses.html" rel="noopener ugc nofollow" target="_blank">CC BY-SA 4.0</a>)。</p></figure><p id="88e0" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">这项任务旨在测试模型表现高频细节的能力，目标是了解(非常大的)图像的2D坐标与其RGB颜色之间的映射。基本上，该模型正在<strong class="lq iu">学习有效地压缩</strong>图像，并逐个像素地重建图像，也就是说，给定一个像素的坐标，它将返回该位置处原始图像的颜色。</p><p id="d9f7" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">例如，上图的分辨率为20 000 X 23 466 (469 M RGB像素)，而根据我们稍后将介绍的超参数t的选择，模型的可训练参数分别为117 k (T = 2)、2.7 M (T = 2 ⁷)和47.5 M (T = 2)。</p><h2 id="09a2" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">符号距离函数</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi of"><img src="../Images/58567be3584fd1320a442d14a4d4a20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wJEq7bjlL89E5oN0lukt5A.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">经<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄的图像。</p></figure><p id="8b38" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated"><strong class="lq iu">带符号距离函数</strong>(<strong class="lq iu">SDF</strong>)用于<strong class="lq iu">将3D形状表示为函数</strong>的零水平集。想象在感兴趣的表面上的一个点上计算SDF，在这种情况下，SDF将等于零，而如果该点在表面之外，则它将具有等于该点与表面的最小距离的正值，如果它在表面之内，则相同，但具有负号。</p><p id="f923" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">在这个任务中，MLP学习从3D坐标到离表面的距离的映射。这可用于3D形状压缩(类似于之前的任务，但用于3D形状)和形状完成等任务，如<a class="ae ku" href="http://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html" rel="noopener ugc nofollow" target="_blank"> DeepSDF:学习形状表示的连续带符号距离函数</a>所示。</p><h2 id="88ab" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">神经辐射缓存</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi og"><img src="../Images/59bee1e03550914e0ca9f8ae815f4f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ffwG6VH5VyAo46WQqTcZbw.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="d39b" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">该任务涉及<strong class="lq iu">从特征缓冲区</strong>预测照片级像素颜色。</p><p id="118f" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">在这种情况下，MLP从<strong class="lq iu">蒙特卡洛</strong> <a class="ae ku" href="https://en.wikipedia.org/wiki/Path_tracing" rel="noopener ugc nofollow" target="_blank"> <strong class="lq iu">路径跟踪器</strong> </a>中学习给定场景的5D <a class="ae ku" href="https://en.wikipedia.org/wiki/Light_field" rel="noopener ugc nofollow" target="_blank"> <strong class="lq iu">光场</strong> </a>。</p><p id="24e4" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">在这种情况下，<strong class="lq iu">训练</strong>在线<strong class="lq iu">发生</strong>，在渲染过程中，“过拟合”在后台运行的路径跟踪器的输出。</p><h2 id="bae6" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">神经辐射和密度场(NeRF)</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oh"><img src="../Images/9780c5eed924a42ec8a52e6e0bffd540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-7X1EM72ZyROWI9hJ7HTQg.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="40dd" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">最后，最后一项任务是以发起该研究系列的论文命名的，即时NGP也是该研究系列的一部分。在这种情况下，MLP从图像观察和相应的透视变换中学习给定场景的3D密度和5D光场。</p><p id="60e2" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">通过这种方式，可以从新的有利位置创建场景的新视图，这个问题称为<a class="ae ku" href="https://paperswithcode.com/task/novel-view-synthesis" rel="noopener ugc nofollow" target="_blank"> <strong class="lq iu">新颖的视图合成</strong> </a>，逼真地再现灯光效果和材质属性。更多细节请看<a class="ae ku" href="https://blog.devgenius.io/paper-explained-nerf-representing-scenes-as-neural-radiance-fields-for-view-synthesis-e16567180531" rel="noopener ugc nofollow" target="_blank">我之前的文章</a>。</p><p id="4876" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">既然我们已经提出了我们想要解决的任务，让我们看看这篇论文的主要贡献是什么。</p><h1 id="0c00" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">输入编码</h1><h2 id="899f" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">频率编码</h2><p id="f29f" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">NeRF受早期作品的启发，比如介绍Transformer架构的著名论文<a class="ae ku" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwik29Hph-_4AhU7_bsIHZ11BTUQFnoECAQQAQ&amp;url=http%3A%2F%2Fpapers.neurips.cc%2Fpaper%2F7181-attention-is-all-you-need.pdf&amp;usg=AOvVaw0urMr7lge7zRenHpISFM80" rel="noopener ugc nofollow" target="_blank"/>，将标量位置x∈R编码为L∈N正弦和余弦函数的多分辨率序列</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/19f274cf0a57997b18e7d63f67a74d5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*gl08ORZ_abyg0Shf6HXmfg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="5d58" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">如NeRF论文中的消融研究所示，如果没有这种编码，高频细节将无法捕捉。</p><p id="e849" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">这种编码是<strong class="lq iu">固定的</strong>，因此不太有表现力，这意味着<strong class="lq iu">需要一个“大”MLP</strong>来学习前面介绍的复杂任务，因为从输入到输出的任务都委托给它了。</p><h2 id="fcd1" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">参数编码</h2><p id="d4fe" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">最新的先进方法使用参数编码，其思想是在<strong class="lq iu">辅助数据结构</strong>中安排额外的可训练参数，例如<strong class="lq iu">网格</strong>或<strong class="lq iu">树</strong>。然后根据输入查找这些参数，并(可选地)进行插值。</p><p id="c66e" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">为什么这种方法应该是有益的？我们<strong class="lq iu">用较大的内存占用换取较小的计算成本</strong>；我们可以拥有一个小得多的MLP，而不是一个大的，虽然以这种方式消除的参数可以通过使用额外的数据结构以某种方式重新获得，<strong class="lq iu">只有其中的一个小的子集会随着每个梯度反向推</strong>而更新，从而大大加快了训练速度。这一点很关键，所以让我们看一个例子来更好地理解它。假设我们用3D网格划分我们感兴趣的场景，对于网格内的给定点，对于每个反向传播的样本，我们只需要更新8个嵌入(对于包含该点的网格中的3D体素的每个顶点一个嵌入)。当我们介绍所提出的方法时，这一点将变得更好理解。</p><p id="6714" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">即时NGP使用的编码就属于这一类；在描述它之前，让我们先看看以前的方法有什么问题。</p><p id="37f7" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">一种可能的方法是使用类似于<a class="ae ku" href="https://arxiv.org/abs/2105.02788" rel="noopener ugc nofollow" target="_blank"> ACORN:用于神经场景表示的自适应坐标网络</a>中的域的<strong class="lq iu">树细分</strong>，其中大型辅助坐标编码器神经网络被训练为在x周围的叶节点中输出密集的特征网格。这种方法虽然比以前的方法产生更大程度的自适应性，但它以更高的计算成本<strong class="lq iu">实现，仅当足够数量的输入在每个叶节点结束时才可摊销。</strong></p><p id="5d9a" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">另一种方法是使用可训练特征的<strong class="lq iu">密集网格</strong>，但是它们<strong class="lq iu">比神经网络权重消耗更多的内存</strong>。特别是，这种方法是<strong class="lq iu">浪费的</strong>，因为空白空间的区域被视为靠近表面的区域，这导致参数的数量增长为O(N)，而感兴趣的可见表面的区域仅增长为O(N)。</p><p id="a7c2" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated"><strong class="lq iu">如果感兴趣的表面是先验已知的</strong>，诸如<strong class="lq iu">八叉树</strong>或<strong class="lq iu">稀疏网格</strong>的数据结构可用于剔除密集网格中未使用的特征。然而，<strong class="lq iu">在NeRF设置中，表面仅在训练期间出现</strong>。</p><p id="bcf5" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">对于这些先前作品的所有参考，请参考论文。现在让我们来看看即时NGP最重要的组成部分之一。</p><h1 id="eb32" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">多分辨率散列编码</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oj"><img src="../Images/ae7ff6decd09578785866c42ea27bdf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ErCC2gJh-aAqkEYsD8GJA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><h2 id="74c4" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">程序概要</h2><p id="8875" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">论文的主要贡献肯定是提出了<strong class="lq iu">输入坐标</strong>的<strong class="lq iu">编码</strong>。</p><p id="647c" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">让我们首先简要地总结一下这个过程，然后分别分析细节:</p><ol class=""><li id="fb31" class="ok ol it lq b lr mk lu ml lx om mb on mf oo mj op oq or os bi translated"><strong class="lq iu"> L </strong> <strong class="lq iu"> d维</strong> <strong class="lq iu">网格</strong>被定义。具体来说，如果我们要建模的是一幅图像，至于“Gigapixel”任务，d等于2；另一方面，如果我们想要对三维体积建模，至于“NeRF”任务，d等于3。在上图中，你可以看到两个2D网格的例子，一个是分辨率为1 / N0的<strong class="lq iu">网格，另一个是分辨率为1 / N1的网格，我们将在后面看到这些<strong class="lq iu"> N </strong> l是如何选择的</strong></li><li id="2e58" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">每个<strong class="lq iu">级</strong> <strong class="lq iu"> l </strong>与多达<strong class="lq iu"> T </strong> <strong class="lq iu">个具有<strong class="lq iu">维度</strong> <strong class="lq iu"> F </strong>的特征向量</strong>相关联</li><li id="0a21" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">对于一个给定的样本，其<strong class="lq iu">输入坐标</strong> <strong class="lq iu"> x </strong>被映射到每一层中相应的<strong class="lq iu">体素</strong> (d维单元)。例如，在图像中，x落在级别0的右下角单元格中，而在级别1的中间单元格中</li><li id="9eff" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">给定层的顶点数<strong class="lq iu">为<strong class="lq iu"> V </strong> = (Nl + 1)^d，例如，如果N1 = 3且d = 2(就像上图中N1将边精确地分为3)，对于层1，我们有(3 + 1) = 16个顶点。如果V ≤T，我们在该层的顶点和特征向量之间有1:1的映射。在更精细的级别，其中V &gt; T，我们使用一个<strong class="lq iu">散列函数</strong>T34】h</strong>将每个d维顶点映射到相应级别的T个特征向量之一。我们确实可以想到一个散列表，尽管<strong class="lq iu">没有明确的冲突处理</strong></li><li id="55e7" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">我们现在有了每层的d个特征向量，每个向量都与各自体素的顶点相关联。在这一点上，我们<strong class="lq iu">线性内插</strong>d矢量以获得代表该层的最终矢量</li><li id="e96e" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">我们<strong class="lq iu">连接</strong>每一层的最终矢量，如果有的话，<strong class="lq iu">辅助输入</strong>(视角方向，材质参数等。)，这是将作为输入给一个<strong class="lq iu">多层感知器</strong> ( <strong class="lq iu"> MLP </strong>)的向量，从这里开始，程序类似于最初的NeRF</li></ol><p id="9589" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">现在让我们更详细地了解每一步。</p><p id="7987" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated"><strong class="lq iu">选择每个级别的网格分辨率</strong></p><p id="8bc5" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">一个<strong class="lq iu">几何级数</strong>用于定义在<strong class="lq iu">最粗</strong> ( <strong class="lq iu"> Nmin </strong>)到<strong class="lq iu">最细</strong> ( <strong class="lq iu"> Nmax </strong>)级别之间的中间<strong class="lq iu">分辨率</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/8cf3dd91c0e3fa400295f20ef81c794c.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*-kcACtyTfPNwugtI1eOgbg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="aa15" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">使用简单的对数规则，我们可以证明:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oz"><img src="../Images/3a9ca35cdc2cea10834d3964b99f8113.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDp5VF3JzbHVDtJiTZM7PQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由作者提供。</p></figure><p id="7169" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">我们看到，如果l = 0，Nl = Nmin * b⁰ = Nmin，而如果l = L - 1(级别范围从0到L - 1)，Nl = Nmin * Nmax / Nmin = Nmax，则其他值介于两者之间。</p><p id="c235" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">由于等级L的数量很大，<strong class="lq iu">增长因子</strong> <strong class="lq iu"> b </strong>通常很小。论文的用例有b ∈[1.26，2]。</p><h2 id="f256" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">空间哈希函数</h2><p id="eedc" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在一个<strong class="lq iu">散列函数</strong>中我们想要什么<strong class="lq iu">特性</strong>？作者列举如下:</p><ol class=""><li id="342d" class="ok ol it lq b lr mk lu ml lx om mb on mf oo mj op oq or os bi translated">高效计算</li><li id="864c" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">导致连贯的查找</li><li id="a2c4" class="ok ol it lq b lr ot lu ou lx ov mb ow mf ox mj op oq or os bi translated">一致覆盖特征向量阵列，而不管查询点的结构如何</li></ol><p id="ab43" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">由于这些原因，即时NGP使用了一个<strong class="lq iu">空间哈希函数</strong> [ <a class="ae ku" href="https://www.researchgate.net/publication/2909661_Optimized_Spatial_Hashing_for_Collision_Detection_of_Deformable_Objects" rel="noopener ugc nofollow" target="_blank"> Teschner等人2003 </a> ]的形式</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/986eeceb1962aefa332e0b82035ee248.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*j23orYUKQWzCLxFKKRwdoA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">经<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄的图像。</p></figure><p id="d753" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">其中⊕denotes的逐位<strong class="lq iu">异或</strong>运算和<strong class="lq iu">ππ</strong>I唯一，<strong class="lq iu">大素数</strong>。</p><p id="5f0b" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">优化散列函数也被认为是未来的工作，将该方法变成一种<strong class="lq iu">字典学习</strong>方法。</p><p id="6bbc" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">原文提供了其他细节，并为感兴趣的读者提供了有用的参考。</p><h2 id="272d" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">性能与质量</h2><p id="594c" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">可以想象，随着T的增加，我们拥有更高的质量、更高的内存使用率和更低的性能(更长的训练/推理时间)。该论文强调的有趣方面是，虽然内存随T线性增长，但质量和性能往往呈亚线性增长。</p><p id="5549" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">同样，L和F也代表了质量和性能之间的权衡。作者发现F = 2和L = 16对于他们的大多数应用来说都是很好的值。</p><h2 id="4c0a" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">隐式哈希冲突解决</h2><p id="699e" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">我们说冲突不被处理，这意味着什么？</p><p id="c12b" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">首先，我们注意到<strong class="lq iu">在低层没有碰撞</strong>，因为映射是1:1。在可能发生这些碰撞的较高层，梯度被平均化。一个重要的观察是，不是所有碰撞的点都同等重要；<strong class="lq iu">可见表面上的点</strong>将具有更大的梯度，因此<strong class="lq iu">对学习的编码</strong>具有更大的影响。</p><p id="614a" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">值得注意的是，这并非完全没有后果，正如在一项关于使用MLP的重要性的最终消融研究中所示，我们看到哈希碰撞会在重建中产生一些噪声，如果我们用线性层替换MLP，这种噪声会特别明显。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/3cd17dd7aff11ac936b5f7a2430a3068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*MgxRBuLm7r0np91NGDF97g.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><h2 id="0c9b" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">d-线性插值</h2><p id="77cc" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">需要注意的是<strong class="lq iu">插补</strong>不是可选的。没有它，我们将有网格对齐的不连续性(块状外观)。线性插值不是人们能想到的最高阶，对于需要更高阶的应用，作者提出了<a class="ae ku" href="https://en.wikipedia.org/wiki/Smoothstep" rel="noopener ugc nofollow" target="_blank"> <strong class="lq iu">平滑步骤</strong> </a>函数</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/8b82e36d6cbbc6c2360dbdad6979cf77.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*g0YoTq3nfkzYtNzHP1IL0Q.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="8603" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">这是更昂贵的d-二次或d-三次插值的低成本替代方案。</p><p id="a26d" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">然而，这种解决方案在本文中从未使用过，根据经验，它会降低所考虑用例的重建质量。</p><h1 id="365f" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">履行</h1><h2 id="0a19" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">性能考虑因素</h2><p id="7638" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">这项工作的一个相关方面是架构是如何实现的，在这里我们可以看到NVIDIA研究人员在充分利用GPU方面的经验。整个系统实现利用了<strong class="lq iu">完全融合的CUDA内核</strong>(融合运算以加速计算)，并专注于最小化浪费的带宽和计算操作。散列表条目以半精度存储，以全精度维护参数的主副本，用于稳定的<strong class="lq iu">混合精度</strong>参数更新。他们还优化了GPU缓存，<strong class="lq iu">调度计算</strong>，以便在移动到下一个输入之前，在一个批处理中查找所有输入的多分辨率哈希编码的每个级别。关于哈希表的大小，他们能够最大限度地提高性能，直到T ≤ 2 ⁹，超过这个阈值，性能开始显著下降，因为NVIDIA RTX 3090 GPU的二级缓存对于各个级别来说变得太小。</p><p id="a3ab" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">这种高度优化的C++实现比Python中的简单实现快10倍。</p><p id="d2fd" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">有了这种级别的优化，将实现带来的改进与文章中提出的创新带来的改进区分开来是很重要的；在所有的实验中，作者都小心翼翼地将这两种效应分开，有时会重新实现以前的架构。</p><h2 id="4693" class="no kx it bd ky np nq dn lc nr ns dp lg lx nt nu li mb nv nw lk mf nx ny lm nz bi translated">架构、初始化和培训</h2><p id="83e4" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">架构、初始化和训练程序都相当标准。我不会在这里报告我建议查阅文件的所有细节。重要的是要注意，同样在这种情况下，在编码之后，我们使用了一个在结构上与原始NeRF非常相似的MLP，一个密度MLP后面跟着一个彩色MLP，但是由于额外的可训练数据结构而变得更小。</p><h1 id="ba12" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">实验和结果</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pd"><img src="../Images/161d9db1226a5ed6574c3d949ad5dce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XrLYeP3-jwdqCu3UWJDmpQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由<a class="ae ku" href="https://nvlabs.github.io/instant-ngp/assets/mueller2022instant.pdf" rel="noopener ugc nofollow" target="_blank">报社</a>许可拍摄。</p></figure><p id="4989" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">即时NGP超越了以前方法的性能和/或增加了所有考虑的任务的灵活性，具有更简单的额外优势。最令人惊讶的结果之一是，他们<strong class="lq iu">与<strong class="lq iu">的峰值信噪比</strong> ( <strong class="lq iu"> PSNR </strong>)相匹配</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pe"><img src="../Images/7dee650c143f577329f3d801d5163a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HN-dl_tk5sZAGUXKQsaG7A.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片由作者提供。这个指标还有其他定义，这是它在即时NGP的GitHub库<a class="ae ku" href="https://github.com/NVlabs/instant-ngp" rel="noopener ugc nofollow" target="_blank">中的实现方式。</a></p></figure><p id="abf2" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated"><strong class="lq iu">原来的NeRF(训练小时数)只需5–15s</strong>，与<strong class="lq iu">相比提升了20–60倍</strong>，这可以<strong class="lq iu">归功于</strong>提出的<strong class="lq iu">哈希编码</strong>。</p><p id="011d" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">在其他任务中也可以看到类似的结果，例如，即时NGP在2.5分钟而不是36.9小时的训练后，在重建东京的千兆像素图像方面实现了与ACORN相同的PSNR。</p><p id="3aab" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">总的来说，我们可以说瞬时NGP令人难以置信的速度将使得有可能将NeRF应用于新的任务，例如，所提出的多分辨率散列编码是将NeRF加速几个数量级并匹配并行非神经3D重建技术的性能的直接替代。</p><h1 id="980b" class="kw kx it bd ky kz la lb lc ld le lf lg jz lh ka li kc lj kd lk kf ll kg lm ln bi translated">结论</h1><p id="de0a" class="pw-post-body-paragraph lo lp it lq b lr ls ju lt lu lv jx lw lx ly lz ma mb mc md me mf mg mh mi mj im bi translated">在本文中，我们探讨了NVIDIA的即时NGP如何让NeRF快如闪电。</p><p id="46ee" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">如果这项新技术引起了你的兴趣，并且你想亲自尝试一下即时NGP，你可以！看看<a class="ae ku" href="https://github.com/NVlabs/instant-ngp" rel="noopener ugc nofollow" target="_blank">官方GitHub库</a>并按照所有的说明去做，结果会很惊人。</p><p id="f65a" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">感谢您读到这里，如果您有任何与本文相关的建议或问题，请随时留下评论或与我联系，我的联系方式如下。</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="77d7" class="pw-post-body-paragraph lo lp it lq b lr mk ju lt lu ml jx lw lx mm lz ma mb mn md me mf mo mh mi mj im bi translated">想保持联系，不要错过我的新文章？在<a class="ae ku" href="https://medium.com/@mnslarcher" rel="noopener">中</a>、<a class="ae ku" href="https://www.linkedin.com/in/mnslarcher/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ku" href="https://twitter.com/mnslarcher" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p></div></div>    
</body>
</html>