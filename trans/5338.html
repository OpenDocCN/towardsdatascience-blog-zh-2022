<html>
<head>
<title>DBSCAN Clustering: Break It Down For Me</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DBSCAN 集群:给我分解一下</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dbscan-clustering-break-it-down-for-me-859650a723af#2022-11-30">https://towardsdatascience.com/dbscan-clustering-break-it-down-for-me-859650a723af#2022-11-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cc12" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">强大算法的简单介绍</h2></div><p id="e6a1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">欢迎回到<em class="le">我不知道为什么我对这个算法感到不安的世界，因为我完全凭直觉得到它</em>，在这里我们采用复杂的机器学习算法，并用有趣的插图将它们分解成简单的步骤。</p><p id="e806" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天，我们将处理另一种叫做<strong class="kk iu"> DBSCAN </strong> ( <strong class="kk iu">基于密度的应用程序空间聚类</strong>)的聚类算法。为了更好地理解 DBSCAN，首先查看一下 K-Means 和层次聚类文章。</p><p id="8f7f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">顾名思义，DBSCAN 通过点的密度来识别簇。聚类通常位于高密度区域，异常值往往位于低密度区域。使用它的 3 个主要优势(根据这个<a class="ae lf" href="https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf" rel="noopener ugc nofollow" target="_blank">算法</a>的先驱)是它需要最少的领域知识，可以发现任意形状的集群，并且对于大型数据库是有效的。</p><p id="2372" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">既然我们已经介绍完了，让我们进入有趣的部分——真正理解它是如何工作的。假设我们的原始数据是这样的:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi lg"><img src="../Images/fef56ab2d181550c298340b871db4f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U6Tevq5Vsc4wa7a2CoajEg.png"/></div></div></figure><p id="b31a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一件要做的事是数点<em class="le">接近</em>的每一个点。我们通过围绕一个点画一个具有一定半径的圆(<strong class="kk iu"> <em class="le"> eps </em> </strong>)来确定这个接近度，并且任何落在这个圆内的其他点都被称为接近第一个点。例如，从这个粉红色的点开始，围绕它画一个圆。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ls"><img src="../Images/38188b4fb733c1397d9b566166cf9e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WiKZrEeHGSFfRSbl8bwRCQ.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">围绕任意一点画一个半径为 eps 的圆</p></figure><p id="4393" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们看到这一点与其他 7 点完全或部分重叠。所以我们说粉点接近 7 分。</p><blockquote class="lx ly lz"><p id="8b2c" class="ki kj le kk b kl km ju kn ko kp jx kq ma ks kt ku mb kw kx ky mc la lb lc ld im bi translated">称为<strong class="kk iu"> <em class="it"> eps </em> </strong>的圆的半径，是我们需要定义的 DSBCAN 算法中的第一个参数。我们需要适当地定义<strong class="kk iu"> eps </strong>，因为如果我们选择的值太小，很大一部分数据将不会被聚集。另一方面，如果我们选择一个太大的值，聚类将合并，许多数据点将在同一个聚类中。一般来说，较小的<strong class="kk iu"> eps </strong>值是优选的。</p></blockquote><p id="ab1d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在考虑这个蓝点。我们看到它接近 3 个点，因为它的半径为<strong class="kk iu"> <em class="le"> eps </em> </strong>的圆与另外 3 个点重叠。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi md"><img src="../Images/7d02eba656b104ddc790b24e91d2ec49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EH3PFY2He10jSDxKBJCooA.png"/></div></div></figure><p id="a89c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">同样，对于所有剩余的点，我们计算接近点的数量。一旦我们这样做了，我们需要决定哪些点是<strong class="kk iu"> <em class="le">核心点</em> </strong>，哪些点是<strong class="kk iu"> <em class="le">非核心点</em> </strong>。</p><blockquote class="lx ly lz"><p id="9b5d" class="ki kj le kk b kl km ju kn ko kp jx kq ma ks kt ku mb kw kx ky mc la lb lc ld im bi translated">这就是我们算法的第二个参数——<strong class="kk iu"><em class="it">min points</em></strong>——出现的地方。我们使用<strong class="kk iu">最小点</strong>来确定一个点是否是<strong class="kk iu">核心点</strong>。假设我们将<strong class="kk iu">最小点</strong>设置为 4，那么我们说如果至少有 4 个点靠近一个点，那么这个点就是<strong class="kk iu">核心点</strong>。如果少于 4 个点接近一个点，则视为<strong class="kk iu">非核心点</strong>。</p><p id="9104" class="ki kj le kk b kl km ju kn ko kp jx kq ma ks kt ku mb kw kx ky mc la lb lc ld im bi translated">一般来说，<strong class="kk iu"> minPoints </strong> <em class="it"> ≥ </em>数据集中的维数+ 1。对于有噪声的数据集，较大的值通常更好。<strong class="kk iu"> minPoints </strong>的最小值必须是 3，但是我们的数据集越大，<strong class="kk iu"> minPoints </strong>的值就必须越大。</p></blockquote><p id="aa86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于我们的示例，让我们将<strong class="kk iu"> <em class="le"> minPoints </em> </strong>设置为 4。那么我们可以说粉色点是一个<strong class="kk iu"> <em class="le">核心点</em> </strong>因为至少有 4 个点接近它，而蓝色点是一个<strong class="kk iu"> <em class="le">非核心点</em> </strong>因为只有 3 个点接近它。</p><p id="9f13" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，利用以上过程，我们可以确定以下高亮点是<strong class="kk iu"> <em class="le">核心点……</em></strong></p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi me"><img src="../Images/94c3ed971bbdd9446b1cff4dc4a4beab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9x43mSx270iwcobbe2Kerw.png"/></div></div></figure><p id="499b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">…而剩下的就是<strong class="kk iu"> <em class="le">非核心点</em> </strong>。</p><p id="73de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们随机选取一个<strong class="kk iu"> <em class="le">核心点</em> </strong>并将其分配给第一个集群。这里，我们随机选择一个点，并将其分配给<em class="le">蓝色</em>簇。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi me"><img src="../Images/4aba8e51388fbe7916a99e8efa8c27b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hlRHMkp4VXyXdAR0KgDTWw.png"/></div></div></figure><p id="904f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，靠近蓝色星团的<strong class="kk iu"> <em class="le">核心点</em> </strong>，意味着它们与半径为<strong class="kk iu"> <em class="le"> eps </em> </strong>的圆重叠…</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mf"><img src="../Images/71d35ef17c40cac7ab98f480b7fcda19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pru3fKSRqhXsGzHiJgo6Pw.png"/></div></div></figure><p id="b0a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">…全部添加到蓝色集群中:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mg"><img src="../Images/5f393fdb6871828246d9d3ccf4515365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8uDqRboAsb9SFvhV1yVPTA.png"/></div></div></figure><p id="0e24" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，将靠近成长中的蓝色星团的<strong class="kk iu"> <em class="le">核心点</em> </strong>加入其中。下面，我们看到 2 个<strong class="kk iu"> <em class="le">核心点</em> </strong>和 1 个<strong class="kk iu"> <em class="le">非核心点</em> </strong>靠近蓝色集群，但是我们只把 2 个<strong class="kk iu"> <em class="le">核心点</em> </strong>添加到集群中。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mh"><img src="../Images/6e6f9f884ee91b80e35a8fa346c4f150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*550BykrUimrskdiuYHBpsQ.png"/></div></div></figure><p id="ab4b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最终，所有靠近增长的蓝色集群的<strong class="kk iu"> <em class="le">核心点</em> </strong>都被添加到其中，数据将如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mi"><img src="../Images/0c954a94ca0860a832887ab2e21ec700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idlkg34Rr5tEgJ23s_9Zxw.png"/></div></div></figure><p id="e4e2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们将所有靠近蓝色星团的<strong class="kk iu"><em class="le"/></strong>非核心点加入其中。例如，这 2 个<strong class="kk iu"> <em class="le">非核心点</em> </strong>靠近蓝色集群，因此它们被添加到其中:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mj"><img src="../Images/862bf932e5571a70c31b38b3c7d27e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r_m9ktvPNs3HnH-gto1bMw.png"/></div></div></figure><p id="357e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，由于它们不是<strong class="kk iu"><em class="le"/></strong><em class="le">核心点，我们不使用它们来进一步扩展蓝色集群</em>。这意味着靠近<strong class="kk iu"> <em class="le">非核心点</em> </strong> 1 的另一个<strong class="kk iu"> <em class="le">非核心点</em> </strong>将不会被添加到蓝色群集。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mk"><img src="../Images/50eaed3b8bd80a52b226da6de09d971b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*juQEc1UqrFthkRPZLNeCBg.png"/></div></div></figure><p id="4317" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以，与<strong class="kk iu"> <em class="le">核心点</em></strong><strong class="kk iu"><em class="le">不同，非核心点</em> </strong>只能加入一个簇，不能用来进一步扩展。</p><p id="ce64" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">添加完所有的<strong class="kk iu"> <em class="le">非核心点</em> </strong>后，我们就完成了蓝色集群的创建，看起来像这样:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi ml"><img src="../Images/f7a31fe36662f8d4989b55f59b25aacc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wt6qhd2BAtP4dNaOUVWxtQ.png"/></div></div></figure><p id="59f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在因为剩余的<strong class="kk iu"> <em class="le">核心点</em> </strong>都没有接近第一个集群，我们开始形成新的集群的过程。首先，我们随机挑选一个<strong class="kk iu"> <em class="le">核心点</em> </strong>(不在一个集群中)并将其分配给我们的第二个<em class="le">黄色</em>集群。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mm"><img src="../Images/31875cc0196f976b9f187a1f699f9495.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xbhTVB1Ol92YADezBwuKxQ.png"/></div></div></figure><p id="ed75" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后我们添加所有靠近黄色聚类的<strong class="kk iu"> <em class="le">核心点</em> </strong>并用它们来进一步扩展聚类。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mn"><img src="../Images/367ada3c279e3761c1faa741beef2bee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gZf-h3Hg6rJyRtT-8Kw0bA.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">将剩余的核心点添加到第二个黄色聚类中</p></figure><p id="def0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后将靠近黄色簇的<strong class="kk iu"> <em class="le">非核心点</em> </strong>加入其中。完成后，我们的 2 个集群的数据如下所示:</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi mo"><img src="../Images/71d06760121569148d0cd7174c40c0ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUPX8NjOHSTCqfNjgO_FmA.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">在将非核心点添加到黄色聚类之后</p></figure><p id="7545" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们不断重复这个创建集群的过程，直到我们没有核心点<strong class="kk iu"><em class="le"/></strong>了。在我们的例子中，由于所有的<strong class="kk iu"> <em class="le">核心点</em> </strong>都已经被分配给一个集群，我们就完成了新集群的创建。最后，<em class="le">任何剩余的</em> <strong class="kk iu"> <em class="le">非核心点</em> </strong> <em class="le">不接近</em> <strong class="kk iu"> <em class="le">核心点</em> </strong> <em class="le">且不属于任何聚类的点称为</em> <strong class="kk iu"> <em class="le">离群点</em> </strong>。</p><p id="42ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就这样，我们建立了两个集群，发现了异常值，并从另一边毫发无损地出来了。</p><h2 id="7ffc" class="mp mq it bd mr ms mt dn mu mv mw dp mx kr my mz na kv nb nc nd kz ne nf ng nh bi translated">有人可能会问——为什么 DBSCAN 要优于 K-Means 或层次聚类？</h2><p id="8ca8" class="pw-post-body-paragraph ki kj it kk b kl ni ju kn ko nj jx kq kr nk kt ku kv nl kx ky kz nm lb lc ld im bi translated">K-Means 和 Hierarchical 适用于紧凑且分离良好的聚类，但也会受到数据中的噪声和异常值的严重影响。另一方面，DBSCAN 捕捉复杂形状的集群，并在识别异常值方面做得很好。DBSCAN 的另一个好处是，与 K-Means 不同，我们不必指定聚类的数量(<em class="le"> k </em>)，算法会自动为我们找到聚类。下图举例说明了两者的区别，以及为什么 DBSCAN 在适当使用时会很强大。</p><figure class="lh li lj lk gt ll gh gi paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gh gi nn"><img src="../Images/9a244d3fb366b97c3952df022d570ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cOhVdF9WGsy5SVFD.png"/></div></div><p class="lt lu gj gh gi lv lw bd b be z dk translated">图片来源:【https://github.com/NSHipster/DBSCAN T2】</p></figure><p id="4e67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">今天到此为止。请随时在<a class="ae lf" href="https://www.linkedin.com/in/shreyarao24/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系，或在<em class="le">shreya.statistics@gmail.com</em>给我发电子邮件，向我发送关于任何其他您想要说明的算法的问题和建议！</p></div><div class="ab cl no np hx nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="im in io ip iq"><p id="6ade" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你想支持我的工作，可以考虑使用<a class="ae lf" href="https://medium.com/@shreya.rao/membership" rel="noopener">我的链接来注册一个媒体订阅</a>！(每月 5 美元，随时取消)</p></div></div>    
</body>
</html>