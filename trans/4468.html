<html>
<head>
<title>How to monitor Data Lake health status at scale</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何大规模监控数据湖的健康状况</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-monitor-data-lake-health-status-at-scale-d0eb058c85aa#2022-10-04">https://towardsdatascience.com/how-to-monitor-data-lake-health-status-at-scale-d0eb058c85aa#2022-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="091e" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">配套的GitHub库:【Spark手把手的远大前程</h2><div class=""/><div class=""><h2 id="6bcf" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">带着巨大的期望和火花构建数据质量工作流</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/5d1ba9b3f66fd741934ddc61767db6d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ta3BX-zQ2gZGAlDzDPyfg.jpeg"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@markuswinkler" rel="noopener ugc nofollow" target="_blank">马库斯·温克勒</a>在<a class="ae le" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="c772" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">介绍</h2><p id="98a1" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">在<a class="ae le" href="https://www.mfemediaforeurope.com/en/" rel="noopener ugc nofollow" target="_blank"> Mediaset </a>，数据湖是每个想要获得一些公司见解或激活数据的人日常使用的基本工具。</p><p id="5aee" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">根据定义，<strong class="mc ja">数据湖</strong>是"<em class="my">一个集中的存储库，可以存储任何规模的所有结构化和非结构化数据。您可以本地存储来自源的数据，而不必在运行时转换它们。这允许您保留大量的原始数据，您可以在以后使用不同类型的分析来激活这些数据。</em></p><p id="fc83" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">访问数据湖的Mediaset员工数量正在上升，随着数据湖的增长，我们接收和保存的产品和数据的数量也在增加。随着用户和归档数据量的增加，管理数据湖的复杂性也在增加。</p><p id="8bbb" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">这是一个关键点，事实上，如果没有实现数据质量和数据治理系统，数据湖可能会变成一个<strong class="mc ja">数据沼泽</strong>:<em class="my">一个没有组织和精确元数据的数据存储，以使检索变得容易</em> " ( <a class="ae le" href="https://www.integrate.io/blog/turning-your-data-lake-into-a-data-swamp/#:~:text=A%20data%20swamp%20is%20essential,gathered%20and%20dumped%20into%20storage." rel="noopener ugc nofollow" target="_blank"> Integrate.io </a>)。</p><p id="ee85" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">数据沼泽可能会很快出现，并给希望实施高级分析解决方案的数据驱动型公司带来问题。如果对数据进行严密管理，并执行持续的数据健康状态检查，Data Lake有可能为公司提供一个准确的、改变游戏规则的业务洞察工具。</p><blockquote class="mz"><p id="ade0" class="na nb iq bd nc nd ne nf ng nh ni ms dk translated">全面控制数据湖中的持久数据，并知道会从数据湖中得到什么，以防止它变成数据沼泽，变得越来越重要和相关。</p></blockquote><p id="f13d" class="pw-post-body-paragraph ma mb iq mc b md nj ka mf mg nk kd mi lo nl mk ml ls nm mn mo lw nn mq mr ms ij bi translated">为此，我们实施了数据质量工作流，以支持不同的业务部门完成数据验证的高要求任务，跟踪数据运行状况、漂移和异常情况。这有助于人们不断评估摄取的和转换的数据，增强数据的可靠性和数据驱动产品的总体质量。</p><p id="0aec" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">该工作流是围绕开源框架<a class="ae le" href="http://helps data teams eliminate pipeline debt, through data testing, documentation" rel="noopener ugc nofollow" target="_blank"> Great Expectations </a> (GE)构建的，该框架将自己定义为“<em class="my">一个共享的、开放的数据质量标准，帮助数据团队始终知道对新数据有什么期望。</em>“GE是一个python包，它使我们能够编写测试并评估数据质量。它的简单性和可定制性允许我们轻松地将其与ETL管道集成，以验证我们从输入和输出数据中期望的得到满足。</p><p id="84da" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">在本文中，我们介绍了Mediaset的数据质量工作流的体系结构。我们列出了促使我们构建它的关键点以及整个涉及的技术堆栈。</p><h1 id="7fc7" class="no lg iq bd lh np nq nr lk ns nt nu ln kf nv kg lr ki nw kj lv kl nx km lz ny bi translated">Mediaset的数据湖:一个实际的用例</h1><p id="be65" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">Mediaset是意大利和西班牙领先的私营电视出版商，是真正的观众领导者，拥有五个公共网络和30多个免费和付费主题频道。</p><p id="ba54" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">每天，数百万人观看视频点播和直播，阅读文章，收听Mediaset服务提供的广播节目。人们通过不同的设备与媒体集属性进行交互:智能手机、网络浏览器、智能电视和互联网电视。所有这些视频浏览量、页面浏览量和点击量都来自Mediaset系统，以了解我们的客户(<em class="my">那些接受简介的客户</em>)喜欢看、读和听什么，并提高产品的总体质量。</p><p id="c704" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">在过去几年中，Mediaset决定投入资源设计和构建一个数据湖，以存储用户通过公司提供的几个平台和服务与其设备进行交互时产生的所有数据。</p><p id="ccd3" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">为了勾勒出Mediaset工作的总体环境和数量级，我们提供了由<em class="my">Mediaset Business Digital(MBD)</em>提供的摘要信息，该业务部门负责客户开发、数据接收和第一层数据转换的提供:</p><ul class=""><li id="c190" class="nz oa iq mc b md mt mg mu lo ob ls oc lw od ms oe of og oh bi translated">媒体集数据湖每天存储约100千兆字节的客户端生成的原生数据及其与媒体集属性和平台(流媒体平台、新闻网站、博客和电台)的交互；</li><li id="3357" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">获取几种类型的数据:点击流、页面浏览量、视频浏览量、视频播放器互动、营销活动结果、服务台票证、社交媒体反馈等等；</li><li id="c3fe" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">数据湖存储从客户端获取的原始数据和ETL管道的输出，由业务和数据分析师用于数据探索任务，由数据科学家用于机器学习模型训练；</li><li id="c0a8" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">从第一天起，当一个新的平台、服务或资产出现时，数据就存储在数据湖中，以后当业务需求精确时再激活它们。</li></ul><h2 id="415c" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">大数据，大责任</h2><p id="91f6" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">随着数据湖的发展，存储数据量的增加，以及每天查询和激活数据的人数的增加，控制数据湖健康状态的必要性开始出现。</p><p id="439a" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">更具体地说，<em class="my">遇到的临界点有四个</em>:</p><ol class=""><li id="47e9" class="nz oa iq mc b md mt mg mu lo ob ls oc lw od ms on of og oh bi translated">验证已发布的客户端(移动应用程序、智能电视应用程序和网站)正在正确跟踪所有事件(点击、查看和操作)，因此存储在数据湖中的所有数据都是正确和可信的。否则，必须将任何发现的问题通知开发团队，以便尽快解决。</li><li id="72ee" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms on of og oh bi translated">扩展ETL管道单元测试，检查实现的转换是否返回您期望的输出。</li><li id="3a6e" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms on of og oh bi translated">监控所有管道或所有服务是否启动并运行，跟踪每天的数据量变化。</li><li id="b37c" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms on of og oh bi translated">检测机器学习模型中涉及的数据集中的数据漂移或数据退化，防止错误预测或误导性预测。</li></ol><blockquote class="mz"><p id="8f0b" class="na nb iq bd nc nd oo op oq or os ms dk translated">这些要点促使Mediaset业务数字部门开发了一个能够监控数据湖健康状态的数据质量工作流程。</p></blockquote><p id="ea0c" class="pw-post-body-paragraph ma mb iq mc b md nj ka mf mg nk kd mi lo nl mk ml ls nm mn mo lw nn mq mr ms ij bi translated">这个过程中涉及的主要工具是<a class="ae le" href="https://greatexpectations.io/" rel="noopener ugc nofollow" target="_blank"> Great Expectations </a> (GE)，它提供了采用Spark作为执行引擎的可能性，非常适合当前的Mediaset数据堆栈。GE也是一个开源项目，拥有巨大的社区支持，被设计成可扩展和完全可定制的。</p><h1 id="f77e" class="no lg iq bd lh np nq nr lk ns nt nu ln kf nv kg lr ki nw kj lv kl nx km lz ny bi translated">数据质量工作流概述</h1><blockquote class="ot ou ov"><p id="a038" class="ma mb my mc b md mt ka mf mg mu kd mi ow mv mk ml ox mw mn mo oy mx mq mr ms ij bi translated"><strong class="mc ja">注意</strong>:这不是一个“远大前程简介”教程，而是我们实现的监控数据湖健康状态的架构的概述，以及我们如何使用GE来完成这项任务。<br/></p></blockquote><p id="5bc7" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">该工作流已经开发并与基于Amazon Web Services (AWS)的当前媒体集数据堆栈集成。涉及的主要服务有:</p><ul class=""><li id="b4e1" class="nz oa iq mc b md mt mg mu lo ob ls oc lw od ms oe of og oh bi translated"><strong class="mc ja"> <em class="my">亚马逊S3:“</em></strong>一种对象存储服务，提供业界领先的可扩展性、数据可用性、安全性和性能<strong class="mc ja"><em class="my">”(</em></strong><a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html" rel="noopener ugc nofollow" target="_blank">AWS</a>)<strong class="mc ja"><em class="my">)。这是中央数据湖存储器，所有接收和转换的数据都存储在这里。</em></strong></li><li id="e913" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated"><strong class="mc ja"><em class="my">AWS Glue Data Catalog:“</em></strong>提供了跨多种数据源和数据格式的统一元数据库。它提供了与亚马逊S3、亚马逊雅典娜和亚马逊EMR的开箱即用集成”(<a class="ae le" href="https://docs.aws.amazon.com/athena/latest/ug/glue-faq.html#faq-benefits" rel="noopener ugc nofollow" target="_blank"> AWS </a>)。</li><li id="94f2" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated"><strong class="mc ja"> <em class="my">亚马逊EMR:“</em></strong>一个托管集群平台，简化在AWS上运行大数据框架，如Apache Spark，以处理和分析海量数据”(<a class="ae le" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html" rel="noopener ugc nofollow" target="_blank"> AWS </a>)。Amazon EMR代表了MBD单元所采用的ETL工作的领先AWS服务；这与作为数据协调器的Airflow相结合，使我们能够开发和安排日常转换例程。</li><li id="dbc4" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated"><strong class="mc ja"> <em class="my">亚马逊Athena: </em> </strong>“一种交互式查询服务，可以使用标准SQL轻松分析存储在亚马逊S3的数据”(<a class="ae le" href="https://docs.aws.amazon.com/athena/latest/ug/what-is.html" rel="noopener ugc nofollow" target="_blank"> AWS </a>)。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/9820a13220e497662a84d965ab5604c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4J34aqLw96GEsFilH3v7cw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">数据质量工作流架构(图片由作者提供)</p></figure><p id="1c0c" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">实施的数据质量工作流程(参见上述架构)包括五个步骤。</p><h2 id="d623" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak"> 1。数据质量套件开发</strong></h2><p id="01f5" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">一切都从这里开始，从本地开发环境开始，这允许你开发GE称之为<a class="ae le" href="https://docs.greatexpectations.io/docs/reference/expectations/#expectation-suites" rel="noopener ugc nofollow" target="_blank"> <em class="my">的期望套件</em> </a>，一组规则(<a class="ae le" href="https://docs.greatexpectations.io/docs/reference/expectations/" rel="noopener ugc nofollow" target="_blank">期望</a>)描述你对数据集的期望。该环境由一个Docker映像组成，该映像运行一个带有PySpark的Jupyter notebook实例和您需要的所有python包。一旦您获得了想要评估的数据子集(原始数据或经过处理的数据)，您就可以在笔记本上编写数据必须满足的所有期望，并以JSON文件的形式生成期望套件。</p><p id="11e2" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">基于docker的开发环境也在<a class="ae le" href="https://docs.greatexpectations.io/docs/terms/custom_expectation" rel="noopener ugc nofollow" target="_blank">定制期望</a>开发期间支持你；您可以使用Docker映像作为远程python解释器，在您最喜欢的IDE中对所有期望进行编码和测试。</p><p id="1f45" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">开发定制期望的可能性代表了GE为我们的工作流程提供的最重要的特征之一。这些类型的期望确实允许我们测试甚至是最复杂的多列条件，给予细致的数据验证。</p><blockquote class="ot ou ov"><p id="da76" class="ma mb my mc b md mt ka mf mg mu kd mi ow mv mk ml ox mw mn mo oy mx mq mr ms ij bi translated"><strong class="mc ja">奖金</strong>:检查<a class="ae le" href="https://github.com/MDS-BD/hands-on-great-expectations-with-spark/tree/master/data_quality/custom_expectations" rel="noopener ugc nofollow" target="_blank">仓库</a>中三个定制期望类型的代码:单列、对列和多列。它还包括单元测试以及使用PyCharm使用所提供的Docker映像运行它们的步骤。</p></blockquote><h2 id="a62a" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak"> 2。套件部署</strong></h2><p id="fde7" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">一旦套件准备就绪(<em class="my">文档化和测试</em>)，提交到git存储库的主分支将触发一个持续集成管道，该管道将编译好的期望套件和所有定制的期望python模块复制到一个S3桶中。CI管道还负责生成最新的GE数据文档，并将其存储在专用的S3存储桶中。</p><h2 id="0e27" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak"> 3。数据验证运行</strong></h2><p id="87ea" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">是时候真正评估这些数据有多好了。如上所述，我们采用Airflow作为数据编排器，其中我们实现了几个数据质量Dag。详细来说，<em class="my">对于原始数据，我们有专门运行验证作业</em>的专用DAG(这种DAG涉及的<code class="fe pa pb pc pd b">Operators</code>和<code class="fe pa pb pc pd b">Sensors</code>的顺序见下图)；</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/30b525b2936ddf62007c28bc86bec7b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iv5QQrWSkwpNT4df5IVhCw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">验证原始数据质量的气流DAG结构(图片由作者提供)</p></figure><p id="a374" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">在<em class="my">处理数据时，我们将验证气流任务附加到转换任务</em>(见下图)以使整个处理层保持一致:如果转换生成质量较差的数据，我们会收到警报，以便我们可以中断所有后续任务(见步骤4)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pf"><img src="../Images/463a3fa7e62057a64ae2e6569d10863f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTLKHIqreuOFUPAa65CV3A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">验证处理数据质量的气流DAG结构(图片由作者提供)</p></figure><p id="7f2f" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">验证作业获取先前开发和部署的期望套件和定制期望作为输入。数据验证输出是一个JSON文件，在S3上以原始格式存储后，通过气流<code class="fe pa pb pc pd b">PythonOperator</code>进行解析，并作为分区的拼花文件保存在数据湖中。最后，AWS Glue数据目录中的元数据用新的分区进行了更新，使得数据质量验证结果可以用Amazon Athena进行查询。</p><blockquote class="ot ou ov"><p id="6284" class="ma mb my mc b md mt ka mf mg mu kd mi ow mv mk ml ox mw mn mo oy mx mq mr ms ij bi translated"><strong class="mc ja">额外收获</strong>:在配套的<a class="ae le" href="https://github.com/MDS-BD/hands-on-great-expectations-with-spark/tree/master/data_quality" rel="noopener ugc nofollow" target="_blank">资源库</a>中，你可以找到一个现成的“验证你的数据”作业，你可以快速<strong class="mc ja">运行它来模拟我们在这一步用Amazon EMR </strong>实现的东西(即Docker容器运行一个<code class="fe pa pb pc pd b">spark-submit</code>命令来执行数据验证python模块)。</p></blockquote><h2 id="a2fa" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak"> 4。数据验证结果分析</strong></h2><p id="8750" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">我们决定将<a class="ae le" href="https://superset.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache超集</a>集成到数据质量工作流中，以探索验证结果，并使其可视化尽可能有影响力。Superset是一个开源的数据探索和可视化平台，能够连接到现代数据库(包括Amazon Athena)，易于掌握，内置丰富的可视化情节。由于其简单性，超集使我们能够专注于核心任务，例如设计定制指标和通过交互式仪表板可视化见解来评估我们的数据质量，而不是工具本身(参见下面的截图以获得样本超集数据质量仪表板)。</p><p id="5ac7" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">用于评估数据的指标示例如下:</p><ul class=""><li id="7270" class="nz oa iq mc b md mt mg mu lo ob ls oc lw od ms oe of og oh bi translated">数据量</li><li id="2670" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">不成功的期望百分比</li><li id="c8fe" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">至少有一个不成功预期的所有列的列表</li><li id="049b" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">每列的<em class="my">错误</em>记录的百分比</li><li id="78df" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">第一个<em class="my"> n </em>预期不成功的每列的意外值。</li></ul><p id="ce08" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">超集最后提供了两个对工作流有用的关键特性:</p><ul class=""><li id="3032" class="nz oa iq mc b md mt mg mu lo ob ls oc lw od ms oe of og oh bi translated"><strong class="mc ja"> <em class="my">警报</em> </strong> <em class="my"> </em>在达到SQL条件时被触发，发送一个关于Slack的通知或电子邮件。您可以为您想要监控的KPI设置阈值(<em class="my">，例如，“今天和昨天运行之间的不成功预期数的变化必须低于10%”，</em>，当条件不满足时，将发送通知警报。</li><li id="69ce" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated"><strong class="mc ja"> <em class="my">报告</em> </strong> <em class="my">按计划发送，允许您分析与上周</em>相关的验证结果，以更有条理、更清晰的方式传达结果。</li></ul><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pg"><img src="../Images/0ab0332f2b29bb43406effa00d4258d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2W-6NjmFJk4__P5BJ9gLKQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">“超集数据质量仪表板”的示例—仪表板由以下部分组成:a) <em class="ph">左上角的</em>数据量直方图，按媒体集属性分组；b)在右上角的环形图上，显示每个媒体集属性的不成功预期数；c)对于每个数据集列，列出不成功的期望、用于评估被检查列的补充列(在多列期望的情况下)以及有问题的属性的数量的表格；d)折线图，按属性分组，显示所选列的每日(上个月)不成功记录的百分比-期望值。(图片由作者提供)</p></figure><h2 id="70a0" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated"><strong class="ak"> 5。数据文件</strong></h2><p id="97c5" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">该工作流程的最后一步是发布数据文档网站，该网站之前由Great Expectations通过CI pipeline触发器生成。Data Docs包含属于每一列的所有期望的完整列表，以及由表和套件组织的已实现规则的描述。除了为每个期望套件提供文档外，【Great Expectations Data Docs还允许我们与非技术人员分享为每个表开发的检查，从而更容易讨论可能的和未来的套件增强。</p><h2 id="a368" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">结论</h2><p id="78f6" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">在本文中，我们向您展示了基于Great Expectations实现的工作流，它赋予Mediaset持续监控数据湖健康状态的能力。这防止了数据湖变成数据沼泽，保持了数据的高可靠性，提高了所有涉及数据的项目的质量。</p><p id="cb32" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">一旦部署了数据质量工作流程，不同Mediaset业务部门的开发人员只需专注于Expectation Suites开发和(<em class="my">显然是</em>)数据质量警报和报告分析。</p><p id="f15e" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">本地开发环境为所有业务单元提供了一个舒适的地方来开发它们的套件，因此，在监视它们权限内的数据时是独立的。每个业务单位都能够拒绝自己的需求，并通过本地和定制的期望使它们达到更高的期望。</p><p id="c313" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">开发环境结合了云的能力和弹性，以及EMR等服务，允许在任何规模上应用期望，包括原始数据和处理后的数据，主动监控我们每天摄取并保存在我们心爱的数据湖中的内容。在这种情况下，EMR集群的成本将取决于您想要评估的数据集的大小、套件中包含的预期数量以及已经实现的自定义预期的复杂性。</p><p id="6b92" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated"><em class="my">套件中所有控件的组织-每表</em>，以及数据文档的自动生成，为所有用户提供了一种简单的方式来检查期望套件所覆盖的表的列表，并查阅为每一列实现的逻辑。</p><p id="2f38" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">最后，可视化工具允许数据验证结果分析民主化，使得那些希望在使用数据之前对表或数据湖进行状态检查的非技术人员也可以访问这些结果。</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><p id="a26d" class="pw-post-body-paragraph ma mb iq mc b md mt ka mf mg mu kd mi lo mv mk ml ls mw mn mo lw mx mq mr ms ij bi translated">感谢您阅读我们的作品！<br/>如果您有问题或反馈，请随时给我发送<a class="ae le" href="https://www.linkedin.com/in/davideromano90/" rel="noopener ugc nofollow" target="_blank">连接</a>。</p><h2 id="286b" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">承认</h2><p id="9d02" class="pw-post-body-paragraph ma mb iq mc b md me ka mf mg mh kd mi lo mj mk ml ls mm mn mo lw mp mq mr ms ij bi translated">感谢来自Mediaset的<a class="ae le" href="https://www.linkedin.com/in/nicola-saraceni-9228b0127/" rel="noopener ugc nofollow" target="_blank"> Nicola </a>、<a class="ae le" href="https://www.linkedin.com/in/daniele-c-367b904/" rel="noopener ugc nofollow" target="_blank"> Daniele </a>、<a class="ae le" href="https://www.linkedin.com/in/fabiomelen/" rel="noopener ugc nofollow" target="_blank"> Fabio </a>、来自Coveo的<a class="ae le" href="https://www.linkedin.com/in/jacopotagliabue/" rel="noopener ugc nofollow" target="_blank"> Jacopo </a>和来自Tecton的<a class="ae le" href="https://www.linkedin.com/in/danny-chiao/" rel="noopener ugc nofollow" target="_blank"> Danny </a>对本文和Github资源库的评论和建议。</p></div><div class="ab cl pi pj hu pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="ij ik il im in"><h2 id="4536" class="lf lg iq bd lh li lj dn lk ll lm dp ln lo lp lq lr ls lt lu lv lw lx ly lz iw bi translated">参考</h2><ul class=""><li id="f0a0" class="nz oa iq mc b md me mg mh lo pp ls pq lw pr ms oe of og oh bi translated">什么是数据湖？—亚马逊网络服务(AWS)。<a class="ae le" href="https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/" rel="noopener ugc nofollow" target="_blank">https://AWS . Amazon . com/big-data/data lakes-and-analytics/what-a-data-lake/</a></li><li id="2567" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">把你的数据湖变成数据沼泽| integrate . io .<a class="ae le" href="https://www.integrate.io/blog/turning-your-data-lake-into-a-data-swamp/" rel="noopener ugc nofollow" target="_blank">https://www . integrate . io/blog/turning-Your-Data-Lake-Into-a-Data-Swamp/</a></li><li id="1eb8" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">什么是亚马逊S3？—亚马逊网络服务(AWS)。<br/><a class="ae le" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/Amazon S3/latest/user guide/welcome . html</a></li><li id="1f52" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">升级到AWS Glue数据目录— Amazon Athena。<a class="ae le" href="https://docs.aws.amazon.com/athena/latest/ug/glue-faq.html" rel="noopener ugc nofollow" target="_blank">https://docs.aws.amazon.com/athena/latest/ug/glue-faq.html</a></li><li id="8de6" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">什么是亚马逊EMR？—亚马逊网络服务(AWS)。<br/><a class="ae le" href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-what-is-emr.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/EMR/latest/management guide/EMR-what-is-EMR . html</a></li><li id="37ff" class="nz oa iq mc b md oi mg oj lo ok ls ol lw om ms oe of og oh bi translated">亚马逊雅典娜是什么？—亚马逊网络服务(AWS)。<br/><a class="ae le" href="https://docs.aws.amazon.com/athena/latest/ug/what-is.html" rel="noopener ugc nofollow" target="_blank">https://docs.aws.amazon.com/athena/latest/ug/what-is.html</a></li></ul></div></div>    
</body>
</html>