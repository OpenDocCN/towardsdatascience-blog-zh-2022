<html>
<head>
<title>Triplet Loss — Advanced Intro</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">三重损失—高级简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905#2022-03-24">https://towardsdatascience.com/triplet-loss-advanced-intro-49a07b7d8905#2022-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6daf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">三重损失比对比损失有什么优势，如何高效实现？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/c7118fd1d12d34c25ddf7fc9c6c5f375.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Evpi9IqvPVRqqv9HEVLitg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">三重损失下移动点的路径。图片作者。</p></figure><p id="066a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">三重损失最早于 2015 年在<a class="ae ln" href="https://arxiv.org/abs/1503.03832" rel="noopener ugc nofollow" target="_blank"> FaceNet:人脸识别和聚类的统一嵌入</a>中引入，此后它一直是监督相似性或度量学习最受欢迎的损失函数之一。用最简单的解释来说，三重态损失促使不同的线对与任何相似的线对相距至少一定的余量值。数学上，损失值可计算为<code class="fe lo lp lq lr b">L=max(d(a, p) - d(a, n) + m, 0)</code>，其中:</p><ul class=""><li id="bcfe" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm lx ly lz ma bi translated"><code class="fe lo lp lq lr b">p</code>，即阳性，是与<code class="fe lo lp lq lr b">a</code>标签相同的样本，即锚，</li><li id="c7a3" class="ls lt iq kt b ku mb kx mc la md le me li mf lm lx ly lz ma bi translated"><code class="fe lo lp lq lr b">n</code>，即阴性，是另一个标签不同于<code class="fe lo lp lq lr b">a</code>的样品，</li><li id="1f23" class="ls lt iq kt b ku mb kx mc la md le me li mf lm lx ly lz ma bi translated"><code class="fe lo lp lq lr b">d</code>是测量这三个样本之间距离的函数，</li><li id="c09a" class="ls lt iq kt b ku mb kx mc la md le me li mf lm lx ly lz ma bi translated">并且<code class="fe lo lp lq lr b">m</code>是保持负样本远离的裕度值。</li></ul><p id="2f7c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该论文使用欧几里德距离，但是使用任何其他距离度量也同样有效，例如余弦距离。</p><p id="b60f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该功能有一个学习目标，可以如下图所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mg"><img src="../Images/1901105f01e182c2b43a9cc999b5fa2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADu4F-SoI-cLqyO0IqqBrQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">三重损失目标。作者图片</p></figure><p id="fbcc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，三元组丢失不会像对比丢失那样具有促使将锚和正样本编码到向量空间中的同一点的副作用。这使得三重损失容忍一些类内差异，不像对比损失，因为后者迫使锚和任何正值之间的距离基本上为<code class="fe lo lp lq lr b">0</code>。换句话说，三联体丢失允许以包括异常值的方式拉伸聚类，同时仍然确保来自不同聚类(例如，负对)的样本之间的余量。</p><p id="054f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另外，三重态损失不太贪婪。与对比损失不同，当不同的样本很容易从相似的样本中区分出来时，它就已经令人满意了。如果没有负面例子的干扰，它不会改变正面簇中的距离。这是因为三重损耗试图确保负对距离和正对距离之间的余量。然而，对比损失仅在比较不相似对时才考虑裕度值，它根本不关心相似对在该时刻的位置。这意味着对比损失可以更早地达到局部最小值，而三重损失可以继续以更好的状态组织向量空间。</p><p id="c2b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们通过动画演示两个损失函数如何组织向量空间。为了更简单的可视化，向量由二维空间中的点表示，并且它们是从正态分布中随机选择的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/404f41e53aca74bb264e0218ddef9b3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/0*9ouGHpVpgmNy1Nrv.gif"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">展示对比损失如何在培训过程中移动点数的动画。图片作者。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/083199fb264f9c41da36af639aa6dda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/0*tn3xh9wT3E9uyonE.gif"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">展示三连音缺失如何在训练过程中移动点数的动画。图片作者。</p></figure><p id="09cb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从对双损耗函数的数学解释来看，很明显，三重损耗在理论上更强，但三重损耗有更多的技巧来帮助它更好地工作。最重要的是，三元组丢失引入了在线三元组挖掘策略，例如，自动形成最有用的三元组。</p><h2 id="fb67" class="ml mm iq bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc nd bi translated">为什么三重开采很重要？</h2><p id="7bd8" class="pw-post-body-paragraph kr ks iq kt b ku ne jr kw kx nf ju kz la ng lc ld le nh lg lh li ni lk ll lm ij bi translated">三重损失的公式表明它同时作用于三个物体:</p><ol class=""><li id="b4c0" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm nj ly lz ma bi translated"><code class="fe lo lp lq lr b">anchor</code>，</li><li id="f225" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated"><code class="fe lo lp lq lr b">positive</code> -与锚具有相同标签的样品，</li><li id="9437" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">和<code class="fe lo lp lq lr b">negative</code>——一个标签与锚和正不同的样本。</li></ol><p id="aaab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在一个简单的实现中，我们可以在每个时期的开始形成这样的样本三元组，然后在整个时期将成批的这样的三元组提供给模型。这就是所谓的“线下策略”然而，由于几个原因，这不是很有效:</p><ul class=""><li id="0b11" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm lx ly lz ma bi translated">它需要通过<code class="fe lo lp lq lr b">3n</code>个样本才能得到<code class="fe lo lp lq lr b">n</code>个三元组的损失值。</li><li id="5b1d" class="ls lt iq kt b ku mb kx mc la md le me li mf lm lx ly lz ma bi translated">并非所有这些三元组都对模型学习任何东西有用，例如，产生正损失值。</li><li id="1369" class="ls lt iq kt b ku mb kx mc la md le me li mf lm lx ly lz ma bi translated">即使我们用我将在本系列中实现的方法之一在每个时期的开始形成“有用的”三元组，它们也可能在时期中的某个点变得“无用”,因为模型权重将不断更新。</li></ul><p id="275e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">相反，我们可以得到一批<code class="fe lo lp lq lr b">n</code>样本和它们相关的标签，并动态地形成三元组。这就是所谓的“在线策略”通常，这给出了<code class="fe lo lp lq lr b">n^3</code>可能的三元组，但是只有这些可能的三元组的子集实际上是有效的。即使在这种情况下，我们也会从比离线策略多得多的三元组中计算出损失值。</p><p id="eceb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">给定三个一组的<code class="fe lo lp lq lr b">(a, p, n)</code>，它仅在以下情况下有效:</p><ol class=""><li id="7b8c" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm nj ly lz ma bi translated"><code class="fe lo lp lq lr b">a</code>和<code class="fe lo lp lq lr b">p</code>有相同的标号，</li><li id="dc7d" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated"><code class="fe lo lp lq lr b">a</code>和<code class="fe lo lp lq lr b">p</code>是不同的样本，</li><li id="06b9" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">并且<code class="fe lo lp lq lr b">n</code>具有与<code class="fe lo lp lq lr b">a</code>和<code class="fe lo lp lq lr b">p</code>不同的标签。</li></ol><p id="3d9a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些约束可能看起来需要使用嵌套循环进行昂贵的计算，但它可以通过距离矩阵、屏蔽和广播等技巧有效地实现。本系列的其余部分将集中在这些技巧的实现上。</p><h2 id="b512" class="ml mm iq bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc nd bi translated">距离矩阵</h2><p id="0647" class="pw-post-body-paragraph kr ks iq kt b ku ne jr kw kx nf ju kz la ng lc ld le nh lg lh li ni lk ll lm ij bi translated">距离矩阵是形状为<code class="fe lo lp lq lr b">(n, n)</code>的矩阵，用于保存由两个<code class="fe lo lp lq lr b">n</code>大小的集合中的项目组成的所有可能对之间的距离值。该矩阵可用于矢量化计算，否则将需要低效的循环。它的计算也可以优化，我们将实现 Samuel Albanie 解释的<a class="ae ln" href="https://www.robots.ox.ac.uk/~albanie/notes/Euclidean_distance_trick.pdf" rel="noopener ugc nofollow" target="_blank">欧几里德距离矩阵技巧(PDF) </a>。您可能想阅读这份三页的文档，以全面了解这个技巧，但下面是一个简短的解释:</p><ol class=""><li id="3758" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm nj ly lz ma bi translated">计算两个向量集合的点积，例如，在我们的例子中是嵌入。</li><li id="9a84" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">从这个矩阵中提取对角线，它包含每个嵌入的平方欧几里德范数。</li><li id="2fb5" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">基于以下等式计算平方欧几里德距离矩阵:<code class="fe lo lp lq lr b">||a - b||^2 = ||a||^2 - 2 ⟨a, b⟩ + ||b||^2</code></li><li id="6977" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">对于非平方距离，求这个矩阵的平方根。</li></ol><p id="21b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将在 PyTorch 中实现它，所以我们从导入开始。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h2 id="79f9" class="ml mm iq bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc nd bi translated">无效的三元组屏蔽</h2><p id="9fae" class="pw-post-body-paragraph kr ks iq kt b ku ne jr kw kx nf ju kz la ng lc ld le nh lg lh li ni lk ll lm ij bi translated">既然我们可以为一批中所有可能的嵌入对计算距离矩阵，我们可以应用广播来枚举所有可能的三元组的距离差异，并在形状为<code class="fe lo lp lq lr b">(batch_size, batch_size, batch_size)</code>的张量中表示它们。然而，正如我前面提到的，这些<code class="fe lo lp lq lr b">n^3</code>三元组中只有一个子集是有效的，我们需要一个相应的掩码来正确计算损失值。我们将分三步实现这样一个助手函数:</p><ol class=""><li id="23ab" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm nj ly lz ma bi translated">计算不同索引的掩码，例如<code class="fe lo lp lq lr b">(i != j and j != k)</code>。</li><li id="5fae" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">计算有效锚点正-负三元组的掩码，例如<code class="fe lo lp lq lr b">labels[i] == labels[j] and labels[j] != labels[k]</code>。</li><li id="d9d4" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">结合两个面具。</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h2 id="3eb4" class="ml mm iq bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc nd bi translated">在线三元组挖掘的批量策略</h2><p id="2551" class="pw-post-body-paragraph kr ks iq kt b ku ne jr kw kx nf ju kz la ng lc ld le nh lg lh li ni lk ll lm ij bi translated">现在，我们已经准备好实际实现三重态损失本身。三联体丢失涉及形成或选择三联体的几种策略，最简单的一种是使用所有有效的三联体，这些三联体可以由一批样品形成。由于我们已经实施了实用程序功能，这可以通过四个简单的步骤实现:</p><ol class=""><li id="f7ca" class="ls lt iq kt b ku kv kx ky la lu le lv li lw lm nj ly lz ma bi translated">获得所有可能对的距离矩阵，这些可能对可以由一批嵌入形成。</li><li id="8de0" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">将广播应用于该矩阵，以计算所有可能的三元组的损失值。</li><li id="db57" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">将无效或简单三连音的损失值设置为<code class="fe lo lp lq lr b">0</code>。</li><li id="27c8" class="ls lt iq kt b ku mb kx mc la md le me li mf lm nj ly lz ma bi translated">对剩余的正值求平均值，以返回标量损失。</li></ol><p id="d40b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将从实施这一策略开始，更复杂的将作为单独的文章跟进。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nk nl l"/></div></figure><h2 id="59f1" class="ml mm iq bd mn mo mp dn mq mr ms dp mt la mu mv mw le mx my mz li na nb nc nd bi translated">结论</h2><p id="eb58" class="pw-post-body-paragraph kr ks iq kt b ku ne jr kw kx nf ju kz la ng lc ld le nh lg lh li ni lk ll lm ij bi translated">我提到过，三元组损失与对比损失不仅在数学上不同，而且在样本选择策略上也不同，在这篇文章中，我通过使用几个技巧有效地实现了在线三元组挖掘的批量策略。还有其他更复杂的策略，比如批量硬挖掘和批量半硬挖掘，但是它们的实现，以及我在这篇文章中使用的提高效率的技巧的讨论，值得单独发表。未来的帖子将涵盖这些主题，并对一些技巧进行额外的讨论，以避免向量折叠并控制类内和类间的差异。同时，您可以加入 Qdrant 的 Discord 服务器，讨论、了解更多信息，并就公制学习提出问题。</p><div class="nm nn gp gr no np"><a href="https://discord.com/invite/tdtYvXjC4h" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">加入 qdrant Discord 服务器！</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">在 Discord 上查看 qdrant 社区-与 111 名其他成员一起闲逛，享受免费语音和文本聊天。</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">discord.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kl np"/></div></div></a></div><p id="5e26" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最初发布于<a class="ae ln" href="https://qdrant.tech/articles/triplet-loss/" rel="noopener ugc nofollow" target="_blank">https://qdrant.tech/articles/triplet-loss/</a></p></div></div>    
</body>
</html>