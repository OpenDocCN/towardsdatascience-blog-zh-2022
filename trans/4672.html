<html>
<head>
<title>How to run inference with a PyTorch time series Transformer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用PyTorch时序转换器运行推理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-run-inference-with-a-pytorch-time-series-transformer-394fd6cbe16c#2022-10-18">https://towardsdatascience.com/how-to-run-inference-with-a-pytorch-time-series-transformer-394fd6cbe16c#2022-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2e4c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在您不知道解码器输入的情况下，在推断时间使用PyTorch转换器进行时间序列预测</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a3c24d1314f123d98a2397d943ea8dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KZDCVJBpmVbnJ3Wq"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@spacexuan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">郭锦恩</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="64a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇文章中，我将展示如何使用PyTorch转换器进行时间序列预测。具体来说，我们将使用PyTorch时间序列转换器，我在上一篇文章<a class="ae kv" rel="noopener" target="_blank" href="/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e">中描述了如何使用PyTorch </a>制作用于时间序列预测的转换器。</p><p id="a633" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的结构如下:首先，我将简要描述PyTorch时序转换器需要什么输入。然后，我将向您展示当您不知道解码器输入值时，如何使用模型进行推理。最后，我将指出所示方法的一些缺点。</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">如何制作用于时间序列预测的PyTorch转换器</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">这篇文章将向你展示如何一步一步地将时序转换器架构图转换成PyTorch代码。</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj kp lv"/></div></div></a></div><h1 id="3d6c" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">时序转换器模型需要什么输入？</h1><p id="4966" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">如果你没有读过我的文章“如何为时间序列预测制作PyTorch转换器”，让我们先简单回顾一下时间序列转换器需要什么输入。关于更详细的演示，请参见上面提到的帖子。请注意，术语<code class="fe nh ni nj nk b">trg</code>和<code class="fe nh ni nj nk b">tgt</code>有时会在这篇文章和另一篇文章中互换使用。</p><p id="a5c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">变压器模型需要以下输入:</p><p id="1de7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj nk b">src</code>编码器所使用的。<code class="fe nh ni nj nk b">src</code>的形状必须是【批量大小，<em class="nl"> n </em>，输入特征的数量】或<em class="nl"> n </em>，批量大小，输入特征的数量(取决于<code class="fe nh ni nj nk b">batch_first</code>构造函数参数的值)，其中<em class="nl"> n </em>是输入序列中数据点的数量。例如，如果你正在预测每小时的电价，并且你想根据上周的数据进行预测，那么n=168。</p><p id="6d57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj nk b">tgt</code>是变压器需要的另一个输入。它被解码器使用。<code class="fe nh ni nj nk b">tgt</code>由<code class="fe nh ni nj nk b">src</code>中输入序列的最后一个值和目标序列除最后一个值以外的所有值组成。换句话说，它将具有[批量大小，<em class="nl"> m </em>，预测变量数]或[ <em class="nl"> m </em>，批量大小，预测变量数]的形状，其中<em class="nl"> m </em>是预测范围。继续电价预测的例子，如果你想提前48小时预测电价，那么<em class="nl"> m=48。</em></p><p id="749b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，编码器和解码器需要所谓的掩模。读者可以参考上面提到的关于屏蔽的介绍。</p><p id="0797" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们继续之前，另一件重要的事情是，我们在这篇博客文章中使用的特定时序转换器实现总是输出形状为[批量大小，<em class="nl"> m </em>，预测变量数]或[ <em class="nl"> m，</em>，批量大小，预测变量数]，【T22的张量，即模型输出序列的长度由在 <code class="fe nh ni nj nk b">tgt</code> <em class="nl">张量中给解码器的输入序列的长度决定。</em></p><p id="bcad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，如果<code class="fe nh ni nj nk b">tgt</code>具有形状【72，批量大小，1】，这意味着<code class="fe nh ni nj nk b">tgt</code>中序列的长度是72，因此模型也将输出72的序列。</p><div class="ls lt gp gr lu lv"><a rel="noopener follow" target="_blank" href="/multi-step-time-series-forecasting-with-xgboost-65d6820bec39"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">XGBoost多步时间序列预测</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">本文展示了如何使用XGBoost生成多步时间序列预测和24小时电价预测…</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">towardsdatascience.com</p></div></div><div class="me l"><div class="nm l mg mh mi me mj kp lv"/></div></div></a></div><h1 id="c7bc" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">如何使用时间序列转换器进行推理</h1><p id="9323" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">好了，准备工作已经就绪，现在让我们考虑一下为什么会有一篇关于如何使用转换器进行时间序列预测的博文:</p><p id="7496" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在训练期间，直接产生<code class="fe nh ni nj nk b">tgt</code>，因为我们知道目标序列的值。然而，在推理过程中(例如在生产环境中)，我们在进行预测时当然不知道目标序列的值——否则我们就不需要首先进行预测。因此，我们需要找到一种方法来产生一个合理的<code class="fe nh ni nj nk b">tgt</code>，它可以在推理过程中用作模型的输入。</p><p id="db14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们知道了时间序列转换器需要什么输入，以及为什么我们需要以某种方式生成<code class="fe nh ni nj nk b">tgt</code>，让我们看看实际上如何做。在接下来的内容中，请记住，总体目的是生成一个<code class="fe nh ni nj nk b">tgt</code>张量，该张量一旦生成，就可以用作模型的输入来进行预测。</p><p id="18bc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">举一个简单的例子来说明，假设在推断时间<em class="nl"> t </em>，我们想要根据序列的5个最近观察值来预测序列的下3个值。</p><p id="b149" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是<code class="fe nh ni nj nk b">src</code>的样子:</p><p id="1bdb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj nk b">src = [xt-4, xt-3, xt-2, xt-1, xt]</code></p><p id="0b26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<code class="fe nh ni nj nk b">x</code>表示我们正在处理的系列，例如电价。</p><p id="4f8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目标是预测<code class="fe nh ni nj nk b">tgt_y</code>，它将是:</p><p id="0320" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj nk b">tgt_y = [xt+1, xt+2, xt+3]</code></p><p id="97de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们的<code class="fe nh ni nj nk b">tgt</code>，模型需要它作为输入，以便对<code class="fe nh ni nj nk b">tgt_y</code>进行预测，应该是:</p><p id="5211" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nh ni nj nk b">tgt = [xt, xt+1, xt+2]</code></p><p id="d433" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们知道<code class="fe nh ni nj nk b">xt</code>的值，但不知道<code class="fe nh ni nj nk b">xt+1</code>和<code class="fe nh ni nj nk b">xt+2</code>的值，所以我们需要以某种方式估计这些值。在本文中，我们将首先预测<code class="fe nh ni nj nk b">xt+1</code>，然后将此预测添加到<code class="fe nh ni nj nk b">tgt</code>中，这样<code class="fe nh ni nj nk b">tgt = [xt, xt+1]</code>将使用此<code class="fe nh ni nj nk b">tgt</code>预测<code class="fe nh ni nj nk b">xt+2</code>，然后将此预测添加到<code class="fe nh ni nj nk b">tgt</code>中，这样<code class="fe nh ni nj nk b">tgt = [xt, xt+1, xt+2]</code>，最后使用此<code class="fe nh ni nj nk b">tgt</code>生成最终预测。</p><p id="fc6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的函数是您在PyTorch中使用时序转换器模型运行推理所需的代码。该函数根据上述方法生成预测。您传入一个Transformer模型和<code class="fe nh ni nj nk b">src</code>以及docstring中描述的一些其他参数。然后，该函数迭代生成<code class="fe nh ni nj nk b">tgt</code>，并基于由时间<em class="nl"> t </em>的最后已知观测值和剩余<em class="nl"> m-1 </em>数据点的估计值组成的<code class="fe nh ni nj nk b">tgt</code>生成最终预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="e7ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该函数设计用于验证或测试循环中。您可以调用推理函数，而不是调用模型来生成预测。下面是如何使用它的一个简单示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="b808" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，您不能照原样使用该脚本。这仅仅是一个展示整体思想的例子，并不意味着你可以复制粘贴并期望工作。例如，在让脚本工作之前，您需要实例化模型和数据加载器。在这篇博文的GitHub repo中，参见文件<em class="nl"> sandbox.py </em>中关于如何做的例子。如果你以前从未训练、验证和测试过PyTorch神经网络，我建议你看看PyTorch的初级教程<a class="ae kv" href="https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="1096" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">使用时序转换器运行推理的所示方法的缺点</h1><p id="9b88" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">假设推理函数依赖于一个循环来迭代产生<code class="fe nh ni nj nk b">tgt</code>，如果<em class="nl"> m </em>很大，该函数会很慢，因为这会增加循环中的迭代次数。这是上述方法的主要缺点。我没有足够的想象力想出一个更有效的方法，但是如果你有任何想法，我很乐意在评论区听到你的意见。也欢迎你直接参与回购。</p><p id="25ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设推理函数每批调用模型<em class="nl"> m-1 </em>次，您可能需要警惕一些增加调用模型的计算时间的事情，例如使用具有许多参数的模型或使用大的<em class="nl"> n. </em>此外，您拥有的批越多，推理函数将被调用的次数就越多，总的训练或测试脚本运行的时间就越长。</p><p id="5822" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用时序转换器运行推理的代码以及PyTorch转换器实现可以在以下报告中找到:</p><div class="ls lt gp gr lu lv"><a href="https://github.com/KasperGroesLudvigsen/influenza_transformer" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">GitHub-KasperGroesLudvigsen/influence _ Transformer:py torch实现的变压器模型…</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">PyTorch实现的变压器模型用于“时间序列预测的深度变压器模型:流感…</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">github.com</p></div></div><div class="me l"><div class="np l mg mh mi me mj kp lv"/></div></div></a></div></div><div class="ab cl nq nr hu ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ij ik il im in"><p id="7ce3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就是这样！我希望你喜欢这篇文章🤞</p><p id="7c2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请留下评论让我知道你的想法。</p><p id="0734" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关注更多与<a class="ae kv" rel="noopener" target="_blank" href="/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e">时间序列预测</a>、<a class="ae kv" href="https://kaspergroesludvigsen.medium.com/the-10-most-energy-efficient-programming-languages-6a4165126670" rel="noopener">绿色软件工程</a>和数据科学<a class="ae kv" rel="noopener" target="_blank" href="/8-podcast-episodes-on-the-climate-impact-of-machine-learning-54f1c19f52d">环境影响</a>相关的帖子🍀</p><p id="8733" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请随时在LinkedIn上与我联系。</p></div></div>    
</body>
</html>