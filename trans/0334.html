<html>
<head>
<title>Introducing Fugue — Reducing PySpark Developer Friction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">介绍神游—减少PySpark显影剂的摩擦</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introducing-fugue-reducing-pyspark-developer-friction-a702230455de#2022-02-14">https://towardsdatascience.com/introducing-fugue-reducing-pyspark-developer-friction-a702230455de#2022-02-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ed6b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">提高开发人员的工作效率，降低大数据项目的成本</h2></div><p id="0c3b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">这篇文章的最初版本发表在James Le的博客</em> <a class="ae lc" href="https://jameskle.com/writes/fugue" rel="noopener ugc nofollow" target="_blank"> <em class="lb">这里</em> </a> <em class="lb">。它已经更新，包括新的赋格功能。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/c11df0f56abcf6f48e6f2b1477e6e143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QvkX_aYJUXVZk2Fo"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">塞萨尔·卡里瓦里诺·阿拉贡在<a class="ae lc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="cfd5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">赋格的动机</h1><p id="1d2c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">数据从业者通常从使用Pandas或SQL开始。处理的数据量迟早会超出熊猫的处理能力，分布式计算就变得必不可少。Spark就是这样一个工具，它是一个流行的分布式计算框架，能够在一个机器集群上处理内存中的大量数据。虽然Spark引擎在扩展数据管道方面非常强大，但新用户，甚至是有经验的用户，在使用Spark时都会面临许多陷阱。</p><p id="ccbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预计最初的困难是必须学习一个全新的框架。Spark和Pandas的语法和用法很不一样。将项目从Pandas迁移到Spark的用户经常会发现自己要重新编写大部分代码，即使是完全相同的应用程序逻辑。更糟糕的是，一些在Pandas中微不足道的操作在Spark中变得更加困难，并且需要一段时间才能实现。</p><p id="91e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">这种差异的一个简单例子是获取每组数据的中位数。</strong>在熊猫身上，得到各组的中位数是不需要三思的。不过在Spark上，操作并不简单。我们在下面的代码片段中比较了两个框架的语法:</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">熊猫对星火的分组中位数</p></figure><p id="2fbb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种语法差异是因为在分布式设置中计算中值的开销很大。属于一个组的所有数据都需要移动到同一台机器上。因此，在获得中位数之前，需要对数据进行洗牌和排序。为了降低计算成本，可以用指定的容差获得近似的中值。在上面的代码片段中，20是精度，意味着相对误差可能是1/20，或5%。指定容差允许用户平衡精度和速度。</p><p id="7eff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了语法上的差异，<strong class="kh ir">分布式环境中还有一些重要的概念(比如分区、混排、持久化和惰性评估)</strong>Pandas用户最初并没有意识到。这些概念需要大量的时间来学习和掌握，这使得很难充分利用火花发动机。</p><p id="4b5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lc" href="https://github.com/fugue-project/fugue" rel="noopener ugc nofollow" target="_blank"> Fugue </a>，一个开源的抽象层，提供了从单机到分布式计算设置的无缝过渡。使用Fugue，用户可以用原生Python、Pandas或SQL编写他们的逻辑，然后将其带到Spark(或Dask)引擎执行。这意味着<strong class="kh ir">用户甚至不需要学习Spark语法就可以使用Spark。</strong></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ms"><img src="../Images/2d29cab128346d66633d091eac339845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QgMjc3vz7_twxzjh"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">图片作者:神游logo</p></figure><p id="8f65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文将讨论Spark用户面临的棘手问题以及Fugue如何解决这些问题。<strong class="kh ir">神游是几年来对如何改善Spark开发者体验的质疑的直接结果。</strong>除了为Spark中的编码提供更简单的接口，使用抽象层还带来了更多实实在在的好处。在这里，我们将展示如何赋格:</p><ul class=""><li id="7323" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">处理不同计算框架(Pandas、Spark和Dask)之间的不一致行为</li><li id="3ecc" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">允许跨熊猫大小和Spark大小的数据重用代码</li><li id="f29e" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">极大地加快了测试速度，降低了项目总成本</li><li id="65f5" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">让新用户使用Spark更快地提高工作效率</li><li id="b0cb" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">提供能够处理端到端工作流的SQL界面</li></ul><h1 id="ebe3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">熊猫和火花之间的矛盾</h1><p id="1431" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">大小数据能否有一个统一的接口？</em></p><p id="dde1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">过渡到Spark的Pandas用户经常会遇到不一致的行为。首先，Pandas允许混合列类型。这意味着字符串和数字可以在同一列中混合使用。在Spark中，模式是严格执行的，不允许混合类型的列。这是因为Pandas在执行操作时可以看到所有的数据，而Spark在保存不同部分数据的几台机器上执行操作。这意味着如果没有严格执行模式，Spark很容易让不同的分区表现不同。</p><p id="9bd5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">熊猫和Spark对空值的处理也不同。下表总结了空值的默认处理方式</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nh"><img src="../Images/984b61fc75aed9f6eb73d2235eda9f43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fv0FKyt3jB0ehVrU"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">熊猫大战火花中的空处理</p></figure><p id="ba7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是使用Fugue作为抽象层的第一个好处。让熊猫代码在Spark上运行是一回事，但让代码在计算引擎之间给出一致的结果是一个非常乏味的过程。在很多情况下，必须编写额外的代码来获得相同的结果。神游照顾到了一致性，在熊猫和Spark之间建立了一致的桥梁。Fugue被设计成与Spark和SQL一致，因为这保证了代码在分布式设置中会像预期的那样工作。<strong class="kh ir">用户不应该花时间担心特定于框架的行为。</strong></p><h1 id="a980" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">逻辑和执行的分离</h1><p id="54bc" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">为什么我需要在开始一个数据项目之前选择一个框架？</em></p><p id="caa5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Pandas和Spark的一个难点是逻辑与接口紧密耦合。这是不切实际的，因为它要求数据从业者在项目开始时选择他们要用什么来编码。这里有两个场景，是同一个问题的两面。</p><ol class=""><li id="b589" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la ni mz na nb bi translated">一个用户在熊猫里面编码，然后数据变得太大。为了解决这个问题，必须升级底层硬件以支持执行(垂直扩展)。</li><li id="59ab" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la ni mz na nb bi translated">一个用户在Spark中编码，期望数据很大，但是它从来没有增长到需要Spark的大小。由于Spark开销，代码和测试的运行速度比实际速度要慢。</li></ol><p id="c1ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这两种情况下，用户最终都使用了错误的工具。如果逻辑和执行分离，这些场景是可以避免的。<strong class="kh ir">使用Fugue作为抽象层允许用户编写一个与Pandas和Spark都兼容的代码库</strong>。然后可以在运行时通过传递执行引擎来指定执行。为了演示这一点，让我们来看看使用Fugue最简单的方法，即<code class="fe nj nk nl nm b">transform()</code>函数。</p><p id="b89e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于这个例子，我们有一个包含列<code class="fe nj nk nl nm b">id</code>和<code class="fe nj nk nl nm b">value</code>的数据帧。我们想通过将<code class="fe nj nk nl nm b">value</code>映射到<code class="fe nj nk nl nm b">mapping</code>中相应的食物来创建一个名为<code class="fe nj nk nl nm b">food</code>的列。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">我们问题的简单设置</p></figure><p id="1376" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">熊猫对此有一个简单的方法。我们可以创建一个熊猫函数来调用它。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">使用熊猫来执行地图操作</p></figure><p id="332b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不用编辑熊猫函数，我们可以用Fugue的<code class="fe nj nk nl nm b">transform()</code>函数把它带到Spark。这个函数可以接受Pandas数据帧或Spark数据帧，如果使用Spark引擎，它将返回Spark数据帧。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">用赋格变换移植一个函数到Spark</p></figure><p id="919f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意我们需要调用<code class="fe nj nk nl nm b">.show()</code>,因为Spark的求值是延迟的。输出如下所示。</p><pre class="le lf lg lh gt nn nm no np aw nq bi"><span id="d854" class="nr lu iq nm b gy ns nt l nu nv">+---+-----+------+<br/>| id|value|  food|<br/>+---+-----+------+<br/>|  0|    A| Apple|<br/>|  1|    B|Banana|<br/>|  2|    C|Carrot|<br/>+---+-----+------+</span></pre><p id="cca7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个场景中，我们不需要编辑最初的基于Pandas的函数。<code class="fe nj nk nl nm b">transform()</code>函数负责将执行移植到Spark，因为我们提供了一个<code class="fe nj nk nl nm b">spark_session</code>作为引擎。如果没有指定<code class="fe nj nk nl nm b">engine</code>，则使用默认的基于Pandas的执行引擎。Pandas用户可能不习惯显式定义模式，但这是分布式计算的一个要求。</p><p id="4eea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但实际上，熊猫并不总是最容易表达逻辑的方式。因此，通过灵活处理不同的输入和输出类型，Fugue还支持使用原生Python函数。下面是我们的<code class="fe nj nk nl nm b">map_letter_to_food()</code>函数的三种不同实现。它们都与Fugue <code class="fe nj nk nl nm b">transform()</code>函数兼容，可以在Pandas、Spark和Dask引擎上使用相同的语法。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">我们函数的不同实现，都与赋格兼容</p></figure><p id="f12f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意所有的逻辑都是在<code class="fe nj nk nl nm b">map_letter_to_food()</code>函数中定义的。然后执行被推迟到我们指定引擎的<code class="fe nj nk nl nm b">transform()</code>调用。<strong class="kh ir">用户只需要关心以他们喜欢的方式定义他们的逻辑。然后，Fugue会把它带到指定的执行引擎。</strong></p><p id="b175" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark提供了<code class="fe nj nk nl nm b">pandas_udf</code>作为在Spark上执行Pandas功能的方式，而Fugue则提供了一个更简单的模式接口。模式管理最终会在Spark 中产生大量<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/tutorials/beginner/introduction.html#optional-spark-equivalent-of-transform" rel="noopener ugc nofollow" target="_blank">样板代码。这里，模式以一个最小的字符串传递给<code class="fe nj nk nl nm b">transform()</code>，保留原来的函数定义不变。此外，如果用户指定，Fugue可以使用pandas_udf，在这种情况下使用Fugue的<strong class="kh ir">开销不到一秒</strong>，正如在基准测试</a>中看到的<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/tutorials/appendix/fugue_spark_benchmark.html" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="ef2f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在更实际的层面上，对于数据科学团队来说，拥有包含用于清理和转换数据的特定业务逻辑的共享库是非常常见的。目前，该逻辑必须实现两次——一次用于熊猫规模的项目，另一次用于Spark规模的项目。通过使用Fugue，<strong class="kh ir">相同的功能可以在Pandas和Spark引擎上使用，而无需任何代码更改。</strong></p><p id="0056" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这也是<strong class="kh ir">面向未来的代码</strong>。如果有一天，你决定要使用Dask引擎呢？如果你想使用光线引擎呢？使用Fugue作为抽象层可以让您无缝迁移，因为这只是在运行时指定执行引擎的问题。另一方面，使用Spark API编写代码会自动锁定该框架的代码库。如果用户想的话，Fugue的极简界面有意地使其易于离线。</p><h1 id="7de0" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">提高火花的可测试性</h1><p id="0a46" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">我们如何加快大数据项目的开发迭代和测试？</em></p><p id="ad0a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在Spark中测试代码是乏味的。目前有两种方法用于开发Spark应用程序。Databricks上的用户可以使用<code class="fe nj nk nl nm b">databricks-connect</code> Python库，它取代了PySpark的本地安装。每当调用<em class="lb"> </em> <code class="fe nj nk nl nm b">pyspark</code>时，执行计划都在本地编译，然后在配置好的集群上执行。这意味着<strong class="kh ir">简单的测试和代码更改需要启动后端集群</strong>。这需要一段时间，也非常昂贵。</p><p id="d625" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二种方法是在本地开发，然后使用spark-submit工具打包代码，并通过SSH在集群上运行。这个过程需要更多的工作和时间。对于进行测试驱动开发的团队来说，整个测试套件可能需要很长时间来测试。即使所有的测试都在本地完成，Spark与Pandas相比仍然运行缓慢，因为需要设置JVM环境。对数据帧操作上的值的断言需要一个<code class="fe nj nk nl nm b">collect()</code>或<code class="fe nj nk nl nm b">toPandas()</code>调用，与基于Pandas的评估相比，这将花费大量时间。</p><p id="f756" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为在运行时选择执行引擎，我们可以在测试期间对较小的数据使用基于Pandas的引擎，然后将Spark引擎用于生产。<strong class="kh ir">测试变得更快更便宜，因为代码与Spark </strong>解耦，这意味着Spark运行时不必为每个小代码测试而加速。在用Pandas进行本地测试之后，同样的代码可以被带到Spark执行引擎中进行扩展。</p><p id="2ed1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Fugue保证的一致性确保了在默认引擎上运行和在Spark执行引擎上运行提供相同的结果。这种分离极大地加快了开发周期，并使大数据项目的成本大大降低，因为可以避免代价高昂的错误。测试时间通常从几分钟减少到几秒钟。</p><p id="1dec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Fugue的用户也受益于不得不编写更少的测试。在我们上面的<code class="fe nj nk nl nm b">transform()</code>例子中，只有原始函数需要被测试。用户也可以测试<code class="fe nj nk nl nm b">transform()</code>，不过已经在赋格级别上重重测试过了。相比之下，使用PySpark方法将需要1或2个助手函数，然后也必须进行测试。与<code class="fe nj nk nl nm b">transform()</code>等价的PySpark代码片段可以在<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/tutorials/beginner/introduction.html#optional-spark-equivalent-of-transform" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="d561" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">减少代价高昂的错误</h1><p id="aaee" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">怎样才能减少分布式计算初学者面临的摩擦？</em></p><p id="e4ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">许多Spark用户并不知道在Spark中重新计算数据是非常容易的。分布式计算框架延迟评估代码，这意味着计算图(或DAG)被构造，然后在执行一个动作以具体化一个结果时被执行。动作是像打印或保存数据帧这样的操作。</p><p id="9d49" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的计算图中，针对运行C、D和e的操作重新计算B。这意味着它被计算三次。如果B的一次运行需要一个小时，我们就不必要地给工作流程增加了两个小时。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nw"><img src="../Images/c96083e7ffe510e12b0160c01df1849c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sFWHvHWQ6ktWlt8i"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片:DAG示例</p></figure><p id="7a4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有经验的Spark用户会知道B应该被持久化以避免重新计算。然而，<strong class="kh ir">不太熟悉懒求值的人往往会遭受不必要的重算</strong>。在极端情况下，当操作不确定时，这种懒惰的评估和重新计算会导致意外的行为。最明显的例子是B中包含随机数的列。如果B没有被持久化，那么C、D和E的随机数列将被重新计算，得到不同的结果。</p><p id="b22b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解决这个问题，神游在工作流程层面也有优化。之前我们展示了单一功能的Fugue的<code class="fe nj nk nl nm b">transform()</code>界面。Fugue还支持通过使用<code class="fe nj nk nl nm b">FugueWorkflow()</code>构建完整的工作流，如下所示。这是整个工作流的引擎无关的DAG表示。<code class="fe nj nk nl nm b">FugueWorkflow()</code>可以像前面显示的<code class="fe nj nk nl nm b">transform()</code>功能一样接受一个引擎，将其移植到Spark或Dask。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">富格工作流示例</p></figure><p id="e0fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过分析构建的计算图(DAG)的依赖关系，Fugue可以灵活地持久存储将被多个操作重用的数据帧。为了更好地控制，Fugue还为用户提供了一个接口来保存数据帧。</p><p id="b5a0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过这个DAG，Fugue还可以执行允许代码快速失败验证(比如模式和分区)。如果模式与未来的操作不匹配，Fugue会识别出来，并立即出错。许多Spark用户经常花费大量金钱和时间在集群上运行代码，几个小时后才发现它失败了。<strong class="kh ir">拥有Fugue的DAG编译过程有助于用户避免代价高昂的错误</strong>。</p><h1 id="0e8c" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">SQL接口</h1><p id="71cb" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">如何将SQL提升为计算工作流的一级语法？</em></p><p id="2d04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark的创新之一是SparkSQL中的SQL接口。SparkSQL接口非常适合喜欢SQL的人描述他们的计算逻辑。不幸的是，它不允许用户利用Spark提供的所有功能，因为它紧密地基于ANSI SQL。它还是第二类接口，通常在主要基于Python的代码之间调用。</p><p id="0162" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Fugue有一个基于SparkSQL实现的SQL接口，但是增加了一些增强功能。首先，有一些额外的关键字，如BROADCAST、PERSIST、PREPARTITION和PRESORT，允许用户明确地利用Spark的分布式计算操作。还支持通过TRANSFORM关键字将Python函数与FugueSQL一起使用(等等)。添加了加载和保存等更多关键字，以支持端到端工作流。下面相当于我们之前的<code class="fe nj nk nl nm b">FugueWorkflow</code>。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">FugueSQL示例</p></figure><p id="a96f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，大量SQL用户可以在Spark引擎上使用FugueSQL加载数据、执行转换和保存结果。SQL爱好者可以在类似SQL的界面中表达他们的端到端计算逻辑。一个缺点是ANSI SQL只允许一个select语句，而FugueSQL允许多个。FugueSQL允许将变量赋值为临时表，这是一种比通用表表达式(cte)更友好的语法。欲了解更多信息，请查看<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/en/latest/tutorials/fugue_sql/index.html" rel="noopener ugc nofollow" target="_blank"> FugueSQL文档</a>。</p><p id="2187" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个FugueSQL接口建立在抽象层之上，使它与Pandas、Spark、Dask和BlazingSQL兼容。<strong class="kh ir">它是一等公民，提供与Fugue Python API </strong>相同的灵活性和好处。</p><p id="4aac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有一个带有语法高亮的笔记本扩展，允许用户调用<em class="lb"> %%fsql </em>单元格魔术。欲了解更多信息，请参阅本文<a class="ae lc" rel="noopener" target="_blank" href="/interoperable-python-and-sql-in-jupyter-notebooks-86245e711352"/>。请注意，语法突出显示目前仅适用于经典的Jupyter笔记本，不适用于JupyterLab。它在<a class="ae lc" href="https://www.kaggle.com/kvnkho/fugue-workshop" rel="noopener ugc nofollow" target="_blank"> Kaggle环境</a>中也工作得很好，利用了Kaggle内核中的多个内核。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nx"><img src="../Images/d2c97671ee8a447fce7bbd75415f7d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cJ-fIBcMUhYlU17O"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片:Jupyter笔记本赋格扩展演示</p></figure><h1 id="bd86" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">分割</h1><p id="099b" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="lb">对于某些用例，是否有更好的方法来划分数据？</em></p><p id="67ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Spark默认使用散列分区。对于少量的键，这很容易导致不均匀的分区。这看起来没什么大不了的，但是如果每个键需要一个小时来运行，那么不均衡的分区可能会使一个作业需要多花几个小时来运行。棘手的是，即使不编写大量代码，Spark上的分区也无法实现。</p><p id="d596" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Fugue允许用户在默认散列分区、随机分区或均匀分区之间进行选择。<strong class="kh ir">这些划分策略中的每一种都非常适合不同的用例</strong>。下面是何时使用每种方法的表格摘要。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ny"><img src="../Images/eb33faa9608208987344818351ef380d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5_v4ziLbsZztCavk"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片:赋格中不同的分割策略</p></figure><p id="e841" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">均匀分区对于需要大量计算的较小数据特别有用。当数据不对称时，一些分区最终会比其他分区包含更多的数据。因此，执行时间取决于数据量最大的分区的完成时间。通过为每个分区强制相同数量的元素，可以减少执行时间。更多信息，请查看<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/en/latest/tutorials/advanced/partition.html" rel="noopener ugc nofollow" target="_blank">分区文档</a>。</p><p id="314d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的代码中，我们得到了包含最高值<em class="lb"> col2 </em>的五行。预排序在数据分区时应用。<code class="fe nj nk nl nm b">transform()</code>函数也可以接受一个<code class="fe nj nk nl nm b">partition</code>策略。</p><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="mq mr l"/></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">赋格上的分区操作示例</p></figure><h1 id="f871" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">神游vs考拉vs摩丁</h1><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nz"><img src="../Images/a59954e412fa45fd03e7f48f14c881a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6YTpB4ZYfsT32bSX"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片:考拉、摩丁、赋格</p></figure><p id="42c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Fugue经常被拿来与考拉和摩丁相比较，作为单核计算到分布式计算之间的桥梁。考拉是Spark的熊猫接口，摩丁是Dask和Ray的熊猫接口。很难比较这两个项目，因为目标不同，但主要的区别是<strong class="kh ir">这两个框架认为Pandas可以成为分布式计算的语法，而Fugue认为native Python和SQL应该是，但也支持Pandas的用法</strong>。</p><p id="4035" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一开始，当来自熊猫时，转换到考拉或摩丁可能看起来容易得多。一些用户错误地期望熊猫<code class="fe nj nk nl nm b">import</code>语句可以被修改，并且代码将在分布式设置上完美地工作。在很多情况下，这种承诺好得难以置信，因为这需要库的接口与Pandas API完全同步，而这几乎是不可能的。例如，滚动操作的<a class="ae lc" href="https://koalas.readthedocs.io/en/latest/reference/api/databricks.koalas.DataFrame.rolling.html?highlight=rolling#databricks.koalas.DataFrame.rolling" rel="noopener ugc nofollow" target="_blank">的考拉实现没有熊猫API提供的窗口类型。</a></p><p id="0485" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是在分布式环境中，与Pandas API完全对等并不总是有意义的。例如，一个转置操作可以在Pandas中工作，但是当数据分布在不同的机器上时，它的开销非常大。在极端的情况下，应用程序必须做出极端的妥协才能让这个import语句发挥作用。如果一个操作在Modin API中不存在，架构<a class="ae lc" href="https://modin.readthedocs.io/en/latest/supported_apis/index.html#defaulting-to-pandas" rel="noopener ugc nofollow" target="_blank">默认使用熊猫</a>，它将所有的数据收集到一台机器上。这很容易使收集所有数据的机器过载，这些数据以前分散在多个工作人员中。</p><p id="4699" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">神游避免使用Pandas作为分布式计算操作的语法也有哲学上的原因。考拉和摩丁在语法中增加了词汇，比如持久化和广播操作来控制工人之间数据移动。但是这里的错位是熊猫的基本语法不能很好地翻译成分布式场景。索引对熊猫的工作流程非常重要。在一个典型的脚本中，会使用大量的<code class="fe nj nk nl nm b">reset_index()</code>和<code class="fe nj nk nl nm b">set_index()</code>调用。执行groupby操作时，会自动设置索引。该索引保留了一个全局顺序，允许使用<code class="fe nj nk nl nm b">iloc</code>方法。一些操作甚至在连接条件中使用索引。在分布式设置中，顺序是无法保证的，因为跟踪顺序通常会产生不必要的计算开销。</p><h1 id="4217" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">性能-生产率权衡和神游</h1><p id="a1a3" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在代码性能和开发人员生产力之间总是有一个折衷。性能优化需要深入的特定于引擎的技巧，这些技巧很难编码和维护。另一方面，优化开发人员的生产力意味着尽可能快地生产出解决方案，而不用担心代码性能。<strong class="kh ir">为了迭代速度和可维护性的显著提高，Fugue牺牲了一点性能。</strong>通过专注于在分区级别定义逻辑，用户通常会发现他们的代码变得更加清晰，并且<strong class="kh ir">大数据问题变得小而易管理。</strong></p><p id="78ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然在Spark上使用Pandas和自定义函数曾经较慢，但由于Spark引擎的改进(Apache Arrow的使用)，它的性能越来越好。Fugue应用转换的效率损失非常小，用户经常看到在分布式设置中通过更有效地处理数据而获得的代码加速。事实上，Fugue将许多代码转录为Spark代码，这意味着在许多情况下唯一改变的是界面。</p><h1 id="7a3b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="aca8" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在本文中，我们讨论了使用Spark的难点，包括可测试性、与Pandas的不一致性以及缺乏健壮的SQL接口。我们展示了一个更友好的界面来使用Spark。神游不与火花发动机竞争；神游使它更容易使用。通过使用Fugue，用户通常会看到大数据项目更快的迭代，从而减少交付时间和项目成本。</p><p id="1072" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用神游是非侵入性的，没有任何依赖性。逻辑可以用原生Python代码或者熊猫来定义，然后移植到Spark。<strong class="kh ir"> Fugue相信适应用户</strong>，所以他们可以专注于定义他们的逻辑，而不是担心它的执行。尽管本文没有涉及，但Fugue也提供了使用本机Spark代码或Spark配置的方法。<strong class="kh ir">它不限制对底层框架的访问。</strong></p><h1 id="1951" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">联系我们</h1><p id="a928" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">如果你想了解更多关于赋格的知识，讨论你的Spark痛点，甚至纠正本文中提到的一些错误，我们很乐意听到你的意见！此外，如果您希望我们向您的团队、聚会或会议做演示，请随时联系我们。</p><ul class=""><li id="87e3" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la my mz na nb bi translated">邮箱:<a class="ae lc" href="mailto:hello@fugue.ai" rel="noopener ugc nofollow" target="_blank"> hello@fugue.ai </a></li><li id="e8aa" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la my mz na nb bi translated">松弛:<a class="ae lc" href="http://slack.fugue.ai" rel="noopener ugc nofollow" target="_blank">加入这里</a></li></ul><h1 id="1289" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">资源</h1><p id="279f" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">赋格的附加资源:</p><ol class=""><li id="ebda" class="mt mu iq kh b ki kj kl km ko mv ks mw kw mx la ni mz na nb bi translated"><a class="ae lc" href="https://fugue-tutorials.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">赋格教程</a></li><li id="c4fb" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la ni mz na nb bi translated"><a class="ae lc" href="https://github.com/fugue-project/fugue" rel="noopener ugc nofollow" target="_blank">赋格回购</a></li><li id="1b5b" class="mt mu iq kh b ki nc kl nd ko ne ks nf kw ng la ni mz na nb bi translated"><a class="ae lc" href="https://fugue-tutorials.readthedocs.io/tutorials/resources.html" rel="noopener ugc nofollow" target="_blank">赋格会议演示列表</a> (PyCon，PyData，KubeCon等。)</li></ol><p id="2a36" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">抽象层打开了许多更具体的应用程序。到目前为止，我们已经介绍了<a class="ae lc" href="https://www.youtube.com/watch?v=2AdvBgjO_3Q&amp;t=2s" rel="noopener ugc nofollow" target="_blank">验证</a>、<a class="ae lc" href="https://github.com/fugue-project/tune" rel="noopener ugc nofollow" target="_blank">调优</a>和<a class="ae lc" href="https://fugue-tutorials.readthedocs.io/en/latest/tutorials/fugue_sql/index.html#" rel="noopener ugc nofollow" target="_blank"> SQL接口</a>。</p></div></div>    
</body>
</html>