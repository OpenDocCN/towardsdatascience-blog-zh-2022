<html>
<head>
<title>Coding a Convolutional Neural Network (CNN) Using Keras Sequential API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras顺序API编码卷积神经网络(CNN)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875#2022-06-27">https://towardsdatascience.com/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875#2022-06-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a4c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">神经网络和深度学习课程:第24部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/db99f066b0a23adb8f253ff5a8621ab0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s9T2KY2I20HV6wiNWFLvkQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者编辑的来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7255440" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae ky" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7255440" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>的原始图像</p></figure><blockquote class="kz la lb"><p id="4bb5" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated"><strong class="lf iu">先决条件:</strong> <a class="ae ky" rel="noopener" target="_blank" href="/convolutional-neural-network-cnn-architecture-explained-in-plain-english-using-simple-diagrams-e5de17eacc8f">用简单的图表用简单的英语解释卷积神经网络(CNN)架构</a>(强烈推荐)</p></blockquote><p id="4195" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在第23部分中，我详细讨论了卷积神经网络(CNN)中的层和操作。如果你读过那本书，现在你就明白CNN是如何在幕后工作的了。</p><p id="df39" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">今天，我们将讨论如何使用Keras顺序API构建CNN。我们将详细讨论如何使用<code class="fe mc md me mf b">Sequential()</code>类实例化顺序模型，如何使用<code class="fe mc md me mf b">add()</code>方法添加卷积、池化和密集层，如何使用<code class="fe mc md me mf b">Conv2D()</code>、<code class="fe mc md me mf b">MaxPooling2D()</code>和<code class="fe mc md me mf b">Dense()</code>类构建卷积、池化和密集层。</p><p id="a8cc" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">最后，我们将使用<code class="fe mc md me mf b">summary()</code>方法得到整个CNN架构的概要，并统计网络中总参数的数量。该信息可用于在<strong class="lf iu">“参数效率”</strong>方面比较CNN和等效MLP。</p><h1 id="064e" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Keras顺序API</h1><p id="2ee5" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">Keras中有两种类型的API:<strong class="lf iu">顺序</strong>和<strong class="lf iu">功能</strong>。今天，我们将使用顺序API来构建一个CNN。在顺序API中，我们将层一层一层地添加到模型中(因此得名<strong class="lf iu"> <em class="le">顺序</em> </strong>)。使用顺序API很容易。然而，顺序API对于分支层并不太灵活，并且它不允许网络中有多个输入和输出。</p><h1 id="4d0e" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">顺序模型</h1><p id="2cb6" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">在Keras中，可以通过使用<code class="fe mc md me mf b">Sequential()</code>类来构建顺序模型。在这里，我们使用<code class="fe mc md me mf b">add()</code>方法给模型添加层。根据Keras文件，</p><blockquote class="kz la lb"><p id="fe15" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">一个<code class="fe mc md me mf b">Sequential</code>模型适用于<strong class="lf iu">一个简单的层叠</strong>，其中每一层都有<strong class="lf iu">一个输入张量和一个输出张量</strong>——来源:<a class="ae ky" href="https://keras.io/guides/sequential_model/" rel="noopener ugc nofollow" target="_blank">https://keras.io/guides/sequential_model/</a></p></blockquote><p id="d078" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN可以被实例化为一个序列模型，因为每一层只有一个输入和输出，并且堆叠在一起形成整个网络。</p><pre class="kj kk kl km gt nd mf ne nf aw ng bi"><span id="e637" class="nh mh it mf b gy ni nj l nk nl">from tensorflow.keras.models import Sequential</span><span id="951d" class="nh mh it mf b gy nm nj l nk nl"><strong class="mf iu">CNN = Sequential()</strong></span></pre><p id="41a4" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在第16部分中，我们使用相同的<code class="fe mc md me mf b">Sequential()</code>类创建了一个多层感知器(MLP)。MLP中的每一层都只有一个输入和输出，并且堆叠在一起形成整个网络。因此，MLP可以被实例化为序列模型。</p><h1 id="c762" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">CNN中的层排列</h1><p id="49e8" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">在我们讨论CNN层之前，总结一下CNN中的层排列是很有用的。更多详情可在<a class="ae ky" rel="noopener" target="_blank" href="/convolutional-neural-network-cnn-architecture-explained-in-plain-english-using-simple-diagrams-e5de17eacc8f#e962">这里</a>找到。</p><p id="c63f" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">典型地，CNN中的层被堆叠为，</p><p id="6c4e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">卷积池对→卷积池对→一个平坦层→多个密集层</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/9e22c65212e7ba3b538314e8ff3174b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2cOInQFLg83hceu4BW-6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd no">CNN中的图层排列</strong>(图片由作者提供，用draw.io制作)</p></figure><h1 id="832b" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Keras Conv2D类</h1><p id="fce4" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">CNN中的每个卷积层都是使用简单地在二维空间中执行卷积运算的<code class="fe mc md me mf b">Conv2D()</code>类创建的。换句话说，核(过滤器)的移动发生在输入图像上，跨越二维空间。</p><p id="71b2" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在Keras中，卷积层被称为Conv2D层。</p><pre class="kj kk kl km gt nd mf ne nf aw ng bi"><span id="bb9c" class="nh mh it mf b gy ni nj l nk nl">from tensorflow.keras.layers import Conv2D</span><span id="89c4" class="nh mh it mf b gy nm nj l nk nl"><strong class="mf iu">Conv2D(</strong><strong class="mf iu">filters, kernel_size,<br/>       strides, padding,<br/>       activation, </strong><strong class="mf iu">input_shape)</strong></span></pre><h2 id="15bf" class="nh mh it bd mi np nq dn mm nr ns dp mq lz nt nu ms ma nv nw mu mb nx ny mw nz bi translated">Conv2D中的重要参数</h2><ul class=""><li id="f029" class="oa ob it lf b lg my lj mz lz oc ma od mb oe ly of og oh oi bi translated"><strong class="lf iu">滤镜:</strong>滤镜数量(内核)。这也被称为特征图的深度。接受整数。我们通常将每个卷积层中的滤波器数量增加为16、32、64、128等等。</li><li id="d531" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu"> kernel_size: </strong>指定内核(卷积)窗口的高度和宽度。这需要一个整数或两个整数的元组，如(3，3)。在大多数情况下，窗口是一个高度和宽度相同的正方形。方形窗口的大小可以指定为整数，例如，3表示(3，3)窗口。</li><li id="1a1f" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">步数:</strong>我们在输入图像上移动滤镜的步数(像素)。这需要沿着高度和宽度的步幅的元组。如果高度和宽度相同，我们可以使用整数。默认值设置为(1，1)。</li><li id="10c4" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">填充:</strong>有两种选择:<code class="fe mc md me mf b">"valid"</code>或<code class="fe mc md me mf b">"same"</code>。“有效”意味着没有填充。“相同”导致用零填充，使得当<code class="fe mc md me mf b">strides=1</code>时，特征图的大小与输入的大小相同。</li><li id="9451" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">激活:</strong>卷积层中使用的激活函数类型。默认情况下，没有激活等同于线性或身份激活。我们通常在每个卷积层使用<code class="fe mc md me mf b">'relu'</code>激活函数。</li><li id="a787" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu"> input_shape: </strong>将输入的高度、宽度和深度指定为一个整数元组。换句话说，这是输入图像的大小。如果第一个卷积层是模型中紧接在输入层之后的第一层，则必须在第一个卷积层中指定此参数。其他中间卷积层不包含这个参数。</li></ul><blockquote class="kz la lb"><p id="4bad" class="lc ld le lf b lg lh ju li lj lk jx ll lm ln lo lp lq lr ls lt lu lv lw lx ly im bi translated">当<code class="fe mc md me mf b">input_shape</code>被传递到第一个卷积层时，Keras为场景后面的模型添加一个输入层，我们不需要明确指定输入层。</p></blockquote><h1 id="288d" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Keras MaxPooling2D类</h1><p id="cd04" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">创建卷积层后，下一步是创建池层。卷积层和池层成对使用。共有两种拼版操作:<strong class="lf iu">最大拼版</strong>和<strong class="lf iu">平均拼版</strong>。这里，我们使用最大池。</p><p id="b149" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN中的每个池层都是使用<code class="fe mc md me mf b">MaxPooling2D()</code>类创建的，该类只是在二维空间中执行最大池操作。</p><p id="6b19" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在Keras中，最大池层被称为MaxPooling2D层。</p><pre class="kj kk kl km gt nd mf ne nf aw ng bi"><span id="eb91" class="nh mh it mf b gy ni nj l nk nl">from tensorflow.keras.layers import MaxPooling2D</span><span id="c91f" class="nh mh it mf b gy nm nj l nk nl"><strong class="mf iu">MaxPooling2D(</strong><strong class="mf iu">pool_size, strides, padding</strong><strong class="mf iu">)</strong></span></pre><h2 id="c1e0" class="nh mh it bd mi np nq dn mm nr ns dp mq lz nt nu ms ma nv nw mu mb nx ny mw nz bi translated">MaxPooling2D中的重要参数</h2><ul class=""><li id="3508" class="oa ob it lf b lg my lj mz lz oc ma od mb oe ly of og oh oi bi translated"><strong class="lf iu"> pool_size: </strong>池窗口的大小。默认值为(2，2)。这需要一个整数或一个元组。如果我们使用整数，相同的窗口长度将用于两个维度。</li><li id="161c" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">步数:</strong>我们在特征图上为每个合并步骤移动合并窗口的步数(像素)。这需要沿着高度和宽度的步幅的元组。如果高度和宽度相同，我们可以使用整数。默认设置为<code class="fe mc md me mf b">None</code>，采用<code class="fe mc md me mf b">pool_size</code>的值。</li><li id="e4d9" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">填充:</strong>有两种选择:<code class="fe mc md me mf b">"valid"</code>或<code class="fe mc md me mf b">"same"</code>。“有效”意味着没有填充。“相同”会导致以零填充，使得合并的要素地图的大小与输入的大小相同。</li></ul><h1 id="9a72" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Keras稠密类</h1><p id="82e8" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">CNN中的最后几层是完全(密集)连接的层。在Keras中，这些层是使用<code class="fe mc md me mf b">Dense()</code>类创建的。</p><p id="263e" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">CNN中的多层感知器(MLP)部分是使用多个完全连接的层创建的。</p><p id="9c03" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在Keras中，完全连接的层称为密集层。</p><pre class="kj kk kl km gt nd mf ne nf aw ng bi"><span id="d65e" class="nh mh it mf b gy ni nj l nk nl">from tensorflow.keras.layers import Dense</span><span id="7afb" class="nh mh it mf b gy nm nj l nk nl"><strong class="mf iu">Dense(</strong><strong class="mf iu">units, activation, </strong><strong class="mf iu">input_shape)</strong></span></pre><h2 id="b73b" class="nh mh it bd mi np nq dn mm nr ns dp mq lz nt nu ms ma nv nw mu mb nx ny mw nz bi translated">密集中的重要参数</h2><ul class=""><li id="2a80" class="oa ob it lf b lg my lj mz lz oc ma od mb oe ly of og oh oi bi translated"><strong class="lf iu">单元:</strong>层中节点(单元)的数量。这是一个必需的参数，接受一个正整数。</li><li id="dde4" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">激活:</strong>在层中使用的激活函数的类型。默认值为<code class="fe mc md me mf b">None</code>，表示无激活(即线性或身份激活)。</li><li id="2a38" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated">我们不需要包括这个参数，因为任何密集层都不是CNN中的第一层。</li></ul><h1 id="1e9c" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">Keras展平类</h1><p id="db4e" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">在CNN中，在最终汇集层和第一密集层之间有一个平坦层。展平层是一个单列，用于保存CNN中MLP部分的输入数据。</p><p id="c296" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在Keras中，展平过程是通过使用<code class="fe mc md me mf b">flatten()</code>类来完成的。</p><h1 id="4213" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">设计CNN架构</h1><p id="5f81" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">我们将在下面的场景中使用上述类型的层来构建CNN。</p><p id="b849" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><strong class="lf iu">假设我们有MNIST数据集，该数据集包含10个类别(0到9)下的大量手写数字灰度图像。我们需要创建一个CNN，它应该能够准确地对这些图像进行分类。每个灰度(单通道)图像的大小为28 x 28。所以，输入的形状是(28，28，1)。</strong></p><p id="e986" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我们将CNN的架构定义如下。</p><ul class=""><li id="7bfe" class="oa ob it lf b lg lh lj lk lz oo ma op mb oq ly of og oh oi bi translated"><strong class="lf iu">卷积层数:</strong>两层，第一层16个滤波器，第二层32个滤波器，每层ReLU激活</li><li id="3736" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">池层数:</strong>两层，使用最大池</li><li id="14ef" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">展平层:</strong>在最终汇集层和第一致密层之间</li><li id="4fd3" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated"><strong class="lf iu">密集层数:</strong>三层，第一层64单位，第二层32单位，最后一层10单位，前两层ReLU激活，最后一层Softmax激活</li></ul><p id="0411" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">下面的代码块可以用来在Keras中定义上面的CNN架构。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="or os l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/13dfcd15db45a60814365fe690dbbffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*r-PQiqtHMMj577QEEwDteg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CNN输出摘要(图片由作者提供)</p></figure><h1 id="14d2" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">读取输出</h1><p id="5d3e" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated"><code class="fe mc md me mf b">Sequential()</code>类的<code class="fe mc md me mf b">summary()</code>方法给出了输出摘要，其中包含了关于神经网络架构的非常有用的信息。</p><p id="00ad" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在上面的输出中，图层信息按从上到下的顺序列在左侧。第一层在顶部，最后一层在底部。请注意，这里没有显示输入层。</p><p id="8adf" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">在中间的列中，您可以看到每个层的输出形状。例如，第一Conv2D层具有<strong class="lf iu">(无，14，14，16) </strong>的输出，其指示在执行第一卷积运算之后特征图的维度。特征图的大小是14×14，深度是16，因为使用了16个过滤器。元组中的第一个值是<strong class="lf iu"> None </strong>，它表示训练实例的数量(批量大小)。一旦输入数据输入到模型中，就可以确定这一点的确切值。就目前而言，它注定<strong class="lf iu">无</strong>。</p><p id="893b" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">右栏包括每层中涉及的参数数量。请注意，池化层和展平层没有参数！</p><p id="42d8" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">展平层的形状为(无，128)。这意味着MLP部分的输入层形状是(128，)。</p><p id="6b16" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">输出的底部显示了网络中所有参数的数量。</p><h1 id="9430" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">比较模型</h1><ul class=""><li id="6152" class="oa ob it lf b lg my lj mz lz oc ma od mb oe ly of og oh oi bi translated">在第16部分中，我们创建了一个多层感知器(MLP)模型来分类MNIST手写数字。在那里，我们得到了269，322个参数，这对于那种小型分类任务来说是一个巨大的数字。当处理图像数据时，MLP不是参数有效的。</li><li id="643f" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated">作为该问题的解决方案，在<a class="ae ky" rel="noopener" target="_blank" href="/using-pca-to-reduce-number-of-parameters-in-a-neural-network-by-30x-times-fcc737159282">第17部分</a>中，我们将主成分分析(PCA)应用于图像数据，并构建了相同的MLP模型。在那里，我们只有8874个参数。我们能够将参数数量减少30倍，同时还能获得更好的性能。</li><li id="f02c" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated">今天，我们使用了不同的神经网络架构(CNN)而不是MLP。我们只有15466个参数！因此，CNN是参数有效的。</li></ul><h1 id="1d36" class="mg mh it bd mi mj mk ml mm mn mo mp mq jz mr ka ms kc mt kd mu kf mv kg mw mx bi translated">你喜欢哪种型号？</h1><p id="ff8b" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">MLP用PCA模型还是CNN模型？我的答案是CNN。当处理图像数据时，CNN是比MLP更好的选择。这是因为，</p><ul class=""><li id="3ea6" class="oa ob it lf b lg lh lj lk lz oo ma op mb oq ly of og oh oi bi translated">它可以减少参数的数量，同时保持图像的空间信息(相邻像素之间的关系)。需要空间信息来保持图像中的某些模式。</li><li id="29a9" class="oa ob it lf b lg oj lj ok lz ol ma om mb on ly of og oh oi bi translated">如果对RGB图像使用MLP，您将获得大量参数。此外，将PCA应用于RGB图像是复杂的，并且不太实用。</li></ul></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><p id="a0d0" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">今天的帖子到此结束。</p><p id="d80c" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">如果您有任何问题或反馈，请告诉我。</p><p id="e923" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">我希望你喜欢阅读这篇文章。如果你愿意支持我成为一名作家，请考虑 <a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener"> <strong class="lf iu"> <em class="le">注册会员</em> </strong> </a> <em class="le">以获得无限制的媒体访问权限。它只需要每月5美元，我会收到你的会员费的一部分。</em></p><div class="pb pc gp gr pd pe"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="pf ab fo"><div class="pg ab ph cl cj pi"><h2 class="bd iu gy z fp pj fr fs pk fu fw is bi translated">通过我的推荐链接加入Medium</h2><div class="pl l"><h3 class="bd b gy z fp pj fr fs pk fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pm l"><p class="bd b dl z fp pj fr fs pk fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="pn l"><div class="po l pp pq pr pn ps ks pe"/></div></div></a></div><p id="7846" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated">非常感谢你一直以来的支持！下一篇文章再见。祝大家学习愉快！</p></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><h2 id="873a" class="nh mh it bd mi np nq dn mm nr ns dp mq lz nt nu ms ma nv nw mu mb nx ny mw nz bi translated">阅读下一篇(推荐)</h2><p id="6f83" class="pw-post-body-paragraph lc ld it lf b lg my ju li lj mz jx ll lz na lo lp ma nb ls lt mb nc lw lx ly im bi translated">阅读我的<a class="ae ky" href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75" rel="noopener"> <strong class="lf iu">神经网络与深度学习课程</strong> </a>中的所有其他文章。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75"><div class="gh gi pt"><img src="../Images/630fb54f1116e5312b869169d440d063.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*TlvwxjDkx7HKCdyd7-rqqw.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd no">点击此图片进入我的神经网络和深度学习课程</strong>(作者截图)</p></figure></div><div class="ab cl ou ov hx ow" role="separator"><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz pa"/><span class="ox bw bk oy oz"/></div><div class="im in io ip iq"><p id="5978" class="pw-post-body-paragraph lc ld it lf b lg lh ju li lj lk jx ll lz ln lo lp ma lr ls lt mb lv lw lx ly im bi translated"><a class="pu pv ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----ec5211126875--------------------------------" rel="noopener" target="_blank">鲁克山普拉莫迪塔</a><br/><strong class="lf iu">2022–06–27</strong></p></div></div>    
</body>
</html>