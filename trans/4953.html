<html>
<head>
<title>Project OrnithoWav — Bird Species Identification using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">project OrnithoWav——利用深度学习进行鸟类物种识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/project-ornithowav-bird-species-identification-using-deep-learning-2457f456fc22#2022-11-03">https://towardsdatascience.com/project-ornithowav-bird-species-identification-using-deep-learning-2457f456fc22#2022-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1669" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用超低功率深度学习的可扩展的鸟类多样性遥感</h2></div><p id="5047" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">鸟类多样性是评估环境变化的常用指标，并且越来越重要。在这个项目中，我们使用</strong> <a class="ae lb" rel="noopener" target="_blank" href="/how-to-run-a-deep-neural-network-on-a-aa-battery-for-a-week-75ac6247198e"> <strong class="kh ir"> MAX78000 </strong> </a> <strong class="kh ir">根据鸟类的鸣叫声对它们进行检测和分类。从而能够遥感鸟类多样性</strong></p><p id="9e88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于气候变化及其对动物的生态影响，鸟类多样性监测变得越来越重要。在过去的几年里，基于深度学习的方法在减少专家劳动密集型鸟类识别过程方面显示出了希望。康奈尔大学基于157层ResNet的鸟网是目前该领域最先进的技术，可以识别近1000种不同的鸟类[1]。然而，该模型的实现仅限于高带宽互联网可用的区域，因为该模型需要在云中进行评估。</p><blockquote class="lc ld le"><p id="a9fb" class="kf kg lf kh b ki kj jr kk kl km ju kn lg kp kq kr lh kt ku kv li kx ky kz la ij bi translated">提议的解决方案是基于<a class="ae lb" href="https://www.maximintegrated.com/en/design/technical-documents/app-notes/7/7359.html" rel="noopener ugc nofollow" target="_blank"> KWS-20模型</a>的简化CNN，根据声音和叫声识别20种不同的鸟类。</p></blockquote><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lj"><img src="../Images/5d37f22a2f65d822137d44e04ec4b175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3A5B3jQAZuCtigcWBedRg.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">系统框图(图片由Kenneth Joel提供)</p></figure><p id="2fc2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行在超低功耗MAX78000上的PoC可以在非常偏远的地方进行鸟类监测，而不必担心高带宽连接或大电池。它也可以被那些想要跟踪拜访他们家或农场的鸟类的观鸟者使用。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lz"><img src="../Images/8c88611a2eac98375b72048511be6854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EeHb45N1t3LQ47Rr"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">照片由<a class="ae lb" href="https://unsplash.com/ja/@sarahleejs?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Jongsun Lee </a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="8c9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一个项目执行的详细演练，包括4个阶段:<br/> 1。文献综述&amp;开源数据集识别<br/> 2。数据工程<br/> 3。模型训练&amp;使用ai8x的C代码合成——训练&amp;ai8x——合成库<br/> 4。使用测试集中的音频样本对硬件进行测试。</p><p id="ca20" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第一阶段:文献综述&amp;开源数据集识别</strong></p><p id="3707" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">康奈尔鸟类学实验室是这一领域的一个活跃的研究小组，定期发表论文，并在ka ggle(BirdCLEF 2021:<a class="ae lb" href="https://www.kaggle.com/c/birdclef-2021," rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/birdclef-2021,</a>CBL 2020:【https://www.kaggle.com/c/birdsong-recognition/overview】T2举办比赛</p><p id="3f90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些出版物和kaggle数据集为这个项目奠定了坚实的基础。</p><p id="dc90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">赢得这些竞争的网络非常庞大和复杂，对于我们的项目，我们使用了这个数据集的子集，并通过用鸟替换单词来重新训练来自Maxim Integrated 的<a class="ae lb" href="https://github.com/MaximIntegratedAI/ai8x-training" rel="noopener ugc nofollow" target="_blank"> KWS-20模型(ai85kws20)。</a></p><p id="cce9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，一个主要的限制是，所有这些数据的标签都很弱，并且没有按照不同的长度、质量和采样频率进行标准化，如下图所示:</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi ma"><img src="../Images/04e6feba16ef8c453595efd682fc527f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*InKlqGu0zt4UEa8hmxRkNA.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">元数据(肯尼斯·乔尔截图)</p></figure><p id="d6eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第二阶段:数据工程</strong></p><p id="9e5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是最具挑战性的阶段。<br/>前面提到的大部分数据都来自这一个资源:<a class="ae lb" href="https://www.xeno-canto.org/" rel="noopener ugc nofollow" target="_blank">https://www.xeno-canto.org/</a>(知识共享许可)<br/>本网站上的数据是由世界各地的观鸟者收集的，因此样本的质量会有所不同。采样率没有标准化，有时鸟的声音不是很清晰。每只鸟还可以发出多种不同的叫声、声音和警报，增加了复杂性。</p><p id="0230" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了标准化数据集并使其类似于KWS数据集，采取了两个步骤:<br/> 1 .将mp3转换为wav，并将所有数据重新采样为16kHz(与KWS数据集相同，鸟类叫声的频率通常在1-8 khz之间，因此16k足够了):参考code convert.py和convert16k.py <br/> 2。将音频分割成1秒的片段:数据集中的记录长度从1.2秒到900秒不等，一个记录中有1到100个相关的鸟类声音。编写一个处理脚本，首先过滤，然后识别并提取有用的1秒长的片段。请参考代码python_slicer.py和下图，直观了解该算法的工作原理。<br/>注意:代码convert16k.py和python_slicer.py可以在文件夹python-code.zip中找到</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi mb"><img src="../Images/0593498f55401e5fac61e0855c890a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oVyrFD8Td6ViZmgzdNL_rQ.png"/></div></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">音频分段(python_slicer.py)照片由Kenneth Joel拍摄</p></figure><p id="1439" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一过程的结果是一个79025个独特样本的数据集，每只鸟有1000-4000个样本，总共20只独特的鸟。请注意，这些数据在分段后没有被手动清理。</p><p id="8a9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">阶段3:模型训练&amp;使用ai8x的C代码合成——训练&amp;ai8x——合成库</strong></p><div class="mc md gp gr me mf"><a href="https://github.com/MaximIntegratedAI/ai8x-training" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">GitHub-MaximIntegratedAI/ai8x-培训:ADI公司MAX78000和MAX78002 AI器件的模型培训</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">2022年8月29日ADI公司的MAX78000/MAX78002项目由五个资源库组成:从这里开始:顶级文档…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">github.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt lt mf"/></div></div></a></div><p id="dafe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦数据准备好了，只需要对训练脚本做一些修改来训练新数据，步骤如下:<br/> -用新数据更新数据文件夹<br/> -从kws20.py (__extract_archive函数)<br/> -更新类数组和字典(kws20.py中的多个位置)<br/>参考目录/brd20获取更新的代码。</p><p id="29da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行脚本train.sh，但是将历元数减少到50。<br/>使用的网络:ai85net-kws20.py中的ai85kws20net。</p><p id="d958" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们发现网络在50个周期后开始过度训练，因此我们停止了训练过程。<br/>以下图像记录了训练输出:<br/> - PNG文件e1、e10、e20、e30、e40和e50显示了训练期间混淆矩阵的进展<br/> - PNG文件eval和test显示了训练后评估脚本和测试运行的结果。<br/>-tensorboard-plots.png显示了张量板控制台的输出</p><p id="ab2a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后按照标准合成程序，使用ai8x-合成文库合成该模型。合成代码可以在<a class="ae lb" href="https://github.com/Kenneth-Joel/Ornithowav/tree/main/Synthesized-C-Code" rel="noopener ugc nofollow" target="_blank">Synthesized-C-Code.rar</a>中找到</p><p id="3ded" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">阶段4:使用测试集中的音频样本在硬件上进行测试。</strong></p><p id="a914" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后使用KWS20代码库作为参考，将代码闪存到MAX78000羽毛板上。对类别标签进行了适当的更改。<br/>通过笔记本电脑扬声器播放测试音频。<br/>相同的演示可以在下面的<a class="ae lb" href="https://youtu.be/f-ShF_WkPHo" rel="noopener ugc nofollow" target="_blank">视频</a>中找到:</p><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="mu mv l"/></div><p class="lv lw gj gh gi lx ly bd b be z dk translated">项目演示视频</p></figure><p id="056e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请参考<a class="ae lb" href="https://github.com/Kenneth-Joel/Ornithowav/tree/main/brd20_demo" rel="noopener ugc nofollow" target="_blank"> brd20_demo </a>(基于kws20_demo)以便能够在您自己的板上运行项目。还包括视频演示中使用的<a class="ae lb" href="https://github.com/Kenneth-Joel/Ornithowav/tree/main/Test%20Samples%20Used%20in%20Video%20Demo" rel="noopener ugc nofollow" target="_blank">测试样本</a>。不需要额外的硬件来测试这个代码，因为我们已经使用了板载麦克风。</p><p id="9a1d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">硬件设计</strong></p><p id="e157" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经基于MAX78000FTHR原理图构建了<a class="ae lb" href="https://github.com/Kenneth-Joel/Ornithowav/tree/main/Hardware%20Design%20Files" rel="noopener ugc nofollow" target="_blank">定制硬件</a>。对设计的主要改变是<br/> 1。移除所有视频相关硬件。<br/> 2。增加了32MB闪存，用于存储收集的音频数据，并随着时间的推移提高检测精度。<br/> 3。具有成本效益的BoM和PCB设计有助于简化制造和扩大规模。</p><p id="6d72" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">未来范围:</strong> <br/> -清理数据集:生成的数据集是纯基于代码的，没有手动清理。由于xeno-canto数据有时会因大量背景噪音而质量不佳，人工清理和标记可以大大提高准确性。<br/> -增强数据集:更多的鸟类，更多的样本，通过添加人类和非鸟类动物的声音来改进“未知”类别。<br/> -更大的输入尺寸:将输入长度从1秒增加到2.5秒可以提高精确度。[3] <br/> -神经架构搜索:由于资源限制，没有进行这么多的研究。希望在下一个<br/> -改进硬件:这个项目不需要额外的硬件，因为板载麦克风已经足够了。然而，我们有理由相信，更好的话筒可以带来更好的效果。由于这是一个遥感解决方案，电池组和GSM模块也可以增加价值，使其更易于部署。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="a44c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> P.S. <br/> </strong>这是一个爱好项目，没有商业意图，但有很大的社会影响潜力。我已经分享了我为这个项目编写和修改的所有源代码，并将非常兴奋地支持想要继续这项工作的人。随意伸手！不幸的是，重新采样和切片的数据集太大，无法上传，但我很乐意分享。</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><blockquote class="lc ld le"><p id="f25b" class="kf kg lf kh b ki kj jr kk kl km ju kn lg kp kq kr lh kt ku kv li kx ky kz la ij bi translated"><strong class="kh ir">参考文献:</strong><br/>【1】斯特凡·卡尔，康纳·m·伍德，马克西米利安·艾布尔，霍尔格·克林克，<br/> BirdNET:鸟类多样性监测的深度学习解决方案，<br/>生态信息学，<br/>第61卷，2021，101236，ISSN 1574–9541，<br/>https://doi.org/10.1016/j.ecoinf.2021.101236.<br/>(https://www . science direct . com/science/article/pii/s 157495412100021</p></blockquote><h2 id="740d" class="nd ne iq bd nf ng nh dn ni nj nk dp nl ko nm nn no ks np nq nr kw ns nt nu nv bi translated">概念验证的演示视频</h2><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h2 id="665a" class="nd ne iq bd nf ng nh dn ni nj nk dp nl ko nm nn no ks np nq nr kw ns nt nu nv bi translated">Github链接</h2><div class="mc md gp gr me mf"><a href="https://github.com/Kenneth-Joel/Ornithowav" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">GitHub - Kenneth-Joel/Ornithowav:“鸟类传感器”</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">“鸟类传感器”。在GitHub上创建一个帐户，为Kenneth-Joel/Ornithowav的开发做出贡献。</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">github.com</p></div></div><div class="mo l"><div class="nw l mq mr ms mo mt lt mf"/></div></div></a></div></div></div>    
</body>
</html>