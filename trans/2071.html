<html>
<head>
<title>Generation of a synthetic microbial dataset with deep learning style transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有深度学习风格转移的合成微生物数据集的生成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generation-of-a-synthetic-microbial-dataset-with-deep-learning-style-transfer-d6b879aaaf2d#2022-05-09">https://towardsdatascience.com/generation-of-a-synthetic-microbial-dataset-with-deep-learning-style-transfer-d6b879aaaf2d#2022-05-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f658" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">生成用于训练深度学习检测器的带注释的合成数据集的有效策略</h2></div><p id="8fe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">作者</em> <a class="ae lc" href="https://medium.com/@jaroslaw.pawlowski" rel="noopener"> <em class="lb">雅罗斯瓦夫</em> </a> <em class="lb">和</em> <a class="ae lc" href="https://medium.com/@sylwia.majchrowska" rel="noopener"> <em class="lb">西尔维娅</em> </a> <em class="lb">。</em></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/198e69666593c40d21a2e5e93c3fe6e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tjiSFtgObmfB7pMC.jpg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated">作者图片。</p></figure><p id="fca4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">深度学习模型</strong>实现了比传统计算机视觉算法高得多的精确度。当使用传统方法进行图像识别时，特征提取算法是手动调整的，这在许多情况下是一个耗时的过程。相反，在深度卷积网络中，特征工程是自动执行的——网络学习如何自己提取最佳特征图，并在后续卷积中优化内核，以仅保留图像中的相关信息。</p><p id="ad7b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以现在我们不需要花费数周时间来寻找最佳参数。但这是有代价的。为了通过复杂的深度学习模型获得足够的结果，我们需要足够大的数据集。收集和注释大数据集需要大量的时间和财力。此外，贴标过程本身也具有挑战性。<strong class="kh ir">合成数据</strong>是一种很有前途的替代方法，可以解决缺乏足够大的数据集的问题，并减少与收集此类数据相关的资源和成本[1]。此外，它可能有助于机构共享知识，例如高度专业化领域的数据集，同时保护个人隐私。</p><p id="6f9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的目标是<a class="ae lc" href="https://neurosys.com/recognition-and-counting-of-microorganisms" rel="noopener ugc nofollow" target="_blank">识别培养皿上的微生物菌落</a>——这是微生物学中的典型任务。即使对训练有素的专业人员来说，这项任务也很难完成，因为有些菌落容易聚集和重叠，因此非专业人员很难分辨。在这篇文章中，我们将提出一种有效的策略来生成一个由微生物图像组成的<strong class="kh ir">带注释的合成数据集</strong>，我们已经在<a class="ae lc" href="https://www.nature.com/articles/s41598-022-09264-z" rel="noopener ugc nofollow" target="_blank">自然<em class="lb">科学报告</em>杂志</a>【2】上发表了该数据集。然后，生成的数据集用于以完全监督的方式<strong class="kh ir">训练</strong>深度学习<strong class="kh ir">对象检测器</strong>。该生成器采用传统的计算机视觉算法以及神经类型的传输方法进行数据扩充。我们表明，该方法能够合成逼真图像的数据集，该数据集可用于训练能够定位、分割和分类五种不同微生物物种的神经网络模型。我们的方法比<a class="ae lc" href="https://neurosys.com/annotated-germs-automated-recognition-agar" rel="noopener ugc nofollow" target="_blank">收集并标记一大组带有注释的真实图像</a>需要更少的资源来获得有用的数据集。</p><blockquote class="lt lu lv"><p id="d07d" class="kf kg lb kh b ki kj jr kk kl km ju kn lw kp kq kr lx kt ku kv ly kx ky kz la ij bi translated">我们表明，从100幅真实图像开始，我们可以生成数据来训练一个检测器，该检测器可以获得与同一检测器相当的结果[3]，但要在一个真实的、大几十倍的<a class="ae lc" href="https://agar.neurosys.com/" rel="noopener ugc nofollow" target="_blank">微生物数据集</a> [4]上进行训练，该数据集包含超过7k幅图像。</p></blockquote><h1 id="d36d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">生成合成数据集</h1><p id="8e73" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">现在让我们详细描述该方法。目标是生成带有微生物菌落的合成图像，这些图像将在以后用于训练深度学习检测和分割模型。管道如图1所示。注意，我们的生成框架的Python实现的源代码是公开可用的。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/ef2255ca57d90cc26db5415bd507fa6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KaI7HFNqb-61spKB.jpg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="mw">图一。一种合成数据集生成流水线方案。使用传统的计算机视觉算法从真实图像中分割出微生物菌落，然后随机排列在空盘子的碎片上，给出带有精确注释的合成补丁。为了提高生成的数据的真实性，然后使用神经风格转移方法对面片进行风格化。图改编自[2]。</em></p></figure><p id="71bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们从培养皿的标记真实图像开始，使用传统的计算机视觉算法进行菌落分割，包括适当的过滤、CIELab颜色空间中的阈值处理和基于能量的分割——我们使用强大的<a class="ae lc" href="https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_chan_vese.html" rel="noopener ugc nofollow" target="_blank"> Chan-Vese算法</a>。为了获得一个平衡的工作数据集，我们从最近推出的<a class="ae lc" href="https://agar.neurosys.com/" rel="noopener ugc nofollow" target="_blank">琼脂数据集</a>【4】的<em class="lb">高分辨率</em>子集中为5种微生物物种中的每一种随机选择20张图像(总共给出100张图像)，这些图像可以根据请求从<a class="ae lc" href="https://agar.neurosys.com/" rel="noopener ugc nofollow" target="_blank">这个站点</a>免费下载。</p><p id="7769" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二步，<strong class="kh ir">将分割的菌落和菌落簇随机排列在空培养皿的碎片上</strong>(我们称之为贴片)。我们从10个真实的空盘子图像中随机选择一个片段。我们重复这个步骤很多次，把随后的集群放在随机的地方，确保它们不重叠。与此同时，<strong class="kh ir">我们存储了放置在小块上的聚类中每个菌落的位置及其分割掩码</strong>，为该小块创建了一个注释字典。我们在图2中展示了生成的合成补丁的例子。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/06fe47172266cbc09125190c984ae445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MVYwq-YbWMyYXu4l.jpg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="mw">图二。在风格化步骤之前具有微生物菌落的合成贴片的实例。图改编自[2]。</em></p></figure><p id="3b76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们在图2中所看到的，在某些情况下，菌落不能很好地与背景融合，它们的颜色与背景颜色不匹配。为了解决这个问题并<strong class="kh ir">提高生成数据的真实性</strong>，在第三步中，我们使用神经类型转移方法应用<strong class="kh ir">数据扩充。我们将风格从作为风格载体的选定实像之一转移到给定的原始面片。我们选择了20个具有显著不同光照条件的真实片段，以增加生成的碎片的多样性。风格化步骤后的示例性贴片如图3所示。我们使用[5]中介绍的快速有效的深度学习风格化算法。这种方法为我们的原始微生物图像提供了最真实的风格化，而不会引入任何不想要的伪像。</strong></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/baa8ed162a192b75beded4f4647a18f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RisOj_916gaTWSLz.jpg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="mw">图3。生成的微生物图像的风格化。五个合成补片(左)使用五个真实图像(上)的样式进行风格化。图改编自[2]。</em></p></figure><h1 id="be81" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">训练深度学习模型</h1><p id="72ee" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">使用这种方法，我们生成了大约50k个补丁，然后进行了风格化处理。所进行的实验背后的想法是<strong class="kh ir">使用合成数据</strong>训练一个神经网络模型来检测微生物菌落，然后<strong class="kh ir">用培养皿上的细菌菌落在真实图像</strong>上测试其性能。我们使用我们的合成数据集训练流行的R-CNN检测器。图4给出了对琼脂数据集的真实斑块进行级联R-CNN [6]检测器评估的示例。该模型在不同光照条件下检测各种大小的微生物菌落表现得相当好。</p><p id="fab5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自动实例分割是在许多生物医学应用中有用的任务。在面片生成过程中，我们还为每个菌落存储一个像素级的分割掩模。我们使用这些额外的信息来训练深度学习实例分割模型——Mask R-CNN[7]，它扩展了我们已经训练过的R-CNN检测器。真实样本的分割结果也呈现在图4中。获得的不同微生物菌落类型的实例分割正确地再现了菌落形状。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/78eeb74d20363f42e90333fb340dff65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_LBxaBgTTawk1YGL.jpg"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="mw">图四。真实数据上的微生物菌落检测示例(用绿色边框标记)—来自琼脂数据集的不同微生物种类的培养皿片段。例如分割的结果被呈现为颜色分割遮罩。图改编自[2]。</em></p></figure><p id="8b99" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">物体检测在微生物学中的主要应用之一是对培养皿上生长的微生物菌落进行自动计数。我们通过将其与标准方法进行比较来验证所提出的合成数据集生成方法，在标准方法中，我们收集大的真实数据集并训练检测器用于菌落识别和计数任务。</p><p id="cf44" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在使用来自<em class="lb">高分辨率</em>琼脂子集的<strong class="kh ir"> 100 </strong>图像生成的50k大数据集上训练R-CNN检测器(Cascade ),并在与【4】中执行的相同任务中测试微生物菌落计数。结果如图5(右)所示。结果表明，合成数据集的检测精度和计数误差仅比同一检测器稍差[3]，但在包含超过<strong class="kh ir"> 7k </strong>真实图像的整个大数据集上进行训练，给出了大约65k个面片。同样清楚的是，<strong class="kh ir">引入风格转移增强大大提高了检测质量</strong>，并且在没有风格化步骤的情况下，结果相当差——参见图5(左)中的<em class="lb">原始</em>数据集的结果，即在没有风格化步骤的情况下获得的结果。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mx"><img src="../Images/df5bf53698c76f5f1df440daddef1840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rtT2J0PdcklIiCFXj76zw.png"/></div></div><p class="lp lq gj gh gi lr ls bd b be z dk translated"><em class="mw">图5。对两个不同的合成训练数据集的真实数据进行微生物菌落计数测试:</em><em class="mw">raw——无风格化(左)和风格化(右)。风格化大大提高了检测性能。在理想的检测中，代表单个培养皿图像的每个黑点应该位于y = x黑线上。图改编自[2]。</em></p></figure><h1 id="fc21" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">摘要</h1><p id="a93b" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">我们引入了一种有效的策略来生成培养皿微生物图像的带注释的合成数据集，该数据集可用于以完全监督的方式训练深度学习模型。通过使用传统的计算机视觉技术，辅以深度神经类型转移算法，我们能够建立一个仅提供100幅真实图像的微生物数据生成器。与收集和标记包含数千幅真实图像的大型数据集相比，它需要的精力和资源要少得多。</p><blockquote class="lt lu lv"><p id="14ef" class="kf kg lb kh b ki kj jr kk kl km ju kn lw kp kq kr lx kt ku kv ly kx ky kz la ij bi translated">我们证明了该方法在微生物检测和分割中的有效性，但是我们期望该方法具有灵活性和通用性，还可以应用于科学和工业的其他领域来检测各种对象。</p></blockquote><h1 id="a851" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">参考</h1><p id="80d1" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">[1]<a class="ae lc" href="https://blogs.nvidia.com/blog/2021/06/08/what-is-synthetic-data" rel="noopener ugc nofollow" target="_blank">https://blogs . NVIDIA . com/blog/2021/06/08/what-is-synthetic-data</a></p><p id="1802" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]j . paw owski，S. Majchrowska和T. Golan，<em class="lb">具有深度学习风格转移的微生物菌落数据集的生成</em>，科学报告12，5212 (2022)。<a class="ae lc" href="https://doi.org/10.1038/s41598-022-09264-z" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1038/s41598-022-09264-z</a></p><p id="7cfa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3]检测mAP = 0.416(越大越好)，计数MAE = 4.49(越小越好)指标，与mAP = 0.520和MAE = 4.31相比，获得了相同的检测器，但使用琼脂数据集进行了训练[4]。</p><p id="a0b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4] S. Majchrowska，J. Pawł owski，G. Guł，T. Bonus，A. Hanas，A. Loch，A. Pawlak，J. Roszkowiak，T. Golan和Z. Drulis-Kawa，<em class="lb">琼脂微生物菌落数据集用于深度学习检测</em> (2021)。可在arXiv[<a class="ae lc" href="https://arxiv.org/abs/2108.01234" rel="noopener ugc nofollow" target="_blank">arXiv:2108.01234</a>]获得预印本。</p><p id="6ba4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5]，叶春阳，，<em class="lb">用于真实感风格传递的高分辨率网络</em> (2019)。预印本可从atXiv[<a class="ae lc" href="https://arxiv.org/abs/1904.11617" rel="noopener ugc nofollow" target="_blank">arXiv:1904.11617</a>]获得。</p><p id="3f43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[6]蔡志勇和，<em class="lb">级联R-CNN:深入研究高质量目标检测</em>，IEEE/CVF计算机视觉与模式识别会议，6154–6162(2018)。</p><p id="662a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[7] K. He，G. Gkioxari，P. Dollár，R. Girshick，<em class="lb"> Mask R-CNN </em>，IEEE计算机视觉国际会议(ICCV)，2980–2988(2017)。</p></div><div class="ab cl my mz hu na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="ij ik il im in"><p id="06cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为精明增长运营计划的一部分，该项目由欧洲区域发展基金下的欧盟基金共同资助。作为国家研究与发展中心的一部分实施的项目:快速通道。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/3137c0c90fca2f04ca4e93414bac3e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*gyuzfb5sSAL258ki.png"/></div></figure><p id="ac9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">原载于2022年5月06日</em><a class="ae lc" href="https://neurosys.com/deep-learning-synthetic-microbial-dataset" rel="noopener ugc nofollow" target="_blank"><em class="lb">【https://neurosys.com】</em></a><em class="lb">。</em></p></div></div>    
</body>
</html>