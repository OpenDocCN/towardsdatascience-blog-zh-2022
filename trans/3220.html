<html>
<head>
<title>KernelSHAP vs TreeSHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KernelSHAP vs TreeSHAP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kernelshap-vs-treeshap-e00f3b3a27db#2022-07-18">https://towardsdatascience.com/kernelshap-vs-treeshap-e00f3b3a27db#2022-07-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="337d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于速度、复杂性和其他考虑因素比较SHAP近似方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5feff351858397aa47daee72545ca41f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qAfrQhk6zlFT9yyvhNalig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(来源:<a class="ae ky" href="https://www.flaticon.com/premium-icon/corn_1680550" rel="noopener ugc nofollow" target="_blank"> flaticon </a>)</p></figure><p id="9f39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KernelSHAP和TreeSHAP都用于近似Shapley值。<strong class="lb iu"> TreeSHAP </strong>快多了。缺点是它只能和基于树的算法一起使用，比如random forests和xgboost。另一方面，<strong class="lb iu"> KernelSHAP </strong>是模型不可知的。这意味着它可以用于任何机器学习算法。我们将比较这两种近似方法。</p><p id="8901" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为此，我们将做一个实验。这将向我们展示TreeSHAP实际上有多快。我们也将探索树算法的参数如何影响时间复杂度。这些包括<strong class="lb iu">数量的树、</strong> <strong class="lb iu">深度</strong>和<strong class="lb iu">数量的特征</strong>。在使用TreeSHAP进行数据探索时，这些知识非常有用。最后，我们将讨论像特性依赖这样的其他考虑如何影响方法。</p><p id="933b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是第一次来SHAP，那么看看下面的视频。如果你想要更多，那就来看看我的<a class="ae ky" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> SHAP课程</strong> </a> <strong class="lb iu">。</strong>注册我的<a class="ae ky" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">简讯</strong> </a>:)即可免费获取</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure><h1 id="519b" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">每次观察时间</h1><p id="5b6c" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">对于第一个实验，我们想知道计算SHAP值的方法需要多少时间。我们不会讨论用来获得结果的代码，但是你可以在GitHub上找到它。总而言之，我们从模拟回归数据开始。这有<strong class="lb iu"> 10000个</strong>样本、<strong class="lb iu"> 10个</strong>特征和<strong class="lb iu"> 1个</strong>连续目标变量。利用这些数据，我们训练了一个随机森林。具体来说，模型有<strong class="lb iu"> 100 </strong>棵树，最大深度<strong class="lb iu"> 4 </strong>。</p><p id="6ce2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在可以用这个模型来计算SHAP值。我们使用KernelSHAP和TreeSHAP方法来实现这一点。对于每种方法，我们计算<strong class="lb iu"> 10 </strong>、<strong class="lb iu"> 100 </strong>、<strong class="lb iu"> 1000 </strong>、<strong class="lb iu"> 2000 </strong>、<strong class="lb iu"> 5000 </strong>和<strong class="lb iu"> 10000 </strong> SHAP值。对于每一笔金额，我们都记录了计算花费的时间。我们确保每笔金额重复这一过程3次。然后我们取平均值作为最终时间。</p><p id="4706" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在图1 中看到这个过程的结果。你可以看到TreeSHAP明显更快。对于<strong class="lb iu">10000个</strong> SHAP值，该方法花费了<strong class="lb iu"> 1.44秒</strong>。相比之下，KernelSHAP用了<strong class="lb iu"> 13分40.56秒</strong>。这是<strong class="lb iu"> 570倍</strong>那么长。这些计算的速度将取决于你的设备，但你应该期待类似的差异。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/b3e5590cc4043b33676d2197ac6f6b39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UTyB-lUi4V7m5ss3wHJMtg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:每次观察的时间(来源:作者)</p></figure><p id="c733" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的树形线看起来是平的。这是因为它被KernelSHAP线矮化了。在<strong class="lb iu">图2 </strong>中，我们有一条仅用于TreeSHAP的线。你可以看到它也随着观察次数的增加而线性增加。这告诉我们，每个SHAP值需要相似的时间来计算。我们将在下一节探讨原因。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/af1ad0a5f7e8c44845ad7538ff825706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N8M6jM7l-0JL3AJj7WjqGA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图TreeSHAP的每次观察时间(来源:作者)</p></figure><h1 id="27f1" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">时间复杂度</h1><p id="1370" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">两种方法的时间复杂度如下所示。这就是在树算法中计算要素的SHAP值时的复杂性。<strong class="lb iu"> T </strong>是单棵树的数量。<strong class="lb iu"> L </strong>是每棵树的最大叶子数。<strong class="lb iu"> D </strong>是每棵树的最大深度。最后，<strong class="lb iu"> M </strong>是每棵树的最大特征数。对于这些方法，这些参数将以不同的方式影响近似时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/a118b1a33ebae63f936d8c058f6e4354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-M_WyGZSiDXfdLq-HiaYVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(来源:作者)</p></figure><p id="cfda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只有TreeSHAP的复杂度受到深度的影响(<strong class="lb iu"> D </strong>)。另一方面，只有KernelSHAP受到特征数量的影响(<strong class="lb iu"> M </strong>)。不同的是KernelSHAP复杂度是<strong class="lb iu">指数</strong> w.r.t <strong class="lb iu"> M </strong>而TreeSHAP是<strong class="lb iu">二次</strong> w.r.t <strong class="lb iu"> D </strong>。考虑到我们还拥有比树深度(D= 4)更多的特征(M = 10 ),我们可以理解为什么KernelSHAP要慢一些。</p><p id="a3af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了清楚起见，这是每个SHAP值的时间复杂度。我们应该预料到每个值都需要相似的计算时间。这就是为什么我们看到了时间和观察次数之间的线性关系。我们现在将探索时间和其他参数<strong class="lb iu"> T </strong>、<strong class="lb iu"> L </strong>、<strong class="lb iu"> D </strong>和<strong class="lb iu"> M </strong>之间的关系。然后我们将讨论这些结果对模型验证和数据探索的意义。</p><h2 id="1d4c" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">树木数量(吨)</h2><p id="336b" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">对于这两种方法，复杂度与树的数量(T)成线性关系。我们预计这个参数会以类似的方式影响近似时间。为了看到这一点，我们执行了一个与之前类似的实验。这一次，我们通过增加树的数量来训练不同的模型。我们使用每个模型来计算100个SHAP值。</p><p id="62ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在图3中看到结果。对于这两种方法，时间随着树的数量线性增加。这是我们在考虑时间复杂度时所预期的。这告诉我们，通过限制树的数量，我们可以减少计算SHAP值的时间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/3775443401d8499f14601981aaa6ccca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcCPj9Me_qqB3txfs_eoJw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:每棵树的时间(来源:作者)</p></figure><h2 id="7e4a" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">特征数量(M)</h2><p id="68ff" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">只有KernelSHAP受到特性数量的影响(<strong class="lb iu"> M </strong>)。这次我们在不同数量的特征上训练模型。同时，我们保持其他参数(<strong class="lb iu"> T，L </strong>和<strong class="lb iu"> D </strong>不变。在<strong class="lb iu">图4 </strong>中，我们可以看到KernelSHAP的时间随着我们增加<strong class="lb iu"> M </strong>而呈指数增长。相比之下，TreeSHAP的时间没有受到太大影响。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/059faa3ff3210d70f4522c14ec8bb3a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6yBy4eyG2jdNwsrpXMGUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:每个特征的时间(来源:作者)</p></figure><p id="113e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能已经注意到TreeSHAP的时间逐渐增加。这可能会令人困惑，因为我们看到复杂度不依赖于m。要清楚的是，这是计算单个 特征的<strong class="lb iu"><em class="nl">SHAP值时的复杂度。随着M的增加，我们需要为每次观测计算更多的SHAP值。</em></strong></p><h2 id="9cc1" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">树深度(D)</h2><p id="6c78" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">最后，我们改变树的深度。我们确保森林中每棵树的深度始终是最大深度。在图5中，你可以看到当我们增加深度时会发生什么。TreeSHAP的时间增加得更快。甚至有一点TreeSHAP变得比KernelSHAP的计算量更大。我们可能已经预料到了这一点，因为我们看到只有树形复杂度是d的函数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/a17e8d821bf2be88594ccfd6cbd8fd18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xT9WntDwKUzoJsrPIf_K9g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5:每棵树深度的时间(来源:作者)</p></figure><p id="2abe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可能会问为什么内核时间也会增加。这是因为特征(M)和叶子(L)的数量根据树的深度而变化。随着深度的增加，会有更多的裂缝，所以我们会有更多的叶子。更多的分割也意味着树可以使用更多的功能。你可以在<strong class="lb iu">图6 </strong>中看到这一点。这里我们计算了森林中所有树木的特征和叶子的平均数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/983df30c1e182ca0d926ee72935f8ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uc8mv26LfX6tYK9Iqnai8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6:每棵树深度的特征和叶子(来源:作者)</p></figure><h2 id="0978" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">模型验证和数据探索的收获</h2><p id="41e3" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">通过改变深度，我们看到在某些情况下TreeSHAP的计算开销更大。然而，这些情况不太可能发生。我们看到只有当树深度为20时才会发生这种情况。在这么深的地方工作是不常见的。实际上，我们通常会有比树深度(D)更多的特征(M)。</p><p id="5b12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着，在用SHAP验证树模型时，TreeSHAP通常是更好的选择。我们能够更快地计算SHAP值。尤其是当你需要比较多个模型的时候。对于模型验证，我们对参数<strong class="lb iu"> T </strong>、<strong class="lb iu"> L </strong>、<strong class="lb iu"> D </strong>和<strong class="lb iu">m</strong>没有太多选择，因为我们只想验证性能最佳的模型。</p><p id="8567" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于数据探索，我们有更多的灵活性。树算法可用于发现重要的非线性关系和相互作用。要做到这一点，我们的模型只需要好到足以捕捉数据中的潜在趋势。我们可以通过减少树的数量和深度来加速这个过程。同时，我们能够探索许多模型特征(M ),而无需大幅提高速度。</p><h1 id="9bf9" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">其他考虑</h1><p id="2235" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在选择方法时，时间复杂度是一个重要因素。在做出选择之前，您可能需要考虑其他一些差异。这些问题包括KernelSHAP是模型不可知的，这些方法受特征依赖性的影响，并且只有TreeSHAP可以用于计算交互影响。</p><h2 id="de4a" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">模型不可知</h2><p id="5ded" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">在开始，我们提到TreeSHAP的最大限制是它不是模型不可知的。如果你正在使用非基于树的算法，你将不能使用它。神经网络也有自己的逼近方法。这些算法可以使用DeepSHAP。然而，KernelSHAP是唯一可以用于所有算法的方法。</p><h2 id="6136" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">功能依赖关系</h2><p id="becc" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">特性依赖会扭曲KernelSHAP所做的近似。该算法通过随机采样特征值来估计SHAP值。问题是，当要素相关时，采样值可能不太可能。这意味着，当使用SHAP值时，我们可能会对不太可能的观察结果赋予太多的权重。</p><p id="33e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TreeSHAP没有这个问题。然而，由于特征依赖性，该算法具有不同的问题。也就是说，对预测没有影响的特征可以获得非零的SHAP值。当一个要素与另一个影响预测的要素相关时，可能会发生这种情况。在这种情况下，我们可能会得出一个错误的结论，即某个特征有助于预测。</p><h2 id="b825" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">分析相互作用</h2><p id="08b3" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">SHAP互动价值观是SHAP价值观的延伸。它们的工作原理是将一个特征的贡献分解成主要的和交互的效果。对于一个给定的特性，交互效应是它与其他特性的所有联合贡献。当突出显示和可视化数据中的交互时，这些会很有用。我们将在下面的文章中深入探讨这个问题。</p><div class="no np gp gr nq nr"><a rel="noopener follow" target="_blank" href="/analysing-interactions-with-shap-8c4a2bc11c2a"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">分析与SHAP的互动</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">使用SHAP Python包来识别和可视化数据中的交互</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">towardsdatascience.com</p></div></div><div class="oa l"><div class="ob l oc od oe oa of ks nr"/></div></div></a></div><p id="9333" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想使用SHAP交互值，你必须使用TreeSHAP。这是因为这是唯一一种实现了相互作用值的近似方法。这与SHAP互动价值观的复杂性有关。估计这些可能需要更长的时间。</p><p id="954a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，您应该尽可能使用TreeSHAP。它速度快得多，让你有能力分析互动。对于数据探索，您可能希望坚持使用树算法来获得这些好处。如果你正在使用其他类型的算法，那么你必须坚持使用KernelSHAP。它仍然是一种比蒙特卡罗抽样等其他方法更快的近似方法。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><div class="kj kk kl km gt nr"><a href="https://conorosullyds.medium.com/membership" rel="noopener follow" target="_blank"><div class="ns ab fo"><div class="nt ab nu cl cj nv"><h2 class="bd iu gy z fp nw fr fs nx fu fw is bi translated">通过我的推荐链接加入Medium康纳·奥沙利文</h2><div class="ny l"><h3 class="bd b gy z fp nw fr fs nx fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="nz l"><p class="bd b dl z fp nw fr fs nx fu fw dk translated">conorosullyds.medium.com</p></div></div><div class="oa l"><div class="on l oc od oe oa of ks nr"/></div></div></a></div><p id="7356" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在|<a class="ae ky" href="https://twitter.com/conorosullyDS" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae ky" href="https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae ky" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank">时事通讯</a>上找到我——注册免费参加<a class="ae ky" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> Python SHAP课程</a></p><h2 id="1378" class="mx ly it bd lz my mz dn md na nb dp mh li nc nd mj lm ne nf ml lq ng nh mn ni bi translated">图像来源</h2><p id="4c46" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">所有图片都是我自己的或从<a class="ae ky" href="http://www.flaticon.com/" rel="noopener ugc nofollow" target="_blank">www.flaticon.com</a>获得。在后者的情况下，我拥有他们的<a class="ae ky" href="https://support.flaticon.com/hc/en-us/articles/202798201-What-are-Flaticon-Premium-licenses-" rel="noopener ugc nofollow" target="_blank">保费计划</a>中定义的“完全许可”。</p><h1 id="b905" class="lx ly it bd lz ma mb mc md me mf mg mh jz mi ka mj kc mk kd ml kf mm kg mn mo bi translated">参考</h1><p id="4c67" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li mr lk ll lm ms lo lp lq mt ls lt lu im bi translated">南伦德伯格、<strong class="lb iu"> SHAP蟒包</strong> <em class="nl"> </em> (2021) <em class="nl">、</em><a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">https://github.com/slundberg/shap</a></p><p id="4958" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">南Lundberg &amp; S. Lee，<strong class="lb iu">解释模型预测的统一方法</strong> <em class="nl"> </em> (2017)，<a class="ae ky" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1705.07874.pdf</a></p><p id="27c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">南Lundberg，S.M .，G. Erion，G.G .和Lee，s . I .(2018年)。树集成的一致个性化特征属性。<em class="nl"> arXiv预印本arXiv:1802.03888 </em>。</p><p id="cf05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">C.Molnar，<strong class="lb iu">可解释机器学习</strong><em class="nl"/>【2021】<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/shap.html" rel="noopener ugc nofollow" target="_blank">https://christophm . github . io/Interpretable-ml-book/shap . html</a></p><p id="60f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">南Masís，<strong class="lb iu">用Python进行可解释的机器学习</strong> (2021)</p></div></div>    
</body>
</html>