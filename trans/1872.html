<html>
<head>
<title>Demystify Machine Learning Model Selection, a Step by Step Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开机器学习模型选择的神秘面纱，逐步指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystify-machine-learning-model-selection-e3f913bab7e7#2022-05-01">https://towardsdatascience.com/demystify-machine-learning-model-selection-e3f913bab7e7#2022-05-01</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="f607" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">利用交叉验证、性能指标和总运行时间来确定最适合您的数据的模型</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/be8822511af2dba85793b43668a398db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gRdXgKj4JV7HuXak"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">弗拉季斯拉夫·巴比延科在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="0934" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">什么是选型？</h1><p id="db66" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">机器学习中的模型选择就是为你的数据选择最好的模型。不同的模型在不同的数据集上会有不同的表现，而且差距可能很大。如今，梯度增强树是表格数据的<a class="ae kz" href="https://www.quora.com/Why-is-XGBoost-among-most-used-machine-learning-method-on-Kaggle" rel="noopener ugc nofollow" target="_blank">最佳执行模型</a>，例如<a class="ae kz" rel="noopener" target="_blank" href="/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d"> XGBoost </a>，或者SciKit Learn中的实现，这是很常见的。但是，不要总是默认使用XGBoost之类的模型，重要的是要评估不同算法的性能，看看哪种算法最适合您。</p><p id="daad" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">此外，不同的模型也有一些优势。例如，<strong class="lu iv">逻辑回归</strong>可以告诉你模型的<strong class="lu iv">系数</strong>，让你解释每个特征对最终预测的影响。像<strong class="lu iv"> RandomForest </strong>这样的袋装树模型可以告诉你模型中每一列的<strong class="lu iv">特征重要性</strong>，类似于Logistic回归的系数。</p><p id="00b5" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">让我们来看看如何在您选择的评分标准和训练速度之间选择最佳模型。</p><h1 id="f512" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">入门指南</h1><p id="f1df" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">对于我们今天的演示，我们将使用<strong class="lu iv">银行营销UCI </strong>数据集，您可以在<a class="ae kz" href="https://www.kaggle.com/c/bank-marketing-uci" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上找到该数据集。该数据集包含有关营销活动中银行客户的信息，并且包含一个可以在分类模型中使用的目标变量。该数据集在CC0: public domain下的Public Domain中，可以使用。</p><p id="a1b3" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">有关构建分类模型的更多信息，请查看:<a class="ae kz" rel="noopener" target="_blank" href="/everything-you-need-to-know-to-build-an-amazing-binary-classifier-590de3482aad">构建令人惊叹的二进制分类器所需要知道的一切</a>和<a class="ae kz" rel="noopener" target="_blank" href="/go-beyond-binary-classification-with-multi-class-and-multi-label-models-6ce91ca08264">超越了具有多类和多标签模型的二进制分类</a>。</p><p id="cea6" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">我们将从导入必要的库和加载数据开始。我们今天将利用Scikit-Learn进行分析。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="1d01" class="my lb iu mu b be mz na l nb nc">import numpy as np<br/>import pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from timeit import timeit<br/><br/>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.model_selection import RepeatedStratifiedKFold<br/>from sklearn.preprocessing import OneHotEncoder, LabelEncoder<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.compose import ColumnTransformer<br/><br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.linear_model import Perceptron<br/>from sklearn.linear_model import SGDClassifier<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble import GradientBoostingClassifier<br/>from sklearn.ensemble import HistGradientBoostingClassifier<br/>from sklearn.ensemble import AdaBoostClassifier<br/>from sklearn.ensemble import ExtraTreesClassifier<br/>from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/><br/>from sklearn.compose import make_column_selector as selector<br/>from sklearn.pipeline import Pipeline</span></pre><p id="4b99" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">接下来，我们将数据加载到一个<strong class="lu iv">熊猫数据帧</strong>中，并观察它的形状。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="7245" class="my lb iu mu b be mz na l nb nc">df = pd.read_csv("bank.csv", delimiter=";")<br/>df.shape</span></pre><pre class="nd mt mu mv bn mw mx bi"><span id="315a" class="my lb iu mu b be mz na l nb nc">(4521, 17)</span></pre><h1 id="c47c" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">数据清理</h1><p id="91a2" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">我们有<strong class="lu iv">4500行</strong>17列的数据，包括目标变量。在执行我们的模型选择之前，我们将对数据进行一些简单的清理，首先寻找<strong class="lu iv">空值</strong>，实际上没有空值，并删除任何重复的<strong class="lu iv"/>。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="2fed" class="my lb iu mu b be mz na l nb nc"># check for nan/null<br/>df.isnull().values.any()<br/># drop duplicates<br/>len(df.drop_duplicates())</span></pre><p id="06b0" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">接下来，在这个特定的数据集中，我们需要删除<strong class="lu iv">持续时间</strong>列。如文件中所述，该列对目标变量的结果有很大影响，因此，应从培训中排除。</p><blockquote class="ne nf ng"><p id="7834" class="ls lt nh lu b lv mo jv lx ly mp jy ma ni mq md me nj mr mh mi nk ms ml mm mn in bi translated"><strong class="lu iv">持续时间</strong>:最后一次联系的持续时间，单位为秒(数字)。重要注意事项:该属性对输出目标有很大影响(例如，如果duration=0，则y='no ')。然而，在执行呼叫之前，持续时间是未知的。还有，结束通话后y显然是已知的。因此，该输入应仅用于基准测试目的，如果目的是获得现实的预测模型，则应丢弃。</p></blockquote><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="235b" class="my lb iu mu b be mz na l nb nc">df.drop(columns='duration', inplace=True)</span></pre><h1 id="5442" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">数据准备</h1><p id="294e" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">接下来，让我们利用简单的python切片将数据分成<code class="fe nl nm nn mu b">X</code>和<code class="fe nl nm nn mu b">y</code>两个集合。因为我们的目标变量是最后一列，所以我们可以只取最后一列作为我们的<code class="fe nl nm nn mu b">X</code>数据，只取最后一列作为我们的<code class="fe nl nm nn mu b">y</code>数据。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="bd6e" class="my lb iu mu b be mz na l nb nc">X = df.iloc[:, :-1]<br/>y = df.iloc[:,-1]</span></pre><p id="e763" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">我们的<code class="fe nl nm nn mu b">y</code>列是带有<code class="fe nl nm nn mu b">yes</code>和<code class="fe nl nm nn mu b">no</code>值的二进制列。最好利用Skikit-Learn中的<code class="fe nl nm nn mu b">LabelEncoder</code>将这些编码到<code class="fe nl nm nn mu b">1</code>和<code class="fe nl nm nn mu b">0</code>中。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="3b53" class="my lb iu mu b be mz na l nb nc">enc = LabelEncoder()<br/>enc.fit(y)<br/>y = enc.transform(y)</span></pre><p id="0272" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">接下来，我们将利用<strong class="lu iv">列转换器</strong>将我们的数据转换成机器学习可接受的格式。每当我为可重复性构建模型时，我更喜欢使用管道。关于它们的更多信息，请查看我的文章:<a class="ae kz" rel="noopener" target="_blank" href="/using-pipelines-in-sci-kit-learn-516aa431dcc5">停止一步一步地构建你的模型。利用管道实现流程自动化！</a>。</p><p id="0aea" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">对于我们的转换，我们为数字特征选择了<code class="fe nl nm nn mu b">MinMaxScaler</code>，为分类特征选择了<code class="fe nl nm nn mu b">OneHotEncode</code> (OHE)。OHE将分类数据转换为二进制表示形式，防止模型预测序数值之间的值。更多关于OHE的信息，请查看:<a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank">一个热门编码</a>。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="b2ec" class="my lb iu mu b be mz na l nb nc">column_trans = ColumnTransformer(transformers=<br/>        [('num', MinMaxScaler(), selector(dtype_exclude="object")),<br/>        ('cat', OneHotEncoder(), selector(dtype_include="object"))],<br/>        remainder='drop')</span></pre><h1 id="5623" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">为模型选择创建模型列表</h1><p id="692b" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">现在我们要用我们不同的模型建立一个字典。字典中的每个条目由作为<strong class="lu iv">键</strong>的<strong class="lu iv">型号名称</strong>和作为<strong class="lu iv">值</strong>的<strong class="lu iv">管道</strong>组成。</p><p id="4c6b" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">模型选择的想法是挑选性能最佳的模型，而不是调整模型以获得最佳性能。这就是所谓的超参数调整，您可以在这里了解更多信息:【HalvingGridSearch使超参数调整速度提高了5到10倍。</p><p id="b2f4" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">因此，我们将用默认参数实例化每个模型。一个例外是，我总是倾向于使用可用的<code class="fe nl nm nn mu b">class_weight='balanced'</code>参数。这是一种简单的方法来抵消不平衡数据带来的问题。在这里阅读更多关于处理不平衡数据的内容:<a class="ae kz" rel="noopener" target="_blank" href="/working-with-imbalanced-data-efbd96b3e655">在构建你的ML模型的时候不要陷入不平衡数据的陷阱</a>。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="d548" class="my lb iu mu b be mz na l nb nc">def get_models():<br/>    models = dict()<br/><br/>    models['Logistic Regression'] = Pipeline([('prep', column_trans), <br/>        ('model', LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'))])<br/><br/>    models['Decision Tree'] = Pipeline([('prep', column_trans), <br/>        ('model', DecisionTreeClassifier(random_state=42, class_weight='balanced'))])<br/><br/>    models['Random Forest'] = Pipeline([('prep', column_trans), <br/>        ('model', RandomForestClassifier(random_state=42, class_weight='balanced'))])<br/><br/>    models['Extra Trees'] = Pipeline([('prep', column_trans), <br/>        ('model', ExtraTreesClassifier(random_state=42, class_weight='balanced'))])<br/><br/>    models['Gradient Boosting'] = Pipeline([('prep', column_trans), <br/>        ('model', GradientBoostingClassifier(random_state=42))])<br/><br/>    models['Hist Gradient Boosting'] = Pipeline([('prep', column_trans), <br/>        ('model', HistGradientBoostingClassifier(random_state=42))])<br/><br/>    models['AdaBoost'] = Pipeline([('prep', column_trans), <br/>        ('model', AdaBoostClassifier(random_state=42))]) <br/><br/>    models['SGD'] = Pipeline([('prep', column_trans), <br/>        ('model', SGDClassifier(random_state=42, class_weight='balanced'))])<br/><br/>    models['SVC'] = Pipeline([('prep', column_trans), <br/>        ('model', SVC(class_weight='balanced', random_state=42))])<br/><br/>    models['Nearest Neighbor'] = Pipeline([('prep', column_trans), <br/>        ('model', KNeighborsClassifier(3))])<br/><br/>    models['Perceptron'] = Pipeline([('prep', column_trans), <br/>        ('model', Perceptron(random_state=42))])<br/><br/>    return models</span></pre><h1 id="f34e" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">交叉验证</h1><p id="2c73" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">在训练模型时，不要让模型过度适应您的数据或允许它一次看到所有数据，这一点很重要。通常你会对你的数据进行<strong class="lu iv">训练测试分割</strong>；然而，在这种情况下，我们将使用<strong class="lu iv">交叉验证</strong>方法，利用<code class="fe nl nm nn mu b">RepeatedStratifiedKFold</code>方法找到最佳模型，以处理将数据划分到多个训练和测试集。</p><p id="b0a2" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated"><strong class="lu iv">分层</strong>采样确保相对类别频率在每个训练和验证折叠中大致保持不变，对于不平衡数据至关重要。关于这种方法的更多信息，请查看:<a class="ae kz" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">交叉验证:评估评估者的表现</a>。</p><p id="d690" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">我们将构建一个可重用的函数，允许我们测试存储在字典中的不同模型。根据数据集的大小，这里有几个参数可以使用。您可以确定<strong class="lu iv">分割</strong>和<strong class="lu iv">重复</strong>的次数。如果您有一个像本例这样的较小数据集，请尽量不要多次分割数据，否则您将没有足够的样本来进行训练和测试。</p><p id="67ca" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">此外，您需要指定想要使用的评分标准。Scikit-Learn支持许多不同的工具，您可以在他们的<a class="ae kz" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank">文档</a>中看到如何引用它们。对于这个例子，我选择了<strong class="lu iv"> ROC-AUC </strong>作为我的指标。有关选择最佳度量的更多信息，请查看:<a class="ae kz" rel="noopener" target="_blank" href="/evaluating-ml-models-with-a-confusion-matrix-3fd9c3ab07dd">停止使用准确性来评估您的分类模型</a>。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="bdb3" class="my lb iu mu b be mz na l nb nc"># evaluate a give model using cross-validation<br/>def evaluate_model(model, X, y):<br/>    cv = RepeatedStratifiedKFold(n_splits=5, <br/>                                 n_repeats=10, <br/>                                 random_state=1)<br/>    scores = cross_val_score(model, X, y, <br/>                             scoring='roc_auc', <br/>                             cv=cv, n_jobs=-1)<br/>    return scores</span></pre><h1 id="4d51" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">评估模型</h1><p id="5c66" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated">现在我们可以进行评估了。我们将调用<code class="fe nl nm nn mu b">evaluate_model</code>函数遍历字典，并将结果存储在一个列表中。我们将对模型的名称做同样的处理，以便于我们绘图。</p><p id="4948" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">每次评估模型时，我们还会使用神奇的命令<code class="fe nl nm nn mu b">%time</code>检查模型的速度，它会打印出评估模型所花费的时间，帮助我们进行选择。我们还打印出十次重复的<strong class="lu iv">平均分数</strong>和<strong class="lu iv">标准偏差</strong>分数。</p><p id="36f6" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">最后，我们将利用分数的<strong class="lu iv">盒须图</strong>在单个图上绘制结果。</p><pre class="kk kl km kn gu mt mu mv bn mw mx bi"><span id="2ffd" class="my lb iu mu b be mz na l nb nc"># get the models to evaluate<br/>models = get_models()<br/><br/># evaluate the models and store results<br/>results, names = list(), list()<br/>for name, model in models.items():<br/>    %time scores = evaluate_model(model, X, y)<br/>    results.append(scores)<br/>    names.append(name)<br/>    print('* %s Score = %.3f StdDev = (%.3f)' % (name, np.mean(scores), np.std(scores)), '\n')<br/><br/># plot model performance for comparison<br/>plt.figure(figsize=(10,8))<br/>plt.boxplot(results, labels=names, showmeans=True)<br/>plt.xticks(rotation=45)</span></pre><pre class="nd mt mu mv bn mw mx bi"><span id="ff09" class="my lb iu mu b be mz na l nb nc">290 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Logistic Regression Score = 0.721 StdDev = (0.025) <br/><br/>204 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Decision Tree Score = 0.573 StdDev = (0.021) <br/><br/>1.61 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Random Forest Score = 0.730 StdDev = (0.024) <br/><br/>1.68 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Extra Trees Score = 0.701 StdDev = (0.021) <br/><br/>2.75 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Gradient Boosting Score = 0.756 StdDev = (0.021) <br/><br/>2.04 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Hist Gradient Boosting Score = 0.728 StdDev = (0.021) <br/><br/>886 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* AdaBoost Score = 0.733 StdDev = (0.023) <br/><br/>212 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* SGD Score = 0.690 StdDev = (0.031) <br/><br/>4.01 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* SVC Score = 0.715 StdDev = (0.027) <br/><br/>660 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Nearest Neighbor Score = 0.608 StdDev = (0.022) <br/><br/>127 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)<br/>* Perceptron Score = 0.639 StdDev = (0.043)</span></pre><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj no"><img src="../Images/601e94d2df41c7b44c80994a853b2ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wM_X4TDwcgAHHzVo.png"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">作者图片</p></figure><p id="672d" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">在这里，我们可以很好地看到每个型号的性能。某些算法表现不佳，我们可以在这个用例中丢弃它们，例如简单的<strong class="lu iv">决策树</strong>、最近邻分类器<strong class="lu iv">和<strong class="lu iv">感知器</strong>分类器。这些都是列表中一些比较简单的模型，它们的表现比其他的差并不奇怪。<strong class="lu iv">梯度提升树</strong>是表现最好的分类器，ROC-AUC得分为<code class="fe nl nm nn mu b">0.756</code>，名副其实。AdaBoost </strong>和<strong class="lu iv"> RandomForest </strong>紧随其后，分别获得<code class="fe nl nm nn mu b">0.733</code>和<code class="fe nl nm nn mu b">0.730</code>的分数。</p><p id="024f" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">我们还可以看看运行所用的时间。在这些模型中，<strong class="lu iv">梯度增强树</strong>在<code class="fe nl nm nn mu b">2.75</code>秒时表现最慢，而<strong class="lu iv"> AdaBoost </strong>在<code class="fe nl nm nn mu b">886</code>毫秒时表现最好。看<strong class="lu iv">逻辑回归</strong>；然而，它在<code class="fe nl nm nn mu b">0.721</code>时表现相当好，但在<code class="fe nl nm nn mu b">290</code>毫秒时非常快，这可能会影响我们的选择过程。通过利用其系数，逻辑回归具有<strong class="lu iv">高解释能力</strong>的优点，并且在梯度增强树的大约10%的时间内执行。</p><p id="6082" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">最终的选择取决于你，但是这些方法应该给你一个强大的基线来为你的用例选择最好的模型！</p><p id="42cd" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">本文的所有代码都可以在<a class="ae kz" href="https://github.com/broepke/ModelSelection" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得</p><h1 id="bd9a" class="la lb iu bd lc ld le lf lg lh li lj lk ka ll kb lm kd ln ke lo kg lp kh lq lr bi translated">结论</h1><p id="5848" class="pw-post-body-paragraph ls lt iu lu b lv lw jv lx ly lz jy ma mb mc md me mf mg mh mi mj mk ml mm mn in bi translated"><strong class="lu iv">模型选择</strong>是你建立机器学习模型的关键一步。选择正确的模型会极大地影响机器学习模型的性能，而选择错误的模型会给你留下无法接受的结果。我们通过利用<strong class="lu iv">管道</strong>来实现一致性，完成了<strong class="lu iv">准备数据</strong>的过程。然后，我们建立了一个模型列表，我们希望<strong class="lu iv">评估他们的表现</strong>。我们使用交叉验证在各种数据切片上测试每个模型，并最终绘制出结果。利用这一过程是为您的应用选择正确型号的快速而有效的方法！</p><p id="5a7b" class="pw-post-body-paragraph ls lt iu lu b lv mo jv lx ly mp jy ma mb mq md me mf mr mh mi mj ms ml mm mn in bi translated">如果你喜欢阅读这样的故事，并想支持我成为一名作家，考虑注册成为一名媒体成员。一个月5美元，让你可以无限制地访问成千上万篇文章。如果您使用我的链接  <em class="nh">注册，我会为您赚取一小笔佣金，无需额外费用。</em></p></div></div>    
</body>
</html>