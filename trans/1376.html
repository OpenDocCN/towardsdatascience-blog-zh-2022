<html>
<head>
<title>A Casual Flirt with Image Compression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随意摆弄图像压缩</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-casual-flirt-with-image-compression-abbb2679f492#2022-04-05">https://towardsdatascience.com/a-casual-flirt-with-image-compression-abbb2679f492#2022-04-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/14b77539737b273593f78644c5128f02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ylQyxJxXkdg-Wkip"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated"><a class="ae kc" href="https://unsplash.com/@mustachescactus" rel="noopener ugc nofollow" target="_blank"> mustachescactus </a>在<a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="822a" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="6aaa" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">想象一下。您的网络运行缓慢。Youtube已经自动将720p设置为您的视频质量，您已经从您的youtube建议中随机添加了一些内容。有点标准的场景，对吧？</p><p id="beec" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在，很可能你喜欢内容，然后你突然意识到视频质量应该更好。将光标移至设置按钮，手动将视频设置为更高的质量。但是，你有没有注意到，当你手动调整视频质量时，youtube为你加载的任何缓冲都丢失了:(</p><p id="5863" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这到底是怎么回事？手动更改视频质量会发生什么情况？youtube是如何动态改变视频质量的？所有这些都是非常有趣的问题，需要知道答案。让我们在下一节中尝试理解这些</p><h1 id="dc5d" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">动态视频质量切换</h1><p id="7162" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了理解动态视频质量切换，理解视频如何从服务器流到我们的浏览器是非常重要的。一个通用的技巧是将每个视频分成多个分辨率，并将每个分辨率分成更小的片段。然后，浏览器负责请求所需的分辨率和代码片段，然后将它们整齐地拼接在一起，显示在屏幕上。让我们来看看更多的细节。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/3629199c563749ddbf7acbf03c169fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J6kJmoV9h7qLlI5g.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="e74f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">源视频在后端被转换成多个分辨率，分成几秒钟(比如2秒)的小块。</p><p id="5ee2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在，当用户在浏览器屏幕上打开视频时，youtube会以默认分辨率启动，并获取一些块来启动视频。在接下来的几秒钟内，客户端可以更好地统计网络容量，并基于此向服务器请求不同质量的数据块，以便为用户提供最佳体验。该统计数据被持续维护，并不断适应不断变化的网络行为。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/52ca97d1ba144d9182105c5235fed67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HB3mF2rGDoJfrYjy.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="9328" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上图是视频质量在客户端如何动态变化的时间轴示例。</p><p id="c300" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">使用在所有主流浏览器中实现的媒体源扩展API，在客户端将块缝合在一起。它提供了支持无插件的基于网络的流媒体的功能。使用MSE，可以通过JavaScript创建媒体流，并使用<code class="fe mk ml mm mn b"><a class="ae kc" href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio" rel="noopener ugc nofollow" target="_blank">&lt;audio&gt;</a></code>和<code class="fe mk ml mm mn b"><a class="ae kc" href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video" rel="noopener ugc nofollow" target="_blank">&lt;video&gt;</a></code>元素播放。</p><p id="114a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">如果你对整个过程的更多细节感兴趣，请参考<a class="ae kc" href="https://medium.com/canal-tech/how-video-streaming-works-on-the-web-an-introduction-7919739f7e1" rel="noopener">这篇中间文章</a></p><h1 id="a283" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">那么问题是什么呢？</h1><p id="5391" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">常见的情况是用户在中途明确改变视频质量。下面的事情发生了，播放突然停止，播放器等待下载更多的块。更重要的是，所有下载的缓冲区都被丢弃。现在，这可能与用户无关，但为技术迷带来了一个有趣的声明。</p><blockquote class="mo mp mq"><p id="2adc" class="lb lc mr ld b le lz lg lh li ma lk ll ms mb lo lp mt mc ls lt mu md lw lx ly ij bi translated">我们能把视频数据构造成本质上是可加的吗？</p></blockquote><p id="e04f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我来解释一下上面的说法，作为一个大概的估计。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/f41522d0077255836eed1ca809f6bd28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W35YJ8ntw_IRr2vMR6hZIg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图像</p></figure><p id="99a9" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上表参考了来自<a class="ae kc" href="https://www.whistleout.com/CellPhones/Guides/How-Much-Data-Does-YouTube-Use" rel="noopener ugc nofollow" target="_blank">哨声</a>的数据</p><p id="d33f" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">如果浏览器当前拥有1分钟的360p缓冲区，然后用户请求720p视频质量，则5MB数据将被丢弃，另外25MB数据用于这1分钟的视频。</p><p id="2325" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">然而，如果我们有一个附加算法或方法，我们可以只请求服务器只发送大约20MB的信息来添加到360p视频，并使其成为720p视频。那岂不是很酷！</p><h1 id="e4cf" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">公式化优化问题</h1><p id="d0c6" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">让我们试着进一步解决这个问题。因为视频最终是一系列图像，所以我们可以用图像而不是视频来表述这个问题吗？让我们也把范围缩小到黑白图像，因为图像本质上是3个通道的融合。</p><blockquote class="mo mp mq"><p id="a76c" class="lb lc mr ld b le lz lg lh li ma lk ll ms mb lo lp mt mc ls lt mu md lw lx ly ij bi translated">构建图像数据，使其可以切片以创建一个差的图像，但增加更多的数据切片，图像质量会不断提高！</p></blockquote><p id="57db" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们看一些伪代码</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="6919" class="na ke iq mn b gy nb nc l nd ne">base_image <strong class="mn ir">=</strong> get_buffer<strong class="mn ir">(</strong>'my_image'<strong class="mn ir">,</strong> <strong class="mn ir">(</strong>0<strong class="mn ir">,</strong> 20<strong class="mn ir">))</strong><br/>display<strong class="mn ir">(</strong>base_image<strong class="mn ir">)</strong></span><span id="c9fe" class="na ke iq mn b gy nf nc l nd ne"><em class="mr"># Now let's bring some additive data to improve the image quality<br/></em>additive_info <strong class="mn ir">=</strong> get_buffer<strong class="mn ir">(</strong>'my_image'<strong class="mn ir">,</strong> <strong class="mn ir">(</strong>20<strong class="mn ir">,</strong> 60<strong class="mn ir">))</strong><br/>improved_image <strong class="mn ir">=</strong> base_image<strong class="mn ir">.</strong>add<strong class="mn ir">(</strong>additive_info<strong class="mn ir">)</strong><br/>display<strong class="mn ir">(</strong>improved_image<strong class="mn ir">)</strong></span></pre><h1 id="9a9a" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">图像作为矩阵</h1><p id="b29c" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">图像是数字的矩阵。600x400的黑白图像必然是形状(600，400)的矩阵。一想到矩阵，矩阵代数就暗示一个矩阵可以由一堆其他矩阵组成。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/be656d72e099f350e81419d27b4e289f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_BQOaeMuXXJn8DYs.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="52e3" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">原始图像X (600，400)可以分解成两个矩阵A (600，c)和B (c，400 ),使得A和B的点积产生X。</p><p id="5231" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">此外，矩阵A和B应该使得任何切片A(600，d)和B(d，400)也尽可能精确地产生原始图像X。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/8e67d13b1fc3226f846782abfe5294a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Qf1vgWoYoT8U87NO.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><h1 id="b22e" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">基于梯度的优化</h1><p id="7e64" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">一旦清楚地表述了这个问题，用PyTorch为它编写一个优化器就非常容易了。我们来看看实现。</p><p id="21fb" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们把下面的图片作为我们的参考图片。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9cba05857cefec7537395c317f5088dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q2HTvkA01d-mL5O1"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">在<a class="ae kc" href="https://unsplash.com/s/photos/breakfast?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae kc" href="https://unsplash.com/@flipboard?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Flipboard </a>拍摄的照片</p></figure><p id="9107" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">让我们加载图像并将其转换为黑白图像。</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="d69c" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># imports<br/></em>from PIL import Image<br/>import numpy <strong class="mn ir">as</strong> np</span><span id="068e" class="na ke iq mn b gy nf nc l nd ne"><em class="mr"># load the image and convert it into a b/w image<br/></em>img <strong class="mn ir">=</strong> Image<strong class="mn ir">.</strong><em class="mr">open</em><strong class="mn ir">(</strong>'reference_image.png'<strong class="mn ir">)</strong><br/>bw_img <strong class="mn ir">=</strong> img<strong class="mn ir">.</strong>convert<strong class="mn ir">(</strong>'L'<strong class="mn ir">)</strong></span><span id="0798" class="na ke iq mn b gy nf nc l nd ne">bw_img<strong class="mn ir">.</strong>show<strong class="mn ir">()</strong></span><span id="373e" class="na ke iq mn b gy nf nc l nd ne"><em class="mr"># get the numpy matrix from the image data<br/></em>data <strong class="mn ir">=</strong> bw_img<strong class="mn ir">.</strong>getdata<strong class="mn ir">()</strong><br/>data <strong class="mn ir">=</strong> np<strong class="mn ir">.</strong>asarray<strong class="mn ir">(</strong>data<strong class="mn ir">)</strong><strong class="mn ir"> </strong></span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/32fcee5da75280da57745b257168a107.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n0JlCu29lh4ZZPGKdMJYVA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="9fb2" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在让我们编写一个模块，将图像分成两个矩阵，这样两个矩阵的点积就可以重建原始图像</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="ebb7" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># imports<br/></em>import torch<br/>import random<br/>from torch.optim import Adam<strong class="mn ir">,</strong> SGD<br/>from torch import nn<br/>from torch.nn.functional import l1_loss<br/></span><span id="8442" class="na ke iq mn b gy nf nc l nd ne"><em class="mr"># target variable<br/></em>Y <strong class="mn ir">=</strong> torch<strong class="mn ir">.</strong>from_numpy<strong class="mn ir">(</strong>data<strong class="mn ir">)</strong><br/><em class="mr"># converting b/w data a [0,1] range<br/></em>Y <strong class="mn ir">=</strong> Y<strong class="mn ir">/</strong>255 <br/></span><span id="c787" class="na ke iq mn b gy nf nc l nd ne"><strong class="mn ir">class</strong> <strong class="mn ir">MF(</strong>nn<strong class="mn ir">.</strong>Module<strong class="mn ir">):</strong><br/>    <strong class="mn ir">def</strong> <strong class="mn ir">__init__(</strong><em class="mr">self</em><strong class="mn ir">,</strong> H<strong class="mn ir">,</strong> W<strong class="mn ir">,</strong> N<strong class="mn ir">):</strong><br/>        <em class="mr">super</em><strong class="mn ir">().</strong>__init__<strong class="mn ir">()</strong><br/>        <em class="mr"># Defining parameters A and B<br/></em>        <em class="mr">self</em><strong class="mn ir">.</strong>A <strong class="mn ir">=</strong> nn<strong class="mn ir">.</strong>Parameter<strong class="mn ir">(</strong>torch<strong class="mn ir">.</strong>rand<strong class="mn ir">(</strong>H<strong class="mn ir">,</strong> N<strong class="mn ir">))</strong><br/>        <em class="mr">self</em><strong class="mn ir">.</strong>B <strong class="mn ir">=</strong> nn<strong class="mn ir">.</strong>Parameter<strong class="mn ir">(</strong>torch<strong class="mn ir">.</strong>rand<strong class="mn ir">(</strong>N<strong class="mn ir">,</strong> W<strong class="mn ir">))</strong><br/>        torch<strong class="mn ir">.</strong>nn<strong class="mn ir">.</strong>init<strong class="mn ir">.</strong>xavier_uniform_<strong class="mn ir">(</strong><em class="mr">self</em><strong class="mn ir">.</strong>A<strong class="mn ir">)</strong><br/>        torch<strong class="mn ir">.</strong>nn<strong class="mn ir">.</strong>init<strong class="mn ir">.</strong>xavier_uniform_<strong class="mn ir">(</strong><em class="mr">self</em><strong class="mn ir">.</strong>B<strong class="mn ir">)</strong><br/>    <br/>    <strong class="mn ir">def</strong> <strong class="mn ir">forward(</strong><em class="mr">self</em><strong class="mn ir">,</strong> diff<strong class="mn ir">):</strong><br/>        <strong class="mn ir">if</strong> diff <strong class="mn ir">&gt;</strong> 0<strong class="mn ir">:</strong><br/>            <em class="mr"># slice matrices <br/></em>            A_i <strong class="mn ir">=</strong> <em class="mr">self</em><strong class="mn ir">.</strong>A<strong class="mn ir">[:,</strong> <strong class="mn ir">:-</strong>diff<strong class="mn ir">]</strong><br/>            B_i <strong class="mn ir">=</strong> <em class="mr">self</em><strong class="mn ir">.</strong>B<strong class="mn ir">[:-</strong>diff<strong class="mn ir">,</strong> <strong class="mn ir">:]</strong><br/>        <strong class="mn ir">else:</strong><br/>            A_i <strong class="mn ir">=</strong> <em class="mr">self</em><strong class="mn ir">.</strong>A<br/>            B_i <strong class="mn ir">=</strong> <em class="mr">self</em><strong class="mn ir">.</strong>B</span><span id="da45" class="na ke iq mn b gy nf nc l nd ne">        <em class="mr"># construct image from the matrices<br/></em>        y_hat <strong class="mn ir">=</strong> torch<strong class="mn ir">.</strong>sigmoid<strong class="mn ir">(</strong>A_i <strong class="mn ir">@</strong> B_i<strong class="mn ir">)</strong><br/>        <strong class="mn ir">return</strong> y_hat</span></pre><p id="bb45" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上面的模块非常简单。我们定义了形状为A(H，N)和B(N，W)的两个矩阵A和B，使得矩阵乘法给出形状为(H，W)的矩阵。</p><p id="71cf" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">此外，正向方法有助于训练矩阵，使得即使是它们的切片也能产生原始图像。</p><p id="c7d9" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在让我们看看所有神奇的事情发生的训练循环。</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="bf46" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># init the model and the optimizer</em></span><span id="23e0" class="na ke iq mn b gy nf nc l nd ne"><br/>D = 200<br/>mf <strong class="mn ir">=</strong> MF<strong class="mn ir">(</strong>H<strong class="mn ir">,</strong> W<strong class="mn ir">,</strong> D<strong class="mn ir">)</strong><br/>optimizer <strong class="mn ir">=</strong> Adam<strong class="mn ir">(</strong>mf<strong class="mn ir">.</strong>parameters<strong class="mn ir">(),</strong> lr<strong class="mn ir">=</strong>0.001<strong class="mn ir">)</strong></span><span id="a9c7" class="na ke iq mn b gy nf nc l nd ne"><em class="mr"># some variables<br/></em>running_loss <strong class="mn ir">=</strong> 0<br/>STEPS <strong class="mn ir">=</strong> 128 <strong class="mn ir">*</strong> 50<br/>LOG_STEPS <strong class="mn ir">=</strong> 32</span><span id="c0e1" class="na ke iq mn b gy nf nc l nd ne">losses <strong class="mn ir">=</strong> <strong class="mn ir">[]</strong><br/><em class="mr"># Training loop<br/></em><strong class="mn ir">for</strong> i <strong class="mn ir">in</strong> <em class="mr">range</em><strong class="mn ir">(</strong>STEPS<strong class="mn ir">):</strong><br/>    diff <strong class="mn ir">=</strong> random<strong class="mn ir">.</strong>randint<strong class="mn ir">(</strong>0<strong class="mn ir">,</strong> 100<strong class="mn ir">)</strong><br/>    y_hat <strong class="mn ir">=</strong> mf<strong class="mn ir">.</strong>forward<strong class="mn ir">(</strong>diff<strong class="mn ir">)</strong>    <br/>    <br/>    <em class="mr"># l1 + l2 loss<br/></em>    loss <strong class="mn ir">=</strong> torch<strong class="mn ir">.</strong><em class="mr">abs</em><strong class="mn ir">(</strong>Y <strong class="mn ir">-</strong> y_hat<strong class="mn ir">).</strong>mean<strong class="mn ir">()</strong> <strong class="mn ir">+</strong> <strong class="mn ir">(</strong>Y <strong class="mn ir">-</strong> y_hat<strong class="mn ir">).</strong>square<strong class="mn ir">().</strong><em class="mr">sum</em><strong class="mn ir">().</strong>sqrt<strong class="mn ir">()</strong><br/>    loss <strong class="mn ir">=</strong> loss<br/>    li <strong class="mn ir">=</strong> loss<strong class="mn ir">.</strong>item<strong class="mn ir">()</strong><br/>    running_loss <strong class="mn ir">=</strong> 0.9 <strong class="mn ir">*</strong> running_loss <strong class="mn ir">+</strong> 0.1 <strong class="mn ir">*</strong> li<br/>    <br/>    <em class="mr"># optimizer steps and parameter updates<br/></em>    loss<strong class="mn ir">.</strong>backward<strong class="mn ir">()</strong><br/>    optimizer<strong class="mn ir">.</strong>step<strong class="mn ir">()</strong><br/>    optimizer<strong class="mn ir">.</strong>zero_grad<strong class="mn ir">()</strong><br/>    <br/>    <strong class="mn ir">if</strong> i<strong class="mn ir">%</strong>LOG_STEPS <strong class="mn ir">==</strong> 0<strong class="mn ir">:</strong><br/>        <strong class="mn ir">print(</strong>running_loss<strong class="mn ir">)</strong></span></pre><p id="ee29" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">上面的循环随机选择一个数字传递给模型的forward方法，该方法在内部对矩阵进行切片并生成原始图像。</p><blockquote class="mo mp mq"><p id="4eb3" class="lb lc mr ld b le lz lg lh li ma lk ll ms mb lo lp mt mc ls lt mu md lw lx ly ij bi translated">它迫使矩阵A和B的参数如此，使得最初的几个切片具有更多信息，而后面的切片具有丰富图像的附加信息</p></blockquote><h1 id="1df9" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结果呢</h1><p id="d38e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">让我们首先定义一些效用函数，就像我们在开始时在伪代码中设想的那样</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="9e14" class="na ke iq mn b gy nb nc l nd ne"><strong class="mn ir">def</strong> <strong class="mn ir">get_buffer(</strong>mf<strong class="mn ir">,</strong> rnge<strong class="mn ir">=(</strong>0<strong class="mn ir">,</strong>20<strong class="mn ir">)):</strong><br/>    <em class="mr"># given the original parameters and a range, return the slices of matrices A and B<br/></em>    D = mf.A.shape[1]<br/>    l = int(rnge[0]/100 * D)<br/>    r = int(rnge[1]/100 * D)<br/>    A = mf.A[:, l: r]<br/>    B = mf.B[l: r, :]<br/>    <br/>    data <strong class="mn ir">=</strong> <strong class="mn ir">(</strong>A<strong class="mn ir">,</strong> B<strong class="mn ir">)</strong><br/>    <strong class="mn ir">return</strong> data</span><span id="d3d0" class="na ke iq mn b gy nf nc l nd ne"><strong class="mn ir">def</strong> <strong class="mn ir">add_buffers(</strong>buffers<strong class="mn ir">):</strong><br/>    <em class="mr"># concatenate the buffer slices<br/></em>    <strong class="mn ir">return</strong> <strong class="mn ir">(</strong>torch<strong class="mn ir">.</strong>cat<strong class="mn ir">([</strong>b<strong class="mn ir">[</strong>0<strong class="mn ir">]</strong> <strong class="mn ir">for</strong> b <strong class="mn ir">in</strong> buffers<strong class="mn ir">],</strong> dim<strong class="mn ir">=</strong>1<strong class="mn ir">),</strong> torch<strong class="mn ir">.</strong>cat<strong class="mn ir">([</strong>b<strong class="mn ir">[</strong>1<strong class="mn ir">]</strong> <strong class="mn ir">for</strong> b <strong class="mn ir">in</strong> buffers<strong class="mn ir">]))</strong></span><span id="8b6c" class="na ke iq mn b gy nf nc l nd ne"><strong class="mn ir">def</strong> <strong class="mn ir">display(</strong>data<strong class="mn ir">):</strong><br/>    <em class="mr"># construct image using the buffers<br/></em>    img <strong class="mn ir">=</strong> <strong class="mn ir">(</strong>torch<strong class="mn ir">.</strong>sigmoid<strong class="mn ir">(</strong>data<strong class="mn ir">[</strong>0<strong class="mn ir">]@</strong>data<strong class="mn ir">[</strong>1<strong class="mn ir">])*</strong>255<strong class="mn ir">).</strong>detach<strong class="mn ir">().</strong>numpy<strong class="mn ir">()</strong><br/>    <strong class="mn ir">return</strong> Image<strong class="mn ir">.</strong>fromarray<strong class="mn ir">(</strong>np<strong class="mn ir">.</strong>uint8<strong class="mn ir">(</strong>img<strong class="mn ir">))</strong></span></pre><p id="4366" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在，让我们从quality (0，20)获得一个缓冲区并显示它</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="db4b" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># display the first 20% quality<br/></em>buff_0_20 <strong class="mn ir">=</strong> get_buffer<strong class="mn ir">(</strong>mf<strong class="mn ir">)</strong><br/>display<strong class="mn ir">(</strong>buff_0_20<strong class="mn ir">)</strong></span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/c2cdfcb9ca595917d2064118183fb95b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f5L47S_K4-YDj_A7WjiO4g.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="f83a" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">很糟糕，但还是可以辨认的。现在让我们得到下一组数据来提高这张图像的质量。</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="3a1e" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># get additional 40% (20, 60) data and append it to the earlier buffer<br/></em>buff_20_60 <strong class="mn ir">=</strong> get_buffer<strong class="mn ir">(</strong>mf<strong class="mn ir">,</strong> <strong class="mn ir">(</strong>20<strong class="mn ir">,</strong> 60<strong class="mn ir">))</strong><br/>added_buffer_0_60 <strong class="mn ir">=</strong> add_buffers<strong class="mn ir">([</strong>buff_0_20<strong class="mn ir">,</strong> buff_20_60<strong class="mn ir">])</strong><br/>display<strong class="mn ir">(</strong>added_buffer_0_60<strong class="mn ir">)</strong></span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/3c561f1cd4250e46f6558b05126bd9bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YX-JrG9cUQnjQMiKHLR6Rg.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="132b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">现在好多了。让我们看看最终的图像，它具有我们所拥有的最好的质量。</p><pre class="mf mg mh mi gt mw mn mx my aw mz bi"><span id="4cb6" class="na ke iq mn b gy nb nc l nd ne"><em class="mr"># get the last 40% (60, 100) data and append it to the earlier buffer<br/></em>buff_60_100 <strong class="mn ir">=</strong> get_buffer<strong class="mn ir">(</strong>mf<strong class="mn ir">,</strong> <strong class="mn ir">(</strong>60<strong class="mn ir">,</strong> 100<strong class="mn ir">))</strong><br/>added_buffer_0_100 <strong class="mn ir">=</strong> add_buffers<strong class="mn ir">([</strong>added_buffer_0_60<strong class="mn ir">,</strong> buff_60_100<strong class="mn ir">])</strong><br/>display<strong class="mn ir">(</strong>added_buffer_0_100<strong class="mn ir">)</strong></span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/833363f948e6df839f725727f251e0b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7num-2SI8Zus07omLr1PeA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者形象</p></figure><p id="392b" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">这个图像看起来更接近我们的基础图像。</p><h1 id="1b8e" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="912b" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇文章中，我们探讨了动态视频质量在YouTube这样的网站上是如何工作的，以及前端和后端技术的结合是如何实现的。我们看到了缓冲区不是可加的，因此当用户要求运行视频的更高质量时，缓冲区会被完全丢弃。</p><p id="e992" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">我们使用矩阵分解的思想和定制的训练过程来制定加法方法，该训练过程为输入图像X构造两个矩阵A和B，使得</p><p id="7526" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">A[:，:N] ⋅ B[:N，:]≈X</p><p id="e1b1" class="pw-post-body-paragraph lb lc iq ld b le lz lg lh li ma lk ll lm mb lo lp lq mc ls lt lu md lw lx ly ij bi translated">使得较大的N给出图像X的更好的近似</p><h1 id="13f7" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h1><ul class=""><li id="565d" class="nj nk iq ld b le lf li lj lm nl lq nm lu nn ly no np nq nr bi translated"><a class="ae kc" href="https://medium.com/canal-tech/how-video-streaming-works-on-the-web-an-introduction-7919739f7e1" rel="noopener">视频流如何在网络上工作:简介</a></li><li id="9298" class="nj nk iq ld b le ns li nt lm nu lq nv lu nw ly no np nq nr bi translated">【YouTube使用了多少数据？</li><li id="2232" class="nj nk iq ld b le ns li nt lm nu lq nv lu nw ly no np nq nr bi translated"><a class="ae kc" href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API" rel="noopener ugc nofollow" target="_blank">媒体源API </a></li><li id="d302" class="nj nk iq ld b le ns li nt lm nu lq nv lu nw ly no np nq nr bi translated">【JPEG是如何工作的</li></ul></div></div>    
</body>
</html>