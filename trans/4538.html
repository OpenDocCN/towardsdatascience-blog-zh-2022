<html>
<head>
<title>How to Run Stable Diffusion in Docker with a Simple Web API and GPU Support</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用简单的Web API和GPU支持在Docker中运行稳定的扩散</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/launch-a-web-api-for-stable-diffusion-under-45-seconds-bbd88cfe41d8#2022-10-08">https://towardsdatascience.com/launch-a-web-api-for-stable-diffusion-under-45-seconds-bbd88cfe41d8#2022-10-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2f2f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">启动web API，在45秒内实现稳定传播</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/dd2ecb424fa8ec55a67b574526c7fc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*o2w4ls_r-vo6UqedOsj65Q.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">稳定扩散产生的虚构黑山羊</p></figure><p id="97df" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ln" href="https://github.com/CompVis/stable-diffusion" rel="noopener ugc nofollow" target="_blank">Stability Diffusion</a>是一种潜在的文本到图像扩散模型，这要归功于Stability AI和Runway的合作。它具有最先进的文本到图像合成功能，内存需求相对较小(10 GB)。稳定扩散对其他扩散模型进行了一些改进，以实现这种效率，但这些创新超出了本文的范围，未来的文章将介绍如何在TensorFlow中训练扩散模型，并从技术上详细说明其内部工作原理。</p><p id="be19" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Divam Gupta <a class="ae ln" href="https://github.com/divamgupta/stable-diffusion-tensorflow" rel="noopener ugc nofollow" target="_blank">将稳定扩散从原始权重移植到TensorFlow / Keras </a>，这篇文章重点介绍如何使用简单的web API和GPU支持在Docker映像中运行它。</p><p id="0f32" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">趣闻</strong>:本帖的特色形象也是稳定扩散产生的。</p><h2 id="e802" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">它是如何工作的？</h2><p id="2c08" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我决定在TensorDock Marketplace的GPU上运行它。，它应该可以在其他机器上工作，几乎不需要做任何改变，但这是我最近推出的TensorDock Marketplace的实验的直接结果。它目前处于公开测试阶段，但我已经喜欢上了他们的创新理念，让高性能计算的使用大众化。除了他们的<a class="ae ln" href="https://www.tensordock.com/" rel="noopener ugc nofollow" target="_blank">价格合理的核心云GPU服务</a>之外，Marketplace edition还作为一个市场，将客户和GPU提供商聚集在一起。主机，即那些有备用GPU的主机，可以将它们租给客户，包括独立研究人员、初创公司、业余爱好者、修补匠等。价格极其便宜。<a class="ae ln" href="https://www.tensordock.com/host" rel="noopener ugc nofollow" target="_blank">根据TensorDock </a>的说法，这也让主机赚取2到3倍的采矿利润。为了比挖掘无意义的密码更好的目的。</p><p id="7d21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">服务器可根据所需的RAM、vCPU和分配的磁盘进行定制，启动时间太短，大约只有45秒。您可以选择从安装了NVIDIA驱动程序和Docker的最小Ubuntu映像开始，或者您也可以使用配置了NVIDIA驱动程序、Conda、TensorFlow、PyTorch和Jupyter的成熟映像进行实验。我选择使用Docker而不是Conda或虚拟环境来隔离我的人工智能项目，我将从安装在TensorDock Marketplace上的Docker的最小图像开始。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="7800" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我将展示如何将web API封装成Docker映像中的稳定分发服务。然后，我将一步一步地描述如何在TensorDock GPU上提供它。如果你想在45秒内启动并运行，你可以直接跳到“Ok，演示给我看如何运行”部分，或者你可以选择查看<a class="ae ln" href="https://github.com/monatis/stable-diffusion-tf-docker" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>。</p><h2 id="bfd2" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">让我们来整理一下！</h2><p id="e5ec" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">TensorFlow为每个版本提供官方<a class="ae ln" href="https://www.tensorflow.org/install/docker" rel="noopener ugc nofollow" target="_blank">预建的Docker图像</a>来启动您的Docker文件。如果您配置了<a class="ae ln" href="https://developer.nvidia.com/nvidia-container-runtime" rel="noopener ugc nofollow" target="_blank"> NVIDIA Container Runtime </a>并且更喜欢TensorFlow提供的支持GPU的Docker映像，您可以在GPU支持下立即运行TensorFlow代码，而不会遇到CUDA或CUDNN的问题。幸运的是，TensorDock的最小Ubuntu图像带有NVIDIAContainerRuntime支持。</p><p id="6aa4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了稳定的扩散，我们以<code class="fe mt mu mv mw b">tensorflow/tensorflow:2.10.0-gpu</code>开始我们的Dockerfile。然后我们安装稳定的扩散需求和FastAPI来服务一个web API。最后，我们复制包含web API的<code class="fe mt mu mv mw b">app.py</code>,并将其配置为在容器启动时运行:</p><pre class="kg kh ki kj gt mx mw my mz aw na bi"><span id="12bd" class="lo lp iq mw b gy nb nc l nd ne">from tensorflow/tensorflow:2.10.0-gpu<br/><br/>RUN apt update &amp;&amp; \<br/>    apt install -y git &amp;&amp; \<br/>    pip install --no-cache-dir Pillow==9.2.0 tqdm==4.64.1 \<br/>    ftfy==6.1.1 regex==2022.9.13 tensorflow-addons==0.17.1 \<br/>    fastapi "uvicorn[standard]" git+https://github.com/divamgupta/stable-diffusion-tensorflow.git<br/><br/>WORKDIR /app<br/><br/>COPY ./app.py /app/app.py<br/><br/>CMD uvicorn --host 0.0.0.0 app:app</span></pre><h2 id="06ef" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">撰写以便于配置和启动</h2><p id="e5fc" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">当你有一个<code class="fe mt mu mv mw b">docker-compose.yml</code>文件时，Docker就更有用了。因此，您可以简单地运行<code class="fe mt mu mv mw b">docker compose up</code>，用一个命令就可以启动并运行一切。它在处理多个容器时尤其出色，但对于管理单个容器也非常有用。</p><p id="126a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面的<code class="fe mt mu mv mw b">docker-compose.yml</code>文件定义了几个环境变量，并将它们传递给容器。它还支持容器内部的GPU访问，并根据TensorDock Marketplace的要求正确配置Docker网络。在其他平台上，您可能需要删除有关网络的这一部分</p><pre class="kg kh ki kj gt mx mw my mz aw na bi"><span id="49c0" class="lo lp iq mw b gy nb nc l nd ne">version: "3.3"<br/><br/>services:<br/>  app:<br/>    image: myusufs/stable-diffusion-tf<br/>    build:<br/>      context: .<br/>    environment:<br/>      # configure env vars to your liking<br/>      - HEIGHT=512<br/>      - WIDTH=512<br/>      - MIXED_PRECISION=no<br/>    ports:<br/>      - "${PUBLIC_PORT?Public port not set as an environment variable}:8000"<br/>    volumes:<br/>      - ./data:/app/data<br/><br/>    deploy:<br/>      resources:<br/>        reservations:<br/>          devices:<br/>            - driver: nvidia<br/>              count: 1<br/>              capabilities: [ gpu ]<br/><br/>networks:<br/>  default:<br/>    driver: bridge<br/>    driver_opts:<br/>      com.docker.network.driver.mtu: 1442</span></pre><h2 id="8718" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">编码时间到了</h2><p id="e7e1" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">现在我们已经准备好编写我们的webAPI了。我们从所需的导入开始，然后用由<code class="fe mt mu mv mw b">docker-compose.yml</code>传递的环境变量创建一个图像生成器和FastAPI应用程序。</p><pre class="kg kh ki kj gt mx mw my mz aw na bi"><span id="6bf4" class="lo lp iq mw b gy nb nc l nd ne">import os<br/>import time<br/>import uuid<br/><br/>from fastapi import FastAPI<br/>from fastapi.exceptions import HTTPException<br/>from fastapi.responses import FileResponse<br/>from PIL import Image<br/>from pydantic import BaseModel, Field<br/>from stable_diffusion_tf.stable_diffusion import Text2Image<br/>from tensorflow import keras<br/><br/>height = int(os.environ.get("WIDTH", 512))<br/>width = int(os.environ.get("WIDTH", 512))<br/>mixed_precision = os.environ.get("MIXED_PRECISION", "no") == "yes"<br/><br/>if mixed_precision:<br/>    keras.mixed_precision.set_global_policy("mixed_float16")<br/><br/>generator = Text2Image(img_height=height, img_width=width, jit_compile=False)<br/><br/>app = FastAPI(title="Stable Diffusion API")</span></pre><p id="fdcf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，我们为我们的<code class="fe mt mu mv mw b">/generate</code>端点定义请求和响应主体。值是不言自明的，所以这里不需要额外的文字。</p><pre class="kg kh ki kj gt mx mw my mz aw na bi"><span id="d70a" class="lo lp iq mw b gy nb nc l nd ne">class GenerationRequest(BaseModel):<br/>    prompt: str = Field(..., title="Input prompt", description="Input prompt to be rendered")<br/>    scale: float = Field(default=7.5, title="Scale", description="Unconditional guidance scale: eps = eps(x, empty) + scale * (eps(x, cond) - eps(x, empty))")<br/>    steps: int = Field(default=50, title="Steps", description="Number of dim sampling steps")<br/>    seed: int = Field(default=None, title="Seed", description="Optionally specify a seed for reproduceable results")<br/><br/><br/>class GenerationResult(BaseModel):<br/>    download_id: str = Field(..., title="Download ID", description="Identifier to download the generated image")<br/>    time: float = Field(..., title="Time", description="Total duration of generating this image")</span></pre><p id="0115" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，是时候写我们的端点了。<code class="fe mt mu mv mw b">/generate</code>端点将接受一个文本提示以及几个配置值来控制生成，并且它将用生成的图像的惟一ID来响应。然后，可以通过<code class="fe mt mu mv mw b">/download</code>端点下载图像。生成的图像保存在<code class="fe mt mu mv mw b">docker-compose.yml</code>中配置为Docker卷的目录中。</p><pre class="kg kh ki kj gt mx mw my mz aw na bi"><span id="ec20" class="lo lp iq mw b gy nb nc l nd ne">@app.post("/generate", response_model=GenerationResult)<br/>def generate(req: GenerationRequest):<br/>    start = time.time()<br/>    id = str(uuid.uuid4())<br/>    img = generator.generate(req.prompt, num_steps=req.steps, unconditional_guidance_scale=req.scale, temperature=1, batch_size=1, seed=req.seed)<br/>    path = os.path.join("/app/data", f"{id}.png")<br/>    Image.fromarray(img[0]).save(path)<br/>    alapsed = time.time() - start<br/>    <br/>    return GenerationResult(download_id=id, time=alapsed)<br/><br/>@app.get("/download/{id}", responses={200: {"description": "Image with provided ID", "content": {"image/png" : {"example": "No example available."}}}, 404: {"description": "Image not found"}})<br/>async def download(id: str):<br/>    path = os.path.join("/app/data", f"{id}.png")<br/>    if os.path.exists(path):<br/>        return FileResponse(path, media_type="image/png", filename=path.split(os.path.sep)[-1])<br/>    else:<br/>        raise HTTPException(404, detail="No such file")</span></pre><h2 id="94cc" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">好的，告诉我怎么跑</h2><p id="4e63" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">不要让这些步骤吓到你——这只是从注册到提出请求的整个过程的一步一步的详细介绍。应该不会超过10分钟。</p><ol class=""><li id="3457" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated"><a class="ae ln" href="https://marketplace.tensordock.com/register" rel="noopener ugc nofollow" target="_blank">注册</a>并登录TensorDock市场。</li><li id="ecba" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated"><a class="ae ln" href="https://marketplace.tensordock.com/order_list" rel="noopener ugc nofollow" target="_blank">转到订单页面</a>，选择一台提供至少10 GB内存的GPU的物理机。我建议买一个提供RTX 3090的。</li><li id="2a45" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">这将打开一个允许您配置服务器的模型。我的建议如下:</li></ol><ul class=""><li id="cc3a" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nt nl nm nn bi translated">选择每个GPU型号的数量:1个GeForce RTX 3090 24 GB</li><li id="fc4a" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated">选择内存容量(GB): 16</li><li id="af89" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated">选择虚拟CPU的数量:2</li><li id="1f92" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated">选中复选框，最多可转发15个端口。您将能够通过这些端口访问您的服务器。</li><li id="4ef9" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated">在“自定义您的安装”下，选择“Ubuntu 20.04 LTS”。</li></ul><ol class=""><li id="2591" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">为您的服务器选择一个密码，并为其命名，例如“stable-diffusion-api”</li><li id="a35e" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">点击“部署服务器”,瞧！你的服务器将在几秒钟内准备好。</li><li id="3dc3" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">当您看到成功页面时，请单击“下一步”查看详细信息。</li><li id="03b9" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">查找您的服务器的IPv4地址。这可能是真实的IP，也可能是类似<code class="fe mt mu mv mw b">mass-a.tensordockmarketplace.com</code>的子域。</li><li id="3ba8" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">找到映射到内部端口22的外部端口。您将使用它SSH到您的服务器。例如，可能是20029年。</li><li id="0816" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">使用以下标准连接到您的服务器，例如:</li></ol><ul class=""><li id="e549" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">ssh -p 20029 user@mass-a@tensordockmarketplace.com</code></li></ul><p id="4e46" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Docker已经配置了GPU访问，但是我们需要配置Docker网络来进行外部请求。</p><ol class=""><li id="a446" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">将此存储库和cd克隆到其中:</li></ol><ul class=""><li id="51b2" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">git clone https://github.com/monatis/stable-diffusion-tf-docker.git &amp;&amp; cd stable-diffusion-tf-docker</code></li></ul><ol class=""><li id="c459" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">将<code class="fe mt mu mv mw b">daemon.json</code>复制到现有的<code class="fe mt mu mv mw b">/etc/docker/daemon.json</code>上，并重启服务。不要担心——这只是为MTU值添加了一个设置。</li></ol><ul class=""><li id="b1a7" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">sudo cp ./daemon.json /etc/docker/daemon.json</code></li><li id="0906" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">sudo systemctl restart docker.service</code></li></ul><ol class=""><li id="d036" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">为您想要使用的公共端口设置一个环境变量，运行Docker Compose。我们的<code class="fe mt mu mv mw b">docker-compose.yml</code>文件将从环境变量中提取它，它应该是您配置的端口转发之一，例如20020。</li></ol><ul class=""><li id="58e4" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">export PUBLIC_PORT=20020</code></li><li id="91db" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nt nl nm nn bi translated"><code class="fe mt mu mv mw b">docker compose up -d</code></li></ul><ol class=""><li id="126b" class="nf ng iq kt b ku kv kx ky la nh le ni li nj lm nk nl nm nn bi translated">一旦它启动并运行，进入<code class="fe mt mu mv mw b">http://mass-a.tensordockmarketplace.com:20020/docs</code>获取FastAPI提供的Swagger UI。</li><li id="83a6" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">使用<code class="fe mt mu mv mw b">POST /generate</code>端点生成扩散稳定的图像。它会用一个下载ID来响应。</li><li id="a2ba" class="nf ng iq kt b ku no kx np la nq le nr li ns lm nk nl nm nn bi translated">点击<code class="fe mt mu mv mw b">GET /download/&lt;download_id&gt;</code>端点下载您的图像。</li></ol><h2 id="6eff" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">结论</h2><p id="ea88" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我们能够在TensorDock Marketplace的云GPU上运行稳定扩散，这是最先进的tex-to-image模型之一。它非常便宜，因此适合实验和副业。我将继续在我的一个副业项目中使用它，后续的帖子将提供TensorDock Marketplace上培训工作的一步一步的介绍。</p></div></div>    
</body>
</html>