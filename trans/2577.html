<html>
<head>
<title>Session-Based Recommender Systems with Word2Vec</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于会话的Word2Vec推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/session-based-recommender-systems-with-word2vec-666afb775509#2022-06-04">https://towardsdatascience.com/session-based-recommender-systems-with-word2vec-666afb775509#2022-06-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c4e2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何用Python在浏览器会话数据上用Word2Vec训练一个基本的推荐系统？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/be348ed520b4d053aaa9e0c6d1e8b9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qjuZnAsQiGFIuE_-X-wGPQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com/photos/SYTO3xs06fU" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>。</p></figure><p id="4571" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你熟悉<strong class="lb iu"> Word2Vec </strong>算法，那么很可能是因为你在<strong class="lb iu">自然语言处理</strong> (NLP)领域的某个地方偶然发现了它。自2013年首次发表以来，T. Mikolov等人的论文<a class="ae ky" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">越来越受欢迎，并在各种NLP应用中展示了最先进的结果。从那以后，出现了各种更新的、性能更好的模型——但是，当使用NLP或在信息检索(IR)领域工作时，Word2Vec是不可避免的。</a></p><p id="b354" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了它在NLP中的经典应用之外，我们还可以将底层的Word2Vec算法用于其他应用，比如某些类型的推荐系统问题。</p><p id="9abb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将了解如何利用<strong class="lb iu"> Word2Vec的CBOW算法</strong>为基于会话的数据构建一个简单的<strong class="lb iu">推荐系统。</strong></p><p id="35bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">首先</strong>，我们将讨论使用Word2Vec算法解决此类问题背后的动机是什么，其次<strong class="lb iu"/>，<strong class="lb iu"> </strong>我们将看看如何在实践中使用Python 3实现这一点。</p><h1 id="534b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">1 |为什么要用Word2Vec？</h1><p id="effa" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于本文，我假设您非常熟悉Word2Vec模型及其底层架构(CBOW和SkipGram)的工作方式。如果你不熟悉这些，我强烈推荐你看看这篇文章，它很好地解释了这些概念。</p><p id="3fb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在本文中重点介绍的特定类型的推荐系统是所谓的<em class="ms">基于会话的</em>。在这种情况下，我们希望根据匿名用户当前的浏览器会话，向他们提供下次点击推荐。<strong class="lb iu">什么意思？</strong></p><p id="6e68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们考虑一个销售不同类别的各种产品的电子商务网站。有一天，用户可能会来到我们的网站，浏览我们的产品目录。我们的目标显然是让用户将产品添加到购物车中，并最终购买它。在推荐系统的帮助下，我们的目标是向用户推荐“相关”的产品。这增强了用户的购物体验，但也增加了购买的可能性。</p><p id="8456" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，如果我们的用户对我们来说是匿名的，我们没有关于他们的任何历史数据，例如关于他们以前的购买或关于他们以前的浏览器会话。这使得给出“相关建议”变得越来越复杂。</p><p id="3aa1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是Word2Vec发挥作用的地方。</p><p id="7633" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总结一下:Word2Vec是一个模型，当训练有素时，它能够根据上下文捕捉单词的含义。</p><p id="98cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在考虑我们上面的例子，我们可能有以下匿名用户的历史会话数据:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="379c" class="my lw it mu b gy mz na l nb nc">session_1 = [1, 2, 5]</span></pre><p id="7360" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在当前会话中，用户查看了产品编号1、2和5。如果我们有足够多的这种类型的会话数据，我们可以在Word2Vec模型中使用它们作为输入向量，特别是使用CBOW算法。这样，我们的模型将能够赋予我们的项目“意义”，从而确定它们最有可能适合哪个上下文(即会话)。</p><blockquote class="nd"><p id="4c03" class="ne nf it bd ng nh ni nj nk nl nm lu dk translated">对于我们的用例，我们可以将“单词”翻译成“产品”，将“上下文”翻译成“会话”。</p></blockquote><p id="1615" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">你可能会说，不使用Word2Vec，我们也可以只向用户推荐来自同一类别的产品。事实上，这可能是一种选择。然而，由于类别可以是相当高的级别，并且产品仍然可以在类别中有所不同，因此产生的推荐可能变得与我们的用户不那么“相关”。</p><p id="357c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们已经研究了理论，并且理解了Word2Vec在这个用例中可以为我们做什么，那么让我们实际上开始实现我们的想法，看看结果是什么样的。</p><h1 id="e621" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">2 |用Python实现</h1><p id="c6f9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">对于我们的用例，我们将使用一个Kaggle数据集，其中包含来自多类别商店的电子商务数据(来源:【Kaggle.com】T2和<a class="ae ky" href="https://rees46.com/" rel="noopener ugc nofollow" target="_blank"> REES46营销平台</a>)。数据集的大小相当大，因此，出于简化和演示的目的，我将使用2019年10月的原始数据集的子集。</p><h2 id="e07f" class="my lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">数据探索</h2><p id="e56a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在我们进入任何处理步骤之前，让我们先来看看我们的数据:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/e88fff5cf433fe7989cc19b01d19c9a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P-5KqieYdEzydtZRycd-Ew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2019年10月电商数据(数据集来源:<a class="ae ky" href="https://www.kaggle.com/datasets/mkechinov/ecommerce-behavior-data-from-multi-category-store?select=2019-Oct.csv" rel="noopener ugc nofollow" target="_blank">Kaggle.com</a>和<a class="ae ky" href="https://rees46.com/" rel="noopener ugc nofollow" target="_blank"> REES46营销</a>)。图片作者。</p></figure><p id="521e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们观察了各种各样的特性，但是对于我们的用例来说，只有几个特性是有趣的:<em class="ms"> event_type </em>、<em class="ms"> product_id </em>、<em class="ms"> category_code </em>和<em class="ms"> user_session </em>。在这个数据集中，我们也有关于我们的用户的数据，因为我们有<em class="ms"> user_id </em>值。尽管如此，我们不会使用它们，因为这个例子的目的是展示我们如何基于<strong class="lb iu">匿名</strong>用户会话数据来实现郑重推荐。</p><p id="7636" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms"> event_type </em>变量描述了会话中发生的事件类型。这可以是“查看”、“购物车”或“已购买”。我们将使用包含<em class="ms">product _ id’</em>的每个会话的向量作为Word2Vec模型的输入。稍后，使用来自我们的<em class="ms"> category_code </em>变量的数据，我们将能够测试我们的模型的预测结果。</p><h2 id="8e3f" class="my lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">数据预处理</h2><p id="76a9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在将数据输入Word2Vec模型之前，我们首先需要执行一些处理步骤。为此，我们将使用熊猫库。</p><p id="72ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们的数据可能包含需要删除的缺失值。其次，我们只需要保留数据中的特定列，因为我们的用例不需要所有的列。这两个步骤在下面的代码中完成:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="3822" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，出于演示的目的，我将只使用原始数据的一个子集。如下面的代码所示，为了创建数据的子集，我们将首先按照<em class="ms"> user_session </em>对数据进行排序。这是为了确保我们将每个会话的所有数据分组在一起。然后我们选择指数2'000'000作为我们的分裂点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="49ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了确保我们的数据不会在会话中间被拆分，只要我们数据中的下一行仍然是同一先前会话的一部分，我们就将拆分索引<em class="ms"> split_at </em>增加1。最后，我们执行从第一行到找到的拆分索引的实际拆分。在我们的例子中，数据集在行索引2'000'006处被拆分。我们的子集现在包含总共483，508个唯一浏览会话数据。</p><h2 id="c0ba" class="my lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">构建W2V推荐系统</h2><p id="0722" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在我们的数据已经被清理和处理了，我们终于可以继续构建我们实际的基于Word2Vec的推荐系统了。我们将使用<strong class="lb iu"> Gensim </strong>库，它有Word2Vec算法的实际实现，正如在原始论文中发表的。</p><p id="35e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了用Gensim训练我们自己的Word2Vec模型，我们首先需要将我们的数据变成正确的形状，以便库可以在其上进行实际训练。它将一个向量列表作为输入，因此我们将使用下面的<em class="ms"> create_w2v_data </em>辅助函数来转换我们的数据:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="8fd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该函数将Pandas数据帧作为输入，并输出数据集中每个会话的列表<strong class="lb iu">，而<strong class="lb iu">是在该会话</strong>中查看、放入购物车和/或购买的所有产品的列表。运行可能需要几分钟时间，但结果数据如下所示:</strong></p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8241" class="my lw it mu b gy mz na l nb nc">[['2501061'],<br/> ['2701673', '2701773'],<br/> ['2900802', '2900090', '2900802', '2900803'],<br/> ['1004573'],<br/> ['1004792'],<br/>  ...<br/>]</span></pre><p id="afc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为我们在数据中组合了所有三种事件类型(view、cart、purchased ),所以一个购买的产品将在同一个会话中出现三次。这很好:它让<strong class="lb iu">与实际购买的产品有了额外的关联</strong>，因为它们通常会更频繁地出现在数据集中。</p><p id="1a4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们会话的平均长度为4.14，最长的会话包含324个已查看、放入购物车和/或已购买的产品。</p><h1 id="4092" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">训练模型</h1><p id="ec93" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">最后我们可以开始我们模型的实际训练了！🎉</p><p id="9543" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在Gensim库的帮助下，这可以通过几行代码完成:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="8bb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用准备好的会话列表作为输入数据建立了一个模型，并设置了模型参数。我们将<em class="ms"> min_count </em>设置为3，因为这将确保我们的模型只针对在整个数据集中出现至少3次的产品进行训练——换句话说:该产品必须被查看过至少3次，或者被查看过两次并放入购物车一次，或者被购买过至少一次。我们还使用了一个<em class="ms"> window_size </em>，它对应于我们数据集中最长的会话。为什么？以便我们考虑在会话中查看的所有产品。我们保留Gensim库中建议的其余参数。</p><p id="b565" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">万岁，我们已经训练好了我们的模型！接下来:让我们看看它能为我们做什么。</p><h1 id="639b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3 |测试和可视化</h1><p id="f7d7" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">训练一个模型很好，但是看到它的结果更好。</p><h2 id="f811" class="my lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">测试</h2><p id="8fc3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">让我们看看我们的模型给出的建议。假设用户查看了保存在<em class="ms"> product_id </em> 4802936下的特定类型的耳机。我们模型推荐的产品可以用Gensim函数<em class="ms"> predict_output_word </em>检索。前10条建议的结果如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/166c8d8bca055e68f65f1463fed6f6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E7whr2YozSTVciPLdLWGAQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">产品ID 4802936的建议(音频耳机)。图片作者。</p></figure><p id="3399" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，我们可以看到，我们的模型成功地正确理解了这些产品属于相似的类别，并且这些<em class="ms"> product_id </em>之间有相似之处。因此，如果用户查看id为4802936的耳机，模型将推荐其他替代耳机。</p><p id="c60a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以对product_id 42300039进行同样的操作，它是属于“客厅”类别的“橱柜”:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/58f8dffba319d57a219120083f39426b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ATezd6qkmrlKVsDlBBd4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">产品ID 42300039的建议(客厅橱柜)。图片作者。</p></figure><p id="6486" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们看到我们的模型设法推荐相关的项目。</p><h2 id="46ac" class="my lw it bd lx ns nt dn mb nu nv dp mf li nw nx mh lm ny nz mj lq oa ob ml oc bi translated">肉眼观察</h2><p id="816a" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我们还可以通过绘图来查看我们的数据，因为这可能会让我们对模型有更好的整体理解。我们将把模型中嵌入向量的维数减少到2，这将允许我们很好地绘制数据。为此，我们可以利用来自<strong class="lb iu"> umap-learn </strong>库中的<em class="ms"> umap </em>降维工具。</p><p id="3d04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该图将包含二维乘积嵌入向量，这些向量将按其各自的类别进行着色。为了简单起见，我们将只根据它们的主要类别对它们进行分组，即类别名称中列出的第一个类别。结果图如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/539c80c4b34bf5d437ac06ae6b1c8725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sj2c3DQfftrIwLrS5AJEVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">W2C推荐系统模型捕获的按类别划分的产品图。图片作者。</p></figure><p id="02a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在上面的图中看到非常好的结果！这表明，我们的模型确实能够很好地按类别对产品进行分组。</p><h1 id="b7db" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">4 |总结和结论</h1><p id="5c0b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">总的来说，我们在本文中展示了，借助Word2Vec CBOW算法，可以快速、轻松地为基于匿名会话的数据构建一个相当好的推荐系统。</p><p id="165e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于未来的工作，该模型可以通过各种其他方式进行微调和测试。例如，我们可以通过调整<em class="ms">窗口</em>的大小，以及<em class="ms"> min_count </em>参数来改变模型的训练输入参数，并查看最终的推荐结果。</p><p id="f981" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这对你有所帮助，并且你学到了一些新的东西。请随意评论您可能有的任何反馈或问题！🎉</p></div><div class="ab cl oj ok hx ol" role="separator"><span class="om bw bk on oo op"/><span class="om bw bk on oo op"/><span class="om bw bk on oo"/></div><div class="im in io ip iq"><h1 id="94ac" class="lv lw it bd lx ly oq ma mb mc or me mf jz os ka mh kc ot kd mj kf ou kg ml mm bi translated">参考资料:</h1><p id="c708" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">[1] T. Mikolov等人，<a class="ae ky" href="https://arxiv.org/abs/1301.3781" rel="noopener ugc nofollow" target="_blank">向量空间中单词表示的有效估计</a> (2013)</p><p id="23db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] R. Rehurek，<a class="ae ky" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank">Gensim models . word 2 vec</a>(2022)</p><p id="fd44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] T. Mikolov等人，<a class="ae ky" href="https://arxiv.org/abs/1310.4546" rel="noopener ugc nofollow" target="_blank">单词和短语的分布式表示<br/>及其组合性</a> (2013)</p></div></div>    
</body>
</html>