<html>
<head>
<title>JAX vs PyTorch: Automatic Differentiation for XGBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">JAX vs py torch:XGBoost的自动微分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/jax-vs-pytorch-automatic-differentiation-for-xgboost-10222e1404ec#2022-05-14">https://towardsdatascience.com/jax-vs-pytorch-automatic-differentiation-for-xgboost-10222e1404ec#2022-05-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5780" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">执行快速损失函数原型，以充分利用XGBoost的灵活性</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5f135c7ea2662ba5c6e776bd858d388f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A-vJCtK_c1fdhAzI"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马特·阿特兹在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="3cb2" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">动机</h2><p id="2a35" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在某些应用中，使用<strong class="lu ir">自定义损失函数运行XGBoost可以大大提高</strong>分类/回归<strong class="lu ir">性能</strong>。在时间紧迫的研究环境中，能够快速测试许多不同的损失函数是关键。因此，<em class="ml">手动微分</em>并不总是可行的(有时甚至容易出现人为错误，或数值不稳定)。</p><p id="86e5" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated"><em class="ml">自动微分</em>允许我们自动得到一个函数的导数，给定它的计算。它通过将我们的函数表示为具有已知导数的函数的组合来实现这一点，不需要开发人员付出任何努力。</p><p id="da38" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">我们将从一个简短的介绍开始，澄清我们的问题。然后，我们将深入研究用PyTorch和JAX实现自动微分，并将其与XGBoost集成。最后，我们将执行运行时基准测试，并展示对于此应用，<strong class="lu ir"> JAX比PyTorch </strong>快大约10倍。</p><h2 id="c1ea" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">背景</h2><p id="d175" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">梯度推进是机器学习算法的框架。它基于弱学习器的集合(通常是决策树)输出预测。弱学习器可以根据任意的可微分损失函数进行优化，这给了我们很大的灵活性。我们将把重点放在决策树作为弱学习器的情况上——梯度增强决策树(GBDT)。</p><p id="03df" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">在神经网络缺乏的任务中，例如，表格数据和小训练集，GBDTs表现出最先进的性能。</p><p id="93f4" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">XGBoost是一个有效实现GBDT的流行库。它提供了一个简单的<a class="ae kv" href="https://xgboost.readthedocs.io/en/stable/tutorials/custom_metric_obj.html" rel="noopener ugc nofollow" target="_blank">接口</a>，用于为我们的决策树编写定制的损失函数。给定一个定制的损失函数，我们所要做的就是向XGBoost提供其梯度和Hessian的计算结果。让我们看看如何在几分钟内实现自动微分。</p><h2 id="a7ff" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">问题设置</h2><p id="5c48" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们将在<a class="ae kv" href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset" rel="noopener ugc nofollow" target="_blank">加州住房数据集</a>上运行我们的实验，这是一个预测房价的回归任务。</p><p id="b16d" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">我们的损失函数将是对数误差的平方(SLE):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/08eccd868f986383c765eb1e245933f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sCTEDe1H7ee8gfX0.png"/></div></div></figure><p id="5e61" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">请注意，这种损失对预测不足估计的影响大于预测过高估计。在预测房价时，它可以反映真实的业务需求，我们可以通过选择自定义损失函数来实现。</p><p id="4c3b" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">让我们将其应用于XGBoost。</p><h2 id="72b7" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">用PyTorch自动计算黑森数</h2><p id="1e01" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在下文中，我们将重点关注与PyTorch的合作，因为这一点很清楚——稍后将与JAX进行比较。</p><p id="8fba" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">使用PyTorch计算梯度是神经网络编程中常见的工作。然而，我们很少需要计算赫斯安数。谢天谢地，PyTorch为我们实现了一个方便的功能<code class="fe ms mt mu mv b"><a class="ae kv" href="https://pytorch.org/docs/stable/generated/torch.autograd.functional.hessian.html" rel="noopener ugc nofollow" target="_blank">torch.autograd.functional.hessian</a></code>。在涵盖了这些技术细节后，我们可以开始实施了。</p><p id="9110" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">首先，我们实现了我们的损失函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="7b7a" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">接下来，我们的自动微分:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0da4" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">将它们放在一起:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/87c9b441d0c9172936810bbffdd31f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ay9wli4nl5_Srk-dD_5OCQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图1:</strong>PyTorch-实体模型数据自动区分演示。</p></figure><p id="59c3" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">运行在真实世界的数据上:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/2d66d630b6ad34d20c6009e362c1c589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPay1Ccyk5539gWPnqbBHA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图2: </strong>加载列车数据并显示汇总。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/705cb6b2997c616c8bbb20b50a3b7d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5qEhfmM55C4q9gC93seVg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图3: </strong> PyTorch —对现实世界数据进行自动区分的运行时性能(图2中加载)。</p></figure><p id="87e3" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">这给了我们一个使用PyTorch自动区分的简单工作实现。然而，该代码不能很好地扩展到大型数据集。因此，在下一节中，我们将展示一种更复杂的方法来改进我们的运行时。</p><h2 id="c283" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">使用JAX优化运行时性能</h2><p id="53a0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">如果我们正确使用JAX，我们可以实现相当大的运行时加速。让我们在JAX从上面写下PyTorch代码:</p><p id="e466" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">我们将损失计算变更为使用<code class="fe ms mt mu mv b">jax.numpy</code>(进口为<code class="fe ms mt mu mv b">jnp</code>),</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="f034" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">并在JAX使用相应的语法进行自动区分，</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="739a" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">根据前面的数据，与PyTorch实现(图3)相比，我们看到了约2倍的加速:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/2f4bc167354fb1e8b7a901c7b8b02254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHt72FgekbCq1jmHf1KCjQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图4: </strong> JAX —对现实世界数据进行自动区分的运行时性能。</p></figure><p id="9508" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">请注意，我们使用<a class="ae kv" href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#hessian-vector-products-using-both-forward-and-reverse-mode" rel="noopener ugc nofollow" target="_blank"> JAX的《自动烹饪书》</a>中的<code class="fe ms mt mu mv b">hvp</code>(黑森矢量积)函数来计算黑森对角线。只有当Hessian是对角的(所有非对角条目都为零)时，这个技巧才可能实现，这在我们的例子中是成立的。这样，我们就不会存储整个hessian，并动态计算它，从而减少内存消耗。</p><p id="ba49" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">然而，最显著的加速是由于通过“正向-反向微分”对Hessian的有效计算。技术细节超出了这篇文章的范围，你可以在<a class="ae kv" href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#hessian-vector-products-using-both-forward-and-reverse-mode" rel="noopener ugc nofollow" target="_blank"> JAX的自学食谱</a>中读到。</p><p id="e902" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">此外，我们利用JAX的JIT编译来进一步减少运行时间，减少了大约3倍。</p><h2 id="74a6" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">运行时性能基准</h2><p id="7c4e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们对运行时性能进行更彻底的比较。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/27fe553767bbb3f16cccc394e02e0940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COv-QzkQql6lXe4_4_GzuA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图5: </strong>运行时基准测试结果:JAX比PyTorch快。</p></figure><p id="2b6b" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">我们注意到PyTorch实现具有二次运行时复杂度(在示例数量中)，而JAX实现具有<strong class="lu ir">线性</strong>运行时复杂度。这是一个巨大的优势，允许我们在大型数据集上使用JAX实现。</p><p id="f6c3" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">现在，让我们比较自动微分和手动微分:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/3f765452cb33d859c7b0e183481e826e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pngEojfhG-NLnqQz7MlK-A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><strong class="bd mz">图6: </strong>运行时基准测试结果:手动微分比JAX快。</p></figure><p id="a3a0" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">事实上，相比之下，手动区分速度非常快(快40倍)。然而，对于复杂的损失函数或小数据集，自动微分仍然是工具箱中一项有价值的技能。</p><p id="e1a0" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">该基准测试的完整代码可在此处找到:</p><div class="nc nd gp gr ne nf"><a href="https://github.com/1danielr/auto-gb" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd ir gy z fp nk fr fs nl fu fw ip bi translated">GitHub - 1danielr/auto-gb:梯度增强决策树的自动微分。</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">github.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt kp nf"/></div></div></a></div><h2 id="d9e7" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结论</h2><p id="c707" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们利用自动微分的能力无缝地使用XGBoost中的定制损失函数，并对运行时性能进行了可行的折衷。当然，上面的代码也适用于其他流行的梯度增强库，如LightGBM和CatBoost。</p><p id="80c6" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">我们看到JAX为我们提供了实质性的速度提升，这要归功于它对Hessian的高效实现，以及对JIT编译的透明利用。此外，我们列出了几行代码，允许我们一般地计算梯度和Hessians。也就是说，我们的方法可以推广到需要高阶自动微分的额外工作负载。</p></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><p id="24a3" class="pw-post-body-paragraph ls lt iq lu b lv mm jr lx ly mn ju ma lf mo mc md lj mp mf mg ln mq mi mj mk ij bi translated">感谢阅读！我很想听听你的想法和评论😃</p></div></div>    
</body>
</html>