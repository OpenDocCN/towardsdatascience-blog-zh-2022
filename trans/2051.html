<html>
<head>
<title>GreenLIT: Using GPT-J with Multi-Task Learning to Create New Screenplays</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">格林利特:使用GPT J与多任务学习创造新的电影剧本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c#2022-05-09">https://towardsdatascience.com/greenlit-using-gpt-j-with-multi-task-learning-to-create-new-screenplays-54a2d04f761c#2022-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6e03" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何微调一个ML模型来创建具有新标题、情节概要和脚本的电视节目和电影</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/15429c36f2c2a30af32e8217e6ef3e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X2lCne3U74NYCh3e"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">科技日报在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的<a class="ae ky" href="https://unsplash.com/@techdailyca?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="e64e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在<a class="ae ky" rel="noopener" target="_blank" href="/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701">的上一篇文章</a>中展示了我如何微调GPT J来生成俳句，结果相当不错。在我的最新实验GreenLIT中，我想突破使用GPT J进行创意写作的限制，看看它是否能为全新的电视节目和电影制作剧本。</p><p id="3768" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是GreenLIT的组件和流程框图。我将在下面的小节中详细讨论这些。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/d363a10ebf96fa86f59e150828fcaddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6O3HoLozP2k-hZg1rnqBug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw"> GreenLIT组件</strong>，作者提供的图表</p></figure><p id="eda1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我在网上搜索了一下，找到了五个带文本的开源数据集，用作训练数据:</p><ul class=""><li id="c61a" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">康奈尔大学ConvoKit项目的电影对话(麻省理工学院许可)[1]</li><li id="a647" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">电影情节摘要来自Kaggle上的Rounak Banik(CC0许可证)[2]</li><li id="ab5b" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">来自ConvoKit项目的朋友对话(麻省理工学院许可)[1]</li><li id="85c5" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">来自维基百科的朋友情节摘要(CC-BY-SA许可)[3]</li><li id="7b7a" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">Kaggle上Shivam Bansal的流媒体节目分析(CC0许可证)[4]</li></ul><p id="f332" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一个和第三个数据集包含电影和热门情景喜剧《老友记》中的对话其他数据集包括电视节目和电影的标题、类型和情节概要。我写了一些Python代码来预处理和过滤文本，为GPT-J要学习的四个任务创建一组条目:</p><ol class=""><li id="fda0" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu ml md me mf bi translated">体裁和主题→标题和情节</li><li id="cc0b" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">标题和情节→对话框</li><li id="cc07" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">标题和情节→剧本</li><li id="2a2e" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">对话框→脚本</li></ol><p id="3427" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意对话仅仅意味着角色的名字和台词，而剧本是对话加上舞台指示。我将在下面进一步详细解释这一切。</p><p id="546d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从GPT-J [5]模型开始，它是GPT-3 [6]的开源变体。GPT-J之前在一个名为Pile [7]的网络上接受了大量文本数据的训练。</p><p id="9f70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在Google Colab上用超过38，000个训练条目对GPT-J进行了20小时的微调，以创建我的GreenLIT模型。在我对其进行微调之后，我使用了以下文本提示作为输入。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="bd46" class="mr ms it mn b gy mt mu l mv mw">GENRE: <strong class="mn iu">crime drama</strong><br/>THEME: <strong class="mn iu">cryptocurrency</strong></span></pre><p id="524b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据该提示，GreenLIT模型生成了以下标题和情节摘要:</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="0ab0" class="mr ms it mn b gy mt mu l mv mw">#1. TITLE: <strong class="mn iu">Bitcoin Heist</strong><br/>SUMMARY: Two young men embark on a heist that could be the start of a new revolution.</span><span id="c001" class="mr ms it mn b gy mx mu l mv mw">#2. TITLE: <strong class="mn iu">Satoshi's Daughter</strong><br/>SUMMARY: A crime drama about a woman who inherits a cryptocurrency fortune.</span><span id="4ee8" class="mr ms it mn b gy mx mu l mv mw">#3. TITLE: <strong class="mn iu">The Dark Web</strong><br/>SUMMARY: The story of two brothers who join the underground Bitcoin economy.</span><span id="d333" class="mr ms it mn b gy mx mu l mv mw">#4. TITLE: <strong class="mn iu">Cryptostorm</strong><br/>SUMMARY: Cryptostorm revolves around the story of a young man who has been trying to keep his life on track after being sent to<br/>prison for a crime he didn't commit.</span><span id="4262" class="mr ms it mn b gy mx mu l mv mw">#5. TITLE: <strong class="mn iu">The Cypher</strong><br/>SUMMARY: A young hacker joins a group of underground hackers to create a secure platform.</span></pre><p id="62c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从这个列表中选择了#3，黑暗之网，并将标题和摘要发送回GreenLIT以创建脚本的第一页。在这里。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="cf6d" class="mr ms it mn b gy mt mu l mv mw">TITLE: <strong class="mn iu">The Dark Web<br/></strong>SUMMARY: The story of two brothers who join the underground Bitcoin economy.<br/>SCRIPT:</span><span id="7ddb" class="mr ms it mn b gy mx mu l mv mw">[Scene: The living room of the house, the door opens and the brothers come in. They are both dressed in black, have their hoods up.]</span><span id="fd6a" class="mr ms it mn b gy mx mu l mv mw">LEO - Okay, we did it! We hit the mother lode!<br/>DREW - We hit the mother lode?<br/>LEO - Yeah!<br/>DREW - How much is in here?<br/>LEO - Six hundred and forty dollars worth.<br/>DREW - (To himself) Well, that's better thaan nothing.<br/>LEO - The bitcoins are untraceable.<br/>DREW - The bitcoins?<br/>LEO - Yeah, the Bitcoin is basically just a name for a cryptographic currency.<br/>DREW - A cryptographic currency?<br/>LEO - Yeah, like, a secure, internet way of transferring money from one person to another.<br/>DREW - Sounds like they invented the internet.<br/>LEO - Well, the internet is just a network of computers connected to other computers by phone lines, but the internet is also the thing that makes it possible to transfer money from one computer to another without a bank.<br/>DREW - Oh, yeah?<br/>LEO - Yeah.<br/>DREW - How do you do that?<br/>LEO - Well, it's actually really complicated, and I don't understand it myself, but the short version is that the Bitcoin is run by a bunch of computers all connected to each other. It's kind of like a decentralized Ponzi scheme.<br/>DREW - A decentralized Ponzi scheme?<br/>LEO - Yeah, you know, like the government runs a Ponzi scheme.</span></pre><p id="93d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，有意思。剧本似乎幽默地解释了加密货币的基础知识，并对角色进行了一些发展。加上一点社会评论。请稍等，我给我的代理人打电话。😉</p><p id="bd77" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以在Google Colab上免费查看GreenLIT <a class="ae ky" href="https://github.com/robgon-art/GreenLIT" rel="noopener ugc nofollow" target="_blank">这里</a>。请务必查看下面附录中的更多示例输出。</p><h1 id="4497" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">系统详细信息</h1><p id="564c" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">在接下来的小节中，我将深入探讨GreenLIT中使用的组件和流程的细节。我将首先讨论一种称为多任务学习的训练神经网络的技术。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/b57cfa77fb2cc523cee3208b686d3704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ycyal_vjjMaaAHvzSsGacw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw">多任务</strong>，来源:<a class="ae ky" href="https://pxhere.com/en/photo/1538475?utm_content=clipUser&amp;utm_medium=referral&amp;utm_source=pxhere" rel="noopener ugc nofollow" target="_blank">T5】PxHereT7】，<strong class="bd lw">T9】CC0公共域</strong></a></p></figure><h2 id="62b5" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">多任务学习</h2><p id="34ce" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">对于GreenLIT项目，我有两个主要目标，(A)根据给定的类型和主题创建新节目的标题和情节概要，以及(B)根据给定的标题和情节概要创建脚本的第一页。虽然微调两个专门的人工智能模型可以工作，但我想看看一个微调的模型是否可以完成这两项任务。这样做有几个好处。正如我在我的<a class="ae ky" rel="noopener" target="_blank" href="/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701">深度俳句</a>项目中发现的那样，针对多个但相似的任务微调一个模型，即多任务学习，可以提高两个任务的结果。里奇·卡鲁纳在卡内基·梅隆大学研究了这一技术。</p><blockquote class="og oh oi"><p id="d6ab" class="kz la oj lb b lc ld ju le lf lg jx lh ok lj lk ll ol ln lo lp om lr ls lt lu im bi translated">多任务学习是一种归纳迁移的方法，它通过使用相关任务的训练信号中包含的领域信息作为归纳偏差来提高泛化能力。它通过使用共享表示并行学习任务来做到这一点；每个任务学到的东西可以帮助其他任务学得更好。—里奇·卡鲁纳</p></blockquote><p id="917d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解释多任务学习是如何工作的，亚历山大·巴甫洛夫·洪查尔在他的文章中描述了一个叫做“特征选择双重检查”的概念。他说，“如果一个特征对于不止一个任务是重要的，那么很可能这个特征对于你的数据来说确实是非常重要和有代表性的”，并且将在多任务学习期间被系统强化。</p><p id="9f66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个优势是实际效率——只需要加载一个AI模型来执行这两项任务。使用一种模式可以减少磁盘存储、加载时间和GPU内存。</p><p id="421f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我将讨论我是如何为项目收集训练数据的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/a32f1be3dca23f9422ae02af6066d6e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_MO5mi7e_jcDwhtr"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@sortino?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Joshua Sortino </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="ab17" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated"><strong class="ak">收集训练数据</strong></h2><p id="cc16" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">为了针对第一项任务(生成新节目的标题和剧情摘要)对系统进行微调，我寻找了包含电影和电视节目元数据的开源数据集。</p><h2 id="ea9f" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">收集电影情节</h2><p id="39b8" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">在拥有众多数据集的Kaggle上，我发现了一个由Rounak Banik编写的电影情节摘要的大型列表，名为<a class="ae ky" href="https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset" rel="noopener ugc nofollow" target="_blank">电影数据集</a>。它包含标题、发行年份、类型、摘要等。，对于超过40K的电影。他在CC0(公共领域)许可下发布了数据集。以下是5个条目的示例。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/12e6e59f1d48f12ab1f30060142747f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMbrIqabMMEH7PDveiz7Ig.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw">来自电影数据集</strong>的样本条目，来源:<a class="ae ky" href="https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上的Rounak Banik，CC0公共域</p></figure><p id="6c57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了一个名为KeyBERT [9]的模块来从摘要中提取主题。你可以在这里看到我的Python代码<a class="ae ky" href="https://gist.github.com/robgon-art/7d438f3fcb3d012af594bfd7e2313549" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="c7ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在Shivam Bansal的Kaggle上找到了另一个数据集集合。他收集了网飞、亚马逊、Hulu和Disney+上大约2万个流媒体节目的摘要。这是一个数据样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/d3157cf5ad8a313273352f8e54fa9cdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6KNo9NZ-bdmMAOrA3ubBNw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw">来自流媒体服务</strong>的样本条目，来源:<a class="ae ky" href="https://www.kaggle.com/shivamb/datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上的Shivam Bansal，CC0公共域</p></figure><p id="65ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我再次使用KeyBERT从流媒体节目的摘要中捕捉主题。</p><p id="2cc5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了教GPT-J如何从类型和主题中创建标题和摘要，我为每个电影和电视节目收集了一个这样的条目。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="2d95" class="mr ms it mn b gy mt mu l mv mw">GENRE: action science fiction<br/>THEME: saving the world<br/>TITLE: The Matrix<br/>SUMMARY: Set in the 22nd century, The Matrix tells the story of a computer hacker who joins a group of underground insurgents fighting the vast and powerful computers who now rule the earth.</span><span id="4812" class="mr ms it mn b gy mx mu l mv mw">GENRE: comedy sitcom<br/>THEME: workplace comedy<br/>TITLE: 30 Rock<br/>SUMMARY: The life of the head writer at a late-night television variety show. From the creator and stars of SNL comes this workplace comedy. A brash network executive bullies head writer Liz Lemon into hiring an unstable movie star.</span></pre><h2 id="cdb9" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">收集电影和电视剧本</h2><p id="4b6f" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">接下来，我搜索脚本数据集。引用黑暗网络的Leo的话来说，当我发现康奈尔大学的ConvoKit时，“我找到了主矿脉”。收集数据集的正式名称是康奈尔对话分析工具包[1]，在麻省理工学院开源许可下发布。</p><blockquote class="og oh oi"><p id="3219" class="kz la oj lb b lc ld ju le lf lg jx lh ok lj lk ll ol ln lo lp om lr ls lt lu im bi translated">[ConvoKit]包含提取对话特征和分析对话中社会现象的工具，使用受scikit-learn启发(并与之兼容)的单一统一界面。包括了几个大型对话数据集，以及在这些数据集上使用工具包的脚本示例。— Jonathan P. Chang等人。</p></blockquote><p id="91f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我使用了ConvoKit中两个数据集的dialog来微调GreenLIT。以下是来自他们网站的数据集描述。</p><ul class=""><li id="80f8" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu mc md me mf bi translated">康奈尔电影对话语料库-从原始电影剧本中提取的大量元数据丰富的虚构对话集。(617部电影中10，292对电影角色之间的220，579次会话交流)。</li><li id="5659" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu mc md me mf bi translated">《老友记》语料库——收集了10季《老友记》中的所有对话，这是一部流行于20世纪90年代的美国电视情景喜剧。</li></ul><p id="84b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是康奈尔电影对话语料库中《卢旺达酒店》中的一段对话。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="6c5d" class="mr ms it mn b gy mt mu l mv mw">PAUL - What's wrong?<br/>ZOZO - Beg your pardon sir, you are Hutu. You are safe there.<br/>PAUL - You are with me, Zozo, don't worry.<br/>ZOZO - What is it like to fly on a plane, sir?<br/>PAUL - It depends where you sit Zozo. In coach it is like the bus to Giterama.<br/>ZOZO - That is why they call it coach?<br/>PAUL - Maybe. But in business class there are fine wines, linens, Belgian chocolates.<br/>ZOZO - You have taken business class?<br/>PAUL - Many times.<br/>PAUL - I will try my best George but these days I have no time for rallies or politics.<br/>GEORGE - Politics is power, Paul. And money.Gathering TV Scriptss</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ef4e338376864bd604b33898c41b3e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*m4A0WcWzc45z2Vjk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伊尔塞·奥尔塞尔在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="28bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是《老友记》的一个片段，故事发生在他们最喜欢的咖啡馆中央公园。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="ecab" class="mr ms it mn b gy mt mu l mv mw"><strong class="mn iu">SCRIPT:<br/></strong>[Scene, Central Perk]</span><span id="3c95" class="mr ms it mn b gy mx mu l mv mw">MONICA - There's nothing to tell! He's just some guy I work with!<br/>JOEY - C'mon, you're going out with the guy! There's gotta be something wrong with him!<br/>CHANDLER - All right Joey, be nice. So does he have a hump? A hump and a hairpiece?<br/>PHOEBE - Wait, does he eat chalk?</span><span id="0e43" class="mr ms it mn b gy mx mu l mv mw">(They all stare, bemused.)</span><span id="f460" class="mr ms it mn b gy mx mu l mv mw">PHOEBE - Just, 'cause, I don't want her to go through what I went through with Carl- oh!<br/>MONICA - Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.<br/>CHANDLER - Sounds like a date to me.</span></pre><h2 id="e017" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">添加舞台方向</h2><p id="b9b4" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">注意，与《老友记》的剧本不同，《卢旺达饭店》的剧本没有任何舞台指导。它只有对话框。</p><p id="2d80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了教GreenLIT模型如何添加舞台指示，我从老友记创建了一组只有对话框的脚本，如下所示，后跟脚本。这些训练条目由以下内容组成:“对话:“+台词+”脚本:“+带舞台指示的台词。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="f525" class="mr ms it mn b gy mt mu l mv mw"><strong class="mn iu">DIALOG</strong>:<br/>MONICA - There's nothing to tell! He's just some guy I work with!<br/>JOEY - C'mon, you're going out with the guy! There's gotta be something wrong with him!<br/>CHANDLER - All right Joey, be nice. So does he have a hump? A hump and a hairpiece?<br/>PHOEBE - Wait, does he eat chalk?<br/>PHOEBE - Just, 'cause, I don't want her to go through what I went through with Carl- oh!<br/>MONICA - Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.<br/>CHANDLER - Sounds like a date to me.</span></pre><p id="9bf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">微调之后，如果我用“…对话框:”结束提示，它将只创建对话框。但是如果我以“… SCRIPT:”结束提示，它会知道生成带有舞台指示的对话框。这是行动中的多任务学习！</p><p id="c966" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我将讨论如何解决在生成的脚本中重复字符名称的问题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/7981f57ed77e3398343aae4f074c8a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnsuG5tKuLqiqhERpdIUFQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw">顶级婴儿名字</strong>，来源:美国社会安全局，<a class="ae ky" href="https://www.ssa.gov/policy/accessibility.html" rel="noopener ugc nofollow" target="_blank">公共领域</a></p></figure><h2 id="1c02" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">使角色名字多样化</h2><p id="b128" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">经过一些初步实验后，我注意到在训练数据集中包含朋友脚本会导致模型经常使用六个中心人物的名字。例如，系统将创建以18世纪为背景的具有名为乔伊、菲比和钱德勒的人物的时期片断。</p><p id="c5cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使角色名字多样化，我把236集《老友记》的角色名字都换了。我用的是美国社会保障办公室收集的<a class="ae ky" href="https://www.ssa.gov/oact/babynames/" rel="noopener ugc nofollow" target="_blank">名</a>列表。</p><p id="cda7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，上面显示的脚本将这些角色名称用于训练数据:</p><p id="c096" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">罗斯→卢卡斯<br/>钱德勒→安东尼奥<br/>乔伊→埃迪<br/>瑞秋→夏洛特<br/>菲比→斯特拉<br/>莫妮卡→露丝安娜</p><p id="2696" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还把所有提到“中央公园”的地方都改成了“咖啡店”，以帮助去掉剧本中的“朋友关系”。下面是修改后的脚本:</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="534f" class="mr ms it mn b gy mt mu l mv mw"><strong class="mn iu">SCRIPT</strong>:<br/>[Scene, Coffee Shop]</span><span id="9f38" class="mr ms it mn b gy mx mu l mv mw">LUCIANA - There's nothing to tell! He's just some guy I work with!<br/>EDDIE - C'mon, you're going out with the guy! There's gotta be something wrong with him!<br/>ANTONIO - All right Eddie, be nice. So does he have a hump? A hump and a hairpiece?<br/>STELLA - Wait, does he eat chalk?</span><span id="05c7" class="mr ms it mn b gy mx mu l mv mw">(They all stare, bemused.)</span><span id="8b75" class="mr ms it mn b gy mx mu l mv mw">STELLA - Just, 'cause, I don't want her to go through what I went through with Carl- oh!<br/>LUCIANA - Okay, everybody relax. This is not even a date. It's just two people going out to dinner and- not having sex.<br/>ANTONIO - Sounds like a date to me.</span></pre><p id="ef19" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，仅仅改变角色的名字就让它看起来像是一部不同的电视剧。</p><h2 id="fa0d" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">为朋友收集情节摘要</h2><p id="5904" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">因为ConvoKit数据集不包含任何情节摘要，所以我从维基百科上搜集了所有老友记剧集的摘要。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/8b36f8e8b7704b07bf8b54d9f2003b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRLOUAaSgiNTfwHmtPn8Sw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">《老友记》第一季的剧集，来源:<a class="ae ky" href="https://en.wikipedia.org/wiki/Friends_(season_1)#Episodes" rel="noopener ugc nofollow" target="_blank">维基百科</a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License" rel="noopener ugc nofollow" target="_blank"> CC-BY-SA </a></p></figure><p id="94fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获取摘要的源代码是这里的<a class="ae ky" href="https://gist.github.com/robgon-art/1186da076dcc5cef6148716fc62c381a" rel="noopener ugc nofollow" target="_blank"/>。我再次使用KeyBERT来获取剧集主题的关键词。</p><p id="f0b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是我为训练GPT-J而收集的数据摘要</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/da5164e909756bae0d9b2b5c5ace9c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O3xna1yJBzsJ3kuShZg2zA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd lw">green lit</strong>的培训数据汇总，表格由作者提供</p></figure><p id="da1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦我准备好了所有的训练，我就开始微调GPT J来创作新的节目和剧本。</p><h2 id="5b51" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">微调GPT J</h2><p id="052b" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">类似于我在我的<a class="ae ky" rel="noopener" target="_blank" href="/deep-haiku-teaching-gpt-j-to-compose-with-syllable-patterns-5234bca9701">深度俳句</a>项目中所做的，我微调了GPT-J来学习和运行GreenLIT所需的所有四个任务:</p><ol class=""><li id="b999" class="lx ly it lb b lc ld lf lg li lz lm ma lq mb lu ml md me mf bi translated">体裁和主题→标题和情节</li><li id="2842" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">标题和情节→对话框</li><li id="354c" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">标题和情节→剧本</li><li id="b264" class="lx ly it lb b lc mg lf mh li mi lm mj lq mk lu ml md me mf bi translated">对话框→脚本</li></ol><p id="a242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">来自Eleuther AI [5]的GPT-J模型是OpenAI的<em class="oj">居里</em>模型的大小，是第二大的GPT-3模型[6]。Eleuther AI在Pile上训练模型，这是一个用于语言建模的多样化文本的巨大(800GB)数据集[7]。</p><p id="64bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谷歌实验室只有16g内存的GPU，如果照原样使用，GPT J将耗尽内存。为了在Colab上运行它，我使用微软的Edward Hu等人的低秩自适应技术将具有32位参数的GPT-J 6-B转换为8位参数[8]。你可以在这里阅读艾勒瑟艾的模型卡<a class="ae ky" href="https://huggingface.co/hivemind/gpt-j-6B-8bit" rel="noopener ugc nofollow" target="_blank">上的详细内容。</a></p><h2 id="0c96" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">运行系统</h2><p id="960c" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">在对模型进行微调后，我用它来创建新的标题和摘要以及节目的脚本。</p><p id="286d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我注意到的第一件事是，系统经常会为以前制作的节目生成标题。这并不令人惊讶，因为我用现有节目的数据对它进行了微调。为了弥补这一点，我创建了一个小的<a class="ae ky" href="https://gist.github.com/robgon-art/92237f1f92af32ceb4aaca4533339cfe" rel="noopener ugc nofollow" target="_blank"> Python函数</a>来检查是否有任何新创建的标题以前被使用过，使用维基百科作为参考。</p><p id="bb8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，我用类型:<strong class="lb iu">犯罪喜剧</strong>和主题:<strong class="lb iu">巴迪银行抢劫案</strong>运行系统。七个生成的标题中有四个来自现有的节目。我在下面的结果中用一串星号标记了这些“重复”。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="6ecc" class="mr ms it mn b gy mt mu l mv mw">01 <strong class="mn iu">The Bank Heist Gang</strong> - A group of friends decides to do a bank heist before things go haywire.</span><span id="a2c1" class="mr ms it mn b gy mx mu l mv mw">02 *** <strong class="mn iu">The Bank Job</strong> - A group of ex-cons and petty criminals rob a bank in a small town. While carrying out the heist, they become involved in romantic entanglements, and the heist itself turns into a big, silly mess.</span><span id="b2bb" class="mr ms it mn b gy mx mu l mv mw">03 *** <strong class="mn iu">Buddy Buddy</strong> - The film opens with a young man who, while on a business trip, is robbed by his own bodyguard who is also the son of the man who owns the bank.</span><span id="0d63" class="mr ms it mn b gy mx mu l mv mw">04 <strong class="mn iu">The Bumstead Affair</strong> - When a bank robbery goes awry, a group of young men decide to get rich quick by robbing the other robbers.</span><span id="eb4d" class="mr ms it mn b gy mx mu l mv mw">05 *** <strong class="mn iu">Get Shorty</strong> - Get Shorty is a crime comedy centered around three friends who get involved in a heist.</span><span id="2785" class="mr ms it mn b gy mx mu l mv mw">06 <strong class="mn iu">The Great American Caper</strong> - A man and his best friend have a scheme to rob a bank.</span><span id="4502" class="mr ms it mn b gy mx mu l mv mw">07 *** <strong class="mn iu">The Hustler</strong> - A Las Vegas bank robber attempts to double-cross the mob by holding up their own bank... and the movie changes into a slapstick comedy.</span></pre><p id="fc28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我从原始标题中选择了Bumstead事件来查看生成的脚本。在这里。</p><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="b84f" class="mr ms it mn b gy mt mu l mv mw">[Scene: All of the guys are in the basement where Trench is at the computer. The guys are discussing the upcoming robbery attempt.]</span><span id="d64a" class="mr ms it mn b gy mx mu l mv mw">D'JACK - We're gonna hit the bank on Sunday. The place is closed on Sunday. The cops will never know.<br/>TRENCH - Yeah, but...<br/>D'JACK - But what?<br/>TRENCH - What about the cameras?<br/>D'JACK - The cameras are gonna be out.</span><span id="bd11" class="mr ms it mn b gy mx mu l mv mw">(The guys are looking at the computer monitor)</span><span id="4772" class="mr ms it mn b gy mx mu l mv mw">D'JACK - And we'll make sure the alarm's gonna be out, too.<br/>TRENCH - Yeah, but then...<br/>D'JACK - Then what?<br/>TRENCH - Then we'll be in the bank and we're gonna get rich?<br/>D'JACK - Right, that's the goal.</span></pre><p id="db85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">好吧，这很简单。但我喜欢特伦奇和杰克这两个角色的名字。我也喜欢包含舞台说明。</p><h1 id="cf3e" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">讨论结果</h1><p id="a9bb" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我和GreenLIT玩了一周左右，它似乎在为节目提出新想法方面做得很好，尽管它经常重复使用标题。请注意，插入一个新的流派和主题会减少重复。</p><p id="ffc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，生成的脚本中的对话框对我来说似乎有点乏味。好消息是对话看起来很自然，但是散文的内容通常很简单。这可能是因为所有的新剧本都是为一部剧的第一页第一场设计的。他们直接进入介绍性的阐述。</p><p id="f512" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看附录以获得更多示例脚本。</p><h1 id="dd5d" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">源代码和Colabs</h1><p id="79a4" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">这个项目的所有源代码都可以在GitHub上找到。我在<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA许可</a>下发布了源代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/37ef39d2cabebede7364aae1bbf5780b.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/0*HijS4AlOrqGMtXF4.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">知识共享署名共享</p></figure><h1 id="5e9d" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">感谢</h1><p id="ee98" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我要感谢詹尼弗·林和奥利弗·斯特瑞普对这个项目的帮助。</p><h1 id="f06e" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">参考</h1><p id="3f81" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">[1] Jonathan P. Chang，Caleb Chiam，Liye Fu，，Justine Zhang，Cristian Dane scu-Niculescu-Mizil .2020.<a class="ae ky" href="https://www.cs.cornell.edu/~cristian/ConvoKit_Demo_Paper_files/convokit-demo-paper.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">对话工具包</strong>:对话分析工具包</a>《SIGDIAL会议录》。</p><p id="ce53" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] R. Banik，<a class="ae ky" href="https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Kaggle上的电影数据集</strong></a>(2018)</p><p id="b3a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">【3】维基百科，<a class="ae ky" href="https://en.wikipedia.org/wiki/Friends_(season_1)#Episodes" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">好友剧情概要</strong> </a></p><p id="db7a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] S. Bansal，<a class="ae ky" href="https://www.kaggle.com/shivamb/datasets" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu">Kaggle上的流媒体电影和电视节目</strong></a>(2022)</p><p id="ad8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5] <strong class="lb iu"> GPT-J </strong>，<a class="ae ky" href="https://www.eleuther.ai/projects/mesh-transformer-jax/" rel="noopener ugc nofollow" target="_blank">网格-变压器-JAX:模型-与JAX并行实现变压器语言模型</a> (2021)</p><p id="f7ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6] <strong class="lb iu"> GPT-3 </strong>、T. B .布朗、b .曼恩、n .赖德、m .苏比亚、j .卡普兰、p .达里瓦尔、A .尼拉坎坦等人<a class="ae ky" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank">语言模型是一次性学习者</a> (2020)</p><p id="f601" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[7] L.Gao等，<a class="ae ky" href="https://arxiv.org/pdf/2101.00027.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> The Pile </strong>:一个800GB的用于语言建模的多样化文本数据集</a> (2020)</p><p id="59a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[8] R .卡鲁阿纳，<a class="ae ky" href="http://www.cs.cornell.edu/~caruana/mlj97.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">多任务学习</strong> </a> (1997)</p><p id="986e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[9] M. Grootendorst，<a class="ae ky" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> KeyBERT </strong>:用BERT </a>进行最小关键词提取(2020)</p><p id="3ab4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[10] E .胡等，<a class="ae ky" href="https://arxiv.org/pdf/2106.09685.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> LoRA </strong>:大型语言模型的低秩适应</a> (2021)</p><h1 id="e6e5" class="my ms it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">附录</h1><p id="e65e" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">以下新节目的剧本是用GreenLIT创作的。我提供了流派和主题，系统生成了5到10个标题和摘要。然后我选择我最喜欢的，系统生成脚本。</p><h2 id="cc0f" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">机器人定位系统</h2><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="1e7b" class="mr ms it mn b gy mt mu l mv mw">GENRE: science fiction drama<br/>THEME: robot uprising<br/>TITLE: Robopocalypse<br/>SUMMARY: Robopocalypse is a science fiction drama about a coming robot uprising, and the people left behind to survive it.<br/>SCRIPT:</span><span id="8c30" class="mr ms it mn b gy mx mu l mv mw">[Scene: A lab. Dr. Nathan Frost is looking at a robot on a cart. A technician is walking around the room, adjusting wires on the robot.]</span><span id="a97d" class="mr ms it mn b gy mx mu l mv mw">FROST - What the hell is he doing?<br/>TECHNICIAN - We're trying to figure that out. He's been giving us static for the last three hours.<br/>FROST - Static?<br/>TECHNICIAN - Yeah, like he's been transmitting.<br/>FROST - What does he do?<br/>TECHNICIAN - I've been running diagnostics on him, but there's nothing wrong.<br/>FROST - Does he have a malfunction?<br/>TECHNICIAN - We've tried every possible combination of switches, buttons, and dials, and nothing seems to work.<br/>FROST - He's got to be controlled by a central computer. Who is he?<br/>TECHNICIAN - He doesn't have a tag, like the other robots. He's supposed to be a model.<br/>FROST - Where'd he come from?<br/>TECHNICIAN - He looks like the others, except for the fact that he's a few hundred years ahead of the development schedule.<br/>FROST - Well, he's ours now, so I guess we'll have to wait till he figures out what he's supposed to do.</span></pre><h2 id="2eaa" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">夜静止了</h2><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="9f03" class="mr ms it mn b gy mt mu l mv mw">GENRE: thriller drama<br/>THEME: cold war spy<br/>TITLE: The Night Stands Still<br/>SUMMARY: When a Russian defector arrives at the home of an American diplomat, he makes a startling confession, and the diplomat and the diplomat's wife are forced to hunt for a killer, and a traitor.</span><span id="f3b4" class="mr ms it mn b gy mx mu l mv mw">[Scene: The American embassy in Moscow. The diplomat, an older man, is sitting alone in his office. His wife enters.]</span><span id="1b38" class="mr ms it mn b gy mx mu l mv mw">ROBERT - How are you doing?<br/>SYLVIA- I'm not sure.<br/>ROBERT- Oh.</span><span id="ed15" class="mr ms it mn b gy mx mu l mv mw">ROBERT- The guy's in there. He's a Russian defector. He came here last night.<br/>SYLVIA - What did he say?<br/>ROBERT - Well, he's not exactly talking, but he has to be kept alive. And he's got something to tell us.<br/>SYLVIA- What?<br/>ROBERT - I don't know. He came in last night and made these phone calls.</span><span id="f8b0" class="mr ms it mn b gy mx mu l mv mw">SYLVIA - He's on the run.  I'm sorry.<br/>ROBERT - It's not your fault, Sylvia.</span></pre><h2 id="20dc" class="mr ms it bd mz nv nw dn nd nx ny dp nh li nz oa nj lm ob oc nl lq od oe nn of bi translated">斯托纳高中</h2><pre class="kj kk kl km gt mm mn mo mp aw mq bi"><span id="c3b2" class="mr ms it mn b gy mt mu l mv mw">GENRE: stoner comedy<br/>THEME: goofy friends smoke pot<br/>TITLE: Stoner High<br/>SUMMARY:<strong class="mn iu"> </strong>A group of high school students try to save a local marijuana grow operation from a sheriff.<br/>SCRIPT:</span><span id="3e13" class="mr ms it mn b gy mx mu l mv mw">[Scene: A room at Stoner High. The school principal is looking at a report from the sheriff]</span><span id="7627" class="mr ms it mn b gy mx mu l mv mw">PRINCIPAL - What's going on, Sheriff?<br/>JASON - The grower's name is Randy "Duke" Burdon. He's got a rap sheet a mile long. They found marijuana plants growing in his garage.<br/>PRINCIPAL - Duke Burdon?<br/>JASON - That's the guy.  He's been arrested for growing pot twice before, but he always gets off on a technicality.<br/>PRINCIPAL - Are you sure that's him?<br/>JASON - I know this guy.</span><span id="3140" class="mr ms it mn b gy mx mu l mv mw">PRINCIPAL - Okay. I'll find out what I can...<br/>JASON - I don't think that's a good idea.<br/>PRINCIPAL - Why not?<br/>JASON - Because you're a principal. And because you're too old to party, and you don't need to be the target of a bunch of kids.<br/>PRINCIPAL - I'm not going to let it happen.<br/>JASON - And what if it does?<br/>PRINCIPAL - I'll handle it.</span></pre></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="2215" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae ky" href="https://robgon.medium.com/membership" rel="noopener">成为会员</a>，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>