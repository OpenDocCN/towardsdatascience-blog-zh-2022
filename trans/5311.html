<html>
<head>
<title>Stable Diffusion 2 Is the First Artist-Friendly AI Art Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">稳定扩散 2 是第一个艺术家友好的人工智能艺术模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stable-diffusion-2-is-not-what-users-expected-or-wanted-abfd39524dff#2022-11-29">https://towardsdatascience.com/stable-diffusion-2-is-not-what-users-expected-or-wanted-abfd39524dff#2022-11-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="012f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">意见</h2><div class=""/><div class=""><h2 id="36e8" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">但这不是用户想要的——他们生气是对的吗？</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/89a898372dd2f49be18135f33d1e80c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kkwcjsBq7kBrJULE.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">现在谁坐在生成人工智能的宝座上？鸣谢:作者 via Midjourney(哦，讽刺的是)</p></figure><p id="1ac3" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我通常不报道模特发布会。我为先验的下游含义(如<a class="ae md" href="https://thealgorithmicbridge.substack.com/p/galactica-what-dangerous-ai-looks" rel="noopener ugc nofollow" target="_blank">卡拉狄加</a>和<a class="ae md" href="https://thealgorithmicbridge.substack.com/p/bloom-is-the-most-important-ai-model" rel="noopener ugc nofollow" target="_blank">布鲁姆</a>)或高趣味性/有用性做了例外。</p><p id="6d6f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">今天的话题大概是两个都查:Stability.ai，开源的生成式 ai 之王，已经宣布<a class="ae md" href="https://stability.ai/blog/stable-diffusion-v2-release" rel="noopener ugc nofollow" target="_blank">稳定扩散 2 </a>。</p><p id="3278" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">新版本的稳定扩散带来了关键的改进和更新。在一个不同的世界里，很有可能每一个使用稳定传播的应用/功能/程序都会马上使用新版本。</p><p id="c7a6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，这是不可能的。Stable Diffusion 2 尽管技术质量出众，但被很多用户(如果不是全部的话)认为<em class="me">退一步讲</em>。</p><p id="5dc2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在这篇文章中，我将尽可能简单地描述稳定扩散 2 的主要特性，它与 1.x 版本的比较，为什么人们认为它是一种回归，以及我对所有这些的看法。</p><p id="792f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">要明确的是，这不仅仅是关于稳定扩散 2。正在发生的事情超出了稳定性。人工智能——这是一个迹象，表明即将发生的事情以及生成性人工智能将如何与现实世界发生冲突。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="d19d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="me">本文选自</em><a class="ae md" href="https://thealgorithmicbridge.substack.com/subscribe?" rel="noopener ugc nofollow" target="_blank"><strong class="lj jd"><em class="me">The Algorithmic Bridge</em></strong></a><em class="me">，这是一份旨在弥合算法与人之间鸿沟的教育通讯。它将帮助你理解人工智能对你生活的影响，并开发工具来更好地导航未来。</em></p><div class="mm mn gp gr mo mp"><a href="https://thealgorithmicbridge.substack.com/subscribe" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd jd gy z fp mu fr fs mv fu fw jc bi translated">算法桥</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">弥合算法和人之间的鸿沟。关于对你重要的人工智能的时事通讯。点击阅读…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">thealgorithmicbridge.substack.com</p></div></div><div class="my l"><div class="mz l na nb nc my nd lb mp"/></div></div></a></div></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><h2 id="5220" class="ne nf it bd ng nh ni dn nj nk nl dp nm lq nn no np lu nq nr ns ly nt nu nv iz bi translated">稳定扩散 2:模型和特征</h2><p id="3fc2" class="pw-post-body-paragraph lh li it lj b lk nw kd lm ln nx kg lp lq ny ls lt lu nz lw lx ly oa ma mb mc im bi translated">让我们从故事的客观部分开始。</p><p id="5752" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这一部分稍微有点技术性(虽然不难)，所以可以随意浏览一下(如果您计划使用该模型，仍然值得一读)。</p><p id="8272" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">稳定扩散 2 是源自共同基线的整个模型家族的通用名称:稳定扩散 2.0-base (SD 2.0-base)原始文本到图像模型。</p><p id="b203" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">基线模型在开放数据集 LAION-5B 的美学子集上进行训练(记住这一点，它在以后会很重要)，并生成 512x512 图像。</p><p id="f663" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在 SD 2.0 基础之上，Stability.ai 又训练了几个具有特定功能的模型(下面的例子)。</p><p id="564a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">SD 2.0-v 也是文本到图像模型，但默认分辨率更高(768x768):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/edebbf14109288cfa4d032aedb2387ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/0*4ZsVPWHCtltdCely.jpeg"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">信用:<a class="ae md" href="https://twitter.com/StabilityAI/status/1595590345374326785" rel="noopener ugc nofollow" target="_blank"> Stability.ai </a></p></figure><p id="4689" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Depth2img 是一个深度到图像模型，它建立在经典的 img2img 版本的基础上，以提高模型保持结构和连贯性的能力:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/ea00ebccdb70ba5edb66cfdc826fcd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MmjgoRrlMRTR4VAX.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">鸣谢:<a class="ae md" href="https://github.com/Stability-AI/stablediffusion#depth-conditional-stable-diffusion" rel="noopener ugc nofollow" target="_blank">GitHub 上的 stability . ai</a></p></figure><p id="e20f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">升级型号采用其他型号的输出，并将分辨率提高了 4 倍(例如，从 512x512 提高到 2048x2048):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/9f9b699fcfc6daef39d0e1d89a19387a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mH9uidBwN_q3vudZ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">鸣谢:<a class="ae md" href="https://github.com/Stability-AI/stablediffusion#image-upscaling-with-stable-diffusion" rel="noopener ugc nofollow" target="_blank">GitHub 上的 stability . ai</a></p></figure><p id="f5c7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">最后，文本引导的修复模型提供了语义替换原始图像部分的工具(就像你可以用 DALL E 做的那样):</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/8ea4cfa53d011b39b089b20932be912f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cpEmeQdYQNDVNyp9.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">功劳:<a class="ae md" href="https://github.com/Stability-AI/stablediffusion#image-inpainting-with-stable-diffusion" rel="noopener ugc nofollow" target="_blank">GitHub 上的 stability . ai</a></p></figure><p id="ae30" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为了方便现有用户的可移植性，Stability.ai 对模型进行了优化，以在单个 GPU 上运行。正如他们在博客文章中解释的那样:“我们希望从一开始就让尽可能多的人可以使用它。”</p><p id="db37" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">像 Stable diffusion 1.x 一样，新版本属于许可许可证。代码是 MIT 许可的(<a class="ae md" href="https://github.com/Stability-AI/stablediffusion" rel="noopener ugc nofollow" target="_blank">在 GitHub </a>上)，重量(<a class="ae md" href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="noopener ugc nofollow" target="_blank">在拥抱面</a>上)遵循<a class="ae md" href="https://github.com/Stability-AI/stablediffusion/blob/main/LICENSE-MODEL" rel="noopener ugc nofollow" target="_blank">creative ml Open RAIL ++ M 许可</a>。</p><p id="052b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Stability.ai 也在<a class="ae md" href="https://platform.stability.ai/" rel="noopener ugc nofollow" target="_blank"> API 平台</a>(面向开发者)和<a class="ae md" href="https://beta.dreamstudio.ai/dream" rel="noopener ugc nofollow" target="_blank"> DreamStudio </a>(面向用户)上发布模型。</p><h2 id="8e6d" class="ne nf it bd ng nh ni dn nj nk nl dp nm lq nn no np lu nq nr ns ly nt nu nv iz bi translated">与 SD 2 最相关的变化:OpenCLIP 编码器</h2><p id="30a2" class="pw-post-body-paragraph lh li it lj b lk nw kd lm ln nx kg lp lq ny ls lt lu nz lw lx ly oa ma mb mc im bi translated">现在来看更重要的消息。</p><p id="335a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Stable Diffusion 2 在架构上比它的前身更好，但也很相似。没什么好惊讶的。然而，Stability.ai 彻底改变了一个特定组件的性质:文本/图像编码器(将文本-图像对转换为向量的内部模型)。</p><p id="1178" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">所有公开的文本到图像模型——包括 DALL E 和 mid journey——都使用<a class="ae md" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> OpenAI 的 CLIP </a>作为编码器。</p><p id="36a0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">毫不夸张地说，CLIP 是 2022 年生成式 AI 浪潮中最具影响力的模型。如果没有 OpenAI 或 CLIP，它根本不会发生。</p><p id="1c45" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这让人们看到了稳定性。ai 的决定打破了两年的标准做法，用一种新的编码器取代了 OpenAI 在稳定扩散 2 上的剪辑。</p><p id="446c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在 Stability.ai 的支持下，LAION 已经训练了<a class="ae md" href="https://github.com/mlfoundations/open_clip" rel="noopener ugc nofollow" target="_blank"> OpenCLIP-ViT/H </a> (OpenCLIP)，据报道，这创造了一个新的最先进的性能:“【它】<a class="ae md" href="https://twitter.com/StabilityAI/status/1595590334624321536" rel="noopener ugc nofollow" target="_blank">与早期的 V1 版本相比，大大提高了生成图像的质量。”</a></p><p id="0910" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">稳定扩散 2 是第一个也是唯一一个集成 OpenCLIP 而不是 CLIP 的模型。</p><p id="d031" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">为什么这是值得注意的？因为 OpenCLIP 不仅仅是开源的，就像原始剪辑一样——它是在<em class="me">公共</em>数据集(LAION-5B) <em class="me">上训练的。</em></p><p id="44c6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如艾玛德·莫斯塔克(Stability.ai 首席执行官)解释的那样，“(视频)很棒，但没人知道里面有什么。”</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="oc od l"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae md" href="https://twitter.com/EMostaque/status/1595731398450634755" rel="noopener ugc nofollow" target="_blank">艾玛德·莫斯塔克的推特</a></p></figure><p id="8d96" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">OpenCLIP 在公开可用的数据集上进行训练的事实意义重大(尽管不一定是好的)，因为现在开发人员和用户可以知道它编码了什么(即它学习了什么以及如何学习)。</p><p id="2f8f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这有两个直接的影响。</p><p id="eee6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">第一，因为 OpenCLIP 和 CLIP 的训练数据不一样，稳定扩散 2“知道”的东西<em class="me">和稳定扩散 1、DALL E、Midjourney“知道”的东西</em>不一样。</p><p id="7aca" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Mostaque 解释说，对早期版本的稳定扩散有效的提示技术和启发法，可能对新模型不太有效:“(稳定扩散)V2 提示不同，人们需要一段时间来适应。”</p><p id="43ee" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然而，他解释说，即使稳定扩散 2 已经以不同的方式学习了一些东西——这将迫使用户重新思考他们的提示技能——它已经更好地学习了这些技能。</p><p id="b4c8" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">其次，因为现在我们可以准确地找出谁的作品出现在数据集中，Stability.ai 可以在未来的版本中为艺术家实现选择加入/选择退出功能(我不知道该公司是否会这样做，但 Mostaque 自己承认这是一个问题)。</p><p id="a693" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这意味着稳定扩散 2 更尊重训练数据中存在的艺术家的作品。与 Midjourney 和 DALL E 相比，这是一个显著的改进。</p><h2 id="60c3" class="ne nf it bd ng nh ni dn nj nk nl dp nm lq nn no np lu nq nr ns ly nt nu nv iz bi translated">人工智能社区为何愤怒</h2><p id="a832" class="pw-post-body-paragraph lh li it lj b lk nw kd lm ln nx kg lp lq ny ls lt lu nz lw lx ly oa ma mb mc im bi translated">但是，如果我们深入挖掘，我们会发现一个非常不同的观点。</p><p id="a86c" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">事实证明，Stability.ai 在不同的 LAION 子集上训练 OpenCLIP(和模型),而不是用户想要的。</p><p id="9d2e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">他们删除了大部分 NSFW 内容和名人图片，最让人们愤怒的是，他们把著名(现代)艺术家的名字从标签上完全删除了(尽管不是他们的作品)。</p><p id="6a02" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这对稳定扩散 2 和整个生殖人工智能领域有着严重的(尽管不一定是坏的)二阶影响。</p><p id="50d6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">一方面，Stability.ai 显然试图通过减少其法律上可疑的做法来遵守版权法，即在没有署名、同意或报复的情况下，从互联网上抓取在世艺术家的作品来训练他们的模型。</p><p id="d78a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">另一方面，稳定扩散的用户相当恼火，因为他们以前用唯一存在的高质量开源模型(稳定扩散)可以产生的许多东西现在都不可能了。</p><p id="3242" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Mostaque 说，提示的工作方式不同，但新的隐式限制不会通过更好的提示工程来解决。</p><p id="8ffe" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">例如，你不能再提示“以格雷格·鲁特科夫斯基的风格”并得到一个有魔法和龙的史诗般的中世纪场景，因为稳定扩散 2 不再认为“格雷格·鲁特科夫斯基”是任何特别的东西。</p><p id="158a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">那已经过去了。和他在一起的，还有你用过的其他在世的或已故的艺术家。他们的作品仍然存在于数据中，但是编码器不再能够将图像与名字相关联。</p><p id="6928" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我承认《稳定扩散 2》在客观上比它的上一个版本在制作艺术的能力上受到了更多的限制(例如，《中途 v4》在质量方面要好得多)。</p><p id="388d" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">AI 社区可以通过调整 OpenCLIP 来绕过这些限制吗？虽然 Mostaque 在 Discord 服务器上提出了这种可能性，但不清楚他们如何才能做到这一点(最终，是 Stability.ai 拥有 5408 个 A100s)，微调编码器是<em class="me">昂贵的</em>。</p><h2 id="483a" class="ne nf it bd ng nh ni dn nj nk nl dp nm lq nn no np lu nq nr ns ly nt nu nv iz bi translated">生成式人工智能的回归？</h2><p id="5b1b" class="pw-post-body-paragraph lh li it lj b lk nw kd lm ln nx kg lp lq ny ls lt lu nz lw lx ly oa ma mb mc im bi translated">然而，尽管用户普遍感到失望，但 Stability.ai 有一个很好的理由这样做——如果你生活在社会中，你就必须适应社会设定的边界。</p><p id="91e0" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你不应该仅仅因为技术允许你这样做，就把别人踩在脚下(那些作品被记录在案的艺术家就有这种感觉)。如果你说这就是自由的含义，让我告诉你，从这个角度来看，今天的“自由”就是明天的危险。</p><p id="5341" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">诚然，监管的发展比技术慢，但它最终会赶上。当法律制定时，争论“妖怪已经从瓶子里出来”或“进步是不可阻挡的”是不够的。</p><p id="d339" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">现在，<a class="ae md" href="https://githubcopilotlitigation.com/" rel="noopener ugc nofollow" target="_blank">正在对微软、GitHub 和 OpenAI 提起诉讼，指控他们抓取网页来训练 Copilot (Codex)。如果它最终支持开源开发，它可能会从根本上重新定义生成式人工智能的前景。</a></p><p id="0380" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">Stability.ai 对艺人的所作所为和那些公司对编码员的所作所为没什么区别。他们未经许可就拿走了数千人的作品来创造人工智能技术，现在任何人都可以用它来模仿艺术家的创作。</p><p id="c34e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这很可能是该公司这么做的原因。他们正在采取措施避免潜在的诉讼(很难说他们是在保护艺术家，因为如果是这样的话，他们从一开始就已经这么做了)。</p><p id="6fb4" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">但是，不管他们的动机如何，最终的结果才是最重要的:人工智能拥有他们的技术，艺术家得到了更多的保护。</p><p id="dfb1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果人工智能社区现在声称稳定扩散毫无价值，因为“以…的风格”各种提示不起作用(即使艺术家的作品仍然存在于数据中)，那么唯一合理的结论可能是艺术家一直是正确的:他们在数据中的明确存在承担了创造伟大人工智能艺术的大部分重量。</p><h2 id="201b" class="ne nf it bd ng nh ni dn nj nk nl dp nm lq nn no np lu nq nr ns ly nt nu nv iz bi translated">最后的想法</h2><p id="2234" class="pw-post-body-paragraph lh li it lj b lk nw kd lm ln nx kg lp lq ny ls lt lu nz lw lx ly oa ma mb mc im bi translated">正如我几个月前所说的，我们应该开诚布公、相互尊重地讨论这个问题。</p><p id="d1d2" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">可悲的是——也是意料之中的——这并没有发生。AI 人很大程度上驳回了艺人的投诉和请愿。在大多数情况下，艺术家并不愿意适应新的发展，有时甚至会对人工智能社区变得咄咄逼人。</p><p id="f763" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这些都没有用。</p><p id="25c7" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我进入了 r/StableDiffusion subreddit 来了解总体情绪，它与我在这里告诉你的相符。AI 社区与 Stability.ai 的决定严重相左。</p><p id="078f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">把稳定扩散 2 称为“后退一步”和“一次回归”是最软的评论。</p><p id="c455" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">只有一条评论道出了我读到这些愤怒和沮丧时的想法:</p><blockquote class="oe of og"><p id="6584" class="lh li me lj b lk ll kd lm ln lo kg lp oh lr ls lt oi lv lw lx oj lz ma mb mc im bi translated"><em class="it">“显然这里没有人认为未经许可复制艺术家的作品是错误的。我发现所有的信息都在暗示，模仿人们的风格在某种程度上是一种倒退。我不是艺术家，但是想象一下，有人使用别人开发的工具复制了你的作品，让你失业，你的作品无疑是独一无二的。有人会认为这是公平的吗？”</em></p></blockquote><p id="0b6f" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我认为在考虑稳定扩散 2 和一般的生成性人工智能时，最重要的是考虑“另一面”(无论你是艺术家，还是人工智能用户，或者两者都是)。</p><p id="7f1b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">用户现在对 Stability.ai 很恼火——从某种意义上来说是合理的，但在其他方面是不合理的——但他们不应该忘记，当监管发生时——它将会发生——Midjourney 和 OpenAI(以及微软和谷歌)也必须适应和遵守。</p><p id="069a" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这远远超出了任何特定的公司。这是一个世界在不忽视人的权利的情况下重新适应新技术的问题(顺便提一下，我可能不同意人工智能监管的细节，但我强烈认为监管不应该不存在)。</p><p id="04ff" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">生殖型 AI 公司和用户一直享受的这种非问责差距(有人可能称之为自由)即将结束。</p><p id="5b2e" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">而且，在我看来，这样更好。</p></div><div class="ab cl mf mg hx mh" role="separator"><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk ml"/><span class="mi bw bk mj mk"/></div><div class="im in io ip iq"><p id="13fb" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="me">订阅</em> <a class="ae md" href="https://thealgorithmicbridge.substack.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lj jd">算法桥</strong> </a> <em class="me">。弥合算法和人之间的鸿沟。关于与你生活相关的人工智能的时事通讯。</em></p><p id="41b9" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><em class="me">您也可以直接支持我在 Medium 上的工作，并通过使用我的推荐链接</em> <a class="ae md" href="https://albertoromgar.medium.com/membership" rel="noopener"> <strong class="lj jd">这里</strong> </a>成为会员来获得无限制的访问权限！<em class="me"> :) </em></p></div></div>    
</body>
</html>