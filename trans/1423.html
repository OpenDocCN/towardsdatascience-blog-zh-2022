<html>
<head>
<title>Your validation loss is lower than your training loss? This is why!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的验证损失低于你的培训损失？这是为什么！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-your-validation-loss-is-lower-than-your-training-loss-this-is-why-5e92e0b1747e#2022-04-08">https://towardsdatascience.com/what-your-validation-loss-is-lower-than-your-training-loss-this-is-why-5e92e0b1747e#2022-04-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1fe2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">仅仅因为你的模型从训练集中学习并不意味着它的性能会更好。</h2></div><p id="515d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，数据科学家会遇到验证损失低于训练损失的情况。<strong class="kk iu">这是一个奇怪的观察结果</strong>因为模型正在从训练集中学习，所以它应该能够更好地预测训练集，然而我们观察到更高的训练损失。出现这种情况有几个原因，我将在本文中逐一介绍常见的原因。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/1fce460d0c8379f19cf1d743a6e66e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*077GfPqWXlpeACGbEOfj2Q.jpeg"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">Freepik.com的Wayhome工作室</p></figure><h1 id="c011" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">原因1: L1或L2正规化</h1><p id="a662" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">症状:验证损失始终低于培训损失，但两者之间的差距随着时间的推移而缩小</strong></p><p id="a64d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">无论是使用L1正则化还是L2正则化，都是通过向误差函数添加模型权重来有效地扩大误差函数:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mr"><img src="../Images/43ffdb79babae1981ff77ca3621e568e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y9F0ly2AyYkfGWw_EdvvvQ.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="e3bf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">正则化项仅在训练集上训练模型时应用，增加了训练损失</strong>。在验证和测试期间，您的损失函数只包含预测误差，因此损失通常低于训练集。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ms"><img src="../Images/9cf3da43fe47674efd3836147f9c8d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a2N3cap60LIBnHnS8V2Epw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="cd84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意验证和列车丢失之间的差距是如何在每个时期后缩小的。这是因为随着网络学习数据，它也会缩小正则化损失(模型权重)，从而导致验证和训练损失之间的微小差异。</p><p id="4aaf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，该模型在训练集上仍然更准确。</p><p id="6ed1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们比较一下模型在训练集和验证集上的R2分数:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi gj"><img src="../Images/bde3a93974decfded8860f47d81a435f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NJVm4KNC79YvseHd7VUQJw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="1ace" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，我们不是在讨论损失，而是只关注模型对训练集和验证集的预测。正如预期的那样，模型对训练集的预测优于验证集。</p><h1 id="b3e1" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">原因二:辍学</h1><p id="66ad" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">症状:验证损失始终低于培训损失，两者之间的差距大致相同，培训损失有波动。</strong></p><p id="ec59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在模型训练期间，通过随机冻结层中的神经元，丢弃会惩罚模型变化。像L1和L2正则化一样，退出仅适用于培训过程，并影响培训损失，导致验证损失低于培训损失的情况。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/a61e786401c4bdaf061359fed6f97cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HuHYb5Nvl6LwULPDbI2Gkg.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="5120" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这种情况下，模型在训练集上也更准确:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi gj"><img src="../Images/96911cd7558dbad29fa4140ef898e9d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P4wXpnB-b8f75gDQGZ3Khw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="5c64" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是意料之中的。当网络中存在正则化或丢失时，较低的损耗并不总是意味着较高的精度。</p><h1 id="4012" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">原因3:训练损失是在每个时段期间计算的，但是验证损失是在每个时段结束时计算的</h1><p id="fa3b" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">症状:开始时验证损失低于培训损失，但后来有类似或更高的值</strong></p><p id="9750" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，当您的所有训练数据通过网络精确传递一次时，每个时期就完成了，如果您以小批量传递数据，每个时期可能会有多次反向传播。每个反向传播步骤都可以显著地改进模型，尤其是在最初的几个时期，此时权重仍然相对未经训练。</p><p id="449a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，当每次反向传播显著更新模型时，您可能会在最初的几个时期中获得较低的验证损失。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/7bcb158f4ee4952a10272a2f1dedae3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3WYM__8yle3RLXyJ8SuEiA.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><h1 id="1082" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">理由4:纯粹的运气！(适用于所有ML型号)</h1><p id="64aa" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated"><strong class="kk iu">症状:验证集比训练集有更低的损失和更高的准确率。你也没有那么多数据。</strong></p><p id="90df" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，噪音是独立变量无法解释的因变量的变化。当您进行训练/验证/测试分割时，在某些迭代中，训练集中的噪声可能比测试或验证集中的噪声多。如果模型没有过度拟合，这会使模型在训练集上不太准确。</p><p id="8edf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您正在使用它，这可以通过更改train_test_split函数中的随机种子来解决(不适用于时间序列分析)。</p><p id="e229" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，由于大数定律，当数据集很重要时，不太可能出现这种结果。</p><p id="003b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们进行一个实验，观察验证精度对train_test_split函数中随机种子的敏感度。我将在for循环中运行模型训练和超参数调整，并且只更改train_test_split中的随机种子，并可视化结果:</p><pre class="lf lg lh li gt mu mv mw mx aw my bi"><span id="06c8" class="mz lv it mv b gy na nb l nc nd">for i in range(10):<br/>    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size = 0.3, random_state = i)<br/>    xg = XGBRegressor()<br/>    grid_obj = GridSearchCV(xg, parameters, n_jobs=-1)<br/>    grid_obj = grid_obj.fit(X_train, y_train)<br/>    val_r2.append(r2_score(y_val, grid_obj.predict(X_val)))<br/>    train_r2.append(r2_score(y_train, grid_obj.predict(X_train)))</span></pre><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ne"><img src="../Images/5c9947f3e1e6d238cd768515e249cbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zJoCRW8572g40z_KjrOgdw.png"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">作者图片</p></figure><p id="70ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在10个实验中的3个实验中，模型在验证集上的R2分数略好于训练集。在这种情况下，将随机种子更改为在验证集和定型集之间均匀分布噪声的值将是合理的下一步。</p><p id="2289" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于剧情还有更多要说的。数据科学家通常专注于超参数调整和模型选择，而忽略了对我们的结果有重大影响的简单事物，如随机种子。不过，我会在以后的文章中写这方面的内容！</p><h1 id="b3a4" class="lu lv it bd lw lx ly lz ma mb mc md me jz mf ka mg kc mh kd mi kf mj kg mk ml bi translated">摘要</h1><p id="7453" class="pw-post-body-paragraph ki kj it kk b kl mm ju kn ko mn jx kq kr mo kt ku kv mp kx ky kz mq lb lc ld im bi translated">我们讨论了导致验证低于培训损失的四种情况，并解释了根本原因。我们经常看到，较低的验证损失不一定转化为较高的验证准确性，但当它转化为较高的验证准确性时，重新分配训练集和验证集可以解决这个问题。</p><p id="5d7c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们进行这项研究的假设是，我们没有遭受其他问题，如数据泄漏或采样偏差，因为它们也可能导致类似的观察结果。</p><p id="ec21" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请务必关注更多内容！</p></div></div>    
</body>
</html>