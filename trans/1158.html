<html>
<head>
<title>Estimate Weights for Multifactor Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">估计多因素模型的权重</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/estimate-weights-for-multifactor-model-e061174ca79#2022-03-24">https://towardsdatascience.com/estimate-weights-for-multifactor-model-e061174ca79#2022-03-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="36d8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用神经网络的思想来估计具有多个因素的系统的权重</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c3a08dc8fba111fd23e4eb0f390bca0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D7MIGQsTu70rzSXLCaPZuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">网从<a class="ae ky" href="https://unsplash.com/photos/n6B49lTx7NM" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="c738" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">假设您有一个包含许多特征的客户数据集，并且您正试图构建一个加权系统来预测某些客户行为(比如购买或不购买)。如何确定那些个体的权重值？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi me"><img src="../Images/9f82511246fb4d9567a4660500f1cf63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*WDzqfFoFOpJqTdFJWTtM-A.png"/></div></figure><p id="8a32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当特征尺寸非常小时，我们可以用肉眼读取、分析和确定权重。对于任何超过 3 个权重的系统，我们将需要一个系统化的解决方案来确定权重值，<strong class="lb iu">自动</strong>。</p><p id="f931" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将介绍一个解决方案(用 Python 代码)来实现它。一种思想借用了神经网络。</p><h1 id="7500" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">一个重量系统</h1><p id="8225" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">为了尽可能简单地演示这个想法，让我从一个重量系统开始。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/65b2b25e7ec062defc5853b3b0fd5c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*opVKiKVIt02HnK1HFfow-A.png"/></div></figure><p id="5734" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是的，这是一个简单的线性系统。如果<code class="fe nd ne nf ng b">w = 2, b = 3</code>。该函数的工作方式如下:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="3311" class="nl mg it ng b gy nm nn l no np">f(1) = 2*1 + 3 = 5<br/>f(2) = 2*2 + 3 = 7<br/>f(3) = 2*3 + 3 = 9<br/>f(4) = 2*4 + 4 = 12<br/>...</span></pre><p id="3254" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，假设我们对<strong class="lb iu"> w </strong>和<strong class="lb iu"> b </strong>一无所知。但只知道 f(x)及其结果:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="8eb7" class="nl mg it ng b gy nm nn l no np">f(1) = 5<br/>f(2) = 7<br/>f(3) = 9<br/>f(4) = 12</span></pre><p id="4a1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并利用上面的成对数字估算出<strong class="lb iu"> w </strong>和<strong class="lb iu"> b </strong>。</p><p id="df85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">步骤 1 </strong>，初始化参数和测试数据。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="b855" class="nl mg it ng b gy nm nn l no np">import numpy as np<br/># model = y = 2*x + 3<br/>X = np.array([1,2,3,4],dtype=np.float32)<br/>Y = [(2*x + 3) for x in X]<br/># w and b to be predicted<br/><strong class="ng iu">w,b = 0.0,0.0</strong></span></pre><p id="f2fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第二步</strong>，类似于神经网络模型，定义<strong class="lb iu">正向</strong>、<strong class="lb iu">损失</strong>和<strong class="lb iu">梯度</strong>函数。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="5345" class="nl mg it ng b gy nm nn l no np"><em class="nq">def</em> forward(<em class="nq">x</em>):<br/>    return w*<em class="nq">x</em>+b</span><span id="b768" class="nl mg it ng b gy nr nn l no np"><em class="nq">def</em> loss(<em class="nq">y</em>,<em class="nq">y_pred</em>):<br/>    return ((<em class="nq">y_pred</em>-<em class="nq">y</em>)**2).mean()</span><span id="7425" class="nl mg it ng b gy nr nn l no np"><em class="nq">def</em> gradient(<em class="nq">x</em>,<em class="nq">y</em>,<em class="nq">y_pred</em>):<br/>    return np.dot(<em class="nq">x</em>,(<em class="nq">y_pred</em>-<em class="nq">y</em>))</span><span id="0021" class="nl mg it ng b gy nr nn l no np">print(<em class="nq">f</em>'print the prediction before training: f(5)={forward(5)}')</span></pre><p id="81d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">步骤 3 </strong>，用 4 对数据进行训练，并用 f(5)检验结果</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="51f1" class="nl mg it ng b gy nm nn l no np">learning_rate,n_inters = (0.01,10000)<br/>for epoch in range(n_inters):<br/>    y_pred  = forward(X)<br/>    l       = loss(Y,y_pred)<br/>    dw      = gradient(X,Y,y_pred)<br/>    w       = w - learning_rate*dw<br/>    b       = b + learning_rate*l<br/>print(<em class="nq">f</em>'epoch {epoch+1}: w= {w<em class="nq">:.3f</em>},b= {b<em class="nq">:.3f</em>} loss = {l<em class="nq">:.8f</em>}, dw = {dw<em class="nq">:.3f</em>}')<br/>print(<em class="nq">f</em>'print the prediction after training: f(5)={forward(5)}')</span></pre><p id="245f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里是完整的代码，我强烈建议您自己运行代码并查看结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="3f9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过一万轮的训练。我们“几乎”拥有正确的<strong class="lb iu"> w </strong>和<strong class="lb iu"> b </strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/49c61981150325fb33c47a659e94095b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUrsHc1BccLCoXdaSPxvLg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">w = 2.019b= 2.942</p></figure><p id="adb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们得到<strong class="lb iu">w = 2.019</strong>；<strong class="lb iu"> b= 2.942 </strong>。非常接近<code class="fe nd ne nf ng b">w = 2</code>和<code class="fe nd ne nf ng b">b = 3</code>。看起来不错，嗯？毕竟只有 8 个数字用来预测权重和偏倚。</p><h1 id="eb62" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">三重制</h1><p id="3b7f" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">现在，让我们将模型扩展到估计三重系统中的重量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi me"><img src="../Images/9f82511246fb4d9567a4660500f1cf63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*WDzqfFoFOpJqTdFJWTtM-A.png"/></div></figure><p id="02c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设，<strong class="lb iu"> w1 = 2 </strong>，<strong class="lb iu"> w2 = 3 </strong>，<strong class="lb iu"> w3 = 4 </strong>，<strong class="lb iu"> bias = 5 </strong>。填入上面的函数。我们将拥有:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="a26e" class="nl mg it ng b gy nm nn l no np">f(1,2,3) = 25<br/>f(2,3,4) = 24<br/>f(3,4,5) = 43<br/>...</span></pre><p id="60a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">闭上眼睛，忘记重量和偏见。假设我只知道输入和输出，用 Python 代码实现权重估计逻辑。</p><p id="6e84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第 1 步</strong>，初始化数据。因为 bias 实际上是一个变量乘以 1。所以，我们可以认为 bias 为<strong class="lb iu"> w4 </strong>，但总会乘以 1。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="0953" class="nl mg it ng b gy nm nn l no np">import numpy as np</span><span id="e3e9" class="nl mg it ng b gy nr nn l no np">X = np.array(<br/>    [[1,2,3,1]<br/>    ,[2,3,4,1]<br/>    ,[3,4,5,1]<br/>    ,[4,3,2,1]<br/>    ,[12,13,14,1]<br/>    ,[7,8,9,1]<br/>    ,[5,2,10,1]]<br/>    ,<em class="nq">dtype</em>=np.float32<br/>)<br/># w1= 2, w2= 3, w3= 4, b= 5<br/>W_r = np.array([2,3,4,5],<em class="nq">dtype</em>=np.float32)# r-&gt;real<br/>W = np.array([0,0,0,0],<em class="nq">dtype</em>=np.float32)  # for estimation</span><span id="6692" class="nl mg it ng b gy nr nn l no np">Y = np.array([x@W_r for x in X],<em class="nq">dtype</em>=np.float32)</span></pre><p id="905d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在代码中，X 是一个 4 列 2d 数组。最后一列是偏差。</p><p id="51d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第二步，</strong>定义模型。几乎与单权重系统模型相同，但不需要单独处理偏差。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="56a9" class="nl mg it ng b gy nm nn l no np"><em class="nq">def</em> forward(<em class="nq">X</em>):<br/>    return np.dot(<em class="nq">X</em>,W)</span><span id="dcbe" class="nl mg it ng b gy nr nn l no np"><em class="nq">def</em> loss(<em class="nq">Y</em>,<em class="nq">Y_pred</em>):<br/>    return ((<em class="nq">Y_pred</em>-<em class="nq">Y</em>)**2)</span><span id="a64a" class="nl mg it ng b gy nr nn l no np"><em class="nq">def</em> gradient(<em class="nq">X</em>,<em class="nq">Y</em>,<em class="nq">Y_pred</em>):<br/>    return <em class="nq">X</em>*(<em class="nq">Y_pred</em>-<em class="nq">Y</em>)</span></pre><p id="e2c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第三步</strong>，训练，看预估权重和偏差。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="e249" class="nl mg it ng b gy nm nn l no np">learning_rate,num_epoch = 0.001,3000</span><span id="ea11" class="nl mg it ng b gy nr nn l no np">for epoch in range(num_epoch):<br/>    for i,x in enumerate(X):<br/>        y_pred  = forward(x)<br/>        l       = loss(y_pred,Y[i])<br/>        dw      = gradient(x,Y[i],y_pred)<br/>        W       = (W - dw*learning_rate)<br/>    print(<em class="nq">f</em>'epoch:{epoch} | loss:{l<em class="nq">:.8f</em>}')<br/>print(W)</span></pre><p id="caa5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是完整的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d131" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过 3000 轮训练后，模型返回如下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/6747cb33ec73c8e8d0cf505001150ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*QL1mcGzby3o0AdlH4FLmcg.png"/></div></figure><p id="ee84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常接近[2，3，4，5]！</p><h1 id="2277" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">将模型应用于 30 个权重的数据集</h1><p id="f07d" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">是时候研究一些真实的数据了。这次让我根据输入和输出数据来预测 30 个权重。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/567c5c3f580f2d0b949c1cbab050e604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7A4LV_PuqXfzdR5S4ceCQQ.png"/></div></div></figure><p id="7b21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将要使用的数据集是来自 scikit-learn 的著名的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html" rel="noopener ugc nofollow" target="_blank">乳腺癌数据</a>。如果你决定试一试代码，不需要手动下载数据。如果您安装了 scikit-learn 软件包，数据将自动下载。</p><p id="359c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">导入包和加载数据:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="3caf" class="nl mg it ng b gy nm nn l no np">from sklearn import datasets<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.model_selection import train_test_split<br/>import numpy as np</span><span id="3888" class="nl mg it ng b gy nr nn l no np"># prepare data<br/>bc = datasets.load_breast_cancer()<br/>X,y = bc.data,bc.target<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, <em class="nq">test_size</em>=0.5, <em class="nq">random_state</em>=1234)</span></pre><p id="7a70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将数据集转换为标准格式:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="f4d3" class="nl mg it ng b gy nm nn l no np"># transform to the standard dataset<br/>sc      = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test  = sc.transform(X_test)<br/>y_train = np.where(y_train==0,-1,y_train) # replace 0 with -1<br/>y_test  = np.where(y_test==0,-1,y_test)   # replace 0 with -1</span></pre><p id="7027" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nd ne nf ng b">fit() </code>得到平均值和标准差。<code class="fe nd ne nf ng b">transform()</code>将原始数据转换为正态分布风格的数据。<code class="fe nd ne nf ng b">mean = 0</code>，<code class="fe nd ne nf ng b">stdev =1</code>。为什么？因为原始数据可能会有极大的偏差，有些介于-0.1 到 0.1 之间，而另一些特征则从 0 到 10。fit_transform()在一个函数调用中执行拟合和转换。如果你不熟悉 fit 和 transform 操作，我发现<a class="ae ky" href="https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models/12346#12346" rel="noopener ugc nofollow" target="_blank">这个</a> stackexchange 线程最好地解释了转换操作。</p><p id="d6e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还将 y 数组中的 0 转换为-1，以便于后面的数值处理。</p><p id="272e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，定义模型，训练并验证结果，下面是完整的代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="aa5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/2d16bd2cf245b2c4154d1fea046ffb5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*WBhRjXuU96QjrCuiTvdm0A.png"/></div></figure><p id="2669" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该模型适用于训练数据集，在测试数据集上的准确率为<strong class="lb iu"> 97.7% </strong>和<strong class="lb iu"> 97.2% </strong>。结果即使不是最好的，也应该足够好了。(参见附录部分中 scikit-learn 的其他模型的结果。).</p><p id="80dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便说一下，10，000 轮训练大约需要 10-20 秒。</p><h1 id="c208" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">核心思想</h1><p id="e87e" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">很多年前，我的第一个 C 语言程序是一个价格猜谜游戏。我的程序会随机生成一个价格#。在终端，我输入我的价格猜测。如果我的输入高于真实价格，程序会提醒我输入过高，反之亦然。</p><p id="19dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">经过多轮尝试，我可以大致估算出价格范围。最后，我输入正确的数字，程序会告诉我“成功”和试验次数。</p><p id="0147" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我是价格学习者:我根据程序的反馈上下移动我的猜测数字。</p><p id="9ebe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的三个权重估计的例子中，我在价格猜测游戏中的想法是一样的。</p><p id="0fdc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在一个权重和一个偏置系统中，当输出高于真实结果时，模型将稍微增加/减少权重。因为权重<code class="fe nd ne nf ng b">w</code>是倍数<code class="fe nd ne nf ng b">x</code>，所以我根据输出微分和输入 x 按比例移动了#。</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="9376" class="nl mg it ng b gy nm nn l no np">dw = np.dot(<strong class="ng iu"><em class="nq">x</em></strong>,(<em class="nq">y_pred</em>-<em class="nq">y</em>))<br/>w  = w - learning_rate*dw</span></pre><p id="9b98" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不仅仅是另外两个模型，现在连神经网络深度学习模型都在用同样的思路，没有任何魔力。简单明了。</p><h1 id="92fc" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">包裹</h1><p id="8c47" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">ML 是<strong class="lb iu">而不是</strong>学习一个框架并按照官方教程调用函数。那有点无聊。真正神奇的是下划线的思想和逻辑。</p><blockquote class="ny"><p id="8640" class="nz oa it bd ob oc od oe of og oh lu dk translated">一套逻辑如何根据已知信息准确预测未知？</p></blockquote><p id="0e0a" class="pw-post-body-paragraph kz la it lb b lc oi ju le lf oj jx lh li ok lk ll lm ol lo lp lq om ls lt lu im bi translated">我们生活在一个可以接触到强大的 CPU 和 GPU 的时代，真是太幸运了。如果我们生活在 100 年前，没有人能做这种预测，因为人类几乎不可能在训练数据上迭代这么多次。但是我们可以让 CPU 或者 GPU 来做这个重复性的工作。而且真的管用。</p><p id="b8f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ML 模型有时不是纯粹的数学，而是数学和蛮力的结合。</p><p id="75ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我在思考神经网络模型时，我想到了这个权重系统预测。如果 NN 对图像如此有效，而神经网络深度学习模型的核心是找到一种微调(上下微调)权重和偏差的方法，那么无论定义了多少个隐藏层，核心思想都是一样的。</p><p id="8299" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为什么不应用同样的想法来建立一个适用于其他数据集的模型呢？这很有效。</p></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><p id="4f55" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你有任何问题，请留下评论，我会尽力回答，如果你发现了错误，不要犹豫，把它们标记出来。感谢阅读。</p><h1 id="7200" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">参考链接</h1><ol class=""><li id="4fc2" class="ou ov it lb b lc mx lf my li ow lm ox lq oy lu oz pa pb pc bi translated"><a class="ae ky" href="https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models/12346#12346" rel="noopener ugc nofollow" target="_blank">https://data science . stack exchange . com/questions/12321/what-the-difference-of-fit-and-fit-transform-in-scikit-learn-models/12346 # 12346</a></li><li id="2147" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . datasets . load _ breast _ cancer . html</a></li><li id="fd0b" class="ou ov it lb b lc pd lf pe li pf lm pg lq ph lu oz pa pb pc bi translated"><a class="ae ky" href="https://github.com/xhinker/nn_sample_code" rel="noopener ugc nofollow" target="_blank">https://github.com/xhinker/nn_sample_code</a></li></ol><h1 id="3603" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">附录—与 Scikit-Learn 中的其他模型进行比较</h1><p id="f0c9" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">在相同的训练和测试数据集上应用来自 scikit-learn 的其他模型，并测量准确度分数。</p><h2 id="9eb6" class="nl mg it bd mh pi pj dn ml pk pl dp mp li pm pn mr lm po pp mt lq pq pr mv ps bi translated">决策树:90.5%</h2><p id="6baf" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">代码:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="f146" class="nl mg it ng b gy nm nn l no np">from sklearn.tree import DecisionTreeClassifier as dtc<br/>tree = dtc(<em class="nq">random_state</em>=1)<br/>tree.fit(X_train,y_train)<br/>print(<em class="nq">f</em>"decision tree Accuracy on test set:{tree.score(X_test,y_test)}")</span></pre><p id="b8d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="390a" class="nl mg it ng b gy nm nn l no np">decision tree Accuracy on test set:0.9052631578947369</span></pre><h2 id="b462" class="nl mg it bd mh pi pj dn ml pk pl dp mp li pm pn mr lm po pp mt lq pq pr mv ps bi translated">最近邻法:94.7%</h2><p id="28d5" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">代码:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="5168" class="nl mg it ng b gy nm nn l no np">from sklearn.neighbors import KNeighborsClassifier as knt<br/>k_model = knt(<em class="nq">n_neighbors</em>=3)<br/>k_model.fit(X_train,y_train)<br/>print(<em class="nq">f</em>"K-nearest Accuracy on test set:{k_model.score(X_test,y_test)}")</span></pre><p id="acc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="a80b" class="nl mg it ng b gy nm nn l no np">K-nearest Accuracy on test set:0.9473684210526315</span></pre><h2 id="5573" class="nl mg it bd mh pi pj dn ml pk pl dp mp li pm pn mr lm po pp mt lq pq pr mv ps bi translated">逻辑回归分析:96.1%</h2><p id="f09b" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">代码:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="e6af" class="nl mg it ng b gy nm nn l no np">from sklearn.linear_model import LogisticRegression as LR<br/>lr_model = LR().fit(X_train,y_train)<br/>print(<em class="nq">f</em>'Logistic Regression Accuracy on test set:{lr_model.score(X_test,y_test)}')</span></pre><p id="98a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="9e93" class="nl mg it ng b gy nm nn l no np">Logistic Regression Accuracy on test set:0.9614035087719298</span></pre><h2 id="03ed" class="nl mg it bd mh pi pj dn ml pk pl dp mp li pm pn mr lm po pp mt lq pq pr mv ps bi translated">贝叶斯估计:91.2%</h2><p id="b71b" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">代码:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="909a" class="nl mg it ng b gy nm nn l no np">from sklearn.naive_bayes import GaussianNB as bayes<br/>b_model = bayes().fit(X_train,y_train)<br/>print(<em class="nq">f</em>'Bayes Estimation on test set:{b_model.score(X_test,y_test)}')</span></pre><p id="3511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果:</p><pre class="kj kk kl km gt nh ng ni nj aw nk bi"><span id="c411" class="nl mg it ng b gy nm nn l no np">Bayes Estimation on test set:0.9122807017543859</span></pre><p id="6e86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请随意运行它，如果有更好的结果，请告诉我。</p></div></div>    
</body>
</html>