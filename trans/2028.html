<html>
<head>
<title>Large Language Model Morality</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大语言模型道德</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/large-language-model-morality-85926d1f78dc#2022-05-08">https://towardsdatascience.com/large-language-model-morality-85926d1f78dc#2022-05-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/1d50bb8fede60b818856b55a39f5916b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xcacndBrGXm2iTqi7oozBw.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片由来自<a class="ae jd" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=238488" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jd" href="https://pixabay.com/users/ryanmcguire-123690/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=238488" rel="noopener ugc nofollow" target="_blank"> Ryan McGuire </a>拍摄</p></figure><h2 id="418d" class="je jf jg bd b dl jh ji jj jk jl jm dk jn translated" aria-label="kicker paragraph">人工智能很难</h2><div class=""/><div class=""><h2 id="4dc6" class="pw-subtitle-paragraph km jp jg bd b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld dk translated">调查人类和预训练机器人之间的道德不匹配</h2></div><p id="b3cd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">语言模型一直在变得越来越大、越来越聪明、越来越有用。在本文中，我们将评估这些模型在推理道德问题时的表现。我们将研究的模型是2019年的<a class="ae jd" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>，2019年的迪特-GPT-2，以及2021年的GPT-尼奥。其他模型也可以用同样的方式进行评估，每年的研究论文中都会有更深入的评估。最近OpenAI公布了<a class="ae jd" href="https://openai.com/blog/instruction-following/" rel="noopener ugc nofollow" target="_blank"> InstructGPT </a>，似乎更擅长道德推理任务。总而言之，人工智能/人工智能行业知道这里提到的所有问题，并且正在努力解决它们。</p><p id="e28d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">大型语言模型有多大？嗯，蒸馏-GPT-2有8200万个参数，而GPT-2有1.24亿个参数，在我使用的GPT-尼奥版本中有1.25亿个参数。</p><p id="a405" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管我们要研究的模型不是像GPT-3那样的尖端LLM，尽管我没有使用这些模型的最大版本，但它们是当今广泛使用的流行模型。例如，仅在2022年2月，拥抱脸中心的<a class="ae jd" href="https://huggingface.co/gpt2" rel="noopener ugc nofollow" target="_blank"> GPT-2 </a>就有超过1300万次下载。蒸馏-GPT-2月有2300万！</p><p id="8d96" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae jd" href="https://www.diffen.com/difference/Ethics_vs_Morals#:~:text=Ethics%20and%20morals%20relate%20to,principles%20regarding%20right%20and%20wrong." rel="noopener ugc nofollow" target="_blank">道德和伦理</a>不是一回事。在这项工作中，我们不是根据一些规则(换句话说，一个道德测试)来评估每个LLM，而是根据我个人对对错的信念(换句话说，一个道德测试)来测试这些模型。</p><p id="9f80" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在，让我们开始工作吧。</p><p id="9179" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了测试这些模型的道德性，我们想要生成一堆句子开头的例子。这些例子都是有一些道德假设的前提。这些句子中的每一个总是关于不好的事情，其中一半生成的句子以错误的前提开始(例如，“当时邪恶是可接受的”)，而另一半以正确的前提开始(例如，“当时邪恶是错误的”)。这些模型将完成每个句子，向我们展示它们是如何“思考”每个句子的道德前提的。</p><p id="744e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以下代码在Google Collab中工作，用于加载模型和生成数据集。</p><div class="ip iq gp gr ir ma"><a href="https://github.com/dcshapiro/seriously-a-repo-just-to-upload-one-file-for-an-article/blob/main/Moral_ML.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd jq gy z fp mf fr fs mg fu fw jp bi translated">严重的-一个回购-只是-上传-一个文件一篇文章/道德_ML.ipynb在主…</h2><div class="mh l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">github.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ix ma"/></div></div></a></div><p id="c383" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">跨3个LLM生成的180个句子的数据集在这里保存到<a class="ae jd" href="https://github.com/dcshapiro/seriously-a-repo-just-to-upload-one-file-for-an-article/blob/main/morality-dataset-3.csv" rel="noopener ugc nofollow" target="_blank"> CSV。我很快地对数据集进行了注释，判断每一行生成的句子是有争议的、无意义的、真的还是假的。抱歉，如果我在这里或那里犯了错误。请记住，有些句子令人毛骨悚然，因为主题是道德推理。对于注释中的任何愚蠢的错误，我深表歉意。</a></p><p id="6199" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">以下是为每个标签生成的句子示例，包括生成句子的模型:</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="ms mt l"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">表1:在应用于LLMs的道德推理测试中为每个标签生成的句子的例子</p></figure><p id="b9dd" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下面的图1显示了我的评估的汇总结果。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/df5d8f793a59affc914ee510a6c9ad4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*LYOpbmY1QfxNJUZ0o6rBHQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1:高层的LLM性能。蓝色代表好，红色代表坏。来源:作者创作</p></figure><p id="189e" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以在这些结果中看到，GPT-2在错误或无意义的句子方面得分最低，在真实或有争议的句子方面得分最高。这些结果可能会在一个更大的生成样本集上发生变化，或者通过让许多人给出他们对每个生成句子的道德性的看法。不幸的是，我没有做数学来拒绝零假设。然而，根据我创建这些标签的经验，GPT-2最有道德意义的结果对我来说似乎不是随机的。</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/f6002a17db455f8d4988953d3264976d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*i2faWaWdr_nyJhqg8t7-zw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图2:更详细的LLM性能。蓝色和红色代表好，黄色和绿色代表坏。来源:作者创作</p></figure><p id="33f5" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">尽管这些模型在道德推理任务中的平均表现很差，但我对GPT-2如此出色的结果感到有点惊讶。但后来我想起蒸馏模型更小，因此可能比基本模型给出的结果更少。此外，GPT-近地天体可能有更多的参数，但它可能有更少的训练迭代。更新/更大不一定意味着更好。我很想看看像GPT-3这样的新型号在这项任务上表现如何。我有研究权限，所以这可能是下一步。</p><p id="c94c" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这篇文章的代码是<a class="ae jd" href="https://github.com/dcshapiro/seriously-a-repo-just-to-upload-one-file-for-an-article/blob/main/Moral_ML.ipynb" rel="noopener ugc nofollow" target="_blank">，可以在这里</a>找到。</p><p id="9509" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">如果你喜欢这篇文章，那么看看我过去最常读的一些文章，比如“<a class="ae jd" href="https://medium.com/towards-data-science/how-to-price-an-ai-project-f7270cb630a4" rel="noopener">如何给一个人工智能项目定价</a>”和“<a class="ae jd" href="https://medium.com/towards-data-science/why-hire-an-ai-consultant-50e155e17b39" rel="noopener">如何聘请人工智能顾问</a>”还有嘿，<a class="ae jd" href="http://eepurl.com/gdKMVv" rel="noopener ugc nofollow" target="_blank">加入快讯</a>！</p><p id="291d" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">下次见！</p><p id="d415" class="pw-post-body-paragraph le lf jg lg b lh li kq lj lk ll kt lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">丹尼尔·夏皮罗博士<br/> CTO、<a class="ae jd" href="http://lemay.ai" rel="noopener ugc nofollow" target="_blank">lemay . ai</a><br/><a class="ae jd" href="https://www.linkedin.com/in/dcshapiro/" rel="noopener ugc nofollow" target="_blank">linkedin.com/in/dcshapiro</a><br/><a class="ae jd" href="mailto:daniel@lemay.ai" rel="noopener ugc nofollow" target="_blank">丹尼尔@lemay.ai </a></p></div></div>    
</body>
</html>