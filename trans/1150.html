<html>
<head>
<title>Inductive Link Prediction in Knowledge Graphs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">知识图中的归纳链接预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inductive-link-prediction-in-knowledge-graphs-23f249c31961#2022-03-24">https://towardsdatascience.com/inductive-link-prediction-in-knowledge-graphs-23f249c31961#2022-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8d33" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">开始新的感应链路预测挑战 2022</h2></div><p id="3682" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自从 2011 年以来，知识图上的表征学习领域一直由一项任务主导:直推式链接预测。2022 年还相关吗？🤔不太可能。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/ebb9f6a9fc6da94fa169a9da380d4ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EA4KN94-dZzqQwkbAQ1R0g.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">直推式设置:训练和推理在同一个图上进行。归纳:推论在新图上。彩色箭头代表不同的边类型(关系)。问号表示要预测的边。作者图片</p></figure><p id="4cd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<strong class="kh ir">直推式</strong>设置(🖼 ☝️)中，我们在训练时看到的<strong class="kh ir">相同的</strong>图上执行推理(我们的链接预测)。我们还假设我们<strong class="kh ir">没有</strong>任何预先计算的节点特征。这个事实:</p><ul class=""><li id="fed3" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">🔐在训练和推理时将实体集锁定为相同</li><li id="ecaa" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">🥚允许<em class="mg">浅</em>嵌入模型学习图形中每个节点的唯一向量</li><li id="064c" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">🙅不支持使用预先训练的模型对新图表进行推理</li></ul><blockquote class="mh"><p id="d38d" class="mi mj iq bd mk ml mm mn mo mp mq la dk translated"><strong class="ak">是时候给基于三重 kg 的直推式链路预测最后一击，让它退役了</strong></p></blockquote><p id="b837" class="pw-post-body-paragraph kf kg iq kh b ki mr jr kk kl ms ju kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">随着图在工业中的增长(100M 到 10B+节点)以及每次图改变时重新训练的巨大计算成本，KG 表示学习的焦点正转向不受上述限制的<strong class="kh ir">归纳</strong>模型。</p><h1 id="218d" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">实际影响:我为什么要关心？</h1><p id="da86" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">嗯，对普通三基 KG 的直推式链接预测停止了跟踪 KG 表示学习的大部分进展:这里是代码为的<a class="ae lb" href="https://paperswithcode.com/" rel="noopener ugc nofollow" target="_blank">论文的摘录，可视化了标准</a><a class="ae lb" href="https://www.aclweb.org/anthology/W15-4007/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">FB15k-237</strong></a><strong class="kh ir"/>基准中的进展。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nt"><img src="../Images/e0e8ecb0efd452bbba626b4b7e0ed31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c9Oi1izTB_avyjP2-Nf5pQ.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">自 2019 年以来，直推式 LP 没有实质性进展。作者图片</p></figure><p id="e4ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">🤨自 2019 年以来，你看到任何重大进展吗？(是的，我也没有)</p><p id="4775" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">几年来，普通的转导链路预测已经相当陈旧了。相反，2021 年至 2022 年表征学习的大部分进展(如<a class="ae lb" href="https://arxiv.org/pdf/2106.06935.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">神经贝尔曼-福特网络</strong> </a>或<a class="ae lb" href="https://openreview.net/forum?id=xMJWUKJnFSw" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">节点块</strong> </a>)要么是在新的 KG 模态(如<a class="ae lb" rel="noopener" target="_blank" href="/representation-learning-on-rdf-and-lpg-knowledge-graphs-6a92f2660241">超关系 KG</a>)上实现的，要么是记住了<strong class="kh ir">归纳</strong>属性👉查看<a class="ae lb" rel="noopener" target="_blank" href="/graph-ml-in-2022-where-are-we-now-f7f8242599e0#93ee">我们最近的文章</a>了解更多详情。</p><h1 id="7a40" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">什么是“感应式”设置？</h1><p id="64db" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">在<strong class="kh ir">归纳</strong>设置中，我们取消了在训练和推理时具有相同图形的要求。在我们的<a class="ae lb" href="https://arxiv.org/pdf/2107.04894.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> ISWC 2021 </strong> </a>论文中(谦虚地提一下它获得了最佳研究论文奖😊)我们定义了两种类型的感应设置:</p><ol class=""><li id="4808" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la nu ly lz ma bi translated"><strong class="kh ir">全归纳</strong>:完全脱离训练图的新图。因此，仅在<em class="mg">不可见的</em>实体上执行链接预测(从<em class="mg">不可见到不可见的</em>模式)。</li></ol><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nv"><img src="../Images/f4a5283486e44bac554c6c9d4ab4bf04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0ALxgo9Mx7yZ0dzN1E0AA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">完全归纳设置—推理图与训练图断开。问号表示要预测的边缘。作者图片</p></figure><p id="7b5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.<strong class="kh ir">半归纳</strong>:一个更大的更新图，包括并扩展了训练图。链接预测可以涉及可见和不可见的实体，因此模式<em class="mg">可见到不可见</em>和<em class="mg">不可见到不可见</em>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nw"><img src="../Images/1f32b8dcc02280ec0bdc7906ffcbc20e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-ayRLo2EbfzoH9KPUM6VA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">半归纳设置:推理图用新节点(橙色)扩展了训练图。问号表示要预测的边缘。图片作者。</p></figure><p id="f1d7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">✅归纳模型的一些直接好处:</p><ul class=""><li id="db39" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><strong class="kh ir">没有浅节点嵌入</strong>！在存在新的看不见的节点时，它们是无用的，我们需要新的方法来学习实体表示。</li><li id="a732" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">预训练模型<strong class="kh ir">不需要重新训练</strong>，可以立即用于新的或更新的图表。</li></ul><p id="1616" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">归纳模型带来了额外的<strong class="kh ir">表示学习</strong>挑战，即，我们不能再对每个节点使用浅层向量分配，我们需要更有效的方法来构建能够推广到新的看不见的节点的节点特征。GNNs 和消息传递在这个探索中似乎很有前途。</p><p id="e345" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于完全归纳设置中的归纳 LP 的第一项工作可追溯到由<a class="ae lb" href="https://arxiv.org/pdf/1911.06962.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Teru、Denis 和 Hamilton(ICML 2020)</strong></a><strong class="kh ir"/>提出的论文，他们引入了基于局部节点邻域的归纳特征化方法。由于这种方法的可扩展性不强，因此采样的归纳数据集也相对较小，大多为 2000–5000 个节点。是时候扩大规模了！🚀</p><h1 id="4d42" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">感应链路预测挑战 2022</h1><p id="f048" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">🐍在<a class="ae lb" href="https://github.com/pykeen" rel="noopener ugc nofollow" target="_blank">团队 PyKEEN </a>中，我们设计了一个新的<a class="ae lb" href="https://github.com/pykeen/ilpc2022" rel="noopener ugc nofollow" target="_blank">归纳链接预测挑战</a> (ILPC)，旨在巩固社区在创建归纳推理模型方面的努力。对于 2022 年，我们提出了在<strong class="kh ir">全归纳</strong>模式下的归纳链接预测挑战，即当训练图和推理图不相交时。</p><p id="a41f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着<a class="ae lb" href="https://arxiv.org/abs/2203.01520" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">新论文</strong> </a>描述基准，ILPC 2022 特性:</p><ul class=""><li id="bddf" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">新的数据集<a class="ae lb" href="https://github.com/pykeen/ilpc2022#ilpc22-small" rel="noopener ugc nofollow" target="_blank">ilpc 22-小型</a>和<a class="ae lb" href="https://github.com/pykeen/ilpc2022#ilpc22-large" rel="noopener ugc nofollow" target="_blank">ilpc 22-大型</a>从<a class="ae lb" href="https://www.wikidata.org/wiki/Wikidata:Main_Page" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">维基数据</strong> </a>中取样，最大的公开公斤数。较小的版本(s)非常适合假设检验🧪和有限的计算资源，而较大的版本(l)甚至对现代 gnn 构成了重大挑战，特别是在推理图大小方面——据我们所知，这是模型第一次必须推广到如此大小的看不见的图👀。</li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nx"><img src="../Images/513ac9ffc92199c485fa6bc9c2d8246d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6rFfT_dNkCo1vjF1XgmcuA.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">ILPC 2022 数据集。作者图片</p></figure><ul class=""><li id="7c52" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">公共分割包含训练、验证和测试集，但我们还保留了一个<strong class="kh ir">隐藏测试</strong> <strong class="kh ir">集</strong>，用于对每个数据集大小提交的模型进行最终评估(例如，就像他们在 Kaggle 上做的那样)。此外，我们在 Zenodo 上公开了数据集</li><li id="a9d9" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">一个<a class="ae lb" href="https://github.com/pykeen/ilpc2022" rel="noopener ugc nofollow" target="_blank">代码库</a>,包含一组不同的指标和一个标准化的评估程序。顺便说一下，我们最近发表了一份👉<a class="ae lb" href="https://arxiv.org/abs/2203.07544" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">新作</strong> </a> <strong class="kh ir">👈</strong>设计与数据集大小无关的排名指标，我们计划在最终评估中也使用这些指标！</li><li id="b81d" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">两个强基线采用归纳版本的<a class="ae lb" href="https://openreview.net/forum?id=xMJWUKJnFSw" rel="noopener ugc nofollow" target="_blank">节点件</a>作为组合特征:1️⃣普通节点件+非参数解码器；具有 2 层<a class="ae lb" href="https://github.com/malllabiisc/CompGCN" rel="noopener ugc nofollow" target="_blank"> CompGCN </a>消息传递编码器+非参数解码器的 2️⃣节点。数据集非常具有挑战性，而且远未解决:</li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ny"><img src="../Images/9e2bdd4b6d0b9cb5da9835224659fb33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tggSL122HAwLFiJY8N8Tvg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">ILPC22-Small 上的基准性能。</p></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nz"><img src="../Images/19bb286eb85bfb748f1424f6f97122d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wLVjItngt-bmfHgVtiTBfw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">ILPC22-Large 上的基准性能。</p></figure><ul class=""><li id="8013" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><a class="ae lb" href="https://github.com/pykeen/ilpc2022#-challenge" rel="noopener ugc nofollow" target="_blank">提交材料</a>非常容易制作，并将在♻️公开复制</li><li id="0620" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">最后，ILPC 发布了新的<a class="ae lb" href="https://github.com/pykeen/pykeen" rel="noopener ugc nofollow" target="_blank"> PyKEEN 1.8.0 </a>版本，具有归纳链接预测管道、构建归纳模型的新接口以及许多新的评估指标📏</li></ul><h1 id="9ff3" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">摘要</h1><p id="2655" class="pw-post-body-paragraph kf kg iq kh b ki no jr kk kl np ju kn ko nq kq kr ks nr ku kv kw ns ky kz la ij bi translated">一个新的和开放的感应链路预测挑战 2022 已经开始，尽你所能 GNNs 和其他架构！</p><ul class=""><li id="83c6" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">📜论文:<a class="ae lb" href="https://arxiv.org/abs/2203.01520" rel="noopener ugc nofollow" target="_blank">T17】arxivT19】</a></li><li id="5e72" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">💾数据集:<a class="ae lb" href="https://github.com/pykeen/ilpc2022" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<a class="ae lb" href="https://zenodo.org/badge/latestdoi/460713416" rel="noopener ugc nofollow" target="_blank">芝诺多</a>，开放 CC0 许可</li><li id="8ef6" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">🛠 <a class="ae lb" href="https://github.com/pykeen/ilpc2022#-challenge" rel="noopener ugc nofollow" target="_blank"> Github 知识库，包含排行榜和说明</a></li><li id="36da" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">♻️ <a class="ae lb" href="https://zenodo.org/badge/latestdoi/460713416" rel="noopener ugc nofollow" target="_blank">芝诺多条目</a></li></ul><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/1e5ca972974634132286d4b637076f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*wRXnpR1hrrbwp9NmpKGtgA.gif"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">我们将关注您提交的内容！资料来源:gfycat.com</p></figure></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><p id="d9d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没有查尔斯·塔普利·霍伊特  <em class="mg">(哈佛大学)和马克斯·贝伦多夫</em>  <em class="mg"> (LMU) </em>这部作品就不可能完成🙌</p></div></div>    
</body>
</html>