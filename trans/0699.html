<html>
<head>
<title>A practical introduction to Kmeans clustering using scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 scikit-learn 进行 Kmeans 聚类的实用介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-practical-introduction-to-kmeans-clustering-using-scikit-learn-fd9cff95144b#2022-02-28">https://towardsdatascience.com/a-practical-introduction-to-kmeans-clustering-using-scikit-learn-fd9cff95144b#2022-02-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ddb1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">UCL 数据科学学会研讨会 16:什么是 Kmeans 集群、实现、评估和解释</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b36791773ea1e2dcaff5309b202c6f5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*C_LxXHfIujVCjLPX"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">法比奥·巴拉西纳在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="7ff1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今年，作为 UCL 数据科学协会的科学负责人，该协会将在整个学年举办一系列 20 场研讨会，主题包括 Python 简介、数据科学家工具包和机器学习方法等。每个人的目标是创建一系列的小博客文章，这些文章将概述主要观点，并为任何希望跟进的人提供完整研讨会的链接。所有这些都可以在我们的<a class="ae ky" href="https://github.com/UCL-DSS" rel="noopener ugc nofollow" target="_blank"> GitHub </a>资源库中找到，并将在全年更新新的研讨会和挑战。</p><p id="0b8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本系列的第十六个研讨会是 Python 数据科学研讨会系列的一部分，涵盖了 scikit-learn 中的 Kmeans 集群。在本次研讨会中，我们将讲述什么是 Kmeans 聚类，如何实现该模型，如何选择最佳的聚类数，以及如何解释结果。和往常一样，这篇博文是整个研讨会的总结，可以在<a class="ae ky" href="https://github.com/UCL-DSS/Kmeans-clustering-workshop7" rel="noopener ugc nofollow" target="_blank">这里</a>找到，它更详细地涵盖了这些主题并展示了数据集。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="8efb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您错过了 UCL 数据科学协会之前举办的任何研讨会，可以在这里找到最后三场研讨会:</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/a-practical-introduction-to-support-vector-machines-from-scikit-learn-6e678cf1f228"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">来自 scikit-learn 的支持向量机实用介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 15:什么是支持向量机，如何实现它们，以及如何评估它们</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a href="https://python.plainenglish.io/a-practical-introduction-to-random-forest-classifiers-from-scikit-learn-536e305d8d87" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">scikit-learn 中随机森林分类器的实用介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 14:什么是随机森林分类器、实现、评估和改进</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">python .平原英语. io</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/how-to-implement-and-evaluate-decision-tree-classifiers-from-scikit-learn-36ef7f037a78"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">如何实现和评估来自 scikit-learn 的决策树分类器</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">UCL 数据科学学会研讨会 13:什么是决策树，决策树的实现，可视化和…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mv l mq mr ms mo mt ks mf"/></div></div></a></div></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="2e22" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">什么是 Kmeans 集群？</h2><p id="9927" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">Kmeans 聚类是机器学习的无监督分支的一部分。这意味着我们没有一个明确的目标变量来工作，或者像我们在传统的回归或分类任务中那样去瞄准。因此，该算法的目标是能够识别具有相似特征的不同对象组，例如购物者、电影或本例中的商店。</p><p id="a6ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该方法的工作方式是首先定义要创建的组的目标数量 k，然后算法将初始化数据中的多个质心。从这些质心，每个数据点被分配到每个聚类的距离最近的质心。然后，这些点将进行调整以优化它们的位置，从而最小化类内平方和值。然后，当质心不随每次迭代而改变或者定义的迭代次数已经完成时，该模型被认为是优化的。</p><p id="7d4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这方面的主要问题是，由于这是一种无监督的机器学习算法，我们并不总是知道最佳的聚类数是多少。该算法可以通过“肘方法”评估聚类的数量或通过识别最大轮廓分数来帮助实现这一点。这些将在后面展示，但需要注意的是，这两种技术并不总是完全一致，分组可能是主观的。这意味着我们需要评估与聚类背后的实际值相关的结果，看看它们对我们是否有意义，然后我们是否可以向我们选择的受众解释它们。</p><h2 id="4d3e" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">Kmeans 实现</h2><p id="debd" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们将在此应用中使用的数据集是伦敦便利店数据集，该数据集用于尝试复制由<a class="ae ky" href="https://www.tandfonline.com/doi/abs/10.1080/09593969.2015.1086403" rel="noopener ugc nofollow" target="_blank"> Hood 等人(2016) </a>执行的分析。这里的目的是能够根据便利店服务的客户群来识别便利店群体。出于我们的目的，这意味着数据集包含以下信息:</p><ul class=""><li id="1bb3" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated">500 米内居住人口的估计</li><li id="5968" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">500 米内白天人口的估计</li><li id="b99b" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">500 米范围内交通站数量的计数</li><li id="5d03" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">500 米范围内其他零售店的数量</li><li id="92af" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">社会阶层 1 内居住人口的百分比(根据 2011 年人口普查的定义)</li></ul><p id="e65c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">伦敦的每一家便利店。我们可以将这些分布视为:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="3075" class="mw mx it oj b gy on oo l op oq">#set the columns we are interested in<br/>columns = ["residential_pop", <br/>            "class_1_pop",<br/>            "WZ_area_pop",<br/>            "transport_nearby",<br/>            "stores_nearby"]<br/>#set the histogram titles<br/>hist_titles = ["Residential population nearby distribution",<br/>              "Social Class 1 nearby distribution",<br/>              "Daytime population nearby distribution",<br/>              "Transport stops nearby distribution",<br/>              "Retail stores nearby distribution"]<br/>#set the acis labels<br/>axis_labels = ["Population", <br/>              "Percentage of population",<br/>              "Population",<br/>              "Number of transport stops",<br/>              "Number of stores"]</span><span id="4a40" class="mw mx it oj b gy or oo l op oq">#create a base axis for teh plots<br/>fig, ax = plt.subplots(3,2, figsize = (20,20))<br/>#flatten the axis to make it easy to iteratre over<br/>axis = ax.flatten()</span><span id="3fc0" class="mw mx it oj b gy or oo l op oq">#iterate over each columns using the labels information already set up<br/>for i, col in enumerate(columns):<br/>    <br/>    #create the histogram using the column<br/>    stores_dataset[col].hist(bins = 100, ax = axis[i],<br/>                                       color = "red",<br/>                                       alpha = 0.7)<br/>    #add label information<br/>    axis[i].set_title(hist_titles[i], fontsize = 25, pad = 25)<br/>    axis[i].set_ylabel("Frequency", fontsize  =20, labelpad = 30)<br/>    axis[i].set_xlabel(f"{axis_labels[i]}", fontsize = 20, labelpad = 20)<br/>    axis[i].tick_params(axis = "both", labelsize = 20)</span><span id="4676" class="mw mx it oj b gy or oo l op oq">#remove the unused axis<br/>axis[5].set_axis_off()<br/>#keep the layout tight<br/>plt.tight_layout()<br/>#show the plot <br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/31cc9751763353bad48b81fdb18af663.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dOvE5thz8KiEvmaxZ8nyWw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="59f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就探索 Kmeans 算法而言，我们可以简单地关注商店 500 米范围内的居住人口，以及人口普查定义的社会阶层 1 中的人口百分比。</p><p id="de05" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以根据这些数据创建一个散点图，以查看分布情况，并查看是否有我们可以识别的明确分组:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="f017" class="mw mx it oj b gy on oo l op oq">from matplotlib.gridspec import GridSpec<br/>#<a class="ae ky" href="https://stackabuse.com/matplotlib-scatter-plot-with-distribution-plots-histograms-jointplot/" rel="noopener ugc nofollow" target="_blank">https://stackabuse.com/matplotlib-scatter-plot-with-distribution-plots-histograms-jointplot/</a></span><span id="2882" class="mw mx it oj b gy or oo l op oq">#set the grid<br/>fig = plt.figure(figsize = (8,8))<br/>gs = GridSpec(4,4)</span><span id="4f34" class="mw mx it oj b gy or oo l op oq">#set the grids fr the catter and the distributions<br/>ax_scatter = fig.add_subplot(gs[1:4, 0:3])<br/>ax_hist_x = fig.add_subplot(gs[0, 0:3])<br/>ax_hist_y = fig.add_subplot(gs[1:4, 3])</span><span id="8229" class="mw mx it oj b gy or oo l op oq">#add the scatter plots<br/>ax_scatter.scatter(<br/>    stores_dataset["residential_pop"],<br/>    stores_dataset["class_1_pop"])</span><span id="a12c" class="mw mx it oj b gy or oo l op oq">#add the histograms<br/>ax_hist_x.hist(stores_dataset["residential_pop"])<br/>ax_hist_y.hist(stores_dataset["class_1_pop"],<br/>              orientation = "horizontal")</span><span id="b727" class="mw mx it oj b gy or oo l op oq">ax_scatter.set_ylabel("Percentage of residents \nclass 1 (%)",<br/>                     fontsize = 20,<br/>                     labelpad = 20)<br/>ax_scatter.set_xlabel("Residential population \nsurrounding stores",<br/>                     fontsize = 20,<br/>                     labelpad = 20)</span><span id="c2ba" class="mw mx it oj b gy or oo l op oq">#show the plot<br/>plt.tight_layout()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/314d37158c005398bd73c48165fd60c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpjxjgkXTmLS1UQmRJTitg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="ff93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由此我们可以清楚地看到，从当前图中没有出现明显的数据组。这可能意味着它可能不是最好的数据，但现在我们将运行它，看看我们会得到什么。</p><p id="e12e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要注意的一个关键问题是，这两个目标变量的规模有很大不同。由于 Kmeans 聚类是一种基于距离的算法，我们需要确保这些值在大致相同的范围和比例内。我们可以使用 sklearn 的定标器套件和归一化算法来实现这一点。因为为了简单起见，这些分布看起来大致是正态的(仅仅是大致的),我们可以如下使用<code class="fe ou ov ow oj b">RobustScaler</code>:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="8f3c" class="mw mx it oj b gy on oo l op oq">#import the necessary scaler<br/>from sklearn.preprocessing import RobustScaler</span><span id="7c75" class="mw mx it oj b gy or oo l op oq">#create the scaler<br/>scaler = RobustScaler()</span><span id="4aa8" class="mw mx it oj b gy or oo l op oq">#create data to transform on<br/>tr_data = stores_dataset[["id", "retailer", "fascia",<br/>                         "store_name", "residential_pop",<br/>                         "class_1_pop"]].copy()</span><span id="83b1" class="mw mx it oj b gy or oo l op oq">#set the columns to transofmr<br/>cols_transform = ["residential_pop",<br/>                 "class_1_pop"]</span><span id="cae4" class="mw mx it oj b gy or oo l op oq">#fit the algorithm to the data<br/>for col in cols_transform:<br/>    tr_data[col] = scaler.fit_transform(tr_data[col].values.reshape(-1,1))</span><span id="ae49" class="mw mx it oj b gy or oo l op oq">#reapet the plot as before<br/>fig = plt.figure(figsize = (8,8))<br/>gs = GridSpec(4,4)</span><span id="e5da" class="mw mx it oj b gy or oo l op oq">ax_scatter = fig.add_subplot(gs[1:4, 0:3])<br/>ax_hist_x = fig.add_subplot(gs[0, 0:3])<br/>ax_hist_y = fig.add_subplot(gs[1:4, 3])</span><span id="0250" class="mw mx it oj b gy or oo l op oq">ax_scatter.scatter(<br/>    tr_data["residential_pop"],<br/>    tr_data["class_1_pop"])</span><span id="3990" class="mw mx it oj b gy or oo l op oq">ax_hist_x.hist(tr_data["residential_pop"])<br/>ax_hist_y.hist(tr_data["class_1_pop"],<br/>              orientation = "horizontal")</span><span id="f650" class="mw mx it oj b gy or oo l op oq">plt.tight_layout()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/4c1cb9219076e14462d9b649f14f6ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5wSLDBJHTQYcRb6JzbwDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9c26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到数据大致符合相同的范围，并遵循大致的正态分布。</p><p id="cfb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是等等，当初不是说不知道要实现多少个集群吗？正确！除非我们有一些理论或者上面数据中突然出现的聚类数，否则我们必须找出聚类数的最佳值。</p><h2 id="e7d5" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated"><strong class="ak">挑选集群数量</strong></h2><p id="fbf6" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">两种主要的方法是“肘图”法和轮廓评分法。</p><p id="c20c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一种方法使用聚类中的<strong class="lb iu">惯性</strong>，它是样本到它们最近的聚类中心的平方距离之和。目的是找到惯性增益开始变平的拐点(添加更多的集群总会有一些增益)，这表明已经达到了最佳的集群数量。为此，我们也可以在这种情况下使用失真值(从各自聚类的聚类中心的平均平方距离)。问题是添加更多集群总会有一些好处，因此不会出现明显的瓶颈。</p><p id="b0dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二种方法试图找到轮廓分数处于最大值的地方。这是因为这是一种衡量数据点与其自己的聚类相比与其他聚类相似程度的方法，值越接近 1，表明聚类分离越好。每个点都可以有自己的轮廓分数，所以我们的目标是找到最大的平均轮廓分数，因为这将建议最佳的聚类数。因此，我们将争取最大的价值。</p><p id="f5f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以按如下方式实现和评估这些功能:</p><ul class=""><li id="7922" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated">对于肘法</li></ul><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="00eb" class="mw mx it oj b gy on oo l op oq">#import the necessary libraries<br/>from sklearn import metrics<br/>from sklearn.cluster import KMeans</span><span id="e82e" class="mw mx it oj b gy or oo l op oq">#create an empty list<br/>list_SSE = []<br/>#set ther ange of clusters to evaluate<br/>min_k = 1<br/>max_k = 10<br/>range_k = range(min_k, max_k)</span><span id="dff5" class="mw mx it oj b gy or oo l op oq">#iterate over the range<br/>for i in range_k:<br/>    #perform the clustering algorithm<br/>    km = KMeans(n_clusters = i,<br/>               init = "random",<br/>               n_init = 10,<br/>               max_iter = 300,<br/>               tol = 1e-04, <br/>                random_state = 22)<br/>    #fit this to the data<br/>    km.fit(tr_data[["residential_pop",<br/>                 "class_1_pop"]])<br/>    #add the SEE score<br/>    list_SSE.append(km.inertia_)</span></pre><ul class=""><li id="6985" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated">为了剪影配乐</li></ul><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="03f8" class="mw mx it oj b gy on oo l op oq">#for the silhouette score<br/>import random</span><span id="9016" class="mw mx it oj b gy or oo l op oq">#create an empty list<br/>silhouette = []</span><span id="9378" class="mw mx it oj b gy or oo l op oq">#iteratre over the number of clusters to evaluate<br/>for i in range(2,10):<br/>    <br/>    #create an empty list to hold the averages<br/>    average = []<br/>    #perform the clustering algorithm several times for each number of clusters<br/>    for x in range(1,10):<br/>        #set the number of clusters<br/>        k_cluster = i<br/>        #generate a arandom seed number<br/>        random_seed = random.randint(1,101)<br/>        #apply the KMeans clustering algorithm<br/>        kmeans_method = KMeans(n_clusters = k_cluster,<br/>                              random_state = random_seed)<br/>        kmeans_method.fit(tr_data[["residential_pop",<br/>                 "class_1_pop"]])<br/>        #extract the labels<br/>        labels = kmeans_method.labels_<br/>        #extract the silhouette score<br/>        a = metrics.silhouette_score(tr_data[["residential_pop",<br/>                 "class_1_pop"]], labels)<br/>        #append the result<br/>        average.append(a)<br/>    #clauclate the average silhouette score for each number of clusters <br/>    silhouette.append(sum(average)/len(average))</span></pre><p id="2e01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两者都可以绘制成:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="ba06" class="mw mx it oj b gy on oo l op oq">#combine both plots<br/>fig, ax = plt.subplots(1,2, figsize = (15,8))</span><span id="4764" class="mw mx it oj b gy or oo l op oq">ax[0].plot(range(2,10), silhouette, marker = "o")<br/>ax[0].set_xlabel("Number of Clusters", fontsize = 20, labelpad = 20)<br/>ax[0].set_ylabel("Silhoute score", fontsize =20, labelpad = 20)<br/>ax[0].set_title("Kmeans silhouette plot", fontsize = 25, pad = 20)</span><span id="6d61" class="mw mx it oj b gy or oo l op oq">ax[1].plot(range_k, list_SSE, marker = "o")<br/>ax[1].set_xlabel("Number of Clusters", fontsize = 20, labelpad = 20)<br/>ax[1].set_ylabel("SSE", fontsize =20, labelpad = 20)<br/>ax[1].set_title("Kmeans Elbow plot", fontsize = 25, pad = 20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/ea8367497d02e72453cab284bdeeedab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Fs01DamgVb6O7JMlFWBDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="8f44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两个图似乎表明，用该数据集实现的聚类的最佳数量是三个聚类(最高轮廓得分和肘图的开始)。当然，尽管模型显示了这些结果，我们需要实际验证它们是否对我们有意义。</p><h2 id="1ba9" class="mw mx it bd my mz na dn nb nc nd dp ne li nf ng nh lm ni nj nk lq nl nm nn no bi translated">评估集群</h2><p id="a2b8" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们可以首先从模型中提取标签，并将其附加到我们的数据集，如下所示:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="c5df" class="mw mx it oj b gy on oo l op oq">#create the model<br/>kmeans_method = KMeans(n_clusters = 3,<br/>                      random_state = 42,<br/>                      n_init = 10)<br/>#fit it to the data<br/>kmeans_method.fit(tr_data[["residential_pop",<br/>                 "class_1_pop"]])<br/>#extract the labels<br/>tr_data["labels"] = kmeans_method.labels_ + 1</span></pre><p id="28aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们可以提取聚类的质心，并将结果绘制为:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="1dcd" class="mw mx it oj b gy on oo l op oq">#extract the centres<br/>centres = pd.DataFrame(kmeans_method.cluster_centers_,<br/>                       columns = ["x", "y"])</span><span id="0001" class="mw mx it oj b gy or oo l op oq">#plot the results<br/>fig, ax = plt.subplots(1,1, figsize = (8,8))</span><span id="24be" class="mw mx it oj b gy or oo l op oq">sns.scatterplot(data = tr_data,<br/>               x = "residential_pop",<br/>               y = "class_1_pop",<br/>               hue = "labels",<br/>               palette = "tab10" )</span><span id="4289" class="mw mx it oj b gy or oo l op oq">sns.scatterplot(data = centres,<br/>               x = "x",<br/>               y = "y",<br/>               marker = "x",<br/>               facecolor = "red",<br/>               s = 200,<br/>               label = "centroids")</span><span id="a5cd" class="mw mx it oj b gy or oo l op oq">ax.legend(fontsize = 20,<br/>         title_fontsize = 20,<br/>         title = "Labels",<br/>         bbox_to_anchor = (1.02, 0.7))</span><span id="5bc9" class="mw mx it oj b gy or oo l op oq">ax.set_ylabel("Class 1 population",<br/>             fontsize = 20,<br/>             labelpad = 20)<br/>ax.set_xlabel("Residential population",<br/>             fontsize = 20,<br/>             labelpad = 20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/79e85a877c85705054dde863cb0c5577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r-GqbSBnfrK92ura40Al6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="4c50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，这是基于转换后的数据，可能很难解释(我们可以开始在转换后的数据上探索这一点，并比较聚类的均值和标准差，但我更喜欢在原始数据集上检查这一点)，因此我们可以在原始数据上应用这一点。由于这是二维地理数据，我们可以在以下位置查看模型:</p><ul class=""><li id="ceb7" class="nu nv it lb b lc ld lf lg li nw lm nx lq ny lu nz oa ob oc bi translated">原始数据</li><li id="febd" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">群体的手段</li><li id="c148" class="nu nv it lb b lc od lf oe li of lm og lq oh lu nz oa ob oc bi translated">地域代表性</li></ul><p id="6895" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看看它们是否有意义。我们可以这样做:</p><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="25dc" class="mw mx it oj b gy on oo l op oq">#add the labels back to the original data<br/>stores_dataset["labels"] = kmeans_method.labels_ + 1</span><span id="6f72" class="mw mx it oj b gy or oo l op oq">#create the base axis<br/>fig, ax = plt.subplots(1,1, figsize = (8,8))</span><span id="19c9" class="mw mx it oj b gy or oo l op oq">#plot the results<br/>sns.scatterplot(data = stores_dataset,<br/>               x = "residential_pop",<br/>               y = "class_1_pop",<br/>               hue = "labels",<br/>               palette = "tab10" )</span><span id="25fc" class="mw mx it oj b gy or oo l op oq">#adjust the legend<br/>ax.legend(fontsize = 20,<br/>         title_fontsize = 20,<br/>         title = "Labels",<br/>         bbox_to_anchor = (1.02, 0.7))</span><span id="5ae4" class="mw mx it oj b gy or oo l op oq">#add the xis labels<br/>ax.set_ylabel("Class 1 population (%)",<br/>             fontsize = 20,<br/>             labelpad = 20)<br/>ax.set_xlabel("Residential population",<br/>             fontsize = 20,<br/>             labelpad = 20)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/5cd73a7841b3c51de5f95954d7990e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_ROnjFlMpbAMyFu_NZ92dw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="3866" class="mw mx it oj b gy on oo l op oq">#extract the columns<br/>columns = ["residential_pop",<br/>          "class_1_pop"]</span><span id="2fed" class="mw mx it oj b gy or oo l op oq">#set the titles<br/>titles = ["Residential population per cluster", <br/>         "Percentage of class 1 population per cluster"]<br/>#set the labels<br/>ylabels = ["Population",<br/>          "Percentage (%)"]</span><span id="a96e" class="mw mx it oj b gy or oo l op oq">#create a base plot<br/>fig, ax = plt.subplots(2,1, figsize = (10,15))<br/>#flatten the axis<br/>axis = ax.flatten()</span><span id="8210" class="mw mx it oj b gy or oo l op oq">#iterate over each column to create plots for each <br/>for i, col in enumerate(columns):<br/>    #create an empty dictionary<br/>    col_dict = {}<br/>    #iterate over each label<br/>    for label in list(stores_dataset["labels"].unique()):<br/>        #crete a new dataframe for each label<br/>        label_df = stores_dataset[stores_dataset["labels"] == label]<br/>        #add the mean to the dataframe<br/>        col_dict[label] = label_df[col].mean()<br/>    #convert the dictionary to a dataframe<br/>    column_df = pd.DataFrame.from_dict(col_dict, orient = "index")<br/>    #reset the index<br/>    column_df.reset_index(inplace=True)<br/>    #sort the values by the index<br/>    column_df.sort_values(by = "index", inplace=True)<br/>    <br/>    #plot the results<br/>    axis[i].plot(column_df["index"], column_df[0],<br/>                marker = "o")<br/>    <br/>    #set the plots up<br/>    axis[i].set_title(titles[i], fontsize = 25, pad = 25)<br/>    axis[i].set_xlabel("Cluster", fontsize = 25, labelpad = 25)<br/>    axis[i].set_ylabel(ylabels[i], fontsize =25, labelpad = 25)<br/>    axis[i].tick_params(axis = "both", labelsize = 20)</span><span id="769f" class="mw mx it oj b gy or oo l op oq">#set the layout to tight so no overalp<br/>plt.tight_layout()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/676a79b82de38e5392b3e1016c6181fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*teBOh3VMpUmBzIW_Xv8jCQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt oi oj ok ol aw om bi"><span id="fe96" class="mw mx it oj b gy on oo l op oq">#create the base axis<br/>fig, ax = plt.subplots(1,1, figsize = (12,12))</span><span id="8db5" class="mw mx it oj b gy or oo l op oq">#plot the boundary<br/>London_outline.boundary.plot(ax = ax,<br/>                        color = "black")</span><span id="b5cd" class="mw mx it oj b gy or oo l op oq">#add the labels<br/>stores_dataset.plot(column = "labels",<br/>                   categorical = True,<br/>                   legend = True,<br/>                   ax = ax,<br/>                   cmap = "tab10",<br/>                   alpha = 0.7,<br/>                   legend_kwds = {"title":"Cluster",<br/>                                 "fontsize":"20",<br/>                                 "title_fontsize":"25"})</span><span id="aeb9" class="mw mx it oj b gy or oo l op oq">#add the basemap<br/>cx.add_basemap(crs = "EPSG:27700",<br/>              ax = ax)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/f78acbc1d2773f7772c3a7c1dd8e7c94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1TPkTJXY7lh8dVf6mcflQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="5b47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据我个人的理解，这些集群可以解释为:</p><h1 id="104f" class="pd mx it bd my pe pf pg nb ph pi pj ne jz pk ka nh kc pl kd nk kf pm kg nn pn bi translated">群组 1 —低密度低收入</h1><p id="735c" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">这个集群中的商店似乎位于伦敦的外围，在低收入地区的相对低密度区域。</p><h1 id="0b89" class="pd mx it bd my pe pf pg nb ph pi pj ne jz pk ka nh kc pl kd nk kf pm kg nn pn bi translated">集群 2 —低密度高收入</h1><p id="e55e" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">这些商店往往位于伦敦市中心附近，事实上有些高度集中在伦敦市中心，尽管它们的当地人口数量与第 1 类商店没有太大区别，但它们往往位于更靠近高收入客户的地方</p><h1 id="c180" class="pd mx it bd my pe pf pg nb ph pi pj ne jz pk ka nh kc pl kd nk kf pm kg nn pn bi translated">集群 3 —高密度商店</h1><p id="ed10" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">这些商店往往集中在靠近伦敦市中心的地方，但不在工作区，因为那里的人口密度较高，因此集中在居民需求上。</p><p id="dcb2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，这些只是解释，我们只使用了数据的一个子集！如果这些集群对你我都有意义，那么我已经完成了我的工作，但是你也可以根据你的目标和受众创建不同数量的集群。我们还可以使用<a class="ae ky" href="https://github.com/UCL-DSS/Kmeans-clustering-workshop/blob/main/Problems.ipynb" rel="noopener ugc nofollow" target="_blank">问题工作簿</a>中的完整数据集，您可以尝试自己解释结果并创建自己的聚类。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="84fa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您想了解我们协会的更多信息，请随时关注我们的社交网站:</p><p id="a976" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">https://www.facebook.com/ucldata<a class="ae ky" href="https://www.facebook.com/ucldata" rel="noopener ugc nofollow" target="_blank">脸书</a></p><p id="a7be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">insta gram:【https://www.instagram.com/ucl.datasci/ T4】</p><p id="6dea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">领英:<a class="ae ky" href="https://www.linkedin.com/company/ucldata/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/company/ucldata/</a></p><p id="1f5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解 UCL 数据科学协会和其他优秀作者的最新信息，请使用我下面的推荐代码注册 medium。</p><div class="mc md gp gr me mf"><a href="https://philip-wilkinson.medium.com/membership" rel="noopener follow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">通过我的推荐链接加入媒体-菲利普·威尔金森</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">philip-wilkinson.medium.com</p></div></div><div class="mo l"><div class="po l mq mr ms mo mt ks mf"/></div></div></a></div><p id="ff71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者看看我的其他商店</p><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/maximum-likelihood-estimation-and-ols-regression-36c049c94a48"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">最大似然估计和 OLS 回归</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">介绍他们的关系和工作方式</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="pp l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/an-introduction-to-object-oriented-programming-for-data-scientists-879106d90d89"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">面向数据科学家的面向对象编程介绍</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">面向对象的基础知识，适合那些以前可能没有接触过这个概念或者想知道更多的人</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="pq l mq mr ms mo mt ks mf"/></div></div></a></div><div class="mc md gp gr me mf"><a rel="noopener follow" target="_blank" href="/the-use-of-list-dictionary-and-set-comprehensions-to-shorten-your-code-66e6dfeaae13"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd iu gy z fp mk fr fs ml fu fw is bi translated">使用列表、字典和集合理解来缩短代码</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">在使用 Python 将近一年的时间里，我经常遇到“理解”这个词，但不一定…</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="pr l mq mr ms mo mt ks mf"/></div></div></a></div></div></div>    
</body>
</html>