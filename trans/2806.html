<html>
<head>
<title>Machine Learning On A Large Scale</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大规模的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-on-a-large-scale-2eef3bb749ee#2022-06-18">https://towardsdatascience.com/machine-learning-on-a-large-scale-2eef3bb749ee#2022-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="db5f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">PySpark中二项式和多项式逻辑回归的演示</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3ad7f0ddd8a3dc5e4f869ef4bf5f7bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i2ldZkI0bpP-6tCU"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">戴维·尤斯科在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ed42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着本文本地部署的Spark 3.2.1的发布，PySpark提供了一个流畅的API，类似于<a class="ae kv" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的表达能力，但还提供了分布式计算的好处。本文演示了如何使用pyspark.ml模块在spark数据帧上构建ml管道(而不是使用旧的pyspark.mllib模块构建rdd)。使用二项式和多项逻辑回归来举例说明该功能，不可否认，这不是最先进的机器学习算法。尽管如此，它们的简单性使它们成为演示PySpark机器学习API的理想选择。对于不熟悉PySpark机器学习的读者，以及更熟悉早期版本的Spark，尤其是pyspark.mllib模块的读者，本教程可能会感兴趣。</p><p id="3319" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">目录</strong></p><p id="50ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="#2366" rel="noopener ugc nofollow">设定场景</a> <br/> <a class="ae kv" href="#cb21" rel="noopener ugc nofollow">二项逻辑回归</a> <br/> ∘ <a class="ae kv" href="#942a" rel="noopener ugc nofollow">准备工作</a> <br/> ∘ <a class="ae kv" href="#ea64" rel="noopener ugc nofollow">首次建模尝试</a> <br/> ∘ <a class="ae kv" href="#8a85" rel="noopener ugc nofollow">评估模型质量</a> <br/> ∘ <a class="ae kv" href="#caf5" rel="noopener ugc nofollow">交叉验证和超参数调优</a> <br/> ∘ <a class="ae kv" href="#6609" rel="noopener ugc nofollow">模型解释</a> <br/> <a class="ae kv" href="#c53a" rel="noopener ugc nofollow">多项逻辑回归</a> <br/> <a class="ae kv" href="#a329" rel="noopener ugc nofollow">结论</a></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="2366" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">设定场景</strong></h1><p id="0902" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我们首先通过分配8gb内存和四个内核来创建一个spark会话</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="091e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的代码还包含整篇文章所需的所有pyspark导入。当涉及到其他软件包时，我们将根据需要使用更多的进口产品。</p><p id="2a14" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用通过<code class="fe my mz na nb b">df = sns.load_dataset('iris')</code>从<a class="ae kv" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> seaborn </a>获得的虹膜数据集。这是一个著名的数据集，包含四个连续的特征，即属于三个不同物种的150朵鸢尾花的萼片和花瓣的长度和宽度:<em class="nc">鸢尾</em>、<em class="nc">杂色鸢尾</em>和<em class="nc">海滨鸢尾</em>。数据集没有空值，并且所有要素的比例都相当合理，但我们稍后将回到这一点。</p><p id="29d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，这是一个非常小的数据集，绝不需要分布式计算。然而，鉴于本文的目的是说明PySpark机器学习API，选择一个小数据集进行实验是理想的，特别是在使用交叉验证进行超参数调整时，正如我们在本文中所做的那样。使用一个基本的机器学习算法和一个小的、相当干净的数据集并没有打破数据科学的新前沿，但这些选择是有意的。</p><p id="9a1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了了解分类的效果，我们使用<code class="fe my mz na nb b">sns.pairplot(df, hue='species')</code>在数据集中绘制成对关系，给出</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/02cb47130af157e5894f6cf4bde14700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7nyiyralkoFoUm3lf6n79A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:数据集中要素的成对关系</p></figure><p id="d52a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">粗略地看一下，我们可以看到<em class="nc">鸢尾</em>可能被正确分类，但我们预计在区分<em class="nc">杂色鸢尾</em>和<em class="nc">海滨鸢尾</em>时会有一些困难。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="cb21" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">二项逻辑回归</strong></h1><p id="ef89" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">为简单起见，我们将对二项式和多项式逻辑回归使用相同的数据集。对于二元分类，我们试图预测该物种是<em class="nc">海滨鸢尾</em>还是<em class="nc">海滨鸢尾</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0693" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从这一点开始，所有操作都将在PySpark中进行，将pandas数据帧转换成PySpark数据帧</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="ee75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">自动转换自动生成了预期的模式。</p><h2 id="942a" class="ne ma iq bd mb nf ng dn mf nh ni dp mj lf nj nk ml lj nl nm mn ln nn no mp np bi translated">准备工作</h2><p id="85da" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">PySpark使用转换器和估算器将数据转换为机器学习功能:</p><ul class=""><li id="7713" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">转换器是一种可以将一个数据帧转换成另一个数据帧的算法</li><li id="c7a6" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">估计器是一种算法，它可以适用于数据帧以产生变换</li></ul><p id="3ff3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以上意味着变压器不依赖于数据。机器学习模型是一个转换器，它获取具有特征的数据帧，并通过其<code class="fe my mz na nb b">.transform()</code>方法产生包含预测的数据帧。另一方面，估计器有一个<code class="fe my mz na nb b">.fit()</code>方法，它接受数据帧并产生一个转换器。PySpark中的流水线链接了ML工作流中的多个转换器和估算器。scikit-learn的用户一定会有宾至如归的感觉！</p><p id="26bb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回到我们的数据集，我们构造第一个转换器，将四个特征打包成一个向量</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="e0a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">features列看起来像一个数组，但它是一个向量。方便的是，向量组装器还会填充模式中features列的元数据属性</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="169a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还可以检索原始特征的列名，尽管使用<code class="fe my mz na nb b">feature_assembler.getInputCols()</code>可能会更方便。</p><p id="4ffe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管这些特征或多或少是成比例的，但是如果我们确保所有特征的范围从0到1，那么拟合的逻辑回归系数的解释将变得容易。这可以使用最小-最大缩放器估计器来实现</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="fbea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码中，<code class="fe my mz na nb b">minMax_scaler_model</code>是一个通过将<code class="fe my mz na nb b">minMax_scaler</code>估计器与数据相匹配而产生的转换器。使用矢量可以方便地一次性缩放所有连续要素。顺便提一下，<code class="fe my mz na nb b">pyspark.ml.feature</code>模块包含了<code class="fe my mz na nb b">vector_to_array()</code>和<code class="fe my mz na nb b">array_to_vector()</code>函数来转换向量和数组，所以像<code class="fe my mz na nb b">minMax_scaler</code>这样的估计器也可以用于机器学习之外的数据转换。</p><p id="f721" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原则上，features_scaled和species列现在可用于拟合逻辑回归模型。然而，在此之前，我们将引入另一个概念，ML管道，它可用于编排ML工作流</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="5a52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果和以前一样，但是代码更简洁。管道在技术上是一个估计器，并有一个返回转换器的<code class="fe my mz na nb b">.fit()</code>函数。在幕后，装配一个管道调用用于变压器的<code class="fe my mz na nb b">.transform()</code>函数和用于估计器的<code class="fe my mz na nb b">.fit()</code>函数，按照它们在管道阶段被引入的顺序。在实践中，我们可以用不同的变压器和估算器构建多条管道，并通过构建模型来试验我们的选择的效果。</p><h2 id="ea64" class="ne ma iq bd mb nf ng dn mf nh ni dp mj lf nj nk ml lj nl nm mn ln nn no mp np bi translated">首次建模尝试</h2><p id="8123" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在调整模型和评估其准确性之前，先做一个粗略的尝试，看看最终得到一个合理模型的可能性有多大，这是很有用的。为此，我们不使用交叉验证，我们只指定必需的模型参数，其余的都保留默认值。</p><p id="1485" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先要做的是增加一个管道阶段，即使用一个<code class="fe my mz na nb b">StringIndexerModel</code>将物种列从字符串转换为数值</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="4ff2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为这是以后需要的。或者，我们可以使用<code class="fe my mz na nb b">StringIndexer</code> <a class="ae kv" href="https://spark.apache.org/docs/latest/ml-features.html#stringindexer" rel="noopener ugc nofollow" target="_blank">估计器</a>通过使用数据创建模型，并根据物种名称的频率分配指数。我们选择不这样做，因为我们想确保<em class="nc"> Iris virginica </em>映射到1.0，而不是<em class="nc"> Iris virginica </em>映射到0.0。然后，我们将数据集分成训练集和测试集</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="a43f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将种子指定为一种良好的实践，尽管在Spark世界中，由于数据的底层分区，这并不能确保确定性行为。如果你对这个令人难以置信的话题感到好奇，下面的实验可以说明这个问题</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="ed01" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以在这篇<a class="ae kv" href="https://medium.com/udemy-engineering/pyspark-under-the-hood-randomsplit-and-sample-inconsistencies-examined-7c6ec62644bc" rel="noopener">文章</a>中阅读更多内容，包括如何避免这个问题的想法，例如，通过缓存整个数据集而不仅仅是训练集(如下所述)。存储训练集和测试集并再次读取它们以构建模型是确保确定性行为的另一种方式。请注意，训练数据集在任何情况下都应该被缓存，因为在拟合模型时会重复使用它。这可能是Spark中最典型的缓存用例。</p><p id="493d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">剩下的唯一事情就是拟合模型并评估其准确性。为了完整起见，提供了整个代码，这样更容易理解</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="b451" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了方便起见，我们使用<code class="fe my mz na nb b">pyspark.ml.feature.IndexToString()</code>将预测的数值转换回标签。请注意，我们只使用了萼片宽度和花瓣宽度作为自变量。此外，我们只使用了20%的数据集进行训练。这些奇怪选择的原因是，这个机器学习问题实际上非常容易解决，因此我们几乎总是不费吹灰之力就能获得一个好的模型。通过丢弃一些特征和使用一个小的训练集，我们从一开始就计算出不完美的度量。</p><p id="1ebe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在有了对测试集的预测，并且可以一瞥我们做得有多好。</p><h2 id="8a85" class="ne ma iq bd mb nf ng dn mf nh ni dp mj lf nj nk ml lj nl nm mn ln nn no mp np bi translated">评估模型质量</h2><p id="52ef" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">也许获得关于二项式分类模型性能的概念的最常见方法是计算<a class="ae kv" href="https://medium.com/@shivangisareen/confusion-matrix-3ac02a1719ba" rel="noopener">混淆矩阵</a>。在PySpark中，这可以很容易地用</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="067b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用seaborn中带注释的热图，混淆矩阵也可以很容易地可视化</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="e6c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">产生了</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/fbec88ce4ec5b4427371a6840e08bf31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*KxqjkgwIcj_6fMF-GBRJ1A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:混淆矩阵</p></figure><p id="cd9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您尝试跟随，由于训练集和测试集的不同划分，您可能会获得稍微不同的结果。</p><p id="45ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多可以计算的指标，但我列出了与稍后的ROC曲线计算相关的最重要的指标:</p><ul class=""><li id="9c9e" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated"><strong class="ky ir">召回率、灵敏度或真阳性率:</strong>反映模型识别阳性的能力，定义为TP/(TP+FN)</li><li id="60cb" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><strong class="ky ir">精度或阳性预测值</strong>:显示预测阳性为真阳性的频率，定义为TP/(TP+FP)</li><li id="39fd" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><strong class="ky ir">特异性或真阴性率</strong>:反映模型识别阴性的能力，定义为TN/(TN+FP)</li><li id="f40f" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><strong class="ky ir">假阳性率</strong>:反映假阳性的概率，定义为FP/(TN+FP)= 1-特异性</li></ul><p id="3925" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在计算出混淆矩阵后，这些度量很容易手动计算。或者，为了方便起见，也可以使用PySpark API</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="a42d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">测试集的受试者操作者特征(ROC)曲线可从<code class="fe my mz na nb b">metrics.roc</code>中检索，但我们也将使用原始概率手动计算。我们使用seaborn来可视化这两种方法的结果</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="bd29" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">产生了</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/581331aa21312533d97ef25883442115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*spMiH5z85zPBkwB6ifv-mg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3: ROC曲线。曲线从(0。, 0.)对应于等于1的阈值。这意味着每个预测都是负面的。曲线在(1)处结束。, 1.)对应于等于0的阈值。，这意味着每个预测都是正面的。</p></figure><p id="3897" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不建议手动计算ROC曲线，原因有几个，包括对性能的担忧。然而，考虑到基于数据帧的PySpark机器学习API是新的，文档还不完善，所以要小心谨慎。建议检查结果是否有意义，以确保正确使用API。PySpark API还可以返回精确召回(PR)曲线，这在类非常不平衡时很有用。ROC曲线的目的是选择阈值，以实现所需的灵敏度和特异性。阈值可视为模型的<a class="ae kv" href="https://alonhzn.medium.com/the-fallacy-of-an-roc-curve-on-a-test-set-c96d8fdf774" rel="noopener">参数，与所有参数一样，它不应在测试集上计算，而应在训练集上计算，或者更好的是，在验证集上计算(见下一节)。PySpark API通过<code class="fe my mz na nb b">lr_model.summary.roc</code>和<code class="fe my mz na nb b">lr_model.summary.pr</code>为训练集曲线提供ROC和PR曲线。</a></p><p id="1073" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ROC曲线也用于计算ROC曲线指标下的面积。完美模型的ROC曲线会接近左上角，而随机模型会接近对角线(真阳性率=假阳性率)。ROC曲线下的面积介于0。并且可以通过一个<code class="fe my mz na nb b">BinaryClassificationEvaluator</code>对象来计算</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="f757" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果令人印象深刻，尽管试图阻碍模型质量。训练集的ROC曲线下的面积可从模型摘要中获得<code class="fe my mz na nb b">lr_model.summary.areaUnderROC.</code><code class="fe my mz na nb b">BinaryClassificationEvaluator</code>对象也可用于计算PR曲线下的面积。</p><h2 id="caf5" class="ne ma iq bd mb nf ng dn mf nh ni dp mj lf nj nk ml lj nl nm mn ln nn no mp np bi translated">交叉验证和超参数调整</h2><p id="d184" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">与大多数其他模型一样，逻辑回归模型具有可以微调的参数，以优化模型的准确性和稳健性。上一节描述了第一次建模的尝试，这种尝试走了很多弯路。我们对逻辑回归模型的所有参数使用默认值，并通过将原始数据集分成两部分来简化模型开发，一部分用于训练，一部分用于测试。这是一个很好的开始方式，以便获得可以实现的第一个想法。一旦我们确信我们有可能产生一个可行的模型，我们就可以使用交叉验证来优化模型的参数。这是一个昂贵的手术。首先，对于一组给定的模型参数，我们对模型进行多次拟合和评估(这就是所谓的折叠)。其次，我们尝试许多不同的模型参数集。本节给出了使用4重交叉验证的二项式逻辑回归的完整代码，并作为PySpark中其他机器学习模型如何训练和优化的示例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/70354b7aeb5c59c012ecded54c7e30ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1nY9ggfI88vfuPl38Eo9Xg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:将原始数据集分成训练集、验证集和测试集(图片由作者提供)</p></figure><p id="8ccd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">交叉验证需要三个构件:</p><ul class=""><li id="63ee" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">估计器(模型)，通常封装在ML管道中</li><li id="f3ad" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">我们试图调整的超参数网格</li><li id="9f6d" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated">一个评估度量，本质上是超参数调整的目标函数</li></ul><p id="681f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，我们使用早期设置的管道。我们将微调逻辑回归模型的两个<a class="ae kv" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html#pyspark.ml.classification.LogisticRegression" rel="noopener ugc nofollow" target="_blank">参数</a>，即</p><ul class=""><li id="b81a" class="nq nr iq ky b kz la lc ld lf ns lj nt ln nu lr nv nw nx ny bi translated">弹性净混合参数<a class="ae kv" href="https://www.statlearning.com/" rel="noopener ugc nofollow" target="_blank">α</a>(α= 0表示L2惩罚，α-1表示L1惩罚)，以及</li><li id="c72c" class="nq nr iq ky b kz nz lc oa lf ob lj oc ln od lr nv nw nx ny bi translated"><a class="ae kv" href="https://www.statlearning.com/" rel="noopener ugc nofollow" target="_blank">正则化参数</a></li></ul><p id="e170" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这听起来可能很奇怪，但是我们也将通过调整传递给向量汇编器的特性来使用超参数调优来选择特性。对于这个例子来说，这有点牵强，但是我选择这样做是为了表明所有管道阶段的所有参数原则上都可以包含在微调中。参数组合的数量迅速增长，实际上运行时间的限制抑制了热情。</p><p id="fcb6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用的评估器是在不同折叠的平均验证集上计算(正确)的ROC曲线下的面积。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="59df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网格搜索检查了165个参数组合，每个组合都适合并评估了四个模型。尽管iris数据集与Spark通常处理的数据集相比非常小，但这花费了大约350秒。每个参数组合的ROC曲线下的平均面积可以用<code class="fe my mz na nb b">cv_model.avgMetrics</code>来检索，这表明几个组合达到了近乎完美的度量(ROC曲线下的面积~=1。).可以用<code class="fe my mz na nb b">cv_model.bestModel</code>从中检索最佳模型(不确定当两组参数表现相同时Spark如何选择最佳模型，但这在现实世界用例中不太可能发生)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="51a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有拟合的模型被存储，并可通过<code class="fe my mz na nb b">cv_model.subModels[k][i]</code>检索，其中k是折叠，I是参数网格中参数集的索引。在我们的例子中，对于i=4获得了最好的结果，并且对应于四个折叠的4个模型可以通过<code class="fe my mz na nb b">[cv_model.subModels[k][4] for k in range(4)]</code>获得。我们应该检查不同褶皱的系数分布，这是模型<a class="ae kv" href="https://stats.stackexchange.com/questions/253605/do-average-coefficients-in-k-fold-cross-validation-resemble-coefficients-when-tr" rel="noopener ugc nofollow" target="_blank">稳定性</a>的指示，甚至使用最佳超参数再次拟合整个训练集。这超出了本文的范围。我们将使用与<code class="fe my mz na nb b">cv_model.bestModel</code>一起返回的最佳模型，无需进一步调查。</p><h2 id="6609" class="ne ma iq bd mb nf ng dn mf nh ni dp mj lf nj nk ml lj nl nm mn ln nn no mp np bi translated">模型解释</h2><p id="bf41" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">也许令人惊讶的是，通过仅使用萼片和花瓣宽度而不进行正则化，我们获得了一个非常好的模型。线性模型的系数和截距可以很容易地恢复</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="78d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并储存在熊猫系列中。方便的是，vector assembler将特征名称存储为可用于设置系列索引的模式元数据。这些特征已经过最小-最大缩放，有助于解释。花瓣宽度的影响大约是萼片宽度的4倍。</p><p id="4468" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个特殊的情况:超参数调整碰巧只保留了两个特征，而没有必要进行正则化。这允许可视化决策边界，唯一的复杂性是特征缩放的处理</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="7bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">产生了</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/af6a8d10ebf2e8fa0f326e0b6b205e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*d4ByzL7rSFmis4OPhl1D5A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:最佳模型的决策边界</p></figure><p id="9bd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图5显示了训练集(意味着除测试集之外的所有数据点)，我们可以看到有一个假阴性和两个假阳性(一个几乎在决策边界上)，这与训练集的混淆矩阵一致。一切看起来都很好。</p><h1 id="c53a" class="lz ma iq bd mb mc og me mf mg oh mi mj jw oi jx ml jz oj ka mn kc ok kd mp mq bi translated"><strong class="ak">多项逻辑回归</strong></h1><p id="68a0" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">PySpark还支持<a class="ae kv" href="https://spark.apache.org/docs/latest/ml-classification-regression.html" rel="noopener ugc nofollow" target="_blank">多项式</a>逻辑回归(softmax)，因此可以一次性预测虹膜数据集的所有类别。我们不会涵盖所有细节，因为这篇文章已经很长了。下面是首次尝试拟合多项式逻辑回归模型的完整代码</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="0130" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们再次获得了一个良好的模型与第一次尝试。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a329" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated"><strong class="ak">结论</strong></h1><p id="d6fd" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">机器学习是一个广阔的领域。解决问题需要设计功能、选择模型、决定使用哪个指标进行超参数调整，并设计一个策略通过改变参数来最大化该指标。本文不提供以上问题的答案，而是重点介绍如何使用PySpark最新的机器学习API。构建模型从来都不是一个线性的过程，熟悉<code class="fe my mz na nb b">pyspark.ml</code>模块提供的功能是加速实验的良好起点。大规模构建模型从未如此简单！</p></div></div>    
</body>
</html>