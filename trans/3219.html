<html>
<head>
<title>Train a Neural Network to Detect Breast MRI Tumors with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch训练神经网络检测乳腺MRI肿瘤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-a-neural-network-to-detect-breast-mri-tumors-with-pytorch-250a02be7777#2022-07-18">https://towardsdatascience.com/train-a-neural-network-to-detect-breast-mri-tumors-with-pytorch-250a02be7777#2022-07-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ed51" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">医学图像分析实用教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/b961b20216bf1faa9703bab0cd5703ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*LNqXEbe_PYfEW9uSVG3kWQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来自我们数据集的乳腺MRI扫描示例。</p></figure><p id="5a20" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">大多数具有深度学习的计算机视觉研究都是在常见的自然图像数据集上进行的，如<a class="ae ln" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>、<a class="ae ln" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>和<a class="ae ln" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>。然而，计算机视觉的一个重要应用领域是医学图像分析，其中深度学习已用于癌症检测、器官分割、数据协调和许多其他示例等任务。然而，与自然图像数据集相比，医学图像数据集通常更容易“插入”深度学习系统。在这里，我提供了一个实用的分步指南，介绍如何使用深度学习来完成一个简单的医学图像分析任务，从数据采集一直到模型测试。</p><p id="ef0f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇文章中，我将展示如何使用PyTorch训练一个神经网络分类器来检测乳腺MRI图像中的肿瘤。在我之前的文章中(在我实验室的博客上找到了<a class="ae ln" href="https://sites.duke.edu/mazurowski/2022/07/13/breast-mri-cancer-detect-tutorial-part1/" rel="noopener ugc nofollow" target="_blank">,我介绍了我实验室公开的乳腺MRI数据集，以及如何使用Python与原始医学成像数据进行交互。我演示了如何以一种格式和标签提取和排序图像文件，这将有助于用PyTorch训练和测试我们的模型。该数据集最初出现在论文中:</a></p><p id="5521" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="lo"> Saha，a .，Harowicz，M.R .，Grimm，L.J .，Kim，C.E .，Ghate，S.V .，Walsh，r .和Mazurowski，M.A .，2018。</em> <strong class="kt ir"> <em class="lo">乳腺癌放射基因组学的机器学习方法:对922名受试者和529个DCE-MRI特征的研究。</em> </strong> <em class="lo">《英国癌症杂志》，第119卷第4期，第508–516页。(这篇论文的免费版本可以在这里找到:</em><a class="ae ln" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6134102/" rel="noopener ugc nofollow" target="_blank"><em class="lo">PMC 6134102</em></a><em class="lo">)</em></p><p id="c2dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有了我们的数据，我们可以继续构建、训练和测试我们的深度分类器。除了在计算机视觉中测量分类器性能(总预测精度)的典型方法之外，我还将展示如何使用医学图像分析常用的度量来进一步分析我们的模型的性能。</p><p id="443b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本教程的所有代码可以在这里找到<a class="ae ln" href="https://github.com/mazurowski-lab/MRI-deeplearning-tutorial" rel="noopener ugc nofollow" target="_blank"/>；需要一些Python方面的经验，PyTorch知识是有帮助的，但不是必需的。</p><h1 id="fc04" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">(1)建立数据加载管道</h1><p id="2851" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">深度学习是数据驱动的，因此拥有一个可靠的框架来处理(图像)数据至关重要。py torch(Python中的<code class="fe mm mn mo mp b">torch</code>和<code class="fe mm mn mo mp b">torchvision</code>库)允许对数字矩阵进行有效的操作和管理，是最流行的深度学习框架之一(因为神经网络通过许多矩阵乘法和加法进行操作和学习)。图像也可以用大的数字矩阵来描述，其中矩阵的维数对应于图像的大小，矩阵的每个元素是一个像素强度值。因此，使用PyTorch对所有图像数据加载/处理和神经网络操作进行抽象是非常有帮助的，py torch附带了无数方便的模块和工具来实现这些功能。</p><p id="69df" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用的中心对象是<code class="fe mm mn mo mp b">torch.utils.data</code>的<code class="fe mm mn mo mp b">Dataset</code>和<code class="fe mm mn mo mp b">DataLoader</code>。虽然<code class="fe mm mn mo mp b">Dataset</code>允许轻松存储和索引数据样本和标签，但<code class="fe mm mn mo mp b">DataLoader</code>使我们能够以一种与我们将如何训练和测试神经网络非常好地集成的方式轻松访问这些样本。详情请见PyTorch的<a class="ae ln" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html" rel="noopener ugc nofollow" target="_blank">教程</a>。首先，让我们导入所需的库和对象:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="56d7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，让我们定义一些常数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="02f8" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">数据集</h1><p id="4745" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">首先，我们必须为DBC数据集定义我们自己的<code class="fe mm mn mo mp b">Dataset</code>，称为<code class="fe mm mn mo mp b">DBCDataset</code>。总之，<code class="fe mm mn mo mp b">DBCDataset</code>中定义的重要方法有:</p><ol class=""><li id="930d" class="ms mt iq kt b ku kv kx ky la mu le mv li mw lm mx my mz na bi translated"><code class="fe mm mn mo mp b">create_labels()</code>方法为数据集中的每个图像分配一个易于访问的标签，</li><li id="e3d9" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated"><code class="fe mm mn mo mp b">normalize()</code>方法将图像标准化到像素值范围<code class="fe mm mn mo mp b">[0,255]</code>，因为标准化数据对于深度学习很重要，</li><li id="5f51" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated"><code class="fe mm mn mo mp b">__getitem__()</code>方法是<code class="fe mm mn mo mp b">Dataset</code>所必需的，它描述了如何从带有一个(或多个)索引的数据集中获取数据</li></ol><p id="294b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">查看下面的代码块，我在其中添加了注释来解释每一步。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="1056" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从这里，我们可以简单地创建一个数据集实例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="e4bf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="0218" class="nk lq iq mp b gy nl nm l nn no">building DBC dataset labels. <br/>5200</span></pre><h1 id="088b" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">训练集、验证集和测试集:区别是什么？</h1><p id="2ea2" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">为了开发我们的分类模型，我们需要将数据集分成训练集、验证集和测试集。对于数据点中的每个图像，都有一个我们希望分类模型预测的关联标签。但是这些数据子集之间有什么区别呢？</p><ol class=""><li id="b846" class="ms mt iq kt b ku kv kx ky la mu le mv li mw lm mx my mz na bi translated">定型集用于为模型提供如何进行预测的示例；这就是模型“学习”的内容。学习算法只是修改神经网络参数，以最小化训练集的平均预测误差。</li><li id="31f3" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated">验证集用于评估模型在预测未学习的新数据标签方面的表现(开发该模型的最终目标，也称为<em class="lo">泛化</em>)。此验证预测误差用于选择我们希望在训练中的哪一点保存模型:我们希望在验证误差最低时保存模型。您也可以使用验证集来选择<em class="lo">超参数</em>或不是从训练集中学习的训练算法设置。</li><li id="2c04" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated">测试集和验证集一样，也用于估计神经网络对新数据的<em class="lo">泛化能力</em>；但是，这必须与验证集分开，因为验证集本身是用来选择最终模型的，我们需要对泛化能力的无偏估计</li></ol><p id="bcea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于2600 + 2600 = 5200的数据集大小，用于将数据集划分为训练/验证/测试的一组典型百分比可能是80%/10%/10%，这导致训练集大小为4160，验证和测试集大小分别为520。实际上，我们可以使用有用的函数<code class="fe mm mn mo mp b">torch.utils.data.random_split()</code>从我们的数据集中提取这些子集，该函数随机地将整个数据集分成子集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="0a2b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="92a7" class="nk lq iq mp b gy nl nm l nn no">5200 <br/>4160 520 520</span></pre><h1 id="9df1" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">数据加载器</h1><p id="18a2" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我们已经创建了PyTorch <code class="fe mm mn mo mp b">Dataset</code>用于模型训练、验证和测试，这是我们数据加载管道的大部分工作。最后，我们需要创建PyTorch <code class="fe mm mn mo mp b">Dataloader</code>来方便地访问数据集中的图像。但是首先，快速注意一下<em class="lo">批次大小</em>。</p><h2 id="ddb4" class="nk lq iq bd lr np nq dn lv nr ns dp lz la nt nu mb le nv nw md li nx ny mf nz bi translated">批量大小和计算设备</h2><p id="55af" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">虽然我们可以一次对一张图像训练神经网络，但这将非常慢，因为它们通常需要多次从数百或数千张图像中学习。相反，我们可以同时对<em class="lo">批</em>多幅图像进行训练，受限于我们计算处理设备的存储容量；例如，GPU(图形处理单元)，它是专门为图像处理而设计的。</p><p id="109b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下面，我们将为三个数据子集分别创建<code class="fe mm mn mo mp b">Dataloaders</code>。对于训练集，我们将使用200的批量大小，但这在很大程度上取决于您用于计算的CPU或GPU硬件。对于大多数现实的计算机视觉应用程序来说，GPU是必需的，因为CPU非常慢；因此，我们将使用8 GB的英伟达GTX 1070。我们将在其上加载数据的设备可以通过以下方式指定:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="18d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="edd6" class="nk lq iq mp b gy nl nm l nn no">running on cuda</span></pre><p id="566d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，让我们创建我们的数据加载器:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="9776" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，为了确保我们的结果具有可重复性，我们将使用以下方法修复所有随机种子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="6ba2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有了这些，我们就可以开始介绍和构建我们的分类神经网络了！</p><h1 id="ea53" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">(2)加载神经网络</h1><p id="b507" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">神经网络实际上只是具有许多许多参数的函数(也就是拨号调谐)。这些参数是<em class="lo">从大量数据中学习到的</em>来调整网络，以最佳地逼近我们试图模拟的功能。例如，像我们将使用的图像分类神经网络，被训练以图像作为输入，并输出图像的正确类别身份，例如，乳房图像是否是癌性的。神经网络的许多连续计算<em class="lo">层</em>允许它们学习非常复杂的功能，这实际上是不可能手工设计的。</p><p id="defd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">卷积神经网络是专门为学习检测图像中的空间模式而设计的，因此特别适合我们的任务。今天，我们将使用一种非常流行的现代神经网络架构，称为残差网络，简称为<em class="lo"> ResNet </em>。事实上，根据谷歌学术的说法，最初的<a class="ae ln" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet论文</a>是有史以来被引用最多的论文之一，截至2022年6月已被引用超过120，000次。我们将使用ResNet <em class="lo">模型</em>的一个特定版本，称为ResNet-18，其细节超出了本教程的范围。ResNet-18和类似的模型可以很容易地用PyTorch的<code class="fe mm mn mo mp b">torchvision.models</code>库加载(未经训练),如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="d6e0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这里我们也导入了PyTorch的神经网络库<code class="fe mm mn mo mp b">torch.nn</code>。接下来，我们将加载一个ResNet-18来使用(因为<code class="fe mm mn mo mp b">resnet18</code>是一个类):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="42b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">ResNets设计用于处理彩色三通道图像。然而，我们的MRI切片是单通道的，所以我们需要修改我们的<code class="fe mm mn mo mp b">net</code>来接受单通道输入。这可以通过将<code class="fe mm mn mo mp b">net</code>的<em class="lo">输入层</em>修改为:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="4e67" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们需要将网络加载到我们的计算设备上:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="627a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这样，我们的网络就可以接受训练，对我们的图像进行分类。让我们建立一个培训管道！</p><h1 id="fb4e" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">(3)为培训做准备</h1><p id="8e41" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">神经网络通过最小化对整个训练集进行预测的平均误差来“学习”。在训练集上的每次迭代，或<em class="lo">时期</em>，调整参数以便在下一次迭代中表现得更好。每个参数的变化由<em class="lo">反向传播</em>算法决定，该算法调整每个参数，使给定迭代的误差在平均值上最大程度地降低(该过程被称为<em class="lo">随机梯度下降</em>或“SGD”)。</p><p id="229b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了实现这一点，我们需要定义几件事情。首先，我们必须定义这个预测误差，也称为<em class="lo">损失</em>。对于分类的任务，我们需要的损失是<code class="fe mm mn mo mp b">nn.CrossEntropyLoss()</code>，随着网络预测训练集中更多不正确的图像分类，损失增加。这是我们在训练中要尽量减少的；我们可以将其定义为:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="f6ed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们要定义我们将使用的<em class="lo">误差最小化</em>算法；同样，这个<em class="lo">是随机梯度下降</em>，或SGD当然还有其他的，但是SGD是最基本的，也很好。当创建一个SGD实例时，我们需要告诉它我们将最小化哪些参数(参数<code class="fe mm mn mo mp b">net</code>，和<em class="lo">学习率</em>)。学习率(<code class="fe mm mn mo mp b">lr</code>)是一个固定的常数，它基本上决定了在学习过程中对参数进行调整的大致大小。根据任务、数据、网络和其他因素，可以选择不同的学习速率，但现在，我们将选择<code class="fe mm mn mo mp b">lr=0.001</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="e9b9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，让我们将训练时期的数量(通过整个训练集)设置为100:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="a4ad" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">(4)训练和验证你的模型！</h1><p id="2af5" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我们现在拥有了训练分类模型所需的一切。如前所述，在每个训练时期，我们可以评估验证数据集上的模型，以估计它在看不见的数据上的表现如何。然后，我们将最终训练的模型保存为在训练期间在验证集上发现具有最佳性能/分类准确性的模型。</p><p id="9806" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了在实践中做到这一点，我们可以创建我们的培训模型<code class="fe mm mn mo mp b">net</code>的副本，并将其保存为一个单独的网络<code class="fe mm mn mo mp b">net_final</code>。让我们继续初始化它:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="d981" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们可以用下面的代码(每一步都有注释)创建并运行我们的训练循环。在实践中，我们将使用分类准确度作为预测误差的度量，即给定数据集中被网络正确分类的图像的百分比。需要处理的一个微妙之处是，网络实际上输出了输入图像在每个类别中的概率<em class="lo">。同样地，单个预测类仅由最高概率类给出。</em></p><p id="3e86" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们还可以为训练集和验证集存储我们的精度与时期数据，以便观察模型如何通过训练演变。</p><p id="63e2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好吧，让我们开始训练我们的模型吧！这可能需要一些时间，取决于您的计算设备的强度。我还包含了一些代码来记录训练的每一步。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="4ae2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="8b93" class="nk lq iq mp b gy nl nm l nn no">### Epoch 0:<br/>21it [00:16,  1.30it/s]<br/>Training accuracy: 0.23557692307692307<br/>100%|████████████████████████████████████████████████████████████████| 52/52 [00:01&lt;00:00, 29.09it/s]</span><span id="6f9a" class="nk lq iq mp b gy oa nm l nn no">Validation accuracy: 0.5153846153846153<br/>Validation accuracy improved; saving model.</span><span id="b5c7" class="nk lq iq mp b gy oa nm l nn no">### Epoch 1:<br/>21it [00:15,  1.37it/s]<br/>Training accuracy: 0.5454326923076923<br/>100%|████████████████████████████████████████████████████████████████| 52/52 [00:01&lt;00:00, 28.46it/s]</span><span id="0382" class="nk lq iq mp b gy oa nm l nn no">Validation accuracy: 0.551923076923077<br/>Validation accuracy improved; saving model.</span></pre><p id="bafe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">…(未显示线路)…</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="6150" class="nk lq iq mp b gy nl nm l nn no">### Epoch 98:<br/>21it [00:14,  1.40it/s]<br/>Training accuracy: 0.9992788461538461<br/>100%|████████████████████████████████████████████████████████████████| 52/52 [00:01&lt;00:00, 29.27it/s]</span><span id="8e52" class="nk lq iq mp b gy oa nm l nn no">Validation accuracy: 0.925<br/>Validation accuracy improved; saving model.</span><span id="dfb5" class="nk lq iq mp b gy oa nm l nn no">### Epoch 99:<br/>21it [00:15,  1.39it/s]<br/>Training accuracy: 0.9992788461538461<br/>100%|████████████████████████████████████████████████████████████████| 52/52 [00:01&lt;00:00, 28.57it/s]</span><span id="ed72" class="nk lq iq mp b gy oa nm l nn no">Validation accuracy: 0.9230769230769231</span></pre><p id="0fb7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们通过<code class="fe mm mn mo mp b">matplotlib</code>用一个简单的图表来看看我们的模型的性能是如何随着时间的推移而发展的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="520c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/4b9cf413845374db74e9127db5da211f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*N4DKGaaMRd2XHcfolK1_4Q.png"/></div></figure><p id="12c3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦完全训练，该模型获得了92.5%的验证准确性，这意味着在520个图像的验证集中，它正确地将其中的大约480个分类为癌症或非癌症。</p><p id="637d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可能还会注意到模型过度适应了训练集。这可以通过某种正则化来缓解，但是这超出了本入门教程的范围。</p><p id="b1e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这种性能很好，但是我们只有通过在测试集上对模型进行评估，才能知道模型对新数据进行分类的真正能力，如下所示。</p><h1 id="1172" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">(5)测试你的最佳模型</h1><p id="e304" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">现在我们的模型已经训练好了，它在测试集上表现如何？我们可以用下面的代码来测试这一点，这里我还展示了一些分类的例子；这与我们在验证集上的评估非常相似。</p><h2 id="ee0b" class="nk lq iq bd lr np nq dn lv nr ns dp lz la nt nu mb le nv nw md li nx ny mf nz bi translated">医学图像分析中分类器性能的度量</h2><p id="92bb" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">在医学图像分析中，为了更好地分析分类器的表现，除了单独的分类精度之外，通常还要报告更多的性能指标。<em class="lo">假阳性</em> (FP)是当分类器将阴性(无癌症)图像错误分类为阳性时，而<em class="lo">真阳性</em> (TP)是当阳性图像被正确分类时。让我们在代码中也估算一下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="0dbd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出:</p><pre class="kg kh ki kj gt ng mp nh ni aw nj bi"><span id="b7fd" class="nk lq iq mp b gy nl nm l nn no">Example Images: <br/>Target labels: [0, 0, 0, 1, 1, 1, 0, 0, 1, 0] <br/>Classifier predictions: [0, 0, 0, 1, 1, 1, 0, 0, 1, 0] <br/>Test set accuracy: 0.9442307692307692<br/>238 true positive classifications, 19 false positive classifications</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oc"><img src="../Images/631eae66f6fb400bb0dceacc263133a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mswYCPPoJdJsWlJSDwzNw.png"/></div></div></figure><p id="e520" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们的520个未知样本的测试集上，我们得到了癌症检测任务的94.4%的预测准确率，或者只有大约30个错误分类！在257个阳性(癌症)检测中，238个或约93%是真阳性(正确)，而19个(约7%)是假阳性(不正确)。</p><h1 id="030b" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">讨论</h1><p id="4f08" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">为医疗成像等安全关键型应用设计自动化方法时，检查可能的风险和限制至关重要。这方面的一个例子是假阳性的可能性:如果像这样的癌症检测模型被用于临床，阳性检测将立即保证对患者的进一步研究，因此假阳性可能是误导的。一个相关的可能性是假的<em class="lo">阴性</em>:肿瘤被检测模型完全遗漏。虽然我们的模型总体上具有很高的预测准确性，但它并不完美，因此不应该完全信任所有的诊断决策。这就是为什么计算机辅助诊断(CAD)设备的开发目标的常见范例是帮助而不是取代放射科医师。</p><p id="5ef5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">同样重要的是要记住，用深度学习训练的模型完全是数据驱动的:它们完全根据训练集的标签进行学习。例如，在本教程中，我选择通过将3D MRI扫描的每个2D切片分配到阳性(包含乳腺肿瘤注释)或阴性类别来标记数据集。然而，即使来自3D扫描的一些切片被发现是阴性的，这并不<em class="lo">而不是</em>表明整个扫描/患者的癌症是阴性的:扫描中可能有其他切片是<em class="lo">阳性的</em>。这是一个例子，说明计算机辅助设计系统所做的所有预测都应该清楚地、可量化地表述出来。</p><p id="2124" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有许多可能的补充可以用来改进这个检测模型。正如我们在第(4)节的训练演化图中看到的，我们的模型似乎过度适应训练集(由训练准确性和验证准确性之间的差距来指示)。这可以通过一些技术来减轻或防止；参见<a class="ae ln" href="https://atcold.github.io/pytorch-Deep-Learning/en/week14/14-3/" rel="noopener ugc nofollow" target="_blank">这篇教程</a>，它很好地介绍了如何在PyTorch中做到这一点。我们可以做的另一个改进是训练我们的模型，不要将每个2D MRI切片分类为在某处有肿瘤<em class="lo"/>，而是精确地<em class="lo">定位</em>切片内任何可能的肿瘤；在计算机视觉中被称为<em class="lo">物体检测</em>的任务。我在这篇文章中没有探讨这个问题，因为对象检测是一个比分类更微妙的问题，但它肯定可以用我们的数据集来实现，因为它包含肿瘤位置标签/边界框。快速R-CNN对象检测模型的PyTorch实现可能是一个很好的起点。</p><h1 id="12de" class="lp lq iq bd lr ls lt lu lv lw lx ly lz jw ma jx mb jz mc ka md kc me kd mf mg bi translated">结论</h1><p id="269d" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">在本教程中，我展示了如何在我们的DBC-MRI数据集上使用PyTorch通过深度学习来训练乳房MRI分类模型。</p><p id="0a75" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我的实验室博客上的前一篇文章中，我介绍了DICOM医学成像数据类型，展示了如何从癌症成像档案中获取数据，以及如何从数据中提取对PyTorch有用的图像。</p><p id="154c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇文章中，我展示了如何在真实的乳腺MRI数据上加载、训练和测试分类神经网络。</p><p id="9596" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我写这些博客文章是为了提供一个介绍性的例子，说明如何将神经网络用于医学图像分析的实际应用。这仅仅触及了深度学习的广泛医学图像分析(MIA)应用的表面。对于有兴趣了解更多信息的人，请查看:</p><ol class=""><li id="d388" class="ms mt iq kt b ku kv kx ky la mu le mv li mw lm mx my mz na bi translated">MICCAI会议的最新会议记录。</li><li id="a703" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated"><a class="ae ln" href="https://www.journals.elsevier.com/medical-image-analysis" rel="noopener ugc nofollow" target="_blank">医学影像分析</a>和<a class="ae ln" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=42" rel="noopener ugc nofollow" target="_blank">医学影像汇刊</a>期刊。</li><li id="7b1f" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated">我实验室的<a class="ae ln" href="https://sites.duke.edu/mazurowski/" rel="noopener ugc nofollow" target="_blank">网站</a>，以及<a class="ae ln" href="https://scholar.google.com/citations?user=HlxjJPQAAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">我实验室的导师</a>和<a class="ae ln" href="https://scholar.google.com/citations?user=a9rXidMAAAAJ&amp;hl=en" rel="noopener ugc nofollow" target="_blank">本人</a>的学术出版物。</li><li id="b095" class="ms mt iq kt b ku nb kx nc la nd le ne li nf lm mx my mz na bi translated">我的<a class="ae ln" href="https://twitter.com/KickNonz" rel="noopener ugc nofollow" target="_blank">推特</a>和<a class="ae ln" href="https://twitter.com/MazurowskiLab" rel="noopener ugc nofollow" target="_blank">我实验室的推特</a>。</li></ol><p id="e217" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>