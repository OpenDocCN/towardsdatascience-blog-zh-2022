<html>
<head>
<title>Visual Question Answering with DeepProbLog Using Neuro-Symbolic AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经符号人工智能的DeepProbLog视觉问答</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visual-question-answering-with-deepproblog-using-neuro-symbolic-ai-621099805bc7#2022-10-04">https://towardsdatascience.com/visual-question-answering-with-deepproblog-using-neuro-symbolic-ai-621099805bc7#2022-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="22e6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于视觉问答的神经符号人工智能与纯神经网络方法的比较</h2></div><p id="0a6c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文重点关注视觉问题回答，其中将具有知识库的神经符号人工智能方法与纯粹基于神经网络的方法进行了比较。从实验中可以看出，用于神经符号人工智能方法的框架<a class="ae le" href="https://github.com/ML-KULeuven/deepproblog" rel="noopener ugc nofollow" target="_blank"> DeepProbLog </a>能够实现与基于纯神经网络的方法相同的准确性，而迭代次数几乎减少了200倍。显然，这种训练更有针对性，但也是有代价的。DeepProbLog内部的代数运算符非常昂贵，因此实际的训练时间要慢得多。DeepProbLog的另一个缺点是无法轻松实现加速，因为代数运算符只在CPU上工作(至少目前是这样)，因此无法从GPU等加速器中受益。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/d87770da5a712717a8a4e015ba95213f.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*5HvT6psiAPRYqo527jQNpA.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图片由<a class="ae le" href="https://pixabay.com/users/marquetand-3570369/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5076887" rel="noopener ugc nofollow" target="_blank"> Philipp Marquetand </a>来自<a class="ae le" href="https://pixabay.com//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=5076887" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><h1 id="7600" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">1.介绍</h1><p id="610d" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">神经符号人工智能领域感兴趣的是在概率知识的鲁棒性和深度神经网络的众所周知的普及性和已证实的优势之间建立一座桥梁。DeepProbLog [1]通过利用<strong class="kk iu">神经网络</strong>(即系统1，典型的潜意识任务，如视觉识别、语言处理……)的优势，以及<strong class="kk iu">基于规则的概率系统</strong>(即系统2，缓慢、有序的思维，如证明的推导)[2]的优势，提供了这种能力。</p><blockquote class="mo mp mq"><p id="f9ec" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">本文详细阐述了一个需要使用这两个系统的应用程序，即视觉问答。需要系统1来理解被研究的图像，特别是它们的形状和颜色。另一方面，系统2将使用该提取的信息来导出对象的某些属性(例如，找到绿色对象的形状)，或者甚至用于捕捉对象之间的关系(例如，计算图像中的圆的数量)。</p></blockquote></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="59dd" class="lr ls it bd lt lu nc lw lx ly nd ma mb jz ne ka md kc nf kd mf kf ng kg mh mi bi translated">2.文学</h1><p id="2de7" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">该应用程序侧重于视觉问题回答(VQA)，其中存在巨大的数据集，以及非常复杂的方法。VQA最著名的数据集是CLEVR [3]，它包含10万张图片和100万个问题。下面给出了一个示例图像，而示例问题是:</p><ul class=""><li id="e123" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld nm nn no np bi translated">大型物体和金属球体的数量相等吗？</li><li id="137d" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">大球体左边的棕色金属物体的左边的圆柱体有多大？</li><li id="09e0" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">有多少物体不是小圆柱体就是金属的东西？</li></ul><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi nv"><img src="../Images/4828e72846011aa5e06444b394580837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJiXoPzfe5OloMuDVfEbPQ.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图CLEVR数据集的样本图像[3]</p></figure><blockquote class="mo mp mq"><p id="1a8a" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">显然，在回答这些问题时，系统1和系统2都被积极地使用。人们可能会想，在没有明确的系统2编码(即，基于规则的知识库)的情况下，神经网络是否能够独自回答这些问题。直觉上，如果知道世界上的某些事实，学习会进行得更快。从优化的角度来看，在这种设置中，预测期间产生的误差可以被精确地瞄准，这使得优化过程也更有针对性，因此更有效。最后，本文还为这些说法提供了证据，因为在第4.1小节中，VQA实现与DeepProbLog之间的比较是用一种纯粹基于神经网络的方法进行的。</p></blockquote><p id="97ea" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文受CLEVR数据集的启发，但是使用了一个更加简化的版本。本质上，它几乎就像是一个分类数据集[4]。CLEVR分类数据集包含如图2所示的图像，同时提出如下问题:</p><ul class=""><li id="0601" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld nm nn no np bi translated">非关系型问题:物体的形状、水平或垂直位置。</li><li id="4e1f" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">关系问题:离被调查物体最近/最远的物体的形状，或者具有相同形状的物体的数量。</li></ul><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/02aed710a18bb3b3c45050ed98aa2c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*vAh8tZ8uydRj1NNEc3Ttaw.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图2:来自分类数据集的样本图像[4]</p></figure><blockquote class="oa"><p id="66fe" class="ob oc it bd od oe of og oh oi oj ld dk translated">如前所述，这些类型的VQA需要系统1和系统2。</p></blockquote><p id="0646" class="pw-post-body-paragraph ki kj it kk b kl ok ju kn ko ol jx kq kr om kt ku kv on kx ky kz oo lb lc ld im bi translated">A.桑托罗等人用本文中的Sort-of-CLEVR数据集进行了类似的实验，他们能够在CNN的关系问题上达到63%的准确率。相比之下，CNN的关系型和非关系型问题的准确率都达到了94%，并辅以RN。对他们来说，用一个关系模块，比如一个RN，来扩充模型，结果足以克服解决关系问题的障碍[4]。他们是唯一在与本文相似的数据集上进行实验的研究人员，因此是唯一的参考点。</p><p id="86d3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，由于这个应用程序使用DeepProbLog，所以花了相当多的时间来消化DeepProbLog文章[1]，以及理解代码库中提供的示例[5]。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="8948" class="lr ls it bd lt lu nc lw lx ly nd ma mb jz ne ka md kc nf kd mf kf ng kg mh mi bi translated">3方法</h1><p id="616b" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">实施过程包括三个主要部分:</p><ol class=""><li id="65d5" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld op nn no np bi translated">数据的生成</li><li id="9170" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld op nn no np bi translated">用纯Python代码链接数据和控制训练过程。</li><li id="a596" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld op nn no np bi translated">用DeepProbLog语句创建逻辑部分。</li></ol><h2 id="0949" class="oq ls it bd lt or os dn lx ot ou dp mb kr ov ow md kv ox oy mf kz oz pa mh pb bi translated">3.1数据的生成</h2><blockquote class="mo mp mq"><p id="f0a1" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">如第2节所述，本应用程序中使用的数据基于Sort-of-CLEVR数据集，并进行了额外的简化。假设逻辑部分将必须决定对象是否例如位于图像的左侧，则神经网络将必须向逻辑部分传送位置信息。因此，每个离散的位置必须由神经网络的可能结果编码。因此，对象可能只位于网格中的特定位置。在本文中，将讨论2x2和6x6网格上的结果。</p></blockquote><p id="294c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用于创建分类数据集的数据生成器已经过修改，以便将对象定位在上述网格位置[4]。图3给出了一个生成图像的例子，与图2的区别在于网格布局。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/0f8495b5b1f58fb57726b0e61c5ab8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*v9g_PSXOs7VMvloYgWCRwg.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图3:这个应用程序使用的数据集的样本图像</p></figure><p id="9a1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每种指定的颜色都有一个位于网格中某处的对象，其形状可以是正方形或圆形。这些图像附有一个关于随机对象的问题，可以是以下内容之一:</p><ul class=""><li id="8429" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld nm nn no np bi translated">非相关—这个对象的形状是什么(正方形或圆形)？</li><li id="4276" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">非相关—该对象是否位于图像的左侧<br/>？</li><li id="4048" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">非相关—该对象是否位于图像的底部<br/>侧？</li><li id="11c6" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">相关——有多少物体与<br/>这个物体具有相同的形状？</li></ul><p id="1d95" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些问题以矢量编码方式进行编码，然后与预期答案一起存储在CSV文件中。为了使训练过程更有效，已经预先生成了训练和测试数据集。</p><h2 id="20ba" class="oq ls it bd lt or os dn lx ot ou dp mb kr ov ow md kv ox oy mf kz oz pa mh pb bi translated">3.2控制培训过程</h2><p id="cdc8" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">整个训练过程是通过DeepProbLog的Python API以及CNN的一般PyTorch实现来控制的。首先，CNN是用PyTorch定义的。使用相对简单的网络，其中输入作为100像素宽的正方形RGB图像给出，由CNN转换成6x6网格的72个输出特征(对于2x2网格的例子，需要8个输出特征)。图像中出现的每种颜色都有其伴随的CNN网络，因此72个输出特征用该颜色编码了物体的可能位置，以及它们的形状，可以是正方形或圆形(6 6 2 = 72)。</p><p id="93d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在开始训练过程之前，最后一件事(除了逻辑规则编码之外)是数据加载器。这里最具挑战性的部分是从生成的数据到特定查询映射及其结果的转换。</p><h2 id="200a" class="oq ls it bd lt or os dn lx ot ou dp mb kr ov ow md kv ox oy mf kz oz pa mh pb bi translated">3.3逻辑规则编码</h2><p id="e86b" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">一旦属于特定颜色的CNN已经确定了该对象的位置和形状，逻辑规则就可以推断出该对象是否位于图像的左侧、底部，以及有多少对象具有相同的形状。逻辑规则程序可以在相关的Github中找到，链接在本文的底部。显示了一个示例片段:</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="pc pd l"/></div></figure></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="1c18" class="lr ls it bd lt lu nc lw lx ly nd ma mb jz ne ka md kc nf kd mf kf ng kg mh mi bi translated">4次实验</h1><blockquote class="mo mp mq"><p id="c9a8" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">本文的主要重点是概述使用神经符号人工智能方法(由DeepProbLog框架提供)的优势，而不是纯粹的基于神经网络的方法。因此，必须实施基于神经网络的方法。这里不会列出所有细节，但主要思想是图像必须与问题融合，然后才能做出预测。该网络的一般结构如图4所示。</p></blockquote><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi pe"><img src="../Images/56c3bfc277d3ab911229168d7966a95a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*exo0pezWwkGU2xWGp2P5tg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图4:纯神经网络架构的抽象表示[6]</p></figure><h2 id="5bb7" class="oq ls it bd lt or os dn lx ot ou dp mb kr ov ow md kv ox oy mf kz oz pa mh pb bi translated">4.1与纯系统1方法的比较</h2><ul class=""><li id="438d" class="nh ni it kk b kl mj ko mk kr pf kv pg kz ph ld nm nn no np bi translated">实验— 2x2网格:</li></ul><p id="d4e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图5和图6分别显示了DeepProbLog方法和纯神经网络方法的损耗曲线。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/6cd22866d4847ae092954622d081dcf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*e2dXqTEkP4nbqvzhw10z7Q.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图5: DeepProbLog 2x2:损耗曲线</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/19440c6e9f92ef4cc61a0980da62f303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*yXWt5jBAm_Tu4GSm4-4H2w.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图6:基于纯神经网络的方法2x2:损耗曲线</p></figure><blockquote class="mo mp mq"><p id="94ad" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">一个非常重要的注释是“迭代次数”和“纪元次数”之间的区别。迭代次数意味着一批(大小为32)的向前和向后传递的次数，而时期数表示训练集的所有图像向前和向后传递的次数。在该应用中，使用了10 000的训练大小，因此一个时期由312.5次迭代组成。</p></blockquote><p id="34d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从损失曲线可以清楚地看出，这两种方法似乎都达到了100%的精度。然而，DeepProbLog只需要大约40次迭代，而基于纯神经网络的方法至少需要7 800次迭代。这再次证明了神经符号人工智能的价值。</p><p id="1e4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，我们必须考虑这些迭代的实际运行时间。DeepProbLog需要大约10分钟来完成它的160次迭代，而纯粹基于神经网络的方法只需要大约5分钟来完成7 800次迭代。考虑到纯粹基于神经网络的方法可以被大规模加速(通过使用GPU)，而DeepProbLog不能，很明显DeepProbLog训练<strong class="kk iu">更有针对性</strong>，但<strong class="kk iu">计算量极大</strong>(至少目前如此)。</p><blockquote class="mo mp mq"><p id="b3d0" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">请注意，DeepProbLog提供了将CNN发送到GPU以进行更快推断的能力，但是，DeepProbLog的算术运算符(即半环)在CPU上工作。这些算术运算符拥有最高的计算成本。</p></blockquote><ul class=""><li id="ec4f" class="nh ni it kk b kl km ko kp kr nj kv nk kz nl ld nm nn no np bi translated">实验— 6x6网格:</li></ul><p id="dbfd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepProbLog的6x6实验和基于神经网络的方法的损耗曲线分别如图7和图8所示。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/cba923cecb45e21c39248719dc87aa53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*OuSAJC4AqCa2bDoZ4Cz6RQ.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图7: DeepProbLog 6x6:损耗曲线</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/42dd2992bcf5b1b1a06dd4ea54f8d878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*JHYLtodV4T2pBkl-IyIAZw.png"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图8:基于纯神经网络的方法6x6:损耗曲线</p></figure><p id="90b7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这些实验中，基于纯神经网络的方法的训练时间为<strong class="kk iu"> 20分钟</strong>(为了公平的速度估计，已经在CPU上进行了训练)，而DeepProbLog方法的训练时间略低于<strong class="kk iu">八小时</strong>。</p><p id="6731" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，应该提到的是，每次大约有一半的时间花费在计算准确性上，因为整个测试集必须通过网络转发，而对于训练迭代来说，这只是一个批次。</p><blockquote class="mo mp mq"><p id="dd86" class="ki kj mr kk b kl km ju kn ko kp jx kq ms ks kt ku mt kw kx ky mu la lb lc ld im bi translated">这里最重要的观察是，纯神经网络方法很快过拟合，并且也实现了相当低的准确度(DeepProbLog的68%而不是75%)。另一个重要的注意事项是，这两种方法显然不再能够达到100%的准确度。然而，如果DeepProbLog网络可以训练更长时间，它将能够进一步收敛。</p></blockquote><p id="56fb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在图9和图10中，描述了混淆矩阵，以显示典型错误发生的位置。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi pj"><img src="../Images/1870d8fc60d96097f0e32673249518ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zg3XE70tiWAovRYuwTyJzg.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图9:来自DeepProbLog的6x6数据集的混淆矩阵</p></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="nw nx di ny bf nz"><div class="gh gi pk"><img src="../Images/5cc203b21543f03fb31d5d52da7a4486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BF7zCbx42Vigrw_LMBdXGA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">图10:来自纯神经网络方法的6x6数据集的混淆矩阵</p></figure><p id="8cdc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">DeepProbLog自然不会犯任何“无意义”的错误，比如对“正在研究的物体是什么形状？”这个问题回答“是”，因为可能的正确答案已编码在程序中。然而，基于纯神经网络的方法已经很好地学会了将问题的可能答案联系起来。</p><p id="d802" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个观察结果是，DeepProbLog在回答“正在研究的物体是什么形状？”这个问题时要好得多以及“物体是位于图像的左侧(还是底部)？”比纯粹的神经网络方法更有效。这是有意义的，因为一旦给定对象的位置(和形状)被确定，DeepProbLog可以使用其<strong class="kk iu">知识库</strong>来导出这些属性。a .桑托罗等人[4]也观察到，基于纯神经网络的方法很难区分这些情况，在这些问题上，他们采用基于纯神经网络的方法实现了63%的准确率。DeepProbLog无法实现这些研究人员通过添加RN模块在所有问题上实现的94%的准确性，这可能是由于代数运算符的固有培训成本，以及由于资源较少、超参数调整较少和缺少RN模块等许多其他未知变量。</p><p id="a161" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于关系问题:“有多少物体与被研究的物体具有相同的形状？”这两种方法都存在更多的混乱。DeepProbLog通常能够接近正确的答案，但可能会犯一些<strong class="kk iu">“一个接一个”的错误</strong>(即一个CNN错误地预测了其对象的形状)。从这个角度来看，基于纯神经网络的方法也稍差一些。还有一种可能是，在这种方法中，神经网络可能已经观察到，由于概率原因，可能有三个或四个相同的对象(包括正在研究的对象)，因此更喜欢这样的答案。</p></div><div class="ab cl mv mw hx mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="im in io ip iq"><h1 id="55f9" class="lr ls it bd lt lu nc lw lx ly nd ma mb jz ne ka md kc nf kd mf kf ng kg mh mi bi translated">5个结论</h1><p id="8e74" class="pw-post-body-paragraph ki kj it kk b kl mj ju kn ko mk jx kq kr ml kt ku kv mm kx ky kz mn lb lc ld im bi translated">神经符号人工智能领域的优势已经在视觉问题回答的背景下得到证明。通过使用DeepProbLog，为神经符号人工智能任务选择的框架，很明显，几乎需要<strong class="kk iu"> 200倍的迭代</strong>来实现与纯粹基于神经网络的方法相同的准确性。然而，由于<strong class="kk iu">昂贵的代数运算符</strong>，与纯粹基于神经网络的方法相比，DeepProbLog方法的总训练时间要慢得多<strong class="kk iu"/>。</p><blockquote class="oa"><p id="dd74" class="ob oc it bd od oe pl pm pn po pp ld dk translated">值得注意的是，DeepProbLog在非关系问题上表现得更好。这是因为知识库可以更准确地推导出这些属性，而基于纯神经网络的方法在这种推导上有更多的困难。</p></blockquote><p id="40bd" class="pw-post-body-paragraph ki kj it kk b kl ok ju kn ko ol jx kq kr om kt ku kv on kx ky kz oo lb lc ld im bi translated">因此，尽管代数运算代价高昂，但神经符号人工智能方法仍有很多价值。特别是对于知识库非常大的任务，这些方法可以决定是否能够学习某项任务。随着时间的推移，这些代数运算符的加速可能会得到发展，这为更多的应用开辟了道路。</p><h1 id="bc17" class="lr ls it bd lt lu lv lw lx ly lz ma mb jz mc ka md kc me kd mf kf mg kg mh mi bi translated">参考</h1><ul class=""><li id="7475" class="nh ni it kk b kl mj ko mk kr pf kv pg kz ph ld nm nn no np bi translated">[1] R. Manhaeve，A. Kimmig，s . duman ci，T. Demeester，L. De Raedt，“Deepproblog: <a class="ae le" href="https://arxiv.org/abs/1907.08194v2" rel="noopener ugc nofollow" target="_blank">神经概率逻辑编程”，载于《神经信息处理系统进展</a>，2018-Decem卷，第3749-3759页，2018年7月，doi:10.48550/arxiv.1907.08194，URL:<a class="ae le" href="https://arxiv.org/abs/1907.08194v2" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1907.08194v2【T10</a></li><li id="4841" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">[2] D .卡尼曼，《思考，快与慢》，企鹅出版社，伦敦，2012年。</li><li id="4ecd" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">[3] J. Johnson，l .飞飞，B. Hariharan，C. L. Zitnick，L. Van Der Maaten，R. Girshick，“CLEVR:一个用于组合语言和基本视觉推理的诊断数据集”，会议录-第30届IEEE计算机视觉和模式识别会议，CVPR 2017年，第2017卷-Janua，第1988-1997页，2017年，doi:10.1109/cvpr . 2017 . 2017 . 2017 . 2017</li><li id="3842" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">[4] K. Heecheol，“<a class="ae le" href="https://github.com/kimhc6028/relational-networks" rel="noopener ugc nofollow" target="_blank">kimhc 6028/Relational-Networks:py torch实现“用于关系推理的简单神经网络模块”(Relational Networks) </a>，URL:【https://github.com/kimhc6028/relational-networks】<a class="ae le" href="https://github.com/kimhc6028/relational-networks" rel="noopener ugc nofollow" target="_blank"/>，许可证:BSD 3-Clause</li><li id="fad4" class="nh ni it kk b kl nq ko nr kr ns kv nt kz nu ld nm nn no np bi translated">[5] R. Manhaeve，“<a class="ae le" href="https://github.com/ML-KULeuven/deepproblog" rel="noopener ugc nofollow" target="_blank">ML-KULeuven/Deepproblog:DeepProbLog是ProbLog的扩展，通过引入神经谓词将概率逻辑编程与深度学习相结合。</a>”，网址:<a class="ae le" href="https://github.com/ML-KULeuven/deepproblog" rel="noopener ugc nofollow" target="_blank">https://github.com/ML-KULeuven/deepproblog</a>，许可证:Apache 2.0<br/>【6】c . Theodoropoulos，“信息检索与搜索引擎[H02C8b]项目视觉问答”，托莱多，第1–5页，2022。</li></ul><p id="3cf2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除非另有说明，所有图片均为作者所有。</p><blockquote class="oa"><p id="1e8e" class="ob oc it bd od oe pl pm pn po pp ld dk translated">属于这篇文章的代码可以在这里找到<a class="ae le" href="https://github.com/JorritWillaert/Capita-Selecta-Neuro-Symbolic-AI/tree/master/deepproblog/src/deepproblog/examples/SORTOFCLEVR" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote></div></div>    
</body>
</html>