<html>
<head>
<title>The Intuition Behind the Use of Expectation Maximisation to Train Record Linkage Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用期望最大化来训练记录关联模型背后的直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-intuition-behind-the-use-of-expectation-maximisation-to-train-record-linkage-models-5d7ac9f019ca#2022-10-14">https://towardsdatascience.com/the-intuition-behind-the-use-of-expectation-maximisation-to-train-record-linkage-models-5d7ac9f019ca#2022-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8e52" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">如何使用无监督学习来估计Splink中的模型参数</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/fa5c23759ca760ba379898cf5a4ddc39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jf9kuTASzzNvF_bwONzqQA.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">由<a class="ae kw" href="https://unsplash.com/@scw1217?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">苏珊·威廉姆斯</a>在<a class="ae kw" href="https://unsplash.com/s/photos/emerge?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5876" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Splink 是一个免费的概率记录连接库，可以预测两个记录引用同一个实体的可能性。比如下面两条记录匹配的概率是多少？</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lt"><img src="../Images/cf5880b18f9baa9be43c424e61370bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oNKlv-3mjJ1UdK_EF4Z7rQ.png"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">成对记录比较示例</p></figure><p id="6da3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">潜在的统计模型被称为Fellegi Sunter模型。它通过计算部分匹配权重来工作，部分匹配权重是在计算匹配概率时不同列的重要性的度量。例如，在上面的例子中,“Smith”的匹配没有“email”的匹配重要。</p><p id="262a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">然而，在训练记录链接模型的问题的核心有一个悖论:为了估计模型的参数，您需要知道哪些记录匹配。但是找到匹配的记录是你要解决的全部问题。手动标记比较容易出错且成本高，因此不是一个好的选择。</p><p id="2d18" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">期望最大化(EM)算法为这个悖论提供了一个解决方案。这篇文章直观地解释了这是如何工作的，以及如何在我们的大规模记录链接软件<a class="ae kw" href="https://github.com/moj-analytical-services/splink" rel="noopener ugc nofollow" target="_blank"> Splink </a>中实现的一些细节。有关更正式的处理方式，请参见<a class="ae kw" href="https://imai.fas.harvard.edu/research/files/linkage.pdf" rel="noopener ugc nofollow" target="_blank"> FastLink论文。</a></p><h1 id="439c" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">新兴市场方法</h1><p id="1aa7" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">记录关联模型的参数——m和u概率——可以分别从匹配记录和非匹配记录的集合特征中计算出来。(如果这个术语不熟悉，推荐阅读<a class="ae kw" href="https://www.robinlinacre.com/maths_of_fellegi_sunter/" rel="noopener ugc nofollow" target="_blank">这篇博文</a>。)一旦知道了这些值，模型通常就能够准确地预测哪些记录匹配。</p><p id="c1d3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">EM方法的关键是利用匹配和不匹配形成两个相当不同的“集群”这一事实:</p><ul class=""><li id="e0d8" class="mr ms iq kz b la lb ld le lg mt lk mu lo mv ls mw mx my mz bi translated">在匹配记录中，两个记录中大多数或所有列的信息通常是匹配的。</li><li id="2991" class="mr ms iq kz b la na ld nb lg nc lk nd lo ne ls mw mx my mz bi translated">在不匹配记录中，两个记录中大多数或所有列的信息通常不匹配</li></ul><p id="3e3a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这导致记录比较的双峰分布:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi nf"><img src="../Images/8449d550c4c369bd22ff3a2e8a9ec2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TII5QtArQnCs9w6Q"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">成对记录比较的双峰分布的概念图。作者图解。</p></figure><p id="e4cb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">匹配和不匹配之间的这种分离意味着，提出一个能够正确识别大多数匹配和大多数不匹配的粗略决策规则是相对容易的。例如，我们可以简单地计算匹配的列数(名字和姓氏，等等)，并预测超过一半匹配的记录对的匹配。</p><p id="6061" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">既然我们已经将每个记录比较指定为匹配或不匹配，我们可以计算模型的隐含m和u参数。这使我们能够使用以下算法迭代地改进该决策规则:</p><p id="7474" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">期望步骤:</strong>使用估计的模型参数来预测哪些记录比较是匹配的</p><p id="4d1f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">最大化步骤:</strong>使用预测来重新估计模型参数</p><p id="7619" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这个例子中，我们最初的决策规则通过简单地计算具有匹配信息的列的数量来工作。因此，我们对每一列都给予了同等的重视。显然，这条规则还有改进的空间——在现实中，邮政编码列的匹配比性别的匹配更重要。</p><p id="0de0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">期望最大化过程将立即开始学习这些权重，因为它将认识到，在不匹配的情况下，有许多记录比较在性别上匹配，但在邮政编码上匹配的很少。这将在重新计算的m和u概率中表示，并且在下一次迭代中，将对邮政编码的匹配给予更大的权重。</p><p id="f02e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在每次迭代中，决策规则将随着模型错误的减少而改进，权重也因此变得更加准确。</p><p id="e77b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当参数估计稳定，并且在迭代之间参数估计不再有任何变化时，收敛发生。</p><p id="3f5e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">事实证明，这种算法相当于最大化Fellegi-Sunter模型的似然函数(尽管注意，它只能保证收敛到局部最大值，而不一定是全局最大值)。</p><h1 id="43df" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">EM方法如何在Splink中实施</h1><p id="a650" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">在Splink中，对上述过程进行了一些修改，在实践中，这些修改导致更快的收敛和收敛到全局最大值的更大可能性。</p><h2 id="2c93" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">估计u概率</h2><p id="066e" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">虽然有可能使用EM方法估计u概率，但我们建议使用Splink中的<a class="ae kw" href="https://moj-analytical-services.github.io/splink/linker.html#splink.linker.Linker.estimate_u_using_random_sampling" rel="noopener ugc nofollow" target="_blank">替代估计程序</a>，该程序通常更准确。</p><p id="5417" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">回想一下，u概率表示我们在真正不匹配的记录中观察到匹配列的概率。例如，我们观察到两个不同的人有相同的名字的巧合有多频繁？</p><p id="ad8e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们可以通过随机两两比较记录来估计u概率，假设它们不匹配，并计算这些巧合发生的频率。由于两个随机记录相匹配(代表同一实体)的概率通常很低，因此这将产生u值的良好估计。</p><p id="05ae" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这种方法的另一个好处是，如果u概率是正确的，它“锚定”EM估计过程，并大大提高它收敛到全局最大值而不是局部最大值的机会。</p><h2 id="6ba6" class="ng lv iq bd lw nh ni dn ma nj nk dp me lg nl nm mg lk nn no mi lo np nq mk nr bi translated">起始值和初始决策边界</h2><p id="9145" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">在上文中，我们为EM的第一步建议了一个简单的决策规则:计算匹配列的数量，并将超过一半的字段匹配的任何比较指定为匹配。</p><p id="c1a5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">实际上，有可能从通常更准确的决策规则开始，从而导致更快的收敛。具体来说，初始决策规则使用已经使用上述随机抽样程序估计的u个概率，以及m个概率的“合理默认”初始值。</p><p id="6f9b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">你可以在我们的一些<a class="ae kw" href="https://moj-analytical-services.github.io/splink/examples_index.html" rel="noopener ugc nofollow" target="_blank">示例笔记本</a>中看到所有这些在实践中的工作。</p><h1 id="f376" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="91b9" class="pw-post-body-paragraph kx ky iq kz b la mm jr lc ld mn ju lf lg mo li lj lk mp lm ln lo mq lq lr ls ij bi translated">EM是估计Fellegi Sunter框架中概率连锁模型参数的有力工具。根据我们的经验，EM方法在使用随机抽样估计u概率之后，仅用于估计模型的m概率时效果最佳。</p></div></div>    
</body>
</html>