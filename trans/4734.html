<html>
<head>
<title>Understanding Logistic Regression — the Odds Ratio, Sigmoid, MLE, et al</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解逻辑回归——优势比、Sigmoid、MLE等</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-logistic-regression-the-odds-ratio-sigmoid-mle-et-al-740cebf349a3#2022-10-21">https://towardsdatascience.com/understanding-logistic-regression-the-odds-ratio-sigmoid-mle-et-al-740cebf349a3#2022-10-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fc82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">逻辑回归是分类中最常用的机器学习技术之一。然而，尽管看起来很简单，但理解正在发生的事情的实际机制——优势比、对数变换、sigmoid——以及为什么使用它们可能相当棘手。在这篇博客中，我将解释逻辑回归，大部分是直观的，但有时会用少量的数学。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/1a98ed9835efcd54a984c1fc93555b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKmQr0qvB_n6Py8a-9KEpg.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">我的收藏</p></figure><p id="f445" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章将关注逻辑回归的方法和原因。关于它在分类和分类评价中的用途，可以查看我的帖子<a class="ae lb" href="https://shaileydash.medium.com/understanding-the-roc-and-auc-intuitively-31ca96445c02" rel="noopener">这里</a>。</p><p id="916e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我一直困惑的一点是，我们如何从所谓的比值比到实际的概率，因为这是我们通常估计的。所以，这是一个关于逻辑回归方程的推导的简短帖子，为什么它被转换成臭名昭著的“比值比”,它是如何被转换回来的，以及它是如何被估计的。</p><p id="cee4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么，让我们开始吧..</p><h2 id="de6d" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">何时使用</h2><p id="77e9" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">假设我们要根据验血结果把病人分成两组，身体质量指数，BP。这些类别是:糖尿病和非糖尿病。这是一个典型的分类问题。我们有一个二元因变量，即:</p><p id="4aea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">糖尿病患者= 1</p><p id="96ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果不是糖尿病患者，则= 0</p><p id="d590" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们估计的等式是:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/681e86246fae4f19ffa33f8b6adcf567.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XndqOQ8SGfB5Kbthzhkriw.png"/></div></div></figure><p id="11cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中，如果是糖尿病患者，y = 1；如果是非糖尿病患者，y = 0。x变量代表各种输入特征，如考试分数、身体质量指数等。目前我们只有一个x，比如说，测试分数。</p><p id="69b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="mb">这是什么挑战？</em> </strong></p><p id="b975" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个典型的线性回归问题，我们可以通过最小化误差平方和来估计它。然而，与回归不同的是，我们预测一个数字，如销售额。这里我们试图预测一个被值1或0限制的类别。如果我们得到一个接近1的值，比如说83，我们可以把它四舍五入到1，类似地，0.33可以归类为0。因此，这个等式有效地预测了属于类别1或0的特定实例的概率。通常，一些外部定义的临界值，如0.5或0.75，将用于定义预测得分。逻辑回归分类过程可以在图像中可视化。在这篇<a class="ae lb" href="https://shaileydash.medium.com/understanding-the-roc-and-auc-intuitively-31ca96445c02" rel="noopener">文章</a>中阅读更多关于分类阈值的信息。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mc"><img src="../Images/13bcae935884a4f9e647b15403fa992e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wCkyTnBfx8DoxzH9.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">分类过程(图片来源:我的收藏)</p></figure><p id="17d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，这其中的一个关键问题是线性回归是无界的。这意味着，例如，对于某些独立变量值，预测的y值可能大于1，甚至为负。这在分类问题上显然没有意义。</p><p id="2c7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从<a class="ae lb" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank">维基百科</a>中取一个简单的例子。我们有学生的及格-不及格数据与学习时数的关系图。通过-失败是一个二元变量，可以取值1或0。学习时间是数字。我们可以把它绘制成一个带有预测线的标准图。我们在x轴上绘制了学习小时数，在y轴上绘制了给定学习小时数时通过或失败的概率(p(y|x))。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi md"><img src="../Images/b0d1c574e75e2f76093f6e41e4c72d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qSorvJjdlpLfiy1ss-OrcQ.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">对分类数据绘制线性回归图(图片来源:我的收藏)</p></figure><p id="f575" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们观察如下:根据预测线，如果小时数超过5，我们的预测值超过1。类似地，如果学习的小时数少于半小时，预测的y，在这种情况下是p(y=1)，变成负数。</p><p id="9b5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些结果显然没有意义，我们需要一种方法来估计一个上界为1，下界为0的方程，而不考虑x的值。</p><p id="3ea8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">逻辑回归的案例</strong></p><p id="49d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就带来了逻辑回归。逻辑回归听起来非常类似于线性回归。它本质上是将线性回归转换成一个方程，使其极限值为0和1。我们仍然希望使用线性回归来解决这个问题，但是我们需要确保函数保持在其极限内。我们希望估计的是下面的线性方程。</p><p id="1b53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">P(y=1)=ax + b</p><p id="99c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">线性方程有两个问题:</p><ol class=""><li id="60bd" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">如上所述，它是无界的</li><li id="ec67" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">在许多情况下，我们看到，当p已经很大(或很小)时，与p接近1/2时相比，改变p相同的量需要x有更大的变化。这是一种非线性关系，线性模型无法做到这一点。</li></ol><p id="688e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">解决这个问题的方法是通过逻辑转换。通常代数只会增加混乱而不是清晰。但在这种情况下，一点点代数帮助我们看到逻辑回归方程的实际含义，它不是凭空想象出来的。</p><p id="9c2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">逻辑方程式如下。显然这需要解释…</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/d4b487c8925ab2c296bb44144c4af3d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0WO5Pr8eA021Fr2apNhVUg.png"/></div></div></figure><p id="143a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中P(y=1)= a + bx</p><p id="78b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">开始解释吧。</p><p id="bf85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">推导逻辑回归方程</strong></p><p id="7073" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为第一步，我们需要变换p(y=1 ),使它的极限不能是负数或无穷大。接下来，为了简单起见，我们将p(y=1)表示为p。线性方程的转换通过取比值比来完成。</p><p id="730b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你现在会呻吟着问，‘赔率是多少？’。</p><blockquote class="ms mt mu"><p id="2060" class="jn jo mb jp b jq jr js jt ju jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj kk ij bi translated">几率是某件事情发生与某件事情没有发生的比率(即3/2 = 1.5)。</p><p id="fa86" class="jn jo mb jp b jq jr js jt ju jv jw jx mv jz ka kb mw kd ke kf mx kh ki kj kk ij bi translated">概率是某件事情发生的比率，是所有可能发生的事情的比率(3/5 = 0.6)。</p></blockquote><p id="e9b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(扎布洛茨基，2022年)</p><p id="dfdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以如果一个事件发生的概率是. 6，那么比值比就是. 6/.4 =1.5。它告诉我们一个事件发生与不发生的几率。优势比定义为:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/bab76ffce28b3aef5cbf157ab664042f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0LcpS098-HOY3YjOkSsNUw.png"/></div></div></figure><p id="ea4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，这个比率的下限为0。在上端，它是未定义的(当p=1时，在分母中被零除)。比值比可以取0到0之间的任何值，并且在上限是无界的。该比率的值为中间的<strong class="jp ir"> 1 </strong>，表示发生和不发生的概率<strong class="jp ir">T3为. 5。小范围的赔率，从0到1 <strong class="jp ir">，</strong>失败的概率比成功的概率高。然后是无限的赔率范围，从1到无穷大，这表明成功的概率高于失败的概率。</strong></p><p id="8111" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于不平衡的范围，为了使比值比集中在0左右，我们需要对比值比进行对数转换。这有助于比值比的范围在0附近变得对称，即从-无穷大到+无穷大。如下图所示。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi my"><img src="../Images/9274c275baa90ea2a96a052b86b15d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qiPLsQf8syBPkkX8N7tnzA.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/a4ac40b002f3e49af9cb9bed2dd22dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nobvoloRGv0qjZA0JxlZFg.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">对数赔率转换(<a class="ae lb" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank">图像源</a>)</p></figure><p id="75cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">几率对数的这种转换也称为Logit函数，是逻辑回归的基础。通过这种变换获得的对称性提高了对数几率的可解释性，负值表示失败的几率，正值表示成功的几率更高。</p><p id="d8d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，函数的定义域仅从0延伸到1，但实际上并未定义在0或1。这是因为如果我们在log odds表达式中代入<em class="mb"> p=1 </em>，将导致除以零，产生一个未定义的值。类似地，当代入p=0时，将导致计算零的对数，这同样是未定义的(Zablotski，2022)。</p><p id="a6c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们假设观察值的对数概率<em class="mb"> y </em>可以表示为输入变量<strong class="jp ir"> x. </strong>的线性函数</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi my"><img src="../Images/015ddda565a4e4355803b493f3f0dc3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqTvTH_Go5s6yx2_2sxPqA.png"/></div></div></figure><p id="ed90" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">从赔率到概率</strong></p><p id="b2a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们有了对数概率方程。我们相当清楚，这必须以某种方式进行估计。然而，你现在可能会问:“但因变量是对数概率，而我需要一个简单的概率p。我如何在没有非常复杂的计算的情况下回溯呢！”</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi na"><img src="../Images/bcb03df64c6fc96f7fb57ba85360e7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gr4s_ugnCUprK2ZzvmpfhQ.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">从log odds到p(图片来源:我的收藏)</p></figure><p id="ebfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">别担心。这就是使用逻辑转换的原因。我们将看到，通过几个代数步骤，我们可以回到我们的好的旧的可理解的概率，p。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi my"><img src="../Images/015ddda565a4e4355803b493f3f0dc3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AqTvTH_Go5s6yx2_2sxPqA.png"/></div></div></figure><p id="161b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤1我们首先对两边取幂:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a5ada4eef1ce0f9f067a4074887134db.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*YahZxvlgYGrniXliUd4khA.png"/></div></figure><p id="836c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤2一些简单的代数操作(为代数有挑战的人提供详细的步骤)</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/dc965fc481ef2134ebc7dd5f19093cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yec7Uwvzj98tTTo8O60AnQ.png"/></div></div></figure><p id="6dff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LHS的合并条款</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/53629ad92ee0f60189c58d5c39c2eb4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Tpv4coeg6rD8xuxdvXy4Q.png"/></div></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/60dc9462bf822a9294dd515198b3f6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ik7YREc_nYo1sMvTeDJ2xQ.png"/></div></div></figure><p id="951f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们可以将分子和分母相除，得到:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/006f1f3151418b5e7194327c65b470c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZ8s72iWljDxjkMClzuRZA.png"/></div></div></figure><p id="c3a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这可以表示为我们熟悉的逻辑回归方程的函数形式，也称为Sigmoid。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/085a906cfa72382b02192759bc8c5879.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-32fDtgh-uOgurdP7S5FLg.png"/></div></div></figure><p id="2a52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个<strong class="jp ir"> <em class="mb"> </em> </strong>是我们的标准逻辑回归方程，它将一个线性回归转换为根据各种因变量得出正数的概率。</p><p id="a4f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以绘制逻辑回归方程，它给出一条S形曲线，中点为0.5，极限值为概率1和0。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nc"><img src="../Images/b44745024ebd2dc616c67803d1dddbea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEjTds01OsWZt_nKYGU1gg.png"/></div></div><p class="kx ky gj gh gi kz la bd b be z dk translated">逻辑回归图(图片来源:我的收藏)</p></figure><p id="f2b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上面的图中，我画出了给定x的事件y的概率，这被称为Sigmoid函数。x表示为标准化的。如您所见，概率值在图表的下端以0为上限，在上端以1为上限。中点是0.5的概率。</p><p id="7926" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">这个方程是怎么估计出来的？</strong></p><p id="5112" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们理解了曲线和sigmoid(困难的部分)，我们可以简单地看一下如何估计逻辑模型。正如我们所看到的，逻辑斯谛模型是线性回归模型的非线性转换。线性模型通常通过最优化最小化误差平方和来拟合。然而，不可能通过标准的优化技术如正规方程来拟合逻辑回归，因此我们使用最大似然估计(MLE)。MLE也是一种基于数据的方法。它试图解决这个问题:给定我们所拥有的数据，什么样的模型参数最大化了观察我们所观察到的数据的可能性。</p><p id="64e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个简单的例子来说明基本思想:</p><p id="0aae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们有一个盒子，里面有蓝色和绿色的球。我们现在还不知道颜色的分布。然而，我们随机抽取10个替换样本，得到8个蓝色球和2个绿色球。MLE提出的问题是:蓝球和绿球在盒子中的分布是什么，在重复的10轮平局中，会产生8个蓝球和2个绿球的结果？我们可以尝试使用各种基础分布来测试哪个基础分布会给出8个蓝色和2个绿色的结果。例如，两种颜色50:50的分布最有可能给出得到8个蓝色和2个绿色结果的非常低的概率。基础分布越接近绘制的分布，概率可能越高:例如7个蓝色和3个绿色，9个蓝色和1个绿色，等等。</p><p id="e58c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">实际上，这就是最大似然估计对逻辑回归方程的作用。深入研究MLE的细节需要一篇单独的文章，所以我将把它留到下一次。然而，这篇文章应该已经为你提供了逻辑回归理论基础的直观理解。当我们必须解释我们所做的事情的基本原理以及该算法与其他算法有何不同时，理论基础在机器学习中是有用的。简而言之，机器学习的“智能”部分。</p><p id="6832" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你喜欢这篇文章，请继续关注我关于<a class="ae lb" href="https://shaileydash.medium.com/understanding-the-roc-and-auc-intuitively-31ca96445c02" rel="noopener">分类评估</a>的文章。</p><p id="349b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢您的阅读，并在下面告诉我您的意见！</p><p id="cbfb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><ol class=""><li id="987c" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">【https://en.wikipedia.org/wiki/Logistic_regression T4】</li><li id="29a2" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" href="https://shaileydash.medium.com/understanding-the-roc-and-auc-intuitively-31ca96445c02" rel="noopener">https://shaileydash . medium . com/understanding-the-roc-and-AUC-直观地-31ca96445c02 </a></li><li id="c6f3" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" href="https://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf" rel="noopener ugc nofollow" target="_blank">https://www . stat . CMU . edu/~ cshalizi/uADA/12/lectures/ch12 . pdf</a></li><li id="7cec" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" href="https://data-se.netlify.app/2020/11/28/derivation-of-the-logistic-regression/#:~:text=In%20simple%20words%3A%20%E2%80%9CTake%20the,b%200%20%2B%20b%201%20x%20." rel="noopener ugc nofollow" target="_blank">https://data-se . netlify . app/2020/11/28/derivation-of-the-logistic-regression/#:~:text = In % 20 simple % 20 words % 3A % 20% E2 % 80% 9c take % 20 the，b%200%20%2B%20b%201%20x%20。</a></li><li id="63c6" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" href="https://yury-zablotski.netlify.app/post/how-logistic-regression-works/" rel="noopener ugc nofollow" target="_blank">https://yury-zablotski . netlify . app/post/how-logistic-regression-works/</a></li><li id="ef08" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" href="https://yury-zablotski.netlify.app/post/from-odds-to-probability/" rel="noopener ugc nofollow" target="_blank">https://yury-zablotski . netlify . app/post/from-odds-to-probability/</a></li><li id="71fb" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/understanding-maximum-likelihood-estimation-mle-7e184d3444bd">https://towards data science . com/understanding-maximum-likelihood-estimation-mle-7e 184d 3444 BD</a></li><li id="e012" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1">https://towards data science . com/probability-concepts-explained-maximum-likelihood-estimation-c7b 4342 fdb B1</a></li></ol></div></div>    
</body>
</html>