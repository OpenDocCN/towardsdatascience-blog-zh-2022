<html>
<head>
<title>Demystifying PyTorch’s WeightedRandomSampler by example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过示例揭开PyTorch加权随机抽样器的神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452#2022-08-30">https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452#2022-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e3e2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种处理不平衡数据集的简单方法</h2></div><p id="27bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，我发现自己在熟悉的情况下工作，处理一个非常不平衡的数据集，这影响了我的CNN模型在计算机视觉任务上的训练。虽然有各种方法可以实现这一点，但<a class="ae lb" href="https://arxiv.org/abs/1710.05381" rel="noopener ugc nofollow" target="_blank">的研究发现，在不同数据集上训练CNN模型时处理类别不平衡</a>得出结论，在几乎所有情况下，最佳策略是对少数类别进行过采样；增加了模型在训练期间看到这些类别的图像的频率。</p><p id="d099" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，尽管这个想法看起来很简单，但在PyTorch中实现它通常需要与有点神秘的<code class="fe lc ld le lf b">WeightedRandomSampler</code>进行交互。<a class="ae lb" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank">关于<code class="fe lc ld le lf b">WeightedRandomSampler</code>的文档</a>很少，既包括它是如何工作的，也包括如何设置参数以确保它按照我们预期的方式运行。尽管在过去已经使用了很多次，但是当我在很长一段时间没有使用它的时候，我经常发现自己在各种论坛和StackOverflow帖子中搜索，以确保我的设置是正确的。虽然有一篇<a class="ae lb" rel="noopener" target="_blank" href="/address-class-imbalance-easily-with-pytorch-bb540497d2a6">很棒的博客文章提供了它如何在幕后实现的数学上的严格分析</a>，但众所周知，我们人类往往不太理解概率论，因此很难仅从这一点获得直觉。</p><p id="0bdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将采取务实的方法来理解<code class="fe lc ld le lf b">WeightedRandomSampler</code>的行为，目的是回答以下问题:</p><ul class=""><li id="9269" class="lg lh iq kh b ki kj kl km ko li ks lj kw lk la ll lm ln lo bi translated"><em class="lp">如何计算用于平衡数据集的权重？</em></li><li id="1221" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><em class="lp">由于这种方法是基于概率的，我能确定这将以我想要的方式平衡数据集吗？</em></li><li id="3abe" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><em class="lp">在训练期间，我的所有数据集都会被看到吗？</em></li><li id="a832" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><em class="lp">如果我不想均衡地平衡数据集，而是达到某个其他比率，该怎么办？</em></li></ul><p id="fe51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将通过在处理真实数据集的上下文中与<code class="fe lc ld le lf b">WeightedRandomSampler</code>对象进行交互来实现这一点，然后运行一个简单的实验来确定平衡数据集是否会为我们的简单问题带来任何性能改进。</p><p id="17e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"><em class="lp">Tl；dr: </em> </strong> <em class="lp">如果你只是想看到一些可以直接使用的工作代码，复制这篇文章所需的所有代码都可以在这里</em><a class="ae lb" href="https://gist.github.com/Chris-hughes10/260c70650c5a6f322d273a8a8728b91a" rel="noopener ugc nofollow" target="_blank"><em class="lp">GitHub gist</em></a><em class="lp">中找到。</em></p><h1 id="542d" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">创建不平衡的数据集</h1><p id="c6da" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">首先，让我们下载一些数据作为例子。这里，我使用的是<a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津宠物数据集</a>，它包含了37种不同类别的猫和狗。在Linux上，我们可以用以下命令下载它:</p><pre class="ms mt mu mv gt mw lf mx my aw mz bi"><span id="ae25" class="na lw iq lf b gy nb nc l nd ne">wget <a class="ae lb" href="https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz" rel="noopener ugc nofollow" target="_blank">https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz</a> -P data/pets<br/>ls data/pets<br/>tar -xzf data/pets/images.tar.gz -C data/pets<br/>rm data/pets/images.tar.gz</span></pre><p id="d7f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了一些数据，我经常发现探索这个问题的一个好方法是创建一个熊猫数据框架。我们可以使用标准库中的<code class="fe lc ld le lf b">pathlib</code>来快速获得所有图像路径的列表，由于类名包含在每个文件名中，我们可以在同一个步骤中提取这些路径。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nf"><img src="../Images/bfe5dd9e384f117697577f8c270b87dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrM8MGO8S30FHwQTHLnH7g.png"/></div></div></figure><p id="41ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用这些工具轻松创建一个数据框架，用于快速检查我们的标签分布情况:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nn"><img src="../Images/53c694d96bb26b091020dcbb60b70c93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zPKTZ-D1rPIWAS0XuAwOyA.png"/></div></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi no"><img src="../Images/a6e6f7ff44fb557c4a41afbe7f023832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DLa2gdl-Y2w1obEPFOlMzQ.png"/></div></div></figure><p id="4fae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此，我们可以看到数据集非常均衡，几乎所有的类都有大约200张图片。虽然这通常是一件好事，但为了使数据集适合我们的目的，我们可以定义一个函数来提取不平衡的子集:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="cc54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">选择其中两个类别，我们可以用它来创建不平衡数据集，如下所示:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nr"><img src="../Images/44e8f41cca8145e65d5c5fa43ea3227f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88Alv5Tx2E0NLR-f-PvMYQ.png"/></div></div></figure><p id="4dba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用整数值对我们的类标签进行编码，并创建一个在我们的数据集中使用的查找。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ns"><img src="../Images/0750af950e8ee3d95c627eb710d05d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oSFD1PWaSbMdCwRdw4ZSow.png"/></div></div></figure><p id="a291" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我选择了<em class="lp">暹罗猫</em>和<em class="lp">伯尔曼猫</em>品种，因为根据数据集网站上的预览图片，它们具有短暂的相似性。我们可以通过随机检查一些图像来确认这一点。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nt"><img src="../Images/a57a56c482ba36c1fd1a17528e966519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xkb1gHKEF430Y0zNhmCZNg.png"/></div></div></figure><p id="4818" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于这一点，这些类似乎是一个简单但重要的任务的合适选择。</p><h1 id="c6e9" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">可视化批量分配</h1><p id="b0b1" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">现在，我们已经定义了数据集，让我们通过检查模型在单个训练时期将看到的每一批的分布来探索类不平衡的影响。</p><p id="e21a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为此时我们不需要加载图像，所以让我们从每个图像的标签和索引创建一个张量数据集，这样我们就可以快速迭代。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nu"><img src="../Images/dab5694db5a9e15230c0b092a07b44a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxxGC5l6r_gC1R2ciVA67A.png"/></div></div></figure><p id="0214" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以定义一个函数来实现这一点，方法是跟踪每个批处理期间看到的类和索引，并绘制它们，如下所示:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="e912" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以用它来研究我们的数据是什么样子的。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nv"><img src="../Images/a7e33d044f2a0e78f9e824803f3634a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*adroqswNhxZLBzeJvN0k_g.png"/></div></div></figure><p id="4004" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此，我们可以清楚地观察到不平衡的影响，因为一些批次根本不包含任何来自我们少数类的图像！此外，我们可以看到，数据集中的每幅图像都会在训练过程中出现。当我们对所有批次取平均值时，我们观察到与数据集中相同的比例，这是我们所期望的。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi nw"><img src="../Images/53c96583a580e4c50313c2d6bf5e0f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gXCKCz3KR1pvOsXa0D8fSQ.png"/></div></div></figure><h2 id="4e88" class="na lw iq bd lx nx ny dn mb nz oa dp mf ko ob oc mh ks od oe mj kw of og ml oh bi translated">用<em class="oi">加权随机采样器</em>平衡我们的数据集</h2><p id="b2d9" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">现在，让我们看看如何使用<code class="fe lc ld le lf b">WeightedRandomSampler</code>来平衡数据集。</p><p id="8f36" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们需要做的第一件事是计算将用于对每个图像进行采样的<code class="fe lc ld le lf b">weights</code>;<a class="ae lb" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank">从文档</a>中，我们可以看到我们需要为数据集中的每幅图像设定一个权重。在我看来，最令人困惑的是这些权重的总和不一定是1。实际上，这些权重代表了图像被选中的概率，PyTorch只是为了方便起见，在幕后将这些权重缩放到[0，1]范围内。</p><p id="9711" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经了解了我们需要什么，让我们看看如何计算这些权重。首先，我们需要计算有多少图像属于我们的每个类，使用Pandas我们可以这样做，如下所示:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oj"><img src="../Images/6e8ac398cbb7306a8626b8da592d4b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAHlcMvctdKV5lUDYMjKbQ.png"/></div></div></figure><p id="f880" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们有了类计数，我们可以通过取计数的倒数来计算每个类的权重。这将确保具有较高代表性的类将具有较小的权重。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/66db6932f776dfc7fd0ce97142fd5b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*dDygG8LUJVEozEWmvdJ_Yw.png"/></div></figure><p id="d55e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们只需要根据类别为每个样本分配适当的权重。在实践中，我们可以直接从类计数中完成，如下所示:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ol"><img src="../Images/c2f97068bb1282fb7394fe7260bc17ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRtYT7TUwE3ohoCqeDfr4Q.png"/></div></div></figure><p id="86fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们可以创建我们的采样器和数据加载器:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi om"><img src="../Images/b23bfa5772603048f618a8d259a07fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smRz-2-BauswKIRbNjVIUw.png"/></div></div></figure><p id="8bd2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到我们已经提供了计算的样本权重作为参数，并将<code class="fe lc ld le lf b">replacement</code>设置为True否则，我们根本无法进行过采样。现在，我们只是将样本的数量设置为数据集的长度，但是我们将在后面对此进行更多的讨论。</p><p id="9db4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再次，我们可以可视化我们的数据加载器批次的分布，这次使用<code class="fe lc ld le lf b">WeightedRandomSampler</code>。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi on"><img src="../Images/4677ab5facccdc68e8118d209a7c0503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6I5O3NKBlX2YL5zjoigcvg.png"/></div></div></figure><p id="535e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此可见，我们的批次相当均衡！查看所看到的图像数量，我们可以看到采样器通过对少数类进行过采样而对多数类进行欠采样来实现这一点。</p><p id="445c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更详细地了解选择了哪些图像，我们可以创建一个数据帧，其中包含每个图像在这个时期被看到的次数。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oo"><img src="../Images/6315707ed609fd3178ae86aab6bd5faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w06HzffEmK3155ui03qq8A.png"/></div></div></figure><p id="e50e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使这些数据更容易解释，我们可以使用下面的代码片段将其表示为<a class="ae lb" href="https://seaborn.pydata.org/generated/seaborn.ecdfplot.html" rel="noopener ugc nofollow" target="_blank">经验累积分布函数图</a>:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi op"><img src="../Images/5b7ac5359eb51cf942fd707646b34d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvCjT5rIglsniSw7ZyLCgw.png"/></div></div></figure><p id="f013" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此可见，要达到我们想要的比例，我们少数民族班的每张图片至少被看了5次，有的多达13次！相比之下，我们多数班的很多图像根本就没看到！</p><p id="52ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能会注意到，我们多数班的一些图像被多次看到，而另一些根本没有看到，这似乎很奇怪，这似乎并不理想。不幸的是，这是基于概率的采样方法的一个折衷。虽然我们可以将<code class="fe lc ld le lf b">WeightedRandomSampler</code>设置为无替换采样，但这也会阻止我们过采样；所以对我们这里没用！</p><p id="31b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一个合乎逻辑的问题是，我们能否确保在训练过程中看到每一张图像。</p><h1 id="9202" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">训练期间什么时候可以看到我的所有图像？</h1><h2 id="5040" class="na lw iq bd lx nx ny dn mb nz oa dp mf ko ob oc mh ks od oe mj kw of og ml oh bi translated">调整每个时期的样本数量</h2><p id="1bcf" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">如上所述，来自我们多数班的97幅图像在训练期间不会被看到。原因在于我们在创建<code class="fe lc ld le lf b">WeightedRandomSampler</code>实例时定义的<code class="fe lc ld le lf b">num_samples</code>参数。由于我们指定样本数等于原始不平衡数据集中的图像总数，因此我们的采样器必须忽略一些图像才能对少数类进行过采样。</p><p id="ea04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">调整这个参数，将原始数据集的大小增加一倍，我们可以看到，在一个时期内，我们可以看到更多的图像。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oq"><img src="../Images/46182b55b97419a0e77590b85f811fec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6r9H-DJYyVWS3P0yZ7g1g.png"/></div></div></figure><p id="eac6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，这确实给纪元的确切含义带来了一些混乱。在机器学习中，我们将一个时期定义为<em class="lp">单次通过整个数据集</em>。当每个样本只被看到一次时，这个定义使得准确地理解模型到训练中的当前点已经看到了什么变得非常清楚；当以不同的频率对图像进行采样时，这一点变得不太清楚。</p><p id="c88a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于历元的概念主要是为了帮助我们跟踪训练过程中的进展，而与模型本身没有关系——它只看到一个恒定的图像流——我更喜欢将<code class="fe lc ld le lf b">num_samples</code>设置为数据集的长度，并相信随着我们训练更多的历元，所有图像都会在某个点被看到。</p><h2 id="1cd1" class="na lw iq bd lx nx ny dn mb nz oa dp mf ko ob oc mh ks od oe mj kw of og ml oh bi translated">在模型看到所有图像之前需要多少个历元？</h2><p id="66be" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">将我们的采样器重置回其原始参数:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi or"><img src="../Images/b757c9e0a10db3c27942e1d003b5b5dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV2x4oz4RAF5H3grFy1utw.png"/></div></div></figure><p id="e61f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们探索一下在一次训练运行中需要多长时间才能看到我们的所有数据集。</p><p id="8260" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了做到这一点，我们可以建立一个简单的实验，我们跟踪在多个时期内看到的所有图像，并绘制每个时期结束时到目前为止的唯一图像的数量。我们可以使用下面的代码片段来做到这一点:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi os"><img src="../Images/b74840c5e3967e072c16c5bd44359389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*blHL0dhn6-7mGLZfGjt0qg.png"/></div></div></figure><p id="6935" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们可以看到，直到所有图像至少被看到一次，需要10个历元。然而，由于这取决于概率，这个数字很可能会改变！</p><p id="db88" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了得到一个更稳健的估计，让我们从<a class="ae lb" href="https://en.wikipedia.org/wiki/Monte_Carlo_method" rel="noopener ugc nofollow" target="_blank">蒙特卡罗方法</a>中得到启发，多次运行这个实验并观察分布。为了更容易解释，我们可以将它表示为<a class="ae lb" href="https://seaborn.pydata.org/generated/seaborn.kdeplot.html" rel="noopener ugc nofollow" target="_blank">核密度估计图</a>。</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ot"><img src="../Images/40c0b305dc1793b451eab77482404ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRefGLQXQ0Z5LHXBLdC5OA.png"/></div></div></figure><p id="bebd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此我们可以看出，在大多数情况下，大约需要9-10个历元才能确信所有数据都会被看到。</p><p id="bcd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，这个估计高度依赖于底层数据集中不平衡的比例。似乎合乎逻辑的建议是，随着不平衡比率的增加，将需要更多的时代。我们可以通过对不同程度的不平衡重复我们的试验来证实这一点，如下所示:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ou"><img src="../Images/da8976e8e2bc161f5cf86ad0587d0e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iYAgMpqkY9yjTD1Rb9tF1A.png"/></div></div></figure><p id="8f3a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从图中，我们可以看出我们的直觉是正确的。然而，有趣的是，当在平衡数据集上使用<code class="fe lc ld le lf b">WeightedRandomSampler</code>时，需要大约5个时期才能看到所有数据；这表明在这种情况下这并不理想！</p><h1 id="dad8" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">获取不平衡的数据集比例</h1><p id="9c03" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">既然我们已经探索了如何使用WeightedRandomSampler来平衡我们的训练集，那么让我们简单地研究一下如何调整我们的类权重来达到我们想要的任何比例。</p><p id="5ebc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这可能有用的一个例子是在对象检测中，我们希望我们的大部分训练集中在包含我们希望检测的项目的图像上，但是可用的数据集通常包含大量的<em class="lp">背景</em>图像。</p><p id="fd92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为一个例子，让我们研究一下如何以另一种方式使数据集严重失衡；这样我们的少数阶级就占了主导地位。</p><p id="6ee6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，首先我们需要计算每个类别的样本总数:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi oj"><img src="../Images/711d1c53a948eb8910c3e4d4fa165898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLM4PH9N9MyJBipaZqjioA.png"/></div></div></figure><p id="6c2d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们可以为每个类别定义目标比例:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ov"><img src="../Images/8e5ffdcab24a03adabc8a00515a97802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvbqBoxmHNeX8SCYOFqACA.png"/></div></div></figure><p id="dcfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，为了计算我们的样品重量，我们只需将每个重量乘以我们相应的目标比例，如下所示:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ow"><img src="../Images/3d0a55efde56a926b1d15ea390a9beeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O9YyfjJapP1t2yh33zQLVA.png"/></div></div></figure><p id="17dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像以前一样，让我们将这些重量传递到我们的采样器，并可视化我们的批次。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi ox"><img src="../Images/5c45cb2390a9ec3de5b74c7c9d77a640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JkfgHm_2f-BPyQNJAHyBwA.png"/></div></div></figure><p id="0e68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此可以看出，我们已经获得了我们正在寻找的分布。</p><h1 id="dd0f" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">过采样能提高性能吗？</h1><p id="03fc" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">希望在这一点上，我们已经对<code class="fe lc ld le lf b">WeightedRandomSampler</code>如何工作有了一个直觉。然而，你可能会想，只是更频繁地向网络显示相同的图像真的会有所不同吗？让我们设置一个小实验来研究一下。</p><p id="d01c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们在不平衡数据集上训练一个图像分类器。当然，结果在很大程度上取决于许多因素，例如使用的模型和数据集，但这只是一个简单的例子。在这里，我根据过去一直对我有效的训练食谱选择了以下内容:</p><ul class=""><li id="7b98" class="lg lh iq kh b ki kj kl km ko li ks lj kw lk la ll lm ln lo bi translated">型号:ResNet-RS50</li><li id="234a" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated">优化器:AdamW</li><li id="369c" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated">LR调度程序:带预热的余弦衰减</li><li id="4712" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated">图像大小调整为224</li></ul><p id="e698" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们的数据集非常小，为了进一步简化，让我们只训练在我们的架构中用于分类的最终线性层；由于我们的图像非常类似于模型已经过预训练的ImageNet图像，因此可以安全地假设主干中学习到的特性在这里应该足够好。</p><p id="f598" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进行评估，我们可以使用我们之前创建的验证集，它包含了在训练中没有看到的图像的平衡样本。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/65be4b7940ba1353c12486d0bb9844b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*odeBqnrP4u_1WzVTqM-aLQ.png"/></div></figure><p id="2cc3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有训练都是使用单个NVIDIA V100 GPU进行的。为了处理训练循环，我使用了<a class="ae lb" href="https://github.com/Chris-hughes10/pytorch-accelerated" rel="noopener ugc nofollow" target="_blank"> PyTorch加速库</a>。然而，由于PyTorch-accelerated处理所有分布式训练问题，相同的代码可以在多个GPU上使用——无需将<code class="fe lc ld le lf b">WeightedRandomSampler</code>更改为分布式采样器——只需通过<a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank">定义一个配置文件，如这里所述</a>。</p><p id="4121" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以定义一个脚本来进行这个实验，如下所示:</p><figure class="ms mt mu mv gt ng"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="b73f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用的包:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/f75acf05a107fc4c1d2d0e3a7dfe0d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*vS9ks23IIKZKh0ULmU1vGw.png"/></div></figure><p id="1247" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过运行以下命令，在训练10个时期后选择最佳指标:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pa"><img src="../Images/34f81e7771e5dd8960db1617e193cdd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WSlam-TGOvlU3P-xr-eT7w.png"/></div></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pb"><img src="../Images/cff97ff001a81911fb61b498a53759a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qzi5AGFMMshVT2WLXQcqrw.png"/></div></div></figure><p id="969b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我得到了以下结果:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pc"><img src="../Images/1e1073a1a417f4c6f8798ca68954b4f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jspdZo-iFD-kXb6Ye6gmjQ.png"/></div></div></figure><p id="29b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哦，不，这看起来像过采样实际上使事情变得更糟！</p><p id="389c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，就我们实验的设置方式而言，这并不十分令人惊讶，因为我们将模型的曝光限制在来自多数群体的新图像，而倾向于重复显示少数群体的少量图像。如果有一种方法可以从Birman图像的小集合中获取更多信息就好了…</p><h2 id="616a" class="na lw iq bd lx nx ny dn mb nz oa dp mf ko ob oc mh ks od oe mj kw of og ml oh bi translated">添加数据扩充</h2><p id="d584" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">为了尝试并帮助模型从我们的图像中学习更多，我们可以在训练期间使用数据增强来生成每个图像的稍微修改的版本。</p><p id="bfc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这种情况下，我决定使用timm的预定义RandAugment策略，因为这需要最小的超参数调整；timm的RandAugment实现是<a class="ae lb" rel="noopener" target="_blank" href="/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055#8549">这里详细描述</a>。</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pd"><img src="../Images/355a85ec044392e2a785f273a0e6e78d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4nmI5o__k5y8zbzLjxIFeQ.png"/></div></div><p class="pe pf gj gh gi pg ph bd b be z dk translated">将RandAugment应用于来自我们训练数据集的图像</p></figure><p id="2508" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们再次运行这个实验，这一次使用数据扩充:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pi"><img src="../Images/095f07f4d8c138ea51f5be7020606b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mE2EGm6B5O_Yoilid3IOfw.png"/></div></div></figure><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pj"><img src="../Images/a1d202211a718ac561856bc59cf43dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*355Wajcoc55Znd5W4XbX1Q.png"/></div></div></figure><p id="bb8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果如下所示:</p><figure class="ms mt mu mv gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nh ni di nj bf nk"><div class="gh gi pk"><img src="../Images/0693bf3189ab2444706bb5cb5fdc3322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ANr_RWeKQDutfDmhdjHLQw.png"/></div></div></figure><p id="4db3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一次，我们可以看到数据扩充和过采样的结合导致了性能的显著提高！</p><h1 id="0ae5" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">结论</h1><p id="6cd7" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">希望这已经提供了如何开始使用<code class="fe lc ld le lf b">WeightedRandomSampler</code>的全面概述，并有助于说明如何使用它。</p><p id="4fb2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">复制这篇文章所需的所有代码都可以从GitHub gist 中获得。</p><p id="2c3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lp">克里斯·休斯上的是</em> <a class="ae lb" href="http://www.linkedin.com/in/chris-hughes1/" rel="noopener ugc nofollow" target="_blank"> <em class="lp">领英</em> </a> <em class="lp">。</em></p><h1 id="c93e" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">参考</h1><ul class=""><li id="2288" class="lg lh iq kh b ki mn kl mo ko pl ks pm kw pn la ll lm ln lo bi translated"><a class="ae lb" href="https://arxiv.org/abs/1710.05381" rel="noopener ugc nofollow" target="_blank">【1710.05381】卷积神经网络中类不平衡问题的系统研究(arxiv.org)</a></li><li id="80c9" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler" rel="noopener ugc nofollow" target="_blank">torch . utils . data—py torch 1.12文档</a></li><li id="dda1" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" rel="noopener" target="_blank" href="/address-class-imbalance-easily-with-pytorch-bb540497d2a6">使用Pytorch轻松解决阶级失衡问题第2部分| masta fa Foufa |迈向数据科学</a></li><li id="133b" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津大学视觉几何组</a></li><li id="4e61" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://seaborn.pydata.org/generated/seaborn.ecdfplot.html" rel="noopener ugc nofollow" target="_blank">seaborn . ecdfplot—seaborn 0 . 11 . 2文档(pydata.org)</a></li><li id="6af7" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/Monte_Carlo_method" rel="noopener ugc nofollow" target="_blank">蒙特卡罗方法——维基百科</a></li><li id="fac1" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://seaborn.pydata.org/generated/seaborn.kdeplot.html" rel="noopener ugc nofollow" target="_blank">seaborn . k deplot—seaborn 0 . 11 . 2文档(pydata.org)</a></li><li id="9d19" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated">pytorch-accelerated:一个轻量级库，旨在通过提供一个最小但可扩展的训练循环来加速pytorch模型的训练过程，该训练循环足够灵活，可以处理大多数用例，并且能够利用不同的硬件选项，而无需更改代码。文件:https://pytorch-accelerated.readthedocs.io/en/latest/(github.com)</li><li id="7c8e" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated"><a class="ae lb" href="https://pytorch-accelerated.readthedocs.io/en/latest/quickstart.html" rel="noopener ugc nofollow" target="_blank">快速入门— pytorch加速0.1.3文档</a></li><li id="e0f8" class="lg lh iq kh b ki lq kl lr ko ls ks lt kw lu la ll lm ln lo bi translated">【PyTorch图像模型(timm)入门:实践者指南|作者克里斯·休斯|走向数据科学</li></ul><h1 id="f401" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">使用的数据集</h1><ul class=""><li id="c4c9" class="lg lh iq kh b ki mn kl mo ko pl ks pm kw pn la ll lm ln lo bi translated">牛津Pets数据集，<a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津大学视觉几何组</a>。<a class="ae lb" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名-共享4.0国际许可</a>，包括商业和研究目的。</li></ul></div></div>    
</body>
</html>