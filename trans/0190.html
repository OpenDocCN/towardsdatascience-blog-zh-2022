<html>
<head>
<title>Building A Deep Learning-Based Object Detection App Using R Shiny and Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 R Shiny 和 Tensorflow 构建基于深度学习的对象检测应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-deep-learning-based-object-detection-app-using-r-shiny-and-tensorflow-5c17e93301d0#2022-02-08">https://towardsdatascience.com/building-a-deep-learning-based-object-detection-app-using-r-shiny-and-tensorflow-5c17e93301d0#2022-02-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="da05" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解如何基于您自己的数据集微调用于对象检测的定制深度学习模型</h2></div><p id="39ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为对象检测训练一个像样的深度学习模型需要很多努力，当在最终用户的 web 应用程序中部署和嵌入该模型时，这变得更加复杂。在本教程中，我们打算通过提供一个如何使用 Python 和 Tensorflow 框架开发准确的深度学习模型的实际示例来解决这个看似艰巨的任务，并使用 R Shiny 框架构建一个支持动态对象检测的工作 web 应用程序。在本教程结束时，您将能够为杂货项目构建一个全面的对象识别应用程序，如下所示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/44b4a31898f6fdeda32b0a59c9d207d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h-oVg54R27rIyLags1eVbQ.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">物体检测应用。图片由作者提供。</p></figure><h1 id="6ca1" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">训练用于对象检测的深度学习模型</h1><p id="59c9" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">训练用于对象检测的执行深度学习模型需要大量数据和计算能力。为了促进开发，我们可以通过细化基于其他相关数据集预训练的调整模型来使用迁移学习。在本例中，我们选择由<a class="ae mo" href="https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1" rel="noopener ugc nofollow" target="_blank"> Tensorflow Hub </a>提供的 sdd mobilenet，它在速度和准确性之间提供了良好的平衡。</p><p id="a727" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于在训练全面的深度学习模型时，需要考虑多个后端逻辑，如路径和超级参数，因此我们可以创建一个中央字典来存储这些配置参数，包括设置不同的路径，安装相关的库，以及下载预训练的模型。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="79d3" class="mu ls iq mq b gy mv mw l mx my"># Configuration parameters<br/>CUSTOM_MODEL_NAME <strong class="mq ir">=</strong> 'my_ssd_mobnet' <br/><br/><em class="mz"># SSD has good tradeoff between speed and accuracy; can switch to other pretrained model</em><br/>PRETRAINED_MODEL_NAME <strong class="mq ir">=</strong> 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'<br/>PRETRAINED_MODEL_URL <strong class="mq ir">=</strong> 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'<br/><br/><em class="mz"># TF official script to encode training data to tf record format</em><br/>TF_RECORD_SCRIPT_NAME <strong class="mq ir">=</strong> 'generate_tfrecord.py'<br/><br/><em class="mz"># Mapping dictionary between label and integer id</em><br/>LABEL_MAP_NAME <strong class="mq ir">=</strong> 'label_map.pbtxt'<br/><br/><em class="mz"># Define a list of folder paths to be created (if needed) and used later</em><br/>paths <strong class="mq ir">=</strong> {<br/>    'WORKSPACE_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace'),<br/>    'SCRIPTS_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow','scripts'),<br/>    'APIMODEL_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow','models'),<br/>    <em class="mz"># bounding box annotation</em><br/>    'ANNOTATION_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','annotations'),<br/>    'IMAGE_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','images'),<br/>    'MODEL_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','models'),<br/>    'PRETRAINED_MODEL_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','pre-trained-models'),<br/>    'CHECKPOINT_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), <br/>    'OUTPUT_PATH': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), <br/>    'PROTOC_PATH':os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow','protoc')<br/>}<br/><br/>files <strong class="mq ir">=</strong> {<br/>    'PIPELINE_CONFIG':os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),<br/>    'TF_RECORD_SCRIPT': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), <br/>    'LABELMAP': os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)<br/>}</span><span id="422d" class="mu ls iq mq b gy na mw l mx my"># Download TF model training utility scripts from TF model zoo<br/><strong class="mq ir">if</strong> <strong class="mq ir">not</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>exists(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['APIMODEL_PATH'], 'research', 'objection_detection')):<br/>    !git clone https:<strong class="mq ir">//</strong>github<strong class="mq ir">.</strong>com<strong class="mq ir">/</strong>tensorflow<strong class="mq ir">/</strong>models {paths['APIMODEL_PATH']}</span><span id="8433" class="mu ls iq mq b gy na mw l mx my"># Install TF object detection library<br/><strong class="mq ir">if</strong> os<strong class="mq ir">.</strong>name<strong class="mq ir">==</strong>'posix':  <br/>    !apt<strong class="mq ir">-</strong>get install protobuf<strong class="mq ir">-</strong>compiler<br/>    !cd Tensorflow<strong class="mq ir">/</strong>models<strong class="mq ir">/</strong>research <strong class="mq ir">&amp;&amp;</strong> protoc object_detection<strong class="mq ir">/</strong>protos<strong class="mq ir">/*.</strong>proto <strong class="mq ir">--</strong>python_out<strong class="mq ir">=.</strong> <strong class="mq ir">&amp;&amp;</strong> cp object_detection<strong class="mq ir">/</strong>packages<strong class="mq ir">/</strong>tf2<strong class="mq ir">/</strong>setup<strong class="mq ir">.</strong>py <strong class="mq ir">.</strong> <strong class="mq ir">&amp;&amp;</strong> python <strong class="mq ir">-</strong>m pip install <strong class="mq ir">.</strong></span></pre><p id="30cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还需要为杂货项目识别的特定任务提供训练图像和边界框。这些数据将用于通过将默认输出更改为特定设置来微调预训练模型，即识别字典中描述的六种杂货项目(苹果、鳄梨、香蕉、卷心菜、胡萝卜和土豆)。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="6d26" class="mu ls iq mq b gy mv mw l mx my"><strong class="mq ir"># </strong>Download training images<strong class="mq ir"><br/>import</strong> shutil<br/><br/><strong class="mq ir">if</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>exists('object_detection_using_tensorflow'):<br/>    shutil<strong class="mq ir">.</strong>rmtree('object_detection_using_tensorflow')<br/><br/>!git clone <a class="ae mo" href="https://github.com/jackliu333/object_detection_using_tensorflow.git" rel="noopener ugc nofollow" target="_blank">https:<strong class="mq ir">//</strong>github<strong class="mq ir">.</strong>com<strong class="mq ir">/</strong>jackliu333<strong class="mq ir">/</strong>object_detection_using_tensorflow<strong class="mq ir">.</strong>git</a></span><span id="3252" class="mu ls iq mq b gy na mw l mx my"># Create label map<br/>labels <strong class="mq ir">=</strong> [{'name':'Apple', 'id':1},<br/>          {'name':'Avocado', 'id':2},<br/>          {'name':'Banana', 'id':3},<br/>          {'name':'Cabbage', 'id':4},<br/>          {'name':'Carrot', 'id':5},<br/>          {'name':'Potato', 'id':6}]<br/><br/><strong class="mq ir">with</strong> open(files['LABELMAP'], 'w') <strong class="mq ir">as</strong> f:<br/>    <strong class="mq ir">for</strong> label <strong class="mq ir">in</strong> labels:<br/>        f<strong class="mq ir">.</strong>write('item { \n')<br/>        f<strong class="mq ir">.</strong>write('\tname:\'{}\'\n'<strong class="mq ir">.</strong>format(label['name']))<br/>        f<strong class="mq ir">.</strong>write('\tid:{}\n'<strong class="mq ir">.</strong>format(label['id']))<br/>        f<strong class="mq ir">.</strong>write('}\n')</span></pre><p id="b87b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还将把数据分成训练集和测试集。请注意，这种划分需要按照类别索引进行，以便特定类别的项目不会完全分配到训练集或测试集中。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="7b52" class="mu ls iq mq b gy mv mw l mx my"># Split into train test folders<br/>tmp_folders <strong class="mq ir">=</strong> ['train', 'test']<br/><br/><strong class="mq ir">for</strong> i <strong class="mq ir">in</strong> tmp_folders:<br/>    <strong class="mq ir">if</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>exists(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], i)):<br/>        shutil<strong class="mq ir">.</strong>rmtree(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], i))<br/>        !mkdir <strong class="mq ir">-</strong>p {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], i)}<br/>    <strong class="mq ir">else</strong>:<br/>        !mkdir <strong class="mq ir">-</strong>p {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], i)}</span><span id="0703" class="mu ls iq mq b gy na mw l mx my"><strong class="mq ir">import</strong> shutil<br/><br/><strong class="mq ir">for</strong> i <strong class="mq ir">in</strong> range(len(labels)):<br/>    <em class="mz"># print(labels[i]['name'])</em><br/>    from_path <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join('object_detection_using_tensorflow','images',labels[i]['name'])<br/>    <em class="mz"># print(from_path)</em><br/><br/>    <em class="mz"># get unique file names</em><br/>    tmp_files <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>listdir(from_path)<br/>    tmp_names <strong class="mq ir">=</strong> []<br/>    tmp_file_types <strong class="mq ir">=</strong> []<br/>    <strong class="mq ir">for</strong> tmp_file <strong class="mq ir">in</strong> tmp_files:<br/>        tmp_name <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>splitext(tmp_file)[0]<br/>        tmp_file_type <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>splitext(tmp_file)[1]<br/>        tmp_names<strong class="mq ir">.</strong>append(tmp_name)<br/>        tmp_file_types<strong class="mq ir">.</strong>append(tmp_file_type)<br/>    tmp_names <strong class="mq ir">=</strong> list(set(tmp_names))<br/>    tmp_names <strong class="mq ir">=</strong> [i <strong class="mq ir">for</strong> i <strong class="mq ir">in</strong> tmp_names <strong class="mq ir">if</strong> i <strong class="mq ir">!=</strong> '.DS_Store']<br/>    tmp_file_types <strong class="mq ir">=</strong> list(set(tmp_file_types))<br/>    tmp_file_types <strong class="mq ir">=</strong> [i <strong class="mq ir">for</strong> i <strong class="mq ir">in</strong> tmp_file_types <strong class="mq ir">if</strong> len(i) <strong class="mq ir">!=</strong> 0]<br/>    <em class="mz"># random shuffle the files</em><br/>    random<strong class="mq ir">.</strong>shuffle(tmp_names)<br/>    <br/>    <em class="mz"># training and test files</em><br/>    tmp_names_train <strong class="mq ir">=</strong> tmp_names[0:int(len(tmp_names)<strong class="mq ir">*</strong>0.9)]<br/>    tmp_names_test <strong class="mq ir">=</strong> [i <strong class="mq ir">for</strong> i <strong class="mq ir">in</strong> tmp_names <strong class="mq ir">if</strong> i <strong class="mq ir">not</strong> <strong class="mq ir">in</strong> tmp_names_train]<br/><br/>    <em class="mz"># move into respective target folders</em><br/>    <strong class="mq ir">for</strong> tmp_name <strong class="mq ir">in</strong> tmp_names_train:<br/>        <strong class="mq ir">for</strong> tmp_file_type <strong class="mq ir">in</strong> tmp_file_types:<br/>            tmp_name_full <strong class="mq ir">=</strong> tmp_name <strong class="mq ir">+</strong> tmp_file_type<br/>            shutil<strong class="mq ir">.</strong>copy(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(from_path, tmp_name_full), \<br/>                        os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], "train"))<br/><br/>    <strong class="mq ir">for</strong> tmp_name <strong class="mq ir">in</strong> tmp_names_test:<br/>        <strong class="mq ir">for</strong> tmp_file_type <strong class="mq ir">in</strong> tmp_file_types:<br/>            tmp_name_full <strong class="mq ir">=</strong> tmp_name <strong class="mq ir">+</strong> tmp_file_type<br/>            shutil<strong class="mq ir">.</strong>copy(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(from_path, tmp_name_full), \<br/>                        os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], "test"))</span></pre><p id="a2dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果图像数据然后被转换成 TF 记录格式，以便更快地处理。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="04a0" class="mu ls iq mq b gy mv mw l mx my"><em class="mz"># </em>Create TF Record<em class="mz"><br/># download conversion script</em><br/><strong class="mq ir">if</strong> <strong class="mq ir">not</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>exists(files['TF_RECORD_SCRIPT']):<br/>    !git clone https:<strong class="mq ir">//</strong>github<strong class="mq ir">.</strong>com<strong class="mq ir">/</strong>nicknochnack<strong class="mq ir">/</strong>GenerateTFRecord {paths['SCRIPTS_PATH']}</span><span id="9232" class="mu ls iq mq b gy na mw l mx my">!python {files['TF_RECORD_SCRIPT']} <strong class="mq ir">-</strong>x {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], 'train')} <strong class="mq ir">-</strong>l {files['LABELMAP']} <strong class="mq ir">-</strong>o {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['ANNOTATION_PATH'], 'train.record')} <br/>!python {files['TF_RECORD_SCRIPT']} <strong class="mq ir">-</strong>x {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], 'test')} <strong class="mq ir">-</strong>l {files['LABELMAP']} <strong class="mq ir">-</strong>o {os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['ANNOTATION_PATH'], 'test.record')}</span></pre><p id="b594" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在开始训练模型之前，我们需要更新一些将偏离默认设置的配置参数，以便训练管道知道我们正在基于六个类别执行对象识别。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="90ce" class="mu ls iq mq b gy mv mw l mx my"><strong class="mq ir"># </strong>Update configuration file for transfer learning<strong class="mq ir"><br/>import</strong> tensorflow <strong class="mq ir">as</strong> tf<br/><strong class="mq ir">from</strong> object_detection.utils <strong class="mq ir">import</strong> config_util<br/><strong class="mq ir">from</strong> object_detection.protos <strong class="mq ir">import</strong> pipeline_pb2<br/><strong class="mq ir">from</strong> google.protobuf <strong class="mq ir">import</strong> text_format<br/><br/><em class="mz"># Read current configuration file</em><br/>pipeline_config <strong class="mq ir">=</strong> pipeline_pb2<strong class="mq ir">.</strong>TrainEvalPipelineConfig()<br/><strong class="mq ir">with</strong> tf<strong class="mq ir">.</strong>io<strong class="mq ir">.</strong>gfile<strong class="mq ir">.</strong>GFile(files['PIPELINE_CONFIG'], "r") <strong class="mq ir">as</strong> f:                                                                                                                                                                                                                     <br/>    proto_str <strong class="mq ir">=</strong> f<strong class="mq ir">.</strong>read()                                                                                                                                                                                                                                          <br/>    text_format<strong class="mq ir">.</strong>Merge(proto_str, pipeline_config)  <br/><br/><em class="mz"># Update based on new labels</em><br/>pipeline_config<strong class="mq ir">.</strong>model<strong class="mq ir">.</strong>ssd<strong class="mq ir">.</strong>num_classes <strong class="mq ir">=</strong> len(labels)<br/>pipeline_config<strong class="mq ir">.</strong>train_config<strong class="mq ir">.</strong>batch_size <strong class="mq ir">=</strong> 4<br/>pipeline_config<strong class="mq ir">.</strong>train_config<strong class="mq ir">.</strong>fine_tune_checkpoint <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')<br/>pipeline_config<strong class="mq ir">.</strong>train_config<strong class="mq ir">.</strong>fine_tune_checkpoint_type <strong class="mq ir">=</strong> "detection"<br/>pipeline_config<strong class="mq ir">.</strong>train_input_reader<strong class="mq ir">.</strong>label_map_path<strong class="mq ir">=</strong> files['LABELMAP']<br/>pipeline_config<strong class="mq ir">.</strong>train_input_reader<strong class="mq ir">.</strong>tf_record_input_reader<strong class="mq ir">.</strong>input_path[:] <strong class="mq ir">=</strong> [os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['ANNOTATION_PATH'], 'train.record')]<br/>pipeline_config<strong class="mq ir">.</strong>eval_input_reader[0]<strong class="mq ir">.</strong>label_map_path <strong class="mq ir">=</strong> files['LABELMAP']<br/>pipeline_config<strong class="mq ir">.</strong>eval_input_reader[0]<strong class="mq ir">.</strong>tf_record_input_reader<strong class="mq ir">.</strong>input_path[:] <strong class="mq ir">=</strong> [os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['ANNOTATION_PATH'], 'test.record')]<br/><br/><em class="mz"># Write to configuration file</em><br/>config_text <strong class="mq ir">=</strong> text_format<strong class="mq ir">.</strong>MessageToString(pipeline_config)                                                                                                                                                                                                        <br/><strong class="mq ir">with</strong> tf<strong class="mq ir">.</strong>io<strong class="mq ir">.</strong>gfile<strong class="mq ir">.</strong>GFile(files['PIPELINE_CONFIG'], "wb") <strong class="mq ir">as</strong> f:                                                                                                                                                                                                                     <br/>    f<strong class="mq ir">.</strong>write(config_text)</span></pre><p id="987d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用 Tensorflow 提供的训练脚本可以简化模型训练。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="b5e3" class="mu ls iq mq b gy mv mw l mx my">TRAINING_SCRIPT <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')<br/>command <strong class="mq ir">=</strong> "python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000"<strong class="mq ir">.</strong>format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])<br/>!{command}</span></pre><p id="52db" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于训练过程将保存中间检查点，即模型权重，因此我们可以选择加载哪个模型检查点并将其用于检测。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="69a3" class="mu ls iq mq b gy mv mw l mx my"><strong class="mq ir"># </strong>Load trained model from checkpoint<strong class="mq ir"><br/>import</strong> os<br/><strong class="mq ir">import</strong> tensorflow <strong class="mq ir">as</strong> tf<br/><strong class="mq ir">from</strong> object_detection.utils <strong class="mq ir">import</strong> label_map_util<br/><strong class="mq ir">from</strong> object_detection.utils <strong class="mq ir">import</strong> visualization_utils <strong class="mq ir">as</strong> viz_utils<br/><strong class="mq ir">from</strong> object_detection.builders <strong class="mq ir">import</strong> model_builder<br/><strong class="mq ir">from</strong> object_detection.utils <strong class="mq ir">import</strong> config_util<br/><br/><em class="mz"># Load pipeline config and build a detection model</em><br/>configs <strong class="mq ir">=</strong> config_util<strong class="mq ir">.</strong>get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])<br/>detection_model <strong class="mq ir">=</strong> model_builder<strong class="mq ir">.</strong>build(model_config<strong class="mq ir">=</strong>configs['model'], is_training<strong class="mq ir">=False</strong>)<br/><br/><em class="mz"># Restore checkpoint</em><br/>ckpt <strong class="mq ir">=</strong> tf<strong class="mq ir">.</strong>compat<strong class="mq ir">.</strong>v2<strong class="mq ir">.</strong>train<strong class="mq ir">.</strong>Checkpoint(model<strong class="mq ir">=</strong>detection_model)<br/>ckpt<strong class="mq ir">.</strong>restore(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['CHECKPOINT_PATH'], 'ckpt-3'))<strong class="mq ir">.</strong>expect_partial()<br/><br/><em class="mz"># @tf.function</em><br/><strong class="mq ir">def</strong> detect_fn(image):<br/>    image, shapes <strong class="mq ir">=</strong> detection_model<strong class="mq ir">.</strong>preprocess(image)<br/>    prediction_dict <strong class="mq ir">=</strong> detection_model<strong class="mq ir">.</strong>predict(image, shapes)<br/>    detections <strong class="mq ir">=</strong> detection_model<strong class="mq ir">.</strong>postprocess(prediction_dict, shapes)<br/>    <strong class="mq ir">return</strong> detections</span></pre><p id="0d45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以通过传递从前面定义的图像文件夹中随机选择的图像来测试微调后的模型。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="361a" class="mu ls iq mq b gy mv mw l mx my"><strong class="mq ir">import</strong> cv2 <br/><strong class="mq ir">from</strong> matplotlib <strong class="mq ir">import</strong> pyplot <strong class="mq ir">as</strong> plt<br/><strong class="mq ir">%</strong>matplotlib inline<br/><br/><em class="mz"># Randomly select an image to be detected</em><br/>tmp_img <strong class="mq ir">=</strong> random<strong class="mq ir">.</strong>choice([file <strong class="mq ir">for</strong> file <strong class="mq ir">in</strong> os<strong class="mq ir">.</strong>listdir(os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], <br/>                                              'test')) <strong class="mq ir">if</strong> file<strong class="mq ir">.</strong>endswith(".jpg")])<br/>IMAGE_PATH <strong class="mq ir">=</strong> os<strong class="mq ir">.</strong>path<strong class="mq ir">.</strong>join(paths['IMAGE_PATH'], 'test', tmp_img)<br/><br/>category_index <strong class="mq ir">=</strong> label_map_util<strong class="mq ir">.</strong>create_category_index_from_labelmap(files['LABELMAP'])<br/><br/>img <strong class="mq ir">=</strong> cv2<strong class="mq ir">.</strong>imread(IMAGE_PATH)<br/>image_np <strong class="mq ir">=</strong> np<strong class="mq ir">.</strong>array(img)<br/><br/>input_tensor <strong class="mq ir">=</strong> tf<strong class="mq ir">.</strong>convert_to_tensor(np<strong class="mq ir">.</strong>expand_dims(image_np, 0), dtype<strong class="mq ir">=</strong>tf<strong class="mq ir">.</strong>float32)<br/>detections <strong class="mq ir">=</strong> detect_fn(input_tensor)<br/><br/>num_detections <strong class="mq ir">=</strong> int(detections<strong class="mq ir">.</strong>pop('num_detections'))<br/>detections <strong class="mq ir">=</strong> {key: value[0, :num_detections]<strong class="mq ir">.</strong>numpy()<br/>              <strong class="mq ir">for</strong> key, value <strong class="mq ir">in</strong> detections<strong class="mq ir">.</strong>items()}<br/>detections['num_detections'] <strong class="mq ir">=</strong> num_detections<br/><br/><em class="mz"># detection_classes should be ints.</em><br/>detections['detection_classes'] <strong class="mq ir">=</strong> detections['detection_classes']<strong class="mq ir">.</strong>astype(np<strong class="mq ir">.</strong>int64)<br/><br/>label_id_offset <strong class="mq ir">=</strong> 1<br/>image_np_with_detections <strong class="mq ir">=</strong> image_np<strong class="mq ir">.</strong>copy()<br/><br/>viz_utils<strong class="mq ir">.</strong>visualize_boxes_and_labels_on_image_array(<br/>            image_np_with_detections,<br/>            detections['detection_boxes'],<br/>            detections['detection_classes']<strong class="mq ir">+</strong>label_id_offset,<br/>            detections['detection_scores'],<br/>            category_index,<br/>            use_normalized_coordinates<strong class="mq ir">=True</strong>,<br/>            max_boxes_to_draw<strong class="mq ir">=</strong>5,<br/>            min_score_thresh<strong class="mq ir">=</strong>.5,<br/>            agnostic_mode<strong class="mq ir">=False</strong>)<br/><br/>plt<strong class="mq ir">.</strong>imshow(cv2<strong class="mq ir">.</strong>cvtColor(image_np_with_detections, cv2<strong class="mq ir">.</strong>COLOR_BGR2RGB))<br/>plt<strong class="mq ir">.</strong>show()</span></pre><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nb"><img src="../Images/8a9cc0e0561ff4aa50e408ce6463b69d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CkVey1tniMFw1ZXg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">检测图像中的对象。图片由作者提供。</p></figure><h1 id="e946" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">使用 R Shiny 构建 Web 应用程序</h1><p id="c564" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">R Shiny 是构建现代 web 应用程序的一个很好的工具，不需要深入了解 HTML、CSS 或 Javascript。我们可以通过选择特定的应用程序框架并填充前端(ui)来快速启动应用程序。r)和后端(服务器。r)脚本，以及可选的全局文件(global。r)处理整个应用程序的环境。</p><p id="7ede" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">R Shiny 中用户界面的设计可以遵循如下的网格系统，这样可以很容易地决定在特定的行或列中添加什么组件。</p><pre class="lc ld le lf gt mp mq mr ms aw mt bi"><span id="8810" class="mu ls iq mq b gy mv mw l mx my">ui &lt;- dashboardPage(<br/> skin=”blue”,<br/> #(1) Header<br/> dashboardHeader(title=”Object Recognition App”,#,style=”font-size: 120%; font-weight: bold; color: white”),<br/> titleWidth = 250,<br/> tags$li(class = “dropdown”),<br/> dropdownMenu(<br/> type = “notifications”, <br/> icon = icon(“question-circle”),<br/> badgeStatus = NULL,<br/> headerText = “Feedback”,<br/> notificationItem(“Send email to developer”, icon = icon(“file”),<br/> href = “<a class="ae mo" href="mailto:liu.peng@u.nus.edu" rel="noopener ugc nofollow" target="_blank">liu.peng@u.nus.edu</a>”)<br/> )),<br/> #(2) Sidebar<br/> dashboardSidebar(<br/> width=250,<br/> fileInput(“input_image_upload”,”Upload image”, accept = c(‘.jpg’,’.jpeg’)),<br/> tags$br(),<br/> sliderInput(“min_score_threshold”,”Confidence threshold”,0,1,0.5),<br/> # tags$p(“Upload the image here.”)<br/> selectInput(inputId = “product_type”,label = “Choose product”,<br/> choices = c(“Flour”,”Baby Food”),<br/> selected = NA),<br/> selectInput(inputId = “halal_status”,label = “Halal status”,<br/> choices = c(“H”,”NH”),<br/> selected = NA),<br/> selectInput(inputId = “weight”,label = “Choose weight”,<br/> choices = c(“50g”,”100g”),<br/> selected = NA),<br/> actionButton(“submit”,”Submit”,icon(“paper-plane”), <br/> style=”color: #fff; background-color: #337ab7; border-color: #2e6da4")<br/> ),<br/> <br/> <br/> #(3) Body<br/> <br/> dashboardBody(<br/> box(<br/> title = “Object Recognition”, width = 12, solidHeader = TRUE, status = “primary”,<br/> collapsible = T, collapsed = F,<br/> fluidRow(<br/> column(6,<br/> h4(“Instruction:”),<br/> # tags$br(),<br/> tags$p(“1. Upload image to be classified and set confidence threshold.”),<br/> tags$p(“2. Check prediction results.”),<br/> tags$p(“3. Select specific product category.”),<br/> tags$p(“4. Click submit to record in the system.”)<br/> ),<br/> column(6,<br/> h4(“Predicted Category:”),<br/> tableOutput(“text”)<br/> )<br/> ),<br/> <br/> fluidRow(<br/> column(h4(“Image:”),imageOutput(“output_image”), width=6),<br/> column(h4(“Predicted Image:”),imageOutput(“output_image2”), width=6)<br/> )<br/> ),<br/> box(<br/> title = “Image Gallery”, width = 12, solidHeader = TRUE, status = “success”,<br/> collapsible = T, collapsed = F,<br/> fluidRow(<br/> column(3,<br/> h3(“All categories”),<br/> verbatimTextOutput(“all_cats”)<br/> ),<br/> column(3, <br/> selectInput(“input_image_select”, “Select image”,c(“”,ALL_IMGS),selected = “”),<br/> ),<br/> column(6,<br/> column(h4(“Image:”),imageOutput(“output_image_selected”), width=6),<br/> )<br/> )<br/> )<br/> <br/> # box(<br/> # title = “Product Recording”, width = 12, solidHeader = TRUE, status = “success”,<br/> # collapsible = T, collapsed = T,<br/> # “test”<br/> # )<br/> <br/> ))</span></pre><p id="8057" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">服务器处理所有后端处理，例如使用预先训练的模型对上传的图像进行预测，并将预测输出返回到前端 UI。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nc"><img src="../Images/7ed767a9729f674e7b698a0c521e3755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DE0Fyo8c-2jV6K13"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">服务器文件。图片由作者提供。</p></figure><p id="7a9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还在全局文件中定义了一些实用函数和环境设置。注意，R 使用 reticulate 库来处理 Python 脚本。在这种情况下，我们首先构建一个新的虚拟环境，为对象检测 conda 设置必要的背景环境，然后加载核心的图像识别 Python 函数，这些函数将以 API 的形式进行转换，与 R Shiny 生态系统进行交互。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nd"><img src="../Images/54ef7661c61ef20ae6f00c275a479b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6Xd73RHh0ArQh5AA"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">全局文件。图片由作者提供。</p></figure><h1 id="952b" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论</h1><p id="69d6" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在本教程中，我们介绍了如何通过迁移学习在 Tensorflow 中微调预训练的深度学习模型以进行杂货项目识别，以及如何通过 R Shiny 构建现代 web 应用程序来为最终用户托管模型。最终产品是 R &amp; Python 脚本的组合，其中核心 Python 功能(如对象检测)被无缝包装，并作为 API 向 R 公开，由 R 处理应用程序开发。我们希望本教程将是一个很好的起点，让您可以部署自己的模型，并以一种有效且吸引人的方式与他人分享。</p><p id="5d57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有支持数据和代码都可以在附带的<a class="ae mo" href="https://github.com/jackliu333/object_detection_using_tensorflow" rel="noopener ugc nofollow" target="_blank"> github </a>以及下面的 YouTube 浏览中找到。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ne nf l"/></div></figure></div></div>    
</body>
</html>