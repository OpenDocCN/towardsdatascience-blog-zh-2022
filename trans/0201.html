<html>
<head>
<title>Benchmarking 6 AutoML based Imputation techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基准测试 6 种基于 AutoML 的插补技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/benchmarking-6-automl-based-imputation-techniques-3b1defc0d25b#2022-02-08">https://towardsdatascience.com/benchmarking-6-automl-based-imputation-techniques-3b1defc0d25b#2022-02-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f7ef" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">插补策略基本指南</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e80534b53bb18ffd9c7299a6fcffc264.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qNB4cYKnCnnO4FacKd4CTw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=693873" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的<a class="ae ky" href="https://pixabay.com/users/wilhei-883152/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=693873" rel="noopener ugc nofollow" target="_blank">威利·海德尔巴赫</a></p></figure><p id="5fa2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现实世界中的数据集通常包含大量缺失值，这可能是由于数据损坏或记录数据失败造成的。数据中缺失值的存在妨碍了训练稳健的机器学习模型。大多数机器学习算法不支持缺失值，因此数据科学家需要在特征工程管道中明确处理缺失值。</p><p id="4dcb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有各种技术来处理或估算缺失值。在我以前的一篇文章中，我有 7 种处理缺失值的技术。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">机器学习中处理缺失值的 7 种方法</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">处理数据集中缺失值的常用策略</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="6e2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Scikit-learn、Verstack、Impyute 是各种开源包，提供了在几行 Python 代码中估算缺失值的实现。这些软件包实现了各种插补算法，包括 KNN 插补、随机森林插补、迭代插补等。</p><p id="9e96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将讨论和基准的各种插补算法的性能指标。</p><h1 id="7b0d" class="mn mo it bd mp mq mr ms mt mu mv mw mx jz my ka mz kc na kd nb kf nc kg nd ne bi translated">开始使用:</h1><p id="7f85" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">在开始实施插补算法之前，让我们准备一个自定义数据集，并用缺失值替换一些值。样本数据集有 28 个特征，其中 5 个特征的 25%的值为 NaNs <em class="nk"> (12，500 个数据值)</em>。我们保留了原始数据集的副本(具有 NaNs 的实际值),以比较每种插补策略的性能。</p><p id="d400" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请在我的<a class="ae ky" href="https://gist.github.com/satkr7/887ed6f2348f29086d7d51b8faa1e293" rel="noopener ugc nofollow" target="_blank"> GitHub gist </a>中找到实用函数来计算平均绝对误差并生成误差图。</p><h2 id="da78" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">1)简单估算器:</h2><p id="847c" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">简单估算法可被视为一种基本或最简单的估算技术，其中缺失值由平均值、中间值、最频繁值或常数值替代。Scikit-learn 包提供了<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">简单估算器</a>的实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，简单估算器的实现</p></figure><p id="dcad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用简单估算器的实际值和预测估算值之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank">平均绝对误差</a>为<code class="fe nz oa ob oc b"><strong class="lb iu"><em class="nk">0.01369</em></strong></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/9afa0d352f9495ff14214a0ce77f7d11.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*sT31sqEUkMRtabWxKqig_Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，简单估算器的误差分布图</p></figure><h2 id="e062" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">2)迭代估算器:</h2><p id="48d9" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">迭代输入是一种输入缺失值的策略，通过循环方式将每个具有缺失值的要素建模为其他要素的函数。Scikit-learn 还提供了<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html#sklearn.impute.IterativeImputer" rel="noopener ugc nofollow" target="_blank">迭代估算器</a>的实现。</p><p id="60a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">默认情况下，迭代估算器使用一个可配置的<strong class="lb iu"> <em class="nk"> BayesianRidge </em> </strong>估算器。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，迭代估算器的实现</p></figure><p id="3b66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用简单估算器的实际值和预测估算值之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank">平均绝对误差</a>为<code class="fe nz oa ob oc b"><strong class="lb iu"><em class="nk">0.01359</em></strong></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b775444a55f3d613ffb49c6dddb9e011.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*VXqEjBw9HTRRCsbGmqK6yA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，迭代估算的误差分布图</p></figure><h2 id="93a4" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">3)KNN-估算者:</h2><p id="86a6" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">KNN 估算器使用在训练集中找到的<code class="fe nz oa ob oc b"><strong class="lb iu">n_neighbors</strong></code>最近邻的平均值估算每个缺失值。它假设两个样本是接近的，如果两个样本都不缺少的特征是接近的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，KNN 估算器的实现</p></figure><p id="9a44" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用简单估算器的实际值和预测估算值之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank">平均绝对误差</a>为<code class="fe nz oa ob oc b"><strong class="lb iu"><em class="nk">0.00867</em></strong></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/0fd2beb557393949baa82af035b38df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*uwuTT5PsWMN0CPbLPmCulA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，KNN-估算器的误差分布图</p></figure><h2 id="13d0" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">4)ver stack—nan inputr:</h2><p id="2c00" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated"><a class="ae ky" href="https://verstack.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">nan import</a><strong class="lb iu"/>使用 xgboost 模型对熊猫数据框中所有缺失值进行估算。xgboost 模型经过多重处理训练，因此估算值相对较快。</p><p id="e70e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用 NaN Imputer，您可以使用 XGBoost 回归器/分类器更新数值、二进制、分类的缺失值。这个基于 XGBoost 的 NaNImputer 可以使用 verstack 包在一行 Python 代码中实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，ver stack NaN-inputr 的实现</p></figure><p id="fa1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际值和使用小鼠估算器预测的估算值之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank">平均绝对误差</a>为<code class="fe nz oa ob oc b"><strong class="lb iu"><em class="nk">0.00903</em></strong></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/09aab4bce338929534b399303ba9eb55.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*RUQRPP4W4oxAjq5JL-5dQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，ver stack NaN-inputer 的误差分布图</p></figure><h2 id="5922" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">5)小白鼠:</h2><p id="46f5" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">链式方程多变量插补(<a class="ae ky" href="https://impyute.readthedocs.io/en/latest/_modules/impyute/imputation/cs/mice.html" rel="noopener ugc nofollow" target="_blank">小鼠</a>)是一种插补缺失值的迭代方法。它假设数据是随机丢失的，并通过查看其他样本值对其真实值进行有根据的猜测。Impyute 包提供了鼠标的实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)，MICE 的实现</p></figure><p id="c405" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际值和使用鼠标估算器预测的估算值之间的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html" rel="noopener ugc nofollow" target="_blank"> mean_absolute_error </a>为<code class="fe nz oa ob oc b"><strong class="lb iu"><em class="nk">0.01371</em></strong></code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/b9a7063374100635ca1e39941314b051.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*nAhtKIFigljQ6p2FHZYTTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，老鼠的误差分布图</p></figure><h2 id="0853" class="nl mo it bd mp nm nn dn mt no np dp mx li nq nr mz lm ns nt nb lq nu nv nd nw bi translated">基准测试:</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/620d872fb85da648b98169b9e35fdb7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZBbFchewdhjq71eOoHd1A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)，上述插补技术的基准平均绝对误差</p></figure><p id="67fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从上表中，我们可以得出结论，KNN 估算器(Scikit-learn)和南估算器(verstack)在估算缺失数据值方面表现最佳，性能提高了 55%到 60%。</p><p id="5b3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，KNN 估算器和南估算器的误差图相对优于其他误差图，大多数误差等于或接近于 0。</p></div><div class="ab cl og oh hx oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="im in io ip iq"><h1 id="63f0" class="mn mo it bd mp mq on ms mt mu oo mw mx jz op ka mz kc oq kd nb kf or kg nd ne bi translated">结论:</h1><p id="b92d" class="pw-post-body-paragraph kz la it lb b lc nf ju le lf ng jx lh li nh lk ll lm ni lo lp lq nj ls lt lu im bi translated">在本文中，我们讨论了使用各种开源软件包的 API 函数来估算缺失值的 5 种方法或技术。在这 5 种技术中，scikit-learn 中实现的 KNN 估算器表现最佳，与使用均值策略估算缺失数据的基线简单估算器相比，性能提高了 x%。</p><p id="fa39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，verstack 包中实现的 nan inputr 函数对该数据的执行效果不太好，但它可以估算值，而不考虑要素的数据类型(数值、二进制、分类)。</p><p id="8aef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的基准测试数据是针对一个小的数据集样本生成的，但是很好地概述了各种技术的表现。</p><blockquote class="os"><p id="8d38" class="ot ou it bd ov ow ox oy oz pa pb lu dk translated">感谢您的阅读</p></blockquote></div></div>    
</body>
</html>