<html>
<head>
<title>Diving into C-Support Vector Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究C-支持向量分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/diving-into-c-support-vector-classification-221ced32e4b4#2022-10-18">https://towardsdatascience.com/diving-into-c-support-vector-classification-221ced32e4b4#2022-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3cbc" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">SVC算法能为我们做的技巧</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c882d02335237702f6f4a2b68694450c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YUgLFZm-fyTPJghC2jer5w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@davidrotimi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">大卫·罗蒂米</a>在<a class="ae ky" href="https://unsplash.com/s/photos/separate?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="ad8d" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="5587" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">最近我一直在研究Scikit-Learn，并记下了这个神奇的库所提供的工具。在本帖中，我们来了解一下<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">C-支持向量机</a>分类器。</p><p id="894c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">支持向量机(SVM)是一种监督学习算法，可用于分类或回归。它适用于边界的线性和非线性计算，因此对一些问题很有用。</p><p id="b45e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">支持向量机可以替代其他好的算法，如决策树、逻辑回归或随机森林，因此它是一个很好的技能补充。</p><h1 id="1399" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">支持向量机</h1><p id="52f9" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">支持向量机是一种将数据点分为两类的算法。一旦对所有点都完成了，算法就开始追踪两个类之间的分离边缘处的一些线，目标是最大化它们之间的距离。它找到最大距离的地方就是最佳分隔线所在的地方。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/df2e6553ea2f0d310c81c4eb2b80c6b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*RcsDN9OXRhb9rivErv7cfA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蓝线是两个等级之间的最大距离。图片由作者提供。</p></figure><p id="fc6d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">对于线性分离的数据集，该算法工作得非常好。但是，如果我们的数据不是线性的呢？怎么还能用？</p><p id="53e0" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果我们查看文档，我们会发现有一个名为<code class="fe nf ng nh ni b">kernel</code>的超参数。内核是算法用来将点分成不同组并对它们进行分类的逻辑。</p><blockquote class="nj nk nl"><p id="1cc6" class="ly lz nm ma b mb mu ju md me mv jx mg nn mw mj mk no mx mn mo np my mr ms mt im bi translated"><strong class="ma iu">内核:<em class="it"> { '线性'，' poly '，' rbf '，' sigmoid '，' precomputed'}或可调用，默认='rbf' </em> </strong></p></blockquote><h2 id="fe72" class="nq lh it bd li nr ns dn lm nt nu dp lq mh nv nw ls ml nx ny lu mp nz oa lw ob bi translated">线性的</h2><p id="8e16" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><code class="fe nf ng nh ni b">linear</code>内核非常简单。SVM将创建线条，就像之前显示的图形一样。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="8b50" class="nq lh it ni b gy og oh l oi oj">SVC(kernel='linear')</span></pre><h2 id="e218" class="nq lh it bd li nr ns dn lm nt nu dp lq mh nv nw ls ml nx ny lu mp nz oa lw ob bi translated">多项式</h2><p id="fbaf" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated"><code class="fe nf ng nh ni b"> poly</code>选项是针对多项式内核的。如果你观察多项式的形状，你会发现随着次数的增加，曲线越来越多，变得越来越不规则。因此，对于模型欠拟合，增加多项式次数可能是一个好主意，使决策边界绕过更多的点。<code class="fe nf ng nh ni b">C</code>是正则化超参数，<code class="fe nf ng nh ni b">coef0</code>平衡了模型受高次或低次多项式的影响。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="c9a2" class="nq lh it ni b gy og oh l oi oj">SVC(kernel='poly', degree=3, coef0=1, C=5)</span></pre><h2 id="48e9" class="nq lh it bd li nr ns dn lm nt nu dp lq mh nv nw ls ml nx ny lu mp nz oa lw ob bi translated">肾血流量（renal blood flow的缩写）</h2><p id="e6ab" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">该内核<code class="fe nf ng nh ni b">rbf</code>用于高斯<strong class="ma iu">径向</strong>径向<strong class="ma iu">径向</strong>径向<strong class="ma iu">函数。它创建高斯分布来计算哪一个点更适合，以确定如何对这些点进行分类。超参数<code class="fe nf ng nh ni b">gamma</code>使高斯曲线更窄(高伽玛值，更多偏差)或更宽(低伽玛值，更平滑的边界)。所以，如果我们增加伽玛，我们的决策边界会更加不规则。如果你的模型不合适，试着增加这个数字。如果过拟合，降低伽玛。<code class="fe nf ng nh ni b">C</code>是正则化数。它的工作方式与gamma参数相似。</strong></p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="0024" class="nq lh it ni b gy og oh l oi oj">SVC(kernel='rbf', gamma=4, C=100)</span></pre><h2 id="ddc6" class="nq lh it bd li nr ns dn lm nt nu dp lq mh nv nw ls ml nx ny lu mp nz oa lw ob bi translated">乙状结肠的</h2><p id="3d45" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">内核<code class="fe nf ng nh ni b">sigmoid</code>使用类似逻辑回归的逻辑，其中高达50%的概率属于一个类，超过这个数字，它属于相反的类。你可以使用<code class="fe nf ng nh ni b">gamma</code>超参数来正则化。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="aa21" class="nq lh it ni b gy og oh l oi oj">SVC(kernel='sigmoid', gamma=2)</span></pre><h2 id="83d5" class="nq lh it bd li nr ns dn lm nt nu dp lq mh nv nw ls ml nx ny lu mp nz oa lw ob bi translated">预先计算的</h2><p id="98ae" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">最后，这最后一个内核用于更高级/定制的情况，您可以创建自己的内核来运行模型。</p><h1 id="b2a9" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">编码</h1><p id="433a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">使用sklearn的SVC类创建一个基本的SVM，并不需要花费太多时间。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="afa9" class="nq lh it ni b gy og oh l oi oj"># Imports<br/>import pandas as pd<br/>import seaborn as sns</span><span id="d767" class="nq lh it ni b gy ok oh l oi oj"># Data<br/>from sklearn.datasets import make_classification</span><span id="f73c" class="nq lh it ni b gy ok oh l oi oj"># sklearn<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.svm import SVC<br/>from sklearn.metrics import confusion_matrix</span></pre><p id="4efa" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">创建数据集并在训练和测试中拆分。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="0d37" class="nq lh it ni b gy og oh l oi oj"># Dataset<br/>X, y = make_classification(n_classes=2, n_features=6, n_samples=500, n_informative=2, scale=100, random_state=12)</span><span id="8fc6" class="nq lh it ni b gy ok oh l oi oj"># Dataframe<br/>df = pd.DataFrame(X, columns=['var'+str(i) for i in range(1, X.shape[1]+1)])<br/>df['label'] = y</span><span id="4c2b" class="nq lh it ni b gy ok oh l oi oj">#Train test split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)</span></pre><p id="be50" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">快速查看创建的数据。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/09db3cce30ed7d4c5b36beb7ea533582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*0PYxDIFpUFxQt00R6ounlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">本例的数据集。图片由作者提供。</p></figure><p id="0995" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们使用RBF内核创建一个SVM。建议您缩放数据以获得更好的结果。为此，我们可以用运行该任务的步骤和函数的名称创建元组。请注意，我们正在(1)缩放数据；(2)用核RBF训练一个SVC。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="1d76" class="nq lh it ni b gy og oh l oi oj">steps = [('scaler', StandardScaler()),<br/>         ('svm_classif', SVC(kernel='rbf', gamma=0.5, C=10))]</span><span id="c5a7" class="nq lh it ni b gy ok oh l oi oj"># Create Pipeline object<br/>rbf_kernel = Pipeline(steps)</span><span id="8de2" class="nq lh it ni b gy ok oh l oi oj"># Run the pipeline (fit) <br/>#Scale data and Fit the model<br/>rbf_kernel.fit(X_train,y_train)</span><span id="b34e" class="nq lh it ni b gy ok oh l oi oj"># Predictions<br/>preds = rbf_kernel.predict(X_test)</span></pre><p id="696c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">接下来看看表现。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="50c3" class="nq lh it ni b gy og oh l oi oj"># performance dataframe<br/>result = pd.DataFrame(X_test, columns=['var'+str(i) for i in range(1, X.shape[1]+1)])</span><span id="af77" class="nq lh it ni b gy ok oh l oi oj">result['preds'] = preds</span><span id="efd1" class="nq lh it ni b gy ok oh l oi oj"># Plot var1(on x) and var5(on y)<br/>sns.scatterplot(data=result, x='var1', y='var5', hue='preds');</span></pre><p id="5e0b" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这就产生了下面的情节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/2f25deca3544fcad5f46921fd6db04c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*n8dVWo2lepK5znJYK8wqJA.png"/></div></figure><p id="b1cf" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这里是混淆矩阵，看看这个模型在分类方面的表现。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="450c" class="nq lh it ni b gy og oh l oi oj"># Confusion Matrix<br/>pd.DataFrame(confusion_matrix(y_test, result.preds, labels=[0,1]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7c69851dfea1f266bfde0c751ecf3034.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/1*PDVnJlBN0IOxfMLpus0ofw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SVC的混淆矩阵。图片由作者提供。</p></figure><p id="402d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">非常好！只有5个假阳性和1个假阴性，准确率高达94%。</p><p id="b860" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果我们训练一个随机森林分类器，这就是结果。</p><pre class="kj kk kl km gt oc ni od oe aw of bi"><span id="201d" class="nq lh it ni b gy og oh l oi oj">from sklearn.ensemble import RandomForestClassifier</span><span id="93d3" class="nq lh it ni b gy ok oh l oi oj">steps = [('scaler', StandardScaler()),<br/>         ('rf_classif', RandomForestClassifier())]</span><span id="1ee9" class="nq lh it ni b gy ok oh l oi oj"># Create pipeline<br/>rf = Pipeline(steps)</span><span id="15f8" class="nq lh it ni b gy ok oh l oi oj"># Fit<br/>rf.fit(X_train,y_train)</span><span id="2edd" class="nq lh it ni b gy ok oh l oi oj"># Preds<br/>preds = rf.predict(X_test)</span><span id="1c78" class="nq lh it ni b gy ok oh l oi oj"># performance<br/>result = pd.DataFrame(X_test, columns=['var'+str(i) for i in range(1, X.shape[1]+1)])</span><span id="645c" class="nq lh it ni b gy ok oh l oi oj">result['preds'] = preds</span><span id="5b06" class="nq lh it ni b gy ok oh l oi oj"># Confusion Matrix<br/>pd.DataFrame(confusion_matrix(y_test, result.preds, labels=[0,1]))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/afb5abb291a2a81ff2a874dd11f88946.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/1*FhBLTPc5vE30zZDs7Mx2oQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机森林的混淆矩阵。图片由作者提供。</p></figure><p id="e52c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">类似的结果。这里的准确率是92%，稍微低一点，但是我们必须注意到对于随机森林没有任何调整。可以改进。</p><h1 id="5594" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">在你走之前</h1><p id="35e2" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我相信知道更多的算法和它们如何在引擎盖下工作是很好的。像数据科学中的许多事情一样，最佳选择不是这个或那个算法，而是为您的问题提供最佳结果的算法。所以，多了解一个，你就增加了获得更好结果的机会。</p><p id="acd4" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在这篇文章中，我们深入研究了<code class="fe nf ng nh ni b">SVC</code>算法，学习如何为每个内核选择主超参数，以及它们本质上是如何工作的。</p><p id="7276" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">请记住，文档是您的朋友，可以提供很多帮助。另一个很好的资源是这本书《sklearn、Keras和Tensorflow的机器学习实践》。我一直在阅读和享受很多。</p><p id="8e34" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在GitHub的这个<a class="ae ky" href="https://github.com/gurezende/Studying/blob/master/Python/sklearn/SVC.ipynb" rel="noopener ugc nofollow" target="_blank">库中找到这篇文章的代码。</a></p><p id="1ac6" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这是我的博客，如果你喜欢这个内容，想关注我或者在<a class="ae ky" href="https://www.linkedin.com/in/gurezende/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>找到我。</p><div class="op oq gp gr or os"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg ks os"/></div></div></a></div><p id="1b48" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你想成为中级会员，这个<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">推荐代码</a>会激励我加入你的订阅。</p><h1 id="b077" class="lg lh it bd li lj mz ll lm ln na lp lq jz nb ka ls kc nc kd lu kf nd kg lw lx bi translated">参考</h1><div class="op oq gp gr or os"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">sklearn.svm.SVC</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">c-支持向量分类。该实现基于libsvm。拟合时间至少与…成二次比例</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">scikit-learn.org</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://scikit-learn.org/stable/modules/svm.html#svm-kernels" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">1.4.支持向量机</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">支持向量机是一组用于分类、回归和分类的监督学习方法</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">scikit-learn.org</p></div></div><div class="pb l"><div class="pi l pd pe pf pb pg ks os"/></div></div></a></div><p id="b270" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Support_vector_machine</a></p><div class="op oq gp gr or os"><a href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=asc_df_1492032646/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=385599638286&amp;hvpos=&amp;hvnetw=g&amp;hvrand=847972974391386897&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9009674&amp;hvtargid=pla-523968811896&amp;psc=1&amp;tag=&amp;ref=&amp;adgrpid=79288120515&amp;hvpone=&amp;hvptwo=&amp;hvadid=385599638286&amp;hvpos=&amp;hvnetw=g&amp;hvrand=847972974391386897&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9009674&amp;hvtargid=pla-523968811896" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">使用Scikit-Learn、Keras和TensorFlow进行机器实践学习:概念、工具和技术…</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">用Scikit-Learn、Keras和TensorFlow进行机器学习:概念、工具和技术来构建…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">www.amazon.com</p></div></div><div class="pb l"><div class="pj l pd pe pf pb pg ks os"/></div></div></a></div><div class="op oq gp gr or os"><a href="https://stats.stackexchange.com/questions/90736/the-difference-of-kernels-in-svm" rel="noopener  ugc nofollow" target="_blank"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd iu gy z fp ox fr fs oy fu fw is bi translated">SVM果仁的区别？</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">感谢您为交叉验证提供答案！请务必回答问题。提供详细信息并分享…</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">stats.stackexchange.com</p></div></div><div class="pb l"><div class="pk l pd pe pf pb pg ks os"/></div></div></a></div><p id="bb63" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">一个漂亮的Github页面，包含每个内核的所有可视化内容:</p><p id="c6f2" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><a class="ae ky" href="https://gist.github.com/WittmannF/60680723ed8dd0cb993051a7448f7805" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/WittmannF/60680723 ed 8d d0 CB 993051 a 7448 f 7805</a></p></div></div>    
</body>
</html>