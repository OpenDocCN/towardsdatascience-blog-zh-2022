<html>
<head>
<title>Introduction to Image Classification with TensorFlow — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流图像分类简介(二)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef#2022-10-03">https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef#2022-10-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d5c8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python计算机视觉初学者实用指南</h2></div><p id="940d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" rel="noopener" target="_blank" href="/introduction-to-image-classification-with-tensorflow-part-1-381d0a373b8f">在</a>系列的第一部分中，我们在包含手写数字黑白图像的MNIST数据集上构建了基本的图像分类模型。这些数据很容易通过TensorFlow获得。然而，在实践中，现实生活中的图像是丰富多彩的，数据通常不容易获得。在这篇文章中，我们将练习自己加载图像数据，并在彩色图像上建立模型。我们还将学习一点关于迁移学习的知识。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/a53ab1189ff9618dc9710a08e4c593ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xI150zWls0ow5L2O"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">照片由<a class="ae le" href="https://unsplash.com/@picoftasty?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Mae Mu </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="f4ac" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">📦数据</h1><p id="c5e2" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我们将使用从蔬菜农场和市场收集的15种蔬菜的图像。关于该数据集的官方论文可在<a class="ae le" href="https://www.researchgate.net/publication/352846889_DCNN-Based_Vegetable_Image_Classification_Using_Transfer_Learning_A_Comparative_Study" rel="noopener ugc nofollow" target="_blank">这里</a>获得。数据集可通过<a class="ae le" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0许可证</a>获得。</p><p id="58e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您想跟随教程，请从<a class="ae le" href="https://www.kaggle.com/datasets/misrakahmed/vegetable-image-dataset" rel="noopener ugc nofollow" target="_blank">蔬菜图像数据集| Kaggle </a>下载数据集，并将数据保存在与您的笔记本位于同一目录的名为<code class="fe mz na nb nc b">data</code>的文件夹中，并将<code class="fe mz na nb nc b">validation</code>子目录重命名为<code class="fe mz na nb nc b">valid</code>。完成后，您的工作目录将如下所示:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="1b6c" class="nh md it nc b gy ni nj l nk nl">image_classification<br/>├── *.ipynb<br/>├── data<br/>│   ├── train<br/>│   │   ├── class 1<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg<br/>│   │   ├── ...<br/>│   │   ├── class n<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg<br/>│   ├── valid<br/>│   │   ├── class 1<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg<br/>│   │   ├── ...<br/>│   │   ├── class n<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg<br/>│   ├── test<br/>│   │   ├── class 1<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg<br/>│   │   ├── ...<br/>│   │   ├── class n<br/>│   │   │   ├── image1.jpg<br/>│   │   │   ├── ...<br/>│   │   │   ├── imagen.jpg</span></pre><p id="9a59" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是组织图像的完美格式。每个分区数据集将不同类别的图像保存在以类别命名的单独子目录中。</p><p id="b171" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在将加载图像库并检查图像总数:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="9231" class="nh md it nc b gy ni nj l nk nl">import pathlib<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>import seaborn as sns<br/>sns.set(style='darkgrid', context='talk')</span><span id="fb0f" class="nh md it nc b gy nm nj l nk nl">import tensorflow as tf<br/>from tensorflow.keras.preprocessing import image_dataset_from_directory<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import (Input, Rescaling, Conv2D, <br/>                                     MaxPooling2D, Flatten, Dense)<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.applications.resnet import ResNet50</span><span id="3920" class="nh md it nc b gy nm nj l nk nl">images = [*pathlib.Path('data').glob('**/*.jpg')]<br/>print(f"There are {len(images)} images.")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/aca20f14fa4f41f3d27e965d1129f026.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*HluWC7tI9FAICuZY7jhQJg.png"/></div></figure><p id="1561" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们总共有21K张图片。让我们确认在分区的数据集中类名是相同的:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="59ed" class="nh md it nc b gy ni nj l nk nl">train_classes = [item.name for item in <br/>                 pathlib.Path('data/train').glob('*')]<br/>valid_classes = [item.name for item in <br/>                 pathlib.Path('data/valid').glob('*')]<br/>test_classes = [item.name for item in <br/>                pathlib.Path('data/test').glob('*')]</span><span id="cf45" class="nh md it nc b gy nm nj l nk nl">if train_classes==valid_classes==test_classes:<br/>    print("All datasets have the same classes.")<br/>print(f"There are total of {len(train_classes)} classes.")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/ab717ad5876c3a29929b55fd1ec8f353.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*LVkImW6051iwSLuw92UK4Q.png"/></div></figure><p id="9894" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太棒了，数据集上的类名都匹配。我们现在将创建<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> TensorFlow数据集</a>，它将在需要时批量加载数据。我们将混洗训练图像，以便在每一批中我们都有混合的蔬菜。</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="428d" class="nh md it nc b gy ni nj l nk nl">image_size = (224, 224)<br/>shape = image_size + (3,)<br/>batch_size = 32</span><span id="a129" class="nh md it nc b gy nm nj l nk nl">print("========== Training data ==========")<br/>train_data = image_dataset_from_directory(<br/>    directory='data/train', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    seed=42<br/>)<br/>print("\n========== Validation data ==========")<br/>valid_data = image_dataset_from_directory(<br/>    directory='data/valid', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    shuffle=False<br/>)</span><span id="612d" class="nh md it nc b gy nm nj l nk nl">print("\n========== Test data ==========")<br/>test_data = image_dataset_from_directory(<br/>    directory='data/test', label_mode='categorical',<br/>    image_size=image_size, batch_size=batch_size,<br/>    shuffle=False<br/>)</span><span id="ac9e" class="nh md it nc b gy nm nj l nk nl">len(train_data.class_names)==len(valid_data.class_names)==len(test_data.class_names)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ca3b6d75e261b98108bfa7fd488f663e.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*kB3kU1Rnz1NJ3-cp_hQ2EA.png"/></div></figure><p id="40fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从图像的父目录推断图像的类名。我们看到这些推断的类名可以通过<code class="fe mz na nb nc b">.class_names</code>属性访问。让我们按类检查每个数据集的图像数量:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="956d" class="nh md it nc b gy ni nj l nk nl">summary = pd.DataFrame()<br/>for d in ['train', 'valid', 'test']:<br/>    for c in train_classes:<br/>        n = len([i for i in <br/>                 pathlib.Path(f'data/{d}/{c}').glob('*.jpg')])<br/>        summary.loc[c, d] = n<br/>summary.style.format("{:.0f}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/17522318910ec1b61e897e8f527e2996.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*-2FASMLIGMWZLJki2jjDxg.png"/></div></figure><p id="4f1f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">每堂课有1000个训练、200个验证和200个测试图像。</p><p id="b3bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们在开始建模之前看看示例图像:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="8983" class="nh md it nc b gy ni nj l nk nl">n_rows = 2<br/>n_cols = 3</span><span id="0e03" class="nh md it nc b gy nm nj l nk nl">train_path = pathlib.Path('data/train')<br/>train_images = [item for item in train_path.glob('*/*.jpg')]<br/>np.random.seed(42)<br/>sample_images = np.random.choice(train_images, n_rows*n_cols, <br/>                                 replace=False)</span><span id="665e" class="nh md it nc b gy nm nj l nk nl">plt.figure(figsize=(12,8))<br/>for i, image in enumerate(sample_images):<br/>    ax = plt.subplot(n_rows, n_cols, i+1)<br/>    plt.imshow(mpimg.imread(image))<br/>    plt.axis('off')<br/>    plt.title(image.parts[2])<br/>plt.suptitle('Sample training images', fontsize=20);</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/7668605b6f5ea8f8fce813bc12039cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*wbo_4Jsm2UY3rxIRN-0q_g.png"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="0084" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">🔨系统模型化</h1><h2 id="dc11" class="nh md it bd me ns nt dn mi nu nv dp mm kr nw nx mo kv ny nz mq kz oa ob ms oc bi translated">🔧型号0</h2><p id="991f" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">在第1部分中，我们构建的CNN架构被证明是MNIST数据集上表现最好的模型。因此，我们将从对蔬菜数据应用与基线模型相同的体系结构开始:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="5cf1" class="nh md it nc b gy ni nj l nk nl">n_classes = len(train_data.class_names)</span><span id="092e" class="nh md it nc b gy nm nj l nk nl">model_0 = Sequential([<br/>    Rescaling(1./255, input_shape=shape),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Flatten(),<br/>    Dense(128, activation='relu'),<br/>    Dense(n_classes, activation='softmax')<br/>])</span><span id="f150" class="nh md it nc b gy nm nj l nk nl">model_0.compile(loss='categorical_crossentropy', optimizer='Adam', <br/>                metrics=['accuracy'])<br/>model_0.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d2e4993529e57abee27a55e02b29e2a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*VDF4qS92jO0D-v0T8KGNVw.png"/></div></figure><p id="433e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们训练网络。我们将只运行两个阶段，因为现在培训更加耗时:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="fcbf" class="nh md it nc b gy ni nj l nk nl">hist_0 = model_0.fit(train_data, epochs=2, <br/>                     validation_data=valid_data)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/f3f80c8d3e07c52e17b46d16646eeffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*cXcgtS6ZaV9nvTY4etQ-Sg.png"/></div></figure><p id="41ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于15个类别，大约87%的准确率相当不错。让我们看看不同时期的准确性:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d72a" class="nh md it nc b gy ni nj l nk nl">def clean_history(hist):<br/>    epochs = len(hist.history['accuracy'])<br/>    df = pd.DataFrame(<br/>        {'epochs': np.tile(np.arange(epochs), 2),<br/>         'accuracy': hist.history['accuracy'] + <br/>                     hist.history['val_accuracy'], <br/>         'loss': hist.history['loss'] + <br/>                 hist.history['val_loss'], <br/>         'dataset': np.repeat(['train', 'valid'], epochs)}<br/>    )<br/>    return df</span><span id="0a3a" class="nh md it nc b gy nm nj l nk nl">sns.lineplot(data=clean_history(hist_0), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/032d55954056cdc11786d54341c29e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*JEB-_49qIn7aJy0cQD91xA.png"/></div></figure><p id="3e8b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将为每个测试图像准备标签。这将有助于进一步评估模型:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="3d7b" class="nh md it nc b gy ni nj l nk nl">test_path = pathlib.Path('data/test')<br/>test_images = [item for item in test_path.glob('*/*.jpg')]</span><span id="22e3" class="nh md it nc b gy nm nj l nk nl">test_labels = []<br/>for _, labels in test_data.unbatch():<br/>    test_labels.append(labels.numpy().argmax())<br/>test_labels[:10]</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/4b5af0b8ac8eab79b55e8cd6f8193303.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*cDybMhiCKSSOhwJW3tzWxA.png"/></div></figure><p id="ffb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们根据测试数据检查模型的性能:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="13c5" class="nh md it nc b gy ni nj l nk nl">test_preds_0 = model_0.predict(test_data)<br/>test_classes_0 = test_preds_0.argmax(axis=1)<br/>test_metrics = pd.DataFrame(columns=['Test accuracy'])<br/>test_metrics.loc['model_0'] = np.mean(test_labels==test_classes_0)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5047b6dc1408395afde1fe73ed12b29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*7jp6rVTxM2is5dKu-f0I8A.png"/></div></figure><p id="42d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第一个模型约87%的准确率是一个很好的开始。让我们通过课堂来理解表演:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="275d" class="nh md it nc b gy ni nj l nk nl">def show_confusion_matrix(labels, classes):<br/>    cm = (pd.crosstab(pd.Series(labels, name='actual'), <br/>                      pd.Series(classes, name='predicted'))<br/>            .style.background_gradient('binary'))<br/>    return cm</span><span id="e3b3" class="nh md it nc b gy nm nj l nk nl">show_confusion_matrix(test_labels, test_classes_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/7c6e793e27823740729bdcd4d5141d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*RWtuPpQck-Zvcp0PXJInAA.jpeg"/></div></figure><p id="af9b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很高兴看到大部分图像都集中在对角线上。在这里，我们选择不命名类，因为有空格(用类名代替数字会扩大表格的尺寸)。对角线上有一些较深的灰色单元格。例如，3班有时会与10班混淆。有一种方法可以找到3级和10级的标签:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="7b41" class="nh md it nc b gy ni nj l nk nl">print(f"Class 3 is {train_data.class_names[3]}")<br/>print(f"Class 10 is {train_data.class_names[10]}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oj"><img src="../Images/32ed4000ba40a4f58034639d8c4fb271.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*eq-Ck9sOt4JgPpsW_zhtmQ.png"/></div></div></figure><p id="0476" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">所以布林哈尔偶尔会被误认为是木瓜。现在，让我们看看一些示例图像及其预测:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="0993" class="nh md it nc b gy ni nj l nk nl">def inspect_sample_predictions(images, preds, dataset='test', <br/>                               seed=42, n_rows=2, n_cols=3):<br/>    np.random.seed(seed)<br/>    indices = np.random.choice(range(len(images)), n_rows*n_cols, <br/>                               replace=False)<br/>    plt.figure(figsize=(12,8))<br/>    for i, index in enumerate(indices):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        image = images[index]<br/>        plt.imshow(mpimg.imread(image))<br/>        plt.axis('off')<br/>        <br/>        proba = preds[index].max()<br/>        pred = preds[index].argmax()<br/>        pred_class = test_data.class_names[pred]<br/>        if pred_class == image.parts[2]:<br/>            colour = 'green'<br/>        else:<br/>            colour = 'red'<br/>        plt.title(f"Actual: {image.parts[2]} \nPredicted: {pred_class} ({proba:.1%})", color=colour, fontsize=14)<br/>    plt.suptitle(f'Sample {dataset} images with prediction', fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>inspect_sample_predictions(test_images, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ok"><img src="../Images/6ca58ab79ff564b3a432dbf291a0aa4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsUXOjMTfAy6rRnhtMetJg.png"/></div></div></figure><p id="23e5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很高兴看到所有这些样本图像都被正确预测。我们看到各种预测的置信度。现在，我们来看看最不正确的预测:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="5d2f" class="nh md it nc b gy ni nj l nk nl">def see_most_incorrect(data, images, preds, dataset='test', seed=42, <br/>                       n_rows=2, n_cols=3):<br/>    df = pd.DataFrame()    <br/>    df['true_class'] = [image.parts[2] for image in images]<br/>    df['pred_class'] = [data.class_names[pred] for <br/>                        pred in preds.argmax(axis=1)]<br/>    df['proba'] = preds.max(axis=1)<br/>    incorrect_df = df.query("true_class!=pred_class")\<br/>                     .nlargest(n_rows*n_cols, 'proba')<br/>    <br/>    plt.figure(figsize=(8,5))<br/>    for i, (ind, row) in enumerate(incorrect_df.iterrows()):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        plt.imshow(plt.imread(images[ind]), cmap='binary')<br/>        plt.axis('off')<br/>        true = row['true_class']<br/>        proba = row['proba']<br/>        pred = row['pred_class']<br/>    <br/>        plt.title(f"Actual: {true}\nPred: {pred} ({proba:.1%})", fontsize=14, color='red')<br/>    plt.suptitle(f'Most incorrect {dataset} predictions', fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>see_most_incorrect(test_data, test_images, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/8fa7ef8aea065363feaad6aa6c83e98a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*qVIwx0uHtTADQAE4hEXbdw.png"/></div></figure><p id="cc4f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在上面的中间图像中，您能马上分辨出是西红柿吗？西红柿的颜色不是你所期望的。</p><p id="f31f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我们在上一篇文章中所了解到的，我们可以尝试通过添加层、更多单元、运行更多时代来增加模型的复杂性。如果模型对训练数据过拟合，在神经网络中加入<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" rel="noopener ugc nofollow" target="_blank">脱落层</a>有助于减少过拟合。或者，通过数据增强等技术获取更多数据或增加数据的多样性也有助于最小化过度拟合。<a class="ae le" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank">数据增强</a>是一种通过变换图像使训练数据多样化的技术。例如，作为数据增强的一部分，可以随机旋转、裁剪、平移、缩放和翻转图像。当没有更多数据可用时，通过数据增强使数据多样化可以帮助在更具普遍性的图像上训练模型。</p><p id="f9d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看是否能改进这个模型。</p><h2 id="e517" class="nh md it bd me ns nt dn mi nu nv dp mm kr nw nx mo kv ny nz mq kz oa ob ms oc bi translated">🔧型号1</h2><p id="d66f" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">到目前为止，我们一直在自己构建模型。然而，我们可以考虑另一种选择:迁移学习，在这种情况下，我们重用预先训练的模型。对于这个迭代，我们将使用迁移学习。特别是，我们将使用一种称为特征提取的迁移学习。在特征提取中，我们将保持预训练模型不变，只改变输出层以适应我们的用例。</p><p id="ab2b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用<a class="ae le" href="https://paperswithcode.com/method/resnet" rel="noopener ugc nofollow" target="_blank"> ResNet-50型号</a>。该模型在通过<a class="ae le" href="https://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据库获得的数千张图像上进行训练。在TensorFlow中，有几种不同的方法来加载预训练的模型。我们将使用下面的简单方法来加载一个模型。这里，我们指定ResNet模型不包括顶层，因为我们想要构建自己的输出层，它适用于15个蔬菜类。我们将在ResNet模型上添加展平层和输出层。</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="f948" class="nh md it nc b gy ni nj l nk nl">model_1 = Sequential([<br/>    ResNet50(include_top=False, weights='imagenet', <br/>             input_shape=shape),<br/>    Flatten(),<br/>    Dense(n_classes, activation='softmax')<br/>])</span><span id="fa5a" class="nh md it nc b gy nm nj l nk nl">model_1.compile(optimizer=Adam(learning_rate=0.0001), <br/>                loss='categorical_crossentropy', <br/>                metrics=['accuracy'])<br/>model_1.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/768dad68f0b71ac52d420252ddada58f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*bQP2yN_tdnZgQWuNHqYyLA.png"/></div></figure><p id="911d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们将确保所有层都被设置为不可训练，以便从ImageNet学习的模型的权重和偏差保持不变。然后，我们将训练模型:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d0bf" class="nh md it nc b gy ni nj l nk nl">for layer in model_1.layers[0].layers:<br/>    layer.trainable=False<br/>hist_1 = model_1.fit(train_data, validation_data=valid_data, <br/>                     epochs=2)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/0560da49ba6aea5192fa890b670ecfba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*mN4gxQNx9BG2dETdiwcOJA.png"/></div></figure><p id="c9be" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哇，模型精度明显提高了！即使有1 epoch，性能看起来也很棒。</p><p id="7c20" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们按时代来看性能:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="0dfc" class="nh md it nc b gy ni nj l nk nl">sns.lineplot(data=clean_history(hist_1), x='epochs', y='accuracy', <br/>                                hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b57653886964d5f7dd5f87085fc77834.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*zeAy3dYVAm6PYNxgbMd3Uw.png"/></div></figure><p id="3387" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着第二个纪元，我们开始稍微过度拟合。</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="d91e" class="nh md it nc b gy ni nj l nk nl">test_preds_1 = model_1.predict(test_data)<br/>test_classes_1 = test_preds_1.argmax(axis=1)<br/>test_metrics.loc['model_1'] = np.mean(test_labels==test_classes_1)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b45e6ff17c2cf23fa924c15c11fd748e.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*kTykr7CTHPPfoz1QLuVK8w.png"/></div></figure><p id="a5e0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">15个类别的准确率达到98%左右，这是一个很好的性能。让我们按类进一步挖掘:</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="483b" class="nh md it nc b gy ni nj l nk nl">show_confusion_matrix(test_labels, test_classes_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/65a47a214e9ae798fe6230e4afccd306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*uYyDWYh0B8sij7SZownRog.jpeg"/></div></figure><p id="d67d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很高兴看到大多数值都集中在对角线上。通过重用预训练模型，我们可以达到事半功倍的效果。</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="915b" class="nh md it nc b gy ni nj l nk nl">inspect_sample_predictions(test_images, test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi or"><img src="../Images/f7608ccfc583e940e422260695d8501f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6NbUJU0sXUdkNX-jKQE4dg.png"/></div></div></figure><p id="f1e6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与上一次迭代一样，样本图像被正确预测。预测概率比以前更高。</p><pre class="lg lh li lj gt nd nc ne nf aw ng bi"><span id="80bc" class="nh md it nc b gy ni nj l nk nl">see_most_incorrect(test_data, test_images, test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/7a2e22a6cec31ff335bccc48b341d0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*25PJYkv_X8w7NCUm1NG-UQ.png"/></div></figure><p id="6832" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有趣的是，红底萝卜和胡萝卜被混淆了。这有助于了解模型的错误之处。</p><p id="34c9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">迁移学习也适用于较小的数据集(即较少的图像)，只要您使用的模型是在相似的数据集上预先训练的。已经对迁移学习有了一个快速的介绍，如果你想了解更多关于迁移学习的知识，<a class="ae le" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">这个资源</a>可能会有帮助。如果您想尝试其他预训练模型，请从<a class="ae le" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications" rel="noopener ugc nofollow" target="_blank">这里</a>查看其他可用模型。</p><p id="7e67" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是这篇文章的全部内容！希望你已经学到了一些实用的技能，可以开始你的计算机视觉之旅。如果你想通过在不同的数据集上应用我们作为系列的一部分所学的知识来获得更多的图像分类经验，Kaggle 中的这个<a class="ae le" href="https://www.kaggle.com/datasets?tags=13207-Computer+Vision" rel="noopener ugc nofollow" target="_blank">开放数据集可能对你有用。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ot"><img src="../Images/7516c6e0134b6b2778f564be0d6bd06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LZT7z7uWRpfZjnwg"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">安娜·佩尔泽在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="a5a7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ou">您想访问更多这样的内容吗？媒体会员可以无限制地访问媒体上的任何文章。如果你使用</em> <a class="ae le" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="ou">我的推荐链接</em> </a>，<em class="ou">成为会员，你的一部分会费会直接去支持我。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6e0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谢谢你看我的帖子。如果你感兴趣，这里有我的一些帖子的链接:</p><p id="92d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">◼️️ <a class="ae le" rel="noopener" target="_blank" href="/pipeline-columntransformer-and-featureunion-explained-f5491f815f?source=your_stories_page-------------------------------------">管道、ColumnTransformer和FeatureUnion讲解</a> <br/> ◼️️ <a class="ae le" rel="noopener" target="_blank" href="/featureunion-columntransformer-pipeline-for-preprocessing-text-data-9dcb233dbcb6"> FeatureUnion、ColumnTransformer &amp;管道用于预处理文本数据</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/enrich-your-jupyter-notebook-with-these-tips-55c8ead25255">用这些提示丰富您的Jupyter笔记本</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f">用这些提示整理您的Jupyter笔记本</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/explaining-scikit-learn-models-with-shap-61daff21b12a">讲解Scikit-用SHAP学习模型</a> <br/> ◼️️ <a class="ae le" rel="noopener" target="_blank" href="/feature-selection-in-scikit-learn-dc005dcf38b7">在scikit中选择特性</a></p><p id="6518" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">再见🏃 💨</p></div></div>    
</body>
</html>