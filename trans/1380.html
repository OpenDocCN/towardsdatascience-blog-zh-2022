<html>
<head>
<title>Build a Simple Neural Network Using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch构建一个简单的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-a-simple-neural-network-using-pytorch-38c55158028d#2022-04-06">https://towardsdatascience.com/build-a-simple-neural-network-using-pytorch-38c55158028d#2022-04-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3de9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用PyTorch构建您的第一个人工智能模型的快速简单的步骤</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d3920a5f0e09149928cd4009b7f9ff06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmdAbzvaAye6teoWVXV8WA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的<a class="ae ky" href="https://unsplash.com/@mparzuchowski" rel="noopener ugc nofollow" target="_blank"> Michal Parzuchowski </a>拍摄</p></figure><p id="55b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" rel="noopener" target="_blank" href="/build-a-simple-neural-network-using-numpy-2add9aad6fc8?source=your_stories_page---------------------------">之前的帖子</a>中，我们讨论了如何使用NumPy制作一个简单的神经网络。在本帖中，我们将讨论如何使用内置PyTorch函数制作一个简单的神经网络，而不是自己编写每个函数。</p><p id="1bb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch是由脸书人工智能实验室开发和维护的用于深度学习的开源Python库。PyTorch使用张量(Torch。张量)来存储和操作数字的矩形数组。张量类似于NumPy数组，但它们也可以在GPU中运行。torch.nn包可用于构建神经网络。我们将创建一个具有单个隐藏层和单个输出单元的神经网络。</p><ol class=""><li id="b995" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">导入库</strong></li></ol><p id="6c9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">PyTorch的安装指南可以在PyTorch的官方<a class="ae ky" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">网站</a>上找到。首先，我们需要导入PyTorch库。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="f325" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">import </strong>torch<br/><strong class="mf iu">import </strong>torch.nn <strong class="mf iu">as </strong>nn</span></pre><p id="8b64" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">数据准备</strong></p><p id="1eae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将定义变量，如输入大小、隐藏单元、输出大小、批量大小和学习速率。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="ba9b" class="mj mk it mf b gy ml mm l mn mo">n_input, n_hidden, n_out, batch_size, learning_rate = 10, 15, 1, 100, 0.01</span></pre><p id="e37f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在将如下随机初始化虚拟输入和输出目标数据(或张量):</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="7ad0" class="mj mk it mf b gy ml mm l mn mo">data_x = torch.randn(batch_size, n_input)<br/>data_y = (torch.rand(size=(batch_size, 1)) &lt; 0.5).float()</span></pre><p id="c538" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们用100个数据样本初始化输入数据，每个样本有10个特征，并分别用100个数据点初始化输出数据。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="3880" class="mj mk it mf b gy ml mm l mn mo">print(data_x.size())<br/>print(data_y.size())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/e163f0e45761d242a07a3534d0237a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJJAjqcEVag-458wqektyg.png"/></div></div></figure><p id="87a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。定义神经网络模型</strong></p><p id="adc1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用内置函数，我们将创建带有输出sigmoid层的简单序列模型，如下所示:</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="19dc" class="mj mk it mf b gy ml mm l mn mo">model = nn.Sequential(nn.Linear(n_input, n_hidden),<br/>                      nn.ReLU(),<br/>                      nn.Linear(n_hidden, n_out),<br/>                      nn.Sigmoid())<br/>print(model)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mq"><img src="../Images/1f814d434a83d64702d6e578a5172f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AW9Z4NwSk3eBDvZgoPcASA.png"/></div></div></figure><p id="8ac2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将为梯度下降定义损失函数和优化器。在nn包下，有几种不同的损失函数。这里我们将使用<code class="fe mr ms mt mf b">nn.MSELoss</code>作为模型的损失函数，计算输入和目标之间的均方误差。同样，<code class="fe mr ms mt mf b"><a class="ae ky" href="https://pytorch.org/docs/stable/optim.html#module-torch.optim" rel="noopener ugc nofollow" target="_blank">torch.optim</a></code>包提供了各种优化算法。我们将使用随机梯度下降(SGD)优化器。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="abcf" class="mj mk it mf b gy ml mm l mn mo">loss_function = nn.MSELoss()<br/>optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span></pre><p id="45fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。训练循环</strong></p><p id="cb90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们将通过以下步骤定义训练循环:</p><ul class=""><li id="c23d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu mu mb mc md bi translated">正向传播—计算预测的<strong class="lb iu"> <em class="mv"> y </em> </strong>并计算当前损耗</li><li id="c1aa" class="lv lw it lb b lc mw lf mx li my lm mz lq na lu mu mb mc md bi translated">反向传播——在每个时期之后，我们在开始反向传播之前将梯度设置为零</li><li id="24ee" class="lv lw it lb b lc mw lf mx li my lm mz lq na lu mu mb mc md bi translated">梯度下降—最后，我们将通过调用<strong class="lb iu"> <em class="mv"> optimizer.step() </em> </strong>函数来更新模型参数</li></ul><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="4d92" class="mj mk it mf b gy ml mm l mn mo">losses = []<br/><strong class="mf iu">for </strong>epoch <strong class="mf iu">in </strong>range(5000):<br/>    pred_y = model(data_x)<br/>    loss = loss_function(pred_y, data_y)<br/>    losses.append(loss.item())<br/><br/>    model.zero_grad()<br/>    loss.backward()<br/><br/>    optimizer.step()</span></pre><p id="7a6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 5。输出</strong></p><p id="7f93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以绘制损失图，并查看模型在每个时期的训练情况。</p><pre class="kj kk kl km gt me mf mg mh aw mi bi"><span id="4fe9" class="mj mk it mf b gy ml mm l mn mo"><strong class="mf iu">import </strong>matplotlib.pyplot <strong class="mf iu">as </strong>plt<br/>plt.plot(losses)<br/>plt.ylabel(<strong class="mf iu">'loss'</strong>)<br/>plt.xlabel(<strong class="mf iu">'epoch'</strong>)<br/>plt.title(<strong class="mf iu">"Learning rate %f"</strong>%(learning_rate))<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/f595fe64b6d3bd3c7c41517dd2b39873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHftRppZai3gPYF-b9dxmQ.png"/></div></div></figure><p id="fa88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，损耗在每个时期都在减少，这表明参数正在被学习。</p><p id="30d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，您学习了在PyTorch中逐步开发简单神经网络模型的方法。具体来说，您学习了如何初始化随机数据、定义神经网络模型并训练它们。使用PyTorch的主要优势有两方面:</p><ol class=""><li id="ca8e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">在图形处理单元(GPU)中使用张量来提供操作类似数字的数组的能力。</li><li id="0c91" class="lv lw it lb b lc mw lf mx li my lm mz lq na lu ma mb mc md bi translated">基于磁带自动微分系统的深度神经网络的可用性。</li></ol><p id="0911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你用PyTorch构建并训练了你的第一个神经网络！</p><p id="8031" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mv">成为</em> <a class="ae ky" href="https://medium.com/@rmesfrmpkr/membership" rel="noopener"> <em class="mv">这里</em> </a> <em class="mv">的媒介会员，支持独立写作，每月5美元，获得媒介上每个故事的全部权限。</em></p></div></div>    
</body>
</html>