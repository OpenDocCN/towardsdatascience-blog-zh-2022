<html>
<head>
<title>Unsupervised Learning: K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习:K-均值聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unsupervised-learning-k-means-clustering-6fd72393573c#2022-04-05">https://towardsdatascience.com/unsupervised-learning-k-means-clustering-6fd72393573c#2022-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="cbfc" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">机器学习理论</h2><div class=""/><div class=""><h2 id="59aa" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">k-均值聚类直观解释</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/4e06238fb77511d79880a09a2a876319.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5oS5b3j47zvCe43HuyUiUg.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者Gif</p></figure><p id="c509" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi md translated"><span class="l me mf mg bm mh mi mj mk ml di">K</span>-均值聚类是一种迭代算法，它选择最小化类内方差的聚类中心。</p><h1 id="8c17" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">介绍</h1><p id="9339" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">在本文中，我想介绍一种最简单的数据聚类算法，k-means聚类。这是一种经常在面试中出现的算法，用来测试你的基本面知识。读完这篇文章后，你会理解监督学习和非监督学习之间的区别，以及简单数据聚类模型背后的数学原理。</p><h1 id="7fe0" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">无监督学习</h1><p id="7fb4" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">许多常见的机器学习问题都属于监督学习领域。任何与分类或回归有关的问题通常都属于监督学习。监督学习问题包括我们知道训练数据“标签”的问题。如果我们知道标签，那么任务就包括训练一些隐藏函数，将我们的数据矩阵映射到隐藏标签。例如，在分类器中，我们知道什么训练数据属于什么类，因此我们训练像神经网络这样的函数来拟合数据，并使用训练的模型来预测看不见的数据。</p><p id="8351" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在无监督学习中，我们不知道我们训练数据的标签。我们不能在输入和输出之间建立直接的映射。因此，我们的目标是学会发现数据中的模式并加以利用。</p><h1 id="5518" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">数据聚类:K均值</h1><h2 id="7f2f" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">问题简介</h2><p id="a9cf" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">聚类算法是一种无监督学习模型。他们的目标是将数据分组。考虑一个分类问题，您知道有多少个类，但您的数据是未标记的。</p><p id="cd01" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在k-means聚类中，我们假设我们知道有多少个组，然后我们将数据聚类到那个数量的组中。组的数量被表示为“k”，因此该算法的名称。</p><p id="649b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">假设我们有以下问题:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/680877d3449da2dcc0b14607d5fced26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*AMFYPmaB2mSf1S8_aShtjQ.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">3集群问题(图片由作者提供)</p></figure><p id="cc88" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们有一个二维数据集。数据集似乎包含3个聚类(训练时我们不知道它们的真实标签)。我们不知道每个数据点的类成员，但我们知道系统中有3个组。能不能做一个算法，确定每个点属于哪个聚类？</p><h2 id="51bf" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">制定</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nv"><img src="../Images/e4218a26fbcbd582421252da51f3c475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cB6KqaSIkux94QuEm03TPg.png"/></div></div></figure><p id="b652" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">给定数据矩阵x，它是一个N×d矩阵，有N个数据点，每个数据点有d维(在我们的问题中d = 2)。我们想确定类成员(rnk)。如果数据点不属于某个聚类，则该变量为0，否则为1。这里有一个例子:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/894a2ebff566f7fb5c47c4bfa79eec8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*mYpgjtjfT1kO67f8pT5iSw.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">班级成员可视化(图片由作者提供)</p></figure><p id="5a9b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">上面是一个数据点的向量及其类成员的例子。该点属于簇3，所以它rn3为1，其余均为0。目标是找出所有数据点的rnk。</p><h2 id="98e7" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">目标函数</h2><p id="0cbf" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">为了训练机器学习模型，我们通常会寻找某种可以最小化的误差函数，以便训练我们的模型。在k均值聚类的情况下，<strong class="lj jd">目标是找到最小化类内方差的聚类中心</strong>:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/ebe57c0ab5756ef598a443f0079148e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*Z5Y22YIA-FG14TB0ehQLrw.png"/></div></figure><p id="0ec1" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">如果我们最小化目标函数J，我们就最小化了为该聚类选择的聚类中心μ之间的欧几里德距离的平方。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/206f780c9a630c72392e5875f8cd89fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*O9h19W56r71MpWZJG7vG_g.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者图片</p></figure><p id="c42b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">因此，对于每个聚类，我们查看我们认为属于该聚类的点，并选择最小化聚类中心和该聚类中所有点之间的欧几里德距离的平方的聚类中心。我已经注意到上图中欧几里得距离是L2范数。</p><p id="5df6" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们可以采用上面所示的目标函数，对聚类中心进行微分，并使其等于0，以找到导致最小损失(聚类方差内的最小值)的聚类中心。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nz"><img src="../Images/0dc8a377ca37da2e843224025e0e789f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*VA2fht0EGgdxZ7IPVA-_GQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">最佳聚类中心的推导。注意，当求微分时，在聚类中心K上求和。</p></figure><p id="d02b" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的推导中，我们发现最佳聚类中心(最小化聚类内方差的中心)是每个聚类的平均值。这是一个直观的结果。聚类中使方差最小的点将位于均值中。</p><h2 id="fe9e" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">k均值算法</h2><p id="8504" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">所以我们知道最优聚类中心是每个聚类的均值，但是在不知道类成员(rnk)的情况下，我们无法计算每个聚类的均值。为了解决这个问题，我们实现了一个迭代算法:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/29bab00ebf73e4bb27fc6fbb7332d7b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-fft1bp0llqwBrnL6yGInQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">k-表示伪代码(作者)</p></figure><p id="7afa" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">我们首先随机初始化我们的聚类中心(第1行)。我们可以通过随机选取k个点来实现。然后，我们根据欧几里德距离将每个数据点分配到离它最近的聚类中心(第7-10行)。</p><p id="7d45" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">然后，我们通过计算每个聚类中心的平均值来更新聚类中心(第14–17行)。最后，我们重复这一过程，直到聚类中心收敛。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/5d195e3e0e085aebeab55d50be1baf65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*baOgOBaYw_arRViSXunecA.png"/></div><p class="ld le gj gh gi lf lg bd b be z dk translated">随机初始化(图片作者提供)</p></figure><p id="e5ba" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的图像中，通过随机选取3个点初始化了3个聚类中心。颜色表示每个数据点被分配到哪个聚类中心。通过计算每个点到所有3个聚类中心的欧几里德距离，并挑选最接近它的一个来计算类成员rnk。如您所见，最下面的聚类中心占据了大部分数据。该算法的下一步是计算每个聚类的平均值并更新聚类中心。橙色和蓝色的聚类中心不会移动太多，但绿色的聚类中心会向下移动很远。在更新聚类中心之后，我们再次计算类成员，重复直到点已经收敛:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f71973e3852bb2c21d24a5b28b15aad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*vwqGie88zmJmdBZET_tbbA.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从随机初始化收敛(GIF由作者提供)</p></figure><p id="80ab" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">正如你在上面看到的，k-means算法成功地找到了真正的聚类中心。</p><h1 id="e968" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">k均值聚类的问题</h1><h2 id="92f1" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">对初始化的依赖</h2><p id="1c09" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">k-means聚类的一个大问题是它的一致性。由于随机初始化，k-means不是很一致。根据初始化聚类中心的位置，该算法可以产生非常不同的结果。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/0efaaa66674e1bf55c26f504a6a07766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*QUosO_fJ0un4SWQ8JWshow.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">k-means被错误的初始化卡住(GIF由作者提供)</p></figure><p id="87ec" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">在上面的GIF中，与之前的模型相同，但初始化不同。由于不幸的初始化，该模型未能找到真正的聚类中心。蓝色聚类的平均值卡在两个聚类之间，因为橙色和绿色聚类中心划分了第三个聚类。</p><h2 id="7973" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">我们并不总是知道K</h2><p id="6134" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">由于这是无监督学习，我们可能不知道真实的聚类数。这也将导致错误的聚类中心。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/b15e1caad2a2eb976985a0f30e3b02d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*QAIJeiun_ZGrvZSzBLLJ0g.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">4个聚类中心(GIF由作者提供)</p></figure><h2 id="43a4" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">数据不总是均匀分布的</h2><p id="cdf4" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">在k-means聚类中，每个数据点被分配到它最接近的聚类中心。在二维空间中，两个聚类中心之间的判定边界将是线性的，而不会考虑每个分布的形状。这对于没有相关性的分布很有效，就像我们到目前为止所展示的那样。但如果我们在数据中引入相关性，k均值就开始表现不佳。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/68c7b033571d76a1d5ec552480b1b851.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*WYspvfw9eN5pug5UOH9e9w.gif"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">二元高斯和k均值(GIF由作者提供)</p></figure><p id="8d08" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">看看上面gif中橙色和蓝色的星团。蓝色星团正在吞噬橙色星团，尽管从视觉上我们可以看出这些点属于橙色星团。在k-means中，我们不考虑数据中的相关性，但有其他聚类技术可以考虑。如果您的数据呈正态分布，如上图所示，k-means可能不是最佳的聚类算法。敬请关注未来关于高斯混合模型的文章！</p><h1 id="a780" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">结论</h1><p id="508a" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">本文直观地解释了k-means聚类，这是一种简单的数据聚类算法。k-means聚类迭代地估计未标记数据集的聚类中心，以最小化类内方差。由于我们不知道类成员，为了计算类内方差，我们首先随机初始化类中心，然后期望每个类的新类中心是分配给每个类的数据点的平均值。k-means有很大的缺点，我在文章的最后强调了这一点，在未来，我将引入高斯混合模型，这是一种将高斯分布拟合到未标记数据的方法。</p><h2 id="546b" class="nj mn it bd mo nk nl dn ms nm nn dp mw lq no np my lu nq nr na ly ns nt nc iz bi translated">支持我</h2><p id="c2b7" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated">希望这对你有所帮助，如果你喜欢，你可以<a class="ae ob" href="https://medium.com/@diegounzuetaruedas" rel="noopener"> <strong class="lj jd">关注我！</strong>T3】</a></p><p id="db27" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">你也可以成为<a class="ae ob" href="https://diegounzuetaruedas.medium.com/membership" rel="noopener"> <strong class="lj jd">中级会员</strong> </a> <strong class="lj jd"> </strong>使用我的推荐链接，获得我所有的文章和更多:<a class="ae ob" href="https://diegounzuetaruedas.medium.com/membership" rel="noopener">https://diegounzuetaruedas.medium.com/membership</a></p><h1 id="8f27" class="mm mn it bd mo mp mq mr ms mt mu mv mw ki mx kj my kl mz km na ko nb kp nc nd bi translated">你可能喜欢的其他文章</h1><p id="48bf" class="pw-post-body-paragraph lh li it lj b lk ne kd lm ln nf kg lp lq ng ls lt lu nh lw lx ly ni ma mb mc im bi translated"><a class="ae ob" rel="noopener" target="_blank" href="/data-visualization-theory-an-introduction-a077c0d80498">数据可视化理论</a></p><p id="bdf5" class="pw-post-body-paragraph lh li it lj b lk ll kd lm ln lo kg lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae ob" href="https://medium.com/geekculture/analysis-of-synthetic-hotel-data-in-spain-d6bb5070c2fe" rel="noopener">分析西班牙酒店数据</a></p></div></div>    
</body>
</html>