<html>
<head>
<title>Beyond Object Identification: A Giant-Leap into Pattern Discovery in Imagery Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越目标识别:图像数据中模式发现的巨大飞跃</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beyond-object-identification-a-giant-leap-into-pattern-discovery-in-imagery-data-ca6fbb46ff4a#2022-08-15">https://towardsdatascience.com/beyond-object-identification-a-giant-leap-into-pattern-discovery-in-imagery-data-ca6fbb46ff4a#2022-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5c67" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一个关于发现影像数据中对象之间相关性的简短而有趣的教程</h2></div><p id="90e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在识别图像数据库中的对象(或类别标签)之后出现的一个关键问题是:“<em class="lb">在图像数据库中发现的各种对象是如何相互关联的？</em>“本文试图通过提供一个通用框架来回答这个问题，该框架可以帮助读者发现图像数据库中对象之间隐藏的相关性。(本文的目的是鼓励即将到来的研究人员在顶级会议和期刊上发表高质量的研究论文。本文部分摘自我们发表在IEEE BIGDATA 2021 [1]上的工作。)</p><p id="af11" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">发现影像数据库中对象之间相关性的框架如图1所示。它包括以下三个步骤:</p><ol class=""><li id="629e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">提取存储库中每个图像的对象(或类别标签)及其概率分数。用户可以使用对象检测/实例分割/语义分割技术来提取对象。</li><li id="3794" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">将对象及其概率分数转换到您选择的数据库中。(如有必要，删除具有低概率分数的不感兴趣的对象以减少噪声。)</li><li id="725a" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">根据生成的数据库和所需的知识，应用相应的模式挖掘技术来发现影像数据中对象之间令人兴奋的相关性。</li></ol><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/c346e41ad662475c00d8564903d53a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R5jgKdgic6jePupXUMYgXA.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图1:发现影像数据中有趣模式的框架</p></figure><p id="4af0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">演示:</strong>在本演示中，我们首先将图像数据传递到一个经过训练的模型(例如resnet50)中，并提取对象及其分数。接下来，提取的数据被转换成事务数据库。最后，我们在生成的事务数据库上执行(最大)频繁模式挖掘，以发现图像数据中频繁出现的对象集。图2显示了我们的演示的概况。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mg"><img src="../Images/6cc2b695367bf21f4a6e22ae6cb694fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y8EhjCzeeNOFhBKnn7wb0w.jpeg"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">图2:在影像数据中发现模式的概述</p></figure><p id="5cb0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">先决条件:</strong></p><ol class=""><li id="6011" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">我们假设读者熟悉实例/语义分割和模式挖掘主题。我们推荐<a class="ae mh" href="https://www.youtube.com/watch?v=idQEwXWcQfM&amp;ab_channel=PhilippeFournier-Viger" rel="noopener ugc nofollow" target="_blank"> Phillipe关于模式挖掘的视频讲座</a> s。</li><li id="3aa7" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">安装以下python包:<em class="lb"> pip安装pami torchvision </em></li><li id="8bcc" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">从[2]下载图像数据库</li></ol><p id="a109" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(请根据您的计算环境安装任何所需的附加软件包。)</p><p id="037b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤1:从图像数据中提取对象及其分数</strong></p><p id="4788" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤1.1:加载预训练的对象检测模型</strong></p><p id="0d5f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将以下代码保存为objectDetection.py。该代码接受imagery文件夹作为输入，实现预训练的resnet50模型，并输出包含类标签及其分数的列表(即self.predicted_classes)。该列表中的每个元素表示在图像中找到的类别标签。</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="173d" class="mn mo iq mj b gy mp mq l mr ms">import glob<br/>import os<br/>import csv<br/>import torchvision<br/>from torchvision import transforms<br/>import torch<br/>from torch import no_grad<br/>import cv2<br/>from PIL import Image<br/>import numpy as np<br/>import sys<br/>import matplotlib.pyplot as plt<br/>from IPython.display import Image as Imagedisplay<br/>from PAMI.extras.imageProcessing import imagery2Databases as ob</span><span id="576d" class="mn mo iq mj b gy mt mq l mr ms">class objectDetection:<br/>    def __init__(self):<br/>        self.model_ = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)<br/>        self.model_.eval()<br/>        for name, param in self.model_.named_parameters():<br/>            param.requires_grad = False</span><span id="4b64" class="mn mo iq mj b gy mt mq l mr ms">def model(self, x):<br/>        with torch.no_grad():<br/>            self.y_hat = self.model_(x)<br/>        return self.y_hat</span><span id="1597" class="mn mo iq mj b gy mt mq l mr ms">def model_train(self, image_path):<br/>        # label names <br/>        self.coco_instance_category_names = [<br/>            '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',<br/>            'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',<br/>            'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',<br/>            'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',<br/>            'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',<br/>            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',<br/>            'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',<br/>            'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',<br/>            'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',<br/>            'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',<br/>            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',<br/>            'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'<br/>        ]<br/>        self.transform = transforms.Compose([transforms.ToTensor()])<br/>        self.image_path = image_path<br/>        self.image = Image.open(self.image_path)<br/>        # resize and plotting the image<br/>        self.image.resize([int(0.5 * s) for s in self.image.size])<br/>        del self.image_path<br/>        self.image = self.transform(self.image)</span><span id="f014" class="mn mo iq mj b gy mt mq l mr ms"># predictions without any threshold<br/>        self.predict = self.model([self.image])<br/>        self.predicted_classes = [(self.coco_instance_category_names[i], p) for<br/>                                  i, p in<br/>                                  zip(list(self.predict[0]['labels'].numpy()),<br/>                                      self.predict[0]['scores'].detach().numpy())]</span><span id="b747" class="mn mo iq mj b gy mt mq l mr ms">return self.predicted_classes</span></pre><p id="959b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">步骤1.2:从每幅图像中检测物体</strong></p><p id="bac6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下代码识别每个图像中的各种对象，并将它们附加到一个名为<em class="lb"> detected_objects_list </em>的列表中。在下一步中，这个列表将被转换成一个事务数据库。</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="858a" class="mn mo iq mj b gy mp mq l mr ms">from PAMI.extras.imageProcessing import imagery2Databases as ob<br/># input images path folder <br/>images_path = 'aizu_dataset'</span><span id="8001" class="mn mo iq mj b gy mt mq l mr ms"># list to store output items<br/>detected_objects_list = []</span><span id="feb4" class="mn mo iq mj b gy mt mq l mr ms"># opening the images folder and reading each image<br/>for filename in glob.glob(os.path.join(images_path,'*.JPG')):<br/>    with open(os.path.join(os.getcwd(),filename),'r') as f:<br/>        <br/>        # loading pretrained resnet-50 model to train on our dataset<br/>        model_predict = objectDetection()<br/>        <br/>        # input each image to the pre-trained model<br/>        # model returns detected objects<br/>        objects_detected = model_predict.model_train(filename)<br/>        detected_objects_list.append(objects_detected)</span></pre><p id="f58d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第二步:创建交易数据库</strong></p><p id="49ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用下面的代码删除不感兴趣的类标签。将剩余数据保存为事务数据库。</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="db54" class="mn mo iq mj b gy mp mq l mr ms">#Prune uninteresting objects whose probability score is less than a particular value, say 0.2<br/>obj2db = ob.createDatabase(detected_objects_list,0.2)</span><span id="23c9" class="mn mo iq mj b gy mt mq l mr ms">#save the objects identified in the images as a transactional database<br/>obj2db.saveAsTransactionalDB('aizu_dataset0.2.txt',',')</span></pre><p id="e120" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过键入以下命令查看生成的事务数据库文件:</p><p id="7e80" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">！head -10 aizu_dataset0.2.txt </em></p><p id="b4dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出如下所示:</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="4b66" class="mn mo iq mj b gy mp mq l mr ms">motorcycle,backpack,person<br/>book,baseball bat,refrigerator,cup,toaster<br/>bottle,bowl,tv,toilet,chair,mouse,refrigerator,cell phone,microwave,remote,sink<br/>microwave,refrigerator,bowl,bottle,cell phone,oven,car,person<br/>bench<br/>potted plant<br/>bottle,handbag,suitcase,book<br/>book,laptop,tv,umbrella<br/>oven<br/>parking meter,car</span></pre><p id="dd5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">第三步:在事务数据库中提取模式。</strong></p><p id="aa4d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在生成的事务数据库上应用最大频繁模式增长算法来发现隐藏模式。在下面的代码中，我们找到了在影像数据库中至少出现了十次的模式(即类别标签集)。</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="7ec4" class="mn mo iq mj b gy mp mq l mr ms">from PAMI.frequentPattern.maximal import MaxFPGrowth as alg</span><span id="8274" class="mn mo iq mj b gy mt mq l mr ms">obj = alg.MaxFPGrowth('aizu_dataset0.2.txt',10, ',')<br/>obj.startMine()<br/>print(obj.getPatterns())<br/>obj.savePatterns('aizuDatasetPatterns.txt')<br/>print('Runtime: ' + str(obj.getRuntime()))<br/>print('Memory: ' + str(obj.getMemoryRSS()))</span></pre><p id="8bbe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过键入以下命令查看生成的模式:<br/> <em class="lb">！head-10 aizudatasetpatterns . txt</em></p><p id="a285" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出如下所示:</p><pre class="lr ls lt lu gt mi mj mk ml aw mm bi"><span id="f86a" class="mn mo iq mj b gy mp mq l mr ms">refrigerator	microwave	:11<br/>toilet	:10 <br/>cell phone	:11 <br/>traffic light	:12 <br/>truck	:12 <br/>potted plant	:12 <br/>clock	:15 <br/>bench	:17 <br/>oven	:17 <br/>car	:18</span></pre><p id="6e52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一个图案/线条表示图像库中的11幅图像包含分类标签<em class="lb">冰箱</em>和<em class="lb">微波炉</em>。对于剩余的图案/线条可以做出类似的陈述。</p><p id="9478" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">了解不同对象/类别标签之间的相关性有利于用户做出决策。</p><p id="dfa2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">结论:</strong></p><p id="1254" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在工业和学术界中已经广泛研究了图像数据中对象的有效识别。识别对象后的一个关键问题是，<em class="lb">图像数据中各种对象之间的潜在相关性是什么？本博客试图通过提供一种通用方法来回答这个关键问题，该方法将图像数据中发现的对象转换成事务数据库，应用模式挖掘技术，并发现令人兴奋的模式。</em></p><p id="4005" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">免责声明:</strong></p><ol class=""><li id="fae1" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">本页显示的所有图片均由作者绘制。</li><li id="dfba" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">该图像数据库由作者本人创建，是开源的，可用于商业和非商业目的。</li></ol><p id="add8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">参考文献:</strong></p><p id="def6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1] <a class="ae mh" href="https://dblp.org/pid/311/1191.html" rel="noopener ugc nofollow" target="_blank"> Tuan-Vinh La </a>、<a class="ae mh" href="https://dblp.org/pid/12/6320.html" rel="noopener ugc nofollow" target="_blank"> Minh-Son Dao </a>、<a class="ae mh" href="https://dblp.org/pid/311/0699.html" rel="noopener ugc nofollow" target="_blank">友川Tejima </a>、Rage Uday Kiran、<a class="ae mh" href="https://dblp.org/pid/46/184.html" rel="noopener ugc nofollow" target="_blank"> Koji Zettsu </a> : <strong class="kh ir">通过分析生活日志图像和物联网空气污染数据，提高对可持续智慧城市的认识。</strong><a class="ae mh" href="https://dblp.org/db/conf/bigdataconf/bigdataconf2021.html#LaDTKZ21" rel="noopener ugc nofollow" target="_blank">IEEE BigData 2021</a>:3589–3594</p><p id="5229" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2]影像数据集:<a class="ae mh" href="https://1drv.ms/u/s!Ar09XhBKBP2Mk4Z2gc3W1kKfg_NLyw?e=qTbmQb" rel="noopener ugc nofollow" target="_blank"> aizu_dataset.zip </a></p></div></div>    
</body>
</html>