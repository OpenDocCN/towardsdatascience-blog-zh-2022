<html>
<head>
<title>Image Recognition Algorithm Using Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于迁移学习的图像识别算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-recognition-algorithm-using-transfer-learning-cae1deb2818f#2022-06-18">https://towardsdatascience.com/image-recognition-algorithm-using-transfer-learning-cae1deb2818f#2022-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="316c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从头开始训练神经网络需要大量的时间和巨大的计算能力。克服这两个障碍的一个方法是实施迁移学习。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/9263f8e616911d29611f6e5ae531338c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*Z8UPBnuJP--WW0TWSRastw.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来源:pixabay.com</p></figure><p id="768e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">没有足够的数据、时间或资源是构建高效图像分类网络的一个关键难题。在本文中，我给出了一个简单的实现，可以绕过所有这些资源不足的限制。我们将看到什么是<strong class="ku ir">迁移学习</strong>，为什么它如此有效，最后，我将一步一步地建立一个图像分类学习模型。</p><p id="11b2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我将开发的模型是羊驼与非羊驼分类器，即能够识别输入图像是否包含羊驼的神经网络。我选择这个有限的任务有几个原因:</p><ul class=""><li id="f669" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated">原来的预训练模型不知道一个“羊驼”类。我想用看不见的课探索迁移学习的潜力。</li><li id="fd17" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">我没有很多羊驼和非羊驼的对比数据。我想用几个数据点来评估迁移学习能做什么。</li></ul><p id="078b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，我将用我最近一次徒步旅行中亲自拍摄的一些羊驼图片来测试该算法。这些照片是在不同的光线条件下拍摄的，羊驼并不总是特写。</p><p id="0bf0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">代码和笔记本可以在GitHub资源库中找到:</p><div class="mc md gp gr me mf"><a href="https://github.com/andreoniriccardo/transfer-learning-image-classifier" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab fo"><div class="mh ab mi cl cj mj"><h2 class="bd ir gy z fp mk fr fs ml fu fw ip bi translated">GitHub-andreoniriccardo/transfer-learning-image-classifier:应用迁移学习技术…</h2><div class="mm l"><h3 class="bd b gy z fp mk fr fs ml fu fw dk translated">应用迁移学习技术建立一个图像分类器，能够识别羊驼的存在</h3></div><div class="mn l"><p class="bd b dl z fp mk fr fs ml fu fw dk translated">github.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt kl mf"/></div></div></a></div><p id="f07f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">用于第二步训练的数据集将从<a class="ae kr" href="https://storage.googleapis.com/openimages/web/index.html" rel="noopener ugc nofollow" target="_blank"> Google Open Images V6数据集</a>中获取。</p><h1 id="957f" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">迁移学习</h1><p id="70e7" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">假设您想要构建一个图像分类器，但您负担不起几周的学习模型训练费用，也没有顶级的GPU来完成这项任务。你可以下载一个现有的模型并对其进行更多的训练，而不是从头开始开发一个神经网络。这种技术被称为迁移学习:它包括使用一个完善的神经网络(或只是它的一部分)，并使它适合于您特定的计算机视觉项目。</p><p id="544a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">多年来，学术研究人员和公司开发了非常深度的卷积神经网络，在图像识别任务中实现了最先进的精度水平。这些网络有几十或几百层深，并在数百万张图像上(通常在<a class="ae kr" href="http://www.image-net.org" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据库上)进行了长时间的训练。开源预训练网络的例子有<a class="ae kr" href="https://it.mathworks.com/help/deeplearning/ref/resnet50.html;jsessionid=37e5bb644ba7f69589be2613b4d3" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>、<a class="ae kr" href="https://en.wikipedia.org/wiki/Inceptionv3" rel="noopener ugc nofollow" target="_blank"> Inceptionv3 </a>、<a class="ae kr" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2、</a>等等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/f56db7eda0bd042cdc862d88294b7708.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALaEVO__JSC6SKMQVNMn8Q.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">Inception v3网络的架构示意图。资料来源:researchgate.net。</p></figure><p id="b6d2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在卷积神经网络(CNN)中，第一个卷积层检测简单的特征，如边缘或形状，中间层识别物体的部分(如人脸识别中的眼睛或嘴巴)，最后，最终的卷积层可以识别更复杂的特征，如人脸。由于这个原因，CNN的初始层完成更一般的任务。相反，最后几层更加专门化。卷积神经网络的这一特殊特征允许采用现有的预训练网络，冻结除最后几层之外的所有层的参数(权重和偏差),并训练网络几个额外的时期。因此，我们可以利用在巨大数据集上训练的深度网络，同时，使其专门用于更具体的图像识别项目。根据卷积层对其原始任务的专门化程度，我们可以选择冻结网络中更大或更小的部分。</p><p id="87f0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">迁移学习在开发不同数据可用性条件下的计算机视觉算法中起着重要的作用。如果我只有一些数据来训练网络，我会冻结除输出层之外的所有预训练网络的权重:只有softmax层会用新实例重新训练。另一种情况是，如果我有更大的训练集可用。在这种情况下，我会冻结更少的层，并重新训练更多的层。最后，如果我可以为网络提供大量的训练集，我会使用预先训练的权重作为网络的初始化点。通过这种方式，我可以加速收敛。</p><h1 id="8cee" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">创建张量流数据集</h1><p id="fa1c" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">导入所需的库后，下一步是生成两个<a class="ae kr" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> TensorFlow数据集</a>，一个用于训练，一个用于验证。20%的图像用于验证。测试集和验证集合并成32个批次。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="cd1b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">请查看Jupyter笔记本，了解如何从Google Open Images下载图片。</p><p id="a09f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了生成数据集，我使用了<code class="fe ny nz oa ob b"><a class="ae kr" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory" rel="noopener ugc nofollow" target="_blank"><strong class="ku ir">image_dataset_from_directory</strong></a></code>函数。我提供了包含每个类的子目录的目录的路径。我的情况是“羊驼”和“非_羊驼”。设置了<code class="fe ny nz oa ob b"><strong class="ku ir">validation_split</strong></code>参数后，我必须指定哪一组用于训练，哪一组用于验证。最后，我设置了一个种子来避免两个数据集之间的重叠。</p><p id="8ae7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">TensorFlow API的一个很大的优点是它自动从子文件夹名称中读取类标签。通过对数据集对象应用<code class="fe ny nz oa ob b"><strong class="ku ir">claa_names</strong></code>属性，我们可以看到:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/034ac5f3d0ea810f189a076aa72e6c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*buvMicA5cZpf_nh0ym6zng.png"/></div></figure><p id="9e84" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们可以通过打印一些来看看训练图像是什么样的。羊驼实例有不同的姿势和大小，非羊驼实例主要是动物形状玩具上的动物。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/a2ed1bc07fc2a23f2892a7c782990513.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*-u7UiiAgeP2GkN2BEtQVIA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">一些训练例子的预览。来源:作者。</p></figure><h1 id="d584" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">导入预先训练的模型</h1><p id="f36c" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">TensorFlow API允许轻松导入预先训练的模型。对于这个应用程序，我将使用<a class="ae kr" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>网络，因为它的架构是基于剩余连接的，这导致了一个快速的网络，也可以在智能手机等低计算设备上使用。</p><p id="8007" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">首先要做的是通过调用<code class="fe ny nz oa ob b"><strong class="ku ir">tf.keras.applications.MobileNetV2</strong></code>函数导入网络:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="1ea8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">它需要提供:</p><ul class=""><li id="e002" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated"><strong class="ku ir">输入形状</strong>，它是通过将颜色的尺寸添加到图像形状中获得的</li><li id="66ff" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated"><strong class="ku ir">是否包含最终图层</strong>。在这种情况下，我不会导入最终层，因为我想为我的特定任务训练一个全新的输出层</li><li id="da66" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">是否<strong class="ku ir">导入预训练的重量</strong>。在这种情况下，我导入了在<a class="ae kr" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> Imagenet </a>数据集上训练得到的权重</li></ul><p id="8b83" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">通过打印网络总结，我们可以看到它的样子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi oe"><img src="../Images/ef4f8037aa3a059d941651aac3bb2606.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qT2bnCpDQohMsfmvkCe4FQ.png"/></div></div></figure><p id="43e5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面的图像只描述了前4层，因为整个网络(156层，不包括最后一层)不适合一个图像。你可以在我上传到GitHub库的Jupyter笔记本上看到所有图层的描述。</p><h1 id="65b4" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">修改网络并训练模型</h1><p id="2a00" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">如上所述，我将向网络添加一个特定的输出层，该层将从头开始训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="0f98" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我现在将解释代码的每一行。</p><ol class=""><li id="d4a0" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln of lu lv lw bi translated">MobileNetV2是在归一化范围[-1，1]上预先训练的。出于这个原因，我复制了相同的输入规范化层</li><li id="61fa" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">预训练模型的权重被设置为不可训练</li><li id="7b40" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">定义形状的输入层(160，160，3)</li><li id="bfd8" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">应用输入标准化步骤</li><li id="9c80" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">添加预训练模型</li><li id="b260" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">应用一个<a class="ae kr" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D" rel="noopener ugc nofollow" target="_blank">平均池层</a>来减少复杂图像的尺寸</li><li id="af15" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">添加一个下降层，以应用一些正则化(从而减少过度拟合)</li><li id="3d8b" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">添加输出层，该层由具有Sigmoid激活功能的单个单元组成。对于二元分类问题，单个单元就足够了</li><li id="cfaf" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln of lu lv lw bi translated">最后，通过指定输入和输出来组合模型</li></ol><p id="fa3e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一旦定义了模型，就该编译和训练它了。我使用<a class="ae kr" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank">亚当优化器</a>和二元交叉熵作为损失函数。作为评估标准，我使用准确性。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/77747e7b383d2d2faeb5ded1ef2b4a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*k8laZJL7OtckQyb8IJciRg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">无数据扩充的学习曲线。来源:作者。</p></figure><p id="7bdd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">准确度分数有机地上升到大约95%的平台期。训练和验证准确性是成对的，这意味着算法不会过度适应训练数据。</p><p id="6502" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我想在我徒步旅行时拍摄的一批羊驼图像上测试该算法。我在测试集中添加了一些随机的非羊驼图片(比如金鱼或巧克力蛋糕)，只是为了解决最终的假阳性错误。鉴于测试图像的数量有限，我使用这个简单的片段进行测试:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="439d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">没有假阳性的报道，但是，我的一些羊驼图片被贴错了标签:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/c76c1f0e056aee6ea38e21034135d33c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*4qEpWrbUPibIs2p7OhLUqQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">错误分类的图像。来源:作者。</p></figure><p id="7d4f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">左边的图片实际上与训练示例非常不同:动物在背景中，并且部分被栅栏覆盖。然而，右边的图像被错误地标注了，即使动物清晰可见并处于焦点上。</p><p id="25af" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我将尝试通过添加一些数据增强层来使神经网络更加健壮。</p><h1 id="7745" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">数据扩充</h1><p id="9817" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">我将跳过关于什么是数据增强及其优势的解释。对于所有细节和实际应用，我建议阅读<a class="ae kr" rel="noopener" target="_blank" href="/generating-synthetic-data-to-train-an-ocr-learning-algorithm-4889f443fe92">这篇关于数据扩充</a>的文章。</p><p id="1594" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了实现数据扩充，我添加了网络的一个连续部分，它由两层组成:一层随机水平翻转图像，一层执行图像的随机旋转。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="8b2c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在对增强模型进行20个时期的训练，并在验证集上达到97%的准确性之后，上面的两张照片都被正确地标记为羊驼。</p><h1 id="2968" class="mu mv iq bd mw mx my mz na nb nc nd ne jw nf jx ng jz nh ka ni kc nj kd nk nl bi translated">结论</h1><p id="eb78" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">迁移学习的可能性数不胜数。在本文中，我介绍了如何利用开源的预训练网络来轻松构建图像分类CNN。我在验证集上达到了令人满意的准确度，但是通过一些安排，它还可以改进得更多。一些改进可能是添加更密集的层(具有ReLu激活功能)，执行更多的增强步骤(剪切、镜像、缩放)，以及重新训练原始MobileNetV2网络的更多最终层。</p></div></div>    
</body>
</html>