<html>
<head>
<title>Stacked Ensembles — Improving Model Performance on a Higher Level</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">堆叠集成—在更高层次上提高模型性能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stacked-ensembles-improving-model-performance-on-a-higher-level-99ffc4ea5523#2022-03-25">https://towardsdatascience.com/stacked-ensembles-improving-model-performance-on-a-higher-level-99ffc4ea5523#2022-03-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1562" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">堆叠集成设计多个预测值的线性组合，以提高模型性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/26564b2b5a017516569d046c776dfa67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hDy9GAbRz9ntU6Vg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@lastnameeaster?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> La-Rel Easter </a>拍摄的照片</p></figure><p id="d4a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将讨论<strong class="ky ir">堆叠系综</strong>，并使用 Scikit 学习模块在 Python 中实现该技术。在此之前，你应该已经知道什么是模型的集合。基本上，模型集合是一个模型，它利用来自多个机器学习模型的预测来产生一个更好的预测模型。如果你错过了我之前关于这个主题的文章，如果你需要复习，请查看一下。</p><p id="3484" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在一个模型集合中，我们试图根据多个机器学习模型的表现分配权重，从而最大化我们的模型的预测。事实证明，让表现更好的模型在集合的最终预测中有更多的发言权并不总是最有利的。我们应该如何知道我们可以给每个模型分配什么样的权重，从而得到最适合的预测呢？</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="08f2" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">堆叠系综框架</h1><p id="5859" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">引入堆叠，一个集成机器学习算法<strong class="ky ir"/>，该算法<strong class="ky ir">学习如何最好地组合集成</strong>中的每个模型，以获得最佳性能。</p><ul class=""><li id="e883" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">普通的机器学习模型仅试图通过生成关系函数来将输入映射到输出。</li><li id="f518" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">通过<strong class="ky ir">学习每个集合模型对样本外预测<strong class="ky ir">的预测结果</strong>和实际值</strong>之间的关系，叠加在普通之上一个级别上起作用。</li></ul><p id="39b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，在堆叠的集合中，每个模型都是一块石头，如下图所示。堆叠模型的工作是学习放置每块岩石的最佳方式，以使其最稳定且差异较小(能够最好地拟合样本外预测)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/138f605d878cc6da2fda62e181ca4473.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*puM-hETOsKkhxQyc"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">肖恩·斯特拉顿在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="697a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">堆叠集合的一般框架由两个或多个基本模型(0 级模型)和一个更高级别的元模型(1 级模型)组成，它们的功能如下:</p><ul class=""><li id="06c5" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated"><strong class="ky ir">基础模型</strong>(0 级模型):拟合训练数据并预测样本外数据的模型。</li><li id="e16a" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated"><strong class="ky ir">元模型</strong>(一级模型):模型符合基础模型的预测，并学习如何最好地组合预测。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="b3f7" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">执行堆栈的理论步骤</h1><p id="a7f6" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">执行堆叠技术的<strong class="ky ir">主要步骤</strong>可以概括为:</p><ol class=""><li id="e15c" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nl nc nd ne bi translated">实施 K 倍交叉验证，将数据集分成 K 倍。</li><li id="85d6" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nl nc nd ne bi translated">伸出其中一个褶皱，将多个独立的基础模型训练到其他褶皱上。</li><li id="09d9" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nl nc nd ne bi translated">使用基础模型预测支撑褶皱</li><li id="ac90" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nl nc nd ne bi translated">重复上述三个步骤 K 次，以获得所有 K 个折叠的样本外预测。</li><li id="e34b" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nl nc nd ne bi translated">将所有样本外预测作为特征(训练数据)提供给元模型。</li><li id="966b" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nl nc nd ne bi translated">使用元模型预测最终输出。</li></ol><p id="d1eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">整个堆垛过程的概要图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4804eb9df3605f2208206ab3b8aff5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*UEpDZ9RQpuUX4Ewx13-8-A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="558b" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">选择合适的元模型</h1><p id="7c62" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在这个阶段出现了一个特殊的问题。</p><p id="fa4f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">我们如何知道选择什么模型作为元模型</strong>？不幸的是，还没有这方面的研究，元模型的选择更像是一门艺术而不是科学。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/5eb9e87ab73212b98cf64499323d44c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p1P6IY3APX5xDmID"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@bdchu614?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">布伦丹·丘奇</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="410a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在大多数讨论堆叠模型的论文中，所使用的<strong class="ky ir">元模型</strong>往往只是一个简单的模型，例如用于回归任务的<strong class="ky ir">线性回归</strong>和用于分类任务的<strong class="ky ir">逻辑回归</strong>。通常不选择更复杂的元模型的一个原因是，元模型更有可能过度适应基础模型的预测。</p><p id="9863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于某些应用来说，<strong class="ky ir">岭回归</strong>要比线性回归好得多。这是因为基础模型的预测通常<strong class="ky ir">强相关</strong>，因为它们都试图预测相同的关系。因此，线性回归拟合可能导致最终预测对数据变化高度敏感。因此，较高的方差导致较差的泛化能力。</p><p id="c250" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">岭回归</strong>带有<strong class="ky ir">正则化</strong> <strong class="ky ir">参数</strong>，因此能够比线性回归更好地处理每个基础模型预测之间的相关性。经验证明这是真的；然而，任何论文都没有给出一个一般性的证明。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="bb23" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">堆叠整体的优势</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/5bbd2d915522eb33e137758c8f1ce2da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QUDuL309qPFi9tGI"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿菲夫·库苏马在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><ul class=""><li id="7d31" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">由于堆叠集合的性质，它通常<strong class="ky ir">产生比常规单个模型或平均集合更稳健的预测性能</strong>。在某些情况下，预测性能的微小改进会对业务场景产生巨大影响。</li><li id="8f85" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">它在 Python StackingRegressor 和 StackingClassifier 中的实现<strong class="ky ir">很容易通过 Scikit 学习模块</strong>获得。它的<strong class="ky ir">实现也相当简单</strong>，我们将在本文后面实现它。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="efc0" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">堆叠系综的缺点</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/9093759eb80a4e2e8dfd6aeb5e13ed72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zeU4uAwAeQoz1yhZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@michalmatlon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Michal Matlon </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><ul class=""><li id="78d5" class="mw mx iq ky b kz la lc ld lf my lj mz ln na lr nb nc nd ne bi translated">使用堆叠技术的一个巨大缺点是，堆叠带来了许多额外的复杂性；也就是说，最终模型变得<strong class="ky ir">更加难以解释</strong>。因此，企业可能不认为实现是值得的，因为它伴随着解释能力的成本。</li><li id="ff97" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">伴随着复杂性增加的一件事是<strong class="ky ir">增加的计算时间</strong>。当手头的数据量呈指数级增长时，一个过于复杂的模型将需要数年时间来运行。这对企业来说没有太大意义，因为它产生的成本比仅仅实现一个简单的模型要大得多。</li><li id="6572" class="mw mx iq ky b kz nf lc ng lf nh lj ni ln nj lr nb nc nd ne bi translated">只有在使用无相关性或低相关性基础模型时，叠加模型的改进<strong class="ky ir">才是最有效的</strong>。这背后的概念类似于正常的平均集合。多样化模型的集合意味着堆叠模型的更多多样性，以优化和达到更好的性能。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="c388" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">Python 实现</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/72fafbc240bb40a80a088f2ed1a1f020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r0iDC_0gqxQ41C03"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@clemhlrdt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Clément Hélardot </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="ebdd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接受了大部分理论之后，是时候看看实践中的技术了。在本文中，我们将使用糖尿病数据集进行演示。</p><p id="725f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们首先导入必要的模块。</p><p id="eda6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用 train_test_split 将数据进一步拆分为训练数据和测试数据。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="4f3a" class="nw ma iq ns b gy nx ny l nz oa">from sklearn.datasets import load_diabetes<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.neighbors import KNeighborsRegressor<br/>from sklearn.svm import SVR<br/>from sklearn.ensemble import RandomForestRegressor, StackingRegressor<br/>from sklearn.metrics import mean_squared_error<br/><strong class="ns ir">import</strong> <!-- -->timeit</span><span id="bae7" class="nw ma iq ns b gy ob ny l nz oa">X, y = load_diabetes(return_X_y=True)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</span></pre><p id="f7f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下一步中，我们定义将要使用的基本模型。</p><p id="5eb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用 KNN，支持向量，随机森林和线性回归。我们还从 Scikit Learn 的模块中定义了一个 StackingRegressor，将基本估计量设置为基本模型，并将最终估计量设置为具有 5 个交叉折叠的线性回归。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="7ed0" class="nw ma iq ns b gy nx ny l nz oa">base_models = [<br/>    ('KNN', KNeighborsRegressor()),<br/>    ('SVR',SVR()),<br/>    ('Random Forest',RandomForestRegressor()),<br/>    ('Linear Regression',LinearRegression()),<br/>    ]</span><span id="5591" class="nw ma iq ns b gy ob ny l nz oa">stacked = StackingRegressor(<br/>    estimators = base_models,<br/>    final_estimator = LinearRegression(),<br/>    cv = 5)</span></pre><p id="c82a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之后，我们将拟合基本模型，并预测我们之前分割的测试数据，以便我们可以将结果与堆叠回归进行比较。</p><p id="9631" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">堆叠回归量也适用于训练数据，并用于预测测试数据。我们来看看每个模型的最终得分。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="d22e" class="nw ma iq ns b gy nx ny l nz oa">for name, model in base_models:<br/>    start_time = time.time()</span><span id="531d" class="nw ma iq ns b gy ob ny l nz oa">    model.fit(X_train, y_train)<br/>    prediction = model.predict(X_test)</span><span id="80ac" class="nw ma iq ns b gy ob ny l nz oa">    end_time = time.time()<br/>    <br/>    r2 = model.score(X_test, y_test)<br/>    rmse = mean_squared_error(y_test, prediction, squared = False)<br/>    <br/>    print("-------{}-------".format(name))<br/>    print("Coefficient of determination: {}".format(r2))<br/>    print("Root Mean Squared Error: {}".format(rmse))<br/>    print("Computation Time: {}".format(end_time - start_time))<br/>    print("----------------------------------\n")</span><span id="cfaf" class="nw ma iq ns b gy ob ny l nz oa">start_time = time.time()</span><span id="abce" class="nw ma iq ns b gy ob ny l nz oa">stacked.fit(X_train, y_train)    <br/>stacked_prediction = stacked.predict(X_test)</span><span id="027c" class="nw ma iq ns b gy ob ny l nz oa">end_time = time.time()</span><span id="c8e3" class="nw ma iq ns b gy ob ny l nz oa">stacked_r2 = stacked.score(X_test, y_test)<br/>stacked_rmse = mean_squared_error(y_test, stacked_prediction, squared = False)</span><span id="ce3a" class="nw ma iq ns b gy ob ny l nz oa">print("-------Stacked Ensemble-------")<br/>print("Coefficient of determination: {}".format(stacked_r2))<br/>print("Root Mean Squared Error: {}".format(stacked_rmse))<br/>print("Computation Time: {}".format(end_time - start_time))<br/>print("----------------------------------")</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1517a29a8a96a5b0c41a1185cbbf0c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*Xo6igb8tAVpG8lwoBJtVQw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者输出的代码</p></figure><p id="fa54" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，通过实施堆叠，我们确实获得了比单个模型更好的结果<strong class="ky ir">！</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/8608e387fc26e726f4f391b64226bfcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9Eer7yPuM-wB_Us2"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@preciousjfm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">J E W E L M I T CH E L L L</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="2874" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，堆叠集合的<strong class="ky ir">计算时间比仅使用任何单个模型要高得多</strong>。对于小数据量来说，这不是问题，但随着数据量的增长，这将成为一个令人头疼的问题。</p><p id="b294" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您正面临一个<strong class="ky ir">分类问题</strong>，使用 Scikit Learn 的<strong class="ky ir"> StackingClassifier() </strong>可以轻松实现类似的过程。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="839d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">外卖</h1><p id="4c6f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">堆叠是一种奇妙的技术，可以用来从你的模型集合中榨出每一滴汁液。它可以<strong class="ky ir">优化模型的最佳线性组合。</strong>这使我们能够<strong class="ky ir"> </strong>从每个模型中获得<strong class="ky ir">最佳多样性混合</strong>，并获得<strong class="ky ir">最佳预测性能</strong>。因为它的实现相当简单，所以绝对值得包含在您的机器学习管道中。</p><p id="6ae0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，你的数据量应该一直记在心里<strong class="ky ir"/>因为堆叠集合的计算时间比单个机器学习模型要长得多。</p><p id="30db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非常感谢您花时间阅读这篇文章。我希望你喜欢它，并肯定会感谢你的掌声和关注！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/9249e22976efd041326848dc996422e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1uPOydrM-zLVS3iF"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普里西拉·杜·普里兹</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div></div>    
</body>
</html>