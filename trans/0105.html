<html>
<head>
<title>Classification of Traffic Signs with LeNet-5 CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LeNet-5 CNN在交通标志分类中的应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-of-traffic-signs-with-lenet-5-cnn-cb861289bd62#2022-02-04">https://towardsdatascience.com/classification-of-traffic-signs-with-lenet-5-cnn-cb861289bd62#2022-02-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2a46" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Keras库构建和利用一个简单的CNN</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0ca7def4cc4e44691432bc77f7c2ced4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-fhfBv8iY721qjHnEmpkQQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">丽贝卡·扎尔从<a class="ae kv" href="https://www.pexels.com/photo/selective-focus-photography-of-assorted-color-hanging-decor-lot-764690/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">派克斯</a>拍摄的照片</p></figure><ul class=""><li id="0161" class="kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">在Streamlit上查看应用:<a class="ae kv" href="https://share.streamlit.io/andriigoz/traffic_signs_classification" rel="noopener ugc nofollow" target="_blank">https://share . Streamlit . io/andriigoz/traffic _ signs _ classification</a></li><li id="4493" class="kw kx iq ky b kz lo lb lp ld lq lf lr lh ls lj lk ll lm ln bi translated">GitHub库:<a class="ae kv" href="https://github.com/AndriiGoz/traffic_signs_classification" rel="noopener ugc nofollow" target="_blank">https://github.com/AndriiGoz/traffic_signs_classification</a></li></ul><p id="338a" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">这个项目的目的是训练和测试一个分类任务的LeNet-5卷积神经网络的实现。该模型将用于一个应用程序中，用户可以上传一张交通标志的照片，并获得其类别的预测。</p><h2 id="fa96" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated"><strong class="ak"> 1。数据集</strong></h2><p id="7897" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">该数据集取自德国交通标志识别基准(gt SRB)【1】的<a class="ae kv" href="https://benchmark.ini.rub.de/gtsrb_dataset.html" rel="noopener ugc nofollow" target="_blank"> <em class="ne">，并在2011年</em></a><em class="ne"/>【2】国际神经网络联合会议<a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S0893608012000457?via%3Dihub" rel="noopener ugc nofollow" target="_blank"> <em class="ne">的单幅图像分类挑战赛上首次亮相。它是根据白天在德国不同道路上行驶时录制的大约10个小时的视频制作的。该数据由大约40，000幅真实的彩色交通标志照片组成。这些图像有一个<em class="ne">。ppm </em>扩展名，它们的大小从15x15到250x250像素不等。笔记本的话，我更喜欢用Google Colab。我将数据集保存在我的Google Drive上，只需使用<em class="ne"> drive.mount </em>命令即可访问它:</em></a></p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="9096" class="mg mh iq ng b gy nk nl l nm nn"><strong class="ng ir">from</strong> google.colab <strong class="ng ir">import</strong> drive<br/>drive<strong class="ng ir">.</strong>mount('/content/gdrive', force_remount<strong class="ng ir">=True</strong>)</span></pre><h2 id="35fb" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">2.图书馆</h2><p id="a059" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">对于我们的项目，我们需要以下库:一些标准库，如NumPy、OS和Matplotlib<a class="ae kv" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> <em class="ne"> cv2 </em> </a>，为解决计算机视觉任务而开发的强大库；<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"><em class="ne">sk learn . model _ selection . train _ test _ split</em></a>用于将数据集拆分成训练和测试子集；用于构建模型的<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/models" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . keras . models</em></a>和<a class="ae kv" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers" rel="noopener ugc nofollow" target="_blank"><em class="ne">TF . keras . layers</em></a>中的一些组件。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="8241" class="mg mh iq ng b gy nk nl l nm nn"><strong class="ng ir">import</strong> numpy <strong class="ng ir">as</strong> np<br/><strong class="ng ir">import</strong> random<br/><strong class="ng ir">import</strong> os<br/><strong class="ng ir">import</strong> cv2 <strong class="ng ir">as</strong> cv<br/><strong class="ng ir">import</strong> matplotlib.pyplot <strong class="ng ir">as</strong> plt<br/><strong class="ng ir">from</strong> sklearn.model_selection <strong class="ng ir">import</strong> train_test_split<br/><strong class="ng ir">from</strong> keras.models <strong class="ng ir">import</strong> Sequential, load_model<br/><strong class="ng ir">from</strong> keras.layers <strong class="ng ir">import</strong> Conv2D, Dense, Flatten, Rescaling, AveragePooling2D, Dropout</span></pre><h2 id="026a" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">3.读取和预处理图像文件</h2><p id="13c0" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">我们从读取数据集中的图像开始。这些图像分布在代表43个班级的43个文件夹中。我们遍历文件夹和图像，打开它们，调整到32x32像素，从RGB转换为灰色，并保存为np.arrays。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="3136" class="mg mh iq ng b gy nk nl l nm nn">images <strong class="ng ir">=</strong> []<br/>labels <strong class="ng ir">=</strong> []<br/>classes <strong class="ng ir">=</strong> 43<br/><br/>current_path <strong class="ng ir">=</strong> '/content/gdrive/My Drive/GTSRB/Images/'<br/><br/><strong class="ng ir">for</strong> i <strong class="ng ir">in</strong> range(classes):<br/>    path <strong class="ng ir">=</strong> os<strong class="ng ir">.</strong>path<strong class="ng ir">.</strong>join(current_path, str(str(i)<strong class="ng ir">.</strong>zfill(5)))<br/>    img_folder <strong class="ng ir">=</strong> os<strong class="ng ir">.</strong>listdir(path)<br/>    <strong class="ng ir">for</strong> j <strong class="ng ir">in</strong> img_folder:<br/>        <strong class="ng ir">try</strong>:<br/>            image <strong class="ng ir">=</strong> cv<strong class="ng ir">.</strong>imread(str(path<strong class="ng ir">+</strong>'/'<strong class="ng ir">+</strong>j))<br/>            image <strong class="ng ir">=</strong> cv<strong class="ng ir">.</strong>resize(image, (32, 32))<br/>            image <strong class="ng ir">=</strong> cv<strong class="ng ir">.</strong>cvtColor(image, cv<strong class="ng ir">.</strong>COLOR_BGR2GRAY)<br/>            image <strong class="ng ir">=</strong> np<strong class="ng ir">.</strong>array(image)<br/>            images<strong class="ng ir">.</strong>append(image)<br/>            label <strong class="ng ir">=</strong> np<strong class="ng ir">.</strong>zeros(classes)<br/>            label[i] <strong class="ng ir">=</strong> 1.0<br/>            labels<strong class="ng ir">.</strong>append(label)<br/>        <strong class="ng ir">except</strong>:<br/>            <strong class="ng ir">pass</strong></span></pre><p id="c734" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">我们现在将数据标准化:我们将图像除以255，得到0.0到1.0之间的像素值。最后，我们将总共39.209幅图像分配给43个类别。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="0c6b" class="mg mh iq ng b gy nk nl l nm nn">images <strong class="ng ir">=</strong> np<strong class="ng ir">.</strong>array(images)<br/>images <strong class="ng ir">=</strong> images<strong class="ng ir">/</strong>255<br/>labels <strong class="ng ir">=</strong> np<strong class="ng ir">.</strong>array(labels)</span><span id="691f" class="mg mh iq ng b gy no nl l nm nn">Images shape: (39209, 32, 32)<br/>Labels shape: (39209, 43)</span></pre><p id="4cdb" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">当处理图像时，查看一些样本总是值得的。让我们从数据集中随机抽取25幅图像，并显示它们的标签。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b392bac231a4d358e17e450748522e83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*9C5iQIwlDzcbjyH5Ndayng.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">25张预处理图片样本。图片来自作者的笔记本</p></figure><p id="1afd" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">在这组图片中，我们可以看到一些可能的错误分类问题。例如，在图像7上很难识别数字，图像13和14太暗。图8(“交通信号”)可能被误归类为“一般注意事项”。</p><h2 id="f638" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">4.构建模型</h2><p id="f26b" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">在创建模型之前，我们必须将数据集分成训练和测试子集。对于测试子集，我们取出标准的20%的数据集。另外，一定要确保我们的数据有<em class="ne"> np </em> <strong class="ky ir"> <em class="ne">。</em> </strong> <em class="ne"> float32 </em>格式。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="3ef4" class="mg mh iq ng b gy nk nl l nm nn">X <strong class="ng ir">=</strong> images<strong class="ng ir">.</strong>astype(np<strong class="ng ir">.</strong>float32)<br/>y <strong class="ng ir">=</strong> labels<strong class="ng ir">.</strong>astype(np<strong class="ng ir">.</strong>float32)<br/><br/>X_train, X_test, y_train, y_test <strong class="ng ir">=</strong> train_test_split(X, y,                 <br/>test_size<strong class="ng ir">=</strong>0.2, random_state<strong class="ng ir">=</strong>123)</span><span id="31e8" class="mg mh iq ng b gy no nl l nm nn">X_train shape: (31367, 32, 32)<br/>y_train shape: (31367, 43)<br/>X_test shape: (7842, 32, 32)<br/>y_test shape: (7842, 43)</span></pre><p id="13a6" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">对于我们的分类任务，我们将使用LeNet-5卷积神经网络的实现。LeNet-5是Yann LeCun等人[3]在1998年设计的，是最早的卷积神经网络之一。它的架构非常简单，但非常高效。</p><p id="a61e" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">有三个基于5×5滤波器的卷积层，然后是具有2×2补丁的平均池。我们使用ReLU功能进行激活，因为它可以加快训练速度。然后我们添加系数为0.2的Dropout层来处理过拟合。这意味着20%的输入将被随机取消，以防止层间的强依赖性。我们最终得到了扁平化和两个致密层。在最后一个密集层中，我们必须分配与类别数量相等的神经元数量，并使用Softmax激活函数来获得0.0到1.0之间的概率。该网络中的最终参数数量为70，415。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="fe0e" class="mg mh iq ng b gy nk nl l nm nn"> Model: "sequential_6"<br/>_________________________________________________________________<br/> Layer (type)                  Output Shape              Param #   <br/>=================================================================<br/> rescaling_7 (Rescaling)       (None, 32, 32, 1)         0         <br/> conv2d_19 (Conv2D)            (None, 28, 28, 6)         156       <br/> average_pooling2d_12          (None, 14, 14, 6)         0         <br/>      (AveragePooling2D)                                                    <br/> conv2d_20 (Conv2D)            (None, 10, 10, 16)        2416      <br/> average_pooling2d_13          (None, 5, 5, 16)          0         <br/>      (AveragePooling2D)                                                    <br/> conv2d_21 (Conv2D)            (None, 1, 1, 120)         48120     <br/> dropout_6 (Dropout)           (None, 1, 1, 120)         0         <br/> flatten_6 (Flatten)           (None, 120)               0         <br/> dense_12 (Dense)              (None, 120)               14520     <br/> dense_13 (Dense)              (None, 43)                5203      <br/>=================================================================<br/> Total params: 70,415<br/> Trainable params: 70,415<br/> Non-trainable params: 0</span></pre><p id="54ec" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">现在有了<em class="ne">型号</em> <strong class="ky ir"> <em class="ne">。</em> </strong> <em class="ne">编译</em>的方法，我们配置模型。Adam学习率优化算法是随机梯度下降的扩展，在训练速度方面是一个很好的选择。分类交叉熵损失函数适合这里，因为它为我们的<em class="ne"> </em>分类问题提供了多类概率分布。对于模型的性能评估，我们将采用准确性指标。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="6cea" class="mg mh iq ng b gy nk nl l nm nn">model<strong class="ng ir">.</strong>compile(optimizer<strong class="ng ir">=</strong>'adam',<br/>              loss<strong class="ng ir">=</strong>'categorical_crossentropy',<br/>              metrics<strong class="ng ir">=</strong>['accuracy'])</span></pre><h2 id="c313" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">5.训练模型</h2><p id="a938" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">现在是训练模型的时候了。我们将输入数据(<em class="ne"> X_train </em>)和目标数据(<em class="ne"> y_train </em>)传递给<em class="ne"> model.fit </em>方法，定义了50个训练时期，还添加了验证数据<em class="ne"> X_test </em>和<em class="ne"> y_test </em>，用于在每个时期结束时评估损失和其他模型指标。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="9329" class="mg mh iq ng b gy nk nl l nm nn">history <strong class="ng ir">=</strong> model<strong class="ng ir">.</strong>fit(X_train, y_train, epochs<strong class="ng ir">=</strong>50,<br/>                    validation_data<strong class="ng ir">=</strong>(X_test, y_test))</span></pre><h2 id="57c7" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">6.培训结果评估</h2><p id="bfdb" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">我们如何知道我们的模型是好是坏？来看看学习曲线吧！<em class="ne">训练</em> <em class="ne">精度</em>和<em class="ne">验证精度</em>曲线最终收敛，经过50个历元我们得到了98.9%的精度，相当不错。<em class="ne">验证损失</em>曲线上下跳动一点。这意味着如果有更多的验证数据就好了。大约25个时期后<em class="ne">验证损失</em>超过<em class="ne">列车损失</em>，这意味着我们这里有一点过度拟合。但是曲线不会随着时间的推移而上升，并且<em class="ne">验证</em>和<em class="ne">列车损失</em>之间的差异并不大，<em class="ne"> </em>因此这是可以接受的。我们就此打住。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/8c4164b74f2d561111a9dc4a9632df38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PKa-SE7jY_WFuQ_2qv9E1A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习曲线。作者图片</p></figure><p id="85ab" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">让我们来看看一些样本，找出错误的分类图片。我们用<em class="ne">预测</em>和<em class="ne">地面实况</em>类来标记图像。如果预测等于地面真相，我们分配一个绿色的标签。否则，我们把它变成红色:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/8feefcf75ac72179e9f81977966d12bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*gp2TFk2XDEN8Djsk8CA92w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">25个随机样本的预测和增长的真实性。图片来自作者的笔记本</p></figure><p id="2811" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">对于编号为5955的图片，我们可以看到“限速(50公里/小时)”标志被误归类为“限速(80公里/小时)”。显然，这里标牌上的文字很难辨认。</p><h2 id="36b0" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">7.保存模型。在应用程序中使用模型</h2><p id="cdf7" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">最后，我们使用<em class="ne">模型</em> <strong class="ky ir"> <em class="ne">将模型保存到Google Drive上的一个单独的文件夹中。</em> </strong> <em class="ne">保存</em>方法。该文件夹包含模型的图形定义和权重，并将用于交通标志识别应用程序中的进一步预测。</p><p id="587b" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">很明显，客户或任何数据科学之外的人永远不会深入你的笔记本，他不会对图表、模型、准确性和所有这些机器学习的东西感兴趣。他需要一个应用程序，他可以上传图像，并得到他的结果。让我们开始吧。</p><p id="e135" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">对于我们的Streamlit应用程序，我们必须准备一个GitHub存储库:我们将<em class="ne"> keras_model </em>文件夹、<em class="ne"> streamlit_app.py </em>和<em class="ne"> requirements.txt </em>放在这里。在Python文件中，我们制作一个应用程序本身:定义它的外观、降价、按钮，我们加载模型并进行预测。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="fce9" class="mg mh iq ng b gy nk nl l nm nn"><strong class="ng ir">def</strong> sign_predict(image):<br/>    model = load_model('./keras_model/')    <br/>    image = np.array(image, dtype=np.float32)    <br/>    image = image/255    <br/>    image = np.reshape(image, (1, 32, 32))    <br/>    x = image.astype(np.float32)    <br/>    prediction = model.predict(x)    <br/>    prediction_max = np.argmax(prediction)    <br/>    prediction_label = labels_dict[prediction_max]    <br/>    confidence = np.max(prediction)    <br/>    return prediction_label, confidence</span></pre><p id="088e" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">我们让用户上传他的照片，并得到他的交通标志预测。在开始预测之前，我们要对用户的图像进行预处理:使其灰度化，32x32像素，另存为<em class="ne"> np </em> <strong class="ky ir"> <em class="ne">。</em> </strong> <em class="ne">浮子32 </em>式。我认为这将是很好的显示上传的图像，以及其预处理的32x32灰色版本。此外，我们将显示代表模型中43个可用类的扩展列表。上传一张图片后，得到的是预测和置信度。<a class="ae kv" href="https://share.streamlit.io/andriigoz/traffic_signs_classification" rel="noopener ugc nofollow" target="_blank"> <em class="ne">这里你可以自己试试app </em> </a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/31b41b453c9d78b3e8a4eb07f3a35217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mftnzwop61koKV1-M3Jg8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在Streamlit上的<a class="ae kv" href="https://share.streamlit.io/andriigoz/traffic_signs_classification" rel="noopener ugc nofollow" target="_blank">应用</a>。作者图片</p></figure><h2 id="8e61" class="mg mh iq bd mi mj mk dn ml mm mn dp mo ld mp mq mr lf ms mt mu lh mv mw mx my bi translated">参考</h2><p id="dd04" class="pw-post-body-paragraph lt lu iq ky b kz mz jr lv lb na ju lw ld nb ly lz lf nc mb mc lh nd me mf lj ij bi translated">[1]德国交通标志识别基准(GTSRB):<a class="ae kv" href="https://benchmark.ini.rub.de/gtsrb_dataset.html" rel="noopener ugc nofollow" target="_blank">https://benchmark.ini.rub.de/gtsrb_dataset.html</a></p><p id="ac11" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">[2] J. Stallkamp，M. Schlipsing，J. Salmen，C. Igel，Man vs. computer:交通标志识别的基准机器学习算法:<a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S0893608012000457" rel="noopener ugc nofollow" target="_blank">https://www . science direct . com/science/article/pii/s 0893608012000457</a></p><p id="fe52" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">[3] Lecun，y；博图湖；纽约州本吉奥；哈夫纳，P. (1998年)。基于梯度的学习应用于文档识别:<a class="ae kv" href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" rel="noopener ugc nofollow" target="_blank">http://vision . Stanford . edu/cs 598 _ spring 07/papers/le Cun 98 . pdf</a></p><p id="743f" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">[4] Suhyun Kim，卷积神经网络(CNN)初学者指南:<a class="ae kv" rel="noopener" target="_blank" href="/a-beginners-guide-to-convolutional-neural-networks-cnns-14649dbddce8">https://towardsdatascience . com/A-初学者-卷积神经网络指南-cnns-14649dbddce8 </a></p><p id="c936" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">[5] Keras，Python深度学习API:【https://keras.io/ T2】</p><p id="20d4" class="pw-post-body-paragraph lt lu iq ky b kz la jr lv lb lc ju lw ld lx ly lz lf ma mb mc lh md me mf lj ij bi translated">[6] OpenCV，一个计算机视觉库:【https://opencv.org/ T4】</p></div></div>    
</body>
</html>