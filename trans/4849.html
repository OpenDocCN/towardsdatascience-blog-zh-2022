<html>
<head>
<title>Downloading and Using the ImageNet Dataset with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch下载和使用ImageNet数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/downloading-and-using-the-imagenet-dataset-with-pytorch-f0908437c4be#2022-10-28">https://towardsdatascience.com/downloading-and-using-the-imagenet-dataset-with-pytorch-f0908437c4be#2022-10-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e23a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用最流行的研究数据集训练您的影像分类模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/54162637934b3ff2a4e4def911b8a8d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t2v6-HHY_KAPN60l"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@ionfet?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">离子场效应晶体管</a>拍照</p></figure><p id="ef95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ImageNet是计算机视觉研究中最流行的数据集。图像数据集包含在WordNet层次结构中找到的所有种类的收集图像。168 GB的大型数据集包含130万张图像，分为1，000个类别，具有不同的标签分辨率粒度。例如，它包含飞机和狗的类别，但也包含不同狗品种的类别，这些类别甚至很难对人类进行分类。ImageNet可用于分类和对象检测任务，并在默认情况下提供训练、验证和测试分割。</p><p id="c362" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可能听过ImageNet、ImageNet1k、ImNet、ILSVRC2012、ILSVRC12等术语。被利用了。它们都引用了为ILSVRC 2012竞赛引入的相同数据集。但是，我应该提到，它只是完整ImageNet的一个子集，以“ImageNet21k”的名称存在。ImageNet21k偶尔用于预训练模型。</p><p id="1a3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最初，ImageNet托管在www.image-net.org的<a class="ae kv" href="http://www.image-net.org," rel="noopener ugc nofollow" target="_blank">，</a>，然后数据集私有化，网站进入维护阶段，最后再次公开，但现在只能根据请求下载。在过去的几年里，我肯定申请了十几次，但都没有成功。下载ImageNet似乎是一次漫长的旅程。</p><p id="06fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最近，组织者举办了一场基于原始数据集的Kaggle挑战赛，增加了用于对象检测的标签。因此，数据集是半公开的:<a class="ae kv" href="https://www.kaggle.com/competitions/imagenet-object-localization-challenge/" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/competitions/imagenet-object-localization-challenge/</a></p><p id="7385" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要下载数据集，您需要注册一个Kaggle帐户并加入挑战。请注意，这样做意味着您同意遵守<a class="ae kv" href="https://www.kaggle.com/competitions/imagenet-object-localization-challenge/rules" rel="noopener ugc nofollow" target="_blank">竞赛规则</a>。特别是，您只能将数据集用于非商业研究和教育目的。</p><p id="97a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，安装Kaggle CLI:</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="a2cd" class="lx ly iq lt b gy lz ma l mb mc">pip install kaggle</span></pre><p id="97aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在您需要设置您的凭证。这一步非常重要，否则，你将无法开始下载。请遵循官方<a class="ae kv" href="https://github.com/Kaggle/kaggle-api#api-credentials" rel="noopener ugc nofollow" target="_blank">指南</a>:</p><blockquote class="md me mf"><p id="0733" class="kw kx mg ky b kz la jr lb lc ld ju le mh lg lh li mi lk ll lm mj lo lp lq lr ij bi translated">要使用Kaggle API，请在<a class="ae kv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com</a>注册一个Kaggle账户。然后转到您的用户配置文件(<code class="fe mk ml mm lt b">https://www.kaggle.com/&lt;username&gt;/account</code>)的“帐户”选项卡，并选择“创建API令牌”。这将触发下载<code class="fe mk ml mm lt b">kaggle.json</code>，一个包含您的API凭证的文件。将这个文件放在位置<code class="fe mk ml mm lt b">~/.kaggle/kaggle.json</code>(在Windows上的位置<code class="fe mk ml mm lt b">C:\Users\&lt;Windows-username&gt;\.kaggle\kaggle.json</code>——你可以用<code class="fe mk ml mm lt b">echo %HOMEPATH%</code>检查确切的位置，sans drive)。您可以定义一个shell环境变量<code class="fe mk ml mm lt b">KAGGLE_CONFIG_DIR</code>来将这个位置更改为<code class="fe mk ml mm lt b">$KAGGLE_CONFIG_DIR/kaggle.json</code>(在Windows上是<code class="fe mk ml mm lt b">%KAGGLE_CONFIG_DIR%\kaggle.json</code>)。</p></blockquote><p id="a93b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成后，您就可以开始下载了。请注意，此文件非常大(168 GB)，下载将需要几分钟到几天的时间，这取决于您的网络连接。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="83a8" class="lx ly iq lt b gy lz ma l mb mc">kaggle competitions download -c imagenet-object-localization-challenge</span></pre><p id="fc97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下载完成后，你解压文件。对于Unix，只需使用<code class="fe mk ml mm lt b">unzip</code>。请注意，这也需要一段时间。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="e413" class="lx ly iq lt b gy lz ma l mb mc">unzip imagenet-object-localization-challenge.zip -d &lt;YOUR_FOLDER&gt;</span></pre><p id="455c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还需要两个小的辅助文件。您可以独立地重写下面的代码，但是简单地使用这些文件会更快更简单。因此，只需将它们下载到ImageNet根文件夹(包含ILSVRC文件夹的那个文件夹)中。如果你在Unix系统下，你可以使用<code class="fe mk ml mm lt b">wget</code>:</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="4a53" class="lx ly iq lt b gy lz ma l mb mc">cd &lt;YOUR_FOLDER&gt;<br/>wget <a class="ae kv" href="https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json</a><br/>wget <a class="ae kv" href="https://gist.githubusercontent.com/paulgavrikov/3af1efe6f3dff63f47d48b91bb1bca6b/raw/00bad6903b5e4f84c7796b982b72e2e617e5fde1/ILSVRC2012_val_labels.json" rel="noopener ugc nofollow" target="_blank">https://gist.githubusercontent.com/paulgavrikov/3af1efe6f3dff63f47d48b91bb1bca6b/raw/00bad6903b5e4f84c7796b982b72e2e617e5fde1/ILSVRC2012_val_labels.json</a></span></pre><p id="5915" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在需要做的就是为PyTorch编写一个<code class="fe mk ml mm lt b">Dataset</code>类。我认为实际的代码加载起来很无聊，所以我就不赘述了。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="419c" class="lx ly iq lt b gy lz ma l mb mc">import os<br/>from torch.utils.data import Dataset<br/>from PIL import Image<br/>import json</span><span id="8c14" class="lx ly iq lt b gy mn ma l mb mc">class ImageNetKaggle(Dataset):<br/>    def __init__(self, root, split, transform=None):<br/>        self.samples = []<br/>        self.targets = []<br/>        self.transform = transform<br/>        self.syn_to_class = {}<br/>        with open(os.path.join(root, "imagenet_class_index.json"), "rb") as f:<br/>                    json_file = json.load(f)<br/>                    for class_id, v in json_file.items():<br/>                        self.syn_to_class[v[0]] = int(class_id)<br/>        with open(os.path.join(root, "ILSVRC2012_val_labels.json"), "rb") as f:<br/>                    self.val_to_syn = json.load(f)<br/>        samples_dir = os.path.join(root, "ILSVRC/Data/CLS-LOC", split)<br/>        for entry in os.listdir(samples_dir):<br/>            if split == "train":<br/>                syn_id = entry<br/>                target = self.syn_to_class[syn_id]<br/>                syn_folder = os.path.join(samples_dir, syn_id)<br/>                for sample in os.listdir(syn_folder):<br/>                    sample_path = os.path.join(syn_folder, sample)<br/>                    self.samples.append(sample_path)<br/>                    self.targets.append(target)<br/>            elif split == "val":<br/>                syn_id = self.val_to_syn[entry]<br/>                target = self.syn_to_class[syn_id]<br/>                sample_path = os.path.join(samples_dir, entry)<br/>                self.samples.append(sample_path)<br/>                self.targets.append(target)</span><span id="5193" class="lx ly iq lt b gy mn ma l mb mc">    def __len__(self):<br/>            return len(self.samples)</span><span id="32ef" class="lx ly iq lt b gy mn ma l mb mc">    def __getitem__(self, idx):<br/>            x = Image.open(self.samples[idx]).convert("RGB")<br/>            if self.transform:<br/>                x = self.transform(x)<br/>            return x, self.targets[idx]</span></pre><p id="a047" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们可以通过为预训练的ResNet-50模型运行验证时期来测试它。</p><pre class="kg kh ki kj gt ls lt lu lv aw lw bi"><span id="3411" class="lx ly iq lt b gy lz ma l mb mc">from torch.utils.data import DataLoader<br/>from torchvision import transforms<br/>import torch<br/>import torchvision<br/>from tqdm import tqdm</span><span id="661b" class="lx ly iq lt b gy mn ma l mb mc">model = torchvision.models.resnet50(weights="DEFAULT")<br/>model.eval().cuda()  # Needs CUDA, don't bother on CPUs<br/>mean = (0.485, 0.456, 0.406)<br/>std = (0.229, 0.224, 0.225)<br/>val_transform = transforms.Compose(<br/>            [<br/>                transforms.Resize(256),<br/>                transforms.CenterCrop(224),<br/>                transforms.ToTensor(),<br/>                transforms.Normalize(mean, std),<br/>            ]<br/>        )<br/>dataset = ImageNetKaggle(&lt;YOUR_FOLDER&gt;, "val", val_transform)<br/>dataloader = DataLoader(<br/>            dataset,<br/>            batch_size=64, # may need to reduce this depending on your GPU <br/>            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM<br/>            shuffle=False,<br/>            drop_last=False,<br/>            pin_memory=True<br/>        )<br/>correct = 0<br/>total = 0<br/>with torch.no_grad():<br/>    for x, y in tqdm(dataloader):<br/>        y_pred = model(x.cuda())<br/>        correct += (y_pred.argmax(axis=1) == y.cuda()).sum().item()<br/>        total += len(y)</span><span id="de5b" class="lx ly iq lt b gy mn ma l mb mc">print(correct / total)</span></pre><p id="5ee8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这应该输出0.80342，这是模型的精度(80.342%)。</p><h1 id="17d7" class="mo ly iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">ImageNet的替代产品</h1><p id="017f" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">对于大多数人来说，使用ImageNet进行培训仍然过于昂贵。然而，有许多基于ImageNet的替代数据集，其分辨率和/或样本和标签数量有所减少。这些数据集可以用于训练，只需花费一小部分成本。一些例子有<a class="ae kv" href="https://github.com/fastai/imagenette" rel="noopener ugc nofollow" target="_blank">图像网</a>、<a class="ae kv" href="https://www.kaggle.com/c/tiny-imagenet" rel="noopener ugc nofollow" target="_blank">微型图像网</a>、<a class="ae kv" href="https://www.kaggle.com/datasets/ambityga/imagenet100" rel="noopener ugc nofollow" target="_blank">图像网100 </a>和<a class="ae kv" href="https://github.com/BayesWatch/cinic-10" rel="noopener ugc nofollow" target="_blank"> CINIC-10 </a>。</p><h1 id="cda5" class="mo ly iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">参考</h1><p id="394b" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">[1]邓，董，李，李，，，“ImageNet:一个大规模的层次图像数据库”，<em class="mg"> 2009年IEEE计算机视觉与模式识别会议</em>，2009，第248–255页，doi: 10.1109/CVPR.2009.5206848</p><p id="b1be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集是免费的，用于非商业研究和教育目的。</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><p id="7519" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mg">感谢您阅读这篇文章！如果你喜欢它，请考虑订阅我的更新。如果你有任何问题，欢迎在评论中提出。</em></p></div></div>    
</body>
</html>