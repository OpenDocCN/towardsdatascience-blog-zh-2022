<html>
<head>
<title>Conversational Sentiment Analysis on Audio Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">音频数据的会话情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conversational-sentiment-analysis-on-audio-data-cd5b9a8e990b#2022-07-20">https://towardsdatascience.com/conversational-sentiment-analysis-on-audio-data-cd5b9a8e990b#2022-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6a3b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">分析言语中的情感</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c3b11ef74a97f7eb8dc1f5dda6bed155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*52JJ5lnRj0wADl8e"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@towfiqu999999?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">图为<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的</a></p></figure><p id="f898" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">情感分析，也称为观点挖掘，由于其不同的工业应用，是自然语言处理(NLP)中的一个热门任务。在将NLP技术专门应用于文本数据的情况下，主要目标是训练一个模型，该模型可以在不同的情感类别之间对给定的文本片段进行分类。下图显示了情感分类器的高级概述。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/6f4f3bfc896376c02f3e1bb93d0cd4ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*U6fFYtuR_XqBWAXSpv126Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">情感分析模型概述(图片由作者提供)</p></figure><p id="f39c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，三类分类问题的类可以是<code class="fe lt lu lv lw b">Positive</code>、<code class="fe lt lu lv lw b">Negative</code>和<code class="fe lt lu lv lw b">Neutral</code>。三类情感分析问题的一个例子是流行的<a class="ae kv" href="https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis" rel="noopener ugc nofollow" target="_blank"> Twitter情感分析</a>数据集，这是一个实体级的情感分析任务，针对Twitter上各种用户发布的多语言推文。</p><p id="dfa9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然NLP中的大多数先前的研究和开发主要集中在对文本应用情感分析，但是最近，我们已经看到基于语音的交互工具在用户中的大规模采用和流行，使得研究人员和组织在语音空间中构建情感分类器。</p><p id="c44f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，这篇文章将展示如何使用<strong class="ky ir"> AssemblyAI API </strong>和<strong class="ky ir"> Python </strong>构建一个基于对话数据的情感分析系统。端到端系统在涉及严格的客户支持和反馈评估的领域具有广泛的适用性——这使得它成为一个需要解决的重要且有价值的问题，尤其是在语音领域。最后，我还将展示一个广泛的分析，以增强所获得结果的可解释性，并从数据中得出适当的见解。</p><p id="abcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到这篇文章<a class="ae kv" href="https://deepnote.com/workspace/avi-chawla-695b-aee6f4ef-2d50-4fb6-9ef2-20ee1022995a/project/Conversational-Sentiment-Analysis-6853cafe-37da-4641-aab4-f39fe0f09172/%2Fsentiment%20analysis.ipynb" rel="noopener ugc nofollow" target="_blank">的代码</a>。此外，文章的亮点如下:</p><p id="20fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="#3f04" rel="noopener ugc nofollow"> <strong class="ky ir">对对话音频数据的情感分析</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#7ea6" rel="noopener ugc nofollow"><strong class="ky ir">情感分析结果</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#802b" rel="noopener ugc nofollow"><strong class="ky ir">情感分析见解</strong> </a></p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="3f04" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">会话音频数据的情感分析</h1><p id="da1d" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">在这一节中，我将演示如何使用AssemblyAI API将给定的一段预先录制的语音对话中的各个句子分为三个情感类别:<code class="fe lt lu lv lw b">Positive</code>、<code class="fe lt lu lv lw b">Negative</code>和<code class="fe lt lu lv lw b">Neutral</code>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/50b602e3a76fcefbe9c42d5898fa81b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*jfEBdpmoYV3PWVXrjAUiRA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">通过API概述情感分析模型(图片由作者提供)</p></figure><h2 id="50cc" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤1:安装需求</h2><p id="3f01" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">构建情感分类器的要求很少。就python库而言，我们只需要Python中的<code class="fe lt lu lv lw b"><a class="ae kv" href="https://pypi.org/project/requests/" rel="noopener ugc nofollow" target="_blank">requests</a></code>包。这可以通过以下方式完成:</p><pre class="kg kh ki kj gt nn lw no np aw nq bi"><span id="8669" class="nb mf iq lw b gy nr ns l nt nu">pip install requests</span></pre><h2 id="7435" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤2:生成API令牌</h2><p id="e81b" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">下一步是在AssemblyAI网站上创建一个账户，这是免费的。一旦完成，您将获得您的私有API访问密钥，我们将使用它来访问语音到文本模型。</p><h2 id="1491" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤3:上传音频文件</h2><p id="09e5" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">出于本教程的目的，我将使用两个人之间预先录制的音频对话来对进行情感分析。一旦您获得了API密钥，您就可以继续对预先录制的音频文件执行情感分类任务。</p><p id="f572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，在此之前，您需要上传音频文件，以便可以通过URL访问它。选项包括上传到AWS S3桶，音频托管服务，如SoundCloud或AssemblyAI的自托管服务等。我已经将音频文件上传到SoundCloud，可以在下面访问。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nv nw l"/></div></figure><p id="9d31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你想把音频文件直接上传到AssemblyAI的主机服务，你也可以这样做。我已经在下面的代码块中演示了这个循序渐进的过程。</p><h2 id="d1be" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤3.1:进口要求</h2><p id="718a" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">我们从导入项目的需求开始。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx nw l"/></div></figure><h2 id="0f1b" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤3.2:指定文件位置和API_Key</h2><p id="3985" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">接下来，我们需要指定音频文件在本地机器上的位置以及注册后获得的API密钥。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ny nw l"/></div></figure><h2 id="9d02" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤3.3:指定上传端点</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nz nw l"/></div></figure><ul class=""><li id="e22c" class="oa ob iq ky b kz la lc ld lf oc lj od ln oe lr of og oh oi bi translated"><code class="fe lt lu lv lw b">endpoint</code>:这指定了要调用的服务，在本例中是“上传”服务。</li><li id="d6de" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr of og oh oi bi translated"><code class="fe lt lu lv lw b">headers</code>:保存API密钥和内容类型。</li></ul><h2 id="f5b8" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤3.4:定义上传功能</h2><p id="97b1" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">音频文件一次最多只能上传5 MBs (5，242，880字节)。因此，我们需要分块上传数据。这些然后在服务端点上被合并回来。因此，您不需要担心处理大量的URL。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oo nw l"/></div></figure><h2 id="1c83" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">第3.5步:上传</h2><p id="3c9c" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">最后一步是调用POST请求。post请求的响应是一个保存音频文件的<code class="fe lt lu lv lw b">upload_url</code>的JSON。我将使用这个URL来执行音频情感分类的后续步骤。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="op nw l"/></div></figure><h2 id="b5b7" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">第四步:情感分析</h2><p id="d6f7" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">在这一步，我们已经满足了对音频文件执行情感分析任务的所有必要的先决条件。现在，我们可以继续调用API来获取期望的结果。这是一个两步过程，将在下面的小节中演示。</p><h2 id="2dd4" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤4.1:提交文件进行转录</h2><p id="3854" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">第一步是调用HTTP Post请求。这实质上是将你的音频文件发送给在后台运行的人工智能模型进行转录，并指示它们对转录的文本进行情感分析。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oq nw l"/></div></figure><p id="2f9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">传递给<strong class="ky ir"> POST </strong>请求的参数有:</p><ol class=""><li id="4f7b" class="oa ob iq ky b kz la lc ld lf oc lj od ln oe lr or og oh oi bi translated"><code class="fe lt lu lv lw b">endpoint</code>:指定要调用的转录服务。</li><li id="a4b7" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated"><code class="fe lt lu lv lw b">json</code>:这个包含了你的音频文件的URL作为<code class="fe lt lu lv lw b">audio_url</code>键。由于我们希望对会话数据进行情感分析，所以<code class="fe lt lu lv lw b">sentiment_analysis</code>标志和<code class="fe lt lu lv lw b">speaker_labels</code>被设置为<code class="fe lt lu lv lw b">True</code>。</li><li id="631c" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated"><code class="fe lt lu lv lw b">headers</code>:此处装有<code class="fe lt lu lv lw b">authorization</code>键和<code class="fe lt lu lv lw b">content-type</code>。</li></ol><p id="4dbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">JSON响应中收到的post请求的当前状态是<code class="fe lt lu lv lw b">queued</code>。这表明音频当前正在被转录。</p><p id="c8f0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而且，JSON响应中的<code class="fe lt lu lv lw b">sentiment_analysis</code>标志也是<code class="fe lt lu lv lw b">True</code>。然而，由于当前状态为<code class="fe lt lu lv lw b">queued</code>，对应于<code class="fe lt lu lv lw b">sentiment_analysis_results</code>键的值为<strong class="ky ir">无</strong>。</p><h2 id="8d0b" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">步骤4.2:获取转录结果</h2><p id="694a" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">为了检查POST请求的状态，我们需要使用上面收到的JSON响应中的<code class="fe lt lu lv lw b">id</code>键发出GET请求。</p><p id="4213" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们可以继续处理GET请求，如下面的代码块所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="os nw l"/></div></figure><p id="3b8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">传递给<strong class="ky ir"> GET </strong>请求的参数是:</p><ol class=""><li id="b494" class="oa ob iq ky b kz la lc ld lf oc lj od ln oe lr or og oh oi bi translated"><code class="fe lt lu lv lw b">endpoint</code>:指定调用的服务和使用<code class="fe lt lu lv lw b">id</code>键确定的API调用标识符。</li><li id="38fb" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated"><code class="fe lt lu lv lw b">headers</code>:这个保存了你唯一的API密匙。</li></ol><p id="8b0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里你要知道转录结果要等到<code class="fe lt lu lv lw b">status</code>键变成<code class="fe lt lu lv lw b">completed</code>才准备好。转录所需的时间取决于输入音频文件的长度。因此，您必须定期发出重复的GET请求来检查转录状态。下面实现了一种简单的方法:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot nw l"/></div></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><h1 id="7ea6" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">情感分析结果</h1><p id="2e38" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">一旦<code class="fe lt lu lv lw b">status</code>变为<code class="fe lt lu lv lw b">completed</code>，您将会收到类似下面提到的响应。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ou nw l"/></div></figure><ol class=""><li id="d19b" class="oa ob iq ky b kz la lc ld lf oc lj od ln oe lr or og oh oi bi translated">JSON响应中的<code class="fe lt lu lv lw b">status</code>标记为<code class="fe lt lu lv lw b">completed</code>。这表明在转录音频时没有错误。</li><li id="7f2f" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated"><code class="fe lt lu lv lw b">text</code>键包含输入音频对话的完整转录，共22个句子。</li><li id="e737" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated">由于音频文件由多个扬声器组成，我们将<code class="fe lt lu lv lw b">words</code>键中的所有<code class="fe lt lu lv lw b">speaker</code>键视为<strong class="ky ir">不为空</strong>。<code class="fe lt lu lv lw b">speaker</code>键是“A”或“b”</li><li id="2ece" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated">我们可以看到所有单个单词和整个转录文本的置信度得分。分数范围从0到1，0为最低，1为最高。</li><li id="9f1e" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated">使用JSON响应的<code class="fe lt lu lv lw b">sentiment_analysis_results</code>键可以访问音频中22个单独句子的情感分析结果。</li><li id="1afe" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated">对应每个句子，我们得到一个类似于上面第4点的<code class="fe lt lu lv lw b">confidence</code>分数。</li><li id="487e" class="oa ob iq ky b kz oj lc ok lf ol lj om ln on lr or og oh oi bi translated">使用句子词典的<code class="fe lt lu lv lw b">sentiment</code>键可以检索每个句子的情感。第二句的情感分析结果如下所示:</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ov nw l"/></div></figure><h1 id="802b" class="me mf iq bd mg mh ow mj mk ml ox mn mo jw oy jx mq jz oz ka ms kc pa kd mu mv bi translated">情感分析洞察</h1><p id="4f7e" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">JSONs通常很难阅读和解释。因此，为了使数据在视觉上更具吸引力，并进行进一步的分析，让我们将上面的情感分析结果转换成一个数据框架。我们将存储句子的<code class="fe lt lu lv lw b">text</code>、句子的<code class="fe lt lu lv lw b">duration</code>、句子的<code class="fe lt lu lv lw b">speaker</code>和句子的<code class="fe lt lu lv lw b">sentiment</code>。这在下面实现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb nw l"/></div></figure><p id="5049" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用上面的代码片段生成的DataFrame如下图所示。这里，我们有在对话期间说出的22个句子，以及相应的说话者标签(“A”和“B”)，它们的持续时间(以秒计)，以及由模型预测的句子的情绪。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/502ea1155432f8bd5e1aca6d1332d2f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62b23_PbTNMmisvc52H-3A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">音频文件中的句子(图片由作者提供)</p></figure><h2 id="30b5" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">排名第一的扬声器分布</h2><p id="60ee" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">可以使用如下所示的<code class="fe lt lu lv lw b">value_counts()</code>方法计算每个说话者说出的句子数量:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nz nw l"/></div></figure><p id="05ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要查看发言者的百分比分布，我们可以将<code class="fe lt lu lv lw b">normalize = True</code>传递给<code class="fe lt lu lv lw b">value_counts()</code>方法，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nz nw l"/></div></figure><p id="25d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">就句子数量而言，说话者“A”和“B”对对话的贡献是相等的。</p><h2 id="97b5" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">#2发言者持续时间分布</h2><p id="446b" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">接下来，让我们计算对话中每个发言者的个人贡献。如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd nw l"/></div></figure><p id="8981" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们使用<code class="fe lt lu lv lw b">groupby()</code>方法计算他们演讲的总时长。就持续时间而言，说话者A是占优势的说话者。</p><h2 id="285e" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">#3情感分布</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pe nw l"/></div></figure><p id="48d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在对话中说出的22个句子中，只有3个被标记为<code class="fe lt lu lv lw b">negative</code>情绪。此外，没有一个句子被预测为<code class="fe lt lu lv lw b">positive</code>情绪。</p><p id="e532" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">归一化分布可以计算如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nz nw l"/></div></figure><h2 id="7b75" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">#4演讲者层面的情感分布</h2><p id="cfc4" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">最后，让我们计算一下各个说话者的情绪分布。这里，为了更好的可视化，我们将使用<code class="fe lt lu lv lw b">crosstab()</code>，而不是使用<code class="fe lt lu lv lw b">groupby()</code>方法。下面演示了这一点:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pf nw l"/></div></figure><p id="601a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">说话者“A”所说的否定句比说话者“B”所说的多。</p><h2 id="b2f4" class="nb mf iq bd mg nc nd dn mk ne nf dp mo lf ng nh mq lj ni nj ms ln nk nl mu nm bi translated">情感层面的平均句子时长排名第五</h2><p id="eebd" class="pw-post-body-paragraph kw kx iq ky b kz mw jr lb lc mx ju le lf my lh li lj mz ll lm ln na lp lq lr ij bi translated">最后，我们将计算属于各个情感类别的句子的平均持续时间。这通过使用<code class="fe lt lu lv lw b">groupby()</code>方法实现如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pd nw l"/></div></figure><p id="8e9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe lt lu lv lw b">negative</code>句的平均持续时间小于<code class="fe lt lu lv lw b">neutral</code>句。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="075a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，在这篇文章中，我们讨论了AssemblyAI API的一个特定的NLP用例。具体来说，我们看到了如何在包含多个说话者的预先录制的音频文件上构建情感分类模块。最后，我们对情感分析结果进行了广泛的分析。从API获得的结果突出了输入音频文件中22个单独句子的情感。</p><p id="5deb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到这篇文章的代码。</p><p id="c9b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在接下来的文章中，我将从技术和实践的角度讨论AssemblyAI API的更多用例，比如实体检测、内容审核等等。</p><p id="d1e8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下次见。感谢阅读。</p></div></div>    
</body>
</html>