<html>
<head>
<title>Regression Trees, Step by Step</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归树，循序渐进</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/regression-trees-step-by-step-4de996e27f85#2022-08-03">https://towardsdatascience.com/regression-trees-step-by-step-4de996e27f85#2022-08-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5fa4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习如何构建回归树，了解它们的主要优点和缺点</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/460804b170332a7af430e0419c916b7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0xqfxjSL6CAGcW0a"/></div></div></figure><p id="8d20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">【免责声明:此帖子包含一些我的Udemy课程的附属链接】</em></p><p id="378c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi lr translated">决策树已经存在了几十年，在世界各地的几个机器学习项目中都有使用。虽然它们很可能不会在大多数问题上达到最先进的性能，但它们仍然是最值得测试的可解释算法之一。此外，它们是极端梯度提升、随机森林或贝叶斯回归树等著名算法的支柱，了解它们是数据科学家和机器学习工程师的必备知识。</p><p id="9a58" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">与普通的线性或逻辑回归(不对特征应用二次变换)相反，决策树能够非线性地分割我们的数据，在我们的特征和目标之间建立有趣的关系，这对于其他更简单的算法来说似乎是不可能的。</p><p id="7291" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当然，这不是没有代价的。由于它们的非线性本质，决策树通常是高方差模型，可以很好地适应大多数训练数据集，但在测试数据上表现很差。</p><p id="5d15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我们将探索回归树，两种最常见的决策树之一(另一种是<a class="ae ma" rel="noopener" target="_blank" href="/classification-decision-trees-easily-explained-f1064dde175e">分类</a>)。我们将在一个玩具数据集上做几个实验，并走过以下路径:</p><ul class=""><li id="3257" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">首先，我们将绘制数据集，了解房屋大小和价格之间的关系。</li><li id="bbe8" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">然后，我们将了解线性回归在我们的数据集中表现不佳的原因。</li><li id="142d" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">我们将拟合一个回归树，并可视化它对数据的(几乎)完美拟合。</li><li id="bca1" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">我们将详细介绍回归树以及它们的超参数如何影响训练。</li></ul><p id="5e22" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在整篇文章中，我将使用R编程语言来支持每一个解释，展示一些代码来解释我们将探索的每个细节——让我们开始吧！</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="fb41" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">设置和检查数据集</h1><p id="f1a5" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">在这篇文章中，我们将使用一个房价玩具数据集。点击这个<a class="ae ma" href="https://fastupload.io/en/3EB6gdFj9CFBuPy/file" rel="noopener ugc nofollow" target="_blank">链接</a>可以找到excel源文件。将这个数据集加载到R中非常容易:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="2452" class="ny mx it nu b gy nz oa l ob oc">library(readxl)<br/>library(ggplot2)<br/>library(dplyr)<br/>library(rpart)<br/>library(rpart.plot)</span><span id="c18a" class="ny mx it nu b gy od oa l ob oc">house_prices &lt;- read_excel('./data/house_prices.xlsx')</span></pre><p id="d9aa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上面的代码片段中，我还添加了我们在帖子后面需要的库:</p><ul class=""><li id="c35f" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated"><code class="fe oe of og nu b">readxl</code>加载我们的excel文件。</li><li id="2759" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated"><code class="fe oe of og nu b">ggplot2</code>为我们的地块。</li><li id="5fd4" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated"><code class="fe oe of og nu b">dplyr</code>执行一些数据转换。</li><li id="3b1f" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated"><code class="fe oe of og nu b">rpart</code>构建我们的决策树。</li><li id="8167" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated"><code class="fe oe of og nu b">rpart.plot</code>绘制我们的决策树。</li></ul><p id="78a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的数据包含来自一个虚构地方的57个房屋实例，我们有两个相关变量—房屋的价格及其面积(平方英尺):</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="ab8e" class="ny mx it nu b gy nz oa l ob oc">house_price_plot &lt;- ggplot(<br/>  data = house_prices,<br/>  aes(x = area, y = price)<br/>) + geom_point()</span><span id="39a6" class="ny mx it nu b gy od oa l ob oc">house_price_plot</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/06e4075935e086f1646258522663a1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*QKYrKfEUNHzHe0LRe_lwww.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集-按作者分类的图像</p></figure><p id="21ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">自然，房子的价格和面积是线性关系。这是意料之中的，因为我们知道(同一位置的)大房子往往会更贵。</p><p id="6ddc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但请注意一些奇怪的事情，81到87平方英尺的房子比77到81平方英尺的房子便宜——这将打破我们的线性回归。至少对于这些点来说，我们的回归线将无法捕捉到这种关系，尽管该模型将具有质量，但它将无法理解这一小簇房屋打破了整体趋势。</p><p id="b9a2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当我们发现这种类型的问题时，我们通常会试图寻找一些我们没有测量的影响来源——例如，房子里浴室的数量可以解释这种下降。在这篇文章中，让我们假设我们无法访问更多关于房子的数据。</p><p id="3e3e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">所以……我们的假设是在这个图上拟合一条回归线肯定会建立一些次优的东西</strong>(同样，忽略我们能够做任何特征变换，因为二次特征可能有帮助)<strong class="kw iu">——接下来让我们证明这一点。</strong></p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="9689" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">拟合线性回归</h1><p id="4516" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">如果我们用R对数据拟合一条回归线:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="3314" class="ny mx it nu b gy nz oa l ob oc">linear.model &lt;- lm(price ~ area, data=house_prices)</span></pre><p id="e732" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虽然我们实现了大约0.8998的R平方，<strong class="kw iu">但我们的模型仍然存在一些偏差来源。我们是怎么知道的？让我们将我们的预测与真实目标进行对比。</strong></p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="9808" class="ny mx it nu b gy nz oa l ob oc">simulation_prices &lt;- data.frame(<br/>  area = seq(min(house_prices$area), <br/>            max(house_prices$area))<br/>)</span><span id="b59f" class="ny mx it nu b gy od oa l ob oc"># Predicting house price based on our linear.model<br/>simulation_prices$predicted_house_price &lt;- predict(<br/>  linear.model,<br/>  simulation_prices<br/>)</span><span id="48d2" class="ny mx it nu b gy od oa l ob oc"># Plotting Houses Prices + Predictions<br/>(<br/>  house_price_plot<br/>  +<br/>  geom_line(data=simulation_prices, aes(x=area, y=predicted_house_price), color='red')<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8f828ba471309c81a08520e4824b8129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*ykt_aX5LlXB9xla289KaBQ.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与回归线-作者图片</p></figure><p id="f757" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">红色的是我们预测的回归线。虽然我们的模型很好地捕捉了数据的趋势，但它超越了两组房屋:</p><ul class=""><li id="a8d0" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">面积不超过40平方米的房屋。脚。</li><li id="75b9" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">面积在81至87平方米之间的房屋。脚:</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/45ab26fc9982a6636f31763824dc5c3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*8imkE9kknUF4PvlvoGRkRQ.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与回归线-作者图片</p></figure><p id="7dc2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如我们已经讨论过的，有几种方法可以解决这种偏见，即:</p><ul class=""><li id="87c1" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">1)构建二次特征以更好地捕捉关系-这些特征将能够将我们的回归线“弯曲”成曲线模型。</li><li id="7507" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">2)使用能够解释这些房屋为何打破整体趋势的其他特征。</li><li id="1195" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">3)使用其他类型的模型，更好地捕捉这些类型的复杂关系。</li></ul><p id="73ca" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">我们要走第三条路线！</strong></p><p id="12b6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">回归树是基本的非线性模型之一，能够捕捉特征和目标之间的复杂关系-让我们从拟合一个开始，看看它的性能，然后讨论它们为什么有用以及如何从头构建一个。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="a39e" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">拟合回归树</h1><p id="1cbb" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">决策树是一种算法，能够捕捉我们看到的面积和房价之间关系的下降。有了1个特征，决策树(当我们预测连续变量时称为回归树)将构建类似于<em class="lq">阶跃函数</em>的东西，如下所示。我将从拟合决策树开始，只是为了让您对我们产生的输出感到好奇。</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="f5fa" class="ny mx it nu b gy nz oa l ob oc">d.tree &lt;- rpart(price ~ area,<br/>             data = house_prices, method = 'anova',<br/>             control = list(maxdepth=5,<br/>                            minsplit=2, minbucket=2,<br/>                            cp = 0.0001))</span></pre><p id="cd58" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">暂时忽略<code class="fe oe of og nu b">rpart</code>的那些参数——我将在接下来详述它们。在上面的函数中，我们使用递归分区库<code class="fe oe of og nu b">rpart</code>将决策树拟合到我们的数据中——让我们看看拟合生成的“线”:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/137ee88593238d9b4d5ca6ef45ceb0cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*Q11pTFTQFrgOkjXPCKF94A.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与决策树线-作者图片</p></figure><p id="7951" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">看看这和我们的回归线有多不同？</strong>我们如何能够更好地发现数据中的奇怪模式？</p><p id="8b93" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">两个问题展开了:</p><ul class=""><li id="f0d3" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">为什么决策树更善于捕捉这些类型的关系？</li><li id="aaab" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">它们只有在能够捕捉目标和特征之间的复杂交互时才有优势，还是有缺点？</li></ul><p id="dec7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们看看！</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="4c8e" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">回归树是如何工作的？—第一次拆分</h1><p id="5889" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">回归树基本上按照一定的标准分割数据，直到它们根据它们的超参数集找到同质组。</p><p id="263b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我知道这听起来令人困惑，但是让我们详细说明一下——你会发现这实际上是一个非常简单的概念。</p><p id="4252" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">回归树的核心是只能预测每次分割后的平均值。想象一下，我会让你把我们的数据分成两部分——比如关于<code class="fe oe of og nu b">area=68</code>的数据:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="fb66" class="ny mx it nu b gy nz oa l ob oc">house_price_plot + geom_vline(xintercept=68, color = "red")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/4f9f46b9dbdbc67e53994993235bcc21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*1xWKZ4wXcAtZCbkgNnhLSA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与随机分割-作者图片</p></figure><p id="d09b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设我们最好的猜测是用我们线两边的平均值对每栋新房子进行分类。<strong class="kw iu">每一栋面积小于68平方米的新房子。ft，我们说它的价格是115.844 €: </strong></p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="e8cc" class="ny mx it nu b gy nz oa l ob oc">mean_value = house_prices %&gt;%<br/>  filter(area &lt; 68) %&gt;%<br/>  summarize(mean_price = mean(price))</span><span id="e458" class="ny mx it nu b gy od oa l ob oc">(<br/>  house_price_plot <br/>  + <br/>  geom_vline(xintercept=68, color = "red")<br/>  + <br/>  geom_segment(aes(x=30, xend=68, y=mean_value[[1]], yend=mean_value[[1]], color='orange'))<br/>  +<br/>  theme(legend.position="none")<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/0b3083f09bd8ad861cfa455f8d4b4bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*kNf56zUnFN5m5qNcZDUmnA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与平均预测值-作者图片</p></figure><p id="c1f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果这是我们的猜测，我们清楚地看到，由于低于68平方英尺的房屋价格的可变性，我们最终犯了很多错误。制成范围从100k到125k€。</p><p id="a9dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们如何量化我们的简单模型所犯的错误？我们只是计算每个点与我们的“最佳猜测”的差异。以第一栋房子为例:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8aa8297f8e70dcd9e3e08ca4d40263e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*OBFv_2JbpDG4NlerVqKQQA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与第一套房子的平均预测误差-图片由作者提供</p></figure><p id="9794" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">黑线表示我们的错误</strong>——我们高估了这栋房子16k€的价格。如果你是房子的买家，你会非常生气，因为你会支付高于房子公允价值的价格。</p><p id="20b3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是..还有其他一些情况，你(作为买家)会非常高兴，因为我们也低于一些价格，比如这栋房子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/333fc69c5c7390f071cf66eea62fd72e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*QEPO5EXd1WuwKCQSAx3Uog.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与17号房屋的平均预测误差-图片由作者提供</p></figure><p id="f499" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">不错的交易！</p><p id="9fd1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">好吧，很明显我们的模型还不够好——但它正在某个地方开始。在右边，对于大于或等于68平方英尺的房屋，如果我们用右边的平均值分类，也会发生同样的问题:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="855d" class="ny mx it nu b gy nz oa l ob oc">mean_value_right_split = house_prices %&gt;%<br/>  filter(area &gt;= 68) %&gt;%<br/>  summarize(mean_price = mean(price))</span><span id="22e8" class="ny mx it nu b gy od oa l ob oc">(<br/>  house_price_plot <br/>  + <br/>    geom_vline(xintercept=68, color = "red")<br/>  + <br/>    geom_segment(aes(x=68, xend=100, y=mean_value_right_split[[1]], yend=mean_value_right_split[[1]], color='orange'))<br/>  +<br/>    theme(legend.position="none")<br/>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/db8c1e31a8b87df78973149d7c8b104d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*5NfsHh4wJ7xLv938E7YjrA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">超过68平方英尺的房屋的房价数据集与平均预测。—作者图片</p></figure><p id="b13a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你知道什么最酷吗？这实际上可以转化为一个真实的决策树！</p><p id="fc71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我用根-分支格式来显示我们的分离，而不是用二维图来显示呢？(为了模仿R绘制决策树的方式，我将绘制一个颠倒的决策树)</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi on"><img src="../Images/c5d9ecfcac2efb88328164e5669c1339.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*pWvMbsma7ZdnU8z8r78kcw.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">第一次拆分的树形格式，区域&lt; 68 — Image by Author</p></figure><p id="0990" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">This is our decision tree with a <strong class="kw iu">单次拆分</strong>！</p><p id="6411" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">虽然单个分裂树总是无法构建一个好的模型</strong>(除非你在目标和特征之间有一个完美的阶梯形状关系，这在现实世界的数据集上是不寻常的)，我们肯定需要在我们的数据集上进行更多的分裂。</p><p id="cc43" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">即便如此，我们也要从某个地方开始！<strong class="kw iu">我们应该如何选择第一个分割来开始我们的树？</strong></p><p id="60c4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们回到房子1的例子，在这里我们看到了房子的预测价格和实际价值之间的差异:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/8aa8297f8e70dcd9e3e08ca4d40263e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*OBFv_2JbpDG4NlerVqKQQA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价数据集与第一套房子的平均预测误差-图片由作者提供</p></figure><p id="a201" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">每个点将产生一条黑线</strong>——这条线代表该特定示例的<em class="lq">误差(又名残差)</em>。</p><p id="6f7a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">如果我们将模型生成的所有“黑线”相加，我们将得到一个误差指标</strong>——从视觉上看，我们希望我们的黑线尽可能小。如果发生这种情况，您的点接近预测值(水平红线)。</p><p id="4c27" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们在<code class="fe oe of og nu b">house_prices</code>数据框架中计算每个具体示例的误差，假设我们使用上面的分割:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="f2c2" class="ny mx it nu b gy nz oa l ob oc">house_prices['predicted_price'] &lt;- ifelse(<br/>  house_prices['area'] &lt; 68,<br/>  115844,<br/>  136215<br/>)</span><span id="cad5" class="ny mx it nu b gy od oa l ob oc"># Calculate Error<br/>house_prices['error'] &lt;- (<br/>  house_prices['price']-house_prices['predicted_price']<br/>)</span></pre><p id="2795" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">看看我们的<code class="fe oe of og nu b">house_prices</code>数据框架:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/004ed9069ed8fa3affcedce075cd2e16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*WokyGU98171ul3OJPH5E4g.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">房价与误差栏-作者图片</p></figure><p id="8b9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><code class="fe oe of og nu b">error</code>列表示我们的预测<code class="fe oe of og nu b">predicted_price</code>和房子的<code class="fe oe of og nu b">price</code>之间的差异。由于有些误差是负的，有些是正的，我们需要将误差转换成可比较的东西。一些常见的策略包括获得误差的绝对值或平方值——为了便于解释，我们将使用绝对值:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="a525" class="ny mx it nu b gy nz oa l ob oc">house_prices['error'] &lt;- (<br/>  abs(house_prices['error'])<br/>)</span></pre><p id="f5ec" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这样，我们就可以产生一个理想的度量标准来理解我们模型的质量，即平均误差:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="03d6" class="ny mx it nu b gy nz oa l ob oc">mean(house_prices['error'][[1]])</span></pre><p id="f479" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">目前，我们还差6428 € </strong>左右的房价。我们可以把这个值和分割<code class="fe oe of og nu b">area &lt; 68 or area &gt;= 68</code>联系起来。</p><p id="9191" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">如果我们可以将误差指标与分割相关联，我们现在能做什么？我们可以找到使这个平均误差最小的分裂！</strong></p><p id="f719" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这正是决策树在选择第一次拆分时的机制——接下来让我们看看如何优化我们的第一次拆分。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="5914" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">回归树是如何工作的？—优化第一次分割</h1><p id="cc7e" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">让我们想象一下，我们遍历了<code class="fe oe of og nu b">area</code>变量上的每一个可能的分裂，并具体检查了那个分裂的平均误差。请记住，对于每个不同的分割值，我们预测的是我们构建的红线每一侧的<code class="fe oe of og nu b">price</code>的平均值，例如，50上的分割看起来像这样:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="5c18" class="ny mx it nu b gy nz oa l ob oc">obtain_split_plot &lt;- function(base_plot, split_value) {<br/>  <br/>  mean_value_right_split = house_prices %&gt;%<br/>    filter(area &gt;= split_value) %&gt;%<br/>    summarize(mean_price = mean(price))<br/>  <br/>  mean_value_left_split = house_prices %&gt;%<br/>    filter(area &lt; split_value) %&gt;%<br/>    summarize(mean_price = mean(price))<br/>  <br/>  print(mean_value_left_split)<br/>  print(mean_value_right_split)<br/>  <br/>  (<br/>    base_plot <br/>    + <br/>      geom_vline(xintercept=split_value, color = "red")<br/>    + <br/>      geom_segment(aes(x=30, xend=split_value, y=mean_value_left_split[[1]], yend=mean_value_left_split[[1]]), linetype ='dashed')<br/>    + <br/>      geom_segment(aes(x=split_value, xend=90, y=mean_value_right_split[[1]], yend=mean_value_right_split[[1]]), linetype ='dashed')    +<br/>      theme(legend.position="none")<br/>  )<br/>  <br/>}</span><span id="6235" class="ny mx it nu b gy od oa l ob oc">obtain_split_plot(house_price_plot, 50)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/5b24b1951a4b42f36655e325ad16205f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*S75WNDIC3MVm_0gmezItgg.png"/></div></figure><p id="8171" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">虚线表示左右两侧的预测。如果我们将其转换为树形格式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi op"><img src="../Images/e6a9c4e4313aa2b79d22eacd28d8ec8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*7Yyq0rhpkgJV3kVhnJfg5w.png"/></div></figure><p id="e7f6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">任何不同的分割都会产生不同的误差值。一个想法是绘制每个可能分割的平均误差——让我们使用R函数:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="8083" class="ny mx it nu b gy nz oa l ob oc">produce_error_split &lt;- function(house_data) {<br/>  <br/>  min_area &lt;- min(house_data$area)+1<br/>  max_area &lt;- max(house_data$area)-1<br/>  <br/>  vector_areas &lt;- seq(min_area, max_area)<br/>  <br/>  error_summary &lt;- data.frame(<br/>    split = vector_areas<br/>  )<br/>  <br/>  error_values &lt;- c()<br/>  <br/>  for (split_value in vector_areas) {<br/>    <br/>    mean_value_right_split = house_data %&gt;%<br/>      filter(area &gt;= split_value) %&gt;%<br/>      summarize(mean_price = mean(price))<br/>    <br/>    mean_value_left_split = house_data %&gt;%<br/>      filter(area &lt; split_value) %&gt;%<br/>      summarize(mean_price = mean(price))<br/>    <br/>    predicted_price &lt;- ifelse(<br/>      house_data$area &lt; split_value,<br/>      mean_value_left_split[[1]],<br/>      mean_value_right_split[[1]]<br/>    )</span><span id="bc3e" class="ny mx it nu b gy od oa l ob oc">error &lt;- abs(<br/>      house_data['price']-predicted_price<br/>    )<br/>    <br/>    error_values &lt;- c(error_values, mean(error[[1]]))<br/>  }<br/>  <br/>  error_summary$mean_absolute_error &lt;- error_values<br/>  <br/>  return (error_summary)<br/>}</span><span id="5235" class="ny mx it nu b gy od oa l ob oc">error_summary &lt;- produce_error_split(house_prices)</span></pre><p id="387c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上面的函数为我们的<code class="fe oe of og nu b">area</code>的每次分割产生<strong class="kw iu">平均绝对误差。这将产生类似于“成本函数”的东西:</strong></p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="5439" class="ny mx it nu b gy nz oa l ob oc">ggplot(<br/>  data = error_summary,<br/>  aes(x = split, y = mean_absolute_error)<br/>) + geom_line()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/22fb82189afea2b3257b78bdeecdd480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*-J90SzSTeeNHgYiFs0qeVA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">每次分割的平均绝对误差—按作者分类的图像</p></figure><p id="94ff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那有多酷？由于我们与目标具有“几乎”线性关系，因此成本函数将近似于由线性回归产生的函数。根据上面的图，产生最小误差的分割是什么？</p><p id="3c6b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">55到59之间的区域！如果我们以二维和树形格式查看其中一个拆分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/136b62a09e2c2379be4ab26a07c4468e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*dsZV3j4Go566765rQkaBkw.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">最佳首次分割-2D格式-作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/fc70dd546c7cc5b50003ac6efcd423b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*-p9hg6Lo9PUOBe-Q1Xkl8Q.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">最佳第一分割树格式—作者图片</p></figure><p id="e11d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们已经解决了我们的第一次分裂，因为这是一个最小化我们的错误。</p><p id="eeb2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是，谁说我们需要在一次拆分中停止呢？</p><p id="02f2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><em class="lq">技术说明:虽然我将误差显示为最小化问题(最小化绝对误差)，但rpart通过每次分割使增益最大化，这与我上面显示的图相反。不会改变我们所看到的一切背后的推理，但你知道这一点以避免混淆是很酷的。</em></p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="f239" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">回归树是如何工作的？—进一步分裂我们的树</h1><p id="f715" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">现在我们已经有了第一次分裂，如果我们开始进一步分裂我们的每一方呢？例如，让我放大我们的数据集—仅子集化大于或等于57平方英尺的区域。英尺:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="182a" class="ny mx it nu b gy nz oa l ob oc">right_split &lt;- house_prices %&gt;% filter(area &gt;= 57)</span><span id="aa7b" class="ny mx it nu b gy od oa l ob oc"># Right Split</span><span id="61fc" class="ny mx it nu b gy od oa l ob oc">house_price_plot_right_split &lt;- ggplot(<br/>  data = right_split,<br/>  aes(x = area, y = price)<br/>) + geom_point()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/b5c9c2cd410b538ea3a3acaa9eee133d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*BwvXtnGxVA2vd95I_5pZmw.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">超过57平方米的房子。制成—作者图片</p></figure><p id="93a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在正致力于我们拆分的右侧:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/c0dbca0b3287908a3983d61d42792eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*XR5AlupVjD1GOomahiUhHQ.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">决策树，第一次拆分-作者图片</p></figure><p id="3d70" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们对这个数据子集进行同样的推理，试图找到最佳分割，使我们的平均值和每个点之间的误差最小化，会怎么样？</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="4905" class="ny mx it nu b gy nz oa l ob oc">error_summary_right_split &lt;- produce_error_split(right_split)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d766b47518aa5d9354912b2bb45746eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*cFM6pDjbdcvDrvLRrlPAPw.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">树的右分支每次分割的平均绝对误差-作者图片</p></figure><p id="89c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于树的这个分支，当我们再次在88和89 sq之间分割数据时，我们的误差最小。制成在二维格式中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/38db278c1f4e0ec8fcd2159634c09648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*okFLvUbph_qwkfysyCM6Yg.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">新的分类，树的右侧分割-按作者分类的图片</p></figure><p id="df13" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">但是，不要忘记这个拆分已经依赖于一个过去的拆分了！</strong>用树形格式，这就容易理解多了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/fa72f01846510d1d75f2a8b97072a214.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*8_rWap4uXJD5tchOJe9VcA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">新分类，整个决策树—按作者分类的图片</p></figure><p id="506d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们的决策树开始看起来像一个真正的算法！我们现在有三条路可走:</p><ul class=""><li id="5186" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">如果房子的面积小于57平方米。制成，我们说它的价格是115.844 €。</li><li id="5156" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">如果房子的面积大于或等于57平方英尺小于88平方英尺，我们说它的价格是131.226 €。</li><li id="4db2" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">如果房子的面积超过88平方米。制成，我们说它的价格是145.110 €。</li></ul><p id="8efe" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当然，我们也可以将相同的推理应用于左边的分支——首先检查哪里是最佳的分割:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/05e8b03c9c3bf81a1ac61ca312cbe384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*XDYCY_0yPYmneKjrxhHAGg.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">树的左分支的每次分割的平均绝对误差-作者图片</p></figure><p id="e4bc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">根据我们的“成本函数”,对于左边的分支，我们应该为新的分割选择一个介于47和50之间的值——让我们检查一下我们的新树:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/42903785d4765a39a567b4d1c220ea11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*6fTpfWCGHo1bN2OSe8E2pA.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated">新的分类，两个分支都扩展了——图片由作者提供</p></figure><p id="b00f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可以进一步对数据进行分区(现在你知道递归分区名称的来源了！).我们可以保持这一点，直到我们在一个树节点中有一个单独的例子——这有一些主要的后果，比如巨大的过度拟合。</p><p id="6b0a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那么，我们怎样才能避免那棵树下降得太深呢？是否有办法控制这种情况？是啊！用超参数！</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="d4b4" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">检查一些超参数</h1><p id="e6ee" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">由于这篇文章已经有点长了，我将避免过多地详述超参数。但是检查我的<a class="ae ma" rel="noopener" target="_blank" href="/5-decision-tree-hyperparameters-to-enhance-your-tree-algorithms-aee2cebe92c8">其他帖子</a>来更好地了解他们。</p><p id="b174" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">超参数是基于树的模型的关键——正如我们已经看到的，我们的树可以<strong class="kw iu">下降，直到单个示例属于单个节点。</strong></p><p id="f322" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了控制将导致非常糟糕(高方差)模型的行为，超参数来了。由于树确实容易过度拟合，我们有一些超参数来控制训练过程——下面是其中一些超参数的简短描述:</p><ul class=""><li id="8d64" class="mb mc it kw b kx ky la lb ld md lh me ll mf lp mg mh mi mj bi translated">maxdepth此参数给出树的最大深度(层数)。在上面的例子中，我们下降了两级。</li><li id="3e03" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">minsplit为了尝试分割，结点中必须存在的最小观测值数量。</li><li id="fe07" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">minbucket任何末端叶节点中的最小观测值。</li><li id="b018" class="mb mc it kw b kx mk la ml ld mm lh mn ll mo lp mg mh mi mj bi translated">CP——或复杂度参数——节点为了有效而必须贡献的最小误差增益。基本上，不会执行稍微提高树的整体准确性的分割，并且分区在此停止。</li></ul><p id="1843" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在fit中，您可以控制更多的超参数——您可以使用<code class="fe oe of og nu b">?rpart.control</code>来检查它们。用它们做实验会让你很好的理解你的树是如何随着不同的值而变化的。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="045a" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">视觉化我们的契合度</h1><p id="5147" class="pw-post-body-paragraph ku kv it kw b kx no ju kz la np jx lc ld nq lf lg lh nr lj lk ll ns ln lo lp im bi translated">最后，为了证明我们遵循了<code class="fe oe of og nu b">rpart</code>所遵循的实现，让我们回到我们在本文开始时所拟合的树:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="c59f" class="ny mx it nu b gy nz oa l ob oc">d.tree &lt;- rpart(price ~ area,<br/>             data = house_prices, method = 'anova',<br/>             control = list(maxdepth=5,<br/>                            minsplit=2, minbucket=2,<br/>                            cp = 0.0001))</span></pre><p id="3589" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们使用<code class="fe oe of og nu b">rpart.plot</code>来绘制它，并专注于前两个级别:</p><pre class="kj kk kl km gt nt nu nv nw aw nx bi"><span id="b0a4" class="ny mx it nu b gy nz oa l ob oc">rpart.plot(d.tree)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d5e1c33d04af4c124b624799de2a3ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*_k-JlRjeNjqZvdL0FhE6lw.png"/></div></figure><p id="ebdf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">前两个级别与我们在使用“成本函数”规则之前构建的非常相似！</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><p id="c268" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">尽管很强大，决策树也很容易过度适应<strong class="kw iu">。如果您决定基于少数几个示例(例如，只有1或2个观察值)进行预测，您将最终得到一个不能很好地推广到测试集的模型。</strong></p><p id="dbd2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这篇文章中，我们没有遵循训练-测试分离范式，但如果你在实验中这样做，你会看到决策树在看不见的数据上的表现有多差，只需要对超参数做一点小小的调整。</p><p id="694e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，它们确实是很酷的模型，是任何数据科学家或机器学习工程师的必备知识。如今，您不太可能为您将面临的大多数问题部署决策树，但了解它们是投入到研究更高级的模型(如随机森林或极端梯度推进)的50%的工作！</p><p id="3ef0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">感谢你花时间阅读这篇文章！最后一点，我已经在 <a class="ae ma" href="https://www.udemy.com/course/r-for-data-science-first-step-data-scientist/?referralCode=MEDIUMREADERS" rel="noopener ugc nofollow" target="_blank"> <strong class="kw iu"> Udemy </strong> </a> <strong class="kw iu">上开设了一门<strong class="kw iu">课程，从头开始学习数据科学概念——使用前面的链接或下面的链接加入并立即开始学习数据科学！</strong></strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/783d68346bef933adae1ff35cc175d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/0*5Gs6ECyef9bYO4R7.png"/></div><p class="oi oj gj gh gi ok ol bd b be z dk translated"><a class="ae ma" href="https://www.udemy.com/course/r-for-data-science-first-step-data-scientist/?referralCode=MEDIUMREADERS" rel="noopener ugc nofollow" target="_blank">数据科学训练营课程</a></p></figure><div class="ov ow gp gr ox oy"><a href="https://medium.com/membership/@ivopbernardo" rel="noopener follow" target="_blank"><div class="oz ab fo"><div class="pa ab pb cl cj pc"><h2 class="bd iu gy z fp pd fr fs pe fu fw is bi translated">通过我的推荐链接加入Medium-Ivo Bernardo</h2><div class="pf l"><h3 class="bd b gy z fp pd fr fs pe fu fw dk translated">阅读我在Medium上的所有故事，了解更多关于数据科学和分析的信息。加入中级会员，您将…</h3></div><div class="pg l"><p class="bd b dl z fp pd fr fs pe fu fw dk translated">medium.com</p></div></div><div class="ph l"><div class="pi l pj pk pl ph pm ks oy"/></div></div></a></div></div></div>    
</body>
</html>