<html>
<head>
<title>Semantic Similarity Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语义相似网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semantic-similarity-networks-9aca31082d8e#2022-09-23">https://towardsdatascience.com/semantic-similarity-networks-9aca31082d8e#2022-09-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7ddf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从文档的关联性中挖掘知识</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c21e1756b63201a9ba0c660e4cb7b296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*vQqY4yeSuoGUtn0pjbdDQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从稳定扩散生成的图像</p></figure><p id="1711" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">文字是最简洁、最普遍的信息交流方式。它可以说是我们物理世界最有用的代表。毫不奇怪，许多人工智能(包括当前的大量创新)依赖于自然语言理解(通过提示)。为了让机器能够理解语言，文本需要精确的数字表示，这在过去十年中已经发生了革命性的变化。从一个相对较小规模的语料库的热表示到静态单词嵌入，再到来自巨大互联网规模的虚拟数据的子标记的向量表示(通过注意机制)，这种变化是我们目前参与的人工智能革命的最重要的变化之一。</p><p id="b46c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">前面提到的在文本表示方面的创新使得能够将文本文档存储为向量，在这些向量上可以应用数学运算来探索和利用它们的相互关联性。例如，向量搜索引擎使用余弦相似度来搜索与查询最相关的文档。仅相似性就驱动了许多有用的应用，包括搜索、信息检索和推荐。然而，文本的向量相似性的使用在网络分析中仍然没有得到充分的讨论。</p><p id="631b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">审查现有工作</strong></p><p id="ab2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">大多数以前关于语义网络的工作将单词作为分析单位，而不是整个文档。在社会科学的语义网络分析中，Elad Segev写道，</p><p id="ba75" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">“语义网络分析更多的是一种无监督的方法。它类似于主题建模，但它不是根据常用词对文档进行分类，而是根据单词的邻近性或共现性对文档中的单词进行分类。在这种情况下，输入是一个文本，输出是一个单词网络，根据它们的接近程度进行聚类。语义网络分析被认为是一种无监督的方法，因为不需要事先定义类别，并且根据单词在文本中的共现情况自动将单词分类。”</em></p><p id="0235" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该领域的其他一些工作包括“主题模型的网络方法”(Tiago，Eduardo和Altmann)，详细描述了主题模型和社区检测(用于网络分析)之间的交叉受精。(本文更接近于这里所描述的，但是使用了完全不同的方法，其中“<em class="lr">”节点由文档和单词组成，并且它们之间的边的强度由单词在文档中出现的次数给出，产生了等同于在主题模型中使用的单词-文档矩阵的二分多图。</em>”)。</p><p id="138b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相似性网络本身并不是一个新颖的想法。在《Python中的复杂网络分析》一书中，Dmitry Zinoviev详细介绍了这个主题，其中节点的相似性度量用于形成图中的边。本文讨论了我们感兴趣的项目(也称为网络节点，可以是内容网站上的推荐文章、文献调查的研究论文或电子商务网站上的产品(通过其产品描述))的文本表示的类似方法，以及它们之间仅通过其基础文本描述的向量表示的相互连接。</p><p id="9afb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种方法不同于传统的文本聚类，传统的文本聚类丢失了与较大文档空间的互连性信息。在网络分析中，这些信息通过节点之间的连接来保存。</p><p id="415d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">应用程序</strong></p><p id="c5f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种方法的一些潜在应用包括:</p><ul class=""><li id="f0c8" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">检测整个文档空间中的<strong class="kx ir">空白</strong>—例如，假设有一个关于给定主题的研究论文集合，并且您想要探索尚未得到充分研究的想法。您可以查看网络，以确定在各个集群中等级不高的节点。这些外围节点可以让你接触到文献中潜在的空白。</li><li id="aea6" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">识别与连接两个概念的<strong class="kx ir">不可或缺的文档</strong>——比方说，通过语义节点上的社区检测，您已经能够识别代表某些类别或概念的集群。通过查看感兴趣的两个集群之间的互连，您可以选择在这两个集群之间具有最大边的节点(文档),这些节点可以作为“桥”概念的潜在候选。(这在文献调查中特别有用，在文献调查中，网络的使用通常仅限于将参考文献的数量视为边。某些论文可能会获得更多与论文内容不完全相关的参考文献(参见“Huber，Juergen and M. Inoua，Sabiou and Kerschbamer，Rudolf and knig-Kersting，Christian and Palan，Stefan and Smith，Vernon L .，Nobel and Novice:作者突出影响同行评议”(2022年8月16日)。)</li><li id="c63f" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">排除<strong class="kx ir">建议中的冷启动问题</strong> —建议通常需要用户参与数据，而这些数据在您开始时是不可用的。此外，仅根据相似性提供推荐可能会导致意想不到的后果。(例如，参见艾利森·j·b·邱晨等人的《推荐系统中的算法混淆如何增加同质性并降低效用》(2017)。为了给你的推荐增加多样性，可以使用语义相似度网络。假设用户点击了某篇文章。从网络上，可以使用以下伪代码:</li></ul><ol class=""><li id="68e0" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq mg ly lz ma bi translated">确定节点(文档)所连接的集群集C。</li><li id="c2b1" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mg ly lz ma bi translated">使用度的百分比阈值来过滤出最相关的聚类(C_filtered)[示例:该节点通过4条边连接到聚类号1(它是该聚类的一部分)，3条边连接到聚类2，2条边连接到聚类3，1条边连接到聚类4，选择90%的阈值，并且10条边(度)中的9条被聚类1、2、3占据，这些聚类成为C _ filtered的一部分。</li><li id="24bb" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mg ly lz ma bi translated">从最相似的节点(可能是任何聚类的节点的感兴趣节点的连接边)提供预定数量的推荐。</li><li id="5e93" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mg ly lz ma bi translated">对于剩余的推荐，从C_filtered中选择与感兴趣的节点的集群具有大量边但不与之连接的节点。设这个集合为s。</li><li id="7e09" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq mg ly lz ma bi translated">为了从S中挑选出前k个节点，可以使用最大边际相关性来识别彼此不同但与我们感兴趣的节点所属的集群语义相关的节点。</li></ol><p id="dde4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">主要挑战</strong>:</p><p id="13c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用语义相似性网络的主要挑战详述如下:</p><ul class=""><li id="06dd" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">适应领域的高质量文档嵌入</li><li id="99ef" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">为边缘的形成选择合适的相似性阈值</li><li id="64d0" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">选择适合相似网络的社区发现算法</li></ul><p id="56b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第三个需要实验。我用传统的社区检测算法如贪婪模块性得到的结果不如用欧几里德距离的凝聚聚类得到的结果好。这些聚类用于计算平均距离分数，该平均距离分数被进一步平均以计算网络边的单个阈值。(这个阈值可以认为是一个超参数。)调整阈值将改变网络的稀疏性。</p><p id="7f94" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">至于文档嵌入，这是一个快速发展的领域，并且正在对最精确的领域适应嵌入进行积极的研究。对于我的实验(详见下文)，我使用了一组研究论文，其中最相关的预训练转换器是“allenai/specter”，其嵌入确实给出了不错的结果。我的另一个适用于域适配嵌入的方法是Reimers等人的基于变压器的顺序去噪自动编码器。该架构在解码器之前引入了一个瓶颈，从而提供了精确的文档嵌入(与单词嵌入相反)。这可以在未标记的数据集上训练，随后在标记的数据集上训练(优选地与感兴趣的领域相关)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/cad5fd80730f4be1abe7a37b16cc91c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*i4hPWILjJBEqgW4hQ3HE4w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用TSDAE进行域适配(来源:【www.sbert.net】T2，Apache 2.0)</p></figure><p id="8a6c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">实验:</strong></p><p id="02a6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">cs类别的数据集。arxiv上的CL是2018年、2019年和2020年拍摄的。(这些年来，在使用自我注意力来训练大型语言模型之后，自然语言处理也出现了显著的增长。)如前所述，文档嵌入是从‘allenai/specter’模型获得的，没有任何微调。这些嵌入被输入到sklearn的凝聚聚类中，随后获得101个聚类。(下面给出代码。)</p><p id="813e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">已查询群集。例如，第3组有一些下列文件:</p><ul class=""><li id="9964" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">一个新的用于从代码混合对话中进行自然语言推理的数据集</li><li id="366e" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">夫妻治疗中言语行为的人际影响建模</li><li id="4ccc" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">用于行为编码的多标签多任务深度学习</li><li id="1a85" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">用于交互式语言学习的监督种子迭代学习</li><li id="8c8e" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">重复参照游戏中学习的动态特征</li><li id="8973" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">使用言语和语言预测癌症患者和配偶互动中的行为</li><li id="2ba6" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">Alquist 3.0:使用对话知识图的Alexa奖励机器人</li><li id="4ee3" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">南非低资源语言中半正式患者交流中语码混合的普遍性</li></ul><p id="579b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样，第10组有一些下列文件。</p><ul class=""><li id="a4ae" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">一套盔甲能导电吗？一种新的开卷问答数据集</li><li id="117b" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">相似问题检索中语义表示和树搜索的再探讨</li><li id="f8d2" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">基于匹配的格子细胞神经网络中文问答系统</li><li id="b3be" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">RuBQ:一个用于维基数据问答的俄罗斯数据集</li><li id="efa3" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">Quizbowl:增量问答的案例</li><li id="7769" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">F1不够！以用户为中心的可解释问答模型及其评价</li><li id="b4af" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">生成适当问答对的元序列学习</li><li id="f133" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">主观问题回答:解读主观领域中变形金刚的内部运作</li><li id="aa00" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">问答系统中自然语言问题解释的定量评估</li></ul><p id="bb49" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">粗略地看一下，我们就知道集群3是关于会话式NLP和对话系统的，集群10是关于问题回答的。为了找到聚类3中的外围论文，查询该图并获得以下结果:</p><ul class=""><li id="c39c" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">作为人际多模态范畴化的符号涌现</li><li id="814e" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">南非低资源语言中半正式患者交流中语码混合的普遍性</li><li id="c78e" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">使用健康行为改变的跨理论模型的体重管理聊天的对话注释方案</li><li id="b548" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">帮助还是伤害？通过在线社区互动预测用户自残风险的变化</li><li id="eebd" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">在帖子标题中表达的社会支持会在在线药物使用康复论坛中引发评论吗？</li></ul><p id="d273" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些看起来像利基专业话题。为了找到“桥论文”(在集群3和10之间)，再次查询图网络，并且获得以下结果。</p><ul class=""><li id="ae33" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">将问答数据集转换为自然语言推理\n数据集</li></ul><p id="2c86" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果与预期一致，因为论文谈到了将问答对转换成声明形式。</p><p id="ec90" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(RecSys的实验会单独分享。)</p><p id="a0cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">语义相似性网络确实提供了一种不同的分析和查询数据集的方式。用进一步的实验来探索这一点会很有趣。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/f91c00075656fec35532fa95311937dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wqMJ-7mVHqqcdoJgbPeYAQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:自然语言处理论文的语义相似度网络</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mk ml l"/></div></figure></div></div>    
</body>
</html>