<html>
<head>
<title>Understanding Outliers in Text Data with Transformers, cleanlab, and Topic Modeling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Transformers、cleanlab和主题建模了解文本数据中的异常值</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-outliers-in-text-data-with-transformers-cleanlab-and-topic-modeling-db3585415a19#2022-10-06">https://towardsdatascience.com/understanding-outliers-in-text-data-with-transformers-cleanlab-and-topic-modeling-db3585415a19#2022-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8e18" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用于审计文本数据集的开源python工作流</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/468931a86d3dfae613a75592942ceb1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IJLjbambZjT4fvDX.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自<a class="ae kv" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae kv" href="https://pixabay.com/users/luboshouska-198496/" rel="noopener ugc nofollow" target="_blank"> LubosHouska </a>。</p></figure><p id="3765" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">许多文本语料库包含异构文档，其中一些可能是异常的，值得更多地理解。特别是对于已部署的ML系统，我们可能希望自动标记与它们的训练数据不来自同一发行版的测试文档，并理解这些新文档中出现的、训练数据中没有的主题。</p><p id="3d69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我最近作为一名ML工程师加入了<a class="ae kv" href="https://cleanlab.ai/" rel="noopener ugc nofollow" target="_blank"> Cleanlab </a>，并很高兴地分享我们的<a class="ae kv" href="https://github.com/cleanlab/cleanlab?utm_medium=tds" rel="noopener ugc nofollow" target="_blank">开源库</a>(在AGPL-v3许可下免费提供)可以在各种工作流中用于理解和改进数据集的许多方式。</p><p id="e72f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章演示了如何通过一个基于开源Python包的工作流来发现和分析大型NLP语料库中的异常文本:Transformers、cleanlab、pytorch、UMAP和BERTopic的c-TF-IDF实现。我们使用变压器来获得原始文本的良好表示，使用cleanlab来识别表示空间中的异常值，使用UMAP + c-TF-IDF来更好地理解这些异常。</p><p id="c3e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用抱脸中枢上的<a class="ae kv" href="https://huggingface.co/datasets/multi_nli" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> MultiNLI </strong>数据集，这是一个常用于训练语言理解模型的自然语言推理数据集。</a></p><ul class=""><li id="42fb" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">数据集包含多对句子(前提、假设)，这些句子已经被标记为前提是否需要假设(<code class="fe mb mc md me b">"entailment"</code>)或不需要假设(<code class="fe mb mc md me b">"contradiction"</code>)。中性标签也包括在内(<code class="fe mb mc md me b">"neutral"</code>)。</li><li id="cf27" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">语料库被分成单个训练集和两个验证集。</li><li id="87cd" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">训练集来源于5个不同的流派:<code class="fe mb mc md me b">[fiction, government, slate, telephone, travel]</code>。</li><li id="3adf" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated"><em class="mk">匹配验证集</em>来源于<em class="mk">匹配</em>训练集中的那些流派</li><li id="7474" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">另一个验证集，也称为<em class="mk">错配验证集</em>，来源于<em class="mk">训练数据中不存在的其他</em>流派:<code class="fe mb mc md me b">[nineeleven, facetoface, letters, oup, verbatim]</code>。</li><li id="af2f" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">更多关于语料库的信息可以在找到<a class="ae kv" href="https://cims.nyu.edu/~sbowman/multinli/" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><p id="39b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章中的步骤可以应用于你自己的单词/句子嵌入模型和任何包含多个文本来源的数据集。</p><h2 id="914d" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">太长；没有运行(代码)</h2><p id="f0d6" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">以下是我们从多个文本源中检测异常值并从中发现新主题的一般工作流程:</p><ul class=""><li id="649c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">从Hugging Face Hub加载并预处理文本数据集，以创建PyTorch数据集。</li><li id="b614" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">应用预先训练的句子嵌入模型从文本中创建向量嵌入。<br/>——这里我们利用了一个基于<a class="ae kv" href="https://huggingface.co/sentence-transformers" rel="noopener ugc nofollow" target="_blank"> SentenceTransformers </a>库中的连体神经网络的双编码器。</li><li id="31ec" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">使用<a class="ae kv" href="https://github.com/cleanlab/cleanlab?utm_medium=tds" rel="noopener ugc nofollow" target="_blank"> cleanlab </a>库查找训练数据中的异常文本。</li><li id="6ad8" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">在验证数据中查找非来自训练集中数据分布的异常值示例。<br/> —这类似于在新的数据源/提要中寻找异常。</li><li id="92d4" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">选择一个阈值，以决定是否将某个示例视为异常值。</li><li id="f05c" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">将所选的异常示例进行聚类，以找到异常的文本类型/来源。</li><li id="f604" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">识别异常类型/来源中的主题。</li></ul><p id="508a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的主要目标是在数据集中找到非分布的例子，更多地关注新的类型/领域/来源。在MultiNLI数据集的情况下，使用这些方法，以下4个示例中只有1个被认为是异常的。(你能猜到是哪个吗？)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/95217af28d5962e6248177b3b5674929.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4J2Z55XHxhrMCI7ueqvFqA.png"/></div></figure><p id="3801" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如所预料的那样，我们的方法识别出的最有可能的异常值来自不匹配的验证集中的流派。</p><p id="bf17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些离群值示例中的许多基于它们各自的类型形成聚类，这可用于发现数据中的非分布主题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/a7b2d8c426d3e16fbe30294e29752187.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WlLMNgPLHVmLEP1yv-cG5g.png"/></div></figure><h1 id="fc83" class="nk mm iq bd mn nl nm nn mq no np nq mt jw nr jx mw jz ns ka mz kc nt kd nc nu bi translated">让我们开始编码吧！</h1><p id="5e52" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">本文的剩余部分将展示我们如何用完全可运行的代码实现我们的策略！这里有一个笔记本的链接，你可以在那里运行相同的代码:<a class="ae kv" href="https://github.com/elisno/outlier_mnli/blob/main/outlier_mnli.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a></p><h2 id="fcf9" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">安装依赖项</h2><p id="e55c" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">您可以通过运行以下命令来安装所有必需的软件包:</p><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="ae7c" class="ml mm iq me b gy nz oa l ob oc">!pip install cleanlab datasets hdbscan matplotlib nltk sklearn torch tqdm transformers umap-learn</span></pre><p id="f306" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们将导入必要的包，将日志记录级别设置为“ERROR ”,并为可再现性设置一些RNG种子。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><h2 id="db27" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">预处理数据集</h2><p id="f183" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">MultiNLI数据集可以通过其<code class="fe mb mc md me b">datasets</code> api从Hugging Face Hub获取。我们执行的唯一预处理是从数据集中移除未使用的列/特征。注意，在这篇文章中，我们不是<em class="mk">而是</em>查看数据集中的蕴涵标签(<code class="fe mb mc md me b">label</code>)。更确切地说，我们只是简单地试图仅基于它们的文本来自动识别出非分布的例子。</p><p id="de94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了评估我们的离群点检测算法，我们认为来自不匹配验证集的所有例子都是分布外的例子。我们仍然会使用匹配的验证集来发现自然出现的异常例子。我们的算法也不需要类型信息，这仅用于评估目的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="4aa2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了对数据格式有所了解，我们将看看每个数据集中的几个例子。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="faae" class="ml mm iq me b gy nz oa l ob oc">Training data<br/>Genres: ['fiction' 'government' 'slate' 'telephone' 'travel']</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/88d2f2e3c59dbccd916d1b422b1fba8d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*V-O5bcx2n-4Dm6WMLGQXfw.png"/></div></figure><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="fe73" class="ml mm iq me b gy nz oa l ob oc">Validation matched data<br/>Genres: ['fiction' 'government' 'slate' 'telephone' 'travel']</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/8acd3aecd528000db685d1130295bdc0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*3svD8BmzCfbMSSLqdYEjpQ.png"/></div></figure><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="c7e3" class="ml mm iq me b gy nz oa l ob oc">Validation mismatched data<br/>Genres: ['facetoface' 'letters' 'nineeleven' 'oup' 'verbatim']</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/0417f1b49b761fe5359287879e68e889.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Y8QQBV35d3JDV0gEFg8-0Q.png"/></div></figure><h1 id="f129" class="nk mm iq bd mn nl nm nn mq no np nq mt jw nr jx mw jz ns ka mz kc nt kd nc nu bi translated">将NLI数据转换成矢量嵌入</h1><p id="040c" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">我们将使用预训练的SentenceTransformer模型在MultiNLI数据集中嵌入句子对。</p><p id="987a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从NLI数据(包括MultiNLI)训练句子编码器的一种方法是在如下所示的连体BERT网络上添加一个3路softmax分类器。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/e9f29c54567195b8fddc15e8063632a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*W2INtBxgikAvm181.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带有softmax分类器的连体网络。图片取自<a class="ae kv" href="https://www.sbert.net/examples/training/nli/README.html" rel="noopener ugc nofollow" target="_blank"> SBERT docs </a>。</p></figure><p id="04e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用这种网络的(u，v，| u — v |)层的输出作为每个句子对的单个向量嵌入。这比将句子对连接成单个字符串更可取，因为这将增加截断模型输入和丢失信息(特别是来自假设的信息)的风险。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="ac20" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下一步，您必须从Hugging Face Hub中选择一个预训练的tokenizer+模型，它将为网络的池化层提供令牌嵌入。</p><p id="025f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是通过在Hub上提供模型的名称来实现的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><h2 id="5faa" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">使用cleanlab查找数据集中的异常值</h2><p id="9fdc" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">我们可以用cleanlab的<code class="fe mb mc md me b">OutOfDistribution</code>类发现训练数据中的异常值。这将使最近邻估计器适合训练数据(在特征空间中),并基于每个示例与其<em class="mk"> K </em>最近邻的平均距离返回每个示例的异常值分数。</p><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="aa80" class="ml mm iq me b gy nz oa l ob oc"># Get outlier scores for each of the training data feature embeddings<br/>ood = OutOfDistribution()<br/>train_outlier_scores = ood.fit_score(features=train_embeddings)</span></pre><p id="2641" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以查看训练数据中最高的异常值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/b3d4d9092951fd72a09a0741f139b1ff.png" data-original-src="https://miro.medium.com/v2/format:webp/1*eGDvFi9Th6HBdE-mCoDHTA.png"/></div></figure><p id="c5ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们使用拟合的最近邻估计量来获得验证数据的异常值，包括匹配和不匹配的验证集。</p><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="e889" class="ml mm iq me b gy nz oa l ob oc"># Get outlier scores for each of the feature embeddings in the *combined* validation set<br/>test_feature_embeddings = np.concatenate([val_matched_embeddings, val_mismatched_embeddings], axis=0)<br/>test_outlier_scores = ood.score(features=test_feature_embeddings)</span></pre><p id="aeeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们看看验证数据中最大的异常值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/d3b4fe74f172e5a966935a8c8d5f0904.png" data-original-src="https://miro.medium.com/v2/format:webp/1*28igloS4h8EmUp77FUW7cw.png"/></div></figure><p id="7de0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管组合的确认集在匹配和不匹配的风格方面是平衡的，但是大多数具有高异常值分数的例子来自不匹配的确认集(<code class="fe mb mc md me b">[nineeleven, facetoface, letters, oup, verbatim]</code>)。</p><p id="73db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将此与另一端被认为不太可能是异常值的例子进行比较。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/ed42b5778ec0001446765d729e6b2181.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2hPW8YcNWllPix-CKrv0ug.png"/></div></figure><p id="ebcc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些例子仅来自匹配确认集中的5个流派中的4个(<code class="fe mb mc md me b">[fiction, government, telephone, travel]</code>)。唯一的例外是<code class="fe mb mc md me b">slate</code>类型，但是第一个例子出现在列表的更下方。</p><h2 id="26fa" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">评估异常值分数</h2><p id="a200" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">实际上，如果我们已经知道不匹配的数据集包含与训练集中不同的流派，我们可以分别对每个流派进行离群点检测。</p><ul class=""><li id="0ab4" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">即从<code class="fe mb mc md me b">nineeleven</code>检测异常句子对，然后从<code class="fe mb mc md me b">facetoface</code>检测异常句子对，等等。</li></ul><p id="b265" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了保持简洁，现在让我们考虑组合验证集中的异常例子。</p><p id="45c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以设置一个阈值来决定组合验证集中的哪些例子是异常值。我们将保守地使用训练数据中异常值分数分布的第2.5个百分点作为阈值。该阈值用于从组合验证集中选择样本作为异常值。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/c9f404e4f47b2c914ec4562b86c27406.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YFFI2qw35ET-UPyBKI1jrw.png"/></div></figure><p id="93ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这将导致一些误报，如下所示。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/a4ab1feabc83ce63c3ce254f37935fb8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4_phbE-12mzuhFdI9R47VA.png"/></div></figure><h2 id="015a" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">聚类异常值</h2><p id="1932" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">让我们假设我们不知道来自不匹配数据集的流派的内容。我们可以尝试从验证集中聚集离群值，看看我们是否能对不匹配的类型有更好的了解。</p><p id="2b11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据这一假设，使用基于密度的聚类算法(如HDBSCAN)是有意义的，它可以处理所选异常值示例中的噪声。不幸的是，它在高维数据上表现不佳。我们将使用UMAP来降低数据的维数。出于可视化的目的，我们将把维度降低到2维，但是如果您希望有一些重叠的集群，那么您可能会受益于稍微更高的维度。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/a7b2d8c426d3e16fbe30294e29752187.png" data-original-src="https://miro.medium.com/v2/format:webp/1*WlLMNgPLHVmLEP1yv-cG5g.png"/></div></figure><p id="c598" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速浏览一下，我们会发现不匹配的类型往往会聚集在一起。只有<code class="fe mb mc md me b">facetoface</code>与<code class="fe mb mc md me b">verbatim</code>和大部分匹配的流派重叠。我们最好的办法是寻找小的局部聚类，看看一个流派如何包含多个主题。我们必须设置一个相对较小的最小集群大小，并允许更多的本地化集群。这可以通过降低HDBSCAN算法中的<code class="fe mb mc md me b">min_cluster_size</code>和<code class="fe mb mc md me b">min_samples</code>参数来实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/9a0b8f31004b485e9b8e34d97b0db9d5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9QynG8aOYPjS-6kqoCMIGQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/bc8f49eb9fbbeee917aed9120cd6dcfa.png" data-original-src="https://miro.medium.com/v2/format:webp/1*lY6PwyKmrhlPi_0QA6aacA.png"/></div></figure><p id="1613" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于视觉检查，边缘上的聚类相对较纯，即每个聚类中的大多数点来自同一流派。</p><p id="c275" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">主要的例外是:</p><ul class=""><li id="e823" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">紫罗兰集群由3个流派组成。</li><li id="3eb6" class="ls lt iq ky b kz mf lc mg lf mh lj mi ln mj lr lx ly lz ma bi translated">中间的黄绿色簇中有多个重叠的流派。<br/> —这表明<code class="fe mb mc md me b">verbatim</code>是一个“分布中”的主题。这对于测试NLI模型是没有用的。<br/> —这在某些情况下可以删除。</li></ul><p id="eb98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数“纯粹的”<code class="fe mb mc md me b">verbatim</code>星团可能太小而没有洞察力，但是更大的<code class="fe mb mc md me b">nineeleven</code>和<code class="fe mb mc md me b">oup</code>星团是有希望的。</p><h1 id="61e5" class="nk mm iq bd mn nl nm nn mq no np nq mt jw nr jx mw jz ns ka mz kc nt kd nc nu bi translated">使用c-TF-IDF查找主题</h1><p id="276a" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">从密集的句子/文档嵌入群中提取主题的一个有用的方法是使用<a class="ae kv" href="https://maartengr.github.io/BERTopic/api/ctfidf.html" rel="noopener ugc nofollow" target="_blank"> c-TF-IDF </a>。James Briggs的一篇<a class="ae kv" href="https://www.pinecone.io/learn/bertopic/" rel="noopener ugc nofollow" target="_blank">好文章</a>为预计算嵌入和集群提供了c-TF-IDF的清晰实现。我们在下面重用了部分实现。为了简单起见，我们使用unigrams来提取主题。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="f5b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看每个聚类中c-TF-IDF得分最高的单词，应该会让我们对该聚类的主要主题有所了解。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><pre class="kg kh ki kj gt nv me nw nx aw ny bi"><span id="e786" class="ml mm iq me b gy nz oa l ob oc">Topic class 0: ['barrel', 'firearm', 'ramrod', 'patch', 'monkey', 'ball', 'wood']<br/>Topic class 1: ['prefer', 'perjinkety', 'nicety', 'perjinkity', 'duende', 'perjink', 'derivatives']<br/>Topic class 2: ['flamable', 'inflammable', 'trucks', 'onomatoplazia', 'substituted', 'delaney', 'examples']<br/>Topic class 3: ['industry', 'retailer', 'lean', 'bundle', 'inventory', 'production', 'marker']<br/>Topic class 4: ['muskrat', 'another', 'baby', 'version', 'muscat', 'lollipop', 'ramble']<br/>Topic class 5: ['mihdhar', 'moqed', 'khalid', 'majed', 'hanjour', 'hani', 'al']<br/>Topic class 6: ['abu', 'king', 'farouk', 'training', 'afghanistan', 'ubaidah', 'banshiri']<br/>Topic class 7: ['agreed', 'ladins', 'war', 'efforts', 'turabi', 'bin', 'ladin']<br/>Topic class 8: ['water', 'two', 'first', 'word', 'words', 'english', 'one']<br/>Topic class 9: ['hazmi', 'fighters', 'boston', 'center', 'aircraft', 'command', 'hijacking']<br/>Topic class 10: ['referred', 'tried', 'controller', 'york', 'united', 'crew', 'transponder']<br/>Topic class 11: ['turned', 'shootdown', 'center', 'information', 'neads', 'united', 'american']<br/>Outliers: ['cracker', 'atom', 'iupui', 'penney', 'american', 'bangers', 'controller']</span></pre><p id="9c75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用相关的主题可视化集群嵌入(左)。为了进行比较，我们将把相同的嵌入和它们的原始类型想象成标签(右)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="od oe l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl nj"><img src="../Images/977842294a9f1d53767edbf12503c20d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*BOGrkslR4eLm_IyPKir2aA.png"/></div></figure><p id="ffd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<code class="fe mb mc md me b">nineeleven</code>类型中，有几个主题很突出，一些是关于美国航班，另一些是关于中东领导人。在<code class="fe mb mc md me b">oup</code>类别中发现了一个主题，似乎是关于纺织品的。其余流派重叠太多，无法获得有意义的话题。处理重叠聚类的一种方式是专门在这些点上重复先前的聚类，例如，通过从分析中移除<code class="fe mb mc md me b">nineeleven</code>，并根据需要递归地重复该过程。</p><h2 id="0ac0" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">结论</h2><p id="faf1" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">这个分析演示了如何识别和理解文本数据中的异常值。所需的方法在开源Python库中都可用且易于使用，您应该能够将这里演示的相同代码应用于您自己的文本数据集。</p><p id="81b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关键的一点是用能给出高质量嵌入的模型对文本示例进行编码，并对这些嵌入应用离群点检测算法，以便为主题建模步骤只选择罕见/不寻常的示例。</p><p id="2cce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可能会对BERTopic 包感兴趣，它可以用于:通过BERT变换器嵌入文本，通过UMAP减少其维数，通过HDBSCAN进行聚类，通过c-TF-IDF识别每个聚类中的主题。</p><p id="6fc7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望识别和理解异常值有助于您在自己的应用程序中确保更高质量的数据和ML性能。您可以选择从您的数据集中忽略此类示例，或者扩展您的数据收集以更好地覆盖此类案例(如果它们看起来相关)。</p></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="1863" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除非另有说明，所有图片均为作者所有。</p><h2 id="5c7f" class="ml mm iq bd mn mo mp dn mq mr ms dp mt lf mu mv mw lj mx my mz ln na nb nc nd bi translated">参考</h2><p id="1676" class="pw-post-body-paragraph kw kx iq ky b kz ne jr lb lc nf ju le lf ng lh li lj nh ll lm ln ni lp lq lr ij bi translated">[1] A. Williams，N. Nangia和S. Bowman，<a class="ae kv" href="http://dx.doi.org/10.18653/v1/N18-1101" rel="noopener ugc nofollow" target="_blank">通过推理理解句子的大范围挑战语料库</a> (2018)，计算语言学协会北美分会2018年会议记录:人类语言技术，第1卷(长论文)，第1112-1122页，路易斯安那州新奥尔良。计算语言学协会。</p><p id="20ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] N. Reimers和I. Gurevych，<a class="ae kv" href="https://doi.org/10.48550/arXiv.1908.10084" rel="noopener ugc nofollow" target="_blank">句子-伯特:使用暹罗伯特网络的句子嵌入</a> (2019)，2019年自然语言处理经验方法会议录</p><p id="f6cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] C. Northcutt和J. Mueller，<a class="ae kv" href="https://cleanlab.ai/blog/cleanlab-v2.1" rel="noopener ugc nofollow" target="_blank"> cleanlab 2.1增加了多注释者分析和离群点检测:走向以数据为中心的人工智能的广泛框架</a> (2022)，cleanlab</p><p id="5def" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] J. Kuan和J. Mueller，<a class="ae kv" href="https://doi.org/10.48550/arXiv.2207.03061" rel="noopener ugc nofollow" target="_blank">回到基础:再访分布外检测基线</a> (2022)，ICML分布转移原理研讨会2022</p><p id="7987" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] J. Briggs，<a class="ae kv" href="https://www.pinecone.io/learn/bertopic/" rel="noopener ugc nofollow" target="_blank">高级主题建模与BERTopic </a> (2022)，松果</p><p id="205c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6] M. Grootendorst，<a class="ae kv" href="https://doi.org/10.48550/arXiv.2203.05794" rel="noopener ugc nofollow" target="_blank"> BERTopic:基于类的TF-IDF程序的神经主题建模</a> (2022)，arXiv预印本arXiv:2203.05794</p></div></div>    
</body>
</html>