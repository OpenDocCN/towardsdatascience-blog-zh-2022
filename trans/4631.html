<html>
<head>
<title>Getting Started with Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-apache-spark-cb703e1b3ee9#2022-10-14">https://towardsdatascience.com/getting-started-with-apache-spark-cb703e1b3ee9#2022-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2ee9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索与Spark相关的一些关键概念，以及是什么决定了它在大数据领域的成功</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6c930856302f747b8202ee00418cc066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t12C1zhnV1W4p-k2"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伊恩·施耐德在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="f962" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="f219" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">正如我们今天所知，互联网发展初期的一个主要问题是无法扩展(例如，能够在短时间内搜索大量数据，支持不断变化的用户数量而不停机，等等)。</p><p id="5ce8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这最终是因为在一个网络世界中，不断产生和处理各种形状和大小的新数据(关于<a class="ae ky" rel="noopener" target="_blank" href="/big-data-analysis-spark-and-hadoop-a11ba591c057">大数据分析的更多信息可在我之前的文章</a>中找到)。</p><p id="436f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">试图解决这个问题的第一个方法是<strong class="lt iu"> Apache Hadoop(高可用性分布式面向对象平台)</strong>。Hadoop是一个开源平台，旨在将数据作业分解为小块，并将它们作为作业分布在一个计算节点集群中，以便能够并行处理它们。Hadoop可以分为3个关键组件:</p><ul class=""><li id="754e" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><strong class="lt iu"> HDFS (Hadoop分布式文件系统)</strong>:为大数据支持和容错而设计的分布式文件系统。</li><li id="2ca5" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu"> MapReduce </strong>:一个框架，旨在促进集群中数据作业的并行化。在映射过程中，以键-值对的形式获取并处理输入，然后将输入传递给reduce操作，以便聚合输出并提供最终结果。</li><li id="e8b4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu"> YARN(又一个资源协商者)</strong>:管理集群的不同节点(例如调度作业、任务等)并平均分配工作负载。</li></ul><p id="62cf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">因此，使用Hadoop，可以通过水平扩展我们的基础设施(添加更多机器)和并行执行来处理大量数据。由于<a class="ae ky" href="https://en.wikipedia.org/wiki/Moore%27s_law" rel="noopener ugc nofollow" target="_blank">摩尔定律</a>的放缓以及全球范围内云存储成本的同步降低，水平扩展操作事实上已经成为大多数应用程序中事实上的标准方法。</p><p id="c4fa" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">另一方面，Hadoop也有许多限制:</p><ul class=""><li id="b0a0" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">没有完全设计为支持批处理以外的任务(例如流、机器学习等)</li><li id="c938" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">难以管理和优化。</li><li id="dee8" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">过于冗长的API需要大量样板代码。</li><li id="9d15" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">作为批处理过程的一部分，中间计算被写入，然后从磁盘读取(因此导致性能瓶颈)。</li></ul><p id="6d6c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了尝试解决所有这些限制，Apache Spark应运而生。</p><h1 id="07f7" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">阿帕奇火花</h1><p id="f5b0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Apache Spark始于2009年加州大学伯克利分校Matei Zaharia的一个研究项目，今天被公认为处理大量数据的最受欢迎的计算引擎之一(在某些工作中比Hadoop MapReduce快几个数量级)。Spark over Hadoop的一些关键改进包括:</p><ul class=""><li id="9915" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">一套支持不同类型工作流的库(如Spark ML、结构化流、Spark SQL、Graph X)。</li><li id="3498" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">高度容错和并行的生态系统。</li><li id="3032" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">多种编程语言的API(例如Scala、Java、Python、SQL、R)。独立于所使用的语言，程序被分解成字节码，并在集群的工人上执行。</li><li id="edcf" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">用于中间计算的内存存储。</li><li id="0a1f" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">专注于计算(例如，Hadoop同时包含计算和存储系统，而Spark几乎对任何存储选项都是开放的)。</li></ul><p id="5ec4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Spark应用程序可以分解成许多不同的组件(图1)。使用驱动程序来实例化Spark会话，并使用它来与集群的不同组件(例如，集群管理器和执行器)进行交互。作为程序执行的一部分，驱动程序负责向集群管理器请求必要的资源(例如内存、CPU)，以便让执行器(例如Java虚拟机)继续执行它们的任务，并直接与执行器通信以优化执行。Spark目前能够支持4种不同类型的集群管理器:standalone、Hadoop YARN、Apache Mesos和Kubernetes。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ng"><img src="../Images/96c605a924ff92f37b655fa4a8bfb915.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIbqNPFXU8590SXN-rqw3Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1: Apache Spark架构(图片由作者提供)。</p></figure><p id="694a" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在整个过程中，数据被存储为分区，并且执行者优选地被分配需要处理离他们最近的数据的任务(以最小化网络带宽)。</p><p id="59f9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Spark可以对数据执行两种操作:<strong class="lt iu">转换</strong>和<strong class="lt iu">动作</strong>。变换会创建一个新的Spark数据框，而不会改变原始数据框，并且总是被延迟评估(它们不会立即执行，而是作为沿袭的一部分被记住)。这使得创建转换的<strong class="lt iu">有向无环图(DAG) </strong>成为可能，然后可以利用Spark Catalyst optimizer基于规则和基于成本的优化，以最有效的方式运行。拥有一系列的转换和不可变的数据帧可以让Spark创建一个高度容错的系统。每当一个动作被调用时，转换最终被执行。</p><p id="dc00" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">变换还可以分为<strong class="lt iu">窄</strong>或<strong class="lt iu">宽</strong>。窄转换采用单个输入分区并返回单个输出分区(例如<em class="nh">过滤操作</em>)，而宽转换使用多个分区并要求数据的重新洗牌(例如<em class="nh">分组操作</em>)。</p><p id="0234" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在过去的几年里，为了让Spark更容易开发，在Spark API上开发了不同形式的结构。<strong class="lt iu">rdd(弹性分布式数据集)</strong>是Spark中最基本的抽象形式，如今主要被<strong class="lt iu"> Spark的结构化API(数据集、数据帧API)</strong>等效命令所取代。事实上，Spark结构化API完全构建在rdd之上，旨在为数据处理领域的大多数常见任务提供易于使用的预优化代码。此外，Spark还可以通过<strong class="lt iu">UDF(用户定义函数)</strong>创建自定义函数。Spark UDFs可以用不同的编程语言编写(例如Python、Java、Scala等)，尽管目前建议用Java或Scala编写UDF，因为它们可以提供更好的整体性能(例如UDF就像Catalyst Optimizer的黑盒，因此如果用Python编写，就无法完全优化)。</p><p id="e7e4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，Spark还使得使用Spark ML库运行机器学习工作流成为可能(图2)。该库可分为4个关键组成部分:</p><ul class=""><li id="71b6" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><strong class="lt iu">转换器</strong>:主要用于执行数据工程/预处理任务(如缩放、特征选择等)，它们只应用基于规则的转换(没有从数据中学习)。它们将一个数据帧作为输入，并返回一个新的数据帧。</li><li id="f0b4" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">估计器</strong>:从数据中学习参数，并返回一个训练好的ML模型(它是一个变换器)。</li><li id="8745" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">管道</strong>:在单个对象中组织一系列转换器和估算器。</li><li id="0cbd" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><strong class="lt iu">评估者</strong>:用于通过各种分类、回归等指标评估我们的机器学习模型。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/2976b36f309cd669f2380ef5c52d4330.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcLSm1wLXclfWWCfJCCtsg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2: Spark ML工作流程(图片由作者提供)。</p></figure><p id="3c0b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">此外，Spark ML可以与各种其他开源包集成，如Hyperopt、Horovod、MLFlow等，以提供完整的用户体验。</p><h1 id="e978" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="a396" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">总体而言，Apache Spark是目前业内用于处理大数据的最受欢迎的技术之一，由Databricks和Palantir等公司提供支持。由于最近生态系统的加入，Spark现在也变得越来越与传统数据科学用户相关(例如Spark 上的<a class="ae ky" href="https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html" rel="noopener ugc nofollow" target="_blank"> Pandas API)，使其成为最有趣的学习技术之一。</a></p><h1 id="8c80" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">联系人</h1><p id="811d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果你想了解我最新的文章和项目<a class="ae ky" href="https://pierpaoloippolito28.medium.com/subscribe" rel="noopener">，请通过媒体</a>关注我，并订阅我的<a class="ae ky" href="http://eepurl.com/gwO-Dr?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">邮件列表</a>。以下是我的一些联系人详细信息:</p><ul class=""><li id="e609" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated"><a class="ae ky" href="https://uk.linkedin.com/in/pier-paolo-ippolito-202917146?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="5647" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://pierpaolo28.github.io/?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">个人网站</a></li><li id="6f5f" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://towardsdatascience.com/@pierpaoloippolito28?source=post_page---------------------------" rel="noopener" target="_blank">中等轮廓</a></li><li id="a891" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://github.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li><li id="0fa5" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated"><a class="ae ky" href="https://www.kaggle.com/pierpaolo28?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li></ul></div></div>    
</body>
</html>