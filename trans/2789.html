<html>
<head>
<title>Build your own AI Voice Assistant to Control Your PC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立你自己的人工智能语音助手来控制你的电脑</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-own-ai-voice-assistant-to-control-your-pc-f4112a664db2#2022-06-16">https://towardsdatascience.com/build-your-own-ai-voice-assistant-to-control-your-pc-f4112a664db2#2022-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5882" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一个简单的指南，告诉你如何构建你自己的人工智能助手来控制你电脑上的各种动作</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c95d313a861bdaaaa2ce4a5be0428763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mHav5mZQsFVbp7G_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@agk42?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">亚历山大·奈特</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="d6af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，使用虚拟助手来控制你的周围环境正在成为一种常见的做法。我们利用谷歌人工智能、Siri、Alexa、Cortana和许多其他类似的虚拟助手，通过简单的语音或音频命令为我们完成任务。你可以要求他们播放音乐或打开一个特定的文件或任何其他类似的任务，他们会轻松地执行这些动作。</p><p id="b49e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这些设备很酷，但开发自己的人工智能语音自动化助理也很有趣，你可以利用它来控制你的桌面，只需借助你的声音。我们可以使用这样的人工智能与你聊天，打开视频，播放音乐，等等。</p><p id="8782" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将致力于开发一个人工智能助手的介绍性项目，你可以利用它来控制你的PC或任何其他类似的设备。我们将从介绍构建这个项目所需的一些基本依赖关系开始，并继续将其全部放入一个Python文件中，通过该文件构建AI语音助手来执行您的命令。</p><p id="0958" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在阅读这篇文章之前，如果你对我们从零开始构建东西的其他这样的酷项目感兴趣，我建议看看我以前的一个作品。下面提供了一个链接，您可以在这里用Python开发自己的天气应用程序指示器，只需不到十行代码。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/develop-your-weather-application-with-python-in-less-than-10-lines-6d092c6dcbc9"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">用Python开发不到10行的天气应用程序</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用Python构建我们的天气电视广播应用程序，以接收所需位置的更新</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="b941" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">基础知识入门:</h1><h2 id="a146" class="nm mv it bd mw nn no dn na np nq dp ne li nr ns ng lm nt nu ni lq nv nw nk nx bi translated">第1部分:桌面控件</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/f8fde52bba5d60c36cce4da286bf37d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qysVPerY6qpbPNBC"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/es/@benceboros?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">本斯·博罗斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="9333" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在文章的这一部分，我们将学习如何控制我们的电脑。我们将学习如何管理和处理物理屏幕上的一些基本操作。在PyAutoGUI的帮助下，我们可以执行这个项目所需的许多功能。这个自动化库工具允许用户以编程方式控制鼠标和键盘。</p><p id="dcf2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用一个简单的pip命令安装PyAutoGUI库来处理所有与光标、鼠标和键盘相关的任务，如下所示。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="8eb2" class="nm mv it oa b gy oe of l og oh">pip install PyAutoGUI</span></pre><p id="46c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从这个库中的一些基本命令开始，我们将需要这些命令来开发我们的语音辅助人工智能Python项目。几分钟后，安装应该在各自的环境中顺利完成。</p><p id="a22d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，让我们导入PyAutoGUI库，如下面的代码片段所示。下一个关键步骤是知道你的工作屏幕的分辨率。我们可以使用最近安装的库中可用的尺寸功能打印默认的屏幕尺寸和屏幕高度。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="0d23" class="nm mv it oa b gy oe of l og oh">import pyautogui</span><span id="1ddc" class="nm mv it oa b gy oi of l og oh"># Printing the default screen width and height<br/>screenWidth, screenHeight = pyautogui.size()</span><span id="3596" class="nm mv it oa b gy oi of l og oh">print(screenWidth, screenHeight)</span></pre><p id="b8d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong> 1920 1080</p><p id="89a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以注意到我的屏幕分辨率是1920 x 1080，这应该是大多数电脑的默认屏幕尺寸。但是，如果您的显示器屏幕分辨率较高或较低，您仍然可以轻松地跟随指南。这些命令可以互换使用，以在任何分辨率下获得所需的坐标。如果你的屏幕显示分辨率和我的不匹配，一定要相应地改变一些参数。</p><p id="4d9e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在本节中介绍的另一个基本命令是发现鼠标指针当前位置的命令。库的position()函数将定位鼠标指针所在的当前坐标。我们可以使用这些位置在您的桌面屏幕上定位文件夹和其他重要目录。下面是执行以下操作的代码片段。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="05bd" class="nm mv it oa b gy oe of l og oh"># Showing the current cursor position<br/>currentMouseX, currentMouseY = pyautogui.position() # Get the XY position of the mouse.<br/>print(currentMouseX, currentMouseY)</span></pre><p id="7eed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该库的另一个有趣的功能是，您可以使用下面提供的代码片段来定位当前工作屏幕上某些图像的位置以及相应的坐标。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="ab20" class="nm mv it oa b gy oe of l og oh"># Locating on the Screen by getting the co-ordinates<br/>x, y = pyautogui.locateCenterOnScreen("image.png")</span></pre><p id="3768" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将在本节中看到的最后一个基本命令是允许我们打开所需目录的函数。通过将光标放在左上角，我能够算出我的管理文件夹的坐标。我们可以使用moveTo()函数将光标移动到相应的位置，以及文件夹的相应位置。然后，我们可以使用click()命令，只需输入鼠标左键或右键的点击次数以及您想要的点击次数。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="8d52" class="nm mv it oa b gy oe of l og oh"># Open The Admin Directory<br/>pyautogui.moveTo(37, 35, 1)<br/>pyautogui.click(button='left', clicks=2)</span></pre><p id="a990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上面的代码片段，您应该能够打开admin文件夹，因为光标会自动移动到admin目录并双击它来打开它。如果您的屏幕左上角没有类似的图标，或者您有不同的屏幕分辨率，请随意尝试相应的位置和坐标。</p><h2 id="cb02" class="nm mv it bd mw nn no dn na np nq dp ne li nr ns ng lm nt nu ni lq nv nw nk nx bi translated">第2部分:语音命令控制</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/72cbc5c6345867772a9c9a48d0cb59e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tCQXrpgUg-Ghgjn-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@thomasble?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">托马斯·勒</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="69e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文的这一部分，我们将了解语音识别的一些基本要求，这是这个项目的第二个最核心的部分。我们将需要一个麦克风来通过声音传递我们的命令，并相应地解释信息。建议使用语音识别库，以及您选择的文本到语音转换器。还要确保您的工作环境中安装了PyAudio。</p><p id="49be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果观众对文本到语音转换不太熟悉，我强烈推荐查看我以前的一篇文章，其中我用Python介绍了Google文本到语音转换，并提供了初学者代码来帮助您入门。下面提供了相同内容的链接。</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/how-to-get-started-with-google-text-to-speech-using-python-485e43d1d544"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">如何使用Python开始使用Google文本到语音转换</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">从零开始的文本到语音转换简介</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ok l mj mk ml mh mm ks ly"/></div></div></a></div><p id="e8a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们可以导入必要的库，如下面的代码块所示。语音识别库将使我们能够检测必要的语音命令。此外，我们还可以利用文本到语音库来传递文本命令，并将它们转换为语音，然后传递给系统来执行所需的操作。我们可以为语音识别器创建一个变量。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="f965" class="nm mv it oa b gy oe of l og oh">import speech_recognition as sr<br/>import pyttsx3</span><span id="cd61" class="nm mv it oa b gy oi of l og oh">r = sr.Recognizer()</span></pre><p id="3d27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一步中，我们将读取用户的麦克风输入作为源，并相应地解释语音。一旦音频被识别为期望的，语音输出就显示在终端输出上。但是，如果语音未被检测到，我们可以通过必要的异常来确保用户可以相应地验证他们的设置。下面是简单语音识别的代码片段。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="6563" class="nm mv it oa b gy oe of l og oh">with sr.Microphone() as source:<br/>    r.adjust_for_ambient_noise(source)<br/>    print ("Say Something")<br/>    audio = r.listen(source)<br/>          <br/>    try:<br/>        text = r.recognize_google(audio)<br/>        print("you said: ", text)<br/>      <br/>    except sr.UnknownValueError:<br/>        print("Google Speech Recognition could not understand audio")<br/>      <br/>    except sr.RequestError as e:<br/>        print("Could not request results from Google Speech Recognition service; {0}".format(e))</span></pre><p id="456a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步，我们将构建AI语音助手的最终版本，在这里我们可以将本节中讨论的两个功能组合成一个实体来执行所需的操作。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="899b" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">开发人工智能语音助手的最终版本:</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/f88670365a3e1d75ff82cff0873035ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ywIna7FTvQ3xVuHY"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">附身摄影</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="7b95" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">既然我们对本文中设备控制和语音识别这两个核心组件有了基本的理解，我们就可以开始结合这两个元素来开发我们的项目了。让我们从必要的库导入开始，如下所示。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="b2d9" class="nm mv it oa b gy oe of l og oh">import pyautogui<br/>import speech_recognition as sr</span><span id="d2af" class="nm mv it oa b gy oi of l og oh">r = sr.Recognizer()</span></pre><p id="0ba8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一个片段中，我们将定义命令的功能，在这里我们将解释许多动作。在下面的代码块中，我只定义了几个功能，即打开我的管理目录或开始菜单。该函数接受用户提供的文本输入。我们可以添加几个其他必要的命令来进一步改进这个项目。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="30b9" class="nm mv it oa b gy oe of l og oh">def commands(text):<br/>    if text == "open admin":<br/>        # Open The Admin Directory<br/>        pyautogui.moveTo(37, 35, 1)<br/>        pyautogui.click(button='left', clicks=2)</span><span id="42a4" class="nm mv it oa b gy oi of l og oh">    elif text == "open start menu":<br/>        # Open The start menu<br/>        pyautogui.moveTo(18, 1057, 1)<br/>        pyautogui.click(button='left', clicks=1)</span></pre><p id="1509" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下一个代码块中，我们将定义接收来自用户的音频输入并相应地识别语音的功能。一旦听到音频，在将文本输入传递到我们的命令功能之前，请确保将其转换为小写。一旦构建了下面的代码，您就可以自由地测试和运行这个项目了。</p><pre class="kj kk kl km gt nz oa ob oc aw od bi"><span id="5121" class="nm mv it oa b gy oe of l og oh">with sr.Microphone() as source:<br/>    r.adjust_for_ambient_noise(source)<br/>    print ("Say Something")<br/>    audio = r.listen(source)<br/>          <br/>    try:<br/>        text = r.recognize_google(audio)<br/>        print("you said: ", text)<br/>        commands(text.lower())<br/>      <br/>    except sr.UnknownValueError:<br/>        print("Google Speech Recognition could not understand audio")<br/>      <br/>    except sr.RequestError as e:<br/>        print("Could not request results from Google Speech Recognition service; {0}".format(e))</span></pre><p id="d727" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行项目的首选方法是最小化所有选项卡并打开终端来运行Python代码。您可以发出命令“open admin”来观察光标从默认位置移动到指定位置，并根据需要打开它。我的GitHub资源库中提供了以下项目所需的所有文件。从下面的<a class="ae ky" href="https://github.com/Bharath-K3/AI-Voice-Assistant" rel="noopener ugc nofollow" target="_blank">链接</a>中查看。</p><p id="b64c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面这个项目只是一个入门项目，让你从零开始拥有一个自己的AI语音助手。我们可以对下面的项目进行大量的改进和提高，我会推荐用户去尝试。我还将查看本文的第2部分扩展，在那里我们可以为更好的特性和性能做一些重要的改进。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><h1 id="876b" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">结论:</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/54fe6c3f256ffe0fd0ee4b990b73e5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*w4anmDVtX33XO51L"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@vika_strawberrika?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维卡·斯特劳贝里卡</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><blockquote class="om on oo"><p id="12a6" class="kz la op lb b lc ld ju le lf lg jx lh oq lj lk ll or ln lo lp os lr ls lt lu im bi translated">“任何可以产生比人类更聪明的智能的东西——以人工智能、脑机接口或基于神经科学的人类智能增强的形式——都毫无疑问地成为最能改变世界的东西。其他的甚至都不在一个联盟里。”<br/> <strong class="lb iu"> <em class="it"> —埃利泽·尤科夫斯基</em> </strong></p></blockquote><p id="f876" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对语音和声音的识别是人类理解的原始任务。通过听和读不同类型的声音和比喻，我们能够感知和回应大多数人类情感。然而，机器还没有完全理解语言背后的情感的能力。</p><p id="0f1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然我们还没有完全能够开发出完全理解人类情感的机器，但我们已经成功地开发出了多种可以检测和理解语音的设备。当前编程时，AI可以识别语音并创建网络映射来解释对话并执行相应的任务。</p><p id="d88d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们开发了一个关于语音自动化系统的项目，它可以用来控制桌面上的许多操作。我们介绍了PyAutoGUI库处理所有光标、鼠标和键盘相关任务的基础知识。然后，我们研究了用于语音检测和处理的语音识别库。最后，我们构建了一个人工智能语音助手来控制你的电脑。</p><p id="5d92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想在我的文章发表后第一时间得到通知，请点击下面的<a class="ae ky" href="https://bharath-k1297.medium.com/subscribe" rel="noopener">链接</a>订阅邮件推荐。如果你希望支持其他作者和我，请订阅下面的链接。</p><div class="lv lw gp gr lx ly"><a href="https://bharath-k1297.medium.com/membership" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">通过我的推荐链接加入媒体</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">bharath-k1297.medium.com</p></div></div><div class="mh l"><div class="ot l mj mk ml mh mm ks ly"/></div></div></a></div><p id="86e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你对这篇文章中提到的各点有任何疑问，请在下面的评论中告诉我。我会尽快给你回复。</p><p id="4785" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给所有喜欢看我内容的观众一个快速更新。我很抱歉博客的延迟，因为我工作有点忙。从下个月开始，我会试着每月至少发布三到五篇文章。感谢大家一直以来的支持。</p><p id="a480" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看看我的一些与本文主题相关的文章，你可能也会喜欢阅读！</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/best-seaborn-visualizations-for-data-science-3d866f99c3a9"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">数据科学最佳Seaborn可视化</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用Seaborn库探索数据科学项目的一些最佳可视化选项</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ou l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/7-python-programming-tips-to-improve-your-productivity-a57802f225b6"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">提高生产力的7个Python编程技巧</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">通过修正一些常见的不良编程实践，使您的Python编码更加有效和高效</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ov l mj mk ml mh mm ks ly"/></div></div></a></div><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/develop-your-own-calendar-to-track-important-dates-with-python-c1af9e98ffc3"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">使用Python开发您自己的日历来跟踪重要日期</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">开发一个日历GUI界面来管理您2022年及以后的计划</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="ow l mj mk ml mh mm ks ly"/></div></div></a></div><p id="772e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谢谢你们坚持到最后。我希望你们都喜欢这篇文章。祝大家有美好的一天！</p></div></div>    
</body>
</html>