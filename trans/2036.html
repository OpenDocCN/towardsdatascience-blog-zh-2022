<html>
<head>
<title>Product Quantization for Similarity Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于相似性搜索的产品量化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/product-quantization-for-similarity-search-2f1f67c5fddd#2022-05-09">https://towardsdatascience.com/product-quantization-for-similarity-search-2f1f67c5fddd#2022-05-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9535" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何利用非对称距离计算(ADC)在内存中压缩和适应海量向量集进行相似性搜索</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a3e7f314161862f0e876243c16205924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*p5_lEAB_bMtMgPNt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·温克勒在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d595" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">相似性搜索和最近邻搜索是非常流行的，在很多领域都有广泛的应用。它们用于推荐系统、支持产品图像搜索的在线商店和市场，或者专用于文档、媒体或对象匹配和检索的系统。</p><p id="785a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相似性搜索通常是在大量的对象嵌入集合上完成的，通常是以高维向量的形式。</p><p id="9628" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在内存中拟合一组庞大的高维向量来执行相似性搜索是一个挑战，乘积量化可以通过一些权衡来帮助克服这一点。</p><h1 id="7e9e" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">什么是产品量化</h1><p id="cf14" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">乘积量化(PQ)是一种用于矢量压缩的技术。这对于压缩高维向量进行最近邻搜索是非常有效的。根据作者的<a class="ae ky" href="https://ieeexplore.ieee.org/document/5432202" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">对最近邻搜索</strong></a>【1】、</p><blockquote class="nb"><p id="29ef" class="nc nd it bd ne nf ng nh ni nj nk lu dk translated">其思想是将空间分解成低维子空间的笛卡儿积，并分别量化每个子空间。</p><p id="d830" class="nc nd it bd ne nf ng nh ni nj nk lu dk translated">一个向量由一个由它的子空间量化索引组成的短码来表示。两个向量之间的欧几里德距离可以从它们的代码中有效地估计出来。非对称版本提高了精度，因为它计算矢量和代码之间的近似距离”。</p></blockquote><blockquote class="nl nm nn"><p id="bfa2" class="kz la no lb b lc np ju le lf nq jx lh nr ns lk ll nt nu lo lp nv nw ls lt lu im bi translated">注意，产品量化不是<a class="ae ky" href="https://en.wikipedia.org/wiki/Dimensionality_reduction" rel="noopener ugc nofollow" target="_blank">降维</a>。</p><p id="7a12" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated">在乘积量化中，它是<a class="ae ky" href="https://en.wikipedia.org/wiki/Vector_quantization" rel="noopener ugc nofollow" target="_blank">矢量量化</a>的一种形式，量化后矢量的数量将保持不变。然而，压缩向量中的值现在被转换成短代码，因此它们是符号的而不再是数字的。使用这种表示法，每个向量的大小都大大减小了。</p><p id="1fc4" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated">产品量化也是在<a class="ae ky" href="https://github.com/facebookresearch/faiss" rel="noopener ugc nofollow" target="_blank"> Faiss </a>(脸书人工智能相似性搜索)中实现的许多索引类型之一，这是一个为高效相似性搜索而高度优化的库。</p></blockquote><h1 id="e4cd" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">产品量化如何工作</h1><p id="68b8" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">假设我们在数据库中有一个向量集合，每个向量的维数(或长度)是128。这意味着一个向量的大小是128 x 32位= 4096位(相当于512字节)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/a39f1ed4f2e3c521a0f1cc9c757a6ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*BWJdOEWdMqesX4l4uy7e7Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">除非另有说明，所有图片均为作者所有</p></figure><p id="28af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将向量分割成几段。下图显示了向量被分割成8段，其中每段的长度为16。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/0a2f8754711e658eebb27c4eba637ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*B4IILxmKmtOAyJrqz5Pg_g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将一个向量分割成线段</p></figure><p id="e182" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们对每个向量都这样做，因此我们实际上是把向量分成8个不同的子空间。如果我们在数据库中有1000个向量，那么每个子空间将包含1000个长度为16的段。</p><h2 id="6c96" class="nz mf it bd mg oa ob dn mk oc od dp mo li oe of mq lm og oh ms lq oi oj mu ok bi translated">培养</h2><p id="3a79" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">接下来，我们通过在每个子空间上运行<a class="ae ky" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> k均值聚类</a>来训练我们的向量。基于我们选择的<code class="fe ol om on oo b">k</code>的值，k-means聚类将在该子空间内生成<code class="fe ol om on oo b">k</code>质心(即聚类中心),并且这些质心具有与片段相同的长度。</p><p id="c350" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">质心也称为再现值。质心的集合被称为码本，我们稍后会详细讨论它。</p><p id="685d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">举个例子，如果我们选择<code class="fe ol om on oo b">k=256</code>，我们将会得到总共256 x 8 = 2048个质心。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/57f4c9886e67ae4c01b4800a37653716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*NYzJEi3s0I6UqV-v9XsEdQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在每个子空间上运行k-means聚类</p></figure><blockquote class="nl nm nn"><p id="eb02" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated">质心也称为再现值，因为它们可以用于通过连接来自每个片段的相应质心来近似重构矢量。然而，重构的矢量不会与原始矢量完全相同，因为乘积量化是一种<a class="ae ky" href="https://en.wikipedia.org/wiki/Lossy_compression" rel="noopener ugc nofollow" target="_blank">有损压缩</a>。</p><p id="084b" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated">对于训练，也可以使用不同的向量集或子集，只要它们具有与数据库向量相同的分布。</p></blockquote><h2 id="61ef" class="nz mf it bd mg oa ob dn mk oc od dp mo li oe of mq lm og oh ms lq oi oj mu ok bi translated">编码</h2><p id="f663" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">在训练完成后，对于数据库中的每个向量段，我们从各自的子空间中找到最近的质心。换句话说，对于向量的每一段，我们只需要从属于同一子空间的256个质心中找出最近的质心。</p><p id="3bbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于每个线段，在获得最近的质心后，我们用该质心的id替换它。质心id只不过是子空间内质心的索引(一个从0到255的数)。</p><p id="f523" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是它们，它们是矢量的压缩表示。这些就是我们前面讲过的短码，姑且称之为PQ码。</p><p id="e5ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个例子中，一个PQ码由跨段的8个质心id组成。我们在数据库中有1000个向量，因此会转换成1000个PQ代码。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/c1c3c0c2677e1272a5ceecb71a004a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*9vwp5D_hUBkc6NMjV2S-4Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">PQ码，向量的压缩表示</p></figure><p id="8c16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本上，我们所做的是用质心id编码我们的原始向量，其中每个片段用8位编码。</p><p id="18bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个向量有8个段，因此每个编码的向量仅占用8×8比特= 8字节的空间。与存储512字节的原始向量相比，这节省了大量空间。</p><p id="ac04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如本例所示，我们的内存使用量减少了64倍(每个向量从512字节减少到8字节)，这在我们处理数十万条记录(如果不是数百万条的话)时是一个巨大的数目！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d1d2169fe0eec7a08c314508340a5cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*MaiN1mO-yM_ZkbDE-5EZ5Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">产品量化后内存使用减少</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/a90d13fbbd3c89d70745cdfd31759a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fVU1AZzeBZ3sgueg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ky" href="https://unsplash.com/@krakenimages?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> krakenimages </a>拍摄</p></figure><blockquote class="nl nm nn"><p id="b172" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated"><code class="fe ol om on oo b"><em class="it">k</em></code> <em class="it"> </em>的值通常是2的幂。</p><p id="7739" class="kz la no lb b lc ld ju le lf lg jx lh nr lj lk ll nt ln lo lp nv lr ls lt lu im bi translated">对于<code class="fe ol om on oo b">M</code>段，一个PQ码的存储要求是<code class="fe ol om on oo b">M*(log base 2 of k)</code>位。</p></blockquote><h1 id="9e9a" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">量化搜索</h1><p id="e180" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">因此，我们有效地使用8个质心id来表示一个矢量。但是这种表示对于相似性搜索究竟是如何工作的呢？</p><p id="38e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">答案就在码本中，它包含了质心，即再现值。该过程解释如下。</p><p id="3478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给定一个查询向量<code class="fe ol om on oo b">q</code>，我们的目标是从数据库中的向量集合中找到与<code class="fe ol om on oo b">q</code>非常相似的向量。</p><p id="834f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">典型的过程是计算并比较查询向量和数据库中所有向量之间的距离，并返回距离最短的前N条记录。</p><p id="dee5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我们要做一些不同的事情。我们不会用原始向量来计算距离。相反，我们将进行非对称距离计算(ADC ),并使用矢量到质心的距离来估计距离。</p><p id="047a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先将查询向量分割成相同数量的片段。</p><p id="623f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于每个查询向量段，我们使用来自码本的相同段的所有质心预先计算部分<a class="ae ky" href="https://en.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance" rel="noopener ugc nofollow" target="_blank">平方欧几里德距离</a>。</p><p id="6df8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些部分平方欧几里德距离被记录在距离表<code class="fe ol om on oo b">d</code>中。在我们的示例中，如下所示，距离表由256行和8列组成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/1dd38db65fb379e863f78465a367ecf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*mdq3CkJx-Z743BwxmcJ51w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">预计算距离表</p></figure><p id="057e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们有了距离表，只需查找部分距离并求和，就可以轻松获得PQ代码每行的距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/a46fac3c74380b8bede167a1356006a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*AqyO5IhwrBgFYPPVYOWn6Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从距离表中查找部分距离</p></figure><p id="ac84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在获得PQ代码的所有行的距离之后，我们按照升序对它们进行排序，并且从顶部结果(即，具有最短距离的记录)开始，从数据库中找到并返回相应的向量。</p><p id="1225" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图总结了相似性搜索的产品量化过程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/1dce56cd13004d117d1b6fc2db6c07f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*wI0NGeuhjlv_QA61lSqTdw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">相似性搜索的产品量化过程</p></figure><p id="27c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，对于乘积量化，搜索仍然是强力搜索，因为距离查找和求和是穷举的，并且需要对PQ码的所有行进行。</p><p id="bc18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，因为我们比较的是矢量到质心的距离，这些距离并不是精确的矢量到矢量的距离。它们只是估计的距离，因此结果可能不太精确，并且可能不总是真正的最近邻。</p><p id="0445" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以通过调整质心的数量或分段的数量来提高搜索质量。更多的质心或段导致更高的准确度和精度，但是它们也会减慢搜索操作以及训练和编码所需的时间。除此之外，更多的质心可能会导致表示代码所需的比特数增加，从而节省更少的内存。</p><p id="5eaf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一个简单的Python实现产品量化的例子，灵感来自于<a class="ae ky" href="https://github.com/matsui528/nanopq" rel="noopener ugc nofollow" target="_blank"> nanopq </a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ow ox l"/></div></figure><h1 id="2f2f" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">摘要</h1><p id="aa5a" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">乘积量化将矢量分割并拆分成段，并分别量化矢量的每一段。</p><p id="ef62" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据库中的每个向量都被转换成一个短码(PQ码)，这是一种对于近似最近邻搜索来说非常节省内存的表示。</p><p id="0d8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">带有产品量化的相似性搜索是高度可扩展的，但是我们用一些精度来换取存储空间。</p><blockquote class="nb"><p id="8d4b" class="nc nd it bd ne nf ng nh ni nj nk lu dk translated">以较不精确的搜索为代价，产品量化使大规模搜索成为可能，否则这是不可能的。</p></blockquote><p id="d6f5" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li ns lk ll lm nu lo lp lq nw ls lt lu im bi translated">由于产品量化本身并不是非常大规模搜索的最有效方法，我们将在下一篇文章中看到如何实现更快的非穷举搜索方法。点击下面的链接了解更多信息。</p><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/similarity-search-with-ivfpq-9c6348fd4db3"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">使用IVFPQ进行相似性搜索</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">了解如何实现倒排文件索引(IVF)以及产品量化(PQ ),以实现快速有效的…</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp ks pb"/></div></div></a></div></div><div class="ab cl pq pr hx ps" role="separator"><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv pw"/><span class="pt bw bk pu pv"/></div><div class="im in io ip iq"><h1 id="d4c3" class="me mf it bd mg mh px mj mk ml py mn mo jz pz ka mq kc qa kd ms kf qb kg mu mv bi translated">参考</h1><p id="a292" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">[1] H. Jégou，M. Douze，C. Schmid，<a class="ae ky" href="https://ieeexplore.ieee.org/document/5432202" rel="noopener ugc nofollow" target="_blank">最近邻搜索的乘积量化</a> (2010)</p><p id="9a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] C. McCormick，<a class="ae ky" href="http://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/" rel="noopener ugc nofollow" target="_blank">k-NN教程第一部分</a>的产品量化器(2017)</p><p id="77a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] J. Briggs，<a class="ae ky" href="https://www.pinecone.io/learn/product-quantization/" rel="noopener ugc nofollow" target="_blank">乘积量化:将高维向量压缩97% </a></p><p id="5410" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] <a class="ae ky" href="https://github.com/matsui528/nanopq" rel="noopener ugc nofollow" target="_blank">纳米乘积量子化(nanopq) </a></p><pre class="kj kk kl km gt qc oo qd qe aw qf bi"><span id="43f3" class="nz mf it oo b gy qg qh l qi qj"><strong class="oo iu"><em class="no">Before You Go...</em></strong></span><span id="f731" class="nz mf it oo b gy qk qh l qi qj"><em class="no">Thank you for reading this post, and I hope you’ve enjoyed learning about product quantization for similarity search.</em></span><span id="8663" class="nz mf it oo b gy qk qh l qi qj"><em class="no">If you like my post, don’t forget to hit </em><a class="ae ky" href="https://peggy1502.medium.com/" rel="noopener"><strong class="oo iu"><em class="no">Follow</em></strong></a><em class="no"> and </em><a class="ae ky" href="https://peggy1502.medium.com/subscribe" rel="noopener"><strong class="oo iu"><em class="no">Subscribe</em></strong></a><em class="no"> to get notified via email when I publish.</em></span><span id="8a66" class="nz mf it oo b gy qk qh l qi qj"><em class="no">Optionally, you may also </em><a class="ae ky" href="https://peggy1502.medium.com/membership" rel="noopener"><em class="no">sign up</em></a><em class="no"> for a Medium membership to get full access to every story on Medium.</em></span><span id="112d" class="nz mf it oo b gy qk qh l qi qj">📑 <em class="no">Visit this </em><a class="ae ky" href="https://github.com/peggy1502/Data-Science-Articles/blob/main/README.md" rel="noopener ugc nofollow" target="_blank"><em class="no">GitHub repo</em></a><em class="no"> for all codes and notebooks that I shared in my posts.</em></span><span id="6097" class="nz mf it oo b gy qk qh l qi qj">© 2022 All rights reserved.</span></pre><p id="3b47" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有兴趣阅读我的其他数据科学文章吗？查看以下内容:</p><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/transformers-can-you-rate-the-complexity-of-reading-passages-17c76da3403"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">变形金刚，你能评价阅读段落的复杂程度吗？</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">用PyTorch微调RoBERTa以预测文本摘录的阅读难易程度</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="ql l pm pn po pk pp ks pb"/></div></div></a></div><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/advanced-techniques-for-fine-tuning-transformers-82e4e61e16e"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">微调变压器的先进技术</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">学习这些先进的技术，看看它们如何帮助改善结果</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="qm l pm pn po pk pp ks pb"/></div></div></a></div><div class="oy oz gp gr pa pb"><a href="https://pub.towardsai.net/building-a-product-recommendation-engine-with-aws-sagemaker-321a0e7c7f7b" rel="noopener  ugc nofollow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">用AWS SageMaker构建产品推荐引擎</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">了解如何使用Amazon SageMaker因式分解机构建和训练个性化推荐引擎</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">pub.towardsai.net</p></div></div><div class="pk l"><div class="qn l pm pn po pk pp ks pb"/></div></div></a></div><div class="oy oz gp gr pa pb"><a rel="noopener follow" target="_blank" href="/aws-certified-machine-learning-specialty-97eacbd1a0fe"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">AWS认证机器学习—专业</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">关于如何准备和通过考试的提示和建议</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">towardsdatascience.com</p></div></div><div class="pk l"><div class="qo l pm pn po pk pp ks pb"/></div></div></a></div><div class="oy oz gp gr pa"><div role="button" tabindex="0" class="ab bv gv cb fp qp qq bn qr ks ex"><div class="qs l"><div class="ab q"><div class="l di"><img alt="Peggy Chang" class="l de bw qt qu fe" src="../Images/9e4c26496eb3cca6b350330838259487.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*4RiPT4MGaV1PUkLGaNirFQ.png"/><div class="fb bw l qt qu fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://peggy1502.medium.com/?source=post_page-----2f1f67c5fddd--------------------------------" rel="noopener follow" target="_top">张佩琦</a></p></div></div><div class="qx qy gw l"><h2 class="bd iu vz wa fp wb fr fs ph fu fw is bi translated">掌握动态编程系列</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi wc au wd we wf sq wg an eh ei wh wi wj el em eo de bk ep" href="https://peggy1502.medium.com/list/series-on-mastering-dynamic-programming-ce9124edda06?source=post_page-----2f1f67c5fddd--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wk l fo"><span class="bd b dl z dk">2 stories</span></div></div></div><div class="rk dh rl fp ab rm fo di"><div class="di rc bv rd re"><div class="dh l"><img alt="Article cover for “Mastering Dynamic Programming — Understanding the fundamentals and knowing when and how to apply this optimization technique”. Author: Peggy Chang" class="dh" src="../Images/4189e936345f7dd6622ff2fc4cc61733.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*c0gU2CkZ880j1_pfnGS1fw.png"/></div></div><div class="di rc bv rf rg rh"><div class="dh l"><img alt="Article cover for “Mastering Dynamic Programming II — Manual tabulation and workout is a great way to start grokking, analyzing, and spotting patterns, as well as strengthening our understanding and intuitions”. Author: Peggy Chang" class="dh" src="../Images/2cfd9c02af79a8bee7a11d30e4d2abb9.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2hR-6vz3mdHIh8hS0GXanA.png"/></div></div><div class="di bv ri rj rh"><div class="dh l"><div class="rn ro rp l qf"/></div></div></div></div></div></div></div>    
</body>
</html>