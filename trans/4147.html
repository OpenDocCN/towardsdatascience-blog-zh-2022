<html>
<head>
<title>I Used My Voice to Interact With OpenAI GPT-3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我用我的声音和open ai GPT 3互动</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-used-my-voice-to-interact-with-openai-gpt-3-884b69dd3b0f#2022-09-14">https://towardsdatascience.com/i-used-my-voice-to-interact-with-openai-gpt-3-884b69dd3b0f#2022-09-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8038" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构建一个与GPT 3号对话的网络应用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/80a851a17fb5fdd215f5e3a169987f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0hOVF2QB1uRdUng-"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@soundtrap?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Soundtrap </a>拍摄的照片</p></figure><p id="cfc2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大型语言模型(简称LLMs)，如<a class="ae kv" href="https://arxiv.org/pdf/2204.02311.pdf" rel="noopener ugc nofollow" target="_blank"> PaLM </a> by <em class="ls"> Google </em>，<em class="ls"> OpenAI </em>的<a class="ae kv" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" rel="noopener ugc nofollow" target="_blank"> GPT-3 </a>，<a class="ae kv" href="https://arxiv.org/abs/2201.11990" rel="noopener ugc nofollow" target="_blank">威震天-图灵NLG </a> by <em class="ls">微软-英伟达</em>等。，在生成综合自然语言文本方面取得了显著的成绩。</p><p id="44ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目前，在这三种模型中，只有OpenAI的GPT-3可供公众使用，可使用OpenAI的API进行访问。因此，自发布以来，OpenAI的GPT-3已经在300多个应用程序/产品中使用。(来源:<a class="ae kv" href="https://openai.com/blog/gpt-3-apps/" rel="noopener ugc nofollow" target="_blank">此处</a>)。</p><p id="4e51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GPT-3将文本输入作为提示，并通过一次预测一个标记来执行文本补全任务。GPT-3的特别之处在于它的建造规模，拥有近175个参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/6e54df53712579c35e85497369de9304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*3rNrGWR1eqgF7hCzqk9enw.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GPT 3生成自然语言文本的可视化。(来源:<a class="ae kv" href="https://jalammar.github.io/how-gpt3-works-visualizations-animations/" rel="noopener ugc nofollow" target="_blank">杰伊·阿拉玛</a>)</p></figure><p id="e1df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然GPT-3背后的核心思想是响应“文本”提示，但集成语音输入应用程序最近也引起了社区的极大兴趣。</p><p id="ace0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在这篇博客中，我们将创建一个Streamlit应用程序，通过为它提供基于语音的输入来与OpenAI GPT-3进行交互。</p><p id="522b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">文章的亮点如下:</p><p id="9d08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> </strong> <a class="ae kv" href="#6733" rel="noopener ugc nofollow"> <strong class="ky ir"> App工作流程</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#8d08" rel="noopener ugc nofollow"><strong class="ky ir">先决条件</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#e5a1" rel="noopener ugc nofollow"><strong class="ky ir">构建细流App</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#715d" rel="noopener ugc nofollow"><strong class="ky ir">执行应用</strong></a><strong class="ky ir"><br/></strong><a class="ae kv" href="#cbed" rel="noopener ugc nofollow"><strong class="ky ir">结论</strong> </a></p><p id="bec8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们开始吧！</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="6733" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">应用程序工作流程</h1><p id="6769" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">如上所述，GPT-3模型期望文本提示作为输入。然而，如果我们从语音开始，我们首先需要将语音转换为文本，然后将转录的文本作为输入输入到GPT-3模型。</p><p id="6963" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了生成音频转录，我将使用AssemblyAI的语音到文本转录API。</p><p id="0cc4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图展示了该应用程序的高级工作流程:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/2e2428f3ff30e1805ce92b65b9ee4853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*yLgn3gCJOVxlm0ElEmLwVw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">应用程序的高级工作流(图片由作者提供)</p></figure><p id="ef76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，用户将提供语音输入，这将被记录。接下来，我们将把音频文件发送到AssemblyAI进行转录。一旦转录的文本准备好并从AssemblyAI的服务器中检索出来，我们将使用OpenAI API将其作为输入提供给OpenAI GPT-3模型。</p><h1 id="8d08" class="mb mc iq bd md me mz mg mh mi na mk ml jw nb jx mn jz nc ka mp kc nd kd mr ms bi translated">先决条件</h1><p id="6dfd" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">下面列出了创建可与GPT-3互动的语音应用程序的一些要求:</p><h2 id="6f82" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">排名第一的安装简化版</h2><p id="a0f5" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">首先，当我们使用streamlit创建这个应用程序时，我们应该使用以下命令安装Streamlit库:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h2 id="ec5e" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">#2安装OpenAI</h2><p id="7988" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">接下来，要向GPT-3模型发送请求，我们应该安装OpenAI API，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h2 id="eb01" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">#3导入依赖关系</h2><p id="b958" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">接下来，我们导入将在这个项目中使用的python库。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nr l"/></div></figure><h2 id="74a3" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">#4获取AssemblyAI API令牌</h2><p id="5dd5" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">为了利用AssemblyAI的转录服务，您应该从<a class="ae kv" href="https://app.assemblyai.com/signup" rel="noopener ugc nofollow" target="_blank"> AssemblyAI </a>网站获得一个API访问令牌。让我们为我们的Streamlit应用程序命名为<code class="fe nt nu nv nw b">assembly_auth_key</code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h2 id="4da4" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">#5获取OpenAI API令牌</h2><p id="89ef" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">最后，要访问GPT-3模型并生成文本输出，您应该从OpenAI网站获得一个API访问令牌。在OpenAI中，这被声明为<code class="fe nt nu nv nw b">api_key</code>属性，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nq nr l"/></div></figure><h1 id="e5a1" class="mb mc iq bd md me mz mg mh mi na mk ml jw nb jx mn jz nc ka mp kc nd kd mr ms bi translated">构建Streamlit应用程序</h1><p id="d060" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">一旦我们满足了应用程序的所有先决条件，我们就可以继续构建应用程序了。</p><p id="9cc4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为此，我们将定义五个不同的函数。这些是:</p><ol class=""><li id="fdcc" class="nx ny iq ky b kz la lc ld lf nz lj oa ln ob lr oc od oe of bi translated"><code class="fe nt nu nv nw b"><strong class="ky ir">record_audio(file_name)</strong></code>:顾名思义，这将允许用户向应用程序提供口头输入。该功能将收集音频并将其存储在本地的音频文件中，名为<code class="fe nt nu nv nw b">file_name</code>。我已经引用了<a class="ae kv" href="https://github.com/stefanrmmr/streamlit_audio_recorder" rel="noopener ugc nofollow" target="_blank">这个</a>代码来将这个方法集成到应用程序中。</li><li id="e228" class="nx ny iq ky b kz og lc oh lf oi lj oj ln ok lr oc od oe of bi translated"><code class="fe nt nu nv nw b"><strong class="ky ir">upload_to_assemblyai(file_name)</strong></code>:该函数将获取音频文件，上传到AssemblyAI的服务器，并将文件的URL返回为<code class="fe nt nu nv nw b">upload_url</code>。</li><li id="1a6a" class="nx ny iq ky b kz og lc oh lf oi lj oj ln ok lr oc od oe of bi translated"><code class="fe nt nu nv nw b"><strong class="ky ir">transcribe(upload_url)</strong></code>:一旦<code class="fe nt nu nv nw b">upload_url</code>可用，我们将创建一个POST请求来转录音频文件。这将返回<code class="fe nt nu nv nw b">transcription_id</code>，它将用于从AssemblyAI中获取转录结果。</li><li id="97af" class="nx ny iq ky b kz og lc oh lf oi lj oj ln ok lr oc od oe of bi translated"><code class="fe nt nu nv nw b"><strong class="ky ir">get_transcription_result(transcription_id)</strong></code>:为了检索转录的文本，我们将使用从<code class="fe nt nu nv nw b">transcribe()</code>方法获得的<code class="fe nt nu nv nw b">transcription_id</code>执行一个GET请求。该函数将返回转录的文本，我们将把它存储为一个<code class="fe nt nu nv nw b">prompt</code>变量。</li><li id="0505" class="nx ny iq ky b kz og lc oh lf oi lj oj ln ok lr oc od oe of bi translated"><code class="fe nt nu nv nw b"><strong class="ky ir">call_gpt3(prompt)</strong></code>:最后，这个函数将传递来自用户的提示，并从GPT-3模型中检索输出。</li></ol><h2 id="efcb" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">方法2:将音频文件上传到AssemblyAI</h2><p id="1072" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">一旦音频文件准备好并保存在本地，我们将把这个文件上传到AssemblyAI并获得它的URL。</p><p id="6d6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，在上传文件之前，我们应该声明AssemblyAI的头和转录端点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ol nr l"/></div></figure><p id="b997" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的代码块中:</p><ol class=""><li id="0c42" class="nx ny iq ky b kz la lc ld lf nz lj oa ln ob lr oc od oe of bi translated"><code class="fe nt nu nv nw b">upload_endpoint</code>指定AssemblyAI的上传服务。</li><li id="c73e" class="nx ny iq ky b kz og lc oh lf oi lj oj ln ok lr oc od oe of bi translated">上传文件后，我们将使用<code class="fe nt nu nv nw b">transcription_endpoint</code>转录音频文件。</li></ol><p id="f382" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe nt nu nv nw b">upload_to_assemblyai()</code>方法实现如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="om nr l"/></div></figure><p id="71e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们用<code class="fe nt nu nv nw b">upload_endpoint</code>、<code class="fe nt nu nv nw b">headers</code>和音频文件的路径向AssemblyAI发出post请求(<code class="fe nt nu nv nw b">file_path</code>)。我们从收到的JSON响应中收集并返回<code class="fe nt nu nv nw b">upload_url</code>。</p><h2 id="1b17" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">方法3:转录音频文件</h2><p id="c392" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">接下来，我们将定义<code class="fe nt nu nv nw b">transcribe()</code>方法。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="on nr l"/></div></figure><p id="bce6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与upload_to_assemblyai()方法中的POST请求相反，这里我们调用了<code class="fe nt nu nv nw b">transcription_endpoint</code>,因为目标是转录文件。</p><p id="de23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该方法为我们的POST请求返回<code class="fe nt nu nv nw b">transcription_id</code>，我们可以用它来获取转录结果。</p><h2 id="ffc1" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">方法4:获取转录结果</h2><p id="dd18" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">这个列表中的第四步是使用GET请求从AssemblyAI获取转录结果。</p><p id="85f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了获取与我们的特定请求相对应的结果，我们应该在GET请求中提供从AssemblyAI接收到的惟一标识符(<code class="fe nt nu nv nw b">transcription_id</code>)。<code class="fe nt nu nv nw b">get_transcription_result()</code>方法实现如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oo nr l"/></div></figure><p id="2857" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">转录运行时间将根据输入音频的持续时间而变化。因此，我们应该重复发出GET请求来检查请求的状态，并在状态变为<code class="fe nt nu nv nw b">completed</code>或指示为<code class="fe nt nu nv nw b">error</code>时获取结果。在这里，我们返回转录文本(<code class="fe nt nu nv nw b">prompt</code>)。</p><h2 id="0291" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">方法5:向OpenAI GPT-3发送提示</h2><p id="4c88" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">最后一个方法将使用OpenAI API将提示作为输入发送给GPT-3模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="op nr l"/></div></figure><p id="2ba9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可以在这里找到可用的GPT-3引擎列表<a class="ae kv" href="https://beta.openai.com/docs/models/overview" rel="noopener ugc nofollow" target="_blank"/>。</p><h2 id="0464" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">集成主方法中的功能</h2><p id="6e73" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">作为我们的Streamlit应用程序的最后一步，我们将上面定义的函数集成到<code class="fe nt nu nv nw b">main()</code>方法中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oq nr l"/></div></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="715d" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">执行应用程序</h1><p id="73df" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">现在我们已经构建了整个应用程序，是时候运行它了。</p><p id="83cc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打开一个新的终端会话，并导航到工作目录。在这里，执行以下命令:</p><pre class="kg kh ki kj gt or nw os ot aw ou bi"><span id="0eae" class="ne mc iq nw b gy ov ow l ox oy">streamlit run file-name.py</span></pre><blockquote class="oz pa pb"><p id="1916" class="kw kx ls ky b kz la jr lb lc ld ju le pc lg lh li pd lk ll lm pe lo lp lq lr ij bi translated">用你的应用文件名替换<code class="fe nt nu nv nw b">file-name.py</code>。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/68240308b70dddc368db58232d33532a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mp4H6QeKGNAhB7H8Kop0Vw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Streamlit应用程序的界面(图片由作者提供)</p></figure><h2 id="d011" class="ne mc iq bd md nf ng dn mh nh ni dp ml lf nj nk mn lj nl nm mp ln nn no mr np bi translated">演示演练</h2><p id="3589" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">接下来，让我们快速浏览一下支持Streamlit语音的GPT-3应用程序。</p><p id="d355" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们在上面看到的，应用程序要求说出提示。在下面的演练中，我向GPT-3展示了以下提示:“<em class="ls">想象一下地球之外是否存在生命。</em>”</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pg"><img src="../Images/b534bba59645af0dc92f4239f9bec7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*etikwAk_ok1oUHDIuMRzrQ.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">询问GPT-3关于地球外生命的存在(Gif作者)</p></figure><p id="23d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该应用程序记录音频并将其保存到本地文件中。接下来，它将文件发送到AssemblyAI进行转录。最后，转录的文本被发送到GPT-3，其响应显示在应用程序上。</p><p id="6950" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">GPT 3号对我们的提示的回应是:“<em class="ls">这是一个很难回答的问题，因为没有具体的证据表明地球之外存在生命。然而，关于宇宙中生命可能存在的地方有许多可能的理论。</em>”</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="cbed" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">结论</h1><p id="a22f" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">总之，在这篇文章中，我们使用AssemblyAI API和Streamlit构建了一个基于语音的交互工具，向GPT-3提出问题。</p><p id="845b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">具体来说，我演示了如何获取语音输入，使用AssemblyAI将其转换为文本，然后作为提示发送给GPT-3。</p><p id="4b73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="4590" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://subscribepage.io/450q" rel="noopener ugc nofollow" target="_blank"> 🧑‍💻<strong class="ky ir">成为数据科学专家！获取包含450多个熊猫、NumPy和SQL问题的免费数据科学掌握工具包。</strong> </a></p><p id="f7a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">✉️ <a class="ae kv" href="https://medium.com/subscribe/@avi_chawla" rel="noopener"> <strong class="ky ir">注册我的电子邮件列表</strong> </a>不要错过另一篇关于数据科学指南、技巧和提示、机器学习、SQL、Python等的文章。Medium会将我的下一篇文章直接发送到你的收件箱。</p></div></div>    
</body>
</html>