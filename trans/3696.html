<html>
<head>
<title>Outliers, Leverage, Residuals, and Influential Observations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">异常值、杠杆、残差和有影响的观察值</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/outliers-leverage-residuals-and-influential-observations-df3065a0388e#2022-08-17">https://towardsdatascience.com/outliers-leverage-residuals-and-influential-observations-df3065a0388e#2022-08-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="9818" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/causal-data-science" rel="noopener" target="_blank">因果数据科学</a></h2><div class=""/><div class=""><h2 id="b939" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">是什么让观察变得“不寻常”？</em></h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/51b3802918729214207a46a9daada92a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VcIp56vXZcQaGo4Z13AuNQ.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">封面图片，由作者使用<a class="ae lf" href="https://creator.nightcafe.studio/" rel="noopener ugc nofollow" target="_blank">nightcafe</a>生成</p></figure><p id="88d6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在数据科学中，一个常见的任务是<a class="ae lf" href="https://en.wikipedia.org/wiki/Anomaly_detection" rel="noopener ugc nofollow" target="_blank">异常检测</a>，即理解一个观察值是否<strong class="li ja">“异常”</strong>。首先，不寻常是什么意思？在本文中，我们将考察观察值异常的三种不同方式:它可能具有异常特征，它可能不太适合模型，或者它可能对模型的训练特别有影响。我们将会看到，在线性回归中，后一个特征是前两个特征的副产品。</p><p id="31e6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">重要的是，与众不同不一定是坏事。具有不同特征的观察结果通常包含更多的信息。我们还预计一些观察结果不会很好地拟合模型，否则，模型很可能是有偏差的(我们过度拟合)。然而，“不寻常”的观察结果也更有可能是由不同的数据生成过程产生的。极端情况包括测量错误或欺诈，但其他情况可能更微妙，如具有罕见特征或行为的正版用户。领域知识永远是王道，仅仅因为统计原因而放弃观察是不明智的。</p><p id="4fc9" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">也就是说，让我们看看观察结果“不寻常”的一些不同方式。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="ba53" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">简单的例子</h1><p id="3e7b" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">假设我们是一个<strong class="li ja">点对点在线平台</strong>，我们有兴趣了解我们的业务是否有任何可疑之处。我们掌握了用户在平台上花费时间的信息，以及他们交易的总价值。是不是有些用户<strong class="li ja">可疑</strong>？</p><p id="91f4" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，我们来看一下数据。我从<code class="fe ng nh ni nj b"><a class="ae lf" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py" rel="noopener ugc nofollow" target="_blank">src.dgp</a></code>导入数据生成过程<code class="fe ng nh ni nj b">dgp_p2p()</code>，从<code class="fe ng nh ni nj b"><a class="ae lf" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py" rel="noopener ugc nofollow" target="_blank">src.utils</a></code>导入一些绘图函数和库。为了不仅包括代码，还包括像数据和表格这样的输出，我使用了<a class="ae lf" href="https://deepnote.com" rel="noopener ugc nofollow" target="_blank"> Deepnote </a>，一个类似Jupyter的基于网络的协作笔记本环境。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="21e6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们有50个用户的信息，我们观察他们在平台上花费的<code class="fe ng nh ni nj b">hours</code>和总<code class="fe ng nh ni nj b">transactions</code>金额。因为我们只有两个变量，我们可以很容易地用散点图来检查它们。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nm nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nn"><img src="../Images/babed0102b2b23b505e986040950da6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h6bwz4PEDzhqgmba8EIpqg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">数据散点图，图片由作者提供</p></figure><p id="5435" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><code class="fe ng nh ni nj b">hours</code>和<code class="fe ng nh ni nj b">transactions</code>之间的关系似乎遵循明显的线性关系。如果我们拟合一个<a class="ae lf" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">线性模型</a>，我们会观察到一个特别紧密的拟合。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="no nl l"/></div></figure><p id="fd89" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">是否有任何数据点看起来可疑地不同于其他数据点？怎么会？</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="ca81" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated"><strong class="ak">杠杆</strong></h1><p id="3f73" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">我们用来评估“不寻常”观察的第一个指标是<strong class="li ja">杠杆</strong>。杠杆作用的目标是捕捉单个点相对于其他数据点的不同程度。这些数据点通常被称为<strong class="li ja">异常值</strong>，有几乎无限数量的算法和经验法则来标记它们。然而，想法是相同的:标记在特征方面不寻常的观察。</p><p id="3562" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">观察值<em class="np"> i </em>的杠杆作用定义为</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nq"><img src="../Images/7a9119902de72c5363cc07725f6aee22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_sl4zWHI7bqbVDaM2aO4vg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">线性回归中的杠杆作用，图片由作者提供</p></figure><p id="f4f1" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">对杠杆的一种解释是作为距离的<strong class="li ja">度量，其中将单个观察值与所有观察值的平均值进行比较。</strong></p><p id="0119" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">杠杆的另一种解释是观察结果<em class="np"> i </em>、<em class="np"> yᵢ </em>对相应拟合值<em class="np"> ŷᵢ </em>的影响。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi nr"><img src="../Images/f77950261e0a28355759ef2d903d6723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mbouucmNoxJoh7GCqyrcQ.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">利用替代公式，作者图片</p></figure><p id="f0db" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">从代数上讲，观察的杠杆<em class="np"> i </em>是<strong class="li ja">设计矩阵</strong> X'(X'X)⁻ X的<em class="np"> iₜₕ </em>元素。在杠杆的许多属性中，有一个事实是它们是非负的，并且它们的值总和为<em class="np"> X </em>的维数(在我们的例子中为1)。</p><p id="a609" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们计算一下数据集中观察值的杠杆作用。我们还标记了具有不寻常杠杆的观察结果(我们任意定义为偏离平均杠杆超过两个标准差)。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ns nl l"/></div></figure><p id="b978" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们在数据中绘制杠杆值的分布图。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nt nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="ab gu cl nu"><img src="../Images/96f4352e51c046d2972e0b75bfd8d110.png" data-original-src="https://miro.medium.com/v2/format:webp/1*nj7T6as_ehs0q8fb5b8DCQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">高杠杆点，作者图片</p></figure><p id="8e3b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">正如我们所看到的，分布是偏斜的，两个观察值具有异常高的杠杆作用。事实上，在散点图中，这两个观察值与分布的其余部分略有不同。</p><p id="7d91" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这是坏消息吗？看情况。离群值本身并不是问题。实际上，如果它们是真实的观察，它们可能比其他观察携带更多的信息。另一方面，它们也更有可能<em class="np">而非</em>是真实的观察结果(例如欺诈、测量误差……)，或者与其他观察结果有本质上的不同(例如专业用户与业余用户)。在任何情况下，我们可能希望进一步调查，并尽可能多地使用特定于上下文的信息。</p><blockquote class="nv"><p id="47af" class="nw nx iq bd ny nz oa ob oc od oe mb dk translated">人们永远不应该仅仅因为统计原因而放弃观察</p></blockquote><p id="ccbb" class="pw-post-body-paragraph lg lh iq li b lj of ka ll lm og kd lo lp oh lr ls lt oi lv lw lx oj lz ma mb ij bi translated">重要的是，观察具有高杠杆的事实告诉我们关于模型特征的信息，但是没有关于模型本身的信息。这些用户只是不同还是他们的行为也不同？</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="52b0" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">残差</h1><p id="61aa" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">到目前为止，我们只讨论了不寻常的特性，但是<strong class="li ja">不寻常的行为</strong>呢？这就是回归残差所测量的。</p><p id="c5c2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">回归残差是预测结果值和观察结果值之间的差值。从某种意义上来说，它们捕捉到了模型无法解释的东西:一个观察值的残差越高，就越不寻常，因为模型无法解释它。</p><p id="aadc" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在线性回归的情况下，残差可以写成</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ok"><img src="../Images/3d18fb94c4c435e4e83c4a172fe53bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGBqvskKAlWvMXiacb2mDg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">线性回归中的残差，作者提供的图像</p></figure><p id="4854" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在我们的例子中，由于<em class="np"> X </em>是一维的(<code class="fe ng nh ni nj b">hours</code>，我们可以很容易地把它们想象成观测值和预测线之间的距离。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nm nl l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ns nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ol"><img src="../Images/081796e6c24b680bc06724491983d2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wZ9TiVsUwIT0q7cvyNK9Tg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">数据、预测值和残差，按作者分类的图像</p></figure><p id="352e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">某些观测值是否有异常高的残差？让我们画出它们的分布图。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="om nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="ab gu cl nu"><img src="../Images/533e1b5d8bcb3b3ab3b6635cd7421f1a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*oJX0e0ApS3OuiNZFFmF57Q.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">高残留点，作者图片</p></figure><p id="32dd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">两个观测值具有特别高的残差。这意味着对于这些观察结果，模型不擅长预测观察到的结果。</p><p id="8e2a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这是坏消息吗？还是那句话，不一定。太符合观测值的模型很可能<a class="ae lf" href="https://en.wikipedia.org/wiki/Bias_(statistics)" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja">有偏</strong> </a>。但是，理解为什么一些用户在花费的时间和总事务之间有不同的关系可能仍然很重要。像往常一样，领域知识是关键。</p><p id="6da6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">到目前为止，我们已经从模型的角度观察了具有“不寻常”特征和“不寻常”行为的观察结果。但是<strong class="li ja">哪里来的模型</strong>？我们的模型有多少是由少量的观察数据驱动的？哪些？</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="fbc5" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">影响</h1><p id="065f" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated"><strong class="li ja">影响和影响函数</strong>的概念正是为了回答这个问题而开发的:什么是有影响的观察？这个问题在80年代非常流行，并且在很长一段时间内失去了吸引力，直到最近，因为解释复杂的机器学习和人工智能模型的需求越来越大。</p><p id="8ccb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">总的想法是，如果移除它会显著改变估计的模型，则将观察定义为<strong class="li ja">有影响的</strong>。在线性回归中，我们将观察值<em class="np"> i </em>的影响定义为:</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi on"><img src="../Images/1da3f33b52723be2deb2bf5fdc376be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n4tJTmkMvJtbbhajPYroVA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">线性回归中的影响，作者提供的图像</p></figure><p id="afca" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">其中<em class="np"> β̂-i </em>是省略观测值<em class="np"> i </em>估计的OLS系数。</p><p id="6e04" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如你所见，杠杆<em class="np"> hᵢᵢ </em>和残差<em class="np"> eᵢ </em>之间有着紧密的<strong class="li ja">联系</strong>:这两者的影响力都在增加。实际上，在线性回归中，具有高杠杆的观察值是既有异常值又有高残差的观察值。这两个条件中没有一个足以使观察对模型产生影响。</p><p id="44cd" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们可以从数据中最好地看到这一点。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="om nl l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nt nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="ab gu cl nu"><img src="../Images/0c0ed4b99c3944d44dd9b9d418797875.png" data-original-src="https://miro.medium.com/v2/format:webp/1*gNbiPClNcme-qne6oXsZ5Q.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">高影响点，作者图片</p></figure><p id="708a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在我们的数据集中，只有一个具有高影响的观测值，其值不成比例地大于所有其他观测值的影响。单从散点图上你会猜到吗？</p><p id="599b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们现在可以在同一个图中标出所有“不寻常”的点。我还在单独的图中报告了每个点的残差和杠杆。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="oo nl l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nm nl l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="ab gu cl nu"><img src="../Images/d17eebd225ce95084c81ab60dd5f492e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ymF1W7kCyjT7yy59rCaHIA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">不寻常的观察，作者的图像</p></figure><p id="cbce" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">正如我们所看到的，我们有一个高剩余和低杠杆的点，一个高杠杆和低剩余的点，只有一个高杠杆和高剩余的点:唯一有影响的点。</p><p id="d024" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">从图中还可以清楚地看出，为什么这两个条件中没有一个足以使一个观察结果产生影响并扭曲模型。橙色点具有较高的残差，但它正好位于分布的中间，因此不能倾斜最佳拟合线。相反，绿点具有很高的杠杆作用，并且远离分布的中心，但它与拟合线完全对齐。移除它不会改变任何事情。相反，红点在<strong class="li ja">特性和行为</strong>方面不同于其他红点，因此使拟合线向自身倾斜。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="a640" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">结论</h1><p id="c201" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">在这篇文章中，我们已经看到了观察“不寻常”的几种不同方式:它们可能有<strong class="li ja">不寻常的特征</strong>或<strong class="li ja">不寻常的行为</strong>。在线性回归中，当一个观察同时具有两者时，它也是有影响的:它使模型向自身倾斜。</p><p id="c93d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在本文的例子中，我们集中在一元线性回归上。然而，由于需要让黑盒机器学习算法<strong class="li ja">可以理解</strong>，影响函数的研究最近成为热门话题。对于拥有数百万个参数、数十亿个观察值和大量非线性的模型，很难确定单个观察值是否有影响以及如何影响。</p><h2 id="8005" class="op mk iq bd ml oq or dn mp os ot dp mt lp ou ov mv lt ow ox mx lx oy oz mz iw bi translated">参考</h2><p id="6b01" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">[1] D .库克，<a class="ae lf" href="https://www.jstor.org/stable/1268249" rel="noopener ugc nofollow" target="_blank">线性回归中有影响的观测值的检测</a> (1980)，<em class="np"/>。</p><p id="0942" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[2] D. Cook，S. Weisberg，<a class="ae lf" href="https://www.jstor.org/stable/1268187" rel="noopener ugc nofollow" target="_blank"/>(1980)，<em class="np">技术计量学</em>。</p><p id="b1f1" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[2]许佩文，梁，<a class="ae lf" href="http://proceedings.mlr.press/v70/koh17a" rel="noopener ugc nofollow" target="_blank">通过影响函数理解黑箱预测</a> (2017)，<em class="np">《ICML论文集》</em>。</p><h2 id="bc4b" class="op mk iq bd ml oq or dn mp os ot dp mt lp ou ov mv lt ow ox mx lx oy oz mz iw bi translated">密码</h2><p id="a2d9" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">你可以在这里找到Jupyter的原始笔记本:</p><div class="pa pb gp gr pc pd"><a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/outliers.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ja gy z fp pi fr fs pj fu fw iz bi translated">博客帖子/离群值. ipynb at main matter courthoud/博客帖子</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">我的中型博客文章的代码和笔记本。为matteocourthoud/Blog-Posts的发展作出贡献</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">github.com</p></div></div></div></a></div></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="73ff" class="op mk iq bd ml oq or dn mp os ot dp mt lp ou ov mv lt ow ox mx lx oy oz mz iw bi translated">感谢您的阅读！</h2><p id="ecff" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated"><em class="np">真的很感谢！</em>🤗<em class="np">如果你喜欢这个帖子并想看更多，可以考虑</em> <a class="ae lf" href="https://medium.com/@matteo.courthoud" rel="noopener"> <strong class="li ja"> <em class="np">关注我</em> </strong> </a> <em class="np">。我每周发布一次与因果推断和数据分析相关的主题。我尽量让我的帖子简单而精确，总是提供代码、例子和模拟。</em></p><p id="cc56" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="np">还有，一个小小的</em> <strong class="li ja"> <em class="np">免责声明</em> </strong> <em class="np">:我写作是为了学习所以错误是家常便饭，尽管我尽力了。当你发现他们的时候，请告诉我。也很欣赏新话题的建议！</em></p></div></div>    
</body>
</html>