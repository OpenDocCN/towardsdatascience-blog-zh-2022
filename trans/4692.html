<html>
<head>
<title>Shapley Residuals: Measuring the Limitations of Shapley Values for Explainability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Shapley残差:测量Shapley值的可解释性的限制</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shapley-residuals-measuring-the-limitations-of-shapley-values-for-explainability-d9cdc3582522#2022-10-19">https://towardsdatascience.com/shapley-residuals-measuring-the-limitations-of-shapley-values-for-explainability-d9cdc3582522#2022-10-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b568" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让我们用酒吧琐事来显示沙普利值错过的信息</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/b6f17a9fe490c8b606273bbb87d80ff3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*rSyVjsag7v5Yc-3VYystAg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">我们将使用一个游戏的立方体表示来解释Shapley值的解释和限制。</p></figure><h1 id="f39e" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">简介</strong></h1><p id="354d" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">为了负责任地使用机器学习，你应该尝试解释是什么驱动了你的ML模型的预测。许多数据科学家和机器学习公司正在认识到，能够逐个功能地解释模型如何对给定的输入做出反应是多么重要。本文将展示Shapley值，一种最常见的可解释技术，在解释一个模型时是如何遗漏重要信息的。然后，我们将介绍Shapley残差，一种测量Shapley值如何捕捉模型行为的新技术，以及一些开始计算它们的代码！</p><p id="008a" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">考虑克里斯托弗·莫尔纳尔的<a class="ae mk" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">可解释机器学习书</a>中的以下例子:一家自行车共享公司使用季节信息、星期几、天气信息等功能，训练一个模型来预测某一天被借出的自行车数量。然后，如果他们的模型预测未来某一天的骑手数量低于平均水平，他们可以找出<em class="ml">为什么</em>低于平均水平的分数会出现:通过观察模型对每个特征的反应。是因为一个节日吗？是因为天气吗？</p><p id="6158" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">计算每个模型特征重要性的一种常用方法是使用<strong class="ll ir"> Shapley值</strong>，因为这是一种1)广泛适用于许多问题，2)基于坚实的理论基础，3)易于用SHAP Python库实现的方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/beef8e4a75a048fe299732c57f2f4308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N2t27DMJQ8X_Sb6gzL9IlA.png"/></div></div></figure><p id="787d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">问题:</strong>在某些场景中，Shapley值无法表达关于模型行为的信息，因为它一次只为<em class="ml">的一个特征</em>返回一个分数。例如，在自行车共享场景中，我们将天气和星期几视为独立的特征，但有时这些特征的组合<em class="ml">才是重要的；在那些特征组合比单个特征本身更重要的场景中，Shapley值可能无法正确解释一个模型。</em></p><h1 id="506c" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">酒吧琐事示例</strong></h1><p id="188b" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">让我们使用一个更简单的设置和更少的功能来更详细地解决Shapley值的问题。</p><p id="7abd" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">我喜欢每周和不同的同事去附近的酒吧参加知识之夜。很明显，我们团队中的一些成员比其他人更有贡献。</p><p id="e03f" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">我们能量化每个团队成员对琐事表现的影响吗？我们可以对每个玩家使用Shapley值，其解释如下:当将该玩家添加到琐事团队时，它们应该对应于分数的预期变化。存在其他可能的解释，但我们将使用这一个。</p><p id="2128" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">(* <em class="ml">注:这类计算Shapley值的方法称为“介入性”Shapley值，测量“添加此功能时分数的预期变化”一种不同的类型被称为“有条件的”Shapley值。介入方法和条件方法之间的关键区别在于它们如何处理分数的预期变化为零的特征——其Shapley值应该是多少？零？如果你认为答案是“是”，那就用介入的方法。相反，如果您认为由于相关性，要素可能仍然具有重要性，并且如果您认为重要性应该包括在其Shapley值中，则考虑使用条件方法。)</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mr"><img src="../Images/2996727bfb2456c316d4dc6f27e8633d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YIKNpJA4BPNWOp5gv3g_eg.png"/></div></div></figure><p id="b587" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">从几何角度来看，绘制不同球队的所有3人游戏分数的一个有用方法是将这些分数排列成一个立方体上的点，这样相邻的点只相差一名球员。然后，点之间的路径(也称为立方体的边缘)将代表在将球员加入球队时分数的变化。</p><p id="0107" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">(注意:有两个玩家，我们会把它画成一个正方形。对于四个或更多的玩家，我们将不得不把它画成一个超立方体)</em></p><p id="eb4c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">让我们称这个形状为GameCube这将是一个对我们有用的形状，因为【Shapley值和GameCube边都将对应于增加一名球员时分数的变化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ms"><img src="../Images/bb0b9b249149a564a47ebefecc0bc154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*03-7DoGTaFV0zF8k"/></div></div></figure><p id="a059" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">图1:将每一个琐事分数标绘在一个立方体的不同顶点上，对应于当晚队中在场的球员。</em></p><p id="6c08" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在我们的故事中，Reid只知道体育琐事，GW知道电影、音乐、历史、地理、文学——除了体育琐事，几乎什么都知道。所以当里德演奏时，他提高了一点分数；GW玩的时候，她增加一个<em class="ml"> lot </em>的分数。而我，嗯，我主要是为了啤酒和陪伴。</p><p id="c0f9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">Shapley值是一个<em class="ml">完美的</em>可解释的度量<em class="ml">只有当一个玩家<em class="ml">总是</em>为一个团队的分数贡献相同的</em>数量时。由于每个球员在得分上的变化在我们迄今为止的故事中是恒定的，我们可以将Shapley值1分配给Reid，将Shapley值9分配给GW，将Shapley值0分配给Max。这些Shapley值代表了每个球员加入球队时的预期得分变化！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ms"><img src="../Images/0aa8c09544f18bb9b96784ed99a4430f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fFVSbYRDKFB9QsNX"/></div></div></figure><p id="da63" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">图2:查看添加每个球员时队伍得分的变化。</em></p><p id="f281" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">用更专业的术语来说，每个玩家的影响都一致的游戏(就像我们到目前为止的故事)被称为“无关紧要的游戏”。此外，我们将使用符号<em class="ml"> ▽v </em>来表示GameCube <em class="ml"> v </em>的“梯度”,它计算顶点上的值之间沿边缘的值，我们将使用<em class="ml"> ▽_player_v </em>来表示特定<em class="ml">玩家</em>的方向的边缘值，沿所有其他边缘为零。</p><p id="ce9d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">比如GameCube渐变<em class="ml"> ▽_Reid_ν </em>代表了加入Reid <em class="ml">时所有可能的分数变化。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ms"><img src="../Images/49a030bf2406a0a82f0c453387abf3a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VpZslUKwjpo8vTmI"/></div></div></figure><p id="c7b6" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">图3:将添加玩家时分数的变化表示为游戏立方体相对于每个玩家的部分梯度</em></p><h1 id="a982" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">特征贡献不能总是表示为一个单一的数字——因此Shapley值是不够的。</strong></h1><p id="5118" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">您应该预料到，在大多数情况下，您正在使用的特征不会对模型输出产生持续的影响，相反，一个特征的影响通常取决于其他特征是什么。</p><h2 id="9a09" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">让我们改变一下我们的故事。</h2><p id="6efb" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">假设Max的行为根据他和谁一起玩而改变。当和GW玩的时候，他很冷静，喝他的啤酒，关心他自己的事情，让GW做大部分的工作，所以他不会降低分数。但是当马克斯和里德一起玩的时候，他嫉妒里德对体育的了解，所以马克斯开始说得更多，提出了一些错误的答案，使分数下降了1分！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi ms"><img src="../Images/4c45be973cc4271119dbb9a8608cf680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*euolBet0b_xA2rO1"/></div></div></figure><p id="12e6" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">图4:玩家贡献不一致的新game cube</em></p><p id="f5cb" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在这个新的GameCube上，GW的边是恒定的，所以她的Shapley值9仍然与她玩游戏时分数的变化完全对应。但是马克斯和里德的优势不是恒定的，因为他们对得分的影响取决于他们和谁一起玩。因此，我们使用GameCube边缘来量化Max和Reid带来的东西的方法现在有问题了。</p><p id="0ed7" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">当真实数据科学家使用Shapley值时，他们通过获取玩家对其团队的平均贡献来解决这个问题——在GameCube上，这意味着将玩家的贡献量化为他们所在方向的平均边缘值。所以在我们上面的GameCube上，GW的Shapley值仍然是9，但是Reid的Shapley值现在是0.5，Max的Shapley值现在是-0.5。对于一些用例，故事到此结束——玩家的平均贡献有时可以很好地量化他们的影响！</p><p id="29e9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">然而，当涉及到<em class="ml">信任</em>沙普利价值观时，这可能会导致一个问题。因为我们更信任GW的Shapley价值观，而不是Max或Reid的Shapley价值观，因为她对团队的贡献比Max或Reid的贡献更具一致性。</p><h1 id="61f2" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">沙普利残差</h1><p id="049b" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">Shapley残差是对玩家的边缘偏离恒定值的程度的度量，较低的Shapley残差意味着Shapley值接近完美地代表了特征贡献，而较高的Shapley残差意味着Shapley值遗漏了重要的模型信息:也就是说，一个特征的贡献还取决于其他特征。</p><p id="e24b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">最初Shapley residuals论文的作者将这种缺失信息公式化为最小二乘回归中的误差项。例如，对于玩家<em class="ml">里德</em>:</p><p id="861b" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml"> ▽_Reid_ν = ▽_ν_Reid + r_Reid </em></p><p id="51c8" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">这个方程的左边是和前面一样的偏梯度。等式的右边是一个新的GameCube的梯度之和，<em class="ml"> ▽_ν_Reid，</em>加上一个剩余的Cube，<em class="ml"> r_Reid，</em>，它测量我们的游戏偏离Reid无关紧要的程度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nf"><img src="../Images/9b158818f38da3aa7c7d3e0f824b40ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xl1xWwa2mp5nFsoYUBb-ww.png"/></div></div></figure><p id="6817" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">图5:剩余立方是游戏相对于给定玩家偏离无关紧要性的量。</em></p><p id="f0dd" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">关键的想法是，如果里德对团队有持续的影响，剩余的立方体<em class="ml"> r_Reid </em>将全为零。另一方面，如果剩余立方体上的值<em class="ml"> r_Reid </em>偏离零，那么这是一个信号，即Reid的Shapley值缺少关于Reid的影响<em class="ml">如何取决于还有谁与Reid一起玩的信息。剩余立方体上的值越高，里德的贡献就越依赖于哪些其他玩家在场。</em></p><h1 id="af1d" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">计算Shapley残差的代码</h1><h2 id="0579" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">进口</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="b7fd" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">生成合成数据集</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="7aa1" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">训练模型和内核简单解释器</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="0930" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">计算特征联盟的期望值</h2><p id="5372" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">这使用了<code class="fe ni nj nk nl b">explainer.synth_data</code>，即训练讲解者时由<code class="fe ni nj nk nl b">shap</code>库生成的合成数据样本集。</p><p id="653d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">字典<code class="fe ni nj nk nl b">coalition_estimated_values</code>将特征联盟映射到使用这些特征时模型相对于基线的期望值(当<em class="ml">没有使用特征</em>时的期望值:平均模型输出)。</p><p id="83f1" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><em class="ml">(注意，我们将列表转换为字符串，因为列表在Python中不是可哈希的类型。)</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="c449" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">进度检查</h2><p id="77f6" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><code class="fe ni nj nk nl b">coalition_estimated_values</code>应该是这样的:</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="2974" class="mt ks iq nl b gy nq nr l ns nt">{'[]': 0,<br/> '[0]': -0.3576234198270127,<br/> '[1]': 0.010174318030605423,<br/> '[2]': -0.08009846972721224,<br/> '[0 1]': -0.34261386138613864,<br/> '[0 2]': -0.37104950495049505,<br/> '[1 2]': 0.14435643564356437,<br/> '[0 1 2]': -0.396}</span></pre><h2 id="3c51" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">创建超立方体对象</h2><p id="b572" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们使用的是三维数据，所以这只是一个立方体。但这种方法扩展到超立方体，随着维数的增加，增长速度变慢。</p><p id="6b65" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">请随意使用本文附录中的Hypercube python类的代码，或者自己编写代码。它需要将<code class="fe ni nj nk nl b">coalition_estimated_values</code>放置在立方体的顶点上，并且它需要将边值计算为相邻顶点值之间的<em class="ml">差</em>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h2 id="b57d" class="mt ks iq bd kt mu mv dn kx mw mx dp lb ls my mz ld lw na nb lf ma nc nd lh ne bi translated">计算Shapley残差</h2><p id="2dfc" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">对于每个要素，最小化| |▼_ feature _ cube—▼_ cube _ feature | |以计算残差。这使用了一个名为<code class="fe ni nj nk nl b">residual_norm </code>的助手函数，在本文末尾的附录中有定义。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="829e" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">结论</h1><p id="ad4d" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">Shapley值已经成为一种非常流行和可推广的方法，用于解释哪些特征对机器学习模型很重要。通过使用Shapley残差量化它们的有效性，您将能够进一步确定您的机器学习模型的行为到底来自哪里，以及哪些来自Shapley值的见解值得信任。</p><p id="c186" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">特别感谢<a class="ae mk" href="https://proceedings.neurips.cc/paper/2021/file/dfc6aa246e88ab3e32caeaaecf433550-Paper.pdf" rel="noopener ugc nofollow" target="_blank">原始沙普利残差论文</a>的作者们所做的工作！</p><h1 id="3af3" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">附录</h1><p id="5017" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">作品中的所有图像都是作者创作的。</p><p id="348e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">下面是Hypercube对象和其他帮助函数的代码，您可以使用上面的起始代码来计算Shapley残差。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ng nh l"/></div></figure></div></div>    
</body>
</html>