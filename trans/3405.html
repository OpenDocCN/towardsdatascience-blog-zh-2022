<html>
<head>
<title>Multilingual Text Similarity Matching using Embedding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用嵌入的多语言文本相似性匹配</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multilingual-text-similarity-matching-using-embedding-f79037459bf2#2022-07-28">https://towardsdatascience.com/multilingual-text-similarity-matching-using-embedding-f79037459bf2#2022-07-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bc3f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用句子转换器进行对称的<strong class="ak"> </strong>语义搜索</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/e8d9ef8d4266eee48327d6dc26ae73c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PVtFiTKSpwIwyTggPuE2WQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拉奎尔·马丁内斯在<a class="ae ky" href="https://unsplash.com/s/photos/compare?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="adcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的主题是计算相同或不同语言的两个句子之间的相似度。我们将利用<code class="fe lv lw lx ly b">sentence-transformer</code>框架，它自带预先训练好的多语言transformer模型。</p><p id="102f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以利用这些模型来计算50多种语言的文本嵌入。然后，输出嵌入可以用于对称语义搜索。</p><h2 id="b8df" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">对称和非对称语义搜索的区别</h2><blockquote class="ms mt mu"><p id="f44f" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><strong class="lb iu">对称语义搜索</strong>专注于基于输入查询从语料库中寻找相似问题。例如，鉴于“如何在线学习人工智能？”作为输入查询，预期的输出应该类似于“如何在web上学习人工智能？”大多数时候，您可能会翻转查询和语料库中的数据，最终仍然得到与输出相同的配对。对称语义搜索主要用于文本挖掘或意图分类任务。</p><p id="0762" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated">另一方面，<strong class="lb iu">不对称语义搜索</strong>围绕基于输入查询从语料库中寻找答案。例如，鉴于“什么是AI？”作为输入查询，您可能会期望输出类似“AI是一种模仿人类智能来执行任务的技术。他们可以根据获得的信息学习和提高自己的知识。”输入查询不仅限于问题。可以是关键词，也可以是短语。非对称语义搜索适用于搜索引擎相关的任务。</p></blockquote><p id="0f3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在撰写本文时，<code class="fe lv lw lx ly b">sentence-transformer</code>框架提供了以下用于多语言对称语义搜索的<a class="ae ky" href="https://www.sbert.net/docs/pretrained_models.html#model-overview" rel="noopener ugc nofollow" target="_blank">预训练模型</a>:</p><ul class=""><li id="e14a" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated"><code class="fe lv lw lx ly b">distiluse-base-multilingual-cased-v1</code>—15种语言通用语句编码器的多语言模型。</li><li id="90b0" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><code class="fe lv lw lx ly b">distiluse-base-multilingual-cased-v2</code>—50种语言通用语句编码器的多语言模型。</li><li id="5f5f" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><code class="fe lv lw lx ly b">paraphrase-multilingual-MiniLM-L12-v2 </code>—paraphrase-multilingual-MiniLM-L12-v2的多语言模型，扩展到50+种语言。</li><li id="853b" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated"><code class="fe lv lw lx ly b">paraphrase-multilingual-mpnet-base-v2 </code>—paraphrase-mpnet-base-v2的多语言模型，扩展到50+种语言。</li></ul><p id="3726" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实际上，我们可以利用这些模型来计算英语句子和西班牙语句子之间的相似度。例如，给定我们语料库中的以下句子:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="745d" class="lz ma it ly b gy nr ns l nt nu">What are you doing?<br/>I am a boy<br/>Can you help me?<br/>A woman is playing violin.<br/>The quick brown fox jumps over the lazy dog</span></pre><p id="71e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并输入如下查询:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="0b65" class="lz ma it ly b gy nr ns l nt nu">Qué estás haciendo</span></pre><p id="c9f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相似度最高的句子应该是:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="94ea" class="lz ma it ly b gy nr ns l nt nu">What are you doing?</span></pre><p id="dfa0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为简单起见，我们的对称语义搜索的工作流程如下:</p><ol class=""><li id="9398" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu nv nf ng nh bi translated">计算查询和语料库文本的嵌入</li><li id="7f9e" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu nv nf ng nh bi translated">计算两个嵌入之间的余弦相似度</li><li id="cb24" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu nv nf ng nh bi translated">查找具有最高相似性得分的前5个索引</li></ol><h1 id="9de7" class="nw ma it bd mb nx ny nz me oa ob oc mh jz od ka mk kc oe kd mn kf of kg mq og bi translated">设置</h1><p id="0aa6" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">在此之前，让我们创建一个新的虚拟环境，并安装所有必需的包。</p><h2 id="98ae" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">用pip安装</h2><p id="98a8" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">您可以轻松安装<code class="fe lv lw lx ly b">sentence-transformer</code>包:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="e1ca" class="lz ma it ly b gy nr ns l nt nu">pip install -U sentence-transformers</span></pre><h2 id="a24a" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">用康达安装</h2><p id="4cf3" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">对于Anaconda用户，您可以直接安装该软件包，如下所示:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="c613" class="lz ma it ly b gy nr ns l nt nu">conda install -c conda-forge sentence-transformers</span></pre><p id="01e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">继续下一节的实施。</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="8e4d" class="nw ma it bd mb nx ot nz me oa ou oc mh jz ov ka mk kc ow kd mn kf ox kg mq og bi translated">履行</h1><p id="4b6f" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">在您的工作目录中，创建一个名为<code class="fe lv lw lx ly b">main.py</code>的新Python文件。</p><h2 id="4d76" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">导入</h2><p id="bfcc" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">在文件顶部添加以下导入语句:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="e74b" class="lz ma it ly b gy nr ns l nt nu">from sentence_transformers import SentenceTransformer, util<br/>import torch</span></pre><h2 id="7f41" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">模型初始化</h2><p id="b4c3" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">然后，通过调用<code class="fe lv lw lx ly b">SentenceTransformer</code>类初始化模型，并传入所需模型的名称:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="cb13" class="lz ma it ly b gy nr ns l nt nu">model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')</span></pre><p id="4d8f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在初始运行期间，模块将下载预训练的模型文件，作为缓存在以下目录中:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="a9a7" class="lz ma it ly b gy nr ns l nt nu"># linux<br/>~/.cache/huggingface/transformers</span><span id="eb2b" class="lz ma it ly b gy oy ns l nt nu"># windows (replace username with your username)<br/>C:\Users\&lt;username&gt;\.cache\huggingface\transformers</span></pre><p id="9fc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以将缓存文件夹修改为当前工作目录，如下所示:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="385b" class="lz ma it ly b gy nr ns l nt nu"># save model in current directory<br/>model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', cache_folder='./')</span><span id="6967" class="lz ma it ly b gy oy ns l nt nu"># save model in models folder (you need to first create the folder)<br/>model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', cache_folder='./models/')</span></pre><p id="533c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于生产，您应该将模型移动到工作目录并在本地加载。例如，假设模型文件位于<code class="fe lv lw lx ly b">models</code>文件夹，您可以如下初始化您的模型:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="e5cf" class="lz ma it ly b gy nr ns l nt nu">model = SentenceTransformer('models/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2')</span></pre><p id="a453" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您在一台只有CPU的机器上进行测试，只需将<code class="fe lv lw lx ly b">device</code>参数设置为<code class="fe lv lw lx ly b">cpu</code>:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="7915" class="lz ma it ly b gy nr ns l nt nu">model = SentenceTransformer('models/sentence-transformers_paraphrase-multilingual-MiniLM-L12-v2', device='cpu')</span></pre><h2 id="f6a3" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">语料库和查询</h2><p id="95f6" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">接下来，初始化语料库和查询的数据。在这种情况下，我有一个7个字符串的列表作为<code class="fe lv lw lx ly b">corpus</code>数据，而<code class="fe lv lw lx ly b">queries</code>包含一个不同语言的3个字符串的列表。</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="d471" class="lz ma it ly b gy nr ns l nt nu">corpus = [<br/>'I am a boy',<br/>'What are you doing?',<br/>'Can you help me?',<br/>'A man is riding a horse.',<br/>'A woman is playing violin.',<br/>'A monkey is chasing after a goat',<br/>'The quick brown fox jumps over the lazy dog'<br/>]</span><span id="e120" class="lz ma it ly b gy oy ns l nt nu">queries = ['I am in need of assistance', '我是男孩子', 'Qué estás haciendo']</span></pre><h2 id="64b5" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">将数据编码到嵌入中</h2><p id="0cc7" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">调用<code class="fe lv lw lx ly b">encode</code>函数将语料库转换为嵌入。将<code class="fe lv lw lx ly b">convert_to_tensor</code>参数设置为<code class="fe lv lw lx ly b">True</code>以获取Python张量作为输出。同样，初始化一个名为<code class="fe lv lw lx ly b">top_k</code>的新变量，并将其赋值为最小值5和语料库的总长度。我们稍后将使用这个变量来获得具有最高相似性得分的索引。</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="cc58" class="lz ma it ly b gy nr ns l nt nu">corpus_embedding = model.encode(corpus, convert_to_tensor=True)</span><span id="9810" class="lz ma it ly b gy oy ns l nt nu">top_k = min(5, len(corpus))</span></pre><blockquote class="ms mt mu"><p id="2bc2" class="kz la mv lb b lc ld ju le lf lg jx lh mw lj lk ll mx ln lo lp my lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">encode</code>函数接受字符串列表或单个字符串作为输入。</p></blockquote><h2 id="c8d9" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">计算余弦相似度</h2><p id="59c5" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">最后一步是遍历查询中的所有项目，并执行以下操作:</p><ul class=""><li id="9a11" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">计算单个查询的嵌入。每个嵌入具有以下形状:<code class="fe lv lw lx ly b">torch.Size([384])</code></li><li id="c27f" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">调用<code class="fe lv lw lx ly b"> util.cos_sim</code>函数来获得输入查询和语料库之间的相似性得分</li><li id="f384" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">调用<code class="fe lv lw lx ly b">torch.topk</code>函数获得topk结果</li><li id="bd34" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">打印输出作为参考</li></ul><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="d061" class="lz ma it ly b gy nr ns l nt nu">for query in queries:<br/>    query_embedding = model.encode(query, convert_to_tensor=True)<br/><br/>    cos_scores = util.cos_sim(query_embedding, corpus_embedding)[0]<br/>    top_results = torch.topk(cos_scores, k=top_k)</span><span id="d789" class="lz ma it ly b gy oy ns l nt nu">    print("Query:", query)<br/>    print("---------------------------")<br/>    for score, idx in zip(top_results[0], top_results[1]):<br/>        print(f'{round(score.item(), 3)} | {corpus[idx]}')</span></pre><p id="bcc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe lv lw lx ly b">top_results</code>变量是一个元组，包含:</p><ul class=""><li id="6895" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">表示输入查询和语料库之间的相似性得分的张量阵列</li></ul><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="540e" class="lz ma it ly b gy nr ns l nt nu">tensor([ 0.3326,  0.2809,  0.2258, -0.0133, -0.0333])</span></pre><ul class=""><li id="5fce" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">表示输入查询索引的张量数组</li></ul><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="1507" class="lz ma it ly b gy nr ns l nt nu">tensor([2, 0, 1, 4, 3])</span></pre><p id="d1eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以在以下要点的<a class="ae ky" href="https://gist.github.com/wfng92/448b80bd8ad94ed255788c089c18f5f0" rel="noopener ugc nofollow" target="_blank">中找到完整的代码:</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h2 id="d5b9" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">输出</h2><p id="d3dd" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">运行该脚本时，您应该在终端上得到以下输出:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="6cb2" class="lz ma it ly b gy nr ns l nt nu">Query: I am in need of assistance<br/>---------------------------<br/>0.333 | Can you help me?<br/>0.281 | I am a boy<br/>0.226 | What are you doing?<br/>-0.013 | A woman is playing violin.<br/>-0.033 | A man is riding a horse.</span><span id="a54f" class="lz ma it ly b gy oy ns l nt nu">Query: 我是男孩子<br/>---------------------------<br/>0.919 | I am a boy<br/>0.343 | What are you doing?<br/>0.192 | Can you help me?<br/>0.058 | A monkey is chasing after a goat<br/>-0.001 | The quick brown fox jumps over the lazy dog</span><span id="eca4" class="lz ma it ly b gy oy ns l nt nu">Query: Qué estás haciendo<br/>---------------------------<br/>0.952 | What are you doing?<br/>0.396 | I am a boy<br/>0.209 | Can you help me?<br/>0.037 | A woman is playing violin.<br/>0.032 | The quick brown fox jumps over the lazy dog</span></pre></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="df17" class="nw ma it bd mb nx ot nz me oa ou oc mh jz ov ka mk kc ow kd mn kf ox kg mq og bi translated">最佳化</h1><p id="a1be" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">上面的实现对于小型语料库(低于100万个条目)非常有用。对于大型语料库，执行会相对较慢。因此，我们需要优化实现，以便它可以无缝地工作。一些最流行的优化技术包括:</p><ul class=""><li id="9bde" class="mz na it lb b lc ld lf lg li nb lm nc lq nd lu ne nf ng nh bi translated">归一化嵌入并使用点积作为得分函数</li><li id="49fe" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu ne nf ng nh bi translated">使用近似最近邻将语料库划分成相似嵌入的较小部分</li></ul><p id="d63e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了保持简单和简短，本教程将只涵盖第一种技术。当您规范化嵌入时，输出向量的长度将为1。因此，我们可以使用点积而不是余弦相似度来计算相似度得分。点积是一个更快的损失，你会得到相同的相似性分数。</p><h2 id="eccd" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">标准化嵌入</h2><p id="5a29" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">有两种方法可以标准化嵌入。第一种方法是在调用<code class="fe lv lw lx ly b">encode</code>函数时将<code class="fe lv lw lx ly b">normalize_embeddings</code>参数设置为<code class="fe lv lw lx ly b">True</code>。</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="6f65" class="lz ma it ly b gy nr ns l nt nu">corpus_embedding = model.encode(corpus, convert_to_tensor=True, <!-- -->normalize_embeddings<!-- -->=True)</span></pre><p id="0198" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，您可以利用<code class="fe lv lw lx ly b">util.normalize_embeddings</code>函数来规范化一个现有的嵌入:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="7733" class="lz ma it ly b gy nr ns l nt nu">corpus_embedding = model.encode(corpus, convert_to_tensor=True)<br/>corpus_embedding = util.normalize_embeddings(corpus_embedding)</span></pre><h2 id="daf6" class="lz ma it bd mb mc md dn me mf mg dp mh li mi mj mk lm ml mm mn lq mo mp mq mr bi translated">计算点积</h2><p id="284d" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">调用<code class="fe lv lw lx ly b">util.semantic_search</code>函数并传入<code class="fe lv lw lx ly b">util.dot_score</code>作为<code class="fe lv lw lx ly b">score_function</code>的输入参数。它将返回带有关键字<code class="fe lv lw lx ly b">corpus_id</code>和<code class="fe lv lw lx ly b">score</code>的字典列表。此外，该列表按余弦相似性得分递减排序。</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="eb27" class="lz ma it ly b gy nr ns l nt nu">hits = util.semantic_search(query_embedding, corpus_embedding, score_function=util.dot_score)</span></pre><p id="bab1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">修改后，<a class="ae ky" href="https://gist.github.com/wfng92/27f99e027cdbf8f14a6d18b99312897d" rel="noopener ugc nofollow" target="_blank">新的执行代码</a>应该如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="8d4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您运行脚本时，您应该得到与第一个实现相同的输出:</p><pre class="kj kk kl km gt nn ly no np aw nq bi"><span id="ae88" class="lz ma it ly b gy nr ns l nt nu">Query: I am in need of assistance<br/>---------------------------<br/>0.333 | Can you help me?<br/>0.281 | I am a boy<br/>0.226 | What are you doing?<br/>-0.013 | A woman is playing violin.<br/>-0.033 | A man is riding a horse.</span><span id="f6e9" class="lz ma it ly b gy oy ns l nt nu">Query: 我是男孩子<br/>---------------------------<br/>0.919 | I am a boy<br/>0.343 | What are you doing?<br/>0.192 | Can you help me?<br/>0.058 | A monkey is chasing after a goat<br/>-0.001 | The quick brown fox jumps over the lazy dog</span><span id="8982" class="lz ma it ly b gy oy ns l nt nu">Query: Qué estás haciendo<br/>---------------------------<br/>0.952 | What are you doing?<br/>0.396 | I am a boy<br/>0.209 | Can you help me?<br/>0.037 | A woman is playing violin.<br/>0.032 | The quick brown fox jumps over the lazy dog</span></pre></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="5ac2" class="nw ma it bd mb nx ot nz me oa ou oc mh jz ov ka mk kc ow kd mn kf ox kg mq og bi translated">结论</h1><p id="a2ab" class="pw-post-body-paragraph kz la it lb b lc oh ju le lf oi jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">让我们回顾一下你今天所学的内容。</p><p id="4478" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文首先简要介绍了<code class="fe lv lw lx ly b">sentence-transformer </code>模块。然后，比较了对称和非对称语义搜索的区别。</p><p id="afc4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随后，它介绍了设置和安装。<code class="fe lv lw lx ly b">sentence-transformer</code>可以安装<code class="fe lv lw lx ly b">pip</code>或<code class="fe lv lw lx ly b">conda</code>。</p><p id="11da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在实现部分，本文重点介绍了将语料库编码到嵌入中的步骤，以及使用余弦相似度计算相似度得分的步骤。</p><p id="496b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一节讨论优化技术。一种优化技术是将嵌入归一化为长度1，然后使用点积计算相似性得分。</p><p id="17d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你阅读这篇文章。祝你有美好的一天！</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="2677" class="nw ma it bd mb nx ot nz me oa ou oc mh jz ov ka mk kc ow kd mn kf ox kg mq og bi translated">参考</h1><ol class=""><li id="5a76" class="mz na it lb b lc oh lf oi li pb lm pc lq pd lu nv nf ng nh bi translated"><a class="ae ky" href="https://www.sbert.net/docs/installation.html" rel="noopener ugc nofollow" target="_blank">句子变压器—安装</a></li><li id="a63e" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu nv nf ng nh bi translated"><a class="ae ky" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">句子变压器—预训练模型</a></li><li id="c963" class="mz na it lb b lc ni lf nj li nk lm nl lq nm lu nv nf ng nh bi translated"><a class="ae ky" href="https://www.sbert.net/examples/applications/semantic-search/README.html" rel="noopener ugc nofollow" target="_blank"> SentenceTransformer —语义搜索</a></li></ol></div></div>    
</body>
</html>