<html>
<head>
<title>How Fast GPU Computation Can Be</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPU计算能有多快</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-fast-gpu-computation-can-be-41e8cff75974#2022-09-27">https://towardsdatascience.com/how-fast-gpu-computation-can-be-41e8cff75974#2022-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7ad5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python和PyTorch在CPU和GPU中的矩阵运算比较</h2></div><p id="1ca9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GPU计算增益比CPU快多少？在本文中，我将使用Python和PyTorch线性变换函数来测试它。</p><p id="dc29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是我的一些测试机器规格:</p><ul class=""><li id="d49c" class="le lf it kk b kl km ko kp kr lg kv lh kz li ld lj lk ll lm bi translated">CPU:英特尔i7 6700k (4c/8t)</li><li id="06d0" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">GPU: RTX 3070 TI (6，144个CUDA内核和192个张量内核)</li><li id="d56c" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">内存:32G</li><li id="0e1b" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld lj lk ll lm bi translated">操作系统:Windows 10</li></ul><h2 id="c5bf" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">NVIDIA GPU术语解释</h2><p id="b18b" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated"><strong class="kk iu"> CUDA </strong>是计算统一设备架构的缩写。可以用CUDA直接访问NVIDIA GPU指令集。</p><p id="e4b9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不像DirectX和OpenGL是为了构建游戏引擎而特意设计的，CUDA不需要用户理解复杂的图形编程语言。</p><p id="a27a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">张量核</strong>是加速矩阵乘法过程的处理单元。</p><p id="536a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如，使用CPU或CUDA将两个4×4矩阵相乘涉及64次乘法和48次加法，每个时钟周期一次运算，而张量核可以在每个时钟周期执行多次运算。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mq"><img src="../Images/6827c18568b4854771a6e2a81eae27c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EOo4lhtlrBkKQ6Jm.gif"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">来源:<a class="ae ng" href="https://www.nvidia.com/en-us/data-center/tensor-cores/" rel="noopener ugc nofollow" target="_blank">nvidia.com</a></p></figure><p id="5515" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在Nvidia开发者的YouTube频道的这个视频中有更多关于张量核的介绍。</p><p id="e32c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">CUDA核和张量核是什么关系？张量核心内置于CUDA核心中，这些神奇的核心将在满足<a class="ae ng" href="https://www.youtube.com/watch?v=i8-Jw48Cp8w&amp;ab_channel=NVIDIADeveloper" rel="noopener ugc nofollow" target="_blank">特定条件</a>时被触发。</p><h2 id="5383" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">测试方法</h2><p id="165e" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">GPU计算只在某些典型场景下比CPU快。其他情况下，GPU中的计算可以比CPU慢！</p><p id="ff80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于CUDA在并行矩阵乘法和加法方面的独特优势，它被广泛用于机器学习和深度学习。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nh"><img src="../Images/c78077afbef8c0e93d7511e4e64b7f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GYoe2Ncy4M8vrPsprtJ4rQ.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">来源:<a class="ae ng" href="https://developer.nvidia.com/" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/</a></p></figure><p id="0ad8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数学等式中:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/2c3522160b118182009c32a75324b054.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*ZVSV69-FVXThMETo0IiSbA.png"/></div></figure><p id="8dc9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">PyTorch的线性函数<code class="fe nj nk nl nm b">torch.nn.Linear</code>做完全相同的操作。例如，您可以通过以下代码将2x2矩阵转换为2x3矩阵:</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="3bf8" class="ls lt it nm b gy nr ns l nt nu">import torch</span><span id="a9d8" class="ls lt it nm b gy nv ns l nt nu">in_row,in_f,out_f = 2,2,3<br/>tensor            = torch.randn(in_row,in_f)<br/>l_trans           = torch.nn.Linear(in_f,out_f)<br/>print(l_trans(tensor))</span></pre><h2 id="3317" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">CPU基线</h2><p id="5ad3" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在测量GPU性能之前，我需要从CPU设置一个基准性能。</p><p id="f210" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了减轻芯片的负担，延长运行时间，我增加了<strong class="kk iu"> in_row </strong>、<strong class="kk iu"> in_f </strong>和<strong class="kk iu"> out_f </strong>的数量，还设置了循环操作<strong class="kk iu">10000次</strong>。</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="f524" class="ls lt it nm b gy nr ns l nt nu">import torch<br/>import torch.nn<br/>import time</span><span id="8a71" class="ls lt it nm b gy nv ns l nt nu">in_row, in_f, out_f = 256, 1024, 2048<br/>loop_times = 10000</span></pre><p id="4523" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们看看CPU完成10，000次转换需要多少秒:</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="2a54" class="ls lt it nm b gy nr ns l nt nu">s       = time.time()<br/>tensor  = torch.randn(in_row, in_f).to('cpu')<br/>l_trans = torch.nn.Linear(in_f, out_f).to('cpu')<br/>for _ in range(loop_times):<br/>    l_trans(tensor)<br/>print('cpu take time:',time.time()-s)</span></pre><p id="1184" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果:</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="c48a" class="ls lt it nm b gy nr ns l nt nu">cpu take time: <strong class="nm iu">55.70971965789795</strong></span></pre><p id="e415" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我i7 6700k用时55秒左右，说实话结果还不错。</p><h2 id="0fe0" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">在GPU中计算</h2><p id="bf09" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">为了让GPU的CUDA执行相同的计算，我只需将<code class="fe nj nk nl nm b">.to(‘cpu’)</code>替换为<code class="fe nj nk nl nm b">.cude()</code>。此外，考虑到CUDA中的操作是异步的，我还需要添加一个同步语句，以确保在所有CUDA任务完成后打印所用时间。</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="1584" class="ls lt it nm b gy nr ns l nt nu">s       = time.time()<br/>tensor  = torch.randn(in_row, in_f)<strong class="nm iu">.cuda()</strong><br/>l_trans = torch.nn.Linear(in_f, out_f)<strong class="nm iu">.cuda()</strong><br/>for _ in range(loop_times):<br/>    l_trans(tensor)</span><span id="4e0d" class="ls lt it nm b gy nv ns l nt nu"><strong class="nm iu">torch.cuda.synchronize()</strong><br/>print('CUDA take time:',time.time()-s)</span></pre><p id="40c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">代码更改突出显示，下面是运行结果:</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="4810" class="ls lt it nm b gy nr ns l nt nu">CUDA take time: <strong class="nm iu">1.327127456665039</strong></span></pre><p id="b984" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">几乎比运行在CPU中的<strong class="kk iu">快42x </strong>倍。一个模型在CPU需要几天的训练，现在在GPU可能只需要几个小时。这真的很快。</p><h2 id="5328" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">启用张量核心</h2><p id="6641" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">CUDA已经很快了，启用RTX 3070Ti的197个张量核怎么样？根据这个<a class="ae ng" href="https://www.youtube.com/watch?v=9tpLJpqxdE8&amp;ab_channel=NVIDIADeveloper" rel="noopener ugc nofollow" target="_blank">视频</a>，在PyTorch中，要启用张量核，我需要做的就是把浮点精度从FP32降低到FP16。</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="8dae" class="ls lt it nm b gy nr ns l nt nu">s       = time.time()<br/>tensor  = torch.randn(in_row, in_f).cuda()<strong class="nm iu">.half()</strong><br/>layer   = torch.nn.Linear(in_f, out_f).cuda()<strong class="nm iu">.half()</strong><br/>for _ in range(loop_times):<br/>    layer(tensor)</span><span id="0848" class="ls lt it nm b gy nv ns l nt nu">torch.cuda.synchronize()<br/>print('CUDA with tensor cores take time:',time.time()-s)</span></pre><p id="5e22" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">结果:</p><pre class="mr ms mt mu gt nn nm no np aw nq bi"><span id="04b7" class="ls lt it nm b gy nr ns l nt nu">CUDA with tensor cores take time:<strong class="nm iu">0.5381264686584473</strong></span></pre><p id="1c29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一个2.6倍的性能提升。</p><h2 id="ab29" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">结论</h2><p id="3e9b" class="pw-post-body-paragraph ki kj it kk b kl ml ju kn ko mm jx kq kr mn kt ku kv mo kx ky kz mp lb lc ld im bi translated">在本文中，我通过在<strong class="kk iu"> CPU、GPU CUDA和GPU CUDA +张量核</strong>中调用PyTorch线性变换函数来比较线性变换操作。下面是一个总结结果:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nw"><img src="../Images/da1cf1893aebaaaeed473103f7dc6b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YHJQxWKwoKptGfOthvWOng.png"/></div></div><p class="nc nd gj gh gi ne nf bd b be z dk translated">图片作者:安德鲁·朱</p></figure><p id="c951" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NVIDIA的CUDA和Tensor内核确实让矩阵乘法性能提升了不少。</p><h2 id="ac12" class="ls lt it bd lu lv lw dn lx ly lz dp ma kr mb mc md kv me mf mg kz mh mi mj mk bi translated">参考链接</h2><ol class=""><li id="4fbf" class="le lf it kk b kl ml ko mm kr nx kv ny kz nz ld oa lk ll lm bi translated"><a class="ae ng" href="http://www.eurorisksystems.com/documents/speed_up_of_numeric_calculations_using_GPU.pdf" rel="noopener ugc nofollow" target="_blank">使用图形处理单元(GPU)加速数值计算</a></li><li id="9d39" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld oa lk ll lm bi translated"><a class="ae ng" href="https://www.techcenturion.com/nvidia-cuda-cores/" rel="noopener ugc nofollow" target="_blank"> Nvidia CUDA核心解释:它们有什么不同？</a></li><li id="a1cf" class="le lf it kk b kl ln ko lo kr lp kv lq kz lr ld oa lk ll lm bi translated"><a class="ae ng" href="https://developer.nvidia.com/blog/video-mixed-precision-techniques-tensor-cores-deep-learning/" rel="noopener ugc nofollow" target="_blank">视频系列:使用张量核心进行深度学习的混合精度训练技术</a></li></ol></div></div>    
</body>
</html>