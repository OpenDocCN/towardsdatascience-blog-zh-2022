<html>
<head>
<title>How to Convert Your Custom Model into TensorRT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将您的自定义模型转换为TensorRT</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-convert-your-custom-model-into-tensorrt-5a2ea1dec2e4#2022-06-02">https://towardsdatascience.com/how-to-convert-your-custom-model-into-tensorrt-5a2ea1dec2e4#2022-06-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="cac1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">ML提示和技巧/ TPAT</h2><div class=""/><div class=""><h2 id="61f9" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">用TPAT缓解你紧张的疼痛</h2></div><p id="32a4" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果您曾经和TensorRT一起工作过，那么您可能会遇到类似的错误，对吗？</p><blockquote class="lk"><p id="e795" class="ll lm iq bd ln lo lp lq lr ls lt lj dk translated">[E] [TRT] UffParser:验证器错误:resize/ResizeNearestNeighbor:不支持的operation _ ResizeNearestNeighbor</p></blockquote><p id="1768" class="pw-post-body-paragraph ko kp iq kq b kr lu ka kt ku lv kd kw kx lw kz la lb lx ld le lf ly lh li lj ij bi translated">在这篇博客中，我们将向您展示如何将带有自定义运算符的模型转换成TensorRT，以及如何避免这些错误！</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/89249f8fc6ec39df645f933b8dd7f5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ije1eqpsiIPorinyyyisTw.jpeg"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">(图片来源:Rafael Pol 在<a class="ae mw" href="https://unsplash.com/s/photos/gpu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的<a class="ae mw" href="https://unsplash.com/es/@rapol?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"/></p></figure><p id="bc7c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi mx translated"><span class="l my mz na bm nb nc nd ne nf di">N</span><a class="ae mw" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank"><strong class="kq ja">vidia tensort</strong></a>是目前使用最广泛的GPU推理框架，能够优化使用<a class="ae mw" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>、<a class="ae mw" href="https://www.tensorflow.org/resources/learn-ml?gclid=CjwKCAjwv-GUBhAzEiwASUMm4mUCWNcxPcNSWSQcwKbcQwwDtZ67i_ugrmIBnJBp3rMBL5IA9gd0mhoC9Z8QAvD_BwE" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>、<a class="ae mw" href="https://mxnet.apache.org/versions/1.9.1/" rel="noopener ugc nofollow" target="_blank"> mxnet </a>或<a class="ae mw" href="https://github.com/PaddlePaddle/Paddle" rel="noopener ugc nofollow" target="_blank"> PaddlePaddle </a>构建的机器学习模型，以便在NVIDIA硬件上高效运行它们。众所周知，使用TensorRT图的<a class="ae mw" href="https://developer.nvidia.com/embedded/jetson-benchmarks" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja">推理与本地运行模型相比，显著提高了推理速度和吞吐量</strong> </a> <strong class="kq ja">。</strong></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/e996d950d2d2cb60ada2d1452eec10ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*c4d1mPSmqtKd5-zF.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">TensorRT代表了最流行的深度学习框架和NVIDIA硬件之间的桥梁(来源:<a class="ae mw" href="https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.html" rel="noopener ugc nofollow" target="_blank">https://docs . NVIDIA . com/deep learning/TensorRT/quick-start-guide/index . html</a>)</p></figure><p id="cb80" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">虽然使用tensort推理有很多好处，但是由于支持的操作符数量有限，<strong class="kq ja">真正的难点是手写tensort插件，以便支持在tensort中没有现成支持的自定义操作符</strong>。这使得部署过程变得不必要的复杂，并且可能需要几个小时甚至几天来优化和成功部署tensort模型，这需要编写多个定制tensort操作符。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="8671" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated"><strong class="ak"> TensorRT插件自动生成工具-TPAT </strong></h1><p id="2c2b" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">近日，<a class="ae mw" href="https://www.tencent.com/en-us/index.html" rel="noopener ugc nofollow" target="_blank">腾讯</a>和NVIDIA公布了<a class="ae mw" href="https://github.com/Tencent/TPAT" rel="noopener ugc nofollow" target="_blank"><strong class="kq ja">tensort Plugin Autogen工具——TPAT</strong></a>，这是一款开源工具，可以支持<a class="ae mw" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">开放神经网络交换(ONNX) </a>格式的所有运营商，<strong class="kq ja">端到端生成tensort插件。</strong></p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi oe"><img src="../Images/3bb9ef7c059e6934869f1e6d53228522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o1Ak8gGTzxIFZlPr.jpg"/></div></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">(来源:<a class="ae mw" href="https://www.tencent.com/en-us/media/library/images.html" rel="noopener ugc nofollow" target="_blank">https://www.tencent.com/en-us/media/library/images.html</a>)</p></figure><p id="2a0c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是一个真正的游戏规则改变者，我们在<a class="ae mw" href="http://forsight.ai" rel="noopener ugc nofollow" target="_blank"> Forsight </a>立即开始使用它，以便进一步优化我们ModelZoo中的一些模型，并从我们的硬件中挤出更多的性能。</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><p id="18f5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">TPAT实现了TensorRT插件的自动生成，TensorRT型号的<strong class="kq ja">部署可以简化，不再需要人工干预。</strong></p><p id="45ba" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">TPAT需要的唯一输入是ONNX模型和定制操作符的名称映射。<strong class="kq ja">TPAT优化过程基于</strong> <a class="ae mw" href="https://tvm.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kq ja"> TVM深度学习编译器</strong> </a> <strong class="kq ja">，对定形算子进行自动调优，自动生成高性能CUDA内核。</strong>必要的CUDA内核和运行时参数写在TensorRT插件模板中，用来生成动态链接库，可以直接加载到TensorRT中运行。</p><p id="c7bb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">TPAT确实是一个神奇的工具，因为它提供了以下优于手写插件和本地TensorRT操作符的优势:</p><p id="6a25" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">⦁ <strong class="kq ja">改善运营商覆盖:</strong>支持ONNX、Tensorflow和PyTorch的所有运营商</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="of og l"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">支持TPAT的运营商列表(来源:<a class="ae mw" href="https://github.com/Tencent/TPAT/blob/main/docs/Operators.md" rel="noopener ugc nofollow" target="_blank">https://github.com/Tencent/TPAT/blob/main/docs/Operators.md</a></p></figure><p id="428e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">⦁ <strong class="kq ja">全自动化</strong>:端到端全自动生成用户指定的tensorrt插件</p><p id="0f91" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">⦁ <strong class="kq ja">高性能</strong>:大部分操作者的性能都超过了手写或原装tensorrt插件</p><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="of og l"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">TPAT vs手写插件性能对比(来源:<a class="ae mw" href="https://github.com/Tencent/TPAT/blob/main/docs/Compare_handwritten.md" rel="noopener ugc nofollow" target="_blank">https://github . com/腾讯/TPAT/blob/main/docs/Compare _ handled . MD</a>)</p></figure><figure class="mh mi mj mk gt ml"><div class="bz fp l di"><div class="of og l"/></div><p class="ms mt gj gh gi mu mv bd b be z dk translated">TPAT与原生TensorRT插件性能对比(来源:<a class="ae mw" href="https://github.com/Tencent/TPAT/blob/main/docs/Optimize_TensorRT.md" rel="noopener ugc nofollow" target="_blank">https://github . com/腾讯/TPAT/blob/main/docs/Optimize _ TensorRT . MD</a>)</p></figure></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="b971" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">在NVIDIA Jetson AGX Xavier上使用TPAT</h1><p id="e57b" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">为了使用TPAT和TensorRT优化您的模型，并在<a class="ae mw" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/" rel="noopener ugc nofollow" target="_blank"> NVIDIA Jetson AGX Xavier </a>上运行它，您应该使用以下Docker文件而不是TPAT报告中包含的<a class="ae mw" href="https://github.com/Tencent/TPAT/blob/main/Dockerfile" rel="noopener ugc nofollow" target="_blank">文件来成功构建TPAT Docker映像。</a></p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="3520" class="om ni iq oi b gy on oo l op oq">FROM nvcr.io/nvidia/l4t-tensorflow:r32.4.4-tf1.15-py3</span><span id="8f6c" class="om ni iq oi b gy or oo l op oq">RUN apt-get update &amp;&amp; apt-get install build-essential cmake -y</span><span id="e3c0" class="om ni iq oi b gy or oo l op oq">RUN wget -O "clang+llvm-9.0.1-aarch64-linux-gnu.tar.xz" https://github.com/llvm/llvm-project/releases/download/llvmorg-9.0.1/clang+llvm-9.0.1-aarch64-linux-gnu.tar.xz \</span><span id="8b87" class="om ni iq oi b gy or oo l op oq">&amp;&amp; tar -xvf clang+llvm-9.0.1-aarch64-linux-gnu.tar.xz &amp;&amp; mkdir -p /usr/local/llvm/ \</span><span id="06e0" class="om ni iq oi b gy or oo l op oq">&amp;&amp; mv clang+llvm-9.0.1-aarch64-linux-gnu/* /usr/local/llvm/</span><span id="8692" class="om ni iq oi b gy or oo l op oq">RUN python3 -m pip install --upgrade pip</span><span id="5437" class="om ni iq oi b gy or oo l op oq">RUN pip3 install buildtools onnx==1.10.0</span><span id="7fd8" class="om ni iq oi b gy or oo l op oq">RUN pip3 install pycuda nvidia-pyindex</span><span id="2b9c" class="om ni iq oi b gy or oo l op oq">RUN apt-get install git</span><span id="8f54" class="om ni iq oi b gy or oo l op oq">RUN pip install onnx-graphsurgeon onnxruntime==1.9.0 tf2onnx xgboost==1.5.2</span><span id="8414" class="om ni iq oi b gy or oo l op oq">RUN git clone --recursive https://github.com/Tencent/TPAT.git /workspace/TPAT &amp;&amp; cd /workspace/TPAT/3rdparty/blazerml-tvm &amp;&amp; mkdir build &amp;&amp; cp cmake/config.cmake build &amp;&amp; cd build</span><span id="dc4b" class="om ni iq oi b gy or oo l op oq">RUN sed -i 's/set(USE_LLVM OFF)/set(USE_LLVM \/usr\/local\/llvm\/bin\/llvm-config)/g' /workspace/TPAT/3rdparty/blazerml-tvm/build/config.cmake</span><span id="ad3e" class="om ni iq oi b gy or oo l op oq">RUN sed -i 's/set(USE_CUDA OFF)/set(USE_CUDA ON)/g' /workspace/TPAT/3rdparty/blazerml-tvm/build/config.cmake</span><span id="059f" class="om ni iq oi b gy or oo l op oq">RUN cd /workspace/TPAT/3rdparty/blazerml-tvm/build/ &amp;&amp; cmake .. &amp;&amp; make -j8</span><span id="42e6" class="om ni iq oi b gy or oo l op oq">ENV TVM_HOME="/workspace/TPAT/3rdparty/blazerml-tvm/"</span><span id="9f54" class="om ni iq oi b gy or oo l op oq">ENV PYTHONPATH="$TVM_HOME/python:${PYTHONPATH}"</span></pre><p id="fd27" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">您可以使用以下命令构建Docker映像:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="6edc" class="om ni iq oi b gy on oo l op oq">sudo docker build . -t tpat:master</span></pre><p id="74d5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="os">注意:您应该连接外部存储器，并在那里构建docker映像，因为映像本身相当大，而AGX的内置内存有限。</em></p><p id="ce7e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">成功构建映像后，您可以使用以下命令运行Docker容器:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="4eeb" class="om ni iq oi b gy on oo l op oq">sudo docker run --gpus all --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -it tpat:master</span></pre><p id="bcbc" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">启动容器后，您应该<strong class="kq ja">确保您的TPAT Makefile中的计算能力对应于您的设备的计算能力</strong>。为了在Jetson AGX Xavier上成功构建TPAT插件，你应该在这个<a class="ae mw" href="https://github.com/Tencent/TPAT/blob/6380a44ed1c2c35c97dc30768835197bfb79eeb1/python/trt_plugin/Makefile#L68" rel="noopener ugc nofollow" target="_blank">行</a>上用<code class="fe ot ou ov oi b">-arch=sm_72</code>替换<code class="fe ot ou ov oi b">-arch=sm_75</code>。</p><p id="7b43" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">现在你应该已经拥有了使用TPAT为你的模型自动生成定制插件所需的一切！</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="7a0e" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">如何使用TPAT生成一个自定义的TensorRT插件？</h1><p id="ba1c" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated">为了在Jetson Xavier AGX上使用TPAT优化模型中的某些运算符，请遵循以下步骤。</p><p id="b836" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">首先，您应该运行需要以下参数的<code class="fe ot ou ov oi b">onnx_to_plugin.py</code>脚本:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="480d" class="om ni iq oi b gy on oo l op oq">usage: onnx_to_plugin.py [-h] -i INPUT_MODEL_PATH -o OUTPUT_MODEL_PATH<br/>                         [-n [NODE_NAMES [NODE_NAMES ...]]]<br/>                         [-t [NODE_TYPES [NODE_TYPES ...]]]<br/>                         [-p PLUGIN_NAME_DICT]</span><span id="ef2f" class="om ni iq oi b gy or oo l op oq">optional arguments:<br/>  -h, --help            show this help message and exit<br/>  -i INPUT_MODEL_PATH, --input_model_path INPUT_MODEL_PATH<br/>                        Please provide input onnx model path<br/>  -o OUTPUT_MODEL_PATH, --output_model_path OUTPUT_MODEL_PATH<br/>                        Please provide output onnx model path which used for<br/>                        tensorrt<br/>  -n [NODE_NAMES [NODE_NAMES ...]], --node_names [NODE_NAMES [NODE_NAMES ...]]<br/>                        Please provide the operator name that needed to<br/>                        generate tensorrt-plugin<br/>  -t [NODE_TYPES [NODE_TYPES ...]], --node_types [NODE_TYPES [NODE_TYPES ...]]<br/>                        Please provide the operator type that needed to<br/>                        generate tensorrt-plugin<br/>  -p PLUGIN_NAME_DICT, --plugin_name_dict PLUGIN_NAME_DICT<br/>                        Please provide the dict of op name and plugin name<br/>                        that will be generated by TPAT, such as : {"op_name" :<br/>                        "plugin_name"}</span></pre><p id="0106" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们提供了一个示例命令，该命令优化了<code class="fe ot ou ov oi b">model.onnx</code>图中的<code class="fe ot ou ov oi b">loop_function_1/OneHotEncoding/one_hot</code>运算符，并输出包含优化后的<code class="fe ot ou ov oi b">tpat_onehot</code>运算符的<code class="fe ot ou ov oi b">model_tpat.onnx</code>图:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="fee6" class="om ni iq oi b gy on oo l op oq">OPENBLAS_CORETYPE=ARMV8 python3 onnx_to_plugin.py \<br/> -i “model.onnx” \<br/> -o “model_tpat.onnx” \ <br/> -p “{\”loop_function_1/OneHotEncoding/one_hot\” : \”tpat_onehot\”}”</span></pre><p id="bce6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="kq ja">运行该命令的结果是一个优化的ONNX图，其中不支持的操作符被TPAT生成的操作符替换。</strong>你可以在<code class="fe ot ou ov oi b">TPAT/python/trt_plugin/lib/</code>中找到TPAT生成算子动态库，应该命名为<code class="fe ot ou ov oi b">tpat_onehot.so</code>。</p><p id="2cf1" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="os">注意:您应该在运行TPAT转换脚本的命令前添加</em> <code class="fe ot ou ov oi b"><em class="os">OPENBLAS_CORETYPE=ARMV8</em></code> <em class="os">，以修复Jetson Xavier AGX设备上发生的</em> <a class="ae mw" href="https://github.com/numpy/numpy/issues/18131" rel="noopener ugc nofollow" target="_blank"> <em class="os">问题</em> </a> <em class="os">。</em></p><div class="mh mi mj mk gt ab cb"><figure class="ow ml ox oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/e3c5429c2db0433866b72a1cd53978d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*4svQm9byWsS-965zZPwt7Q.png"/></div></figure><figure class="ow ml pc oy oz pa pb paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><img src="../Images/31416419e49a977346d220e461412304.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*WNL_keFslk_cNbrLqi5uew.png"/></div><p class="ms mt gj gh gi mu mv bd b be z dk pd di pe pf translated">model.onnx图中的OneHot运算符与model_tpat.onnx图中的tpat_onehot运算符(来源:作者使用<a class="ae mw" href="https://netron.app/" rel="noopener ugc nofollow" target="_blank"> Netron </a>生成的图片)</p></figure></div></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="d397" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">将TPAT-翁克斯图优化成张量图</h1><p id="944e" class="pw-post-body-paragraph ko kp iq kq b kr nz ka kt ku oa kd kw kx ob kz la lb oc ld le lf od lh li lj ij bi translated"><code class="fe ot ou ov oi b">trtexec</code>是一款无需开发自己的应用程序即可快速利用TensorRT的工具。<code class="fe ot ou ov oi b">trtexec</code>工具有三个主要用途:</p><ul class=""><li id="ade8" class="pg ph iq kq b kr ks ku kv kx pi lb pj lf pk lj pl pm pn po bi translated">根据随机或用户提供的输入数据对网络进行基准测试。</li><li id="f8d2" class="pg ph iq kq b kr pp ku pq kx pr lb ps lf pt lj pl pm pn po bi translated">从模型生成序列化引擎。</li><li id="aea6" class="pg ph iq kq b kr pp ku pq kx pr lb ps lf pt lj pl pm pn po bi translated">从生成器生成序列化定时缓存。</li></ul><div class="pu pv gp gr pw px"><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#trtexec-ovr" rel="noopener  ugc nofollow" target="_blank"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">开发人员指南::NVIDIA深度学习TensorRT文档</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">本NVIDIA TensorRT开发人员指南演示了如何使用C++和Python APIs来实现最常见的…</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">docs.nvidia.com</p></div></div><div class="qg l"><div class="qh l qi qj qk qg ql mq px"/></div></div></a></div><p id="5ead" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以使用下面的<code class="fe ot ou ov oi b">trtexec</code>命令将模型转换成TensorRT平面图格式:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="c2e1" class="om ni iq oi b gy on oo l op oq">trtexec --onnx=model_tpat.onnx \<br/>        --saveEngine=model.plan \<br/>       --buildOnly --verbose --fp16 \<br/>       --workspace=6000 --noTF32 \<br/>       --plugins=”./python/trt_plugin/lib/tpat_onehot.so”</span></pre><p id="9ff2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="os">请注意，您必须提供TPAT优化运算符的路径。</em></p><p id="81cb" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">成功转换模型后，您可以使用以下命令来测量TensorRT模型性能:</p><pre class="mh mi mj mk gt oh oi oj ok aw ol bi"><span id="091b" class="om ni iq oi b gy on oo l op oq">trtexec --loadEngine=model.plan \<br/>        --verbose --workspace=4096 \ <br/>        --streams=16 --threads \<br/>        --plugins=”./python/trt_plugin/lib/tpat_onehot.so”</span></pre><p id="5af2" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">就这样，您已经<strong class="kq ja">使用TPAT成功转换了tensort不支持的运算符，并优化了tensort图</strong>。你可以尝试这个过程，并在评论中分享你的见解和结果！</p></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><blockquote class="qm qn qo"><p id="fbd6" class="ko kp os kq b kr ks ka kt ku kv kd kw qp ky kz la qq lc ld le qr lg lh li lj ij bi translated">我们希望这篇博客对你有用，请看看我们团队在Forsight写的其他一些博客，如果你有任何问题，请随时通过<strong class="kq ja"> info@forsight.ai </strong>联系我们！</p></blockquote><div class="pu pv gp gr pw px"><a rel="noopener follow" target="_blank" href="/new-tf2-object-detection-api-5c6ea8362a8c"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">新TF2对象检测API</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">欢迎新动物进入动物园——模型评估</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">towardsdatascience.com</p></div></div><div class="qg l"><div class="qs l qi qj qk qg ql mq px"/></div></div></a></div><div class="pu pv gp gr pw px"><a href="https://medium.com/swlh/construction-feat-tf2-object-detection-api-4465a3937c87" rel="noopener follow" target="_blank"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">建筑壮举。TF2对象检测API</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">你受到保护了吗？</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">medium.com</p></div></div><div class="qg l"><div class="qt l qi qj qk qg ql mq px"/></div></div></a></div><div class="pu pv gp gr pw px"><a rel="noopener follow" target="_blank" href="/understand-your-algorithm-with-grad-cam-d3b62fce353"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">使用Grad-CAM了解您的算法</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">当AI是一个黑匣子时，我们为什么要足够信任它来驾驶汽车，检测疾病，识别嫌疑人？</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">towardsdatascience.com</p></div></div><div class="qg l"><div class="qu l qi qj qk qg ql mq px"/></div></div></a></div><div class="pu pv gp gr pw px"><a rel="noopener follow" target="_blank" href="/generalizing-your-model-an-example-with-efficientnetv2-and-cats-dogs-6903740dfe2c"><div class="py ab fo"><div class="pz ab qa cl cj qb"><h2 class="bd ja gy z fp qc fr fs qd fu fw iz bi translated">推广你的模型:EfficientNetV2和猫和狗的例子</h2><div class="qe l"><h3 class="bd b gy z fp qc fr fs qd fu fw dk translated">考虑一下这个场景。你正在使用新的花式最先进的CNN网络架构，EfficientNetV2，来训练…</h3></div><div class="qf l"><p class="bd b dl z fp qc fr fs qd fu fw dk translated">towardsdatascience.com</p></div></div><div class="qg l"><div class="qv l qi qj qk qg ql mq px"/></div></div></a></div></div><div class="ab cl lz ma hu mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="ij ik il im in"><h1 id="c778" class="nh ni iq bd nj nk nl nm nn no np nq nr kf ns kg nt ki nu kj nv kl nw km nx ny bi translated">参考</h1><ol class=""><li id="4f08" class="pg ph iq kq b kr nz ku oa kx qw lb qx lf qy lj qz pm pn po bi translated">https://github.com/Tencent/TPAT-TensorRT插件自动生成工具(<a class="ae mw" href="https://github.com/Tencent/TPAT" rel="noopener ugc nofollow" target="_blank">)</a></li><li id="1a4a" class="pg ph iq kq b kr pp ku pq kx pr lb ps lf pt lj qz pm pn po bi translated">腾讯和英伟达开源TensorRT插件自动生成工具TPAT(<a class="ae mw" href="https://www.codetd.com/en/article/13743533" rel="noopener ugc nofollow" target="_blank">https://www.codetd.com/en/article/13743533</a>)</li></ol></div></div>    
</body>
</html>