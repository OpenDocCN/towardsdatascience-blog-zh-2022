<html>
<head>
<title>Programming Intel Arc Xe Matrix Extensions (XMX) with oneAPI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用oneAPI对英特尔Arc Xe矩阵扩展(XMX)进行编程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/utilizing-intel-arc-xe-matrix-extensions-xmx-using-oneapi-bd39479c9555#2022-10-14">https://towardsdatascience.com/utilizing-intel-arc-xe-matrix-extensions-xmx-using-oneapi-bd39479c9555#2022-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ed8f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用joint_matrix API推动最新的英特尔加速技术</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/39569144ffa5a80c168171282b46f42f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQZ4BCauXfCJV-EHrITx2w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供</p></figure><h1 id="91b3" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">介绍</h1><p id="c4fb" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">随着<a class="ae mj" href="https://www.intel.com/content/www/us/en/products/details/discrete-gpus/arc.html" rel="noopener ugc nofollow" target="_blank">英特尔Arc图形</a>桌面GPU的发布，开发人员有了一些新的硬件加速器选项。作为一名英特尔软件架构师和性能发烧友，我首先想到的总是如何使用新硬件更快地解决我的问题。对于Arc，我首先想尝试的是英特尔Xᵉ矩阵扩展(XMX)硬件及其专用矩阵引擎。</p><h2 id="47e0" class="mk kw iq bd kx ml mm dn lb mn mo dp lf lw mp mq lh ma mr ms lj me mt mu ll mv bi translated">为什么这很重要？</h2><p id="f5c8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated"><a class="ae mj" href="https://www.tensorflow.org/guide/tensor" rel="noopener ugc nofollow" target="_blank">张量</a>运算是深度学习工作负载的核心。英特尔XMX的基本加速功能之一是执行矩阵运算的专用硬件，更高级的张量运算分解成矩阵运算。对于大多数AI最终用户来说，Tensorflow和PyTorch将是我们使用这种硬件的软件中的级别。然而，像我一样的另一类用户/开发人员也在考虑这个问题，并想，我如何能直接对这个新硬件进行编程，并将其用于其他目的？</p><h1 id="30ec" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">oneAPI联合矩阵</h1><p id="1ee9" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">和大多数硬件一样，有几种方法可以为XMX加速器编程。可以写GPU汇编，也可以用GPU内函数。对于你们这些勇敢的人，我建议你们参考<a class="ae mj" href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-gpu-optimization-guide/top.html" rel="noopener ugc nofollow" target="_blank"> oneAPI GPU优化指南</a>作为起点。我想尝试更简单的方法。对我们来说幸运的是，有一个实验性的<a class="ae mj" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html" rel="noopener ugc nofollow" target="_blank"> oneAPI </a>扩展<a class="ae mj" href="https://github.com/intel/llvm/blob/sycl/sycl/doc/extensions/experimental/sycl_ext_oneapi_matrix.asciidoc" rel="noopener ugc nofollow" target="_blank"> joint_matrix </a>，它允许我们使用更高级别的API对硬件进行编程。</p><p id="3c4c" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">除了支持英特尔硬件，joint_matrix C++ API还允许我们在各种硬件上执行矩阵运算。从<a class="ae mj" href="https://github.com/intel/llvm/blob/sycl/sycl/doc/extensions/experimental/sycl_ext_oneapi_matrix.asciidoc#introduction" rel="noopener ugc nofollow" target="_blank">关节_矩阵简介</a>:</p><blockquote class="nb nc nd"><p id="6bca" class="ln lo ne lp b lq mw jr ls lt mx ju lv nf my ly lz ng mz mc md nh na mg mh mi ij bi translated">这个接口意在统一不同的张量硬件:CPU中的Intel AMX，Habana Gaudi和Goya张量和gemm内核，Nvidia TPUs，IBM Power MMA。所有这些硬件都提供了低级内部函数或汇编来访问和执行矩阵运算。我们的目标是提供一个统一的接口，这个接口是可移植的，但也能从这些不同硬件所能提供的最大性能中获益。</p></blockquote><h1 id="572f" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">有趣的部分:测试英特尔Arc A750</h1><p id="6c6c" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我有一个全新的英特尔Arc A750卡，我刚刚将它放入我的个人英特尔Alder Lake Core i9–12900 KF外星人R13系统。我碰巧也在使用Windows，所以如果您使用Linux或WSL，下面的说明可能会略有不同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/a17747a79614c428d87f942273d82449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrZQLm5uGoNP4JL1lqucWg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供</p></figure><h2 id="2e05" class="mk kw iq bd kx ml mm dn lb mn mo dp lf lw mp mq lh ma mr ms lj me mt mu ll mv bi translated">分解联合矩阵矩阵乘法的例子</h2><p id="cc41" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">我的目标只是用一些简单的矩阵运算来锻炼硬件。我从英特尔llvm测试套件中的<a class="ae mj" href="https://github.com/intel/llvm-test-suite/blob/intel/SYCL/Matrix/joint_matrix_bfloat16.cpp" rel="noopener ugc nofollow" target="_blank">开始，它使用bfloat16运行硬件加速矩阵乘法，并确保输出与使用简单CPU矩阵乘法相同。</a></p><p id="c3ba" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">我稍微修改了一下测试，以输出矩阵乘法运行在哪个加速器硬件上。下面是用于执行启用了joint_matrix的矩阵乘法的代码片段:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="d443" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">以下是代码中需要注意的一些高级内容:</p><ul class=""><li id="3194" class="nl nm iq lp b lq mw lt mx lw nn ma no me np mi nq nr ns nt bi translated">第1–11行:big_matrix类允许我们表示任意大小的矩阵。</li><li id="b539" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第23–27行:设备选择器显示了算法运行在哪个加速器上</li></ul><p id="2c2c" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">由于大矩阵并不总是适合硬件，所以矩阵乘法操作是通过将要相乘的两个矩阵分解成子组，然后将这些子组相乘的结果累加成输出矩阵的适当部分来执行的。操作与我们做简单的矩阵乘法时相同，只是顺序略有不同，因为我们在移动到下一行之前不会遍历整个列空间。</p><p id="a853" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">矩阵乘法如何发生的核心分解如下:</p><ul class=""><li id="edf2" class="nl nm iq lp b lq mw lt mx lw nn ma no me np mi nq nr ns nt bi translated">第36行:parallel_for基于二维nd_range分割工作——这就是我们如何在矩阵空间中行走。</li><li id="c24a" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第49–56行:sub_a、sub_b、sub_c被初始化。由于硬件无法将整个矩阵保存在内存中，因此该算法使用joint_matrix API将部分矩阵加载到硬件加速器+寄存器中。sub_a和sub_b是被相乘的矩阵的片段，sub_c是我们的目标输出矩阵</li><li id="8511" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第58行:使用joint_matrix_fill API不从内存加载值，而是直接将寄存器初始化为一个值。在这种情况下，我将寄存器初始化为0。</li><li id="9725" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第64–71行:载入矩阵的部分以相乘并累加到我们的输出矩阵中</li><li id="d571" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第72行:使用XMX加速器，使用sub_a和sub_b作为输入，sub_c作为目标，执行矩阵乘法和加法</li><li id="6ff2" class="nl nm iq lp b lq nu lt nv lw nw ma nx me ny mi nq nr ns nt bi translated">第74–77行:将这部分矩阵计算的进行中的输出值存储回内存</li></ul><p id="d457" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">作为参考，下面是我完整的<a class="ae mj" href="https://gist.github.com/tonym97/783c8ba9cc29b67370648d9883f8de00" rel="noopener ugc nofollow" target="_blank">joint _ matrix _ bfloat 16 _ modified . CPP</a></p><h2 id="f0ef" class="mk kw iq bd kx ml mm dn lb mn mo dp lf lw mp mq lh ma mr ms lj me mt mu ll mv bi translated">测试加速器矩阵乘法</h2><p id="dd09" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">由于这是对oneAPI的实验性扩展，因此需要<a class="ae mj" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-compiler.html" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI DPC++/C++编译器</a>。我使用的是来自<a class="ae mj" href="https://intel.com/content/www/us/en/developer/articles/news/oneapi-2022-3-available.html" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI基础工具包2022.3 </a>版本的最新版本。</p><p id="a4bd" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">该功能自2022.1版本起就已启用，但一些命名空间已更新。例如，以下命名空间从前者更新为后者:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="a5a6" class="mk kw iq oa b gy oe of l og oh">sycl::ext::intel::experimental::bfloat16<br/>sycl::ext::oneapi::experimental::bfloat16</span></pre><p id="2cac" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">要编译此示例，请在安装<a class="ae mj" href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit.html" rel="noopener ugc nofollow" target="_blank">英特尔oneAPI基础工具包</a>并遵循<a class="ae mj" href="https://www.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/oneapi-development-environment-setup/use-the-setvars-script-with-windows.html" rel="noopener ugc nofollow" target="_blank">环境配置步骤</a>后运行以下命令:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="0c23" class="mk kw iq oa b gy oe of l og oh">&gt; icx /EHsc /fsycl joint_matrix_bfloat16_modified.cpp</span></pre><p id="cdc0" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">编译完代码后，我们只需运行可执行文件:</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="b0ca" class="mk kw iq oa b gy oe of l og oh">&gt; joint_matrix_bfloat16_modified.exe<br/>Running on device: Intel(R) Arc(TM) A750 Graphics<br/>Elapsed time in milliseconds (accelerated): 142 ms<br/>Elapsed time in milliseconds (reference): 2118 ms<br/>passed</span></pre><p id="e73c" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">我们可以看到，使用英特尔Arc GPU在142毫秒内执行了矩阵乘法，非加速版本在CPU上运行了2118毫秒。请注意，如果您尝试在支持矩阵运算的硬件上运行加速版本，API定义的当前行为是报告由于缺少支持的矩阵加速器硬件而导致的故障。这可以防止用户在不知不觉中使用较慢的回退矩阵实现，而不是硬件加速版本。</p><h1 id="3d2f" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">启用多个加速器</h1><p id="22c7" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">joint_matrix API不仅仅是为了抽象的可移植性而设计的。最新的英特尔DPC++编译器支持英特尔XMX、英特尔高级矩阵扩展(AMX)和NVIDIA Tensor内核。对于那些不熟悉的人，AMX是用于矩阵乘法加速的新x86指令集，它利用了内置于即将推出的第四代英特尔至强可扩展处理器中的硬件。如果你对张量核感兴趣，这里有一个例子你可以编译运行<a class="ae mj" href="https://github.com/intel/llvm-test-suite/blob/intel/SYCL/Matrix/joint_matrix_tensorcore.cpp" rel="noopener ugc nofollow" target="_blank">这里</a>。它确实需要开源的<a class="ae mj" href="https://intel.github.io/llvm-docs/GetStartedGuide.html" rel="noopener ugc nofollow" target="_blank">英特尔DPC++编译器和NVIDIA后端支持</a>，以及安装NVIDIA CUDA，所以我将把它留到一个单独的帖子中。</p><p id="65c8" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">有关joint_matrix API启用的其他功能的更多详细信息，请参见API文档:</p><div class="oi oj gp gr ok ol"><a href="https://github.com/intel/llvm/blob/sycl/sycl/doc/extensions/experimental/sycl_ext_oneapi_matrix.asciidoc" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd ir gy z fp oq fr fs or fu fw ip bi translated">llvm/sycl _ ext _ one API _ matrix . asciidoc在这样的英特尔/llvm</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">版权所有(c) 2021-2021英特尔公司保留所有权利。Khronos是SYCL和SPIR的注册商标</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">github.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz kp ol"/></div></div></a></div><h1 id="312b" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">结论</h1><p id="f499" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">新的硬件能力意味着新的编程抽象。这些抽象可能存在于许多层次。虽然joint_matrix是一种直接对硬件编程的方法，但在未来的帖子中，我将讨论oneAPI库和TensorFlow和PyTorch等流行AI/ML框架的英特尔实施如何利用XMX和AMX等矩阵加速器。</p><p id="dab5" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated">如果您已经做到这一步，您可能像我一样希望对硬件进行细粒度的控制，这就是为什么像joint_matrix这样的API令人兴奋的原因。joint_matrix API是可用的，可以帮助您利用一些新的matrix硬件。我鼓励您下载工具链，尝试一下API，并提供反馈来帮助构建这个令人兴奋的跨供应商matrix API。</p><p id="6763" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated"><em class="ne">如果你想看看我在看什么科技新闻，你可以在Twitter上关注我。</em></p><p id="c763" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated"><em class="ne"> Tony是英特尔的一名软件架构师和技术宣传员。他开发过多种软件开发工具，最近领导软件工程团队构建了数据中心平台，实现了Habana的可扩展MLPerf解决方案。</em></p><p id="afd9" class="pw-post-body-paragraph ln lo iq lp b lq mw jr ls lt mx ju lv lw my ly lz ma mz mc md me na mg mh mi ij bi translated"><em class="ne">英特尔、英特尔标志和其他英特尔标志是英特尔公司或其子公司的商标。</em></p></div></div>    
</body>
</html>