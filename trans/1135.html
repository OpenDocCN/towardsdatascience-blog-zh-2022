<html>
<head>
<title>I’ve Trained My First Machine Learning Models: Here’s How It’s Gone</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我已经训练了我的第一个机器学习模型:下面是它是如何进行的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ive-trained-my-first-machine-learning-model-and-i-got-sad-8abdc0c5b72b#2022-03-23">https://towardsdatascience.com/ive-trained-my-first-machine-learning-model-and-i-got-sad-8abdc0c5b72b#2022-03-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a966" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一些最大似然算法的概述和一些个人的思考</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/096eef9af9600e77f441aa78eef40ba6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A_xKKGc5Tgjon9N4TYyxrw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·温克勒在<a class="ae ky" href="https://unsplash.com/s/photos/machine-learning?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b079" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我训练了我的第一个机器学习模型！是啊！最终，我做到了。球场上有太多的炒作，我没有看到最终做这件事的时间。</p><p id="a7d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但也许这就是我最初难过的原因:也许，赛场上的炒作太多了。</p><p id="992f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在 2021 年 3 月左右开始学习数据科学和编程，当时我是:</p><ul class=""><li id="21de" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">为我的机械工程学士学位的最后一次考试而学习</li><li id="1687" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">为我的论文而学习，这当然依赖于数据科学</li><li id="9ca6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">全职工作</li><li id="da07" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">做所有和我的家庭相关的事情</li></ul><p id="fe92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，当然，我花了一年时间才来到这里:训练我的第一个 ML 模型。但我想告诉你这一切是如何进行的，我学到了什么(我学到的东西最终真的让我很开心！).</p><h1 id="ebbc" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">k-最近邻:我尝试的第一个算法</h1><p id="3eb0" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在我攻读工程学位的过程中，我学到的真正重要的东西(也许，这是我学到的最重要的东西)是从小处着手，从简单的事情开始，这样我就可以随着时间的推移掌握它们。</p><p id="f045" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我被建议学习的第一个模型(这些天，我正在结束一门数据科学的课程)是 K-NN 和决策树。我决定从 K-NN 开始。我在网上搜索了一下，找到了一个用 K-NN 进行良好锻炼的典型数据集，在这个数据集里，我们有一些特征，如身体质量指数、怀孕、血压等..哪些与糖尿病有关(你可以在网上从不同的来源找到数据；比如这里的<a class="ae ky" href="https://github.com/t-fede/Coursera_Capstone" rel="noopener ugc nofollow" target="_blank"/>。该练习的目的是训练 ML 模型来预测具有这种医学状况的患者是否可能患有糖尿病。</p><p id="f808" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，让我们看看一些带注释的代码。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a444" class="nl mk it nh b gy nm nn l no np">#importing all the needed libraries</span><span id="7dc0" class="nl mk it nh b gy nq nn l no np">import pandas as pd<br/>import numpy as np<br/>import pandas_profiling<br/>from pandas_profiling import ProfileReport<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.neighbors import KNeighborsClassifier as KNN<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.metrics import precision_score<br/>from sklearn.preprocessing import MinMaxScaler</span><span id="b339" class="nl mk it nh b gy nq nn l no np">#importing data<br/>diab = pd.read_csv('diabetes.csv')</span></pre><p id="f53e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我想给你们看的第一个东西是一个包，来自熊猫，这是我几天前发现的；这是“熊猫简介”，我用上面的代码导入了它。这个软件包在探索性数据分析中非常有用，因为它给了我们很多信息。让我们看看:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="cec1" class="nl mk it nh b gy nm nn l no np">#profiling data<br/>profile = ProfileReport(diab, explorative=True, dark_mode=True)</span><span id="098b" class="nl mk it nh b gy nq nn l no np">#output in HTML<br/>profile.to_file('output.html')</span></pre><p id="7ab5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个软件包确实给了你很多关于数据的信息。例如:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/590f5042cc29168a84d448a7f59d6cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uw_Iyum6TCa1qVWXbAKAvA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">熊猫轮廓的输出。图片由作者提供。</p></figure><p id="61da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图向我们展示了 Pandas Profiling 在第一个实例中向我们展示的内容，即变量信息；例如，数据集总共有 9 个变量，其中 8 个是数字变量，1 个是分类变量。</p><p id="ef83" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，如果我们键入“diab.head()”，我们可以看到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/5e08c16c25b88e792538631bfe424150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*7fZdEjU6HHAmm4rBir9nqQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">' diab.head()'的结果。图片由作者提供。</p></figure><p id="387e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，我们有 8 个数字特征(前 8 列)和 1 个分类特征(最后一列，名为“结果”，它告诉我们患者是否患有糖尿病，值为 1，值为 0)。</p><p id="e220" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您看到前面的图像，您可以看到 Pandas Profililing 给出的输出告诉我们有 15 个警报。在这一部分，软件包会给我们更多的信息，例如，它会告诉我们具有高相关性的特性以及更多。我真的建议你去看一看。</p><p id="abe7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们继续分析。首先，我们要用 0 值填充行；事实上，例如血压为 0 毫米汞柱是不现实的。为此，我们可以用同一列上的平均值来代替零；我们可以用下面的代码来实现:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="df0b" class="nl mk it nh b gy nm nn l no np">#filling zeros with mean value<br/>non_zero = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']<br/>for coloumn in non_zero:<br/>    diab[coloumn] = diab[coloumn].replace(0,np.NaN)<br/>    mean = int(diab[coloumn].mean(skipna = True))<br/>    diab[coloumn] = diab[coloumn].replace(np.NaN, mean)<br/>    print(diab[coloumn])</span></pre><p id="88ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以开始训练我们的模型。我们希望特征是前 8 列，以便给定一个患者与前 8 列相关的值(年龄、妊娠、BPM 等)，我们希望预测他/她是否患有糖尿病；因此“结果”栏(有/没有糖尿病)将成为我们的标签。</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="d6a6" class="nl mk it nh b gy nm nn l no np">#all the column except the last one (features)<br/>X =diab.iloc[:,0:8]</span><span id="a2c4" class="nl mk it nh b gy nq nn l no np">#the outcome column (label)<br/>y =diab.iloc[:,8]</span><span id="132b" class="nl mk it nh b gy nq nn l no np">#feature scaling<br/>scaler = MinMaxScaler()<br/>X = scaler.fit_transform(X)</span><span id="c296" class="nl mk it nh b gy nq nn l no np">#testing and training<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0, stratify=y)</span></pre><p id="222a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们拟合我们的模型，看看我们的预测:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="2bb1" class="nl mk it nh b gy nm nn l no np">#fitting model<br/>model = KNN(n_neighbors=5).fit(X_train, y_train)</span><span id="1274" class="nl mk it nh b gy nq nn l no np">#predictions and model accuracy<br/>y_pred = model.predict(X_test)<br/>print(f'Model accuracy on test set: {accuracy_score(y_test, y_pred):.2f}')</span></pre><p id="e600" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7514" class="nl mk it nh b gy nm nn l no np">Model accuracy on test set: 0.75</span></pre><p id="853a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“嗯嗯……“非常好”是我的第一个评论。但是我们能说点别的吗？我用过 k = 5…是个好选择吗？我怎么能理解我做了一个好的选择？好吧，我们可以试着用下面的代码找到一个好的“k”:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5214" class="nl mk it nh b gy nm nn l no np">#best k<br/>for k in [1,2,3,5,10]:<br/>    model = KNN(n_neighbors=k)<br/>    model.fit(X_train, y_train)<br/>    predictions = model.predict(X_test)<br/>    validation_accuracy = accuracy_score(y_test, ypred)<br/>    print('Validation accuracy with k {}: {:.2f}'.format(k,   validation_accuracy))</span></pre><p id="fed2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">利用上面的 for 循环，我们迭代地计算列表中指示的值的最佳 k。结果是:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="7a73" class="nl mk it nh b gy nm nn l no np">Validation accuracy with k 1: 0.71<br/>Validation accuracy with k 2: 0.72<br/>Validation accuracy with k 3: 0.75<br/>Validation accuracy with k 5: 0.75<br/>Validation accuracy with k 10: 0.78</span></pre><p id="413a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，根据计算结果，给出最佳精度的 k=10，我们将使用它。为什么我选择测试上面的 k 值？嗯，3 是一个典型值，选择一个“太高”的值会导致模型不稳定。因此，如果您亲自尝试，您会发现对于高于 k=10 的值，精度实际上是相同的。</p><p id="a533" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们用最好的 k 来训练我们的模型:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="50f5" class="nl mk it nh b gy nm nn l no np">#training model with best k<br/>model = KNN(n_neighbors=10).fit(X_train, y_train)</span><span id="6ff1" class="nl mk it nh b gy nq nn l no np">#predictions and model accuracy<br/>y_pred = model.predict(X_test)</span></pre><p id="351d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们看看混淆矩阵来评估一些指标:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="db75" class="nl mk it nh b gy nm nn l no np">#confusion matrix<br/>cm= confusion_matrix(y_test, y_pred)<br/>cm</span><span id="7fbd" class="nl mk it nh b gy nq nn l no np">--------</span><span id="1ad5" class="nl mk it nh b gy nq nn l no np">array([[89, 11],<br/>       [23, 31]])</span></pre><p id="67bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">混淆矩阵给了我们一个很好的结果。事实上，我们有 89+31=120 个值预测良好(89 个真阳性和 31 个真阴性)，23+11=34 个值预测不良(23 个假阴性和 11 个假阳性)。事实上，如果我们计算精度得分，即模型将真阳性预测为真阳性的能力，我们会得到:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="5539" class="nl mk it nh b gy nm nn l no np">#precision score<br/>precision = precision_score(y_test, y_pred)</span><span id="ec02" class="nl mk it nh b gy nq nn l no np">print(f'{precision: .2f}')</span><span id="160f" class="nl mk it nh b gy nq nn l no np">--------------------</span><span id="ad91" class="nl mk it nh b gy nq nn l no np">0.74</span></pre><p id="973e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是一个令人满意的值。</p><p id="739a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样。所以，我(最初)的悲伤。该模型训练有素，k=10 的 K-NN 是预测患者是否患有糖尿病的良好算法，知道与其健康状态相关的其他值。</p><p id="f1bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有对机器学习的炒作到此结束？</p><p id="a813" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">嗯，我是一个永远不会满足的人，尤其是在这个领域，我对知识的渴望是我无法满足的。所以，我想更深入一点。</p><p id="10b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，我喜欢图表…我需要看东西。所以，我找到了一种图形化评估我的模型的方法。例如，我们可以绘制核密度估计；在统计学中，KDE 是一种估计随机变量概率密度函数的非参数方法(例如，你可以在这里阅读更多<a class="ae ky" href="https://en.wikipedia.org/wiki/Kernel_density_estimation" rel="noopener ugc nofollow" target="_blank"/>)。我们可以这样做:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="51b4" class="nl mk it nh b gy nm nn l no np">import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="ecaa" class="nl mk it nh b gy nq nn l no np">plt.figure(figsize=(10, 10))</span><span id="877d" class="nl mk it nh b gy nq nn l no np">#diabetes outcome (Kernel Density Estimation)<br/>ax = sns.kdeplot(y, color="r", label="Actual Value") #y = diab['Outcome']</span><span id="d938" class="nl mk it nh b gy nq nn l no np">#predictions (Kernel Densiti Estimation), in the same plot (ax=ax)<br/>sns.kdeplot(y_pred, color="b", label="Predicted Values", ax=ax)</span><span id="4cbc" class="nl mk it nh b gy nq nn l no np">#labeling title<br/>plt.title('Actual vs Precited values')</span><span id="0d46" class="nl mk it nh b gy nq nn l no np">#showing legend<br/>plt.legend()</span><span id="dcc4" class="nl mk it nh b gy nq nn l no np">#showing plot<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/69a816ff938cc27aa20b8f8acd7f03e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*EnpKuez7j0nkl8v2cENc0w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实际值(红色)和预测值(蓝色)的 KDE。图片由作者提供。</p></figure><p id="ef3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，我们可以看到，两条曲线非常相似，证实了之前的分析。</p><p id="e3e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我对我的学习变得有点高兴了，但我还不够高兴；事实上，我问自己是否能做得更好，至少在理解的层面上。我研究了决策树模型，想看看它如何处理这样的数据。</p><h1 id="4723" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">决策树:我尝试的第二个 ML 算法</h1><p id="af02" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">由于与分割和训练相关的数学和代码与之前相同，我将向您展示模型拟合后的部分:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="803b" class="nl mk it nh b gy nm nn l no np">from sklearn.tree import DecisionTreeClassifier</span><span id="c8cd" class="nl mk it nh b gy nq nn l no np">#decision tree model and fitting<br/>clf = DecisionTreeClassifier(max_depth=3)<br/>clf.fit(X_train,y_train)</span><span id="ce8a" class="nl mk it nh b gy nq nn l no np">#predictions and model accuracy<br/>y_pred = clf.predict(X_test)<br/>print(f'Model accuracy on test set: {accuracy_score(y_test, y_pred):.2f}')</span><span id="eec0" class="nl mk it nh b gy nq nn l no np">----------------------</span><span id="ce6f" class="nl mk it nh b gy nq nn l no np">Model accuracy on test set: 0.79</span></pre><p id="7352" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个第一个结果真的让我反思…我得到了 0.79 的准确率，而 K-NN 的准确率是 0.78，k=10('最好的' K！)因为我非常确定 K-NN 是在这种情况下使用的更好的算法。我想尝试找到树的最佳深度，我使用了与最佳 k 相同的方法:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="73d1" class="nl mk it nh b gy nm nn l no np">#best depth<br/>for d in [3,5,10, 12, 15]:<br/>    model = DecisionTreeClassifier(max_depth=d)<br/>    model.fit(X_train, y_train)<br/>    predictions = model.predict(X_test)<br/>    validation_accuracy = accuracy_score(y_test, y_pred)<br/>    print('Validation accuracy with d {}: {:.2f}'.format(d, validation_accuracy))</span><span id="c9aa" class="nl mk it nh b gy nq nn l no np">------------------------------</span><span id="a157" class="nl mk it nh b gy nq nn l no np">Validation accuracy with d 3: 0.79<br/>Validation accuracy with d 5: 0.79<br/>Validation accuracy with d 10: 0.79<br/>Validation accuracy with d 12: 0.79<br/>Validation accuracy with d 15: 0.79</span></pre><p id="5ed9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，我们用一堆不同的 d 参数得到相同的精度。</p><p id="3cd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，如果我们计算混淆矩阵，我们得到:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="cfdd" class="nl mk it nh b gy nm nn l no np">cm= confusion_matrix(y_test, y_pred)<br/>cm<br/>-------------------</span><span id="5995" class="nl mk it nh b gy nq nn l no np">array([[84, 16],<br/>       [16, 38]], dtype=int64)</span></pre><p id="7d9f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后是精度分数:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f1c7" class="nl mk it nh b gy nm nn l no np">#precision score<br/>precision = precision_score(y_test, y_pred)</span><span id="e179" class="nl mk it nh b gy nq nn l no np">print(f'{precision: .2f}')</span><span id="c144" class="nl mk it nh b gy nq nn l no np">-------------------------------</span><span id="3e12" class="nl mk it nh b gy nq nn l no np">0.70</span></pre><p id="2c59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我没有报告 KDE 图，因为它实际上与 K-NN 算法生成的图相同。</p><p id="e601" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些结果让我又有点难过，因为，如前所述，在这种情况下，我非常确定 K-NN 是比 DT 更好的算法，但是正如你所看到的，我们得到的两个模型的结果非常相似。</p><p id="0b5d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我问自己:ML 中有这么多算法，一个人(尤其是像我这样的新手)如何能够理解——给定一个问题——哪种算法能够很好地适合给定的问题？</p><p id="55b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">信不信由你，我终于找到了一个让我非常开心的答案。</p><h1 id="7149" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">Pycaret</h1><p id="2fbb" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">所以，我谷歌了一下，找到了<a class="ae ky" href="https://pycaret.org/" rel="noopener ugc nofollow" target="_blank"> Pycaret </a>。正如他们在其网站上所说，“Pycaret 是一个开源、低代码的机器学习库，可以自动化机器学习工作流”。要安装它，您只需键入:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="e1d3" class="nl mk it nh b gy nm nn l no np">pip install pycaret</span></pre><p id="3dd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">工作完成了，像往常一样轻松。</p><p id="9bd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我真正高兴的是发现了这样一个事实，使用 Pycaret，我们可以比较 ML 模型来预测我们正在研究的问题的值，而且我们是以一种非常简单的方式来做的。Pycaret 给出了比较的结果，它使用“交叉验证”方法来评估各种模型的超参数，并为我们提供了所需的度量，用于决定使用哪种算法来解决我们的问题。让我们看看它是如何工作的:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="784f" class="nl mk it nh b gy nm nn l no np">from pycaret.classification import *</span><span id="af0b" class="nl mk it nh b gy nq nn l no np">#defining the features<br/>numeric_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']</span><span id="0614" class="nl mk it nh b gy nq nn l no np">#setting up the data<br/>clf = setup(data=diab, target='Outcome')</span><span id="7ba1" class="nl mk it nh b gy nq nn l no np">#comparing the models<br/>best = compare_models()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/66e24607965320c66a29e16a4430fff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*6e-8NBxEMMhjnIO08AKrlg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ML 算法与 Pycaret 算法的比较。图片由作者提供。</p></figure><p id="53c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所看到的，Pycaret 中的比较非常有用，它告诉我们:</p><ul class=""><li id="2a87" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">K-NN 和 DT 远不是在这种情况下使用的最佳算法(它们处于排名的中下部分)，但是它们为我们提供了具有相似值的度量(请记住，我们已经使用 for 循环计算了超参数，而 Pycaret 使用交叉验证，因此数字略有不同)</li><li id="0f23" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">基于 Pycaret 度量计算的最佳算法是随机森林分类器</li></ul><p id="ea8a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在结束之前，请注意在我写作的时候(2022 年 3 月)，Pycaret 并不与所有可用的 scikit-learn 版本兼容；我有 Scikir-learn 版本 1.0.2，不得不降级到 0.23.2。做起来很简单:</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="b541" class="nl mk it nh b gy nm nn l no np">pip uninstall scikit-learn</span><span id="c956" class="nl mk it nh b gy nq nn l no np">pip install scikit-learn==0.23.2</span></pre><h1 id="9bc6" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">结论</h1><p id="4682" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">正如我们已经看到的，当学习训练一个 ML 模型时，如果你是一个新手，像我一样，尝试不同的算法是一个好主意。这类练习真的给了我们获得‘动手’项目和算法的可能性。</p><p id="365e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，我们仍然需要知道更多，但是随着时间的推移，我们会越来越有经验。我非常确定 Pycaret 是一个很好的解决方案，可以决定我们面对的特定问题使用什么算法，但我甚至确定经验——我实际上是新手，会有所帮助(可能是大多数)。</p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="151d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oc">我们一起连线吧！</em></p><p id="7194" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://federicotrotta.medium.com/" rel="noopener"> <strong class="lb iu"> <em class="oc">中等</em> </strong> </a></p><p id="afe3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://www.linkedin.com/in/federico-trotta/" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="oc">LINKEDIN</em></strong></a><em class="oc">(向我发送连接请求)</em></p><p id="4d1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oc">如果你愿意，你可以</em> <a class="ae ky" href="https://federicotrotta.medium.com/subscribe" rel="noopener"> <strong class="lb iu"> <em class="oc">订阅我的邮件列表</em></strong></a><strong class="lb iu"><em class="oc"/></strong><em class="oc">这样你就可以一直保持更新了！</em></p></div><div class="ab cl nv nw hx nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="im in io ip iq"><p id="aa7d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑成为会员:你可以免费支持我和其他像我一样的作家。点击 <a class="ae ky" href="https://federicotrotta.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="oc">这里</em></strong></a><strong class="lb iu"><em class="oc"/></strong><em class="oc">成为会员。</em></p></div></div>    
</body>
</html>