<html>
<head>
<title>Semantic Keywords And Keyphrases Extraction With KeyBERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 KeyBERT 提取语义关键词和关键短语</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semantic-keywords-and-keyphrases-extraction-with-keybert-999234cab7f#2022-02-14">https://towardsdatascience.com/semantic-keywords-and-keyphrases-extraction-with-keybert-999234cab7f#2022-02-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="56c7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用拥抱面部变形器和余弦相似性从文档中检索语义表达式</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/866755431cb9098d0c47a6cc68fd30c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7P2Pww59U3jZna_Pwwrrcg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="bb7c" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">介绍</h1><p id="be42" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">无论您的工作是分析商业报告、社交媒体还是财务数据，我们大多数人都会提到数字能力，因为这是从这些文档中获得有意义见解的更快方式。寻找和提取能更好地描述文档的有见地的单词和表达式一直是一项挑战，尤其是对于较大的文档。</p><p id="6425" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然而，使用最先进的自然语言处理方法可以增加找到那些有意义的单词和表达的机会。我们将尝试使用<code class="fe mr ms mt mu b"><strong class="ls iu">KeyBERT</strong></code>来解决这样一个任务:这是一个由<a class="ae mv" href="https://www.maartengrootendorst.com/" rel="noopener ugc nofollow" target="_blank">马腾·格罗腾多斯特</a>在 2020 年开发的简单的库。它利用变压器和余弦相似性来有效地提取更好地代表给定文档的关键字和关键短语。我们将首先理解 KeyBERT 是如何工作的，然后实现它，最后讨论它的时间执行复杂度。</p><h1 id="2d0a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">KeyBERT——那又怎样？</h1><p id="323d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">不同的工艺如<a class="ae mv" href="https://github.com/aneesha/RAKE" rel="noopener ugc nofollow" target="_blank">耙子</a>、<a class="ae mv" href="https://github.com/LIAAD/yake" rel="noopener ugc nofollow" target="_blank">雅克！</a>、<a class="ae mv" href="https://en.wikipedia.org/wiki/Tf–idf" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a>等。存在关键字提取。然而，KeyBERT 为表达式提取过程提供了语义值，这与前面所述的主要关注统计方法相反。</p><h2 id="6571" class="mw kz it bd la mx my dn le mz na dp li lz nb nc lk md nd ne lm mh nf ng lo nh bi translated">KeyBERT 的主要组件</h2><p id="c110" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下图显示了 KeyBERT 算法的四个主要组件:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/5b25be398d7999d9a17c402319b83ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nvrZ8zMxMtg_mG21pN3_uA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2: KeyBERT 主要组件(图片由作者提供)</p></figure><p id="29e1" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">①。原始文档嵌入</strong>:第一步是通过利用 BERT 来执行的，目的是获得输入文档的嵌入级表示。如果您想使用其他语言，也可以为多语言任务使用不同的嵌入模型。</p><p id="d7d8" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">②。n 元语法单词/表达式检索</strong>:从相同的先前文档中，使用 n 元语法方法提取关键词和关键短语。当 n-gram 范围为(1，1)时，我们得到关键字。另一方面，将范围增加到(1，2)或更高会得到关键短语。</p><p id="c907" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">③。N-grams 嵌入:</strong>这些 n-grams 中的每一个都使用与原始文档相同的嵌入模型进行嵌入。</p><p id="de69" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu">④。余弦相似性搜索</strong>:在先前的单词/短语/表达集合中，使用余弦相似性度量选择与输入文档最相似的那些。这些最终被认为能更好地描述文档。</p><h1 id="ca65" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">数据</h1><p id="e2e3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我创建了一个列表，包含 2022 年 1 月期间发表的所有文章的介绍部分。因此，我们的分析将集中在这些信息上。</p><p id="8ba7" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">你可以在下面找到其中一个<strong class="ls iu">介绍</strong>的第一行。</p><blockquote class="nj nk nl"><p id="7c51" class="lq lr nm ls b lt mm ju lv lw mn jx ly nn mo mb mc no mp mf mg np mq mj mk ml im bi translated">我们生活在一个被大量文本信息包围的时代，如调查回复、社交媒体评论、推文等。找到满足个人需求的合适信息是一项挑战，尤其是在处理大量不同的数据时。多亏了主题建模，一个自然语言处理的时代通过将大量未标记的文本数据分组/聚类成主题来有效地分析它们…</p></blockquote><p id="9697" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">还有，文章的所有源代码都可以在我的<a class="ae mv" href="https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/Advanced_Topic_Modeling_BERTopic.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="ls iu"> Github </strong> </a>上免费获得。</p><h1 id="c409" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">关键短语和关键词提取</h1><p id="7e41" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">以下三个步骤与从文档中提取关键字和关键短语相关:</p><p id="d9e9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> (1) </strong>安装并导入 KeyBERT 和句子转换器库</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">keybert_prereq.py</p></figure><p id="797a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> (2) </strong>配置 KeyBERT 模型</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">config_keyBERT.py</p></figure><ul class=""><li id="6f7a" class="ns nt it ls b lt mm lw mn lz nu md nv mh nw ml nx ny nz oa bi translated"><code class="fe mr ms mt mu b">all-mpnet-base-v2</code>:这个<a class="ae mv" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子转换器</a>模型将句子&amp;段落映射到一个 768 维的密集向量空间。在撰写本文时，该模型在所有<a class="ae mv" href="https://www.sbert.net/docs/pretrained_models.html" rel="noopener ugc nofollow" target="_blank">可用的当前预训练模型</a>中具有最佳性能。</li><li id="5268" class="ns nt it ls b lt ob lw oc lz od md oe mh of ml nx ny nz oa bi translated"><code class="fe mr ms mt mu b">keyBERT_model</code>:将用于表达式提取的 KeyBERT 实例。</li></ul><p id="d691" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><strong class="ls iu"> (3) </strong>计算关键词和关键短语提取</p><p id="b3a2" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">以下函数以<strong class="ls iu"> (term，cosine_score) </strong>的格式返回最相关表达式的元组列表。余弦值越高，表达的相关性越好。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">extract_terms.py</p></figure><p id="96d7" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">上一个函数中的大多数参数都是不言自明的。下面我们来试着理解一下:<code class="fe mr ms mt mu b">use_mmr</code>和<code class="fe mr ms mt mu b">diversity</code>。</p><ul class=""><li id="cb22" class="ns nt it ls b lt mm lw mn lz nu md nv mh nw ml nx ny nz oa bi translated"><code class="fe mr ms mt mu b">use_mmr</code>:设置为<strong class="ls iu"> True 时，对应使用最大边际相关性。</strong>它使得尽可能减少所选表达方式之间的相似性，以创造更多的多样性，这实际上是我们想要的。因为我们不希望我们所有的最终表达都是一样的。</li><li id="e592" class="ns nt it ls b lt ob lw oc lz od md oe mh of ml nx ny nz oa bi translated"><code class="fe mr ms mt mu b">diversity</code>:用于设置分集阈值，取值范围为 0-1。这就像一个控制<code class="fe mr ms mt mu b">use_mmr</code>的光标，一个更高的值产生的设置(比如在我们的例子中为 0.7)创建了不同的候选表达式/术语/关键字。</li></ul><p id="c8aa" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">既然我们理解了这些参数，我们可以将该函数应用到所有的<strong class="ls iu">简介</strong>文档中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">terms_from_introductions.py</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/1efba89c708dee05a3278441c8c3848f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8iSyNDI4W2URnFBTtdeALQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1:来自我一月份文章介绍部分的相关关键词/关键短语(图片由作者提供)</p></figure><p id="db13" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">检索到的信息似乎准确地描述了每个相应的简介部分。例如，第一个包含 91 个单词的文档已经被总结为很少的几个表达式，这些表达式可以更好地描述整个文档。</p><h1 id="806d" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">执行时间分析</h1><p id="30d5" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在构建模型时，记住与工业化方面相关的所有限制是很重要的。其中一个约束可能与管道的执行时间有关，根据您的用例，可以忽略这一点。</p><p id="78fd" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下表包含每个<strong class="ls iu">简介</strong>的关键词提取时间复杂度的所有指标，单位为毫秒(ms)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/5123bf11d72a63fe10e3bd3e581a229c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QsSAmwMYXoZCQiOP_fvmlw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表 1: KeyBERT 关键字/关键短语提取执行时间(毫秒)(图片由作者提供)</p></figure><p id="0a78" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下面是相应的图形</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/e808cd12145b913eab966621c82c5a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X1Avme2rhzjYKTuwV2_-Bg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2: KeyBERT 关键字/关键短语提取执行时间图(图片由作者提供)</p></figure><p id="9d2a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">正如您所看到的，表达式提取时间随着输入文档的长度而增加，并且很容易达到指数级的时间复杂度，这意味着无论 KeyBERT 的性能有多好，它都可能不适用于具有实时执行约束的应用程序。</p><h2 id="1f6e" class="mw kz it bd la mx my dn le mz na dp li lz nb nc lk md nd ne lm mh nf ng lo nh bi translated">感谢阅读！</h2><p id="7c48" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">你可以在下面找到更多的资源来加深你的理解。不要犹豫，在 LinkedIn 上加我，或者在 YouTube 和 Twitter 上关注我。讨论人工智能，人工智能，数据科学，自然语言处理的东西总是令人愉快的！</p><p id="3f66" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mv" href="https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/Advanced_Topic_Modeling_BERTopic.ipynb" rel="noopener ugc nofollow" target="_blank">Github 上的源代码</a></p><p id="4356" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mv" href="https://github.com/MaartenGr/KeyBERT" rel="noopener ugc nofollow" target="_blank"> KeyBERT Github </a></p><p id="01e9" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated"><a class="ae mv" href="https://maartengr.github.io/KeyBERT/faq.html" rel="noopener ugc nofollow" target="_blank">基伯特常见问题解答</a></p><p id="3a2e" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">再见🏃🏾</p></div></div>    
</body>
</html>