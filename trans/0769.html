<html>
<head>
<title>EDN-GTM: Encoder-decoder Network with Guided Transmission Map for Single Image Dehazing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">EDN-GTM:具有用于单一图像去雾的引导传输图的编码器-解码器网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/edn-gtm-encoder-decoder-network-with-guided-transmission-map-for-single-image-dehazing-78e8036bbaa3#2022-03-03">https://towardsdatascience.com/edn-gtm-encoder-decoder-network-with-guided-transmission-map-for-single-image-dehazing-78e8036bbaa3#2022-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4824" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">当传统的计算机视觉和深度学习结合时。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e71961c93e562442835baafaa024e16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RW90HsFWmBUEk8WZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@drmakete?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> drmakete 实验室</a>拍摄的照片</p></figure><h1 id="f8f1" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">图像去雾</h1><p id="c956" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">增强从自然场景捕获的数字图像的可见性的目的在许多现实世界应用中变得非常必要，因此图像去雾(或去雾)在几十年前已经成为计算机视觉和图像处理中的重要任务。</p><p id="baff" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果你想知道这个话题有多热，我想让你知道何，深度学习中各种经典理论如残差网络、更快 R-CNN、空间金字塔池、特征金字塔网络等的发明者在他的博士研究期间研究了这个主题，并在他的<a class="ae kv" href="http://kaiminghe.com/publications/thesis.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>和<a class="ae kv" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="noopener ugc nofollow" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence</a>中提出了之前的<a class="ae kv" href="https://ieeexplore.ieee.org/document/5567108" rel="noopener ugc nofollow" target="_blank">暗通道(DCP)。</a></p><p id="a7ef" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">去雾算法有两种范式:传统方法和基于深度学习的方法。许多传统方法已经使用纯计算机视觉技术将手工制作的图形模型应用于去雾(例如，DCP)，而基于深度学习的方法已经采用卷积神经网络(CNN)来解决去雾问题。然而，这些方法仍然有它们的缺点，并且总是有改进的空间。</p><p id="7199" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这篇文章回顾了使用导向传输图(EDN-GTM)实现有效的单幅图像去雾的编码器-解码器网络。EDN-GTM 是一种新的方案，它利用传统计算机视觉技术和现代深度学习算法的能力来执行图像去雾。具体地，利用通过采用暗通道先验估计的透射图作为 CNN 模型的指南来执行去雾。论文全文可在<a class="ae kv" href="https://arxiv.org/abs/2202.04757" rel="noopener ugc nofollow" target="_blank"> arXiv </a>(预印本)或<a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S1877050922008201?via%3Dihub#!" rel="noopener ugc nofollow" target="_blank">Procedia Computer Science 204</a>(已发表论文)上找到。</p><h1 id="d648" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">作为 CNN 指南的传输图</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/3e6ad6e3fc772d27607c11194c251ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jkh8LGu1WPAWck52ZBPGxg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">暗通道先验(DCP)的去雾结果:(a)输入模糊图像，(b)通过 DCP 的去雾图像，(c)地面真实图像，(d)通过 DCP 的反转透射图。(纸张中的图像)</p></figure><p id="c278" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">DCP 是基于无薄雾的室外图像的统计而提出的，因此，它在室内场景中不太有效，并且当薄雾图像包含看起来类似于空气光的大区域时可能无效。在上图中可以看到一个例子，当 DCP 试图在看起来像空气光和薄雾的墙壁场景区域中去雾时，从而提出了比地面真实图像更暗的输出图像。</p><p id="eb72" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然而，当重新思考由 DCP 产生的倒置透射图时，它们可以被认为是一种注意力图，其中较亮的区域指示密集雾度的区域，而较暗的区域指示不太雾度的区域(除了墙壁场景区域)。现在的问题是如何找到墙景区域？</p><p id="0feb" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">哦，CNN 刚刚举手了！由于具有提取和分析图像特征的能力，CNN 可能是一个潜在的候选者。</p><p id="a9f6" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">有了这些强有力的证据，由 DCP 和 CNN 模型获得的透射图可以被统一以形成有效的霾去除系统。传输图“告诉”CNN 关注哪里。从这些建议区域，CNN 可以通过监督学习知道它应该更加关注哪些区域(例如，在输入和输出图像中墙壁场景区域没有太大不同，但是模糊区域不同)。</p><h1 id="dd9d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">网络架构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/961094258b3109ede88026849d005021.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gafE8kv27MbUjykGQ0wRiw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图表和网络架构:(a)EDN-GTM 方案的图表，(b) EGN-GTM 设计，以及(c)鉴别器设计。(纸张中的图像)</p></figure><p id="6c12" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">上图显示了 EDN-GTM 方案以及发生器和鉴别器的网络架构。</p><h2 id="bfeb" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">发电机设计(EDN-GTM)</h2><p id="1925" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">作为语义分割和图像恢复中最流行和最强大的网络之一，U-Net 被选为 EDN-GTM 方案的基础网络。为了获得 EDN-GTM 的架构设计，作者进一步将以下主要修改添加到网络中:</p><ol class=""><li id="e730" class="nd ne iq lq b lr mk lu ml lx nf mb ng mf nh mj ni nj nk nl bi translated">输入通道:传输图与图像的深度信息有着密切的关系，在去雾方案中起着重要的作用，然后它被用作网络输入的附加通道(与传统的 RGB 图像一起)。</li><li id="fac6" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">瓶颈:通过使用一组具有不同内核大小的池操作，空间金字塔池(SPP)模块能够分离出最重要的功能，它被插入到基础网络的瓶颈中(就像它在 YOLOv4 object detector 的颈部使用的方式)。</li><li id="b72a" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">激活:ReLU 在最近的 CNN 模型中逐渐变得过时，因此，ReLU 被 Swish 函数所取代，该函数已经被证明在现代深度网络中始终优于 ReLU。</li><li id="8b91" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj ni nj nk nl bi translated">感受野:去雾网络的感受野应该足够大，这是由于在模糊图像中霾(或雾)的扩散分布，因此在基本网络的每个卷积级中增加一个 3×3 conv 层。</li></ol><h2 id="a7eb" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">鉴别器的设计</h2><p id="bd7c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">该方案选择 U-Net 的编码器部分作为鉴别器的结构。鉴别器设计的这种选择可以帮助两个网络(发生器和鉴别器)具有提取和分析输入图像特征的竞争能力，从而两个网络可以相互“战斗”以获得它们的性能。</p><h1 id="5c71" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">损失函数</h1><p id="4a7b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">EDN-GTM 应用积分损失函数，该函数是对抗性损失、MSE 损失和感知损失的加权和。</p><h2 id="a743" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">对抗性损失</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/f424cd26253b7ffaf388122be4d0354f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikk_KQPk4LHJHRcwQd6aWA.png"/></div></div></figure><p id="e5c9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中 B 是批量，z 是模糊图像，G 是发生器，D 是鉴别器。</p><h2 id="71dc" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">MSE 损失</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/bb8cffed29ecff42fa31caa872654dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cz5DrbOdrXofbXWU5fJrzA.png"/></div></div></figure><p id="78c4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中 N 是输入(输出)图像中的像素数，I 是干净的图像。</p><h2 id="9250" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">知觉丧失</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/3db5b44759eedca9ea416793353b7e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vuObkmB4aZ5_0KXEF-2avQ.png"/></div></div></figure><p id="03ad" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">其中 M 是预训练 VGG16 模型的层 Conv3_3 的特征图φ中的元素数量。</p><h2 id="d7bd" class="mr kx iq bd ky ms mt dn lc mu mv dp lg lx mw mx li mb my mz lk mf na nb lm nc bi translated">整体损失</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/f9355addad07f2f65e06e0e18119ee19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1pNgcpiDD6Ce72zOegcKg.png"/></div></div></figure><p id="321f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">积分损失是上述所有相关损失函数的加权和。</p><h1 id="ef07" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">基准测试的结果</h1><p id="7b59" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">提供了去雾任务的四个基准数据集上的实验结果，包括 I-HAZE、O-HAZE、Dense-HAZE 和 NH-HAZE。下图显示了各种方法的典型视觉去雾性能。EDN-GTM 已被证明在可见度方面始终优于其他现代去雾方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/1efccc0813988bc806639823f51a8790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uBxmR6T4xPZLmDSUxgGEeQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">视觉去雾的结果是:(a) I 雾度，(b) O 雾度，(c)致密雾度，和(d) NH 雾度。(图片来自论文)</p></figure><p id="2a9c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">下表显示了 EDN-GTM 和其他最新去雾方法的定量结果(红色和蓝色数字分别表示最佳和次佳性能)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/a3549c8faaf92ad3311ee59f0b2161ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qrZn2mAWcHaZW0snoQSjoA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自纸张的图像</p></figure><h1 id="3d01" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">应用于对象检测</h1><p id="13e2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">EDN-GTM 作为预处理工具应用于目标检测任务。比较了有雾和去雾图像的检测性能。实验中使用的数据集是 WAYMO 数据集。WAYMO 数据集不提供模糊图像数据，因此，通过应用本文<a class="ae kv" rel="noopener" target="_blank" href="/synthesize-hazy-foggy-image-using-monodepth-and-atmospheric-scattering-model-9850c721b74e">帖子</a>中描述的方法合成模糊图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/b08a6120eafbfc5137a414c139e3693d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-AjAaM1t0jxpgUhNJDbGuQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">合成模糊 WAYMO 数据集上的视觉去雾结果。(图片来自论文)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/984e412c6b001909fe307112b24a0005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xEE_JNRVOo5ar3jnO_Xk8w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在两组模糊和去雾图像上的对象检测性能(红色:地面实况框，绿色:预测框，蓝色:放大区域)。(图片来自论文)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/cfec54a9ea2888f119db48d86e4b1963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WKhKbFsR_Q5ox1qQBd6_6A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自纸张。</p></figure><h1 id="5cb8" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="37ba" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在这篇文章中，我简要回顾了 EDN-GTM，一种新颖的单幅图像去雾方案。EDN-GTM 利用纯计算机视觉和深度学习方法来形成一个统一的网络，以实现最先进的去雾性能。EDN-GTM 利用 U-Net 作为基础网络，并对网络进行各种修改，以便能够实现最佳去雾性能。EDN-GTM 的有效性已经在基准去雾数据集上得到验证。论文全文可以在<a class="ae kv" href="https://arxiv.org/abs/2202.04757" rel="noopener ugc nofollow" target="_blank"> arXiv </a>(预印本)或<a class="ae kv" href="https://www.sciencedirect.com/science/article/pii/S1877050922008201?via%3Dihub#!" rel="noopener ugc nofollow" target="_blank">Procedia Computer Science 204</a>(发表的论文)上找到。</p><p id="7c4a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">欢迎读者访问我的脸书粉丝页面分享关于机器学习的事情:<a class="ae kv" href="https://www.facebook.com/diveintomachinelearning" rel="noopener ugc nofollow" target="_blank">投入机器学习</a>。我的其他著名帖子也可以在这里找到:</p><ul class=""><li id="9f67" class="nd ne iq lq b lr mk lu ml lx nf mb ng mf nh mj oa nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/metaformer-de-facto-need-for-vision-93476cc9fec5">元格式器</a></li><li id="14e5" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj oa nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/darkeras-execute-yolov3-yolov4-object-detection-on-keras-with-darknet-pre-trained-weights-5e8428b959e2">黑暗时代</a></li><li id="92cd" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj oa nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/efpn-extended-feature-pyramid-network-for-small-object-detection-980af794a093"> EFPN:扩展特征金字塔网络</a></li><li id="772a" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj oa nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/data-augmentation-compilation-with-python-and-opencv-b76b1cd500e0">数据扩充</a></li><li id="5519" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj oa nj nk nl bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/data-distillation-for-object-detection-92a89fe5d996">数据提炼</a></li><li id="3528" class="nd ne iq lq b lr nm lu nn lx no mb np mf nq mj oa nj nk nl bi translated">而其他人在<a class="ae kv" href="https://tranlevision.medium.com/" rel="noopener">我的页面</a>。</li></ul><p id="e344" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">感谢您抽出时间！</p></div></div>    
</body>
</html>