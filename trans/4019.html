<html>
<head>
<title>Introduction to Image Classification with TensorFlow — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流图像分类简介(一)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-1-381d0a373b8f#2022-09-07">https://towardsdatascience.com/introduction-to-image-classification-with-tensorflow-part-1-381d0a373b8f#2022-09-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d5c8" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Python计算机视觉初学者实用指南</h2></div><p id="39db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" href="https://www.ibm.com/au-en/topics/computer-vision#:~:text=Computer%20vision%20is%20a%20field,recommendations%20based%20on%20that%20information." rel="noopener ugc nofollow" target="_blank">计算机视觉是人工智能的一个领域，它使机器能够将图像和视频等视觉数据处理成有意义的信息</a>。图像分类是计算机视觉的一个普遍应用。在这篇文章中，我们将学习如何使用谷歌开发的开源深度学习库TensorFlow在Python中进行基本的图像分类。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/af79e0c5095b336d9da0fcbd179adfd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xDRQ4cTPXeoIHmeR"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@opticonor?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">康纳·乐迪</a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="bd4b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">📦数据</h1><p id="87f1" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我们将使用手写数字的MNIST数据集，这是众所周知的介绍性图像数据集之一。这些数据可以在知识共享署名-同样分享3.0许可协议下获得。我们将加载必要的库和数据:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="16d7" class="ne md it na b gy nf ng l nh ni">import numpy as np<br/>import pandas as pd<br/>from sklearn.model_selection import train_test_split</span><span id="6f77" class="ne md it na b gy nj ng l nh ni">import tensorflow as tf<br/>from tensorflow.keras.datasets import mnist<br/>from tensorflow.keras import Sequential<br/>from tensorflow.keras.layers import (Flatten, Dense,  <br/>                                     Conv2D, MaxPooling2D)</span><span id="da38" class="ne md it na b gy nj ng l nh ni">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>sns.set(style='darkgrid', context='talk')</span><span id="9f11" class="ne md it na b gy nj ng l nh ni">(train_data, train_labels), (test_data, test_labels) = mnist.load_data()<br/>train_data, valid_data, train_labels, valid_labels =  train_test_split(<br/>    train_data, train_labels, test_size=10000, random_state=42<br/>)<br/>print("========== Training data ==========")<br/>print(f"Data shape: {train_data.shape}")<br/>print(f"Label shape: {train_labels.shape}")<br/>print(f"Unique labels: {np.unique(train_labels)}")</span><span id="1d94" class="ne md it na b gy nj ng l nh ni">print("\n========== Validation data ==========")<br/>print(f"Data shape: {valid_data.shape}")<br/>print(f"Label shape: {valid_labels.shape}")<br/>print(f"Unique labels: {np.unique(valid_labels)}")</span><span id="8981" class="ne md it na b gy nj ng l nh ni">print("\n========== Test data ==========")<br/>print(f"Data shape: {test_data.shape}")<br/>print(f"Label shape: {test_labels.shape}")<br/>print(f"Unique labels: {np.unique(test_labels)}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/9c7c243990bf88d8e7f183f9b3ccbe29.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*dXMofduZlw9Y-xhCAQInxw.png"/></div></figure><p id="cb55" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们有50K的训练，10K验证和10K测试28×28像素的图像。不出所料，有10类数字。现在让我们检查每个分区数据集的类分布:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="de98" class="ne md it na b gy nf ng l nh ni">n_classes = len(np.unique(train_labels))<br/>(pd.concat([pd.Series(train_labels).value_counts(normalize=True)<br/>              .sort_index(),<br/>            pd.Series(valid_labels).value_counts(normalize=True)<br/>              .sort_index(),<br/>            pd.Series(test_labels).value_counts(normalize=True)<br/>              .sort_index()], <br/>           keys=['train', 'valid', 'test'], axis=1)<br/>   .style.background_gradient('YlGn', axis='index').format("{:.2%}"))</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/9447f366b40319b4d5fd9747e90e5ef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*nTaepudLSw72R78U-pKRlg.png"/></div></figure><p id="f26c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">数据集之间的类分布相当均衡。如果你想学习如何像这样美化你的熊猫数据框，你可能会发现这个帖子<a class="ae le" rel="noopener" target="_blank" href="/prettifying-pandas-dataframes-75c1a1a6877d">很有用。</a></p><p id="8ca2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在我们开始构建图像分类模型之前，让我们通过检查一些样本图像来研究数据:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="12ad" class="ne md it na b gy nf ng l nh ni">def inspect_sample_images(data, labels, title, n_rows=2, n_cols=3, <br/>                          seed=42):<br/>    np.random.seed(seed)<br/>    indices = np.random.choice(range(len(data)), n_rows*n_cols, <br/>                               replace=False)<br/>    plt.figure(figsize=(8,5))<br/>    for i, ind in enumerate(indices):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        plt.imshow(data[ind], cmap='binary')<br/>        plt.axis('off')<br/>        plt.title(f"Label: {labels[ind]}", fontsize=14)<br/>    plt.suptitle(title, fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>inspect_sample_images(train_data, train_labels, 'Sample training images')</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/14995b6c20f21ecf58274caab0404334.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*FdyjLelrtU9tlbriiA5ZJA.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="fbe3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到图像反映了不同的笔迹。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="07bd" class="ne md it na b gy nf ng l nh ni">inspect_sample_images(valid_data, valid_labels, 'Sample validation images')</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/9353c5af2669a4ae816c17a197d6088b.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*GC94gqXrebDfdJEApHM8wQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="9423" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">左下角的数字8被稍微切掉了。也许一些图像可能被裁剪。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="513f" class="ne md it na b gy nf ng l nh ni">inspect_sample_images(test_data, test_labels, 'Sample test images')</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/74eec01f78f84b29132983c014f5835f.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*kgnopr00QjyCA27ZqPgFLQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="22d7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个例子中有两个2，他们都有自己的风格。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="2597" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">🔨系统模型化</h1><p id="fffd" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">这是令人兴奋的部分！由于模型构建过程是非常实验性和迭代性的，我们将迭代地构建两个模型。</p><h2 id="cd7c" class="ne md it bd me np nq dn mi nr ns dp mm kr nt nu mo kv nv nw mq kz nx ny ms nz bi translated">🔧模型0</h2><p id="2489" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">目前，标签是1D数组格式。我们需要像这样对我们的标签进行一次热编码:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/8d7755cccdfdabff4f43a6a118cdf71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*F0oSr4phdsAoiiGQWUf1hw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">列标题仅用于说明|图片由作者提供</p></figure><p id="fdff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，让我们建立我们的第一个简单的神经网络。我们将为可复制性播下种子。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="1f95" class="ne md it na b gy nf ng l nh ni">train_labels_ohe = tf.one_hot(train_labels, 10)<br/>valid_labels_ohe = tf.one_hot(valid_labels, 10)<br/>test_labels_ohe = tf.one_hot(test_labels, 10)</span><span id="a66c" class="ne md it na b gy nj ng l nh ni">tf.random.set_seed(42)<br/>model_0 = Sequential([<br/>    Flatten(input_shape=(28, 28)),<br/>    Dense(16, activation="relu"),<br/>    Dense(16, activation="relu"),<br/>    Dense(n_classes, activation="softmax")<br/>])</span><span id="0963" class="ne md it na b gy nj ng l nh ni">model_0.compile(loss="categorical_crossentropy", optimizer='Adam',<br/>                metrics=["accuracy"])<br/>model_0.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/c31669b92b55e257e73670463cbb6301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*kQ5RfcFXV7p0Y99gb4tKyQ.png"/></div></figure><p id="52fa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里我们首先定义了神经网络的架构，然后编译它并打印它的摘要。让我们仔细看看。</p><p id="1a3e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">◼️ <strong class="kk iu">在第一层<code class="fe oc od oe na b">flatten</code>定义了神经网络<br/> </strong>的架构，它将图像从(28，28) 2D阵列展平到(784) 1D阵列。然后，我们有两个完全连接的隐藏层(<code class="fe oc od oe na b">dense</code> &amp; <code class="fe oc od oe na b">dense_1</code>)。对于这些层，我们使用ReLu激活函数。接下来是具有<code class="fe oc od oe na b">softmax</code>激活功能(<code class="fe oc od oe na b">dense_2</code>)的输出层，其单元数量与类别数量相同。</p><p id="b054" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> ◼编译的模型<br/> </strong>我们用的是<code class="fe oc od oe na b">categorical_crossentropy</code>损失函数。输出层中的损失函数和softmax激活函数允许我们获得每个类别的概率，因为我们正在构建多类别分类模型。我们使用了<code class="fe oc od oe na b">Adam</code>优化器。</p><p id="297e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> ◼打印出模型概要<br/> </strong>一旦编译完成，我们可以从概要中看到模型的层数以及参数的数量。</p><p id="d29b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，是时候训练网络了:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="7cc2" class="ne md it na b gy nf ng l nh ni">hist_0 = model_0.fit(train_data, train_labels_ohe, epochs=5, <br/>                     validation_data=(valid_data, valid_labels_ohe))</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/10069cea53ed4088c7523a983105f114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*0leWHuo32R7-jWl2vhFziA.png"/></div></figure><p id="1049" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了更快的训练，我们将只做5个周期。这意味着网络将遍历数据5次。从上面的总结中，我们看到精度随着每个历元而提高。让我们想象一下各个时期的精确度:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="6d3d" class="ne md it na b gy nf ng l nh ni">def clean_history(hist):<br/>    epochs = len(hist.history['accuracy'])<br/>    df = pd.DataFrame(<br/>        {'epochs': np.tile(np.arange(epochs), 2),<br/>         'accuracy': hist.history['accuracy'] + <br/>                     hist.history['val_accuracy'], <br/>         'loss': hist.history['loss'] + <br/>                 hist.history['val_loss'], <br/>         'dataset': np.repeat(['train', 'valid'], epochs)}<br/>    )<br/>    return df</span><span id="7e62" class="ne md it na b gy nj ng l nh ni">sns.lineplot(data=clean_history(hist_0), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/e16c60d45ba40fc2dd897a39ca679598.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*GovQFgWXpgY7K9r_BtzERg.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="bfe7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经创建了一个函数，因为这将有助于评估后续模型。我们将继续为其他评估方法构建函数。让我们根据看不见的测试数据来评估模型的性能:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="5953" class="ne md it na b gy nf ng l nh ni">test_preds_0 = model_0.predict(test_data)<br/>test_classes_0 = test_preds_0.argmax(axis=1)<br/>test_metrics = pd.DataFrame(columns=['Test accuracy'])<br/>test_metrics.loc['model_0'] = np.mean(test_labels==test_classes_0)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7ddddf69b8bd951da38c48de7f0dd760.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*pSae19RgWnPQXwZH_z1Wfg.png"/></div></figure><p id="fa6b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太好了，我们将把后续型号的性能添加到这个数据框架中，这样我们就可以一目了然了。<code class="fe oc od oe na b">test_preds_0</code>由(10000，10) 2D数组组成，该数组包含每条记录的分类预测概率。然后，我们为每条记录分配概率最高的类别，并将其保存到<code class="fe oc od oe na b">test_classes_0</code>中。现在，让我们看看混淆矩阵:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="c305" class="ne md it na b gy nf ng l nh ni">def show_confusion_matrix(labels, classes):<br/>    cm = (pd.crosstab(pd.Series(labels, name='actual'), <br/>                      pd.Series(classes, name='predicted'))<br/>            .style.background_gradient('binary'))<br/>    return cm</span><span id="c3ab" class="ne md it na b gy nj ng l nh ni">show_confusion_matrix(test_labels, test_classes_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/9f5594fd6566585ad466dc21744d502b.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*7dMxF6G-8OZ8vgrQrStR9Q.png"/></div></figure><p id="7e37" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">很高兴看到大多数记录都是沿着对角线从左上延伸到右下。有趣的是，目前的模型经常把8s和2s搞错。</p><p id="8f04" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们用它们的预测来检查一些示例图像:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="eb5a" class="ne md it na b gy nf ng l nh ni">def inspect_sample_predictions(data, labels, preds, dataset='test', <br/>                               seed=42, n_rows=2, n_cols=3):<br/>    np.random.seed(seed)<br/>    indices = np.random.choice(range(len(data)), n_rows*n_cols, <br/>                               replace=False)<br/>    plt.figure(figsize=(8,5))<br/>    for i, ind in enumerate(indices):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        plt.imshow(data[ind], cmap='binary')<br/>        plt.axis('off')<br/>        proba = preds[ind].max()<br/>        pred = preds[ind].argmax()<br/>        if pred == labels[ind]:<br/>            colour = 'green'<br/>        else:<br/>            colour = 'red'<br/>        plt.title(f"Prediction: {pred} ({proba:.1%})", fontsize=14, <br/>                  color=colour)<br/>    plt.suptitle(f'Sample {dataset} images with prediction', <br/>                 fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>inspect_sample_predictions(test_data, test_labels, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/9956df75833effd88e03baccbc538274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*kZBGk25_ZSWidiCUOJlV4w.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="3f71" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在来看看最不正确的预测(即最有可能的不正确预测):</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="9b50" class="ne md it na b gy nf ng l nh ni">def see_most_incorrect(data, labels, preds, dataset='test', seed=42, <br/>                       n_rows=2, n_cols=3):<br/>    df = pd.DataFrame()<br/>    df['true_class'] = labels<br/>    df['pred_class'] = preds.argmax(axis=1)<br/>    df['proba'] = preds.max(axis=1)<br/>    <br/>    incorrect_df = df.query("true_class!=pred_class")\<br/>                     .nlargest(n_rows*n_cols, 'proba')<br/>    <br/>    plt.figure(figsize=(8,5))<br/>    for i, (ind, row) in enumerate(incorrect_df.iterrows()):<br/>        ax = plt.subplot(n_rows, n_cols, i+1)<br/>        plt.imshow(data[ind], cmap='binary')<br/>        plt.axis('off')<br/>        true = int(row['true_class'])<br/>        proba = row['proba']<br/>        pred = int(row['pred_class'])<br/>    <br/>        plt.title(f"Actual: {true} \nPrediction: {pred} ({proba:.1%})", <br/>                  fontsize=14, color='red')<br/>    plt.suptitle(f'Most incorrect {dataset} images', fontsize=20)<br/>    plt.tight_layout();<br/>    <br/>see_most_incorrect(test_data, test_labels, test_preds_0)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/8544b709a0fc3d952bdf5e9d7a379bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*rJj3dpRHz9nZSxYs8S9cDw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="995d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们在打印概率时四舍五入到小数点后一位，所以这里的100.0%很可能代表像99.95这样的概率..%或99.99..%.这让我们看到了该模型肯定会出错的图像。即使对人类来说，第一个和最后一个图像也很难识别为6。</p><p id="cde3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看是否可以改进模型。</p><h2 id="3b80" class="ne md it bd me np nq dn mi nr ns dp mm kr nt nu mo kv nv nw mq kz nx ny ms nz bi translated">🔧模型1</h2><p id="8847" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">神经网络倾向于很好地处理介于0和1之间的数据。因此，我们将使用以下公式将数据重新调整到此范围:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/95efba19b70e864da3b105cada20c3da.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*1yEF61czXZBKf-erpNExdg.png"/></div></figure><p id="c989" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于像素值的范围在0(最小值)和255(最大值)之间，我们只需将值除以255即可缩放。除了重新调整，我们将保持其他一切和以前一样。一次改变一件事并理解它的影响是一个好习惯:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="157a" class="ne md it na b gy nf ng l nh ni">train_data_norm = train_data/255<br/>valid_data_norm = valid_data/255<br/>test_data_norm = test_data/255</span><span id="87b9" class="ne md it na b gy nj ng l nh ni">tf.random.set_seed(42)<br/>model_1 = Sequential([<br/>    Flatten(input_shape=(28, 28)),<br/>    Dense(16, activation="relu"),<br/>    Dense(16, activation="relu"),<br/>    Dense(n_classes, activation="softmax")<br/>])</span><span id="390f" class="ne md it na b gy nj ng l nh ni">model_1.compile(loss="categorical_crossentropy", optimizer='Adam',<br/>               metrics=["accuracy"])<br/>model_1.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/54dbdc88f4b5c181a82d6ea623530542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*Tspc15K3zfqkdTWKmyO98w.png"/></div></figure><p id="17b6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们根据重新调整后的数据训练编译后的模型:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="85fa" class="ne md it na b gy nf ng l nh ni">hist_1 = model_1.fit(<br/>    train_data_norm, train_labels_ohe, epochs=5, <br/>    validation_data=(valid_data_norm, valid_labels_ohe)<br/>)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/23dea3b9db015bbabe1b060ec759eb23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*jyAmyvxqmBwV6r2xAcaSYg.png"/></div></figure><p id="7e42" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过简单的预处理步骤，性能比以前好了很多！现在，让我们来看看各个时期的表现:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="1c63" class="ne md it na b gy nf ng l nh ni">sns.lineplot(data=clean_history(hist_1), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a5edfae6f06ae974b6f0f8ea56fa81d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*NEK_sZFBM81m5-TsP0_9bQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="d7d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是时候根据测试数据评估模型并将其添加到我们的<code class="fe oc od oe na b">test_metrics</code>数据框架中了。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="9c51" class="ne md it na b gy nf ng l nh ni">test_preds_1 = model_1.predict(test_data_norm)<br/>test_classes_1 = test_preds_1.argmax(axis=1)<br/>test_metrics.loc['model_1'] = np.mean(test_labels==test_classes_1)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/3ed7b7192b2f5e8437cc003f01e0e85f.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*YaW-td6meRlE1llxkr2m6w.png"/></div></figure><p id="032f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们通过一个简单的改变大大提高了模型的预测能力。让我们用混淆矩阵更仔细地看看性能:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="7dcb" class="ne md it na b gy nf ng l nh ni">show_confusion_matrix(test_labels, test_classes_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/9c5190e0a6d2318cbdd18e7de71e8270.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*Ead9XPx9coeM7qXFZJiwnw.png"/></div></figure><p id="5de6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，8不再经常与2混淆。现在最常见的错误就是混淆了4和9。这并不奇怪，因为在一些笔迹中，它们看起来确实很相似。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="90a7" class="ne md it na b gy nf ng l nh ni">inspect_sample_predictions(test_data_norm, test_labels, <br/>                           test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/082ff8d5e9f8ea9baf2c891e0f2c1b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*XbDS1eArt-0ik4oFiGBLig.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="57b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们使用相同的种子来抽取随机图像时，我们看到的是与之前相同的图像子集。我们可以看到，一些先前预测不正确的图像现在被正确预测了。很高兴看到正确的图像具有高概率，而不正确的图像具有较低的概率。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="caae" class="ne md it na b gy nf ng l nh ni">see_most_incorrect(test_data_norm, test_labels, test_preds_1)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/0a73013c1c3ca2743e22ea0067749af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*vRP9rrFN6sEgNnCSt1KowQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="50db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到仍有改进的余地。</p><p id="eb63" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看是否可以改进模型。</p><h2 id="c000" class="ne md it bd me np nq dn mi nr ns dp mm kr nt nu mo kv nv nw mq kz nx ny ms nz bi translated">🔧模型2</h2><p id="b6bd" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">我们将使用<code class="fe oc od oe na b">model_1</code>作为基础，并将隐藏层中的单元数量从16增加到64:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="3434" class="ne md it na b gy nf ng l nh ni">tf.random.set_seed(42)</span><span id="71cd" class="ne md it na b gy nj ng l nh ni">model_2 = Sequential([<br/>    Flatten(input_shape=(28, 28)),<br/>    Dense(64, activation="relu"),<br/>    Dense(64, activation="relu"),<br/>    Dense(n_classes, activation="softmax")<br/>])</span><span id="2060" class="ne md it na b gy nj ng l nh ni">model_2.compile(loss="categorical_crossentropy", optimizer='Adam',<br/>                metrics=["accuracy"])</span><span id="c3b3" class="ne md it na b gy nj ng l nh ni">model_2.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d00954f93ea80a7936ed13bef8c5d51c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*kQ6ABiiQzWC6pvYI8ZLg2Q.png"/></div></figure><p id="10e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于增加了单位数量，我们现在有了更多的参数。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="aa78" class="ne md it na b gy nf ng l nh ni">hist_2 = model_2.fit(<br/>    train_data_norm, train_labels_ohe, epochs=5, <br/>    validation_data=(valid_data_norm, valid_labels_ohe)<br/>)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/62461627e8c0af47473f618e1a46bb43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*X0tJtj29XF0AF_Apvo54oQ.png"/></div></figure><p id="ee98" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模型性能看起来比以前略好。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="906b" class="ne md it na b gy nf ng l nh ni">sns.lineplot(data=clean_history(hist_2), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/b989027060ffce54d28d6c6899a21639.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*ezQlSJhi7v5eBtgI4gYf4g.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="41e3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在过去的两个时代中，该模型略有过度拟合。让我们根据测试数据评估模型:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="642b" class="ne md it na b gy nf ng l nh ni">test_preds_2 = model_2.predict(test_data_norm)<br/>test_classes_2 = test_preds_2.argmax(axis=1)<br/>test_metrics.loc['model_2'] = np.mean(test_labels==test_classes_2)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/c40a8b3bc63bbc959093fe619825365a.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*8T5Yyi0_G6WAYN-sqHltHw.png"/></div></figure><p id="8e2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太棒了，很高兴看到我们仍然看到模型的改进。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="a1cb" class="ne md it na b gy nf ng l nh ni">show_confusion_matrix(test_labels, test_classes_2)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/74ffc6eef3f42d90081d456086d058a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*wtz16tm_vWJngztxx53W9w.png"/></div></figure><p id="d5ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">随着模型越来越精确，混淆矩阵看起来沿着对角线越来越集中，在剩余的单元中主要是浅灰色到白色的单元。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="6d0f" class="ne md it na b gy nf ng l nh ni">inspect_sample_predictions(test_data_norm, test_labels, <br/>                           test_preds_2)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/7d6cf266f267eac437b214c6d39e353a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*19IJ9gJq512e1UvaGjcjEQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="57dc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，模型得到了所有正确的样本图像！</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="7c54" class="ne md it na b gy nf ng l nh ni">see_most_incorrect(test_data_norm, test_labels, test_preds_2)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/47857a07d80a3d4ebb43385bceb2c556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*uJb7blz5CGwOjNGs5THx3w.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="f28d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">顶部中间的图像看起来很棘手，而其余的图像相对来说更容易被人类识别。</p><p id="1159" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看我们是否能最后一次改进模型。</p><h2 id="97aa" class="ne md it bd me np nq dn mi nr ns dp mm kr nt nu mo kv nv nw mq kz nx ny ms nz bi translated">🔧模型3</h2><p id="d3ec" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">卷积神经网络(CNN)可以很好地处理图像数据。现在让我们用一个简单的CNN来分析我们的数据。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="41a9" class="ne md it na b gy nf ng l nh ni">model_3 = Sequential([<br/>    Conv2D(32, 5, padding='same', activation='relu', <br/>           input_shape=(28,28,1)),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    Conv2D(32, 5, padding='same', activation='relu'),<br/>    MaxPooling2D(), <br/>    Flatten(),<br/>    Dense(128, activation='relu'),<br/>    Dense(n_classes, activation="softmax")<br/>])</span><span id="1fdc" class="ne md it na b gy nj ng l nh ni">model_3.compile(loss="categorical_crossentropy", optimizer='Adam',<br/>                metrics=["accuracy"])<br/>model_3.summary()</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/983338217ee2b9cee6b6f346c99763ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*HzQOgDGY09ioSYYZckBeXQ.png"/></div></figure><p id="b147" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们现在有了更多的参数。让我们训练模型:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="49dd" class="ne md it na b gy nf ng l nh ni">hist_3 = model_3.fit(<br/>    train_data_norm, train_labels_ohe, epochs=5, <br/>    validation_data=(valid_data_norm, valid_labels_ohe)<br/>)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/7182df7d5e49dbcaa4a30324d48ba3de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*hnahGJMkd9f_2Zo3SAcXzg.png"/></div></figure><p id="cfe1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">太棒了，性能似乎有轻微提高！</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="bd2f" class="ne md it na b gy nf ng l nh ni">sns.lineplot(data=clean_history(hist_3), x='epochs', y='accuracy', <br/>             hue='dataset');</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a4e5671958bc97b5d0b5ae5bc6701e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*3uA10XDlp89dhSKHqKM-vw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="9fe9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，该模型是非常轻微的过度拟合。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="4330" class="ne md it na b gy nf ng l nh ni">test_preds_3 = model_3.predict(test_data_norm)<br/>test_classes_3 = test_preds_3.argmax(axis=1)<br/>test_metrics.loc['model_3'] = np.mean(test_labels==test_classes_3)<br/>test_metrics</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/8b3039bb914aab45fd12ada7e400c01f.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*QPU7SNgxjiG8Ut28KFOVVQ.png"/></div></figure><p id="a6b1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">哇，我们已经达到99%的准确率了！✨</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="0968" class="ne md it na b gy nf ng l nh ni">show_confusion_matrix(test_labels, test_classes_3)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/b046f0ffb7e6156c28fb3b43d5122d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*es4ReLy0WjwQbzRWTxR-nQ.png"/></div></figure><p id="8551" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是迄今为止最好看的混淆矩阵。我们看到对角线上有许多零，一些数字的对角线上有1000+。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="1377" class="ne md it na b gy nf ng l nh ni">inspect_sample_predictions(test_data_norm, test_labels, <br/>                           test_preds_3)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/7ca0e90f7040928f824622fe11510532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*IpxP-5zlG7XU2UM4k1HlCw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="da7e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">像以前一样，样本图像被正确预测。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="ba43" class="ne md it na b gy nf ng l nh ni">see_most_incorrect(test_data_norm, test_labels, test_preds_3)</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/ac295e34642bd0631f01e5e5224b8f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*ChKAHsAfGxrjk5_Fh5Wubw.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片</p></figure><p id="11cf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中一些图像有点棘手，尤其是6s和7。这些6中的一个似乎也被<code class="fe oc od oe na b">model_2</code>认定为最不正确的预测之一。</p><p id="7c70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了节省时间，我们将在这里结束我们的模型实验。在实践中，几乎可以肯定的是，在我们确定一个模型之前，我们将不得不进行更多的迭代。在这篇文章中，我们看到每一次迭代都提高了我们的模型预测能力。然而，这在实践中并不总是正确的，因为一些实验想法并不奏效。这是正常的，只是实验方法的一种性质。</p><p id="a112" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然我们只探索了四个模型中的几个想法，但我们可以通过无数种方式扩展实验来改进模型。这里有一些尝试改进模型的方法:<br/> ◼️增加层数<br/> ◼️改变激活函数<br/> ◼️训练更长时间(即更多的时期)</p><p id="f965" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您正在处理众所周知的数据集，获得神经网络设计灵感的一种方法是查看领先的模型架构。例如，我们可以从代码为的<a class="ae le" href="https://paperswithcode.com/sota/image-classification-on-mnist" rel="noopener ugc nofollow" target="_blank">论文中看到MNIST数据集上的领先模型。写这篇文章的时候，</a><a class="ae le" href="https://paperswithcode.com/paper/an-ensemble-of-simple-convolutional-neural" rel="noopener ugc nofollow" target="_blank">简单CNN的齐次系综</a>正以99.91的准确率领先。如果你很好奇，你可以从<a class="ae le" href="https://arxiv.org/pdf/2008.10400v2.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中了解更多关于该模型及其架构的信息。此外，通常还有一个<a class="ae le" href="https://github.com/ansh941/MnistSimpleCNN" rel="noopener ugc nofollow" target="_blank">伴随代码</a>来进一步挖掘。由于大多数领先的模型往往有很强的性能，你的选择不仅仅局限于顶级模型。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="b716" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">🔐保存模型</h1><p id="c3d5" class="pw-post-body-paragraph ki kj it kk b kl mu ju kn ko mv jx kq kr mw kt ku kv mx kx ky kz my lb lc ld im bi translated">一旦我们对一个模型满意了，就有一个方便直观的方法来保存我们的模型:</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="90c4" class="ne md it na b gy nf ng l nh ni">model_3.save('model_3')</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/f848916d29b18138b260d42962069f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*ZJnym_8XUYwADcEWs1zkjQ.png"/></div></figure><p id="06e1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过保存模型，我们可以在下次加载模型，并直接使用它来进行预测，而不必从头开始构建。加载的模型的性能将与我们刚刚训练的模型完全相同。</p><pre class="lg lh li lj gt mz na nb nc aw nd bi"><span id="0237" class="ne md it na b gy nf ng l nh ni">loaded_model_3 = tf.keras.models.load_model('model_3')<br/>print(f"Test accuracy: {np.mean(loaded_model_3.predict(test_data_norm).argmax(axis=1)==test_labels):.1%}")</span></pre><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/5956e0c7cd77783a3d18f4f341c06cc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*sAD8_2Okaq9ogSZjl7IWIw.png"/></div></figure><p id="c143" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这就是这篇文章的全部内容！希望这篇文章简要介绍了使用Tensorflow构建基本的图像分类模型以及如何迭代改进结果。完成基本的图像分类后，我们将在系列的第2部分<a class="ae le" rel="noopener" target="_blank" href="/introduction-to-image-classification-with-tensorflow-part-2-219cf37aceef#d5c8-d9d3f896c5a">中通过查看更真实的图像来积累经验。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pe"><img src="../Images/9549d4aec8836ffc73e911e12256b841.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hamw7TUt86isugNu"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated"><a class="ae le" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">拥有摄影</a>的照片在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上</p></figure><p id="24ac" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="pf">您想访问更多这样的内容吗？媒体会员可以无限制地访问媒体上的任何文章。如果您使用</em> <a class="ae le" href="https://zluvsand.medium.com/membership" rel="noopener"> <em class="pf">我的推荐链接</em></a><em class="pf">成为会员，您的一部分会费将直接用于支持我。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="6e0e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">谢谢你看我的帖子。如果你感兴趣，这里有我的一些帖子的链接:</p><p id="92d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">◼️️ <a class="ae le" rel="noopener" target="_blank" href="/pipeline-columntransformer-and-featureunion-explained-f5491f815f?source=your_stories_page-------------------------------------">管道、ColumnTransformer和FeatureUnion解释</a> <br/> ◼️️ <a class="ae le" rel="noopener" target="_blank" href="/featureunion-columntransformer-pipeline-for-preprocessing-text-data-9dcb233dbcb6"> FeatureUnion、ColumnTransformer &amp;管道用于预处理文本数据</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/enrich-your-jupyter-notebook-with-these-tips-55c8ead25255">用这些提示丰富您的Jupyter笔记本</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/organise-your-jupyter-notebook-with-these-tips-d164d5dcd51f">用这些提示整理您的Jupyter笔记本</a> <br/> ◼️ <a class="ae le" rel="noopener" target="_blank" href="/explaining-scikit-learn-models-with-shap-61daff21b12a">解释Scikit-用SHAP学习模型</a> <br/> ◼️️ <a class="ae le" rel="noopener" target="_blank" href="/feature-selection-in-scikit-learn-dc005dcf38b7">在scikit中选择特性</a></p><p id="2e29" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">再见🏃 💨</p></div></div>    
</body>
</html>