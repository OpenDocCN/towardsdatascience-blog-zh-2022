<html>
<head>
<title>Why Accuracy Isn’t Everything: Precision and Recall Simply Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么准确性不是一切:精度和召回简单解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-accuracy-isnt-everything-precision-and-recall-simply-explained-25bc093c7cda#2022-03-21">https://towardsdatascience.com/why-accuracy-isnt-everything-precision-and-recall-simply-explained-25bc093c7cda#2022-03-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b8d3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">解释数据科学中精确度和召回率的重要性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b9347ca8aa78023e2a8f195022c236ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XgPVUvp1PZ_BgiH1"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阿菲夫·库苏马在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="c7c0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="5939" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">数据科学面试中的一个常见问题是<em class="mn">‘当你 99%的数据属于一个类别时，你如何衡量一个分类模型的性能？’</em></p><p id="8f60" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这是一个直截了当的问题，然而许多人却结结巴巴，不知道如何回答。</p><p id="fa24" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在本文中，我们将通过讨论<strong class="lt iu">召回率、精确度以及两者的调和平均值(F1 分数)来探索上述问题的答案。</strong></p><h1 id="3f45" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">准确性问题</h1><p id="79d0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们从解释为什么准确性可能不是一个好的衡量标准开始。如果 99%的数据集属于一个类，那么通过简单的猜测，任何模型都可以达到 99%的准确率！</p><p id="8ed7" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">该模型将简单地很好地学习来预测单个类别，从而获得与类别分布相等的准确度分数。</p><p id="f059" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">即使没有机器学习模型，我也可以纯粹猜测样本属于哪一类，准确率达到 99%！</p><p id="a007" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">因此，对于这个特殊的问题，精确度不是衡量模型性能的好指标。因此，我们必须寻求替代的测量方法。</p><blockquote class="mt mu mv"><p id="b6fd" class="lr ls mn lt b lu mo ju lw lx mp jx lz mw mq mc md mx mr mg mh my ms mk ml mm im bi translated">注意:有时准确性是一个很好的衡量标准，但这完全取决于作品的背景。</p></blockquote><h1 id="9445" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">混淆矩阵</h1><p id="44e0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们继续之前，理解<strong class="lt iu">混淆矩阵</strong>很重要。这将您的结果分为正确和不正确的两类<strong class="lt iu">分类</strong>,在测量性能时比测量准确度更能提供信息。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/a64a835fbcd144210a5cbe640116cae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CX6LIPYFcc4RHhi5u5FQDw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者生成的图像。</p></figure><p id="a865" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">每个象限显示了我们对这两个类别的分类情况。我们可能有 99%的准确率，但我们可能总是错误地分类 1%的类别！</p><p id="3472" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这显然是不好的，我们可以从混淆矩阵中推断出这一信息，以确保我们充分预测了这两个类别。</p><p id="b592" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">下面是我使用 Sci-Kit Learn 的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵函数</a>为基本逻辑回归分类器用 Python 编写的一个生成的混淆矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/003b1767cb62a4478e93c0eaca9ac8da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*Qjgfj2RLD4VG28qgsfJUcQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者用 Python 制作的图像。</p></figure><p id="0291" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">用于生成上述图的完整代码可以在我的 GitHub 上找到，如下所示:</p><div class="nb nc gp gr nd ne"><a href="https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Precision_Recall.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">Medium-Articles/Precision _ recall . ipynb at main egorhowell/Medium-Articles</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">我在我的媒体博客/文章中使用的代码。通过创建一个关于…的帐户，为 egorhowell/Medium-Articles 的开发做出贡献</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ks ne"/></div></div></a></div><h1 id="2ee3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">精确</h1><p id="56c2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">精度度量:<strong class="lt iu">在我们预测为真的样本中，有多少是真的。</strong></p><p id="0d4a" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">从数学上来说，这可以计算为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/145d047ac671b1ba9c7c3d0359040edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*c2JruP23RJbA_4zQAx6ZEw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者用 LaTeX 制作的图像。</p></figure><blockquote class="mt mu mv"><p id="ab05" class="lr ls mn lt b lu mo ju lw lx mp jx lz mw mq mc md mx mr mg mh my ms mk ml mm im bi translated">假阳性在统计学中被称为第一类错误。</p></blockquote><p id="cd30" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">如果样本的概率为<strong class="lt iu"> ≥ 0.5 </strong>，大多数算法将该样本指定为阳性，如果<strong class="lt iu"> &lt; 0.5 </strong>，则将该样本指定为阴性。该边界值被称为<strong class="lt iu">阈值。</strong>当我们增加阈值时，<strong class="lt iu">精度也增加并趋向于 1。</strong></p><p id="68c9" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">这是有意义的，因为概率为 0.9 的样本比概率为 0.5 的样本更有可能是阳性的。因此，我们对放入阳性类别的样本更具选择性和精确性。</p><p id="8189" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">当我们想要高度选择性和正确地将哪个样本分类为真实样本时，例如<strong class="lt iu">电子邮件垃圾邮件检测</strong>，就需要使用 Precision。</p><h1 id="ed5a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">回忆</h1><p id="910d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">召回措施:<strong class="lt iu">在所有真实样本中，我们正确地将多少归类为真实。</strong></p><p id="cde2" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在数学上，它的计算方法是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/35400ea0fd529da3605d4fb288f4e475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*4D3_2N6zcLaI3YfZcmLSLg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者用 LaTeX 制作的图像。</p></figure><blockquote class="mt mu mv"><p id="63a9" class="lr ls mn lt b lu mo ju lw lx mp jx lz mw mq mc md mx mr mg mh my ms mk ml mm im bi translated">假阴性在统计学中被称为<strong class="lt iu">第二类</strong>错误。</p></blockquote><p id="b933" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu">随着阈值的降低，召回率增加并趋于 1。</strong>这是因为我们开始将越来越多的样本归类为阳性，最终，在阈值为 0 时，一切都是阳性的。因此，我们不会有假阴性，因此 Recall 将等于 1。</p><p id="469d" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">当我们想要确保捕获所有真正的阳性时，回忆是有用的，即使这意味着增加我们的假阳性(假警报)。这很重要，例如，在癌症检测的情况下，标记它比不标记它更重要。</p><h1 id="e799" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">F1 分数</h1><p id="125f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">然而，我们现在有一个问题。提高阈值可以最大限度地提高准确率，但会降低召回率。那么解决办法是什么呢？</p><p id="2838" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated"><strong class="lt iu"> F1 得分</strong>是通过取召回率和精确度之间的<strong class="lt iu">调和平均值</strong>而在召回率和精确度之间折衷的值；</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/2e2eaae79351c1044fe30e2468118f0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*zrPQXWAeAaZH3sWACy6JKw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者用 LaTeX 制作的图像。</p></figure><p id="8c66" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">我们使用调和平均值的原因是为了<strong class="lt iu">放大极值</strong>的影响。例如，假设我们的精度为 0.9，召回率为 0。这个的算术平均值是 0.45。然而，相应的模型显然是不好的，因为我们将捕捉到非常少的真正的积极因素。</p><h1 id="fd52" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">召回率、精确度和 F1 与阈值图</h1><p id="b3cf" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下面是使用<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html" rel="noopener ugc nofollow" target="_blank"> Sci-Kit Learn 的精确回忆曲线函数</a>的我的基本逻辑回归模型的回忆、精确和 F1 分数作为阈值的函数的图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/ee5fd06388fbfd63394254d87dc58cd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VWm_dADhJgZxKgxCv8siug.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者用 Python 生成的图像。</p></figure><p id="0a02" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">生成上述图形的完整代码可以在我的 GitHub 中找到:</p><div class="nb nc gp gr nd ne"><a href="https://github.com/egorhowell/Medium-Articles/blob/main/Data%20Science%20Basics/Precision_Recall.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd iu gy z fp nj fr fs nk fu fw is bi translated">Medium-Articles/Precision _ recall . ipynb at main egorhowell/Medium-Articles</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">我在我的媒体博客/文章中使用的代码。通过创建一个关于…的帐户，为 egorhowell/Medium-Articles 的开发做出贡献</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ks ne"/></div></div></a></div><p id="ad2f" class="pw-post-body-paragraph lr ls it lt b lu mo ju lw lx mp jx lz ma mq mc md me mr mg mh mi ms mk ml mm im bi translated">在上图中，我们看到当阈值较低时，召回率为 1，而当阈值较高时，精确度为 1。此外，请注意当回忆开始减少时，F1 分数如何显著下降，这表明调和平均值如何惩罚极值。</p><h1 id="15f5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="28fb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我们已经讨论了为什么准确性并不总是您的模型的最佳性能指标。相反，你应该确定它的精确度和回忆分数，以及一个混淆矩阵来全面分析你的结果。当您有一个不平衡的数据集以确保您的模型按预期执行时，这一点尤其重要。</p></div><div class="ab cl nx ny hx nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="im in io ip iq"><h1 id="44a2" class="kz la it bd lb lc oe le lf lg of li lj jz og ka ll kc oh kd ln kf oi kg lp lq bi translated">和我联系！</h1><ul class=""><li id="ca40" class="oj ok it lt b lu lv lx ly ma ol me om mi on mm oo op oq or bi translated">要在媒体上阅读无限的故事，请务必在此注册！T3<em class="mn">T5】💜</em></li><li id="9786" class="oj ok it lt b lu os lx ot ma ou me ov mi ow mm oo op oq or bi translated"><a class="ae ky" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank"> <em class="mn">当我在这里发布注册邮件通知时，可以获得更新！</em> </a> <em class="mn"> </em>😀</li><li id="b8dc" class="oj ok it lt b lu os lx ot ma ou me ov mi ow mm oo op oq or bi translated"><a class="ae ky" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"> <em class="mn">领英</em> </a> <em class="mn"> </em>👔</li><li id="a7a0" class="oj ok it lt b lu os lx ot ma ou me ov mi ow mm oo op oq or bi translated"><a class="ae ky" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="mn">推特</em> </a> <em class="mn"> </em> 🖊</li><li id="fb18" class="oj ok it lt b lu os lx ot ma ou me ov mi ow mm oo op oq or bi translated"><a class="ae ky" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="mn">github</em></a><em class="mn"/>🖥</li><li id="87b0" class="oj ok it lt b lu os lx ot ma ou me ov mi ow mm oo op oq or bi translated"><a class="ae ky" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="mn"/></a><em class="mn"/>🏅</li></ul><blockquote class="mt mu mv"><p id="72f1" class="lr ls mn lt b lu mo ju lw lx mp jx lz mw mq mc md mx mr mg mh my ms mk ml mm im bi translated">(所有表情符号由<a class="ae ky" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计——开源表情符号和图标项目。许可证:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>