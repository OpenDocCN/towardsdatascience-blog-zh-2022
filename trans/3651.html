<html>
<head>
<title>How to Explain Image Classifiers Using LIME</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用石灰解释图像分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-explain-image-classifiers-using-lime-e364097335b4#2022-08-14">https://towardsdatascience.com/how-to-explain-image-classifiers-using-lime-e364097335b4#2022-08-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="1769" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">学习如何应用流行的可解释人工智能(XAI)方法来解释图像分类器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9203f997c379654fa3d6108db6b7eb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7F94Odo-Yf-JJ2erFKwog.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用石灰解释图像(作者提供的图像)</p></figure><p id="5783" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">局部可解释模型不可知解释(LIME) </strong>是最流行的<strong class="la iu">可解释AI (XAI) </strong>方法之一，用于解释机器学习和深度学习模型的工作。LIME可以为解决回归和分类问题提供模型不可知的局部解释，它可以应用于结构化数据集，甚至可以应用于文本和图像等非结构化数据集。在本文中，您将更深入地了解如何使用LIME来解释基于深度学习的图像分类器以及代码演练。</p><p id="aa0b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你对XAI概念不太熟悉，我强烈推荐你观看过去在2021年APAC人工智能加速器节上发表的关于XAI的演讲:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="ef12" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你也可以浏览我的书<a class="ae lw" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">应用机器学习可解释技术</strong> </a> <strong class="la iu"> </strong>并看看<a class="ae lw" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/" rel="noopener ugc nofollow" target="_blank">代码库</a>以获得对其他XAI方法的实际接触。在本文中，我将参考《应用机器学习可解释技术》<a class="ae lw" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"><strong class="la iu"/></a><strong class="la iu">一书中提供的LIME在图像分类器中的实际应用。</strong></p><div class="lx ly gp gr lz ma"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.amazon.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><p id="9b4d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想得到关于这本书的详细反馈，这个视频可能对你有用:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lu lv l"/></div></figure><p id="6545" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们开始吧！</p><h1 id="27cf" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">将石灰应用于图像分类器</h1><p id="acb7" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">使用传统的要素重要性方法和其他框架，如莱姆和SHAP，解释表格数据集仍然很容易。然而，主要的挑战总是在解释基于图像等非结构化数据训练的复杂深度学习模型时出现。</p><p id="d997" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通常，深度学习模型在图像数据上比传统的ML模型更有效，因为这些模型具有执行自动特征提取的能力。它们可以提取复杂的低级特征，如条纹、边缘、轮廓、拐角和图案，甚至更高级的特征，如较大的形状和物体的某些部分。这些高级特征通常被称为图像中的<strong class="la iu">感兴趣区域(RoI) </strong>，或<strong class="la iu">超像素</strong>，因为它们是图像中覆盖图像特定区域的像素集合。</p><p id="da21" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，低级特征不是人类可解释的，但是高级特征是人类可解释的，因为任何非技术终端用户都将关于高级特征来联系图像。石灰也以类似的方式工作。该算法试图突出显示图像中对模型决策过程有积极或消极影响的超像素。那么，让我们看看如何使用LIME来解释图像分类器。</p><div class="lx ly gp gr lz ma"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.amazon.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><h1 id="3537" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">设置所需的Python模块</h1><p id="c583" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">在我们开始代码演练之前，请检查<a class="ae lw" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter05/LIME_with_image_data.ipynb" rel="noopener ugc nofollow" target="_blank">代码库</a>中提供的笔记本。笔记本包含实际应用这些概念所需的必要细节。在这一节中，我将向您演示代码，并解释笔记本教程中涵盖的所有步骤。如果尚未安装Python库的升级版本，请使用以下命令进行安装:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="2fa7" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">!</strong>pip install --upgrade pandas numpy matplotlib seaborn tensorflow lime scikit-image</span></pre><h1 id="8d0c" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">导入Python Jupyter笔记本中已安装的模块</h1><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="4ab3" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">import</strong> warnings<br/>warnings<strong class="nn iu">.</strong>filterwarnings("ignore")<br/><strong class="nn iu">import</strong> os<br/>os<strong class="nn iu">.</strong>environ['TF_CPP_MIN_LOG_LEVEL'] <strong class="nn iu">=</strong> '3'<br/><br/><strong class="nn iu">import</strong> numpy <strong class="nn iu">as</strong> np<br/><strong class="nn iu">import</strong> matplotlib.pyplot <strong class="nn iu">as</strong> plt<br/><strong class="nn iu">import</strong> matplotlib.cm <strong class="nn iu">as</strong> c_map<br/><strong class="nn iu">from</strong> IPython.display <strong class="nn iu">import</strong> Image, display<br/><strong class="nn iu">import</strong> tensorflow <strong class="nn iu">as</strong> tf<br/><strong class="nn iu">from</strong> tensorflow <strong class="nn iu">import</strong> keras<br/><strong class="nn iu">from</strong> tensorflow.keras.applications.xception <strong class="nn iu">import</strong> Xception, preprocess_input, decode_predictions<br/><strong class="nn iu">from</strong> tensorflow.keras.preprocessing <strong class="nn iu">import</strong> image<br/><br/><strong class="nn iu">import</strong> lime<br/><strong class="nn iu">from</strong> lime <strong class="nn iu">import</strong> lime_image<br/><strong class="nn iu">from</strong> lime <strong class="nn iu">import</strong> submodular_pick<br/><br/><strong class="nn iu">from</strong> skimage.segmentation <strong class="nn iu">import</strong> mark_boundaries<br/><br/>np<strong class="nn iu">.</strong>random<strong class="nn iu">.</strong>seed(123)</span></pre><p id="7ee8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以打印安装在您的设置中的tensorflow版本。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="6b21" class="nr mq it nn b gy ns nt l nu nv">print(f" Version of tensorflow used: {tf<strong class="nn iu">.</strong>__version__}")</span><span id="4505" class="nr mq it nn b gy nw nt l nu nv">Version of tensorflow used: 2.3.1</span></pre><h1 id="7947" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">加载数据</h1><p id="1558" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">因为我们更感兴趣的是检查如何使用LIME解释黑盒图像分类器，所以我们将只关注推理部分。让我们加载任何通用的图像数据。对于这个例子，我们将从这个来源获取数据:<a class="ae lw" href="https://unsplash.com/photos/GBDkr3k96DE" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/GBDkr3k96DE</a></p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="79bd" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">def</strong> load_image_data_from_url(url):<br/>    '''<br/>    Function to load image data from online<br/>    '''<br/>    <em class="nx"># The local path to our target image</em><br/>    image_path <strong class="nn iu">=</strong> keras<strong class="nn iu">.</strong>utils<strong class="nn iu">.</strong>get_file(<br/>    "shark.jpg", url<br/>    )<br/><br/>    display(Image(image_path))<br/>    <strong class="nn iu">return</strong> image_path<br/><br/>image_path <strong class="nn iu">=</strong> load_image_data_from_url(url <strong class="nn iu">=</strong> "<a class="ae lw" href="https://images.unsplash.com/photo-1560275619-4662e36fa65c?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80" rel="noopener ugc nofollow" target="_blank">https://images.unsplash.com/photo-1560275619-4662e36fa65c?ixlib=rb-1.2.1&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80</a>")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/c39048f6bde1e3f04e618f053509e833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q4bwbWJs1DPda0gW01meeA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源—Unsplash—<a class="ae lw" href="https://unsplash.com/photos/GBDkr3k96DE" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/GBDkr3k96DE</a></p></figure><p id="3fb6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将对图像进行一些初始数据预处理。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="7181" class="nr mq it nn b gy ns nt l nu nv">IMG_SIZE <strong class="nn iu">=</strong> (299, 299)<br/><strong class="nn iu">def</strong> transform_image(image_path, size):<br/>    '''<br/>    Function to transform an image to normalized numpy array<br/>    '''<br/>    img <strong class="nn iu">=</strong> image<strong class="nn iu">.</strong>load_img(image_path, target_size<strong class="nn iu">=</strong>size)<br/>    img <strong class="nn iu">=</strong> image<strong class="nn iu">.</strong>img_to_array(img)<em class="nx"># Transforming the image to get the shape as [channel, height, width]</em><br/>    img <strong class="nn iu">=</strong> np<strong class="nn iu">.</strong>expand_dims(img, axis<strong class="nn iu">=</strong>0) <em class="nx"># Adding dimension to convert array into a batch of size (1,299,299,3)</em><br/>    img <strong class="nn iu">=</strong> img<strong class="nn iu">/</strong>255.0 <em class="nx"># normalizing the image to keep within the range of 0.0 to 1.0</em><br/>    <br/>    <strong class="nn iu">return</strong> img<br/><br/>normalized_img <strong class="nn iu">=</strong> transform_image(image_path, IMG_SIZE)</span></pre><h1 id="9b45" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">使用预先训练的张量流模型作为我们的黑盒模型</h1><p id="ff08" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">对于本教程，我们使用预训练的TensorFlow Keras异常模型作为我们的黑盒模型。该模型在ImageNet数据集(<a class="ae lw" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">https://www.image-net.org/</a>)上进行预训练，这是最流行的图像分类基准数据集之一。预训练模型可以加载以下代码行:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="dd9c" class="nr mq it nn b gy ns nt l nu nv">from tensorflow.keras.applications.xception import Xception</span><span id="5a4c" class="nr mq it nn b gy nw nt l nu nv">model = Xception(weights="imagenet")</span></pre><p id="4f73" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们使用预训练的XceptionNet模型来生成预测。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="b1f7" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">def</strong> get_model_predictions(data):<br/>    model_prediction <strong class="nn iu">=</strong> model<strong class="nn iu">.</strong>predict(data)<br/>    print(f"The predicted class is : {decode_predictions(model_prediction, top<strong class="nn iu">=</strong>1)[0][0][1]}")<br/>    <strong class="nn iu">return</strong> decode_predictions(model_prediction, top<strong class="nn iu">=</strong>1)[0][0][1]<br/><br/>plt<strong class="nn iu">.</strong>imshow(normalized_img[0])<br/>pred_orig <strong class="nn iu">=</strong> get_model_predictions(normalized_img)</span></pre><p id="232d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这将预测以下输出:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="3b8b" class="nr mq it nn b gy ns nt l nu nv">The predicted class is : tiger_shark</span></pre><p id="077e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">图像被预测为<em class="nx">虎鲨</em>，这是正确的预测，并且黑盒模型能够成功地给出正确的预测。现在，让我们看看前5个预测以及模型置信度。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="822d" class="nr mq it nn b gy ns nt l nu nv">model_prediction <strong class="nn iu">=</strong> model<strong class="nn iu">.</strong>predict(normalized_img)<br/>top5_pred <strong class="nn iu">=</strong> decode_predictions(model_prediction, top<strong class="nn iu">=</strong>5)[0]<br/><strong class="nn iu">for</strong> pred <strong class="nn iu">in</strong> top5_pred:<br/>    print(pred[1])</span></pre><p id="857b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型生成的前5个预测是:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="ba40" class="nr mq it nn b gy ns nt l nu nv">tiger_shark<br/>great_white_shark<br/>hammerhead<br/>scuba_diver<br/>sturgeon</span></pre><p id="726f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们所看到的，尽管该模型被很好地训练以产生正确的预测，但该模型有可能不只是查看图像中的主要对象，而是查看周围的背景。这一点从<em class="nx">水肺_驾驶员</em>出现在前5预测列表的预测中可见一斑。因此，理解模型用来进行预测的图像的关键组件或部分对我们来说很重要。</p><div class="lx ly gp gr lz ma"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.amazon.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><h1 id="eecc" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">用石灰解释模型</h1><p id="0e04" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">在本小节中，我们将了解如何使用LIME框架从模型使用的图像中识别超像素或区域，以预测具体结果。我们首先需要定义一个图像解释器对象:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="d2e5" class="nr mq it nn b gy ns nt l nu nv">explainer <strong class="nn iu">=</strong> lime_image<strong class="nn iu">.</strong>LimeImageExplainer()</span></pre><p id="d3c0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">接下来，我们需要将推断数据(normalized_img[0])传递给explainer对象，并使用LIME框架来突出显示对模型预测有最大积极和消极影响的超像素:</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="47c1" class="nr mq it nn b gy ns nt l nu nv">exp <strong class="nn iu">=</strong> explainer<strong class="nn iu">.</strong>explain_instance(normalized_img[0], <br/>                                 model<strong class="nn iu">.</strong>predict, <br/>                                 top_labels<strong class="nn iu">=</strong>5, <br/>                                 hide_color<strong class="nn iu">=</strong>0, <br/>                                 num_samples<strong class="nn iu">=</strong>1000)</span></pre><p id="2b0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的explainer对象已经准备好了，但是让我们来可视化由LIME算法创建的各种解释片段。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="46a1" class="nr mq it nn b gy ns nt l nu nv">plt<strong class="nn iu">.</strong>imshow(exp<strong class="nn iu">.</strong>segments)<br/>plt<strong class="nn iu">.</strong>axis('off')<br/>plt<strong class="nn iu">.</strong>show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/94b49c8e7d42fe73aa334d3ea26a650f.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*2mfCQGiYkzlBeyr8ApHaBA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由LIME生成的热图图像对我们推断的sharp图像(图片由作者提供)</p></figure><p id="2650" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们使用顶部片段或超级像素来识别模型用来进行预测的图像的感兴趣区域。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="8c34" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">def</strong> generate_prediction_sample(exp, exp_class, weight <strong class="nn iu">=</strong> 0.1, show_positive <strong class="nn iu">=</strong> <strong class="nn iu">True</strong>, hide_background <strong class="nn iu">=</strong> <strong class="nn iu">True</strong>):<br/>    '''<br/>    Method to display and highlight super-pixels used by the black-box model to make predictions<br/>    '''<br/>    image, mask <strong class="nn iu">=</strong> exp<strong class="nn iu">.</strong>get_image_and_mask(exp_class, <br/>                                         positive_only<strong class="nn iu">=</strong>show_positive, <br/>                                         num_features<strong class="nn iu">=</strong>6, <br/>                                         hide_rest<strong class="nn iu">=</strong>hide_background,<br/>                                         min_weight<strong class="nn iu">=</strong>weight<br/>                                        )<br/>    plt<strong class="nn iu">.</strong>imshow(mark_boundaries(image, mask))<br/>    plt<strong class="nn iu">.</strong>axis('off')<br/>    plt<strong class="nn iu">.</strong>show()</span><span id="260a" class="nr mq it nn b gy nw nt l nu nv">generate_prediction_sample(exp, exp<strong class="nn iu">.</strong>top_labels[0], show_positive <strong class="nn iu">=</strong> <strong class="nn iu">True</strong>, hide_background <strong class="nn iu">=</strong> <strong class="nn iu">True</strong>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/dfbbeeafb81f8e35b75268ceb53d1d2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*3g-mnAg11fSpBh7eQpHtSg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LIME拾取的最重要的超级像素预测输出为虎鲨<em class="ob">(图片由作者提供)</em></p></figure><p id="78cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从上图中我们可以看到，模型能够识别正确的区域，这表明模型对结果的预测是正确的。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="bdd3" class="nr mq it nn b gy ns nt l nu nv">generate_prediction_sample(exp, exp<strong class="nn iu">.</strong>top_labels[0], show_positive <strong class="nn iu">=</strong> <strong class="nn iu">True</strong>, hide_background <strong class="nn iu">=</strong> <strong class="nn iu">False</strong>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/47ff964542d163dd48eeb14994238bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*68gZI8JOHIKuiu59ce_sXA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由LIME拾取的最重要的超像素，用于预测输出，如带有背景图像的虎鲨<em class="ob">(图片由作者提供)</em></p></figure><p id="6011" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如我们从前面的图像中看到的，我们也可以只突出超像素的轮廓，并包括背景。但是我们也可以突出正超像素和负超像素。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="458f" class="nr mq it nn b gy ns nt l nu nv">generate_prediction_sample(exp, exp<strong class="nn iu">.</strong>top_labels[0], show_positive <strong class="nn iu">=</strong> <strong class="nn iu">False</strong>, hide_background <strong class="nn iu">=</strong> <strong class="nn iu">False</strong>)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/958bfe44af2d2e80caba2b75cb217788.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*jWqMJWHl1k7yhvAmBN0s3A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由LIME拾取的最重要的超像素预测输出为虎鲨，背景图像和绿色覆盖突出显示正面区域<em class="ob">(作者提供的图像)</em></p></figure><p id="302d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上述示例向我们展示了如何隐藏或显示背景以及超像素，甚至勾勒或突出显示超像素，以识别模型用于进行预测的感兴趣区域。我们从这里看到的确实有意义，也确实让我们增加了对黑盒模型的信任。我们还可以形成一个热图来显示每个超像素对于获得更精细的解释能力有多重要。</p><pre class="kj kk kl km gt nm nn no np aw nq bi"><span id="03da" class="nr mq it nn b gy ns nt l nu nv"><strong class="nn iu">def</strong> explanation_heatmap(exp, exp_class):<br/>    '''<br/>    Using heat-map to highlight the importance of each super-pixel for the model prediction<br/>    '''<br/>    dict_heatmap <strong class="nn iu">=</strong> dict(exp<strong class="nn iu">.</strong>local_exp[exp_class])<br/>    heatmap <strong class="nn iu">=</strong> np<strong class="nn iu">.</strong>vectorize(dict_heatmap<strong class="nn iu">.</strong>get)(exp<strong class="nn iu">.</strong>segments) <br/>    plt<strong class="nn iu">.</strong>imshow(heatmap, cmap <strong class="nn iu">=</strong> 'RdBu', vmin  <strong class="nn iu">=</strong> <strong class="nn iu">-</strong>heatmap<strong class="nn iu">.</strong>max(), vmax <strong class="nn iu">=</strong> heatmap<strong class="nn iu">.</strong>max())<br/>    plt<strong class="nn iu">.</strong>colorbar()<br/>    plt<strong class="nn iu">.</strong>show()<br/><br/>explanation_heatmap(exp, exp<strong class="nn iu">.</strong>top_labels[0])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/30ce136139bdd29502108d8ab41efb74.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*Fa6LUNAv3hDUpv4rRaMBVg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用石灰的解释热图(图片由作者提供)</p></figure><div class="lx ly gp gr lz ma"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.amazon.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><h1 id="cc59" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">摘要</h1><p id="9214" class="pw-post-body-paragraph ky kz it la b lb nh ju ld le ni jx lg lh nj lj lk ll nk ln lo lp nl lr ls lt im bi translated">正如我们在本笔记中清楚看到的，LIME可以轻松地用于解释图像分类器。下次，每当你致力于训练深度学习模型来对图像进行分类时，我会强烈建议你尝试用LIME来解释你的模型，并了解模型是否正在研究图像的正确区域，以做出最终预测！如果你喜欢这篇文章，并想了解更多关于如何应用LIME来解释ML模型的信息，我推荐阅读这本书:<a class="ae lw" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">【应用机器学习可解释技术】</strong> </a> <strong class="la iu"> </strong>并探索<a class="ae lw" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>以获得实际操作的代码示例。</p><h1 id="91fb" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">作者关于TDS的其他XAI相关文章:</h1><ol class=""><li id="bbc4" class="of og it la b lb nh le ni lh oh ll oi lp oj lt ok ol om on bi translated"><a class="ae lw" rel="noopener" target="_blank" href="/explainable-machine-learning-for-models-trained-on-text-data-combining-shap-with-transformer-5095ea7f3a8">用于在文本数据上训练的模型的可解释机器学习:将SHAP与变压器模型相结合</a></li><li id="b9e7" class="of og it la b lb oo le op lh oq ll or lp os lt ok ol om on bi translated"><a class="ae lw" rel="noopener" target="_blank" href="/euca-an-effective-xai-framework-to-bring-artificial-intelligence-closer-to-end-users-74bb0136ffb1">EUCA——一个有效的XAI框架，让人工智能更贴近终端用户</a></li><li id="72f8" class="of og it la b lb oo le op lh oq ll or lp os lt ok ol om on bi translated"><a class="ae lw" rel="noopener" target="_blank" href="/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e">理解可解释人工智能中使用的SHAP和沙普利值的工作原理</a></li></ol><div class="lx ly gp gr lz ma"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd iu gy z fp mf fr fs mg fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">www.amazon.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo ks ma"/></div></div></a></div><h1 id="88bb" class="mp mq it bd mr ms mt mu mv mw mx my mz jz na ka nb kc nc kd nd kf ne kg nf ng bi translated">参考</h1><ol class=""><li id="761f" class="of og it la b lb nh le ni lh oh ll oi lp oj lt ok ol om on bi translated">GitHub中的LIME开源Python框架—<a class="ae lw" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">https://github.com/marcotcr/lime</a></li><li id="d823" class="of og it la b lb oo le op lh oq ll or lp os lt ok ol om on bi translated">应用机器学习解释技术</li><li id="4940" class="of og it la b lb oo le op lh oq ll or lp os lt ok ol om on bi translated">GitHub repo自《应用机器学习可解释技术》——<a class="ae lw" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques/</a></li></ol></div></div>    
</body>
</html>