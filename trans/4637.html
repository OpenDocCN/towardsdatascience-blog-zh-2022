<html>
<head>
<title>Solving NLP Problems Quickly with IBM Watson NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用IBM Watson NLP快速解决NLP问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/solving-nlp-problems-quickly-with-ibm-watson-nlp-42fa50900a47#2022-10-14">https://towardsdatascience.com/solving-nlp-problems-quickly-with-ibm-watson-nlp-42fa50900a47#2022-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="05b0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">让我们探索IBM Watson NLP提供的一些现成的NLP模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/eaf21c47cc2ebcf5df1e0876e1fc5016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*kVNNoCJ1eOkH_K1-JgOYNA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来源:<a class="ae kr" href="https://pixabay.com/illustrations/emotions-emoji-emoticons-icons-5153993/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="2dbb" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">作为数据科学家，在开始开发模型之前，通过尝试查找和下载开源模型或自己开发模型，将所有这些方便地用几行代码实现不是很好吗？这正是我今天在这篇博文中要向你展示的。使用<a class="ae kr" href="https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/watson-nlp.html?context=cpdaas&amp;audience=wdp" rel="noopener ugc nofollow" target="_blank"> Watson NLP </a>，您可以获得大量NLP用例的最先进的预训练模型，这些模型可以让您在几个小时内启动并运行。如果需要的话，这些模型还可以用定制的领域特定知识进行再培训。</p><p id="cd19" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这个例子中，我们将采用情感分析的NLP用例；我们需要做三件事。</p><ol class=""><li id="57b4" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated">提取文本的情感。</li><li id="b951" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">提取自定义目标提及。</li><li id="24e4" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">提取目标词的情感。</li></ol><p id="d489" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于这个例子，我们将使用IMDB上关于《权力的游戏前传，龙之家》的评论。以下是评论。</p><blockquote class="mc md me"><p id="816b" class="ks kt mf ku b kv kw jr kx ky kz ju la mg lc ld le mh lg lh li mi lk ll lm ln ij bi translated">这种情况经常发生在一部非常成功的电视剧取得成功后制作续集或前传的时候……一旦设定了基准，就很难遵循，如果不是不可能的话……这里的情况就是如此..这个规则也有例外，比如旧的原版系列的《太空堡垒卡拉狄加》翻拍版，其中的继任者在每个指标上都超过了原版..因此，它发生了，但不是在这里与GOT…马上，最初的开放场景与龙和年轻的女孩谁是我想，这显示了版本的Daneerys，所有这些场景显示了一个CGI严重缺乏相比，GOT…颜色palete看起来褪色，缺乏细节，真的，它看起来像一个电脑渲染的背景，不会愚弄任何人…是的，这是电脑渲染，但一个好的CGI不会引起人们的注意..它会让你相信…但在这里不是这样的…开场中的龙看起来很狂野，因为原版中的龙是以最高级别的电影质量呈现的…坦率地说，这里的龙看起来很可怜，缺乏细节，威胁或纯粹的存在…它不存在…在这场表演中有10条龙，也许这是一窝中最矮小的，但他们应该做得更好..至于表演，最初我对演员阵容感到失望，正如许多人评论的那样，我没有感觉到与这里的任何人有直接的联系……在费力地看完这部剧的前半部分后，我要说的是，原版《GOT》的氛围和氛围的元素在那里，并注入了一些场景， 尤其是那些小公主和她的父亲以及父亲和达蒙的对话…它不是完全不存在，它是存在的，但以一种更轻的预算节目的形式，演员、效果和布景较低…它不是那么糟糕，你不能进入它，我建议暂停肯定会来的判断，直到你在系列中有几个节目…几乎没有任何新的系列不需要几个节目 大部分新演员感觉僵硬和呆板，因为演员们刚刚进入角色，还没有完全融入角色，没有达到令人信服的程度…是的，这部剧也在做wokeness主题和政治正确的多样性舞蹈，就像这些天的所有事情一样 ..这就是它，它是新世界意识的一部分，它注入了一切…当作家和演员试图符合并使故事符合这些当前趋势时，它看起来太“强迫”而不是故事情节的自然表达…也就是说，如果你喜欢GOT，我也喜欢，那么这当然值得一看，看看它是如何演变的…当一个最喜欢的系列被进一步表达时，为什么要抱怨呢？享受它的本来面目，那些不想看到它的人，打开别的东西……就这么简单！</p></blockquote><p id="5352" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于这个练习，我们将需要语法分析模型(处理基本的自然语言处理操作，如标记化、词汇化、词性标注等)，一个基于规则的提及模型，检测目标关键字在哪里被提及，以及一个目标情感模型。</p><h2 id="f128" class="mj mk iq bd ml mm mn dn mo mp mq dp mr lb ms mt mu lf mv mw mx lj my mz na nb bi translated">下载并加载模型。</h2><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="815a" class="mj mk iq nd b gy nh ni l nj nk">import watson_nlp<br/>from watson_nlp.toolkit.sentiment_analysis_utils.output.document_sentimet import predict_document_sentiment</span><span id="737f" class="mj mk iq nd b gy nl ni l nj nk"># download and load the Syntax model<br/>syntax_model = watson_nlp.download_and_load(‘syntax_izumo_en_stock’)</span><span id="5483" class="mj mk iq nd b gy nl ni l nj nk"># download and load the Sentence sentiment model. <br/>sentiment_model = watson_nlp.download_and_load(‘sentiment_sentence-bert_multi_stock’)</span><span id="675d" class="mj mk iq nd b gy nl ni l nj nk"># download and load the Target sentiment model<br/>targeted_sentiment_model = watson_nlp.download_and_load(‘sentiment_targeted-cnn_en_stock’)</span></pre><h2 id="7970" class="mj mk iq bd ml mm mn dn mo mp mq dp mr lb ms mt mu lf mv mw mx lj my mz na nb bi translated">目标情感</h2><p id="4083" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">我们将首先配置基于规则的模型，以提取评论中提到的目标。我们将设置目标颜色、龙、权力的游戏(GoT)、CGI和演员。这可以通过创建一个包含两列<strong class="ku ir">标签</strong>和<strong class="ku ir">条目的CSV文件来完成。</strong>条目将包含文本中出现的关键字。这需要是单词的基本版本，因为算法也进行词条匹配。比如说；如果您将其设置为鼠标，该算法也将检测鼠标的提及。Label将包含您要对其下的目标进行分组的标签。比如说；关键词猫和狗可以在同一个标签动物下。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="5d03" class="mj mk iq nd b gy nh ni l nj nk">import os<br/>import watson_nlp<br/>module_folder = “NLP_Dict_Module_1” <br/>os.makedirs(module_folder, exist_ok=True)</span><span id="8403" class="mj mk iq nd b gy nl ni l nj nk"># Create a table dictionary<br/>table_file = ‘features.csv’<br/>with open(os.path.join(module_folder, table_file), ‘w’) as features:<br/> features.write(“\”label\”,\”entry\””)<br/> features.write(“\n”)<br/> features.write(“\”COLOR\”,\”color\””)<br/> features.write(“\n”)<br/> features.write(“\”DRAGON\”,\”dragon\””)<br/> features.write(“\n”)<br/> features.write(“\”Game of Thrones\”,\”GOT\””)<br/> features.write(“\n”)<br/> features.write(“\”CGI\”,\”CGI\””)<br/> features.write(“\n”)<br/> features.write(“\”ACTOR\”,\”actor\””)<br/> features.write(“\n”)</span><span id="6ef1" class="mj mk iq nd b gy nl ni l nj nk"># Load the dictionaries<br/>dictionaries = watson_nlp.toolkit.rule_utils.DictionaryConfig.load_all([{<br/>    'name': 'feature mappings',<br/>    'source': table_file,<br/>    'dict_type': 'table',<br/>    'case': 'insensitive',<br/>    'lemma': True,<br/>    'mappings': {<br/>        'columns': ['label', 'entry'],<br/>        'entry': 'entry'<br/>    }<br/>}])</span><span id="39a6" class="mj mk iq nd b gy nl ni l nj nk"># Train the rule based model on the above targets<br/>custom_dict_block = watson_nlp.resources.feature_extractor.RBR.train(module_folder, <br/>language='en', dictionaries=dictionaries)</span></pre><p id="d63a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">既然提取目标提及的规则库模型已经被训练，我们称之为情感分析模型。请注意，模型需要按顺序调用，因为一个模型的输出需要成为另一个模型的输入。我们从语法模型开始，然后是提及模型，最后是目标情感模型，它将语法和提及模型的输出作为输入。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="316d" class="mj mk iq nd b gy nh ni l nj nk">def <strong class="nd ir">get_lemma</strong>(target):<br/>    “””<br/>    Gets the lemma of a target text.<br/>    “””<br/>    lemmas = [token[‘lemma’] if token[‘lemma’] != “” else token[‘span’][‘text’] for token in syntax_model.run(target, parsers=(‘token’, ‘lemma’)).to_dict()[‘tokens’]]<br/>    return “ “.join(lemmas)</span><span id="3941" class="mj mk iq nd b gy nl ni l nj nk">def <strong class="nd ir">get_text_label</strong>(text):<br/>    “””<br/>    Gets the label of a text from the target feature list csv. <br/>    “””<br/>    text = get_lemma(text)<br/>    try:<br/>        label = feature_df[feature_df[‘entry’].str.lower() == text.lower()][‘label’].values[0]<br/>    except:<br/>        label = None<br/>    return label</span><span id="bb57" class="mj mk iq nd b gy nl ni l nj nk">def <strong class="nd ir">extract_mentions</strong>(text):<br/>    “””<br/>    Extracts the spans where the target features have been mentioned in the text.<br/>    “””<br/>    mentions = defaultdict(list)<br/>    for mention in custom_dict_block.run(text):<br/>       mentions[get_text_label(mention.text)].append((mention.begin, mention.end))<br/> <br/>    return mentions.values()</span><span id="24c5" class="mj mk iq nd b gy nl ni l nj nk">def <strong class="nd ir">target_sentiment_of_line</strong>(text):<br/>    syntax_result = syntax_model.run(text, parsers=(‘token’, ‘lemma’))<br/> <br/>    targetMentions = extract_mentions(text)<br/>    targeted_sent_result = targeted_sentiment_model.run(syntax_result, targetMentions, show_neutral_scores=False)<br/>    return targeted_sent_result</span></pre><p id="7657" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们现在可以将文本传递给上面定义的<strong class="ku ir">target _ opinion _ of _ line</strong>函数，并获得下面的结果(我们得到一个JSON响应，但为了可读性，我将它格式化为excel文件)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ns nt di nu bf nv"><div class="gh gi nr"><img src="../Images/badb01ff51fe7de2427c197625027d40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMfRjGc0ngxxJX7bdZUTEQ.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><strong class="bd nw">target _ opinion _ of _ line</strong>函数的输出，Excel格式</p></figure><p id="1145" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于每个目标，我们得到一个总分数，以及检测到目标的每个句子的分数。例如，在四个句子中检测到GOT，并且总体情绪是积极的。然而，第一次提及GOT被检测为负面，其余提及为正面。</p><p id="98ce" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">情感得分可以在-1和1之间。-1是最消极的情绪，1是最积极的情绪，而0是中性的。值-0.4不如值-0.98负。类似地，值0.3不如值0.99积极</p><h2 id="891f" class="mj mk iq bd ml mm mn dn mo mp mq dp mr lb ms mt mu lf mv mw mx lj my mz na nb bi translated">总体情绪</h2><p id="217e" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">我们也通过调用如下所示的句子情感模型来获得文本的整体情感。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="3540" class="mj mk iq nd b gy nh ni l nj nk">def <strong class="nd ir">sentiment_of_line</strong>(text):<br/>    # Run the syntax model on the input text<br/>    syntax_prediction = syntax_model.run(text)</span><span id="6b89" class="mj mk iq nd b gy nl ni l nj nk">    # Run the sentiment model on the result of syntax<br/>    sentiment_result = sentiment_model.run_batch(syntax_prediction.get_sentence_texts(), syntax_prediction.sentences)</span><span id="4276" class="mj mk iq nd b gy nl ni l nj nk">    # Aggregate the sentiment of all the sentences in the text<br/>    document_sentiment = predict_document_sentiment(sentiment_result, sentiment_model.class_idxs, combine_approach="NON_NEUTRAL_MEAN")</span><span id="f453" class="mj mk iq nd b gy nl ni l nj nk">    return document_sentiment</span></pre><p id="3da2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在将文本传递给函数perspection _ of _ line时，我们得到的总体情绪是负面的，得分是-0.424164。</p><h2 id="aaf7" class="mj mk iq bd ml mm mn dn mo mp mq dp mr lb ms mt mu lf mv mw mx lj my mz na nb bi translated">结论</h2><p id="59f0" class="pw-post-body-paragraph ks kt iq ku b kv nm jr kx ky nn ju la lb no ld le lf np lh li lj nq ll lm ln ij bi translated">总之，对我来说，Watson NLP的亮点是能够在工作中快速开始使用NLP用例，而不必担心收集数据集，从头开发模型。这有助于快速起床和跑步。如果需要，我们可以很容易地用领域特定的数据重新训练模型。</p></div></div>    
</body>
</html>