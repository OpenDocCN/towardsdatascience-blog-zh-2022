<html>
<head>
<title>Scikit Learn’s Estimator with Cross Validation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交叉验证的Scikit Learn估计器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scikit-learns-estimator-with-cross-validation-6bca3ce91676#2022-09-28">https://towardsdatascience.com/scikit-learns-estimator-with-cross-validation-6bca3ce91676#2022-09-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="51b9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解常规估计量和CV估计量的区别</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0041fbc77d8774965081c8c949ad9a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWzKqma9eDpRLp8FTg5w4Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@reddalec?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Redd </a>在<a class="ae ky" href="https://unsplash.com/s/photos/crossing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="268e" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="a920" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">Scikit Lean是最完整的Python机器学习库之一。数据科学家在许多项目中使用它，他们中的许多人实际上通过编写或审查代码来帮助项目。这有助于库不断发展，并在编程新模型时使我们的生活更加轻松。</p><p id="424e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">查看Scikit Learn的文档，可以看到许多评估者现在都有交叉验证(CV)选项。比如有<code class="fe mz na nb nc b">LogisticRegression </code>、<code class="fe mz na nb nc b">LogisticRegressionCV</code>，还有很多其他的，像<code class="fe mz na nb nc b">LassoCV</code>、<code class="fe mz na nb nc b">RidgeCV</code>。</p><p id="3b65" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这些估值器与常规估值器的不同之处在于，算法中有一个内置的交叉验证参数，帮助您在创建新模型时节省时间。</p><h1 id="4dc8" class="lg lh it bd li lj nd ll lm ln ne lp lq jz nf ka ls kc ng kd lu kf nh kg lw lx bi translated">交互效度分析</h1><p id="16ad" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">交叉验证可以帮助我们数据科学家确保我们的模型在面对新数据时能够很好地推广。我总是喜欢将有监督的机器学习模型与学生准备考试进行比较。学生从教授那里得到内容，然后必须完成一些练习。但是练习不能总是相同的方式。</p><p id="c6f6" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">有时教授会给学生一份数据，要求学生计算缺失的部分。其他时候，学生接收公式和数据来输入和计算。就这样，教授混合了内容提供的方式，所以学生可以概括这个概念。每次收到问题时，只要有不同的数据，学生现在就可以应用获得的公式和知识来解决问题。</p><blockquote class="ni"><p id="1adc" class="nj nk it bd nl nm nn no np nq nr mt dk translated">交叉验证是一种重采样方法，它使用数据的不同部分在不同的迭代中测试和训练模型。</p></blockquote><p id="a560" class="pw-post-body-paragraph ly lz it ma b mb ns ju md me nt jx mg mh nu mj mk ml nv mn mo mp nw mr ms mt im bi translated">与学生的类比就像交叉验证。我们是教授，模型是学生，公式和内容是算法。如果我们不断混合数据并将其呈现给模型，它可以进行归纳，一旦收到从未见过的数据进行预测，就有更大的成功机会。</p><h1 id="a90d" class="lg lh it bd li lj nd ll lm ln ne lp lq jz nf ka ls kc ng kd lu kf nh kg lw lx bi translated">CV估计量</h1><p id="8065" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">好了，现在让我们进入这篇文章的核心。让我们来看看如何对带有交叉验证(CV)的估计量进行编码，以及它们的行为。</p><p id="a6da" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们导入所需的模块。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="4c7f" class="ob lh it nc b gy oc od l oe of">import pandas as pd<br/>from sklearn.linear_model import LogisticRegression, LogisticRegressionCV<br/>from sklearn.datasets import load_breast_cancer</span></pre><p id="4592" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我选择了逻辑回归估计量来测试它。所以，让我们开始使用那些著名的玩具数据集来进行演示。我们将加载来自<strong class="ma iu"> sklearn </strong>的乳腺癌数据进行预测。</p><p id="0925" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><em class="og">(边注:我们会跳过数据清理和探索，所以这篇帖子不会太长。但是我们仍然可以看到评估者在起作用)</em></p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="d855" class="ob lh it nc b gy oc od l oe of">#Split explanatory (X) and explained (y)<br/>X, y = load_breast_cancer(return_X_y=True)</span></pre><p id="c2f3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">首先，我们可以运行常规的<code class="fe mz na nb nc b">LogisticRegression()</code>。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="fbd3" class="ob lh it nc b gy oc od l oe of"># Regular Logistic Regression<br/>log_reg = LogisticRegression().fit(X, y)</span></pre><p id="41ed" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们来看看比分。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="9891" class="ob lh it nc b gy oc od l oe of">log_reg.score(X,y)</span><span id="90fc" class="ob lh it nc b gy oh od l oe of"><strong class="nc iu">[OUT]:<br/>0.9472759226713533</strong></span></pre><p id="27c7" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在，让我们看看带有CV的估计量是如何表现的。代码差别不大。我们将使用超参数cv=10，将交叉验证折叠的数量添加到训练中。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="3a17" class="ob lh it nc b gy oc od l oe of"># Fit the model with CV<br/>log_cv = LogisticRegressionCV(cv=10, random_state=0).fit(X, y)</span><span id="c1ec" class="ob lh it nc b gy oh od l oe of"># Score<br/>log_cv.score(X, y)</span><span id="c9a6" class="ob lh it nc b gy oh od l oe of"><strong class="nc iu">[OUT]:<br/>0.961335676625659</strong></span></pre><p id="6ea3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在这种情况下，输出提高了2%。但这是否意味着它会一直那样呢？我们应该总是使用带有CV的估计量吗？</p><p id="a230" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">简单的答案是否定的。</p><p id="8d76" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">例如，有时使用交叉验证有助于使模型过度适应训练数据。我能想到的另一个例子是时间问题。根据数据的大小，训练时间可能会随着CV而显著增加。</p><p id="ae44" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">其他时候，如果这是我们在项目中使用的度量标准，这对于提高准确性来说是不够的。让我们看下一个例子。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="6240" class="ob lh it nc b gy oc od l oe of">from sklearn.datasets import make_classification<br/>from sklearn.model_selection import train_test_split</span></pre><p id="c7b3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们将使用sklearn <code class="fe mz na nb nc b">make_classification</code>创建一个数据集。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="d3fc" class="ob lh it nc b gy oc od l oe of"># Creating a sample dataset<br/>data = make_classification(n_samples= 5000, n_features= 9,<br/>                           n_classes=2,random_state=42)</span><span id="6e2c" class="ob lh it nc b gy oh od l oe of"><br/>X = pd.DataFrame(data[0], columns=['V' + str(i) for i in range(1,10)])</span><span id="13b2" class="ob lh it nc b gy oh od l oe of">y= data[1]</span></pre><p id="aa2a" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们可以在训练和测试中拆分它。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="788b" class="ob lh it nc b gy oc od l oe of">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</span></pre><p id="4777" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在让我们试着拟合一个逻辑回归。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="7c67" class="ob lh it nc b gy oc od l oe of"># Logistic Regression<br/>model = LogisticRegression()</span><span id="aff3" class="ob lh it nc b gy oh od l oe of"># Fit<br/>model.fit(X_train, y_train)</span><span id="84a7" class="ob lh it nc b gy oh od l oe of">#score<br/>model.score(X_test, y_test)</span><span id="8529" class="ob lh it nc b gy oh od l oe of"><strong class="nc iu">[OUT]:<br/>0.856</strong></span></pre><p id="c6b4" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果我们使用CV选项，结果如下。</p><pre class="kj kk kl km gt nx nc ny nz aw oa bi"><span id="64f0" class="ob lh it nc b gy oc od l oe of"># Logistic Regression with CV<br/>model_cv = LogisticRegressionCV(cv=10, random_state=42)</span><span id="7d32" class="ob lh it nc b gy oh od l oe of"># Fit<br/>model_cv.fit(X_train, y_train)</span><span id="4439" class="ob lh it nc b gy oh od l oe of">#score<br/>model_cv.score(X_test, y_test)</span><span id="e55c" class="ob lh it nc b gy oh od l oe of"><strong class="nc iu">[OUT]:<br/>0.856</strong></span></pre><p id="c89f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">同样的结果。准确率85.6%。</p><h1 id="4932" class="lg lh it bd li lj nd ll lm ln ne lp lq jz nf ka ls kc ng kd lu kf nh kg lw lx bi translated">在你走之前</h1><p id="d81a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在这篇文章中，我们了解到<strong class="ma iu"> sklearn </strong>已经内置了带有交叉验证的估计器。一般来说，需要做的只是在实例化模型时使用超参数<code class="fe mz na nb nc b">cv</code>。</p><p id="3f7e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">有时，结果会改善，有时则不会。对于大型数据集，训练时间也会增加，因此请记住这一点。</p><p id="3b22" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你喜欢这篇文章，请随时关注我</p><div class="oi oj gp gr ok ol"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="ou l"><div class="ov l ow ox oy ou oz ks ol"/></div></div></a></div><p id="f266" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你正在考虑中等会员资格，<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">这里有一个推荐代码</a>给你。它帮助并激励着我！</p><h1 id="a301" class="lg lh it bd li lj nd ll lm ln ne lp lq jz nf ka ls kc ng kd lu kf nh kg lw lx bi translated">参考</h1><div class="oi oj gp gr ok ol"><a href="https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">交叉验证(统计)-维基百科</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">交叉验证，有时被称为旋转估计或样本外测试，是各种类似的模型…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">en.wikipedia.org</p></div></div><div class="ou l"><div class="pa l ow ox oy ou oz ks ol"/></div></div></a></div><div class="oi oj gp gr ok ol"><a href="https://stats.stackexchange.com/questions/320154/when-not-to-use-cross-validation" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">何时不使用交叉验证？</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">begingroup$ Take-home-messages:不幸的是，你引用的文本在方法1和方法2之间改变了两件事:方法…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">stats.stackexchange.com</p></div></div><div class="ou l"><div class="pb l ow ox oy ou oz ks ol"/></div></div></a></div><div class="oi oj gp gr ok ol"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" rel="noopener  ugc nofollow" target="_blank"><div class="om ab fo"><div class="on ab oo cl cj op"><h2 class="bd iu gy z fp oq fr fs or fu fw is bi translated">sklearn.linear_model。物流注册</h2><div class="os l"><h3 class="bd b gy z fp oq fr fs or fu fw dk translated">逻辑回归CV(又名logit，MaxEnt)分类器。交叉验证估计量见术语表条目。这堂课…</h3></div><div class="ot l"><p class="bd b dl z fp oq fr fs or fu fw dk translated">scikit-learn.org</p></div></div><div class="ou l"><div class="pc l ow ox oy ou oz ks ol"/></div></div></a></div></div></div>    
</body>
</html>