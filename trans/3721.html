<html>
<head>
<title>Make Your Neural Network Hallucinate</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让你的神经网络产生幻觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/make-your-neural-network-hallucinate-a587ceeb4dbe#2022-08-18">https://towardsdatascience.com/make-your-neural-network-hallucinate-a587ceeb4dbe#2022-08-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7741" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">来自谷歌人工智能的深度梦想项目教程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d855d99b037dcfd7cccf377712841eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ag1nJvcGg45HlOjbn-shDA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@flyd2069?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">飞:D </a>在<a class="ae ky" href="https://unsplash.com/s/photos/illusion?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="a68a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个项目中，我们将采用一个输入图像，并使用生成模型对其应用一些幻觉效果。本教程基于谷歌人工智能和<a class="ae ky" href="https://keras.io/examples/generative/deep_dream/" rel="noopener ugc nofollow" target="_blank"> Keras的实现</a>的这篇<a class="ae ky" href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="noopener ugc nofollow" target="_blank">博客文章。它需要对机器学习和深度神经网络有一些基本的了解。</a></p><p id="4cef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">级别:中级—高级</p><blockquote class="lv lw lx"><p id="99bf" class="kz la ly lb b lc ld ju le lf lg jx lh lz lj lk ll ma ln lo lp mb lr ls lt lu im bi translated">最后提供了所有代码参考。作者修改了原始代码，并添加了一些额外的实现来适应本教程。</p></blockquote><div class="kj kk kl km gt ab cb"><figure class="mc kn md me mf mg mh paragraph-image"><img src="../Images/28605b49c67234edb94c3d04df328c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*NkAnsL2qm_vbSZdfKCBB7Q.png"/></figure><figure class="mc kn mi me mf mg mh paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/df19034f69b2ced2f3dcb20f24336553.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*g4mx2hbOWsjqiCJMmKcSEw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk mj di mk ml translated">等等，我的狗怎么了？或者是我？—作者图片</p></figure></div><p id="3547" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">(不用担心！在本教程的剩余部分，我将不再在我的狗身上测试这个模型。)</p></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><h1 id="3a03" class="mt mu it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">概观</h1><p id="aa34" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">对于高级功能，如使用指导图像控制梦境，请参见<strong class="lb iu">继续</strong>T10】进一步会话。</p><p id="b7c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">为了完成这项任务，我们将:</strong></p><ul class=""><li id="42b4" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">处理输入图像</li><li id="49f1" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">通过预先训练的图像分类模型输入该图像</li><li id="c113" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">取一些隐藏层的输出并“放大”激活信号</li><li id="bec1" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">用这些放大的神经元重新构建一个新的图像</li></ul><p id="691a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最大的技术挑战是“放大”激活信号。由于该模型已经被训练来检测和分类图像，我们可以有把握地假设，激活隐藏层可以捕捉有关图像的重要信息:形状，边缘，上下文，…</p><p id="6c18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着模型可以“看到”我们看不到的东西。我们能做的就是把这些信号“放大”到原始的画面，在一个迭代的过程中再次馈入模型。随着我们的图像获得更多的“隐藏上下文”，该模型可以接收这些新信号，甚至发现上下文，从而创建一个反馈循环。</p><p id="170f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">这一步的程序是:</strong></p><ul class=""><li id="086c" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">创建一个新模型，从一些隐藏的图层中提取特征</li><li id="21df" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">通过模型输入图像</li><li id="49e6" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">根据这些特征计算激活信号</li><li id="66c9" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">使用这些信号增强输入图像</li><li id="1df7" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">重复第二步</li></ul><p id="85a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我将使用TensorFlow/Keras来完成这项任务。与PyTorch相比，TF的一个优势(在本文发表时)是可以很容易地获得Keras隐藏层的输出。因此，构建一个新的模型来提取特征成为一个琐碎的任务。</p><p id="44cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，精通这两种框架并了解哪一种最适合您的项目是有利的。</p><h1 id="f366" class="mt mu it bd mv mw oe my mz na of nc nd jz og ka nf kc oh kd nh kf oi kg nj nk bi translated">履行</h1><h2 id="a689" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">属国</h2><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="b78c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本教程在Python3上运行。我使用<a class="ae ky" href="https://www.anaconda.com/products/distribution" rel="noopener ugc nofollow" target="_blank"> Anaconda for Windows </a>来管理和安装所有的依赖项。</p><h2 id="27de" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">预处理和后处理</h2><p id="b117" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我们应用了在训练中使用的相同的预处理。</p><ul class=""><li id="63b5" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">预处理:加载并归一化输入图像到[-1，1]之间</li><li id="7edd" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">后处理:将范围[-1，1]转换为[0，255]，并将数据类型转换为uint8</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><h2 id="a80d" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">定义模型</h2><p id="9759" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">我们将使用InceptionV3作为基线模型。</p><p id="252f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这项任务，我们将构建一个新的模型，从我们的基线模型输出一些隐藏层的激活。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><blockquote class="ox"><p id="d4b3" class="oy oz it bd pa pb pc pd pe pf pg lu dk translated">我怎么知道选择哪几层？</p></blockquote><p id="dadb" class="pw-post-body-paragraph kz la it lb b lc ph ju le lf pi jx lh li pj lk ll lm pk lo lp lq pl ls lt lu im bi translated"><strong class="lb iu">方法1: </strong>使用TF中的<code class="fe pm pn po pp b">summary()</code>方法获得图层名称列表。</p><pre class="kj kk kl km gt pq pp pr ps aw pt bi"><span id="5677" class="oj mu it pp b gy pu pv l pw px">&gt;&gt;&gt; feature_extractor.summary()<br/>Model: "model"<br/>__________________________________________________________________________________________________<br/> Layer (type)                   Output Shape         Param #     Connected to<br/>==================================================================================================<br/> input_1 (InputLayer)           [(None, None, None,  0           []<br/>                                 3)]</span><span id="9cc0" class="oj mu it pp b gy py pv l pw px">conv2d (Conv2D)                (None, None, None,   864         ['input_1[0][0]']<br/>                                32)</span><span id="fe16" class="oj mu it pp b gy py pv l pw px">batch_normalization (BatchNorm  (None, None, None,   96         ['conv2d[0][0]']<br/> alization)                     32)</span><span id="5db1" class="oj mu it pp b gy py pv l pw px">activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']<br/>...</span></pre><p id="d261" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">方法二:</strong>用<a class="ae ky" href="https://netron.app/" rel="noopener ugc nofollow" target="_blank"> Netron </a>可视化(这是我比较喜欢的方法):</p><ul class=""><li id="a426" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">保存模型</li></ul><pre class="kj kk kl km gt pq pp pr ps aw pt bi"><span id="407a" class="oj mu it pp b gy pu pv l pw px">&gt;&gt;&gt;feature_extractor.save('extractor.h5')</span></pre><ul class=""><li id="38f0" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">用Netron加载并检查模型。</li><li id="5a37" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">在这个模型中有一些“交通路口”，看起来它们应该包含有用的信号，让我们使用这些。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pz"><img src="../Images/fd75f95944f1d1c55f57382a3fefec43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEAL7HVFqVJ5flM5PjIptw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">识别“良好”的输出图层-按作者分类的图像</p></figure><ul class=""><li id="74a0" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">网络的每一层都在不同的抽象层次上学习图像。通常，第一层对边缘、颜色和形状等基本特征更敏感。而更深的层可能包含更多关于对象、上下文等的信息</li></ul><h2 id="bb12" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">定义损失函数</h2><p id="8e99" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">这就是事情变得有趣的地方。我们将使用以下损失函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/93335d098e514a91554b7f62b2778cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/1*XEWbxn_2h4VirFeK1ZKe0w.png"/></div></figure><p id="bce6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中<code class="fe pm pn po pp b">y_i’s</code>是特征提取器模型的激活输出，<code class="fe pm pn po pp b">d_i's</code>是这些输出的大小(尺寸的乘积)。</p><p id="1f0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">为什么要用这个损失函数？</strong></p><ul class=""><li id="737c" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">我们想捕捉神经元最“活跃”的地方</li><li id="91ee" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">特征图的范数对应于来自这些层的信号</li><li id="fd75" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">大的损失值意味着特征映射在图像中检测到许多“隐藏的上下文”</li><li id="61eb" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">我们根据输出大小进行归一化，以便所有选择的层对损耗的贡献相等</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><h2 id="d729" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">定义更新规则</h2><p id="4709" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">在一个典型的深度学习问题中，我们会使用梯度下降来最小化目标损失。然而，这里的情况并非如此:</p><ul class=""><li id="3cc5" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">最小化损失函数意味着最小化输出激活的范数。这不是我们的真正目标。</li><li id="7064" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">激活信号是我们想要注入到我们图像中的东西(模型看到的东西，但是我们看不到)</li><li id="c9e7" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">所以我们想保持模型的权重不变。我们将仅使用激活信号来增强我们的输入图像。</li></ul><p id="7a90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> →梯度上升！</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><h2 id="c219" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">把所有的放在一起</h2><p id="d634" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">Google在原始博客中建议，我们应该迭代地将我们的算法应用于图像输入，并在每次迭代后应用一些缩放。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="82a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是一些结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qb"><img src="../Images/ae96f60e90e99be09c8ec1932e7b2518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yeeKeLImV4A7Advkdt0TeA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Fernando Paredes Murillo 在<a class="ae ky" href="https://unsplash.com/s/photos/desert?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qb"><img src="../Images/46135be944d43b69155d189788cd407f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5BeduTsYi6BHfF-3wVqWPQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者的幻觉</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/30a9c5b23146fd3bbd28ac3fb763d9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hiRLy9MDiHezh6nlA1Y_rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@anikeevxo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">弗拉基米尔·阿尼奇耶夫</a>在<a class="ae ky" href="https://unsplash.com/s/photos/cloud?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/9ed938ad2e298c9aa7cbfb0d1b031e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6bTGHLUDbaXeME50pZgHew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">被作者强化的梦</p></figure><h1 id="fc22" class="mt mu it bd mv mw oe my mz na of nc nd jz og ka nf kc oh kd nh kf oi kg nj nk bi translated">更进一步</h1><p id="870c" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">为了控制模型如何做梦，我们可以</p><ul class=""><li id="aacc" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">修改变量:渐变步长、缩放步长数、每次缩放的比例以及每步的迭代次数</li><li id="d55c" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">为特征提取选择一组不同的层:同样，我们可以利用Netron并挑选出一些候选层</li><li id="31cb" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">修改损失函数:归一化范数是从模型中捕捉隐藏信号的最佳函数吗？</li><li id="2007" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">为我们的梦想使用向导图像</li></ul><h2 id="9015" class="oj mu it bd mv ok ol dn mz om on dp nd li oo op nf lm oq or nh lq os ot nj ou bi translated">使用向导图像</h2><p id="7b14" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">除了依赖激活信号，我们还可以使用一个引导图像作为我们迭代的“GPS”。在每一步，来自引导图像的隐藏信号也被注入到我们的图像中。</p><p id="716b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了完成这项任务，我们需要做出以下改变:</p><ul class=""><li id="75da" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">加载指南图像</li><li id="c776" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">将两个图像的大小调整到相同的分辨率</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><ul class=""><li id="a4a4" class="nq nr it lb b lc ld lf lg li ns lm nt lq nu lu nv nw nx ny bi translated">修改损失函数:我们将改为计算图像之间激活的点积。</li><li id="731e" class="nq nr it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">基本原理:模型可以在两幅图像中“看到”我们肉眼看不到的东西。高损耗意味着来自引导图像的强信号增强了点积。因此，随着梯度上升，我们正在添加额外的“抽象”从指南图像到我们的原始图像。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="90f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">示例结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/70c7ccc2260a50d47c1b4b8e26d035ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uRFnVPzgRwdKSTRib1CrCw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qc"><img src="../Images/dcb861071d470b92065df0ea351a7317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eBNQ9VH00YNQ96m-NxHw2A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">因热带梦幻而增强——作者图片</p></figure><h1 id="60ce" class="mt mu it bd mv mw oe my mz na of nc nd jz og ka nf kc oh kd nh kf oi kg nj nk bi translated">结论</h1><p id="ecf6" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">这个项目是机器学习中生成模型的一个很好的例子。我们不是修改权重以最小化损失，而是使用梯度来增强输入图像以最大化该损失。随着我们反复重复这个过程，图像可以逐渐从模型中获得额外的信号，这些信号以前是我们看不到的。</p><p id="972c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">希望你能从本教程中获得乐趣，并创作出一些美丽的仲夏夜之梦。</p><h1 id="2555" class="mt mu it bd mv mw oe my mz na of nc nd jz og ka nf kc oh kd nh kf oi kg nj nk bi translated">资源</h1><p id="b294" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">谷歌人工智能的博客文章:</p><div class="qd qe gp gr qf qg"><a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd iu gy z fp ql fr fs qm fu fw is bi translated">概念主义:深入神经网络</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">更新- 13/07/2015本文中的图片由谷歌公司根据知识共享署名4.0进行许可…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">ai.googleblog.com</p></div></div><div class="qp l"><div class="qq l qr qs qt qp qu ks qg"/></div></div></a></div><p id="4590" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">TensorFlow教程:</p><div class="qd qe gp gr qf qg"><a href="https://www.tensorflow.org/tutorials/generative/deepdream" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd iu gy z fp ql fr fs qm fu fw is bi translated">DeepDream | TensorFlow核心</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">本教程包含了DeepDream的一个最小实现，正如Alexander Mordvintsev在这篇博文中所描述的…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">www.tensorflow.org</p></div></div><div class="qp l"><div class="qv l qr qs qt qp qu ks qg"/></div></div></a></div><p id="691e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Keras深梦:</p><div class="qd qe gp gr qf qg"><a href="https://keras.io/examples/generative/deep_dream/" rel="noopener  ugc nofollow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd iu gy z fp ql fr fs qm fu fw is bi translated">Keras文档:深梦</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">作者:fchollet创建日期:2016/01/13最近修改时间:2020/05/02描述:用Keras生成深度梦境…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">keras.io</p></div></div><div class="qp l"><div class="qw l qr qs qt qp qu ks qg"/></div></div></a></div></div><div class="ab cl mm mn hx mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="im in io ip iq"><p id="bfe1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你愿意支持Thu，你可以考虑注册成为一名中等会员。每月支付5美元，你就可以无限制地阅读媒体上的故事。如果你使用他的推荐链接，Thu也会得到一小笔佣金。</p><div class="qd qe gp gr qf qg"><a href="https://medium.com/@tdinh15/membership" rel="noopener follow" target="_blank"><div class="qh ab fo"><div class="qi ab qj cl cj qk"><h2 class="bd iu gy z fp ql fr fs qm fu fw is bi translated">通过我的推荐链接加入媒体- Thu Dinh</h2><div class="qn l"><h3 class="bd b gy z fp ql fr fs qm fu fw dk translated">阅读Thu Dinh的每一个故事(以及媒体上成千上万的其他作家)。你的会员费直接支持周四…</h3></div><div class="qo l"><p class="bd b dl z fp ql fr fs qm fu fw dk translated">medium.com</p></div></div><div class="qp l"><div class="qx l qr qs qt qp qu ks qg"/></div></div></a></div></div></div>    
</body>
</html>