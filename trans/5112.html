<html>
<head>
<title>Named Entity Recognition with Partially Annotated Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有部分注释数据的命名实体识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/named-entity-recognition-with-partially-annotated-data-ec679d42fceb#2022-11-15">https://towardsdatascience.com/named-entity-recognition-with-partially-annotated-data-ec679d42fceb#2022-11-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e8f3" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用你的字典和规则快速建立一个 NER 模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b9c9a199fe09c72629354343dda7e43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1B_fx1kIefbEJT2-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@pisitheng?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">皮斯特亨</a>在<a class="ae ky" href="https://unsplash.com/ja/s/%E5%86%99%E7%9C%9F/dictionary?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="9495" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">命名实体识别(NER)是信息提取的一个子任务，它识别文档中的实体并将它们分类到预定义的类别中，如人名、组织、位置等。NER 广泛应用于自然语言处理领域，如信息抽取、信息检索、问题回答等。</p><p id="a17f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于大型和高质量的手动注释数据集，这个问题可以通过微调预先训练的大型语言模型(如 BERT 和 RoBERTa)来解决。然而，准备如此大的和完全注释的数据集是昂贵的，并且在许多情况下是不现实的，例如低资源语言。</p><p id="26f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，部分带注释的数据集可以通过知识库、地名词典、正则表达式等轻松创建。在这些数据集中，大多数被识别的实体是正确的(高精度)，但不是所有的实体都被识别(低召回)。如果我们能够充分利用这些数据集，我们应该能够减少注释成本，并加快模型开发。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/432bf034ed3aa18077b1b836552210a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xyslrm0mJrZOKJEm.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">从部分批注的数据集训练 NER 模型。图片来自<a class="ae ky" href="https://github.com/doccano/spacy-partial-tagger/" rel="noopener ugc nofollow" target="_blank">资源库</a>(麻省理工学院许可)。</p></figure><p id="cf0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，部分注释的数据集有一个问题:缺少实体，数据集可能不包含一些实体。这个问题会漏掉一些实体来注释。因此，在这种数据集上训练的标准模型无法识别这些缺失的实体。导致模型性能变差，尤其是召回率低。</p><p id="d298" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决这个问题，在 2021 年 TACL 中提出了预期实体比率(EER)损失[1]。这种损失促使实体在整个数据集中出现的百分比在某个范围内。通过结合这种损失，它将试图尽可能多地预测实体，即使当标签丢失时。</p><p id="9c09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在接下来的几节中，我将向您展示如何使用 EER 从部分带注释的数据集中训练模型。为此，我将使用<a class="ae ky" href="https://github.com/doccano/spacy-partial-tagger/" rel="noopener ugc nofollow" target="_blank"> spacy-partial-tagger </a>，这是一个使用 EER 实现模型的 Python 库。如果你想详细了解 EER，请看报纸。</p><div class="lw lx gp gr ly lz"><a href="https://github.com/doccano/spacy-partial-tagger" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">GitHub-doccano/spacy-partial-tagger:一个用于训练命名实体识别模型的简单库…</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">这是一个为 spaCy 中的部分注释数据集构建 CRF 标记器的库。你可以建立自己的 NER tagger…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">github.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ks lz"/></div></div></a></div><p id="915e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们开始实施。</p><h1 id="5d18" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">快速入门</h1><p id="3bc6" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">首先你需要安装<code class="fe nl nm nn no b">spacy-partial-tagger</code>。如果您使用 M1 Mac，安装<code class="fe nl nm nn no b">fugashi</code>可能会有问题。在这种情况下，请在安装前尝试使用<code class="fe nl nm nn no b">brew install mecab</code>。</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="cb8f" class="nt mp it no b gy nu nv l nw nx">pip install spacy-partial-tagger</span></pre><p id="7c74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，将数据集准备为 spaCy 二进制格式文件。本库期望标记化是基于字符的。关于格式的更多细节，见<a class="ae ky" href="https://spacy.io/api/data-formats#training" rel="noopener ugc nofollow" target="_blank">本页</a>。在下面的示例中，spaCy 的 EntityRuler 和一个小字典用于创建部分带注释的数据集:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="786b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了训练模型，使用<code class="fe nl nm nn no b">spacy train</code>命令。它只需要一个包含所有设置和超参数的<code class="fe nl nm nn no b"><a class="ae ky" href="https://spacy.io/usage/training#config" rel="noopener ugc nofollow" target="_blank">config.cfg</a></code>配置文件。您可以选择在命令行上用<a class="ae ky" href="https://spacy.io/usage/training#config-overrides" rel="noopener ugc nofollow" target="_blank">覆盖</a>设置。下面是一个<code class="fe nl nm nn no b">spact-partial-tagger’s</code>配置文件的例子:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ny nz l"/></div></figure><p id="8bd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，运行<code class="fe nl nm nn no b">train</code>命令:</p><pre class="kj kk kl km gt np no nq nr aw ns bi"><span id="ffaf" class="nt mp it no b gy nu nv l nw nx">python <strong class="no iu">-</strong>m spacy train config<strong class="no iu">.</strong>cfg \<br/>       <strong class="no iu">--</strong>output<strong class="no iu">=./model</strong> \<br/>       <strong class="no iu">--</strong>paths<strong class="no iu">.</strong>train corpus<strong class="no iu">/</strong>train<strong class="no iu">.</strong>spacy \<br/>       <strong class="no iu">--</strong>paths<strong class="no iu">.</strong>dev corpus<strong class="no iu">/</strong>valid<strong class="no iu">.</strong>spacy \<br/>       <strong class="no iu">--</strong>gpu<strong class="no iu">-</strong>id 0 \<br/>       <strong class="no iu">--</strong>training<strong class="no iu">.</strong>patience 1000</span></pre><p id="14ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样。如果你想知道详细情况，请查看<a class="ae ky" href="https://github.com/doccano/spacy-partial-tagger/blob/main/notebooks/bc5cdr.ipynb" rel="noopener ugc nofollow" target="_blank">库中的笔记本</a>。</p><h1 id="d561" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">实验</h1><p id="7557" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">在这一节中，我将在 dictionary match 创建的部分带注释的数据集上运行实验并展示 EER 模型的性能。由于字典大小在真实场景中是有限的，所以我将测试字典大小在 20~100%之间变化时的性能。</p><p id="d09b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在电子商务领域使用 DSNER 数据集进行命名实体识别(<a class="ae ky" href="https://github.com/rainarch/DSNER/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> Unlicense license </a>)。它包含“品牌”、“材料”、“模型”、“产品”和“规格”作为实体类。至于字典，我用的是已经发表在<a class="ae ky" href="https://github.com/rainarch/DSNER/" rel="noopener ugc nofollow" target="_blank">前期研究</a>【2】(同许可)的一本。这个字典中存储的实体数量是 927。至于预训练模型，我选择了 HFL 出版的<code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code>。</p><p id="76f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们来看看以下四款车型的表现:</p><ul class=""><li id="2b73" class="oa ob it lb b lc ld lf lg li oc lm od lq oe lu of og oh oi bi translated"><code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code>全监督数据(full supervised)训练</li><li id="d031" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code>对部分注释的数据进行训练(<code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code></li><li id="5934" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated"><code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code> +针对部分注释数据训练的 EER 模型(+ EER)</li><li id="f427" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu of og oh oi bi translated">字典匹配</li></ul><h1 id="4bf5" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">结果</h1><p id="f439" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">结果如下。在这种情况下，我们可以看到在部分注释的数据集上训练的<code class="fe nl nm nn no b">hfl/chinese-bert-wwm-ext</code>模型的性能优于字典匹配的性能。我们还看到，使用 EER 可以提高性能，尤其是当字典很小时。这是因为使用 EER 可以提高召回率。结果还表明，其性能几乎与完全监督的性能相当。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/8998b74a2e1e2a7d90a3a482b5c30305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEJZzTgom5u9LErQjlzx-g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同字典大小下的性能(图片由作者提供)</p></figure><h1 id="b356" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">最后的话</h1><p id="47ea" class="pw-post-body-paragraph kz la it lb b lc ng ju le lf nh jx lh li ni lk ll lm nj lo lp lq nk ls lt lu im bi translated">在本文中，我将向您展示如何使用 EER 从部分带注释的数据集中训练命名实体识别模型。实验结果表明，EER 对于电子商务数据集和词典组合的有效性，尤其是在词典规模较小时。我认为 EER 并不是在所有情况下都有效，但是如果你对此感兴趣，请尝试<code class="fe nl nm nn no b">spacy-partial-tagger</code>。</p><h1 id="8a80" class="mo mp it bd mq mr ms mt mu mv mw mx my jz mz ka na kc nb kd nc kf nd kg ne nf bi translated">参考</h1><ol class=""><li id="1e82" class="oa ob it lb b lc ng lf nh li op lm oq lq or lu os og oh oi bi translated">托马斯·埃夫兰和迈克尔·柯林斯。2021.<a class="ae ky" href="https://aclanthology.org/2021.tacl-1.78" rel="noopener ugc nofollow" target="_blank">通过预期实体比率损失进行部分监督的命名实体识别</a>。计算语言学协会汇刊，9:1320–1335。</li><li id="ef56" class="oa ob it lb b lc oj lf ok li ol lm om lq on lu os og oh oi bi translated">杨耀生、、、何正秋和。2018.<a class="ae ky" href="https://aclanthology.org/C18-1183" rel="noopener ugc nofollow" target="_blank">远程监督 NER 进行部分标注学习和强化学习</a>。《第 27 届国际计算语言学会议论文集》,第 2159-2169 页，美国新墨西哥州圣达菲。计算语言学协会。</li></ol></div></div>    
</body>
</html>