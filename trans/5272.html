<html>
<head>
<title>How to Build TensorFlow Models with the Keras Functional API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Keras 函数式 API 构建张量流模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-tensorflow-models-with-the-keras-functional-api-bb6f084def83#2022-11-25">https://towardsdatascience.com/how-to-build-tensorflow-models-with-the-keras-functional-api-bb6f084def83#2022-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5e25" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Keras Functional API 构建定制模型的示例和代码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fa1515966bd66fa619c2022e06f88c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xuydIbzFxELKK1Dz"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@marvelous?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">马文·迈耶</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="fe21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Keras Functional API </strong>提供了一种在 TensorFlow 中构建灵活复杂的神经网络的方法。功能 API 用于设计非线性网络。在本文中，您将发现 Keras Functional API 用于创建网络:</p><ul class=""><li id="c790" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">是非线性的。</li><li id="bc47" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">共享图层。</li><li id="6c37" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">有多个输入和输出。</li></ul><h1 id="e26e" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">Keras 序列模型</h1><p id="0323" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们使用了<a class="ae kv" href="https://www.machinelearningnuggets.com/cnn-tensorflow/" rel="noopener ugc nofollow" target="_blank"> CNN 教程</a>中的 Sequential API，用 Keras 和 TensorFlow 建立了一个图像分类模型。顺序 API 包括堆叠层。一层接着一层，直到最后的致密层。这使得用顺序 API 设计网络变得简单明了。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="f643" class="ni mh iq ne b be nj nk l nl nm">parameters = {"shape":28, "activation": "relu", "classes": 10, "units":12, "optimizer":"adam", "epochs":1,"kernel_size":3,"pool_size":2, "dropout":0.5}<br/># Setup the layers<br/>model = keras.Sequential(<br/>  [<br/>      layers.Conv2D(32, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), input_shape =(parameters["shape"], parameters["shape"], 1),activation=parameters["activation"]),<br/>      layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"])),<br/>      layers.Conv2D(64, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), activation=parameters["activation"]),<br/>      layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"])),<br/>      layers.Flatten(),<br/>      layers.Dropout(parameters["dropout"]),<br/>      layers.Dense(parameters["classes"], activation="softmax"),<br/>  ]<br/>)</span></pre><p id="c919" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">顺序 API 将您限制为一个输入和一个输出。但是，在某些情况下，您可能希望设计具有多个输入和输出的神经网络。例如，给定一个人的图像，您可以设计一个网络来预测几个属性，如性别、年龄和头发颜色。这是一个单输入多输出的网络。为此，需要<strong class="ky ir">顺序 API </strong>。绘制网络图显示各层以线性方式排列。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="8d1f" class="ni mh iq ne b be nj nk l nl nm">keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0e505b297bc11a4c2f1f4eebc2d4b9f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/0*Gytr-tXk-kawE5xc.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="707d" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">Keras 功能模型</h1><p id="7679" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">设计功能模型与开发顺序模型略有不同。让我们来看看这些不同之处。</p><h1 id="e2e1" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">定义输入</h1><p id="3f26" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">第一个区别是创建输入层的要求。使用顺序 API，您不必定义输入层。在第一层定义输入形状就足够了。</p><p id="62d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输入层包含要传递给网络的数据的形状和类型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="f446" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>inputs.shape<br/># TensorShape([None, 28, 28, 1])<br/>inputs.dtype<br/># tf.float32</span></pre><p id="a933" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果数据是一维的，则定义输入图层时不考虑批次大小。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="8bf8" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(784,))</span></pre><h1 id="c351" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">连接层</h1><p id="98f6" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">下一个区别是如何使用函数式 API 连接各层。为了创建连接，我们创建另一个层并将<code class="fe no np nq ne b">inputs</code>层传递给它。将每一层都视为一种功能，可以更好地理解这一点。由于这些层是函数，它们可以用参数调用<strong class="ky ir">。例如，让我们将<code class="fe no np nq ne b">inputs</code>传递给一个<code class="fe no np nq ne b">Conv2D</code>层。</strong></p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="9379" class="ni mh iq ne b be nj nk l nl nm">conv2D = layers.Conv2D(32)<br/>x = conv2D(inputs)<br/>x<br/># &lt;KerasTensor: shape=(None, 26, 26, 32) dtype=float32 (created by layer 'conv2d_7')&gt;</span></pre><p id="606d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，我们创建了一个<code class="fe no np nq ne b">Conv2D</code>层，作为一个函数调用它并传递输入。作为传递到卷积层的结果，结果输出的形状不同于初始的<code class="fe no np nq ne b">inputs</code>形状。</p><h1 id="7049" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">函数式 API Python 语法</h1><p id="884c" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">上面的例子显示了如何定义和连接网络。但是，语法可以简化。简化版看起来像这样:</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="691d" class="ni mh iq ne b be nj nk l nl nm">conv2D = Conv2d(...) (inputs)</span></pre><p id="69c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe no np nq ne b">conv2D()</code>类似于<code class="fe no np nq ne b">conv2D.__call__(self,....)</code>。Python 对象实现了<code class="fe no np nq ne b">__call__()</code>方法。Keras 层也<a class="ae kv" href="https://github.com/keras-team/keras/blob/6b2a04f3af0eb53d4cd9abcbf60593c0e086c027/keras/engine/topology.py#L543" rel="noopener ugc nofollow" target="_blank">实现这个方法</a>。该方法返回给定输入张量的输出。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="898b" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>conv2D = layers.Conv2D(32, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), input_shape =(parameters["shape"], parameters["shape"], 1),activation=parameters["activation"])(inputs)<br/>conv2D<br/># &lt;KerasTensor: shape=(None, 26, 26, 32) dtype=float32 (created by layer 'conv2d_8')&gt;</span></pre><h1 id="43b7" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">创建模型</h1><p id="8965" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">让我们向网络中添加几个层，以演示如何在使用 Functional API 定义层时创建 Keras 模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="8845" class="ni mh iq ne b be nj nk l nl nm">parameters = {"shape":28, "activation": "relu", "classes": 10, "units":12, "optimizer":"adam", "epochs":1,"kernel_size":3,"pool_size":2, "dropout":0.5}<br/>inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>conv2D = layers.Conv2D(32, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), input_shape =(parameters["shape"], parameters["shape"], 1),activation=parameters["activation"])(inputs)<br/>maxPooling2D = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D)<br/>conv2D_2 =layers.Conv2D(64, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), activation=parameters["activation"])(maxPooling2D)<br/>maxPooling2D_2 = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D_2)<br/>flatten =   layers.Flatten()(maxPooling2D_2)<br/>dropout = layers.Dropout(parameters["dropout"])(flatten)<br/>ouputs = layers.Dense(parameters["classes"], activation="softmax")(dropout)</span></pre><p id="ed6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当传递<code class="fe no np nq ne b">inputs</code>和<code class="fe no np nq ne b">outputs</code>时，使用<code class="fe no np nq ne b"><strong class="ky ir">keras.Model</strong></code>函数创建一个 Keras 模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="87ac" class="ni mh iq ne b be nj nk l nl nm">model = keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")</span></pre><p id="8a69" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以绘制模型来确认它与我们使用顺序 API 定义的模型相似。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="4856" class="ni mh iq ne b be nj nk l nl nm">keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/86b011fc42c39e97cf86e5a6379d7652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/0*N7P6fsgVnhapLqQm.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="64d0" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">功能 API 模型的训练和评估</h1><p id="f2ce" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在功能 API 和顺序 API 中，训练和评估模型是相同的。<code class="fe no np nq ne b">keras.Model</code>利用<code class="fe no np nq ne b">fit</code>和<code class="fe no np nq ne b">evaluate</code>方法。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="8439" class="ni mh iq ne b be nj nk l nl nm">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()<br/>x_train = x_train.astype("float32") / 255<br/>x_test = x_test.astype("float32") / 255<br/>model.compile(<br/>    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),<br/>    optimizer=keras.optimizers.RMSprop(),<br/>    metrics=["accuracy"],<br/>)<br/>history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)<br/>test_scores = model.evaluate(x_test, y_test, verbose=2)<br/>print("Test loss:", test_scores[0])<br/>print("Test accuracy:", test_scores[1])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/41471d58ba991b0307d357988f2f1adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cPtxSlrq7XdtAv4-.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="b8b8" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">保存和序列化功能 API 模型</h1><p id="9c1f" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated"><strong class="ky ir">模型保存和序列化</strong>在函数式 API 和顺序式 API 中工作相同。例如，我们可以使用<code class="fe no np nq ne b">model.save()</code>保存整个模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="e3d4" class="ni mh iq ne b be nj nk l nl nm">model.save("saved_model")<br/>del model<br/>model = keras.models.load_model("saved_model")<br/>model.summary()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/7dde20c13d25284b954c7a67819fd39b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zshGSOHOqrV7_jy0.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="6e31" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">如何将功能模型转换为顺序 API 模型</h1><p id="3c2d" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">通过创建一个<code class="fe no np nq ne b">Sequential</code>实例并添加层，可将带有线性层的功能模型转换为顺序模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="1a6b" class="ni mh iq ne b be nj nk l nl nm">seq_model = keras.models.Sequential()<br/>for layer in model.layers:<br/>    seq_model.add(layer)<br/>seq_model.summary()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/8a19c2c030794fa9ade8df6ba7b2d11f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jjTDCiBtjfaB8vhQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="26ac" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">如何将顺序模型转换为功能 API 模型</h1><p id="d71a" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">类似地，我们可以将时序网络转换为功能模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="56ec" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(batch_shape=seq_model.layers[0].input_shape)<br/>x = inputs<br/>for layer in seq_model.layers:<br/>    x = layer(x) <br/>outputs = x<br/>func_model = keras.Model(inputs=inputs, outputs=outputs, name="func_mnist_model")<br/>func_model.summary()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/960dcdf0d0075720bfeb6346cf815429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iU-JO1S7RekNEAn4.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="2c3c" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">标准网络模型</h1><p id="b08b" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">让我们看看如何使用功能性 Keras API 定义标准神经网络。</p><h1 id="e0aa" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">多层感知</h1><p id="2adb" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我们首先定义一个具有多个隐藏层的神经网络，并绘制模型。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="1732" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>dense1 = layers.Dense(128)(inputs)<br/>dropout = layers.Dropout(parameters["dropout"])(dense1)<br/>dense2 = layers.Dense(128)(dropout)<br/>dropout1 = layers.Dropout(parameters["dropout"])(dense2)<br/>outputs = layers.Dense(parameters["classes"], activation="softmax")(dropout1)<br/>model = keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/35f3fb86d97e0cfaaad73bbd13976776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/0*ofG87G7a4taV7Z3Y.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="e0a0" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">卷积神经网络</h1><p id="b8bd" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">接下来，我们看看如何使用函数式 API 定义<a class="ae kv" href="https://www.machinelearningnuggets.com/cnn-tensorflow/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>。该网络具有卷积层、汇集层、扁平化层和致密层。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="0b8b" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>conv2D = layers.Conv2D(32, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), input_shape =(parameters["shape"], parameters["shape"], 1),activation=parameters["activation"])(inputs)<br/>maxPooling2D = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D)<br/>conv2D_2 =layers.Conv2D(64, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), activation=parameters["activation"])(maxPooling2D)<br/>maxPooling2D_2 = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D_2)<br/>flatten =   layers.Flatten()(maxPooling2D_2)<br/>dropout = layers.Dropout(parameters["dropout"])(flatten)<br/>outputs = layers.Dense(parameters["classes"], activation="softmax")(dropout)<br/>model = keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/5419573e287a48912d76e4cdcb4c3048.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/0*ManBqduEEoDU_tFE.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="1826" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">递归神经网络</h1><p id="c393" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">让我们看看使用函数式 API 的双向 LSTM 的定义。该网络包含一个<a class="ae kv" href="https://keras.io/api/layers/core_layers/embedding/" rel="noopener ugc nofollow" target="_blank">嵌入层</a>。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="4cd1" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(784,)<br/>embedding = layers.Embedding(512, 64, input_length=1024)(inputs)<br/>bidirectional1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedding)<br/>bidirectional2 = layers.Bidirectional(layers.LSTM(64,))(bidirectional1)<br/>dense1 = layers.Dense(32, activation='relu')(bidirectional2)<br/>outputs = layers.Dense(1, activation='sigmoid')(dense1)<br/>model = keras.Model(inputs=inputs, outputs=outputs, name="lstm_model")<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/46c4544a77f79e4326607c030e3ebd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/0*Ow112HVHErvf7hzb.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="7873" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">共享层模型</h1><p id="7d62" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">使用功能 API 定义层可以创建共享特定层的网络。网络中会多次使用共享层。</p><h1 id="765b" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">共享输入层</h1><p id="a850" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">本例定义了一个 CNN，两个卷积模块共享一个输入层。然后我们使用<code class="fe no np nq ne b">concatenate</code>层连接这些模块的输出。之后，我们将结果传递给一个<code class="fe no np nq ne b">DropOut</code>层，最后传递给完全连接的层。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="5cde" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(shape=(parameters["shape"], parameters["shape"], 1))<br/>conv2D = layers.Conv2D(32, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), input_shape =(parameters["shape"], parameters["shape"], 1),activation=parameters["activation"])(inputs)<br/>maxPooling2D = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D)<br/>flatten1 =   layers.Flatten()(maxPooling2D)<br/>conv2D_2 = layers.Conv2D(64, kernel_size=(parameters["kernel_size"], parameters["kernel_size"]), activation=parameters["activation"])(inputs)<br/>maxPooling2D_2 = layers.MaxPooling2D(pool_size=(parameters["pool_size"], parameters["pool_size"]))(conv2D_2)<br/>flatten2 =   layers.Flatten()(maxPooling2D_2)<br/># merge layers<br/>merged_layers = layers.concatenate([flatten1, flatten2])<br/>dropout = layers.Dropout(parameters["dropout"])(merged_layers)<br/>outputs = layers.Dense(parameters["classes"], activation="softmax")(dropout)<br/>model = keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><p id="82f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">绘制网络图显示了不同层之间的联系。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/020f885b164f436c21472373580a3f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vtlaeK5fIRD_MP6L.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="a287" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">共享特征提取层</h1><p id="e7d6" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本例中，我们创建了一个由两个双向 LSTMs 共享的嵌入层。共享特征提取层允许在网络中多次共享相同的<strong class="ky ir">特征提取器</strong>。例如，在两个输入之间共享此信息可以使用较少的数据训练网络成为可能。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="357c" class="ni mh iq ne b be nj nk l nl nm">inputs = keras.Input(784,)<br/>embedding = layers.Embedding(512, 64, input_length=1024)(inputs)<br/>bidirectional1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedding)<br/>bidirectional2 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(embedding)<br/># merge layers<br/>merged_layers = layers.concatenate([bidirectional1, bidirectional2])<br/>dense1 = layers.Dense(32, activation='relu')(merged_layers)<br/>outputs = layers.Dense(1, activation='sigmoid')(dense1)<br/>model = keras.Model(inputs=inputs, outputs=outputs, name="lstm_model")<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/e8f21004cd9c31e7c1faa66e5f74e055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*a_Cipp8oWxLXpLV3.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f2e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们讨论多输入多输出场景。</p><h1 id="61b7" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">多输入多输出模型</h1><p id="5dea" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">具有多个输入和输出的网络也可以使用函数式 API 来定义。这对于顺序 API 是不可能的。</p><h1 id="934f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">多输入模型</h1><p id="5ffa" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本例中，我们定义了一个网络，它采用两个不同长度的输入。我们将输入传递给密集层，并使用<code class="fe no np nq ne b">add</code>层对它们求和。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="655f" class="ni mh iq ne b be nj nk l nl nm">input1 = keras.Input(shape=(16,))<br/>x1 =layers.Dense(8, activation='relu')(input1)<br/>input2 = layers.Input(shape=(32,))<br/>x2 = layers.Dense(8, activation='relu')(input2)<br/># equivalent to `added = tf.keras.layers.add([x1, x2])`<br/>added = layers.Add()([x1, x2])<br/>out = layers.Dense(4)(added)<br/>model = keras.Model(inputs=[input1, input2], outputs=out)<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/76a2a1e3f33722c09a856cd85f4ab639.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KyK77lOXSysagv_L.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="c2fe" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">多输出模型</h1><p id="f8a5" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">功能 API 支持定义具有<strong class="ky ir">多输出</strong>的模型。下面的例子定义了一个具有两个输出层的<a class="ae kv" href="https://www.machinelearningnuggets.com/cnn-tensorflow/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>。例如，给定一个人的图像，这个网络可以预测性别和头发颜色。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="724a" class="ni mh iq ne b be nj nk l nl nm">image_input = keras.Input(shape=(parameters["shape"], parameters["shape"], 3), name="images") <br/>x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(image_input)<br/>x = layers.MaxPooling2D(pool_size=(2,2))(x)<br/>x = layers.Conv2D(filters=32,kernel_size=(3,3), activation='relu')(x)<br/>x = layers.Dropout(0.25)(x)<br/>x = layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu')(x)<br/>x = layers.MaxPooling2D(pool_size=(2,2))(x)<br/>x = layers.Dropout(0.25)(x)<br/>x = layers.Flatten()(x)<br/>x = layers.Dense(128, activation='relu')(x)<br/>x = layers.Dropout(0.25)(x)<br/>gender_prediction = layers.Dense(3, activation='softmax')(x)<br/>age_prediction = layers.Dense(3, activation='softmax')(x)<br/>model = keras.Model(<br/>    inputs=image_input,<br/>    outputs=[gender_prediction, age_prediction],<br/>)<br/>keras.utils.plot_model(model, "model.png",show_shapes=True)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/27a0460951117074905183cd7bc6edf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pB1XVClJZhvbGoQ5.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="0b8f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">使用相同的图层图表来定义多个模型</h1><p id="931c" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">Functional API 还支持使用相同的层定义多个模型。这是可能的，因为使用函数式 API 创建模型只需要输入和输出。例如，这适用于编码解码器网络架构。</p><pre class="kg kh ki kj gt nd ne nf bn ng nh bi"><span id="542d" class="ni mh iq ne b be nj nk l nl nm">encoder_input = keras.Input(shape=(28, 28, 1), name="img")<br/>x = layers.Conv2D(16, 3, activation="relu")(encoder_input)<br/>x = layers.Conv2D(32, 3, activation="relu")(x)<br/>x = layers.MaxPooling2D(3)(x)<br/>x = layers.Conv2D(32, 3, activation="relu")(x)<br/>x = layers.Conv2D(16, 3, activation="relu")(x)<br/>encoder_output = layers.GlobalMaxPooling2D()(x)<br/>encoder = keras.Model(encoder_input, encoder_output, name="encoder")<br/>encoder.summary()<br/>x = layers.Reshape((4, 4, 1))(encoder_output)<br/>x = layers.Conv2DTranspose(16, 3, activation="relu")(x)<br/>x = layers.Conv2DTranspose(32, 3, activation="relu")(x)<br/>x = layers.UpSampling2D(3)(x)<br/>x = layers.Conv2DTranspose(16, 3, activation="relu")(x)<br/>decoder_output = layers.Conv2DTranspose(1, 3, activation="relu")(x)<br/>autoencoder = keras.Model(encoder_input, decoder_output, name="autoencoder")<br/>autoencoder.summary()</span></pre><h1 id="ab8f" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">Keras 功能 API 的优势和劣势</h1><p id="daa1" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">Keras Functional API 在设计非线性网络时非常方便。如果您认为您可能需要将网络转换为非线性结构，那么您应该使用函数式 API。函数式 API 的一些优势包括:</p><ul class=""><li id="cb18" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">与子类化<code class="fe no np nq ne b"><a class="ae kv" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank">Model</a></code><a class="ae kv" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank"/>的<a class="ae kv" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank">相比，它的<strong class="ky ir">更少冗长。</strong></a></li><li id="1bb8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">创建一个<code class="fe no np nq ne b">Input</code>的要求确保了<strong class="ky ir">所有的功能网络都将运行</strong>，因为传递错误的形状会导致立即出错。</li><li id="3220" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">功能模型<strong class="ky ir">更容易绘制和检查</strong>。</li><li id="3d65" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">易于<strong class="ky ir">序列化和保存功能模型</strong>，因为它们是数据结构。</li></ul><p id="1578" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，使用函数式 API 的一个缺点是它不支持动态架构，如<a class="ae kv" href="https://www.kdnuggets.com/2016/06/recursive-neural-networks-tensorflow.html" rel="noopener ugc nofollow" target="_blank">递归网络或树形网络</a>。</p><h1 id="4688" class="mg mh iq bd mi mj mk ml mm mn mo mp mq jw mr jx ms jz mt ka mu kc mv kd mw mx bi translated">功能 API 最佳实践</h1><p id="1d55" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在使用 Keras Functional API 时，请牢记最佳实践:</p><ul class=""><li id="1d4c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">始终打印网络概要给<strong class="ky ir">以确认各层的形状</strong>符合预期。</li><li id="ee20" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">将网络绘制到<strong class="ky ir">确保各层按照你的预期连接</strong>。</li><li id="207e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">命名图层</strong>以便于在网络图和概要中识别。比如说<code class="fe no np nq ne b">Conv2D(...,name="first_conv_layer")</code>。</li><li id="58e2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用与层相关的<strong class="ky ir">变量名，例如<code class="fe no np nq ne b">conv1</code>和<code class="fe no np nq ne b">conv2</code>用于卷积层。这将在检查地块和网络摘要时阐明图层的类型。</strong></li><li id="f00e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">没有创建<a class="ae kv" href="https://www.machinelearningnuggets.com/keras-custom-training-loops/" rel="noopener ugc nofollow" target="_blank">自定义训练循环</a>，而是使用</strong> <code class="fe no np nq ne b"><strong class="ky ir">keras.Model</strong></code> <strong class="ky ir">来创建模型</strong>，因为这样更容易通过<code class="fe no np nq ne b">fit</code>方法训练模型，并使用<code class="fe no np nq ne b">evalaute</code>方法评估它们。</li></ul></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="c092" class="mg mh iq bd mi mj oi ml mm mn oj mp mq jw ok jx ms jz ol ka mu kc om kd mw mx bi translated">最后的想法</h1><p id="9d35" class="pw-post-body-paragraph kw kx iq ky b kz my jr lb lc mz ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">在本文中，您发现可以使用顺序 API 在 Keras 中设计神经网络。特别是，我们涵盖了:</p><ul class=""><li id="e256" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">如何在 Keras 中定义功能模型？</li><li id="8634" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">如何训练和评估 Keras 序列网络？</li><li id="3bba" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">定义具有多个输入和输出的 Keras 网络。</li><li id="c171" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">如何绘制和检验 Keras 序列模型？</li><li id="8307" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">基于 Keras 序列网络的特征提取。</li></ul><p id="05b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://www.linkedin.com/in/mwitiderrick/" rel="noopener ugc nofollow" target="_blank">在 LinkedIn 上关注我</a>获取更多技术资源。</p></div></div>    
</body>
</html>