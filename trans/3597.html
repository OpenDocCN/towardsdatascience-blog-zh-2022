<html>
<head>
<title>Derivative of Sigmoid and Cross-Entropy Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Sigmoid函数和交叉熵函数的导数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/derivative-of-sigmoid-and-cross-entropy-functions-5169525e6705#2022-08-10">https://towardsdatascience.com/derivative-of-sigmoid-and-cross-entropy-functions-5169525e6705#2022-08-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5520" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">Sigmoid激活和交叉熵损失函数的逐步微分</h2></div><p id="28ef" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">本文将逐步介绍Sigmoid函数和交叉熵函数。在模型训练期间执行<a class="ae le" rel="noopener" target="_blank" href="/how-does-back-propagation-work-in-neural-networks-with-worked-example-bc59dfb97f48">反向传播时，理解这两个函数的导数在机器学习领域是至关重要的。</a></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/240454419616ee09c3850a80117a48e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X5lTBZd9GVvdd7G5"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">由<a class="ae le" href="https://unsplash.com/@saadahmad_umn?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Saad Ahmad </a>在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="0893" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">s形函数的导数</h1><p id="0ea6" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">Sigmoid/ Logistic函数定义为:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ms"><img src="../Images/659b7763e4a476596347c1e9c3bcfe38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aIVSCYjSr3Oru2n3k7bqtA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图1: Sigmoid函数。左:Sigmoid方程，右是方程的绘图(来源:作者)。</p></figure><p id="a20c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<code class="fe mt mu mv mw b">e</code>是<strong class="kk iu">欧拉数</strong>——一个近似等于<code class="fe mt mu mv mw b">2.718281828459</code>的超越常数。对于<code class="fe mt mu mv mw b">x</code>的任意值，Sigmoid函数<code class="fe mt mu mv mw b">g(x)</code>落在<code class="fe mt mu mv mw b">(0, 1)</code>范围内。随着<code class="fe mt mu mv mw b">x</code>的值减小，<code class="fe mt mu mv mw b">g(x)</code>接近<code class="fe mt mu mv mw b">0</code>，而随着<code class="fe mt mu mv mw b">x</code>变大，<code class="fe mt mu mv mw b">g(x)</code>趋向于<code class="fe mt mu mv mw b">1</code>。例子，</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mx"><img src="../Images/765181c6d429a1f78f8cedd4e97ab8a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NYRI38D4Of5tuM_EuNDCkQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">g(x)的某些值给定x的值。</p></figure><p id="898d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从这里开始，我们将使用两种方法— <strong class="kk iu">商和微分链规则对Sigmoid函数进行微分。</strong></p><h2 id="cfe0" class="my lw it bd lx mz na dn mb nb nc dp mf kr nd ne mh kv nf ng mj kz nh ni ml nj bi translated">用商法则求Sigmoid函数的导数</h2><p id="5be0" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated"><strong class="kk iu">第一步:</strong>陈述商法则</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nk"><img src="../Images/f08e7fdc48877032d597530cda24987c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OOincM68oJT-SQonS1XsgA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">商数法则。</p></figure><p id="2b30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">商法则读作“<em class="nl">商的导数是分母乘以分子的导数减去分子乘以分母的导数一切除以分母的平方。</em></p><p id="30ba" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二步:应用商法则</p><p id="6db9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据Sigmoid函数、<code class="fe mt mu mv mw b">g(x) </code>和商法则，我们有</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nm"><img src="../Images/5ae30d3f5a8ad3147c251b5c2d6a61e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHZZKs5rCaPFAke9qxinUA.png"/></div></div></figure><p id="f5e9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">需要注意两件事:</p><ul class=""><li id="9480" class="nn no it kk b kl km ko kp kr np kv nq kz nr ld ns nt nu nv bi translated">常数的导数等于零。这就是为什么<code class="fe mt mu mv mw b">u’=0</code>。</li><li id="4ab4" class="nn no it kk b kl nw ko nx kr ny kv nz kz oa ld ns nt nu nv bi translated"><code class="fe mt mu mv mw b">v</code>中指数函数<code class="fe mt mu mv mw b">e*</code>的微分被<strong class="kk iu">指数微分法则</strong>覆盖。</li></ul><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ob"><img src="../Images/d137e42c24c82ba14dacfef1f5744be6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wdygm3_c2-C62u2spRUGMg.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">指数法则。</p></figure><p id="49c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据商和指数微分法则，我们有</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oc"><img src="../Images/99ad1f72c8f189c428bb77361f49581d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4F-vat941yrhxrw6agc1A.png"/></div></div></figure><p id="de31" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是Sigmoid函数的导数，但我们可以进一步简化，如下一步所示。</p><p id="7469" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第三步:</strong>简化导数</p><p id="c4a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这一步中，我们将使用代数上的一些概念来简化第二步中的求导结果。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi od"><img src="../Images/e03ac2c80198be9c543c4f4589db13cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hgeNo0yxb_hzGUQPNgDO7Q.png"/></div></div></figure><p id="cbd5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">注意:</strong>在等式5中，我们在等式上加了1，减了1，所以我们实际上什么也没改变。</p><p id="3cb9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着使用商法则的微分过程的结束。</p><h2 id="c239" class="my lw it bd lx mz na dn mb nb nc dp mf kr nd ne mh kv nf ng mj kz nh ni ml nj bi translated">用链式法则判别Sigmoid函数</h2><p id="417e" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated"><strong class="kk iu">第一步:</strong>链式法则</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oe"><img src="../Images/0d1754544529904d45b39456b0372025.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4YF4HYPYussSHDkveiuwKA.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">链式法则。</p></figure><p id="6ef7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤2: </strong>将Sigmoid函数重写为负指数</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi of"><img src="../Images/9143d5aa5d7b1a7f54fcf5d967c568c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VLr4hyhZrUuJruHHp0nsaQ.png"/></div></div></figure><p id="60fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">步骤3: </strong>在步骤2中对Sigmoid函数应用链式法则</p><p id="cb78" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让，</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi og"><img src="../Images/a434eb9e5d9d3907e9b261ad388d68a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50gm-mf_iVh6m7JH1sekMw.png"/></div></div></figure><p id="fae4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然后，根据链式法则，我们将如下进行:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oh"><img src="../Images/7e7c4e03bf5ae079e7bbda8c19a36f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9k5oh73wA5xKPTupr0tKw.png"/></div></div></figure><p id="a431" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这一点上，您可以使用我们在处理商数规则时所采取的相同步骤来简化方程(方程<code class="fe mt mu mv mw b">3</code>到<code class="fe mt mu mv mw b">8</code>)。</p><p id="873d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是Sigmoid函数及其导数的图</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi oi"><img src="../Images/c461ea2400bb83789c93d498cfbf1564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sHYEmEIFZZVBYrmcWkTl3w.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">Sigmoid函数及其导数(来源:作者)。</p></figure><h1 id="cf32" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">交叉熵函数的导数</h1><p id="3028" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">交叉熵损失函数是用于分类问题的一个非常重要的代价函数。然而，在本帖中，我们将只关注损失函数的微分。尽管如此，你可以在下面的链接中读到更多关于交叉熵损失函数的内容</p><div class="oj ok gp gr ol om"><a rel="noopener follow" target="_blank" href="/cross-entropy-loss-function-f38c4ec8643e"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">交叉熵损失函数</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">在大多数分类问题中用于优化机器学习模型的损失函数…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa lp om"/></div></div></a></div><p id="1db0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">交叉熵损失函数定义为:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pb"><img src="../Images/6ce89e3564004aa1710ec8b165db8427.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GAHcbrpBdbDg_pZXGwQlaQ.png"/></div></div></figure><p id="071e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中t <strong class="kk iu"> ᵢ </strong>是真值，p <strong class="kk iu"> ᵢ </strong>是i <strong class="kk iu"> ᵗʰ </strong>类的概率。</p><p id="f1c7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于具有两个类别的分类，我们有二元交叉熵损失，其定义如下</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pc"><img src="../Images/b0041051a504b459e8f39fd222a8e2ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6TUQCi6PDUHkKv_mx3xMw.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">二元交叉熵损失函数，其中t是真值，yhat是预测概率。</p></figure><h2 id="f9c5" class="my lw it bd lx mz na dn mb nb nc dp mf kr nd ne mh kv nf ng mj kz nh ni ml nj bi translated">二元交叉熵函数的导数</h2><p id="f790" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">二元损失的真实标签<code class="fe mt mu mv mw b">t</code>是一个已知值，而<code class="fe mt mu mv mw b">yhat</code>是一个变量。这意味着函数将对<code class="fe mt mu mv mw b">yhat</code>进行微分，并将t视为常数。现在让我们继续研究导数。</p><p id="3b97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第一步:</strong>陈述两条规则我们需要区分二元交叉熵损失</p><p id="aeb5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了区分二元交叉熵损失，我们需要这两条规则:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pd"><img src="../Images/eed1d8f2afdffa7df0090c16d70a8931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3pC7-w7hzUb6Krj2FEXOw.png"/></div></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pe"><img src="../Images/f00400cd3dc5b55ce62fca45c1b896a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*znPW-Zmb-uczEU2jgCCifA.png"/></div></div></figure><p id="465a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">而乘积法则是这样写的，“<em class="nl">两个函数乘积的导数就是第一个函数乘以第二个函数的导数加上第二个函数乘以第一个函数的导数。</em>”</p><p id="d623" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">第二步:</strong>功能微分</p><p id="08ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用<em class="nl">乘积规则</em>来分别处理这两项的导数；然后，通过<em class="nl">规则</em> <code class="fe mt mu mv mw b"><em class="nl">1</em></code>我们将结合两个导数。</p><p id="b4fe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于我们有两个未知数——<code class="fe mt mu mv mw b">t</code>和<code class="fe mt mu mv mw b">yhat </code>——我们将实际处理偏导数(一个多变量函数的偏导数是它对其中一个变量的导数，其他变量被视为常数)。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pf"><img src="../Images/2ed8a3be18dcec1effcffcd86753b666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHiEBFnd_OA31ABQwPHA9g.png"/></div></div></figure><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi pg"><img src="../Images/f135d8ef3f40ef6e716a6d75df72b62a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O2seA1btbfx0gUhFpbpUnA.png"/></div></div></figure><p id="1f44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，二元交叉熵损失函数的导数变成</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ph"><img src="../Images/6d4fb703c9ebc1acc8ae43cf9cafbde6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SSacTSvt-ra4dzW11usAlQ.png"/></div></div></figure><p id="fcb7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这标志着本文的结束。感谢阅读:-)</p><h1 id="de37" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="367f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在本文中，我们研究了Sigmoid函数和二元交叉熵函数的导数。前者主要在机器学习中用作激活函数，而后者通常用作评估模型的成本函数。这里发现的导数在网络的<a class="ae le" rel="noopener" target="_blank" href="/how-does-back-propagation-work-in-neural-networks-with-worked-example-bc59dfb97f48">反向传播过程</a>中尤其重要——这是模型训练中的一个重要步骤。</p></div><div class="ab cl pi pj hx pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="im in io ip iq"><p id="6d76" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请<a class="ae le" href="https://medium.com/@kiprono_65591/membership" rel="noopener">以每月5美元的价格注册成为medium会员</a>，以便能够阅读我和其他作者在Medium上的所有文章。</p><p id="1c0a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你也可以<a class="ae le" href="https://medium.com/subscribe/@kiprono_65591" rel="noopener">订阅，以便在我发表文章时将我的文章放入你的邮箱</a>。</p><p id="5a60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢您的阅读，下次再见！！！</p></div></div>    
</body>
</html>