<html>
<head>
<title>CUDA by Numba Examples</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CUDA by Numba示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cuda-by-numba-examples-1-4-e0d06651612f#2022-09-04">https://towardsdatascience.com/cuda-by-numba-examples-1-4-e0d06651612f#2022-09-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9483" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">阅读本系列文章，从头开始学习使用Python进行CUDA编程</h2></div><h1 id="3f88" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">第1部分，共4部分:开始并行之旅</h1><h1 id="4c32" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="70cb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">顾名思义，GPU(图形处理单元)最初是为计算机图形而开发的。从那以后，它们在几乎每个需要高计算吞吐量的领域都变得无处不在。这一进步是由GPGPU(通用GPU)接口的开发实现的，它允许我们为通用计算编程GPU。这些接口中最常见的是<a class="ae lt" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="noopener ugc nofollow" target="_blank"> CUDA </a>，其次是<a class="ae lt" href="https://www.khronos.org/opencl/" rel="noopener ugc nofollow" target="_blank"> OpenCL </a>以及最近的<a class="ae lt" href="https://rocmdocs.amd.com/en/latest/Programming_Guides/Programming-Guides.html" rel="noopener ugc nofollow" target="_blank"> HIP </a>。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lu"><img src="../Images/f20c5249b8832d431f1e49f85751d9c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mQNpI1VA-yBsbmxPIaj3GA.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">图1.0。运行<a class="ae lt" href="https://replicate.com/stability-ai/stable-diffusion" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>带<code class="fe mk ml mm mn b">parallel lines futuristic space</code>。学分:在CreativeML Open RAIL-M许可下拥有作品。</p></figure><h1 id="1a63" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">Python中的CUDA</h1><p id="51e2" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CUDA最初是为了与C兼容而设计的，后来的版本将其扩展到了C++和Fortran。在Python生态系统中，使用CUDA的方法之一是通过<a class="ae lt" href="https://numba.readthedocs.io/en/stable/user/5minguide.html" rel="noopener ugc nofollow" target="_blank"> Numba </a>，这是一个针对Python的实时(JIT)编译器，可以针对GPU(它也针对CPU，但这不在我们的范围之内)。使用Numba，可以直接用Python(的子集)编写内核，Numba将动态编译代码并运行它。虽然它<em class="mo">没有</em>实现完整的CUDA API，但与CPU相比，它支持的功能通常足以获得令人印象深刻的加速(有关所有缺失的功能，请参见<a class="ae lt" href="https://numba.readthedocs.io/en/stable/cuda/overview.html#missing-cuda-features" rel="noopener ugc nofollow" target="_blank">Numba文档</a>)。</p><p id="a7f0" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">然而，Numba并不是唯一的选择。CuPy提供了依赖CUDA的高级功能、集成C语言内核的低级CUDA支持和可JIT的Python功能(类似于Numba)。<a class="ae lt" href="https://documen.tician.de/pycuda/" rel="noopener ugc nofollow" target="_blank"> PyCUDA </a>提供了更细粒度的CUDA API控制。最近，Nvidia发布了官方的<a class="ae lt" href="https://nvidia.github.io/cuda-python/overview.html" rel="noopener ugc nofollow" target="_blank"> CUDA Python </a>，这必将丰富生态系统。所有这些项目都可以互相传递设备阵列，您不会被限制只能使用一个。</p><h1 id="a816" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">在这个系列中</h1><p id="6db5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本系列的目标是通过用Numba CUDA编写的例子提供一个通用CUDA模式的学习平台。本系列不是CUDA或Numba的综合指南。读者可以参考他们各自的文档。本教程的结构灵感来自Jason Sanders和Edward Kandrot所著的《CUDA by Example:a Introduction to General-Purpose GPU Programming》一书。如果您最终不再使用Python，而是想用C语言编写代码，这是一个极好的资源。该系列还有三个部分:<a class="ae lt" rel="noopener" target="_blank" href="/cuda-by-numba-examples-215c0d285088">第二部分</a>、<a class="ae lt" rel="noopener" target="_blank" href="/cuda-by-numba-examples-7652412af1ee">第三部分</a>和<a class="ae lt" rel="noopener" target="_blank" href="/cuda-by-numba-examples-c583474124b0">第四部分</a>。</p><h1 id="17cc" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">在本教程中</h1><p id="447b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们将学习如何运行我们的第一个Numba CUDA内核。我们还将学习如何有效地使用CUDA来处理令人尴尬的并行任务，即彼此完全独立的任务。最后，我们将学习如何从CPU对内核运行时进行计时。</p><p id="f67c" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated"><a class="ae lt" href="https://colab.research.google.com/drive/1h0Savk8HSIgraT61burXQwbEUDMz4HT6?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击此处获取Google Colab中的代码</a>。</p><h1 id="d88c" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">GPU并行编程简介</h1><p id="417b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">与CPU相比，GPU的最大优势在于它们能够并行执行相同的指令。单个CPU内核将一个接一个地串行运行指令。在一个CPU上实现并行化需要同时使用其多个内核(物理内核或<a class="ae lt" href="https://en.wikipedia.org/wiki/Hyper-threading" rel="noopener ugc nofollow" target="_blank">虚拟内核</a>)。一台标准的现代计算机有4-8个内核。另一方面，现代GPU拥有数百个甚至数千个计算核心。这两者之间的比较见图1。GPU核心通常较慢，只能执行简单的指令，但它们的数量通常会成倍地弥补这些缺点。需要注意的是，为了让GPU拥有CPU的优势，它们运行的算法必须是可并行的。</p><p id="1d97" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">我认为<a class="ae lt" href="https://en.wikipedia.org/wiki/Grok#In_computer_programmer_culture" rel="noopener ugc nofollow" target="_blank"> <em class="mo">钻研</em> </a> GPU编程主要有四个方面。第一个我已经提到了:理解如何思考和设计本质上并行的算法。这可能很难做到，因为有些算法是串行设计的，还因为同一算法可能有多种并行方式。</p><p id="0876" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">第二个方面是学习如何将位于主机上的结构(如向量和图像)映射到GPU构造(如线程和块)上。循环模式和辅助函数可以帮助我们做到这一点，但最终，实验对于充分利用GPU是非常重要的。</p><p id="8872" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">第三是理解驱动GPU编程的异步执行模型。不仅GPU和CPU彼此独立地执行指令，GPU还有<em class="mo">流</em>，允许多个处理流在同一个GPU中运行。在设计最佳处理流程时，这种异步性非常重要。</p><p id="26f7" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">第四个也是最后一个方面是抽象概念和具体代码之间的关系:这是通过学习API及其细微差别来实现的。</p><p id="f7e3" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">当你阅读第一章时，试着在下面的例子中识别这些概念！</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/31599d7d1af5e4f395da5c6adcd70b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*4WP7TnRj2gB9aZsq2lDtGQ.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">图1.1。简化的CPU架构(左)和GPU架构(右)。算术发生在ALU(算术逻辑单元)、DRAM数据、高速缓存中，高速缓存甚至保存可以更快访问的数据，但通常容量较小。控制单元执行指令。信用:<a class="ae lt" href="https://commons.wikimedia.org/wiki/File:Cpu-gpu.svg" rel="noopener ugc nofollow" target="_blank">维基百科</a>。</p></figure><h1 id="e64d" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">入门指南</h1><p id="d25b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我们将从设置我们的环境开始:高于0.55的Numba版本和支持的GPU。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="d99e" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">Numba CUDA的主要工具是<code class="fe mk ml mm mn b">cuda.jit</code>装饰器。它用于定义将在GPU中运行的函数。</p><p id="d9e7" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">我们首先定义一个简单的函数，它接受两个数字，并将它们存储在第三个参数的第一个元素上。我们的第一个教训是内核(启动线程的GPU函数)不能返回值。我们通过传递输入<em class="mo">和输出</em>来解决这个问题。这是C中常见的模式，但在Python中并不常见。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="5bf3" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">您可能已经注意到，在我们调用内核之前，我们需要在设备上分配一个数组。此外，如果我们想显示返回值，我们需要将它复制回CPU。您可能会问自己，为什么我们选择分配一个<code class="fe mk ml mm mn b">float32</code>(单精度浮点型)。这是因为，虽然大多数现代GPU都支持双精度算法，但双精度算法比单精度算法耗时4倍或更长。所以最好习惯用<code class="fe mk ml mm mn b">np.float32</code><code class="fe mk ml mm mn b">np.complex64</code>而不是<code class="fe mk ml mm mn b">float</code>/<code class="fe mk ml mm mn b">np.float64</code><code class="fe mk ml mm mn b">complex</code>/<code class="fe mk ml mm mn b">np.complex128</code>。</p><p id="824a" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">尽管内核定义看起来类似于CPU函数，但内核调用略有不同。特别是，它在参数前有方括号:</p><p id="bdfc" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated"><code class="fe mk ml mm mn b">add_scalars[1, 1](2.0, 7.0, dev_c)</code></p><p id="8f7b" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">这些方括号分别表示网格中<em class="mo">块</em>的数量，以及块中<em class="mo">线程</em>的数量。随着我们学习使用CUDA进行并行化，让我们更深入地讨论一下这些意味着什么。</p><h1 id="8db2" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">使用CUDA实现并行化</h1><h2 id="ab3a" class="mx kg iq bd kh my mz dn kl na nb dp kp lg nc nd kr lk ne nf kt lo ng nh kv ni bi translated">CUDA网格的剖析</h2><p id="2e60" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">当一个内核启动时，它有一个<em class="mo">网格</em>与之相关联。一个网格由<em class="mo">块</em>组成；一个滑块由<em class="mo">螺纹</em>组成。图2显示了一个一维CUDA网格。图中的网格有4个块。网格中的块数保存在一个特殊的变量中，这个变量可以在内核中被访问，称为<code class="fe mk ml mm mn b">gridDim.x</code>。<code class="fe mk ml mm mn b">.x</code>是指网格的第一维度(本例中唯一的一个)。二维网格也有<code class="fe mk ml mm mn b">.y</code>和三维网格，<code class="fe mk ml mm mn b">.z</code>变量。截至2022年，没有4维或更高的网格。同样在内核内部，您可以通过使用<code class="fe mk ml mm mn b">blockIdx.x</code>找出哪个块正在被执行，在本例中它将从0运行到3。</p><p id="0305" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">每个程序块都有一定数量的线程，保存在变量<code class="fe mk ml mm mn b">blockDim.x</code>中。线程索引保存在变量<code class="fe mk ml mm mn b">threadIdx.x</code>中，在本例中从0到7运行。</p><p id="d003" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">重要的是，不同块中的线程被调度为不同的运行方式，可以访问不同的内存区域，并且在其他方面也有所不同(参见<a class="ae lt" href="https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/" rel="noopener ugc nofollow" target="_blank"><em class="mo">CUDA Refresher:The CUDA Programming Model</em></a>进行简要讨论)。现在，我们将跳过这些细节。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nj"><img src="../Images/110e3d7330f4ce4f0442589e150a988a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VWSMZtIP-Z_1oQBX9JVPjg.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">图1.2。一维CUDA网格。图片作者。</p></figure><p id="af19" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">当我们在第一个例子中用参数<code class="fe mk ml mm mn b">[1, 1]</code>启动内核时，我们告诉CUDA用一个线程运行一个块。用几个线程传递几个块，会多次运行内核。操纵<code class="fe mk ml mm mn b">threadIdx.x</code>和<code class="fe mk ml mm mn b">blockIdx.x</code>将允许我们唯一地识别每个线程。</p><p id="637d" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">让我们尝试对两个数组求和，而不是对两个数字求和。假设每个数组有20个元素。如上图所示，我们可以启动一个每个块有8个线程的内核。如果我们希望每个线程只处理一个数组元素，那么我们至少需要4个块。启动4个块，每个块8个线程，然后我们的网格将启动32个线程。</p><p id="291d" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">现在我们需要弄清楚如何将线程索引映射到数组索引。<code class="fe mk ml mm mn b">threadIdx.x</code>从0运行到7，所以他们自己不能索引我们的数组。此外，不同的区块有相同的<code class="fe mk ml mm mn b">threadIdx.x</code>。另一方面，他们有不同的<code class="fe mk ml mm mn b">blockIdx.x</code>。为了获得每个线程的唯一索引，我们可以组合这些变量:</p><p id="fe1b" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated"><code class="fe mk ml mm mn b">i = threadIdx.x + blockDim.x * blockIdx.x</code></p><p id="8a1d" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">对于第一个块，<code class="fe mk ml mm mn b">blockIdx.x = 0</code>和<code class="fe mk ml mm mn b">i</code>将从0运行到7。对于第二块，<code class="fe mk ml mm mn b">blockIdx.x = 1</code>。从<code class="fe mk ml mm mn b">blockDim.x = 8</code>开始，<code class="fe mk ml mm mn b">i</code>将从8运行到15。同样，对于<code class="fe mk ml mm mn b">blockIdx.x = 2</code>，<code class="fe mk ml mm mn b">i</code>将从16运行到23。在第四个也是最后一个程序块中，<code class="fe mk ml mm mn b">i</code>将从24运行到31。见下表1。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="e34d" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">我们解决了一个问题:如何将每个线程映射到数组中的每个元素…但现在我们有一个问题，一些线程会溢出数组，因为数组有20个元素，而<code class="fe mk ml mm mn b">i</code>上升到32-1。解决方案很简单:对于那些线程，不要做任何事情！</p><p id="97c5" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">让我们看看代码。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="c509" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">在Numba的新版本中，我们得到一个警告，指出我们用主机数组调用了内核。理想情况下，我们希望避免在主机和设备之间移动数据，因为这非常慢。我们应该在所有参数中使用设备数组来调用内核。我们可以通过预先将阵列从主机移动到设备来做到这一点:</p><pre class="lv lw lx ly gt nk mn nl nm aw nn bi"><span id="2406" class="mx kg iq mn b gy no np l nq nr">dev_a = cuda.to_device(a)</span><span id="d25f" class="mx kg iq mn b gy ns np l nq nr">dev_b = cuda.to_device(b)</span></pre><p id="ff3b" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">此外，每个线程的唯一索引的计算会很快过时。令人欣慰的是，Numba提供了非常简单的包装器<code class="fe mk ml mm mn b">cuda.grid</code>,它是用网格维度作为唯一参数来调用的。新内核将如下所示:</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="2e32" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">当我们改变数组的大小时会发生什么？一种简单的方法是简单地改变网格参数(块的数量和每个块的线程数量),以便启动至少与数组中的元素一样多的线程。</p><p id="789f" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">设定这些参数需要一些科学和艺术。对于“科学”，我们会说(a)它们应该是2的倍数，通常在32到1024之间，以及(b)它们应该被选择为最大化<em class="mo">占用率</em>(有多少线程同时处于活动状态)。Nvidia提供了一个<a class="ae lt" href="https://docs.nvidia.com/cuda/cuda-occupancy-calculator/index.html" rel="noopener ugc nofollow" target="_blank">电子表格</a>可以帮助计算这些。对于“艺术”来说，没有什么可以预测内核的行为，所以如果你真的想优化这些参数，你需要用典型的输入来分析你的代码。实际上，现代GPU的“合理”线程数是256。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="438a" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">在讨论矢量求和之前，我们需要讨论一下硬件限制。GPU不能运行任意数量的线程和块。通常每个块不能有超过1024个线程，一个网格不能有超过2个⁶1 = 65535块。这并不是说您可以启动1024 × 65535个线程…除了其他考虑因素之外，根据寄存器占用的内存大小，可以启动的线程数量是有限制的。此外，必须警惕试图同时处理不适合GPU RAM的大型数组。在这些情况下，可以使用单个GPU或多个GPU来分段处理数组。</p><p id="179d" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated"><strong class="kz ir"> <em class="mo"> INFO: </em> </strong> <em class="mo">在Python中，硬件限制可以通过Nvidia的</em> <code class="fe mk ml mm mn b"><em class="mo">cuda-python</em></code> <em class="mo">库通过</em> <a class="ae lt" href="https://nvidia.github.io/cuda-python/module/cuda.html#cuda.cuda.cuDeviceGetAttribute" rel="noopener ugc nofollow" target="_blank"> <em class="mo">函数</em> </a> <code class="fe mk ml mm mn b"><a class="ae lt" href="https://nvidia.github.io/cuda-python/module/cuda.html#cuda.cuda.cuDeviceGetAttribute" rel="noopener ugc nofollow" target="_blank"><em class="mo">cuDeviceGetAttribute</em></a></code> <a class="ae lt" href="https://nvidia.github.io/cuda-python/module/cuda.html#cuda.cuda.cuDeviceGetAttribute" rel="noopener ugc nofollow" target="_blank"> <em class="mo">在他们的文档</em> </a> <em class="mo">中获得。有关示例，请参见本节末尾的附录。</em></p><h2 id="0909" class="mx kg iq bd kh my mz dn kl na nb dp kp lg nc nd kr lk ne nf kt lo ng nh kv ni bi translated">网格步长循环</h2><p id="84aa" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果每个网格的块数超过了硬件限制，但数组适合内存，我们可以使用一个线程来处理几个元素，而不是每个数组元素使用一个线程。我们将通过使用一种叫做<em class="mo">网格步长循环</em>的技术来实现。除了克服硬件限制之外，grid-stride循环内核还受益于线程重用，这是通过最小化线程创建/销毁开销实现的。马克·哈里斯的博客文章<a class="ae lt" href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/" rel="noopener ugc nofollow" target="_blank"> <em class="mo"> CUDA Pro提示:用网格步长循环编写灵活的内核</em> </a>详细介绍了网格步长循环的一些好处。</p><p id="2251" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">这项技术背后的思想是在CUDA内核中添加一个循环来处理多个输入元素。顾名思义，这个循环的步距等于一个网格中的线程数。这样，如果网格中的线程总数(<code class="fe mk ml mm mn b">threads_per_grid = blockDim.x * gridDim.x</code>)小于数组元素的数量，那么一旦内核处理完索引<code class="fe mk ml mm mn b">cuda.grid(1)</code>，它将处理索引<code class="fe mk ml mm mn b">cuda.grid(1) + threads_per_grid</code>等等，直到所有的数组元素都被处理完。事不宜迟，我们来看看代码。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="cbd0" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">这段代码与上面的非常相似，不同的是我们在<code class="fe mk ml mm mn b">cuda.grid(1)</code>开始<em class="mo">，但是执行更多的样本，每<code class="fe mk ml mm mn b">threads_per_grid</code>一个，直到我们到达数组的末尾。</em></p><p id="cc58" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">现在，哪一个内核更快？</p><h1 id="5609" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">定时CUDA内核</h1><p id="b063" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">GPU编程都是关于速度的。因此，准确测量代码执行是非常重要的。</p><p id="dcbb" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">CUDA内核是由主机(CPU)启动的设备功能，当然它们是在GPU上执行的。GPU和CPU不通信，除非我们告诉他们。因此，当GPU内核启动时，CPU将简单地继续运行指令，无论它们是启动更多的内核还是执行其他CPU功能。如果我们在内核启动前后发出一个<code class="fe mk ml mm mn b">time.time()</code>调用，我们将只计算内核启动<em class="mo">所花的时间，而不是<em class="mo">运行</em>。</em></p><p id="0144" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">我们可以用来确保GPU已经“跟上”的一个函数是<code class="fe mk ml mm mn b">cuda.synchronize()</code>。调用此函数将停止主机执行任何其他代码，直到GPU完成执行其中已启动的每个内核。</p><p id="f316" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">为了给内核执行计时，我们可以简单地计算内核运行和同步的时间。对此有两点需要注意。首先，我们需要使用<code class="fe mk ml mm mn b">time.perf_counter()</code>或<code class="fe mk ml mm mn b">time.perf_counter_ns()</code>而不是<code class="fe mk ml mm mn b">time.time()</code>。<code class="fe mk ml mm mn b">time.time()</code>不计算主机休眠等待GPU完成执行的时间。第二个警告是，来自主机的定时代码并不理想，因为存在与此相关的开销。稍后，我们将解释如何使用CUDA <em class="mo">事件</em>来为设备中的内核计时。马克·哈里斯有另一篇关于这个主题的优秀博文，题为<a class="ae lt" href="https://developer.nvidia.com/blog/how-implement-performance-metrics-cuda-cc/" rel="noopener ugc nofollow" target="_blank"> <em class="mo">如何在CUDA C/C++ </em> </a>中实现性能指标。</p><p id="ffcd" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">在使用Numba的时候，有一个细节是我们必须注意的。Numba是一个实时编译器，这意味着函数只有在被调用时才会被编译。因此，对函数<em class="mo">的第一次调用计时也将对编译步骤</em>计时，编译步骤通常要慢得多。我们必须记住，总是首先通过启动内核来编译代码，然后同步它，以确保没有任何东西留在GPU中运行。这确保了下一个内核无需编译就能立即运行。还要注意数组的<code class="fe mk ml mm mn b">dtype</code>应该是相同的，因为Numba为参数<code class="fe mk ml mm mn b">dtypes</code>的每个组合编译一个唯一的函数。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="67c2" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">对于简单的内核，我们还可以测量算法的吞吐量，即每秒钟浮点运算的次数。它通常以GFLOP/s(每秒千兆次浮点运算)来度量。我们的加法运算只包含一个翻牌:加法。因此，吞吐量由下式给出:</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="bed1" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">2D的例子</h1><p id="2cae" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了结束本教程，让我们制作一个2D内核来对图像应用<a class="ae lt" href="https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.adjust_log" rel="noopener ugc nofollow" target="_blank">对数校正</a>。</p><p id="8528" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">给定值在0和1之间的图像I(x，y ),对数校正图像由下式给出</p><p id="be27" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">Iᵪ(x，y) = γ log₂ (1 + I(x，y))</p><p id="5869" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">首先让我们获取一些数据！</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b9be525d2cba13d89b75fb2cd2336ad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*ImRDohh5K-9Oz-tqSty27w.png"/></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">图1.3。原始“月球”数据集。图片作者。</p></figure><p id="95e9" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">如你所见，数据在低端已经饱和。0.6以上的数值几乎没有。</p><p id="b006" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">让我们来写内核。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure><p id="abe0" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">让我们记下这两个<code class="fe mk ml mm mn b">for</code>循环。请注意，第一个<code class="fe mk ml mm mn b">for</code>循环从<code class="fe mk ml mm mn b">iy</code>开始，第二个最里面的循环从<code class="fe mk ml mm mn b">ix</code>开始。我们可以很容易地选择<code class="fe mk ml mm mn b">i0</code>在<code class="fe mk ml mm mn b">ix</code>开始，而<code class="fe mk ml mm mn b">i1</code>在<code class="fe mk ml mm mn b">iy</code>开始，这样会感觉更自然。那么我们为什么选择这个顺序呢？事实证明，第一种选择的内存访问模式效率更高。由于第一个网格索引是最快的一个，所以我们想让它匹配我们最快的维度:最后一个。</p><p id="7f29" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">如果你不想相信我的话(你不应该相信！)您现在已经了解了如何对内核执行进行计时，您可以尝试这两个版本。对于像这里使用的这种小数组，这种差异可以忽略不计，但是对于更大的数组(比如10，000乘10，000)，我测得的加速大约是10%。不是很令人印象深刻，但是如果我可以通过一次变量交换给你10%的提高，谁会不接受呢？</p><p id="5738" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">就是这样！我们现在可以在校正后的图像中看到更多细节。</p><p id="caa1" class="pw-post-body-paragraph kx ky iq kz b la mp jr lc ld mq ju lf lg mr li lj lk ms lm ln lo mt lq lr ls ij bi translated">作为一个练习，尝试用不同的网格来计时不同的启动，以找到适合您的机器的最佳网格大小。</p><figure class="lv lw lx ly gt lz gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi nu"><img src="../Images/01f1e182d5e22a9d0e8a77e863fc52d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*dLTQXTNHyqK44Q3XR6KWzg.png"/></div></div><p class="mg mh gj gh gi mi mj bd b be z dk translated">图1.4。原始(左)和对数校正(右)“月球”数据集。图片作者。</p></figure><h1 id="f3f0" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">结论</h1><p id="9f37" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在本教程中，你学习了Numba CUDA的基础知识。您学习了如何创建简单的CUDA内核，并将内存转移到GPU来使用它们。您还学习了如何使用一种叫做<em class="mo">网格步长循环</em>的技术迭代1D和2D数组。</p><h1 id="0620" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">附录:使用Nvidia的cuda-python探测设备属性</h1><p id="654e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了对GPU的确切属性进行精细控制，您可以依赖Nvidia提供的底层官方CUDA Python包。</p><figure class="lv lw lx ly gt lz"><div class="bz fp l di"><div class="mv mw l"/></div></figure></div></div>    
</body>
</html>