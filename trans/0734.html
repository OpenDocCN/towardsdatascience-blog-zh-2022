<html>
<head>
<title>How to Install Center Track on Windows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Windows上安装中央轨道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-install-center-track-on-windows-10a109ef7f75#2022-03-01">https://towardsdatascience.com/how-to-install-center-track-on-windows-10a109ef7f75#2022-03-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d44c" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">最先进的姿态估计，内置跟踪器触手可及</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4932f2a3fe100be04a5c508ad83c126c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lk7hhV2xD9PijvS1Rif4eA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CenterTrack的检测。雷尼尔·里道在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="09f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">最近，我受雇开发一个需要实时姿态估计的MVP。前几年，占主导地位的技术是CMU的OpenPose，尽管有点麻烦，但一旦你设法正确设置，它就能很好地工作。备选方案包括<a class="ae ky" href="https://github.com/xingyizhou/CenterNet" rel="noopener ugc nofollow" target="_blank"> CenterNet </a>、<a class="ae ky" href="https://github.com/MVIG-SJTU/AlphaPose" rel="noopener ugc nofollow" target="_blank"> AlphaPose </a>和<a class="ae ky" href="https://blog.tensorflow.org/2018/05/real-time-human-pose-estimation-in.html" rel="noopener ugc nofollow" target="_blank"> PoseNet </a>。总的来说，所有这些技术都缺少内置的<a class="ae ky" href="https://en.wikipedia.org/wiki/Video_tracking" rel="noopener ugc nofollow" target="_blank">跟踪器</a>。快进到2020年，CenterNet背后的同一批作者推出了<a class="ae ky" href="https://github.com/xingyizhou/CenterTrack" rel="noopener ugc nofollow" target="_blank">center track</a>——一个姿势估计网络，包括跟踪作为其问题公式化的一部分。</p><p id="da32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于门外汉来说，<strong class="lb iu">追踪就是将帧连接起来，创造一个历史</strong>。每当我们检测到一个人，我们就给它一个ID，在所有后续帧中，每当我们看到<em class="me">这个人，</em>我们就应该给它相同的ID。换句话说，跟踪确保我们知道视频中谁是谁。例如，假设你有一个监控摄像头发现了一个罪犯。追踪器让我们可以查询这个人在视频中出现的时间和地点。</p><p id="1983" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为参考，CenterTrack中的追踪器是基于数据关联的极简在线追踪器，很像<a class="ae ky" href="https://github.com/abewley/sort" rel="noopener ugc nofollow" target="_blank">排序</a>。简单地说，它只使用过去和现在的数据(而不是未来的)。此外，它将其自身限制为仅使用过去检测的位置/姿态来建立先前和当前帧姿态之间的相似性矩阵。因此，没有使用图像/视觉特征。最后，分配算法将先前姿态的id与当前姿态进行匹配。默认情况下，它使用贪婪的分配策略。</p><p id="01d0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与以前的方法相比，使用CenterTrack的主要优势除了其更高的准确性之外，还在于不必滚动您的跟踪器实现或依赖<a class="ae ky" href="https://docs.opencv.org/4.x/d2/d0a/tutorial_introduction_to_tracker.html" rel="noopener ugc nofollow" target="_blank"> OpenCV的</a>缓慢且过时的跟踪API。此外，与OpenPose不同，它是基于Python的，并获得了麻省理工学院的许可。</p><p id="171a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于限制，尽管在姿势估计方面是最先进的，但它的跟踪器对你来说可能有点太小了，所以你可能仍然想在它上面滚动一些自定义跟踪作为备份。例如，作为一个基于关联的跟踪器，它在分配id时不使用视觉信息。因此，它不能处理闭塞或重入。</p><h1 id="8623" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">在Windows上运行。</h1><p id="ba93" class="pw-post-body-paragraph kz la it lb b lc mx ju le lf my jx lh li mz lk ll lm na lo lp lq nb ls lt lu im bi translated">源代码仅适用于Linux。然而，我们可以带着一点爱在Windows上运行它。在这里，我将列出我为使它工作所采取的步骤以及它们的基本原理。我将坚持使用这种格式，为您提供自己处理任何问题的工具，因为移植库充其量只是一种黑客行为。</p><p id="11c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">总结:</strong>幸运的是，代码库并不严重依赖于Linux特性。大部分工作是为Windows端口(<a class="ae ky" href="https://github.com/rathaROG/DCNv2_Windows" rel="noopener ugc nofollow" target="_blank"> DCNv2 </a>)替换Linux依赖项，并在我们的系统中获得Python (3.8)、CUDA (11.1)和PyTorch (1.8)的正确版本。自始至终，我们混合使用conda和pip命令来安装所有必需的依赖项。</p><p id="d279" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">免责声明:</strong>将知识库移植到Windows后，我只用过它进行推断(网络摄像头和视频)。我并不认为这一过程完全适用于定制数据集或计算数据集指标的培训。</p><p id="ec0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们开始吧:</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="2442" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第一步:</strong>使用Python 3.8构建conda环境。你爱怎么叫都行。不要忘记激活它！</p><blockquote class="nj nk nl"><p id="5932" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">conda create -y --name centertrack python=3.8</code></p><p id="9dc8" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">conda activate <em class="it">centertrack</em></code></p></blockquote><p id="1f2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第二步:</strong>获得合适的CUDA工具包(11.1)，一些加速API，Git，和一个工作的C++编译器。</p><blockquote class="nj nk nl"><p id="5959" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">conda install -y cudatoolkit=11.1 mkl mkl-devel mkl-include tbb intel-openmp blas freetype zlib git cxx-compiler -c conda-forge</code></p></blockquote><p id="a06c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第三步:</strong>从现在开始，我们做任何事情都要用画中画。以我的经验来看，conda在获取原生库方面非常出色，比如CUDA，但是在获取我们需要的Python东西方面却很糟糕。所以我们从更新我们的基础设施开始，然后从它的官方库安装PyTorch 1.8。</p><blockquote class="nj nk nl"><p id="fe97" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">pip install -U pip setuptools wheel</code></p><p id="afdd" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 -f <a class="ae ky" href="https://download.pytorch.org/whl/lts/1.8/torch_lts.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/lts/1.8/torch_lts.html</a></code></p></blockquote><p id="1e87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第四步:</strong>克隆CenterTrack存储库并使用pip安装requirements.txt文件(<code class="fe np nq nr ns b">pip install -r requirements.txt</code>)。最后，在资源库根目录下创建一个名为“models”的文件夹，并从<a class="ae ky" href="https://github.com/xingyizhou/CenterTrack/blob/master/readme/MODEL_ZOO.md" rel="noopener ugc nofollow" target="_blank">官方资源库</a>下载您需要的模型。如果你正在寻找姿势估计，向下滚动到末尾，下载coco_pose_tracking。</p><p id="9a27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第五步:</strong> CenterTrack将DCNv2代码库用于可变形卷积。但是，这个存储库包含一个Linux版本的子模块。相反，我们应该下载这个库，DCNv2的一个Windows端口。将这个repo克隆到<code class="fe np nq nr ns b">src/lib/model/networks/</code>，使用终端导航到它(不要忘记激活conda环境！)和<code class="fe np nq nr ns b">run python setup.py build develop</code></p><p id="f44b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">第六步:</strong>测试您的安装。这里有一个片段，您可以在存储库根目录的终端上使用。如有必要，请确保更改型号名称。</p><blockquote class="nj nk nl"><p id="d269" class="kz la me lb b lc ld ju le lf lg jx lh nm lj lk ll nn ln lo lp no lr ls lt lu im bi translated"><code class="fe np nq nr ns b">python src/demo.py tracking,multi_pose --load_model models/coco_pose.pth --demo webcam</code></p></blockquote></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="c313" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">这是一个简单的教程。将来，我可能会写更多关于跟踪以及它如何帮助创建容错系统的内容。与此同时，我刚刚发表了一篇关于组合人工智能模型如何显著恶化您的性能的文章。在处理视频和流时，您可以减轻这些问题的方法之一是通过跟踪。</p><div class="nt nu gp gr nv nw"><a rel="noopener follow" target="_blank" href="/the-pitfalls-of-using-ai-as-the-input-of-another-ai-e0a3f0f485e4"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">使用人工智能作为另一个人工智能的输入的陷阱</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">为什么AI模型链在一起会失败。</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok ks nw"/></div></div></a></div></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="dc91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">他的一切都是为了现在。如果你对这篇文章有任何问题，请随时评论或与我联系。你也可以订阅我的收件箱，以便在我发表文章的时候得到通知<a class="ae ky" href="https://ygorserpa.medium.com/subscribe" rel="noopener">。</a></p><p id="5a04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是中新，我强烈推荐<a class="ae ky" href="https://ygorserpa.medium.com/membership" rel="noopener">订阅</a>。对于数据和IT专业人士来说，中型文章是<a class="ae ky" href="https://stackoverflow.com/" rel="noopener ugc nofollow" target="_blank"> StackOverflow </a>的完美搭档，对于新手来说更是如此。注册时请考虑使用<a class="ae ky" href="https://ygorserpa.medium.com/membership" rel="noopener">我的会员链接。</a></p><p id="ceb3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读:)</p></div></div>    
</body>
</html>