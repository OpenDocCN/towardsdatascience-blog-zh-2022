<html>
<head>
<title>Is LDA Topic Modeling Dead?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LDA话题建模死了吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/is-lda-topic-modeling-dead-9543c18488fa#2022-07-06">https://towardsdatascience.com/is-lda-topic-modeling-dead-9543c18488fa#2022-07-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c849cbf4c271f6a390f8bfce4d34e4e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jLNPeiabrWe665_QAf3f5w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><div class=""/><div class=""><h2 id="715d" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">利用嵌入式主题模型克服LDA的缺点</h2></div><p id="60f9" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">2003年的论文<em class="lq">Latent Dirichlet Allocation</em>将LDA确立为现在可能是最著名和最广泛使用的主题建模算法(Blei et al. 2003)。然而，尽管LDA无处不在且经久不衰，但经历过LDA的人都很熟悉它的局限性。除了它的不稳定性之外，LDA需要更多的文本预处理来获得好的结果。即使抛开实现细节不谈，LDA也有一个更普遍的问题，这个问题困扰着主题建模者，不管他们使用什么算法——缺乏评估他们模型的基础事实。</p><p id="3f27" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为主题模型建立基础事实的唯一可靠和一致的方法是让专家创建一个公共的语料库主题词汇表，然后让多个注释者将词汇表应用到文本——这是一个耗时且昂贵的过程。这种“手工”方法，在社会科学中已经实践了几十年，正是无监督主题建模试图解决的问题。</p><p id="4a20" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">获得一个客观的标准来衡量和评估一个模型的实际限制无疑导致了许多ML/AI实践者忽略了主题建模而去做其他不那么麻烦的工作。然而，尽管有缺点，主题建模，特别是LDA，已经被证明足够有用来保持它们的流行。一篇讨论这个问题的论文简明扼要地总结了主题建模在面临其缺点时的持续吸引力</p><blockquote class="lr ls lt"><p id="084c" class="ku kv lq kw b kx ky kg kz la lb kj lc lu le lf lg lv li lj lk lw lm ln lo lp ij bi translated"><em class="jf">…虽然不能保证一个“主题”将对应于一个可识别的主题或事件或话语，</em>它们经常以其他方法无法做到的方式做到这一点<em class="jf"> (Nguyen et al. 2020) </em> <em class="jf">(着重部分由作者标明)</em>。</p></blockquote><p id="6692" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">对于这些作者和许多其他人来说，主题建模已经被证明是“足够好”的，值得他们继续关注。</p><p id="435f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">本文探讨了一种新的技术，使用语言嵌入的主题建模，有效地解决了使用LDA时遇到的两个最突出的问题。这种新方法在论文<a class="ae lx" href="https://arxiv.org/abs/2203.05794" rel="noopener ugc nofollow" target="_blank"> <em class="lq"> BERTopic:用基于类的TF-IDF过程进行神经主题建模</em></a><em class="lq"/>(Grootendorst 2022)中有详细描述。BERTopic是一个从嵌入数据中产生主题模型的端到端工具。默认情况下，它利用<a class="ae lx" href="https://github.com/scikit-learn-contrib/hdbscan" rel="noopener ugc nofollow" target="_blank"> HDBSCAN </a>来识别语言嵌入中包含的主题。尽管̶̶h̶̶̶d̶̶̶b̶̶̶s̶̶̶c̶̶̶a̶̶̶n[<a class="ae lx" href="https://umap-learn.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">umap</a>(bertopic中默认使用它来减少语言嵌入的维度)是随机的，并且会受到运行变化的影响，但根据我的经验，它比LDA产生更稳定和可预测的主题分组。其次，因为BERTopic主题模型不同于它们总结的嵌入数据，所以有可能评估特定的运行是否很好地表示了底层数据结构。这个特性有效地创建了一个逐模型的基本事实，可用于评估和调优。没有什么可以和LDA相比。</p><h1 id="792b" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="a164" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">用BERTopic，别用LDA！LDA是一个强大的主题建模工具，但是它的不稳定性是一个主要的，通常不被承认的绊脚石。BERTopic没有不稳定的问题。重要的是，本文试图证明作为主题建模基础的单词嵌入可以有效地创建一个基础事实，在此基础上可以对给定的主题模型进行评估和调整。从实用的角度来看，BERTopic也更容易使用，因为没有文本预处理，并且如下所示，比LDA的资源密集度低得多。</p><h1 id="bd50" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">免责声明和链接</h1><p id="ad7b" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">我与BERTopic项目没有官方关系(与LDA或EnsembleLDA也没有官方关系)。作为本文的配套，我创建了一个<a class="ae lx" href="https://public.tableau.com/views/IsLDATopicModelingDead/EmbeddingsStory?:language=en-US&amp;:display_count=n&amp;:origin=viz_share_link" rel="noopener ugc nofollow" target="_blank"> Tableau演示</a>，它将允许读者交互式地探索为本文创建的模型。本文中使用的数据是公开许可的，可以在<a class="ae lx" href="https://www.kaggle.com/danrobinson707/datasets?scroll=true" rel="noopener ugc nofollow" target="_blank">ka ggle</a>(<a class="ae lx" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">CC0 license</a>)上找到。我将一些技术细节和注释放在了文章末尾的附录中。</p><h1 id="9683" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">不稳定的地面</h1><p id="3e1d" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">反对LDA的案例沿着两条轴线展开。首先是算法固有的不稳定性。我以前写过关于<a class="ae lx" rel="noopener" target="_blank" href="/lda-topic-model-instability-c2fedb77d249"> LDA主题模型不稳定性</a>和为给定LDA模型建立客观正确的<a class="ae lx" rel="noopener" target="_blank" href="/determining-the-right-lda-topic-model-size-part-ii-ff4312e9fd9">目标主题数量</a>时固有的<a class="ae lx" rel="noopener" target="_blank" href="/use-metrics-to-determine-lda-topic-model-size-1a1feaa1ff3c">困难</a>。为本文生成的所有模型都是从同一个语料库中生成的。LDA或EnsembleLDA在三种不同的配置中针对语料库运行。对每一对进行评估，以确定它们彼此的一致程度。</p><p id="e245" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">使用<a class="ae lx" href="https://radimrehurek.com/gensim/models/ldamodel.html" rel="noopener ugc nofollow" target="_blank"> Gensim LDA </a>实施的默认参数的第一次LDA运行产生了以下热图，该热图比较了每个模型主题的文档/主题分配:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/3bd774ab77e7a6a3ca7827452185388d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GjuwSknA5eQ8M35IdlZOVQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">不相关的主题模型。图片作者。</p></figure><p id="1483" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">橙色单元格表示出现在第一个模型的主题2和第二个模型的主题4中的文档数量，并记录了62%的重叠。这是本次运行中最相关的主题对。尽管每个模型都基于相同的数据和相同的参数，但这些模型代表了非常不同的主题集。然而，通过增加我们对问题的处理能力，有可能得到更好的结果。</p><p id="d6b6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lx" href="https://radimrehurek.com/gensim/models/ensemblelda.html" rel="noopener ugc nofollow" target="_blank"> EnsembleLDA </a>，通过将多个模型协调到单个模型实例中，明确处理LDA模型不稳定性问题。使用与上述相同的数据和设置，我们可以看到模型相关性的显著提高:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/d71134f10f5bca06585dc44c1268a97f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5YfyZwevRp_VgfoTh8Azgg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">改进的模型相关性。图片作者。</p></figure><p id="7e07" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">然而，这种改善是有代价的。在Colab+实例上运行时，前两次相关性差的运行只需要几秒钟就能生成。上述改进的运行每个模型花费了三个多小时。如果我们在这个问题上投入更多的资源，将每个模型的处理时间增加到9个小时以上，结果会继续改善:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a286c497d68b95394a020bc3a8d4ca6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*SM0qiqYsU8rxUJCE2owFvg.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="bae2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">但是，尽管最后一组的相关性更好，LDA模型不稳定性的影响是显著的。在第一次运行中，选择任意数量的12个主题作为模型的参数。但是，随后的四个模型都是用EnsembleLDA生成的。EnsembleLDA的一个引人注目的特点是，在无人监督的情况下，该算法将收敛于优化数量的主题。然而，尽管EnsembleLDA在选择主题数量方面做得很好，但我们必须注意，在示例中，对于有多少个主题仍然没有达成一致。在EnsembleLDA模型中，我们分别看到8、11、10和9个主题。因此，即使后来的模型已经显著减少了它们的文档/主题分配中的漂移，在这个数据集中的主题数量上仍然没有一致意见。</p><p id="b8c4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">其他判断LDA模型正确性的方法呢？最常见的方法之一是使用基于npmi的一致性分数(Lau et .艾尔。2014).有许多不同的变体，这里我们用c_v，一个常见的选择。前两个模型的结果分别是. 291和. 295。这些分数比第二组模型的分数低，分别为0.578和0.566。然而，尽管最后一组模型显示出其主题之间的一致性比倒数第二组有显著提高，但它们的得分. 551和. 549比第二组差<em class="lq"/>。虽然基于npmi的指标在实验室中表现良好，但以我的经验来看，它们往往达不到自己的承诺。</p><h1 id="db78" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">使用可视化来理解模型</h1><p id="5238" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">在散点图中可视化文档提供了信息丰富的可视参考，有助于理解每个模型中三万个文档的分布。以下是两个最佳相关EnsembleLDA模型之一的TSNE·2D简化:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/c76a3400825c3569e2dd49895263b3d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VYsSfY-x6kY0PYVJa9U7tw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">2D TSNE对LDA输出的预测。鼓励读者通过<a class="ae lx" href="https://public.tableau.com/app/profile/dan.in.berkeley/viz/IsLDATopicModelingDead/EmbeddingsStory" rel="noopener ugc nofollow" target="_blank">互动版</a>探索剧情。图片作者。</p></figure><p id="9c69" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们可以清楚地看到主题之间的空间分隔。这个可视化的<a class="ae lx" href="https://public.tableau.com/app/profile/dan.in.berkeley/viz/IsLDATopicModelingDead/EmbeddingsStory" rel="noopener ugc nofollow" target="_blank">交互版本</a>允许用户放大并悬停在代表单个文档的每个点上。通过这种方式，可以了解文档的内容是如何以特定的方式将它们分类的。</p><h1 id="88c5" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">BERTopic替代方案</h1><p id="d098" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">如果您不熟悉BERTopic的软件包，我推荐您阅读它的文档以及它的作者Maarten Grootendorst发表的文章和论文中的BERTopic的<a class="ae lx" href="https://maartengr.github.io/BERTopic/algorithm/algorithm.html" rel="noopener ugc nofollow" target="_blank">架构和方法</a>。简而言之，BERTopic使用HDBSCAN(或任何其他您愿意使用的聚类机制)来确定语料库中的主题。然后，它使用TF-IDF的变体— c-TF-IDF，它不是查看单个文档来提取有意义的词汇，而是聚合整个主题的文档并从整个主题中提取有意义的词汇。虽然我认为c-TF-IDF本身是一个重要的贡献，但在本文中，我将重点关注通过对BERT句子嵌入进行HDBSCAN聚类的主题发现，并将其与上面的LDA模型进行比较，而不涉及c-TF-IDF词汇发现阶段。</p><p id="8a15" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在BERTopic中，模型不稳定的问题实际上是不存在的。下面是一个热图，比较了使用相同语料库和相同参数创建的两个不同模型的文档分配:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/5ca275247c4e47578156b8c0946d316d.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/0*lMBK_cTBAQ5mL2sy"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="0b83" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">根据设计，HDBSCAN不会尝试对低于阈值的文档进行分类，这些文档被分配到类别1。此外，BERTopic从文档总数的最大到最小重新编号所有主题，这说明了上面矩阵的对称对角线-这是BERTopic的纯粹美学特征。</p><p id="e02e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">值得注意的是，连续的BERTopic运行将在很大程度上产生相同数量的主题。虽然在文档分配方面，模型与模型之间存在一些偏差和变化，但与LDA相比，不稳定性程度是最小的。最后，这些模型是使用启用GPU的Colab+帐户在几分钟内创建的，与需要数小时计算时间的资源密集型LDA实现相比，这是一个巨大的实际差异。</p><h1 id="06e9" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">我的袖子里几乎没有任何东西</h1><p id="c39a" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">细心的读者会注意到，上面使用的BERTopic模型只产生了六个主题(除了-1“主题”)。在使用这个语料库时，我发现当HDBSCAN针对嵌入运行时，存在一个“自然”的分割，其中体育故事包含大约六分之一的数据，并分成五个主题领域(有趣的是组织为:足球/橄榄球/板球、赛车、高尔夫、网球、拳击、游泳/跑步/奥运会)，而所有其余的被组织为一个非体育相关文档的超级集群。因此，我将数据集分为两部分，运动和非运动。当BERT运行这两个分段的语料库时，体育分段保留了与原始语料库中出现的相同的内部组织，将体育分成六个分段。然而,“非体育”这个以前只有一个类别的blob被分解成了十个独立的主题。我对HDBSCAN难以细分非体育超级集群的原因的假设是，当所有数据都在一个组中时，hdb scan无法在划分体育主题的同时将较大的数据集细分为更精细的分组。当文集被分成两个独立的部分时，一切都水落石出了。</p><p id="b6e4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">正因为如此，也因为BERTopic中还没有工具来执行这种操作，下面的主题分组是从两个不同的BERTopic模型中组合起来的。用于获得正确的HDBSCAN参数的工具和技术超出了本文的范围。</p><h1 id="3760" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">嵌在…中的基本事实。嵌入？</h1><p id="7bef" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">下面是2D·TSNE对伯特嵌入的投影，覆盖了来自伯特普的最终主题，删除了-1文档:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/954f79547417202461d5148200a8b5c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I7gszJGo-1e7o-9n"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="0a92" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在图像的左上方，巨大的粉红色星团主要是足球，还有橄榄球和板球。其他运动:赛车、高尔夫、网球、拳击和游泳/跑步/奥运会，位于紧接其下方和左侧的五个集群中。Tableau表示允许用户自由地遍历数据集，并向下查看文档级别，以了解更多关于BERTopic如何分割该语料库的信息。</p><p id="ca29" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">另一个细分展示了BERTopic在主题之间进行精细、有价值的区分的能力。这种能力似乎远远超出了LDA的能力范围。另一个在BERTopic模型中可以观察到的细微差别的例子是大的中央绿色星团和它左边的两个分离的绿色星团。这些都是一个主题及其主题词的一部分:</p><p id="5f8f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">狗，动物，动物，狗，物种，就像，猫，动物园，时间</p><p id="a7e4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">最左边的群集似乎大部分或全部是关于狗的，中间的是关于猫的，大的分组(从左到右按空间组织)是关于外来动物、野生动物、海洋生物的，然后在这个更大的群集的边缘有一个分组与考古问题和少量的生物科学文献有关。这种清晰的空间/语义组织可以在整个BERTopic模型中找到。</p><p id="2a37" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们可以使用散点图来比较由BERTopic和LDA创建的两个不同的模型。首先，我们可以将LDA主题叠加到BERTopic模型上:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nf"><img src="../Images/6c103db32171e2dd2e1be9002df2f81d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aH0QXymhgTBfMaGW"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="c974" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">LDA主题通常与从BERT嵌入外推的坐标位置有很好的相关性。换句话说，较少数量的LDA主题或多或少符合BERTopic生成的主题分组。使用相同的BERT到LDA映射的热图，我们可以看到相同的有序数据的另一个视图:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/4b4afd45fdf92704ed53fca343c409a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*Ndg39iGP5ped-3vlYl9-8g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">BERT主题/文档分布在左下方，LDA分布在上方。图片作者。</p></figure><p id="02f0" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">0和1 LDA主题是与体育相关的故事。我们可以看到，LDA将这些文档分为两个集群，BERTopic分为6个集群。其他六个BERTopic主题大致对应于LDA主题，但是剩余的四个BERTopic主题集群与LDA主题没有明确的关系。</p><p id="f32e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">反向视图，将BERT主题投影到LDA坐标上，揭示了一个更混乱的视图:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/d6fa5214a9e25eb12449f1827001cd74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K5hzwtUCm4cyqDSO"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片作者。</p></figure><p id="ec61" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在这种情况下，我们可以看到，虽然一些领域大体一致，但在有分歧的地方，事情是相当混乱的。例如，右边有两只“眼睛”的粉色区域是体育报道。两个模型都很好地选择了足球故事。然而，LDA模型无法有效地区分不同种类的运动。</p><p id="64ec" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">翻转的热图以不同的形式显示了混淆程度:</p><figure class="mw mx my mz gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/0bd0521d75083c311778a81b651827ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7D-nTjhTVuRgzQhJVEA1Fg.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">左下方是LDA主题，上方是BERT主题。图片作者。</p></figure><p id="43a2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">只有三个LDA主题可以说与它们的BERTopic对等物有任何程度的关联。</p><h1 id="a42f" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">那又怎样？</h1><p id="3343" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">上面的两个模型，一个是由BERTopic创建的，另一个是由EnsembleLDA创建的，显然是不同的，很难找到比通过关于它们各自的文档/主题分配的协议更多的东西。我们应该从哪里来解释这种分歧呢？主题建模者一直在处理这种不确定性。由于没有客观测量的基础，建模者只能做出他们所能收集到的最明智的主观判断。</p><p id="aca6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">然而，我认为，基于嵌入的主题模型提供了一种替代诉诸纯粹的主观措施。有了上面的数据，我对散点图的分析充满信心，BERTopic模型在主题聚类定义方面更加精确。此外，我无法找到利用LDA散点图来辨别底层数据组织的任何有意义的东西，或者可以做些什么来改进模型。虽然每个散点图都是该特定模型的一个很好的表示，但据我所知，它与文档本身的底层语义结构无关。一次又一次基于BERT的散点图揭示了关于文档的惊人的组织良好的和重要的信息，以合理化的空间关系表达。在LDA可视化中找不到任何可比较的东西。</p><p id="fd93" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">希望这篇文章激发了人们对嵌入主题建模的兴趣，特别是BERTopic。这里介绍的简单实用的事实是:BERTopic不需要文本预处理；LDA模型不稳定性的论证问题；和经验丰富的主题建模者的兴趣所在。</p><p id="8b33" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">然而，除了这些实际考虑之外，还有一种直觉，即BERTopic为其主题模型使用的嵌入有效地为主题建模建立了迄今为止难以捉摸的基础事实。基于我迄今为止的探索，似乎有理由认为BERT嵌入比LDA为创建主题模型创造了更坚实的基础。</p><p id="53d7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当我们查看LDA嵌入时，我们看到的是一个数学过程的结果，该数学过程只有直接的语料库可以操作和推断语义。每个LDA模型代表一个小的、封闭的关系世界。当使用嵌入时，我们将我们的数据连接到一个更大的信息体，这个信息体声称在某种程度上代表了语言本身。在我看来，当检查基于嵌入的模型数据时，这种更大的关系是可见的。</p><h1 id="112e" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">附录</h1><p id="e125" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">这些例子使用的数据是随机选择的，一个更大的公开许可的数据集<a class="ae lx" href="https://www.kaggle.com/harishcscode/all-news-articles-from-home-page-media-house" rel="noopener ugc nofollow" target="_blank">新闻文章</a> ( <a class="ae lx" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CC0许可</a>)的<a class="ae lx" href="https://www.kaggle.com/datasets/danrobinson707/newsdf" rel="noopener ugc nofollow" target="_blank"> 3万篇文章子集</a> ( <a class="ae lx" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CC0许可</a>)。</p><p id="71d3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">正如文章中提到的，我跳出了BERTopic，获得了优化的HDBSCAN参数，以便与BERTopic一起使用，从而得到这里显示的输出。用于实现它们的方法是从BERTopic模型中提取嵌入(实际上是嵌入的UMAP缩减)，然后运行一系列改变<em class="lq"> min_sample_size </em>和<em class="lq"> min_cluster_size </em> HDBSCAN参数的实验。根据确定的主题群的数量和离群值的数量-1，文档分配来判断输出。我在这个数据集上发现，在几十次运行随机选择的值时，会产生“自然”数量的主题。有了这些数据，话题的数量聚集在3、7左右，然后跃升到50多个。我选择了产生这些异常值最少的集群配置的参数，然后运行散点图。基于这些结果，我认为将语料库分成两部分并重新运行调优实验可能是有意义的。最终结果如上所示，并形成Tableau表示的数据。我希望将来能更详细地写下这个技巧，鼓励那些对细节感兴趣的人通过我个人资料中的LinkedIn帐户与我联系。</p><p id="9eb2" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">学术界已经认识到，缺乏基本事实是主题建模的一个障碍。要了解更多关于这个问题的信息，我建议:</p><blockquote class="lr ls lt"><p id="25b2" class="ku kv lq kw b kx ky kg kz la lb kj lc lu le lf lg lv li lj lk lw lm ln lo lp ij bi translated">Nguyen，d .，Liakata，m .，DeDeo，s .，Eisenstein，j .，Mimno，d .，Tromble，r .，和Winters，J. (2020)。<em class="jf">我们如何用文字做事:将文本作为社会和文化数据进行分析</em>。人工智能前沿，3，62。</p><p id="3f40" class="ku kv lq kw b kx ky kg kz la lb kj lc lu le lf lg lv li lj lk lw lm ln lo lp ij bi translated">奥康纳，b，巴曼，d，&amp;史密斯，N. A .(未注明)。社会科学的计算文本分析:模型假设和复杂性。2022年6月28日检索，来自<a class="ae lx" href="https://people.cs.umass.edu/~wallach/workshops/nips2011css/papers/OConnor.pdf" rel="noopener ugc nofollow" target="_blank">https://people . cs . umass . edu/~ wallach/workshop/nips 2011 CSS/papers/oconnor . pdf</a></p><p id="d67c" class="ku kv lq kw b kx ky kg kz la lb kj lc lu le lf lg lv li lj lk lw lm ln lo lp ij bi translated"><em class="jf">人文学科中的主题建模:概述</em>。(未注明)。检索于2022年6月28日，来自<a class="ae lx" href="https://mith.umd.edu/news/topic-modeling-in-the-humanities-an-overview/" rel="noopener ugc nofollow" target="_blank">https://Smith . UMD . edu/news/topic-modeling-in-the-humanity-an-overview/</a></p></blockquote><h1 id="9e99" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">文献学</h1><p id="a2fd" class="pw-post-body-paragraph ku kv jf kw b kx mq kg kz la mr kj lc ld ms lf lg lh mt lj lk ll mu ln lo lp ij bi translated">文中引用:</p><p id="9b92" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">布莱博士，Ng，A. Y .，&amp;乔丹，M. I. (2003年)。潜在狄利克雷分配。<em class="lq">机器学习研究杂志:JMLR </em>。<a class="ae lx" href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com" rel="noopener ugc nofollow" target="_blank">https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com </a></p><p id="040d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Grootendorst，M. (2022)。BERTopic:使用基于类的TF-IDF过程的神经主题建模。在<em class="lq">arXiv【cs。CL] </em>。arXiv。http://arxiv.org/abs/2203.05794<a class="ae lx" href="http://arxiv.org/abs/2203.05794" rel="noopener ugc nofollow" target="_blank"/></p><p id="5157" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">刘，J. H .，纽曼博士和鲍德温博士(2014年)。机器阅读茶叶:自动评估主题连贯性和主题模型质量。<em class="lq">计算语言学协会欧洲分会第14届会议论文集</em>，530–539。</p></div></div>    
</body>
</html>