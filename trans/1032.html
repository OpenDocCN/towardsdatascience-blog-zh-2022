<html>
<head>
<title>Making Deep Learning Climate-Friendly</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">让深度学习变得气候友好</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-deep-learning-climate-friendly-74ed4f2404e2#2022-03-17">https://towardsdatascience.com/making-deep-learning-climate-friendly-74ed4f2404e2#2022-03-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dc39" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何解决人工智能的碳足迹</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/d760952bb82125514fe531be9af1b482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2KrUPGztVtNxb75l"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">佩吉·安克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d093" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">深度学习正在给世界带来许多好处:解决 50 年的蛋白质折叠问题，检测癌症，改善电网。虽然深度学习推动了很多事情，但我们也需要考虑成本。</p><p id="bdb4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在寻求更精确和更通用的模型的过程中，网络规模和功耗出现了爆炸式增长。似乎每年模特的尺寸都在飙升。2020 年，GPT-3 发布，拥有<strong class="ky ir">1750 亿</strong>参数和 460 万美元的理论培训成本，拥有市场上价格最低的 GPU 云。</p><p id="4759" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不到一年后，谷歌发布了参数超过<strong class="ky ir">万亿</strong>的 Switch Transformer。OpenAI 发现，同类最佳大型模型所需的计算能力每 3.4 个月翻一番<a class="ae kv" href="https://openai.com/blog/ai-and-compute/" rel="noopener ugc nofollow" target="_blank">(六年内翻了 300，000 倍</a>)。随着参数的指数增长，能量也有了指数增长。</p><p id="f4eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">人工智能研究人员和工程师如何解决这个问题？</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/ba6bff91a5e5de80e6a6d08ff2992fab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nOpVdc15a7C_m0NH"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">迪伦·吉利斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="b4e9" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">神经架构</strong></h1><p id="8d6b" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">常识告诉我们，模型越大，结果越好。然而，情况并非总是如此。谷歌研究刚刚发布了一份<a class="ae kv" href="https://arxiv.org/abs/2110.02095?utm_campaign=The%20Batch&amp;utm_medium=email&amp;_hsmi=203440838&amp;_hsenc=p2ANqtz-8qegFif9haSvA8KwypHHya-kyDgcMp7_qkYf-6icESppyp55Ih7vmMg4uWFhFU-hSj3bAnxZIrhUE8Q14hvqi0VPHg6g&amp;utm_content=203440838&amp;utm_source=hs_email" rel="noopener ugc nofollow" target="_blank">元分析</a>，展示了<strong class="ky ir">更高的预训练准确度如何达到饱和点</strong>。随着模型精度的提高，其被微调以解决特定任务的能力<em class="ls">(即迁移学习)</em>并没有同样快速地提高。在某些时候，<strong class="ky ir">精度甚至会降低</strong>。</p><p id="8986" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当您开始质疑更大的模型是否总是答案时，探索改进当前架构的机会就来了。更多的努力被放在架构选择上，像<a class="ae kv" href="https://tinyml.mit.edu/projects/spvnas/papers/spvnas_eccv.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">进化算法</strong>这样的工具被用来为一项任务选择最佳的神经架构</a>，从而大大减少了所需的计算量。</p><p id="25ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一个引起兴趣的领域是<strong class="ky ir">彩票假说</strong>，其中神经网络的密集子网络(“彩票”)可以被训练以实现与整个网络类似的性能。以前，这只能在训练完整个网络后才能完成，但是我在这里详细讨论了这些彩票是如何更早地被发现的。</p><p id="1f8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些方法挑战了越大越好的观念。与此同时，他们跳过了训练大型模型的成本，只修剪模型的大部分。相反，他们直接跳到最佳架构，使训练模型更便宜、更快、更节能。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="6259" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">数据移动</strong></h1><p id="0d84" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">虽然训练大型模型消耗大量的能量，但是大部分能量都用于推理(<a class="ae kv" href="https://www.forbes.com/sites/moorinsights/2019/05/09/google-cloud-doubles-down-on-nvidia-gpus-for-inference/#244ad92a6792" rel="noopener ugc nofollow" target="_blank">80–90%</a>)。理想情况下，像 ResNet50 这样的模型被训练一次，然后在应用程序中使用多次。结果，大量的努力进入了推理阶段。这里最大的领域是数据传输。缩小我们的网络规模是有帮助的，但之后，无论如何数据都必须通过。这有软件和硬件方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/b4868f80ba4500559ba4668d6302c1c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8CCHC_GUewk34ryv"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@aoddeh?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾哈迈德·奥德赫</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="5db8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">软件</em></p><p id="a4c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在软件方面，<strong class="ky ir">数据类型选择</strong>是关键。虽然某些应用程序可能需要更高精度的数据类型，但在其他应用程序中，它们可能不会提高模型性能。精度较低的数据类型需要传输的数据较少，比如 16 位浮点数与 32 位浮点数。不同的公司正在创建不同的数据类型，进一步减少数据大小和处理需求，如微软的 MSFP。</p><p id="d782" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经常运行的模型也可以利用<strong class="ky ir">批处理。</strong>批量发送请求通常比发送单个请求或数据包更有效。</p><p id="014c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">硬件</em></p><p id="c982" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在硬件方面，确保数据紧密相连非常重要。深度学习服务器和客户端之间的共享内存比来回发送更有效。在你的 iPhone 上做边缘机器学习更高效(也更安全！)比把这些数据发送到苹果的数据中心要容易得多。数据越接近，需要传输的数据就越少。</p><p id="bcc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也有针对不同深度学习应用的专门芯片，如<a class="ae kv" href="https://ieeexplore.ieee.org/document/8686088" rel="noopener ugc nofollow" target="_blank"> Eyeriss </a>，它通过可重构的片上网络最大化数据重用。</p><p id="55f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">压缩也常用于最小化传输的数据，因为压缩数据比直接发送数据需要更少的资源。这对于稀疏网络来说尤其如此，在稀疏网络中，许多技巧被用来利用稀疏性。稀疏也是剪枝的一个常见动机，因为在存储和计算中 0 值的条目通常可以被忽略。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/9f39ce09f637072c361ca93ad11dbfb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5cHsx6amZH4tiILf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克林特·王茂林在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="6f3b" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated"><strong class="ak">数据存储</strong></h1><p id="51d3" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">除了数据移动，数据存储是另一个丰富的硬件节能领域。当深度学习从大脑中获取灵感时，研究人员会查看大脑的能效。大脑的效率高达深度学习的 1000 倍。不像我们数字计算机世界的 1 和 0，大脑的突触看起来更像模拟系统。随着大脑学习和遗忘，信号变得越来越弱。利用这种更加连续的模拟光谱，研究人员已经创造出更接近大脑能量效率的系统(T21)。</p><p id="dcbd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以类似的方式，其他形式的计算正在被探索。比如存储光子而不是电子，一次以多种状态表示数据(<em class="ls">量子计算</em>)。这些可能是更有效的存储数据的方式。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="c75e" class="mb mc iq bd md me mf mg mh mi mj mk ml jw mm jx mn jz mo ka mp kc mq kd mr ms bi translated">结束语</h1><p id="8a4e" class="pw-post-body-paragraph kw kx iq ky b kz mt jr lb lc mu ju le lf mv lh li lj mw ll lm ln mx lp lq lr ij bi translated">深度学习已经为世界做了很多好事，它有潜力做得更多。随着人工智能使用的增长，提高其效率变得至关重要。研究人员正在将神经结构和大小视为一个关键领域。与此同时，他们正在探索降低数据存储和数据传输成本的方法，<strong class="ky ir">影响了大多数技术</strong>，包括<em class="ls">你正在</em>上阅读这篇文章的设备。</p></div></div>    
</body>
</html>