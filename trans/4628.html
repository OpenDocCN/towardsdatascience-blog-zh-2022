<html>
<head>
<title>Polynomial Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的多项式回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/polynomial-regression-in-python-dd655a7d9f2b#2022-10-14">https://towardsdatascience.com/polynomial-regression-in-python-dd655a7d9f2b#2022-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="926f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">对非线性数据使用更复杂的回归方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/86f1d7e787acd760a9cfb4df837242f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4XN6Wq1YSq9wqB5cSFGDbw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">叶夫根尼·特卡琴科在<a class="ae ky" href="https://unsplash.com/s/photos/curves?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="f407" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="045c" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">传统的线性回归是一种广泛使用的统计工具，用于确定两个变量之间的线性关系，使分析师能够做出推断，并从数据中提取良好的洞察力，包括预测。</p><p id="3e00" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">然而，并不只有线性数据。并非所有数据集都具有线性模式。有些情况下，它们<em class="mz">快到了，</em>但是我们需要进行转换来“帮助”它们适应线性算法。</p><p id="744c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">一种可能性是幂变换，例如，使二次或三次方程表现得像线性方程一样。通过向数据添加一个变换层，我们可以更好地拟合它，正如我们将要看到的。</p><h1 id="62e2" class="lg lh it bd li lj na ll lm ln nb lp lq jz nc ka ls kc nd kd lu kf ne kg lw lx bi translated">多项式</h1><p id="b107" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在数学中，多项式是由变量(x，y，z)和系数(乘以变量的数字)组成的方程。</p><p id="99b3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">简单的线性回归是一次多项式，其中我们有乘以变量x的系数，简单明了。你一定见过很多次了，下面是简单的线性回归公式。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/38b1e3749d7ef6ad9162a8d15a24635c.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*G8WrCGMfE6uPttpuHxT0hA.png"/></div></figure><p id="9b07" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">第二、第三或第n次多项式类似，但在这种情况下，系数乘以变量的二次、三次或第n次幂。例如，在下面的二次公式中，β乘以平方变量，β1乘以非平方变量。因为这里的最高幂是2，所以多项式是二次的。如果我们有一个三次变量，它将是3次，以此类推。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/f80d7f07fa28b4b22d7504ba3213ee44.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*RxsaUs_PT0EZvoPyTkYKvA.png"/></div></figure><p id="f608" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">很好。现在我们知道如何识别多项式的次数。让我们继续，看看it在数据中的影响。</p><h1 id="5eac" class="lg lh it bd li lj na ll lm ln nb lp lq jz nc ka ls kc nd kd lu kf ne kg lw lx bi translated">数据有哪些变化？</h1><p id="079e" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">查看我们的数据图以了解其形状以及线性回归如何拟合是很重要的。或者，更好的是，如果它是最合适的。</p><p id="074c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们来看不同次数多项式的形状。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/20f94f60f2c7ba76cd3ad8d8a4d1f9cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gfv717Zza8-sQUGFcUBQ6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同次数多项式的曲线形状。图片由作者提供。</p></figure><p id="e655" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">观察到每个度数的增加使得数据产生更多的曲线。度1是一条线，正如所料，度2是一条曲线，之后的其他是“S”形或其他曲线。</p><p id="b209" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">知道数据不再是一条直线，使用简单的线性回归就不太合适了。取决于曲线有多亮，你仍然可能得到一些有趣的结果，但是总会有一些点非常偏离。</p><p id="cc36" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们看看如何处理这些情况。</p><h1 id="4e44" class="lg lh it bd li lj na ll lm ln nb lp lq jz nc ka ls kc nd kd lu kf ne kg lw lx bi translated">多项式特征</h1><p id="017e" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">Scikit-Learn有一个类名<code class="fe ni nj nk nl b">PolynomialFeatures()</code>,用于处理线性回归拟合高次多项式的情况。</p><p id="9383" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">事实上，它所做的是转换你的数据，有点像在数据上添加一个<em class="mz">层</em>，帮助<code class="fe ni nj nk nl b">LinearRegression()</code>算法识别所需的正确曲线度数。它以我们需要的度数计算分数。</p><h2 id="8cc0" class="nm lh it bd li nn no dn lm np nq dp lq mh nr ns ls ml nt nu lu mp nv nw lw nx bi translated">二次数据</h2><p id="ed23" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">让我们从二次方程开始。我们可以创建一个数据集。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="42f2" class="nm lh it nl b gy oc od l oe of"># Dataset<br/>X = 8 * np.random.rand(500, 1)<br/>y = 1 + X**2 + X + 2 + np.random.randn(500,1)</span><span id="ad98" class="nm lh it nl b gy og od l oe of"># Plot<br/>plt.scatter(X,y, alpha=0.5);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/b8787c7e253e4fb835c329f63816840d.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*oE8_GHqVV5-0YEojUAuHmA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二次方程。图片由作者提供。</p></figure><p id="e96b" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们导入所需的模块。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="6052" class="nm lh it nl b gy oc od l oe of">from sklearn.linear_model import LinearRegression<br/>from sklearn.preprocessing import PolynomialFeatures</span></pre><p id="3906" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">接下来，我们可以拟合一个线性模型。只是为了展示发生了什么。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="02ec" class="nm lh it nl b gy oc od l oe of"># Linear Regression<br/>linear_model = LinearRegression().fit(X,y)<br/>preds = linear_model.predict(X)</span></pre><p id="8700" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这将产生接下来的情节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/b5f6430586e6dc370da229ff582b6c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*J8cwh1ynvhvL7sropqPDrQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">二次多项式拟合的线性回归。图片由作者提供。</p></figure><p id="1fa9" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">嗯……有几次我们会是正确的，其他时候我们会很接近，但是大多数预测不会太好。我们来评价一下模型。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="5855" class="nm lh it nl b gy oc od l oe of"># y_mean<br/>label_mean =  np.mean(y)<br/>print('label mean:', label_mean )</span><span id="1b4c" class="nm lh it nl b gy og od l oe of"># RMSE<br/>rmse = np.sqrt( mean_squared_error(y, preds))<br/>print('RMSE:', rmse )</span><span id="17da" class="nm lh it nl b gy og od l oe of"># % Off<br/>print('% off:',rmse/label_mean)</span><span id="f34a" class="nm lh it nl b gy og od l oe of"><strong class="nl iu">[OUT]:<br/></strong>label mean: 26.91768042533155 <br/>RMSE: 4.937613270465381 <br/>% off: 0.18343383205555547</span></pre><p id="4112" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">平均打八折。如果我们给它<code class="fe ni nj nk nl b">linear_model.score(X,y)</code>打分，我们会得到94%的R。</p><p id="05d4" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在，我们将转换数据以反映二次曲线，并再次拟合模型。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="df3f" class="nm lh it nl b gy oc od l oe of"># Instance<br/>poly2 = PolynomialFeatures(degree=2, include_bias=False)<br/>X_poly = poly2.fit_transform(X)</span><span id="d8c0" class="nm lh it nl b gy og od l oe of"># Fit Linear model with poly features<br/>poly_model = LinearRegression().fit(X_poly,y)<br/>poly_pred = poly_model.predict(X_poly)</span><span id="9ba8" class="nm lh it nl b gy og od l oe of"># Plot<br/>plt.scatter(X,y, alpha=0.5)<br/>plt.plot(X, poly_pred, color='red', linestyle='', marker='.', lw=0.1);</span></pre><p id="f028" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这就是结果(99% R)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/ca4f97d4a90d7ee12e43e7f73932be5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*S6jiCJEe3r1tA9arLzn_hw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">拟合二次数据的二次线性回归。图片由作者提供。</p></figure><p id="5937" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">哇！现在看起来真不错。我们将对其进行评估。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="848e" class="nm lh it nl b gy oc od l oe of">label mean: 26.91768042533155 <br/>RMSE: 1.0254085813750857 <br/>% off: 0.038094240111792826</span></pre><p id="bec3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们将误差降低到平均值的3%方差。</p><h2 id="af12" class="nm lh it bd li nn no dn lm np nq dp lq mh nr ns ls ml nt nu lu mp nv nw lw nx bi translated">测试多重转换</h2><p id="1c45" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">我们可以测试多个变换，看看拟合值的效果如何。你会注意到，随着我们越来越接近函数的次数，曲线越来越符合这些值。有时，它甚至会过度拟合数据。</p><p id="0d19" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们将创建这个函数，它采用解释变量(<strong class="ma iu"> X </strong>)和响应变量(<strong class="ma iu"> y </strong>)，并通过管道运行数据，该管道在一个循环中为用户指定的值拟合不同程度的线性回归，并绘制结果。我将把这个函数放在我的<a class="ae ky" href="https://github.com/gurezende/Studying/blob/master/Python/sklearn/PolynomialFeatures.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="ff46" class="nm lh it nl b gy oc od l oe of">fit_polynomials(X2, y2, from_= 1, to_= 4)</span><span id="a37c" class="nm lh it nl b gy og od l oe of"><strong class="nl iu">[OUT]: Results for each (degree, R²)<br/></strong>[(1, 0.042197674876638835),  <br/> (2, 0.808477636439972),  <br/> (3, 0.8463294262006292),<br/> (4, 0.9999999996536807)]</span></pre><p id="80b8" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">请注意，我们开始时拟合度很差，只有4%的R，结束时模型拟合度非常好，达到了99%。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/6f6aaff31b5eb4291a71f095e27872f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_vj5jT-yavOij9lqQECefQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">黑点是真正的y。红点非常适合它们。图片由作者提供。</p></figure><p id="968f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">请看上图，其中1度(<em class="mz">蓝点</em>)功能确实非常关闭，4度(<em class="mz">红点</em>)可能是过度拟合的模型(<em class="mz">真正的Y是黑点</em>)。此图显示了多项式变换拟合指数数据的能力。</p><p id="444c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们应该注意的另一件事是，如果我们从<code class="fe ni nj nk nl b">PolynomialFeatures</code>开始不断增加<code class="fe ni nj nk nl b">degree</code>参数，数据会变得越来越过度拟合，直到对于非常高的值，它会开始降低分数，因为它会更适合噪声，而不是数据。</p><pre class="kj kk kl km gt ny nl nz oa aw ob bi"><span id="63f2" class="nm lh it nl b gy oc od l oe of">fit_polynomials(X2, y2, from_=10, to_=30, step=10)</span><span id="6c4d" class="nm lh it nl b gy og od l oe of"><strong class="nl iu">[OUT]: Results for each (degree, R²)<br/></strong>[(10, 0.9999999996655948),<br/> (20, 0.981729752828847), <br/> (30, 0.9246351850951822)]</span></pre><p id="5bfe" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们可以看到，随着我们的增加，R在下降，点不再适合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/beb5f944cad0cd8d52887640ecd8fa8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-RzXKhV3czO5qQBOPtzvw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">较高的度数值会过度拟合，并且可能会模拟噪波。图片由作者提供。</p></figure><h1 id="f5b9" class="lg lh it bd li lj na ll lm ln nb lp lq jz nc ka ls kc nd kd lu kf ne kg lw lx bi translated">在你走之前</h1><p id="c140" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">这是Scikit的另一个好工具——Learn。<code class="fe ni nj nk nl b">PolynomialFeatures()</code>。</p><p id="6bb1" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">它用于将非线性数据转换为可以通过线性回归建模的新数据。</p><p id="4029" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">随着度数的增加，回归线越来越适合数据。</p><p id="90a8" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你喜欢这个内容，请关注我的博客。</p><div class="ol om gp gr on oo"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc ks oo"/></div></div></a></div><p id="3c30" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你正在考虑加入Medium成为会员，这是我的<a class="ae ky" href="https://gustavorsantos.medium.com/membership" rel="noopener">推荐代码</a>，其中部分价值与我分享，所以你也可以激励我。</p><p id="dcf3" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在<a class="ae ky" href="https://www.linkedin.com/in/gurezende/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上找到我。</p><h1 id="1d52" class="lg lh it bd li lj na ll lm ln nb lp lq jz nc ka ls kc nd kd lu kf ne kg lw lx bi translated">参考</h1><div class="ol om gp gr on oo"><a href="https://en.wikipedia.org/wiki/Polynomial" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">多项式-维基百科</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">在数学中，多项式是由不定项(也称为变量)和系数组成的表达式</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">en.wikipedia.org</p></div></div><div class="ox l"><div class="pd l oz pa pb ox pc ks oo"/></div></div></a></div><div class="ol om gp gr on oo"><a rel="noopener follow" target="_blank" href="/polynomial-regression-bbe8b9d97491"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">多项式回归</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">这是我在机器学习系列的第三篇博客。这个博客需要线性回归的先验知识。如果你…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">towardsdatascience.com</p></div></div><div class="ox l"><div class="pe l oz pa pb ox pc ks oo"/></div></div></a></div><div class="ol om gp gr on oo"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html" rel="noopener  ugc nofollow" target="_blank"><div class="op ab fo"><div class="oq ab or cl cj os"><h2 class="bd iu gy z fp ot fr fs ou fu fw is bi translated">sklearn.preprocessing .多项式功能</h2><div class="ov l"><h3 class="bd b gy z fp ot fr fs ou fu fw dk translated">使用sk learn . preprocessing . polynomial features的示例:scikit的发布亮点-learn 0.24发布亮点…</h3></div><div class="ow l"><p class="bd b dl z fp ot fr fs ou fu fw dk translated">scikit-learn.org</p></div></div><div class="ox l"><div class="pf l oz pa pb ox pc ks oo"/></div></div></a></div></div></div>    
</body>
</html>