<html>
<head>
<title>Global deep learning for joint time series forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于联合时间序列预测的全局深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/global-deep-learning-for-joint-time-series-forecasting-4b03bef42321#2022-07-28">https://towardsdatascience.com/global-deep-learning-for-joint-time-series-forecasting-4b03bef42321#2022-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bcce" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">简单介绍一下这个领域最热门的模特</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e6fb6cba00a2a2e00154ef6c53aa3188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*begU8YFliKD5ppdg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@wimvanteinde?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维姆·范因德</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="51ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习是一个众所周知的复杂领域，学术界和工业界都在实践，不断改进其基准，产生有趣的想法和解决问题的方法。</p><p id="0976" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在解释其工作原理的适当理论形成之前，它已经在许多不同领域的无数实际应用中成功部署。</p><p id="5a4a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于这个原因，有时很难跟上最新的架构；在这篇文章中，我们正在探索时间序列预测领域的最新成就，这是一类由于时间维度而具有其特殊地位的预测问题。</p><p id="ef57" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更准确地说，我们将考虑所谓的<strong class="ky ir">全局模型</strong>:被构建来一次检测许多相关时间序列的模式的架构，学习能够单独解释和预测每个序列的单一表示。</p><h1 id="cd10" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">所有的事情，所有的地方，所有的时间</h1><p id="8931" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">当预测模型在许多不同的数据集上训练时，它被称为<strong class="ky ir">全局</strong>，每个数据集都是其自身随机过程的随机结果。</p><p id="3815" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种模型每天都变得越来越常见，利用我们今天在许多领域拥有的大量数据，解决我们需要对单个小规模数据集进行具体预测的问题；然而，以前我们只能希望在更高的总体水平上进行预测。</p><p id="e3bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法的一个明显优势是，模型将受益于更多的训练数据，这在这个大数据<em class="mp">时代</em>可以相当于许多数量级的增长。</p><p id="7b7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，如果我们希望学习的通用模式只存在于数据集中的一个子集，而在其他一些数据集中它还没有发生，全局模型可以学习将其归因于所有数据集。</p><p id="ce95" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，如果数据集来自不同的生成过程，根据定义，它们的结构和模式至少会有一些差异，因此，对于一个模型来说，忽略这些并均匀地预测一切并不总是可取的。</p><p id="af05" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，来自同一家公司的不同商店的销售数据可以被认为是相似的，因为许多有助于数据生成过程的变量都是相同的(相同的产品、价格、营销……)。</p><p id="41ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管如此，许多其他变量(位置、当地客户习惯……)以一种模型难以检测的方式区分每个系列，这就是为什么我们需要将这些变量编码为其输入。</p><p id="767c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">出于这个原因，全球模型倾向于处理关于数据集如何相似以及它们如何彼此不同的信息。我们通常通过给数据集附加标签来传达这一信息，每个标签对应一个我们想要追踪的特征；其他时候，我们只是指示模型相应地自动聚类数据集。</p><p id="f105" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的问题是，生成过程，以及由此产生的结果，必须共享足够的信息，以便模型能够利用它们的交叉学习。</p><p id="5e55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">选择哪些数据集被认为是相关的可能有些随意，因为我们通常事先不知道我们是否能够实现这种交叉学习的优势，并且将太多不同的数据聚集在一起可能会引入太多的差异和噪声，从而造成损害。</p><p id="b9ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总而言之，在尝试训练全球模型时，最重要的先决条件有两个:</p><ul class=""><li id="96b4" class="mq mr iq ky b kz la lc ld lf ms lj mt ln mu lr mv mw mx my bi translated">要预测许多相关的数据集，这些数据集都来自相似的过程并显示相似的模式；</li><li id="cd05" class="mq mr iq ky b kz mz lc na lf nb lj nc ln nd lr mv mw mx my bi translated">对它们有更多的了解，特别是它们的相似之处和不同之处。</li></ul><h1 id="1131" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">几个有趣的模型</h1><p id="08f5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">时间序列预测是一个特别适合全球模型的问题[1][2]，因为有许多相关的时间序列并不罕见，通常是在一个固定的关系结构中:来自公司客户的数据，系统网络中的传感器，不同位置的交通流量…</p><p id="b11e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与此同时，神经网络已被证明是理想的全球模型，因为它们能够处理任何类型的协变量特征，并且它们对巨大复杂数据集的总体偏好。</p><p id="3cb8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，深度学习、时间序列预测和大数据的结合近年来在学术和行业研究中找到了如此肥沃的土壤也就不足为奇了。</p><p id="3a75" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">没有完整性的伪装，这里是这个星体结合的一些更有趣的结果。</p><p id="df1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，这些模型的结果和基准可以在参考文献中找到；我们对这方面不太感兴趣，而是对其中任何一种方法的新颖性和巧妙性感兴趣。</p><h2 id="fa3d" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">迪帕尔</h2><p id="691a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">DeepAR [3]是一个基于递归网络的深度学习模型，致力于学习目标时间序列的一个<strong class="ky ir">自回归表示</strong>。</p><p id="a124" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更具体地，它是LSTM细胞的多层网络，具有编码器-解码器结构，用于在每个训练步骤总结细胞过去的信息输出(称为调节范围)，并使其可用于预测其未来(预测范围)。</p><p id="8a03" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它是一个概率模型，这意味着在给定相同参数的情况下，它输出表示预测值分布概率的似然函数的参数(其形状可由用户指定)。</p><p id="8137" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">预测可能性是一个聪明的技巧，具有很大的灵活性:从这样的函数中，我们可以抽取样本，生成分位数预测，置信区间，甚至可以选择bootstrap Monte Carlo样本，这些样本可以到达未来的任何步骤。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/6d2c57b41d7d47ef4dedcb0c38f7329f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hcl4FWSmmt-r-6RjNsOXkA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">DeepAR [3]中训练(左)和推理(右)的图式。</p></figure><p id="f99a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DeepAR当然配备了动态协变量，如日历特性和静态协变量:如果我们想训练一个单一的全球模型，这些正是我们必须附加到每个系列的标签。</p><div class="kg kh ki kj gt ab cb"><figure class="nr kk ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/600e312e939a83ab35dc56f25eb71204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Fy5JRvNnvfecci35HPXY9w.png"/></div></figure><figure class="nr kk ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/098d94f1700c767b384f62bd39b45594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*YzBUzokB0ShcSG87Yi9CtA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk nx di ny nz translated">目标系列和协变量[3]。</p></figure></div><p id="21f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于这个模型的内部工作的更多细节，例如它处理具有不同尺度的系列的巧妙方式，我们可以参考原始论文[3]。</p><h2 id="439f" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">StemGNN</h2><p id="57ec" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">光谱时间图神经网络[4]是一种创新和聪明的设计，用于联合学习系列间和系列内相关性的全局模型。</p><p id="edad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简而言之，该想法是在两个维度上、跨时间和跨序列使用<strong class="ky ir">傅立叶变换</strong>，以便获得可以被其他神经网络块(如卷积和顺序模块)学习的表示。</p><p id="9723" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然在时域中对一个序列执行傅里叶变换是一种经典而简单的技术，但我们需要理解在固定时间对所有序列执行傅里叶变换意味着什么。</p><p id="dc40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">事实上，StemGNN的第一层，称为<em class="mp">潜在相关层</em>，获取整个数据集并返回一个图，其中节点是时间序列，加权边是层本身推断的它们之间的相关关系。</p><p id="7651" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一层由一个<a class="ae kv" href="https://d2l.ai/chapter_recurrent-modern/gru.html" rel="noopener ugc nofollow" target="_blank">GRU</a>【9】和一个自我关注机制组成，但是如果领域知识建议使用一个特定的图形表示来代替，它也可以被删除；例如，可以使用将作为静态协变量传递给其他模型的相同标签来链接系列。</p><p id="6c26" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这之后，该模型将几个相同的块依次应用于数据集在每个序列(其是图中的节点)的图形域(<a class="ae kv" href="https://en.wikipedia.org/wiki/Graph_Fourier_transform#:~:text=In%20mathematics%2C%20the%20graph%20Fourier,as%20a%20graph%20Fourier%20basis." rel="noopener ugc nofollow" target="_blank"> GFT </a>)和时域(<a class="ae kv" href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform" rel="noopener ugc nofollow" target="_blank"> DFT </a>)中的图形表示；除此之外，卷积块在反转这些变换以返回原始域之前，会学习这些变换所暴露的信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/7aa407e8464579ed3a949c9bd62040ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tdx6PLLRIuBMmKxLsZLHWQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">StemGNN的结构相当复杂[4]。</p></figure><p id="98e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这些块是这种架构的主要新颖部分，它们被恰当地称为StemGNN块。它们的内部工作实际上是非常复杂的，因此我们可以参考文献[4]来了解细节。</p><p id="678e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了我们的目的，可以说在DFT和GFT之后应用谱图卷积允许我们共同学习出现在每个序列的谱表示以及相关图的谱矩阵表示中的模式。</p><p id="582b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，StemGNN块以一种<a class="ae kv" href="https://d2l.ai/chapter_convolutional-modern/resnet.html?highlight=residual" rel="noopener ugc nofollow" target="_blank">剩余</a>的方式被应用，这样每个块可以更深入到前一个块留下的模式中。这是一个强大的技术，也是[4]中突出使用的技术。</p><h2 id="f1a4" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">DSSM</h2><p id="3824" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">深度状态空间模型[5]是一个结合了深度学习和<strong class="ky ir">状态空间模型</strong>的新想法，以利用两种方法的优势。</p><p id="0ed4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">状态空间模型(SSMs)[7][8]是一系列用于预测的经典统计模型，包括臭名昭著的ARIMA和指数平滑方法。</p><p id="c0e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于可以在模型中做出结构性假设，并通过选择模型的组成部分和特征来精心制作模型，因此当时间序列特征明确时，这些方法尤其适用。</p><p id="0d78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，这种量身定制的方法有其问题，因为它需要有足够历史的知名剧集，并且它很难扩展到我们现在经常拥有的剧集数量。此外，作为一个系列的方法，它根本不能跨系列转移学习。</p><p id="285b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DSSM的作者的想法是，然后通过递归神经网络摄取所有系列及其协变量来联合学习SSM参数:这里的术语“联合”是指这样的事实，尽管每个系列都有不同的SSM及其自己的参数，但神经网络的元参数在整个训练过程中是共享的。</p><p id="11ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">换句话说，作为一项<em class="mp">元学习</em>任务，在所有系列中训练的单个RNN正在学习给每个系列分配不同的SSM参数。</p><p id="5706" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">像这样的模型，结合了机器学习和经典统计技术，在这种情况下被称为<strong class="ky ir">混合模型</strong>。</p><p id="bcb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在操作上，在训练时，一个<a class="ae kv" href="https://d2l.ai/chapter_recurrent-modern/lstm.html" rel="noopener ugc nofollow" target="_blank"> LSTM </a>型网络输出SSM参数，这些参数被馈送给一个似然函数，该函数取决于该系列的特定SSM模型以及已知的观测值；然后最大化可能性以更新LSTM参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/3efb3eaf0192d038434d794edfcf0143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMeputXqhuyUPnIYwBT86A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在DSSM培训[5]。</p></figure><p id="d2e5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类似地，在推断时，DSSM通过使用序列的已知值和训练集中的学习参数，计算在最后训练步骤的SSM状态的概率分布；这个概率既代表了知识，也代表了模型对我们所处状态的最佳估计。通过使用该概率，该模型然后在蒙特卡罗方法中展开任意数量的预测，通过递归地使用SSM和RNN在推断时给出的参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/6b34b1ef60bb698c5a2d28ab72d993a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aYAV8h8gZz6Tw_4R60K5lg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">DSSM的推论[5]。</p></figure><h2 id="3b13" class="ne lt iq bd lu nf ng dn ly nh ni dp mc lf nj nk me lj nl nm mg ln nn no mi np bi translated">DeepGLO</h2><p id="39c8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最后，另一个有趣的混合模型:DeepGLO [6]，正如作者所说，是“<em class="mp">一个深度预测模型，它从全球角度思考，从本地角度行动</em>”。</p><p id="9dbb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它是一个经典的<a class="ae kv" href="https://d2l.ai/chapter_recommender-systems/mf.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">矩阵分解</strong> </a> <strong class="ky ir">模型</strong>的组合，一个用于正则化它的卷积网络(TCN)和另一个独立的本地TCN作用于每个系列和第一个模型的输出。</p><p id="afe4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DeepGLO区别于许多竞争对手的特点是不仅在训练中而且在推理中一起使用所有时间序列。</p><p id="0629" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再次引用作者的话，“<em class="mp">例如，在股票市场预测中，在预测苹果的股票价格时，查看Alphabet以及亚马逊股票价格的过去值可能是有益的。同样，在零售需求预测中，可以利用类似商品的过去值来预测某个商品的未来</em>。</p><p id="b250" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该算法的经典部分，即矩阵分解模型，包括将所有时间序列视为单个矩阵，并将其分解为两个矩阵的乘积，称为<em class="mp">因子</em>。</p><p id="e967" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">矩阵乘积的工作方式使得每个因子将共享原始矩阵的一个维度:如果我们将此表示为形状为(n，t + tau)的Y(出于训练和测试的目的，我们已经对时间维度进行了分割)，则因子F和X将分别为(n，k)和(k，t + tau)，k是通常比n小得多的某个数。</p><p id="1775" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分解维度的更清晰描述见下图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/21735b70262a627b75f3268fc910facc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QZ6s9ml1L1H8b8tmgAvH9g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">矩阵分解:在这个示意性例子中，我们有n个长度为t+τ的时间序列，其中t是训练集周期。整体来看，得到的分解是Y = FX [6]。</p></figure><p id="2b40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">实际上，X可以被视为在k个<em class="mp">基序列</em>中编码全局信息，k个基序列与原始基序列一样长，F包含将原始基序列作为基序列的线性组合的系数。</p><p id="2231" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个模型与卷积网络的混合是相当复杂的，对于那些对细节感兴趣的人，我们遵从[6];简而言之，网络被用作正则化器，这意味着它鼓励因子分解过程给出接近网络预测的基序列。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/cffb1a2754a04be17abbc67e759dc8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7Ag4gBr4HgWFIOvtvfIXw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在因子分解模型(a)中，基序列如何组合以形成实际目标的预测，以及来自该模型的全局预测如何与模型的最终TCN层中的局部序列组合[6]。</p></figure><p id="4318" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因子分解和卷积网络在交替步骤中被联合训练；在推断时，网络通过从因式分解给出的值开始预测基序列的未来值，并将它们与系数矩阵相乘给出最终的全局预测。</p><p id="3643" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，另一个局部每序列神经网络通过将序列的过去值、来自先前模型的全局预测和局部协变量序列作为输入来起作用。</p><h1 id="c5eb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="ad39" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">毫无疑问，全球模型将在预测领域占据越来越大的份额，因为我们正在目睹数据、神经网络知识和商业应用的增长，而且这种增长似乎不会很快结束。</p><p id="bb33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如你所看到的，当涉及到它们时，有令人难以置信的多样性，特别是在预测方面:尽管它们都以神经网络为核心，但每个都有自己的<em class="mp">锦囊妙计</em>，主要专注于捕捉有趣的信息并将其暴露给网络本身。</p><p id="7c17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特别值得一提的是混合模型，它不仅管理两个学习引擎的共存，还管理它们有利的相互依赖性，以获得大于其各部分之和的结果。</p><p id="8d94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于哪一个从根本上更好，存在争议:全局与局部[1][2]，经典与混合与纯深度学习[10][11][12]。</p><p id="f998" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可以说，这完全取决于我们所拥有的关于数据生成过程及其实际实现(时间序列)的信息；第一个应该指导我们为问题选择最好的函数类，即算法，第二个应该帮助它在类中找到最好的函数(训练结果)。</p><p id="c2c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通常，先验信息的数量和质量应该与模型的复杂性和特异性相关联。</p></div><div class="ab cl of og hu oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="ij ik il im in"><p id="bb52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] H. Hewamalage等人，<a class="ae kv" href="https://arxiv.org/pdf/2012.12485.pdf" rel="noopener ugc nofollow" target="_blank">时间序列预测的全球模型:模拟研究</a> (2021)。</p><p id="c26b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] P. Montero-Manso等，<a class="ae kv" href="https://arxiv.org/pdf/2008.00444.pdf" rel="noopener ugc nofollow" target="_blank">时间序列组预测的原理和算法:局部性和整体性</a> (2021)。</p><p id="4a60" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] D. Salinas等人，<a class="ae kv" href="https://arxiv.org/pdf/1704.04110.pdf" rel="noopener ugc nofollow" target="_blank"> DeepAR:用自回归递归网络进行概率预测</a> (2019)。</p><p id="9e40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] D .曹等，<a class="ae kv" href="https://papers.nips.cc/paper/2020/file/cdf6581cb7aca4b7e19ef136c6e601a5-Paper.pdf" rel="noopener ugc nofollow" target="_blank">多变量时间序列预测的谱时态图神经网络</a> (2020)。</p><p id="6474" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] D. Rangapuram等人，<a class="ae kv" href="https://proceedings.neurips.cc/paper/2018/file/5cf68969fb67aa6082363a6d4e6468e2-Paper.pdf" rel="noopener ugc nofollow" target="_blank">时间序列预测的深态空间模型</a> (2018)。</p><p id="5a39" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6] R. Sen等，<a class="ae kv" href="https://arxiv.org/pdf/1905.03806.pdf" rel="noopener ugc nofollow" target="_blank">全球思考，局部行动:高维时间序列预测的深度神经网络方法</a> (2019)。</p><p id="6e5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[7] R. J. Hyndman等人，<a class="ae kv" href="https://robjhyndman.com/expsmooth/" rel="noopener ugc nofollow" target="_blank">用指数平滑法预测:状态空间法</a> (2008)。</p><p id="f921" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[8] M. Aoki，<a class="ae kv" href="https://link.springer.com/book/10.1007/978-3-642-75883-6" rel="noopener ugc nofollow" target="_blank">时间序列的状态空间建模</a> (1990)。</p><p id="e815" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[9] A .张等，<a class="ae kv" href="https://d2l.ai/index.html" rel="noopener ugc nofollow" target="_blank">潜入深度学习</a> (2020)。</p><p id="7f98" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[10] S. Makridakis等人，<a class="ae kv" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0194889" rel="noopener ugc nofollow" target="_blank">统计和机器学习预测方法:关注点和前进方向</a> (2018)。</p><p id="18f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[11] B. N. Oreshkin等人，<a class="ae kv" href="https://arxiv.org/abs/1905.10437" rel="noopener ugc nofollow" target="_blank"> N-BEATS:用于可解释时间序列预测的神经基础扩展分析</a> (2019)。</p><p id="4baa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[12] K. Benidis等人，<a class="ae kv" href="https://www.amazon.science/publications/deep-learning-for-time-series-forecasting-tutorial-and-literature-survey" rel="noopener ugc nofollow" target="_blank">用于时间序列预测的深度学习:教程和文献调查</a> (2018)。</p></div></div>    
</body>
</html>