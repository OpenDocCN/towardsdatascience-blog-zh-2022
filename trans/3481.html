<html>
<head>
<title>An Introduction to Graph Partitioning Algorithms and Community Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图划分算法和社区检测简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-graph-partitioning-algorithms-and-community-detection-29e7c962d10e#2022-08-02">https://towardsdatascience.com/an-introduction-to-graph-partitioning-algorithms-and-community-detection-29e7c962d10e#2022-08-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/5b04e2edab3aedc7e30f7d6f9a165cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*arWl57BFDl1ke9Rk"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated"><a class="ae kf" href="https://unsplash.com/@dkoi?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> D锦鲤</a>在<a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="4ab7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated">图划分是一个长期存在的问题，有着广泛的应用。这篇文章分享了图划分的方法，包括一些流行的图划分算法的理论解释和python代码的实际实现。</p><h2 id="96a0" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">澄清</h2><p id="af07" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated"><em class="ml">“聚类”在不同的语境下可能会令人混淆。在本文中，集群意味着节点集群，即将图划分为集群(或社区)。我们交替使用图划分、(节点)聚类和社区检测。换句话说，我们在本文中没有考虑重叠社区。(请注意，社区检测的更广泛定义可以包括重叠社区)</em></p><h1 id="e0bc" class="mm lo it bd lp mn mo mp ls mq mr ms lv mt mu mv ly mw mx my mb mz na nb me nc bi translated">三言两语…</h1><p id="37f4" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">图划分通常是一个无监督的过程，我们定义期望的质量度量，即聚类评估度量，然后我们采用一些算法来基于定义的评估度量找到最佳划分解决方案。在余下的内容中，我们将首先介绍两个最常用的评估指标。然后，我们介绍两种方法，可以有效地找到每个评估指标的(近似)解决方案。</p><h1 id="7591" class="mm lo it bd lp mn mo mp ls mq mr ms lv mt mu mv ly mw mx my mb mz na nb me nc bi translated">聚类评估指标</h1><p id="7f60" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">由于聚类通常是一项无人监督的任务，因此重要的是要有一个质量度量或目标函数来评估聚类解决方案。其他领域中的聚类通常在数据点上使用不同的基于距离的函数来测量聚类的质量。然而，由于图是非欧几里得数据，并且数据点的距离远不如图中的连接重要，所以我们需要对图中的聚类进行不同的测量。换句话说，质量度量需要在图的连通性上定义。</p><h2 id="0d53" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">切割和规格化切割</h2><p id="2cac" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">通常，如果一部分节点和边彼此紧密连接，则它们被认为是一个社区(或一个集群)，否则被认为是不同的社区。因此，很自然地对图进行聚类，使得节点在一个聚类中具有最大边，而在不同的聚类中具有最小边。跨越不同聚类的边的权重之和被定义为图的“切割”。换句话说，“切割”是为了将图完全分离成单独的子图而移除的边的总权重。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0090a0502c1ab9b088de85db7eb3b6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*QICWN4C8vWMtSq9atWMvYQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">切割的简单说明。作者图片</p></figure><p id="f294" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在数学上，将图G‘切割’成两个不相交的集合A和B可以计算为:</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/15baec5b254218115d986e8c460c5180.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*sSD0IFXXN9F7Af09zsOerA.png"/></div></figure><p id="8e9b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">求图G聚类的最佳方式，问题等价于求“割”的最小值，即<em class="ml"> min-cut </em>。然而，也不难看出，最小割的一种可能的退化解决方案是从整个图中切掉少量节点，从而产生仅移除几条边的平凡聚类。一种退化的解决方案如所示</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/aedcee1be4d10b15d60bf08def85b075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*NGHOKfNvBh-rQMTyi4DA7g.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">由<em class="nk"> min-cut提供的琐碎解决方案示例。图来自</em>【1】。</p></figure><p id="f493" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了克服这个问题，[1]提出了一种方法来归一化每个聚类内的边的体积的测量的切割，定义为关联(Assoc)。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/fe1027b5d1f317153499ad31f2049473.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*H5wKwXrz2z5Dc98YtZgzAQ.png"/></div></figure><p id="3bc9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="ml">归一化切割(n-切割)</em>有效地惩罚了<em class="ml">最小切割中的退化解，</em>使其在包括图像分割和图形社区检测在内的许多应用中成为一种鲁棒且流行的聚类度量。</p><h2 id="cd21" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">模块性</h2><p id="b162" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">图模块性是在[2]中作为一个质量函数引入的，用于评估社区的紧密性。模块化<em class="ml"> Q </em>定义为:</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4d9eeeb218cf13ea5b94a2853789dbee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*PHEpXSPmf_zqD_4WG7IIOw.png"/></div></figure><p id="2952" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<em class="ml"> 2m </em>是边的体积，<em class="ml"> A </em>是图邻接矩阵，<em class="ml"> k_i和k_j </em>是节点<em class="ml"> i </em>和节点<em class="ml"> j </em>的度，s_i和s_j是社区指示器。</p><p id="a010" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图形模块性的解释:</p><p id="7620" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">A_ij 是每两个节点之间的实际边数，因为图的邻接矩阵定义了图的连通性。并且表达式(<em class="ml"> k_i*k_j)/2m </em>给出了每两个节点之间的期望边数(假设随机放置边)，或者换句话说，节点<em class="ml"> i </em>和节点<em class="ml"> j </em>之间存在边的概率(如果随机放置边)。</p><p id="bcb2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，模块性可以解释为一个社区(或一个集群)中每对节点的实际边数与期望边数(假设边是随机放置的)之差。</p><p id="d119" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">模块性取[-0.5，1]之间的值，并且当社区与图的剩余部分断开时最大，当社区包含完全断开的节点时最小。</p><h1 id="0961" class="mm lo it bd lp mn mo mp ls mq mr ms lv mt mu mv ly mw mx my mb mz na nb me nc bi translated">图划分算法</h1><p id="a786" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">我们可以很容易地使用前面提到的两个评估指标来测试一个图划分解决方案。然而，寻找(最佳)图划分解决方案是NP完全的。换句话说，没有已知的有效算法能比暴力算法更有效地解决这个问题。通俗地说，<strong class="ki iu">保证</strong>得到<strong class="ki iu">最佳</strong>解决方案的唯一可能方式是尝试每一种可能的组合……由于图形的大小，它几乎对图形聚类解决方案的所有组合进行了详尽的测试(例如强力测试)。因此，多年来，已经提出了不同的有效算法来寻找图聚类的<strong class="ki iu">近似</strong>解。</p><h2 id="3677" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">谱聚类</h2><p id="16ec" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">众所周知，<em class="ml">最小割</em>问题可以通过Ford-Fulkerson算法高效解决。然而，当施加尺寸平衡条件(即<em class="ml">规格化切割</em>)时，这个问题就变成了NP完全问题。谱聚类是一种在归一化的图拉普拉斯上逼近归一化的特征值/特征向量分解的解的方法。</p><ul class=""><li id="21e9" class="nn no it ki b kj kk kn ko kr np kv nq kz nr ld ns nt nu nv bi translated">通过下式获得图拉普拉斯算子:L=D-A</li><li id="cf47" class="nn no it ki b kj nw kn nx kr ny kv nz kz oa ld ns nt nu nv bi translated">执行图拉普拉斯的特征分解。Lv=λv</li><li id="857e" class="nn no it ki b kj nw kn nx kr ny kv nz kz oa ld ns nt nu nv bi translated">将图形投影到对应于k个最小特征值的特征向量，每列投影的特征向量是每个节点的特征特征</li><li id="bd61" class="nn no it ki b kj nw kn nx kr ny kv nz kz oa ld ns nt nu nv bi translated">对本征特征执行k-均值聚类</li></ul><p id="f647" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">特征值表示图的连通性。当我们向下遍历一个图时，图拉普拉斯的特征值给我们洞察变化。最小的特征值总是零。零特征值的数量表示图中连通分量的数量。从下面的例子可以看出这一点。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ob"><img src="../Images/074e8107b62b7a08f8ac4266b03370aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ym5KuCEgmN9SzQaUlG5qCQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">具有两个相连组件的图形(左)。相应的特征值(右)。作者图片</p></figure><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/a3f0bfa3e9b2ab399aa274a375842392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8p5BQqnFOzbc-MhfSIcS5A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">有一个连通分量的图形(左)。相应的特征值(右)。作者图片</p></figure><p id="db81" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果你仔细观察特征值，你会注意到光谱中有一个突然的变化。我通常称之为“本征能隙”(尽管我注意到对此有不同的定义)。间隙表示图中自然存在的簇的数量。这可以从下面的例子中观察到:</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi od"><img src="../Images/c7689c36def3dc7e7194d476433e1256.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6O5CtSi5Cl2W-J6TJvTerA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">有三个自然集群的图表(左)。相应的特征值(右)。作者图片</p></figure><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oc"><img src="../Images/a3f0bfa3e9b2ab399aa274a375842392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8p5BQqnFOzbc-MhfSIcS5A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">具有两个自然集群的图形(左)。相应的特征值(右)。作者图片</p></figure><p id="e268" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意,“间隙”出现的位置从“3”变为“2 ”,正好对应于图中的聚类数。</p><p id="b39f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种观察为我们提供了使用特征值来查找图中聚类数的直觉，特别是当我们不知道数据中实际或预期的聚类数时(这通常是真实世界的用例)。</p><p id="d3ef" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">接下来，我们需要做的就是将特征向量投影到图的每个节点上。在下面的示例中，我们之前已经在特征值图中确定了三个集群。因此，我们只取最小的三个特征值对应的前三个特征向量。注意，每个特征向量正好包含N个数字，其中N是图中节点的数量。我们将前三个特征向量投影到每个节点，每列作为特征特征。执行K-means聚类(或您喜欢的对数据点的任何其他聚类方法)来基于本征特征找到聚类。以下示例中的颜色表示已识别的分类。注意，在计算中仅使用了前三行(即前三个特征向量)。您可以通过查看每个聚类中本征特征的距离来进行快速验证。请注意，我特意在图中的一个集群中制作了{1，5，6}，以表明节点索引无关紧要。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oe"><img src="../Images/6cfd6ea4a682f00311598030ba8f0972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2aFmkZLewXSrJQV4aQtusw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">特征向量聚类的图示。作者图片</p></figure><p id="1d21" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">好了，这就是谱聚类背后的数学。在真实的情况下，除非您是一名研究人员或者您想要完全理解您正在做的事情，否则您并不真的需要经历所有这些复杂的实现。使用谱聚类的一个更简单的方法是使用<em class="ml"> sklearn </em>库中的实现。下面的代码块中显示了一个示例:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="c185" class="ln lo it og b gy ok ol l om on">import networkx as nx<br/>from sklearn.cluster import SpectralClustering<br/>from sklearn.metrics.cluster import normalized_mutual_info_score<br/>import numpy as np</span><span id="c389" class="ln lo it og b gy oo ol l om on"># Here, we create a stochastic block model with 4 clusters for evaluation<br/>sizes = [150, 150, 150, 150]        <br/>probs = [[0.20, 0.05, 0.02, 0.03], [0.05, 0.30, 0.07, 0.02],                 [0.02, 0.07, 0.30, 0.05], [0.03, 0.02, 0.05, 0.50]]</span><span id="fd85" class="ln lo it og b gy oo ol l om on">G = nx.stochastic_block_model(sizes, probs, seed=0)</span><span id="4587" class="ln lo it og b gy oo ol l om on">adj = nx.adjacency_matrix(G)<br/>n_clusters = 4<br/>node_labels = [G.nodes[n]['block'] for n in np.sort(G.nodes)]</span><span id="c95d" class="ln lo it og b gy oo ol l om on">spectral_clusters = SpectralClustering(n_clusters=n_clusters, assign_labels="discretize", affinity='precomputed').fit_predict(adj)</span><span id="ec2a" class="ln lo it og b gy oo ol l om on"># Get the result<br/>nmi = normalized_mutual_info_score(spectral_clusters, node_labels)<br/>print("nmi:", nmi)</span></pre><p id="6a76" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">限制:</strong></p><ol class=""><li id="3649" class="nn no it ki b kj kk kn ko kr np kv nq kz nr ld op nt nu nv bi translated">大型矩阵的特征分解在计算上非常昂贵。这展示了谱聚类在大型图上的应用。</li><li id="28b6" class="nn no it ki b kj nw kn nx kr ny kv nz kz oa ld op nt nu nv bi translated">谱聚类只是最佳聚类解决方案的一种近似。</li></ol><h2 id="0d44" class="ln lo it bd lp lq lr dn ls lt lu dp lv kr lw lx ly kv lz ma mb kz mc md me mf bi translated">鲁文聚类</h2><p id="a66c" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">Louvain的方法[3]是一种快速的图模块优化算法。它在两阶段迭代过程中优化了图的模块性。在阶段1中，首先为图中的每个节点分配一个单独的社区。在那之后，对于每个节点<em class="ml"> i </em>，当:</p><ol class=""><li id="fe19" class="nn no it ki b kj kk kn ko kr np kv nq kz nr ld op nt nu nv bi translated">节点<em class="ml"> i </em>从其原始团体中移除</li><li id="b622" class="nn no it ki b kj nw kn nx kr ny kv nz kz oa ld op nt nu nv bi translated">节点<em class="ml"> i </em>被插入到其相邻节点<em class="ml"> j </em>的社区中</li></ol><p id="2d1f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">重复阶段1，直到模块性没有增加并且达到局部最大值。</p><p id="0cb8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在阶段2期间，通过替换相同社区中的所有节点来创建新的图，将所有节点合并成代表社区的单个节点。社区内的边由到节点的自环代替，社区外的边由到其他节点的加权边代替。一旦创建了新图，它就在新图上重复阶段1。</p><p id="eb5d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用<em class="ml"> sknetwork </em>中的实现来测试Louvain的方法。下面的代码块中显示了一个示例:</p><pre class="ne nf ng nh gt of og oh oi aw oj bi"><span id="927c" class="ln lo it og b gy ok ol l om on">import networkx as nx<br/>from sknetwork.clustering import Louvain<br/>from sklearn.metrics.cluster import normalized_mutual_info_score<br/>import numpy as np</span><span id="0ed1" class="ln lo it og b gy oo ol l om on"># Here, we create a stochastic block model with 4 clusters for evaluation<br/>sizes = [150, 150, 150, 150]        <br/>probs = [[0.20, 0.05, 0.02, 0.03], [0.05, 0.30, 0.07, 0.02],                 [0.02, 0.07, 0.30, 0.05], [0.03, 0.02, 0.05, 0.50]]</span><span id="173f" class="ln lo it og b gy oo ol l om on">G = nx.stochastic_block_model(sizes, probs, seed=0)</span><span id="10a1" class="ln lo it og b gy oo ol l om on">adj = nx.adjacency_matrix(G)<br/>n_clusters = 4<br/>node_labels = [G.nodes[n]['block'] for n in np.sort(G.nodes)]</span><span id="53c1" class="ln lo it og b gy oo ol l om on">louvain = Louvain()    <br/>clusters = louvain.fit_transform(adj)</span><span id="bf31" class="ln lo it og b gy oo ol l om on"># Get the result<br/>nmi = normalized_mutual_info_score(clusters, node_labels)<br/>print("nmi:", nmi)</span></pre><h1 id="af55" class="mm lo it bd lp mn mo mp ls mq mr ms lv mt mu mv ly mw mx my mb mz na nb me nc bi translated">结论</h1><p id="628f" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">在本文中，我们简要介绍了图划分、图划分的两个评估指标，以及分别优化<em class="ml"> n-cut </em>和图模块化的两种算法。这些算法是早期的方法，可以追溯到2000年代，但由于其巨大的效率和可行性，仍然广泛用于许多图划分应用程序。</p><p id="2eaf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，在最近的应用中，图通常在节点特征中包含丰富的信息。因此，尽管这些方法功能强大且高效，但它们越来越不适用于现代图形应用程序。这些方法的局限性在于，它们仅基于图的连通性来划分图，而没有考虑节点特征中的任何信息。尽管已经做了一些工作将部分节点特征编码到边权重中并在加权图上进行划分，但是边权重所能表示的信息量仍然有限。最近有使用<a class="ae kf" rel="noopener" target="_blank" href="/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc"> <strong class="ki iu">图神经网络</strong> </a>进行图划分的方法，该方法可以联合考虑图的连通性和节点特征来检测图中的社区。</p><h1 id="d0a4" class="mm lo it bd lp mn mo mp ls mq mr ms lv mt mu mv ly mw mx my mb mz na nb me nc bi translated">参考资料:</h1><p id="ebd0" class="pw-post-body-paragraph kg kh it ki b kj mg kl km kn mh kp kq kr mi kt ku kv mj kx ky kz mk lb lc ld im bi translated">[1] J. Shi和J. Malik，“归一化切割和图像分割”，<em class="ml"> IEEE模式分析和机器智能汇刊，</em>第22卷第8期，第888–905页，2000年。</p><p id="1270" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] <a class="ae kf" href="https://www.pnas.org/doi/10.1073/pnas.0601602103#con" rel="noopener ugc nofollow" target="_blank"> M. E. J .纽曼</a>，《网络中的模块化与社区结构》，Phy。2006年修订版</p><p id="9d45" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] <a class="ae kf" href="https://ui.adsabs.harvard.edu/search/q=author:%22Blondel%2C+Vincent+D.%22&amp;sort=date%20desc,%20bibcode%20desc" rel="noopener ugc nofollow" target="_blank">布隆德尔，文森特D. </a>，<a class="ae kf" href="https://ui.adsabs.harvard.edu/search/q=author:%22Guillaume%2C+Jean-Loup%22&amp;sort=date%20desc,%20bibcode%20desc" rel="noopener ugc nofollow" target="_blank">纪尧姆，让-卢普</a>，<a class="ae kf" href="https://ui.adsabs.harvard.edu/search/q=author:%22Lambiotte%2C+Renaud%22&amp;sort=date%20desc,%20bibcode%20desc" rel="noopener ugc nofollow" target="_blank">朗比奥特，雷诺</a>，<a class="ae kf" href="https://ui.adsabs.harvard.edu/search/q=author:%22Lefebvre%2C+Etienne%22&amp;sort=date%20desc,%20bibcode%20desc" rel="noopener ugc nofollow" target="_blank">列斐伏尔，艾蒂安</a>，《大网络中社区的快速展开》，统计力学杂志，2008</p></div></div>    
</body>
</html>