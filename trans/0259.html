<html>
<head>
<title>5 Useful Pandas Functions Reimplemented In Pyspark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pyspark中重新实现的5个有用的熊猫函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-useful-pandas-functions-reimplemented-in-pyspark-2619d2359d38#2022-02-10">https://towardsdatascience.com/5-useful-pandas-functions-reimplemented-in-pyspark-2619d2359d38#2022-02-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4788" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在pyspark中重新实现缺失的熊猫函数</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/09587a74ca3997a18ae5958f8c3b1adb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dz1qbFQSQn0cFSMN"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ditakesphotos?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">戴安娜·帕克豪斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="64cf" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="3602" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Pandas是Python中最流行的数据辩论工具之一，因为它具有直观的数据结构和丰富的API。在Pandas和Pyspark之间切换的用户可能会注意到，某些Pandas方法或属性没有Pyspark等价物。</p><p id="5615" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在本文中，我们将研究Pyspark中没有的一些常用的Pandas方法和属性，以及如何在Pyspark中创建我们自己的等效自定义方法。我们将使用<code class="fe ms mt mu mv b">pd_df</code>和<code class="fe ms mt mu mv b">ps_df</code>分别代表熊猫和Pyspark数据帧。</p><p id="f3ab" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">需要以下导入:</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="0463" class="na la it mv b gy nb nc l nd ne">import pyspark<br/>from pyspark.sql.window import Window<br/>from pyspark.sql import functions as f</span></pre><h1 id="f39f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">形状</h1><p id="3976" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">熊猫的<code class="fe ms mt mu mv b">.shape</code>属性允许我们检查数据帧的行数和列数。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="8e7b" class="na la it mv b gy nb nc l nd ne">pd_df.shape</span><span id="ce98" class="na la it mv b gy nf nc l nd ne">&gt;&gt; (45211, 17) # number of rows, columns</span></pre><p id="a6a4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了在Pyspark中获得类似的输出，我们可以通过包含一个新的<code class="fe ms mt mu mv b">shape()</code>方法来扩展<code class="fe ms mt mu mv b">pyspark.sql.DataFrame</code>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="915c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们可以找到Pyspark数据帧的形状</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="6e40" class="na la it mv b gy nb nc l nd ne">ps_df.shape()</span><span id="5066" class="na la it mv b gy nf nc l nd ne">&gt;&gt; (45211, 17) # number of rows, columns</span></pre><h1 id="83cc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">信息</h1><p id="a530" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Pandas的<code class="fe ms mt mu mv b">.info()</code>方法为我们提供了每一列的数据类型和空值数量</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="da44" class="na la it mv b gy nb nc l nd ne">pd_df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/82eb6efbd98a2d879b1efc778e6b2456.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/0*JGrScuK3suZgIBBv"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="91d8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面的代码片段展示了Pyspark的等效代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="8f96" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对Pyspark数据帧执行<code class="fe ms mt mu mv b">.info()</code>会返回相关的Pyspark数据类型，这些数据类型可能与Pandas数据类型不同。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="6242" class="na la it mv b gy nb nc l nd ne">ps_df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/822150ff882db506add5f7dd54278b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/0*2bL03VrWHKJMq310"/></div></figure><h1 id="7253" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">重新命名</h1><p id="2bb7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Pandas的<code class="fe ms mt mu mv b">.rename</code>方法允许我们使用字典重命名多个列，其中键是当前列名，值是新列名<code class="fe ms mt mu mv b">{"old_col_name":"new_col_name"}</code>。</p><p id="ada1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Pyspark允许用<code class="fe ms mt mu mv b">.withColumnRenamed</code>方法重命名Pyspark数据帧。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="f016" class="na la it mv b gy nb nc l nd ne">sp_df = spdf.withColumnRenamed('old_col_name', 'new_col_name')</span></pre><p id="1cba" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了重命名多个列，我们多次调用<code class="fe ms mt mu mv b">.withColumnRenamed</code>方法:</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="fa7c" class="na la it mv b gy nb nc l nd ne">sp_df = spdf.withColumnRenamed('old_col_name1', 'new_col_name1').withColumnRenamed('old_col_name2', 'new_col_name2')</span></pre><p id="9164" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们创建一个Pyspark <code class="fe ms mt mu mv b">.rename()</code>方法，它允许我们使用映射器字典重命名多个列。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="303e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们现在可以使用以下方式重命名<code class="fe ms mt mu mv b">pyspark.sql.DataFrame</code>:</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="45ea" class="na la it mv b gy nb nc l nd ne">new_df = ps_df.select('marital', 'age').rename({'marital':'marital_status', 'age':'customer_age'})<br/>new_df.show(n = 5)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/d9c73ddd49b1da6127801c18aca84c02.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/0*k_zIooiBx8uUStf9"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="b2d4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">值计数</h1><p id="23f5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">熊猫的<code class="fe ms mt mu mv b">.value_counts()</code>计算具有唯一列组合的行数。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="32d6" class="na la it mv b gy nb nc l nd ne">pd_df.value_counts('marital')</span></pre><p id="2fc7" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在派斯帕克</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><p id="f3d4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">与Pandas <code class="fe ms mt mu mv b">.value_counts()</code>类似，有一个使用<code class="fe ms mt mu mv b">normalize</code>参数来标准化频率的选项。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="d657" class="na la it mv b gy nb nc l nd ne">ps_df.value_counts('marital')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/cc620eb1a41f84feaa78f7ca250dd3e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/0*6uQLg9AQ5UXyePkX"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="e83c" class="na la it mv b gy nb nc l nd ne">ps_df.value_counts('marital', normalize = True)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/338300bdc5136ea000543bab8fee6b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/0*XpVLfPAa-cbM9FxI"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="a19f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">复制</h1><p id="0976" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Pandas的<code class="fe ms mt mu mv b">.duplicated</code>方法返回一个布尔序列来表示重复的行。我们的Pyspark对等函数将返回Pyspark数据帧，其中有一个名为<code class="fe ms mt mu mv b">duplicate_indicator</code>的附加列，其中<code class="fe ms mt mu mv b">True</code>表示该行是重复的。</p><pre class="kj kk kl km gt mw mv mx my aw mz bi"><span id="5f00" class="na la it mv b gy nb nc l nd ne">ps_df\\<br/>  .select(['age', 'job', 'marital', 'education', 'balance'])\\<br/>  .duplicated(subset = ['age', 'job', 'marital', 'education'], orderby = ['balance'], ascending = True, keep = 'first')\\<br/>  .show()</span></pre><p id="becb" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><code class="fe ms mt mu mv b">.duplicated()</code>的pyspark当量</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ng nh l"/></div></figure><h1 id="ba20" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="3231" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我们研究了5个常用的Pandas方法/属性，并在Pyspark中创建了它们的对等物。Pyspark中的这些方法可以作为快速数据探索和清理的便利功能。你可以在<a class="ae ky" href="https://github.com/edwintyh/pyspark-utils/blob/main/utils.py" rel="noopener ugc nofollow" target="_blank">这个github资源库</a>中找到完整的代码。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><ul class=""><li id="d9f0" class="nu nv it lt b lu mn lx mo ma nw me nx mi ny mm nz oa ob oc bi translated">加入Medium 阅读更多类似的故事</li><li id="b9dd" class="nu nv it lt b lu od lx oe ma of me og mi oh mm nz oa ob oc bi translated">关注我关于<a class="ae ky" href="https://medium.com/@edwin.tan" rel="noopener">熊猫</a>的教程</li></ul></div></div>    
</body>
</html>