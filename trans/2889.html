<html>
<head>
<title>A New Type of Categorical Correlation Coefficient</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种新型的类别相关系数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-type-of-categorical-correlation-coefficient-f5782036fc85#2022-06-23">https://towardsdatascience.com/a-new-type-of-categorical-correlation-coefficient-f5782036fc85#2022-06-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="59fa" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><strong class="ak">分类预测系数</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6474c98199151912036f1b2e5d2ce3c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqeJOHAVfW8MUydYkD7FzA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@gamell?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">琼·加梅尔</a>在<a class="ae kv" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><ul class=""><li id="b26f" class="kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated"><a class="ae kv" href="#1c0c" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">简介</em> </strong> </a></li><li id="6fc1" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#ef3b" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">二元分类示例</em> </strong> </a></li><li id="eae4" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#0562" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">证明</em> </strong> </a></li><li id="c5c4" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#8a2d" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">回二进制分类示例</em> </strong> </a></li><li id="492b" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#395f" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">特殊情况</em> </strong> </a></li><li id="877a" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#032d" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo"> p值</em> </strong> </a></li><li id="2278" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#7ed4" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">多类分类示例</em> </strong> </a></li><li id="e80c" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#00ab" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">相关矩阵</em> </strong> </a></li><li id="9fe8" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#6564" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">结论</em> </strong> </a></li><li id="538e" class="kw kx iq ky b kz lp lb lq ld lr lf ls lh lt lj lk ll lm ln bi translated"><a class="ae kv" href="#0fd6" rel="noopener ugc nofollow"> <strong class="ky ir"> <em class="lo">算法</em> </strong> </a></li></ul><h2 id="1c0c" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated">介绍</h2><p id="df72" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">想知道变量之间相关性的最常见原因是开发预测模型。输入变量与结果变量的相关性越高，预测变量就越好。但是检查输入变量之间的相关性也很重要。有必要消除模型中的多重共线性，多重共线性会降低模型度量的合法性和模型性能。</p><p id="e4ed" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于数字变量，我们可以创建一个表(相关矩阵)来轻松查看所有输入变量与结果变量的相关性，以及同时所有输入变量之间的相关性。比较很容易，因为相关性都在相同的范围内，通常从-1到1。但是分类变量就不是这样了。</p><p id="1fd3" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于分类变量，相关矩阵不容易使用，甚至不总是有意义的，因为计算出的值通常彼此之间没有相关性。每个相关值都有自己的临界值，必须与之进行比较，临界值根据每个变量对的自由度(以及所选的置信水平)而变化。例如，我们可能与一个结果变量有三个相关性，20、30和40。相关性为20和30的那些可能具有五个自由度，并且高于它们的临界值15。但是相关性为40的变量可能低于其临界值45，甚至不相关。</p><p id="3161" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">如果有一种方法可以创建一个相关矩阵，其中所有的值都与数值变量的大小相同，这不是很好吗？现在有了。</p><h2 id="ef3b" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated">二元分类示例</h2><p id="7bd8" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">假设我们有一个值为A和B的二进制结果变量和一个值为C和D的二进制输入变量。如果输入变量中每次出现C，结果变量都是A。输入变量中每次出现D，结果变量都是B，那么我们就有了一个完美的预测器。如果这是我们模型的唯一输入，我们就有了表现最好的模型。我们会有完美的模型度量，预测系数会是1。如果每个输入变量值都有一个50/50的A和B，那么我们有一个最没有帮助的预测器。如果这是我们模型的唯一输入，我们就会有表现最差的模型。预测系数将是0。这同样适用于输入变量之间的关系。如果一个与另一个100%的时间一致，我们将把基本相同的信息放入模型，并且应该检查它们之间的关系。</p><p id="b014" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们来分析一下这个。二进制变量的50/50分割将是均匀分布。我们要问的是，对于输入变量的每个值，结果变量的分布在多大程度上遵循均匀分布？如果完全匹配，输出变量的每个值出现的次数相同，则输入变量的这个值向模型添加的信息最少。如果所有输入变量值都是这种情况，则预测系数将为0。如果它尽可能远离均匀分布，它会向模型添加最多的信息；100%都是一个值。如果所有输入变量值都是这种情况，则预测系数将为1。同样的原理也适用于具有任意数量值的分类变量。</p><p id="6c91" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们来量化一下这个。对于任何具有两个分类变量的数据集，我们创建一个列联表，其中每个单元格代表具有特定输入/输出组合的行数，即排名。举个例子，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/f12248bae735b643c2112fedd8371535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*forVZ2ZE_t6qZ7H32roPyg.png"/></div></div></figure><p id="ce18" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将对各行求和，以获得每个输入变量值的总数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/6a12304986cd37396e999c3cfe425e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10LurWrja8oCm93OP9gvUQ.png"/></div></div></figure><p id="35cd" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将通过除以每行中的总和来计算每个输入变量值的每个结果变量值的出现百分比。以十进制形式，我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/86c7d5b7ec2761e2d3f77030b4d92413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4VVfH9buyLT57tTiwS6-Sg.png"/></div></div></figure><p id="6aa1" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将计算均匀分布期望值的变化，两个可能值为0.5，并将结果归一化。我们将像计算标准差一样计算它。我们将让n成为整个数据集中结果变量的唯一值的数量。假设它们的概率相等，1/n是得到结果变量任一值的概率，即均匀分布的期望值。我们将xⱼ作为输入变量的一个值的结果变量的每个j值的出现百分比。对于输入变量的每个I值，我们计算</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/fbcf039e560098d7b260fac04618ac19.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*JXMB9YGkHQhZloxssKQEnA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/5027f76c67a9ba4e55e8fc3bbac8d715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-0AIeLbSZnKU5pHV8_4tA.png"/></div></div></figure><p id="567e" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">接下来，我们将根据最大值Eq对这些值进行归一化。1可以服用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/4fc2f23454ae87903086590c80bb60ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*3fUzUM9dq0ooJJ-KE9Lsig.png"/></div></figure><h2 id="0562" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated">证明</h2><p id="45a7" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">为了证明这一点，我们将使用数学归纳法。数学归纳法指出，对于所有整数n和k，如果我们能证明n = k和n = k + 1成立，那么对于所有n ≥ k成立。我们将证明n = 2和n = 3成立。然后通过数学归纳法，它将适用于所有n ≥ 2。</p><p id="f487" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于n = 2，我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/8f74a25137e0432cf1712bbf1118804b.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*YRJieoz6Pfv6vZ2hZJKbSw.png"/></div></figure><p id="9167" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/f418afa308cf675e2f9473bcffbc20bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*CQbCRQL0N0LI2O76SrHr9w.png"/></div></figure><p id="3f76" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">在哪里</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f9c90c17d1d44d7166b0ec23f51fe23d.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*9hNHDdLKx2qRkoPxe_Gy0Q.png"/></div></figure><p id="86d0" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ee3e6559c7058ed473d24dbb88cd4cdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*EPdIN4eCXA91ySKn_8gX0Q.png"/></div></figure><p id="7849" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们可以求解方程。3代表x₁，并将其代入方程。3制作Eq。3一个变量的函数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/42b554245df6290370fa2155bc4a72fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*FsSKsWIUmNdIoz01v0UuXw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/3ed209177c010ff4ebf74aa613c672dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*svY2bJte7zL-o0pr1Sj2LA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/fa73d21575162ec768826221321bffab.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*ofLtmPcXdWrjo4DrXdz6Bg.png"/></div></figure><p id="b102" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们取导数，将其设置为零，并找到临界点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/35e103096398761ce1c167eaa1a1961e.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*bK22WKj_40kPHfrjqBxbwQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/63bcacf1557d8c8d9618f61084101726.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*1_tLKLwRK8HwBRNe_PoSTA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/984ac04611d72437760d17eb78cf0407.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*j4oWNbgNO_6PijPsjzBrpA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/e816709b6396f755e302ef3b62563395.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*zMnkFTHTZlKyORroxqueSw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/0311b13513c9a7b86d870784561731d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:294/format:webp/1*QuTMzIV4tHKQULXVo1HNoA.png"/></div></figure><p id="521d" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">使用等式。5，我们找到了与x₁.的这个值相对应的x₂的临界值</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/34fccec8f05c978773443af0c689d882.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*dKCb7G1cqKTtd-A8KSqjEw.png"/></div></figure><p id="e2de" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">现在，我们将在临界点和端点创建一个函数值表，以确定最大值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/72956e1bb9cb9ca78c74dc8d899f739f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ftWbbKSfqODjOvG5n6uw0Q.png"/></div></div></figure><p id="d859" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">最大值出现在(x₁，x₂) = (0，1)和(x₁，x₂) = (1，0)，两者的计算结果均为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/892b186f3cdf529b6998b8386931a23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:312/format:webp/1*RgloZMQXEKY5b3JHrK0Rdw.png"/></div></div></figure><p id="d36c" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于n = 3，我们将使用拉格朗日乘子法。我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3beeb77f8e7890f37b3715ba9f0e6062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*dBR_sqPhS9NwOHY5pFNafg.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/472ea1144b472966980810a9cb381322.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*oxy8ksFPRtnaHa8pvmv4vQ.png"/></div></div></figure><p id="60bb" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">在哪里</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/c22228ec879371fb14d0ca5d418d863c.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*MVcd-c5ucxjLsGZ8aFuMaQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/3f7624cb38c45bfbf8f5a3502bdc65e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*8KZecX5welsxu4LSF-AZkQ.png"/></div></figure><p id="d39d" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/64e0db70dff7ecceaf480a9e5078ea6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*l7Rf2bitlQRYnnTmn_5Nsw.png"/></div></figure><p id="4edf" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将约束方程转换成一个函数，将所有项放在方程的一边。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/7625579276e6bdfdce279a4adf22a840.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*lBE_8zmF9BJ2mZL9m4lPpQ.png"/></div></div></figure><p id="6585" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将得到𝜎ᵢ相对于x₁的导数，并将其设置为等于f(x₁、x₂、x₃相对于x₁的导数乘以拉格朗日乘数λ。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/6438805ddc5ecf9146dd00cbd821a5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/format:webp/1*BwLcrc9HtrQgp4kLqB2VzQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/5eb57726861b5e89630a59ac58c3ab80.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*RyhhnZ_PELT4LzWvv0vjzw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/e3a0326f75b094bbbfaa51149c5d9342.png" data-original-src="https://miro.medium.com/v2/resize:fit:200/format:webp/1*tnOLWHvamu5FBYHVuSVokA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/740cab0d8ce3be4873883d57ae640501.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*4a7zoe3ZL8MwXPOaYstu4g.png"/></div></figure><p id="29b7" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">通常，我们会对x₁和x₂重复这个过程，用λ求解它们，将它们代入我们的约束方程，用这四个方程求解四个未知数，得到临界点。但是在简化Eq的同时。20，我们的λ项取消，我们直接求解x₁。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1b3750926505a5d1b5dc561b3b419ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*aXIbQ4pcC0Kk2FE-FaI_gw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7f2904507494524f5805fd5cdcc5f3e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*mAoLrpMMfSOiIl4Fmvx3Nw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/122dd9ac45ae9aa869b191ff9a54fad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*gt2W-7ZySNMYiNpzxhqqFw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/a8290822feeaf4b5ba7e46288148ac39.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*6enWnJ2oWNcTgJPj0MQ5Kw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3b78e5d8d92182137f3852210c28bb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*hHmsHomkLkDYvGbR8oe0aw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/3debbfec04946817f3372c26644d93e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/1*OrbaYClpoW0P0-k2HZLzvQ.png"/></div></figure><p id="3b40" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">x₂和x₃的方程与x₁的方程相同，只是去掉了变量。这给了我们临界点。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a2f3d1a045ce2e66b501ab6ebf210bdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*j8066Sxrl7IPOOTRI9L0SQ.png"/></div></figure><p id="36d0" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">现在，我们将创建一个值表，在这个点及其端点评估我们的函数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/b17f198f0da057bf2f37a287bf755189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L0ZRW1leaCebJi7O5bqg3Q.png"/></div></div></figure><p id="ca01" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们的最大值是2/3的平方根，等于</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7cfca7b47928073efa1468442d6463e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*BA0aK3F1ROsJxaPsQd2Oqw.png"/></div></figure><p id="7382" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">通过数学归纳法，最大值</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/f952d0024114712965dcba02ae744d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*1G0lHBLcik0P6TjC56s3tA.png"/></div></figure><p id="f929" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">是</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2c17901e90aa2b83ee8d19ec6ec2cce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:214/format:webp/1*Mc6CKCfMqF1fmeOPbG_7uQ.png"/></div></figure><p id="60a1" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于所有整数n ≥ 2和所有实数xⱼ，这样对于每个xⱼ</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/0a5cfeb2a6822f0844aa3db0dad8171a.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*QsV5DBFA47BWjt_v9ZLhNQ.png"/></div></figure><p id="b13c" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">和</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/5025fc2e86ff03d0566d12a6735b2aa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/1*_W_fJYzKi3sWsQapwkoHIg.png"/></div></figure><p id="afb8" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于n = 1，我们有一个简单的情况，即结果变量只有一个值。</p><h2 id="8a2d" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated">回到二进制分类示例</h2><p id="9bcc" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">现在，我们将除以1/2的平方根，得到归一化变量，ψᵢ。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/80e3201ced915bf6b5b7917626001a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*SaBVvZiphwXbpdZRr5Bk9g.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/72281bece6dae0bb3ac50eb855e57e99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4VFDRm3CuUwHAgTKNYajg.png"/></div></div></figure><p id="d5a9" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将取这些值的平均值，得到我们的预测系数ω。我们假设m是唯一输入变量值的数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/78b7432ca8d7edcd75957e27cd3cd535.png" data-original-src="https://miro.medium.com/v2/resize:fit:318/format:webp/1*Xq-o3CqN0ow8-rXfaoU_sw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/d2ba18556f61a7ce914c31dcd3339909.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*c-xOnrSVghI68QqOxTWTYA.png"/></div></figure><p id="d9c2" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">为了说明每个输入变量的变化对整个数据集的贡献有多大，我们可以采用加权平均值，权重是它们在数据集中出现的百分比。但是我们将通过将每个权重除以它们的最大值来归一化我们的权重。假设𝜌ᵢ是每个输入变量的出现百分比，ϕᵢ是加权归一化变量，我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/74eadd31050515186023e0bfcb76bc0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*ixIYBDk8RVtLt5VPouXbog.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/3bb12e3b0ca8e344db664382fa11ab41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKXZY6UKZDFr5MNE4Q5gZA.png"/></div></div></figure><p id="3178" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">取这些的平均值，我们就有了加权预测系数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/940d86834621172600ea8a4bf3b3aa7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*oVzIhwbxt8Q9-567G5XIzQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/4d5dd078df0a005e3e1136cdbfc9b6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*IoUCd8WauQL7kedgLgc-YA.png"/></div></figure><h2 id="395f" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated"><strong class="ak">特殊情况</strong></h2><p id="c5f6" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">让我们看看一个完美的预测器是什么样的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/a1022cf3637cbf55b848ebee5929c434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-YwAflNtFj1I4mi3MuT7cQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/6f95f572ad0f4a927ec22c38dd1e2c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N45GaaBjwT46yJAbx0bNDQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/4a0fd418a9cb8ec17d8dd11a5c2ad246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5tfPttqlKbNSTroSkIbVA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/72313967460760d850b068deaa967bed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTXReh8-xE_x8EAYwLSs5A.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/5e2d3fdb3a3a2b3c2cea7529f67120a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*pIKowA9rkY5B2IHzbPcRzA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/890b443c1efe66bdb872499f94e4c4c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4uos8ZN6rjrsXKWhMmmRvw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/53b2f42b547d3a4403c116a423778fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*5b3pAs8SKyKonRFdjUR8oA.png"/></div></figure><p id="2f60" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">请注意，加权导致即使是完美的预测值也小于1。</p><p id="19c3" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">当试图识别数据泄漏和输入变量之间的关系时，如数值变量之间的多重共线性，未加权的预测系数可能更具指示性。当使用预测系数进行特征选择时，加权预测系数可以给出更好的整体表示。建议两者都分析。</p><p id="8f24" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">让我们看一个统一的预测器。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/bb3d817aadbb0209116247718f21508c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*yRMSUG9hWJ3AfxW9eNl0tA.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/38ba7ff333c95ba18e37b9463f565f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kmQ6PuCDM9jItmgM3GLImw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/6f3406b60e8de28a8ec39fcd01917728.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXmQrfLXcWrzOm_vPMxytw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/94e9337d8bf0e89fa795462b394708cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61HQr-3VuVF6H8OIs4taCA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/66b3dfdcbe0d739d7d1850cb34b5ef1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*Dd-q5u-ZT19wupnBIWbl9w.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/ae41d1270a9890b8596a66d25ac3f82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56Kp5eoTu-tyyb1IEdA33g.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/d71f5f5f49d27716237d8fd7ae7f2b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*p399r0DI9YTwT4PD3fZQjw.png"/></div></figure><p id="b987" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">请注意，第一个示例中的ω值和加权ω值虽然与1相差甚远，但并不表示预测变量不佳。对于输入变量的第一个和第二个值，我们的结果变量的最大出现百分比分别是85%和80%。这是一个相当强的预测。当同时比较许多输入变量之间的值时，如在相关矩阵中，相对值将清楚地表明哪个作为预测变量表现更好。</p><p id="78e2" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">为了更好地理解这些值的含义，我们来看一下预测系数的变化趋势，它取决于输出变量的一个值相对于输入变量的一个值出现的频率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/abe90b6bfbab8e6af650aaa2ae519179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*y8IyVgVWr89B9-60dr0zIw.png"/></div></figure><p id="135f" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们可以看到，预测系数等于x₁和1/n(n = 2)之差乘以2。因此，给定一对二元变量的预测系数，我们可以取该值，除以2，加上0.5，并计算其中一个结果变量值的最大出现百分比，通过其出现百分比告诉我们该变量对结果变量的预测有多强。</p><p id="531e" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">这是图表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/ce07fe490e099f4a774674df026cd1fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Moe-MeqjPrGs-MAJ0rXog.png"/></div></div></figure><p id="37f4" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">趋势是线性的，系数可以放心使用。</p><h2 id="032d" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated"><strong class="ak"> p值</strong></h2><p id="ddfe" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">我们的零假设是，对于每个输入变量值，每个结果变量值都是同样可能的。并且它们的出现百分比遵循均匀分布。获得每个结果变量值出现的概率等于从多项式分布的概率质量函数(PMF)计算的概率。二元结果变量的概率值将遵循二项式分布的PMF，这是多项式分布的一种特殊情况。我们必须计算每个输入变量值的概率。然后我们取它们的平均值。不需要考虑每个值出现的百分比。概率计算已经考虑到了这一点。</p><p id="312b" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">下面是从遵循二项式分布的试验总数中获得任意次数出现的概率的公式，其中每个值都是等概率的。为了避免重新定义我们已经在使用的变量，我们将与标准符号稍有不同。设t是试验的总数，y₁是一个结果变量值出现的次数，y₂是另一个结果变量值出现的次数，p是从t个试验中获得y₁和y₂出现的概率。提醒一下，m是结果变量的所有可能值。无效假设是这m个值中的每一个都是同样可能的。所以其中任何一个发生的概率都是1/m。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/004460f7cf04d823cde0740f9a0104ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/format:webp/1*C9J71FMDpFRRxfpgO6hdFA.png"/></div></figure><p id="dad1" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们可以用tᵢ选择y₂，而不是tᵢ选择y₁。38并得到相同的概率。对于不熟悉这个公式的人，<a class="ae kv" href="https://en.wikipedia.org/wiki/Binomial_distribution%23Probability_mass_function" rel="noopener ugc nofollow" target="_blank">点击此处</a>了解更多信息。</p><p id="bd3c" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">现在，我们将添加下标I来表示每个输入变量值，并将大写的P改为小写的P。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/82b984e86df37636a664a086367ce9f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*OcGj8HZw5QMGB8qPdiNuUQ.png"/></div></figure><p id="f526" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们将在多类分类示例中看到多项式分布的更通用公式。</p><p id="37c2" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于我们的第一个例子，我们有</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/f15bee43745d838f11e52c2081bbc406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Luck4Xy-6b01kCOoOQxFlg.png"/></div></div></figure><p id="b894" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">然后我们取平均值得到p值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/b3673c41098ad5731e02386a578a557f.png" data-original-src="https://miro.medium.com/v2/resize:fit:266/format:webp/1*2pWPW74EVPG7KVLXWLV84w.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/6cc23f7233608e44d766472cde831969.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*jRS0zlLZKXoDNTn7rSUNPA.png"/></div></figure><h2 id="7ed4" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated"><strong class="ak">多类分类示例</strong></h2><p id="7e2d" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">假设我们的数据集中有一个变量，它的输入和输出值如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/c951faa70745f566ed095642a11c9f95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pep1_O_-7csaQhAfjWAxSA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/b9809396fab59d66b80425d69c9e5194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPOLz2qhl-4CVVyk0_LLCA.png"/></div></div></figure><p id="f3df" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">使用Eq。1，我们从期望值计算我们的变化，对于三个可能的结果值是1/3。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pn"><img src="../Images/c6648d0504ac869b3bc3b172cca740f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yPcjzWtBLbG6vb56E0asbQ.png"/></div></div></figure><p id="00db" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">现在，我们将通过除以(n — 1)/n的平方根进行归一化，其中n = 3，2/3的平方根。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/39036bd80aefb92d08879c1f710d45dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*acktZT2i4rLSLJhplHbm3A.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi po"><img src="../Images/b81fc0074dd91f3831ab387cf745ae51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*SbGjZ3aUE-x95RdL3VXBtA.png"/></div></figure><p id="9ad4" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">这里我们看到0.4到0.5的值表示一个强预测值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/90bad1b8b5ea67823d55fa2dd7e62363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ce4KOpgJGMhk_ed5y9L9vg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pp"><img src="../Images/d758741f8bea426340a785155070c1b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*Gv04DkzKvAa8_qaN07cLJg.png"/></div></div></figure><p id="d370" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">以下是当每个可能值的概率为1/m时多项式分布的概率质量函数的公式。p将是概率，t将是结果变量值的总数，y₁到yₘ将是m个结果变量值中的每一个的出现次数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/06ebfd920757c700d0d7cd6cc757119d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*LIAubMjrQKC_1uA93-79Zg.png"/></div></figure><p id="1895" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">关于此公式的更多信息，<a class="ae kv" href="https://en.wikipedia.org/wiki/Multinomial_distribution%23Probability_mass_function" rel="noopener ugc nofollow" target="_blank">点击此处</a>。</p><p id="c94c" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">现在我们将添加下标I来表示这是针对I个输入变量值中的每一个的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/2a68b2c0964db304eeab8efbae3db026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*bCfJ1djQl7ucpQ98G2KaEQ.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ps"><img src="../Images/1e1e267ee229a1d71ece686ef1a9e451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xntMdauvz9kAskf7L7k-zQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pt"><img src="../Images/d18127904c52d669855b0a722b194764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*SMYYlPtVj9_M-QNnwg6gtg.png"/></div></figure><p id="402d" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于具有三个值的结果变量，具有一个结果变量值出现百分比的预测系数的趋势基本上是分段线性的。如果我们将剩余的百分比平均分配给另外两个值，我们就会得到这个图表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pu"><img src="../Images/acf01f882eb929c4bcf19eadaf761e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*dDx5QqfEK63tz-AB7-Z32w.png"/></div></figure><p id="cc93" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">在实践中，与直线的偏差并不值得关注。当我们每4%评估一次时，每一件的趋势都是线性的。即使在这个图表中，每一块的趋势仍然是单调的。</p><p id="5299" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">我们的最小值出现在均匀分布的期望值处，对于具有三个值的结果变量为1/3。随着结果变量值数量的增加，该值趋于零。并且可以通过从原点开始斜率为1的直线来估计这些值。</p><h2 id="00ab" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated"><strong class="ak">相关矩阵</strong></h2><p id="28ef" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">预测系数不是双向的，但是可以在一个视图中看到两个方向的关系。我们可以创建一个关联矩阵，其中每个单元格将行中的变量作为输入，将列中的变量作为输出。这将创建一个由两个对角矩阵组成的矩阵，每个矩阵显示两个方向中的一个。</p><p id="7df2" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">举个例子，</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pv"><img src="../Images/348cef8519cafef3b0d19a1c3604bed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kKcMjggTRRvCiLYFyj3MgA.png"/></div></div></figure><p id="9a6f" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">利用这一点，我们可以在第一列中按降序对我们的表进行排序，并按最强预测值的顺序查看我们的输入变量。我们还可以检测数据泄漏和输入变量之间的关系。我们可以看到，输入变量1与输出变量在两个方向上都有很强的关系，这可能是数据泄漏的迹象。输入变量2不是结果变量的强预测器，并且与输入变量1没有强关系。</p><p id="a61e" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated">对于加权系数，我们用NA代替对角线。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/9101e41cd9c114a79aab8cc447d9170e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sUEDvPcnRiF4rD4gVDDiOQ.png"/></div></div></figure><h2 id="6564" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated"><strong class="ak">结论</strong></h2><p id="e88a" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">该方法旨在简化分类变量之间强关系的检测。所有变量对都有一个相同范围内的数字，这将使检测哪些变量比其他变量具有更强的关系变得更简单、更容易、更快。虽然它被称为预测系数，但它告诉我们一个变量的变化与另一个变量的变化有多大关系。我们有一个单一的数字，它会告诉我们，一个变量作为另一个变量的预测器，根据这个信息会有多好。</p><h2 id="0fd6" class="lu lv iq bd lw lx ly dn lz ma mb dp mc ld md me mf lf mg mh mi lh mj mk ml mm bi translated">算法</h2><p id="73d2" class="pw-post-body-paragraph mn mo iq ky b kz mp jr mq lb mr ju ms ld mt mu mv lf mw mx my lh mz na nb lj ij bi translated">该算法的优化实现已经开发出来，并将免费发布。Python的预发行版<a class="ae kv" href="https://github.com/QuantumAudio/Prediction-Coefficient" rel="noopener ugc nofollow" target="_blank">在这里</a>可用。官方版本将很快推出。我可能会发布一个r语言版本。请在评论中写下你想用的其他语言，我会尽最大努力满足你的要求。要在未来版本可用时得到通知，请单击“跟随我的名字”。</p><p id="15d6" class="pw-post-body-paragraph mn mo iq ky b kz la jr mq lb lc ju ms ld nc mu mv lf nd mx my lh ne na nb lj ij bi translated"><em class="lo">(除特别注明外，所有图片均为作者</em>。)</p></div></div>    
</body>
</html>