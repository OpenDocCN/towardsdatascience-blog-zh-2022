<html>
<head>
<title>Creating an Ensemble Voting Classifier with Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Scikit-Learn创建集成投票分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-an-ensemble-voting-classifier-with-scikit-learn-ab13159662d#2022-10-15">https://towardsdatascience.com/creating-an-ensemble-voting-classifier-with-scikit-learn-ab13159662d#2022-10-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d7c9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">您可以使用Python创建自己的具有不同算法的分类器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1f17ab9f79ebbeb057a68869de99615d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CjpLkJhMjtACB_26LZTMoQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@element5digital?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Element5数码</a>在<a class="ae ky" href="https://unsplash.com/s/photos/vote?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="3767" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="8eef" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">分类集成模型是由适合相同数据的许多模型组成的模型，其中分类的结果可以是多数人的投票、结果的平均值或最佳执行模型结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/737b43a5a85a454cba719d84f93eccd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pS27XG-PSkjqMcbY58dznA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:带有投票结果的集合模型。图片由作者提供。</p></figure><p id="91ca" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">在图1中，有一个我们将在这个快速教程中构建的投票分类器的例子。观察到有三个模型符合数据。其中两个把数据归类为1，一个归类为0。所以，通过大多数人的投票，1班获胜，这就是结果。</p><p id="3c35" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">在Scikit-Learn中，集成模型的一个常用示例是<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林分类器</a>。顺便说一句，这是一个非常强大的模型，它使用许多决策树的组合来给我们一个观察的最佳结果。另一个选项是<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier" rel="noopener ugc nofollow" target="_blank">梯度增强</a>模型，这也是一个集合类型的模型，但它有一个不同的配置来获得结果。</p><blockquote class="na nb nc"><p id="b328" class="ly lz nd ma b mb mv ju md me mw jx mg ne mx mj mk nf my mn mo ng mz mr ms mt im bi translated">如果你感兴趣，这里有一篇非常完整的<a class="ae ky" rel="noopener" target="_blank" href="/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"> TDS文章</a>是关于打包和提升集合模型的。</p></blockquote><p id="0e00" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">然而，这些都是为了方便我们作为数据科学家的生活而创建的预包装模型。它们表现得非常好，并将提供良好的结果，但它们只使用一种算法来训练模型。</p><p id="8f02" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">如果我们想用不同的算法创建自己的投票分类器会怎么样？</p><p id="fe9f" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">这就是我们将要学习的内容。</p><h1 id="a972" class="lg lh it bd li lj nh ll lm ln ni lp lq jz nj ka ls kc nk kd lu kf nl kg lw lx bi translated">投票分类器</h1><blockquote class="nm"><p id="f339" class="nn no it bd np nq nr ns nt nu nv mt dk translated">投票分类器使用选择的算法训练不同的模型，返回多数人的投票作为分类结果。</p></blockquote><p id="faec" class="pw-post-body-paragraph ly lz it ma b mb nw ju md me nx jx mg mh ny mj mk ml nz mn mo mp oa mr ms mt im bi translated">在Scikit-Learn中，有一个名为<code class="fe ob oc od oe b">VotingClassifier()</code>的类可以帮助我们以一种简单的方式创建具有不同算法的投票分类器。</p><p id="fed3" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">首先，导入所需的模块。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="a251" class="oj lh it oe b gy ok ol l om on"># Dataset<br/>from sklearn.datasets import make_classification</span><span id="4f6d" class="oj lh it oe b gy oo ol l om on"># sklearn<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier<br/>from sklearn.metrics import f1_score, accuracy_score</span></pre><p id="fcf1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">让我们为我们的练习创建一个数据集。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="8c5f" class="oj lh it oe b gy ok ol l om on">seed=56456462<br/># Dataset<br/>df = make_classification(n_samples=300, n_features=5, n_informative=4, n_redundant=1, random_state=seed)</span><span id="8958" class="oj lh it oe b gy oo ol l om on"># Split<br/>X,y = df[0], df[1]</span><span id="d99c" class="oj lh it oe b gy oo ol l om on"># Train Test<br/>X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=seed)</span></pre><p id="3a4f" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">好了，一切就绪。接下来我们需要决定我们想要使用的算法。我们将使用<strong class="ma iu">逻辑回归</strong>、<strong class="ma iu">决策树</strong>和集合模型<strong class="ma iu">梯度推进</strong>的组合。因此，我们可以注意到，投票分类器可以由其他集成模型组成，这很好。想象一下用梯度推进聚集随机森林的力量？</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="cd27" class="oj lh it oe b gy ok ol l om on"># Creating instances of the algorithms<br/>logit_model = LogisticRegression()<br/>dt_model = DecisionTreeClassifier()<br/>gb_model = GradientBoostingClassifier()</span></pre><p id="4dbc" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">现在，我们有了组成投票分类器的所有东西。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="5288" class="oj lh it oe b gy ok ol l om on"># Voting Classifier<br/>voting = VotingClassifier(estimators=[<br/>          ('lr', logit_model),<br/>          ('dt', dt_model),<br/>          ('gb', gb_model) ],<br/>           voting='hard')</span></pre><p id="b196" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated"><code class="fe ob oc od oe b">voting='hard'</code>是默认值，它意味着用多数规则投票来预测类标签。接下来，让我们创建这些模型的列表，这样我们可以循环它们来分别比较结果。</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="4937" class="oj lh it oe b gy ok ol l om on"># list of classifiers<br/>list_of_classifiers = [logit_model, dt_model, gb_model, voting]</span><span id="ecc1" class="oj lh it oe b gy oo ol l om on"># Loop scores<br/>for classifier in list_of_classifiers:<br/>    classifier.fit(X_train,y_train)<br/>    pred = classifier.predict(X_test)<br/>    print("F1 Score:")<br/>    print(classifier.__class__.__name__, f1_score(y_test, pred))<br/>    print("Accuracy:")<br/>    print(classifier.__class__.__name__, accuracy_score(y_test, pred))<br/>    print("----------")</span></pre><p id="e2db" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">结果是:</p><pre class="kj kk kl km gt of oe og oh aw oi bi"><span id="0564" class="oj lh it oe b gy ok ol l om on">F1 Score: LogisticRegression 0.8260869565217391<br/>Accuracy: LogisticRegression 0.8222222222222222<br/>---------- <br/>F1 Score: DecisionTreeClassifier 0.8172043010752689 <br/>Accuracy: DecisionTreeClassifier 0.8111111111111111 <br/>---------- <br/>F1 Score: GradientBoostingClassifier 0.8421052631578948 <br/>Accuracy: GradientBoostingClassifier 0.8333333333333334 <br/>---------- <br/>F1 Score: VotingClassifier 0.851063829787234 <br/>Accuracy: VotingClassifier 0.8444444444444444 <br/>----------</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/890b212c1a6d06bc50aed9ebdad53f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tS_XPJzifIKdxqi0C8FuDg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:优于独立模型的投票分类器。图片由作者提供。</p></figure><p id="b3c1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">在这个例子中，投票分类器优于其他选项。F1分数(正类准确性和真阳性率的混合)和准确性分数都略高于单独的梯度增强，并且比单独的决策树好得多。</p><p id="afa2" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">值得注意的是，如果您更改种子值，输入数据集也会更改，因此您可能会得到不同的结果。例如，尝试使用<code class="fe ob oc od oe b">seed=8</code>，您将得到这个结果，其中投票分类器被逻辑回归和梯度提升所超越。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/8e9aa032ca33247688f437fa1960b0dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrrnQy0yZUqTPOTWM6bRHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3:投票分类器的性能比Logit和Grad差。助推模型。图片由作者提供。</p></figure><p id="332d" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">我告诉你这些是因为表明数据科学不是一门精确的科学是很重要的。它依赖于精确的科学，但不仅仅是成功的秘诀。大多数情况下，为了得到最终的结果，你必须对你的模型进行更多的调整。但是拥有像本文中介绍的工具可以给你很大的帮助。</p><h1 id="9d57" class="lg lh it bd li lj nh ll lm ln ni lp lq jz nj ka ls kc nk kd lu kf nl kg lw lx bi translated">在你走之前</h1><p id="2869" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">集合模型是很好的选择，它们经常能提供很好的结果。</p><ul class=""><li id="010c" class="or os it ma b mb mv me mw mh ot ml ou mp ov mt ow ox oy oz bi translated">他们不太可能过度拟合数据，因为他们用不同的数据分割来训练许多模型</li><li id="92c5" class="or os it ma b mb pa me pb mh pc ml pd mp pe mt ow ox oy oz bi translated">它们可以提供更好的准确性，因为有更多的模型确认分类是在正确的方向上。</li><li id="d783" class="or os it ma b mb pa me pb mh pc ml pd mp pe mt ow ox oy oz bi translated"><code class="fe ob oc od oe b">VotingClassifier()</code>可以帮助你用不同的算法创建一个集成模型。</li><li id="e346" class="or os it ma b mb pa me pb mh pc ml pd mp pe mt ow ox oy oz bi translated">语法:使用带有<code class="fe ob oc od oe b">VotingClassifier("name of the model", Instance() )</code>的元组</li></ul><p id="bd4c" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">如果你喜欢这个内容，请关注我的博客。也可以在LinkedIn上找到我。</p><div class="pf pg gp gr ph pi"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw ks pi"/></div></div></a></div><h1 id="5eaf" class="lg lh it bd li lj nh ll lm ln ni lp lq jz nj ka ls kc nk kd lu kf nl kg lw lx bi translated">参考</h1><p id="7702" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">奥雷连恩·盖伦，<a class="ae ky" href="https://tinyurl.com/2s3tsh9x" rel="noopener ugc nofollow" target="_blank"> <em class="nd"> 2019。用Scikit-Learn，Keras&amp;tensor flow</em>T3】动手机器学习。第二版，奥赖利。</a></p><div class="pf pg gp gr ph pi"><a href="https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1492032646/ref=asc_df_1492032646/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=385599638286&amp;hvpos=&amp;hvnetw=g&amp;hvrand=10774777250311570064&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9009674&amp;hvtargid=pla-523968811896&amp;psc=1&amp;tag=&amp;ref=&amp;adgrpid=79288120515&amp;hvpone=&amp;hvptwo=&amp;hvadid=385599638286&amp;hvpos=&amp;hvnetw=g&amp;hvrand=10774777250311570064&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9009674&amp;hvtargid=pla-523968811896" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">使用Scikit-Learn、Keras和TensorFlow进行机器实践学习:概念、工具和技术…</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">用Scikit-Learn、Keras和TensorFlow进行机器学习:概念、工具和技术来构建…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">www.amazon.com</p></div></div><div class="pr l"><div class="px l pt pu pv pr pw ks pi"/></div></div></a></div><div class="pf pg gp gr ph pi"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd iu gy z fp pn fr fs po fu fw is bi translated">sk learn . ensemble . voting classifier</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">使用sk learn . ensemble . voting classifier的示例:绘制由VotingClassifier Plot计算的类概率…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">scikit-learn.org</p></div></div><div class="pr l"><div class="py l pt pu pv pr pw ks pi"/></div></div></a></div></div></div>    
</body>
</html>