<html>
<head>
<title>The Complete Guide to Time Series Forecasting Using Sklearn, Pandas, and Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Sklearn、Pandas和Numpy进行时间序列预测的完整指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-complete-guide-to-time-series-forecasting-using-sklearn-pandas-and-numpy-7694c90e45c1#2022-09-01">https://towardsdatascience.com/the-complete-guide-to-time-series-forecasting-using-sklearn-pandas-and-numpy-7694c90e45c1#2022-09-01</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><div class=""/><div class=""><h2 id="59bd" class="pw-subtitle-paragraph js iu iv bd b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj dk translated">在Python中使用任何scikit-learn模型进行时间序列预测的实践教程和框架</h2></div><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi kk"><img src="../Images/098817154456f673a9701e9cade7f619.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*quj079IBqD1qsda6"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated"><a class="ae la" href="https://unsplash.com/@stanyw?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">王禹</a>在<a class="ae la" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><h1 id="0430" class="lb lc iv bd ld le lf lg lh li lj lk ll kb lm kc ln ke lo kf lp kh lq ki lr ls bi translated">介绍</h1><p id="8fe1" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">时间序列预测有很多所谓的<em class="mp">传统</em>模型，比如<a class="ae la" href="https://www.datasciencewithmarco.com/blog/time-series-forecasting-with-sarima-in-python" rel="noopener ugc nofollow" target="_blank"> SARIMAX </a>系列模型、<a class="ae la" href="https://www.datasciencewithmarco.com/offers/G6ULNc7n" rel="noopener ugc nofollow" target="_blank">指数平滑</a>，或者<a class="ae la" href="https://www.datasciencewithmarco.com/blog/how-to-forecast-time-series-with-multiple-seasonalities" rel="noopener ugc nofollow" target="_blank"> BATS和TBATS </a>。</p><p id="f130" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">然而，我们很少提到最常见的回归机器学习模型，如决策树，随机森林，梯度推进，甚至支持向量回归机。我们看到这些模型广泛应用于典型的回归问题，但不是时间序列预测。</p><p id="7158" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">因此写这篇文章的原因！在这里，我们设计了一个框架，将一个时间序列问题框定为一个监督学习问题，允许我们从我们最喜欢的库中使用任何我们想要的模型:<em class="mp"> scikit-learn </em>！</p><p id="22a1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">到本文结束时，您将拥有将任何机器学习模型与上述统计模型一起应用于时间序列预测的工具和知识。</p><p id="b7e6" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们开始吧！</p><p id="5e59" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">完整的源代码可以在<a class="ae la" href="https://github.com/marcopeix/datasciencewithmarco/blob/master/sklearn_time_series.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。</p><blockquote class="mv"><p id="767a" class="mw mx iv bd my mz na nb nc nd ne mo dk translated"><strong class="ak"> <em class="nf">用我的</em> </strong> <a class="ae la" href="https://www.datasciencewithmarco.com/pl/2147608294" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> <em class="nf">免费时间序列小抄</em> </strong> </a> <strong class="ak"> <em class="nf">在Python中学习最新的时间序列分析技巧！获得统计和深度学习技术的实现，全部在Python和TensorFlow中！</em>T29】</strong></p></blockquote><h1 id="b7b3" class="lb lc iv bd ld le lf lg lh li lj lk ll kb ng kc ln ke nh kf lp kh ni ki lr ls bi translated">准备数据集</h1><p id="24e5" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">首先，我们导入完成教程所需的所有库。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="2e10" class="no lc iv nk b gy np nq l nr ns">import numpy as np<br/>import pandas as pd<br/>import statsmodels.api as sm<br/>import matplotlib.pyplot as plt</span></pre><p id="35d0" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这里，我们使用<em class="mp"> statsmodels </em>库来导入数据集，这是从1958年到2001年的每周CO2浓度。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="0c26" class="no lc iv nk b gy np nq l nr ns">data = sm.datasets.co2.load_pandas().data</span></pre><p id="4b24" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">一个好的第一步是用下面的代码块可视化我们的数据。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="59fb" class="no lc iv nk b gy np nq l nr ns">fig, ax = plt.subplots(figsize=(16, 11))</span><span id="e27a" class="no lc iv nk b gy nt nq l nr ns">ax.plot(data['co2'])<br/>ax.set_xlabel('Time')<br/>ax.set_ylabel('CO2 concentration (ppmw)')</span><span id="5b55" class="no lc iv nk b gy nt nq l nr ns">fig.autofmt_xdate()<br/>plt.tight_layout()</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi nu"><img src="../Images/9946243fcbf2d45770e1b88199a5b797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AYNeAI8Zbl18rcgRv3x_5w.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">1958年至2001年的周CO2浓度(ppmv)。我们注意到，由于季节的原因，数据中存在明显的年度季节性(冬季的CO2浓度高于夏季)。还有一个明显的积极趋势，我们注意到数据集开始时有一些缺失的数据。图片由作者提供。</p></figure><p id="8a61" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">从上图中，我们注意到数据中明显的积极趋势，因为浓度随着时间的推移而增加。我们还观察到一种年度季节性模式。这是由于季节的变化，冬季的CO2浓度高于夏季。最后，我们在数据集的开头看到一些缺失的数据。</p><p id="be82" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">然后，让我们用插值法处理缺失的数据。我们将简单地在两个已知点之间进行线性插值来填充缺失值。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="deba" class="no lc iv nk b gy np nq l nr ns">data = data.interpolate()</span></pre><p id="ec24" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">既然我们没有丢失数据，我们就可以开始建模了！</p><h1 id="caca" class="lb lc iv bd ld le lf lg lh li lj lk ll kb lm kc ln ke lo kf lp kh lq ki lr ls bi translated">使用scikit建模-学习</h1><p id="f52f" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">正如您将看到的，用scikit-learn预测时间序列的最大挑战是正确设置问题。</p><p id="8a98" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">有3种不同的方法可以将时间序列预测问题构建为监督学习问题:</p><ol class=""><li id="c429" class="nv nw iv lv b lw mq lz mr mc nx mg ny mk nz mo oa ob oc od bi translated">使用之前的观察预测下一个时间步</li><li id="29ba" class="nv nw iv lv b lw oe lz of mc og mg oh mk oi mo oa ob oc od bi translated">使用一系列过去的观察结果预测下一个时间步</li><li id="2d3c" class="nv nw iv lv b lw oe lz of mc og mg oh mk oi mo oa ob oc od bi translated">使用一系列过去的观测值预测一系列未来的时间步长</li></ol><p id="9992" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">让我们详细探讨每种情况！</p><h2 id="1229" class="no lc iv bd ld oj ok dn lh ol om dp ll mc on oo ln mg op oq lp mk or os lr ot bi translated">使用之前的观察预测下一个时间步</h2><p id="4fc3" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">这是最基本的设置。该模型输出下一个时间步长的预测，仅给出前一个观察值，如下图所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/693143ded3f467d59ffd1db9b4a07e6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*Nx9RF_NDs73X68qaLfIESQ.jpeg"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">根据前面的观察，模型被训练来预测下一个时间步。图片由作者提供。</p></figure><p id="d1cb" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这是一个几乎没有实际应用的简单用例，因为一个模型很可能不会仅仅从之前的观察中<em class="mp">学到</em>任何东西。然而，它可以作为一个很好的起点，帮助我们理解后面更复杂的场景。</p><p id="7334" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">现在，我们的数据集看起来像这样:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/07af37657d66a5c2d29dd54ed112750e.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*ExxHzc7lNkRcqgoVXSCS6w.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">作者图片</p></figure><p id="cf57" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这不是很有用。没错，所有的值都在一列中，但是我们需要格式化数据集，使得当前观察值是预测下一个观察值(目标)的特征。</p><p id="1a55" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">因此，我们添加了第二列，该列简单地移动了<em class="mp"> co2 </em>列，使得1958–03–29的值现在是1958–04–05的值的预测值。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="37e3" class="no lc iv nk b gy np nq l nr ns">df = data.copy()</span><span id="b3e0" class="no lc iv nk b gy nt nq l nr ns">df['y'] = df['co2'].shift(-1)</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c299f90373aae3006eb96d3b12b9d310.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*raTVjPX--2pooXiTF_gUYQ.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">数据集没有被格式化为监督学习问题，其中当前观察是特征，下一个观察是目标。图片由作者提供。</p></figure><p id="5274" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">正如您所看到的，我们的数据集现在已经格式化，因此每个当前观察都是下一个观察的预测值！请注意，我们的数据集末尾缺少一个值。这对于最后已知的观察来说是正常的。我们将在以后的步骤中删除该行。</p><p id="acfa" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">现在，让我们将数据集分成训练集和测试集，以便运行我们的模型并对它们进行评估。这里，我们使用最近两年的数据作为训练集。由于我们有每周数据，并且一年有52周，这意味着最后104个样本被保留用于测试集。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="f425" class="no lc iv nk b gy np nq l nr ns">train = df[:-104]<br/>test = df[-104:]<br/>test = test.drop(test.tail(1).index) # Drop last row</span></pre><p id="e6c9" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">基线模型</strong></p><p id="5c35" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">当然，我们需要一个基线模型来确定使用机器学习模型是否更好。这里，我们天真地预测下一个观察值将与当前观察值相同。</p><p id="ef50" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">换句话说，我们简单地将<em class="mp"> co2 </em>列设定为我们的基线预测。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="b3c2" class="no lc iv nk b gy np nq l nr ns">test = test.copy()<br/>test['baseline_pred'] = test['co2']</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi ox"><img src="../Images/95c52a963639d3935e7393343cddfcf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*GpkRuidcfZSoNabY-37hnA.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">基线预测只是简单地重复未来已知的观察。图片由作者提供。</p></figure><p id="dfe7" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">太好了！完成这一步后，让我们继续更复杂的模型。</p><p id="a404" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">决策树</strong></p><p id="76e5" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这里，让我们应用一个决策树回归器。这个模型可以被scikit-learn库中您想要的任何模型替换！请注意，我们使用随机状态来确保可重复性。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="8d51" class="no lc iv nk b gy np nq l nr ns">from sklearn.tree import DecisionTreeRegressor</span><span id="4fdc" class="no lc iv nk b gy nt nq l nr ns">X_train = train['co2'].values.reshape(-1,1)<br/>y_train = train['y'].values.reshape(-1,1)<br/>X_test = test['co2'].values.reshape(-1,1)</span><span id="3199" class="no lc iv nk b gy nt nq l nr ns"># Initialize the model<br/>dt_reg = DecisionTreeRegressor(random_state=42)</span><span id="8f13" class="no lc iv nk b gy nt nq l nr ns"># Fit the model<br/>dt_reg.fit(X=X_train, y=y_train)</span><span id="13cc" class="no lc iv nk b gy nt nq l nr ns"># Make predictions<br/>dt_pred = dt_reg.predict(X_test)</span><span id="4689" class="no lc iv nk b gy nt nq l nr ns"># Assign predictions to a new column in test<br/>test['dt_pred'] = dt_pred</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/1dbe5cbad14b3a65d320468861d8645f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*HMdmHmF0RgplCS7fflBEGQ.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">测试集现在有来自决策树模型的预测！图片由作者提供。</p></figure><p id="02fd" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">注意，我们保持建模部分简单。我们不执行任何交叉验证或超参数调整，尽管这些技术可以正常应用于此，就像在任何其他回归问题中一样。</p><p id="49b7" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">随意运用这些技巧，看看你是否能得到更好的表现。</p><p id="3c79" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">梯度增强</strong></p><p id="3093" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">为了尝试不同的模型，让我们现在应用梯度推进。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="d699" class="no lc iv nk b gy np nq l nr ns">from sklearn.ensemble import GradientBoostingRegressor</span><span id="d4f9" class="no lc iv nk b gy nt nq l nr ns">gbr = GradientBoostingRegressor(random_state=42)</span><span id="77cb" class="no lc iv nk b gy nt nq l nr ns">gbr.fit(X_train, y=y_train.ravel())</span><span id="75d9" class="no lc iv nk b gy nt nq l nr ns">gbr_pred = gbr.predict(X_test)</span><span id="dd77" class="no lc iv nk b gy nt nq l nr ns">test['gbr_pred'] = gbr_pred</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi oz"><img src="../Images/b45e54666046e16672c1154175c45da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8kDUDhGaywgk8wmip9RdA.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">测试集现在具有来自梯度推进模型的预测。图片由作者提供。</p></figure><p id="80c4" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">太好了！我们现在有了来自两个机器学习模型和一个基线的预测。是时候评估每种方法的性能了。</p><p id="9f17" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">评估</strong></p><p id="50eb" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这里，我们使用平均绝对百分比误差(MAPE)。这是一个特别有用误差指标，因为它返回一个百分比，很容易解释。确保只在没有接近0的值时应用它，这里就是这种情况。</p><p id="de65" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">不幸的是，MAPE还没有在<em class="mp"> scikit-learn </em>中实现，所以我们必须手工定义这个函数。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="2cf8" class="no lc iv nk b gy np nq l nr ns">def mape(y_true, y_pred):<br/>    return round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)</span></pre><p id="0970" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">然后，我们可以评估每个模型，并生成以下条形图:</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="ac64" class="no lc iv nk b gy np nq l nr ns">baseline_mape = mape(test['y'], test['baseline_pred'])<br/>dt_mape = mape(test['y'], test['dt_pred'])<br/>gbr_mape = mape(test['co2'], test['gbr_pred'])</span><span id="c592" class="no lc iv nk b gy nt nq l nr ns"># Generate bar plot<br/>fig, ax = plt.subplots(figsize=(7, 5))</span><span id="d4b6" class="no lc iv nk b gy nt nq l nr ns">x = ['Baseline', 'Decision Tree', 'Gradient Boosting']<br/>y = [baseline_mape, dt_mape, gbr_mape]</span><span id="86d4" class="no lc iv nk b gy nt nq l nr ns">ax.bar(x, y, width=0.4)<br/>ax.set_xlabel('Regressor models')<br/>ax.set_ylabel('MAPE (%)')<br/>ax.set_ylim(0, 0.3)</span><span id="29c5" class="no lc iv nk b gy nt nq l nr ns">for index, value in enumerate(y):<br/>    plt.text(x=index, y=value + 0.02, s=str(value), ha='center')<br/>    <br/>plt.tight_layout()</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/77e7a5f1503edec4676ea950318c8601.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*kRhvXq3YvBCyYDZxpQsJWQ.png"/></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">每种预测方法的MAPE。这里，基线提供了最佳性能，因为它具有最低的MAPE。图片由作者提供。</p></figure><p id="6cf9" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">看上面的图，我们看到基线具有最好的性能，因为它具有最低的MAPE。这是有道理的，因为二氧化碳浓度似乎不会从一周到另一周发生剧烈变化。</p><p id="02a2" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">在这种情况下，使用机器学习模型并没有给我们带来任何附加值。同样，这可能是因为模型仅从一个观察中学习来做出预测。最好给它一个序列作为输入，以便预测下一个时间步。</p><p id="5fa1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这就把我们带到了下一个场景！</p><h2 id="adc0" class="no lc iv bd ld oj ok dn lh ol om dp ll mc on oo ln mg op oq lp mk or os lr ot bi translated">使用一系列过去的观察结果预测下一个时间步</h2><p id="25a1" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">正如我们在前面的例子中所看到的，使用单个观察值来预测下一个时间步并不是很好。现在，让我们尝试使用一个序列作为模型的输入，并预测下一个时间步，如下所示</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pb"><img src="../Images/0021d64d5ebd64273ca202026b3becc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rQKLFiAwfGTTefrYiDcXtg.jpeg"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">采用输入序列预测下一时间步的模型的模式。图片由作者提供。</p></figure><p id="4ad3" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">同样，我们必须格式化我们的数据集，以便我们有一系列过去的观察值作为下一个时间步的预测值。</p><p id="28c9" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们可以很容易地编写一个函数，通过添加移位的列来获得所需的输入长度。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="8e63" class="no lc iv nk b gy np nq l nr ns">def window_input(window_length: int, data: pd.DataFrame) -&gt; pd.DataFrame:<br/>    <br/>    df = data.copy()<br/>    <br/>    i = 1<br/>    while i &lt; window_length:<br/>        df[f'x_{i}'] = df['co2'].shift(-i)<br/>        i = i + 1<br/>        <br/>    if i == window_length:<br/>        df['y'] = df['co2'].shift(-i)<br/>        <br/>    # Drop rows where there is a NaN<br/>    df = df.dropna(axis=0)<br/>        <br/>    return df</span></pre><p id="6df6" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">让我们使用这个函数输入5个观测值，以便预测下一个时间步。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="9973" class="no lc iv nk b gy np nq l nr ns">new_df = window_input(5, data)</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pc"><img src="../Images/8487c5cf88a62cda779bac98a53e21a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfvfgr2SSxFmCXmZSvMRMg.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">结果数据集。如你所见，我们现在有5个观测值作为下一个时间步的预测值。图片由作者提供。</p></figure><p id="5a95" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">查看上图，我们可以看到我们的数据集以这样的方式排列，我们有五个观察值来预测下一个时间步，存储在<em class="mp"> y </em>列中。</p><p id="3636" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这基本上解决了最难的部分！现在，简单的问题是应用不同的模型，看看哪个表现最好。</p><p id="71e1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">在进入这一步之前，让我们首先将数据分为训练集和测试集。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="6998" class="no lc iv nk b gy np nq l nr ns">from sklearn.model_selection import train_test_split<br/><br/>X = new_df[['co2', 'x_1', 'x_2', 'x_3', 'x_4']].values<br/>y = new_df['y'].values<br/><br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)</span></pre><p id="5083" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">基线模型</strong></p><p id="f157" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">同样，让我们为这种情况定义一个基线模型。这里，我们将简单地预测输入序列的平均值</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="d1fc" class="no lc iv nk b gy np nq l nr ns">baseline_pred = []<br/><br/>for row in X_test:<br/>    baseline_pred.append(np.mean(row))</span></pre><p id="9d60" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">决策树</strong></p><p id="63b6" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">同样，让我们应用决策树回归器。这与前面的实现一样简单。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="81ca" class="no lc iv nk b gy np nq l nr ns">dt_reg_5 = DecisionTreeRegressor(random_state=42)<br/><br/>dt_reg_5.fit(X_train, y_train)<br/><br/>dt_reg_5_pred = dt_reg_5.predict(X_test)</span></pre><p id="b838" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">梯度增强</strong></p><p id="88af" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">为了保持一致，我们也来试试梯度提升。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="18f8" class="no lc iv nk b gy np nq l nr ns">gbr_5 = GradientBoostingRegressor(random_state=42)<br/><br/>gbr_5.fit(X_train, y_train.ravel())<br/><br/>gbr_5_pred = gbr_5.predict(X_test)</span></pre><p id="7ec6" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">评估</strong></p><p id="f4f7" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们现在可以评估每个模型的性能。同样，我们使用MAPE并将结果绘制在柱状图中。这基本上是和以前一样的代码。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="9741" class="no lc iv nk b gy np nq l nr ns">baseline_mape = mape(y_test, baseline_pred)<br/>dt_5_mape = mape(y_test, dt_reg_5_pred)<br/>gbr_5_mape = mape(y_test, gbr_5_pred)</span><span id="6c91" class="no lc iv nk b gy nt nq l nr ns"># Generate the bar plot</span><span id="9c4d" class="no lc iv nk b gy nt nq l nr ns">fig, ax = plt.subplots()<br/><br/>x = ['Baseline', 'Decision Tree', 'Gradient Boosting']<br/>y = [baseline_mape, dt_5_mape, gbr_5_mape]<br/><br/>ax.bar(x, y, width=0.4)<br/>ax.set_xlabel('Regressor models')<br/>ax.set_ylabel('MAPE (%)')<br/>ax.set_ylim(0, 2.5)<br/><br/>for index, value in enumerate(y):<br/>    plt.text(x=index, y=value + 0.1, s=str(value), ha='center')<br/>    <br/>plt.tight_layout()</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pd"><img src="../Images/fad02fc909c775538915819c6e2d1a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ag-Hymdi_6MgqUrmfQRYWQ.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">MAPE针对不同的预测方法使用五个观测值来预测下一个时间步。同样，机器学习模型并没有超越基线。图片由作者提供。</p></figure><p id="21f9" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">令人惊讶的是，从上图中，我们看到机器学习模型并没有超越基线。</p><p id="e4cb" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">虽然超参数调整可能会提高ML模型的性能，但我怀疑输入窗口太短。五周的输入不足以让模型获得趋势和季节性成分，因此我们可能需要更长的时间窗口。</p><p id="6f8b" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们将在下一个场景中尝试这样做！</p><h2 id="60e9" class="no lc iv bd ld oj ok dn lh ol om dp ll mc on oo ln mg op oq lp mk or os lr ot bi translated">使用一系列过去的观测值预测一系列未来的时间步长</h2><p id="06bc" class="pw-post-body-paragraph lt lu iv lv b lw lx jw ly lz ma jz mb mc md me mf mg mh mi mj mk ml mm mn mo io bi translated">最后一个场景是使用一系列观察值来预测一系列未来的时间步长，如下所示。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pe"><img src="../Images/ce911d67a6df7bd6a194a2e4204fa4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjP58CRMpXIH_jpxk8yYVQ.jpeg"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">采用输入序列并预测未来时间步长序列的模型架构。图片由作者提供。</p></figure><p id="a569" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这里，我们的模型需要输出一系列预测。这可以看作是一个多输出回归问题。</p><p id="a5db" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">因此，第一步是适当地格式化我们的数据集。我们开发了另一个函数，它使用<em class="mp"> shift </em>方法将数据集格式化为多输出回归问题。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="dc2a" class="no lc iv nk b gy np nq l nr ns">def window_input_output(input_length: int, output_length: int, data: pd.DataFrame) -&gt; pd.DataFrame:<br/>    <br/>    df = data.copy()<br/>    <br/>    i = 1<br/>    while i &lt; input_length:<br/>        df[f'x_{i}'] = df['co2'].shift(-i)<br/>        i = i + 1<br/>        <br/>    j = 0<br/>    while j &lt; output_length:<br/>        df[f'y_{j}'] = df['co2'].shift(-output_length-j)<br/>        j = j + 1<br/>        <br/>    df = df.dropna(axis=0)<br/>    <br/>    return df</span></pre><p id="85c4" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这里，我们将使用26个观测值的序列来预测接下来的26个时间步。换句话说，我们输入半年来预测下半年。注意，输入和输出序列不需要具有相同的长度。这是我的一个武断的决定。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="1fe9" class="no lc iv nk b gy np nq l nr ns">seq_df = window_input_output(26, 26, data)</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pf"><img src="../Images/2e77186633396ab3dcd1dc004b11d6d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3MOuEqJr9Ev0dyFrJNoaGw.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">数据集未格式化，因此26个观察值是接下来26个时间步的预测值。图片由作者提供。</p></figure><p id="dc4d" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">如您所见，我们现在有一个数据集，其中26个观测值用作接下来26个时间步长的预测值。</p><p id="d883" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">在继续建模之前，我们再次将数据分为训练集和测试集。这里，我们为测试集保留最后两行，因为它给了我们52个测试样本。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="44e6" class="no lc iv nk b gy np nq l nr ns">X_cols = [col for col in seq_df.columns if col.startswith('x')]<br/><br/>X_cols.insert(0, 'co2')<br/><br/>y_cols = [col for col in seq_df.columns if col.startswith('y')]</span><span id="ef65" class="no lc iv nk b gy nt nq l nr ns">X_train = seq_df[X_cols][:-2].values<br/>y_train = seq_df[y_cols][:-2].values<br/><br/>X_test = seq_df[X_cols][-2:].values<br/>y_test = seq_df[y_cols][-2:].values</span></pre><p id="6b91" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">基线模型</strong></p><p id="f22b" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">作为基线模型，我们将简单地重复输入序列。换句话说，我们获取输入序列并输出与基线预测相同的序列。</p><p id="0273" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这是一个非常琐碎的预测，所以我们将在准备评估模型时实现它。</p><p id="219f" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">决策树</strong></p><p id="8841" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">同样，让我们尝试应用决策树。注意，决策树可以产生多输出预测，所以我们不需要在这里做任何额外的工作。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="0992" class="no lc iv nk b gy np nq l nr ns">dt_seq = DecisionTreeRegressor(random_state=42)<br/><br/>dt_seq.fit(X_train, y_train)<br/><br/>dt_seq_preds = dt_seq.predict(X_test)</span></pre><p id="89c8" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">梯度推进</strong></p><p id="9ce1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">现在，梯度推进需要一点额外的工作。它不能处理多输出目标。试图立即拟合梯度增强模型将导致错误。</p><p id="72e0" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">在这里，我们必须包装模型，以便它的预测被用作下一个预测的输入。这是通过使用来自<em class="mp"> scikit-learn </em>的<em class="mp">回归链</em>包装器实现的。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="fd81" class="no lc iv nk b gy np nq l nr ns">from sklearn.multioutput import RegressorChain<br/><br/>gbr_seq = GradientBoostingRegressor(random_state=42)<br/><br/>chained_gbr = RegressorChain(gbr_seq)<br/><br/>chained_gbr.fit(X_train, y_train)<br/><br/>gbr_seq_preds = chained_gbr.predict(X_test)</span></pre><p id="ed93" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">这允许训练模型并进行预测，而不会遇到任何错误。正如我提到的，在幕后，模型预测下一个时间步，并使用该预测进行下一次预测。这种方法的缺点是，如果第一个预测是坏的，那么序列的其余部分很可能也是坏的。</p><p id="8f7e" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">现在我们来评价一下每一款。</p><p id="d373" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated"><strong class="lv iw">评估</strong></p><p id="35da" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">同样，我们使用MAPE来评估我们的预测方法。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="b38c" class="no lc iv nk b gy np nq l nr ns">mape_dt_seq = mape(dt_seq_preds.reshape(1, -1), y_test.reshape(1, -1))<br/>mape_gbr_seq = mape(gbr_seq_preds.reshape(1, -1), y_test.reshape(1, -1))<br/>mape_baseline = mape(X_test.reshape(1, -1), y_test.reshape(1, -1))</span><span id="fd4b" class="no lc iv nk b gy nt nq l nr ns"># Generate the bar plot</span><span id="1b6c" class="no lc iv nk b gy nt nq l nr ns">fig, ax = plt.subplots()<br/><br/>x = ['Baseline', 'Decision Tree', 'Gradient Boosting']<br/>y = [mape_baseline, mape_dt_seq, mape_gbr_seq]<br/><br/>ax.bar(x, y, width=0.4)<br/>ax.set_xlabel('Regressor models')<br/>ax.set_ylabel('MAPE (%)')<br/>ax.set_ylim(0, 1)<br/><br/>for index, value in enumerate(y):<br/>    plt.text(x=index, y=value + 0.05, s=str(value), ha='center')<br/>    <br/>plt.tight_layout()</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi pg"><img src="../Images/31ac1e26ed758f6d0fcc460c089647c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WHc1DyFoaTlY8vNv7YDwTQ.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">所有多输出回归模型的MAPE。这里，ML模型优于基线，决策树是最好的模型。图片由作者提供。</p></figure><p id="1be1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">从上图可以看出，我们终于成功训练出了跑赢基线的ML模型！在这里，决策树模型是冠军模型，因为它实现了最低的MAPE。</p><p id="6ea4" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们可以选择将去年的预测可视化。</p><pre class="kl km kn ko gt nj nk nl nm aw nn bi"><span id="120e" class="no lc iv nk b gy np nq l nr ns">fig, ax = plt.subplots(figsize=(16, 11))</span><span id="5e66" class="no lc iv nk b gy nt nq l nr ns">ax.plot(np.arange(0, 26, 1), X_test[1], 'b-', label='input')<br/>ax.plot(np.arange(26, 52, 1), y_test[1], marker='.', color='blue', label='Actual')<br/>ax.plot(np.arange(26, 52, 1), X_test[1], marker='o', color='red', label='Baseline')<br/>ax.plot(np.arange(26, 52, 1), dt_seq_preds[1], marker='^', color='green', label='Decision Tree')<br/>ax.plot(np.arange(26, 52, 1), gbr_seq_preds[1], marker='P', color='black', label='Gradient Boosting')</span><span id="34f0" class="no lc iv nk b gy nt nq l nr ns">ax.set_xlabel('Timesteps')<br/>ax.set_ylabel('CO2 concentration (ppmv)')</span><span id="ec77" class="no lc iv nk b gy nt nq l nr ns">plt.xticks(np.arange(1, 104, 52), np.arange(2000, 2002, 1))<br/>plt.legend(loc=2)</span><span id="f586" class="no lc iv nk b gy nt nq l nr ns">fig.autofmt_xdate()<br/>plt.tight_layout()</span></pre><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="gh gi nu"><img src="../Images/5fd9bd8407c409fffeee1d9321c0cbaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRqOxb_KEUhV7-4GHWcuXg.png"/></div></div><p class="kw kx gj gh gi ky kz bd b be z dk translated">可视化去年每个模型的预测。显然，基线偏离得很远，而决策树和梯度推进更接近实际值。图片由作者提供。</p></figure><p id="861a" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">进一步支持MAPE，我们可以看到决策树和梯度推进比基线预测更接近实际值。</p></div><div class="ab cl ph pi hz pj" role="separator"><span class="pk bw bk pl pm pn"/><span class="pk bw bk pl pm pn"/><span class="pk bw bk pl pm"/></div><div class="io ip iq ir is"><p id="5668" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">在本文中，我们看到了如何将时间序列预测问题构建为一个回归问题，可以使用<em class="mp"> scikit-learn </em>回归模型来解决该问题。</p><p id="01d1" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们探讨了以下场景:</p><ol class=""><li id="e94c" class="nv nw iv lv b lw mq lz mr mc nx mg ny mk nz mo oa ob oc od bi translated">使用之前的观察预测下一个时间步</li><li id="c2a1" class="nv nw iv lv b lw oe lz of mc og mg oh mk oi mo oa ob oc od bi translated">使用一系列过去的观察结果预测下一个时间步</li><li id="237b" class="nv nw iv lv b lw oe lz of mc og mg oh mk oi mo oa ob oc od bi translated">使用一系列过去的观测值预测一系列未来的时间步长</li></ol><p id="0734" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我们现在有了一个框架，可以将任何时间序列预测问题构建为一个监督学习问题，在这个框架中，您可以应用来自<em class="mp"> scikit-learn </em>的任何回归模型。</p><p id="d751" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">我希望这篇文章对你有用！</p><p id="ab05" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">一定要下载我用Python写的<a class="ae la" href="https://www.datasciencewithmarco.com/pl/2147608294" rel="noopener ugc nofollow" target="_blank">免费时间序列预测小抄</a>，涵盖统计和深度学习模型！</p><p id="65c9" class="pw-post-body-paragraph lt lu iv lv b lw mq jw ly lz mr jz mb mc ms me mf mg mt mi mj mk mu mm mn mo io bi translated">干杯！🍺</p></div></div>    
</body>
</html>