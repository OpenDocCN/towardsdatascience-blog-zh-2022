<html>
<head>
<title>Are the OLS Estimators Normally Distributed in a Linear Regression Model?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在线性回归模型中，OLS 估计量是正态分布的吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/are-ols-estimators-normally-distributed-in-a-linear-regression-model-89b688fa8dc3#2022-11-29">https://towardsdatascience.com/are-ols-estimators-normally-distributed-in-a-linear-regression-model-89b688fa8dc3#2022-11-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="640d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">OLS 估计量的分布是什么？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6ccb9afc2c98a51d45d6ca7fedb12918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y1Q-wfG-IsLefBIa"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马丁·桑切斯在<a class="ae ky" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="12e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们都知道，在线性回归模型中，正态假设对于计算无偏估计是可选的。在本帖中，我们将讨论线性回归模型中的 OLS 估计量是否是正态分布的，以及需要什么样的假设才能得出结论。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="4e17" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">线性回归模型中的 OLS 估计量是什么？</h2><p id="c312" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">OLS 估计量(β^)是根据样本计算的，用于估计线性回归模型中的总体参数(β)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/7838a952405ce0d1d258a2a422c2d0ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1B3w_KR6XhXzgw0N.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="33e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">OLS 估值器是具有概率分布的<strong class="lb iu">随机变量</strong>(即，OLS 估值器的<strong class="lb iu">采样分布</strong>)。抽样分布描述了<strong class="lb iu">个可能值</strong>，OLS 估计器可以在不同的样本中采用这些值。</p><p id="ab29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道，对于给定的样本，OLS 估计量可以用封闭形式的解来求解。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/665a5ca10cbe3c67f6b5939285e665b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dhS5swKuqW9xR_jc.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nb nc nd"><p id="b263" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">我们可以这样想，很可能 Y 在不同的样本中取不同的值。因此，OLS 估计量(β^)随着响应值(y)而变化。</p></blockquote><p id="49ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">借助一点数学知识，我们可以计算 OLS 估计量的均值和方差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/cb05a7f70710ebff680b731ac17cfb31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8jVKaaZ97TzxnIWrQfiYGg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="3699" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"> <strong class="lb iu">此外，我们期望 OLS 估计量具有以下性质</strong>，</a></p><ul class=""><li id="1a63" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated">OLS 估计量是<strong class="lb iu">无偏的</strong>:OLS 估计量的期望值等于真实的总体参数值。</li><li id="9cda" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">OLS 估计量是<strong class="lb iu">一致的:</strong>随着样本量的增加，OLS 估计量<strong class="lb iu">收敛</strong>到真实的总体参数值。</li><li id="b9bb" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">OLS 估计量是蓝色的(所有线性无偏估计量中方差最小的)。因此，它们是<strong class="lb iu">最佳</strong> ( <strong class="lb iu">高效</strong>)估计器。</li></ul></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="eafa" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">如何估计线性回归模型中 OLS 估计量的方差？</h2><p id="b034" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">在 OLS 估计量的方差公式中，<strong class="lb iu"> σ2 是误差项</strong>的方差，它是总体模型中的一个<strong class="lb iu">未知</strong>参数。我们通常使用样本数据中的<strong class="lb iu">残差</strong>来估计这个值。</p><p id="bf3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">S2(又名均方差、MSE 或剩余方差)是误差(σ2)方差的<strong class="lb iu">无偏估计量</strong>。S2 可以用下面的公式计算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cab758054157ac693ed22ae07182c2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pz-TCTsFOGMuNn3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nb nc nd"><p id="7253" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">因此，如果我们建立一个更精确的线性回归模型，残差往往更接近于 0，MSE (S2)往往更小，OLS 估计量的抽样分布的方差也更小，那么我们最终会有更精确的 OLS 估计量(即，更紧密的置信区间)。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="73de" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">假设 OLS 估计量在线性回归模型中呈正态分布的动机是什么？</h2><p id="9f2a" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">此时，我们还没有在线性回归模型中做任何正态性假设。我们只知道 OLS 估计量是随机变量，以及如何计算它们的均值和方差。</p><p id="ea67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也知道正态假设是<strong class="lb iu">而不是</strong>计算<strong class="lb iu">无偏、一致、蓝 OLS 估计量</strong>所必需的。那我们为什么要假设 OLS 估计量在线性回归模型中是正态分布的呢？</p><p id="2d08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">答案很简单。我们永远无法从样本数据中估计出真正的流行参数。我们的估计永远不会准确。OLS 估计量的正态假设允许我们计算假设检验的 p 值并构造可靠的置信区间。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="60ec" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">为什么在线性回归模型中假设 OLS 估计量呈正态分布是合理的？</h2><p id="e384" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">我们通常假设线性回归模型中的误差项是正态分布的。那么它意味着 OLS 估计量也是正态分布的。我们很容易证明这一点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7d9774d36266cd37401d2c35c17e4d18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D-mZWSt72b5gMwah.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在上面的方程中，我们已经表明 OLS 估计量是误差项的线性组合。因此，正态性假设(即误差是正态分布的)意味着 OLS 估计量是正态分布的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/5ab2b85f566cc169c98e37217317c6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I9-pAtod9ABmf0Qd.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><blockquote class="nb nc nd"><p id="e217" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">如果样本量足够大，我们不需要假设误差项是正态分布的。因为当<strong class="lb iu">样本量足够大</strong>时，<strong class="lb iu">中心极限定理</strong>开始起作用，并证明 OLS 估值器由多元正态分布<strong class="lb iu">很好地逼近，而不管误差项的分布</strong>。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="bc97" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">如何计算线性回归模型中 OLS 估计量的置信区间？</h2><p id="a40a" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">从样本数据中，我们可以用 OLS 估计量来估计总体参数(β),用残差来估计 OLS 估计量的抽样分布的标准差(也称为标准误差)。如果我们假设 OLS 估计量是正态分布的，那么我们可以计算置信区间</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/36d27645ccf1cebcba3e3cb96aa36a24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EbfOyxi8kskk-JwyCZjRTA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="0395" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，95%置信区间表示我们 95%确信 CI 包含总体参数(βi)的真实值。换句话说，如果我们对许多不同的样本重复这个过程，95%的时间 CI 包含真实值。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="37bc" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">影响 OLS 估计量分布的因素是什么？</h2><p id="d149" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">首先，让我们用下面的格式重写 OLS 估计量的方差。你可以在这里找到它的推导<a class="ae ky" href="https://medium.com/analytics-vidhya/expectation-variance-of-ols-estimates-9acd2b48a635" rel="noopener">。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/11a60a1ff69b9c5c68348980013887fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s0UzoWbO4aFDIj0W1wHjWA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="5ee1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，样本大小在 OLS 估计量的分布中起着巨大的作用。随着样本量的增加，OLS 估计量的抽样分布将更接近正态分布，OLS 估计量的方差将更小，这意味着我们有更精确的 OLS 估计量。</p><blockquote class="nb nc nd"><p id="463f" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">换句话说，样本中的数据点越多，模型捕捉 X 和 Y 之间关系的能力就越强，OLS 估计值就越精确。</p></blockquote><p id="85c9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，随着 Xi 的方差增加，相应的 OLS 估计量的方差将减少。</p><blockquote class="nb nc nd"><p id="c5bc" class="kz la ne lb b lc ld ju le lf lg jx lh nf lj lk ll ng ln lo lp nh lr ls lt lu im bi translated">换句话说，解释可以提供的信息越多(即方差越大)，我们就可以更精确地估计参数的真实值。</p></blockquote></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="3f1a" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">结论</h2><p id="94d2" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">如果我们假设误差是正态分布的，或者样本量足够大，OLS 估计量的抽样分布将接近正态分布。</p><p id="d9b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">随着样本量的增加，我们期望 OLS 估计量的分布具有更小的方差。</p><p id="bd78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，随着 Xi 方差的增加，相应的 OLS 估计量的方差将趋于减少。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="9684" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想探索更多与<strong class="lb iu">统计</strong>相关的帖子，请查看我的文章:</p><ul class=""><li id="ce61" class="nj nk it lb b lc ld lf lg li nl lm nm lq nn lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/7-most-asked-questions-on-central-limit-theorem-82e95eb7d964"> <strong class="lb iu"> 7 关于中心极限定理的最常见问题</strong> </a></li><li id="9760" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/standard-deviation-vs-standard-error-whats-the-difference-ae969f48adef"> <strong class="lb iu">标准差 vs 标准误:有什么区别？</strong>T11】</a></li><li id="7a35" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/the-most-common-misinterpretations-hypothesis-testing-confidence-interval-p-value-4548a10a5b72"> <strong class="lb iu"> 3 种最常见的曲解:假设检验、置信区间、P 值</strong> </a></li><li id="8dae" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/are-the-error-terms-normally-distributed-in-a-linear-regression-model-15e6882298a4"> <strong class="lb iu">线性回归模型中误差项是否呈正态分布？</strong>T19】</a></li><li id="2fa3" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">线性回归模型中的 OLS 估计量是否正态分布？T3】</li><li id="c80f" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/machine-learning-bias-variance-tradeoff-and-regularization-94846f945131"> <strong class="lb iu">什么是正则化:偏差-方差权衡</strong> </a></li><li id="2cc3" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" href="https://medium.com/geekculture/variance-vs-covariance-vs-correlation-what-is-the-difference-95adff96d542" rel="noopener"> <strong class="lb iu">方差 vs 协方差 vs 相关性:有什么区别？</strong>T11】</a></li><li id="13cf" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/confidence-interval-vs-prediction-interval-what-is-the-difference-64c45146d47d"> <strong class="lb iu">置信区间 vs 预测区间:有什么区别？</strong>T15】</a></li><li id="bf51" class="nj nk it lb b lc ns lf nt li nu lm nv lq nw lu no np nq nr bi translated">I 型和 II 型错误哪个更糟糕？T19】</li></ul><h1 id="b734" class="oa md it bd me ob oc od mh oe of og mk jz oh ka mn kc oi kd mq kf oj kg mt ok bi translated">感谢您的阅读！！！</h1><p id="3c6e" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">如果你喜欢这篇文章，并且想<strong class="lb iu">请我喝杯咖啡，</strong>请<a class="ae ky" href="https://ko-fi.com/aaronzhu" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><p id="9e9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以注册一个<a class="ae ky" href="https://aaron-zhu.medium.com/membership" rel="noopener"> <strong class="lb iu">会员</strong> </a>来解锁我的文章的全部访问权限，并且可以无限制访问介质上的所有内容。如果你想在我发表新文章时收到电子邮件通知，请订阅。</p></div></div>    
</body>
</html>