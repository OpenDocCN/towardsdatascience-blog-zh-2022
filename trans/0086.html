<html>
<head>
<title>Key Learning Points from MLOps Specialization — Course 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MLOps专业化认证的关键学习点—课程3</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/key-learning-points-from-mlops-specialization-course-3-9e67558212ee#2022-02-03">https://towardsdatascience.com/key-learning-points-from-mlops-specialization-course-3-9e67558212ee#2022-02-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="329b" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">MLOPS专业化系列</h2><div class=""/><div class=""><h2 id="cbe2" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">DeepLearning的面向生产的机器学习工程(MLOps)课程的主要见解(含课堂讲稿)。艾&amp;吴恩达</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/89293edc0676ac4144cf0199a158fce8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_xwgJThtN_fulqc5"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">里卡多·戈麦斯·安吉尔在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="dce0" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">虽然机器学习(ML)和深度学习概念是必不可少的，但在用数据科学解决现实世界的问题时，拥有生产工程技能同样(如果不是更多)重要。</p><p id="1f93" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">深度学习。AI开发了<a class="ae lh" href="https://www.deeplearning.ai/program/machine-learning-engineering-for-production-mlops/" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> MLOps专业化课程</strong> </a>来分享在生产中构建和维护ML系统的实践经验。</p><p id="673d" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">在这篇文章中，我总结了经验教训，这样你就可以跳过几个小时的在线视频，同时仍然可以收集关键的见解。</p><h1 id="1228" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">内容</h1><blockquote class="mw mx my"><p id="614c" class="li lj mz lk b ll lm kd ln lo lp kg lq na ls lt lu nb lw lx ly nc ma mb mc md im bi translated"><strong class="lk jd"> <em class="it"> (1) </em> </strong> <a class="ae lh" href="#5555" rel="noopener ugc nofollow"> <em class="it">概述</em></a><em class="it"><br/></em><strong class="lk jd"><em class="it">(2)</em></strong><a class="ae lh" href="#0652" rel="noopener ugc nofollow"><em class="it">重点课</em></a><em class="it"><br/></em><strong class="lk jd"><em class="it">(3)</em></strong><a class="ae lh" href="#ffd1" rel="noopener ugc nofollow"><em class="it">讲义</em> </a></p></blockquote><p id="222c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated"><em class="mz">本文涵盖了</em> <strong class="lk jd"> <em class="mz"> 3 </em> </strong> <em class="mz">的</em><strong class="lk jd"><em class="mz">4-课程</em> </strong> <em class="mz">的MLOps专业化。</em> <a class="ae lh" href="https://kennethleungty.medium.com/" rel="noopener"> <em class="mz">跟随本页</em> </a> <em class="mz">了解后续课程的最新内容。</em></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="5555" class="me mf it bd mg mh nk mj mk ml nl mn mo ki nm kj mq kl nn km ms ko no kp mu mv bi translated">(1)概述</h1><p id="8910" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">在MLOps专业化的第三个课程中，我们重点关注为<strong class="lk jd">不同的服务环境</strong>构建模型，同时管理建模资源以实现最佳模型推断。</p><p id="6956" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">我们还探索了解决<strong class="lk jd">模型分析、公平性和可解释性</strong>的技术和指标。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi nu"><img src="../Images/02df9b824a8d19c4230014870451e4a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CFNRY1_zApYvjdUw"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated"><a class="ae lh" href="https://unsplash.com/@victor_g?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">维克多</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="0652" class="me mf it bd mg mh nk mj mk ml nl mn mo ki nm kj mq kl nn km ms ko no kp mu mv bi translated">(2)主要经验教训</h1><blockquote class="nv"><p id="2e69" class="nw nx it bd ny nz oa ob oc od oe md dk translated">第1部分——神经结构搜索</p></blockquote><h2 id="6beb" class="of mf it bd mg og oh dn mk oi oj dp mo lr ok ol mq lv om on ms lz oo op mu iz bi translated">什么是神经架构搜索？</h2><ul class=""><li id="1114" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">神经架构搜索(<strong class="lk jd"> NAS </strong> ) <strong class="lk jd">自动化</strong>神经网络<strong class="lk jd">架构</strong>的设计(例如，层数、激活类型和连接)</li><li id="5faf" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">这个概念类似于超参数调优，其目标是找到对数据表现良好的<strong class="lk jd">最优架构。</strong></li><li id="48fa" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">NAS是自动化机器学习的<strong class="lk jd">子领域</strong>(<strong class="lk jd">AutoML</strong>)。</li><li id="e4e8" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">用NAS设计的模型与手工制作的模型不相上下，甚至更好。</li><li id="9d93" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">我们可以使用像<a class="ae lh" href="https://www.tensorflow.org/tutorials/keras/keras_tuner" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> Keras Tuner </strong> </a>这样的库来运行NAS。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pe"><img src="../Images/e63a1cccd4eade4eb481da1e26722dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bewGNMWSSkbxxKHuweHMg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">神经结构搜索(NAS)概述|作者图片</p></figure><ul class=""><li id="9338" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">NAS有三个部分<strong class="lk jd"> : </strong>一个<strong class="lk jd">搜索空间</strong>，一个<strong class="lk jd">搜索策略</strong>，一个<strong class="lk jd">性能评估策略</strong>。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="d147" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">搜索空间</h2><ul class=""><li id="77a7" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">搜索空间定义了构建不同架构的可能组件。</li><li id="4a2c" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">有两种类型的架构搜索空间:<strong class="lk jd">宏观</strong>和<strong class="lk jd">微观</strong>。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pn"><img src="../Images/74fc73a59d034ae33dcf62641cbe8b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*odil6T0jTXeOVsaowbNodA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">两种主要类型的搜索空间|作者图片</p></figure><ul class=""><li id="fe3c" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated"><strong class="lk jd">宏</strong> <strong class="lk jd">搜索空间</strong>包括单个层(例如卷积、池化)和连接类型，通过顺序堆叠层以形成链式结构空间来找到最佳模型。</li><li id="24f0" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">相比之下，在<strong class="lk jd">微搜索</strong> <strong class="lk jd">空间</strong>中，NAS从细胞构建神经网络，其中每个细胞都是一个更小的神经网络。</li><li id="269e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">微观</strong>方法已被证明比宏观方法具有显著的性能优势。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="9e14" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">搜索策略</h2><ul class=""><li id="42ba" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">NAS基于<strong class="lk jd">特定策略</strong>在搜索空间中搜索，以找到要测试的架构，从而找到性能最佳的架构。</li><li id="9584" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">五种常用策略</strong>包括网格搜索、随机搜索、贝叶斯优化、进化算法和强化学习。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="2ea7" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">性能评估</h2><ul class=""><li id="b7f7" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">NAS依赖于测量它所尝试的不同体系结构的性能。</li><li id="3c0b" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">评估性能最直接的方法是评估每个架构的<strong class="lk jd">验证准确性</strong>。</li><li id="5457" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">然而，考虑到大的搜索空间和复杂的网络，计算验证准确性可能是计算量很大的。</li><li id="5dc3" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">降低计算成本的策略包括使用<strong class="lk jd">较低保真度估计</strong>、<strong class="lk jd">学习曲线外推</strong>和<strong class="lk jd">网络态射。</strong></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi po"><img src="../Images/8f9aab78077087e33d0799e33e44fba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6vXbk0nTZKbwNcGPuK91A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">降低架构性能成本估算的策略|作者图片</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><blockquote class="nv"><p id="8ed7" class="nw nx it bd ny nz oa ob oc od oe md dk translated">第2部分—模型资源管理</p></blockquote><h2 id="70ad" class="of mf it bd mg og oh dn mk oi oj dp mo lr ok ol mq lv om on ms lz oo op mu iz bi translated">高维度问题</h2><ul class=""><li id="3bc3" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">虽然神经网络<strong class="lk jd">忽略了</strong>的特征，但是<strong class="lk jd">而不是</strong>具有预测信息，这确实<strong class="lk jd">而不是</strong>意味着我们应该用<strong class="lk jd">所有</strong>的特征来训练我们的模型。</li><li id="90e1" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">不需要的特征消耗计算资源，提高存储成本，增加解释的复杂性，将噪声引入数据，并增加过度拟合的风险。</li><li id="ad78" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">随着我们添加更多的功能，我们增加了训练所需的处理能力和训练数据(其中所需的训练示例的数量随着每个添加的功能而呈指数增长)。</li><li id="dae2" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">一个拥有高质量特性的差模型会比一个拥有低质量特性的好模型表现得更好。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="70e1" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">维度缩减技术</h2><ul class=""><li id="200a" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">我们希望用尽可能少的特征保留尽可能多的预测信息。</li><li id="292d" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">手动降维</strong> <strong class="lk jd">降维</strong>涉及理解数据和业务上下文，并利用领域知识来执行特征工程和选择。</li><li id="71be" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">除了手工技术，还有<strong class="lk jd">算法途径</strong>进行降维，如线性判别分析<strong class="lk jd"> (LDA) </strong>、<strong class="lk jd">、</strong>偏最小二乘法<strong class="lk jd">、【PLS】、<strong class="lk jd">、</strong>主成分分析<strong class="lk jd"> (PCA) </strong>。</strong></li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="581c" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">模型优化的需求</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pp"><img src="../Images/af618438bdcf03f6f3e629979952af78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ixUEHCTPn41R0pSD"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">照片由<a class="ae lh" href="https://unsplash.com/@benceboros?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">本斯·博罗斯</a>在<a class="ae lh" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><ul class=""><li id="3c9c" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">随着移动、物联网和边缘设备变得无处不在，有必要将ML功能从云转移到设备上。这意味着我们需要优化模型的性能和资源需求。</li><li id="80ed" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">设备上的模型推断包括将训练好的模型加载到设备应用中，这提供了<strong class="lk jd">改进的速度</strong>和<strong class="lk jd">独立于网络连接</strong>。</li><li id="e3de" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">将模型部署到移动应用的框架有<a class="ae lh" href="https://developers.google.com/ml-kit" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> ML Kit </strong> </a>，<strong class="lk jd"/><a class="ae lh" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">CoreML</strong></a>，<a class="ae lh" href="https://www.tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"><strong class="lk jd">tensor flow Lite</strong></a>。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="beac" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">量化</h2><ul class=""><li id="eb75" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">量化是一种优化ML模型的技术，它使用较低精度的参数和计算将模型转换成一种等效的表示形式。</li><li id="e904" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">一个例子是使用较少的比特来表示图像的像素。</li><li id="226e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">虽然量化可能会降低模型精度，但它通过<strong class="lk jd"> </strong>缩小神经网络规模，减少计算资源，降低延迟<strong class="lk jd">提高执行性能和效率</strong>。</li><li id="7534" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">我们可以通过将浮点<strong class="lk jd"> 32 </strong>位值转换为<strong class="lk jd"> 8 </strong>位整数来量化神经网络中的<strong class="lk jd">权重参数</strong>和<strong class="lk jd">激活计算。</strong></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pq"><img src="../Images/643c397544a1dd101186c31bf198fd82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o1gnH9UR5zlc9S9mIA-TJA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">量化后精度降低|图片由作者提供</p></figure><ul class=""><li id="d1bd" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">量化可以在 ( <strong class="lk jd">量化感知</strong>训练)期间<strong class="lk jd">完成，也可以在</strong>模型训练(<strong class="lk jd">后训练</strong>量化)之后<strong class="lk jd">完成。</strong></li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="16cb" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">最佳型号选择</h2><ul class=""><li id="5c72" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">如果不需要高精度，最好使用更小、更简单的模型，因为嵌入式设备的计算资源有限。</li><li id="9b43" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">为移动设备优化的模型的一个例子是为计算机视觉应用而设计的MobileNets。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="30d7" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">修剪</h2><ul class=""><li id="c11a" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">修剪是一种优化技术，通过删除对产生准确结果没有实质性贡献的部分来提高模型效率。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pr"><img src="../Images/fccd4aff3a3e7c77ac1fecdcf50fd09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmxsKTgAczWzz2fMnOTmJA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">网络剪枝示例|作者图片</p></figure><ul class=""><li id="1a26" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated"><strong class="lk jd"> TensorFlow </strong>有一个<a class="ae lh" href="https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">权重剪枝API </strong> </a>设计用于在训练期间基于幅度迭代移除连接。</li><li id="da79" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">权重修剪与量化兼容，在模型优化中产生复合效益。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><blockquote class="nv"><p id="3e6a" class="nw nx it bd ny nz oa ob oc od oe md dk translated">第3部分—高性能建模</p></blockquote><h2 id="f470" class="of mf it bd mg og oh dn mk oi oj dp mo lr ok ol mq lv om on ms lz oo op mu iz bi translated">分布式培训</h2><ul class=""><li id="272b" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">当我们处理更大的数据集和更大的模型时，我们需要模型训练中的分布式方法。</li><li id="4ba3" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">两种类型的分布式训练是<strong class="lk jd">数据</strong>并行和<strong class="lk jd">模型</strong>并行。</li><li id="9814" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">数据并行</strong>将模型复制到不同的加速器(GPU或TPU)上，并在它们之间拆分数据。</li><li id="6d7c" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">模型并行</strong>将一个大型模型(太大而无法在单个设备上安装)划分为多个分区，并将它们分配给不同的加速器。</li><li id="ac4a" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">数据并行<strong class="lk jd">比模型并行</strong>更容易实现，并且与模型无关，适用于任何神经架构。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ps"><img src="../Images/5ec8fa1b8c22e1adfd418efbb3db20cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y3Jz5RvE_NOp8_7UEGUKPw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">数据并行性图解|作者图片</p></figure><ul class=""><li id="97e3" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">数据并行可以分为<strong class="lk jd">同步</strong>(所有工人同步训练并完成更新)或<strong class="lk jd">异步</strong>训练。</li><li id="a048" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">要执行分布式训练，我们可以使用TensorFlow的<a class="ae lh" href="https://www.tensorflow.org/guide/distributed_training" rel="noopener ugc nofollow" target="_blank"> tf.distribute.Strategy </a>库。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="0998" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">高效摄入</h2><ul class=""><li id="3fa0" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">加速器(GPU/TPU)对于高性能建模至关重要，但它们价格昂贵，必须高效使用。</li><li id="e6e3" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">这种效率是通过<strong class="lk jd">以足够快的速度向加速器提供数据来保持的</strong>，以避免保持空闲并改善训练时间。</li><li id="5a2c" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">我们可以使用诸如<strong class="lk jd">预取</strong>、<strong class="lk jd">缓存</strong>、<strong class="lk jd">内存减少</strong>和<strong class="lk jd">数据提取和转换的并行化</strong>等方法来优化输入管道(即ETL过程)的性能。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pt"><img src="../Images/38dec7fc59d06f9aa305d9c4e719c2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVyxu2DzGNzrF-Y655aMeQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">Pipeline有助于高效利用可用硬件，减少加载和预处理数据所需的时间|作者图片</p></figure><ul class=""><li id="029b" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">通过<strong class="lk jd">流水线</strong>，我们可以通过重叠加速器的CPU预处理和模型执行来克服CPU瓶颈。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="71c1" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">流水线并行性</h2><ul class=""><li id="64fb" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">近年来，我们已经看到模型尺寸(例如，比根、伯特、GPT-3)越来越大，以提高性能。</li><li id="3a36" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">模型增长和硬件改进之间的差距增加了并行性的重要性。</li><li id="285d" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">这些更大的模型在数据并行性(加速器的内存有限)和模型并行性(加速器计算能力的利用不足)方面带来了<strong class="lk jd">新问题</strong>。</li><li id="af66" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">这些问题导致了流水线并行的发展。</li><li id="8928" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">流水线并行</strong>通过在多个加速器上划分一个模型，并自动将一个<strong class="lk jd">小</strong>批次的训练数据分割成更小的<strong class="lk jd">微</strong>批次，从而实现大型模型的高效训练。</li><li id="037e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">一些管道并行框架(整合数据和模型并行)有Google的<a class="ae lh" href="https://ai.googleblog.com/2019/03/introducing-gpipe-open-source-library.html" rel="noopener ugc nofollow" target="_blank"> GPipe </a>和微软的<a class="ae lh" href="https://www.microsoft.com/en-us/research/blog/pipedream-a-more-effective-way-to-train-deep-neural-networks-using-pipeline-parallelism/" rel="noopener ugc nofollow" target="_blank"> PipeDream </a>。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pu"><img src="../Images/bdd1d5a93aebbc3144106251902b6498.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTpb6V9Gpa5KTbnuVOjQCg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">流水线并行支持更高效的培训|作者图片</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="6f0c" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">知识蒸馏</h2><ul class=""><li id="f64e" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">知识提炼背后的想法是创建一个简单的“学生”模型，从更复杂的“<strong class="lk jd">教师</strong>”模型中学习。</li><li id="3e04" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">目标是将复杂模型的性能复制到更简单、更高效的模型中。</li><li id="9a3e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">例如，<a class="ae lh" href="https://arxiv.org/abs/1910.01108" rel="noopener ugc nofollow" target="_blank"> DistilBERT </a>是BERT的<strong class="lk jd">提炼</strong>版本，它使用的参数少了40%，运行速度快了60%，同时保留了BERT 97%的性能(GLUE语言理解基准)。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><blockquote class="nv"><p id="5e55" class="nw nx it bd ny nz oa ob oc od oe md dk translated">第4部分—模型分析</p></blockquote><h2 id="d879" class="of mf it bd mg og oh dn mk oi oj dp mo lr ok ol mq lv om on ms lz oo op mu iz bi translated">聚合指标与切片指标</h2><ul class=""><li id="bdcf" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">在训练和部署模型之后，下一个阶段是评估它的性能。</li><li id="3de8" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">我们通常监控<strong class="lk jd">顶级的聚合指标</strong>，这些指标评估整个数据集的性能(例如，整体准确性)，但这通常隐藏了性能和公平性方面的具体问题。</li><li id="26cf" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">需要<strong class="lk jd">分割</strong>数据，以了解它在单个数据子集的粒度级别上的表现。</li><li id="0bec" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">选择重要切片进行分析通常基于<strong class="lk jd">领域知识。</strong></li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pv"><img src="../Images/82ec5c27b03584034e29814b3b9b6bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3IdagFmOd7fDQym-LIhD0g.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">平均性能良好的模型可能会表现出从聚合指标|作者图片中看不出来的故障模式</p></figure><ul class=""><li id="7dd5" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">例如，不同年龄组的客户对模型输出的体验可能非常不同。</li><li id="28f4" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><a class="ae lh" href="https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> TensorFlow模型分析(TFMA) </strong> </a>是一个开源的框架，用于模型性能的深度分析，包括在数据切片上分析性能。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="7150" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">模型稳健性</h2><ul class=""><li id="aa45" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">除了模型性能，我们还应该评估模型的健壮性。</li><li id="00c2" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">如果一个模型的结果始终准确，即使一个或多个特征发生了相对剧烈的变化，该模型也被认为是健壮的。它不应该随着数据的变化而产生非常不同和不可预测的结果。</li><li id="6e3e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">用于评估稳健性的<strong class="lk jd">指标</strong>与我们用于培训的指标相同，例如，用于回归模型的RMSE和用于分类的AUC。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="42ff" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">模型调试</h2><ul class=""><li id="f62a" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">模型调试是一门新兴的学科，专注于发现和修复模型中的问题，并提高模型的健壮性。</li><li id="01aa" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">它的目标包括提高模型透明度，防止有害的社会歧视，减少对抗性攻击<strong class="lk jd">或隐私伤害</strong>的脆弱性，避免模型衰退。</li><li id="843e" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">三种最流行的<strong class="lk jd">调试技术</strong>是<strong class="lk jd">基准模型、敏感性分析和残差分析</strong>。</li><li id="ed57" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">用于评估对抗性攻击漏洞的两个开源库是<a class="ae lh" href="https://github.com/cleverhans-lab/cleverhans" rel="noopener ugc nofollow" target="_blank"> Cleverhans </a>和<a class="ae lh" href="https://github.com/bethgelab/foolbox" rel="noopener ugc nofollow" target="_blank"> Foolbox </a>。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="5c77" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">持续评估和监控数据漂移和偏移</h2><ul class=""><li id="d7bb" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">当收集和标记数据时，训练数据仅表示世界的快照，因此模型性能会随着世界的变化而受到影响。</li><li id="cff1" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">当数据漂移和偏移发生时，<strong class="lk jd">持续</strong>监控数据和模型性能以获得<strong class="lk jd">早期警告</strong>是至关重要的。这些漂移和转移包括<strong class="lk jd">概念漂移</strong>、<strong class="lk jd">概念涌现</strong>、<strong class="lk jd">协变量转移</strong>和<strong class="lk jd">先验概率转移</strong>。</li><li id="f975" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">监督</strong>监控技术包括统计过程控制、顺序分析(使用线性四比率)和误差分布监控(自适应窗口)。</li><li id="e73d" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated"><strong class="lk jd">无监督</strong>技术包括聚类/新奇检测(如OLINDDA、MINAS)、特征分布监控和模型相关监控(如边缘密度漂移检测)。</li><li id="461d" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">领先的云提供商提供持续评估的服务，如微软Azure机器学习<strong class="lk jd"> DataSense </strong>，亚马逊SageMaker <strong class="lk jd">模型监视器</strong>，谷歌云AI <strong class="lk jd">持续评估。</strong></li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><blockquote class="nv"><p id="4696" class="nw nx it bd ny nz oa ob oc od oe md dk translated">第5部分—可解释性和可解释性</p></blockquote><h2 id="db74" class="of mf it bd mg og oh dn mk oi oj dp mo lr ok ol mq lv om on ms lz oo op mu iz bi translated">可解释人工智能的重要性</h2><ul class=""><li id="7325" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">模型<strong class="lk jd">可解释性</strong>和<strong class="lk jd">可解释性</strong>在生产ML中至关重要，原因包括公平性、监管和法律要求，以及更好地理解我们的模型以改进它。</li><li id="fd2f" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">可解释性和可解释性是被称为负责任的人工智能的更大领域的一部分。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pw"><img src="../Images/c4464a3e2bc26a96f9e526a7e3c07825.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2RW0sXRSM_IB0JhFD67fSw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">负责任的人工智能包含几个部分|作者图片</p></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="8b92" class="of mf it bd mg og pi dn mk oi pj dp mo lr pk ol mq lv pl on ms lz pm op mu iz bi translated">模型可解释性</h2><ul class=""><li id="3905" class="oq or it lk b ll np lo nq lr os lv ot lz ou md ov ow ox oy bi translated">如果我们可以通过查询模型来回答以下问题，那么模型就是可解释的:</li></ul><ol class=""><li id="cac2" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md px ow ox oy bi translated">为什么模型会以某种方式运行？</li><li id="88fd" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md px ow ox oy bi translated">我们如何相信模型做出的预测？</li><li id="c758" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md px ow ox oy bi translated"><strong class="lk jd">模型可以提供哪些</strong>信息来避免预测错误？</li></ol><ul class=""><li id="fe0a" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">虽然复杂的模型(例如神经网络)可以产生高精度，但它通常以可解释性为代价(也称为<strong class="lk jd">可解释性与精度的权衡</strong>)。</li><li id="a66a" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">固有的可解释模型是经典的模型，如基于<strong class="lk jd">树的</strong>(例如决策树)和<strong class="lk jd">线性</strong>模型(例如线性回归)。</li><li id="cc7b" class="oq or it lk b ll oz lo pa lr pb lv pc lz pd md ov ow ox oy bi translated">尽管我们不能总是使用本质上可解释的模型，但是有<strong class="lk jd">模型不可知的方法</strong>来解释任何模型的结果。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi py"><img src="../Images/20643953e76919eb596dc4e3ae2e73a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vlm549L2eCo4nC7_qDf8OA.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">模型不可知的可解释性方法示例|作者图片</p></figure><ul class=""><li id="f374" class="oq or it lk b ll lm lo lp lr pf lv pg lz ph md ov ow ox oy bi translated">流行的方法包括部分相关图(<strong class="lk jd"> PDP </strong>)、排列特征重要性、沙普利加法解释(<strong class="lk jd"> SHAP </strong>)和局部可解释模型不可知解释(<strong class="lk jd">莱姆</strong>)。</li></ul></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h1 id="ffd1" class="me mf it bd mg mh nk mj mk ml nl mn mo ki nm kj mq kl nn km ms ko no kp mu mv bi translated">(3)课堂讲稿</h1><p id="26d8" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">为了表示感谢，下面是从幻灯片和抄本中编译的PDF讲义  的<a class="ae lh" href="https://github.com/kennethleungty/MLOps-Specialization-Notes/tree/main/3.%20Machine%20Learning%20Modeling%20Pipelines%20in%20Production" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd"> <em class="mz"> GitHub repo。给回购打一颗星，以便随时了解后续课程的最新信息。</em></strong></a></p><p id="5cd5" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">准备好了吗？点击此处查看下一期课程总结:</p><div class="pz qa gp gr qb qc"><a rel="noopener follow" target="_blank" href="/key-learning-points-from-mlops-specialization-course-4-ee39bbd2864b"><div class="qd ab fo"><div class="qe ab qf cl cj qg"><h2 class="bd jd gy z fp qh fr fs qi fu fw jc bi translated">MLOps专业化认证的关键学习点—课程4</h2><div class="qj l"><h3 class="bd b gy z fp qh fr fs qi fu fw dk translated">来自面向生产的机器学习工程(MLOps)课程的主要见解(附课堂讲稿)</h3></div><div class="qk l"><p class="bd b dl z fp qh fr fs qi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ql l"><div class="qm l qn qo qp ql qq lb qc"/></div></div></a></div><p id="4e7c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">您可以在此处找到前两个课程的总结:</p><div class="pz qa gp gr qb qc"><a rel="noopener follow" target="_blank" href="/key-learning-points-from-mlops-specialization-course-deeplearning-ai-andrew-ng-5d0746605752"><div class="qd ab fo"><div class="qe ab qf cl cj qg"><h2 class="bd jd gy z fp qh fr fs qi fu fw jc bi translated">MLOps专业化认证的关键学习点—课程1</h2><div class="qj l"><h3 class="bd b gy z fp qh fr fs qi fu fw dk translated">面向生产的机器学习工程课程1的主要内容</h3></div><div class="qk l"><p class="bd b dl z fp qh fr fs qi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ql l"><div class="qr l qn qo qp ql qq lb qc"/></div></div></a></div><div class="pz qa gp gr qb qc"><a rel="noopener follow" target="_blank" href="/key-learning-points-from-mlops-specialization-course-2-13af51e22d90"><div class="qd ab fo"><div class="qe ab qf cl cj qg"><h2 class="bd jd gy z fp qh fr fs qi fu fw jc bi translated">MLOps专业化认证的关键学习点—课程2</h2><div class="qj l"><h3 class="bd b gy z fp qh fr fs qi fu fw dk translated">面向生产的机器学习工程课程的见解摘要</h3></div><div class="qk l"><p class="bd b dl z fp qh fr fs qi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ql l"><div class="qs l qn qo qp ql qq lb qc"/></div></div></a></div><h1 id="7b69" class="me mf it bd mg mh mi mj mk ml mm mn mo ki mp kj mq kl mr km ms ko mt kp mu mv bi translated">在你走之前</h1><p id="9742" class="pw-post-body-paragraph li lj it lk b ll np kd ln lo nq kg lq lr nr lt lu lv ns lx ly lz nt mb mc md im bi translated">欢迎您<strong class="lk jd">加入我的数据科学学习之旅！</strong>点击此<a class="ae lh" href="https://kennethleungty.medium.com/" rel="noopener">媒体</a>页面，查看我的<a class="ae lh" href="https://github.com/kennethleungty" rel="noopener ugc nofollow" target="_blank"> GitHub </a>，了解更多精彩的数据科学内容。同时，享受构建生产ML系统的乐趣！</p></div></div>    
</body>
</html>