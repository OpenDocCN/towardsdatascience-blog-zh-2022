<html>
<head>
<title>Two (completely different) types of dbt incremental models in BigQuery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BigQuery中两种(完全不同的)dbt增量模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/two-completely-different-types-of-dbt-incremental-models-in-bigquery-db794cbe022c#2022-07-28">https://towardsdatascience.com/two-completely-different-types-of-dbt-incremental-models-in-bigquery-db794cbe022c#2022-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7662" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于分区的加载或使用增量加载跟踪下游模型的历史</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/326813d5bb64d98f85417245c9b5c39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Nm3N3egV4BqUeW6V"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@killerfvith?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">黄福生</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="ea04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://docs.getdbt.com/" rel="noopener ugc nofollow" target="_blank"> dbt </a>中的增量模型不是新发明，它们是将数据追加到表中的传统方式。在老式的数据仓库中，这是将日常数据引入数据存储环境的方法。为了不让事情失去控制，您应该放置一个键，并决定更新行(如果它存在的话),否则追加它(用一个<code class="fe ls lt lu lv b">MERGE</code>操作)。</p><p id="b3b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">dbt已经有了很棒的关于增量模型的文档<a class="ae kv" href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models" rel="noopener ugc nofollow" target="_blank">https://docs . get dbt . com/docs/building-a-dbt-project/building-models/configuring-incremental-models</a>。几乎所有示例中提到的典型用例是切换到增量模型以降低成本，因此您不会每天删除表并从头开始重新构建，而是增量添加行。如果您正在使用BigQuery，那么您应该已经了解了每天扫描数百GB或TB数据的成本(或者每天扫描几次，这取决于您如何安排dbt)。下面，我将介绍两种类型的用例，以及如何在dbt中设计一个高效的增量模型。</p><h2 id="502e" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">类型1增量模型用例</strong></h2><ul class=""><li id="89a1" class="mp mq iq ky b kz mr lc ms lf mt lj mu ln mv lr mw mx my mz bi translated">您的数据已经在您的数据湖中，完全，所有的，所以您可以每天重新创建您的表。</li><li id="d4c5" class="mp mq iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">您有不可变的事件数据，并且有时间戳。例子可以是点击、浏览、印象、电子邮件打开等。</li><li id="cfaf" class="mp mq iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">在表实体化上创建模型的成本很高。</li></ul><h2 id="eeb7" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">类型1增量模型示例</strong></h2><p id="7399" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">假设我有关于客户点击的数据，这些点击有<code class="fe ls lt lu lv b">user_id</code>和<code class="fe ls lt lu lv b">clicked_at</code>时间戳</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/8f17a233f4d597911c9397a53408e0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*Dvom8rEcAfKe0Wn537j8tQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">原始客户点击数据示例</p></figure><p id="9f8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并且您希望创建一个模型，其中包含每个客户每天的点击量:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3779cee0dfa04539e2e858fe2bc09572.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*3-oX9T7TDhsZqUNiI1j5YA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">点击数据的类型1增量模型输出示例</p></figure><p id="d134" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对此的查询非常简单:</p><pre class="kg kh ki kj gt nk lv nl nm aw nn bi"><span id="c391" class="lw lx iq lv b gy no np l nq nr">select <br/>     user_id, <br/>     date(clicked_at) as day, <br/>     count(clicked_at) as nr_clicks<br/>from raw_data<br/>group by user_id, date(clicked_at)</span></pre><p id="ef5b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">想象一下，你有万亿字节的数据，当你只能计算最后一天时，为什么每次都要从头开始重新计算所有的点击历史？</p><h2 id="f2e2" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">1型增量模型的解决方案</strong></h2><p id="c939" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">首先这类数据天生就是要分区的，请做到。在这个<a class="ae kv" href="https://discourse.getdbt.com/t/benchmarking-incremental-strategies-on-bigquery/981" rel="noopener ugc nofollow" target="_blank">链接</a>中，您可以看到BigQuery上不同策略的简洁对比以及每种策略的性能。很明显<em class="ns">插入+覆盖静态</em>策略的性能最好，几乎与数据<strong class="ky ir"> 🥳 </strong>的增长成线性关系。所以让我们来实现它吧！</p><pre class="kg kh ki kj gt nk lv nl nm aw nn bi"><span id="db83" class="lw lx iq lv b gy no np l nq nr">-- Let's define the partitions and decide the replace the last 2 <br/>-- days, just in case some clicks did not arrive yet.</span><span id="9b6a" class="lw lx iq lv b gy nt np l nq nr">{% set partitions_to_replace = [</span><span id="820c" class="lw lx iq lv b gy nt np l nq nr">      'current_date',<br/>      'date_sub(current_date, interval 1 day)'</span><span id="4295" class="lw lx iq lv b gy nt np l nq nr">] %}</span><span id="afea" class="lw lx iq lv b gy nt np l nq nr">-- Here we define the incremental model, the data will be<br/>-- partitioned by the date and I am also clustering by user_id<br/>-- to improve performance. I am choosing the insert_overwrite<br/>-- strategy explicitly</span><span id="2000" class="lw lx iq lv b gy nt np l nq nr">{{ <br/>   config(<br/>          materialized='incremental',<br/>          partition_by = { 'field': 'day', 'data_type': 'date' },<br/>          cluster_by = "user_id",<br/>          incremental_strategy = 'insert_overwrite'<br/>         )<br/>}}</span><span id="3916" class="lw lx iq lv b gy nt np l nq nr">select <br/>     {{ dbt_utils.surrogate_key(['user_id',    dbt_utils.date_trunc('day','clicked_at')]) }} as user_day_pk,<br/>     user_id, <br/>     date(clicked_at) as day, <br/>     count(clicked_at) as nr_clicks<br/>from raw_data</span><span id="23c0" class="lw lx iq lv b gy nt np l nq nr">-- This is to replace the last 2 day partitions</span><span id="4088" class="lw lx iq lv b gy nt np l nq nr">{% if is_incremental() %}</span><span id="7ab6" class="lw lx iq lv b gy nt np l nq nr">where date(clicked_at) in ({{ partitions_to_replace | join(',') }})</span><span id="65bc" class="lw lx iq lv b gy nt np l nq nr">{% endif %}<br/>group by user_id, date(clicked_at)</span></pre><p id="53c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我甚至没有展示这个用例的<code class="fe ls lt lu lv b">merge</code>策略的例子，尽管它们会起作用，因为这确实是实现这个模型并获得最佳性能的一个简洁的方法。注意<strong class="ky ir">对于<code class="fe ls lt lu lv b">insert_overwrite</code>策略，你不需要一个键</strong>。更重要的是，即使您在配置中为惟一键添加了一行，那一行也不会运行！所以不要这样做，你会给自己制造错误的期望:</p><pre class="kg kh ki kj gt nk lv nl nm aw nn bi"><span id="0671" class="lw lx iq lv b gy no np l nq nr">{{ <br/>   config(<br/>          materialized='incremental',<br/>-- do not do this line below, it won't run anyways<br/>          unique_key = 'user_day_pk'<br/>          partition_by = { 'field': 'day', 'data_type': 'date' },<br/>          cluster_by = "user_id",<br/>          incremental_strategy = 'insert_overwrite'<br/>         )<br/>}}</span></pre><p id="2a3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">那为什么不需要钥匙呢？嗯，上面的代码盲目地工作，从dbt模型中删除最近2天的分区，从<code class="fe ls lt lu lv b">raw_data</code>中选择最近2天的分区，并重新追加它们。所以手术不需要钥匙，但是如果你愿意，你可以在桌子上留一把钥匙。</p><h2 id="e31b" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">类型2增量模型用例</strong></h2><ul class=""><li id="348f" class="mp mq iq ky b kz mr lc ms lf mt lj mu ln mv lr mw mx my mz bi translated">您的数据源不保留历史记录，但您希望开始构建历史记录并停止丢失数据。</li><li id="d2d0" class="mp mq iq ky b kz na lc nb lf nc lj nd ln ne lr mw mx my mz bi translated">您的dbt模型有几个下游转换，并且您想要跟踪您的下游模型的历史。</li></ul><p id="2902" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个与前一个案例完全不同的用例，因为这类似于保存快照。<a class="ae kv" href="https://docs.getdbt.com/blog/change-data-capture?utm_content=215567626&amp;utm_medium=social&amp;utm_source=linkedin&amp;hss_channel=lcp-10893210" rel="noopener ugc nofollow" target="_blank">这里的</a>是dbt实验室关于这个用例的一个非常好的博客，其中他们明确声明不要给你的下游模型拍快照。我将展示的解决方案不仅可以帮助您跟踪历史和防止数据丢失，而且比维护多个快照的成本要低得多。</p><h2 id="bb8b" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">类型2增量模型示例</strong></h2><p id="8e4b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">假设您的数据源中有6个表，这些表保存了Twitter个人资料的不同属性，比如Twitter个人资料URL、Twitter用户名、Twitter描述、Twitter照片URL和Twitter位置。这些是工程表，保存了每个属性，以及创建和修改的时间戳。</p><p id="9e37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_profile</code> — <code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_modified_at</code>、<code class="fe ls lt lu lv b">t_deleted_at</code></p><p id="4eb1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_username</code> — <code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_username</code>、<code class="fe ls lt lu lv b">t_created_at</code>、<code class="fe ls lt lu lv b">t_modified_at</code></p><p id="479a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_url</code> — <code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_url</code>、<code class="fe ls lt lu lv b">t_created_at</code>、<code class="fe ls lt lu lv b">t_modified_at</code></p><p id="e46a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_description</code> — <code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_description</code>、<code class="fe ls lt lu lv b">t_created_at</code>、<code class="fe ls lt lu lv b">t_modified_at</code></p><p id="eaa6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_photo_url</code> — <code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_photo_url</code>、<code class="fe ls lt lu lv b">t_created_at</code>、<code class="fe ls lt lu lv b">t_modified_at</code></p><p id="b788" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_location</code>——<code class="fe ls lt lu lv b">t_profile_id</code>、<code class="fe ls lt lu lv b">t_longitude</code>、<code class="fe ls lt lu lv b">t_latitude</code>、<code class="fe ls lt lu lv b">t_created_at</code>、<code class="fe ls lt lu lv b">t_modified_at</code></p><p id="69ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ls lt lu lv b">t_profile_id</code>是每个表的一个键。用户名和配置文件URL是必需的属性，但是配置文件中可能缺少其他属性。连接这些数据的查询很简单，但是它只给出Twitter概要文件的当前版本。实际上，除非您开始跟踪历史，否则您无法找到每个属性的版本，只能找到当前的版本。</p><pre class="kg kh ki kj gt nk lv nl nm aw nn bi"><span id="520e" class="lw lx iq lv b gy no np l nq nr">select<br/>      t_profile.t_profile_id,<br/>      t_username,<br/>      t_url,<br/>      t_description,<br/>      <!-- -->t_photo_url,<br/>      t_longitude,<br/>      t_latitude,<br/>      <!-- -->t_profile<!-- -->.t_created_at as t_profile_created_at,<br/>      <!-- -->t_profile<!-- -->.t_deleted_at as t_profile_deleted_at<br/>from <!-- -->t_profile<br/>inner join t_username<br/>      on t_profile.t_profile_id = t_username.t_profile_id<br/>left join t_url<br/>      on t_profile.t_profile_id = t_url.t_profile_id<br/>left join <!-- -->t_description<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_description<!-- -->.t_profile_id<br/>left join <!-- -->t_photo_url<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_photo_url<!-- -->.t_profile_id<br/>left join <!-- -->t_location<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_location<!-- -->.t_profile_id</span></pre><p id="4e89" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您想要基于前面的查询创建一个表<code class="fe ls lt lu lv b">t_profile_history</code>，但是还要跟踪工程数据中的每个属性。</p><h2 id="fd0f" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated"><strong class="ak">2型增量模型的解决方案</strong></h2><p id="602d" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">我们不能再将分区用于数据加载策略，因为我们不希望删除任何分区并从数据源重新计算，因为数据源不保留历史记录。让我们把这种情况简化为每天进行一次修改。</p><pre class="kg kh ki kj gt nk lv nl nm aw nn bi"><span id="5d61" class="lw lx iq lv b gy no np l nq nr">-- Here we set the config as incremental and the unique key of each -- profile per day<br/>-- I am pratitioning by date for query performance after the model <br/>-- is live, but it won't affect the merge<br/>-- Add the strategy as merge<br/>-- Do not forget full_refresh = false so there are no accidents</span><span id="2cf2" class="lw lx iq lv b gy nt np l nq nr">{{ config(<br/>          materialized='incremental',<br/>          unique_key = 't_profile_history_pk',<br/>          partition_by = { 'field': 't_profile_modified_at',     'data_type': 'timestamp', "granularity": "day" }, <br/>          cluster_by = "t_profile_id",<br/>          incremental_strategy = 'merge',<br/>          full_refresh = false<br/>         )<br/>}}</span><span id="8e68" class="lw lx iq lv b gy nt np l nq nr">with twitter_profile_versions as (<br/>select<br/>      t_profile.t_profile_id,<br/>      t_username,<br/>      t_url,<br/>      t_description,<br/>      <!-- -->t_photo_url,<br/>      t_longitude,<br/>      t_latitude,<br/>      <!-- -->t_profile<!-- -->.t_created_at as t_profile_created_at,<br/>      <!-- -->t_profile<!-- -->.t_deleted_at as t_profile_deleted_at,<br/>      <!-- -->GREATEST(<br/>               COALESCE(<br/>                        t_profile.<!-- -->t_created_at<!-- -->,<br/>                        t_username.<!-- -->t_modified_at<!-- -->,<br/>                        t_url.<!-- -->t_modified_at<!-- -->,<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at,<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at,<br/>                        t_location<!-- -->.<!-- -->t_modified_at<br/>                       ),<br/>               COALESCE(<br/>                        t_username.<!-- -->t_modified_at<!-- -->,<br/>                        t_url.<!-- -->t_modified_at<!-- -->,<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at,<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at,<br/>                        t_location<!-- -->.<!-- -->t_modified_at,<br/>                        <!-- -->t_profile.<!-- -->t_created_at<br/>                       ),<br/>               COALESCE(<br/>                        t_url.<!-- -->t_modified_at<!-- -->,<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at,<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at,<br/>                        t_location<!-- -->.<!-- -->t_modified_at,<br/>                        <!-- -->t_profile.<!-- -->t_created_at<br/>                        t_username.<!-- -->t_modified_at<br/>                       ),<br/>               COALESCE(<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at,<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at,<br/>                        t_location<!-- -->.<!-- -->t_modified_at,<br/>                        <!-- -->t_profile.<!-- -->t_created_at<br/>                        t_username.<!-- -->t_modified_at<br/>                        t_url.<!-- -->t_modified_at<br/>                       ),<br/>               COALESCE(<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at,<br/>                        t_location<!-- -->.<!-- -->t_modified_at,<br/>                        <!-- -->t_profile.<!-- -->t_created_at<br/>                        t_username.<!-- -->t_modified_at<br/>                        t_url.<!-- -->t_modified_at,<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at<br/>                       ),<br/>               COALESCE(<br/>                        t_location<!-- -->.<!-- -->t_modified_at,<br/>                        <!-- -->t_profile.<!-- -->t_created_at<br/>                        t_username.<!-- -->t_modified_at<br/>                        t_url.<!-- -->t_modified_at,<br/>                        <!-- -->t_description<!-- -->.<!-- -->t_modified_at<br/>                        t_photo_url<!-- -->.<!-- -->t_modified_at<br/>                       ),<br/>               ) as <!-- -->t_profile_modified_at</span><span id="53c5" class="lw lx iq lv b gy nt np l nq nr">from <!-- -->t_profile<br/>left join t_username<br/>      on t_profile.t_profile_id = t_username.t_profile_id<br/>left join t_url<br/>      on t_profile.t_profile_id = t_url.t_profile_id<br/>left join <!-- -->t_description<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_description<!-- -->.t_profile_id<br/>left join <!-- -->t_photo_url<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_photo_url<!-- -->.t_profile_id<br/>left join <!-- -->t_location<br/>      <!-- -->on t_profile.t_profile_id = <!-- -->t_location<!-- -->.t_profile_id</span><span id="bd26" class="lw lx iq lv b gy nt np l nq nr">)</span><span id="232f" class="lw lx iq lv b gy nt np l nq nr">select <br/>     {{ dbt_utils.surrogate_key(['t_profile_id',      dbt_utils.date_trunc('day','t_profile_modified_at')}} as t_profile_history_pk,<br/>     twitter_profile_versions.*<br/>from twitter_profile_versions</span><span id="f067" class="lw lx iq lv b gy nt np l nq nr">{% if is_incremental() %}</span><span id="209a" class="lw lx iq lv b gy nt np l nq nr">where date_diff(current_date(), date(t_profile_modified_at), DAY) &lt;= 2</span><span id="8140" class="lw lx iq lv b gy nt np l nq nr">{% endif %}</span></pre><p id="5455" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面这段代码为我们的<code class="fe ls lt lu lv b">t_profile_history</code>设计了加载过程，它为每天保存一个版本的概要文件，以防有任何变化。我保留了带有属性的表的连接，以选择最近两天修改过的属性。要小心，因为内部连接要求所有属性都已更改，但情况可能并非如此。</p><p id="3d2e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用<code class="fe ls lt lu lv b">GREATEST()</code>来选择最后修改的时间戳，这是为了简化查询，并试图找到每个表的修改时间戳之间的中间版本。在本例中，我们简化了用例，用运行dbt时获得的快照构建历史。注意，我正在使用<code class="fe ls lt lu lv b">COALESCE()</code>并旋转所有修改过的时间戳，包括概要文件中的<code class="fe ls lt lu lv b">t_created_at</code>。我这样做是因为如果任何元素为空，那么<code class="fe ls lt lu lv b">GREATEST()</code>将返回<code class="fe ls lt lu lv b">NULL</code><a class="ae kv" href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/big query/docs/reference/standard-SQL/functions-and-operators</a>并且我们可能有空值，因为我们有5个左连接。我轮换每个修改过的时间戳，所以如果它们不为空，那么它们都有机会成为<code class="fe ls lt lu lv b">COALESCE()</code>的输出。</p><p id="4075" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">记得用<code class="fe ls lt lu lv b">full_refresh=FALSE</code>。这将防止当有人运行<code class="fe ls lt lu lv b">dbt run --full --refresh</code>而你的模型连同你迄今为止跟踪的历史不见了的时候发生意外。</p><p id="6dd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">边上的一张纸条:</p><p id="5681" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二类使用情形的替代解决方案也可以通过快照来解决。在这种情况下，您将每天对所有6个表进行快照，并在下游照常进行转换(表或增量具体化)。快照解决方案的优点是，您仍然有一种ELT过程，您可以跟踪源数据的历史，并在以后决定转换。当您不确定要跟踪什么并且希望模式发生变化时，这是一个很大的优势。快照解决方案的缺点是，与增量模型相比，它在处理(增量模型解决方案仅扫描最近2天的数据)和存储(我们在增量解决方案中仅存储1个模型，而不是在快照解决方案中存储7个模型)方面都非常昂贵。</p><h2 id="e8b2" class="lw lx iq bd ly lz ma dn mb mc md dp me lf mf mg mh lj mi mj mk ln ml mm mn mo bi translated">让我们结束吧！</h2><p id="17fe" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf nf lh li lj ng ll lm ln nh lp lq lr ij bi translated">dbt增量模型是提高性能和优化成本的神奇工具。当你的表很大并且事件不可变时，考虑使用<code class="fe ls lt lu lv b">insert_overwrite</code>策略。一个不太传统的例子是跟踪下游模型的历史。这更像是一个ETL过程，您提取、执行转换，然后增量加载，这可以通过<code class="fe ls lt lu lv b">merge</code>策略实现，保持唯一的键，并确保您不允许完全刷新。</p></div></div>    
</body>
</html>