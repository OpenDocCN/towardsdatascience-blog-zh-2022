<html>
<head>
<title>Putting Machine Learning model into production with Google Cloud Platform and DVC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用谷歌云平台和DVC将机器学习模型投入生产</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/putting-machine-learning-model-into-production-with-google-cloud-platform-and-dvc-f6a22cdcf4a5#2022-03-01">https://towardsdatascience.com/putting-machine-learning-model-into-production-with-google-cloud-platform-and-dvc-f6a22cdcf4a5#2022-03-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="a3d4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="17d0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">机器学习模型作为一个独立的产品没有太大的价值。无论他们的表现有多不可思议，在交付给相关用户之前，他们都没有给企业带来任何实质性的价值。然而，部署方面通常被考虑在ML项目的最后，因为它不是数据科学家熟悉的主题。</p><p id="46c8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">本文将展示一种简单的方法来将ML模型付诸实践，以及用来完成它的工具，这样那些从未部署过模型的人就能更好地了解它的样子。</p><h1 id="e3e2" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">模型部署策略</h1><p id="ac3a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我们开始之前，让我们看看有哪些选项可以用来部署我们的模型。将ML模型投入生产的方法有多种，大致可分为以下三类:</p><ul class=""><li id="2597" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">模型即服务(Model-as-a-service)<br/>模型是软件的一部分，它按照用户的要求实时提供服务。大多数情况下，它以web服务或API的形式出现，其中模型的输入和输出通过HTTP或其他众所周知的协议进行传输。</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/e7342c4ca0cb8183fb3f3068ce195bed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tbrO6fnGEQcNMK2e5Rt4UA.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">模型即服务策略(图片由作者提供)。</p></figure><ul class=""><li id="a142" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated"><strong class="kn ir">批量预测<br/> </strong>与实时服务相反，批量预测策略离线进行推理。通过数据管道为模型准备输入，一旦处理完成，结果在交付给用户之前保存在数据库或数据存储器中。处理管道可以由计划的作业或用户请求触发，但输出不会实时提供。</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mn"><img src="../Images/16c49f562d1a42a3271c185846c5b6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*26gugryds-bst6L-pYVXEg.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">批量预测策略(图片由作者提供)。</p></figure><ul class=""><li id="7ef6" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated"><strong class="kn ir">边缘模型<br/> </strong>与前两种通过互联网来回传输输入和输出的策略不同，边缘模型策略在传感器收到数据后立即使用ML模型进行预测，以便做出实时决策。这些情况通常会在自动化系统、机器人和物联网应用中大量出现。</li></ul><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mo"><img src="../Images/e05436904936f026d2922f1fff460df6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XDKE1JhSW05xlm6nmsACg.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">边缘模型策略(图片由作者提供)。</p></figure><h1 id="d7ff" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">概观</h1><p id="964e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将创建一个工作流，从云存储中获取图像，执行图像分割，并将结果放回云存储中。您可能已经猜到了，我们在这里使用的策略是<em class="mp">批量预测</em>。</p><h2 id="1f04" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">模型</h2><p id="73f0" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们要部署的模型是一个图像分割模型，它可以识别图像中的云。模型的输入和输出如下:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/c48ecc379843b525f0e76daad1b0ea72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SksD3AMWFt1vkFCJ6zu80Q.jpeg"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">模型输入和输出(图片由作者提供)。</p></figure><p id="ecb4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">关于模型架构、训练过程和性能的细节超出了本文的范围。我们将假设模型已经过训练，可以使用了。</p><h2 id="1675" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">数据管道</h2><p id="285d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">批外预测流水线包括如下3个阶段:</p><ol class=""><li id="9329" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li nd lu lv lw bi translated">用户上传图像到云存储桶(<em class="mp">)实际上，这个步骤可能由系统处理，而不是手动上传。然而，这不会影响我们的批量预测管道的工作方式</em>。</li><li id="696c" class="lo lp iq kn b ko ne ks nf kw ng la nh le ni li nd lu lv lw bi translated">调度的作业向API发送HTTP请求来触发计算。</li><li id="0a9a" class="lo lp iq kn b ko ne ks nf kw ng la nh le ni li nd lu lv lw bi translated">计算服务通过<br/> 3.1开始计算。下载一个训练好的模型<br/> 3.2。下载输入云存储<br/> 3.3中的所有图片。对所有图像进行推理</li><li id="bbd6" class="lo lp iq kn b ko ne ks nf kw ng la nh le ni li nd lu lv lw bi translated">所有输出都保存到输出云存储中</li></ol><p id="4c5f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">下图显示了工作流程:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi nj"><img src="../Images/d2c1caa7079db2ecfc3db670fc62b0e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A2PGqY8gPraTVOP9yq9UhA.jpeg"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">数据管道(图片作者提供)。</p></figure><h2 id="40cc" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">模型注册表</h2><p id="b7df" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">模型部署的另一个关键方面是软件组件(无论是应用程序、数据管道等。)访问训练好的模型。一个可能的选择是将训练好的模型存储在远程存储上，然后将文件路径放入配置文件中。这种方法，即使是一个有效的选项，也使得训练和部署模型的过程不连续，这导致了不期望的情况，例如应用程序没有意识到存在模型的较新版本，系统因为文件被重定位到新路径而无法启动，等等。现在更好且更广泛接受的方法是使用<em class="mp">模型注册中心</em>。</p><p id="5bcc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">模型注册中心是一个集中的存储库，用于存储、版本化、服务和管理经过训练的ML模型。它充当模型开发和模型部署之间的桥梁，前者只需要知道模型应该在哪里注册，而后者只需要知道要使用什么模型。在这篇文章中，我们将使用<em class="mp">数据版本控制</em> (DVC)从GitHub项目中创建一个简单的模型注册表。</p><h1 id="f4a7" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">履行</h1><h2 id="323a" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">管道组件</h2><p id="fdd1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们将使用<em class="mp"> Google云存储</em>作为输入和输出桶，使用<em class="mp">云调度器</em>作为调度作业。下面是使用Google Cloud SDK创建buckets和计划作业的命令。您也可以通过GCP控制台或谷歌云CLI来完成这些操作。</p><p id="9acb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于计算服务，为了简单起见，使用了云函数，因为它只需要Python代码及其依赖项。<em class="mp">注意，在现实中，对于图像处理和深度学习等计算密集型任务，使用云运行或计算引擎等服务可能更好。</em>运行推理的代码如下:</p><pre class="ly lz ma mb gt nk nl nm nn aw no bi"><span id="eaab" class="mq jo iq nl b gy np nq l nr ns">def run_inference(request):     <br/>    model = load_model()     <br/>    with torch.no_grad():         <br/>        for blob in input_bucket.list_blobs():             <br/>            obj_name = blob.name             <br/>            img = load_image(obj_name)             <br/>            out = inference(img)             <br/>            save_image(out, obj_name)             <br/>            blob.delete()</span></pre><p id="e76b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">函数<code class="fe nt nu nv nl b">load_model</code>负责连接模型注册表并下载训练好的模型，而<code class="fe nt nu nv nl b">load_image</code>、<code class="fe nt nu nv nl b">save_image</code>、<code class="fe nt nu nv nl b">inference</code>分别从指定位置读取/写入图像并进行推理。</p><h2 id="00eb" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">模型加载</h2><p id="f68b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如前所述，我们将使用DVC创建一个简单的模型注册中心。简而言之，DVC是一个用于数据科学项目的工具，它让你以类似于Git版本化你的源代码的方式来版本控制你的数据。DVC的一个便利特性是，它可以让你毫不费力地将你的存储库变成一个数据注册中心。假设您有一个DVC项目，其中有一组被跟踪的文件，您可以像这样列出并下载所有被跟踪的文件。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0f5efc41794fba7dae722e21380da627.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*tRqIBdQ7QqJ5vFac29So7g.gif"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">使用DVC加载模型(图片由作者提供)。</p></figure><p id="f5ab" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">除了使用CLI，DVC还提供Python API，允许您以编程方式使用这些功能。我们使用这个API从存储库中加载训练好的模型，如下所示:</p><pre class="ly lz ma mb gt nk nl nm nn aw no bi"><span id="a99f" class="mq jo iq nl b gy np nq l nr ns">import dvc.api  <br/>def load_model():<br/>  with dvc.api.open(path=model_path, repo=url, mode='rb') as f:         <br/>       params = yaml.safe_load(io.BytesIO(f.read()))<br/>       model_params = params['model']</span><span id="4b1d" class="mq jo iq nl b gy nx nq l nr ns">  with dvc.api.open(path=model_path, repo=repo_url, mode='rb') as f:<br/>       buffer = io.BytesIO(f.read())<br/>       state_dict = torch.load(buffer)</span><span id="8aea" class="mq jo iq nl b gy nx nq l nr ns">  model = Model(n_classes=model_params['n_classes'],<br/>                in_channel=model_params['in_channels'])<br/>  model.load_state_dict(state_dict)<br/>  <br/>  return model</span></pre><h2 id="5134" class="mq jo iq bd jp mr ms dn jt mt mu dp jx kw mv mw kb la mx my kf le mz na kj nb bi translated">部署</h2><p id="6dac" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">即使我们可以手动部署代码，最好是自动化这个过程。我们可以使用GitHub Actions通过google提供的插件<a class="ae ny" href="https://cloud.google.com/blog/topics/developers-practitioners/deploying-serverless-platforms-github-actions" rel="noopener ugc nofollow" target="_blank">Google-GitHub-Actions/deploy-Cloud-Functions</a>来自动化云功能部署，如下所示:</p><pre class="ly lz ma mb gt nk nl nm nn aw no bi"><span id="1f5f" class="mq jo iq nl b gy np nq l nr ns">name: Merge</span><span id="8349" class="mq jo iq nl b gy nx nq l nr ns">on:<br/>  push:<br/>    branches:<br/>      - main</span><span id="2d25" class="mq jo iq nl b gy nx nq l nr ns">jobs:<br/>  deploy_function:<br/>    runs-on: ubuntu-latest<br/>    steps:<br/>      - uses: actions/checkout@v2</span><span id="bf45" class="mq jo iq nl b gy nx nq l nr ns">      - name: "Authenticate GCP"<br/>        id: auth<br/>        uses: google-github-actions/auth@v0<br/>        with:<br/>          credentials_json: ${{ secrets.gcp_credentials }}</span><span id="1b5a" class="mq jo iq nl b gy nx nq l nr ns">      - name: "Deploy a Cloud Function"<br/>        id: deploy-function<br/>        uses: google-github-actions/deploy-cloud-functions@v0<br/>        with:<br/>          name: cloud-segmentation<br/>          runtime: python37<br/>          entry_point: run_inference<br/>          memory_mb: 2048MB<br/>          deploy_timeout: 600          <br/>          env_vars: INPUT_BUCKET_NAME=cloud-segmentation-input,OUTPUT_BUCKET_NAME=cloud-segmentation-output</span></pre><p id="540f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">添加这个之后，每当新的PR合并到<code class="fe nt nu nv nl b">main</code>分支，云功能就会自动部署。GCS bucket和scheduler只创建一次，所以如果需要，我们可以手动创建。</p><p id="155c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">下面的GIF显示了当我们将所有组件放在一起时管道的样子。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/64c175216163832c5beb107cef4d215e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*viDsyOptSiRB8-oVhQ56gg.gif"/></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">所有组件组装在一起(图片由作者提供)。</p></figure><h1 id="9f61" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="0916" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如您所看到的，尽管我们已经有了一个训练好的模型，但是要让它能够提供真正的价值，还有很多工作要做。选择部署策略、挑选模型服务模式、设计基础设施和构建CI/CD管道，所有这些对于机器学习项目的成功都至关重要，就像使用正确的算法、确保数据质量和训练模型以实现高精度指标一样重要。</p></div></div>    
</body>
</html>