<html>
<head>
<title>Explainable AI: Unfold the Blackbox</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可解释的人工智能:打开黑盒</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/explainable-ai-unfold-the-blackbox-5488253c01fd#2022-05-26">https://towardsdatascience.com/explainable-ai-unfold-the-blackbox-5488253c01fd#2022-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9e0a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">与XAI一起建立对机器学习的信任,《SHAP &amp;沙普利价值观指南》</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3092727b9b31c75a45e5f151a6252f64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3MtFp_HCvIdMcA_jejScmw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">塔拉·温斯泰德在<a class="ae kv" href="https://www.pexels.com/" rel="noopener ugc nofollow" target="_blank">的照片</a></p></figure><p id="41fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着AI变得更加先进，成为我们生活中至关重要的一部分，当我们不了解AI的效果和副作用时，危险就来了。重要的是要理解如何区分人工智能决策过程的事实和幻想，同时保持人工智能的效率，并为结果提供最大的透明度。所有这些都可以通过可解释的人工智能(XAI)来实现。</p><h1 id="d72e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是XAI及其好处？</h1><blockquote class="mk ml mm"><p id="d34c" class="kw kx mn ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated">可解释的人工智能是一种旨在创造人类可解释的机器学习的技术。这些技术将帮助人类理解、解释和信任机器学习模型做出的预测。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/84989dacce60a8fdd6b82a4dffe19f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*n--EAYf_7rSDHkz9_0nfww.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9241" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上图展示了常规人工智能与可解释人工智能的对比，以及它如何影响最终用户。</p><blockquote class="mk ml mm"><p id="584e" class="kw kx mn ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated">当我们理解了ML算法预测背后的逻辑，它就不再是一个黑箱了。这不仅有助于数据科学家和ML工程师解释预测背后的故事，也有助于企业和整个组织信任和采用人工智能。</p></blockquote><p id="c509" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可解释的人工智能在高风险人工智能领域更重要，如金融投资、医疗诊断、自动驾驶汽车以及法律或国防相关的决策。目前，很难相信这些地方的“黑匣子”人工智能模型的推断。</p><p id="4115" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">好处</strong></p><ol class=""><li id="eab6" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">建立对人工智能驱动的商业决策的信心- 可解释的人工智能将有助于建立对商业决策的信任&amp;信心。来自可解释的人工智能系统的推理往往会增加系统的信心，因为它有可能看到这些决定的主要驱动因素。</li><li id="03c2" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated"><strong class="ky ir">透明和可问责的人工智能系统- </strong>随着人工智能对项目的影响越来越大，可解释性将确保研究和决策透明。因此，更容易让工程师/团队/组织对决策负责。</li><li id="b22e" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated"><strong class="ky ir">减轻法律、合规性&amp;声誉风险- </strong>使用人工智能是不够的，我们有义务公平使用人工智能。保持人工智能模型的可解释性和透明性，可以大大降低错误结果的影响，组织可以减轻监管合规机构带来的风险&amp;。</li><li id="3acb" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated"><strong class="ky ir">减轻偏见&amp;促进公平- </strong>有了可解释的人工智能，更容易看到数据中影响ML模型输出的模式。因此，可解释的系统可以减少有偏见的预测的影响，减轻它们的风险，并培养对预测的公平信任。</li></ol></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="3775" class="ls lt iq bd lu lv nn lx ly lz no mb mc jw np jx me jz nq ka mg kc nr kd mi mj bi translated">模型复杂性-可解释性权衡</h1><blockquote class="mk ml mm"><p id="b9c9" class="kw kx mn ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated">在创建一个ML模型时，总是要在模型的准确性/复杂性和模型的可解释性之间进行权衡。</p></blockquote><p id="df62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数简单的预测模型，如线性模型，精确度较低，复杂性较低，并且易于解释。而先进的方法，如神经网络更准确，能够对更复杂的数据进行预测，并且不容易解释。因此平衡可解释性和模型复杂性总是一个挑战。当模型复杂性增加时，可解释性降低。</p><p id="7917" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了不同ML模型在模型复杂性和可解释性之间的权衡。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/a0b28d19b2493712bb1fca246e08a0ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*NDEal6pQY5aeXpnokuA5Ug.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5c3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可解释的人工智能可以在增加高度复杂模型的可解释性方面发挥至关重要的作用。不能自我解释的模型可以与XAI方法接口，该方法可以基于局部和全局解释提供基于特征重要性的洞察。有许多开源框架和技术可以用来向非人工智能专家解释复杂的ML方法。让我们看看技术。</p><h1 id="875f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">XAI技术</h1><p id="a884" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated">XAI技术可以分为两类</p><ol class=""><li id="24eb" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">透明方法</li><li id="d9ff" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">事后方法</li></ol><p id="93ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">透明方法</strong>是模型的内在架构易于解释并且特性关联不复杂的地方。线性/逻辑回归、决策树、KNN和贝叶斯模型都是透明模型的例子。</p><p id="323f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">事后方法</strong>适用于数据中存在复杂决策界限且模型复杂性难以解释的情况。临时方法进一步分为两类-</p><ul class=""><li id="ff80" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr ny my mz na bi translated"><strong class="ky ir">特定于模型- </strong>特定于模型的方法作用于单个或一组模型，并且依赖于特定模型类型的功能和能力。</li><li id="d879" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated"><strong class="ky ir">模型不可知- </strong>模型不可知方法通过分析模型输入&amp;输出特征对任何ML模型起作用，并且不依赖于模型功能或复杂性。当无法解释模型功能时，这些方法非常有用。</li></ul><p id="b0d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了各种XAI技术-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/0c4d8bd2661cbc0c92f956a2efd7c082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*s1xC_15ju-OwGLcPDIax8A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="aae1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上图只显示了一种看待不同类型的XAI方法的方式。XAI还有其他的分类方法</p><ol class=""><li id="854e" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">范围-全局或本地</li><li id="9b9e" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">访问——解释方法对模型的访问是有限的或者完全的</li><li id="9db8" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">解释阶段——在模型开发(培训)期间或培训之后应用解释</li></ol><p id="e636" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">XAI幅员辽阔，方法很多。在这篇文章中，我将只讨论SHAP方法。其余的模型不可知和特定于模型的技术将在XAI帖子的下一部分中讨论。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="3ac6" class="ls lt iq bd lu lv nn lx ly lz no mb mc jw np jx me jz nq ka mg kc nr kd mi mj bi translated">SHAP</h1><p id="a732" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">SHAP</a>(SHapley Additive explaints)方法是python中的一种博弈论方法，使用SHapley值来解释任何机器学习模型的输出。</p><p id="9df1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要了解SHAP，让我们首先了解什么是沙普利价值观。</p><p id="332c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">沙普利值</strong></p><p id="8d6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Shapley值是博弈论中的一个概念，用于测量预测中某个要素实例的平均边际贡献。</p><p id="1b25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们先来了解一下为什么沙普利值很重要。以收入预测为例，我们必须对收入是≤50K还是&gt; 50K进行分类。我们已经使用xgboost分类器来预测收入(你可以在这里找到完整的代码<a class="ae kv" href="https://github.com/charumakhijani/explainable-ai-shap/blob/main/IncomePrediction.ipynb" rel="noopener ugc nofollow" target="_blank"/>)。现在我们必须检查哪些特征对预测有贡献，我们可以使用<strong class="ky ir"> plot_importance </strong>方法来检查。该plot_importance方法有一个名为importance_type的参数，该参数基于<strong class="ky ir">权重(特征在树中出现的次数)、增益(使用该特征的分割的平均增益)和覆盖(使用该特征的分割的平均覆盖范围)</strong>来计算特征重要性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/8e9f9849b972aa8dd79eca0d6cbaf43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8kFXiHKYLuUYDKr4nD6a2Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0dd1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">查看importance_type的这3个值，我们使用Xgboost获得3组不同的特征贡献，但是我们不知道哪一种方法是最好的，也不知道如何获得实际上对模型有贡献的可靠特征。<strong class="ky ir">使用这种方法的第二个问题是，这种方法只能有助于<em class="mn">全局可解释性</em>，如果我们必须获得特定记录的重要特征(<em class="mn">局部可解释性</em> </strong> <em class="mn"> ) </em>)，这种方法将不起作用。</p><p id="3ec2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">python中的SHAP方法可以帮助我们解决这两个问题。</strong>但在研究SHAP实施以及如何解决这些问题之前，首先让我们了解什么是Shapley值，以及如何使用相同的收入预测示例来计算它们。</p><blockquote class="mk ml mm"><p id="729b" class="kw kx mn ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated">虽然SHAP方法对于获得特征对于模型预测的重要性是有用的，但是它不是评估预测本身的度量。</p></blockquote><p id="44a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了预测收入是否大于50K，假设有这三个特征的贡献——年龄、婚姻状况和资本收益。现在让我们来理解这些特性的边际贡献。如下图所示，这里——</p><ul class=""><li id="fdd1" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr ny my mz na bi translated">年龄贡献:2.5万美元</li><li id="a3ea" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">婚姻状况贡献:4.5万美元</li><li id="0a26" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">资本收益贡献:7万美元</li><li id="31ed" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">年龄和婚姻状况:3.2万美元</li><li id="d90d" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">年龄和资本收益贡献:6万美元</li><li id="828b" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">资本收益和婚姻状况贡献:7.5万美元</li><li id="fd53" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">年龄、婚姻状况和资本收益:9.5万美元</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/dd442e591b35437a9aaa2c9b640e322c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*5KppVtmduVsaS_5-mU_fpQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="3d28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了找到年龄的边际贡献，我们必须计算年龄的边际贡献</p><ol class=""><li id="0266" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">50K美元收入组</li><li id="4ff5" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">年龄和婚姻状况组</li><li id="b5fb" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">年龄和资本收益组</li><li id="c651" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">年龄、婚姻状况和资本收益组</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/bf863e3ee84356aff12e2f0e4124844e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zYNJ7Kgb_n2IACBLcsqeSA.png"/></div></div></figure><p id="10a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如下图所示。同样的，我们可以计算所有特性的边际贡献。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/edc9c81bd87ff64acae66f6c72cd7b6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*QqeePn-9SMSR1DSr0rC6jg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4684" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们来计算每个级别的权重。</p><ul class=""><li id="2b11" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr ny my mz na bi translated">第一层有3条边，所以这一层上每条边的权重是1/3——我们称之为<strong class="ky ir"> w1 </strong></li><li id="d8a3" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">第二层有6条边，所以这一层上每条边的权重是1/6——我们称之为<strong class="ky ir"> w2 </strong></li><li id="7cc0" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr ny my mz na bi translated">第三层有3条边，所以这一层上每条边的权重是1/3——我们称之为<strong class="ky ir"> w3 </strong></li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/f48ba3a63c4f2b5b671b4614dcc60e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*QRePu79KmVElxpGmzFlgOA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a1c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们有了所有级别的特征和权重的边际贡献，让我们计算特征的总贡献。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/56408ed6445986371c47262fdb9c7930.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*YSmhnX4DV-vpsg9PmgZ9Bw.png"/></div></figure><p id="7d94" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这表明年龄对收入预测的贡献为-7.5K美元，因此-7.5K美元是年龄的Shapley值。</p><p id="c33c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，我们可以计算婚姻状况和资本收益的Shapley值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d5a7c78f334f1d2230ffab4592c541f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*IQHSOWKo6si1A0h0pUt8SQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="b0ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> SHAP(年龄)= -$7.5K </strong></p><p id="9740" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> SHAP(婚姻状况)=＄11.5k</strong></p><p id="768d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> SHAP(资本收益)=＄38K</strong></p><p id="9bdf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们对这3个特性的Shapley值求和，结果是$42K (-$7.5K+$11.5K+$38K)，相当于从$50K到$92K的收入路径($92K-$50K)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/2e8d554226acfdd153df62a88457aac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*Yqnsb6pZ8ZBC7VZvXMdbxQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a202" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经了解了什么是Shapley值以及如何计算它们，让我们看看用python实现SHAP库的实际方法。</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="a22d" class="ls lt iq bd lu lv nn lx ly lz no mb mc jw np jx me jz nq ka mg kc nr kd mi mj bi translated">Python实现</h1><p id="ddbf" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated">要使用SHAP，首先pip安装<a class="ae kv" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP </a>库并导入它。然后创建一个SHAP解释器对象，并使用它来获得shap值，以解释模型的预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="dd42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们使用 Shapley值来理解全局和局部<em class="mn">可解释性。</em></p><h2 id="a666" class="oj lt iq bd lu ok ol dn ly om on dp mc lf oo op me lj oq or mg ln os ot mi ou bi translated"><strong class="ak">全局可解释性</strong></h2><p id="0ff4" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated"><strong class="ky ir">汇总条形图- </strong>该图以降序显示特征重要性。图顶部的要素对模型预测的贡献较大，而图底部的要素贡献较小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/4513ae85aba53023a614e80a2a87a237.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HEOlF7eaaUbaWkEFTwG33g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="b5b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">汇总图- </strong>汇总图还以降序显示特征重要性，并显示每个特征与目标变量的影响和相关性。对于每次观察，我们可以看到颜色从蓝色(低)变为红色(高)的高/低影响。我们可以看到这种相关性，因为高资本收益(红色)对收入有积极影响(向+ve轴移动)，而年龄与收入呈负相关。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/d47d3c9368f828644384b0e5354fddbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DWEIucxlbD2XaFHH7hWgAA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="2293" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">依赖图-依赖图</strong>显示了一个特性对模型预测的影响。y轴变量是自动选择的，通常情况下，该变量是要素在进行模型预测时更频繁交互的变量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/9dacd6d044e51462318995e9ee771e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9qlBQ1kBGTShiImi8NT6vg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4f7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还可以通过使用参数<strong class="ky ir"> interaction_index </strong>并为y轴提供另一个变量来改变y轴变量和特征交互图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/ac32ee9b60211698cc15a9cef2635cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jz-nC0aUz3Xciv-S6-UQ4g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="2a76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">力图- </strong>力图显示特征如何影响模型输出。贡献较大的要素用红色表示，贡献较小的要素用蓝色表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/034349b86dc56eb1930f0d6fc46e205f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-x0vCt4Xn7sCnLvPwPXyA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="42f7" class="oj lt iq bd lu ok ol dn ly om on dp mc lf oo op me lj oq or mg ln os ot mi ou bi translated"><strong class="ak">本地可解释性</strong></h2><p id="561e" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated"><strong class="ky ir">条形图- </strong>该图显示了特定观察中特征的贡献。下图显示了资本损失、关系和教育是对这一观察最有贡献的特征。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/4db02e6fac6cc9fa66726927620c5177.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uErS4QCBXN1cIMo7uPpMEg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="5262" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">瀑布图- </strong>水流图是另一种在特定观察中绘制特征贡献的方式，如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/0753eac5f22c7246e9f39d7a47dac5f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tu4r3BemwiR_YhVzGiyJQA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="4472" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">力图- </strong>对于一个具体的观察，力图显示了哪些特征最有贡献。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/1445b558f0ab1e43474d137f258ff0f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mBBk559RsJVB9R82IJ84kQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1e80" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用SHAP，我们不仅在全球和本地级别获得了可解释性，而且特征集也不会随着不同的情节而改变。多酷啊！！</p></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><h1 id="b2ba" class="ls lt iq bd lu lv nn lx ly lz no mb mc jw np jx me jz nq ka mg kc nr kd mi mj bi translated">最后的想法</h1><p id="fddd" class="pw-post-body-paragraph kw kx iq ky b kz nt jr lb lc nu ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated">我们已经在上面看到了XAI是如何帮助我们得到关于人工智能系统的为什么和如何的答案的。随着人工智能在许多行业变得越来越主流，对可解释性的需求也在增加。然而，尽管对可解释的人工智能越来越感兴趣，但可解释的人工智能愿景和实践之间存在巨大差距。同一个人工智能算法可能需要多种解释，因此可解释的人工智能在这种情况下将如何有所帮助仍是一个问题。此外，缺乏来自真实世界用例的指导来实现和测试这些解释。</p><blockquote class="mk ml mm"><p id="2bba" class="kw kx mn ky b kz la jr lb lc ld ju le mo lg lh li mp lk ll lm mq lo lp lq lr ij bi translated">最后，XAI是一个新兴的领域，有许多挑战和未解决的问题，但毫无疑问，XAI将在人工智能文学的未来扮演不可或缺的角色。</p></blockquote><p id="b252" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要访问使用Xgboost进行收入预测的完整代码并使用SHAP进行解释，请参考GitHub <a class="ae kv" href="https://github.com/charumakhijani/explainable-ai-shap" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><div class="pd pe gp gr pf pg"><a href="https://github.com/charumakhijani/explainable-ai-shap" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd ir gy z fp pl fr fs pm fu fw ip bi translated">GitHub-charumakhijani/explable-ai-shap</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu kp pg"/></div></div></a></div></div><div class="ab cl ng nh hu ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="ij ik il im in"><p id="160c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谢谢你的阅读。如果你喜欢这个故事，请喜欢，分享和关注更多这样的内容。如往常一样，请联系我们以获得任何问题/评论/反馈。</p><p id="225e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mn">Github:</em><a class="ae kv" href="https://github.com/charumakhijani" rel="noopener ugc nofollow" target="_blank">https://github.com/charumakhijani</a><em class="mn"><br/>LinkedIn:</em>T22】https://www.linkedin.com/in/charumakhijani/</p><p id="5783" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考- </strong></p><p id="fc24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30">https://towards data science . com/shap-explained-the-way-I-wish-someone-explained-it-to-me-ab 81 cc 69 ef 30</a></p></div></div>    
</body>
</html>