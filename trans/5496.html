<html>
<head>
<title>Causal Python — Level Up Your Causal Discovery Skills in Python (2023)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">因果 Python-提升您在 Python 中的因果发现技能(2023)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715#2022-12-11">https://towardsdatascience.com/beyond-the-basics-level-up-your-causal-discovery-skills-in-python-now-2023-cabe0b938715#2022-12-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="40b0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">…并释放 Python 中最佳因果发现包的潜力！</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/062703ba1511b620708e647a969e50f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-t66eXjm-XhVw0lcLUx13A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由佩克斯(【https://www.pexels.com/photo/purple-leaf-459301/】T2)的<a class="ae ky" href="https://www.pexels.com/@pixabay/" rel="noopener ugc nofollow" target="_blank">皮克斯拜拍摄</a></p></figure><h1 id="b3d0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="5bdd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di"> T </span>最近，人们对 Python 中因果关系相关主题的兴趣激增，这带来了大量资源，让人们决定应该关注哪些挑战。</p><p id="b763" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di">例如，互联网上的许多资源将流行的 NOTEARS 算法(郑等，2018)描述为<em class="nb">“最先进的结构学习方法”</em>，然而 NOTEARS 已经多次被证明至少在这方面是有问题的(Kaiser &amp;，，2021；Reisach 等人，2021；Seng 等人，2022 年)。这并不意味着笔记总是无用的，但是不加批判地把它应用到你的问题中可能会给你带来更多的伤害。</span></p><p id="e55c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在这篇博文中，我们将学习如何在 Python 中执行<strong class="lt iu">因果发现</strong>，讨论所选方法的<strong class="lt iu">主要优势</strong>，并强调与因果发现过程相关的<strong class="lt iu">常见风险</strong>。</p><p id="dc46" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">这个博客是<strong class="lt iu">系列</strong>的一部分，我在这里分享关于<a class="ae ky" href="https://aleksander-molak.medium.com/yes-six-causality-books-that-will-get-you-from-zero-to-advanced-2023-f4d08718a2dd" rel="noopener"> <strong class="lt iu">学习</strong> </a>因果关系和<a class="ae ky" rel="noopener" target="_blank" href="/causal-kung-fu-in-python-3-basic-techniques-to-jump-start-your-causal-inference-journey-tonight-ae09181704f7"> <strong class="lt iu">在 Python 中实现</strong> </a>因果模型的实用技巧。</p><blockquote class="nc nd ne"><p id="6d92" class="lr ls nb lt b lu mw ju lw lx mx jx lz nf my mc md ng mz mg mh nh na mk ml mm im bi translated">【链接到<strong class="lt iu">笔记本</strong>和<strong class="lt iu">康达环境</strong>文件<strong class="lt iu">在</strong>下面】</p></blockquote><p id="7dfc" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们学习如何发现！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/36d87883e4b459a3996d4f6720e11047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_qr0MaDygM2_Y2SUwDUJg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://www.pexels.com/@alexant/" rel="noopener ugc nofollow" target="_blank">Alexander Ant</a>@<a class="ae ky" href="https://www.pexels.com/photo/abstract-background-of-bright-paints-5603660/" rel="noopener ugc nofollow" target="_blank">Pexels</a>提供</p></figure><h1 id="59dd" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是因果发现？</h1><p id="9ba8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di"> C </span> <strong class="lt iu">因果发现</strong>，也称为<strong class="lt iu">因果结构学习</strong>表示一套广泛的方法，旨在从观察或干预数据中检索有关因果机制的信息。换句话说，因果发现算法试图解码<strong class="lt iu">数据生成过程</strong>的<strong class="lt iu">因果结构</strong>，使用该过程生成的数据。</p><p id="e1ed" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">这些算法中的一些允许我们以约束的形式容易地结合先验知识(也称为<em class="nb">专家知识</em>)。这有助于缩小问题空间<strong class="lt iu">并使算法更容易找到好的解决方案。</strong></p><p id="dde1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在大多数情况下，我们使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">有向无环图</strong> </a> ( <strong class="lt iu"> DAG </strong>)来描述数据生成过程。</p><h1 id="7868" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">因果发现方法的四大家族</h1><p id="4c34" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">因果发现</strong>算法有<strong class="lt iu">四大类</strong>:</p><ul class=""><li id="e1e8" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">基于约束的</strong></li><li id="6719" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">基于分数的</strong></li><li id="f20a" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">功能性</strong></li><li id="d120" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">其他</strong>(包括混合动力、基于梯度等)</li></ul><p id="128a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">请记住，这种类型学在因果文献中是不一致的，类别也不总是相互排斥的。也就是说，每一种都会带来一些独特的味道。</p><p id="3e4b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们做一些品尝！</p><h1 id="c9ad" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">基于约束的方法</h1><p id="cc3e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">基于约束的方法(也称为<em class="nb">基于独立性的方法</em>)旨在通过利用三元组变量之间的独立性结构，从数据中解码因果结构。听起来很密集？让我们打开它！</p><p id="6700" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">假设我们有一个由三个变量组成的系统:<strong class="lt iu"> <em class="nb"> A </em> </strong>，<strong class="lt iu"> <em class="nb"> B </em> </strong>，<strong class="lt iu"> <em class="nb"> C </em> </strong>。每个变量由图中的一个节点表示，在这样的图中我们只能有两条有向边。而且我们把这些变量保持有序，这样边就只能连接节点<strong class="lt iu"> <em class="nb"> A </em> </strong>和<strong class="lt iu"> <em class="nb"> B </em> </strong>和<strong class="lt iu"> <em class="nb"> B </em> </strong>和<strong class="lt iu"> <em class="nb"> C </em> </strong>。这给了我们三个可能的图表。我们在<strong class="lt iu">图 1 </strong>中展示了它们。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/3515c5fe3e34cfe42e7d49024fcd978c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IuZc6RjSbn-60jwOz7-jw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图一。</strong>三种基本的图形因果结构。真实的你的形象。</p></figure><p id="f0bb" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">上图中的箭头表示变量之间的因果关系(这里我们遵循<a class="ae ky" href="https://causalpython.io/#define-causality" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">珀尔对因果关系的定义</strong> </a>)。在<strong class="lt iu">图 1 </strong>中呈现的每个图形结构都有一个特定的名称。从上到下依次是:</p><ul class=""><li id="205b" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">链条</strong></li><li id="6f10" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">叉子</strong></li><li id="9b28" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">对撞机</strong>(又称<em class="nb">不道德</em>(原文如此！)<em class="nb"> </em>或<em class="nb"> v 型结构</em></li></ul><h2 id="3423" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">独立结构</h2><p id="7bff" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">事实证明，在某些情况下，我们可以在表示数据生成过程的图形结构和作为该过程结果的变量的统计属性之间进行映射。此外，在某些情况下，从数据到图形的另一个方向的映射也是可能的。</p><p id="8216" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在我们在<strong class="lt iu">图 1 </strong>中展示的三种结构中，<strong class="lt iu">对撞机结构</strong>有一个独特的性质。如果你的数据集中的任何三个变量都是从碰撞器结构的因果过程中产生的，我们可以使用成对统计独立性测试从观察数据中检索这些信息。这意味着我们可以根据观察到的数据本身重建图表。太刺激了！</p><p id="e3a4" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">不幸的是，使用叉子和链条的事情并不顺利。这两种图形结构的统计独立性结构是相同的，我们不能明确地将它们映射回图形。尽管如此，如果我们足够幸运，相邻的碰撞器也可以帮助我们恢复和定向分叉和链结构的边缘。</p><blockquote class="nc nd ne"><p id="1cb9" class="lr ls nb lt b lu mw ju lw lx mx jx lz nf my mc md ng mz mg mh nh na mk ml mm im bi translated">如果你想了解更多关于链条、叉子和碰撞器的属性，可以查看<strong class="lt iu">布雷迪·尼尔关于主题的视频</strong>(<a class="ae ky" href="https://www.youtube.com/watch?v=Q9CAtMpuWCA" rel="noopener ugc nofollow" target="_blank">1</a>、<a class="ae ky" href="https://www.youtube.com/watch?v=5xIujBzwi7E" rel="noopener ugc nofollow" target="_blank"> 2 </a>)或<a class="ae ky" href="https://www.youtube.com/watch?v=kyRUDTexwGM&amp;t=2063s" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">这部分</strong> </a> <strong class="lt iu"> </strong>我在<strong class="lt iu"> PyData 汉堡</strong>的演讲或我的<a class="ae ky" href="https://causalpython.io" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">即将出版的关于因果关系的书</strong> </a> <strong class="lt iu">的第六章。</strong></p></blockquote><h2 id="8d2f" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">PC 算法</h2><p id="090d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">基于约束的算法的一个经典例子是<strong class="lt iu"> PC 算法</strong> (Sprites &amp; Glymour，1991)。它的名字来自于它的创造者的名字:彼得·斯普里茨和克拉克·格里穆尔。PC 算法是维尔马&amp;珀尔(1990)早些时候提出的<strong class="lt iu"> IC 算法</strong>的变体。</p><p id="289a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">图 2 </strong>展示了 PC 算法的逐步流程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c83b08e039087689dadf21c816e3de26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*8yJYYwaeg5OvXcJmTM3K1Q.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图二。</strong>PC 算法的逐步可视化(Glymour 等人，2019 年)</p></figure><p id="9c59" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">为了找到地面真相(<strong class="lt iu">图 2 A </strong> ) PC 算法从一个全连通无向图开始(<strong class="lt iu"> B </strong>)。接下来，它移除无条件独立变量之间的边(<strong class="lt iu"> C </strong>)，然后移除有条件独立变量之间的边(<strong class="lt iu"> D </strong>)。最后，该算法基于检测到的<strong class="lt iu"> <em class="nb">碰撞器结构</em> </strong> ( <strong class="lt iu"> E </strong>)找到有向边，并在可能的情况下消除碰撞器相邻边的歧义(<strong class="lt iu"> F </strong>)。</p><p id="1312" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">有时，算法可能无法确定所有边的方向。在这种情况下，返回所谓的<strong class="lt iu">马尔可夫等价类</strong> ( <strong class="lt iu"> MEC </strong>)。实际上，MEC 意味着你得到一个图，它的一些边没有确定的方向。</p><p id="6364" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">PC 算法的一个重要限制是，如果你的数据中有隐藏的<a class="ae ky" href="https://causalpython.io/#confounding" rel="noopener ugc nofollow" target="_blank">混淆</a>，结果可能会被任意误导。PC 算法的推广，称为 FCI(快速因果推理；<a class="ae ky" href="https://amzn.to/3uDx9X8" rel="noopener ugc nofollow" target="_blank"> Sprites 等人，2001 </a>)解决了这个问题(至少在渐近状态下)。</p><p id="8055" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">另一个更普遍的限制是，PC 和 IC 等基于约束的算法依赖于条件独立性测试，这在非参数设置中是一项困难的任务。据我所知，这个问题没有通用的非参数无模型解决方案(Azadkia 等人，2021)。</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ot"><a href="https://aleksander-molak.medium.com/yes-six-causality-books-that-will-get-you-from-zero-to-advanced-2023-f4d08718a2dd" rel="noopener follow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">是啊！六本因果关系书，让你从零到高级(2023)</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">…如果您愿意，您可以完全免费获得其中的 3 个！🤗</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">aleksander-molak.medium.com</p></div></div><div class="pc l"><div class="pd l pe pf pg pc ph ks ot"/></div></div></a></div></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b961712fdb4d147a8ec6856af13d930e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoE3Ohy7D8xr_KFXK7Gfrg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://www.pexels.com/@sebastian/" rel="noopener ugc nofollow" target="_blank">Sebastian Arie Voortman</a>@<a class="ae ky" href="https://www.pexels.com/photo/two-silver-chess-pieces-on-white-surface-411207/" rel="noopener ugc nofollow" target="_blank">Pexels</a></p></figure><h1 id="b627" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">基于分数的方法</h1><p id="65c0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">基于分数的方法通过迭代地生成候选图，评估每个候选图对数据的解释程度，并选择最好的一个来工作。基于分数的方法的一个众所周知的例子是戴维·马克斯韦尔·奇克林(奇克林，2003 年)提出的<strong class="lt iu">贪婪等价搜索</strong> ( <strong class="lt iu"> GES </strong>)。</p><h2 id="31f0" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">GES</h2><p id="9ca7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">他的算法是一个两阶段的过程。首先，它生成边，然后修剪图形。</p><p id="5bf0" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> GES </strong>的第一阶段从一个未连接的图开始。该算法然后迭代地添加边，计算每一步的分数。这种情况一直持续到分数不能再增加为止。在第二阶段，该算法开始<em class="nb">修剪</em>现有的边，以查看分数是否可以进一步提高。所有这些计算都是以贪婪的方式进行的(因此得名)。</p><p id="ef37" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">类似于 PC 算法，GES 对隐藏的混淆敏感。它也可能无法确定所有边的方向，从而为您提供一个可能图形的<a class="ae ky" href="https://www.youtube.com/watch?v=nnjKCtdORwY" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">马尔可夫等价类</strong> </a>(因此再次得名)。</p><p id="b651" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">根据我的经验，尽管有其理论基础，但在应用于现实世界的数据时，GES 的表现往往不如其他方法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/7eeca7d67cd10aad93be75cde301e892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jdjbNtByreK7T1ZIYZtLxg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片由<a class="ae ky" href="https://www.pexels.com/@shkrabaanthony/" rel="noopener ugc nofollow" target="_blank">Antoni shk raba</a>@<a class="ae ky" href="https://www.pexels.com/photo/compass-in-a-case-6969337/" rel="noopener ugc nofollow" target="_blank">Pexels</a></p></figure><h1 id="d31e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">功能方法</h1><p id="c754" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在某种意义上，大多数函数式方法都可以被认为是基于分数的方法，因为它们在某种程度上涉及某种拟合优度计算。另一方面，它们的机制不同于后者。经典的泛函方法，如<a class="ae ky" href="https://sites.google.com/view/sshimizu06/lingam" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> LiNGAM </strong> </a> ( <strong class="lt iu">线性非高斯无环模型</strong>；Shimizu 等人，2006 年)利用数据中的分布不对称性，而不是(贪婪的)边搜索，以便从数据中检索因果关系。</p><h2 id="de6c" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">男性生殖器像</h2><p id="ea29" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di"> L </span> <strong class="lt iu"> iNGAM </strong>(线性非高斯非循环模型)由 Shohei Shimizu 及其同事于 2006 年首次提出。原始方法使用<a class="ae ky" href="https://en.wikipedia.org/wiki/Independent_component_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">独立分量分析</strong> </a> ( <strong class="lt iu"> ICA </strong>)来检索关于数据生成过程的信息。其后来的变体 DirectLiNGAM (Shimizu 等人，2011 年)利用了线性模型和基于内核的独立性度量。</p><p id="066d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">LiNGAM 背后的两个<strong class="lt iu">主要假设</strong>是:</p><ul class=""><li id="dd2f" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">没有隐藏的变乱</strong></li><li id="863b" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">所有(或除一个之外的所有)误差项都是非高斯的</strong></li></ul><p id="f728" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">也就是说，人们对 LiNGAM 提出了各种扩展，允许将该模型应用于具有<strong class="lt iu">隐藏混杂</strong>(霍耶等人，2008 年)或<strong class="lt iu">周期</strong>(拉塞达等人，2008 年)的场景。</p><p id="6097" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">LiNGAM 背后的主要思想是<strong class="lt iu">相对简单</strong>。想象一个简单的线性系统，只有两个变量<strong class="lt iu"> <em class="nb"> X </em> </strong>和<strong class="lt iu"> <em class="nb"> Y </em> </strong>，其中<strong class="lt iu"> <em class="nb"> X </em> </strong>导致<strong class="lt iu"> <em class="nb"> Y </em> </strong>。您可以对该数据进行两个方向的线性回归:在<strong class="lt iu"/>上回归<strong class="lt iu"><em class="nb">Y</em></strong>X(<strong class="lt iu"><em class="nb">X→Y</em></strong>)或者在<strong class="lt iu"><em class="nb">Y</em></strong>(<strong class="lt iu"><em class="nb">Y→X</em></strong>)上回归<strong class="lt iu"> <em class="nb"> X </em> </strong>。如果数据中的误差项是高斯型的，那么这些模型不会告诉你任何关于因果方向的信息。两个模型的残差将是完全独立的。</p><p id="6876" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">然而，如果你的误差项是非高斯的…</p><p id="89d5" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们可以打破对称！</p><p id="465a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">事实证明，当我们试图对<strong class="lt iu">非因果方向</strong>建模时，非高斯数据将迫使线性回归返回<strong class="lt iu">相关残差</strong>。</p><p id="500f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">图 2 </strong>展示了一个简单实验的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pi"><img src="../Images/e72e247a5f484658e54c4111c5f6377f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*977XB3GQ6G2A3iJPnakusQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图二。</strong>当回归真实模型 X 的高斯和非高斯数据时的原始数据和残差- &gt; Y .左半部分:在 X 上回归 Y；右半部分:在 y 轴上回归 X 轴。真实的你的图像。</p></figure><p id="9e27" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">请注意，对于高斯误差项(顶行)，当我们回归<strong class="lt iu"><em class="nb">Y</em></strong>on<strong class="lt iu"><em class="nb">X</em></strong>(左)和<strong class="lt iu"><em class="nb">X</em></strong>on<strong class="lt iu"><em class="nb">Y</em></strong>(右)时，残差看起来非常相似。对于非高斯数据(底行)，残差在因果方向上不相关(<strong class="lt iu"><em class="nb">Y ~ X</em></strong>)；左)，但在非因果方向上变得相关(<strong class="lt iu"><em class="nb">X ~ Y</em></strong>；对)。</p><h1 id="881e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">其他方法</h1><p id="389f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">这些方法是一个庞大的范畴！我选择了一种方法让我们今天讨论。该算法被称为<strong class="lt iu"> GOLEM </strong>，由 Ignavier Ng 及其同事在他们的 NeurIPS 2020 论文中介绍(Ng 等人，2020)。<strong class="lt iu"> GOLEM </strong>可以归类为<strong class="lt iu">基于梯度的方法</strong>(这意味着它使用梯度下降进行优化)，在某种意义上，它也是一种基于分数的方法，因为我们在途中计算数据似然分数。</p><p id="9e02" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">傀儡<strong class="lt iu">有两个变种</strong>:</p><ul class=""><li id="09ae" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">魔像 EV </strong></li><li id="c1a3" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">傀儡女</strong></li></ul><p id="a468" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Reisach 等人(2021)已经表明 GOLEM EV 在非标准化数据上优于它的 NV 对应物。</p><h2 id="86ce" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">不流泪</h2><p id="c00a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">GOLEM 是<strong class="lt iu"> NOTEARS 算法</strong>的继承者(郑等，2018)。NOTEARS 是革命性的，因为它是第一个将<strong class="lt iu">结构学习</strong>框定为纯粹的<strong class="lt iu">连续优化</strong>问题的算法(在某些情况下，它减少了 DAG 搜索空间爆炸的问题，这种爆炸随着节点数量的增加而超指数地增长，但它并不总是这样做；Reisach 等人，2021 年)。</p><p id="01e2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">尽管开始时很有希望，但 NOTEARS 被反复证明不适合稳定的因果发现(凯泽&amp;希波什，2021；Reisach 等人，2021；Seng 等人，2022 年)。虽然 GOLEM 不能解决 NOTEARS 带来的所有问题，但是根据我的经验，它在实践中的某些情况下效果很好。</p><p id="12d4" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">要了解更多关于傀儡如何工作的信息，请查看 Ng 等人的文章。</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><div class="kj kk kl km gt ot"><a rel="noopener follow" target="_blank" href="/causal-kung-fu-in-python-3-basic-techniques-to-jump-start-your-causal-inference-journey-tonight-ae09181704f7"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">因果 Python: 3 个简单的技术，今天就开始你的因果推理之旅</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">学习 3 种识别因果关系的技术，并在 Python 中实现它们，而不会损失几个月、几周或几天的时间…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">towardsdatascience.com</p></div></div><div class="pc l"><div class="pj l pe pf pg pc ph ks ot"/></div></div></a></div></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="ec2b" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">准备好把手弄脏了吗？</p><h1 id="a805" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">我城堡的国王</h1><p id="cad4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">先介绍一下今天博文的主人公——<strong class="lt iu">g castle</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/7d2bfe0ab990abf8fb305aa7d53c86cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fcDqOeT9Eb8-LLf2gFHhzQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图三。</strong> gCastle 标志。来源:<a class="ae ky" href="https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle" rel="noopener ugc nofollow" target="_blank">https://github . com/Huawei-Noah/trustworthyAI/tree/master/g castle</a></p></figure><p id="d428" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> g </strong> <a class="ae ky" href="https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">城堡</strong> </a> <strong class="lt iu"> </strong>是由<a class="ae ky" href="https://www.noahlab.com.hk/#/home" rel="noopener ugc nofollow" target="_blank">华为诺亚方舟实验室</a>开发的开源库。该软件包为我们提供了一个令人惊叹的最新的因果结构学习工具包，包括:</p><ul class=""><li id="1e52" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">数据相关工具</strong>(包括模拟和预处理)</li><li id="03b9" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated">一组广泛的<strong class="lt iu">因果发现算法</strong></li><li id="41eb" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">评估指标</strong></li></ul><p id="ff38" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">当前可用算法的完整列表可在<a class="ae ky" href="https://github.com/huawei-noah/trustworthyAI/tree/master/gcastle" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">此处</strong> </a> <strong class="lt iu">获得。</strong></p><p id="fa4f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">据我所知，这是<strong class="lt iu"/><strong class="lt iu">最大的</strong>、<strong class="lt iu">最完整的</strong>和<strong class="lt iu">最新的</strong>因果发现算法列表，你可以在<strong class="lt iu">任何开源的因果 Python 包</strong>中找到。</p><p id="3825" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">你知道什么是最好的吗？这个名单正在<strong class="lt iu">系统地增长</strong>！</p><p id="68e7" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu"> gCastle </strong>的一个很大的优势是，它为我们提供了一个统一的、非常直观的、优雅的 API，用于与各种因果模型进行交互。忘记加载五个不同的因果发现包，其中两个移植到 R，每个都有完全不同的 API，以便比较几个经典算法。<strong class="lt iu"> gCastle </strong>让这一切变得简单多了！</p><p id="c55d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">但是不要把我的话当成理所当然。你自己看吧。</p><h1 id="230c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">我们开始吧！</h1><p id="4423" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di">在</span>这一节中，我们将使用<strong class="lt iu"> gCastle </strong>实现并比较四种因果发现算法:</p><ul class=""><li id="4b02" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">电脑</strong></li><li id="a84b" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu"> GES </strong></li><li id="7e47" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu"> ICA-LiNGAM </strong></li><li id="5183" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">傀儡</strong></li></ul><p id="34b2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">先说导入和一些基础设置。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 1。</strong>导入和基本设置</p></figure><p id="7310" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们导入<code class="fe pn po pp pq b">os</code>模块来修改 gCastle 的环境变量，并将库的后端设置为 PyTorch。我们导入<code class="fe pn po pp pq b">OrederedDict</code>来很好地组织我们的实验，导入<code class="fe pn po pp pq b">networkx</code>来可视化图形。</p><p id="11bd" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">接下来，我们有几个来自<code class="fe pn po pp pq b">castle</code>的对象(这就是<strong class="lt iu"> gCastle </strong>如何出现在 Python 的名称空间中):</p><ul class=""><li id="753d" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><code class="fe pn po pp pq b">GraphDAG</code>用于绘制邻接矩阵</li><li id="e5c0" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><code class="fe pn po pp pq b">MetricsDAG</code>用于自动化指标计算</li><li id="5e2e" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated">用于生成模拟数据的<code class="fe pn po pp pq b">DAG</code>和<code class="fe pn po pp pq b">IIDSimulation</code></li><li id="22f1" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated">型号:<code class="fe pn po pp pq b">PC</code>、<code class="fe pn po pp pq b">GES</code>、<code class="fe pn po pp pq b">ICALiNGAM</code>和<code class="fe pn po pp pq b">GOLEM</code></li></ul><h2 id="a7a8" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">开始简单</h2><p id="7707" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">我们将从实现图 2 中的例子开始。我们将根据<strong class="lt iu">图 2 </strong>中的图<strong class="lt iu"> A </strong>生成一些线性高斯数据，并使用<strong class="lt iu"> PC 算法</strong>从数据中恢复该图的结构。我们的数据集将由 1000 个样本组成。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 2。</strong>按照图 2A 所示的结构随机生成 1000 个样本。</p></figure><p id="f326" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们实例化并拟合模型，并打印出学习到的图表。我们之前说过，<strong class="lt iu"> gCastle </strong>为我们提供了一个统一的因果发现模型的训练 API。为了拟合模型，我们使用模型的<code class="fe pn po pp pq b">.learn()</code>方法。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 3。</strong>实例化并拟合 PC 算法。模型训练完成后，我们打印出学习过的结构。</p></figure><p id="37c6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">注意，所学习的图形被表示为<a class="ae ky" href="https://en.wikipedia.org/wiki/Adjacency_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">邻接矩阵</strong> </a>。</p><p id="400e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们绘制学习过的图形，并将其与原始图形进行比较。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 4。</strong>绘制学习过的图形。</p></figure><p id="e679" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们使用<code class="fe pn po pp pq b">networkx</code>将邻接矩阵投射到一个<code class="fe pn po pp pq b">nx.DiGraph()</code>对象上，并绘制它。途中，我们重新标记了节点，以便于解释。</p><p id="d530" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><strong class="lt iu">图 4 </strong>呈现学习图形(右)和地面实况(左)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/4631fcbc9c823452c364f918ef419fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-c4WILnWd5L9TTOw-0R8-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图 4。</strong>来自图 2A 的原始图形(左)和由 PC 算法学习的图形(右)。来源:Glymour 等人，2019(左)，yours truly(右)。</p></figure><p id="8ede" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">两种表示看起来不同，但是它们表示相同的图(如果有疑问，写下它们中每一个的有向边列表；名单是一样的吗？).</p><p id="6c28" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">这意味着 PC 能够完美地恢复结构！恭喜 PC！🎉</p><h2 id="9eec" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">波涛汹涌的水域</h2><p id="65de" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">在第一个例子中，PC 算法非常有效。这是个好消息！现在是时候看看它在更复杂的情况下表现如何了。</p><p id="3d83" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们将探索 PC 算法的能力，看看它与其他三种算法相比如何。</p><p id="f0f9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们从生成一个有 10 个节点和 15 条边的随机 DAG 开始。我们将使用一个<a class="ae ky" href="https://en.wikipedia.org/wiki/Scale-free_network" rel="noopener ugc nofollow" target="_blank">无标度网络</a>来生成我们的图。然后，我们将使用此 DAG 作为结构模型来生成三个不同的数据集:</p><ul class=""><li id="b3cc" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><strong class="lt iu">线性高斯</strong></li><li id="f008" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">线性指数</strong></li><li id="c474" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">非线性二次型</strong></li></ul><p id="e662" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">并将它们存储在 Python 字典中。参见<strong class="lt iu">代码块 5 </strong>实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 5。</strong>生成一个随机 DAG 和三个不同的数据集。</p></figure><p id="067f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">注意，在双 for 循环中，我们为每组条件(线性高斯、线性指数等)创建了一个新的<code class="fe pn po pp pq b">IIDSimulation</code>对象实例。您可以通过检查<strong class="lt iu">代码块 5 </strong>底部的打印输出来验证我们的数据集是否属于类别<code class="fe pn po pp pq b">castle.datasets.simulator.IIDSimulation</code>。</p><p id="8407" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我们现在准备运行我们的比较。我们首先创建一个 Python 字典，用算法的名称作为键，用<strong class="lt iu"> gCastle </strong>对象表示算法的值。</p><p id="6e7a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">接下来，我们遍历数据集，并在每个数据集上训练每个模型。请注意，为了确定算法的迭代次数，我们实例化 GOLEM 的方式与其他模型不同。检查<strong class="lt iu">代码块 6 </strong>中的执行情况。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pl pm l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">代码块 6。</strong>在三个数据集上训练所有四个模型，并打印出结果。</p></figure><p id="7949" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在每次迭代中，我们绘制真实 DAG、发现的 DAG，并打印出六个评估指标:</p><ul class=""><li id="2d43" class="nj nk it lt b lu mw lx mx ma nl me nm mi nn mm no np nq nr bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/False_discovery_rate" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">假发现率</strong></a><strong class="lt iu"/>(<strong class="lt iu">FDR</strong>)</li><li id="abba" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">召回</strong> </a></li><li id="35e2" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">精度</strong> </a></li><li id="af30" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/F-score" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu"> F1 得分</strong> </a></li><li id="bc35" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><a class="ae ky" href="https://rdrr.io/cran/pcalg/man/shd.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">结构海明距离</strong></a><strong class="lt iu"/>(<strong class="lt iu">SHD</strong>)</li><li id="2545" class="nj nk it lt b lu ns lx nt ma nu me nv mi nw mm no np nq nr bi translated"><strong class="lt iu">无向边的数量</strong></li></ul><h1 id="cef4" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结果</h1><p id="877c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated"><strong class="lt iu">图 5 </strong>显示了 SHD 方面的结果。要获得完整的结果，请查看笔记本(下面的链接)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/19e6f64b308ba23cf45deab16ee25f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZoK7r911AMfpq4KPOxP04g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd ny">图 5。</strong>每个数据集/模型组合的 SHD。真实的你的形象。</p></figure><p id="f603" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">零 SHD 意味着模型能够完美地恢复<strong class="lt iu">的真实结构</strong>。正如我们所见，GOLEM 平均表现最好，但在非线性二次数据集上表现很差。这个数据集是所有算法中最难的。请注意 LiNGAM 如何在线性指数数据上表现良好，而在其他两个数据集上表现不佳。原因是线性指数数据集是唯一符合模型假设(线性、非高斯、非循环)的数据集。与其他模型相比，GES 的表现严重落后，但在最具挑战性的数据集上却给出了最佳结果。也就是说，我们需要记住，SHD 并没有讲述整个故事。</p><p id="49d6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我鼓励您检查笔记本以获得完整的结果，并从其他角度分析数据(例如，错误发现率或精确度)。根据您的用例，可能 FDR 对您来说比总体正确性更重要。</p><h1 id="d4fb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">包装它</h1><p id="17b5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">恭喜你！你坚持到了最后！👏🏼👏🏼👏🏼</p><p id="0f18" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">让我们快速回顾一下！</p><p id="c438" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di">在今天的</span>博文中，我们了解了四类<strong class="lt iu">因果发现方法</strong>。我们讨论了它们的一些主要优缺点，并使用 awesome <strong class="lt iu"> gCastle </strong>库在 Python 中实现了它们。</p><p id="2578" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">读完这篇博文和附带的代码后，你应该能够将讨论过的技术应用到你自己的数据集和问题中。</p><h2 id="3385" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">最后的想法(不要错过！)</h2><p id="4e24" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated"><span class="l mo mp mq bm mr ms mt mu mv di"> C </span>因果发现是一个<strong class="lt iu">难题</strong>，在使用因果发现方法时，总是格外谨慎<strong class="lt iu">是有好处的。在进入下一阶段之前，确保检查两次您的结果，并使用任何可用的验证方法(专家知识、<a class="ae ky" rel="noopener" target="_blank" href="/causal-kung-fu-in-python-3-basic-techniques-to-jump-start-your-causal-inference-journey-tonight-ae09181704f7"> <strong class="lt iu">反驳测试</strong> </a>),并记住在<strong class="lt iu">现实世界</strong>中，很难从因果发现方法中获得<strong class="lt iu">任何</strong> <strong class="lt iu">保证</strong>，尤其是如果您无法确定所有相关变量是否都出现在您的数据集中。</strong></p><p id="cd19" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">如果您有机会在感兴趣的系统上执行<strong class="lt iu">最小干预</strong>，来自这种干预的数据可以用来以更可靠的方式验证您的因果图。有一些有趣的方法可以让你在这种情况下选择最佳的干预措施，但那是另一篇文章的内容了。</p><p id="2f12" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">要了解更多关于因果发现和因果推理的知识，请加入我们快速发展的社区，地址:<a class="ae ky" href="https://causalpython.io" rel="noopener ugc nofollow" target="_blank"><strong class="lt iu">【causal python . io</strong></a>！</p><h2 id="208e" class="nz la it bd lb oa ob dn lf oc od dp lj ma oe of ll me og oh ln mi oi oj lp ok bi translated">代码和环境</h2><p id="4185" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">笔记本和环境文件在这里:</p><div class="pt pu gp gr pv ot"><a href="https://github.com/AlxndrMlk/blogs-code/tree/main/Beyond%20The%20Basics!%20Level%20Up%20Your%20Causal%20Discovery%20Skills%20in%20Python%20Now%C2%A0%282023%29" rel="noopener  ugc nofollow" target="_blank"><div class="ou ab fo"><div class="ov ab ow cl cj ox"><h2 class="bd iu gy z fp oy fr fs oz fu fw is bi translated">博客-代码/超越基础！提升你在 Python 中的因果发现技能，现在(2023)在 main …</h2><div class="pa l"><h3 class="bd b gy z fp oy fr fs oz fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="pb l"><p class="bd b dl z fp oy fr fs oz fu fw dk translated">github.com</p></div></div><div class="pc l"><div class="pw l pe pf pg pc ph ks ot"/></div></div></a></div></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="85d1" class="kz la it bd lb lc px le lf lg py li lj jz pz ka ll kc qa kd ln kf qb kg lp lq bi translated">脚注</h1><p id="1d60" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">注意，如果使用例如互信息来测试(不)依赖性，这甚至可以用于高度非线性和/或非单调数据。也就是说，为了使其工作，需要满足某些条件(例如，忠实假设)。</p><p id="7257" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最初的论文建议贝叶斯信息准则(BIC)作为一个分数，但历史上也使用过许多其他分数。</p><p id="1887" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">结构汉明距离类似于<a class="ae ky" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjAy_GopvL7AhUZa6QEHYMbDswQFnoECBAQAQ&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FHamming_distance&amp;usg=AOvVaw0hUr5LPl0FZNyI29MTfrIU" rel="noopener ugc nofollow" target="_blank">汉明距离</a>。<strong class="lt iu"> SHD </strong>通过计算将前者转变为后者所需的边插入、删除和翻转(反转)次数来测量真实图和恢复图之间的距离。</p><h1 id="c564" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="295e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Azadkia，m .，Taeb，a .，和 Buhlmann，P. (2021 年)。一种快速的非参数局部因果结构学习方法。</p><p id="b912" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">奇克林博士(2003 年)。基于贪婪搜索的最优结构识别。<em class="nb"> J .马赫。学习。第 3507-554 号决议。</em></p><p id="34eb" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Glymour，c .，Zhang，k .，&amp; Spirtes，P. (2019)。回顾基于图形模型的因果发现方法<em class="nb">。遗传学前沿，10。</em></p><p id="7350" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Hoyer，P.O .，Shimizu，s .，Kerminen，A.J .，&amp; Palviainen，M. (2008)。用带隐变量的线性非高斯因果模型估计因果效应。<em class="nb"> Int。j .大约。原因。，49 </em>，362–378。</p><p id="51a4" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">凯撒和希波什(2021)。注释不适合因果图发现。<em class="nb"> ArXiv，abs/2104.05441 </em>。</p><p id="3212" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">拉塞达、斯皮尔特斯、拉姆齐和霍耶出版公司(2008 年)。通过独立成分分析发现循环因果模型。<em class="nb">人工智能不确定性会议</em>。</p><p id="0077" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">吴，张，张(2020)。稀疏性和 DAG 约束在学习线性 DAG 中的作用。<em class="nb"> ArXiv，abs/2006.10201 </em>。</p><p id="daf2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Reisach，A.G .，Seiler，c .，&amp; Weichwald，S. (2021 年)。小心模拟匕首！加性噪声模型中的变量可排序性。ArXiv，abs/2102.13647 。</p><p id="c9e1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Seng，j .、Zecevic，m .、Dhami，D.S .、k .和 Kersting(2022)。撕开注释:通过方差操作控制图形预测。<em class="nb"> ArXiv，abs/2206.07195 </em>。</p><p id="0961" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Shimizu，s .，Hoyer，p .，Hyvä rinen，a .，和 Kerminen，A. (2006 年)。用于因果发现的线性非高斯无环模型。j .马赫。学习。第 7 号决议，2003 年至 2030 年。</p><p id="4d50" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Shimizu，t . in azumi，Sogawa，y .，Hyvä rinen，a .，Kawahara，y .，Washio，t .，Hoyer，P.O .，&amp; Bollen，K.A. (2011 年)。DirectLiNGAM:学习线性非高斯结构方程模型的直接方法。<em class="nb"> J .马赫。学习。第 12 </em>号决议，1225–1248。</p><p id="467e" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Spirtes，p .和 Glymour，C. (1991 年)。稀疏因果图的快速恢复算法。<em class="nb">社科计算机评论</em>，<em class="nb"> 9 </em> (1)，62–72 页。</p><p id="f429" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">Spirtes，p .，Glymour，c .和 Scheines，R. (2001 年)。<em class="nb">因果关系、预测和搜索</em>，第二版。麻省理工出版社。T13】</p><p id="96c6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">维尔马和珀尔(1990 年)。因果模型的等价与综合。第六届人工智能不确定性会议论文集，220–227。</p><p id="5377" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">郑，x .，阿拉干，b .，拉维库马尔，p .，&amp;邢，E.P. (2018)。无泪 DAGs:结构学习的持续优化。<em class="nb">神经信息处理系统</em>。</p><blockquote class="nc nd ne"><p id="a840" class="lr ls nb lt b lu mw ju lw lx mx jx lz nf my mc md ng mz mg mh nh na mk ml mm im bi translated">这篇文章中的一些书籍链接是亚马逊会员链接，通过使用这些链接购买，你将支持作者(或他们的家庭)和我的写作(我将从你的每一笔购买中获得一小笔费用)。谢谢大家！</p></blockquote></div></div>    
</body>
</html>