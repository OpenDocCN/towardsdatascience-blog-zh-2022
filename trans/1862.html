<html>
<head>
<title>Build an Image Duplicate Finder System: A Guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建图像重复查找器系统:指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-guide-to-building-an-image-duplicate-finder-system-4a46021410f1#2022-04-30">https://towardsdatascience.com/a-guide-to-building-an-image-duplicate-finder-system-4a46021410f1#2022-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="521e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你的零英雄指南检测重复和近似重复的图像</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/98245ff082b9f8ed4267bccaec13e4fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6FgPwIICQQrB3APnUsgRA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由来自<a class="ae kv" href="https://pixabay.com/illustrations/koi-fish-painting-japanese-dragon-4410009/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的Manu9899提供</p></figure><p id="b526" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您想识别重复或近似重复的图像吗？或者计算数据集中每个图像的副本数？</p><p id="7270" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如果是的话，那么这篇文章就是给你的。</strong></p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="5e4d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文的目标有五个方面:</p><ol class=""><li id="f915" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">理解图像重复查找器和基于内容的图像检索系统之间的区别</li><li id="a9f9" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">演练比较相似图像的5种不同方法的概念</li><li id="3751" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">学习python中的每个方法实现</li><li id="6244" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">确定图像变换对所述算法的整体性能的敏感度</li><li id="c380" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">从速度和准确性(包括实验)方面为选择适合您应用需求的最佳方法铺平道路</li></ol></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="4d73" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">基本架构</h1><p id="3dda" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">首先，我需要定义一个重要的术语。<strong class="ky ir"> <em class="nk">查询图像</em> </strong>是用户输入以获取信息的图像。在相似性块的帮助下，系统在数据集中搜索相似的图像，该数据集计算图像彼此的接近程度。图1说明了这些步骤。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/4cabe1f9f8345ac696ee1480c2575bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xy-r9xR39-INNzGGuz9s0w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图像1 —图像重复查找器系统的基本结构(作者提供的图像)</p></figure><p id="6e68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第3节中，我们将研究这个相似性模块，并探索实现该功能的最常见方法。</p><h1 id="3b11" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">图像重复查找器与基于内容的图像检索系统</h1><p id="2eff" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">这两种系统的主要区别在于，图像重复/近似重复探测器仅检测相同和近似相同的图像(图2)。另一方面，<a class="ae kv" href="https://en.wikipedia.org/wiki/Content-based_image_retrieval#:~:text=Content%2Dbased%20image%20retrieval%2C%20also,this%20survey%20for%20a%20scientific" rel="noopener ugc nofollow" target="_blank">基于内容的图像检索(CBIR) </a>系统搜索相似的感兴趣区域，并显示与这些区域最相似的图像(图像3)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/dc48ed93839f9f182d7a6ae7575310cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xs-3h_qrgsEoruh2h7V_kw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片2 —图片重复查找系统的详细示例(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/80aca33b959009f0f97a0ee3fb1175be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tqyhMwZTTwLzGmsGSFsQEw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3 —基于内容的图像检索系统的详细示例(图片由作者提供)</p></figure><p id="6390" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意基于内容的图像检索系统是如何识别苹果并输出不同场景的图像的。</p><h1 id="6d1d" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">比较相似图像的五种常用方法</h1><p id="e780" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">本文将考察五种主要方法:</p><ol class=""><li id="a1bc" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">欧几里得距离</li><li id="e245" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">结构相似性指数度量(SSIM)</li><li id="e044" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">图像哈希</li><li id="10ea" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">余弦相似性</li><li id="f05b" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">特征的相似性(使用CNN)</li></ol><h2 id="ac8b" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">1.欧几里得距离</h2><p id="c523" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">转到第一种方法，如图4所示，欧几里德距离是平面上两个数据点之间的直线距离[ <a class="ae kv" href="https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7" rel="noopener"> 8 </a> ]。它也被称为L2范数距离度量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/b47833fa113c2174b37d7733b98b6ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeiXiUkJedNaEGnpBA1FnQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片4 —欧几里得距离(图片由作者提供)</p></figure><p id="eece" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以用向量来表示图像。矢量是一个有一个起点和一个终点的量[ <a class="ae kv" href="https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/08%3A_Further_Applications_of_Trigonometry/8.08%3A_Vectors" rel="noopener ugc nofollow" target="_blank"> 4 </a> ]。这两点构成了矢量的两个特征:大小和方向。</p><p id="26f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在向量空间中，假设我们有两张图片来比较x =[x1，x2，x3]和y = [y1，y2，y3]。图5显示了通式[ <a class="ae kv" href="https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7" rel="noopener"> 8 </a> ]，而图6显示了一个使用示例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/628ddf63e16498716a194602ec35b2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GD4w_WP81VvCKWpSVX0F_w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5 —欧几里德距离的一般公式(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/657600f2381b5c0ce34a5f9d3a7b8c4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gQxd4FznmWPKHlfD0ZzsCA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图6-应用欧几里得距离公式的示例(图片由作者提供)</p></figure><p id="a358" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">方法公式很简单。由于它类似于勾股定理公式，所以又称为勾股距离[ <a class="ae kv" href="https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7" rel="noopener"> 8 </a> ]。</p><p id="3f31" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在python中，实现非常简单:</p><ul class=""><li id="fbc7" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr oi mf mg mh bi translated"><strong class="ky ir">实现1: </strong>使用Scipy库</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><ul class=""><li id="f2ee" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr oi mf mg mh bi translated"><strong class="ky ir">实现2: </strong>使用NumPy的linalg.norm ( <a class="ae kv" href="https://bit.ly/3yfghJp" rel="noopener ugc nofollow" target="_blank">引用</a>)</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="a5e5" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">2.S <strong class="ak">结构相似指数测度</strong> ( <strong class="ak"> SSIM </strong></h2><p id="6107" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">论文<a class="ae kv" href="https://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nk">图像质量评估:从错误可见性到结构相似性</em></a><em class="nk"/><a class="ae kv" href="https://www.cns.nyu.edu/pub/eero/wang03-reprint.pdf" rel="noopener ugc nofollow" target="_blank"><em class="nk">1</em></a><em class="nk">】介绍了SSIM在2004年。</em>它计算两个给定图像之间的相似度，得出一个介于0和1之间的值。</p><p id="1ebd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了寻找副本，它的许多应用之一是测量压缩图像如何影响其质量。此外，它还估计数据传输损失如何严重降低质量[ <a class="ae kv" href="https://www.imatest.com/docs/ssim/" rel="noopener ugc nofollow" target="_blank"> 2 </a> ]。</p><p id="335b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据作者的说法，影响该指数的三个主要因素是亮度、对比度和结构。因此，如果这些因素中的一个发生变化，指数也会发生变化。</p><p id="82d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">至于实现，它是如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="37c7" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">3.图像哈希</h2><p id="da60" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">另一种计算两幅图像之间相似性的方法是图像哈希(也称为数字指纹)。这是为每个图像分配唯一哈希值的过程。但是，该方法会导致相同的值。平均散列是许多散列类型中的一种。它的工作方式如下[ <a class="ae kv" href="https://content-blockchain.org/research/testing-different-image-hash-functions/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]。此外，请参考图7进行澄清。</p><ol class=""><li id="bf59" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">缩小图像尺寸(例如:8x8)</li><li id="8f14" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">将其转换为灰度</li><li id="4a85" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">取其平均值</li><li id="e223" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">将每个像素与平均值进行比较。如果像素高于平均值，则为其赋值1，否则为0</li><li id="a012" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">构造散列:将64位设置为64位整数</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/1450a3e31a530c56e029ffa09797063c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SG4e7D7w2iASpGHqDUvbXA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图7 —平均哈希步骤(作者图片)</p></figure><p id="f7c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由此产生的64位整数<strong class="ky ir"> <em class="nk">可能是</em> </strong>的样子:</p><p id="692c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">1011111101100001110001110000111101101111100001110000001100001001</p><p id="83e2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">注<em class="nk">可能</em>可能</strong>。我们可以用不同的方式来表现这个形象。从左上角开始列出0和1位(如上例所示)，从右上角开始，依此类推[ <a class="ae kv" href="https://content-blockchain.org/research/testing-different-image-hash-functions/" rel="noopener ugc nofollow" target="_blank"> 6 </a> ]。</p><p id="c381" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最重要的是，如果我们改变长宽比，增加或减少亮度或对比度，甚至改变图像的颜色，其哈希值将是相同的[ <a class="ae kv" href="https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]，这使其成为比较同一性的最佳方式之一。</p><p id="6f38" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">比较两幅图像的过程如下[ <a class="ae kv" href="https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html" rel="noopener ugc nofollow" target="_blank"> 7 </a> ]:</p><ol class=""><li id="4474" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">构建每个图像的散列(按照上面的5个步骤)</li><li id="ace7" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">计算<a class="ae kv" href="http://en.wikipedia.org/wiki/Hamming_distance" rel="noopener ugc nofollow" target="_blank">汉明距离</a>。(通过计算与每个散列不同的比特位置的数量)零距离表示相同的图像。(下面的代码块对此有更好的解释)</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="ef2d" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">4.余弦相似性</h2><p id="fe12" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">余弦相似度是一种计算两个向量(可以是图像)相似度的方法，通过取点积并除以每个向量的幅度[ <a class="ae kv" href="https://clay-atlas.com/us/blog/2020/03/27/cosine-similarity-text-calculate-python/" rel="noopener ugc nofollow" target="_blank"> 9 </a> ]，如下图8所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/d80c2daa673190c4fdbdbd8321533f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v97gyi4PHfcJEtB0xZ7bBg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片8 —余弦相似性方程(图片由作者提供)</p></figure><p id="1f30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">随着两个向量之间的角度变小，相似性变强[ <a class="ae kv" href="https://clay-atlas.com/us/blog/2020/03/27/cosine-similarity-text-calculate-python/" rel="noopener ugc nofollow" target="_blank"> 9 </a> ]。如图9所示，与A和B相比，矢量C和B具有很高的相似性，因为它们的角度非常小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/48fe3e582c17c8636a7e19445caa70e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RIftefvOItIJM2pNNik23g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片9-余弦相似性插图(图片由作者提供)</p></figure><p id="d747" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是使用torch计算两幅PIL图像的度量的代码。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><h2 id="aecb" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">5.特征的相似性(使用CNN)</h2><p id="b0ad" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">最后一种比较图像的方法是计算特征的相似性。众所周知，卷积神经网络CNN可以挑选图像的模式并理解它。卷积层有检测模式的过滤器。图像中的不同图案可以是边缘、形状或纹理。这些图案被称为<strong class="ky ir">特征</strong>。</p><p id="a685" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以从CNN的卷积层中提取这些特征。图10清楚地展示了一个示例架构。通常，我们指定网络的最后一个卷积层用于特征提取。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/3670325d2cdf1e8576a9633c92008972.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpJncGd2rZdfj7YGGnpq3Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图10——一个简单的CNN架构(图片由作者提供)</p></figure><p id="095c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个伟大的艺术级CNN架构是<a class="ae kv" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNet </a>。这是一种使用复合系数统一缩放所有维度(深度/宽度/分辨率)的缩放方法。我不会深究它，因为它超出了本文的范围。但是，我将在下面的部分中使用它。</p><blockquote class="op oq or"><p id="d7ba" class="kw kx nk ky b kz la jr lb lc ld ju le os lg lh li ot lk ll lm ou lo lp lq lr ij bi translated">通常，数据科学社区在<a class="ae kv" href="https://en.wikipedia.org/wiki/Content-based_image_retrieval#:~:text=Content%2Dbased%20image%20retrieval%2C%20also,this%20survey%20for%20a%20scientific" rel="noopener ugc nofollow" target="_blank">基于内容的图像检索(CBIR) </a>系统中广泛使用特征的相似性。实验部分将解释原因。</p></blockquote><p id="60fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 5.1。EfficientNet-b0和欧几里德距离</strong></p><p id="907e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从EfficientNet中提取特征后，我应用欧几里德距离来度量查询和数据集图像的特征之间的相似性，以找到最相似的特征。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><p id="65d5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> 5.2。EfficientNet-b0和余弦相似度</strong></p><p id="c4f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算特征的余弦相似性与上一个非常相似。但是，应用余弦相似度而不是欧几里德距离。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj ok l"/></div></figure><blockquote class="ov"><p id="51a7" class="ow ox iq bd oy oz pa pb pc pd pe lr dk translated">在结束这一部分之前，如果得到的相似度是250、0.04或10809呢？让一对图像相似的数字是多少？答案如下:您必须基于对您选择的数据集的研究或特殊测试来定义这个阈值。</p></blockquote><h1 id="7d7e" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw pf jx mz jz pg ka nb kc ph kd nd ne bi translated">数据集</h1><p id="0b73" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在整个实验中，我使用了两个不同的数据集进行评估:</p><ul class=""><li id="5b35" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr oi mf mg mh bi translated"><a class="ae kv" href="https://www.kaggle.com/datasets/moltean/fruits?resource=download" rel="noopener ugc nofollow" target="_blank">部分成果360 </a>数据集(96张多尺寸图片)<em class="nk">(license:</em><a class="ae kv" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"><em class="nk">CC BY-SA 4.0</em></a><em class="nk">)</em></li><li id="bdc5" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">我收集的一个名为<a class="ae kv" href="https://www.kaggle.com/datasets/orjwanzaafarani/sfbench" rel="noopener ugc nofollow" target="_blank"> SFBench </a>的数据集由40张图片组成(3024 x 4032 px)<em class="nk">(license:</em><a class="ae kv" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"><em class="nk">CC0:Public Domain</em></a><em class="nk">)</em></li></ul><p id="af28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我指定第一个数据集来评估重复/近似重复图像查找器，因为它由每个类别360度拍摄的不同水果的图像组成，如图3所示。这些框架略有不同；图4显示了棕色划痕是如何顺时针移动的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/edc28b7a9efb11e042af78d9dad888c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QjZN1QOdKMLqYPP1wVSXjw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图11 —一个<a class="ae kv" href="https://www.kaggle.com/datasets/moltean/fruits?resource=download" rel="noopener ugc nofollow" target="_blank">水果360 </a>数据集的样本(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/9aee67e26601a117f0bb52715e2fb0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dS2mZeWAvvv52FOCxYQRfQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图12——三帧<a class="ae kv" href="https://www.kaggle.com/datasets/moltean/fruits?resource=download" rel="noopener ugc nofollow" target="_blank">结果360 </a>数据集之间的差异(图片由作者提供)</p></figure><p id="eb09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个数据集上的测试将为我们提供关于图像重复/近似重复查找器性能如何的很好的反馈，因为所有图像都是相邻的帧。这意味着每个独特类别的图片都非常相似。</p><p id="0853" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其次，<a class="ae kv" href="https://www.kaggle.com/datasets/orjwanzaafarani/sfbench" rel="noopener ugc nofollow" target="_blank"> SFBench </a>是一个由40幅图像组成的数据集，用于评估<a class="ae kv" href="https://en.wikipedia.org/wiki/Content-based_image_retrieval#:~:text=Content%2Dbased%20image%20retrieval%2C%20also,this%20survey%20for%20a%20scientific" rel="noopener ugc nofollow" target="_blank">基于内容的图像检索(CBIR) </a>系统。</p><p id="f6e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，本文的目的不是构建或评估CBIR系统。我们使用这个数据集只是为了测试图像变换(如3D投影和旋转)如何影响这些方法的性能。</p><p id="1cad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的图13展示了数据集的一些样本图像。像第一个数据集一样，它由每个场景的4幅图像组成。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pk"><img src="../Images/cb71007af17c10c6c7fed12f9cf138a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mOkPDNpYkbYbns-aygw-6g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图SFBench数据集的示例(图片由作者提供)</p></figure><h1 id="8c27" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">实验</h1><p id="9e02" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">我按照以下方式使用两个数据集测试了每种方法:</p><ul class=""><li id="e72c" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr oi mf mg mh bi translated">实验1:速度和准确性</li><li id="1a63" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">实验2:对图像变换的弹性</li><li id="89f7" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">实验3:科学距离.欧几里得速度与数字线性速度.范数速度</li></ul><blockquote class="op oq or"><p id="fedb" class="kw kx nk ky b kz la jr lb lc ld ju le os lg lh li ot lk ll lm ou lo lp lq lr ij bi translated">注:所有测试我用的都是2019款MacBook Pro CPU。此外，您可以在<a class="ae kv" href="https://github.com/OrjwanZaafarani/image-duplicate-finder-guide" rel="noopener ugc nofollow" target="_blank"> Github存储库</a>中找到所有的测试。</p></blockquote><h2 id="19f1" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">实验1:速度和准确性</h2><p id="f419" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">该测试提出了图像重复查找器系统在速度和准确性方面的最佳方法。接下来的步骤如下:</p><ul class=""><li id="7d77" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr oi mf mg mh bi translated">读取<a class="ae kv" href="https://www.kaggle.com/datasets/moltean/fruits?resource=download" rel="noopener ugc nofollow" target="_blank">水果360 </a>数据集的图像。</li><li id="5368" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">将它们转换为RGB</li><li id="42a4" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">将图像调整到固定大小</li><li id="33c7" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">使用五种方法</li><li id="bdae" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">获取与参考图片最相似的3个图片。</li><li id="aa6f" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">计算该方法比较一对图像所需的平均时间(秒)</li><li id="a491" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated">计算准确度(对于每个参考图像，如果检测到3个副本/近似副本，则准确度为100%)</li></ul><p id="cadb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果(如表1所示)清楚地表明，余弦相似性占主导地位，而使用CNN计算特征的相似性被认为是寻找图像的副本/近似副本的过度工程化，因为它的运行时间比余弦相似性慢大约250倍，同时保持接近的精度。此外，如果速度是一个重要因素，图像哈希是一个很好的选择。</p><blockquote class="op oq or"><p id="f7cd" class="kw kx nk ky b kz la jr lb lc ld ju le os lg lh li ot lk ll lm ou lo lp lq lr ij bi translated">访问这篇<a class="ae kv" href="https://medium.com/@sasi24/cosine-similarity-vs-euclidean-distance-e5d9a9375fc8#:~:text=Although%20the%20magnitude%20(length)%20of,to%20OB%20than%20to%20OC.&amp;text=As%20can%20be%20seen%20from,better%20than%20the%20Euclidean%20distance." rel="noopener">文章【5】</a>了解更多关于欧几里德距离何时优于余弦相似度，反之亦然..</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/ab056f66190387db053b53907fb77889.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Ga5gtGvlSrwNJO7XzOPZw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表1 —实验1的结果</p></figure><h2 id="14b0" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">实验2:对图像变换的弹性</h2><p id="cd1b" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">该测试遵循与实验1相同的步骤。唯一的区别是使用的数据集和调整大小的因素；我使用了<a class="ae kv" href="https://www.kaggle.com/datasets/orjwanzaafarani/sfbench" rel="noopener ugc nofollow" target="_blank"> SFBench </a>，注意到图像重复查找器的目的不是检测和识别相似的转换图像。我只是在评估这些方法在CBIR系统中潜在用途的弹性。</p><p id="8017" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从逻辑上讲，由于CNN在其图层中保存空间信息，因此特征相似度方法表现最佳。表2总结了如下结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pl"><img src="../Images/963880bc8ba9471448ef7ccfda16c433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wQbKiH8c5wFPZ_PedVfp3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表2 —实验2的结果</p></figure><h2 id="7338" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">实验3: Scipy distance.euclidean与Numpy linalg.norm速度(Extra)</h2><p id="7910" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">最后一个实验通过重复大约2300次相同的操作来考察Scipy和Numpy实现之间的比较。这个测试是本文的一个额外步骤，不影响图像重复/近似重复查找器系统的功能。</p><p id="0d52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果显示，它们的性能相似(表3)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pm"><img src="../Images/66cf83a9404196df59813fc72e6a457b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tzvi1DR_YdHq53CjXUt98w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">表3-实验3的结果</p></figure><h1 id="0a35" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">结论</h1><p id="fe9d" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">总之，我们浏览了欧几里德距离、SSIM、图像散列、余弦相似性和特征相似性的概念和Python代码。此外，我们还确定了图像变换对这些算法性能的敏感性。最后，通过实验，我们根据要求总结出了最佳的方法:速度和精度。</p><h1 id="0e2f" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">文章的材料</h1><p id="f4a1" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">您可以在<a class="ae kv" href="https://github.com/OrjwanZaafarani/image-duplicate-finder-guide" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>中找到所有的数据集、实验和结果。此外，只要每个数据集遵循相同的命名约定，您就可以测试您选择的数据集。</p><h1 id="4b30" class="mn mo iq bd mp mq nm ms mt mu nn mw mx jw no jx mz jz np ka nb kc nq kd nd ne bi translated">资源</h1><p id="fd7d" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">[1]，，王，等.图像质量评价:从错误可见性到结构相似性，2004 </p><p id="e32d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2]<a class="ae kv" href="https://www.imatest.com/docs/ssim/" rel="noopener ugc nofollow" target="_blank">SSIM Imatest有限责任公司:结构相似性指数，v.22.1 </a></p><p id="eb7a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] <a class="ae kv" href="https://medium.com/srm-mic/all-about-structural-similarity-index-ssim-theory-code-in-pytorch-6551b455541e" rel="noopener">达塔，关于结构相似指数的一切(SSIM):py torch中的理论+代码，2020年</a></p><p id="90d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【4】<a class="ae kv" href="https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/08%3A_Further_Applications_of_Trigonometry/8.08%3A_Vectors" rel="noopener ugc nofollow" target="_blank">数学书库，</a> <a class="ae kv" href="https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/08%3A_Further_Applications_of_Trigonometry/8.08%3A_Vectors" rel="noopener ugc nofollow" target="_blank">三角学的进一步应用</a> : <a class="ae kv" href="https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/08%3A_Further_Applications_of_Trigonometry/8.08%3A_Vectors" rel="noopener ugc nofollow" target="_blank">向量。2021年</a></p><p id="fc9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] <a class="ae kv" href="https://medium.com/@sasi24/cosine-similarity-vs-euclidean-distance-e5d9a9375fc8#:~:text=Although%20the%20magnitude%20(length)%20of,to%20OB%20than%20to%20OC.&amp;text=As%20can%20be%20seen%20from,better%20than%20the%20Euclidean%20distance." rel="noopener"> Nagella，余弦相似度Vs欧几里德距离，2019 </a></p><p id="45fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[6] <a class="ae kv" href="https://content-blockchain.org/research/testing-different-image-hash-functions/" rel="noopener ugc nofollow" target="_blank">内容区块链项目，测试不同图像哈希函数，2019 </a></p><p id="db7f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[7] <a class="ae kv" href="https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html" rel="noopener ugc nofollow" target="_blank"> Krawetz，黑客因素博客，看起来像它，2011年</a></p><p id="ce82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[8] <a class="ae kv" href="https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7" rel="noopener"> Gohrani，机器学习中使用的不同类型的距离度量，2019 </a></p><p id="e848" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[9] <a class="ae kv" href="https://clay-atlas.com/us/blog/2020/03/27/cosine-similarity-text-calculate-python/" rel="noopener ugc nofollow" target="_blank">克雷，如何计算余弦相似度(附代码)，2020 </a></p><h2 id="eadd" class="nt mo iq bd mp nu nv dn mt nw nx dp mx lf ny nz mz lj oa ob nb ln oc od nd oe bi translated">其他有用的资源</h2><ul class=""><li id="9e9e" class="lz ma iq ky b kz nf lc ng lf pn lj po ln pp lr oi mf mg mh bi translated"><a class="ae kv" href="https://medium.com/analytics-vidhya/various-types-of-distance-metrics-machine-learning-cc9d4698c2da" rel="noopener">昆都，机器学习中的各类距离度量，2019 </a></li><li id="c3b2" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr oi mf mg mh bi translated"><a class="ae kv" href="https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy#:~:text=Use%20numpy.linalg.norm%3A" rel="noopener ugc nofollow" target="_blank">雅图，如何用NumPy计算欧氏距离？，2020年</a></li></ul></div></div>    
</body>
</html>