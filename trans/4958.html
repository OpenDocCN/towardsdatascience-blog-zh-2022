<html>
<head>
<title>A control theoretic introduction to Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习的控制理论介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-control-theoretic-introduction-to-reinforcement-learning-3c2972498c17#2022-11-04">https://towardsdatascience.com/a-control-theoretic-introduction-to-reinforcement-learning-3c2972498c17#2022-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="bac2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第1部分:搭建舞台</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0f44d63e3aecc6d65c98da2b1a3625d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Eu5fxYQ3J-EvJyrpLTP0g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有芯片的人工神经网络，由利亚姆挂在<a class="ae ky" href="https://www.flickr.com/photos/chen-meng/49203125457" rel="noopener ugc nofollow" target="_blank">闪烁的</a>上。许可证CC-BY 2.0</p></figure><p id="9498" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="noopener ugc nofollow" target="_blank">强化学习</a>是三种基本的机器学习范式之一，与<a class="ae ky" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">监督</a>和<a class="ae ky" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank">非监督</a>学习并列。在过去的十年中，它已经成为解决复杂工程任务的最成功的方法之一。DeepMind通过<a class="ae ky" href="https://en.wikipedia.org/wiki/AlphaGo" rel="noopener ugc nofollow" target="_blank"> AlphaGo </a>或<a class="ae ky" href="https://en.wikipedia.org/wiki/AlphaFold" rel="noopener ugc nofollow" target="_blank"> AlphaFold </a>取得的成功就是最好的例证。但是，尽管它越来越受欢迎，强化学习依赖于数学技术和vocab，与监督或无监督学习的常规实践者可能习惯的完全不同。这是从熟悉线性最优控制理论的人的角度看强化学习的系列文章的第一篇。通过这样做，我希望揭开几个概念的神秘面纱，澄清关于强化学习的常见误解，并强调它与经典控制理论的紧密联系。</p><h2 id="edf9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">搭建舞台</h2><p id="f372" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">在深入研究强化学习的数学之前，让我们先来看看将伴随我们整个旅程的机械系统。如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/cd35d18c73439825a2f3d7172c7fd886.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*1xYyDnP8uQi_g4S-7hqldA.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">平衡车，1976年左右的简单机器人系统。推车包含一个伺服系统，监控杆的角度，并来回移动推车以保持直立。来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Inverted_pendulum" rel="noopener ugc nofollow" target="_blank">维基百科</a>。</p></figure><p id="24de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">俗称<em class="mu">小车倒立摆</em>或简称<strong class="lb iu">小车</strong>。这是控制理论中一个相当普遍的问题。实际上它是如此受欢迎，以至于它进入了OpenAI <a class="ae ky" href="https://www.gymlibrary.dev/" rel="noopener ugc nofollow" target="_blank">体育馆</a>图书馆的<a class="ae ky" href="https://www.gymlibrary.dev/environments/classic_control/" rel="noopener ugc nofollow" target="_blank">经典控制环境</a>。</p><p id="b2d5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你们中有物理学背景的人应该对推导这个机械系统的控制方程没有问题。在小角度极限下，这些等式表示为</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/4ca62101d50feb204d4ed0e136849338.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*amQ3a6KVbEVi1-Nt5xYWAA.png"/></div></figure><p id="d7e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中上标点表示时间导数。我们的系统因此具有四个自由度:<em class="mu"> z </em> (t)是小车的水平位置，<em class="mu"> ϑ </em> (t)是摆锤相对于垂直方向的角度位置，<em class="mu"> ϑ=0 </em>是直立位置。另外两个自由度是小车的水平速度和摆的角速度。参数如下:<em class="mu"> m </em>为杆的质量，<em class="mu"> M </em>为大车的质量，<em class="mu"> L </em>为杆的长度，<em class="mu"> J </em>为其惯性，<em class="mu"> b </em>为大车与地面的摩擦常数。小角度限制的原因是它导致<strong class="lb iu">线性</strong>运动方程。这样做的主要好处是使我们的问题易于分析，这在试图理解事物时是非常可取的。</p><p id="98ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了进一步简化问题，我们还将<em class="mu">根据时间离散化</em>这些方程。这将允许我们用和或差来代替积分和微分学，公认更容易操作。这导致下面的<em class="mu">线性移位不变</em>(或<em class="mu">离散时间</em>)动力系统</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4f551166501a351b34c2b5aa68e6599e.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*RI2NOva3thIp-ykgLl1iuA.png"/></div></figure><p id="c2eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用哪种技术来离散方程并不重要，无论是隐式还是显式欧拉法，一阶还是二阶格式等等。数学仍然是一样的。此外，在你的离散时间步长δt趋于零的限度内，你应该得到相同的解！</p><p id="f119" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个模型中，<strong class="lb iu">x</strong>[<em class="mu">I</em><strong class="lb iu"/>是系统在<em class="mu"> tᵢ </em>时刻的四维状态向量，而<strong class="lb iu"> u </strong> [ <em class="mu"> i </em>是当时对系统的输入，也就是当前作用在推车上的力。矩阵<strong class="lb iu"> A </strong>是一个4×4矩阵，描述了小车的<em class="mu">自然动态</em>，即在没有外部驱动的情况下它将如何演变。矩阵<strong class="lb iu"> B </strong>是一个4×1矩阵。描述输入<strong class="lb iu"> u </strong> [ <em class="mu"> i </em>如何影响下一个状态<strong class="lb iu"> x </strong> [ <em class="mu"> i+1 </em> ]。最后，<strong class="lb iu"> C </strong>是描述我们正在进行的测量的q×4矩阵，其中q是测量的次数，而<strong class="lb iu"> y </strong> [ <em class="mu"> i </em> ]是我们在时间<em class="mu"> tᵢ </em>进行的测量的实际向量。这些测量可以简单到观察系统的单个状态变量，或者它们的线性组合。如果q &lt;为4，那么我们就面临一个<em class="mu">部分观测到的</em>控制问题。另一方面，如果<strong class="lb iu"> C </strong>是例如4×4单位矩阵，那么我们就处于全状态信息设置中。这些情况中的每一种都需要稍微不同的过程，我们将在本系列的剩余部分中探讨这些过程。</p><h2 id="0c20" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">游戏的名字是什么？</h2><p id="3f33" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">控制理论和强化学习都与设计输入序列{ <strong class="lb iu"> u </strong> [ <em class="mu"> 0 </em> ]，<strong class="lb iu"> u </strong> [ <em class="mu"> 1 </em> ]，…，<strong class="lb iu"> u </strong> [ <em class="mu"> n </em> ]}有关，以使我们的系统做我们想让它做的任何事情。在我们的例子中，这决定了施加到推车上的脉冲的顺序，使得钟摆稳定在直立位置。在温和的条件下，控制理论和强化学习实际上会给你完全相同的输入序列。它们本质上不同于它们如何到达那里。当控制理论自然地试图最小化操作系统的成本时，强化学习试图最大化回报的概念。然而，在这两种情况下，我们将不得不制定一个优化问题，并找出如何有效地解决它。</p><p id="95b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解更多关于这个问题的控制观点，我强烈建议你看看史蒂夫·布伦顿的YouTube频道。史蒂夫现在有20多万订户，从我看来，他的频道真的随着他神奇的<a class="ae ky" href="https://www.youtube.com/watch?v=Pi7l8mMjYVE&amp;list=PLMrJAkhIeNNR20Mz-VpzgfQs5zrYi085m&amp;ab_channel=SteveBrunton" rel="noopener ugc nofollow" target="_blank">控制训练营系列</a>而起飞。就我们而言，我们将从强化学习的角度来看待这个问题。然而，为了让那些对控制理论有所了解的人更清楚，我们仍然使用控制词汇。</p><h2 id="e61a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">接下来是什么？</h2><p id="4225" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我知道简单的搭建舞台可能会让你们中的很多人感到沮丧，但是请耐心听我说！在学术界，我的时间分为研究、教学和公共宣传。保持这些帖子相对较短(即5分钟阅读)有两个主要好处:</p><ol class=""><li id="dc25" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu nc nd ne nf bi translated">我可以每周抽时间写一两篇，定期给你更多的内容来满足你学习的欲望。</li><li id="a38d" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated">根据我的教学经验，我发现较短但重点突出的帖子更容易消化内容，最终更好地理解内容。</li></ol><p id="00b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那么，接下来会发生什么？嗯，我们将逐步引入新的概念，如状态值函数<em class="mu"> V </em>，或质量函数<em class="mu"> Q </em>。我们还将研究价值迭代和策略迭代之间的差异，以及在基于模型和无模型的上下文中讨论Q-learning的优缺点。在整个系列中，我们将尝试与控制理论中的重要概念建立联系，如系统的可观测性和可控性，其马尔可夫参数，李亚普诺夫和里卡提方程，或线性二次调节器(LQR)和估计器(LQE)，等等。所以系好安全带，下周见！</p></div><div class="ab cl nl nm hx nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="im in io ip iq"><blockquote class="ns nt nu"><p id="9ab0" class="kz la mu lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated">想看更多这方面的内容？查看我关于<a class="ae ky" href="https://loiseau-jc.medium.com/list/lowrank-structure-and-datadriven-modeling-8f39635a90ea" rel="noopener">低秩结构和数据驱动建模</a>的其他文章或者我的<a class="ae ky" href="https://loiseau-jc.medium.com/list/machine-learning-basics-0baf10d8f8b5" rel="noopener">机器学习基础</a>！</p></blockquote><div class="ny nz gp gr oa ob"><a rel="noopener follow" target="_blank" href="/rosenblatts-perceptron-the-very-first-neural-network-37a3ec09038a"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">罗森布拉特的感知机，第一个神经网络</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">深度学习快速入门。</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div></div></div>    
</body>
</html>