<html>
<head>
<title>Critical Facts That Every Data Scientist Should Know — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个数据科学家都应该知道的关键事实—第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/critical-facts-that-every-data-scientist-should-know-part-1-31f9c25e5e00#2022-04-13">https://towardsdatascience.com/critical-facts-that-every-data-scientist-should-know-part-1-31f9c25e5e00#2022-04-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aa78" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">许多数据科学家都是出色的程序员，但是忽视某些统计事实会导致非常严重的后果。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c35c5431ac3c2541c08ca9fb839d8fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UCQHGCc7s9ISvVhk"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">康纳·塞缪尔在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h1 id="229c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="090f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这篇文章中，我想向你解释一些简单但同时重要的概念，以避免像上面的机器一样结束。根据我的经验，即使是经验丰富的数据科学家有时也不知道或不完全理解至少我要告诉你的一些主题。</p><p id="d0a3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">虽然不知道最新流行的算法通常是无害的，但对本文中描述的一些概念有部分了解是数据科学中代价最大的失败的根源。</p><blockquote class="ms"><p id="d933" class="mt mu it bd mv mw mx my mz na nb mm dk translated">对本文中描述的一些概念的部分理解是数据科学中代价最大的失败的根源</p></blockquote><p id="6456" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">我将在下面描述的每一个主题很容易在一篇专门的文章中被涵盖。我的目标是用最少的努力给你最大的回报，并尽可能简单地解释这些经常模糊的概念。</p><p id="ebd4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">由于涉及的论据太多，我决定将本文分成两部分，第二部分比第一部分更高级:</p><h2 id="aa17" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">第一部分</h2><ol class=""><li id="6b3a" class="nt nu it lt b lu lv lx ly ma nv me nw mi nx mm ny nz oa ob bi translated">用例及混淆矩阵介绍</li><li id="1740" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">你真的想最大化准确性吗？</li><li id="dda9" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">精确度、召回率和F1分数</li><li id="e9fe" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">当感兴趣的类变得不那么频繁时，精度会发生什么变化</li><li id="c463" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">不平衡分类的度量</li></ol><h2 id="4987" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">第二部分</h2><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/critical-facts-that-every-data-scientist-should-know-part-2-c9c06cde6e21"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">每个数据科学家都应该知道的关键事实—第2部分</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">在本文的第二部分，我们将总结一些你需要知道的重要事实来成为…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="ou l ov ow ox ot oy ks ok"/></div></div></a></div><ol class=""><li id="29e1" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm ny nz oa ob bi translated">数据泄漏，当你的结果好得令人难以置信</li><li id="953a" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">可解释性与辛普森悖论</li><li id="b3ca" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">采样偏差如何影响您的模型</li><li id="d144" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">非平稳性和协变量移位</li><li id="6098" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">观察者效应和概念漂移</li></ol><p id="d52f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">本文中显示的图表和结果可以使用从Google Colab轻松运行的</strong> <a class="ae ky" href="https://github.com/mnslarcher/critical-facts-that-every-data-scientist-should-know" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">相关Jupyter笔记本</strong> </a> <strong class="lt iu">来复制和更好地理解，我强烈推荐您尝试一下！</strong></p><h1 id="df50" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">用例及混淆矩阵介绍</h1><p id="e6e5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文的第一部分将关注数据科学领域中最常见的问题之一:二进制分类。来自二进制分类的<a class="ae ky" href="https://en.wikipedia.org/wiki/Binary_classification" rel="noopener ugc nofollow" target="_blank">维基百科页面</a>:</p><blockquote class="pc pd pe"><p id="30cc" class="lr ls pf lt b lu mn ju lw lx mo jx lz pg mp mc md ph mq mg mh pi mr mk ml mm im bi translated"><strong class="lt iu">二进制分类</strong>是根据分类规则将集合中的元素分成两组的任务</p></blockquote><p id="86db" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">虽然在我们的例子中我们只有两个类，但是实际上所有给出的参数都同样适用于多类分类的情况。</p><p id="4033" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为了帮助发挥想象力，在本文的第一部分，我将使用一家公司的例子，该公司希望使用机器学习来了解其一些客户是否正在实施欺诈，这个问题通常被称为<strong class="lt iu">欺诈检测</strong>。</p><p id="26c6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">然后我们将【T11级/<strong class="lt iu">正</strong>定义为<strong class="lt iu">诈骗者</strong>，将<strong class="lt iu">0级</strong>/<strong class="lt iu">负</strong>定义为<strong class="lt iu">普通客户</strong>。</p><p id="e767" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">由于我们将使用的许多指标很容易从<strong class="lt iu">混淆矩阵</strong>中计算出来，在我开始写真正的文章之前，我将简要回顾一下它是如何定义的。如果你以前遇到过这个概念，请跳过这一部分。让我们先来看看这个矩阵的结构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/4431303ae0709e5df7180f505c2984a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*y7k67CrYqT6tNmC-8W76sA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="473b" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如我们所见，混淆矩阵报告了实际类别和预测类别之间的四种可能组合:</p><ul class=""><li id="9e4e" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated">真正的否定:一个我们如此预测的否定。在我们的案例中:一个没有犯欺诈行为的客户，我们的模型(正确地)没有报告他。</li><li id="9d60" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated"><strong class="lt iu">假阳性</strong> ( <strong class="lt iu"> FP </strong>):我们预测为阳性的阴性。在我们的案例中:一个没有犯欺诈行为的客户，我们的模型(错误地)报告了他。</li><li id="507f" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated">假阴性:我们预测为阴性的阳性。在我们的案例中:一个客户犯了欺诈罪，而我们的模型(错误地)没有报告他。</li><li id="3f84" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated">真阳性 ( <strong class="lt iu"> TP </strong>):我们预测的阳性。在我们的案例中:一个犯了欺诈罪的客户，我们的模型(正确地)报告了他。</li></ul><p id="8be1" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这就是我们在继续这篇文章之前所需要的，如果你还有任何疑问，我建议你看看混乱矩阵上的优秀的<a class="ae ky" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">维基百科页面。</a></p><blockquote class="pc pd pe"><p id="2f1e" class="lr ls pf lt b lu mn ju lw lx mo jx lz pg mp mc md ph mq mg mh pi mr mk ml mm im bi translated"><strong class="lt iu">注意</strong>:有时行和列的顺序与上面的相反，由于本文附有一个笔记本来进行实验，所以我使用了著名的<a class="ae ky" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>库所使用的相同约定(参见附带的代码)。</p></blockquote><h1 id="39ee" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">你真的想最大化准确性吗？</h1><p id="0dea" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在分类问题中，用于测量性能的最流行但也是最容易误导的度量之一是准确性。</p><ul class=""><li id="171e" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated"><strong class="lt iu">准确性</strong> ( <strong class="lt iu"> ACC </strong>):我们的模型预测正确类别的次数百分比。数学上:ACC = (TP + TN) / (TP + TN + FP + FN)。</li></ul><p id="ef18" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">假设我们训练了两个模型来将我们的客户分为欺诈者和非欺诈者，看看下面的准确度值，哪个模型似乎表现得更好？</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="4c9c" class="nh la it pm b gy pq pr l ps pt">DummyClassifier accuracy: 90.91%<br/>LogisticRegression accuracy: 77.82%</span></pre><p id="cd1e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第一个模型的名字可能会让你怀疑一些事情，但是只看数字，似乎很明显DummyClassifier比LogisticRegression表现得更好。</p><p id="2307" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">真的是这样吗？让我们看看混淆矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/591bd3cd19a0faa8e41a5e1e1a746358.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0btlJMArpKM70gnH7KEtyA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="d1d4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">实际上，DummyClassifier给出正确预测的次数比LogisticRegression多(否则其准确性不会更高)，但它从不预测欺诈类。另一方面，LogisticRegression会犯更多的错误，但至少它帮助我们识别了我们的客户正在犯的100起欺诈中的74起。</p><p id="214f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这种现象是由于什么？让我们首先考虑可能出现的<strong class="lt iu">类型的错误</strong>:</p><ul class=""><li id="f185" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated">我的客户是一个欺诈者，而我的模型没有意识到这一点(假阴性)。</li><li id="e42f" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated">我的客户不是欺诈者，但我的模型认为他是(误报)。</li></ul><p id="e449" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">准确性对这两种类型的错误给予同等的重视，最重要的是，不关心我们的模型是否犯了“太多”这两种类型的错误。</p><blockquote class="ms"><p id="f88c" class="mt mu it bd mv mw mx my mz na nb mm dk translated">准确性[…]并不关心我们的模型是否犯了“太多”这两种类型的错误</p></blockquote><p id="9b9e" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">显然，一个从不报告欺诈的识别欺诈的模型是完全无用的，就像一个将所有客户报告为欺诈者的模型一样，因此我们希望指标能够帮助我们知道模型何时以某种方式夸大了事实。</p><p id="ec72" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">一个可能出现的问题是:那么在什么情况下我必须在使用准确性作为主要度量标准之前好好思考？</p><p id="06a8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">当类别非常<strong class="lt iu">不平衡</strong>时，不管模型有多好，精度往往都很高，因为在这种情况下，预测最频繁的类别就足以获得非常高的精度。</p><blockquote class="ms"><p id="0353" class="mt mu it bd mv mw mx my mz na nb mm dk translated">当类别非常不均衡时，不管模型有多好，准确性往往都很高，因为在这种情况下，预测最频繁的类别就足以获得非常高的准确性</p></blockquote><p id="f59b" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">事实上，我们的DummyClassifier只是使用“最频繁”策略，因此它的预测总是“不欺诈”，即训练数据集中最频繁的类。</p><h1 id="28c1" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">精确度、召回率和F1分数</h1><p id="4351" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们来看一些解决准确性问题的分类指标。</p><ul class=""><li id="5ff5" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated"><strong class="lt iu">精度</strong>(或<strong class="lt iu">阳性预测值，PPV </strong>):模型预测第1类时正确的次数百分比。例如，如果模型说“欺诈”100次，精度是75%，平均来说它在75种情况下是正确的，其他25种是错误警报。数学上:PPV = TP / (TP + FP)。</li><li id="d9ac" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated"><strong class="lt iu">回忆</strong>(或<strong class="lt iu">真阳性率</strong>，<strong class="lt iu"> TPR </strong>):模型归类为类1的观察值的百分比。例如，如果我的客户中有100名欺诈者，召回率为75%，我将平均识别其中的75名，遗漏另外25名。数学上:TPR = TP / P = TP / (TP + FN)。</li><li id="fc44" class="nt nu it lt b lu oc lx od ma oe me of mi og mm pk nz oa ob bi translated"><strong class="lt iu"> F1-score </strong> ( <strong class="lt iu"> F1 </strong>):精度和召回率的调和平均值，F1-score的一个“好”值(什么是“好”取决于问题)通常保证精度和召回率都是“好”的。数学上:F1 = 2 * PPV * TPR / (PPV + TPR)。</li></ul><p id="c647" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为什么要使用调和平均值，而不是更简单、更受欢迎的算术平均值？</p><p id="b666" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">好吧，首先，如果我们使用算术平均值，F1分数将会有与准确性相同的缺陷，这是一个无用的模型，它总是预测两个类别中的一个会有明显不同于零的分数。例如，如果精度是1%,召回率是100%,两者的算术平均值接近50%,而F1值(调和平均值)大约是2%。</p><p id="4954" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">使用这种类型的平均值还有更深层的原因，要了解更多，我推荐这篇优秀的文章:</p><div class="oh oi gp gr oj ok"><a rel="noopener follow" target="_blank" href="/on-average-youre-using-the-wrong-average-geometric-harmonic-means-in-data-analysis-2a703e21ea0"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">平均而言，你使用了错误的平均值:数据分析中的几何与调和平均值</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">当意思不是你想的那样</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">towardsdatascience.com</p></div></div><div class="ot l"><div class="pv l ov ow ox ot oy ks ok"/></div></div></a></div><p id="648f" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们看看我们的新指标在前面的场景中给出了什么指示:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="3450" class="nh la it pm b gy pq pr l ps pt">DummyClassifier precision: 0.00%<br/>DummyClassifier recall: 0.00%<br/>DummyClassifier F1-score: 0.00%<br/><br/>LogisticRegression precision: 25.34%<br/>LogisticRegression recall: 74.00%<br/>LogisticRegression F1-score: 37.76%</span></pre><p id="0ee4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">厉害！F1分数概括了精确度和召回率，它正确地给我们的LogisticRegression一个较高的分数，给我们的DummyClassifier一个零分。</p><p id="be59" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这种情况下，所有三个指标都是一致的，但是需要注意的是，一般来说，情况并不总是这样。如前所示，精确度和召回率之间的一个接近于零就足够了，F1分数也接近于零，不同于两者的算术平均值。</p><p id="7a06" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您还不相信，我建议模拟一个总是预测“欺诈”的模型，并使用它在包含1%欺诈的测试集上进行预测，在这种情况下，您应该会看到如下结果:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="18d5" class="nh la it pm b gy pq pr l ps pt">DummyClassifier precision: 1.00%<br/>DummyClassifier recall: 100.00%<br/>DummyClassifier F1-score: 1.98%</span></pre><p id="81e5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，设想一个模型，该模型只预测几个非常可疑的客户的欺诈行为:一个伪现实案例可能是一个只报告在最近所有检查中被识别为欺诈的欺诈客户的模型。如果这些是模型报告的唯一欺诈，因为我们可以想象它们在总数中所占的百分比非常小，召回率将约为0%，而精确度将接近100%，因为我们几乎可以肯定这些客户是欺诈者。</p><p id="44d5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">总而言之，在这种情况下，我们期望的值类似于:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="36b8" class="nh la it pm b gy pq pr l ps pt">DummyClassifier precision: 100.00%<br/>DummyClassifier recall: 0.00%<br/>DummyClassifier F1-score: 0.00%</span></pre><p id="dccc" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这应该让你意识到，只看精度或只看回忆可能很有欺骗性。</p><blockquote class="ms"><p id="96df" class="mt mu it bd mv mw mx my mz na nb mm dk translated">只看精确度或只看召回率可能很有欺骗性</p></blockquote><h1 id="c7af" class="kz la it bd lb lc ld le lf lg lh li lj jz pw ka ll kc px kd ln kf py kg lp lq bi translated">当感兴趣的类变得不那么频繁时，精度会发生什么变化</h1><p id="a50f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">精确度、召回率和F1分数当然是监控我们模型的很好的指标，但是它们在每种情况下都是最合适的吗？答案显然是否定的。首先，因为没有完美的度量标准，用来评估模型性能的度量标准必须根据我们想要实现的目标来选择。</p><blockquote class="ms"><p id="1880" class="mt mu it bd mv mw mx my mz na nb mm dk translated">没有完美的度量标准，评估模型性能的度量标准必须根据我们想要实现的目标来选择</p></blockquote><p id="128c" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">记住我们给不同类型的错误的“价格”。</p><p id="beb4" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">但是有一个特殊的例子，使用精确度，因此F1分数至少是误导的。</p><p id="d289" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们想象一下，在包含50%欺诈客户和50%非欺诈客户的测试集上计算我们的指标。这种情况并不罕见，因为有时数据科学家会平衡他们的数据集，或者正如我们将在本文的第2部分中看到的，我们用来训练和验证模型的数据分布与我们在生产中使用它们的分布不同。</p><p id="1c68" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">鉴于此，我们得到以下值:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="342e" class="nh la it pm b gy pq pr l ps pt">Precision: 75.92% ± 3.52% (mean ± std. dev. of 100 runs)<br/>Recall: 75.97% ± 4.79% (mean ± std. dev. of 100 runs)<br/>F1-Score: 75.87% ± 3.42% (mean ± std. dev. of 100 runs</span></pre><p id="b622" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们对模型的性能感到满意，决定在生产中使用它来识别欺诈者。在一系列有针对性的检查之后，我们重新计算了我们的指标，从而得出:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="f322" class="nh la it pm b gy pq pr l ps pt">Precision: 3.04% ± 0.17% (mean ± std. dev. of 100 runs)<br/>Recall: 75.88% ± 4.42% (mean ± std. dev. of 100 runs)<br/>F1-Score: 5.84% ± 0.33% (mean ± std. dev. of 100 runs)</span></pre><p id="df1e" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">发生了什么事？第一个想法可能是我们将在本文的<a class="ae ky" rel="noopener" target="_blank" href="/critical-facts-that-every-data-scientist-should-know-part-2-c9c06cde6e21">第二部分</a>中讨论的一些特殊现象，如<strong class="lt iu">协变量转移</strong>或<strong class="lt iu">概念漂移</strong>，但事实真的如此吗，或者这里有更简单的解释吗？</p><p id="48c5" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">事实是，当第一类变得更少时，回忆保持不变，而精确度，因此F1分数下降。</p><blockquote class="ms"><p id="89a9" class="mt mu it bd mv mw mx my mz na nb mm dk translated">当类别1变得更少时，回忆保持不变，而精确度，因此F1分数下降</p></blockquote><p id="9a2f" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">为什么？让我们从回忆开始，为什么我们期望它保持不变？召回只取决于模型对欺诈客户的行为。在分子中，它有真阳性(模型识别的欺诈者)，在分母中，它有真阳性加上假阴性(模型错误地分类为非欺诈者的欺诈者)。换句话说，我们正在分类的数据集中非欺诈者的数量，以及他们相对于欺诈者的比例，不会以任何方式决定召回。</p><blockquote class="ms"><p id="464d" class="mt mu it bd mv mw mx my mz na nb mm dk translated">我们正在分类的数据集中非欺诈者的数量，以及他们相对于欺诈者的比例，不会以任何方式决定召回</p></blockquote><p id="894f" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">让我们现在做这个心理练习:如果在生产中我们有100个欺诈者和10000个非欺诈者，让我们首先计算我们期望在由100个欺诈者加上从10000个非欺诈者中随机选取的100个非欺诈者组成的数据集上获得的精确度。我们期望获得什么样的精度值？嗯，这很容易，因为这个数据集与我们的测试集具有相同的欺诈者比例，在不考虑其他可能因素的情况下(参见<a class="ae ky" rel="noopener" target="_blank" href="/critical-facts-that-every-data-scientist-should-know-part-2-c9c06cde6e21">第2部分</a>)，我们可以预期精度等于已经获得的精度，即大约75%。</p><p id="f8bf" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在我们必须问自己:在最终性能的计算中，哪一个结果可以具有剩余9900种情况下尚未考虑的模型的预测？因为他们都是非欺诈客户，所以他们每个人的结果只能是真阴性或假阳性。换句话说，在任何情况下，它都不能增加精度的分子(真阳性)，而对于每一个额外的非欺诈性客户，精度的分母有非零的概率将增加，特别是，分母中的假阳性将增加，因此精度(以及F1分数)降低。</p><h1 id="5ffe" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">不平衡分类的度量</h1><p id="90c2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">那么有没有对阶级不平衡不那么敏感的度量标准呢？还好，是的！</p><p id="af86" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">不平衡分类</strong>是一个非常重要的问题，在现实生活中我们很少对每一类都有相同百分比的观察值，</p><blockquote class="ms"><p id="e5e7" class="mt mu it bd mv mw mx my mz na nb mm dk translated">在现实生活中，我们很少对每一类都有相同的观察百分比</p></blockquote><p id="1b98" class="pw-post-body-paragraph lr ls it lt b lu nc ju lw lx nd jx lz ma ne mc md me nf mg mh mi ng mk ml mm im bi translated">有大量关于它的文献。在这里，我只想向您展示一些我认为非常有用的指标，这些指标与精确度、召回率和F1值非常相似。</p><p id="7b9d" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第一个指标是<strong class="lt iu">敏感度</strong>，敏感度是……召回率！是的，不幸的是，根据上下文的不同，相同的指标有许多不同的名称，理解我们正在谈论的内容的唯一方法是查看数学定义。</p><p id="ec55" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">第二个指标是新的:</p><ul class=""><li id="5811" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated"><strong class="lt iu">特异性</strong>(或<strong class="lt iu">真阴性率</strong>，<strong class="lt iu"> TNR </strong>):模型正确分类的0类观测值的百分比。在我们的例子中，有多少次我们的模型认为一个非欺诈者是一个非欺诈者，而不是报告一个假警报。数学上:TNR = TN / N = TN / (TN + FP)。</li></ul><p id="9498" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，与F1分数类似，我们这次使用<strong class="lt iu">几何平均值</strong>(再次参见之前的链接文章)来总结两个指标:</p><ul class=""><li id="13da" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm pk nz oa ob bi translated"><strong class="lt iu"> G均值</strong>:敏感性和特异性的几何均值。数学上:G均值= sqrt(TPR * TNR)。</li></ul><p id="4e8c" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">让我们看看在平衡测试集(1:1)的情况下，这些指标假设了什么值:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="e34f" class="nh la it pm b gy pq pr l ps pt">Sensitivity: 76.20% ± 4.84% (mean ± std. dev. of 100 runs)<br/>Specificity: 76.05% ± 4.38% (mean ± std. dev. of 100 runs)<br/>G-Mean: 76.05% ± 3.22% (mean ± std. dev. of 100 runs)</span></pre><p id="21cd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">现在，与上一个案例一样，让我们在一个类似的数据集上重新计算它们，但不平衡度为1:100:</p><pre class="kj kk kl km gt pl pm pn po aw pp bi"><span id="0ba8" class="nh la it pm b gy pq pr l ps pt">Sensitivity: 75.69% ± 4.12% (mean ± std. dev. of 100 runs)<br/>Specificity: 75.68% ± 0.41% (mean ± std. dev. of 100 runs)<br/>G-Mean: 75.65% ± 2.08% (mean ± std. dev. of 100 runs)</span></pre><p id="4b50" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">可以看出，如果数据集也高度不平衡，这些指标不会改变(除了统计上不显著的变化)。</p><p id="94b8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">为什么？</p><p id="3cf3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">我们已经说过为什么敏感性(又名回忆)不变，同样的推理也适用于特异性。此外，特异性不依赖于模型在两个类上的表现，因此依赖于它们的比例，而只来自两个类中的一个。敏感性衡量模型对欺诈客户的表现，而特异性告诉我们模型对非欺诈客户的表现。</p><h1 id="27fb" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="1b81" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这就结束了文章的第一部分，关于你绝对应该知道的事情，我希望你喜欢它，至少我描述的一些内容是新的，因此对你有用。在<a class="ae ky" rel="noopener" target="_blank" href="/critical-facts-that-every-data-scientist-should-know-part-2-c9c06cde6e21"> <strong class="lt iu">第二部分</strong> </a>中，我们将涵盖一些更为<strong class="lt iu">的高级主题</strong>如:</p><ol class=""><li id="33f4" class="nt nu it lt b lu mn lx mo ma oz me pa mi pb mm ny nz oa ob bi translated">数据泄漏，当你的结果好得令人难以置信</li><li id="fbef" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">可解释性与辛普森悖论</li><li id="cabc" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">采样偏差如何影响您的模型</li><li id="88a3" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">非平稳性和协变量移位</li><li id="3aad" class="nt nu it lt b lu oc lx od ma oe me of mi og mm ny nz oa ob bi translated">观察者效应和概念漂移</li></ol><p id="2725" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果你喜欢这篇文章，并希望我写更多类似的文章，你可以做几件事来支持我:开始在Medium上关注我，在社交媒体上分享这篇文章，并使用下面的鼓掌按钮，这样我就知道你对这种类型的内容感兴趣。</p><p id="ae76" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">最后，如果您还不是中等会员，您可以使用我的推荐链接成为中等会员:</p><div class="oh oi gp gr oj ok"><a href="https://mnslarcher.medium.com/membership" rel="noopener follow" target="_blank"><div class="ol ab fo"><div class="om ab on cl cj oo"><h2 class="bd iu gy z fp op fr fs oq fu fw is bi translated">马里奥·南陶·希安蒂·拉彻-中号</h2><div class="or l"><h3 class="bd b gy z fp op fr fs oq fu fw dk translated">阅读Mario Namtao Shianti Larcher在媒体上的文章。艾尼路集团的计算机视觉主管。我喜欢意大利面条代码…</h3></div><div class="os l"><p class="bd b dl z fp op fr fs oq fu fw dk translated">mnslarcher.medium.com</p></div></div><div class="ot l"><div class="pz l ov ow ox ot oy ks ok"/></div></div></a></div><p id="2655" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">想保持联系吗？在<a class="ae ky" href="https://www.linkedin.com/in/mnslarcher/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae ky" href="https://twitter.com/mnslarcher" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我！</p></div></div>    
</body>
</html>