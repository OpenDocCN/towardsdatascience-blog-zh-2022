<html>
<head>
<title>Improving Marketing Mix Modeling Using Machine Learning Approaches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习方法改进营销组合建模</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/improving-marketing-mix-modeling-using-machine-learning-approaches-25ea4cd6994b#2022-06-08">https://towardsdatascience.com/improving-marketing-mix-modeling-using-machine-learning-approaches-25ea4cd6994b#2022-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e1cc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用基于树的集合构建MMM模型，并使用SHAP解释媒体通道性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2b78803b28dc2cc1644f5a3af494891a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jFaR-0t1MfTGme8Wv36O1g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@adrienconverse?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">阿德里安·匡威</a>在<a class="ae kv" href="https://unsplash.com/s/photos/blue-mixture?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5315" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di"> T </span>有许多方法可以建立营销组合模型(MMM ),但通常来说，由于其简单的可解释性，它可以归结为使用线性回归。更复杂的非线性模型的可解释性是过去5-6年的研究主题，因为在机器学习社区中提出了<a class="ae kv" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">时间</a>或<a class="ae kv" href="https://shap.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> SHAP </a>这样的概念来解释模型的输出。然而，这些新概念在营销归因领域似乎几乎无人知晓。在本文中，我继续研究营销组合建模的实用方法，使用随机森林构建基于树的集合，并使用SHAP概念解释媒体渠道绩效。</p></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="2022" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我的上一篇文章中，我使用贝叶斯编程建立了一个营销组合模型，并将结果与Robyn框架进行了比较。我的主要兴趣是调查这两种方法是否具有可比性，在讲故事时是否一致。由于Robyn生成了多个解决方案，我能够找到一个与贝叶斯解决方案一致的解决方案，即两个模型的效果份额始终高于或低于每个渠道的支出份额。百分比差异可归因于方法的差异和模型很好地拟合数据的能力。然而，这两种方法的共同点是都描述了媒体支出和回应之间的线性关系，因此无法捕捉更复杂的变量关系，如互动。</p><div class="mi mj gp gr mk ml"><a rel="noopener follow" target="_blank" href="/modeling-marketing-mix-using-pymc3-ba18dd9e6e68"><div class="mm ab fo"><div class="mn ab mo cl cj mp"><h2 class="bd ir gy z fp mq fr fs mr fu fw ip bi translated">使用PyMC3建模营销组合</h2><div class="ms l"><h3 class="bd b gy z fp mq fr fs mr fu fw dk translated">实验先验，数据规范化，并比较贝叶斯建模与罗宾，脸书的开源MMM…</h3></div><div class="mt l"><p class="bd b dl z fp mq fr fs mr fu fw dk translated">towardsdatascience.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz kp ml"/></div></div></a></div><p id="2f9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我能找到的在营销组合建模中使用更复杂算法的第一个商业概念证明之一是由<a class="ae kv" href="https://h2o.ai/resources/white-paper/the-benefits-of-budget-allocation-with-ai-driven-marketing-mix-models/" rel="noopener ugc nofollow" target="_blank"> H2O.ai </a>描述的，如梯度推进机(GBM)和SHAP。</p><p id="7978" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我总结了转向更复杂算法背后的主要动机:</p><ul class=""><li id="84a4" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">线性回归等经典方法具有挑战性，需要时间和专业知识来识别适当的模型结构，如变量相关性、相互作用或非线性关系。在某些情况下，应该移除高度相关的特征。交互变量应该被明确地设计。不同的转换应该明确地引入像饱和和收益递减这样的非线性。</li><li id="0ab8" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">为了更容易的模型可解释性，牺牲了一些模型结构，这可能导致较差的模型性能。</li><li id="0a7e" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">更复杂的机器学习算法，如基于树的集成，在存在高度相关的变量时工作良好，可以捕捉变量之间的交互，是非线性的，并且通常更准确。</li></ul><p id="7a0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">SHAP对于模型解释背后的细节在很多<a class="ae kv" href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf" rel="noopener ugc nofollow" target="_blank">文章</a>和<a class="ae kv" href="https://christophm.github.io/interpretable-ml-book/shapley.html" rel="noopener ugc nofollow" target="_blank">书籍</a>里都有解释。我将SHAP背后的主要直觉总结如下:</p><blockquote class="no np nq"><p id="e03f" class="kw kx nr ky b kz la jr lb lc ld ju le ns lg lh li nt lk ll lm nu lo lp lq lr ij bi translated">SHAP(SHapley Additive explaints)是一种解释任何机器学习模型输出的博弈论方法。它将最优信用分配与使用博弈论及其相关扩展的经典Shapley值的本地解释联系起来</p></blockquote><ul class=""><li id="1368" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">SHAP是一种解释个体预测的方法，并回答了问题<em class="nr">每个特征对这个预测有多大贡献</em></li><li id="9aa8" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">SHAP值是特征重要性的度量</li><li id="31d4" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">SHAP值可以是负的也可以是正的，并显示相对于所有预测平均值的预测量。绝对量值表示特定个体预测的特征强度</li><li id="ee8d" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">每个特征的SHAP值的绝对值的平均值表示该特征的全局重要性</li><li id="1c5d" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">在某种程度上，SHAP特征重要性可以替代排列特征重要性。与SHAP相反，排列特征重要性基于模型性能的整体下降。</li></ul></div><div class="ab cl mb mc hu md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="ij ik il im in"><p id="7868" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">MMM转向更复杂模型的最大挑战是缺乏解释单个媒体渠道影响的工具。虽然机器学习社区正在广泛使用像SHAP这样的模型可解释性方法，这是由数百篇论文和会议讨论提出的，但在MMM上下文中找到SHAP用法的例子仍然非常困难。这篇<a class="ae kv" rel="noopener" target="_blank" href="/explainable-ai-application-of-shapely-values-in-marketing-analytics-57b716fc9d1f">精彩的文章</a>将MMM与SHAP联系起来，并解释了我们如何解读营销组合的结果。受这篇文章的启发，我写了一个几乎通用的解决方案来模拟营销组合，结合Robyn的趋势和季节性分解方法的思想，使用随机森林估计器(可以很容易地改变为其他算法)，并使用<a class="ae kv" href="https://optuna.org" rel="noopener ugc nofollow" target="_blank"> Optuna </a>(超参数优化框架)优化adstock和模型特定的参数。该解决方案允许在MMM中通常使用的单目标优化和Robyn使用的多目标优化之间切换。</p><h1 id="2f65" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">数据</h1><p id="04ec" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">在我的第一篇文章中，我继续使用由<a class="ae kv" href="https://github.com/facebookexperimental/Robyn" rel="noopener ugc nofollow" target="_blank"> Robyn </a>在麻省理工学院许可下提供的数据集进行一致性和基准测试，并通过应用Prophet来分解趋势、季节性和假日，遵循相同的数据准备步骤。</p><p id="ce8b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集包含208周的收入(从2015年11月23日到2019年11月11日),包括:</p><ul class=""><li id="45e6" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">5个媒体消费渠道:电视、网络、印刷品、facebook、搜索</li><li id="798f" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">2个也有曝光信息(印象，点击)的媒体渠道:facebook_I，search_clicks_P(本文未使用)</li><li id="20df" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">无支出有机媒体:时事通讯</li><li id="f7c2" class="na nb iq ky b kz nj lc nk lf nl lj nm ln nn lr nf ng nh ni bi translated">控制变量:事件、节假日、竞争对手销售额(competitor_sales_B <strong class="ky ir"> ) </strong></li></ul><p id="ee2f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分析窗口为2016年11月21日至2018年8月20日的92周。</p><h1 id="8040" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">库存/结转效应</h1><p id="caa9" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">不考虑建模算法，广告素材在MMM中起着重要的作用。因此，我们必须决定我们要试验哪种adstock，以及对于每个媒体频道，它可能具有的最小和最大值是什么(请参考我的<a class="ae kv" rel="noopener" target="_blank" href="/modeling-marketing-mix-using-pymc3-ba18dd9e6e68">以前的文章</a>以了解各种adstock功能的概述)。优化算法将尝试定义值范围内的每个adstock值，以找到最小化优化标准的最佳值。</p><p id="8935" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我正在使用scikit中实现的几何adstock函数，如下所示:</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="dffd" class="ox nw iq ot b gy oy oz l pa pb">from sklearn.base import BaseEstimator, TransformerMixin<br/>from sklearn.utils import check_array<br/>from sklearn.utils.validation import check_is_fitted</span><span id="840a" class="ox nw iq ot b gy pc oz l pa pb">class AdstockGeometric(BaseEstimator, TransformerMixin):<br/>    def __init__(self, alpha=0.5):<br/>        self.alpha = alpha<br/>        <br/>    def fit(self, X, y=None):<br/>        X = check_array(X)<br/>        self._check_n_features(X, reset=True)<br/>        return self<br/>    <br/>    def transform(self, X: np.ndarray):<br/>        check_is_fitted(self)<br/>        X = check_array(X)<br/>        self._check_n_features(X, reset=False)<br/>        x_decayed = np.zeros_like(X)<br/>        x_decayed[0] = X[0]<br/>        <br/>        for xi in range(1, len(x_decayed)):<br/>            x_decayed[xi] = X[xi] + self.alpha* x_decayed[xi - 1]<br/>        return x_decayed</span></pre><h1 id="9e1a" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">收益递减/饱和效应</h1><p id="63b3" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">我已经提到过，线性模型无法捕捉不同水平的广告支出和结果之间的非线性关系。因此，在建模之前，对媒体信道应用了各种非线性变换，例如<a class="ae kv" href="https://analyticsartist.wordpress.com/2015/03/08/advertising-diminishing-returns-saturation/" rel="noopener ugc nofollow" target="_blank">幂、负指数</a>和<a class="ae kv" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46001.pdf" rel="noopener ugc nofollow" target="_blank">山</a>。</p><p id="1ad0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">基于树的算法能够捕捉非线性。因此，我没有明确地应用任何非线性变换，而是让模型自己学习非线性。</p><h1 id="21b9" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated"><strong class="ak">造型</strong></h1><p id="50c0" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">建模由几个步骤组成:</p><p id="677f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> Adstock参数</strong></p><p id="5526" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">广告能有多长时间的效果取决于媒体渠道。因为我们正在寻找一个最佳的吸附衰变率，我们必须对参数的可能范围持现实态度。例如，众所周知，电视广告可能具有持久的效果，而印刷广告具有较短的效果。因此，我们必须灵活地为每个媒体通道定义现实的超参数。在这个例子中，我使用Robyn在他们的演示文件中提出的精确范围。</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="317f" class="ox nw iq ot b gy oy oz l pa pb">adstock_features_params = {}<br/>adstock_features_params["tv_S_adstock"] = (0.3, 0.8)<br/>adstock_features_params["ooh_S_adstock"] = (0.1, 0.4)<br/>adstock_features_params["print_S_adstock"] = (0.1, 0.4)<br/>adstock_features_params["facebook_S_adstock"] = (0.0, 0.4)<br/>adstock_features_params["search_S_adstock"] = (0.0, 0.3)<br/>adstock_features_params["newsletter_adstock"] = (0.1, 0.4)</span></pre><p id="9a9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">时间序列交叉验证</strong></p><p id="3479" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们希望找到能很好地概括未知数据的参数。我们必须将数据分成训练集和测试集。由于我们的数据代表了时间线上发生的支出和收入，我们必须应用时间序列交叉验证，以便训练集只包含测试集中事件之前发生的事件。</p><p id="fce4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">机器学习算法在对大量数据进行训练时效果最佳。随机森林算法也不例外，为了捕捉变量之间的非线性和相互作用，应该对大量数据进行训练。正如我前面提到的，我们总共只有208个数据点，在分析窗口中有92个数据点。我们需要在泛化能力和模型的学习能力之间做一些权衡。</p><p id="2929" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">经过一些实验，我决定通过分配20周的数据(大约10%)作为测试集来使用3个cv-splits。</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="6f01" class="ox nw iq ot b gy oy oz l pa pb">from sklearn.model_selection import TimeSeriesSplit<br/>tscv = TimeSeriesSplit(n_splits=3, test_size = 20)</span></pre><p id="4c42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个连续的训练集分裂都比前一个大。</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="4fa4" class="ox nw iq ot b gy oy oz l pa pb">tscv = TimeSeriesSplit(n_splits=3, test_size = 20)<br/>for train_index, test_index in tscv.split(data):<br/>    print(f"train size: {len(train_index)}, test size: {len(test_index)}")</span><span id="10ec" class="ox nw iq ot b gy pc oz l pa pb">#train size: 148, test size: 20<br/>#train size: 168, test size: 20<br/>#train size: 188, test size: 20</span></pre><p id="3d5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">使用Optuna优化超参数</strong></p><p id="bf83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">超参数优化由大量实验或试验组成。每次审判大致可以分为三步。</p><ul class=""><li id="fe05" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">使用一组adstock参数在媒体频道上应用adstock变换</li></ul><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="a07c" class="ox nw iq ot b gy oy oz l pa pb">for <strong class="ot ir">feature </strong>in <strong class="ot ir">adstock_features</strong>:<br/>  adstock_param = f"{feature}_adstock"<br/>  min_, max_ = adstock_features_params[adstock_param]<br/>  <strong class="ot ir">adstock_alpha </strong>= trial.suggest_uniform(f"adstock_alpha_{feature}", min_, max_)<br/>  adstock_alphas[feature] = adstock_alpha<br/>        <br/>  #adstock transformation<br/>  x_feature = data[feature].values.reshape(-1, 1)<br/>  temp_adstock = <strong class="ot ir">AdstockGeometric</strong>(alpha = adstock_alpha).fit_transform(x_feature)<br/>  data_temp[feature] = temp_adstock</span></pre><ul class=""><li id="0cc7" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">为<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">随机森林</strong> </a>定义一组建模参数。</li></ul><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="d68c" class="ox nw iq ot b gy oy oz l pa pb">#Random Forest parameters<br/>n_estimators = trial.suggest_int("n_estimators", 5, 100)<br/>min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)<br/>min_samples_split = trial.suggest_int('min_samples_split', 2, 20)<br/>max_depth = trial.suggest_int("max_depth", 4,7)<br/>ccp_alpha = trial.suggest_uniform("ccp_alpha", 0, 0.3)<br/>bootstrap = trial.suggest_categorical("bootstrap", [False, True])<br/>criterion = trial.suggest_categorical("criterion",["squared_error"])</span></pre><ul class=""><li id="9d27" class="na nb iq ky b kz la lc ld lf nc lj nd ln ne lr nf ng nh ni bi translated">交叉验证并测量所有测试集的平均误差</li></ul><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="0c30" class="ox nw iq ot b gy oy oz l pa pb">for train_index, test_index in <strong class="ot ir">tscv.split</strong>(data_temp):<br/> <strong class="ot ir">x_train </strong>= data_temp.iloc[train_index][<strong class="ot ir">features</strong>]<br/> <strong class="ot ir">y_train </strong>=  data_temp[target].values[train_index]<br/>        <br/> <strong class="ot ir">x_test </strong>= data_temp.iloc[test_index][features]<br/> <strong class="ot ir">y_test </strong>= data_temp[target].values[test_index]<br/>        <br/> #apply Random Forest<br/> <strong class="ot ir">params </strong>= {"n_estimators": n_estimators, <br/>           "min_samples_leaf":min_samples_leaf, <br/>           "min_samples_split" : min_samples_split,<br/>           "max_depth" : max_depth, <br/>           "ccp_alpha" : ccp_alpha, <br/>           "bootstrap" : bootstrap, <br/>           "criterion" : criterion<br/>           }<br/> <br/> #train a model      <br/> rf = <strong class="ot ir">RandomForestRegressor</strong>(random_state=0, **params)<br/> rf.<strong class="ot ir">fit</strong>(x_train, y_train)<br/> <br/> #predict test set<br/> prediction = rf.<strong class="ot ir">predict</strong>(x_test)<br/> <br/> #RMSE error metric       <br/> rmse = <strong class="ot ir">mean_squared_error</strong>(y_true = y_test, y_pred = prediction, squared = False)<br/> <br/> #collect errors for each fold<br/> scores.<strong class="ot ir">append</strong>(rmse)</span><span id="f1f5" class="ox nw iq ot b gy pc oz l pa pb">#finally return the average of the cv error<br/><strong class="ot ir">return np.mean(scores)</strong></span></pre><p id="de73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每次试验都将adstock、模型参数和误差度量作为用户属性返回。这允许在最佳试验中容易地检索参数。</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="a7e8" class="ox nw iq ot b gy oy oz l pa pb">trial.set_user_attr("scores", scores)<br/>trial.set_user_attr("params", params)<br/>trial.set_user_attr("adstock_alphas", adstock_alphas)</span></pre><p id="da6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开始优化的主要函数是<em class="nr"> optuna_optimize。</em>它返回包含所有试验的Optuna <a class="ae kv" href="https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html" rel="noopener ugc nofollow" target="_blank">研究</a>对象，包括最佳试验(具有最小的平均RMSE误差)</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="ad14" class="ox nw iq ot b gy oy oz l pa pb">tscv = TimeSeriesSplit(n_splits=3, test_size = 20)</span><span id="b9a4" class="ox nw iq ot b gy pc oz l pa pb">adstock_features_params = {}<br/>adstock_features_params["tv_S_adstock"] = (0.3, 0.8)<br/>adstock_features_params["ooh_S_adstock"] = (0.1, 0.4)<br/>adstock_features_params["print_S_adstock"] = (0.1, 0.4)<br/>adstock_features_params["facebook_S_adstock"] = (0.0, 0.4)<br/>adstock_features_params["search_S_adstock"] = (0.0, 0.3)<br/>adstock_features_params["newsletter_adstock"] = (0.1, 0.4)</span><span id="8a7d" class="ox nw iq ot b gy pc oz l pa pb">OPTUNA_TRIALS = 2000</span><span id="0c29" class="ox nw iq ot b gy pc oz l pa pb">#experiment is an optuna study object<br/>experiment = <strong class="ot ir">optuna_optimize</strong>(<strong class="ot ir">trials </strong>= OPTUNA_TRIALS, <br/>                             <strong class="ot ir">data </strong>= data, <br/>                             <strong class="ot ir">target </strong>= target, <br/>                             <strong class="ot ir">features </strong>= features, <br/>                             <strong class="ot ir">adstock_features </strong>= media_channels + organic_channels, <br/>                             adstock_features_params = adstock_features_params, <br/>                             <strong class="ot ir">media_features</strong>=media_channels, <br/>                             <strong class="ot ir">tscv </strong>= tscv, <br/>                             is_multiobjective=False)</span></pre><p id="e046" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最佳试验各折的RMSE分数:</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="363e" class="ox nw iq ot b gy oy oz l pa pb">experiment.best_trial.user_attrs["scores"]</span><span id="51ef" class="ox nw iq ot b gy pc oz l pa pb">#[162390.01010327024, 114089.35799374945, 79415.8649240292]</span></pre><p id="8449" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对应于最佳试验的Adstock参数:</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="6d3e" class="ox nw iq ot b gy oy oz l pa pb">experiment.best_trial.user_attrs["adstock_alphas"]</span><span id="6e82" class="ox nw iq ot b gy pc oz l pa pb">#{'tv_S': 0.5343389820427953,<br/># 'ooh_S': 0.21179063584028718,<br/># 'print_S': 0.27877433150946473,<br/># 'facebook_S': 0.3447366707231967,<br/># 'search_S': 0.11609804659096469,<br/># 'newsletter': 0.2559060243894163}</span></pre><p id="d034" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对应于最佳试验的模型参数:</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="4e90" class="ox nw iq ot b gy oy oz l pa pb">experiment.best_trial.user_attrs["params"]</span><span id="5a48" class="ox nw iq ot b gy pc oz l pa pb">#{'n_estimators': 17,<br/># 'min_samples_leaf': 2,<br/># 'min_samples_split': 4,<br/># 'max_depth': 7,<br/># 'ccp_alpha': 0.19951653203058856,<br/># 'bootstrap': True,<br/># 'criterion': 'squared_error'}</span></pre><p id="4f6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">最终型号</strong></p><p id="5c08" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我通过提供分析的开始和结束时段，使用优化的参数构建最终模型。该模型首先基于截至分析期结束时的所有数据。仅检索分析期间的预测值和SHAP值。</p><pre class="kg kh ki kj gt os ot ou ov aw ow bi"><span id="0028" class="ox nw iq ot b gy oy oz l pa pb"><strong class="ot ir">best_params </strong>= experiment.best_trial.user_attrs["params"]<br/><strong class="ot ir">adstock_params </strong>= experiment.best_trial.user_attrs["adstock_alphas"]<br/>result = <strong class="ot ir">model_refit</strong>(data = data, <br/>                     target = target,<br/>                     features = features, <br/>                     media_channels = media_channels, <br/>                     organic_channels = organic_channels, <br/>                     model_params = best_params, <br/>                     adstock_params = adstock_params, <br/>                     <strong class="ot ir">start_index </strong>= START_ANALYSIS_INDEX, <br/>                     <strong class="ot ir">end_index </strong>= END_ANALYSIS_INDEX)</span></pre><h1 id="83ae" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">结果</h1><p id="3fa6" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">要检查的第一个图是模型与92周分析期数据的拟合程度:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/ee91f669166b20b07317979630b1562f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mj--rm_hDIsHujk5M8muHw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="25bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与<a class="ae kv" rel="noopener" target="_blank" href="/modeling-marketing-mix-using-pymc3-ba18dd9e6e68">贝叶斯方法</a>相比，MAPE提高了40%，NRMSE提高了17%。</p><p id="5f73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，让我们绘制支出份额与效果份额的对比图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/14726b8c1db204a9ae7888b34cfceb97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JS29PafhVEauZkzPAKjjuw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a534" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用分析间隔内每个媒体通道的SHAP值的绝对和来计算效果份额，并通过所有媒体通道的SHAP值的总和来归一化。</p><p id="ae3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">效果份额与<a class="ae kv" rel="noopener" target="_blank" href="/modeling-marketing-mix-using-pymc3-ba18dd9e6e68">上一篇</a>的效果份额几乎一致。我观察到在<em class="nr">搜索</em>频道的效果份额之间只有一个不一致。</p><p id="6a47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">收益递减/饱和效应</strong></p><p id="b3dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我没有应用任何非线性转换来明确地模拟收益递减。所以让我们来看看随机森林是否能捕捉到任何非线性。</p><p id="ce68" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是通过散点图实现的，散点图显示了单个媒体渠道对模型所做预测的影响，其中x轴是媒体支出，y轴是该媒体渠道的SHAP值，它表示知道特定支出会在多大程度上改变该特定预测的模型输出。水平线对应于SHAP值0。垂直线对应于渠道中的平均花费。绿线是一条较低的平滑曲线。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/7122529fcf04290a8ce1f078b8887a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7s0d4Huso_M_xPUr3ujIMw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pg"><img src="../Images/4cf8155453c39489af45c36826c6450e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y7uBvAsBI6f_Skn3IUmYjQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ph"><img src="../Images/065caf390bb8490b7ff5cd5f96208263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CmjV3_cPdGcJ1QnP1DUlg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pi"><img src="../Images/0413dd1fa3073704c43819f57e964da1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kq9ye-dFMPcHOSWze7TukQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pf"><img src="../Images/c9121adda2fbcb340c21b6b3277dd2a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mxxKfkBFrO2Ytb4RFEMfEw.png"/></div></div></figure><p id="3c4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">纵观所有媒体渠道，我们可以看到，更高的支出与收入的增加相关联。但是这种关系并不总是线性的。</p><p id="3a02" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以<em class="nr"> print_S </em>为例，我们可以观察到支出达到25K时收入略有下降。然后它开始增加到大约90K，在那里收入的增加减慢。</p><p id="a615" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以facebook_S 为例，我们可以观察到花费高达9万英镑和超过25万英镑的收入几乎没有变化。9万到25万之间的花费可能是最理想的花费。</p><p id="c240" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一些媒体渠道如<em class="nr"> facebook_S，print_S，和search_S </em>对于同样的花费，SHAP值之间有很大的差异。这可以通过与其他媒体渠道的互动来解释，应该进一步调查。</p><h1 id="ca40" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">多目标优化</h1><p id="61d5" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">这个解决方案可以管理多目标优化。这个想法来自Robyn，他引入了第二个优化指标RSSD(分解均方根距离)</p><blockquote class="no np nq"><p id="831a" class="kw kx nr ky b kz la jr lb lc ld ju le ns lg lh li nt lk ll lm nu lo lp lq lr ij bi translated"><em class="iq">距离说明了花费份额和渠道的系数分解份额之间的关系。如果距离太远，其结果可能太不现实——例如，花费最小的媒体活动获得最大的效果</em></p></blockquote><p id="35b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在多目标优化的情况下，所谓的Pareto前沿，即所有最优解的集合，将由Optuna确定。该过程将与单个优化情况相同:对于属于Pareto前沿的每个模型，我们检索其参数，构建最终模型并可视化结果。<br/>在下图中，所有带红色的点都属于最优集合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pj"><img src="../Images/df430a8842a82cb2abe52f4d1a74a926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBKA1IvZPQcl1ISBcFkoKg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h1 id="2c80" class="nv nw iq bd nx ny nz oa ob oc od oe of jw og jx oh jz oi ka oj kc ok kd ol om bi translated">结论</h1><p id="f928" class="pw-post-body-paragraph kw kx iq ky b kz on jr lb lc oo ju le lf op lh li lj oq ll lm ln or lp lq lr ij bi translated">在这篇文章中，我继续探索通过使用更复杂的算法来改进营销组合模型的方法，这些算法能够捕捉非线性和可变的交互。结果，通过省略非线性变换步骤，简化了整个流水线，当使用线性回归时，总是应用非线性变换步骤。使用SHAP值可以进一步分析效应份额和反应曲线。我的第二个目标是在不同的方法之间达到一致的结果。我使用贝叶斯建模的<a class="ae kv" rel="noopener" target="_blank" href="/modeling-marketing-mix-using-pymc3-ba18dd9e6e68">上一篇文章</a>的结果与本文的结果之间的比较显示，每个媒体频道的分解效果具有高度的一致性。</p><p id="aa90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完整的代码可以从我的<a class="ae kv" href="https://github.com/slavakx/medium_posts" rel="noopener ugc nofollow" target="_blank"> Github repo </a>下载</p><p id="e5a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>