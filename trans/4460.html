<html>
<head>
<title>The Limitations of SHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SHAP的局限性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-limitations-of-shap-703f34061d86#2022-10-04">https://towardsdatascience.com/the-limitations-of-shap-703f34061d86#2022-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c686" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">特征依赖、因果推理和人类偏见如何影响SHAP</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c68d45c21aa9782ad801d770599c337f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nYIuuKdSmyAjDczz"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">维基·西姆在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="8a59" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP是最流行的IML/XAI方法。这是一种用来理解我们的模型如何做出预测的强大方法。</p><p id="a613" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">但是不要让声望说服你。</strong></p><p id="beda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP仍然有局限性。使用这种方法做结论时，你需要记住它们。</p><p id="4ee8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将讨论4个重大限制:</p><ul class=""><li id="631d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">第一个来自SHAP方案本身</li><li id="e108" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">第二个来源于SHAP值的计算方式——我们假设<strong class="lb iu">特征独立</strong></li><li id="5dee" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">第三个来自于我们如何使用它们——不是为了<strong class="lb iu">因果推断</strong></li><li id="ddeb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">最后一点来自于人类如何使用它们——我们<strong class="lb iu">编造故事</strong></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mj mk l"/></div></figure><h1 id="5c87" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">1)SHAP一揽子计划</h1><p id="9bf5" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">第一个与SHAP方案本身有关。内核SHAP在<em class="ni">理论</em>中是一种模型不可知的方法，但这并不意味着它在<em class="ni">实践</em>中是模型不可知的。为什么？嗯，因为它还没有在所有的包中实现。</p><p id="94d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就我个人而言，我用了5个建模包:Scikit learns，XGBoost，Catboost，PyTorch和Keras。记住，如果你正在使用一个不太流行的建模框架，你可能会有一些麻烦。即使是在深度学习方面，SHAP也可能相当善变。我费了很大劲才让它和PyTorch一起工作</p><h1 id="f8eb" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">2)特征依赖性</h1><p id="4712" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">特征依赖是指两个或多个模型特征相关联。也就是说，一个特性的值<em class="ni">取决于另一个特性的值</em>。SHAP在两个方面受到特性依赖的影响。</p><p id="c06d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先是SHAP值的近似值。以KernelSHAP为例。这种方法的工作原理是置换特征值并对这些置换进行预测。一旦我们有足够的排列，Shapley值使用线性回归估计。问题是，当置换特征时，我们假设它们是独立的。</p><blockquote class="nj"><p id="f386" class="nk nl it bd nm nn no np nq nr ns lu dk translated">像许多其他基于排列的解释方法一样，当特征相关时，Shapley值方法受到包含不切实际的数据实例的影响。</p><p id="2bab" class="nk nl it bd nm nn no np nq nr ns lu dk translated">克里斯托弗·莫尔纳尔</p></blockquote><p id="5043" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">这个假设并不总是正确的。取<strong class="lb iu">图1 </strong>中<strong class="lb iu">公里行驶</strong>和<strong class="lb iu">车龄</strong>散点图。这些特征用于预测二手车的价格。有明显的相关性。汽车越旧，我们就有越多的时间来增加它的里程。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/2c98e7de3622e75651bb9f97ee39a2ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*e7U5SabS5HL5_CHy.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:行驶里程与车龄的散点图(来源:作者)</p></figure><p id="3253" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在拿<strong class="lb iu">图2 </strong>中的红色观察来说。这辆车有10年历史了。这个时代的汽车将在实心椭圆内行驶一定距离。当模型被训练时，它只“看到”这些真实的观察结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/139f76745db808d300081f73ca1228ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*2l_naRsZG0RJqybX.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:随机抽样的问题(来源:作者)</p></figure><p id="76f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，当计算SHAP值时，我们在它们的整个范围内置换特征。对于<strong class="lb iu"> km_driven，</strong>这包括虚线范围内不切实际的观察。我们希望模型能够根据这些观察结果做出预测。这可能导致不可靠的预测和SHAP值。</p><p id="92c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在解释SHAP图时，特征依赖性也会导致一些混乱。例如，一个模型可以使用原产国来预测患皮肤癌的几率。有些国家的人是不是先入为主？防晒霜更贵吗？不，是每个国家不同程度的日照。</p><p id="6b7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">原产国被称为代理变量。为什么一个模型会使用它们，这可能不是很明显。归根结底，这是因为机器学习只关心相关性，代理变量与事件的真正原因相关。这就引出了第二个限制。</p><h1 id="9190" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">3)因果推理</h1><p id="8d48" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">SHAP值不能用于因果推断。这是找到事件/目标的真正原因的过程。SHAP值告诉我们每个模型特征对预测的贡献。它们没有告诉我们这些特征是如何影响目标变量的。这是因为模型不一定能很好地代表现实。</p><blockquote class="nj"><p id="5d3b" class="nk nl it bd nm nn no np nq nr ns lu dk translated">Shap并不是衡量“一个给定的特性在现实世界中有多重要”的指标，它只是简单的“一个特性对模型有多重要”。—吉安卢卡·祖恩</p></blockquote><p id="15f8" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">预测可能不正确。在这种情况下，SHAP值将对与真实目标不同的预测做出贡献。如上所述，即使模型是100%准确的，它也可能使用代理变量。所有这些都意味着我们不应该做出超越模型的结论。即使这样做很诱人…</p><h1 id="45f5" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">4)人为错误</h1><p id="0fa4" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">从技术分析到占星术，人类喜欢寻找并不存在的模式。数据科学也不例外。</p><p id="3ff7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在分析SHAP价值观时，我们可能会编造虚假的故事。为什么模型预测癌症发病率高？肯定是帽子不流行了！</p><p id="e392" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以把这些故事强加到分析中，即使它们来自模型的怪癖。作为确认偏差的结果，我们可以无意识地这样做。它也可以被恶意地用来支持一个对某人有利的结论。这类似于p黑的过程。我们烧毁我们的数据和模型，直到它们给出我们想要的结果。</p><blockquote class="nj"><p id="51cc" class="nk nl it bd nm nn no np nq nr ns lu dk translated">确认偏差——无意识地<strong class="ak">偏向于确认你先前已有信念的信息</strong></p></blockquote><p id="0a74" class="pw-post-body-paragraph kz la it lb b lc nt ju le lf nu jx lh li nv lk ll lm nw lo lp lq nx ls lt lu im bi translated">最后，所有这些局限性应该会增加你对使用SHAP得出的结论的怀疑。该结论可能基于不正确的特征独立性假设。永远不要接受超出模型的结论——尤其是如果它支持一个不可告人的动机。</p><p id="aefc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们从总体上审视了SHAP的局限性。不同的近似方法有其特定的局限性。比如KernelSHAP就慢。TreeSHAP更快，但它不是模型不可知的。我们将在下面的文章中讨论这些和其他考虑事项。</p><div class="nz oa gp gr ob oc"><a rel="noopener follow" target="_blank" href="/kernelshap-vs-treeshap-e00f3b3a27db"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">KernelSHAP vs TreeSHAP</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">基于速度、复杂性和其他考虑因素比较SHAP近似方法</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">towardsdatascience.com</p></div></div><div class="ol l"><div class="om l on oo op ol oq ks oc"/></div></div></a></div></div><div class="ab cl or os hx ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="im in io ip iq"><p id="c84b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">支持我成为我的<a class="ae ky" href="https://conorosullyds.medium.com/membership" rel="noopener"> <strong class="lb iu">推荐会员</strong> </a> <strong class="lb iu"> :) </strong></p><div class="nz oa gp gr ob oc"><a href="https://conorosullyds.medium.com/membership" rel="noopener follow" target="_blank"><div class="od ab fo"><div class="oe ab of cl cj og"><h2 class="bd iu gy z fp oh fr fs oi fu fw is bi translated">通过我的推荐链接加入Medium康纳·奥沙利文</h2><div class="oj l"><h3 class="bd b gy z fp oh fr fs oi fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ok l"><p class="bd b dl z fp oh fr fs oi fu fw dk translated">conorosullyds.medium.com</p></div></div><div class="ol l"><div class="oy l on oo op ol oq ks oc"/></div></div></a></div><p id="7356" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">|<a class="ae ky" href="https://twitter.com/conorosullyDS" rel="noopener ugc nofollow" target="_blank">Twitter</a>|<a class="ae ky" href="https://www.youtube.com/channel/UChsoWqJbEjBwrn00Zvghi4w" rel="noopener ugc nofollow" target="_blank">YouTube</a>|<a class="ae ky" href="https://mailchi.mp/aa82a5ce1dc0/signup" rel="noopener ugc nofollow" target="_blank">时事通讯</a> —注册免费参加<a class="ae ky" href="https://adataodyssey.com/courses/shap-with-python/" rel="noopener ugc nofollow" target="_blank"> Python SHAP课程</a></p><h2 id="b905" class="oz mm it bd mn pa pb dn mr pc pd dp mv li pe pf mx lm pg ph mz lq pi pj nb pk bi translated">参考</h2><p id="69cd" class="pw-post-body-paragraph kz la it lb b lc nd ju le lf ne jx lh li nf lk ll lm ng lo lp lq nh ls lt lu im bi translated">南伦德伯格，<strong class="lb iu">SHAP</strong><em class="ni"/>【2021】<em class="ni"/><a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">https://github.com/slundberg/shap</a></p><p id="0a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">南Lundberg &amp; S. Lee，<strong class="lb iu">解释模型预测的统一方法</strong> <em class="ni"> </em> (2017)，<a class="ae ky" href="https://arxiv.org/pdf/1705.07874.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1705.07874.pdf</a></p><p id="4958" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">C.莫尔纳尔、<strong class="lb iu">可解释机器学习</strong> <em class="ni"> </em> (2021)、<a class="ae ky" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">https://christophm.github.io/interpretable-ml-book/</a></p><p id="b3a9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">南Masís，<strong class="lb iu">用Python进行可解释的机器学习</strong> (2021)</p><p id="30e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="pl pm ep" href="https://medium.com/u/25a92c29cc1?source=post_page-----703f34061d86--------------------------------" rel="noopener" target="_blank">钱丹·杜吉亚</a> <strong class="lb iu">利用SHAP进行可解释性——先了解这些限制</strong>(2021)<a class="ae ky" rel="noopener" target="_blank" href="/using-shap-for-explainability-understand-these-limitations-first-1bed91c9d21">https://towardsdatascience . com/Using-shap-for-explability-Understand-these-limits-First-1 bed 91 c9d 21</a></p></div></div>    
</body>
</html>