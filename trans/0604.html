<html>
<head>
<title>Transfer Learning on Greyscale Images: How to Fine-Tune Pretrained Models on Black-and-White Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">灰度图像的迁移学习:如何微调黑白数据集的预训练模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-on-greyscale-images-how-to-fine-tune-pretrained-models-on-black-and-white-9a5150755c7a#2022-02-24">https://towardsdatascience.com/transfer-learning-on-greyscale-images-how-to-fine-tune-pretrained-models-on-black-and-white-9a5150755c7a#2022-02-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f8a4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">您需要了解的一切，以理解为什么通道数量很重要以及如何解决这个问题</h2></div><p id="d996" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着深度学习领域的不断成熟，在这一点上，人们普遍认为迁移学习是计算机视觉快速取得良好结果的关键，尤其是在处理小数据集时。虽然从预训练模型开始会产生的差异部分取决于新数据集与原始训练数据的相似程度，但可以认为从预训练模型开始几乎总是有利的。</p><p id="fae4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管越来越多的预训练模型可用于图像分类任务，但在撰写本文时，其中大多数都是在某个版本的<a class="ae lb" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet数据集</a>上训练的；其中包含彩色图像。虽然这通常是我们正在寻找的，但在某些领域，如制造业和医学成像，经常会遇到黑白图像数据集。</p><p id="5f6e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于彩色图像和黑白图像之间的差异对我们人类来说是微不足道的，所以您可能会认为微调预训练模型应该开箱即用，但这很少发生。因此，尤其是如果您在图像处理方面的背景知识有限，可能很难知道在这些情况下采取什么样的最佳方法，</p><p id="4b77" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我们将尝试通过探索RGB和灰度图像之间的差异，以及这些格式如何影响卷积神经网络模型完成的处理操作，来消除黑白图像微调时需要考虑的所有因素，然后再演示如何将灰度图像用于预训练模型。最后，我们将检查在一些开源数据集上探索的不同方法的性能，并将其与灰度图像上的从头训练进行比较。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/8bcc01a8b93a92b1c354e0357e22e53c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UJ8SZBLWkNVNv6rBRv_1sg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">图片取自公开的<a class="ae lb" href="https://github.com/AI-Lab-Makerere/ibean/" rel="noopener ugc nofollow" target="_blank">豆类数据集</a></p></figure><h1 id="2995" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">RGB和灰度图像有什么区别？</h1><p id="12a3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">虽然彩色和灰度图像可能与我们非常相似，因为计算机只将图像视为一组数字，但这可能会对图像的解释产生巨大的影响！因此，为了充分理解为什么灰度图像可能对预训练网络构成挑战，我们必须首先检查计算机如何解释彩色和灰度图像的差异。</p><p id="b9a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为一个例子，让我们使用来自<a class="ae lb" href="https://github.com/AI-Lab-Makerere/ibean/" rel="noopener ugc nofollow" target="_blank">豆子数据集</a>的图像。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mp"><img src="../Images/9cb45a5fe8ce2cacfd3f3b4942d2e20e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hwmzBwl9ccHgFYPvNpr9vQ.png"/></div></div></figure><h2 id="bec1" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">RGB图像</h2><p id="8e94" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">通常，当我们在深度学习中处理彩色图像时，这些图像是以RGB格式表示的。在高层次上，RGB是加色模型，其中每种颜色由红、绿和蓝值的组合来表示；这些通常存储为单独的“通道”，因此RGB图像通常被称为3通道图像。</p><p id="7ee5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以检查图像的模式——一个定义图像中像素类型和深度的字符串，如这里的<a class="ae lb" href="https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes" rel="noopener ugc nofollow" target="_blank">所描述的</a>——以及检查可用的通道，使用PIL如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nc"><img src="../Images/bae2eb6f978e692ca7a5cfc8d9546470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mC-SvEjs6BfgK1v5nwb7mw.png"/></div></div></figure><p id="59b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这证实了PIL已经认识到这是一个RGB图像。因此，对于每个像素，存储在这些通道中的值(称为强度)构成了整体颜色的一个组成部分。</p><p id="3b0c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些组件可以用不同的方式表示:</p><ul class=""><li id="19cc" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated">最常见的是，组件值存储为0到255范围内的无符号整数；单个8位字节可以提供的范围。</li><li id="2287" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">在浮点表示法中，值可以用0到1来表示，其间可以有任何小数值。</li><li id="73a7" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">每个颜色分量值也可以写成从0%到100%的百分比。</li></ul><p id="ded9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将我们的图像转换为NumPy数组，我们可以看到，默认情况下，图像被表示为一个无符号整数数组:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nr"><img src="../Images/0549de8a6dc6074ea4dc4e93a094aec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ud7-F5G8EEh-wfeBbpeUA.png"/></div></div></figure><p id="0426" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">检查阵列的形状，我们可以看到图像有3个通道，这符合我们的预期:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/743c8a5b57aea1209d0781155015d3e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*1DrAF6M4uSVHOqY3fJD6tA.png"/></div></figure><p id="b3df" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了将我们的图像数组转换成浮点表示，我们可以在创建时显式指定数组的<code class="fe nt nu nv nw b">dtype</code>。让我们看看当我们转换和绘制我们的图像时会发生什么。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nx"><img src="../Images/2e6e2f634bbf3885aac7ad2bb14dccb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3NWH1DCbgDjqRhCrOi9EQ.png"/></div></div></figure><p id="d2fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哦不！</p><p id="5377" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从可以通过检查数据来确认的警告消息中，我们可以看到图像不能正确显示的原因，因为输入数据不在浮点表示的正确范围内。为了纠正这一点，让我们将数组中的每个元素除以255；这应该确保每个元素都在范围[0，1]内。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ny"><img src="../Images/ceb239e2c613d3965009c1a374ff98d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tvcn-NTBHQINO_P7ZZcXWw.png"/></div></div></figure><p id="8f40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">绘制我们的标准化数组，我们可以看到图像现在显示正确！</p><p id="c439" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">了解成分强度</strong></p><p id="e01b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过调整每种成分的强度，我们可以使用RGB模型来表现各种颜色。</p><p id="6dfd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当每个分量的0%强度被组合时，没有光产生，所以这产生了黑色(最暗的颜色)。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/ec203e4446839fd627832ba714b051ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*84sUJiuF4zsChSd7Pi2Wug.png"/></div></figure><p id="c9ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当所有成分的强度都相同时，结果是灰色的阴影，根据强度的大小而变暗或变亮。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oa"><img src="../Images/051e9cc70915d6ed24e0e282981edca3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*is7dAt8jN71NIZ0s0Ibckw.png"/></div></div></figure><p id="7ce7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当其中一种成分的强度比其他成分强时，最终的颜色更接近具有最强成分的原色(红色、绿色或蓝色):</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ob"><img src="../Images/79550272cb9ae3f132ceca3f262035fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g7xhHnoYw0ZP0BzH4rGRAg.png"/></div></div></figure><p id="2913" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当每个成分的100%强度被组合时，这产生白色(最浅的可能颜色)。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oc"><img src="../Images/3af83de948afe0b7d045ccffbf24460a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CU1RGFIagSsl037fEHv_-g.png"/></div></div></figure><p id="d41f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这有望提供RGB图像的概述，但关于RGB颜色模型的更多细节可以在<a class="ae lb" href="https://en.wikipedia.org/wiki/RGB_color_model" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="4fe3" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">灰度图像</h2><p id="f5fd" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在，我们已经研究了如何使用RGB颜色模型来表示彩色图像，让我们研究一下灰度图像与此有何不同。</p><p id="41c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">灰度图像是一种简单的图像，其中仅有的颜色是不同的灰色阴影。虽然我们在日常对话中经常将这样的图像称为“黑白”，但真正的“黑白图像”将只由这两种不同的颜色组成，这种情况很少发生；使“灰度”成为更准确的术语。</p><p id="c588" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于灰度图像没有颜色信息表示，每个像素需要存储的信息更少，并且不需要加色模型！对于灰度图像，我们需要的唯一信息是代表每个像素强度的单一值；该值越高，灰色越浅。因此，灰度图像通常由一个通道组成，其中每个像素强度只是一个从0到255的单一数字。</p><p id="316c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进一步探索这一点，我们可以使用PIL将我们的图像转换成灰度，如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi od"><img src="../Images/c111d5208b0169379b5f20772d07612c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwNO42EhEkCEQx6By50cGA.png"/></div></div></figure><p id="5d21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像以前一样，我们可以使用PIL检查模式和图像通道。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/3426db5b28967c2d2eafd73ffc5f09f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*zfMCdolL3mJmNkjMTKcKSQ.png"/></div></figure><p id="5813" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从<a class="ae lb" href="https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes" rel="noopener ugc nofollow" target="_blank"> PIL的文档</a>中，我们可以看到<code class="fe nt nu nv nw b">L</code>指的是单通道、灰度图像。同样，我们可以通过将该图像转换为数组并检查形状来确认这一点。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi of"><img src="../Images/9471c50c7aeee2a4edcfc2a5fb055d6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaIfB9bZHHmOFcXydJ_kIA.png"/></div></div></figure><p id="f1c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，因为我们只有一个通道，所以默认情况下通道维度被完全删除；这可能会给一些深度学习框架带来问题。我们可以使用NumPy的<code class="fe nt nu nv nw b">expand_dims</code>函数显式添加通道轴。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi og"><img src="../Images/46c52e5e71cf4d97024c8d8b7a11a210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*d0WRFLG5qEvkwW9xNMTMIg.png"/></div></figure><p id="8e48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在PyTorch中，我们可以使用<code class="fe nt nu nv nw b">unsqueeze</code>方法完成同样的事情，如下所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oh"><img src="../Images/60dbbdb0892b99f2cd4fc62ef198f4ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TziWo4dh8_FP1Y7IBQsIBg.png"/></div></div></figure><h1 id="984f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">为什么这会影响预训练模型？</h1><p id="40d3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在观察了RGB和灰度图像之间的差异后，我们可能开始理解这些表示法是如何给模型带来问题的；尤其是如果该模型已经在图像数据集上进行了预训练，而该数据集的格式与我们当前训练的格式不同。</p><p id="777e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目前，大多数可用的预训练模型都是在ImageNet数据集的版本上训练的，该数据集包含RGB格式的彩色图像。因此，如果我们对灰度图像进行微调，我们提供给预训练模型的输入与之前遇到的任何输入都有很大不同！</p><p id="47f0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在撰写本文时，卷积神经网络(CNN)是视觉任务最常用的预训练模型，我们将把重点限制在理解CNN如何受图像中通道数量的影响；其他架构超出了本文的范围！这里，我们假设熟悉CNN，以及卷积是如何工作的——因为有<a class="ae lb" href="https://github.com/fastai/fastbook/blob/master/13_convolutions.ipynb" rel="noopener ugc nofollow" target="_blank">优秀的资源</a>详细介绍了这些主题——并关注改变输入通道的数量将如何影响这一过程。</p><p id="f16b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就我们的目的而言，要记住的关键信息是，CNN的核心构建模块是卷积层，我们可以将其视为应用一组滤波器(也称为内核)的过程，其中滤波器只是一个小矩阵，通常为3×3，作为图像上的滑动窗口；在对结果求和之前执行逐元素乘法。在这里可以找到一个很好的工具来理解这是如何工作的<a class="ae lb" href="https://deeplizard.com/resource/pavq7noze2" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="e4f0" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">通道数量如何影响过滤器？</h2><p id="397b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在深度学习之前的计算机视觉中，过滤器是出于某些目的而手工创建的，例如边缘检测、模糊化等。例如，让我们考虑一个用于检测水平线的手工制作的3×3滤波器:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oi"><img src="../Images/a6d53f7e8cb1a0d9c5ffd72d8150c68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JXWPvhgATw-pmjZPGG1LDQ.png"/></div></div></figure><p id="b55c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然在滑动窗口操作期间在整个图像上使用相同的滤波器“权重”,但是这些权重并不在通道之间共享；这意味着滤波器必须始终具有与输入相同数量的通道。因此，我们想要应用于3通道RGB图像的任何滤镜也必须有3个通道！过滤器拥有的通道数量有时被称为“深度”。</p><p id="cc6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">考虑到我们上面定义的水平线过滤器，为了将其应用于3通道图像，我们需要增加该过滤器的深度，使其为3x3x3。由于我们希望每个通道具有相同的行为，在这种情况下，我们可以简单地沿通道轴复制3×3滤波器。</p><p id="3ee6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以这样做，如下所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oj"><img src="../Images/cd5a9934603bd3a690cd01d5ce23f3ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sI7Tmis5CTq-xLuJVwzbUw.png"/></div></div></figure><p id="8250" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，过滤器的深度与通道的数量兼容，我们能够将此过滤器应用于3通道图像！</p><p id="3faf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，对于每个通道，我们将图像的滑动窗口部分的元素乘以相应滤波器的元素；这将产生3×3矩阵，该矩阵表示对应于每个通道的当前滤波器位置的特征。这些矩阵然后可以被求和以获得我们的输出特征图的相应部分。</p><p id="c46f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个过程如下图所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ok"><img src="../Images/adff991ad83446a5ea9ab7a0aea4e8a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V7TXFAd0hc-uumzKwd70lw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">注意，特征图左上角的像素对应于内核中心像素的位置。由于我们无法计算图像每个边缘上最外层像素的完整卷积，这些像素将不会包含在特征图中。</p></figure><p id="3e6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以重复这个过程，在图像上移动过滤器的位置，以获得完整的输出特征图。注意，不管输入图像的通道数是多少，当每个通道的特征被加在一起时，特征图将总是具有深度1。</p><h2 id="d7a0" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">卷积神经网络</h2><p id="3275" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">既然我们已经探讨了如何将手动定义的滤波器应用于3通道图像，此时，您可能想知道:CNN是如何做到这一点的？</p><p id="85ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CNN背后的一个关键思想是，这些过滤器可以随机初始化，而不是让专家手动定义过滤器，我们相信优化过程可以确保这些过滤器在训练期间学会检测有意义的特征；CNN学习的过滤器类型的可视化<a class="ae lb" href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" rel="noopener ugc nofollow" target="_blank">在这里</a>探讨。因此，除了这些过滤器是学习的而不是定义的，整体过程在很大程度上是相同的！</p><p id="a5bd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在CNN中，每个卷积层包含与将要学习的滤波器相对应的参数；初始化的随机过滤器的数量是我们可以指定的超参数。正如我们在上面的例子中看到的，每个滤波器都会产生一个单通道特征图，因此卷积层初始化的滤波器数量将决定输出通道的数量。</p><p id="b866" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，假设我们有一个单通道图像，我们想创建一个学习单个3×3滤波器的卷积层。我们可以如下所示指定这一点:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ol"><img src="../Images/133e24ec5738f18c41d520b35bf828d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVcvKQC2WT0lPEuyTNg-Mg.png"/></div></div></figure><p id="26e7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们希望滤波器的尺寸与我们之前定义的单通道水平线滤波器相同。让我们通过检查该层的“权重”属性来确认这一点:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fe8f94a56800a20a53439dcad5eae2d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*TU7J3zNXZArq3Zepl3avBQ.png"/></div></figure><p id="6e97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回想一下PyTorch默认情况下首先存储通道数，并注意到出于计算目的添加了一个批次维度，我们可以看到该层已经初始化了一个3x3过滤器，正如我们所预期的那样！</p><p id="04ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们创建另一个卷积层，这一次指定我们有3个输入通道，以便能够处理RGB图像，并检查权重。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi on"><img src="../Images/6b55d889285f4f83932ad30afce18130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XdRzDJLngUbyy-QEZauMIw.png"/></div></div></figure><p id="6795" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似于当我们扩展我们手动定义的过滤器时，初始化的过滤器现在具有与输入通道的数量相同的深度；这给出了3x3x3的尺寸。</p><p id="675e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，当我们扩展手动定义的过滤器时，我们只是复制了相同的权重。这里，关键的区别是每个通道的3×3权重将是不同的；使得网络能够检测每个信道的不同特征。因此，每个内核根据输入图像的每个通道学习特定的特征！</p><p id="42e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过直接检查重量来确认这一点，如下所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oo"><img src="../Images/600791c817033a433a39011fd267b1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PfI3_fbOebUNFZbSgJfNaA.png"/></div></div></figure><p id="e774" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由此，我们可以看到，将应用于每个通道的3×3滤波器的权重是不同的。</p><p id="9e6c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然在创建新的卷积层时，基于我们的输入来调整初始化的滤波器维度是容易的，但是当我们开始考虑预训练的架构时，这变得更加困难。</p><p id="6de4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为一个例子，让我们检查一个来自<a class="ae lb" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank"> PyTorch图像模型(timm)库</a>的<a class="ae lb" href="https://arxiv.org/pdf/2103.07579v1.pdf" rel="noopener ugc nofollow" target="_blank"> Resnet-RS50模型</a>的第一个卷积层，它已经在ImageNet上进行了预训练；如果你对PyTorch图像模型不熟悉，想了解更多，我<a class="ae lb" rel="noopener" target="_blank" href="/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055?source=friends_link&amp;sk=3c4f742ff07279e68652bc254ed0c6e5">以前在这里</a>探索过这个库的一些特性。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ob"><img src="../Images/66182db412b4fb6bdbedfd87a57a1180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iHx5tDmjMa7JWfjpYrhpZw.png"/></div></div></figure><p id="9868" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于该模型是在RGB图像上训练的，我们可以看到每个滤波器都需要一个3通道输入。因此，如果我们试图用一个单一的通道在灰度图像上使用这个模型，这是行不通的，因为我们丢失了重要的信息；过滤器将试图检测不存在的频道中的特征！</p><p id="4e55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，在我们之前的例子中，我们考虑了学习单个滤波器的卷积层；这在实践中很少发生。通常，我们希望每个卷积层有多个滤波器，这样每个滤波器都能够专门识别输入的不同特征。根据任务的不同，有些人可能学会检测水平边缘，有些人可能学会检测垂直边缘，等等。这些特征可以由后面的层进一步组合，使模型能够学习越来越复杂的特征表示。在这里，我们可以看到ResNet-RS50模型的卷积层有32个输出通道，这意味着它已经学习了32个不同的滤波器，每个滤波器都需要一个3通道输入！</p><h1 id="5f5b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">如何在预训练模型中使用灰度图像</h1><p id="ec6f" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">既然我们理解了为什么通道数量减少的灰度图像与在RGB图像上训练的预训练模型不兼容，那么让我们探索一些可以克服这一点的方法吧！</p><p id="2a1f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据我的经验，有两种常用的主要方法:</p><ul class=""><li id="3b5a" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated">向每个灰度图像添加附加通道</li><li id="4478" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">修改预训练网络的第一卷积层</li></ul><p id="725b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们将探索这两种方法。</p><h2 id="240d" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">向灰度图像添加附加通道</h2><p id="bb55" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">可以说，使用灰度图像和预训练模型的最简单的方法是根本避免修改模型；相反，复制现有的通道，使每个图像有3个通道。使用我们之前看到的相同的灰度图像，让我们来探索如何做到这一点。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi op"><img src="../Images/96a6f3f788087bbfd249e3d66992e179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BAVY4Ql4pGtBGrZALBm-tg.png"/></div></div></figure><p id="12b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用NumPy </strong></p><p id="1ff1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们需要将图像转换成一个NumPy数组:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi oq"><img src="../Images/81863e6bce2420ed1c36d54591fe195d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*ExdbrXMrq9yQu7-Wcztd0Q.png"/></div></div></figure><p id="fbc8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们之前观察到的，因为我们的图像只有一个通道，所以通道轴还没有创建。同样，我们可以使用<code class="fe nt nu nv nw b">expand_dims</code>函数来添加这个。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi or"><img src="../Images/7093a40f9c8360b9fadf712ad5930575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Usedkw0xKDyaOjLeKXwQxA.png"/></div></div></figure><p id="6299" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经为渠道维度创建了一个额外的轴，我们需要做的就是在这个轴上重复我们的数据；为此我们可以使用<code class="fe nt nu nv nw b">repeat</code>方法，如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi os"><img src="../Images/ca836453298b364007569455879ea042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*olksQHKGUzE53VFpTYIgVw.png"/></div></div></figure><p id="2623" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了方便起见，让我们将这些步骤总结成一个函数，以便在需要时可以轻松地重复这个过程:</p><pre class="ld le lf lg gt ot nw ou ov aw ow bi"><span id="c2a1" class="mq lt iq nw b gy ox oy l oz pa">def expand_greyscale_image_channels(grey_pil_image):<br/>    grey_image_arr = np.array(grey_image)<br/>    grey_image_arr = np.expand_dims(grey_image_arr, -1)<br/>    grey_image_arr_3_channel = grey_image_arr.repeat(3, axis=-1)<br/>    return grey_image_arr_3_channel</span></pre><p id="101a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将这个函数应用到我们的图像，并绘制输出，我们可以看到结果图像显示正确，虽然现在它有3个通道。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pb"><img src="../Images/bb95b910beae8d5b1317656b534a553d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qETT7aKFXagxNIhp1-FTtw.png"/></div></div></figure><p id="f365" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用PyTorch </strong></p><p id="e7d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们做的是深度学习，那么探索如何直接使用PyTorch进行这种转换可能会更有用，而不是使用NumPy作为中介。虽然我们可以在PyTorch张量上执行与上述类似的一系列步骤，但作为训练过程的一部分，我们可能希望在我们的图像上执行额外的变换，如TorchVision中定义的数据扩充操作。因为我们希望3通道转换发生在我们的增强管道的开始，并且一些后续的转换可能期望PIL图像，所以直接操纵张量可能不是这里的最佳方法。</p><p id="648e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令人欣慰的是，虽然有些违反直觉，但我们可以使用TorchVision中现有的灰度转换来完成这一转换！虽然这种变换需要torch张量或PIL图像，但我们希望这是我们管道中的第一步，所以我们在这里使用PIL图像。</p><p id="fd7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">默认情况下，这种转换将RGB图像转换为单通道灰度图像，但是我们可以通过使用<code class="fe nt nu nv nw b">num_output_channels</code>参数来修改这种行为，如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pc"><img src="../Images/dacc7cb8e04ef530d38dce2df3bedf06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lC9u5qRfhzKo9Hie6YuVfQ.png"/></div></div></figure><p id="f432" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们看看如果我们把这个变换应用到灰度图像上会发生什么。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pd"><img src="../Images/c3059c231f13a4dc146bb2ae9a015039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Jgq_EjfRWTXrdtfafxwbA.png"/></div></div></figure><p id="09ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">乍一看，虽然一切都变了，但看起来并不像。但是，我们可以通过检查PIL图像的通道和模式来确认转换已经按预期工作。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/cedf05301a38a79a7cb1fb104db5d842.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*f7VfXVnIwZ6-Qq-Nxz9r4w.png"/></div></figure><p id="75f4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于添加了额外的通道，我们可以看到PIL现在将该图像称为RGB图像；这正是我们想要的！</p><p id="9b70" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，通过这种方法，使用灰度图像的训练脚本所需的唯一修改是将该变换预先添加到增强管道中，如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pf"><img src="../Images/cb1bc48def833845b4ad4d2c6e497985.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Np6MFIke2Rs07Cr0y38UHg.png"/></div></div></figure><h2 id="870a" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">修改预训练网络的第一卷积层</h2><p id="7327" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">虽然如上所述，将单个通道图像扩展到3个通道是方便的，但是这样做的潜在缺点是需要额外的资源来存储和处理额外的通道；在这种情况下没有提供任何新的信息！</p><p id="df20" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一种不同的方法是修改模型以适应不同的输入，在大多数情况下，这需要修改第一卷积层。虽然我们可以用一个新的层来替换整个层，但这将意味着丢弃模型的一些学习到的权重，除非我们冻结后续层并孤立地训练新层，这需要额外的努力，否则来自这些新的、随机初始化的权重的输出可能会负面地扰乱一些后面的层。</p><p id="9122" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">或者，回想卷积层中的每个滤波器都有单独的通道，我们可以沿通道轴将这些通道相加。下面我们来探讨一下如何做到这一点。我们将再次使用PyTorch图像模型中的Resnet-RS50模型。</p><p id="4a47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们创建我们的预训练模型:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pg"><img src="../Images/95b3eb493c390c25d39dd208b7be8bde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QU2LHCzhsz9_pxA2cXC07A.png"/></div></div></figure><p id="4f55" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所料，根据我们之前对滤镜和通道的探索，如果我们试图在开箱即用的单通道图像上使用此模型，我们会观察到以下错误。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi ph"><img src="../Images/eeba8cd42cf061371d3e6e05def30a77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10GufA1jMSLajbC4BLn-pQ.png"/></div></div></figure><p id="9ad6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过调整第一个卷积层的权重来解决这个问题。对于该模型，我们可以如下所示进行访问，但这将因所用模型而异！</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/85dc44a52ee0fa67ad2f3c45111f044a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*u7UsuPEbsuR6aJry1MKHPg.png"/></div></figure><p id="da9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们更新这个层的<code class="fe nt nu nv nw b">in_channels</code>属性来反映我们的变化。这实际上不会修改权重，但是会更新打印模型时看到的概述，并确保我们能够正确地保存和加载模型。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/3456055c299a15198aacf8d3afa3e47f.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*lz86EFAxUWhZ91LX-QpR_w.png"/></div></figure><p id="bf1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们执行实际重量更新。我们可以使用<code class="fe nt nu nv nw b">sum</code>方法做到这一点，确保将<code class="fe nt nu nv nw b">keepdim</code>参数设置为<code class="fe nt nu nv nw b">True</code>以保留维度。唯一需要注意的是，由于一个新的张量作为<code class="fe nt nu nv nw b">sum</code>操作的结果被创建，我们必须将这个新的张量包装在<code class="fe nt nu nv nw b">nn.Parameter</code>中；以便新的权重将被自动添加到模型的参数中。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pk"><img src="../Images/fbb309c8a9504ad7f41b66c260c18fba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjUNixd2P3Ppkmcp-non0Q.png"/></div></div></figure><p id="1f42" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，使用单通道图像的模型，我们可以看到正确的形状已经返回！</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/0719304636b0c40935590eee2ab769c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*CS68n46CbNvzHalrqvhC3w.png"/></div></figure><p id="2273" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">使用timm </strong></p><p id="ef8a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然我们可以在任何PyTorch模型上手动执行上述步骤，但timm已经包含了为我们执行这些步骤的功能！要以这种方式修改timm模型，我们可以在创建模型时使用<code class="fe nt nu nv nw b">in_chans</code>参数，如下所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pm"><img src="../Images/580785f3bdfeabadb99f47a907138e21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hHqYP8EPBpisDIzeh6kxEA.png"/></div></div></figure><h1 id="c980" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">比较开源数据集上的性能</h1><p id="5f97" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">现在我们已经研究了两种方法，我们可以使用灰度图像与预训练的模型，你可能想知道使用哪一个；或者简单地在灰度图像上从头开始训练模型是否更好！</p><p id="a079" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，由于可以使用的模型、优化器、调度器和训练策略的几乎无限的组合，以及数据集中的差异，为此确定通用规则是极其困难的；“最佳”方法可能会因您正在调查的特定任务而异！</p><p id="3831" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管如此，为了大致了解这些方法的执行情况，我决定在三个开源数据集上训练我最喜欢的模型-优化器-调度器组合之一，以查看不同方法之间的比较。虽然改变培训政策可能会影响不同方法的表现，但为了简单起见，培训过程保持相对一致；基于我发现行之有效的实践。</p><h2 id="aa66" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">实验设置</h2><p id="3a17" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">对于所有实验运行，以下保持一致:</p><ul class=""><li id="0309" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated"><strong class="kh ir">型号</strong> : ResNet-RS50</li><li id="fbcb" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">优化器</strong> : AdamW</li><li id="4d67" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir"> LR调度器</strong>:余弦衰减</li><li id="8377" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">数据扩充</strong>:图像尺寸调整为224，训练时使用了水平翻转</li><li id="8b3c" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">初始LR </strong> : 0.001</li><li id="3b2e" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">最大段数</strong> : 60</li></ul><p id="50b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有训练都是使用单个NVIDIA V100 GPU进行的，批量大小为32。为了处理训练循环，我使用了<a class="ae lb" href="https://github.com/Chris-hughes10/pytorch-accelerated" rel="noopener ugc nofollow" target="_blank"> PyTorch加速库</a>。</p><p id="0859" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用的数据集有:</p><ul class=""><li id="8ad2" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated"><a class="ae lb" href="https://github.com/AI-Lab-Makerere/ibean/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">豆子</strong> </a>:豆子是用智能手机相机在田间拍摄的豆子图像数据集。它包括3个类别，2个疾病类别和健康类别。</li><li id="fea8" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="http://laurencemoroney.com/rock-paper-scissors-dataset" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">石头剪子布</strong> </a> <strong class="kh ir"> (RPS) </strong>:双手玩石头剪子布游戏的画面。</li><li id="28f4" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">牛津宠物</strong></a>:37类宠物数据集，每类大约有200张图片。</li></ul><p id="0788" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于每个数据集，我探索了以下处理灰度图像的方法:</p><ul class=""><li id="22c3" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated"><strong class="kh ir"> RGB </strong>:使用RGB图像作为基线，对模型进行微调。</li><li id="8f34" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">带有3个通道的灰度图像</strong>:灰度图像被转换为3个通道的格式。</li><li id="d48b" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">灰度w/ 1通道</strong>:模型的第一层被转换成接受单通道图像。</li></ul><p id="ba63" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在与每种方法相关的地方，我使用了以下培训策略:</p><ul class=""><li id="63bd" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated"><strong class="kh ir"> Finetune </strong>:使用预训练模型，首先训练模型的最后一层，然后解冻和训练整个模型。解冻后，学习率降低10倍。</li><li id="e6f8" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">微调整个模型</strong>:训练整个预训练模型，不冻结任何层。</li><li id="28ba" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><strong class="kh ir">从零开始</strong>:从零开始训练模型</li></ul><p id="68b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面提供了用于运行该实验的培训脚本，使用的包版本有:</p><ul class=""><li id="216b" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated">PyTorch: 1.10.0</li><li id="4d0c" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">py torch-加速:0.1.22</li><li id="f6dd" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">timm: 0.5.4</li><li id="f1c2" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">火炬度量:0.7.1</li><li id="3d18" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">熊猫</li></ul><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="pn po l"/></div></figure><h2 id="907a" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated">结果</h2><p id="b13b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这些运行的结果如下表所示。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi pp"><img src="../Images/708f39844f3a07eca5495a172dd276b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pA9wPCP2X_uaGWRxBVk7oQ.png"/></div></div></figure><p id="78a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这些实验中，我的主要观察结果是:</p><ul class=""><li id="2e27" class="nd ne iq kh b ki kj kl km ko nf ks ng kw nh la ni nj nk nl bi translated">使用预先训练的模型，并使其适应灰度图像，似乎比从头开始训练更容易获得好的结果。</li><li id="483a" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">对这些数据集的最佳方法似乎是修改图像中的通道数，而不是修改模型。</li></ul><h1 id="a7f3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="bf53" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">希望这已经提供了一个合理的全面概述如何微调灰度图像上的预训练模型，以及理解为什么需要额外的考虑。</p><p id="1e92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="pq">克里斯·休斯上了</em> <a class="ae lb" href="http://www.linkedin.com/in/chris-hughes1/" rel="noopener ugc nofollow" target="_blank"> <em class="pq">领英</em> </a> <em class="pq">。</em></p><h1 id="3ea7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ul class=""><li id="2666" class="nd ne iq kh b ki mk kl ml ko pr ks ps kw pt la ni nj nk nl bi translated"><a class="ae lb" href="https://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">ImageNet(image-net.org)</a></li><li id="b1aa" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://en.wikipedia.org/wiki/RGB_color_model" rel="noopener ugc nofollow" target="_blank"> RGB颜色模型—维基百科</a></li><li id="c4c6" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://pillow.readthedocs.io/en/latest/handbook/concepts.html#modes" rel="noopener ugc nofollow" target="_blank">概念—枕头(PIL叉)9.1.0.dev0文档</a></li><li id="654a" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://github.com/fastai/fastbook/blob/master/13_convolutions.ipynb" rel="noopener ugc nofollow" target="_blank">fastbook/13 _ convolutions . ipynb at master fastai/fastbook(github.com)</a></li><li id="d5e4" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://deeplizard.com/resource/pavq7noze2" rel="noopener ugc nofollow" target="_blank">深蜥蜴——卷积演示</a></li><li id="a85b" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" rel="noopener ugc nofollow" target="_blank">nyu.edu LNCS 8689——可视化和理解卷积网络</a></li><li id="8607" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://arxiv.org/pdf/2103.07579v1.pdf" rel="noopener ugc nofollow" target="_blank">重访ResNets:改进培训和扩展战略(arxiv.org)</a></li><li id="4568" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://github.com/rwightman/pytorch-image-models" rel="noopener ugc nofollow" target="_blank">rwightman/py torch-image-models:py torch图像模型、脚本、预训练权重ResNet、ResNeXT、EfficientNet、EfficientNetV2、NFNet、Vision Transformer、MixNet、MobileNet-V3/V2、RegNet、DPN、CSPNet等(github.com)</a></li><li id="fea9" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">【PyTorch图像模型(timm)入门:实践者指南|克里斯·休斯| 2022年2月|迈向数据科学</li><li id="2b45" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated"><a class="ae lb" href="https://github.com/Chris-hughes10/pytorch-accelerated" rel="noopener ugc nofollow" target="_blank">Chris-Hughes 10/pytorch-accelerated:一个轻量级库，旨在通过提供一个最小但可扩展的训练循环来加速py torch模型的训练过程，该训练循环足够灵活，可以处理大多数用例，并且能够利用不同的硬件选项，而无需更改代码。文件:https://pytorch-accelerated.readthedocs.io/en/latest/(github.com)</a></li></ul><h2 id="b8ff" class="mq lt iq bd lu mr ms dn ly mt mu dp mc ko mv mw me ks mx my mg kw mz na mi nb bi translated"><strong class="ak">使用的数据集</strong></h2><ul class=""><li id="32dd" class="nd ne iq kh b ki mk kl ml ko pr ks ps kw pt la ni nj nk nl bi translated">bean数据集，<a class="ae lb" href="https://github.com/AI-Lab-Makerere/ibean/" rel="noopener ugc nofollow" target="_blank">AI-Lab-Makerere/ibean:AIR Lab的ibean项目的数据报告。</a>(github.com)。麻省理工学院许可，无限制使用。</li><li id="c35a" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">石头、剪子、布数据集，劳伦斯·莫罗尼<a class="ae lb" href="https://laurencemoroney.com/datasets.html" rel="noopener ugc nofollow" target="_blank">机器学习数据集——劳伦斯·莫罗尼——人工智能家伙。</a> CC By 2.0许可证，可自由共享并适用于所有用途，包括商业或非商业用途</li><li id="ff52" class="nd ne iq kh b ki nm kl nn ko no ks np kw nq la ni nj nk nl bi translated">牛津Pets数据集，<a class="ae lb" href="https://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津大学视觉几何组</a>。<a class="ae lb" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名-共享4.0国际许可</a>，包括商业和研究目的。</li></ul></div></div>    
</body>
</html>