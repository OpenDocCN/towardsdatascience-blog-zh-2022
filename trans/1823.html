<html>
<head>
<title>Lasso and Ridge regression: An intuitive comparison</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">套索和岭回归:直观的比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lasso-and-ridge-regression-an-intuitive-comparison-3ee415487d18#2022-04-28">https://towardsdatascience.com/lasso-and-ridge-regression-an-intuitive-comparison-3ee415487d18#2022-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="6058" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">以及它们如何帮助你理解正规化</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7f120722358a9d83ac5b0cc9977e1e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sxb7OPYTp5FAkQ72YrXrIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">套索和山脊(<a class="ae ky" href="https://hastie.su.domains/Papers/ESLII.pdf" rel="noopener ugc nofollow" target="_blank">统计学习的要素</a></p></figure><h1 id="4492" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="bfbd" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当人们开始他们的机器学习之旅时，他们通常从线性回归开始，这是最简单的算法之一。然而，这种模型很快就显示出它的局限性，特别是在处理导致模型过度拟合的数据集时。对此的主要解决方案被称为岭和套索回归。</p><h2 id="61d6" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">偏差方差权衡</h2><p id="25c5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">为了理解为什么这些模型是有用的，我们首先需要讨论偏差-方差权衡。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/beadedb6245df73bfc5d90315d08251d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U3LfTrsIdOS8wWs2CvigrQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">偏差方差权衡(<a class="ae ky" href="https://hastie.su.domains/Papers/ESLII.pdf" rel="noopener ugc nofollow" target="_blank">统计学习的要素</a></p></figure><p id="212f" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">在监督设置中，模型的误差主要有两个来源:偏差和方差。</p><ul class=""><li id="b8fc" class="nf ng it lt b lu na lx nb ma nh me ni mi nj mm nk nl nm nn bi translated"><strong class="lt iu"> <em class="no">偏差</em> </strong>是学习算法中错误假设产生的误差。高偏差会使算法错过特征和目标之间的相关关系(也称为欠拟合)</li><li id="3e13" class="nf ng it lt b lu np lx nq ma nr me ns mi nt mm nk nl nm nn bi translated"><strong class="lt iu"> <em class="no">方差</em> </strong>是由于对训练数据的微小波动敏感而产生的误差。高方差将使算法模拟训练数据的随机噪声(也称为过拟合)。</li></ul><p id="6763" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">理想情况下，您希望找到这两个分量之和最小的最佳点。这将为您提供性能最佳的模型。</p><h2 id="bc50" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">例子</h2><p id="41bb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们将看到一个拟合不足的例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/424003a74ed052a771dd93af48e6d5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fBXlkLnktB9J6SAN_4Ej2w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">底切的例子(图片由作者提供)</p></figure><p id="d355" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这里，您可以看到模型没有很好地捕捉特征和目标之间的关系。因此，它具有高偏差(算法错过了特征和目标之间的相关关系)但具有低方差(没有对数据的随机噪声建模)。</p><p id="a158" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">相反，这里有一个过度拟合的例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/822ef4f3d6a85bf13b3a37783a1d4cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SsOBD8psde3hnaNlR2UgIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">过度拟合的例子(图片由作者提供)</p></figure><p id="2481" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">在这里，您可以看到算法理解特征和目标之间的关系，但也对数据的噪声进行建模。因此，它具有低偏差(算法获得特征和目标之间的相关关系)但具有高方差(模拟训练数据的随机噪声)。</p><p id="a429" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">现在，让我们看看一个合适的例子是什么样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/34dc2cf7524a23ed3b23028980f81074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6q3aLgLdyLkF5jT_JzXL2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">非常适合的示例(图片由作者提供)</p></figure><p id="85d5" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">在这里，您可以看到该算法能够模拟特征和目标之间的关系，但它不能模拟数据的噪声。因此，它具有低偏差和低方差。这就是我们想要达到的契合度。</p><h2 id="f133" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">这和山脊/套索有什么联系？</h2><p id="ee95" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当您拟合线性回归模型时，会发生以下情况。您有一组特征(通常称为X，表示为矩阵),并且您想要找到一组系数(通常称为β，表示为向量),通过乘以X中的值来预测您的目标(通常称为y，表示为向量)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/06157d952b7a46436998cc053700333b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_amMSndwM1cgr-Ojw067w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用线性模型进行预测(图片由作者提供)</p></figure><p id="771a" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">问题是，在某些情况下，线性回归会过度拟合特定的数据集。这种情况下你会怎么做？使用脊和套索回归。</p><h1 id="4bf9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">这些模型是如何工作的？</h1><p id="2503" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Lasso和Ridge都是线性回归模型，但有一个惩罚(也称为正则化)。它们以不同的方式增加了β向量的惩罚。</p><h2 id="9259" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">套索回归</h2><p id="5a9e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">Lasso对你的Beta向量的l1范数进行惩罚。向量的l1范数是该向量中绝对值的和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/551c378f0e2617743f4ab2e64fdce23f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mLGmWk09-2mfBb27Qm13jQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">向量的l1范数(图片由作者提供)</p></figure><p id="c9c6" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这使得拉索零出一些系数在你的贝塔矢量。我不会详细解释原因，因为这会使本教程过于复杂，并且需要优化方面的背景知识。如果你对为什么会发生这种情况感兴趣，看看这个<a class="ae ky" href="https://online.stat.psu.edu/stat508/lesson/5/5.4" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="6e8c" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">简而言之，使用Lasso就像是在说:“尽可能实现最佳性能，但如果你发现一些系数没有用，就把它们丢掉”。</p><h2 id="79df" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated"><strong class="ak">岭回归</strong></h2><p id="7eda" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">里奇对β向量的l2范数进行了惩罚。向量的2范数是向量中平方值之和的平方根。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/da757803c30d7c80dd6e21f0729b84ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9dmjrMj7uw_nspKtuShs6w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">向量的l2范数(图片由作者提供)</p></figure><p id="c369" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这使得Ridge防止Beta向量的系数达到极值(这在过度拟合时经常发生)。</p><p id="3b5c" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">简而言之，使用Ridge就像是说:“尽可能实现最佳性能，但任何系数都不应有极值”。</p><h2 id="738b" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">正则化参数</h2><p id="5c40" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这两个模型都有一个称为lambda的正则化参数，它控制惩罚的大小。在λ=0时，Lasso和Ridge都成为线性回归模型(我们只是不加任何惩罚)。通过增加λ，我们增加了对β向量大小的约束。这是每个模型进行不同优化的地方，并试图找到给定其自身约束的最佳系数集。</p><h1 id="a594" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">一个例子:波士顿住房数据集</h1><p id="f4c6" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">让我们试着看看在数据集的实践中我们会遇到什么问题，以及我们如何用脊和套索来解决这些问题。</p><p id="1d52" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">要跟进，请访问我的GitHub上的这个<a class="ae ky" href="https://github.com/tlemenestrel/lasso_vs_ridge" rel="noopener ugc nofollow" target="_blank">链接</a>，并简单地按照自述文件中的说明进行操作。我使用的数据集可以从Kaggle下载<a class="ae ky" href="https://www.kaggle.com/prasadperera/the-boston-housing-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h2 id="6185" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">波士顿住房数据集</h2><p id="bb4e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">波士顿住房数据集来自1993年，是机器学习领域最著名的数据集之一。目标要素是波士顿住宅的中值，而要素是相关联的住宅和街区属性。</p><h2 id="28c4" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">读取数据集</h2><p id="09a7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">第一步是读取数据集并打印其前5行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/9e829f606de6c52b5ba17b22b8ef67ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oFbLp52r-XffoTw7RCNvyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">读取数据(图片由作者提供)</p></figure><p id="b0e9" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">首先，我使用一个列表定义列名。然后，我调用read _ CSV with<em class="no">delim _ white space = True</em>来告诉pandas我们的数据是由空格而不是逗号分隔的，<em class="no"> header=None </em>来表示文件的第一行不是列标题，最后<em class="no"> names=colnames </em>使用我们之前定义的列表作为列名。</p><p id="5a56" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我也用。head(100)仅保留数据集的前100行，而不是包含505行数据的完整数据集。这样做的原因是我想说明过度拟合，如果我们有更少的数据，这将是更有可能的。实际上，您应该保存完整的数据集(一般来说，数据越多越好)。</p><h2 id="0b8c" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">列车测试分离</h2><p id="7cca" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下一步是将我们的数据分为X(特征)和Y(目标)，然后将这两个数据分为训练集(X_train，y_train)和测试集(X_test，y_test)。我将80%的数据放在训练集中，20%放在测试集中，这是机器学习问题最常见的分裂之一。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/dda22fd40dcc6898779f309258ffeec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZvlgCkTjmcm_gEZXmEMog.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">训练测试分割(图片由作者提供)</p></figure><h2 id="5a18" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">拟合线性回归模型</h2><p id="120b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在此之后，我对训练数据拟合线性回归模型，并计算测试数据的均方误差(MSE)。最后，我打印出β向量，看看我们的模型的系数是什么样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/92733fb2bc8d314695f56d93e2a5c79b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAnCXZQ6LEEtw4tTDdVMGg.png"/></div></div></figure><p id="4214" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">那么，我们能做得比≈6.4 MSE更好吗？是的。</p><p id="45b8" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated"><strong class="lt iu">套索回归</strong></p><p id="6b3a" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">在本例中，我使用一系列的lambda值拟合各种Lasso回归模型，lambda值是正则化参数(lambda值越高，我们对模型的惩罚就越高，即我们限制beta向量的绝对值之和)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/4c4acdaec37636520462d4355e534266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WSXizBugkQqwQQ80NXLbgw.png"/></div></div></figure><p id="ee1e" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我们看到，当λ= 0.3时，性能最高，MSE约为4.2。现在，让我们看看β向量的系数是什么样的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/b936c4352915f610dc0c03ce07616700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_PtmXkNJtS2P5mTpJ98mzw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带套索的贝塔矢量的系数(图片由作者提供)</p></figure><p id="f3e6" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">你可以看到这个模型已经剔除了大约一半的系数。它只保留了14个系数中的8个，但保留了其中一个相当大的权重，RM是每个住宅的平均房间数。这是有道理的，因为一处房产的房间数量通常与其价格相关(6人公寓几乎总是比1人公寓贵)。</p><p id="fa05" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">因此，您可以看到与我们之前讨论的内容之间的联系。我们“告诉”Lasso找到最佳模型，给出每个系数的权重限制(即“预算”)，它“决定”将大量“预算”放在房间数量上，以计算出房产的价格。</p><p id="7c16" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">现在，让我们看看里奇能做什么。</p><h2 id="02ab" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">里脊回归</h2><p id="b0b3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这里，我用套索应用与之前相同的步骤。我在这里使用的λ值是不同的。请记住，脊和套索之间的λ值不成比例，即套索的λ值为5并不等于脊的λ值为5。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/71e3bf5c2ec3accc20b07ea8238a3cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JoDp0sHnykWgRPH5OTbHGA.png"/></div></div></figure><p id="41a7" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我们在这里看到，在λ= 3时，我们能够做得比以前更好，MSE ≈ 4.1，这比Lasso和线性回归都好。现在，让我们看看β向量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/929c1274d27002727209fb2c4cae3820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMTb6MaBoIhbo0zyY8Yg6A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">山脊的贝塔矢量(图片由作者提供)</p></figure><p id="9842" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我们看到，RM的系数仍然很高(约3.76)，而所有其他系数都降低了。然而，没有一个像套索一样被归零。</p><p id="ea7b" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">这是两者之间的关键区别:Lasso通常会将特征清零，而Ridge会减少模型中大多数特征的权重。</p><p id="a61d" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我邀请您仔细检查每个模型的Beta向量，并仔细检查这些值:理解Beta向量中发生的事情是理解这些模型的关键。</p><h2 id="c058" class="mn la it bd lb mo mp dn lf mq mr dp lj ma ms mt ll me mu mv ln mi mw mx lp my bi translated">如何决定用哪一个？</h2><p id="b23e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">当你有几个预测能力很强的特征而其他特征没有用的时候，Lasso是很好的:它会将无用的特征清零，只保留变量的子集。</p><p id="39f1" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">当数据集的预测能力分布在不同的要素上时，岭很有用:它不会将可能有助于进行预测的要素清零，而只是减少模型中大多数变量的权重。</p><p id="33ac" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">实际上，这通常很难确定。因此，最好的方法是简单地做我上面编码的事情，看看在测试集上使用不同的lambda值能得到什么样的最佳MSE。</p><h1 id="f8aa" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">更进一步</h1><p id="4cc5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如果你想更深入地研究数学(我建议你这样做，因为它会帮助你更好地理解正则化是如何工作的)，我推荐你阅读特雷弗·哈斯蒂、罗伯特·蒂伯拉尼和杰罗姆·弗里德曼的《统计学习的要素》第3.4章。罗伯特·提布拉尼是套索的发明者，也是我在斯坦福大学的机器学习教授。他的书是这一领域的参考，深入研究了数学，同时也给出了正在发生的事情的全貌。</p><p id="a359" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated">我还建议在不同的数据集上重新实现这些模型，看看哪一个表现最好，并尝试了解为什么会这样。</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><p id="8980" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated"><em class="no">我希望你喜欢这个教程！让我知道你对它的看法。</em></p><p id="38c8" class="pw-post-body-paragraph lr ls it lt b lu na ju lw lx nb jx lz ma nc mc md me nd mg mh mi ne mk ml mm im bi translated"><em class="no">随时连接上</em><a class="ae ky" href="https://www.linkedin.com/in/thomas-le-menestrel/" rel="noopener ugc nofollow" target="_blank"><em class="no">LinkedIn</em></a><em class="no">和</em><a class="ae ky" href="https://github.com/tlemenestrel" rel="noopener ugc nofollow" target="_blank"><em class="no">GitHub</em></a><em class="no">谈论更多关于数据科学和机器学习的话题并关注我上</em> <a class="ae ky" href="https://tlemenestrel.medium.com" rel="noopener"> <em class="no">中</em> </a> <em class="no">！</em></p></div></div>    
</body>
</html>