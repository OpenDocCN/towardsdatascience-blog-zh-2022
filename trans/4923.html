<html>
<head>
<title>Outlier Detection With Autoencoders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用自动编码器的异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/outlier-detection-with-autoencoders-6c7ac3e2aa90#2022-11-02">https://towardsdatascience.com/outlier-detection-with-autoencoders-6c7ac3e2aa90#2022-11-02</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="09ca" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">自动编码器</h2><div class=""/><div class=""><h2 id="530d" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">如果你不能压缩它，它可能有问题</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/772c83043208c9aac3b6e9447d85b38c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Mo58U59Ro2lqmSYo"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">兰迪·法特在<a class="ae li" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5dad" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">你在数据科学和机器学习中遇到的一个经典障碍是<em class="mf">离群值</em>。离群值的概念对人类来说是直观明了的，然而除了涉及标准偏差或四分位间距的简单统计数据101之外，没有一般有意义的数学定义。</p><p id="57e8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我认为原因可能是想出一个异常值是相当棘手的，因为一个异常值对不同的人可能意味着不同的事情。以下面的数据集为例:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj mg"><img src="../Images/b5e99720eed372f0cee2f1a5c06771c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UBACLCZSzUpEsc_Rze7auA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="78fd" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我认为大多数人——包括我——会认为右上角的点是异常值。中间的点更有意思:一方面，它不在你脑子里画的这个假想的圆上，所以它应该是一个离群值。另一方面，与其他点相比，它的<em class="mf"> x </em>和<em class="mf"> y </em>坐标都不是真正疯狂的——中心点实际上是尽可能平均的。</p><p id="2ec8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我仍然认为这个点是一个异常值，因为实际数据点形成一个圆感觉是对的。然而，这不是你可以变成一个实际的算法来寻找离群值。</p><p id="a1b8" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">如果这个小小的二维例子已经引发了一些讨论，想象一下当我们处理更高维的数据时会发生什么，你不能再可视化来看它。</p><p id="8250" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">在本文中，您将学习如何使用Tensorflow中的自动编码器用几行代码构建一个离群点检测器。</strong></p><h2 id="0cd4" class="mh mi iu bd mj mk ml dn mm mn mo dp mp ls mq mr ms lw mt mu mv ma mw mx my ja bi translated">我们为什么关心？</h2><p id="8b17" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">根据<em class="mf">定义</em>，异常值不像其他数据点。除其他原因外，异常值可能是:</p><ul class=""><li id="b8db" class="ne nf iu ll b lm ln lp lq ls ng lw nh ma ni me nj nk nl nm bi translated"><strong class="ll je">测量错误或输入错误:</strong>有人输入了777公斤，而不是77公斤</li><li id="5e89" class="ne nf iu ll b lm nn lp no ls np lw nq ma nr me nj nk nl nm bi translated"><strong class="ll je">虚拟值:</strong>有些东西无法测量，数据管道将999估算为固定值</li><li id="4563" class="ne nf iu ll b lm nn lp no ls np lw nq ma nr me nj nk nl nm bi translated"><strong class="ll je">稀有数据点/自然离群值:</strong>如果你有一个由二手车组成的数据集，一辆法拉利与其他汽车不同</li></ul><p id="aa43" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们关心异常值，因为它会严重扭曲分析和机器学习模型训练的结果。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ns"><img src="../Images/c9a8ffa20da09f3f142de112434dd3bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFrtMHL5sOSfvfVHLLqZdA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="57f9" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">向模型提供源自错误、输入错误和伪值的离群值基本上意味着向模型提供垃圾，这反过来又使模型学习并输出垃圾。</p><p id="37a5" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">用自然离群值填充模型可能会导致对这些稀有数据点的过度拟合，这是需要记住的一件重要事情。</p><blockquote class="nt nu nv"><p id="dc70" class="lj lk mf ll b lm ln ke lo lp lq kh lr nw lt lu lv nx lx ly lz ny mb mc md me in bi translated"><strong class="ll je"> <em class="iu">注:</em> </strong> <em class="iu">处理离群值的方法有很多，这里就不赘述了。最常用的方法是删除异常值。因此，您会丢失一些数据，但是您的分析或模型的整体质量可能会提高。</em></p></blockquote><h1 id="1892" class="nz mi iu bd mj oa ob oc mm od oe of mp kj og kk ms km oh kn mv kp oi kq my oj bi translated">寻找异常值</h1><p id="acbc" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">有多种方法可以发现异常值。来自<a class="ae li" href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html" rel="noopener ugc nofollow" target="_blank">牛逼的scikit-learn网站</a>:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ok"><img src="../Images/f673d73c5fe2fa840864db67d8ca87f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lHvX0zko0QjRjMom.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated"><a class="ae li" href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/auto _ examples/miscellaneous/plot _ anomaly _ comparison . html</a></p></figure><p id="aa61" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">然而，我们将关注另一种你不知道的方法(还不知道？)在scikit-learn中查找。</p><h2 id="9107" class="mh mi iu bd mj mk ml dn mm mn mo dp mp ls mq mr ms lw mt mu mv ma mw mx my ja bi translated">自动编码器</h2><p id="cb21" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">它基于我在另一篇文章中介绍的自动编码器。</p><div class="ol om gq gs on oo"><a rel="noopener follow" target="_blank" href="/introduction-to-autoencoders-b6fc3141f072"><div class="op ab fp"><div class="oq ab or cl cj os"><h2 class="bd je gz z fq ot fs ft ou fv fx jd bi translated">自动编码器简介</h2><div class="ov l"><h3 class="bd b gz z fq ot fs ft ou fv fx dk translated">如何使用Tensorflow简化您的数据</h3></div><div class="ow l"><p class="bd b dl z fq ot fs ft ou fv fx dk translated">towardsdatascience.com</p></div></div><div class="ox l"><div class="oy l oz pa pb ox pc lc oo"/></div></div></a></div><p id="4af5" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">提醒:一个好的自动编码器应该能够将数据压缩(编码)成更少的维度，然后再次解压缩(解码)，而不会引入很多错误。</strong></p><p id="5ccc" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以利用这种直觉得出以下逻辑，用自动编码器找出异常值:</p><blockquote class="pd"><p id="bc2f" class="pe pf iu bd pg ph pi pj pk pl pm me dk translated">如果自动编码器为某些数据点引入了较大的误差，则该数据点可能是异常值。</p></blockquote><p id="8429" class="pw-post-body-paragraph lj lk iu ll b lm pn ke lo lp po kh lr ls pp lu lv lw pq ly lz ma pr mc md me in bi translated">更直观地说:自动编码器试图为给定的数据集学习好的编码。由于数据集中的大多数数据点都不是异常值，自动编码器将受<em class="mf">正常</em>数据点的影响最大，并且应该在这些数据点上表现良好。</p><p id="fdb6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">离群值是autoencoder在训练过程中不常看到的，因此它可能很难为它们找到一个好的编码。很简单，对吧？让我们试试这个主意吧！</p><h1 id="ab10" class="nz mi iu bd mj oa ob oc mm od oe of mp kj og kk ms km oh kn mv kp oi kq my oj bi translated">Tensorflow自动编码器的简单示例</h1><p id="6c83" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">下面，我们将看一个简单的例子，它将帮助您理解和实现上述逻辑。</p><h2 id="cdde" class="mh mi iu bd mj mk ml dn mm mn mo dp mp ls mq mr ms lw mt mu mv ma mw mx my ja bi translated">给圆圈编码</h2><p id="649b" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">让我们将带有圆圈的介绍性示例编写成代码。首先，让我们创建一个数据集。</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="53ff" class="px mi iu pt b be py pz l qa qb">import tensorflow as tf<br/><br/>tf.random.set_seed(1234)<br/><br/>t = tf.expand_dims(tf.linspace(0., 2*3.14, 1000), -1)<br/>noise = tf.random.normal((1000, 2), stddev=0.05)<br/>points = tf.concat([tf.cos(t), tf.sin(t)], axis=1) + noise</span></pre><p id="e918" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">绘制该图应该如下所示:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj qc"><img src="../Images/7a1776bd2ba64c665d08bd2b3fe70f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*dAprsqFOjkmvZufbksKDhg.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="6519" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在让我们添加一些异常值。</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="3d6f" class="px mi iu pt b be py pz l qa qb">points_with_outliers = tf.concat(<br/>    [<br/>        points,<br/>        tf.constant([[0., 0.], [2., 2.]]) # the outliers<br/>    ],<br/>    axis=0)</span></pre><p id="c509" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">结果是:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj qd"><img src="../Images/2a8aec04612080e9ed067c52322d3ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*Ujq8DZB3bKZ4BTKieaqheg.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="c101" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">现在，我们准备定义和训练一个简单的自动编码器，将二维数据压缩成一维数据。</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="5f16" class="px mi iu pt b be py pz l qa qb">shuffled_points = tf.random.shuffle(points)<br/><br/>encoder = tf.keras.Sequential([<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(1) # one-dimensional output<br/>])<br/><br/>decoder = tf.keras.Sequential([<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(16, activation="relu"),<br/>    tf.keras.layers.Dense(2) # decode to two dimensions again<br/>])<br/><br/>autoencoder = tf.keras.Sequential([<br/>    encoder,<br/>    decoder<br/>])<br/><br/>autoencoder.compile(loss="mse")<br/><br/>autoencoder.fit(<br/>    x=shuffled_points, # goal is that output is <br/>    y=shuffled_points, # close to the same input<br/>    validation_split=0.2, # to check if the model is generalizing<br/>    epochs=500<br/>)<br/><br/># Output:<br/># [...]<br/># Epoch 500/500<br/># 25/25 [==============================] - 0s 2ms/step - loss:       # 0.0037 - val_loss: 0.0096</span></pre><p id="a78a" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们现在可以通过以下方式将我们的点放入自动编码器</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="bcc2" class="px mi iu pt b be py pz l qa qb">reconstructed_points = autoencoder(points_with_outliers)</span></pre><p id="8b81" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">看看重建是什么样的:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div class="gi gj qd"><img src="../Images/f62a8cbc0b3a931b3e73af7ef75b54ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*ZiP8eamoRfLr3uFheVFsgA.png"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="adca" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以看到，我们的自动编码器在识别潜在模式方面做得很好。我认为，这不是一个完美的圆，但也足够好了。</p><p id="e29f" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">顺便提一下，在这里我们可以看到，我们的自动编码器基本上是<strong class="ll je">学会了</strong> <strong class="ll je">将圆展开成一维线，然后再卷回来</strong>:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qe"><img src="../Images/e9ed1ba5dd7b28e01d7c9aae53ad52f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qIGeJZpacuRvPx51QTVDyA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="4bcf" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">此外，通过观察颜色，我们可以看到重建的点与它们的原始点非常接近。</p><h2 id="77dd" class="mh mi iu bd mj mk ml dn mm mn mo dp mp ls mq mr ms lw mt mu mv ma mw mx my ja bi translated">获取异常值</h2><p id="cb93" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">但是离群值会发生什么呢？现在，让我们将所有的点都放到模型中，并突出显示我们添加的两个异常值。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qf"><img src="../Images/90df3d0902f53a0a62234914fc53cc04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvNNh5-mFo8-Ks4GZHbXBw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="3d93" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">自动编码器也将两个异常值放在其学习的圆近似上，这意味着它们都移动了相当多，因为它们之前都远离该圆。让我们打印一些数字:</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="1bb0" class="px mi iu pt b be py pz l qa qb">import pandas as pd<br/><br/>reconstruction_errors = tf.reduce_sum(<br/>    (model(points_with_outliers) - points_with_outliers)**2,<br/>    axis=1<br/>) # MSE<br/><br/>pd.DataFrame({<br/>    "x": points_with_outliers[:, 0],<br/>    "y": points_with_outliers[:, 1],<br/>    "reconstruction_error": reconstruction_errors<br/>})</span></pre><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qg"><img src="../Images/7845985afde72caf58dd214910359fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O06k6e7t4PIZojATHAsgaw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="c0e4" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">即使没有太多的分析，我们已经可以看到正常的数据点有大约0.002的微小重建误差，而我们人工添加的异常值有大约1和4的误差。不错！</p><blockquote class="pd"><p id="3bba" class="pe pf iu bd pg ph pi pj pk pl pm me dk translated">但是，等等，我们只是再次查看一个表来找出异常值。我们不能自动化吗？</p></blockquote><p id="f50c" class="pw-post-body-paragraph lj lk iu ll b lm pn ke lo lp po kh lr ls pp lu lv lw pq ly lz ma pr mc md me in bi translated">好问题！是的，我们可以。从这里有几种方法可以处理。例如，我们可以说重建误差&gt;<em class="mf"/>+3<em class="mf"/>的所有点都是异常值，其中<em class="mf"> </em>是所有重建误差的平均值，<em class="mf"> σ </em>是标准偏差。</p><p id="6f08" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我们可以做的另一件事是说重建误差最高x%的数据点是异常值。在这种情况下，我们假设数据集的x%由异常值组成，也称为<em class="mf">污染因子</em>，您可以在隔离森林等其他几种异常值检测算法中找到。</p><h2 id="a60a" class="mh mi iu bd mj mk ml dn mm mn mo dp mp ls mq mr ms lw mt mu mv ma mw mx my ja bi translated">与Scikit-Learn异常检测器的比较</h2><p id="1bc7" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">我创建了一个快速和肮脏的scikit-learn兼容异常检测器，以便能够将这种方法与其他scikit-learn异常检测器进行比较，如这里的<a class="ae li" href="https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_anomaly_comparison.html" rel="noopener ugc nofollow" target="_blank">所示</a>。</p><pre class="kt ku kv kw gu ps pt pu bn pv pw bi"><span id="e7e7" class="px mi iu pt b be py pz l qa qb">from sklearn.base import BaseEstimator, OutlierMixin<br/>import numpy as np<br/><br/><br/>class AutoencoderOutlierDetector(BaseEstimator, OutlierMixin):<br/>    def __init__(self, keras_autoencoder, contamination):<br/>        self.keras_autoencoder = keras_autoencoder<br/>        self.contamination = contamination<br/><br/>    def fit(self, X, y=None):<br/>        self.cloned_model_ = tf.keras.models.clone_model(self.keras_autoencoder)<br/>        self.cloned_model_.compile(loss="mse")<br/><br/>        self.cloned_model_.fit(<br/>            x=X,<br/>            y=X,<br/>            epochs=1000,<br/>            verbose=0,<br/>            validation_split=0.2,<br/>            callbacks=[<br/>                tf.keras.callbacks.EarlyStopping(patience=10)<br/>            ]<br/>        )<br/><br/>        reconstruction_errors = tf.reduce_sum(<br/>            (self.cloned_model_(X) - X) ** 2,<br/>            axis=1<br/>        ).numpy()<br/><br/>        self.threshold_ = np.quantile(reconstruction_errors, 1 - self.contamination)<br/><br/>        return self<br/><br/>    def predict(self, X):<br/>        reconstruction_errors = tf.reduce_sum(<br/>            (self.cloned_model_(X) - X) ** 2,<br/>            axis=1<br/>        ).numpy()<br/><br/>        return 2 * (reconstruction_errors &lt; self.threshold_) - 1</span></pre><p id="6642" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">如果我们使用与圆形相同的自动编码器架构，我们会得到以下结果:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qh"><img src="../Images/e910ec6a70adbbe0b9553252bb328c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0f-BAMX09-QoKXezOrnEQA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="b84b" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这里我们看到了整个方法的一个缺点:<strong class="ll je">如果我们使用错误的神经网络架构，我们可能会以奇怪的形状结束</strong>。如果我们使用一个更简单的自动编码器，每个隐藏层有<strong class="ll je"> 2个单元，而不是之前的16个</strong>，我们得到:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj qh"><img src="../Images/e72544645b6c8e44d4886fc8893c6168.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nVdFZ-Chhyx9A9uMzv9EpQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">图片由作者提供。</p></figure><p id="653d" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我认为这稍微好一点，但还远远不够好。</p><blockquote class="pd"><p id="a2a4" class="pe pf iu bd pg ph pi pj pk pl pm me dk translated">给你的作业:找一个在这些小玩具数据集上表现不错的架构！</p></blockquote><h1 id="7631" class="nz mi iu bd mj oa ob oc mm od oe of mp kj qi kk ms km qj kn mv kp qk kq my oj bi translated">结论</h1><p id="73c3" class="pw-post-body-paragraph lj lk iu ll b lm mz ke lo lp na kh lr ls nb lu lv lw nc ly lz ma nd mc md me in bi translated">离群值有可能破坏分析和模型。因此，我们应该能够发现并处理它们。一种方法是使用自动编码器:一种机器学习模型——通常是神经网络——对数据进行编码，然后再次解码。如果编码/解码步骤对于一个数据点效果不好，这个点可能是一个异常值。</p><p id="5e19" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">这个基本的想法很简洁，但是你仍然需要考虑如何设计自动编码器。虽然这可能非常困难，但这是其他异常值检测模型无法做到的。隔离林和公司有一个固定的架构，只允许你调整一些超参数。有了自动编码器，你就自由了——不管有什么优点和缺点。</p></div><div class="ab cl ql qm hy qn" role="separator"><span class="qo bw bk qp qq qr"/><span class="qo bw bk qp qq qr"/><span class="qo bw bk qp qq"/></div><div class="in io ip iq ir"><p id="53a6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">我希望你今天学到了新的、有趣的、有用的东西。感谢阅读！</p><p id="3f07" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">作为最后一点，如果你</strong></p><ol class=""><li id="5b69" class="ne nf iu ll b lm ln lp lq ls ng lw nh ma ni me qs nk nl nm bi translated"><strong class="ll je">想支持我多写点机器学习和</strong></li><li id="4aac" class="ne nf iu ll b lm nn lp no ls np lw nq ma nr me qs nk nl nm bi translated"><strong class="ll je">无论如何都要计划获得一个中等订阅，</strong></li></ol><p id="ddf3" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><strong class="ll je">为什么不做</strong> <a class="ae li" href="https://dr-robert-kuebler.medium.com/membership" rel="noopener"> <strong class="ll je">通过这个环节</strong> </a> <strong class="ll je">？这将对我帮助很大！😊</strong></p><p id="ffa6" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated"><em class="mf">说白了，给你的价格不变，但大约一半的订阅费直接归我。</em></p><p id="9f53" class="pw-post-body-paragraph lj lk iu ll b lm ln ke lo lp lq kh lr ls lt lu lv lw lx ly lz ma mb mc md me in bi translated">非常感谢，如果你考虑支持我的话！</p><blockquote class="pd"><p id="1787" class="pe pf iu bd pg ph pi pj pk pl pm me dk translated"><em class="qt">如有问题，在</em><a class="ae li" href="https://www.linkedin.com/in/dr-robert-k%C3%BCbler-983859150/" rel="noopener ugc nofollow" target="_blank"><em class="qt">LinkedIn</em></a><em class="qt">上写我！</em></p></blockquote></div></div>    
</body>
</html>