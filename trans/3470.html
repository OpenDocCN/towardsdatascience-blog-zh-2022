<html>
<head>
<title>Model Selection and Hyperparameter Tuning on Amazon Kindle Book Reviews with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现亚马逊Kindle书评的模型选择和超参数调整</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/model-selection-and-hyperparameter-tuning-on-amazon-kindle-book-reviews-with-python-6d17ec46d318#2022-08-01">https://towardsdatascience.com/model-selection-and-hyperparameter-tuning-on-amazon-kindle-book-reviews-with-python-6d17ec46d318#2022-08-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fa2f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">基于模型选择和超参数优化的书评情感分析</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/76034460fdb852d3dfd17a0a2873d83a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1XjvHNSqzCOQy4Or"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Emil Widlund 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="5443" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="d0e9" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi mn translated">这篇文章旨在选择和部署最佳的机器学习模型，对亚马逊Kindle商店的书评数据集进行情感分析。</p><p id="a79f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在之前的一篇文章中，我们在一个<a class="ae ky" href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews" rel="noopener ugc nofollow" target="_blank"> IMDB </a>电影评论数据库上优化了一个支持向量机算法。虽然SVM是分类问题的一个很棒的算法，但它也是最好的选择吗？对于这个新项目，现在的目标是包含模型选择机制。</p><p id="9f6a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">通过管道化多个模型，我们可以从不同的方面比较它们，包括准确性和效率。</p><h1 id="104b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">数据</h1><p id="ac95" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">你可以在下面的<a class="ae ky" href="https://www.kaggle.com/datasets/bharadwaj6/kindle-reviews" rel="noopener ugc nofollow" target="_blank">链接</a>中找到这个数据集，它由大约1，000，000篇书评组成[1][6]。目标是通过对数据集的一部分进行训练，产生一个高性能的情感分析器。如果你想复习什么是情绪分析，我可以建议快速阅读<a class="ae ky" href="https://giovanni-valdata.medium.com/what-is-sentiment-analysis-and-what-are-the-top-two-tools-to-perform-it-in-python-da21e0c3cd3" rel="noopener">这篇文章</a>，它涵盖了所有的基础知识。</p><p id="4b62" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">csv文件的结构包括10列:</p><ul class=""><li id="3ed9" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">asin</code> -产品的ID，如B000FA64PK</li><li id="df0f" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">helpful</code> -评价的有用性等级-例如:2/3。</li><li id="dbe0" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">overall</code> -对产品的评级。</li><li id="f0e2" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">reviewText</code> -审查文本(标题)。</li><li id="62de" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">reviewTime</code> -审查时间(未加工)。</li><li id="3154" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">reviewerID</code> -审核人的ID，如A3SPTOKDG7WBLN</li><li id="2909" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">reviewerName</code> -审核人的姓名。</li><li id="d524" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">summary</code> -评审总结(描述)。</li><li id="4b3c" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><code class="fe nk nl nm nn b">unixReviewTime</code> - UNIX时间戳。</li></ul><p id="2f09" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">对于该算法，我们只需要两个:评论语料库及其评级。</p><p id="ddea" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">以下是一个示例评论:</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="cd91" class="nx la it nn b gy ny nz l oa ob">I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual. Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today. Still it was a good read for me.</span></pre><p id="a6a1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">正如您所注意到的，该文本呈现出很少的“特殊”字符，这使得它更容易清理。最重要的是，我们应该删除所有不增加价值的介词和代词，因为它们太复杂了。</p><h1 id="569a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">文本处理</h1><p id="13e4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">尽管文本预处理不是本文的重点，我还是要简单解释一下，如果你想了解更多细节，请点击下面的链接，链接到我以前的文章之一。</p><p id="e32c" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在自然语言处理领域，文本包含各种各样对ML算法没有用的符号和单词。因此有一个阶段，称为文本处理，指的是文本的分析、处理和生成[2]。</p><p id="946d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">这使得ML模型更容易训练，因为它减少了“噪声”，即对于预测无用的信息量。</p><h1 id="cc0f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">模型</h1><p id="6fe7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">对于这个特殊的分类问题，我考虑了7种流行的高性能机器学习算法。每种方法都有其独特之处，很可能会返回与其他方法不同的结果:</p><ul class=""><li id="f7d7" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu">线性判别分析(LDA) </strong>关注组间方差的最小化以及组间方差的最大化。换句话说，该算法跟踪保证最大类别可分性的超平面(帮助分类数据点的决策边界)。</li><li id="d315" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><strong class="lt iu"> k个最近邻居(kNN) </strong>创建多个<em class="oc"> k个</em>最近邻居的数据记录<em class="oc"> t </em>的“邻域”。然后，多数表决机制决定该记录<em class="oc"> t </em>是否属于该类。该方法不考虑基于距离的加权。</li><li id="277d" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><a class="ae ky" href="https://medium.com/mlearning-ai/a-bow-vs-a-tfidf-feature-extractor-a-practical-application-on-a-na%C3%AFve-bayes-classifier-in-python-a68e8fb2248c" rel="noopener"> <strong class="lt iu">高斯朴素贝叶斯</strong> </a> <strong class="lt iu"> </strong>是一种概率分类器。简单和高效是它最显著的特点。贝叶斯定理是分类器的基础。它计算一个记录属于某个类别的概率[3]。</li><li id="62b0" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">利用给定的独立变量数据集，<strong class="lt iu">逻辑回归</strong>计算事件发生的概率。为此，首先使用一个函数计算赔率，该函数返回一个介于0和1之间的数字，其中0表示不太可能发生。最后，应用logit变换将结果精确分类为0或1。</li><li id="c449" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><strong class="lt iu">决策树分类器(CART) </strong>是一种通过“询问”一系列问题来分离数据的模型，因此决定将一个新记录放在哪个桶中。这会创建一个树形图，其中每个节点代表一个问题，每个叶子代表一个用于预测的输出变量。</li><li id="451a" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/sentiment-analysis-on-a-imdb-movie-review-dataset-with-a-support-vector-machines-model-in-python-50c1d487327e"><strong class="lt iu">【SVM】</strong></a><strong class="lt iu"/>支持向量机是非概率分类器。与LDA类似，SVM采用了超平面的概念。假设两个类是线性可分的，它们可以被超平面所除。在此基础上，该算法旨在通过在称为“向量”的超平面上的两条线来最大化类别1和类别2之间的空间。</li></ul><h2 id="b386" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">超参数</h2><p id="4b28" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在定义超参数之前，定义一个“标准”参数很重要。当一个模型收敛时，我们可以说它找到了描述它所训练的数据的一般行为的最佳参数组合。</p><p id="407a" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">每个机器学习模型都有一个隐喻性的架构。超参数让用户有机会使用实验方法找到模型“结构”的最佳配置。假设有5个超参数，每个超参数有10种可能的设置，当专业人员尝试各种设置组合直到性能达到峰值时，就会发生“调整”。例如，超参数1可能等于5，超参数2可能等于0.2，依此类推。</p><p id="8143" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">我想强调参数和超参数之间的根本区别。前者也意味着系数或权重，这是学习过程的结果。后者由用户在训练前手动设置。</p><h1 id="2cd3" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">代码部署</h1><h2 id="2fdc" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">数据可视化</h2><p id="cdac" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码部署的第一部分侧重于数据探索和可视化。与文本评论相关的分数分布可以告诉我们有价值的信息。</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="9f08" class="nx la it nn b gy ny nz l oa ob"><strong class="nn iu">#Importing libraries</strong><br/>import matplotlib.pyplot as plt<br/>import pandas as pd</span><span id="a3e2" class="nx la it nn b gy oo nz l oa ob"><strong class="nn iu">#Reading Dataset</strong><br/>df = pd.read_csv('kindle_reviews.csv')</span><span id="aab7" class="nx la it nn b gy oo nz l oa ob"><strong class="nn iu">#Counting values within each review bucket</strong><br/>category_dist = df['overall'].value_counts()</span><span id="c0cf" class="nx la it nn b gy oo nz l oa ob"><strong class="nn iu">#Defining chart</strong><br/>plt.figure(figsize=(8,6))<br/>category_dist.plot(kind='bar')<br/>plt.grid()<br/>plt.xlabel("Scores", fontsize = 12)<br/>plt.ylabel("Number of Reviews by Rating", fontsize = 12)<br/>plt.title("Distribution of Reviews by Rating", fontsize = 15)</span><span id="c27d" class="nx la it nn b gy oo nz l oa ob"><strong class="nn iu">#Generating chart</strong><br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c01cd14e82c303e020455681d9e883c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRua6flrabHPoi8UlGHoUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">按评级列出的评论分布—按作者列出的图表</p></figure><p id="0944" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">绝大多数评论都集中在4星和5星之间，这通常是不好的。数据集是不平衡的，因此当我们训练它时，算法可能会有偏差。</p><p id="4521" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最重要的是，研究表明，与多类分类相比，二元分类总体上更准确[4]。由于我们要有更高的精度，我们需要将这个项目转化为一个二元分类问题。</p><p id="b5aa" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">进行改变的一种可能方式是将所有高于3分的评论视为“正面的”，而将所有低于3分(包括3分)的评论视为“负面的”。接下来的步骤是仅对数据集的一部分执行模型选择。</p><p id="abf2" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在将近1，000，000行上确定最佳模型可能会大幅增加处理时间，而不会增加任何越来越有价值的性能信息。</p><p id="df47" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在从原始数据集中选择50，000行并将检查分数分成两类后，最终结果应该如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/c447012d64f5213ae31de3c548078840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQhHlmaQamIQQRNeuib8dg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">仅分析50，000条记录的评论分布(按情感分类)——按作者分类的图表</p></figure><h2 id="8ec2" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">文本清理</h2><p id="1591" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码部署的第二部分侧重于文本清理。如前所述，句子中的单词越多，复杂度越高，但对准确性的贡献却微乎其微。</p><p id="f56f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">解决方案在于消除停用词。在英语中，<strong class="lt iu">、【the】、</strong>、<strong class="lt iu">、</strong>等都可以作为停用词。在文本挖掘中，停用词被定义为携带很少有用信息的不重要的词。</p><p id="cdc4" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最重要的是，单词需要统一，全部小写，特殊字符需要消除。如果我们在前面看到的例句上部署代码，结果类似如下:</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="fc75" class="nx la it nn b gy ny nz l oa ob">enjoy vintage books movies enjoyed reading book plot unusual think killing someone self defense leaving scene body without notifying police hitting someone jaw knock would wash today still good read</span></pre><p id="3901" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">你会同意我的观点，现在消极和积极的词更容易识别，例如，“享受”，“享受”和“好”标志着潜在的积极评价。检查后，评论家给这本书打了5颗星。在项目结束时，我们的模型应该将此归类为“积极”。</p><p id="a8e8" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">最后一步是增加负面评论的数量，直到它们达到相同数量的正面评论。“上采样”人工生成少数类的数据点，并将它们添加到数据集中。该过程旨在使两个标签具有相同的计数，并防止模型偏向多数类。</p><h2 id="39b8" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">型号选择</h2><p id="e237" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码部署的第三部分侧重于为我们的数据选择性能最佳的模型。</p><ul class=""><li id="b890" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated"><strong class="lt iu"> <em class="oc"> Scikit-learn </em> </strong>和<strong class="lt iu"> <em class="oc"> matplotlib </em> </strong>是唯一需要的两个库。Sklearn包括对数据执行机器学习所需的所有功能。每个模型需要分配一个“子库”:逻辑回归、KNeighborsClassifier、决策树分类器、SVC、GaussianNB和线性判别分析。</li><li id="08e5" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">在上一节中，我们使用了一种称为“上采样”的技术来匹配负面书评和正面书评的数量。在这个阶段，我们可以从数据中定义输入和目标变量。输入变量<strong class="lt iu"> <em class="oc"> x </em> </strong>为“<strong class="lt iu"> <em class="oc"> reviewText </em> </strong>”，包含评论的语料库；输出变量<strong class="lt iu"> <em class="oc"> y </em> </strong>为“<strong class="lt iu"><em class="oc"/></strong>”，包含标签“<strong class="lt iu"> <em class="oc">正</em> </strong>”和“<strong class="lt iu"> <em class="oc">负</em> </strong>”。</li><li id="1aae" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">我们知道，一些用于分析的模型，包括决策树分类器，需要一个密集的矩阵。密集矩阵大多包含非零值。密集转换器类确保所有矩阵都是密集的，以避免任何错误。</li><li id="85c1" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">然后创建一个名为“模型”的列表，然后将分配给每个模型的对象添加到列表中。另一方面，列表“结果”将包含与其名称相关联的所有不同的模型分数。</li><li id="b4b3" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">kfold参数表示我们需要多少k倍。这引入了交叉验证的概念。交叉验证旨在更好地估计模型的准确性。它被定义为k重交叉验证，k是数据被划分的子组数。该模型在一个子组上训练，并在剩余的k-1上测试。准确度是根据平均分计算的。</li><li id="fc6e" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">管道在k-fold of choice上应用计数矢量器、密集转换器和选择模型，并执行交叉验证。然后它在控制台上打印结果。</li><li id="171d" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">matplotlib最后生成一个箱线图，这样我们就可以更好地解释结果。</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为我们的数据寻找性能最佳的模型</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/0d84935e7b42a5ef28869fb6c5da08ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*19c6kTkdLCjl9KaF7x-cwg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型选择过程后算法的准确性比较—作者提供的图表</p></figure><p id="1656" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">箱线图为您提供了关于我们的模型在精确度方面的五个临界值的信息:最小值、第一个四分位数(25%)、中值(第二个四分位数)、第三个四分位数(75%)和最大值。</p><p id="195d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在x轴上，有所有用于交叉验证分析的模型。相反，在y轴上，我们有准确度分数。例如，逻辑回归模型是表现最好的模型，其最小精度为0.82，最大精度为0.86，但是支持向量机保证了最一致的性能，其最小值和最大值彼此接近。KNN是表现最差的，表现出很少的一致性。LDA、CART和朴素贝叶斯也表现不佳。</p><p id="610d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">由于上述原因，超参数优化现在将集中在两个性能最高的模型上:逻辑回归和支持向量机。</p><h2 id="fb5c" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">支持向量机超参数调整</h2><p id="3339" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码部署的第四部分关注支持向量机模型的超参数调整:</p><ul class=""><li id="214b" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated">在前一个代码单元中已经导入了库，但是我决定重新导入它们以使这个代码片段独立</li><li id="a0c8" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">这次的流水线只包括计数矢量器和支持向量机模型，不需要密集转换器</li><li id="5d6a" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">转到参数列表，这些参数包含grid_search将为管道的每个组件尝试的所有可能的超参数组合。例如，计数矢量器的参数<em class="oc"> max_df </em>负责模型的泛化。Max_df删除出现太频繁的单词，max_df为0.7会忽略出现在70%以上文档中的术语。在一个场景中，“<em class="oc"> vect__max_df </em>”将使用内核<em class="oc"> poly </em>和C参数10，将0.7的<em class="oc"> max_df </em>与(1，1)的<em class="oc"> ngram_range </em>组合起来。因为每个交叉验证进行了5次，所以总“适合”(组合)是405。</li><li id="7f45" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">在启动<em class="oc"> grid_search.fit </em>之后，最后一部分代码开始在控制台上打印计算结果</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为计数矢量器和SVM模型寻找最佳参数</p></figure><p id="88e9" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">结果如下:</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="7943" class="nx la it nn b gy ny nz l oa ob">Best: 0.840734 using {'SVM__C': 10, 'SVM__kernel': 'rbf', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 2)} </span><span id="f55e" class="nx la it nn b gy oo nz l oa ob">0.730129 (0.038366) with: {'SVM__C': 10, 'SVM__kernel': 'poly', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 1)} </span><span id="6b4f" class="nx la it nn b gy oo nz l oa ob">0.692791 (0.049500) with: {'SVM__C': 10, 'SVM__kernel': 'poly', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 2)}</span></pre><p id="372f" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">性能最佳的超参数设置是:</p><ul class=""><li id="7af7" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated">C = 10</li><li id="2e2e" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">核类型= rbf</li><li id="cb95" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">max_df = 0.7</li><li id="656a" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">ngram_range = (1，1)</li></ul><p id="97a6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">如果我们对90，000个向上采样的行应用上面找到的具有优化的超参数的管道，并且我们计算精确度方面的性能，结果是相当惊人的。针对kindle评论优化的支持向量机模型在分类新数据方面的效率为99%。大约<strong class="lt iu"> 1小时</strong>的处理时间后显示结果。</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="8fde" class="nx la it nn b gy ny nz l oa ob">              precision    recall  f1-score   support      </span><span id="32d9" class="nx la it nn b gy oo nz l oa ob">    Negative       0.98      1.00      0.99      8924     <br/>    Positive       1.00      0.98      0.99      9109      </span><span id="a697" class="nx la it nn b gy oo nz l oa ob">    accuracy                           0.99     18033    <br/>   macro avg       0.99      0.99      0.99     18033 <br/>weighted avg       0.99      0.99      0.99     18033</span></pre><h2 id="1a82" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">逻辑回归超参数调整</h2><p id="ddb1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码部署的第五部分关注逻辑回归算法的超参数优化。所有代码都与上一节极其相似，只有很少的重要区别。</p><p id="a3bd" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">逻辑回归模型需要一个参数来表示它可以达到的最大迭代次数，没有这个参数，模型就不会收敛。最重要的是，与SVM模型相比，求解器的类型发生了变化。考虑用于分析的解算器是“牛顿-cg”、“lbfgs”和“liblinear”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oq or l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为计数向量机和逻辑回归模型寻找最佳参数</p></figure><p id="fc17" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">结果如下:</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="ca43" class="nx la it nn b gy ny nz l oa ob">Best: 0.857362 using {'LR__C': 1.0, 'LR__solver': 'newton-cg', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 3)}<br/> <br/>0.825643 (0.003937) with: {'LR__C': 100, 'LR__solver': 'newton-cg', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 1)} </span><span id="6ee8" class="nx la it nn b gy oo nz l oa ob">0.852704 (0.004520) with: {'LR__C': 100, 'LR__solver': 'newton-cg', 'vect__max_df': 0.7, 'vect__ngram_range': (1, 2)}</span></pre><p id="40ff" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">性能最佳的超参数有:</p><ul class=""><li id="b31a" class="nb nc it lt b lu mw lx mx ma nd me ne mi nf mm ng nh ni nj bi translated">C = 1</li><li id="f646" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">求解器=牛顿-重心</li><li id="6e25" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">max_df = 0.7</li><li id="2f32" class="nb nc it lt b lu no lx np ma nq me nr mi ns mm ng nh ni nj bi translated">ngram_range = (1，3)</li></ul><p id="c9d1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">同样，如果我们对90，000个向上采样的行应用具有优化超参数的逻辑回归模型，结果非常接近SVM模型。在任何与机器学习相关的场景中，都很难达到98%的准确率。这次的处理时间大致是<strong class="lt iu"> 3分钟</strong>。</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="6a27" class="nx la it nn b gy ny nz l oa ob">              precision    recall  f1-score   support<br/>      <br/>    Negative       0.97      1.00      0.98      8924     <br/>    Positive       1.00      0.96      0.98      9109</span><span id="fccb" class="nx la it nn b gy oo nz l oa ob">    accuracy                           0.98     18033    <br/>   macro avg       0.98      0.98      0.98     18033 <br/>weighted avg       0.98      0.98      0.98     18033</span></pre><h2 id="33b1" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated">测试算法</h2><p id="fa85" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">SVM和逻辑回归在准确性方面都表现出色。如果我们只根据这个参数来选择算法，那么支持向量机模型将是最佳选择。然而，需要考虑的另一个重要方面是:处理时间。SVM模型在70，000行上训练需要一个小时，而逻辑回归只需要3分钟。当涉及到模型部署时，准确性之上的计算效率是基础。</p><p id="ec0d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">在这个阶段，需要进行最后的检查。“<em class="oc">测试</em>包含一个肯定句，而“<em class="oc">测试_ 1”</em>包含一个否定句。</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="59fe" class="nx la it nn b gy ny nz l oa ob">##Testing Algorithm on single sentences<br/>test = ['The book was really good, I could have not imagined a better ending']</span><span id="aa3f" class="nx la it nn b gy oo nz l oa ob">test_1 = ['The book was generally bad, the plot was boring and the characters were not original']</span><span id="34b4" class="nx la it nn b gy oo nz l oa ob">test = count_vect.transform(test).toarray()<br/>test_1 = count_vect.transform(test_1).toarray()</span><span id="da43" class="nx la it nn b gy oo nz l oa ob">#Printing prediction<br/>print(LR.predict(test))<br/>print(LR.predict(test_1))</span></pre><p id="97c6" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">下面的输出显示，经过训练的分类器正确地预测了一篇书评是正面的还是负面的。</p><pre class="kj kk kl km gt nt nn nu nv aw nw bi"><span id="0e03" class="nx la it nn b gy ny nz l oa ob">Output:</span><span id="c3f4" class="nx la it nn b gy oo nz l oa ob">['Positive'] <br/>['Negative']</span></pre><h2 id="e3d2" class="nx la it bd lb od oe dn lf of og dp lj ma oh oi ll me oj ok ln mi ol om lp on bi translated"><strong class="ak">结论</strong></h2><p id="c3ea" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">本文展示了模型选择和超参数调整如何显著提高精度，并提供了其他方面的全貌。我们从6个模型开始，4个被过滤掉了，剩下的两个有很好表现的模型中，只有一个有可能进入生产。多亏了来自亚马逊Kindle商店的非常结构化的数据，除了单独确定情绪之外，还会有如此多的未来项目。从人工智能开始，它可以在一本书出版前对其进行评论和评级，或者在书籍被添加到商店后立即了解哪些书会做得很好。尤其是机器学习，可能性是无穷无尽的。</p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="0c7d" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="oc">最后一点，如果您喜欢该内容，请考虑添加一个关注，以便在新文章发布时得到通知。如果你对这篇文章有什么要考虑的，写在评论里吧！我很想读读它们:)谢谢你的阅读！</em></p><p id="3056" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated"><em class="oc"> PS:如果你喜欢我写的东西，如果你能通过</em> <a class="ae ky" href="https://giovanni-valdata.medium.com/membership" rel="noopener"> <em class="oc">这个链接</em> </a> <em class="oc">订阅一个中等会员，那对我来说就是全世界。这是一种间接的支持我的方式，你会得到媒体文章提供的惊人价值！</em></p></div><div class="ab cl ot ou hx ov" role="separator"><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy oz"/><span class="ow bw bk ox oy"/></div><div class="im in io ip iq"><p id="6aa1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">参考</p><p id="9744" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[1]麦考利，J. (2018)。亚马逊评论数据。检索于2022年7月31日，来自Ucsd.edu网站:<a class="ae ky" href="http://jmcauley.ucsd.edu/data/amazon/" rel="noopener ugc nofollow" target="_blank">http://jmcauley.ucsd.edu/data/amazon/</a></p><p id="f817" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[2]阿佩尔，o .，奇克拉纳，f .，卡特，j .，&amp;藤田，H. (2016年5月19日)。句子级情感分析问题的混合方法。检索于2022年7月30日，来自ResearchGate网站:<a class="ae ky" href="https://www.researchgate.net/publication/303402645_A_Hybrid_Approach_to_the_Sentiment_Analysis_Problem_at_the_Sentence_Level" rel="noopener ugc nofollow" target="_blank">https://www . ResearchGate . net/publication/303402645 _ A _ Hybrid _ Approach _ to _ the _ opinion _ Analysis _ Problem _ at _ the _ Sentence _ Level</a></p><p id="7297" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[3] Raschka，s .，&amp; Mirjalili，V. (2014年)。<em class="oc">朴素贝叶斯和文本分类I导论和理论</em>。从https://arxiv.org/pdf/1410.5329.pdf<a class="ae ky" href="https://arxiv.org/pdf/1410.5329.pdf" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="b9b1" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[4]杰哈，a .，戴夫，m .，，马丹，S. (2019)。使用不同数据挖掘分类技术的二分类器和多分类器的比较。<em class="oc"> SSRN电子杂志</em>。<a class="ae ky" href="https://doi.org/10.2139/ssrn.3464211" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.2139/ssrn.3464211</a></p><p id="d7da" class="pw-post-body-paragraph lr ls it lt b lu mw ju lw lx mx jx lz ma my mc md me mz mg mh mi na mk ml mm im bi translated">[5]何，r .，&amp;麦考利，j .(未注明)。<em class="oc">沉浮:用一类协同过滤对流行趋势的视觉演变建模</em>。<a class="ae ky" href="https://doi.org/10.1145/2872427.2883037" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1145/2872427.2883037</a></p></div></div>    
</body>
</html>