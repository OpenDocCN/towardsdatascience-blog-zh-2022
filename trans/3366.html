<html>
<head>
<title>Implementing RepVGG in PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在PyTorch中实现RepVGG</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-repvgg-in-pytorch-fc8562be58f9#2022-07-26">https://towardsdatascience.com/implementing-repvgg-in-pytorch-fc8562be58f9#2022-07-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/90689a96fe7df3c0bafd821a9d8b7590.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WLD-4t57hZYyZyTukvRRWQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">Alberto Restifo 在<a class="ae jg" href="https://unsplash.com/photos/_RBcxo9AU-U?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="4987" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">让您的CNN速度快100倍以上</h2></div><p id="6d4c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你好。！今天我们将看看如何在PyTorch中实现RepVGG，这是在<a class="ae jg" href="https://arxiv.org/pdf/2101.03697.pdf" rel="noopener ugc nofollow" target="_blank"> RepVGG:让VGG风格的网络再次伟大</a>中提出的</p><p id="4c7e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里的代码是<a class="ae jg" href="https://github.com/FrancescoSaverioZuppichini/RepVgg" rel="noopener ugc nofollow" target="_blank">这里的</a>，这篇文章的互动版本可以从<a class="ae jg" href="https://github.com/FrancescoSaverioZuppichini/RepVgg/blob/main/README.ipynb" rel="noopener ugc nofollow" target="_blank">这里的</a>下载。</p><p id="5036" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们开始吧！</p><p id="e797" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该论文提出了一种新的架构，可以在训练后进行调整，使其在现代硬件上运行更快。我说的更快是指更快的照明速度，这个想法被苹果的手机型号所采用。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lu"><img src="../Images/8cedabb81664aaac8e113dcd49f27033.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1TDpJ08DyX4MQVjO.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图像由<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X" rel="noopener ugc nofollow" target="_blank">丁小寒</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">张翔宇</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+N" rel="noopener ugc nofollow" target="_blank">马宁宁</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J" rel="noopener ugc nofollow" target="_blank">韩</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+G" rel="noopener ugc nofollow" target="_blank">丁桂光</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" rel="noopener ugc nofollow" target="_blank">孙健</a></p></figure><h1 id="27dc" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">单分支与多分支模型</h1><p id="311c" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">许多最近的模型使用多分支，其中输入通过不同的层传递，然后以某种方式聚合(通常有加法)。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mw"><img src="../Images/ed27553ef837f4239651fb846cbc6aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*al79sjWHo-t74AAg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="0135" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这很棒，因为它使多分支模型成为众多较浅模型的隐式集合。更具体地说，<em class="mx">该模型可以解释为2^n模型的集合，因为每个模块将流量分成两条路径。</em></p><p id="42b2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不幸的是，多分支模型比单分支模型消耗更多的内存，速度也更慢。让我们创建一个经典的<code class="fe my mz na nb b">ResNetBlock</code>来看看为什么(查看我在PyTorch 中关于<a class="ae jg" rel="noopener" target="_blank" href="/residual-network-implementing-resnet-a7da63c7b278"> ResNet的文章)。</a></p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="8336" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">存储<code class="fe my mz na nb b">residual</code>双倍内存消耗。这也显示在论文的下图中</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ne"><img src="../Images/e2c033e6f89d03716d698e5ae5bc162d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b_h-uhu2uF15ldiM.png"/></div></div></figure><p id="2804" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作者注意到多分支结构仅在训练时有用。因此，如果我们有办法在测试时删除它，我们就可以提高建模速度和内存消耗。</p><h1 id="bcc0" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">从多分支到单分支</h1><p id="3579" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">考虑以下情况，您有两个由两个<code class="fe my mz na nb b">3x3</code>conv组成的分支</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="lv lw lx ly gt nf nb ng nh aw ni bi"><span id="e029" class="nj ma jj nb b gy nk nl l nm nn">torch.Size([1, 8, 5, 5])</span></pre><p id="bd2a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们可以创建一个conv，姑且称之为<code class="fe my mz na nb b">conv_fused</code>，这样<code class="fe my mz na nb b">conv_fused(x) = conv1(x) + conv2(x)</code>。很简单，我们只需将两个convs的<code class="fe my mz na nb b">weight</code> s和<code class="fe my mz na nb b">bias</code>相加即可！因此我们只需要运行一个<code class="fe my mz na nb b">conv</code>而不是两个。</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="0a12" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看它快了多少！</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><pre class="lv lw lx ly gt nf nb ng nh aw ni bi"><span id="a3b9" class="nj ma jj nb b gy nk nl l nm nn">conv1(x) + conv2(x) tooks 0.000421s<br/>conv_fused(x) tooks 0.000215s</span></pre><p id="2a6c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">几乎<code class="fe my mz na nb b">50%</code>更少(请记住，这是一个非常幼稚的基准，稍后我们会看到一个更好的)</p><h1 id="ec4c" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">融合Conv和BatchNorm</h1><p id="be70" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">在现代网络架构中，<code class="fe my mz na nb b">BatchNorm</code>被用作卷积块之后的正则化层。我们可能希望将它们融合在一起，因此创建一个conv，如<code class="fe my mz na nb b">conv_fused(x) = batchnorm(conv(x))</code>。这个想法是改变<code class="fe my mz na nb b">conv</code>的权重，以便结合<code class="fe my mz na nb b">BatchNorm</code>的移动和缩放。</p><p id="88dd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该文件解释如下:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi no"><img src="../Images/d44688d99b9a8436d047b040fd55a373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f9lGs66ZQSOefEEY.png"/></div></div></figure><p id="c68f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">代码如下:</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="3b02" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看它是否有效</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="f6fa" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，我们融合了一个<code class="fe my mz na nb b">Conv2d</code>和一个<code class="fe my mz na nb b">BatchNorm2d</code>图层。PyTorch也有一篇关于这个的<a class="ae jg" href="https://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html" rel="noopener ugc nofollow" target="_blank">文章</a></p><p id="17d1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们的目标是将所有分支融合在一个conv中，使网络更快！</p><p id="2946" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作者提出了一种新型砌块，称为<code class="fe my mz na nb b">RepVGG</code>。与ResNet类似，它有一个快捷方式，但它也有一个身份连接(或更好的分支)。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi np"><img src="../Images/0b84f28573ee3be685677c562ff3b9fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AohCMx0uU64QiJ9b.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图像由<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X" rel="noopener ugc nofollow" target="_blank">丁小寒</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">、</a><a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+N" rel="noopener ugc nofollow" target="_blank">、</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J" rel="noopener ugc nofollow" target="_blank">韩</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+G" rel="noopener ugc nofollow" target="_blank">丁桂光</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" rel="noopener ugc nofollow" target="_blank">孙健</a>组成</p></figure><p id="dd5b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在PyTorch:</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h2 id="b00a" class="nj ma jj bd mb nq nr dn mf ns nt dp mj lh nu nv ml ll nw nx mn lp ny nz mp oa bi translated">重新参数化</h2><p id="c491" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">我们有一个<code class="fe my mz na nb b">3x3</code> <code class="fe my mz na nb b">conv-&gt;bn</code>，一个<code class="fe my mz na nb b">1x1</code> <code class="fe my mz na nb b">conv-bn</code>(有时)一个<code class="fe my mz na nb b">batchnorm</code>(身份分支)。我们希望将它们融合在一起，创建一个单一的<code class="fe my mz na nb b">conv_fused</code>，这样<code class="fe my mz na nb b">conv_fused</code> = <code class="fe my mz na nb b">3x3conv-bn(x) + 1x1conv-bn(x) + bn(x)</code>，或者如果我们没有身份连接，则<code class="fe my mz na nb b">conv_fused</code> = <code class="fe my mz na nb b">3x3conv-bn(x) + 1x1conv-bn(x)</code>。</p><p id="3280" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们一步一步来。要创建<code class="fe my mz na nb b">conv_fused</code>,我们必须:</p><ul class=""><li id="b0ef" class="ob oc jj la b lb lc le lf lh od ll oe lp of lt og oh oi oj bi translated">将<code class="fe my mz na nb b">3x3conv-bn(x)</code>融合成一个<code class="fe my mz na nb b">3x3conv</code></li><li id="bdaf" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated"><code class="fe my mz na nb b">1x1conv-bn(x)</code>，然后将其转换为<code class="fe my mz na nb b">3x3conv</code></li><li id="f84e" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated">将身份<code class="fe my mz na nb b">bn</code>转换为<code class="fe my mz na nb b">3x3conv</code></li><li id="0411" class="ob oc jj la b lb ok le ol lh om ll on lp oo lt og oh oi oj bi translated">将所有三个<code class="fe my mz na nb b">3x3conv</code>相加</li></ul><p id="b30f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">由下图总结:</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/5064a316323e5106ec4b094da076663f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1CX6dheEjqhEY8Qa.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">图像由<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+X" rel="noopener ugc nofollow" target="_blank">肖汉鼎</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+X" rel="noopener ugc nofollow" target="_blank">张翔宇</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ma%2C+N" rel="noopener ugc nofollow" target="_blank">马宁宁</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Han%2C+J" rel="noopener ugc nofollow" target="_blank">韩</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ding%2C+G" rel="noopener ugc nofollow" target="_blank">桂广鼎</a>、<a class="ae jg" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" rel="noopener ugc nofollow" target="_blank">孙健</a>组成</p></figure><p id="cfbf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第一步很简单，我们可以在<code class="fe my mz na nb b">RepVGGBlock.block</code>(主<code class="fe my mz na nb b">3x3 conv-bn</code>)上使用<code class="fe my mz na nb b">get_fused_bn_to_conv_state_dict</code>。</p><p id="7fec" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二步类似，<code class="fe my mz na nb b">get_fused_bn_to_conv_state_dict</code>上<code class="fe my mz na nb b">RepVGGBlock.shortcut</code>(下<code class="fe my mz na nb b">1x1 conv-bn</code>)。然后我们在每个维度上用<code class="fe my mz na nb b">1</code>填充融合的<code class="fe my mz na nb b">1x1</code>的每个内核，创建一个<code class="fe my mz na nb b">3x3</code>。</p><p id="b487" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">身份<code class="fe my mz na nb b">bn</code>更加棘手。我们需要创建一个<code class="fe my mz na nb b">3x3</code> <code class="fe my mz na nb b">conv</code>作为身份函数，然后使用<code class="fe my mz na nb b">get_fused_bn_to_conv_state_dict</code>将其与身份<code class="fe my mz na nb b">bn</code>融合。这可以通过使<code class="fe my mz na nb b">1</code>位于对应通道的对应内核的中心来实现。</p><p id="10b5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回想一下，conv的重量是一个张量<code class="fe my mz na nb b">in_channels, out_channels, kernel_h, kernel_w</code>。如果我们想要创建一个身份conv，比如<code class="fe my mz na nb b">conv(x) = x</code>，我们需要为该通道创建一个单独的<code class="fe my mz na nb b">1</code>。</p><p id="c0ca" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如:</p><p id="89fe" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae jg" href="https://gist.github.com/c499d53431d243e9fc811f394f95aa05" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/c499d53431d243e9fc811f394f95aa05</a></p><pre class="lv lw lx ly gt nf nb ng nh aw ni bi"><span id="79eb" class="nj ma jj nb b gy nk nl l nm nn">torch.Size([2, 2, 3, 3])<br/>Parameter containing:<br/>tensor([[[[0., 0., 0.],<br/>          [0., 1., 0.],<br/>          [0., 0., 0.]],</span><span id="fbf7" class="nj ma jj nb b gy oq nl l nm nn">         [[0., 0., 0.],<br/>          [0., 0., 0.],<br/>          [0., 0., 0.]]],<br/></span><span id="2459" class="nj ma jj nb b gy oq nl l nm nn">        [[[0., 0., 0.],<br/>          [0., 0., 0.],<br/>          [0., 0., 0.]],</span><span id="ecf4" class="nj ma jj nb b gy oq nl l nm nn">         [[0., 0., 0.],<br/>          [0., 1., 0.],<br/>          [0., 0., 0.]]]], requires_grad=True)</span></pre><p id="3528" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看，我们创建了一个<code class="fe my mz na nb b">Conv</code>，它的行为就像一个身份函数。</p><p id="a809" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，把所有东西放在一起，这一步正式称为重新参数化</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="f9b9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们来定义一个<code class="fe my mz na nb b">RepVGGFastBlock</code>。它只由一个<code class="fe my mz na nb b">conv + relu</code>组成</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="784f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">并在<code class="fe my mz na nb b">RepVGGBlock</code>中添加一个<code class="fe my mz na nb b">to_fast</code>方法来快速创建正确的<code class="fe my mz na nb b">RepVGGFastBlock</code></p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="eb8a" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">RepVGG</h1><p id="9ba4" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">让我们用一个方便的<code class="fe my mz na nb b">switch_to_fast</code>方法来定义<code class="fe my mz na nb b">RepVGGStage</code>(块集合)和<code class="fe my mz na nb b">RepVGG</code>，该方法将就地切换到快速块:</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><h1 id="c408" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">让我们来测试一下！</h1><p id="4f09" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">我在<code class="fe my mz na nb b">benchmark.py</code>中创建了一个基准测试，在我的gtx 1080ti上运行不同批量的模型，结果如下:</p><p id="8587" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">模型每级两层，四级，宽度<code class="fe my mz na nb b">64, 128, 256, 512</code>。</p><p id="df7d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在他们的论文中，他们将这些值缩放了一定的量(称为<code class="fe my mz na nb b">a</code>和<code class="fe my mz na nb b">b</code>)，并使用了分组转换。因为我们对重新参数化部分更感兴趣，所以我跳过它们。</p><figure class="lv lw lx ly gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi or"><img src="../Images/78f47168a59d2723e753f80c587a344b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kL2Fy7ATm8D-_VMo.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="f2bf" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">是的，所以基本上再参数化模型和普通模型相比，是在不同的时间尺度上。哇！</p><p id="e01d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我复制并粘贴我用来存储基准的数据帧</p><figure class="lv lw lx ly gt iv"><div class="bz fp l di"><div class="nc nd l"/></div></figure><p id="a5c3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以看到默认模型(多分支)对于一个<code class="fe my mz na nb b">batch_size=128</code>花费了<code class="fe my mz na nb b">1.45</code> s，而参数化模型(快速)只花费了<code class="fe my mz na nb b">0.0134</code> s，即108x🚀🚀🚀</p><p id="1de2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">.</p><h1 id="027c" class="lz ma jj bd mb mc md me mf mg mh mi mj kp mk kq ml ks mm kt mn kv mo kw mp mq bi translated">结论</h1><p id="ff99" class="pw-post-body-paragraph ky kz jj la b lb mr kk ld le ms kn lg lh mt lj lk ll mu ln lo lp mv lr ls lt im bi translated">结论在本文中，我们已经一步步地了解了如何创建RepVGG使用巧妙的重新参数化技术的超快的模型。</p><p id="3eff" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这项技术也可以移植到其他体系结构中。</p><p id="c469" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢您的阅读！</p><p id="7a41" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">👉<a class="ae jg" href="https://medium.com/p/8f4705e2ed0e" rel="noopener">在PyTorch中实现seg former</a></p><p id="d2bb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">👉<a class="ae jg" href="https://medium.com/p/7e37a67abba6" rel="noopener">在PyTorch中实现conv next</a></p><p id="b5c2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">弗朗西斯科</p></div></div>    
</body>
</html>