<html>
<head>
<title>Statistical Tests Won’t Help You to Compare Distributions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">统计测试不会帮助你比较分布</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/statistical-tests-wont-help-you-to-compare-distributions-d829eefe418#2022-04-08">https://towardsdatascience.com/statistical-tests-wont-help-you-to-compare-distributions-d829eefe418#2022-04-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a568" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">忘记p值，开始了解“标准化的Wasserstein距离”:一个实际有用的测量分布之间差异的方法。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8b2a3aa6584722efb4ac4b1d65b62220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LhKvc0kgBvpx20GQ55t6kw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[图片由作者提供]</p></figure><p id="778a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di"> O </span>数据世界中最常出现的问题之一，从<strong class="la iu">机器学习</strong>到<strong class="la iu">商业分析</strong>，从<strong class="la iu">金融</strong>到<strong class="la iu">医学研究</strong>是:</p><blockquote class="md"><p id="9f6c" class="me mf it bd mg mh mi mj mk ml mm lt dk translated">"这些变量在这些群体中有多大差异？"</p></blockquote><p id="82d6" class="pw-post-body-paragraph ky kz it la b lb mn ju ld le mo jx lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我打赌你以前去过那里。您有一个数据集和两组(或更多组)客户，比如来自美国的客户和来自德国的客户，并且您记录了一些变量，如年龄、购买频率和平均购买金额。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ms"><img src="../Images/09115e2ce0f9cbcf373922c045d07ea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DR4KaYQMH2gQsbzyzkcjIA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[图片由作者提供]</p></figure><p id="3725" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您想知道哪个变量更能区分美国客户和德国客户。或者，换句话说，<strong class="la iu">美国和德国客户之间哪个变量的差异更大</strong>。</p><p id="6fdf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要做到这一点，你需要<strong class="la iu">一种测量分布差异的方法</strong>，例如，德国客户的年龄与美国客户的年龄有多大差异，等等。</p><p id="2d6a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这项措施在许多领域都很有用:</p><ul class=""><li id="840e" class="mt mu it la b lb lc le lf lh mv ll mw lp mx lt my mz na nb bi translated"><strong class="la iu">机器学习</strong>。在预测分析中，确定哪些功能可能更具预测性非常有用。此外，它还有助于检测分布变化(也称为培训/服务偏差)。</li><li id="f179" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated"><strong class="la iu">聚类分析</strong>。它允许识别哪些特征将一个给定的聚类与群体的其余部分区分开来。</li><li id="e69a" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated"><strong class="la iu">数据/业务分析</strong>。它可以突出显示哪些变量在客户群体(或细分市场)之间更具鉴别力。</li></ul><h1 id="6df5" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">p值是不够的</h1><p id="e8e5" class="pw-post-body-paragraph ky kz it la b lb nz ju ld le oa jx lg lh ob lj lk ll oc ln lo lp od lr ls lt im bi translated">我见过的更常用于评估分布差异的方法来自统计学:</p><ul class=""><li id="01c9" class="mt mu it la b lb lc le lf lh mv ll mw lp mx lt my mz na nb bi translated"><strong class="la iu"> F检验(p值)</strong>，检验各组均数之间是否存在统计意义上的显著差异；</li><li id="0229" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated"><strong class="la iu"> Kolmogorov-Smirnov检验(p值)</strong>，检验各组的分布之间是否存在统计显著性差异。</li></ul><p id="5aee" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">原则上，人们喜欢使用p值的原因很明显。因为p值总是在0和1之间，所以它们很容易在不同变量之间进行比较。例如，如果变量“年龄”的p值为30%，而“购买频率”的p值为3%，那么购买频率在两组中明显有更大的差异。</p><blockquote class="oe of og"><p id="f595" class="ky kz oh la b lb lc ju ld le lf jx lg oi li lj lk oj lm ln lo ok lq lr ls lt im bi translated">请注意，在下文中，我将使用1减去p值来代替p值，p值可以粗略地解释为分布之间的差异显著的概率。</p></blockquote><p id="df86" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，<strong class="la iu">使用统计测试的p值很少是最佳选择</strong>。我举个例子解释一下。</p><p id="dc35" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面，我绘制了8个分布，每个分布由20个数据点组成，从最小值到最大值等距分布。蓝色组包含0到10之间的点，橙色组包含1到9之间的点，依此类推。</p><p id="6316" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在每组的旁边，我报告了关于分布本身和蓝色分布之间的差异的以下指标:</p><ul class=""><li id="aef2" class="mt mu it la b lb lc le lf lh mv ll mw lp mx lt my mz na nb bi translated">F: 1减去f检验的p值；</li><li id="eeaf" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">KS: 1减去Kolmogorov-Smirnov检验的p值；</li><li id="4bb5" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">SWD:标准化Wasserstein距离(即不是统计检验)；</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/72080c824222af361bef7101b61649d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SSWEKHyHK7JFzAGMo-_nFg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">20个数据点的不同均匀分布。第一列是1减去f检验的p值。第二列是1减去Kolmogorov-Smirnov检验的p值。第三列是按距离标准化的瓦瑟斯坦距离。[图片由作者提供]</p></figure><p id="4619" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">f给出的信息很差，因为它只确定两组的均值之间是否有显著差异。尽管如此，你可能认为KS的结果是可以接受的，因为它随着分布离蓝色分布“更远”而增加。</p><p id="c7de" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是如果我们用1000个数据点而不是20个数据点重复同样的过程会发生什么呢？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/db06dad37a9398c7bdbc05a3563207f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k_tT2upGmxQ2hRZYl157KQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">1000个数据点的不同均匀分布。第一列是1减去f检验的p值。第二列是1减去Kolmogorov-Smirnov检验的p值。第三列是按距离标准化的瓦瑟斯坦距离。[图片由作者提供]</p></figure><p id="33cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，KS现在毫无用处。事实上，区分不同的分布没有帮助:<strong class="la iu">1到9(橙色点)之间的均匀分布与10到13(灰色点)之间的均匀分布具有相同的p值</strong>。</p><p id="ddec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">相反，标准化的Wasserstein距离(SWD)做得很好，因为它给了我们一个关于每个分布与基准分布有多大不同的非常准确的想法。</p><p id="bec3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了理解什么是标准化的瓦瑟斯坦距离，我们先来看看瓦瑟斯坦距离计算背后的逻辑。</p><h1 id="415a" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">瓦瑟斯坦距离</h1><p id="a1c2" class="pw-post-body-paragraph ky kz it la b lb nz ju ld le oa jx lg lh ob lj lk ll oc ln lo lp od lr ls lt im bi translated">Wasserstein distance背后的想法简单得令人尴尬。</p><p id="0eb8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们有2个组，A组和B组，每组由3个人组成，他们的年龄都有记录。问题是:我们如何衡量A组和B组的年龄差异？</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/cae1fb15776eb014eaebc5fcc31b2525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nj6IiqKTCLj-jNb7S0zh4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">两组点。[图片由作者提供]</p></figure><p id="809f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">想象一下，按照年龄对两组进行排序，通过将A的第一个元素与B的第一个元素放在一起，将A的第二个元素与B的第二个元素放在一起，以此类推，来形成对。瓦瑟斯坦距离是B的每一点与A的对应点之间的<strong class="la iu">平均距离。</strong></p><p id="6a0c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">换句话说，瓦瑟斯坦距离回答了这个问题:</p><blockquote class="oe of og"><p id="a50b" class="ky kz oh la b lb lc ju ld le lf jx lg oi li lj lk oj lm ln lo ok lq lr ls lt im bi translated">平均来说，当<strong class="la iu">保持点的相对位置</strong>时，你应该移动一组中的每个点多少来得到另一组？</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/456e77aae2caeda54e353564578566b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K12JZ29uq4q-texa647DFw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有相同点数的两组之间的距离。[图片由作者提供]</p></figure><p id="1e5c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据这个定义，计算Wasserstein距离非常简单，我们还可以检查它是否给出了与Scipy的实现相同的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/eb944b54624048dbf9262ea44d2236f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fpEu_PqRyDoE90d5byPNXA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">当数组a和数组b具有相同的长度时，很容易再现Scipy的Wasserstein距离的相同输出。[图片由作者提供]</p></figure><p id="ac42" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，<strong class="la iu">这个定义只适用于具有相同数量</strong>的组。为了使这个概念更普遍，我们必须用累积分布的概念来扩展它。</p><p id="9595" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，在更一般的情况下，Wasserstein距离被计算为两组累积分布曲线之间的<strong class="la iu">面积</strong>。只有当两个累积分布完全重叠时，它才等于0，并且随着分布的远离，它可以是任意大的。</p><p id="6ded" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">注意，计算两个累积分布之间的面积非常简单，因为它总是矩形的和。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/ea855212fb9edc1d4f782e644633483f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JG-CVjiRCoJ4-6Ripb7JMg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">累积分布之间的Wasserstein距离。[图片由作者提供]</p></figure><p id="bed3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们可以调整我们先前的定义，说瓦瑟斯坦距离回答了这个问题:</p><blockquote class="oe of og"><p id="cd5c" class="ky kz oh la b lb lc ju ld le lf jx lg oi li lj lk oj lm ln lo ok lq lr ls lt im bi translated">平均来说，当<strong class="la iu">保持点数的分位数</strong>时，你应该将一组中的每个点数移动多少才能得到另一组？</p></blockquote><p id="8ffa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们还可以验证这个定义在我们的第一个例子中是否成立:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/91de6c1c09adc325728d9a573c0d857d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aSn3TPNEPXL4XpiR7XDOlg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">累积分布之间的Wasserstein距离。[图片由作者提供]</p></figure><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="a8a2" class="ow ni it os b gy ox oy l oz pa">swd = (43.3-40.5) * .33 + (44.7-46.3) * .33 + (51.8-47.8) * .33<br/>    = 2.8 * .33 + 1.6 * .33 + 4.0 * .33 <br/>    = 2.8</span></pre><p id="8929" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是我们最初发现的数字。</p><h1 id="446d" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">标准化瓦瑟斯坦距离</h1><p id="4487" class="pw-post-body-paragraph ky kz it la b lb nz ju ld le oa jx lg lh ob lj lk ll oc ln lo lp od lr ls lt im bi translated">从上一段可以清楚地看出，Wasserstein距离(作为平均距离计算)取决于要素的测量单位。这是一个问题，因为它不允许比较不同的特性。</p><p id="ad14" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了获得一个可比较的度量，我们应该在某些方面标准化瓦瑟斯坦距离。有许多选项可用，例如将其除以变量的范围(即最大值减去最小值)或除以四分位数范围(即第75个百分点减去第25个百分点)。</p><p id="1488" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，我更喜欢的是<strong class="la iu">将Wasserstein距离除以变量的标准差</strong>(即A组和B组总共的标准差)。我们终于有了我们一直在寻找的指标:</p><pre class="kj kk kl km gt or os ot ou aw ov bi"><span id="dd47" class="ow ni it os b gy ox oy l oz pa">import numpy as np<br/>from scipy.stats import wasserstein_distance</span><span id="1c87" class="ow ni it os b gy pb oy l oz pa">def <strong class="os iu">standardized_wasserstein_distance</strong>(a, b):<br/><strong class="os iu">  """a and b are numpy arrays."""<br/></strong>  numerator = wasserstein_distance(a, b)<br/>  denominator = np.std(np.concatenate([a, b]))<br/>  return numerator / denominator if denominator != .0 else .0</span></pre><p id="f11d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是标准化Wasserstein距离的一些有用属性:</p><ul class=""><li id="24a8" class="mt mu it la b lb lc le lf lh mv ll mw lp mx lt my mz na nb bi translated"><strong class="la iu">大于等于0 </strong>(其中0表示两个分布完全相同)；</li><li id="6d06" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated"><strong class="la iu">可能大于1</strong>；</li><li id="d134" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">不同变量之间具有可比性，因为<strong class="la iu">是一个纯数字</strong>；</li><li id="3085" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">可以解释为“<strong class="la iu">通过多少个标准差，平均下来，我们要移动一组的每一个点，才能得到另一组</strong>”。</li></ul><h1 id="60e7" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">在真实数据集上验证SWD</h1><p id="abd8" class="pw-post-body-paragraph ky kz it la b lb nz ju ld le oa jx lg lh ob lj lk ll oc ln lo lp od lr ls lt im bi translated">为了评估标准化的瓦瑟斯坦距离是否真的比其他指标更好，我在24个数据集上进行了测试(在Keras中可用，在<a class="ae pc" href="https://github.com/keras-team/keras/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> Apache许可</a>下，在<a class="ae pc" href="https://github.com/pycaret/pycaret" rel="noopener ugc nofollow" target="_blank"> Pycaret </a>中可用，在<a class="ae pc" href="https://github.com/pycaret/pycaret/blob/master/LICENSE" rel="noopener ugc nofollow" target="_blank"> MIT许可</a>下)。</p><p id="16dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个数据集都有一个离散的目标变量，我们将把它用作集群化的自然“基础事实”。下面，我报告了每个数据集的主要统计数据:目标变量中的类的数量、列(或特性)的数量以及行的数量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/e25bb83bad84397e24d47b37bc091403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBURBdurzMqhchzIKy_2YA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用于测试指标的24个数据集的主要统计数据。[图片由作者提供]</p></figure><p id="b586" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用目标变量作为分组变量，对于每个数据集的每一列，我计算了:</p><ul class=""><li id="c331" class="mt mu it la b lb lc le lf lh mv ll mw lp mx lt my mz na nb bi translated">f检验(1减去p值)；</li><li id="046e" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">Kolmogorov-Smirnov检验(1减去p值)；</li><li id="d50c" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">标准化瓦瑟斯坦距离(瓦瑟斯坦距离除以全分布的标准差)；</li><li id="fbdf" class="mt mu it la b lb nc le nd lh ne ll nf lp ng lt my mz na nb bi translated">特征重要性(在训练CatBoost分类器，然后提取列的重要性之后获得)。</li></ul><p id="3112" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是最终输出的一瞥(大约有7千行，每个数据集的每个要素一行):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/000647a0ec9bd87442a6c6344b8610e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0aWec8shTno0pJ7eP8EkHQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出表的5个随机行。[图片由作者提供]</p></figure><p id="4154" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">合理的预期是<strong class="la iu">具有高特征重要性的列必须具有正分布和负分布之间的高差异</strong>。</p><p id="8099" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，衡量指标的优劣的代表是衡量指标本身与CatBoost估计的特性重要性之间的<strong class="la iu">相关性</strong>。为此，我计算了F、KS、SWD和CatBoost的特性重要性之间的相关性。以下是24个数据集的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/2cd7248d8c40ce129696faf3ace052d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrkLCED-dgsgRavpHRvvjA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个数据集的F、KS、SWD和要素重要性之间的相关性。[图片由作者提供]</p></figure><p id="e2cc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">可以看出，<strong class="la iu"> SWD在大多数时候都优于其他指标</strong>。此外，通过取相关系数的平均值，我们可以得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/4cbc1cde8362ee0659d2b228dca5a82d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TXLD4fy83AczAXt6mcotnw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">所有数据集的F、KS、SWD和要素重要性之间的平均相关性。[图片由作者提供]</p></figure><p id="849c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">平均而言，SWD与CatBoost估计的特征重要性的相关性为62%,而KS p值仅为39 %, F p值仅为19%,从而证实了我们最初的猜测，即SWD是评估分布之间差异的更好的指标。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/29557ee849a8017cc1d6abd1e01258cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AGF_zXDfkRcqlhcq.png"/></div></div></figure><p id="d651" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以在下面的笔记本中找到我在本文中使用的全部代码:<a class="ae pc" href="https://github.com/smazzanti/standardized_wasserstein_distance/blob/main/swd.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/smazzanti/standardized _ wasser stein _ distance/blob/main/swd . ipynb</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ph"><img src="../Images/29557ee849a8017cc1d6abd1e01258cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AGF_zXDfkRcqlhcq.png"/></div></div></figure><p id="3f14" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="oh">感谢您的阅读！我希望你喜欢这篇文章。如果你愿意，</em> <a class="ae pc" href="https://www.linkedin.com/in/samuelemazzanti/" rel="noopener ugc nofollow" target="_blank"> <em class="oh">在Linkedin上加我</em> </a> <em class="oh">！</em></p></div></div>    
</body>
</html>