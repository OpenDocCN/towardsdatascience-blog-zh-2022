<html>
<head>
<title>How we optimized Python API server code 100x</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们如何优化Python API服务器代码100倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-we-optimized-python-api-server-code-100x-9da94aa883c5#2022-02-09">https://towardsdatascience.com/how-we-optimized-python-api-server-code-100x-9da94aa883c5#2022-02-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="443d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们用来加速调用用Python编写的分析API的一些技巧:用asyncio玩，用SQLAlchemy捣乱，深入研究asyncpg，用Cython重写部分，找到更好的数据结构，用pure numpy替换一些pandas。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/993d31a9411466184c012bfe336335e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YVLOeTvU7-VDrVFQTaVduA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">根据CC0许可的图像。鸣谢:最大像素贡献者。</p></figure><p id="3e92" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Python代码优化看起来容易或困难，取决于性能目标。如果目标是“尽最大努力”，仔细选择算法并应用众所周知的常见实践通常就足够了。如果目标是由UX决定的，有时你必须深入几个抽象层，侵入系统。或者重写底层库。或者换个语言，真的。</p><p id="c070" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这篇文章是关于我们在Python代码优化方面的经验，无论你做什么都不够快。我个人非常乐于接受挑战，并将API响应时间压缩在一秒钟之内。事实上，这太有趣了，我们已经为一系列博客帖子准备了足够的笔记。</p><p id="418d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我说的“我们”是指在雅典的<a class="ae lu" href="https://athenian.com" rel="noopener ugc nofollow" target="_blank">工作的工程师。雅典人提供了一个SaaS来帮助工程领导者建立一个持续改进的软件开发文化。为了从landing-pagish进行翻译，我们将GitHub和JIRA元数据镜像到我们自己的数据库，对其进行分析，并在SPA中显示指标和图表。暂时如此。当然，计划是征服世界。</a></p><h2 id="5e3a" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">那些淘气的花冠</h2><p id="fcee" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">API请求处理通常在两个极端之间平衡:CPU和IO等待。它们之间没有明确的界限；就像阴阳一样，它们以复杂的关系携手共舞。如果你分析一个请求，你会看到一堆杂乱的函数调用，这些调用会投射到CPU和IO占用轴上。让我们考虑这个简化的代码:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="706d" class="lv lw it mu b gy my mz l na nb">await asyncio.gather(query_sql_a(), query_sql_b(), query_sql_c())</span></pre><p id="b2f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们启动了三个从SQL DB请求数据的协同例程。雅典人使用PostgreSQL，那么让我们假设我们使用PostgreSQL。每个协程都经过三个阶段:</p><ol class=""><li id="0336" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt nh ni nj nk bi translated">(CPU)准备对PostgreSQL的请求并发送它。</li><li id="6504" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">(IO wait)等待PostgreSQL响应。</li><li id="9a73" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">(CPU)读取响应并将其转换为Python对象。</li></ol><p id="c8cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们假设(1)和(3)对于每个协程都用了一秒钟，PostgreSQL是无限强大的，总是需要5秒钟来计算<code class="fe nq nr ns mu b">query_sql_a</code>的响应，3秒钟计算<code class="fe nq nr ns mu b">query_sql_b</code>的响应，1秒钟计算<code class="fe nq nr ns mu b">query_sql_c</code>的响应。这并不意味着，例如<code class="fe nq nr ns mu b">query_sql_a</code>会一直在IO wait (2)中花费5秒，因为Python在每个时刻只能执行三个协程中的一个。</p><p id="24d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nq nr ns mu b">asyncio.gather</code>按照传递参数的顺序启动协程。这并没有写在<a class="ae lu" href="https://docs.python.org/3/library/asyncio-task.html#asyncio.gather" rel="noopener ugc nofollow" target="_blank">文档</a>中，必须是一个实现细节，但是考虑这一点很重要:我们将首先执行<code class="fe nq nr ns mu b">query_sql_a</code>的(1)，然后是<code class="fe nq nr ns mu b">query_sql_b</code>的(1)，然后是<code class="fe nq nr ns mu b">query_sql_c</code>的(1)，然后在PostgreSQL繁忙时等待一秒钟，然后以相反的顺序执行(3)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/c398011e092c1474f60727827be37062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwnTM49nsJsG-88zjaJIMA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">A、B、C协同程序的执行计划。CPU时间是86%，IO等待时间是14%。图片作者。</p></figure><p id="a94a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据执行计划，我们在CPU中遇到瓶颈:86%的操作系统线程时间CPU在做一些有用的工作。现在考虑启动协程的不同顺序:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="0140" class="lv lw it mu b gy my mz l na nb">await asyncio.gather(query_sql_c(), query_sql_b(), query_sql_a())</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/8dcba68bb052a08f36be1bd0bc35e140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K5k86dINAdpx5cIEVJkBQQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">C，B，A协同程序的执行计划。CPU时间是60%，IO等待时间是40%。图片作者。</p></figure><p id="c6dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二个执行计划演示了如果我们不猜测启动协程的最佳顺序，事情会变得多么糟糕。墙壁时间从7秒增加到10秒，增加了43%。我们不再有严重的CPU瓶颈(60%对86%)。<code class="fe nq nr ns mu b">query_sql_c</code>阶段3与<code class="fe nq nr ns mu b">query_sql_a</code>阶段1竞争，胜负取决于事件循环内部。</p><p id="338b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我在这里写的是Python代码优化，所以我不会讨论SQL性能和减少单个IO等待这样的突出问题。因此我的建议是</p><blockquote class="nv nw nx"><p id="c5db" class="ky kz ny la b lb lc ju ld le lf jx lg nz li lj lk oa lm ln lo ob lq lr ls lt im bi translated">尝试传递按预期IO等待时间降序排序的<code class="fe nq nr ns mu b">asyncio.gather()</code>中的协同程序。也就是说，第一个参数应该是具有最高预期IO等待的协程，依此类推。</p></blockquote><p id="d783" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">真实的例子:我们在代码中有一个地方放了10个协程。当我按照前面提到的启发式方法排序时，平均总执行时间减少了<strong class="la iu"> x2 </strong>。</p><p id="898b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设<code class="fe nq nr ns mu b">thread_gather</code>启动并加入线程而不是协程，对其参数排序有意义吗？当然不是。在我的例子中，启动线程比启动协程更快吗？实际上，考虑到GIL，协程的性能会更好:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/cb268ed540b8f24cdd907a36e310ec33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hoKqxHQxnqrzfSbncf5ihw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">A、B、C线程的执行计划。CPU时间是66%，IO等待时间是33%。图片作者。</p></figure><h2 id="eedd" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">在联盟中共享</h2><p id="f762" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我们的API使用SQLAlchemy核心来生成SQL(没有ORM)。<code class="fe nq nr ns mu b">WHERE</code>中有些条件重复的地方不少。一个例子是用<code class="fe nq nr ns mu b">UNION ALL</code>代替<code class="fe nq nr ns mu b">OR</code>;而不是</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6bd5" class="lv lw it mu b gy my mz l na nb">SELECT * FROM table WHERE ((a = 1 and b = 2) OR (a = 2 and b = 1)) AND c = 3</span></pre><p id="0285" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们写作</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="8337" class="lv lw it mu b gy my mz l na nb">(SELECT * FROM table WHERE a = 1 and b = 2 and c = 3)<br/>UNION ALL<br/>(SELECT * FROM table WHERE a = 2 and b = 1 and c = 3)</span></pre><p id="38d3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为什么在这种情况下<code class="fe nq nr ns mu b">UNION ALL</code>通常更好是另一篇博文的主题。让我们关注一下<code class="fe nq nr ns mu b">UNION ALL</code>在SQLAlchemy中的样子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9dca" class="lv lw it mu b gy my mz l na nb">union_all(select([table]).where(and_(a == 1, b == 2, c == 3)),<br/>          select([table]).where(and_(a == 2, b == 1, c == 3)))</span></pre><p id="8fa9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">想象有一个大的表达式代替了<code class="fe nq nr ns mu b">c = 3</code>，还有变量<code class="fe nq nr ns mu b">IN</code>，等等。—两次构建这样的对象是很昂贵的。相反，我们可以写:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="787a" class="lv lw it mu b gy my mz l na nb">shared_cond = c == 3<br/>union_all(select([table]).where(and_(a == 1, b == 2, shared_cond)),<br/>          select([table]).where(and_(a == 2, b == 1, shared_cond)))</span></pre><p id="fe22" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这并不适用于每一个SQLAlchemy引擎，尤其是SQLite，因为SQLAlchemy在那里生成<code class="fe nq nr ns mu b">?, ?, ?</code>作为参数占位符，而不是索引引用<code class="fe nq nr ns mu b">$1, $2, $3</code>。然而，随着从SQLAlchemy 1.3升级到1.4，他们改进了对大T4的处理，我们得到了1.5-2倍的SQL编译速度。</p><h2 id="6c27" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">从行到列</h2><p id="8124" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我们通过asyncpg查询PostgreSQL。asyncpg像几乎所有其他关系数据库驱动程序一样获取返回行。然而，我们的分析API需要构建列式的<code class="fe nq nr ns mu b">pd.DataFrame</code> -s:每个返回列的值存储在一起。此外，在pandas 2.0之前，相同dtype的几个列一起存储在同一个numpy数组(也称为块)中。</p><p id="62cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用<code class="fe nq nr ns mu b">DataFrame.from_records()</code>天真地构造DataFrame是非常低效的。假设PostgreSQL敲asyncpg的门。接下来是:</p><ol class=""><li id="4b92" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt nh ni nj nk bi translated">解析PostgreSQL网络协议并创建Python对象。</li><li id="40cf" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">将这些Python对象插入到创建的<code class="fe nq nr ns mu b">asyncpg.Record</code> -s中。</li><li id="3b15" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">迭代行并将Python对象插入dtype <code class="fe nq nr ns mu b">object</code>的numpy数组。</li><li id="a464" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">推断更好的数据类型(例如int、datetime等。)并将Python对象转换成它们。</li><li id="e84c" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">Consolidate — BlockManager是pandas 1.x的特别之处，它将相同数据类型的numpy数组合并在一起。</li></ol><p id="b2e8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">给定纯<code class="fe nq nr ns mu b">object</code>列(例如，带有SQL空值)，我们接触它们的引用计数器4次:在(1)、(3)、(4)和(5)中。<code class="fe nq nr ns mu b">asyncpg.Record</code>用作辅助容器，可以排除。此外，我们不必执行(4 ),因为我们已经从SQL查询中知道了正确的dtypes。因此，在现代x86 CPU上，从pgproto到ready DataFrame的端到端转换需要超过500毫秒，包含大约20个对象、大约20个类型化列和300，000行。</p><p id="7b42" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理想的管道是:</p><ol class=""><li id="6d90" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt nh ni nj nk bi translated">解析PostgreSQL wire协议，直接写入numpy数组，无需具体化严格类型的对象。</li><li id="acf0" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">构建没有冗余整合的块管理器。</li></ol><p id="9bcf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">纯<code class="fe nq nr ns mu b">object</code>值只会增加一次参考计数器。仅仅估计一下，整个过程就要过去大约5毫秒。然而，不幸的是，解析pgproto和构造<code class="fe nq nr ns mu b">asyncpg.Record</code> -s驻留在Cython甚至<code class="fe nq nr ns mu b">asyncpg</code>的C代码深处，所以制作理想的管道意味着分叉项目。我们肯定会在征服世界之前叉掉它，但同时必须找到一个折中的办法。</p><p id="2751" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们当前的折衷渠道:</p><ol class=""><li id="5ab0" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt nh ni nj nk bi translated">解析PostgreSQL网络协议并创建Python对象。</li><li id="e5bb" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">将这些Python对象插入到创建的<code class="fe nq nr ns mu b">asyncpg.Record</code> -s中。</li><li id="e29f" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">迭代行并将Python对象插入到两个dtype <code class="fe nq nr ns mu b">object</code>的numpy数组中——一个用于dtyped，一个用于<code class="fe nq nr ns mu b">object</code>列。</li><li id="3a6d" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">给定SQL查询中的先验知识，转换数据类型。</li><li id="5338" class="nc nd it la b lb nl le nm lh nn ll no lp np lt nh ni nj nk bi translated">构造块并将它们包装在块管理器中。</li></ol><p id="2166" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，纯<code class="fe nq nr ns mu b">object</code>值将refcounters递增两次:在(1)和(3)中。我们不再试图猜测类型。内存复制膨胀显著减少。我们的测量显示转换时间至少比<strong class="la iu">快10倍，约为50毫秒。</strong></p><p id="ed32" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际的源代码可以在我们的API所在的存储库中找到:<a class="ae lu" href="https://github.com/athenianco/athenian-api-open" rel="noopener ugc nofollow" target="_blank">雅典人/雅典人-api-open </a>。它不是通用的，也没有足够的意愿使它成为一个合适的开源库。请随意根据您的需求进行调整！我们在麻省理工学院的许可下分发这些文件。</p><p id="96a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">更新(2020年6月):</strong>我们通过使用<a class="ae lu" href="https://betterprogramming.pub/i-forked-asyncpg-and-it-parses-database-records-to-numpy-20x-faster-e71024a84bff" rel="noopener ugc nofollow" target="_blank"> asyncpg-rkt </a>达到了理想的流水线。</p><p id="ed49" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我通过给出一般性的建议来结束这一部分。</p><blockquote class="nv nw nx"><p id="8f02" class="ky kz ny la b lb lc ju ld le lf jx lg nz li lj lk oa lm ln lo ob lq lr ls lt im bi translated">尽可能避免pandas DataFrame-s中的<code class="fe nq nr ns mu b">object</code>列。使用它们的操作比使用正确类型的要慢得多。</p></blockquote><h2 id="2123" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">迭代没有GIL的元组列表</h2><p id="fceb" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">一个非常具体的目标:在原始的<code class="fe nq nr ns mu b">asyncpg.Record</code> -s上优化迭代。确实有可能在GIL发布后直接与他们合作。Cython代码如下:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2453" class="lv lw it mu b gy my mz l na nb">cdef extern from "asyncpg_recordobj.h":<br/>    PyObject *ApgRecord_GET_ITEM(PyObject *, int)</span><span id="8a3f" class="lv lw it mu b gy od mz l na nb">cdef extern from "Python.h":<br/>    # added nogil -&gt; from cpython cimport ...<br/>    # these are the macros that read from the internal ob_items<br/>    PyObject *PyList_GET_ITEM(PyObject *, Py_ssize_t) nogil</span><span id="d008" class="lv lw it mu b gy od mz l na nb">cdef nogil_iter(rows: list[asyncpg.Record]):<br/>    cdef:<br/>        Py_ssize_t i, size<br/>        PyObject *record<br/>        PyObject *value</span><span id="754b" class="lv lw it mu b gy od mz l na nb">    size = len(rows)<br/>    with nogil:<br/>        for i in range(size):<br/>            record = PyList_GET_ITEM(&lt;PyObject *&gt;rows, i)<br/>            value = ApgRecord_GET_ITEM(record, 0)</span></pre><p id="5b1b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nq nr ns mu b">asyncpg_recordobj.h</code>是asyncpg中真实<a class="ae lu" href="https://github.com/MagicStack/asyncpg/blob/master/asyncpg/protocol/record/recordobj.h" rel="noopener ugc nofollow" target="_blank"> recordobj.h </a>的简化:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3c1e" class="lv lw it mu b gy my mz l na nb">typedef struct {<br/>    PyObject_VAR_HEAD<br/><br/>    // asyncpg specifics begin here<br/>    // if they add another field, we will break spectacularly<br/>    Py_hash_t self_hash;<br/>    PyObject *desc;  // we don't care of the actual type<br/>    PyObject *ob_item[1];  // embedded in the tail, the count matches len()<br/>} ApgRecordObject;<br/><br/>#define ApgRecord_GET_ITEM(op, i) (((ApgRecordObject *)(op))-&gt;ob_item[i])</span></pre><p id="dac9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据类型<code class="fe nq nr ns mu b">value</code>的不同，<code class="fe nq nr ns mu b">nogil</code>的攻击可能很方便，也可能看起来毫无用处。例如，如果<code class="fe nq nr ns mu b">value</code>是一个字符串，并且您的CPython将Unicode字符串存储在UTF-8内部，<code class="fe nq nr ns mu b">&lt;const char *&gt;PyUnicode_Data(value)</code>将会工作。如果<code class="fe nq nr ns mu b">value</code>是整数，<code class="fe nq nr ns mu b">PyLong_AsLong(value)</code>也可以。但是处理复杂的类需要GIL。</p><p id="3c3c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">加速应该是<strong class="la iu"> ~10x。</strong></p><p id="f877" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们使用元组而不是<code class="fe nq nr ns mu b">asyncpg.Record</code> -s，我们可以稍微修改上面的代码以保持功能性:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="6685" class="lv lw it mu b gy my mz l na nb">cdef extern from "Python.h":<br/>    # added nogil -&gt; from cpython cimport ...<br/>    # these are the macros that read from the internal ob_items<br/>    PyObject *PyList_GET_ITEM(PyObject *, Py_ssize_t) nogil<br/>    PyObject *PyTuple_GET_ITEM(PyObject *, Py_ssize_t) nogil</span><span id="853c" class="lv lw it mu b gy od mz l na nb">cdef nogil_iter(rows: list[tuple]):<br/>    cdef:<br/>        Py_ssize_t i, size<br/>        PyObject *record<br/>        PyObject *value</span><span id="0ba7" class="lv lw it mu b gy od mz l na nb">    size = len(rows)<br/>    with nogil:<br/>        for i in range(size):<br/>            record = PyList_GET_ITEM(&lt;PyObject *&gt;rows, i)<br/>            value = PyTuple_GET_ITEM(record, 0)</span></pre><p id="94dd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你最好不要同时索引<code class="fe nq nr ns mu b">asyncpg.Record</code>和元组，否则你会立刻在本机代码中抓住一条龙。</p><h2 id="e943" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">零拷贝(反)序列化</h2><p id="316a" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我们目前在PostgreSQL中存储各种预先计算的数据。我们根据来自应用程序逻辑的许多过滤器来获取它。在<a class="ae lu" href="https://sentry.io/" rel="noopener ugc nofollow" target="_blank"> Sentry </a>中收集的配置文件和跟踪明确显示，在<code class="fe nq nr ns mu b">INSERT INTO … VALUES</code>和反序列化期间，我们有时在数据序列化上花费了太多时间——在解析pgproto时创建Python对象，我在前面的一节中提到过。</p><p id="3d30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们能够通过使用基于<a class="ae lu" href="https://numpy.org/doc/stable/user/basics.rec.html" rel="noopener ugc nofollow" target="_blank">结构化numpy数组</a>的特殊的、有限的、不可变的数据结构来优化这个热点。简而言之，它是一个围绕<code class="fe nq nr ns mu b">bytes</code>的数组包装器。那是<code class="fe nq nr ns mu b">__slots__</code>里唯一的一项，真的。</p><p id="25cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当我们想从结构中提取一些字段<code class="fe nq nr ns mu b">"foobar"</code>时，我们执行:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b601" class="lv lw it mu b gy my mz l na nb">@property<br/>def foobar(self):<br/>    return self._array["foobar"][0]</span></pre><p id="74f8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的序列化是零拷贝:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="abc5" class="lv lw it mu b gy my mz l na nb">def serialize(self):<br/>    return self._array.view(np.uint8).data</span></pre><p id="b493" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">反序列化也没什么:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e99a" class="lv lw it mu b gy my mz l na nb">def __init__(self, data: bytes):<br/>    self._array = np.frombuffer(data, dtype=self.dtype, count=1)</span></pre><p id="caab" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nq nr ns mu b">dtype</code>看起来像<code class="fe nq nr ns mu b">np.dtype([("foobar", int), ("baz", "datetime64[ns]")])</code></p><p id="6775" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们结构的秘密武器是非常有效地转换成熊猫数据帧:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="672c" class="lv lw it mu b gy my mz l na nb">concat_bytes = b"".join([x.serialize() for x in rows])<br/>boss = np.frombuffer(concat_bytes, dtype=dtype, count=len(rows))<br/>pd.DataFrame({"foobar": boss["foobar"], "baz": boss["baz"]})</span></pre><p id="46fc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">使用Cython中的<code class="fe nq nr ns mu b">nogil</code>可以进一步优化字节的连接。</p><p id="b6fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">实际的实现更加复杂。它支持:</p><ul class=""><li id="6d21" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt oe ni nj nk bi translated">numpy具有的标量非<code class="fe nq nr ns mu b">object</code>字段，包括unicode字符串和blobs。</li><li id="ac02" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">这些类型的可变长度数组。</li><li id="33a2" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">属性会自动生成。</li><li id="0357" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">可选可变附加字段(未序列化)。</li></ul><p id="387c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是一个例子:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="a1de" class="lv lw it mu b gy my mz l na nb"><a class="ae lu" href="http://twitter.com/numpy_struct" rel="noopener ugc nofollow" target="_blank">@numpy_struct</a><br/>class PullRequestFacts:<br/>    class Immutable:<br/>        created: "datetime64[s]"<br/>        first_commit: "datetime64[s]"<br/>        ...<br/>        <br/>    class Optional:<br/>        repository_full_name: str<br/>        ...</span></pre><p id="0547" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很难比零拷贝和O(1)快。与将字段存储在单个SQL表列中的<code class="fe nq nr ns mu b">pickle</code>相比，<code class="fe nq nr ns mu b">@numpy_struct</code>至少为我们带来了<strong class="la iu">10–50倍的</strong>性能提升。</p><p id="3432" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，也有缺点:</p><ul class=""><li id="4e36" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt oe ni nj nk bi translated">我们不能处理任意的类型。</li><li id="cf27" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">我们不能将字段上的过滤器下推到SQL。</li></ul><p id="2b1c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以<code class="fe nq nr ns mu b">@numpy_struct</code>并不是所有问题的万能解决方案。</p><h2 id="ac78" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">没有熊猫的熊猫</h2><p id="af0e" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">熊猫1.x是微性能垃圾箱火。那是<a class="ae lu" href="https://dev.pandas.io/pandas2/internal-architecture.html#removal-of-blockmanager-new-dataframe-internals" rel="noopener ugc nofollow" target="_blank">官方</a>。同时，pandas非常方便，总的来说是一个很棒的、有据可查的工具。</p><p id="4e9c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们不得不重写API代码的某些部分，以支持低级的numpy数组操作。让我举几个例子。第一个是通过列上的一些条件提取子数据帧。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="df73" class="lv lw it mu b gy my mz l na nb">df = pd.DataFrame({"a": [...], "i": [...]}).set_index("i")<br/>df[df["b"] &gt; 10]</span></pre><p id="6923" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们做得更详细但更有效:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="21c1" class="lv lw it mu b gy my mz l na nb">df.take(np.flatnonzero(df["a"].values &gt; 10))</span></pre><p id="38a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们在一个循环中重复调用这个函数几百次，并且数据帧的大小小于100行，那么我们的提取速度会快一个数量级。发生这种情况是因为<code class="fe nq nr ns mu b">df[...]</code>通过索引值进行选择，因此执行了不必要的索引查找，还因为我们没有执行大量底层粘合代码。</p><p id="2d53" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第二个例子是对由列“a”的值分组的列“b”的值执行一些<code class="fe nq nr ns mu b">function</code>。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="e342" class="lv lw it mu b gy my mz l na nb">df = pd.DataFrame({"a": [...], "b": [...]})<br/>df.groupby("a")["b"].apply(function)</span></pre><p id="e638" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是另一种更快捷的方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2113" class="lv lw it mu b gy my mz l na nb">arr_a = df["a"].values<br/>arr_b = df["b"].values<br/>keys, indexes, counts = np.unique(<br/>    arr_a, return_inverse=True, return_counts=True)<br/>order = np.argsort(indexes)  # better when arr_a's dtype is S or U<br/>offsets = np.zeros(len(keys) + 1, dtype=int)<br/>np.cumsum(counts, out=offsets[1:])<br/>for i, key in enumerate(keys):<br/>    grouped_b = arr_b[offsets[i]:offsets[i + 1]]<br/>    function(key, grouped_b)</span></pre><p id="c059" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这段代码利用了<code class="fe nq nr ns mu b"><a class="ae lu" href="https://numpy.org/doc/stable/reference/generated/numpy.unique.html" rel="noopener ugc nofollow" target="_blank">np.unique</a></code>的强大功能，它可以有效地计算数组中的唯一值(<code class="fe nq nr ns mu b">return_counts=True</code>)，还可以找到第一次遇到的值(<code class="fe nq nr ns mu b">return_index=True</code>)或将每个值映射到一个唯一的索引(<code class="fe nq nr ns mu b">return_inverse=True</code>)。我们对<code class="fe nq nr ns mu b">arr_a</code>的元素进行排序，并在知道每个组的大小的情况下迭代这些组。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/58c1b88b464a20d16ab84df3107edb2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*-8TB6NgxtGqLG8rp1LUV_w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">DataFrame.groupby替换为np.unique. Image by Author。</p></figure><p id="697b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Pandas对<code class="fe nq nr ns mu b">groupby</code>使用了一种<a class="ae lu" href="https://github.com/pandas-dev/pandas/blob/539d51ce4c1c3be4e13566305f84bae2028648bd/pandas/core/algorithms.py#L556" rel="noopener ugc nofollow" target="_blank">散列表技术</a>，因此比排序具有更好的big-O，然而，高度的抽象和糟糕的微性能增加了巨大的线性损失。实际的加速取决于数据帧的大小以及列“a”和“b”的性质。在我们的生产中，典型的提升是<strong class="la iu"> 20到50倍</strong>。</p><p id="66a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">可以类似地替换<code class="fe nq nr ns mu b">groupby</code>之上的许多其他操作，例如<code class="fe nq nr ns mu b">idxmin()</code>或<code class="fe nq nr ns mu b">count()</code>，甚至可以通过NaN-s和NaT-s解决丢失的值</p><p id="fa7b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们过去常常遵循另一种方法:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="2ac1" class="lv lw it mu b gy my mz l na nb">df.groupby("a").grouper.groups.values()</span></pre><p id="ac8f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><code class="fe nq nr ns mu b">np.unique</code>方式避免了具体化每个组的可变长度数组索引的整个列表，因此速度更快。</p><h2 id="4f24" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">所有这些都值得吗？</h2><p id="abd2" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我不会把性能优化和剃牦牛比，而是和训练跑马拉松比。你开始时的状态非常糟糕，然后慢慢地进步，一周接一周，每次都会产生稍微好一点的结果。直到有一天你达到了体能要求，跑了马拉松。比赛的每一公里都会提醒你，为了能够向前跑，你经历了什么。</p><p id="7d95" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Athenian API处理由10个不同属性过滤的数十万个项目，在几毫秒内将几个软件开发活动逻辑地加入到一个巨大的可查询DAG中。两年前，我们从一个非常慢的MVP代码库开始，当时公司刚刚成立4个月。我为那段代码感到羞耻，这是一件好事:我们没有矫枉过正。两年后，同样的API查询执行速度提高了约1000倍。我几乎触及了我们达到1000倍所做的事情的表面，我们绝对没有完成！下面这篇博文应该总结了我们的PostgreSQL查询优化经验。仅考虑Python代码性能，<strong class="la iu">提升了~ 100倍</strong>。</p><h2 id="205a" class="lv lw it bd lx ly lz dn ma mb mc dp md lh me mf mg ll mh mi mj lp mk ml mm mn bi translated">TL；速度三角形定位法(dead reckoning)</h2><p id="f0e6" class="pw-post-body-paragraph ky kz it la b lb mo ju ld le mp jx lg lh mq lj lk ll mr ln lo lp ms lr ls lt im bi translated">我考虑了一些Python代码技巧，帮助我们提高分析后端性能。他们是:</p><ul class=""><li id="a738" class="nc nd it la b lb lc le lf lh ne ll nf lp ng lt oe ni nj nk bi translated"><code class="fe nq nr ns mu b">asyncio.gather</code>按IO等待时间排序的自变量。</li><li id="f13a" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">SQLAlchemy核心中的共享过滤器。</li><li id="d47c" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">从<code class="fe nq nr ns mu b">asyncpg.Record</code> -s定制构建熊猫数据帧。</li><li id="2fd9" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">在Cython中迭代没有GIL的列表。</li><li id="623b" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">零拷贝(解)序列化数据结构。</li><li id="1bf1" class="nc nd it la b lb nl le nm lh nn ll no lp np lt oe ni nj nk bi translated">用纯numpy替换熊猫<code class="fe nq nr ns mu b">groupby</code>。</li></ul><p id="6a4e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些技巧让我们的工作负载性能提高了两个数量级。示例源代码在<a class="ae lu" href="https://github.com/athenianco/athenian-api-open" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。关于我们如何决定优化什么，我写了后续的帖子:<a class="ae lu" href="https://betterprogramming.pub/continuous-performance-improvement-of-http-api-86290433aa54" rel="noopener ugc nofollow" target="_blank">HTTP API的持续性能提升</a>。还有类似的关于PostgreSQL优化的:<a class="ae lu" rel="noopener" target="_blank" href="/how-we-optimized-postgresql-queries-100x-ff52555eabe">我们如何优化PostgreSQL查询100x </a>。</p><p id="91b1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果我们正在构建的产品听起来像是你的工程组织需要的东西，去看看Athenian.com。</p></div></div>    
</body>
</html>