<html>
<head>
<title>Grid Search or Random Search for Model Tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型调整的网格搜索或随机搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/grid-search-or-random-search-for-model-tuning-f09edab6aaa3#2022-10-12">https://towardsdatascience.com/grid-search-or-random-search-for-model-tuning-f09edab6aaa3#2022-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aab5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何在SciKit-Learn的GridSearchCV或RandomizedSearchCV之间进行选择</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/27f16dbd714f2d5ab33509e8cc236a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AD6zBUpnf2W221eut7Go4Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@markuswinkler?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马库斯·温克勒</a>在<a class="ae ky" href="https://unsplash.com/s/photos/search?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="711f" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">为什么要微调模型？</h1><p id="9a0a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">机器学习并不总是像在<em class="mu"> Iris </em>、<em class="mu">泰坦尼克号</em>或<em class="mu">波士顿房价</em>数据集那样简单明了。</p><p id="56f1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">但是，嘿，不要误会我。我从那些著名的玩具数据集中学到了很多东西(并且一直在学)。它们的最大优点是不需要太多的探索或预处理。很多时候，我们可以直接进入我们想要练习和学习的点，比如管道、建模、模型调整、可视化<em class="mu">等。</em></p><p id="86aa" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">我想我想说的是，当对数据建模时，它不会像我们用来研究的玩具数据集那样容易。真实数据需要调整、拟合，并对模型进行微调，因此我们可以从算法中获得最佳效果。为此，Scikit-Learn的<code class="fe na nb nc nd b">GridSearchCV</code>和<code class="fe na nb nc nd b">RandomizedSearchCV</code>是两个不错的选择。</p><p id="ecac" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">好吧，也许是因为你需要通过为你的模型选择正确的超参数来使你的预测更好。因此，本快速教程中介绍的两个选项将允许我们为建模算法提供一个超参数列表。它会把选项一个一个组合起来，测试很多不同的模型，然后呈现给我们最好的选项，性能最好的那个。</p><p id="7b78" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">太棒了，不是吗？因此，让我们继续了解它们之间的区别。</p><h1 id="580d" class="lg lh it bd li lj ne ll lm ln nf lp lq jz ng ka ls kc nh kd lu kf ni kg lw lx bi translated">差别</h1><p id="bb5a" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">为了用一个简单的类比来说明这个概念，让我们想象一下，我们要去参加一个聚会，我们想要选择最佳的服装组合。我们带了几件衬衫、几条裤子和几套衣服。</p><blockquote class="nj nk nl"><p id="8818" class="ly lz mu ma b mb mv ju md me mw jx mg nm mx mj mk nn my mn mo no mz mr ms mt im bi translated">如果我们是<strong class="ma iu"> GridSearchCV </strong>，我们会尝试<strong class="ma iu">每一种</strong> <strong class="ma iu">衬衫、裤子、鞋子的</strong>组合，对着镜子照一张照片。最后，我们将审视一切，选择最佳方案。</p><p id="efe5" class="ly lz mu ma b mb mv ju md me mw jx mg nm mx mj mk nn my mn mo no mz mr ms mt im bi translated">如果我们是<strong class="ma iu"> RandomizedSearchCV </strong>，我们会尝试<strong class="ma iu">一些<strong class="ma iu">随机挑选</strong>的组合</strong>，拍照，最后选出表现最好的。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/6ff8070d3e5ecf23d56192ef12e5d29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ooIjs48-nyAj2XhqFnys-A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@zuizuii?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">卢卡斯·黄</a>在<a class="ae ky" href="https://unsplash.com/s/photos/clothes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="950b" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">现在，用这个比喻，我相信你能感觉到网格搜索将花费更多的时间，因为我们增加了服装的数量来尝试。如果只是两件衬衫，一条裤子，一双鞋，用不了多久。但是如果有10件衬衫，5条裤子和4双不同的鞋子，那么…你明白了。但是，从另一方面来说，它会有一张所有东西的图片，所以它有非常完整的选项集可供选择。</p><p id="0b76" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">随机搜索不会花很长时间，因为它只会尝试一些随机选择的组合。因此，如果你的选择范围很小，那么使用它就没有意义。训练所有选项或其中几个选项的时间基本相同。但是当你有很多组合可以尝试的时候，可能更有意义。但是请记住，这个选项不会尝试所有选项，所以真正的“最佳估计者”甚至可能不会尝试。</p><p id="1678" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">现在让我们看看他们的行动。</p><h1 id="42fb" class="lg lh it bd li lj ne ll lm ln nf lp lq jz ng ka ls kc nh kd lu kf ni kg lw lx bi translated">编码</h1><p id="461f" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">让我们进入编码部分。我们将开始导入本练习所需的模块。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="929b" class="nu lh it nd b gy nv nw l nx ny"># Imports<br/>import pandas as pd<br/>import numpy as np<br/>import seaborn as sns</span><span id="7e9d" class="nu lh it nd b gy nz nw l nx ny"># Dataset<br/>from sklearn.datasets import make_regression</span><span id="1d1f" class="nu lh it nd b gy nz nw l nx ny"># sklearn preprocess<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.tree import DecisionTreeRegressor<br/>from sklearn.model_selection import train_test_split</span><span id="1aff" class="nu lh it nd b gy nz nw l nx ny"># Search<br/>from sklearn.model_selection import RandomizedSearchCV, GridSearchCV</span></pre><p id="98a1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">接下来，我们可以创建一个回归数据集。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="9a59" class="nu lh it nd b gy nv nw l nx ny"># Dataframe<br/>df = make_regression(n_samples=2000, n_features=5,<br/>                     n_informative=4, noise=1, random_state=12)</span><span id="7c43" class="nu lh it nd b gy nz nw l nx ny"># Split X and y<br/>X= df[0]<br/>y= df[1]</span></pre><p id="5e53" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">我们可以分开训练和测试。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="554a" class="nu lh it nd b gy nv nw l nx ny"># Train test split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random)</span></pre><p id="1c7b" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">让我们创建一个管道来扩展数据并适应决策树模型。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="5e8d" class="nu lh it nd b gy nv nw l nx ny"># Creating the steps for the pipeline<br/>steps = [ ('scale', StandardScaler()),<br/>          ('model', DecisionTreeRegressor())  ]</span><span id="6c29" class="nu lh it nd b gy nz nw l nx ny"># Creating pipeline for Decision Tree Regressor<br/>pipe = Pipeline(steps)</span><span id="b035" class="nu lh it nd b gy nz nw l nx ny"># Fit the model<br/>pipe.fit(X_train, y_train)</span></pre><p id="43a9" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">下一步是创建一个要测试的超参数网格<code class="fe na nb nc nd b">params</code>，以微调模型。这里有(2 x 3 x 2 = 12)个选项需要测试。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="d158" class="nu lh it nd b gy nv nw l nx ny">%%timeit<br/># Creating dictionary of parameters to be tested<br/>params= {'model__max_features': [2,5], 'model__min_samples_split':[2, 5, 10], 'model__criterion': ['friedman_mse', 'absolute_error']}</span><span id="a59f" class="nu lh it nd b gy nz nw l nx ny"># Applying the Grid Search<br/>grid = GridSearchCV(pipe, param_grid=params, cv=5, scoring='neg_mean_squared_error')</span><span id="cec9" class="nu lh it nd b gy nz nw l nx ny">grid.fit(X_train, y_train)</span><span id="60c1" class="nu lh it nd b gy nz nw l nx ny"># Best model<br/>grid.best_estimator_</span></pre><p id="d1e6" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">时间结果如下。循环2.37秒。总时间约为18秒。那很好。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="a3aa" class="nu lh it nd b gy nv nw l nx ny">2.37 s ± 526 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span></pre><p id="641f" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">但是，如果我们增加要测试的选项的数量，会发生什么呢？让我们试试(4 x 6 x 2 = 48)个选项。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="e2e8" class="nu lh it nd b gy nv nw l nx ny">%%timeit</span><span id="0073" class="nu lh it nd b gy nz nw l nx ny"># Creating dictionary of parameters to be tested<br/>params= {'model__max_features': [2,3,4,5], 'model__min_samples_split':[2,5,6,7,8,10],'model__criterion': ['friedman_mse', 'absolute_error']}</span><span id="2f34" class="nu lh it nd b gy nz nw l nx ny"># Applying the Grid Search<br/>grid = GridSearchCV(pipe, param_grid=params, cv=5, scoring='neg_mean_squared_error')</span><span id="b408" class="nu lh it nd b gy nz nw l nx ny">grid.fit(X_train, y_train)</span><span id="1d9b" class="nu lh it nd b gy nz nw l nx ny"># Best model<br/>grid.best_estimator_</span></pre><p id="1892" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">时间增加了很多。每圈6.93秒。这里的总时间超过1分钟。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="ccfc" class="nu lh it nd b gy nv nw l nx ny">6.93 s ± 505 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span></pre><p id="19ec" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">现在让我们看看随机搜索。首先，我们将尝试与第一轮相同的12个选项。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="3caa" class="nu lh it nd b gy nv nw l nx ny">%%timeit</span><span id="5ec4" class="nu lh it nd b gy nz nw l nx ny"># Creating dictionary of parameters to be tested<br/>params= {'model__max_features': [2,5],'model__min_samples_split':[2, 5, 10],'model__criterion': ['friedman_mse', 'absolute_error']}</span><span id="b128" class="nu lh it nd b gy nz nw l nx ny"># Applying the Grid Search<br/>randcv = RandomizedSearchCV(pipe, param_distributions=params, cv=5, scoring='neg_mean_squared_error')</span><span id="c606" class="nu lh it nd b gy nz nw l nx ny">randcv.fit(X_train, y_train)</span><span id="55b3" class="nu lh it nd b gy nz nw l nx ny"># Best model<br/>randcv.best_estimator_</span></pre><p id="3f12" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">时间低于网格搜索，不出所料。每个循环1.47秒，总共运行大约10秒。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="bc15" class="nu lh it nd b gy nv nw l nx ny">1.47 s ± 140 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span></pre><p id="a6c7" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">如果我们增加网格中的选项数量，让我们看看会发生什么。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="dd46" class="nu lh it nd b gy nv nw l nx ny">%%timeit</span><span id="b9b0" class="nu lh it nd b gy nz nw l nx ny"># Creating dictionary of parameters to be tested<br/>params= {'model__max_features': [2,3,4,5],<br/>         'model__min_samples_split':[2,5,6,7,8,9,10],<br/>         'model__criterion': ['friedman_mse', 'absolute_error']}</span><span id="fdf4" class="nu lh it nd b gy nz nw l nx ny"># Applying the Grid Search<br/>randcv = RandomizedSearchCV(pipe, param_distributions=params, cv=5, scoring='neg_mean_squared_error')</span><span id="4763" class="nu lh it nd b gy nz nw l nx ny">randcv.fit(X_train, y_train)</span><span id="f44c" class="nu lh it nd b gy nz nw l nx ny"># Best model<br/>randcv.best_estimator_</span></pre><p id="30ef" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">这是结果。哇，几乎同时！每圈1.46秒。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="0776" class="nu lh it nd b gy nv nw l nx ny">1.46 s ± 233 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span></pre><p id="ee4c" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">嗯，那很好。但是他们给了我们相似的结果吗？接下来看看。</p><h1 id="6228" class="lg lh it bd li lj ne ll lm ln nf lp lq jz ng ka ls kc nh kd lu kf ni kg lw lx bi translated">结果</h1><p id="75c0" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">现在让我们来评估一下来自<code class="fe na nb nc nd b">GridSearchCV</code>和<code class="fe na nb nc nd b">RandomizedSearchCV</code>的结果。</p><p id="ff3a" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">计算网格搜索的RMSE。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="6e2d" class="nu lh it nd b gy nv nw l nx ny"># Taking the best estimator<br/>best_grid = grid.best_estimator_</span><span id="a67b" class="nu lh it nd b gy nz nw l nx ny"># Predict<br/>preds_grid = best_grid.predict(X_test)</span><span id="4781" class="nu lh it nd b gy nz nw l nx ny"># RMSE<br/>np.sqrt( mean_squared_error(y_test, preds_grid) )</span><span id="af26" class="nu lh it nd b gy nz nw l nx ny"><strong class="nd iu">[OUT]:<br/>53.70886778489411</strong></span></pre><p id="b421" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">计算随机搜索的RMSE。</p><pre class="kj kk kl km gt nq nd nr ns aw nt bi"><span id="375f" class="nu lh it nd b gy nv nw l nx ny"># Taking the best estimator<br/>best_rand = randcv.best_estimator_</span><span id="07cc" class="nu lh it nd b gy nz nw l nx ny"># Predict<br/>preds_rand = best_rand.predict(X_test)</span><span id="9639" class="nu lh it nd b gy nz nw l nx ny"># RMSE<br/>np.sqrt( mean_squared_error(y_test, preds_rand) )</span><span id="83c7" class="nu lh it nd b gy nz nw l nx ny"><strong class="nd iu">[OUT]:<br/>55.35583215782757</strong></span></pre><p id="629f" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">结果有3%的差异。网格搜索得到了最好的结果，因为它训练每一个模型，因此，它会找到最适合的。当你尝试太多组合时，权衡就是训练的时间。在这种情况下，随机搜索可能是一个很好的选择。</p><h1 id="dffb" class="lg lh it bd li lj ne ll lm ln nf lp lq jz ng ka ls kc nh kd lu kf ni kg lw lx bi translated">在你走之前</h1><p id="c3e1" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">在这篇文章中，我们想展示两个微调模型的好方法。</p><p id="1381" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">当你需要考虑每一个可能的优化时，你可以使用<code class="fe na nb nc nd b">GridSearchCV</code>。但是要考虑训练模型的时间。如果您知道应该选择哪个超参数，这可能是您的最佳选择。</p><p id="b817" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">当您有太多的超参数组合可供选择时，<code class="fe na nb nc nd b">RandomizedSearch</code>可能是最佳选择。例如，当使用网格搜索时，您可以运行它并获得最佳估计值，从而为您指出从哪个组合开始的正确方向。</p><p id="3df1" class="pw-post-body-paragraph ly lz it ma b mb mv ju md me mw jx mg mh mx mj mk ml my mn mo mp mz mr ms mt im bi translated">如果你喜欢这篇文章，关注我的博客或者在<a class="ae ky" href="https://www.linkedin.com/in/gurezende/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上找到我。</p><div class="oa ob gp gr oc od"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="om l"><div class="on l oo op oq om or ks od"/></div></div></a></div><h1 id="8793" class="lg lh it bd li lj ne ll lm ln nf lp lq jz ng ka ls kc nh kd lu kf ni kg lw lx bi translated">参考</h1><div class="oa ob gp gr oc od"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">sklearn.model_selection。GridSearchCV</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">对估计量的特定参数值进行穷举搜索。重要成员是适合的，预测。GridSearchCV…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">scikit-learn.org</p></div></div><div class="om l"><div class="os l oo op oq om or ks od"/></div></div></a></div><div class="oa ob gp gr oc od"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" rel="noopener  ugc nofollow" target="_blank"><div class="oe ab fo"><div class="of ab og cl cj oh"><h2 class="bd iu gy z fp oi fr fs oj fu fw is bi translated">sklearn.model_selection。随机搜索</h2><div class="ok l"><h3 class="bd b gy z fp oi fr fs oj fu fw dk translated">超参数随机搜索。RandomizedSearchCV实现了一个“fit”和一个“score”方法。它还实现了…</h3></div><div class="ol l"><p class="bd b dl z fp oi fr fs oj fu fw dk translated">scikit-learn.org</p></div></div><div class="om l"><div class="ot l oo op oq om or ks od"/></div></div></a></div></div></div>    
</body>
</html>