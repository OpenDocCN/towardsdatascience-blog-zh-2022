<html>
<head>
<title>Learn Precision, Recall, and F1 Score of Multiclass Classification in Depth</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入了解多类分类的精确度、召回率和F1值</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/precision-recall-and-f1-score-of-multiclass-classification-learn-in-depth-6c194b217629#2022-06-16">https://towardsdatascience.com/precision-recall-and-f1-score-of-multiclass-classification-learn-in-depth-6c194b217629#2022-06-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/c1993f0d125370c501d76865bf4fc9d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VmHNE3Xc8K6Lv9x1"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">维克多·瓦西塞克在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="469d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">从混淆矩阵手动计算和sklearn库的语法</h2></div><p id="bc31" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">精确度、召回率和f1值是评估分类算法时非常常用的指标。现在使用库或包来计算它们是非常容易的。但是我相信理解幕后发生的事情对于真正理解输出也是很重要的。</p><p id="5d91" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果这些概念对您来说是全新的，我建议您先阅读这篇文章，其中详细解释了精确度、召回率和f1分数的概念。</p><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/a-complete-understanding-of-precision-recall-and-f-score-concepts-23dc44defef6"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">完全理解精确度、召回率和F分数的概念</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">机器学习中如何处理倾斜数据集</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="me l mf mg mh md mi ja lu"/></div></div></a></div><p id="05d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文将关注多类分类模型的精确度、召回率和f1值。</p><h2 id="3d35" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">精确</h2><p id="39d1" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">作为复习，精度是真阳性的数量除以总阳性预测的数量。换句话说，precision找出了实际上有多少预测值是正数。</p><p id="c222" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是精度的公式:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/a63f8efa81cbb339b5a05013403ec258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDx6oWDXDGBkjnkRoJS6JA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="539f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，</p><p id="6974" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">TP =真阳性</p><p id="1020" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">FP =假阳性</p><p id="8541" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将看到如何从一个多分类模型的混淆矩阵中计算精度。考虑这个混淆矩阵:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/c5ec1c713d2acec9dc6647733ae12da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*F5EN0xM9JOfMg49PgIQMzw.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="06f8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，这个混淆矩阵是一个10 x 10的矩阵。因为这个模型有10个类。当我们处理二进制分类时，混淆矩阵是2 x 2，因为二进制分类有2个类。</p><p id="a865" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我将这个混淆矩阵表示为热图，以便更好地了解实际标签在x轴上的位置以及预测标签在y轴上的位置。该模型有10个类，用数字0到9表示。</p><blockquote class="nn no np"><p id="db87" class="ky kz nq la b lb lc kk ld le lf kn lg nr li lj lk ns lm ln lo nt lq lr ls lt im bi translated"><strong class="la jk">这里的真阳性和假阳性是什么？</strong></p></blockquote><p id="ccb6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将通过几个例子来理解它。让我们以标签9为例进行演示。标签9的真正阳性应该是实际上是9并且预测也是9的样本。在上面的热图中，947(看右下角的单元格)是真正的正数，因为它们被预测为9，而实际标签也是9。</p><p id="5bed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们来看看什么是误报。看，当我们处理9号标签时，只有9号标签是阳性的，其他标签都是阴性的。在预测标签为9的列中，仅对于947个数据，实际标签也是9。该列中的其余数据(用红色标记)被模型错误地预测为9。他们的实际标签不是9。所以标签9的误报是(1+38+40+2)。</p><p id="b365" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签9的精度为:</p><p id="ffea" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">947/ (947 + 1 + 38 + 40 + 2) = 0.92</p><p id="d280" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签9的精度是0.92，非常高。因为差不多接近1了。</p><blockquote class="nu"><p id="5ec4" class="nv nw jj bd nx ny nz oa ob oc od lt dk translated">如果模型是完美的，就不应该有任何假阳性。如果误报为0，精度将为TP/TP，即1。</p></blockquote><p id="a03f" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">我们将再举一个例子。让我们也计算一下标签2的精度。</p><p id="9b6e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，从热图中找到实际标签和预测标签都为2交叉单元格。看第二栏。是762(浅色的细胞)。其余细胞为假阳性。当我们考虑标签2时，只有标签2是正的，所有其他标签都是负的。因此，在第2列中，标签2的所有其他值实际上都是负值，但是我们的模型错误地将它们预测为标签2。</p><p id="2cd1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签2的精度:762/(762+18+4+16+72+105+9)= 0.77</p><p id="8e96" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，您可以计算每个标签的精度。</p><h2 id="8ac3" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">回忆</h2><p id="8278" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">召回是真阳性除以真阳性和假阴性。换句话说，回忆衡量的是模型预测积极事物的能力。</p><p id="a656" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">公式如下:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/2d4aba3eb9ae262990a803e70a1385d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*OV0hfgCStTI8hy6lAY1SdA.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="a59f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将再次计算标签9和标签2的召回。所以，真正的积极因素是一样的。但这次我们需要找出假阴性。我建议试着先想想什么可能是假阴性，然后看看这里的解释。</p><p id="28a9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这又是热图:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/3d6c0249bafe128083e263ee3c81868c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*leyww4gMRMVMkfJayNSIMw.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="730c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看这里，红色的矩形有不同的方向。我们来看看为什么。</p><blockquote class="nn no np"><p id="2ce3" class="ky kz nq la b lb lc kk ld le lf kn lg nr li lj lk ns lm ln lo nt lq lr ls lt im bi translated">什么是假阴性？</p></blockquote><p id="38a0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假阴性是实际上是阳性但被预测为阴性的样本。让我们考虑标签9。提醒一下，当我们处理标签9时，标签9是唯一的阳性，其余的标签都是阴性。看第九排。所有的样本实际上都是阳性的。但是有947个样本被预测为阳性。但是14 + 36 + 3个样本被预测为阴性。这些是标签9的假阴性。</p><p id="e05d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签9的召回:947 / (947 + 14 + 36 + 3) = 0.947</p><p id="9184" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">同样，标签2的召回是:</p><p id="0803" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">762 / (762 + 14 + 2 + 13 + 122 + 75 + 12) = 0.762</p><p id="5e3d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您可以使用同样的方法计算每个标签的召回率。</p><h2 id="a0fe" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">F1分数</h2><p id="6b7a" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">F1分数是精确度和召回率的调和平均值。只是提醒一下，这不是算术平均值。如果precision为0，recall为1，f1分数将为0，而不是0.5。公式如下:</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ol"><img src="../Images/b26c8c65dc3d9b6dc31c4f0d59759035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tEck5hzpmrv7lfnjiT7DhQ.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="293a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们使用标签9和标签2的精度和召回，并使用此公式找出f1分数。</p><p id="7cf9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签9的F1分数:2 * 0.92 * 0.947/(0.92+0.947)= 0.933</p><p id="816b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">标签2的F1分数:2 * 0.77 * 0.762/(0.77+0.762)= 0.766</p><p id="868e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我相信你现在已经知道如何计算多类分类问题中每个标签的精度、召回率和f1值。</p><p id="2f2a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是我们仍然需要一个模型的单精度、召回率和f1值。<strong class="la jk">我们如何得到它？</strong></p><h2 id="4aa3" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">宏观平均和加权平均精度、召回率和F1分数</h2><p id="fed2" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">有两种不同的方法可以获得模型的单一精度、召回率和f1值。</p><p id="884f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">先说精度。</strong>我们需要所有标签的精度来找出模型的单精度。但是我们在这里只展示了标签9和2的精度。请随意使用我们在此演示的相同方法计算所有标签的精度。</p><p id="7b7a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下表中，我列出了所有标签的精确度、召回率和f1值。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/fb785ff5e30d785cc8fd71453995f6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*y62WJqfwst6uFYRlMTNgig.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><p id="cdf4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">宏平均精度</strong>是所有标签精度的简单算术平均值。因此，该模型的宏观平均精度为:</p><p id="5fe4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">精度=(0.80+0.95+0.77+0.88+0.75+0.95+0.68+0.90+0.93+0.92)/10 = 0.853</p><blockquote class="nu"><p id="0df4" class="nv nw jj bd nx ny nz oa ob oc od lt dk translated">请随意以同样的方式计算该模型的宏观平均召回率和宏观平均f1分数。</p></blockquote><p id="c442" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">加权平均精度还考虑了每个标签的样本数。</p><p id="7d52" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该数据集中每个标签的样本数如下:</p><p id="cbc7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">0 — — 760</p><p id="d55b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">1 — — 900</p><p id="d36b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">2 — — 535</p><p id="48f4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">3 — — 843</p><p id="d699" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">4 — — 801</p><p id="f665" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">5 — — 779</p><p id="9206" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">6 — — 640</p><p id="0fbd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">7 — — 791</p><p id="f23a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">8 — — 921</p><p id="8711" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">9 — — 576</p><p id="fc6a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型的加权平均精度是样本数乘以单个标签的精度，再除以样本总数。</p><p id="3f1c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">样本总数将是所有单个样本的总和:</p><p id="0305" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">760 + 900 + 535 + 848 + 801 + 779 + 640 + 791 + 921 + 576 = 7546</p><p id="d872" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了计算加权平均精度，我们将每个标签的精度乘以它们的样本大小，然后除以我们刚刚找到的样本总数。</p><p id="529f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi">(760*0.80 + 900*0.95 +535*0.77 + 843*0.88 + 801*0.75 + 779*0.95 + 640*0.68 + 791*0.90 + 921*0.93 + 576*0.92) / 7546 = 0.86</p><p id="785e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，算术平均值和加权平均值略有不同。<strong class="la jk">如果单个标签的样本量相同，算术平均值将与加权平均值完全相同。</strong></p><h2 id="c62a" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">Sklearn函数</h2><p id="52f4" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">好消息是，你不需要用这种方式计算精确度、召回率和f1分数。Scikit-learn library有一个函数<strong class="la jk">‘classification _ report’</strong>，它分别为您提供每个标签的精确度、召回率和f1分数，以及模型的精确度分数、单个宏平均值和加权平均值精确度、召回率和f1分数。下面是语法:</p><pre class="ni nj nk nl gt on oo op oq aw or bi"><span id="3fb4" class="mj mk jj oo b gy os ot l ou ov">from sklearn import metrics<br/>print(metrics.classification_report(y_test, y_pred))</span></pre><p id="bb24" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这里，y_test是测试数据的原始标签，y_pred是使用模型预测的标签。</p><p id="efcb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该函数还为您提供了一个名为“support”的列，它是每个标签的单个样本大小。对应于精确度、宏平均值和加权平均值的支持值是数据集的总样本大小。</p><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/4861e7376420d480fe03b03b5677b489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*NP5k_ZwQlu6Sdc3mxlllAw.jpeg"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">作者图片</p></figure><blockquote class="nu"><p id="0bbd" class="nv nw jj bd nx ny ox oy oz pa pb lt dk translated">上图可以看到支持值都是1000。这意味着所有标签的样本量是1000。</p></blockquote><p id="b506" class="pw-post-body-paragraph ky kz jj la b lb oe kk ld le of kn lg lh og lj lk ll oh ln lo lp oi lr ls lt im bi translated">我上面说过，如果每个标签的样本量相同，那么宏观平均和加权平均也就相同。你可以看到，在这张图中，宏观平均和加权平均都是一样的。</p><p id="a13a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">您将在此链接中找到分类项目的完整代码以及我是如何获得上表的:</p><div class="is it gp gr iu lu"><a href="https://github.com/rashida048/Few-Machine-Learning-projects/blob/master/image_classification_problems.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">少数机器学习项目/image _ class ification _ problems . ipynb at master…</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">这些项目使用pandas，matplotlib，numpy，scipy和scikitlearn …</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">github.com</p></div></div><div class="md l"><div class="pc l mf mg mh md mi ja lu"/></div></div></a></div><h2 id="dfd5" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">结论</h2><p id="fefb" class="pw-post-body-paragraph ky kz jj la b lb nc kk ld le nd kn lg lh ne lj lk ll nf ln lo lp ng lr ls lt im bi translated">本文解释了如何从给定的混淆矩阵手动计算多类分类的单个标签的精度、召回率和f1值，以及多类分类模型的单精度、召回率和f1值。我们还讨论了如何使用scikit-learn库中的一行代码非常容易地获得它们。希望对你有帮助。</p><p id="c8ac" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的视频解释了同样的概念:</p><figure class="ni nj nk nl gt iv"><div class="bz fp l di"><div class="pd pe l"/></div></figure><p id="8cc8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎在推特上关注我，喜欢我的T2脸书页面。</p><h2 id="de51" class="mj mk jj bd ml mm mn dn mo mp mq dp mr lh ms mt mu ll mv mw mx lp my mz na nb bi translated">更多阅读</h2><div class="is it gp gr iu lu"><a href="https://pub.towardsai.net/complete-detailed-tutorial-on-linear-regression-in-python-for-beginners-f9fa3f65faca" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">针对初学者的Python线性回归完整详细教程</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">线性回归Scikit-Learn中的基本、简单和多元线性回归实现</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">pub.towardsai.net</p></div></div><div class="md l"><div class="pf l mf mg mh md mi ja lu"/></div></div></a></div><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/simple-explanation-on-how-decision-tree-algorithm-makes-decisions-34f56be344e9"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">浅谈决策树算法如何决策</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">决策树算法背后的直觉</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="pg l mf mg mh md mi ja lu"/></div></div></a></div><div class="is it gp gr iu lu"><a href="https://pub.towardsai.net/data-analysis-91a38207c92b" rel="noopener  ugc nofollow" target="_blank"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">数据分析</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">Python中数据科学家/分析师日常工作中的常见数据清理任务</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">pub.towardsai.net</p></div></div><div class="md l"><div class="ph l mf mg mh md mi ja lu"/></div></div></a></div><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/a-complete-guide-for-detecting-and-dealing-with-outliers-bad26b1e92b6"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">检测和处理异常值的完整指南</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">6种检测异常值的方法和4种处理异常值的方法</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="pi l mf mg mh md mi ja lu"/></div></div></a></div><div class="is it gp gr iu lu"><a rel="noopener follow" target="_blank" href="/6-tips-for-dealing-with-null-values-e16d1d1a1b33"><div class="lv ab fo"><div class="lw ab lx cl cj ly"><h2 class="bd jk gy z fp lz fr fs ma fu fw ji bi translated">处理空值的6个技巧</h2><div class="mb l"><h3 class="bd b gy z fp lz fr fs ma fu fw dk translated">包括迭代方法、平均值和中值填充以及分组依据、平均值和中值填充</h3></div><div class="mc l"><p class="bd b dl z fp lz fr fs ma fu fw dk translated">towardsdatascience.com</p></div></div><div class="md l"><div class="pj l mf mg mh md mi ja lu"/></div></div></a></div></div></div>    
</body>
</html>