<html>
<head>
<title>An Effective Approach for Image Anomaly Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种有效的图像异常检测方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-effective-approach-for-image-anomaly-detection-7b1d08a9935b#2022-10-27">https://towardsdatascience.com/an-effective-approach-for-image-anomaly-detection-7b1d08a9935b#2022-10-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="de29" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用来自英特尔OpenVinoToolkit的Anomalib来基准测试、开发和部署基于深度学习的图像异常检测</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c3405623c037f87dc6f80c70ad1235b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6t0AqDbIAHaHDmec.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源:<a class="ae ky" href="https://pixabay.com/photos/nuts-black-acorn-oak-animal-food-60812/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a> ( <a class="ae ky" href="https://pixabay.com/service/license/" rel="noopener ugc nofollow" target="_blank"> Pixabay许可</a>:免费商业使用)</p></figure><p id="6fb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检测图像异常甚至比检测结构化数据集或来自<a class="ae ky" rel="noopener" target="_blank" href="/effective-approaches-for-time-series-anomaly-detection-9485b40077f1">时间序列数据</a>的异常更加困难。这部分是因为在结构化数据集中，视觉特征比数值特征更难捕捉。这就是深度学习(DL)技术的用武之地，因为深度学习模型可以对图像等非结构化数据进行自动特征提取。</p><p id="6452" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了方便执行图像异常检测任务，英特尔OpenVino推出了<strong class="lb iu"> Anomalib </strong>，这是一个DL框架，提供了最先进的异常检测算法，用于公共和私有数据集的基准测试。该框架提供了最近文献中描述的异常检测算法的许多现成可用的实现，以及加速定制DL模型的开发和实现的工具集合。该框架重点关注<strong class="lb iu">无监督的基于图像的异常检测</strong>，其目标是识别图像中的异常值或数据集中图像内的异常像素区域。这个框架被开发者(<a class="ae ky" href="https://openvinotoolkit.github.io/anomalib/" rel="noopener ugc nofollow" target="_blank">https://openvinotoolkit.github.io/anomalib/</a>)很好地维护着，并且不断地用新的算法和训练/推理插件进行更新。</p><h1 id="050a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">工业应用领域</h1><p id="774b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">现在，如果您想知道为什么Anomalib会对您有用，那么我将从我的经验中提到这个框架可以产生巨大影响的以下工业应用领域:</p><ul class=""><li id="330e" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><strong class="lb iu">制造过程质量检测</strong>:金属螺母、齿轮、容器、密封件等小零件和设备的缺陷检测。该库可以检测不同于正常样品的异常和有缺陷的图案。</li><li id="f048" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">从医学图像中检测医学状况</strong>:从放射医学图像中检测和定位肿瘤、出血、胸部感染等医学状况是另一个大规模使用案例，在这种情况下，该框架将非常有用</li></ul><h1 id="2344" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">为什么是Anomalib？</h1><p id="c3b1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果你想知道为什么anomalib用于无监督图像异常检测，我会列出以下主要原因:</p><ol class=""><li id="21e9" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu ng my mz na bi translated">很难捕捉和注释大量的异常图像数据。这就是为什么无人监管的异常检测是当务之急。</li><li id="fc11" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu ng my mz na bi translated">传统的计算机视觉算法是无效的，因为正常样本和异常样本之间的差异可能非常小。然而，可能存在多种类型的变化，因此很难预先预测所有类型的图像异常。因此，基于DL的方法可以自动学习正常和异常特征之间的差异。</li><li id="6dbb" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu ng my mz na bi translated">您可以使用Anomalib在全球和局部范围内进行检测和定位。因此，您不仅可以识别不同类型的异常，还可以突出显示局部像素级异常区域</li><li id="bea6" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu ng my mz na bi translated">为您自己的用例编写您自己的异常检测器的简单抽象。</li><li id="f41a" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu ng my mz na bi translated">支持高速用例的实时推理过程！</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nh"><img src="../Images/322c98b8523125355fc94b30b0cd6bcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tIJS17g3RO_n3STeM0Bkbg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">anomalib可视化工具产生的示例性输出(来源:<a class="ae ky" href="https://arxiv.org/abs/2202.08341" rel="noopener ugc nofollow" target="_blank"> ArXiv Anomalib论文</a></p></figure><h1 id="6bb6" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">理论——:-(</h1><p id="1c37" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">是的，我知道太多的理论会令人厌烦。但重要的是要知道Anomalib是如何工作的！我保证我不会抛出太多的技术信息和花哨的术语来使这篇文章变得非常专业。相反，我将介绍这个框架的高层次直观理解和机制。详细了解请阅读关于Anomalib的研究文献原文——<em class="ni">Anomalib:Akcay等人的异常检测深度学习库</em>:【https://arxiv.org/abs/2202.08341】T4</p><h2 id="14f5" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">架构图</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/9df66f5f558543e7824dcc4abf8b8e87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMzt-DBENWYKaocmOgz_lg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">anomalib框架架构图(来源:<a class="ae ky" href="https://arxiv.org/abs/2202.08341" rel="noopener ugc nofollow" target="_blank"> ArXiv Anomalib论文</a>)</p></figure><p id="d62b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图总结了anomalib库从开发到部署的整个端到端流程。</p><h2 id="d9b2" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">支持的型号</h2><p id="2b92" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">Anomalib为无监督异常检测和定位方法提供了以下<a class="ae ky" href="https://developers.google.com/machine-learning/gan/generative" rel="noopener ugc nofollow" target="_blank">判别和生成方法</a>:</p><ul class=""><li id="a290" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><strong class="lb iu"> PaDiM:一个用于异常检测和定位的补丁分布建模框架</strong>—<a class="ae ky" href="https://arxiv.org/pdf/2011.08785.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2011.08785.pdf</a></li><li id="11e4" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">patch core</strong>——<a class="ae ky" href="https://arxiv.org/pdf/2106.08265.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2106.08265.pdf</a></li><li id="c7c7" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu"> STFPM:用于无监督异常检测的学生-教师特征金字塔匹配</strong>——<a class="ae ky" href="https://arxiv.org/pdf/2103.04257.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2103.04257.pdf</a></li><li id="36f3" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu"> FastFlow:通过https://arxiv.org/abs/2111.07677</strong>T22D归一化流的无监督异常检测和定位</li><li id="f952" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">从一类嵌入中通过反蒸馏进行异常检测—<a class="ae ky" href="https://arxiv.org/pdf/2201.10703v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2201.10703v2.pdf</a></li><li id="8949" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">还有更多！—<a class="ae ky" href="https://openvinotoolkit.github.io/anomalib/reference_guide/algorithms/index.html#available-models" rel="noopener ugc nofollow" target="_blank">https://openvinotoolkit . github . io/anomalib/reference _ guide/algorithms/index . html # available-models</a></li></ul><h2 id="baf8" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">培训用数据</h2><p id="149b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">该框架还为越来越多的公共基准数据集提供了数据集适配器，这些数据集来自广泛用于文献中的图像和视频领域。</p><ul class=""><li id="bc15" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><strong class="lb iu">图像</strong>。Anomalib支持CIFAR-10进行快速原型制作，支持MVTec、BTAD和Kolektor进行真实世界的缺陷检测应用。</li><li id="788e" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">视频</strong>。该库支持视频数据集，如ShanghaiTec [10]。目前，视频数据集仅在帧级基础上受支持，因为现有的anomalib模型针对图像域进行了优化。作者计划在未来版本中支持视频异常检测模型来解决这个问题。</li><li id="122a" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">自定义</strong>。除了前面提到的公共数据集，anomalib还为用户提供了一个数据集接口，以实现定制数据集，在其上可以训练新的和现有的anomalib模型。</li></ul><p id="cb32" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">关于这些数据集的参考、引用和许可，我建议你阅读全文—<a class="ae ky" href="https://arxiv.org/pdf/2202.08341.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2202.08341.pdf</a></p><h2 id="5451" class="nj lw it bd lx nk nl dn mb nm nn dp mf li no np mh lm nq nr mj lq ns nt ml nu bi translated">超越基准</h2><p id="0949" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这篇论文的作者(<a class="ae ky" href="https://arxiv.org/pdf/2202.08341.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2202.08341.pdf</a>)报告了他们在图像级和像素级得分上的表现，这似乎令人印象深刻！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/c0afb61b016b9870c9ff578d47f02226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rRBs18A07X73TVgicPECA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Anomalib的MVTec数据集类别的图像级AUROC分数(来源:<a class="ae ky" href="https://arxiv.org/abs/2202.08341" rel="noopener ugc nofollow" target="_blank"> ArXiv Anomalib论文</a></p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/9077f6033c16059d3756e7ac48926441.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bho0zXuyvN1beUDbpJcAiA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用Anomalib的MVTec数据集类别的像素级AUROC分数(来源:<a class="ae ky" href="https://arxiv.org/abs/2202.08341" rel="noopener ugc nofollow" target="_blank"> ArXiv Anomalib论文</a>)</p></figure><p id="f129" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于任何工业应用来说，结果看起来都非常惊人！</p><h1 id="1294" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">代码示例在哪里？？？</h1><p id="b2f1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">不要担心！在我自己运行了几个用例之后，我确保提供了代码示例！然而，我将在另一篇文章中解释代码的完整工作方式。但是完整的工作代码已经可以在我的GitHub repo上找到:<a class="ae ky" href="https://github.com/adib0073/unsupervised-anomaly-detection/blob/main/unsupervised-anomaly-detection.ipynb" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/adib 0073/unsupervised-anomaly-detection/blob/main/unsupervised-anomaly-detection . ipynb</a>。该算法超级快，非常容易运行和复制的结果！</p><h1 id="1b0d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated"><strong class="ak">图像异常检测为可解释的人工智能</strong></h1><p id="df95" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">你有兴趣了解更多关于图像分类和分割模型的可解释人工智能吗？然后，Anomalib中提出的方法可能是解释建立在图像数据集上的模型的非常有用的方法。如果你有兴趣了解更多关于可解释AI的知识，我推荐阅读这本书:<a class="ae ky" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">【应用机器学习可解释技术】</strong> </a> <strong class="lb iu"> </strong>并探索<a class="ae ky" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques" rel="noopener ugc nofollow" target="_blank"> GitHub知识库</a>以获得实际操作的代码示例。</p><div class="ny nz gp gr oa ob"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">www.amazon.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div><h1 id="a2b8" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="5daa" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本文中，我们讨论了<strong class="lb iu"> Anomalib </strong>，这是一个用于培训、基准测试、部署和开发基于深度学习的无监督异常检测模型的综合框架。Anomalib提供了一组工具，允许对任何图像数据集上的不同无监督异常检测模型进行快速和可重复的比较。开源框架可在:<a class="ae ky" href="https://github.com/openvinotoolkit/anomalib" rel="noopener ugc nofollow" target="_blank">https://github.com/openvinotoolkit/anomalib</a>获得，完整文档可在:<a class="ae ky" href="https://openvinotoolkit.github.io/anomalib/" rel="noopener ugc nofollow" target="_blank">https://openvinotoolkit.github.io/anomalib/</a>获得。希望你喜欢这篇文章！在<a class="ae ky" href="https://adib0073.medium.com/membership" rel="noopener"> Medium </a>和<a class="ae ky" href="https://www.linkedin.com/in/aditya-bhattacharya-b59155b6/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我，了解更多关于计算机视觉、可解释的人工智能和机器学习的信息。</p><div class="ny nz gp gr oa ob"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="oc ab fo"><div class="od ab oe cl cj of"><h2 class="bd iu gy z fp og fr fs oh fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="oi l"><h3 class="bd b gy z fp og fr fs oh fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="oj l"><p class="bd b dl z fp og fr fs oh fu fw dk translated">www.amazon.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op ks ob"/></div></div></a></div><h1 id="687a" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考</h1><ul class=""><li id="71bc" class="ms mt it lb b lc mn lf mo li oq lm or lq os lu mx my mz na bi translated">阿卡伊，s .，阿梅隆，d .，瓦伊迪亚，a .，拉克什马南，b .，阿胡贾，n .，根茨，U. (2022)。Anomalib:用于异常检测的深度学习库。doi:10.48550/ARXIV</li><li id="a34a" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://github.com/adib0073/unsupervised-anomaly-detection" rel="noopener ugc nofollow" target="_blank">https://github.com/adib0073/unsupervised-anomaly-detection</a></li><li id="c805" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://blog.ml6.eu/a-practical-guide-to-anomaly-detection-using-anomalib-b2af78147934" rel="noopener ugc nofollow" target="_blank">https://blog . ml6 . eu/a-practical-guide-to-anomali b-using-b2af 78147934</a></li><li id="8c26" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">【https://openvinotoolkit.github.io/anomalib/ T4】</li><li id="0d02" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://pypi.org/project/anomalib/" rel="noopener ugc nofollow" target="_blank">https://pypi.org/project/anomalib/</a></li><li id="3492" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://www.kaggle.com/code/ipythonx/mvtec-ad-anomaly-detection-with-anomalib-library/notebook" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/code/ipythonx/mvtec-ad-anomaly-detection-with-anomali b-library/notebook</a></li><li id="7f25" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://www.mvtec.com/company/research/datasets/mvtec-ad" rel="noopener ugc nofollow" target="_blank">https://www.mvtec.com/company/research/datasets/mvtec-ad</a></li></ul></div></div>    
</body>
</html>