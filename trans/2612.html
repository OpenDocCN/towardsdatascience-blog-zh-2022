<html>
<head>
<title>Unbalanced Data? Stop Using ROC-AUC and Use AUPRC Instead</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡的数据？停止使用ROC-AUC，改用AUPRC</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/imbalanced-data-stop-using-roc-auc-and-use-auprc-instead-46af4910a494#2022-06-07">https://towardsdatascience.com/imbalanced-data-stop-using-roc-auc-and-use-auprc-instead-46af4910a494#2022-06-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="967e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">AUPRC在数据不平衡的情况下衡量绩效的优势——解释清楚</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/402349048a891f9d3357f6799e1e68fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*c9KLMG0CCiyQSckK"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@saltsup?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Piret Ilver </a>拍摄</p></figure><p id="f13d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在<strong class="ky ir"> C </strong> urve (ROC-AUC)度量下的<strong class="ky ir"> R </strong>接收方<strong class="ky ir"> O </strong>操作方<strong class="ky ir"> C </strong>特征量<strong class="ky ir"> A </strong> rea <strong class="ky ir"> U </strong>被广泛用于评估二元分类器的性能。然而，有时候，基于测量<strong class="ky ir"> P </strong>精度- <strong class="ky ir"> R </strong> ecall <strong class="ky ir"> C </strong>曲线(AUPRC)下的<strong class="ky ir"> A </strong> rea <strong class="ky ir"> U </strong>来评估您的分类器更合适。</p><p id="2b1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将详细比较这两种方法，并附有实验结果和图表。Scikit-learn实验也可在相应的笔记本中获得。</p><h2 id="42b6" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">准备工作——计算曲线</h2><p id="a314" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我假设你熟悉精度和召回以及混淆矩阵的元素(TP，FN，FP，TN)。如果你需要的话，<a class="ae kv" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">维基百科的文章</a>是很好的复习资料。</p><p id="be37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们快速回顾一下ROC曲线和PRC的计算。 我们将使用下图，这大大有助于我的理解。</p><p id="906d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们有一个训练好的预测概率的二元分类器。也就是说，给定一个新的例子，它输出正类的概率。接下来，我们采用一个包含3个肯定和2个否定的测试集，并计算分类器的预测概率——我们在下图中按降序排列它们。在相邻的预测之间，我们放置一个阈值，并计算相应的评估指标，TPR(相当于召回)，FPR和精度。每个阈值代表一个二元分类器，其预测值对于阈值以上的点为正，对于阈值以下的点为负-评估测量值是针对该分类器计算的。将上述内容放到一个图形中:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/4016b8849be52b9233c7faa2b37a658f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P8fxjDl4ti27B0frLbE2Cw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1: <strong class="bd ms"> </strong>计算ROC曲线和PRC，给定概率和地面真相。这些点按正类概率排序(最高概率在顶部)，绿色和红色分别代表正或负标注。归功于我的同事。</p></figure><p id="8e76" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用这些计算，我们可以绘制ROC曲线和PRC:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/e7afa7b28a8785dec399867c28e67296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1afOwtSPv4jAIfUFdnbXDQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2: <strong class="bd ms"> </strong>根据图1所示的数据，绘制ROC曲线和PRC。</p></figure><p id="39e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">计算每条曲线下的面积现在很简单——面积如图2所示。请注意，AUPRC也被称为<strong class="ky ir">A</strong>verage<strong class="ky ir">P</strong>recision(AP)，这是一个来自<a class="ae kv" href="https://en.wikipedia.org/wiki/Information_retrieval" rel="noopener ugc nofollow" target="_blank">信息检索</a>领域的术语(稍后将详细介绍)。</p><p id="2410" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在sklearn中，这些计算对我们来说是透明的，我们可以使用<code class="fe mu mv mw mx b"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank">sklearn.metrics.roc_auc_score</a></code>和<code class="fe mu mv mw mx b"><a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html" rel="noopener ugc nofollow" target="_blank">sklearn.metrics.average_precision_score</a></code>。</p><h2 id="ac63" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">ROC-AUC和AUPRC的比较</h2><p id="51df" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">让我们直接看结果，然后讨论实验。</p><p id="8fa9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在图3中，我们看到两个强模型(高AUC ),它们的AUC得分略有不同，因此橙色模型略好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/83e524d13fb560ec916bea1838541fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CKqNF3aYnvGP6dqAnCxzww.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:两个看似相似的模型，橙色的那个(“另一个模型”)显示出一点优势。</p></figure><p id="12c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，在图4中，情况完全不同——蓝色模型明显更强。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/2a7c583099aaccf591fddfd0f8476dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r04iShRFAC3LM5EvqZeuSA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4:两个模型，其中蓝色的模型(“首选模型”)显示了很大的优势。</p></figure><p id="2a1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">什么意义上的更强？考虑到ROC曲线告诉我们一个不同的故事，这真的有趣吗？在回答这些问题之前，让我们先描述一下我们的实验。</p><p id="2ade" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里的关键是分类标签的分布:</p><ul class=""><li id="815d" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">20个阳性</li><li id="193d" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">2000张底片</li></ul><p id="4725" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一种严重的不平衡。根据这些数据，我们模拟了两个模型的预测。第一个模型在其前20个预测中找到80%的肯定结果，第二个模型在其前60个预测中找到80%的肯定结果，如图5所示。其余的积极因素平均分布在其余的例子中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/d110e0bb4fed988f2bde5810b7407901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VaFcxGtc12EC4tb6pHLlIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图5:图3和图4中考虑的模型的前100个预测。</p></figure><p id="afe8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">换句话说，这两种模型的区别在于它们发现积极因素的速度。让我们看看为什么这是一个重要的属性，以及为什么ROC-AUC未能捕捉到它。</p><h2 id="f6f2" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">解释差异</h2><p id="7531" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">ROC曲线的x轴是FPR。鉴于不平衡的数据，FPR的变化与召回的变化相比是缓慢的。这一因素决定了所有的差异。</p><p id="d744" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了理解这一点，在看了100个例子后，回到我们的不平衡数据集并考虑FPR。我们可能看到最多100个阴性(假阳性)，最少80个，因此FPR在区间[0.04，0.05]内。相比之下，我们的模型在100个例子中已经实现了80%的召回率，在召回率方面几乎没有改进的空间，并导致了高AUC。</p><p id="8bbf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，对于PRC，获得假阳性具有显著的影响，因为每次我们看到一个假阳性时，精确度都显著降低。因此，“其他模式”表现不佳。但是为什么这里的精度很有趣呢？</p><p id="716d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑一下欺诈检测、疾病识别和YouTube视频推荐的任务。由于正面的例子很少，它们有着相似的数据不平衡的性质。然而，如果我们模型的用户能更快地找到他们的优点，他们将会节省很多时间。也就是说，积极因素的分数是至关重要的，即使差异在概率的排序列表中高出几个点。AUPRC抓住了这一要求，而ROC-AUC没有做到这一点。</p><h2 id="f714" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">解释差异——ROC-AUC作为概率</h2><p id="77a2" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">ROC-AUC有一个很好的概率解释(在[2]中提到了额外的等价解释，在[4]或[5]中提供了一个证明)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/cd610f93abe25a672dab5da7d898ab14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/0*UtqzJViMXX1z3Vav"/></div></figure><p id="d963" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">也就是说，ROC-AUC是“均匀随机抽取的阳性<em class="mq">比均匀随机抽取的阴性<em class="mq">得分高的概率”。</em></em></p><p id="8b45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在面对如上所述的严重数据不平衡时思考一下这种解释。当我们统一抽取一个随机的<em class="mq">负值</em>时，很可能是一个不感兴趣的负值或者是一个“容易”的负值，因为这通常是不平衡数据的原因——负值更容易收集。因此，当我们一致地抽取一个随机的<em class="mq">正</em>时，给它分配一个比这个“容易”负的分数更高的分数是微不足道的。即上述概率会很高。</p><p id="80d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们感兴趣的是积极因素与“硬”消极因素相比是如何评分的，这些消极因素出现在我们预测的顶部。ROC-AUC没有区分这些负面因素，但AUPRC正是这样做的。</p><h2 id="9ba5" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">关于排序的一个注记</h2><p id="b495" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">对不平衡数据的分类可以被看作是一种积极的检索任务(例如，web文档检索)，在这种情况下，我们只关心来自我们的分类器(或排序器)的前K个预测。通常使用平均精度(AUPRC)来测量top-K预测，因为这是评估通用检索系统的最先进的方法[3]。因此，如果你发现你的不平衡任务类似于检索任务，强烈建议考虑AUPRC。</p><h2 id="145f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">代码实验</h2><p id="eec5" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">要重现本文的结果，请参见下面的知识库。您也可以使用参数，并检查它们如何影响结果。</p><div class="np nq gp gr nr ns"><a href="https://github.com/1danielr/rocauc-auprc" rel="noopener  ugc nofollow" target="_blank"><div class="nt ab fo"><div class="nu ab nv cl cj nw"><h2 class="bd ir gy z fp nx fr fs ny fu fw ip bi translated">GitHub - 1danielr/rocauc-auprc:相应介质物品的代码</h2><div class="nz l"><h3 class="bd b gy z fp nx fr fs ny fu fw dk translated">在Google Colab上运行实验。</h3></div><div class="oa l"><p class="bd b dl z fp nx fr fs ny fu fw dk translated">github.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kp ns"/></div></div></a></div><h2 id="fe25" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><p id="acf9" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">尽管ROC-AUC封装了许多用于评估的有用信息，但它不是一个万能的衡量标准。我们进行了实验来支持这一说法，并使用ROC-AUC的概率解释提供了理论依据。由此，我们得出结论，在处理数据不平衡时，AUPRC可以为我们提供更多的信息。</p><p id="6ecb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，ROC在评估通用分类时是有用的，而AUPRC在分类罕见事件时是更好的方法。</p><p id="3469" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一个旁注，我们提到在高度不平衡的数据中的分类有时更适合作为一个积极的检索任务。在下一篇文章中，我们将回顾专门为这类任务定制的排名方法——如果你有兴趣，可以考虑关注我。</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><h2 id="848d" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">参考</h2><ol class=""><li id="652a" class="mz na iq ky b kz ml lc mm lf oo lj op ln oq lr or nf ng nh bi translated">戴维斯、杰西和马克·戈德里奇。"<a class="ae kv" href="https://www.biostat.wisc.edu/~page/rocpr.pdf" rel="noopener ugc nofollow" target="_blank">精确回忆与ROC曲线的关系</a>"<em class="mq"> ICML </em>。2006.</li><li id="fab4" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr or nf ng nh bi translated"><a class="ae kv" href="https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/132777/what-does-AUC-stand-for-and-what-is-it</a></li><li id="4572" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr or nf ng nh bi translated">巴克利，克里斯和埃伦m .沃尔赫斯。"评估评估措施的稳定性."ACM SIGIR论坛。2017.</li><li id="da83" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr or nf ng nh bi translated"><a class="ae kv" href="https://stats.stackexchange.com/questions/180638/how-to-derive-the-probabilistic-interpretation-of-the-auc" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/180638/how-to-derive-the-probabilical-interpretation-of-the-AUC</a></li><li id="28a8" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr or nf ng nh bi translated"><a class="ae kv" href="https://stats.stackexchange.com/questions/190216/why-is-roc-auc-equivalent-to-the-probability-that-two-randomly-selected-samples" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/190216/why-is-roc-AUC-equivalent-to-the-probability-that-two-random-selected-samples</a></li></ol></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="7b8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！我很想听听你的想法和评论😃</p></div></div>    
</body>
</html>