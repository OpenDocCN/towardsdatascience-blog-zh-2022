<html>
<head>
<title>Causal Inference with Linear Regression: Endogeneity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归因果推断:内生性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/causal-inference-with-linear-regression-endogeneity-9d9492663bac#2022-05-18">https://towardsdatascience.com/causal-inference-with-linear-regression-endogeneity-9d9492663bac#2022-05-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0d58" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">关于外生变量、<strong class="ak">外生变量、遗漏变量、测量误差和</strong>同时偏差的讨论</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/fca1db6133b0b3c536c60d9bc8d23099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/0*Gea_2cLlP1TUPNoZ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">作者图片</p></figure><p id="be39" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我的<a class="ae lq" rel="noopener" target="_blank" href="/understand-bias-and-variance-in-causal-inference-with-linear-regression-a02e0a9622bc">上一篇文章</a>中，我们讨论了设计线性回归时的一些常见问题——<strong class="kw iu">省略重要变量</strong>和<strong class="kw iu">包括无关变量。</strong>在本文中，我们将讨论线性回归模型中的<strong class="kw iu">内生性</strong>，尤其是在<strong class="kw iu">因果推断</strong>的背景下。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><p id="54e4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">线性回归模型是一种常用工具，用于绘制反应变量(Y)和治疗变量(即T)之间的因果关系，同时控制其他协变量(如X)，如下所示。治疗效果(即α)的偏差(准确度)和方差(精确度)是此类研究的重点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ly"><img src="../Images/db3f84a66a26a92977e919d2461b3cd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HjyHSko0Ymwa8d-rZy18yQ.png"/></div></div></figure><h2 id="1276" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated">什么是<strong class="ak">内生性？</strong></h2><blockquote class="mw mx my"><p id="2821" class="ku kv mz kw b kx ky ju kz la lb jx lc na le lf lg nb li lj lk nc lm ln lo lp im bi translated"><strong class="kw iu">内生性</strong>是指线性回归模型中的预测因子(如治疗变量)<strong class="kw iu">与误差项</strong>相关的情况。</p></blockquote><p id="bb02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你称这样的预测器为<strong class="kw iu">内生变量。</strong>内生变量的系数估计<strong class="kw iu">不再蓝</strong>(最佳线性无偏估计量)因为内生性违背了线性回归的经典假设之一——<em class="mz">所有的自变量都与误差项不相关。</em></p><p id="acb2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另一方面，如果一个变量没有被模型中的其他变量(例如，响应变量、其他解释变量和误差项)解释，则该变量被称为<strong class="kw iu">外生变量</strong>。外生变量由模型之外的因素决定。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h2 id="90aa" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated">内生性的来源有哪些？</h2><p id="f2ea" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">内生性有多种来源。内生性的常见来源可分为:省略变量、同时性和测量误差。</p><h2 id="b96e" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated"><strong class="ak">来源1:省略变量</strong></h2><p id="e20a" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">如果变量Z与响应变量和预测变量都相关，我们称这样的变量为<strong class="kw iu">混杂变量。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ni"><img src="../Images/d3257de84d54273510e688a5663b2816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hy78guz7yUFSxN4f3MRQcA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图1(作者图片)</p></figure><blockquote class="mw mx my"><p id="fa30" class="ku kv mz kw b kx ky ju kz la lb jx lc na le lf lg nb li lj lk nc lm ln lo lp im bi translated">如果一个混杂变量Z在线性回归模型中被<strong class="kw iu">省略</strong>，那么受影响的预测因子(如治疗变量)将成为<strong class="kw iu">内生的</strong>，因为在这种情况下，<em class="it">“无法解释的”变量Z漏入误差项，那么受影响的预测因子将是</em> <strong class="kw iu"> <em class="it">与误差项</em>相关的 </strong> <em class="it">。</em></p></blockquote><p id="286d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果由于省略变量而存在内生性，<a class="ae lq" rel="noopener" target="_blank" href="/understand-bias-and-variance-in-causal-inference-with-linear-regression-a02e0a9622bc">对受影响变量(如治疗变量)的估计会变得有偏差(即<strong class="kw iu">省略变量偏差</strong>)。</a>见证明<a class="ae lq" rel="noopener" target="_blank" href="/understand-bias-and-variance-in-causal-inference-with-linear-regression-a02e0a9622bc">此处</a>。这意味着我们有一个<strong class="kw iu">不准确的</strong>因果效应。</p><p id="cfac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果混杂变量Z在线性回归模型中添加了<strong class="kw iu">和</strong>，那么受影响的预测因子(如治疗变量)将不再是内源性的<strong class="kw iu">。因此，对治疗效果的系数估计将不再有偏差。</strong></p><h2 id="a45d" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated">来源2: S <strong class="ak">不一致性</strong></h2><p id="e551" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">同时性是内生性的另一个常见原因。当一个或多个预测因子(如治疗变量)由反应变量(Y)决定时，同时性出现。简单来说，X导致Y，Y导致X，例如，我们可以用教育水平来解释家庭收入，因为受过高等教育的人往往挣得更多。同时，我们知道收入较高的人更容易负担得起高等教育。</p><p id="e549" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通常这种关系可以通过<strong class="kw iu">联立方程</strong>(也称为<strong class="kw iu">结构方程</strong>)来解释。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nj"><img src="../Images/2ec78d9b88ed15f5978446d04d3256b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Y7edV5n1XxukY94bJx1nQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图2(作者图片)</p></figure><p id="adac" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过求解上面的两个方程，我们得到了模型的简化形式</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nk"><img src="../Images/aaa917a42a66d45e043a253a2dadf5b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTs3vuhki3p_o16uFhbLzA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图3(作者图片)</p></figure><p id="2e6a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在因果推断的背景下，如果治疗效果X由响应变量决定，那么很容易看出治疗效果与图2中的误差项u相关联。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nl"><img src="../Images/c4dbef7d3cf3e1665d2937c0bf2e1c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qRu-Kfq_ffqm2T1Licz4BA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图4(作者图片)</p></figure><p id="abc7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，如果我们应用图2中的OLS，治疗效果和反应变量都是内生变量。这会导致对治疗效果的估计有偏差(即<strong class="kw iu">同时偏差</strong>)。所以治疗效果永远不可能是真正的效果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nm"><img src="../Images/1d5be764df73d5b6df149bbae1b51a9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sOcpdlA71A53E9XBXw5Y5w.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图5(作者图片)</p></figure><h2 id="c54b" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated">来源3:测量误差</h2><p id="eaa7" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">在线性回归模型中，假设观测值被正确测量，没有任何误差。在许多情况下，这种假设是违反的。一些变量(例如，人们锻炼的能力和意愿)可能无法衡量，那么我们使用<strong class="kw iu">代理变量</strong>(例如，人们的智商得分和在健身房的小时数)来衡量效果。有时候，很难做出正确的观察。例如，年龄变量通常以整数记录，而月和日通常被忽略。在这些情况下，变量的真实值不包括在模型中。<em class="mz">变量的观测值与真值之差称为</em> <strong class="kw iu"> <em class="mz">测量误差</em> </strong> <em class="mz">。</em></p><p id="c41b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">情景一</strong>:当测量误差在<strong class="kw iu">因变量Y </strong>中时，它<strong class="kw iu">不会引起内生性</strong>，因为在这种情况下，无法解释的测量误差是外生变量，与包含的解释变量无关。因此，即使无法解释的测量误差泄漏到误差项，解释变量也不会与误差项相关联。</p><p id="44c9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">情景二</strong>:相比之下，当测量误差在<strong class="kw iu">解释变量</strong>中时，内生性的问题就产生了。</p><p id="0cf3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">假设<strong class="kw iu"> X* </strong>是观察到的解释变量，而<strong class="kw iu"> X </strong>是变量的真实值。X*和X之间的关系可以解释如下，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nn"><img src="../Images/9cad032d41783a702ddd7559532ae55f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MitQBFmJNBCqhytWCJXtaA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图6(作者图片)</p></figure><p id="052a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们照常建立线性回归，不包括测量误差项v，因为它是不可测量的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi no"><img src="../Images/e00c4206ffd3e5d090bf7766eb29999d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QKTScrsEVwsPZt4vlET9jQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图7(作者图片)</p></figure><p id="738c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那么我们实际估算的模型是</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi np"><img src="../Images/6faab75fb26f17ed219df7361ab36f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avnZRqFp5ccNvUHNoW78mA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图8(作者图片)</p></figure><p id="0338" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">通过一些数学，我们可以发现X*与实际误差项u相关，然后内生性发生。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nq"><img src="../Images/7ff3dc003a2738b994ea1a86e962417c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrUE7bbv-3E-yzX1z5sJ3g.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图9(作者图片)</p></figure><p id="2eb1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在图9中，Cov(X，v)为0，因为测量误差与自变量X无关，Cov(X，ε)和Cov(v，ε)都为0，因为ε与X无关，而ε与测量误差不太相关。</p><blockquote class="mw mx my"><p id="b418" class="ku kv mz kw b kx ky ju kz la lb jx lc na le lf lg nb li lj lk nc lm ln lo lp im bi translated">那么在有测量误差的线性回归中，OLS估计量β_hat不再是无偏的。此外，估计器将总是被低估(例如<strong class="kw iu">衰减偏差</strong>)。</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi nr"><img src="../Images/9dacd016844827421d1ace109e6cfa5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Q5vjfZCIqHUjvQjrKJ20g.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图10(作者图片)</p></figure></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h2 id="3a49" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated"><strong class="ak">内生性</strong>的补救方法是什么<strong class="ak">？</strong></h2><p id="6fde" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">在线性回归模型中处理内生性的一种流行方法是通过<strong class="kw iu">两阶段最小二乘法(2SLS) </strong>引入一个或多个<strong class="kw iu">工具变量</strong>。</p><p id="709b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们定义这个工具变量Z:</p><ul class=""><li id="f2a9" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated">z与模型中的任何其他协变量(包括误差项)都不相关</li><li id="581c" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">z与受影响的预测因子(如治疗变量)有意义且强相关，因此通过X间接影响Y</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi og"><img src="../Images/a5cab582943a29a78664ed177c6cdf36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvNJoEHQokz1KmZIZV2fkA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图11(作者图片)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oh"><img src="../Images/fa85fb756ad8391f5f7d9c6901f4eb8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9cPCusDBAYf7Y6lpgxeIQ.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图12(作者图片)</p></figure><p id="4d15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在实践中，工具变量(IV)模型可以分两步实施(2sl):</p><ul class=""><li id="716f" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated">步骤1:我们回归受影响的预测因子x的工具变量。请记住，我们需要IV和x之间有很强的相关性。否则，我们可能仍然对受影响的预测因子有偏差。</li><li id="f871" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated">第二步:我们在第一步拟合的X和其他协变量上回归Y。我们从步骤2中得到的估计值将比图11中的估计值更加准确和一致。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi oi"><img src="../Images/c6ff67f2491d007a2164fd73da8cf1eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y_QYK3JuokoLrZCHpL25NA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图13(作者图片)</p></figure><h2 id="4426" class="md me it bd mf mg mh dn mi mj mk dp ml ld mm mn mo lh mp mq mr ll ms mt mu mv bi translated">最终注释</h2><p id="1c48" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">当使用线性回归模型进行因果推断时，内生性是我们需要解决的问题，否则，我们会由于遗漏变量、同时性或测量误差而得到有偏差的处理效果。</p><p id="deb0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你对<strong class="kw iu">线性回归</strong>和<strong class="kw iu">因果推断</strong>感兴趣，这里有一些相关的帖子可以浏览。</p><ul class=""><li id="4eef" class="ns nt it kw b kx ky la lb ld nu lh nv ll nw lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/causal-inference-econometric-models-vs-a-b-testing-190781fe82c5"> <strong class="kw iu">因果推断:计量经济模型vs. A/B检验</strong> </a></li><li id="0b7c" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/linear-regression-vs-logistic-regression-ols-maximum-likelihood-estimation-gradient-descent-bcfac2c7b8e4"> <strong class="kw iu">线性回归与逻辑回归:OLS、最大似然估计、梯度下降</strong> </a></li><li id="c874" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/linear-regression-with-ols-unbiased-consistent-blue-best-efficient-estimator-359a859f757e"><strong class="kw iu">OLS线性回归:无偏、一致、蓝色、最佳(有效)估计量</strong> </a></li><li id="c16e" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/understand-bias-and-variance-in-causal-inference-with-linear-regression-a02e0a9622bc"> <strong class="kw iu">线性回归因果推断:省略变量和无关变量</strong> </a></li><li id="da61" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/causal-inference-with-linear-regression-endogeneity-9d9492663bac"> <strong class="kw iu">用线性回归进行因果推断:内生性</strong> </a></li><li id="974f" class="ns nt it kw b kx ob la oc ld od lh oe ll of lp nx ny nz oa bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/linear-regression-with-ols-heteroskedasticity-and-autocorrelation-c12f1f65c13"> <strong class="kw iu">与OLS的线性回归:异方差和自相关</strong> </a></li></ul><h1 id="a11d" class="oj me it bd mf ok ol om mi on oo op ml jz oq ka mo kc or kd mr kf os kg mu ot bi translated">感谢您的阅读！！！</h1><p id="2934" class="pw-post-body-paragraph ku kv it kw b kx nd ju kz la ne jx lc ld nf lf lg lh ng lj lk ll nh ln lo lp im bi translated">如果你喜欢这篇文章，并且想<strong class="kw iu">请我喝杯咖啡，请<a class="ae lq" href="https://ko-fi.com/aaronzhu" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</strong></p><p id="a934" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">您可以注册一个<a class="ae lq" href="https://aaron-zhu.medium.com/membership" rel="noopener"> <strong class="kw iu">会员</strong> </a>来解锁我的文章的全部访问权限，并且可以无限制地访问介质上的所有内容。如果你想在我发表新文章时收到电子邮件通知，请<a class="ae lq" href="https://aaron-zhu.medium.com/subscribe" rel="noopener"> <strong class="kw iu">订阅</strong> </a>。</p></div></div>    
</body>
</html>