<html>
<head>
<title>How to Save Trained Models on Disk with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 Python 在磁盘上保存训练好的模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/save-trained-models-python-22a11376d975#2022-02-26">https://towardsdatascience.com/save-trained-models-python-22a11376d975#2022-02-26</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="c66c" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">用 scikit 探索模型持久性——在 Python 中学习</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/ddf5e693390ce6dbcc3012abe4559eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNJJ5KI9usGY1Q7weYpO1w.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">图为<a class="ae kz" href="https://unsplash.com/@filmlav?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">费尔南多·拉文</a>在<a class="ae kz" href="https://unsplash.com/s/photos/save?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><h2 id="43fc" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">介绍</h2><p id="26a7" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">当开发机器学习模型时，我们使用所谓的训练集中包含的数据点来训练它们。通常，我们需要在磁盘上保存一个训练好的模型，以便以后将它加载回内存中。这可能需要发生，因为我们想要在不同的数据集上评估模型的性能，或者可能因为我们想要进行一些小的修改。</p><p id="0a31" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">在今天的简短教程中，我们将展示如何在磁盘上存储经过训练的<code class="fe mu mv mw mx b">scikit-learn</code>模型。此外，我们还将讨论如何将预先训练好的模型加载回内存中，并在新的实例上运行它(例如，测试或验证集中可能包含的数据点)。</p></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><p id="2148" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">首先，让我们训练一个示例模型，我们将在本教程中引用它来演示一些概念。我们将使用<a class="ae kz" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html" rel="noopener ugc nofollow" target="_blank">鸢尾数据集</a>(它也包含在<code class="fe mu mv mw mx b">scikit-learn</code>的<code class="fe mu mv mw mx b">datasets</code>模块中，所以如果你想按照本教程学习，你不必依赖外部资源)来训练 K-Neighbors 分类器，以便根据花瓣和萼片的长度和宽度来预测数据集(<em class="nf"> Setosa </em>、<em class="nf"> Versicolour </em>和<em class="nf"> Virginica </em>)中包含的鸢尾的类型。</p><p id="54f0" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">现在，让我们开始加载我们的 Iris 数据集，并创建一个训练和测试集(如果您想了解更多关于如何将数据集分为训练、测试和验证测试的信息，您可以阅读我的一篇旧文章):</p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="3ef3" class="la lb iu mx b gz nk nl l nm nn">import numpy as np<br/>from sklearn import datasets<br/></span><span id="edb0" class="la lb iu mx b gz no nl l nm nn"># Load the Iris Dataset<br/>iris_X, iris_y = datasets.load_iris(return_X_y=True)<br/></span><span id="4c5f" class="la lb iu mx b gz no nl l nm nn"># Split the data into training and testing sets<br/># Note that we use a fixed seed so that results<br/># are reproducible</span><span id="9a22" class="la lb iu mx b gz no nl l nm nn">np.random.seed(0)<br/>indices = np.random.permutation(len(iris_X))</span><span id="52d5" class="la lb iu mx b gz no nl l nm nn">iris_X_train = iris_X[indices[:-10]]<br/>iris_y_train = iris_y[indices[:-10]]<br/>iris_X_test = iris_X[indices[-10:]]<br/>iris_y_test = iris_y[indices[-10:]]</span></pre><p id="99f7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">然后，我们使用在上一步中创建的一组训练实例来训练 K-Neighbors 分类器:</p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="a884" class="la lb iu mx b gz nk nl l nm nn">from sklearn.neighbors import KNeighborsClassifier<br/></span><span id="dbb8" class="la lb iu mx b gz no nl l nm nn">knn = KNeighborsClassifier()<br/>knn.fit(iris_X_train, iris_y_train)</span></pre></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><h2 id="ec5b" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">保存已训练的模型</h2><p id="71bc" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated"><strong class="ly iv">酸洗</strong>是 Python 中使用的一个过程，目的是<strong class="ly iv">将对象序列化(或反序列化)成字节流</strong>。机器学习模型也是对象，因此我们可以利用酸洗方法将它们存储在本地磁盘上。</p><p id="fef0" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">在 Python 中，你可以使用<code class="fe mu mv mw mx b"><a class="ae kz" href="https://docs.python.org/3/library/pickle.html" rel="noopener ugc nofollow" target="_blank">pickle</a></code>或<code class="fe mu mv mw mx b"><a class="ae kz" href="https://joblib.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">joblib</a></code>库来挑选对象。请注意，<code class="fe mu mv mw mx b"><strong class="ly iv">joblib</strong></code> <strong class="ly iv">在对携带大型数组</strong>的对象进行序列化(解序列化)时效率更高(这在使用<code class="fe mu mv mw mx b">scikit-learn</code>模型/估算器时很常见)。注意，与<code class="fe mu mv mw mx b">pickle</code>相反，<code class="fe mu mv mw mx b">joblib</code>也可以 pickle 磁盘上的对象(而不是字符串对象)。</p><p id="221f" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">下面我们将演示如何持久化模型以供将来使用，而不必使用两个库进行重新训练。</p></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><p id="2571" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">使用</strong> <code class="fe mu mv mw mx b"><strong class="ly iv">pickle</strong></code></p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="a74b" class="la lb iu mx b gz nk nl l nm nn">import pickle</span><span id="30c9" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv">with open('my_trained_model.pkl', 'wb') as f:<br/>    pickle.dump(knn, f)</strong></span></pre><p id="266b" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">使用</strong>和<code class="fe mu mv mw mx b"><strong class="ly iv">joblib</strong></code></p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="04d1" class="la lb iu mx b gz nk nl l nm nn">import joblib</span><span id="01cd" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv">joblib.dump(knn, 'my_trained_model.pkl', compress=9)</strong></span></pre><p id="aba7" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">注意<code class="fe mu mv mw mx b">compress</code>参数可以取 0 到 9 之间的整数值。较高的值意味着更多的压缩，但也意味着较慢的读写时间。</p></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><h2 id="3636" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">从磁盘加载预训练模型</h2><p id="0e1a" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">现在，为了从磁盘加载回预先训练好的模型，你需要解开字节流。同样，我们将展示如何使用<code class="fe mu mv mw mx b">pickle</code>和<code class="fe mu mv mw mx b">joblib</code>库来做到这一点。</p><p id="b547" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">使用</strong> <code class="fe mu mv mw mx b"><strong class="ly iv">pickle</strong></code></p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="f3a8" class="la lb iu mx b gz nk nl l nm nn">import pickle</span><span id="c94b" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv">with open('my_trained_model.pkl', 'rb') as f:<br/>    knn = pickle.load(f)</strong></span></pre><p id="c99c" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">使用</strong> <code class="fe mu mv mw mx b"><strong class="ly iv">joblib</strong></code></p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="4ece" class="la lb iu mx b gz nk nl l nm nn">import joblib</span><span id="1056" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv">knn = load('</strong><strong class="mx iv">my_trained_model.pkl</strong><strong class="mx iv">')</strong></span></pre></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><h2 id="240f" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">在新数据点上运行加载的模型</h2><p id="e9bd" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">现在，一旦我们加载回(即解除)预训练的 scikit-learn 模型，我们就可以在本教程开始时准备的测试集上运行它。</p><p id="a5f9" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">下面我们演示一个端到端的例子，包含今天教程中用到的全部代码</p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="3a36" class="la lb iu mx b gz nk nl l nm nn">import joblib<br/>import numpy as np<br/>from sklearn import datasets<br/>from sklearn.neighbors import KNeighborsClassifier<br/></span><span id="cf96" class="la lb iu mx b gz no nl l nm nn"># Load the Iris Dataset<br/>iris_X, iris_y = datasets.load_iris(return_X_y=True)</span><span id="ad5b" class="la lb iu mx b gz no nl l nm nn"># Split the data into training and testing sets<br/># Note that we use a fixed seed so that results<br/># are reproducible</span><span id="65e8" class="la lb iu mx b gz no nl l nm nn">np.random.seed(0)<br/>indices = np.random.permutation(len(iris_X))</span><span id="2849" class="la lb iu mx b gz no nl l nm nn">iris_X_train = iris_X[indices[:-10]]<br/>iris_y_train = iris_y[indices[:-10]]<br/>iris_X_test = iris_X[indices[-10:]]<br/>iris_y_test = iris_y[indices[-10:]]<br/></span><span id="a514" class="la lb iu mx b gz no nl l nm nn"># Fit the classifier<br/>knn = KNeighborsClassifier()<br/>knn.fit(iris_X_train, iris_y_train)</span><span id="4d7f" class="la lb iu mx b gz no nl l nm nn"><br/># Persist the trained model on the local disk<br/>joblib.dump(knn, 'my_trained_model.pkl', compress=9)</span><span id="3781" class="la lb iu mx b gz no nl l nm nn"># Load the trained model from the disk<br/>knn = load('<!-- -->my_trained_model.pkl<!-- -->')</span><span id="e4ba" class="la lb iu mx b gz no nl l nm nn"># Make predictions on the loaded pre-trained model<br/>knn.predict(iris_X_test)</span></pre></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><h2 id="78f3" class="la lb iu bd lc ld le dn lf lg lh dp li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最后的想法</h2><p id="f311" class="pw-post-body-paragraph lw lx iu ly b lz ma jv mb mc md jy me lj mf mg mh ln mi mj mk lr ml mm mn mo in bi translated">在今天的文章中，我们讨论了保存经过训练的机器学习模型的重要性，以便它们可以在以后使用。我们使用一个示例<code class="fe mu mv mw mx b">scikit-learn</code>模型展示了如何做到这一点，我们最初将它存储在本地磁盘上，然后将其加载回内存，以便在新的、不可见的数据集上运行它，这些数据集包括在我们一开始准备的示例测试集中。</p><p id="58c8" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated">请注意，在某些情况下(主要与文本分类任务相关)，您可能还希望持久化 vectoriser。您可以通过使用包含矢量器和训练模型的元组来实现，如下所示:</p><pre class="kk kl km kn gu ng mx nh ni aw nj bi"><span id="68dc" class="la lb iu mx b gz nk nl l nm nn">import pickle</span><span id="e462" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv"># Pickle the vectorizer and the classifier</strong><br/>with open('trained_model_with_vecotizer.pkl', 'wb') as f:<br/>  pickle.dump((vectorizer, clf), f)</span><span id="4463" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv"># Unpickle the vectorizer and the classifier</strong><br/>with open('trained_model_with_vecotizer.pkl', 'rb') as f:<br/>  vectorizer, clf = pickle.load(f)</span><span id="463d" class="la lb iu mx b gz no nl l nm nn"><strong class="mx iv"># Vectorize the testing instances and perform predictions</strong><br/>X_test = vectorizer.transform(X_test)<br/>predictions = clf.predict(X_test)</span></pre></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><p id="1b77" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><a class="ae kz" href="https://gmyrianthous.medium.com/membership" rel="noopener"> <strong class="ly iv">成为会员</strong> </a> <strong class="ly iv">阅读介质上的每一个故事。你的会员费直接支持我和你看的其他作家。你也可以在媒体上看到所有的故事。</strong></p><div class="np nq gq gs nr ns"><a href="https://gmyrianthous.medium.com/membership" rel="noopener follow" target="_blank"><div class="nt ab fp"><div class="nu ab nv cl cj nw"><h2 class="bd iv gz z fq nx fs ft ny fv fx it bi translated">通过我的推荐链接加入 Medium-Giorgos Myrianthous</h2><div class="nz l"><h3 class="bd b gz z fq nx fs ft ny fv fx dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="oa l"><p class="bd b dl z fq nx fs ft ny fv fx dk translated">gmyrianthous.medium.com</p></div></div><div class="ob l"><div class="oc l od oe of ob og kt ns"/></div></div></a></div></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><p id="676e" class="pw-post-body-paragraph lw lx iu ly b lz mp jv mb mc mq jy me lj mr mg mh ln ms mj mk lr mt mm mn mo in bi translated"><strong class="ly iv">你可能也会喜欢</strong></p><div class="np nq gq gs nr ns"><a rel="noopener follow" target="_blank" href="/predict-vs-predict-proba-scikit-learn-bdc45daa5972"><div class="nt ab fp"><div class="nu ab nv cl cj nw"><h2 class="bd iv gz z fq nx fs ft ny fv fx it bi translated">scikit-learn 中的 predict()和 predict_proba()有什么区别？</h2><div class="nz l"><h3 class="bd b gz z fq nx fs ft ny fv fx dk translated">如何对数据集使用 predict 和 predict_proba 方法来执行预测</h3></div><div class="oa l"><p class="bd b dl z fq nx fs ft ny fv fx dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="oh l od oe of ob og kt ns"/></div></div></a></div></div><div class="ab cl my mz hy na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="in io ip iq ir"><div class="kk kl km kn gu ns"><a rel="noopener follow" target="_blank" href="/scikit-learn-vs-sklearn-6944b9dc1736"><div class="nt ab fp"><div class="nu ab nv cl cj nw"><h2 class="bd iv gz z fq nx fs ft ny fv fx it bi translated">Scikit-Learn 和 Sklearn 有区别吗？</h2><div class="nz l"><h3 class="bd b gz z fq nx fs ft ny fv fx dk translated">Python 中的 scikit-learn vs sklearn</h3></div><div class="oa l"><p class="bd b dl z fq nx fs ft ny fv fx dk translated">towardsdatascience.com</p></div></div><div class="ob l"><div class="oi l od oe of ob og kt ns"/></div></div></a></div></div></div>    
</body>
</html>