<html>
<head>
<title>Understanding Omitted Variable Bias</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解遗漏变量偏差</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/omitted-variable-bias-and-what-can-we-do-about-it-344ac1477699#2022-05-24">https://towardsdatascience.com/omitted-variable-bias-and-what-can-we-do-about-it-344ac1477699#2022-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="de33" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/causal-data-science" rel="noopener" target="_blank">因果数据科学</a></h2><div class=""/><div class=""><h2 id="25fe" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">最普遍的偏见类型的逐步指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/972c74faabdc0b3a47b5b39acf8c925d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZp5vyPIS2yPF-XYA9aq-Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="05b7" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在因果推理中，<strong class="lg ja">偏差</strong>是非常成问题的，因为它使推理无效。偏差通常意味着估计者不会给出因果效应的平均估计值。</p><p id="081b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这就是为什么，一般来说，我们更喜欢<strong class="lg ja">无偏</strong>的估值器，代价是更高的方差，也就是更多的噪声。是不是说每个有偏估计量都没用？实际上不是。有时，有了领域知识，我们仍然可以得出因果结论，即使是有偏见的估计。</p><p id="e139" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在本帖中，我们将回顾一个具体但常见的偏差来源，<strong class="lg ja">省略变量偏差(OVB) </strong>。我们将探索偏见的原因，并利用这些见解做出因果陈述，尽管存在偏见。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="47c8" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">理论</h1><p id="f83d" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">假设我们对变量<em class="ne"> D </em>对变量<em class="ne"> y </em>的影响感兴趣。然而，还有第三个变量<em class="ne"> Z </em>我们没有观察到，它与<em class="ne"> D </em>和<em class="ne"> y </em>都相关。假设数据生成过程可以用下面的<a class="ae nf" rel="noopener" target="_blank" href="/b63dc69e3d8c"> <strong class="lg ja">有向无环图(DAG) </strong> </a>来表示。如果你不熟悉DAGs，我在这里写了一个简短的<a class="ae nf" rel="noopener" target="_blank" href="/b63dc69e3d8c">介绍</a>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ng"><img src="../Images/b6111ebecce2d0309bcc2d91ee577fc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OFFeoPxNJU3xkyIlECZkwQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="56fc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于从<em class="ne"> D </em>到<em class="ne"> y </em>有一条<a class="ae nf" rel="noopener" target="_blank" href="/b63dc69e3d8c"> <strong class="lg ja">后门路径</strong> </a>经过<em class="ne"> Z </em>，我们需要以<em class="ne"> Z </em>为条件进行分析，以恢复<em class="ne"> D </em>对<em class="ne"> y </em>的因果关系。如果我们可以观察到<em class="ne"> Z </em>，我们将在<em class="ne"> D </em>和<em class="ne"> Z </em>上运行<em class="ne"> y </em>的线性回归来估计以下模型:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nh"><img src="../Images/0b503a72636397c9c58e7f2b0e382873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MrwXxWnn22-fsJaCKNyQLw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="91a4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中<em class="ne"> α </em>为利息的影响。这种回归通常被称为<strong class="lg ja">长回归</strong>，因为它包括模型的所有变量。</p><p id="4918" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，由于我们没有观察到<em class="ne"> Z </em>，我们不得不估计以下模型:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ni"><img src="../Images/0e8b981db0113d4b6fdca60de61b6ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RA4ur01GpgV2-cQlIU218Q.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="ec0a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">相应的回归通常被称为<strong class="lg ja">短回归</strong>，因为它不包括模型的所有变量。</p><p id="3e5b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">估计短回归而不是长回归的<strong class="lg ja">后果</strong>是什么？简而言之，我们不能给估计的系数一个<strong class="lg ja">因果解释</strong>。</p><p id="dcf5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这种情况下，<em class="ne"> α </em>的OLS估计量为</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nj"><img src="../Images/c794fd7e1ce0f4e7997750977c42ddc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7xcCPZjNud8WU5Fozo6B3A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="aefe" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，我们可以把<strong class="lg ja">省略变量偏差</strong>写成</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/00245cbdf18b1f3fe1596af852c05186.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bk2tL5b8jUGWG1SRygnpiw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="8977" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这个公式的美妙之处在于它的<strong class="lg ja">可解释性</strong>:被省略的变量bias仅由两个部分组成<strong class="lg ja">，两者都非常容易解释。</strong></p><ul class=""><li id="ee16" class="nl nm iq lg b lh li lk ll ln nn lr no lv np lz nq nr ns nt bi translated"><em class="ne">γ</em>:Z<em class="ne">对y<em class="ne">的影响</em></em></li><li id="f08f" class="nl nm iq lg b lh nu lk nv ln nw lr nx lv ny lz nq nr ns nt bi translated"><em class="ne">δ</em>:D<em class="ne">对Z </em>的影响</li></ul><p id="68dc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请注意，这是一个<strong class="lg ja">渐近偏差</strong>，这意味着随着样本量的增长，估计量不会收敛到它应该估计的参数(estimand)。或者，我们可以说估计量是<strong class="lg ja">不</strong> <a class="ae nf" href="https://en.wikipedia.org/wiki/Consistency_(statistics)" rel="noopener ugc nofollow" target="_blank"> <strong class="lg ja">一致</strong> </a>。</p><h2 id="3068" class="nz mi iq bd mj oa ob dn mn oc od dp mr ln oe of mt lr og oh mv lv oi oj mx iw bi translated">附加控制</h2><p id="1549" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">如果我们在回归中有<strong class="lg ja">个额外的控制变量</strong>会发生什么？例如，假设除了感兴趣的变量<em class="ne"> D </em>之外，我们还观察到其他变量的向量<em class="ne"> X </em>，因此<strong class="lg ja">长回归</strong>为</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nk"><img src="../Images/e67667618d0f072427acbf85906eb4e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bdwE783EJPEEBqeEQ8oV3A.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="7094" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于有了<a class="ae nf" rel="noopener" target="_blank" href="/59f801eb3299"> <strong class="lg ja">弗里希-沃-洛厄尔定理</strong> </a>，我们可以简单地将<strong class="lg ja">部分剔除</strong> <em class="ne"> X </em>并用<em class="ne"> D </em>和<em class="ne"> Z </em>来表示省略的变量bias。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ok"><img src="../Images/b77770bb9a8c49dae08284ce3aa0664f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tn30b1u61Nk3UHCXeIsHOA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="9483" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">其中<em class="ne"> D⊥X </em>是从<em class="ne"> X </em>上回归<em class="ne"> D </em>的残差，而<em class="ne"> Z⊥X </em>是从<em class="ne"> X </em>上回归<em class="ne"> Z </em>的残差。如果你不熟悉弗里希-沃-洛厄尔定理，我在这里写了一个简短的<a class="ae nf" rel="noopener" target="_blank" href="/59f801eb3299">注释</a>。</p><p id="42a3" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">Chernozhukov、西内利、纽伊、夏尔马和Syrgkanis (2022) 进一步将分析概括为处理变量<em class="ne"> D </em>、控制变量<em class="ne"> X、</em>和未观察变量<em class="ne"> Z </em>以非参数方式进入长模型的设置，即没有特定的函数形式。你可以在他们的论文中找到更多的细节，但是基本思想是一样的。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="0df9" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">例子</h1><p id="14e7" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">假设我们是一名对教育和工资之间的关系感兴趣的研究员。从未来的工资来看，投资教育有回报吗？假设我们有受教育年限不同的人的工资数据。为什么不看看受教育年限和工资的相关性？</p><p id="7212" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">问题是可能有许多<strong class="lg ja">未观察到的变量</strong>与教育和工资都相关。为了简单起见，我们集中讨论一下<strong class="lg ja">能力</strong>。能力较高的人可能会决定在教育上投入更多，只是因为他们在学校表现更好，获得更多机会。另一方面，他们也可能会获得更高的工资，纯粹是因为他们天生的能力。</p><p id="dbfc" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以用下面的<strong class="lg ja">有向无环图</strong> (DAG)来表示数据生成过程。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ol"><img src="../Images/7767b95e6f08f5aeae54a654431b408c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUsJC2RKsezKc2iZrFz2mA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="d720" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们加载并检查<strong class="lg ja">数据</strong>。我从<code class="fe om on oo op b"><a class="ae nf" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py" rel="noopener ugc nofollow" target="_blank">src.dgp</a></code>导入数据生成过程，从<code class="fe om on oo op b"><a class="ae nf" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py" rel="noopener ugc nofollow" target="_blank">src.utils</a></code>导入一些绘图函数和库。</p><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="d2cc" class="nz mi iq op b gy ou ov l ow ox">from src.utils import *<br/>from src.dgp import dgp_educ_wages<br/><br/>df = dgp_educ_wages().generate_data(N=50)<br/>df.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/4f4bec5a0274bd8acdc495f8e0e7b88e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*at8s8WNcV2dQZxXCpwUfgQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="af5e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们有300个人的信息，我们观察他们的T2、T3、T4和当前的T5。</p><p id="cad5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">假设我们在<code class="fe om on oo op b">education</code>上直接回归<code class="fe om on oo op b">wage</code>。</p><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="4305" class="nz mi iq op b gy ou ov l ow ox">short_model = smf.ols('wage ~ education + gender + age', df).fit()<br/>short_model.summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi oz"><img src="../Images/53fd7b7308fcd861b9cbbcf5b4097660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y5YF8TrtLV-MHExksn8vPw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="860f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe om on oo op b">education</code>的系数为正且显著。然而，我们知道可能有一个<strong class="lg ja">遗漏变量偏差</strong>，因为我们没有观察到<code class="fe om on oo op b">ability</code>。就Dag而言，从<code class="fe om on oo op b">education</code>到<code class="fe om on oo op b">wage</code>有一条<strong class="lg ja">后门路径</strong>通过<code class="fe om on oo op b">ability</code>未被阻塞，因此会使我们的估计产生偏差。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/9a5cd08882cefa64c5d7574ac7ebc49d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSHLxVtXalvdfM-nQGUn2w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="a72d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">是不是说我们所有的分析都是<strong class="lg ja">垃圾</strong>？我们还能从回归结果中得出一些因果结论吗？</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="b0bd" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">偏向的方向</h1><p id="9e5d" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">如果我们知道<em class="ne"> γ </em>和<em class="ne"> δ </em>的符号，我们可以推断偏差的符号，因为它是两个符号的乘积。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/6b51a421a3e1e2381eb368383a4560b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpzOQ44RnFxc9JGreV2WLQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="092a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们的例子中</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/0db7b4d5781c56d87eddf8a125fb4648.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LWoPP4-2RV00tdkgHUKqlA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="fc93" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们分别分析这两种相关性:</p><ul class=""><li id="734c" class="nl nm iq lg b lh li lk ll ln nn lr no lv np lz nq nr ns nt bi translated"><code class="fe om on oo op b">ability</code>和<code class="fe om on oo op b">wage</code>之间的相关性很可能是正的</li><li id="29c7" class="nl nm iq lg b lh nu lk nv ln nw lr nx lv ny lz nq nr ns nt bi translated"><code class="fe om on oo op b">ability</code>和<code class="fe om on oo op b">education</code>之间的相关性很可能是正的</li></ul><p id="b00b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，偏差最有可能是<strong class="lg ja">正</strong>。由此，我们可以得出结论，我们对<code class="fe om on oo op b">education</code>的<code class="fe om on oo op b">wage</code>回归的估计很可能是对因果效应的<strong class="lg ja">高估</strong>，这很可能更小。</p><p id="58e1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这可能看起来像一个小的洞察力，但它实际上是巨大的。现在我们可以很有信心地说，一年的<code class="fe om on oo op b">education</code>每月最多给<code class="fe om on oo op b">wages</code>增加<strong class="lg ja">95美元，这是一个比仅仅说估计有偏差更有信息量的说法。</strong></p><p id="9011" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一般来说，我们可以在一个2乘2的<strong class="lg ja">表</strong>中总结偏差的不同可能影响。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/d8b5363c390c5bbe1f724d402d35d7d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBuLNyfQl1UOJpZxxBLGDQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">偏向的方向(作者图片)</p></figure></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="a9c5" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">进一步的敏感性分析</h1><p id="d5f8" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">在不做强有力假设的情况下，我们能说更多关于省略变量偏差的T21吗？</p><p id="abf1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">答案是肯定的！特别是，我们可以问自己:偏相关<em class="ne"> γ </em>和<em class="ne"> δ </em>应该有多强，才能<strong class="lg ja">推翻</strong>我们的结论？</p><p id="fb37" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在我们的例子中，我们发现数据中的<code class="fe om on oo op b">education</code>和<code class="fe om on oo op b">wages</code>之间存在正相关关系。然而，我们知道我们在回归中省略了<code class="fe om on oo op b">ability</code>。问题是:<code class="fe om on oo op b">ability</code>与<code class="fe om on oo op b">wage</code>、<em class="ne"> γ </em>、<code class="fe om on oo op b">ability</code>与<code class="fe om on oo op b">education</code>、<em class="ne"> δ </em>之间的相关性应该有多强，才能使效果不显著甚至为负？</p><p id="9e5c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae nf" href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssb.12348" rel="noopener ugc nofollow" target="_blank">西内利和黑兹利特(2020) </a>表明，我们可以根据所解释的残差变异，即<a class="ae nf" href="https://en.wikipedia.org/wiki/Coefficient_of_determination" rel="noopener ugc nofollow" target="_blank">决定系数R </a>来转化这个问题。这种方法的优点是<strong class="lg ja">可解释性</strong>。猜测所解释的方差百分比比猜测条件相关的大小要容易得多。</p><p id="2600" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">作者编写了一个配套包<code class="fe om on oo op b"><a class="ae nf" href="https://github.com/carloscinelli/sensemakr" rel="noopener ugc nofollow" target="_blank">sensemakr</a></code>来进行敏感性分析。你可以在这里找到<a class="ae nf" href="https://cran.r-project.org/web/packages/sensemakr/vignettes/sensemakr.html" rel="noopener ugc nofollow" target="_blank">包的详细描述。</a></p><p id="ba8b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们现在将使用<code class="fe om on oo op b">Sensemakr</code>函数。<code class="fe om on oo op b">Sensemakr</code>函数的主要<strong class="lg ja">参数</strong>为:</p><ul class=""><li id="4ea4" class="nl nm iq lg b lh li lk ll ln nn lr no lv np lz nq nr ns nt bi translated"><code class="fe om on oo op b">model</code>:我们要分析的回归模型</li><li id="6a47" class="nl nm iq lg b lh nu lk nv ln nw lr nx lv ny lz nq nr ns nt bi translated"><code class="fe om on oo op b">treatment</code>:感兴趣的特征/协变量，在我们的例子中是<code class="fe om on oo op b">education</code></li></ul><p id="68bd" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们将尝试回答以下问题:</p><blockquote class="pe pf pg"><p id="4124" class="le lf ne lg b lh li ka lj lk ll kd lm ph lo lp lq pi ls lt lu pj lw lx ly lz ij bi translated"><em class="iq">对于</em> <code class="fe om on oo op b"><em class="iq">education</em></code> <em class="iq">对</em> <code class="fe om on oo op b"><em class="iq">wages</em></code> <em class="iq">到</em> <strong class="lg ja"> <em class="iq">变化符号</em> </strong> <em class="iq">的效果</em><code class="fe om on oo op b"><em class="iq">ability</em></code><code class="fe om on oo op b"><em class="iq">education</em></code><em class="iq">需要说明</em> <code class="fe om on oo op b"><em class="iq">education</em></code> <em class="iq"> (x轴)和<em class="iq"> (y轴)的残差变化量有多大？</em></em></p></blockquote><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="f63e" class="nz mi iq op b gy ou ov l ow ox">import sensemakr<br/><br/>sensitivity = sensemakr.Sensemakr(model = short_model, treatment = "education")<br/>sensitivity.plot()<br/>plt.xlabel("Partial $R^2$ of ability with education");<br/>plt.ylabel("Partial $R^2$ of ability with wage");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/12978797f214a757a0d707020f2ea5b6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1cq5hD-_zKEXS8MdroSZcw.png"/></div></figure><p id="c707" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在<strong class="lg ja">图</strong>中，我们看到<code class="fe om on oo op b">ability</code>的<em class="ne"> R </em>与<code class="fe om on oo op b">education</code>和<code class="fe om on oo op b">wage</code>的局部(因为以<code class="fe om on oo op b">age</code>和<code class="fe om on oo op b">gender</code>为条件)如何影响<code class="fe om on oo op b">wage</code>上<code class="fe om on oo op b">education</code>的估计系数。标有<strong class="lg ja">三角形</strong>的<em class="ne"> (0，0) </em>坐标对应于当前估计值，反映了如果<code class="fe om on oo op b">ability</code>对<code class="fe om on oo op b">wage</code>和<code class="fe om on oo op b">education</code>都没有解释力会发生什么:什么都没有。随着<code class="fe om on oo op b">ability</code>的解释力增加(从三角形向上和向右移动)，估计系数减小，如<strong class="lg ja">水平曲线</strong>所示，直到在<strong class="lg ja">红色虚线</strong>处变为零。</p><p id="8a3c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们应该如何<strong class="lg ja">解读</strong>剧情？我们可以看到，为了消除<code class="fe om on oo op b">education</code>对<code class="fe om on oo op b">wages</code>的影响，我们需要<code class="fe om on oo op b">ability</code>来解释<code class="fe om on oo op b">education</code>和<code class="fe om on oo op b">wage</code>中大约30%的剩余变化，对应于红线。</p><p id="08eb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你现在可能(有理由)会问:30%是多少？是大还是小？我们可以通过<strong class="lg ja">基准测试</strong>用另一个<em class="ne">观察到的</em>变量解释的剩余方差的结果来了解部分R的<strong class="lg ja">大小</strong>。我们以<code class="fe om on oo op b">age</code>为例。</p><p id="e706" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><code class="fe om on oo op b">Sensemakr</code>函数接受以下可选参数:</p><ul class=""><li id="9056" class="nl nm iq lg b lh li lk ll ln nn lr no lv np lz nq nr ns nt bi translated"><code class="fe om on oo op b">benchmark_covariates</code>:用作基准的协变量</li><li id="f177" class="nl nm iq lg b lh nu lk nv ln nw lr nx lv ny lz nq nr ns nt bi translated"><code class="fe om on oo op b">kd</code>和<code class="fe om on oo op b">ky</code>:这些自变量参数化了与观察到的基准协变量(<code class="fe om on oo op b">age</code>)相比，未观察到的变量(<code class="fe om on oo op b">ability</code>)相对于治疗(<code class="fe om on oo op b">kd</code>)和结果(<code class="fe om on oo op b">ky</code>)强多少倍。在我们的例子中，设置<code class="fe om on oo op b">kd</code>和<code class="fe om on oo op b">ky</code>等于<em class="ne"> [0.5，1，2] </em>意味着我们想要研究一个变量的最大强度是<code class="fe om on oo op b">age</code>的一半、相同或两倍(在解释<code class="fe om on oo op b">education</code>和<code class="fe om on oo op b">wage</code>变化时)。</li></ul><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="9a5c" class="nz mi iq op b gy ou ov l ow ox">sensitivity = sensemakr.Sensemakr(model = short_model, <br/>                                  treatment = "education",<br/>                                  benchmark_covariates = "age",<br/>                                  kd = [0.5, 1, 2],<br/>                                  ky = [0.5, 1, 2])<br/>sensitivity.plot()<br/>plt.xlabel("Partial $R^2$ of ability with education");<br/>plt.ylabel("Partial $R^2$ of ability with wage");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/45b28c6b86ed6c5d840fd9a8c098f521.png" data-original-src="https://miro.medium.com/v2/format:webp/1*29PxJ3j5_oArXS4FT13YJg.png"/></div></figure><p id="4237" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">看起来即使<code class="fe om on oo op b">ability</code>有两倍于<code class="fe om on oo op b">age</code>的解释力，<code class="fe om on oo op b">education</code>对<code class="fe om on oo op b">wage</code>的影响仍然是正面的。但是它会是<strong class="lg ja">统计上显著的</strong>吗？</p><p id="c967" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以重复同样的练习，查看t统计量而不是系数的大小。我们只需要将绘图功能中的<code class="fe om on oo op b">sensitivity_of</code>选项设置为等于<code class="fe om on oo op b">t-value</code>。</p><p id="1674" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这种情况下，我们试图回答的问题是:</p><blockquote class="pe pf pg"><p id="2b70" class="le lf ne lg b lh li ka lj lk ll kd lm ph lo lp lq pi ls lt lu pj lw lx ly lz ij bi translated"><em class="iq">对于</em><code class="fe om on oo op b"><em class="iq">education</em></code><code class="fe om on oo op b"><em class="iq">wages</em></code><em class="iq"/><strong class="lg ja"><em class="iq"/> </strong> <em class="iq">对</em><em class="iq"/><strong class="lg ja"><em class="iq">变得不显著</em></strong><em class="iq">的影响<em class="iq">在</em><code class="fe om on oo op b"><em class="iq">education</em></code><em class="iq"><em class="iq"><em class="iq"><code class="fe om on oo op b"><em class="iq">ability</em></code><em class="iq">中的残差变化有多大？</em></em></em></em></em></p></blockquote><pre class="kp kq kr ks gt oq op or os aw ot bi"><span id="050d" class="nz mi iq op b gy ou ov l ow ox">sensitivity.plot(sensitivity_of = 't-value')<br/>plt.xlabel("Partial $R^2$ of ability with education");<br/>plt.ylabel("Partial $R^2$ of ability with wage");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/abe7ec8154ee40594460256843807b5a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ANJuQuHdmUrD9JhowZjPLw.png"/></div></figure><p id="8fac" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">从图中我们可以看出，为了使<code class="fe om on oo op b">education</code>对<code class="fe om on oo op b">wage</code>的影响不显著，我们需要<code class="fe om on oo op b">ability</code>来解释<code class="fe om on oo op b">education</code>和<code class="fe om on oo op b">wage</code>中大约5%到10%的剩余变化。特别是，红线绘制了t统计量等于2.01的水平曲线，对应于5%的显著性水平。从与<code class="fe om on oo op b">age</code>的比较中，我们看到稍强一点的解释力(大于<code class="fe om on oo op b">1.0x age</code>)就足以使<code class="fe om on oo op b">education</code>对<code class="fe om on oo op b">wage</code>的系数不具有统计显著性。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="a3be" class="mh mi iq bd mj mk ml mm mn mo mp mq mr kf ms kg mt ki mu kj mv kl mw km mx my bi translated">结论</h1><p id="8c5b" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">在这篇文章中，我介绍了<strong class="lg ja">省略变量偏差</strong>的概念。我们已经看到了如何在一个简单的线性模型中计算它，以及我们如何利用变量的定性信息在省略变量偏差的情况下做出推断。</p><p id="962a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些工具非常有用，因为省略变量偏差基本上到处都是<strong class="lg ja"/>。首先，总有我们没有观察到的因素，比如我们玩具例子中的能力。然而，即使我们可以观察一切，遗漏变量偏差也可能以<strong class="lg ja">模型错误设定</strong>的形式出现。假设<code class="fe om on oo op b">wages</code>二次依赖<code class="fe om on oo op b">age</code>。然后，从回归中省略二次项会引入偏差，可以使用我们用于<code class="fe om on oo op b">ability</code>的相同工具对其进行分析。</p><h2 id="da99" class="nz mi iq bd mj oa ob dn mn oc od dp mr ln oe of mt lr og oh mv lv oi oj mx iw bi translated">参考</h2><p id="7821" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">[1] C .西内利，c .黑兹莱特，<a class="ae nf" href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssb.12348" rel="noopener ugc nofollow" target="_blank">弄清楚敏感性:扩展省略变量偏倚</a> (2019)，<em class="ne">英国皇家统计学会杂志</em>。</p><p id="adc9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2] V. Chernozhukov，c .西内利，W. Newey，A. Sharma，V. Syrgkanis，<a class="ae nf" href="https://arxiv.org/abs/2112.13398" rel="noopener ugc nofollow" target="_blank">长话短说:因果机器学习中省略的变量偏差</a> (2022)，工作论文。</p><h2 id="5688" class="nz mi iq bd mj oa ob dn mn oc od dp mr ln oe of mt lr og oh mv lv oi oj mx iw bi translated">相关文章</h2><ul class=""><li id="794f" class="nl nm iq lg b lh mz lk na ln pk lr pl lv pm lz nq nr ns nt bi translated"><a class="ae nf" rel="noopener" target="_blank" href="/59f801eb3299">理解弗里希-沃-洛弗尔定理</a></li><li id="ea3f" class="nl nm iq lg b lh nu lk nv ln nw lr nx lv ny lz nq nr ns nt bi translated"><a class="ae nf" rel="noopener" target="_blank" href="/b63dc69e3d8c">Dag和控制变量</a></li></ul><h2 id="ea56" class="nz mi iq bd mj oa ob dn mn oc od dp mr ln oe of mt lr og oh mv lv oi oj mx iw bi translated">密码</h2><p id="ee1a" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">你可以在这里找到Jupyter的原始笔记本:</p><div class="pn po gp gr pp pq"><a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/ovb.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pr ab fo"><div class="ps ab pt cl cj pu"><h2 class="bd ja gy z fp pv fr fs pw fu fw iz bi translated">博客帖子/ovb.ipynb在main matter courthoud/博客帖子</h2><div class="px l"><h3 class="bd b gy z fp pv fr fs pw fu fw dk translated">我博客文章的代码和笔记本。通过在…上创建帐户，为matteocourthoud/Blog-Posts的发展做出贡献</h3></div><div class="py l"><p class="bd b dl z fp pv fr fs pw fu fw dk translated">github.com</p></div></div><div class="pz l"><div class="qa l qb qc qd pz qe ky pq"/></div></div></a></div></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h2 id="d9a2" class="nz mi iq bd mj oa ob dn mn oc od dp mr ln oe of mt lr og oh mv lv oi oj mx iw bi translated">感谢您的阅读！</h2><p id="1594" class="pw-post-body-paragraph le lf iq lg b lh mz ka lj lk na kd lm ln nb lp lq lr nc lt lu lv nd lx ly lz ij bi translated">我真的很感激！🤗<em class="ne">如果你喜欢这个帖子并想看更多，可以考虑</em> <a class="ae nf" href="https://medium.com/@matteo.courthoud" rel="noopener"> <strong class="lg ja"> <em class="ne">关注我</em> </strong> </a> <em class="ne">。我每周发布一次与因果推断和数据分析相关的主题。我尽量让我的帖子简单而精确，总是提供代码、例子和模拟。</em></p><p id="ba22" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="ne">还有，一个小小的</em> <strong class="lg ja"> <em class="ne">免责声明</em> </strong> <em class="ne">:我写作是为了学习所以错误是家常便饭，尽管我尽了最大努力。当你发现他们的时候，请告诉我。也很欣赏新话题的建议！</em></p></div></div>    
</body>
</html>