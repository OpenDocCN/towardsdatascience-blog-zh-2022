<html>
<head>
<title>Categorical Embeddings with CatBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CatBoost的分类嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/categorical-embeddings-with-catboost-9f87ceda76a2#2022-04-14">https://towardsdatascience.com/categorical-embeddings-with-catboost-9f87ceda76a2#2022-04-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0a4e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">研究使用来自fast.ai神经网络的分类嵌入是否可以提高CatBoost在分类任务中的性能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/35b87a187b70f456f91d49f276624e40.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*53pulVM8jc3BDc-63OiAGA.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">泰勒·伊斯顿在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b35c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><a class="ae kr" href="https://catboost.ai/" rel="noopener ugc nofollow" target="_blank"> CatBoost </a>是Yandex的开源机器学习算法。它的名字来源于单词<strong class="ku ir">Cat</strong>egory<strong class="ku ir">Boost</strong>ing。正如您所料，该库的主要优势之一是以比其他决策树算法更直观的方式处理分类数据。与其他决策树算法相比，它的性能也很好。我将fast.ai分类嵌入传递给随机森林和XGBoost模型，代替一次性编码的分类变量，取得了很好的结果。本文旨在回答CatBoost是否也能从使用它们中获益的问题。我们将使用Kaggle的<a class="ae kr" href="https://www.kaggle.com/competitions/petfinder-adoption-prediction" rel="noopener ugc nofollow" target="_blank">pet finder . my Adoption Prediction</a>数据集对此进行调查。<a class="ae kr" href="https://www.petfinder.my/" rel="noopener ugc nofollow" target="_blank"> PetFinder.my </a>是一个帮助防止虐待马来西亚流浪动物并在那里为它们寻找新家的资源。如果这是你感兴趣的话题，他们确实有一个志愿者人工智能任务组。该组织好心地允许我在这篇文章中使用他们的数据集。</p><p id="6943" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我的Kaggle笔记本，包括下面显示的代码，可以在这里找到<a class="ae kr" href="https://www.kaggle.com/code/johnwillcox/notebook7496488236" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="cf42" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在本文中，我们将了解:</p><ol class=""><li id="cf39" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated">什么是范畴嵌入</li><li id="9064" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">如何制作和检查一个fast.ai表格学习器</li><li id="2894" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">如何构建CatBoost模型</li><li id="01af" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">传递分类嵌入来代替或补充离散分类值是否可以提高性能</li></ol><h1 id="4691" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">什么是范畴嵌入？</h1><p id="7203" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">类别要素是不包含连续数据的要素，具有来自一组固定类(或类别)的离散值。这些类别可以是数字，尽管它们通常是字符串值。这些值需要以某种方式转换成数字，然后才能输入到大多数机器学习模型中，因为大多数模型只接受数字输入。CatBoost是不常见的，因为它接受没有这种转换的分类特征。但是<a class="ae kr" href="http://catboost.ai/en/docs/concepts/algorithm-main-stages_cat-to-numberic" rel="noopener ugc nofollow" target="_blank">即使是CatBoost也以类似的方式转换这些功能</a>。</p><p id="3421" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一种典型的方法是一键编码。为每个固定类别建立一个单独的二进制变量，当样本属于给定类别时，该变量的值为1，否则为0。如果我们查看PetFinder.my数据集中的Breed1特性，我们会看到文档中描述了307个狗和猫的品种，其中176个出现在训练数据集中。对该列进行一次性编码意味着要管理额外的176列！此外，我们会失去任何内在的关系或品种之间可能存在的相似性。</p><p id="57c4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">范畴嵌入(有时称为实体嵌入)克服了这两个缺点。嵌入是分类数据的向量表示。例如，在嵌入之前，Breed1数据点由单个分类变量表示，用每个品种的数字ID填充(品种名称可以在附带的BreedLabels.csv文件中看到)。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="d689" class="ne md iq na b gy nf ng l nh ni">df_train.Breed1.value_counts()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/082469dffa58549680b84ce8bc623704.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*lpAm_wThACz069mxZJfVvg.png"/></div></figure><p id="e521" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">嵌入后，Breed1数据如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/a53ee6af45f2873e75988322cd9ffada.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKn1GDcGoI4AG_qrf1Y0zg.png"/></div></div></figure><p id="ab29" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们可以看到，单列已被29列浮点值所取代。我们将在后面看到29这个数字是如何确定的。但是现在，知道离散数据已经被一些连续的数据点所取代就足够了，这些数据点可以直接用作我们模型的特征输入。这个数字几乎比一次性编码数据所需的数字小一个数量级。</p><p id="87c0" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">值得注意的是，这些输入既连续又有意义，正如论文“<a class="ae kr" href="https://arxiv.org/abs/1604.06737" rel="noopener ugc nofollow" target="_blank">分类变量的实体嵌入</a>”(郭城和费利克斯·贝克汉)中所展示的。作者表明，连续值描述了潜在类别的内在属性。这意味着我们可以计算和比较不同类别(在我们的例子中，猫和狗品种)之间的嵌入距离，并发现我们认为在现实生活中相似的类别之间的距离比我们认为相距较远的类别之间的距离更短。</p><p id="f818" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">例如，在宠物收养的情况下，我们可能会认为两种家庭犬种，拉布拉多犬和梗犬，彼此之间的距离比罗威纳犬更近，罗威纳犬更多地被认为是一种护卫犬。并且，计算这些品种的嵌入之间的简单欧几里德距离，我们看到这确实是事实。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="cde1" class="ne md iq na b gy nf ng l nh ni">breed1_embeddings = [x for x in df_train_embeddings.columns if x.startswith('Breed1_')]<br/>terrier=df_train_embeddings[df_train_embeddings.Breed1=='218'][breed1_embeddings].head(1)<br/>labrador=df_train_embeddings[df_train_embeddings.Breed1=='141'][breed1_embeddings].head(1)<br/>rottweiler=df_train_embeddings[df_train_embeddings.Breed1=='189'][breed1_embeddings].head(1)<br/>print('Terrier -&gt; Labrador', round(np.linalg.norm(np.array(terrier)-np.array(labrador)),3))<br/>print('Rottweiler -&gt; Terrier', round(np.linalg.norm(np.array(rottweiler)-np.array(terrier)),3))<br/>print('Rottweiler -&gt; Labrador', round(np.linalg.norm(np.array(rottweiler)-np.array(labrador)),3))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/bf614615ff87b90331d50705a108a64e.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*fOeHuz5oTXbwap6skitDjw.png"/></div></figure><h1 id="0728" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">安装</h1><p id="de59" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">好了，现在我们知道了一点什么是嵌入，以及它们如何帮助我们，让我们通过代码来使用fast.ai库生成它们。如果你不熟悉fast.ai，<a class="ae kr" href="https://www.fast.ai/" rel="noopener ugc nofollow" target="_blank">是一家由杰瑞米·霍华德和瑞秋·托马斯创立的研究机构</a>，致力于让深度学习变得更容易实现。</p><p id="e4f6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">首先，我们导入我们的库。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="083c" class="ne md iq na b gy nf ng l nh ni">import catboost as cb<br/>from fastai.tabular.all import *<br/>import numpy as np<br/>import os<br/>import pandas as pd<br/>import scipy as sp<br/>import seaborn as sns<br/>from sklearn.model_selection import train_test_split<br/>from typing import Dict, Tuple</span></pre><p id="cc95" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然后，我们加载提供的训练、测试和样本提交文件。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="d6cc" class="ne md iq na b gy nf ng l nh ni">input_folder = '../input/petfinder-adoption-prediction'<br/>df_train = pd.read_csv(f'{input_folder}/train/train.csv')<br/>df_test = pd.read_csv(f'{input_folder}/test/test.csv')<br/>df_sample_submission = pd.read_csv(f'{input_folder}/test/sample_submission.csv')<br/>df_sample_submission.drop('AdoptionSpeed', axis=1, inplace=True)</span></pre><h2 id="093a" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">预处理</h2><p id="4bdd" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">我们对数据做一些非常基本的预处理。品种栏似乎很混乱，用各种组合来表示一只狗或猫是混种。所以我们设计了一个简单的二进制标志。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="4833" class="ne md iq na b gy nf ng l nh ni">def get_mixed_breed(breed1: int, breed2: int) -&gt; int:    <br/>    # mixed breed with both breeds specified<br/>    if breed1 != 307 and breed2 != 307 and breed1 != 0 and breed2 != 0 and breed1 != breed2:<br/>        return 1<br/>    # mixed breed with only one breed specified<br/>    elif (breed1 != 307 and breed1 != 0 and breed2 == 307) or (breed2 != 307 and breed2 != 0 and breed1 == 307):<br/>        return 2<br/>    # mixed breed with no breed specified<br/>    elif (breed1 == 307 and breed2 == 307) or (breed1 == 307 and breed2 == 0):<br/>        return 3<br/>    <br/>    # breed is not mixed<br/>    return 0</span><span id="e0aa" class="ne md iq na b gy ob ng l nh ni">df_train['mixed_breed'] = df_train.apply(lambda row: get_mixed_breed(row.Breed1, row.Breed2), axis=1)<br/>df_test['mixed_breed'] = df_test.apply(lambda row: get_mixed_breed(row.Breed1, row.Breed2), axis=1)</span></pre><p id="6a4b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">每个宠物档案的描述都通过谷歌的自然语言API运行，这意味着我们可以提取描述长度、语言、情感程度和分数的特征。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="dd5d" class="ne md iq na b gy nf ng l nh ni">def get_sentiment(filename: str) -&gt; pd.Series:    <br/>    try:<br/>        with open(filename) as file:<br/>            data = json.load(file)<br/>        return pd.Series((data['documentSentiment']['magnitude'], data['documentSentiment']['score'], data['language']))<br/>    except FileNotFoundError:<br/>        return pd.Series((np.nan, np.nan))<br/>    <br/>df_train[['description_sentiment_magnitude', 'description_sentiment_score', 'description_language']] = df_train.PetID.apply(lambda pet_id: get_sentiment(f'{input_folder}/train_sentiment/{pet_id}.json'))<br/>df_test[['description_sentiment_magnitude', 'description_sentiment_score', 'description_language']] = df_test.PetID.apply(lambda pet_id: get_sentiment(f'{input_folder}/test_sentiment/{pet_id}.json'))<br/>df_train['description_length'] = df_train.Description.str.count(' ')<br/>df_test['description_length'] = df_test.Description.str.count(' ')</span></pre><p id="ccdc" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">从阅读这3个样本的描述中，我们可以看到年龄被错误地输入了月份而不是年份。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="ce39" class="ne md iq na b gy nf ng l nh ni">df_train.loc[df_train.PetID=='e3b589e13', 'Age']=2<br/>df_train.loc[df_train.PetID=='e77f9e778', 'Age']=3<br/>df_train.loc[df_train.PetID=='53923463d', 'Age']=3</span></pre><p id="e1d8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们定义了相关(目标)变量以及分类和连续特征的列表，并根据CatBoost的要求创建了类型为<code class="fe oc od oe na b">str</code>的分类变量。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="555a" class="ne md iq na b gy nf ng l nh ni">reproducible_results = True<br/>random_state = 42 if reproducible_results else None<br/>dependent_var = 'AdoptionSpeed'<br/>categorical = ['Breed1', 'Breed2', 'Gender', 'Color1', 'Color2', 'Color3', 'State', 'Vaccinated', 'Dewormed', 'Sterilized', 'mixed_breed', 'Type', 'MaturitySize', 'FurLength', 'Health', 'description_language']<br/>continuous = ['Age', 'Quantity', 'Fee', 'VideoAmt', 'PhotoAmt', 'description_length', 'description_sentiment_score', 'description_sentiment_magnitude']</span><span id="f26c" class="ne md iq na b gy ob ng l nh ni">df_train[categorical] = df_train[categorical].astype('str')<br/>df_test[categorical] = df_test[categorical].astype('str')</span></pre><p id="fd92" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果我们想要可再现的结果，特别是从fast.ai表格学习器中，我们可以重新播种<em class="of">一切</em>。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="98b0" class="ne md iq na b gy nf ng l nh ni">def seed_everything(seed): <br/>    random.seed(seed) <br/>    os.environ['PYTHONHASHSEED'] = str(seed) <br/>    np.random.seed(seed) <br/>    torch.manual_seed(seed) <br/>    torch.cuda.manual_seed_all(seed) <br/>    torch.cuda.manual_seed(seed) <br/>    torch.backends.cudnn.deterministic = True<br/>    <br/>if reproducible_results:<br/>    seed_everything(random_state)</span></pre><p id="b421" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在我们使用<a class="ae kr" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> sklearn的</a> <code class="fe oc od oe na b">train_test_split</code>实用程序将训练数据分成80/20分割的训练集和验证集。我们设置分层参数以确保训练和验证数据的AdoptionSpeed类的划分是相同的。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="f429" class="ne md iq na b gy nf ng l nh ni">train_xs, valid_xs, _, _ = train_test_split(df_train, df_train[dependent_var], test_size=0.2, shuffle=True, stratify=df_train[dependent_var], random_state=random_state)<br/>splits = (train_xs.index.tolist(), valid_xs.index.tolist())</span></pre><h2 id="f7d8" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">表格熊猫</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi og"><img src="../Images/8f40e5105a0a8eb2dabeaab8535a1263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GzLba_uvmN5g_eKA"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://unsplash.com/@stonewyq?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯通王</a>在<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b8ac" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">fast.ai <code class="fe oc od oe na b"><a class="ae kr" href="https://docs.fast.ai/tabular.core.html#TabularPandas" rel="noopener ugc nofollow" target="_blank">TabularPandas</a></code>对象是<a class="ae kr" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html" rel="noopener ugc nofollow" target="_blank">熊猫数据帧</a>的有用包装器。我们选择<a class="ae kr" href="https://docs.fast.ai/tabular.core.html#Categorify" rel="noopener ugc nofollow" target="_blank">对</a>进行分类，<a class="ae kr" href="https://docs.fast.ai/tabular.core.html#FillMissing" rel="noopener ugc nofollow" target="_blank">填充缺失值</a>(默认行为是使用中值)，而<a class="ae kr" href="https://docs.fast.ai/data.transforms.html#Normalize" rel="noopener ugc nofollow" target="_blank">对</a>我们的数据进行标准化。<code class="fe oc od oe na b">splits</code>参数是一个元组，包含训练集和验证集的行索引列表。我们将使用<code class="fe oc od oe na b">CategoryBlock</code>来完成这个分类任务。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="7493" class="ne md iq na b gy nf ng l nh ni">procs = [Categorify, FillMissing, Normalize]<br/>tabdata = TabularPandas(df=df_train, procs=procs, cat_names=categorical.copy(), cont_names=continuous.copy(), splits=splits, y_names=dependent_var, y_block=CategoryBlock())</span></pre><h2 id="9309" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">嵌入尺寸</h2><p id="a71b" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">现在，我们第一次可以看到. ai计划以多快的速度构建分类嵌入。<a class="ae kr" href="https://docs.fast.ai/tabular.model.html#get_emb_sz" rel="noopener ugc nofollow" target="_blank">这个方法</a>给了我们要使用的默认嵌入大小。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="2194" class="ne md iq na b gy nf ng l nh ni">embedding_sizes = get_emb_sz(tabdata)<br/>embedding_sizes</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/f04ff9b2ab258c48ee15c490be2a2aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:170/format:webp/1*N7d9XoFMlk8Z-oK01jBsNA.png"/></div></figure><p id="bacd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">该方法返回一个元组列表，每个分类变量一个，按照我们在<code class="fe oc od oe na b">cat_features</code>参数中添加它们的顺序。我们来看第一个元组。列表中的第一个分类变量是Breed1。正如我们已经看到的，在训练数据集中有176个不同的值。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="7e23" class="ne md iq na b gy nf ng l nh ni">df_train['Breed1'].nunique()</span></pre><p id="2129" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">第一个元组是(177，29)。177值是具有一个额外类别的176个唯一值，该类别将用于任何验证、测试或未来样本，该样本具有迄今为止未在训练数据集中表示的未知值。</p><p id="f2af" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">29是fast的连续值的数目。ai已经确定它将用来表示Breed1。换句话说，我们认为在收养宠物的情况下，主要品种之间的关系可以用29个连续的值来充分表达。让我们看看这个数字是如何得出的。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="6967" class="ne md iq na b gy nf ng l nh ni">emb_sz_rule??</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/5dd2e7ea80331dba9179699a7844c97f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*TeMGZ1LbtGKxx156DcJcNQ.png"/></div></figure><p id="e788" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们可以看到fast.ai用来确定嵌入矩阵大小的经验法则——它是600的最小值或类别数的0.56次方乘以1.6。杰瑞米·霍华德提到，这条规则是通过运行许多模型并调整尺寸以找出最佳公式得出的。他特别提到这只是一个起点，应该像任何其他超参数一样进行优化(他甚至开玩笑地称之为他的“<a class="ae kr" href="https://twitter.com/jeremyphoward/status/1242128706740551681" rel="noopener ugc nofollow" target="_blank">可怕的嵌入黑客</a>”)。我们将在后面看到如何覆盖嵌入的默认大小。</p><p id="86ac" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我在上面说过,<code class="fe oc od oe na b">get_emb_sz</code>方法返回一个元组列表，每个元组对应一个分类变量。然而，仔细观察，我们看到有19个元组(或嵌入)，但我们只有16个分类变量！为了理解这是怎么回事，我们可以看看表格熊猫对象的属性<code class="fe oc od oe na b">cat_names</code>。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="060c" class="ne md iq na b gy nf ng l nh ni">[col for col in tabdata.cat_names]</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/690841d777400f8cc4650405ac3a5087.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*n6e8D7tptXN70WjaInE62A.png"/></div></figure><p id="e9ec" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们已经获得了3个新的分类变量，最后三个带有<code class="fe oc od oe na b">_na</code>后缀。这种意外的行为是由于我们在创建表格熊猫对象时传递给它的<code class="fe oc od oe na b">FillMissing</code> proc参数。默认情况下，该方法在替换那些<code class="fe oc od oe na b">na</code>值之前，为每个具有<code class="fe oc od oe na b">na</code>值的连续变量添加一列。这样做是为了确保模型保留对给定样本缺少列值这一事实的预测能力。(请注意，如果需要，您可以使用<code class="fe oc od oe na b">FillMissing(add_col=False)</code>来覆盖此行为。)</p><h1 id="f5bc" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">制作表格学习器</h1><p id="0fe6" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">考虑嵌入大小的另一种方式是注意每个嵌入都是表格学习模型的输入层，因此每个嵌入的大小实际上是该嵌入层的输出数量。为了更好地理解这一点，我们可以继续创建表格学习器，看看整体结构。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="28b6" class="ne md iq na b gy nf ng l nh ni">def get_default_nn_layers(num_embeddings: int, num_continuous: int, num_outputs: int, num_layers: int=2) -&gt; List[int]:<br/>    num_input_nodes = num_embeddings + num_continuous  <br/>    first_layer = 2**(num_layers-1) * round((((2 / 3) * num_input_nodes) + num_outputs) / 2**(num_layers-1))<br/>    <br/>    return [first_layer] + [int(first_layer / 2**n) for n in range(1, num_layers)]</span><span id="44c5" class="ne md iq na b gy ob ng l nh ni">num_embeddings = sum(n for _, n in get_emb_sz(tabdata))<br/>num_classes = df_train[dependent_var].nunique()<br/>layers = get_default_nn_layers(num_embeddings, num_continuous=len(continuous), num_outputs=num_classes)<br/>batchsize = 16<br/>train_dl = TabDataLoader(tabdata.train, bs=batchsize, shuffle=True, drop_last=False)<br/>valid_dl = TabDataLoader(tabdata.valid, bs=batchsize, shuffle=False, drop_last=False)<br/>dls = DataLoaders(train_dl, valid_dl)<br/>config = tabular_config(ps=[0.001, 0.01], embed_p=0.04)<br/>nn_model = tabular_learner(dls=dls, layers=layers, config=config, loss_func=CrossEntropyLossFlat(), metrics=accuracy, n_out=num_classes)</span></pre><p id="c304" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里有很多，让我们来分解一下。首先，我们使用<code class="fe oc od oe na b">layers</code>参数指定隐藏层的数量和每层中神经元的数量，以覆盖<code class="fe oc od oe na b"><a class="ae kr" href="https://docs.fast.ai/tabular.learner.html#tabular_learner" rel="noopener ugc nofollow" target="_blank">tabular_learner</a></code>的默认值[200，100]。我发现一个有用的经验法则是从两层开始，第一层包含的神经元数量等于输入节点数量加上输出(在此上下文中为类)数量的2/3倍，第二层包含这个数量的一半。我的<code class="fe oc od oe na b">get_default_nn_layers</code>方法简单地获取嵌入的总数、连续变量的总数(每个变量一个输入)、输出类的数量和所需的层数，以返回层的建议起始值(在我们的例子中是[88，44])。这是一个应该像其他参数一样优化的超参数。如果神经元数量过多，网络可能会过拟合，如果神经元数量过少，网络可能会过拟合。</p><p id="d0fc" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">接下来，我们生成<a class="ae kr" href="https://docs.fast.ai/tabular.core.html#TabDataLoader" rel="noopener ugc nofollow" target="_blank">表格数据加载器对象</a>，一个用于训练集，一个用于验证集。我们选择16个小批量(因为这是一个小数据集，训练很快)。我们选择在每次迭代数据加载器时打乱训练集。</p><p id="cbfd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">最后，我们创建模型本身。我们传入一个<code class="fe oc od oe na b"><a class="ae kr" href="https://docs.fast.ai/tabular.model.html#tabular_config" rel="noopener ugc nofollow" target="_blank">tabular_config</a></code>参数，这样我们就可以指定退出率。<a class="ae kr" href="https://arxiv.org/abs/1207.0580" rel="noopener ugc nofollow" target="_blank"> Geoffrey Hinton和其他人</a>介绍了一种正则化技术，在训练时随机比例的激活被设置为零，试图减少过度拟合的可能性。<code class="fe oc od oe na b">ps</code>参数提供两个隐藏层的退出率，而<code class="fe oc od oe na b">embed_p</code>参数提供嵌入层的退出率。我们选择<code class="fe oc od oe na b"><a class="ae kr" href="https://docs.fast.ai/losses.html#CrossEntropyLossFlat" rel="noopener ugc nofollow" target="_blank">CrossEntropyLossFlat</a></code>方法作为损失函数，并指示模型使用<code class="fe oc od oe na b"><a class="ae kr" href="https://docs.fast.ai/metrics.html#accuracy" rel="noopener ugc nofollow" target="_blank">accuracy</a></code>度量。</p><h2 id="a119" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">检查模型</h2><p id="ccf4" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">现在我们创建了模型，让我们看看底层结构。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="7fec" class="ne md iq na b gy nf ng l nh ni">nn_model.model</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ce04dc2cc54d083b32574dd625c098c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*ormvZUaIrE1FxToqe2tg-w.png"/></div></figure><p id="bd92" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们看到16个分类变量的19个嵌入层，加上由库生成的另外3个嵌入层，后面是嵌入删除层。</p><p id="26a4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">8个连续变量还有一个额外的输入层。这被称为BatchNorm1d，因为表格学习器应用批量标准化，即标准化每批每个输入的激活的过程(回想一下，这里的批次包含16个样本)。这有助于规范网络并加快收敛速度。</p><p id="7b26" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">接下来，我们有两个隐藏层的第一个。我们看到126个输入特征(来自分类嵌入层和8个连续层的总共118个输出节点)，馈入ReLU激活层，在应用第一轮非嵌入退出之前，对88个输出应用批量归一化。第二个隐藏层有88个输入和44个输出，在应用最终漏失之前再次进行批量归一化。最后，输出层有44个输入和5个输出，每个AdoptionSpeed类一个。</p><p id="eb2a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在我们调整网络和生成嵌入之前，最后一点需要注意。我在上面提到嵌入数组的建议大小仅仅是建议。如果我们想要覆盖任何给定列的默认嵌入大小，我们可以将包含列名和值的字典传递给调用中的<code class="fe oc od oe na b">emb_szs</code>参数，以构造表格学习器。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="24e7" class="ne md iq na b gy nf ng l nh ni">embedding_sizes_override={'Breed1': 30, 'Breed2': 24, 'State': 8}<br/>nn_model = tabular_learner(dls=dls, layers=layers, config=config, emb_szs=embedding_sizes_override, loss_func=CrossEntropyLossFlat(), metrics=accuracy, n_out=num_classes)</span></pre><h2 id="265a" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">训练模型</h2><p id="e48f" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">现在让我们训练网络。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="ce5e" class="ne md iq na b gy nf ng l nh ni">valley = nn_model.lr_find()<br/>plt.show()<br/>num_epochs = 5<br/>nn_model.fit_one_cycle(n_epoch=num_epochs, lr_max=valley, wd=0.01)<br/>nn_model.recorder.plot_loss()<br/>plt.show()</span></pre><p id="9bad" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们使用<a class="ae kr" href="https://docs.fast.ai/callback.schedule.html#Learner.fit_one_cycle" rel="noopener ugc nofollow" target="_blank"> fit_one_cycle </a>方法实现<a class="ae kr" href="https://fastai1.fast.ai/callbacks.one_cycle.html" rel="noopener ugc nofollow" target="_blank">单周期回调</a>来提高收敛速度。我们采用来自<a class="ae kr" href="https://docs.fast.ai/callback.schedule.html#Learner.lr_find" rel="noopener ugc nofollow" target="_blank"> fast.ai学习率查找器</a>的建议学习率，以及权重衰减的默认参数。同样，这里没有列出的这些和其他超参数都可以并且应该进行调整和优化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/dfd1260db13a1b4253575bd946b7ff74.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*fd1aWofO8XT0-LAhxm3rgA.png"/></div></figure><h2 id="304e" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">检查嵌入物</h2><p id="f0e2" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">既然我们已经训练了网络，表格学习者模型将已经学习了分类嵌入。让我们来看看它们。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="c504" class="ne md iq na b gy nf ng l nh ni">def embed_features(learner: tabular_learner, xs: TabularPandas) -&gt; pd.DataFrame:<br/>    xs = xs[learner.dls.cat_names]<br/>    for i, col in enumerate(xs.columns):<br/>        embeddings = learner.model.embeds[i]<br/>        embedding_data = embeddings(tensor(xs[col], dtype=torch.int64))<br/>        embedding_names = [f'{col}_{j}' for j in range(embedding_data.shape[1])]<br/>        <br/>        df_local = pd.DataFrame(data=embedding_data, index=xs.index, columns=embedding_names)<br/>        xs = xs.drop(col, axis=1)<br/>        xs = xs.join(df_local)<br/>    <br/>    return xs</span><span id="0810" class="ne md iq na b gy ob ng l nh ni">df_train_embeddings = embed_features(learner=nn_model, xs=tabdata.train.xs)<br/>df_valid_embeddings = embed_features(learner=nn_model, xs=tabdata.valid.xs)<br/>embedded = df_train_embeddings.columns.tolist() <br/>df_train_embeddings = df_train_embeddings.merge(right=df_train, left_index=True, right_index=True)<br/>df_valid_embeddings = df_valid_embeddings.merge(right=df_train, left_index=True, right_index=True)</span></pre><p id="a964" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><code class="fe oc od oe na b">embed_features</code>方法采用一个表格学习器模型和一个表格熊猫来返回一个只包含新的嵌入列和值的dataframe的副本。上面的代码(重新)为定型和验证数据集生成嵌入值，并将它们与原始列联接，准备将它们输入到决策树模型(或任何其他类型的模型)中。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="9993" class="ne md iq na b gy nf ng l nh ni">state_embeddings = [x for x in df_train_embeddings.columns if x.startswith('State_')]<br/>df_train_embeddings[['State']+state_embeddings].head(10)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/32585d0cbea46a0666f0a4730d7caa5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*LR5_XXqhXY8whNSdkfXj1w.png"/></div></figure><p id="0d3d" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这里，我们看到州特征的原始值和这10个样本中表示的三个值的相关7个分类嵌入(三个唯一的州值是41326、41327和41401，分别对应于柔佛、槟榔屿和吉隆坡)。</p><p id="574c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们使用表格熊猫<code class="fe oc od oe na b">process</code>方法准备我们的测试数据。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="e1bd" class="ne md iq na b gy nf ng l nh ni">tabdata_test = tabdata.new(df_test)<br/>tabdata_test.process()<br/>df_test_embeddings = embed_features(learner=nn_model, xs=tabdata_test)<br/>df_test_embeddings = df_test_embeddings.merge(right=df_test, left_index=True, right_index=True)</span></pre><h1 id="475f" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">构建CatBoost模型</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3cc0aa9ad0b90bf407dc103895e739a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*TDC-fKxw6kWBNgipiyKEKg.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">照片由<a class="ae kr" href="https://unsplash.com/@whyloyd?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯服从</a>于<a class="ae kr" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="31cb" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我采用的是单标签、有序、多类、不平衡的分类任务。那是相当多的。我们来分解一下。</p><ul class=""><li id="d998" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln oo lu lv lw bi translated">单一标签意味着一个给定的样本只能分配到一个采用速度类别</li><li id="3718" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln oo lu lv lw bi translated">序数意味着类之间有一个固有的顺序。它们的范围从0到4，0表示宠物在上市当天被收养，4表示宠物在上市100天后没有被收养</li><li id="848f" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln oo lu lv lw bi translated">多类别意味着给定样品可以被分配到三个或更多类别(与二进制分类任务相反，在二进制分类任务中，样品将被分配到两个类别中的一个)</li><li id="4090" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln oo lu lv lw bi translated">不平衡意味着在训练数据集中类的频率是偏斜的(并且，可能在测试数据集中)；例如，制作类的直方图显示，采用速度为4的样本数是采用速度为0的样本数的10倍</li></ul><p id="4067" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">所有这一切意味着，我们可以通过几种不同的方式来实现使用CatBoost预测采用速度的目标。我们可以使用带有<a class="ae kr" href="https://catboost.ai/en/docs/concepts/loss-functions-multiclassification#MultiClass" rel="noopener ugc nofollow" target="_blank">多类</a>损失函数的<a class="ae kr" href="https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier" rel="noopener ugc nofollow" target="_blank"> CatBoost分类器</a>来分配给多个类。我们可以使用<a class="ae kr" href="https://catboost.ai/en/docs/concepts/loss-functions-multiclassification#WKappa" rel="noopener ugc nofollow" target="_blank"> WKappa </a>(二次加权Kappa)评估指标来利用平凡性来改进结果。我们还可以确定类权重，将其传递给模型，以尝试解决训练数据集的不平衡性质。</p><p id="517e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，竞赛中最成功的团队倾向于利用回归技术，结合使用<a class="ae kr" href="https://codesachin.wordpress.com/2016/01/16/nelder-mead-optimization/" rel="noopener ugc nofollow" target="_blank"> Nelder-Meads算法</a>和二次加权kappa度量的优化舍入器来帮助确定最佳点，以设置类别之间的阈值。让我们一步一步来。</p><h2 id="af27" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">CatBoost回归器</h2><p id="ba8f" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">首先，让我们定义方法来获取我们的<a class="ae kr" href="https://catboost.ai/en/docs/concepts/python-reference_catboostregressor" rel="noopener ugc nofollow" target="_blank"> CatBoost回归器</a>和相关的<a class="ae kr" href="https://catboost.ai/en/docs/concepts/python-reference_pool" rel="noopener ugc nofollow" target="_blank">数据池</a>。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="343c" class="ne md iq na b gy nf ng l nh ni">def get_catboost_regressor(iterations: int=1000, loss_function: str='RMSE', eval_metric: str='RMSE', ignored_features: List[str]=['PetID'], depth: int=6) -&gt; cb.CatBoostRegressor:<br/>    return cb.CatBoostRegressor(iterations=iterations, loss_function=loss_function, eval_metric=eval_metric, ignored_features=ignored_features, depth=depth, random_seed=random_state)</span><span id="d3b9" class="ne md iq na b gy ob ng l nh ni">def get_catboost_pool(df: pd.DataFrame, use_categorical: bool, use_embedded: bool, has_label: bool=True) -&gt; cb.Pool:<br/>    columns = continuous + (categorical if use_categorical else []) + (embedded if use_embedded else []) + ['PetID']<br/>    cat_features = ['PetID'] + (categorical if use_categorical else [])    <br/>    label = df[dependent_var] if has_label else None<br/>    <br/>    return cb.Pool(data=df[columns], label=label, cat_features=cat_features)</span></pre><p id="dc24" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如果我们不覆盖默认参数，返回一个使用默认参数的回归量。我们告诉CatBoost忽略PetID列，因为尽管我们希望以后使用它，但我们不希望模型试图从PetID值中学习。</p><p id="f15c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><code class="fe oc od oe na b">get_catboost_pool</code>使用带有附加布尔值的数据帧来定义我们希望模型使用的列组。</p><p id="3bff" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">顺便提一下，熟悉CatBoost池文档的读者可能会注意到我们在这里没有使用的参数<code class="fe oc od oe na b"><a class="ae kr" href="https://catboost.ai/en/docs/concepts/python-reference_pool#embedding_features" rel="noopener ugc nofollow" target="_blank">embedding_features</a></code>。尽管有这个名字，这个参数并不涉及分类嵌入。它与用于文本分析的特定类型的嵌入相关(在这里<a class="ae kr" rel="noopener" target="_blank" href="/boosted-embeddings-with-catboost-8dc15e18fb9a">讨论</a>)。</p><p id="0e66" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们将进行三次试验进行比较。</p><ol class=""><li id="e4f5" class="lo lp iq ku b kv kw ky kz lb lq lf lr lj ls ln lt lu lv lw bi translated">仅使用连续特征和离散分类特征</li><li id="deeb" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">使用由表格学习器生成的连续特征和分类嵌入</li><li id="5f47" class="lo lp iq ku b kv lx ky ly lb lz lf ma lj mb ln lt lu lv lw bi translated">使用由表格学习器生成的连续特征、离散分类特征和分类嵌入</li></ol><h2 id="dec2" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">第1轮-仅连续特征和离散分类特征</h2><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="2d9e" class="ne md iq na b gy nf ng l nh ni"># switch to indicate whether or not to feed the original categorical values into the CatBoost regressor<br/>use_categorical = True<br/># switch to indicate whether or not to feed categorical embeddings into the CatBoost regressor<br/>use_embedded = False</span><span id="2719" class="ne md iq na b gy ob ng l nh ni">train_pool = get_catboost_pool(df=df_train_embeddings, use_categorical=use_categorical, use_embedded=use_embedded)<br/>valid_pool = get_catboost_pool(df=df_valid_embeddings, use_categorical=use_categorical, use_embedded=use_embedded)<br/>test_pool = get_catboost_pool(df=df_test_embeddings, use_categorical=use_categorical, use_embedded=use_embedded, has_label=False)</span><span id="c3d1" class="ne md iq na b gy ob ng l nh ni">model = get_catboost_regressor(iterations=10000)</span></pre><p id="0f48" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在，我们将模型拟合10，000次迭代，仅显示每1000轮的输出。CatBoost根据验证集自动评估模型的每次迭代，并恢复到得分最低的迭代。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="df21" class="ne md iq na b gy nf ng l nh ni">model.fit(X=train_pool, eval_set=valid_pool, verbose=1000)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi op"><img src="../Images/9c7069f6bfa2cf241b9e65ccc07df6ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YFqWQou6WO2BPJJvrpX6jw.png"/></div></div></figure><p id="8b80" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在连续特征和离散分类特征上训练的最佳模型的RMSE是1.0760086，在6，104次训练迭代后达到。</p><p id="60df" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">现在我们拟合了我们的模型，让我们看看预测是什么样子的。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="457d" class="ne md iq na b gy nf ng l nh ni">predictions = model.predict(train_pool)<br/>predictions</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/faee37fb98f3c003192e622f774b03ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*9jNBBaucwkDRX_QPdCYRrw.png"/></div></figure><p id="ba19" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">预测是以一个浮动数组的形式出现的。我们需要以某种方式将它们中的每一个都转换成0到4之间的整数。我们可以简单地通过舍入来实现，使用0.5、1.5、2.5和3.5之间的阈值。但是更好的技术可能是使用算法来确定要使用的最佳阈值。</p><h2 id="d8b2" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">优化舍入器</h2><p id="b179" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">我们将使用许多领先的竞赛笔记本中引用的优秀的<code class="fe oc od oe na b">OptimizedRounder</code>类和相关方法。我用的是Kaggle里<a class="ae kr" href="https://www.kaggle.com/code/adityaecdrid/8th-place-solution-code/script?scriptVersionId=12171797" rel="noopener ugc nofollow" target="_blank">第八名笔记本</a>的版本。定义很长，所以我不会在这里包括它们，但是你可以在我的笔记本版本中看到它们，在这篇文章的顶部。</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="5a89" class="ne md iq na b gy nf ng l nh ni">optR = OptimizedRounder()<br/>optR.fit(predictions, df_train_embeddings[dependent_var].values)<br/>coefficients = optR.coefficients()<br/>coefficients</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/0ece97fb1aaa71e28e632ea52450d834.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*Q5IQfjGT1xs6dchGkFdLvQ.png"/></div></figure><h2 id="f22b" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">二次加权Kappa</h2><p id="6899" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">优化舍入器使用二次加权kappa度量来确定为训练集返回最小误差的上述4个边界。二次加权kappa对在序数尺度上相距较远的错误分类给予更大的权重。在不使用二次加权kappa度量的情况下，被误分类为类别1或类别4的类别0的样本将具有相同的误差。对于二次加权kappa，错误分类到类别4的惩罚比错误分类到类别1的惩罚严厉4 = 16倍。</p><h2 id="11be" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">做预测</h2><p id="5ec8" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">最后，我们可以根据测试数据集进行预测，并将结果提交给Kaggle。PetFinder.my的采用是一个纯内核的竞赛，要求所有提交都通过内核输出来完成。(如果你自己尝试这样做，你需要在Kaggle内核右下角的笔记本设置中关闭互联网接入。)</p><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="1645" class="ne md iq na b gy nf ng l nh ni">test_predictions = model.predict(test_pool)<br/>test_predictions = optR.predict(test_predictions, coefficients)<br/>df_predictions = pd.concat([df_test[['PetID']], pd.DataFrame(test_predictions, columns=[dependent_var])], axis=1)<br/>df_submission = pd.merge(df_sample_submission, df_predictions, on='PetID')<br/>df_submission.to_csv('submission.csv', index=False)</span></pre><p id="c423" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">Kaggle使用连续和离散分类特征对该提交进行评分，得分为0.35155。</p><h2 id="1b6d" class="ne md iq bd me nq nr dn mi ns nt dp mm lb nu nv mo lf nw nx mq lj ny nz ms oa bi translated">第2轮—连续特征和分类嵌入</h2><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="8c91" class="ne md iq na b gy nf ng l nh ni">use_categorical = False<br/>use_embedded = True</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi os"><img src="../Images/8c90aafdeaa119007cb737625b07fa36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0mQb6Cntr3S2xDwwBLVMZQ.png"/></div></div></figure><p id="1edd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在连续特征和分类嵌入上训练的最佳模型的RMSE是1.0775805，在1，869次训练迭代后达到。这比第一轮的0.15%略有下降。</p><p id="4717" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">Kaggle对本次提交的评分为0.34823，比我们的第一次Kaggle评分下降了0.94%。</p><h1 id="9d96" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">第3轮—连续特征、离散分类特征和分类嵌入</h1><pre class="kg kh ki kj gt mz na nb nc aw nd bi"><span id="262d" class="ne md iq na b gy nf ng l nh ni">use_categorical = True<br/>use_embedded = True</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi ot"><img src="../Images/7643d870f163deccf8b4d0b56013cdf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EraPPoA8abRls5_0oEBJlQ.png"/></div></div></figure><p id="32ec" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在连续特征、离散分类特征和分类嵌入上训练的最佳模型的RMSE值是1.0787290。这比第一轮的最佳RMSE下降了0.24%。</p><p id="33ee" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">然而，当我们将这个模型提交给Kaggle时，我们得到了最好的分数，0.35787，比第一轮提交的1.80%有所提高。</p><h1 id="711d" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">结论</h1><p id="7b24" class="pw-post-body-paragraph ks kt iq ku b kv mu jr kx ky mv ju la lb mw ld le lf mx lh li lj my ll lm ln ij bi translated">我们进行了三次训练并提交给Kaggle，有和没有离散的分类特征和分类嵌入。我们只做了最少量的预处理和特征工程。这些是结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/e1e3832509e5f05fb1646498ab27a76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*prgi7T7maoSwvx4cDwW4-Q.png"/></div></figure><p id="83e4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们发现，针对验证数据集的最低RMSE是由仅使用离散分类特征的模型实现的(所有模型都使用归一化的连续特征)。然而，在RMSE，三种模式之间的差异很小。</p><p id="531b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">Kaggle分数是最重要的指标。它决定了参赛者在整体竞争中的位置。它还提供了模型针对全新数据集做出概括预测的能力的最佳指示。</p><p id="46d9" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我们可以看到，在这一指标上得分最高的模型是我们使用原始连续特征、离散分类特征和分类嵌入所尝试的最终模型。该模型的得分为0.35787，比我们第二好的提交结果提高了1.8%。这可能不是一个巨大的进步，但在每一分都很重要的Kaggle比赛中意义重大。</p><p id="3e38" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这也许并不奇怪。尽管分类嵌入是从离散的分类特征中提取的，但其中包含的信息不仅仅是离散值。这是因为表格学习器已经推断出离散值之间的关系，并将这些关系封装在分类嵌入中。</p><p id="24a6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我选择了PetFinder.my领养数据集，因为它很小，很容易理解。具有更多分类变量的较大数据集，或者具有更高基数(更多离散值)的分类变量的数据集，可能会从分类嵌入的使用中获益更多。此外，我没有对表格学习器的超参数进行优化，例如调整神经元和层的数量、学习速率、权重衰减、退出、嵌入大小等。所有这些可能使范畴嵌入变得更有意义。</p></div></div>    
</body>
</html>