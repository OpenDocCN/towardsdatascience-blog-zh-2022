<html>
<head>
<title>How to Define Custom Layer, Activation Function, and Loss Function in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在 TensorFlow 中定义自定义图层、激活函数和损失函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-define-custom-layer-activation-function-and-loss-function-in-tensorflow-bdd7e78eb67#2022-11-10">https://towardsdatascience.com/how-to-define-custom-layer-activation-function-and-loss-function-in-tensorflow-bdd7e78eb67#2022-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/36610972df23d22207b12da5c5f3bd80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rFRE8Ah6U6f87-fa"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://unsplash.com/@adrienconverse?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿德里安·匡威</a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="9768" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">一步一步的解释和完整代码的例子</h2></div><p id="c39f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我有几个关于 Tensorflow 的教程，其中一直使用内置损失函数和层。但是 Tensorflow 比这更有活力。它允许我们编写自己的自定义损失函数，并创建自己的自定义层。所以，在 Tensorflow 中制作高效模型的方法有很多。</p><p id="0295" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最好的学习方法是边做边学。因此，我们将通过使用免费公共数据集的练习来学习，我在上一篇关于多输出模型的教程中使用了该数据集。</p><p id="8c9a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我假设你已经知道数据分析、数据清理和 Tensorflow 的基础知识。所以，我们会在开始的时候动作快一点。</p><h2 id="b7cc" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">数据处理</h2><p id="df8a" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我将在本教程中使用的<a class="ae jg" href="https://opendatacommons.org/licenses/pddl/" rel="noopener ugc nofollow" target="_blank">开放公共数据集</a>相当干净。但是，一点点的清洁是必要的。</p><p id="be88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是数据集的链接:</p><div class="is it gp gr iu ms"><a href="https://datahub.io/machine-learning/autos#resource-autos" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">汽车</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">DataHub.io by -我们构建能够释放数据潜力的解决方案，让我们从您的解决方案开始吧！了解更多关于我们的信息“现在…</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">数据中心. io</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng ja ms"/></div></div></a></div><p id="d717" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我已经根据需要清理了数据集。请随时从这里下载干净的数据集，以便跟进:</p><div class="is it gp gr iu ms"><a href="https://github.com/rashida048/Tensorflow/blob/main/auto_price.csv" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">tensor flow/auto _ price . CSV at main rashida 048/tensor flow</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">github.com</p></div></div><div class="nb l"><div class="nh l nd ne nf nb ng ja ms"/></div></div></a></div><p id="bc8a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们开始吧。</p><p id="002a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先在这里导入所有必需的包:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="650f" class="lu lv jj nn b gy nr ns l nt nu">import numpy as np<br/>import pandas as pd</span><span id="3ea8" class="lu lv jj nn b gy nv ns l nt nu">import tensorflow as tf <br/>from tensorflow.keras import Sequential <br/>from tensorflow.keras.layers import Dense <br/>from tensorflow.keras.optimizers import Adam <br/>from tensorflow.keras import backend as K<br/>from tensorflow.keras.layers import Layer</span></pre><p id="5bfc" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是数据集:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="1f4c" class="lu lv jj nn b gy nr ns l nt nu">df = pd.read_csv("auto_price.csv")</span></pre><p id="046a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">尽管我说过这是一个干净的数据集，但它仍然有两个不必要的列需要删除:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="cdfa" class="lu lv jj nn b gy nr ns l nt nu">df = df.drop(columns=['Unnamed: 0', 'symboling'])</span></pre><p id="f314" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将把数据集分成三部分。一个用于培训，一个用于测试，一个用于验证。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="daa8" class="lu lv jj nn b gy nr ns l nt nu">from sklearn.model_selection import train_test_split<br/>train, test = train_test_split(df, test_size=0.2, random_state=2)<br/>train, val = train_test_split(train, test_size=0.2, random_state=23)</span></pre><p id="da40" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">要使用 z 得分方法对训练数据进行规范化，我们需要知道所有训练特征的平均值和标准差。我是这样得到它的:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="4d7f" class="lu lv jj nn b gy nr ns l nt nu">train_stats = train.describe()<br/>train_stats= train_stats.transpose()<br/>train_stats</span></pre><figure class="ni nj nk nl gt iv gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/c19d1479b15c0fab646d0171bf627134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*1qeuycUdGH5GI7SzgyRAwg.jpeg"/></div></figure><p id="e946" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有额外的信息，但平均值和标准差也在那里。</p><p id="f242" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该范数函数获取数据，并使用我们在上一步中获得的平均值和标准差对其进行归一化处理:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="c405" class="lu lv jj nn b gy nr ns l nt nu">def norm(x):<br/>    return (x - train_stats['mean']) / train_stats['std']</span></pre><p id="4fc9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们标准化训练、测试和验证数据:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="2330" class="lu lv jj nn b gy nr ns l nt nu">train_x = norm(train)<br/>test_x = norm(test)<br/>val_x = norm(val)</span></pre><p id="1ac5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本练习中，汽车的价格将用作目标变量，其余变量用作训练特征。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="de21" class="lu lv jj nn b gy nr ns l nt nu">train_x = train_x.drop(columns='price')<br/>test_x = test_x.drop(columns='price')<br/>val_x=val_x.drop(columns='price')</span><span id="c994" class="lu lv jj nn b gy nv ns l nt nu">train_y = train['price']<br/>test_y = test['price']<br/>val_y = val['price']</span></pre><p id="b519" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">训练和目标变量准备好了。</p><h2 id="39fd" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">自定义损失和自定义图层</h2><p id="6e6c" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">先说损失函数，大家都知道。这就是均方根误差。我们将它定义为一个函数，并在编译模型时传递该函数。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="3baf" class="lu lv jj nn b gy nr ns l nt nu">def rmse(y_true, y_pred):<br/>    return K.sqrt(K.mean(K.square(y_pred - y_true)))</span></pre><p id="244f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">看起来很眼熟吧？让我们把这个函数放在手边，以备后用。你可以尝试许多其他种类的损失函数。</p><p id="1470" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，转到自定义层。同样，我们将使用简单的线性公式 Y=WX+B 作为公式。该公式要求权重是 X 和偏差的系数(在公式中表示为“B”)。在您看到代码后，我会更详细地解释这一点:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="3e1b" class="lu lv jj nn b gy nr ns l nt nu">class SimpleLinear(Layer):</span><span id="4bd0" class="lu lv jj nn b gy nv ns l nt nu">def __init__(self, units=64, activation=None):<br/>        super(SimpleLinear, self).__init__()<br/>        self.units = units<br/>        self.activation=tf.keras.activations.get(activation)</span><span id="1bbb" class="lu lv jj nn b gy nv ns l nt nu">def weightsAndBias(self, input_shape):<br/>        w_init = tf.random_normal_initializer()<br/>        self.w = tf.Variable(name="kernel",<br/>            initial_value=w_init(shape=(input_shape[-1], self.units),<br/>                                 dtype='float32'),<br/>            trainable=True)</span><span id="3a06" class="lu lv jj nn b gy nv ns l nt nu">b_init = tf.zeros_initializer()<br/>        self.b = tf.Variable(name="bias",<br/>            initial_value=b_init(shape=(self.units,), dtype='float32'),<br/>            trainable=True)</span><span id="3e22" class="lu lv jj nn b gy nv ns l nt nu">def call(self, inputs):<br/>        return self.activation(tf.matmul(inputs, self.w) + self.b)</span></pre><p id="c6a9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的代码中，我们从传递单元和激活作为参数开始。这里我使用的单位是 64，这意味着 64 个神经元。我们将最终在模型中指定不同数量的神经元。这里没有激活。我们也将在模型中使用激活。</p><p id="8887" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在上面的“权重和偏差”中，我们初始化权重和偏差，其中权重初始化为随机数，偏差初始化为零。</p><p id="21a3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在调用函数中，我们使用矩阵乘法(matmul 方法执行矩阵乘法)将输入和权重相乘，并添加偏差(记住公式 wx+b)</p><blockquote class="nx"><p id="3a69" class="ny nz jj bd oa ob oc od oe of og lt dk translated">这是最基本的一条。请随意尝试一些非线性层，可能是二次或三次公式。</p></blockquote><h2 id="16ed" class="lu lv jj bd lw lx oh dn lz ma oi dp mc lh oj me mf ll ok mh mi lp ol mk ml mm bi translated">模型开发</h2><p id="6c04" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">模型开发是比较简单的部分。我们有 24 个变量作为训练特征。所以输入形状是(24，)。以下是完整的模型:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="d661" class="lu lv jj nn b gy nr ns l nt nu">model = tf.keras.models.Sequential([<br/>    tf.keras.layers.Flatten(input_shape=(24,)),<br/>    SimpleLinear(512, activation='relu'),<br/>    tf.keras.layers.Dropout(0.2),<br/>    SimpleLinear(256, activation='relu'),<br/>    SimpleLinear(128, activation='relu'),<br/>    tf.keras.layers.Dense(1, activation='relu')<br/>])</span></pre><p id="69d2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，我们简单地称我们之前定义的简单线性方法为层。<strong class="la jk"> 512、256 和 128 是单位，激活是“relu”</strong>。</p><p id="aaed" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不过也可以使用自定义激活方法，这将在下一部分中介绍。</p><p id="5da1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们编译模型并使用我们之前定义的损失函数“rmse ”:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="1514" class="lu lv jj nn b gy nr ns l nt nu">model.compile(optimizer='adam',<br/>              loss = rmse,<br/>              metrics=tf.keras.metrics.RootMeanSquaredError())<br/>h = model.fit(train_x, train_y, epochs=3)<br/>model.evaluate(val_x, val_y)</span></pre><p id="f7bb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">输出:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="e5ca" class="lu lv jj nn b gy nr ns l nt nu">Epoch 1/3<br/>4/4 [==============================] - 0s 3ms/step - loss: 13684.0762 - root_mean_squared_error: 13726.8496<br/>Epoch 2/3<br/>4/4 [==============================] - 0s 3ms/step - loss: 13669.2314 - root_mean_squared_error: 13726.8496<br/>Epoch 3/3<br/>4/4 [==============================] - 0s 3ms/step - loss: 13537.3682 - root_mean_squared_error: 13726.8496</span></pre><p id="d00f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在下一部分中，我们将实验一些自定义的激活函数。</p><h2 id="d295" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">自定义激活功能</h2><p id="9403" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">我将在这里解释使用自定义激活功能的两种方法。第一个是使用λ层。lambda 层定义了该层中的函数。</p><p id="05e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，在下面的模型中，lambda 层获取 SimpleLinear 方法的输出，并获取其绝对值，因此我们不会得到任何负值。</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="2aaf" class="lu lv jj nn b gy nr ns l nt nu">model = tf.keras.models.Sequential([<br/>    tf.keras.layers.Flatten(input_shape=(24,)),<br/>    SimpleLinear(512),<br/>    tf.keras.layers.Lambda(lambda x: tf.abs(x)),<br/>    tf.keras.layers.Dropout(0.2),<br/>    SimpleLinear(256),<br/>    tf.keras.layers.Lambda(lambda x: tf.abs(x)),<br/>    tf.keras.layers.Dense(1),<br/>    tf.keras.layers.Lambda(lambda x: tf.abs(x)),<br/>])</span></pre><p id="541a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请随意尝试 lambda 层中的任何其他类型的操作。</p><blockquote class="nx"><p id="a803" class="ny nz jj bd oa ob oc od oe of og lt dk translated">您不必在 lambda 层本身定义操作。它可以在函数中定义，并传递给 lambda 层。</p></blockquote><p id="da48" class="pw-post-body-paragraph ky kz jj la b lb om kk ld le on kn lg lh oo lj lk ll op ln lo lp oq lr ls lt im bi translated">这是一个获取数据并求平方的函数:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="d1ee" class="lu lv jj nn b gy nr ns l nt nu">def active1(x):<br/>    return x**2</span></pre><p id="528b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，这个函数可以像这样简单地传递给 lambda 层:</p><pre class="ni nj nk nl gt nm nn no np aw nq bi"><span id="1f32" class="lu lv jj nn b gy nr ns l nt nu">model = tf.keras.models.Sequential([<br/>    tf.keras.layers.Flatten(input_shape=(24,)),<br/>    SimpleLinear(512),<br/>    tf.keras.layers.Lambda(active1),<br/>    tf.keras.layers.Dropout(0.2),<br/>    SimpleLinear(256),<br/>    tf.keras.layers.Lambda(active1),<br/>    tf.keras.layers.Dense(1),<br/>    tf.keras.layers.Lambda(active1),<br/>])</span></pre><p id="4be8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据您的项目和需求，可以使用许多其他不同的功能。</p><h2 id="5131" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">结论</h2><p id="848a" class="pw-post-body-paragraph ky kz jj la b lb mn kk ld le mo kn lg lh mp lj lk ll mq ln lo lp mr lr ls lt im bi translated">Tensorflow 可以如此动态地使用。有很多不同的方法可以操纵它。在这篇文章中，我想分享一些让 Tensorflow 更加灵活的方法。我希望它是有帮助的，并且你在你自己的项目中尝试它。</p><p id="0042" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欢迎在<a class="ae jg" href="https://twitter.com/rashida048" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我，并喜欢我的<a class="ae jg" href="https://www.facebook.com/rashida.smith.161" rel="noopener ugc nofollow" target="_blank">脸书</a>页面。</p><h2 id="ebb6" class="lu lv jj bd lw lx ly dn lz ma mb dp mc lh md me mf ll mg mh mi lp mj mk ml mm bi translated">更多阅读</h2><div class="is it gp gr iu ms"><a rel="noopener follow" target="_blank" href="/a-step-by-step-tutorial-to-develop-a-multi-output-model-in-tensorflow-ec9f13e5979c"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">在 TensorFlow 中开发多输出模型的分步教程</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">有完整的代码</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="or l nd ne nf nb ng ja ms"/></div></div></a></div><div class="is it gp gr iu ms"><a rel="noopener follow" target="_blank" href="/regression-in-tensorflow-using-both-sequential-and-function-apis-314e74b537ca"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">TensorFlow 中使用顺序 API 和函数 API 的回归</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">演示几种不同类型的模型结构</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="os l nd ne nf nb ng ja ms"/></div></div></a></div><div class="is it gp gr iu ms"><a rel="noopener follow" target="_blank" href="/what-is-a-recurrent-neural-network-and-implementation-of-simplernn-gru-and-lstm-models-in-keras-f7247e97c405"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">在 Keras 中实现 SimpleRNN、GRU 和 LSTM 模型</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">什么是递归神经网络以及三种递归神经网络在 Tensorflow 和</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="ot l nd ne nf nb ng ja ms"/></div></div></a></div><div class="is it gp gr iu ms"><a rel="noopener follow" target="_blank" href="/30-very-useful-pandas-functions-for-everyday-data-analysis-tasks-f1eae16409af"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">30 个非常有用的熊猫函数，用于日常数据分析任务</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">熊猫小型张</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="ou l nd ne nf nb ng ja ms"/></div></div></a></div><div class="is it gp gr iu ms"><a rel="noopener follow" target="_blank" href="/pivot-and-unpivot-functions-in-bigquery-for-better-data-manipulation-f0230295bd5e"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd jk gy z fp mx fr fs my fu fw ji bi translated">BigQuery 中的 Pivot 和 Unpivot 函数用于更好的数据操作</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">详细的教程</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">towardsdatascience.com</p></div></div><div class="nb l"><div class="ov l nd ne nf nb ng ja ms"/></div></div></a></div></div></div>    
</body>
</html>