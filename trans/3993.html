<html>
<head>
<title>How to turn your local (zip) data into a Huggingface Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将本地(zip)数据转换成Huggingface数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-turn-your-local-zip-data-into-a-huggingface-dataset-43f754c68f82#2022-09-06">https://towardsdatascience.com/how-to-turn-your-local-zip-data-into-a-huggingface-dataset-43f754c68f82#2022-09-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="af21" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph">拥抱面部数据集</h2><div class=""/><div class=""><h2 id="3850" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在一行代码中快速加载数据集，用于训练深度学习模型</h2></div><div class="kr ks gp gr kt ku"><a href="https://github.com/V-Sher/HF-Loading-Script" rel="noopener  ugc nofollow" target="_blank"><div class="kv ab fo"><div class="kw ab kx cl cj ky"><h2 class="bd jd gy z fp kz fr fs la fu fw jc bi translated">GitHub-V-Sher/HF-Loading-Script:如何为HuggingFace数据集编写自定义加载脚本</h2><div class="lb l"><h3 class="bd b gy z fp kz fr fs la fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="lc l"><p class="bd b dl z fp kz fr fs la fu fw dk translated">github.com</p></div></div><div class="ld l"><div class="le l lf lg lh ld li lj ku"/></div></div></a></div><h1 id="4fc7" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">什么是拥抱脸🤗数据集？</h1><p id="c501" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">如果你已经在深度学习领域工作了一段时间(或者即使你只是最近才开始钻研)，很有可能，你会遇到<a class="ae my" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">hugging face</a>——一个开源的ML库，它是所有人工智能(预训练模型、数据集、推理API、GPU/TPU可扩展性、优化器等)的圣杯。</p><p id="d5a0" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">他们还有一个专门的图书馆—🤗D <a class="ae my" href="https://huggingface.co/docs/datasets/index" rel="noopener ugc nofollow" target="_blank">数据集</a>用于轻松访问和共享自然语言处理(NLP)、计算机视觉和音频任务的数据集。</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="eae4" class="nn ll it nj b gy no np l nq nr">pip install datasets</span></pre><p id="3bdc" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">这个库预装了2500多个数据集。您可以按如下方式检查列表:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="0ec2" class="nn ll it nj b gy no np l nq nr">from datasets import list_datasets<br/>list_datasets()</span><span id="5987" class="nn ll it nj b gy ns np l nq nr">*** OUTPUT ****</span><span id="6751" class="nn ll it nj b gy ns np l nq nr">['acronym_identification',<br/> 'ade_corpus_v2',<br/> 'adversarial_qa',<br/> 'aeslc',<br/> 'afrikaans_ner_corpus',<br/> 'ag_news',<br/> ...<br/>]</span></pre><p id="da7b" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">要在当前的python脚本或jupyter笔记本中加载这些数据集，只需将数据集的名称传递给<code class="fe nt nu nv nj b">load_dataset()</code>。例如，让我们用<code class="fe nt nu nv nj b">asr</code>(自动语音识别)配置加载一个名为<code class="fe nt nu nv nj b">superb</code>的流行音频数据集，并检查第一个音频文件。输出是具有六个特征的字典— <code class="fe nt nu nv nj b">chapter_id</code>、<code class="fe nt nu nv nj b">file</code>、<code class="fe nt nu nv nj b">audio</code>、<code class="fe nt nu nv nj b">id</code>、<code class="fe nt nu nv nj b">speaker_id</code>和<code class="fe nt nu nv nj b">text</code>。</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="05c6" class="nn ll it nj b gy no np l nq nr">from datasets import load_dataset<br/><strong class="nj jd">dataset = load_dataset("superb", "asr")</strong><br/>dataset[0]</span><span id="7823" class="nn ll it nj b gy ns np l nq nr">*** OUTPUT *** <br/>{'chapter_id': 1240,<br/> 'file': 'path/to/file.flac',<br/> 'audio': {<br/>       'array': array([0., 0.003, -0.0002,..., dtype=float32),<br/>       'path': 'path/to/file.flac',<br/>       'sampling_rate': 16000<br/>           }<br/> 'id': '103-1240-0000',<br/> 'speaker_id': 103,<br/> 'text': 'CHAPTER ONE MISSUS RACHEL LYNDE IS SURPRISED MISSUS  RACHEL LYNDE '<br/> }</span></pre><h1 id="0423" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">这篇文章是关于什么的？</h1><p id="9399" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">我开始写这篇文章的主要原因之一是因为我想微调一个🤗在自定义音频数据集上使用<a class="ae my" href="https://huggingface.co/docs/transformers/v4.21.3/en/main_classes/trainer#trainer" rel="noopener ugc nofollow" target="_blank">训练器API </a>的变压器模型(博客随后发布)。我遇到的大多数教程都在使用一个流行的数据集(如<a class="ae my" href="https://huggingface.co/datasets/superb" rel="noopener ugc nofollow" target="_blank"> Superb </a>、<a class="ae my" href="https://huggingface.co/datasets/librispeech_asr" rel="noopener ugc nofollow" target="_blank"> Librispeech </a>等)，这些数据集预装在库中，开箱即用。</p><p id="27d5" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">想要使用Kaggle的<a class="ae my" href="https://www.kaggle.com/datasets/ejlok1/cremad" rel="noopener ugc nofollow" target="_blank"> Crema-D </a>音频数据集，我想——<em class="nw">如果我们也可以像上面一样用一行代码加载我们自己的定制数据，那不是很好吗？大致意思是:</em></p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="76cd" class="nn ll it nj b gy no np l nq nr">dataset = load_dataset("my_custom_dataset")</span></pre><p id="4b30" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">这正是我们在本教程中要学习的！因此，请点击<a class="ae my" href="https://www.kaggle.com/datasets/ejlok1/cremad?resource=download" rel="noopener ugc nofollow" target="_blank">此链接</a>上的<em class="nw">下载</em>按钮，跟随本教程。您应该看到包含Crema-D音频文件的<code class="fe nt nu nv nj b">archive.zip</code>开始下载。它包含7k+音频文件，格式为<code class="fe nt nu nv nj b">.wav</code>。</p><h1 id="004b" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">经历这些麻烦有什么好处吗？</h1><p id="b113" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">创造的一个主要好处是🤗数据集是由箭头<a class="ae my" href="https://huggingface.co/docs/datasets/about_arrow#what-is-arrow" rel="noopener ugc nofollow" target="_blank">支持的。换句话说，数据集缓存在磁盘上。需要时，它们直接从磁盘(提供快速查找)进行</a><a class="ae my" href="https://en.wikipedia.org/wiki/Memory-mapped_file" rel="noopener ugc nofollow" target="_blank">内存映射</a>，而不是加载到内存(即RAM)中。正因为如此，内存相对较小的机器仍然可以使用Huggingface数据集<a class="ae my" href="https://huggingface.co/docs/datasets/about_arrow#memorymapping" rel="noopener ugc nofollow" target="_blank"> <em class="nw">【源】</em> </a>加载大型数据集。</p><h1 id="9ea6" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">好的，我被说服了，我们开始吧…</h1><p id="e56b" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">假设我们需要使用定制的本地CremaD数据集——这意味着它还不能使用<code class="fe nt nu nv nj b">load_dataset()</code>开箱即用地加载，我们需要编写一个<strong class="me jd">加载脚本</strong>来代替。我们上面看到的每个预装数据集在后端都有自己的加载脚本。<a class="ae my" href="https://github.com/huggingface/datasets/blob/main/datasets/superb/superb.py" rel="noopener ugc nofollow" target="_blank">这里的</a>是针对<code class="fe nt nu nv nj b">superb</code>数据集的。</p><blockquote class="nx ny nz"><p id="1dbd" class="mc md nw me b mf mz kd mh mi na kg mk oa nb mn mo ob nc mr ms oc nd mv mw mx im bi translated">加载脚本是一个<code class="fe nt nu nv nj b"><em class="it">.py</em></code> python脚本，我们将其作为输入传递给<code class="fe nt nu nv nj b"><em class="it">load_dataset()</em></code>。(而不是预安装的数据集名称)。它包含有关列及其数据类型的信息，指定数据集的训练测试拆分，处理下载文件(如果需要)以及从数据集生成样本。</p><p id="1cc0" class="mc md nw me b mf mz kd mh mi na kg mk oa nb mn mo ob nc mr ms oc nd mv mw mx im bi translated">加载脚本还有助于将<strong class="me jd">数据集代码</strong>与<strong class="me jd">模型训练代码</strong>解耦，以获得更好的可读性和模块化。</p></blockquote><p id="601f" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">假设我们已经成功创建了上述脚本，那么我们应该能够如下加载数据集:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="98ac" class="nn ll it nj b gy no np l nq nr">ds = load_dataset(<br/>  dataset_config["LOADING_SCRIPT_FILES"],<br/>  dataset_config["CONFIG_NAME"],<br/>  <em class="nw">data_dir</em>=dataset_config["DATA_DIR"],<br/>  <em class="nw">cache_dir</em>=dataset_config["CACHE_DIR"]<br/>)</span></pre><p id="a06e" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">其中<code class="fe nt nu nv nj b">dataset_config</code>是一个简单的字典，包含以下值:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="8464" class="nn ll it nj b gy no np l nq nr">dataset_config = {<br/>  "LOADING_SCRIPT_FILES": path/to/loading/script.py,<br/>  "CONFIG_NAME": "clean",<br/>  "DATA_DIR": path/to/zip/file,<br/>  "CACHE_DIR": path/to/cache/directory,<br/>}</span></pre><p id="b61f" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">通过在调用<code class="fe nt nu nv nj b">load_dataset()</code>时传递<code class="fe nt nu nv nj b">data_dir</code>，我们告诉加载脚本在哪里寻找包含音频文件的目录。此外，设置一个<code class="fe nt nu nv nj b">cache_dir</code>将允许我们在后续调用<code class="fe nt nu nv nj b">load_dataset()</code>时重用数据集的缓存版本。</p><p id="c0b7" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">最后，我们将专注于构建一个名为<code class="fe nt nu nv nj b">clean</code>的配置。但是，一个数据集内可以有多个配置。例如，在上面的<code class="fe nt nu nv nj b">superb</code>示例中，我们使用特定的配置(即<code class="fe nt nu nv nj b">asr</code>)加载数据集，但是它们还有五个其他配置— <code class="fe nt nu nv nj b">ks</code>、<code class="fe nt nu nv nj b">ic</code>、<code class="fe nt nu nv nj b">si</code>、<code class="fe nt nu nv nj b">sd</code>和<code class="fe nt nu nv nj b">er</code>。</p><p id="211b" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">同样，对于本教程，除了拥有一个包含整个数据集的<code class="fe nt nu nv nj b">clean</code>配置之外，我们还可以拥有第二个配置，比如说<code class="fe nt nu nv nj b">small</code>，它可以是一个用于测试目的的精简数据集，或者第三个配置，比如说<code class="fe nt nu nv nj b">fr</code>，它可以包含这个数据集的法语版本。(在本教程的最后，我将简要讨论如何在同一个加载脚本中定义多个配置)。</p><h2 id="9229" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">快速绕道</h2><p id="51dd" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">在我们开始为数据集(包含在一个zip文件中)编写定制加载脚本之前，我想指出如果我们处理🤗<a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#from-local-files" rel="noopener ugc nofollow" target="_blank">来自简单数据格式</a>文件的数据集，如csv、JSON等。以下示例直接取自文档页面:</p><ul class=""><li id="42d0" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#csv-files" rel="noopener ugc nofollow" target="_blank"> csv </a></li></ul><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="e463" class="nn ll it nj b gy no np l nq nr">dataset = load_dataset(‘csv’, data_files=[‘my_file_1.csv’, ‘my_file_2.csv’])</span></pre><ul class=""><li id="9e3f" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#json-files" rel="noopener ugc nofollow" target="_blank"> json </a></li></ul><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="37a5" class="nn ll it nj b gy no np l nq nr">dataset = load_dataset(‘json’, data_files=’my_file.json’)</span></pre><ul class=""><li id="1e62" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#text-files" rel="noopener ugc nofollow" target="_blank">正文</a></li></ul><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="cc72" class="nn ll it nj b gy no np l nq nr">dataset = load_dataset(‘text’, data_files={‘train’: [‘my_text_1.txt’, ‘my_text_2.txt’], ‘test’: ‘my_test_file.txt’})</span></pre><ul class=""><li id="02b5" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#from-a-python-dictionary" rel="noopener ugc nofollow" target="_blank"> python字典</a></li></ul><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="aece" class="nn ll it nj b gy no np l nq nr">my_dict = {'id': [0, 1, 2], 'name': ['mary', 'bob', 'eve'], 'age': [24, 53, 19]}</span><span id="f088" class="nn ll it nj b gy ns np l nq nr">dataset = Dataset.from_dict(my_dict)</span></pre><ul class=""><li id="c5aa" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/loading_datasets.html#from-a-pandas-dataframe" rel="noopener ugc nofollow" target="_blank">熊猫数据帧</a></li></ul><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="033c" class="nn ll it nj b gy no np l nq nr">df = pd.DataFrame({"a": [1, 2, 3]})<br/>dataset = Dataset.from_pandas(df)</span></pre><h2 id="4323" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">编写自定义加载脚本</h2><p id="8174" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">回到我们的定制加载脚本，让我们创建一个名为<code class="fe nt nu nv nj b">crema.py</code>的新文件。这是任何新数据集的典型加载脚本:</p><figure class="ne nf ng nh gt ow"><div class="bz fp l di"><div class="ox oy l"/></div><p class="oz pa gj gh gi pb pc bd b be z dk translated">图1:使用Huggingface提供的空白<a class="ae my" href="https://github.com/huggingface/datasets/blob/main/templates/new_dataset_script.py" rel="noopener ugc nofollow" target="_blank">模板</a>生成。</p></figure><p id="b03b" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">如您所见，有三个主要功能需要修改— <code class="fe nt nu nv nj b">info()</code>、<code class="fe nt nu nv nj b">split_generator()</code>和<code class="fe nt nu nv nj b">generate_examples()</code>。让我们一个一个来看:</p><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi pd"><img src="../Images/7c75580570a157838700728d349db392.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b4mYQb9tWDkuGC9s.png"/></div></div><p class="oz pa gj gh gi pb pc bd b be z dk translated"><a class="ae my" href="https://huggingface.co/docs/datasets/about_dataset_load" rel="noopener ugc nofollow" target="_blank">来源</a>:官方拥抱脸文档</p></figure><h2 id="423e" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated"><code class="fe nt nu nv nj b">1. info()</code></h2><p id="2f8f" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">在该方法中要指定的三个最重要的属性是:</p><ul class=""><li id="bb8e" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><em class="nw">描述</em> —包含数据集快速摘要的字符串对象。</li><li id="0968" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated"><em class="nw">特性</em> —就像为数据集定义一个框架/元数据一样。也就是说，您希望为每个音频样本存储哪些特征？(还记得<code class="fe nt nu nv nj b">superb</code>数据集如何为每个音频文件定义了六个特征)。<br/>对于我们的音频分类任务，我们只需要定义一个<code class="fe nt nu nv nj b">file</code>和相应的<code class="fe nt nu nv nj b">label</code>。</li><li id="18bc" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated"><em class="nw">主页—(可选)链接到数据集</em>的主页URL。</li></ul><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi po"><img src="../Images/1bd020a34288c3f7092b5756cf552a4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8T2x0nesZtLiSOrxnsLovg.png"/></div></div></figure><p id="e03f" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">需要考虑的事情很少:</p><ul class=""><li id="b516" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated">每个列名及其类型统称为<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Features" rel="noopener ugc nofollow" target="_blank">特性的</a>🤗数据集。它采用了<code class="fe nt nu nv nj b">dict[column_name, column_type]</code>的形式。</li><li id="02c6" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated">根据<code class="fe nt nu nv nj b">column_type</code>，我们可以拥有<br/> — <a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Value" rel="noopener ugc nofollow" target="_blank">数据集。值</a>(整数和字符串)、<br/> — <a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.ClassLabel" rel="noopener ugc nofollow" target="_blank">数据集。ClassLabel </a>(对于一组预定义的带有相应整数标签的类)，<br/> — <a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Sequence" rel="noopener ugc nofollow" target="_blank">数据集。序列</a>特征(用于对象列表)。<br/>—<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Features" rel="noopener ugc nofollow" target="_blank">还有更多</a>。</li><li id="ac22" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated">在我们的代码中，为了简单起见，<code class="fe nt nu nv nj b">file</code>和<code class="fe nt nu nv nj b">label</code>都被定义为<code class="fe nt nu nv nj b">string</code>类型的<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Value" rel="noopener ugc nofollow" target="_blank">值</a>特征。<br/> <em class="nw">注:除</em> <code class="fe nt nu nv nj b"><em class="nw">string</em></code> <em class="nw">外，其他数据类型包括</em><code class="fe nt nu nv nj b"><em class="nw">int32</em></code><em class="nw"/><code class="fe nt nu nv nj b"><em class="nw">bool</em></code><em class="nw"/><code class="fe nt nu nv nj b"><em class="nw"> timestamp</em></code><em class="nw">等。查看完整列表</em> <a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/main_classes#datasets.Value" rel="noopener ugc nofollow" target="_blank"> <em class="nw">此处</em> </a> <em class="nw">。</em></li><li id="ef24" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated">除了<code class="fe nt nu nv nj b">description</code>、<code class="fe nt nu nv nj b">features</code>、<code class="fe nt nu nv nj b">homepage</code>之外，你可以在<a class="ae my" href="https://huggingface.co/docs/datasets/v1.11.0/package_reference/main_classes.html#datasets.DatasetInfo" rel="noopener ugc nofollow" target="_blank">这里查看</a>其他可以在<code class="fe nt nu nv nj b">info()</code>中指定的属性，如版本号、supervised_keys、引用等。</li></ul><h2 id="a510" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">2.<code class="fe nt nu nv nj b">split_generator()</code></h2><p id="28c5" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">这是负责下载或检索数据文件的功能。这就是为什么在图1的函数定义中，<a class="ae my" href="https://huggingface.co/docs/datasets/v1.1.1/_modules/datasets/utils/download_manager.html#DownloadManager" rel="noopener ugc nofollow" target="_blank">下载管理器</a>(即<code class="fe nt nu nv nj b"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.1.1/_modules/datasets/utils/download_manager.html#DownloadManager" rel="noopener ugc nofollow" target="_blank">dl_manager</a></code>)作为函数参数之一被传递。</p><p id="8d75" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><a class="ae my" href="https://huggingface.co/docs/datasets/v1.1.1/_modules/datasets/utils/download_manager.html#DownloadManager" rel="noopener ugc nofollow" target="_blank"> DownloadManager </a>有一个名为<code class="fe nt nu nv nj b">extract()</code>的预定义函数，负责解压我们的数据集并访问其中的音频文件。</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="7584" class="nn ll it nj b gy no np l nq nr">def _split_generator(self, dl_manager):<br/>    data_dir = <strong class="nj jd">dl_manager.extract</strong>(self.config.data_dir)<br/>    .<br/>    .<br/>    .<br/>    .</span></pre><p id="29ce" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">注意:如果您的zip(或tar)数据托管在ftp链接或URL上(例如，</em> <a class="ae my" href="http://www.openslr.org/resources/12/" rel="noopener ugc nofollow" target="_blank"> <em class="nw">这个</em> </a> <em class="nw">是当前存储</em> <code class="fe nt nu nv nj b"><em class="nw">superb</em></code> <em class="nw">数据集的地方)，您可以使用</em> <code class="fe nt nu nv nj b"><em class="nw">dl_manager.download_and_extract()</em></code> <em class="nw">来负责下载和解压缩文件。因为我们已经下载了。zip文件本地，我们只需使用</em> <code class="fe nt nu nv nj b"><em class="nw">extract()</em></code> <em class="nw">解压文件即可。</em></p><p id="4404" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">该函数将数据目录的路径作为输入(即<em class="nw"> archive.zip </em>位于<em class="nw"> ) </em>。记住，当调用<code class="fe nt nu nv nj b">load_dataset()</code>时，我们将该路径作为<code class="fe nt nu nv nj b">data_dir</code>参数传递，因此它将作为配置的一部分可用，并可通过<code class="fe nt nu nv nj b">self.config.data_dir</code>访问。</p><p id="8571" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><code class="fe nt nu nv nj b">extract()</code>函数的输出是一个字符串，包含文件解压后的缓存目录的路径。例如，在我们的例子中，这将是:<code class="fe nt nu nv nj b">/Audio-Classification-Medium /cache_crema/downloads/extracted/d088ccc5a5716.......</code>。在这个位置，你会发现一个新创建的名为<code class="fe nt nu nv nj b">AudioWav</code>的文件夹，里面有我们所有的<code class="fe nt nu nv nj b">.wav</code>音频文件。</p><p id="eb00" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">最后，<code class="fe nt nu nv nj b">split_generator()</code>还使用<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/builder_classes#datasets.SplitGenerator" rel="noopener ugc nofollow" target="_blank"> SplitGenerator </a>通过拆分来组织数据。目前，我们只有一个split，即由这个函数返回的<code class="fe nt nu nv nj b">train_splits</code>，我们将这个函数的<code class="fe nt nu nv nj b">name</code>指定为<code class="fe nt nu nv nj b">train</code>。在这里，<code class="fe nt nu nv nj b">gen_kwargs</code>指的是从这个数据集生成样本所需的关键字参数。它包含两个参数——<code class="fe nt nu nv nj b">files</code>和<code class="fe nt nu nv nj b">name</code>——接下来这两个参数都将被转发给<code class="fe nt nu nv nj b">_generate_examples()</code>方法。</p><p id="c3c3" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">注:</em> <code class="fe nt nu nv nj b"><em class="nw">gen_kwargs</em></code> <em class="nw">内可以通过的没有限制。试试</em> <code class="fe nt nu nv nj b"><em class="nw">gen_kwargs={"files": data_dir, "name": "train", "useless_arg": "helloworld"}</em></code> <em class="nw">。不用说，在</em> <code class="fe nt nu nv nj b">_generate_examples()</code> <em class="nw">中只包含您认为生成样本所需的kwargs。</em></p><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi pp"><img src="../Images/ba107f07bf218be2cb807d0b6c2ac63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ONhrO4583B1UjzqdiVI3hA.png"/></div></div></figure><p id="bf0d" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">提示:将来，如果您有单独的数据集用于测试和验证分割，您可以创建更多的分割，如下所示:</em></p><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi po"><img src="../Images/c3f638a4be19a01647771b6f20c4e9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZndxneiYoDrPYf1n_QyCw.png"/></div></div></figure><h2 id="2b7d" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">3.<code class="fe nt nu nv nj b">generate_examples()</code></h2><p id="881f" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">如前所述，该方法将从<code class="fe nt nu nv nj b">gen_kwargs</code>解包的所有东西作为参数，如<code class="fe nt nu nv nj b">_split_generators</code>中给出的。在我们的例子中，这将是<code class="fe nt nu nv nj b">files</code>和<code class="fe nt nu nv nj b">name</code>:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="648a" class="nn ll it nj b gy no np l nq nr">def _generate_examples(self, files, name):<br/>      .<br/>      .<br/>      .</span></pre><p id="c6af" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">该方法负责从音频数据集(使用<code class="fe nt nu nv nj b"><a class="ae my" href="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do" rel="noopener ugc nofollow" target="_blank">yield</a></code>)逐个生成(<code class="fe nt nu nv nj b">key</code>，<code class="fe nt nu nv nj b">example</code>)元组，其中<code class="fe nt nu nv nj b">example</code>是包含音频文件和标签的键值对的字典。因为我们没有对标签的显式访问，我们需要使用<code class="fe nt nu nv nj b">split()</code>从文件名中提取它们(例如:<code class="fe nt nu nv nj b">1001_DFA_ANG_XX.wav</code>)。</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="f27a" class="nn ll it nj b gy no np l nq nr">file = <!-- -->1001_DFA_ANG_XX.wav</span><span id="a109" class="nn ll it nj b gy ns np l nq nr">label = file<strong class="nj jd">.split</strong>("_")[-2]<br/>print(label)</span><span id="c378" class="nn ll it nj b gy ns np l nq nr">**** OUTPUT ****<br/>ANG</span></pre><p id="d0b0" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">注:根据官方数据集</em> <a class="ae my" href="https://github.com/CheyneyComputerScience/CREMA-D#description" rel="noopener ugc nofollow" target="_blank"> <em class="nw">文档</em> </a> <em class="nw">，文件名包含有用的元数据(用</em> <code class="fe nt nu nv nj b"><em class="nw">_</em></code> <em class="nw">分隔)包括speaker_id (1001)、句子id (DFA)等。如果您想将它们作为数据集的一部分，请确保您更新了</em> <code class="fe nt nu nv nj b"><em class="nw">info()</em></code> <em class="nw">以为它们中的每一个创建新的要素，然后才能在</em> <code class="fe nt nu nv nj b"><em class="nw">generate_examples()</em></code> <em class="nw">中使用它们。</em></p><p id="aef4" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">在我们生成一个示例之前，我们必须创建一个包含所有示例的<em class="nw">列表。让我们通过遍历<code class="fe nt nu nv nj b">os.path.join(files, “AudioWav")</code>目录中的所有文件来实现这一点。</em></p><p id="ab1c" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">注1:如果你想知道为什么我们需要上面的</em> <code class="fe nt nu nv nj b"><em class="nw">os.path.join()</em></code> <em class="nw">，记住</em> <code class="fe nt nu nv nj b"><em class="nw">files</em></code> <em class="nw">是缓存文件夹</em> <code class="fe nt nu nv nj b"><em class="nw">./Audio-Classification-Medium /cache_crema/downloads/extracted/d088ccc5a5716.......</em></code> <em class="nw">的路径——这里没有音频文件！在这个位置，一个新创建的</em> <code class="fe nt nu nv nj b"><em class="nw">AudioWav</em></code> <em class="nw">文件夹包含了需要的</em> <code class="fe nt nu nv nj b"><em class="nw">.wav</em></code> <em class="nw">音频文件。我花了几个小时调试这个！<br/>后知后觉，我下次应该用</em> <code class="fe nt nu nv nj b"><em class="nw">os.walk()</em></code> <em class="nw">。</em></p><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi pq"><img src="../Images/c93b66f947b7ba9e5536489c89927bda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5tPUjoT_IUOGCLzpXJu3Sg.png"/></div></div></figure><p id="8667" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">注2:如果您有一个包含所有元数据(包括标签)的显式csv/json文件，那么</em> <code class="fe nt nu nv nj b"><em class="nw">generate_examples()</em></code> <em class="nw">的代码看起来会有点不同。不是遍历所有文件，而是需要(a)遍历csv文件中的行,( b)使用</em> <code class="fe nt nu nv nj b"><em class="nw">.todict()</em></code> <em class="nw">将每一行转换成一个字典——以创建</em> <code class="fe nt nu nv nj b"><em class="nw">examples</em></code> <em class="nw">列表。请看下面的虚拟片段:</em></p><figure class="ne nf ng nh gt ow"><div class="bz fp l di"><div class="ox oy l"/></div></figure><p id="3a75" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><strong class="me jd">最终代码为</strong> <code class="fe nt nu nv nj b"><strong class="me jd">crema.py</strong></code> <strong class="me jd">。</strong></p><figure class="ne nf ng nh gt ow"><div class="bz fp l di"><div class="ox oy l"/></div></figure><p id="5e66" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">需要考虑的额外变化很少:</p><ul class=""><li id="6269" class="on oo it me b mf mz mi na ml op mp oq mt or mx os ot ou ov bi translated"><strong class="me jd">在第28行</strong>上，我们设置了一个类属性，即<code class="fe nt nu nv nj b">DEFAULT_WRITER_BATCH_SIZE</code>，表示在将数据集写入箭头文件时，RAM中可以保存多少个示例。对于图像、音频或视频等占用大量内存的数据，将它设置为一个较小的值(比如256)很重要，这样可以避免OOM错误和迭代器阻塞的风险。如果我们不设置一个值，<a class="ae my" href="https://github.com/huggingface/datasets/blob/401d4c4f9b9594cb6527c599c0e7a72ce1a0ea49/src/datasets/builder.py#L1150" rel="noopener ugc nofollow" target="_blank"> Arrow的默认批量大小(10000)被用于</a>，这对语音样本来说太大了。</li><li id="ebf9" class="on oo it me b mf pj mi pk ml pl mp pm mt pn mx os ot ou ov bi translated"><strong class="me jd">在第29行</strong>上，我们已经使用<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/builder_classes#datasets.BuilderConfig" rel="noopener ugc nofollow" target="_blank">数据集定义了为该数据集提供的唯一配置，即<code class="fe nt nu nv nj b">clean</code>。BuilderConfig </a>是构建配置的基类。<br/> <em class="nw">(最后，我们将看到如何子类化</em><a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/builder_classes#datasets.BuilderConfig" rel="noopener ugc nofollow" target="_blank"><em class="nw">builder config</em></a><em class="nw">并添加我们自己的属性来定义多个配置)</em>。</li></ul><h2 id="4c05" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated"><strong class="ak">恭喜，你现在已经准备好加载你的数据集了</strong></h2><p id="6e71" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">打开新的python脚本或jupyter笔记本:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="db23" class="nn ll it nj b gy no np l nq nr">dataset_config = {<br/>  "LOADING_SCRIPT_FILES": os.path.join(PROJECT_ROOT, "crema.py"),<br/>  "CONFIG_NAME": "clean",<br/>  "DATA_DIR": os.path.join(PROJECT_ROOT, "data/archive.zip"),<br/>  "CACHE_DIR": os.path.join(PROJECT_ROOT, "cache_crema"),<br/>}</span><span id="951c" class="nn ll it nj b gy ns np l nq nr">ds = load_dataset(<br/>  dataset_config["LOADING_SCRIPT_FILES"],<br/>  dataset_config["CONFIG_NAME"],<br/>  <em class="nw">data_dir</em>=dataset_config["DATA_DIR"],<br/>  <em class="nw">cache_dir</em>=dataset_config["CACHE_DIR"]<br/>)</span><span id="0366" class="nn ll it nj b gy ns np l nq nr">print(ds)</span><span id="1c4f" class="nn ll it nj b gy ns np l nq nr">********* OUTPUT ********</span><span id="3090" class="nn ll it nj b gy ns np l nq nr">DatasetDict({<br/>    train: Dataset({<br/>        features: ['file', 'label'],<br/>        num_rows: 7442<br/>    })<br/>})</span></pre><figure class="ne nf ng nh gt ow gh gi paragraph-image"><div role="button" tabindex="0" class="pe pf di pg bf ph"><div class="gh gi pr"><img src="../Images/00a53b43ef1976baccdf854eab1be513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t--VGU5ty1guVBR2wy8FCw.png"/></div></div></figure><h1 id="f2ba" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">接下来呢？？</h1><p id="a79d" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">从现在开始，你可以选择使用这个数据集作为模型训练(这是我将在我的<a class="ae my" href="https://medium.com/p/c2d516b41cd8" rel="noopener">下一个教程</a>中做的)或者(如果你拥有数据集的所有权)将它上传到hugging face<a class="ae my" href="https://huggingface.co/datasets" rel="noopener ugc nofollow" target="_blank">Dataset-Hub</a>。说明可以在这里找到<a class="ae my" href="https://huggingface.co/docs/datasets/share" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="515a" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">在结束之前，有必要讨论一些可以在数据加载步骤之后、模型训练步骤之前完成的事情。</p><h2 id="890e" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">1.分为训练测试和开发组</h2><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="ef64" class="nn ll it nj b gy no np l nq nr"># INTRODUCE TRAIN TEST VAL SPLITS</span><span id="2507" class="nn ll it nj b gy ns np l nq nr"><em class="nw"># 90% train, 10% test + validation</em><br/>train_testvalid = ds["train"].train_test_split(<em class="nw">shuffle</em>=True, <em class="nw">test_size</em>=0.1)</span><span id="7f83" class="nn ll it nj b gy ns np l nq nr"><em class="nw"># Split the 10% test + valid in half test, half valid<br/></em>test_valid = train_testvalid["test"].train_test_split(<em class="nw">test_size</em>=0.5)</span><span id="4dc4" class="nn ll it nj b gy ns np l nq nr"><em class="nw"># gather everything into a single DatasetDict</em></span><span id="8f6d" class="nn ll it nj b gy ns np l nq nr">ds = DatasetDict({<br/>     "train": train_testvalid["train"],<br/>     "test": test_valid["test"],<br/>     "val": test_valid["train"],<br/>      }<br/>)</span></pre><h2 id="6288" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">2.将原始音频文件转换为数组</h2><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="cc24" class="nn ll it nj b gy no np l nq nr"><em class="nw"># CONVERING RAW AUDIO TO ARRAYS</em></span><span id="2120" class="nn ll it nj b gy ns np l nq nr">ds = ds.map( <em class="nw">lambda</em> <em class="nw">x</em>: {<br/>        "array": librosa.load(<em class="nw">x</em>["file"],<br/>         <em class="nw">sr</em>=16000,<br/>         <em class="nw">mono</em>=False)[0]<br/>          }<br/>)</span></pre><h2 id="6fb8" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">3.将标签转换为id</h2><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="f865" class="nn ll it nj b gy no np l nq nr">ds = ds.class_encode_column("label")</span></pre><h2 id="1e70" class="nn ll it bd lm od oe dn lq of og dp lu ml oh oi lw mp oj ok ly mt ol om ma iz bi translated">4.为模拟运行选择数据集的子集</h2><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="7a87" class="nn ll it nj b gy no np l nq nr">ds["train"] = ds["train"].select(range(50))</span></pre><p id="dffc" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated"><em class="nw">另外请记住，每个</em> <code class="fe nt nu nv nj b"><em class="nw">map</em></code> <em class="nw">函数，虽然第一次比较耗时，但是会缓存输出，所以在</em> <code class="fe nt nu nv nj b"><em class="nw">model.train()</em></code> <em class="nw">期间后续的</em> <code class="fe nt nu nv nj b"><em class="nw">map</em></code> <em class="nw">调用不会花那么多时间。</em></p><h1 id="c1ef" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">奖励—在数据集中构建多个配置</h1><p id="e662" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">在文章的开始，我提到我们将讨论允许多重(虚拟)配置的代码片段。为此，我们需要引入一个新的类——姑且称之为<code class="fe nt nu nv nj b">CremaConfig</code>——它将是数据集的一个子类。<a class="ae my" href="https://huggingface.co/docs/datasets/v2.4.0/en/package_reference/builder_classes#datasets.BuilderConfig" rel="noopener ugc nofollow" target="_blank"> BuilderConfig </a>。在这个类中，我们定义了数据集的三个属性，包括<code class="fe nt nu nv nj b">data_dir</code>、<code class="fe nt nu nv nj b">url</code>和<code class="fe nt nu nv nj b">citation</code>。</p><figure class="ne nf ng nh gt ow"><div class="bz fp l di"><div class="ox oy l"/></div></figure><p id="344a" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">现在，不是像下面这样定义配置:</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="887c" class="nn ll it nj b gy no np l nq nr">BUILDER_CONFIGS = [<br/><strong class="nj jd">datasets.BuilderConfig</strong>(name="clean", description="Train Set.")<br/>]</span></pre><p id="2a16" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">我们现在可以构建<code class="fe nt nu nv nj b">CremaConfig</code>类的实例来实例化多个配置。这允许我们灵活地指定名称、数据目录、url等。每种配置。</p><pre class="ne nf ng nh gt ni nj nk nl aw nm bi"><span id="b080" class="nn ll it nj b gy no np l nq nr">BUILDER_CONFIGS = [<br/><strong class="nj jd">CremaConfig</strong>(<em class="nw">name</em>="clean", <em class="nw">description</em>="Train Set in English.", data_dir="path/to/english/dir", url="...", citation="..."),<br/><strong class="nj jd">CremaConfig</strong>(name="fr", description="Train Set in French.", data_dir="path/to/french/dir", url="...", citation="..."),<br/>]</span></pre><h1 id="7f3e" class="lk ll it bd lm ln lo lp lq lr ls lt lu ki lv kj lw kl lx km ly ko lz kp ma mb bi translated">结论</h1><p id="ee24" class="pw-post-body-paragraph mc md it me b mf mg kd mh mi mj kg mk ml mm mn mo mp mq mr ms mt mu mv mw mx im bi translated">一个巨大的对已存在的大声喊出来🤗关于本主题的文档。我希望本教程能够将文档向前推进一步，过滤技术术语，并展示真实示例的实现！</p><p id="f88c" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">一如既往，如果有更简单的方法来做/解释本文中提到的一些事情，一定要让我知道。一般来说，避免不请自来的破坏性/垃圾/敌意评论！</p><p id="0e4e" class="pw-post-body-paragraph mc md it me b mf mz kd mh mi na kg mk ml nb mn mo mp nc mr ms mt nd mv mw mx im bi translated">直到下一次✨</p></div></div>    
</body>
</html>