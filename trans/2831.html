<html>
<head>
<title>Reproducible ML: Maybe you shouldn’t be using Sklearn’s train_test_split</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可重复ML:也许你不应该使用Sklearn的train_test_split</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/reproducible-ml-maybe-you-shouldnt-be-using-sklearn-s-train-test-split-ea8550ddd18d#2022-06-20">https://towardsdatascience.com/reproducible-ml-maybe-you-shouldnt-be-using-sklearn-s-train-test-split-ea8550ddd18d#2022-06-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e151223563a641f8d827ef68962dc579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eSN9m7VmBjisuV_xHnXxcw.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">照片由<a class="ae kc" href="https://unsplash.com/@jdent?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">杰森·登特</a>在<a class="ae kc" href="https://unsplash.com/s/photos/careful?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="83cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再现性对于强大的数据科学至关重要，毕竟，这是一门科学。</p><p id="c47f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是ML中的重现性可能非常困难:</p><blockquote class="lb"><p id="29fc" class="lc ld iq bd le lf lg lh li lj lk la dk translated"><strong class="ak">模型的行为不仅取决于你的代码，还取决于用来训练它的底层数据集</strong></p></blockquote><p id="d869" class="pw-post-body-paragraph kd ke iq kf b kg ll ki kj kk lm km kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated">因此，严格控制用于训练和测试模型的数据点对于确保重现性至关重要。</p><h2 id="d9b2" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">分割数据的方式会对感知的模型性能产生重大影响</strong></h2><p id="ec4f" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如果您“随机”分割数据，那么从统计上来说，测试集中的离群值会比训练集中的离群值多。由于您的模型在训练期间不会“看到”许多异常值，因此在预测“异常值”时，它在测试集上的表现会很差。</p><p id="8609" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在想象一下，你再次随机分割数据，现在“离群值”都在训练集中，没有一个在测试集中。很可能你的‘模特表现’会提高。这种性能提升与所选择的模型关系不大，只是与训练/测试集的统计属性有关。</p><p id="4654" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，控制和理解训练和测试拆分非常重要，以便在多次训练运行中有效地比较不同的候选模型。</p><h2 id="6579" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak"> Sklearn train_test_split </strong></h2><p id="06f4" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">大概最流行的分割数据集的方法是使用Sklearn的<a class="ae kc" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> train_test_split </a>函数。</p><p id="953d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">开箱即用，<code class="fe mo mp mq mr b">train_test_split</code>函数会将您的数据随机分成一个训练集和一个测试集。</p><p id="39e6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每次运行该函数时，您将获得不同的数据分割。再现性不理想。</p><blockquote class="lb"><p id="8d3d" class="lc ld iq bd le lf lg lh li lj lk la dk translated">“啊！”—你说</p><p id="6154" class="lc ld iq bd le lf lg lh li lj lk la dk translated">"我设置了随机种子，所以它是可重复的！"。</p></blockquote><p id="2240" class="pw-post-body-paragraph kd ke iq kf b kg ll ki kj kk lm km kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated">公平点。</p><p id="6689" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设置随机种子当然是一个很好的主意，而且对提高可重复性大有帮助。我强烈建议为任何具有非确定性输出的函数设置随机种子。</p><blockquote class="lb"><p id="1e82" class="lc ld iq bd le lf lg lh li lj lk la dk translated"><strong class="ak">然而，随机种子可能不足以确保再现性</strong></p></blockquote><p id="4be3" class="pw-post-body-paragraph kd ke iq kf b kg ll ki kj kk lm km kn ko ln kq kr ks lo ku kv kw lp ky kz la ij bi translated"><strong class="kf ir">本文将展示</strong> <code class="fe mo mp mq mr b"><strong class="kf ir">train_test_split</strong></code> <strong class="kf ir">函数并不总是保证可再现的分割，即使是使用随机种子集。我还将推荐另一种解决方案——散列法——用于更健壮和可重复的分割。</strong></p><p id="f8a6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这并不是说你不应该使用<code class="fe mo mp mq mr b">train_test_split</code>，只是为了强调它可能比你想象的更敏感。在某些情况下，这可能导致难以调试的不一致分割。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="9138" class="lq lr iq mr b gy na nb l nc nd">This article was originally published on my blog, <a class="ae kc" href="https://engineeringfordatascience.com/posts/ml_repeatable_splitting_using_hashing/" rel="noopener ugc nofollow" target="_blank">engineeringfordatascience.com</a></span></pre><h1 id="24b2" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">train_test_split有什么问题？</h1><p id="7118" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated"><strong class="kf ir">如果底层数据没有任何变化，设置随机簧片只能保证可再现的分割。</strong></p><p id="1595" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mo mp mq mr b">train_test_split</code>是<strong class="kf ir">而不是<em class="nv">确定性的</em>。</strong></p><p id="9755" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从<code class="fe mo mp mq mr b">train_test_split</code>生成的分割对底层数据的“排序”和添加到现有数据集中的任何“新数据”都很敏感。</p><p id="0d73" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">如果您的数据集以任何方式被打乱或修改，数据将被完全不同地分割。</strong>不能保证单个数据点会*总是<em class="nv"> * </em>在训练集中，或者*总是<em class="nv"> * </em>在测试集中。这意味着原始训练集中的数据点现在可能出现在测试集中，反之亦然，如果数据被打乱的话。</p><p id="31a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，对于同一个数据集，根据数据集中各行的排序方式，可以得到*完全*不同的拆分。那挺让人担心的。</p><p id="442b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">即使删除了一个数据点，交换了两行的顺序，或者添加了单个数据点，您也会得到完全不同的训练和测试分割。</p><p id="c429" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种对数据的“超敏感性”可能会令人惊讶——起初对我来说的确如此——并导致意想不到的模型训练结果。</p><p id="fff0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用一个简单的演示来说明这个问题。</p><blockquote class="nw nx ny"><p id="339d" class="kd ke nv kf b kg kh ki kj kk kl km kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated"><em class="iq">💻这篇文章的所有代码都在GitHub上的</em> <a class="ae kc" href="https://github.com/julian-west/e4ds-snippets/blob/master/best-practices/repeatable-splitting/Reproducible%20ML%20-%20Maybe%20you%20shouldn%27t%20be%20using%20sklearn%27s%20train_test_split.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="iq">随机笔记本</em> </a> <em class="iq">中提供🚀</em></p></blockquote><p id="6041" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将首先从<code class="fe mo mp mq mr b">sklearn.datasets</code>下载一个示例数据集，并创建一个“索引”列来唯一标识每一行。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="14b0" class="lq lr iq mr b gy na nb l nc nd"><strong class="mr ir">from</strong> <strong class="mr ir">sklearn.datasets</strong> <strong class="mr ir">import</strong> load_breast_cancer</span><span id="921a" class="lq lr iq mr b gy oc nb l nc nd"><strong class="mr ir">import</strong> <strong class="mr ir">pandas</strong> <strong class="mr ir">as</strong> <strong class="mr ir">pd</strong></span><span id="c2b0" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># download an example dataset</em><br/>data = load_breast_cancer()<br/>df = pd.DataFrame(data["data"], columns=data["feature_names"])</span><span id="5368" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># create an 'index' column to use to uniquely identify each row</em><br/>df = df.reset_index(drop=False)</span><span id="dfd1" class="lq lr iq mr b gy oc nb l nc nd">df.head()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/1c83471ab129ffda5d8aab64f6f27e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QgusUzX6vatYoNpn.png"/></div></div></figure><p id="60f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们用Sklearn的<code class="fe mo mp mq mr b">train_test_split</code>拆分数据，设置随机状态(种子)。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="6471" class="lq lr iq mr b gy na nb l nc nd"><strong class="mr ir">from</strong> <strong class="mr ir">sklearn.model_selection</strong> <strong class="mr ir">import</strong> train_test_split</span><span id="5655" class="lq lr iq mr b gy oc nb l nc nd">TEST_RATIO = 0.1<br/>SEED = 42</span><span id="a5bf" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># split into training and test using a random seed</em><br/>x_train_skl, x_test_skl = train_test_split(df, test_size=TEST_RATIO, random_state=SEED)</span></pre><p id="c49b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们打乱原始数据帧，并再次分割数据。为了保持一致性，我们仍将使用与之前相同的随机种子。</p><p id="f731" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，没有添加新数据，我们只是对行进行了重新排序。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="a469" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># shuffle the orginal dataframe</em><br/>df_shuffled = df.sample(frac=1)</span><span id="4a82" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># split the shuffled dataframe using the same random seed</em><br/>x_train_skl_shuffled, x_test_skl_shuffled = train_test_split(<br/>    df_shuffled, test_size=TEST_RATIO, random_state=SEED<br/>)</span></pre><p id="3918" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">理想情况下，<code class="fe mo mp mq mr b">x_test_skl</code>和<code class="fe mo mp mq mr b">x_test_skl_shuffled</code>测试集中包含的行应该是相同的，因为我们使用了相同的随机种子。</p><p id="d147" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，当我们比较每个测试集中包含的行id时，我们注意到它们是不同的！即使两次的随机状态(种子)是相同的。数据没有任何变化，只是被打乱了。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="0124" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># compare the row ids included in the original test set vs shuffled test set. Should return True if identical rows are included in each test set</em></span><span id="5572" class="lq lr iq mr b gy oc nb l nc nd">set(x_test_skl["index"]) == set(x_test_skl_shuffled["index"])</span><span id="5aae" class="lq lr iq mr b gy oc nb l nc nd">False</span></pre><p id="c296" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这凸显了<code class="fe mo mp mq mr b">train_test_split</code>函数是多么敏感，甚至对数据的重新排序也是如此。</p><p id="ca0e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更重要的是，如果底层数据发生了变化，那么重现原始数据分割和调试模型性能将会非常困难。</p><h1 id="bb33" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">依赖随机种子会有什么后果？</h1><h2 id="6f58" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">这很危险</h2><p id="06db" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">随机种子仅在数据集未发生任何变化时保证再现性。</p><p id="ed6c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您能100%确定数据集在两次训练之间没有改变吗？如果同事删除了异常数据点或添加了新行。您的数据分割将与原始分割完全不同，无法轻松复制旧的数据分割。</p><p id="0e02" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以使用数据版本控制工具，比如<a class="ae kc" href="https://dvc.org/" rel="noopener ugc nofollow" target="_blank"> dvc </a>来帮助跟踪变化，然而，这并不能阻止你的数据分割发生变化。最好能防止代码中的分裂变化。</p><h2 id="1411" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">难以有效比较车型</strong></h2><p id="6b83" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在比较模型时，我们希望能够控制尽可能多的变量。这应该包括哪些数据点用于训练和测试。</p><p id="f386" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您的数据拆分在不同的运行之间有很大的不同，您可能会观察到性能上的显著差异。例如，如果您有几个“异常值”数据点，它们在最初的训练运行的训练集中，但现在在您的测试集中，您的模型性能可能会“下降”，因为它不能像以前一样预测测试集中的异常值。</p><h2 id="667d" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">难以调试</strong></h2><p id="e04a" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如果您不能有效地比较模型，那么就很难调试性能问题。</p><p id="b389" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设您向数据集添加了一些新的数据点并重新训练了模型，但是模型的性能下降了。</p><p id="3e4a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您对随机种子集使用了<code class="fe mo mp mq mr b">train_test_split</code>，那么当底层数据发生变化时，您将得到完全不同的数据分割。很难理解模型性能的下降是由于新数据的质量，还是如前一点所强调的，仅仅是因为数据被不同地分割。</p><h1 id="9001" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">什么时候train_test_split可能不合适？</h1><h2 id="cc73" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">…如果您将来需要根据原始数据和新数据重新训练您的模型</h2><p id="296d" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如前所述，对现有数据的任何底层更改，无论是重新排序还是添加一个额外的数据点，都会导致完全不同的数据拆分。您的原始数据分割将不可复制。</p><p id="70d1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你用<em class="nv">全新的</em>数据集重新训练模型，这不成问题，因为显然所有的训练和测试数据点都会不同。</p><p id="d9d2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，如果您再次使用包含原始数据点的数据集进行训练，理想情况下，您应该能够在新的训练运行期间复制它们的原始数据分割。即使有随机种子集，<code class="fe mo mp mq mr b">train_test_split</code>也不能保证这一点。</p><h2 id="dcef" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">…如果您从一个不断发展的数据源中采样或检索源数据</h2><p id="67c1" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在理想情况下，您应该完全控制源数据集，但是，有时情况并非如此。</p><p id="916f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，如果您使用存储在BigQuery中的表作为许多团队使用的源。您不能保证查询返回的行的顺序，同时新行可能被追加到表中。</p><p id="2cf4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个例子是，如果您正在处理存储在文件系统中的图像数据。如果新图像被添加到您的源文件夹，您不能保证文件路径的顺序，尤其是在添加新图像的情况下。</p><h2 id="2ba3" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">…如果您有不适合内存的大型数据集</h2><p id="adad" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如果您需要将数据分布在多台机器上，以便并行处理数据，那么使用非确定性方法分割训练和测试数据可能会有问题，并且难以确保可重复性。</p><h2 id="c534" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">…如果您的实验或生产代码将用另一种语言重写</h2><p id="f2b2" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">由于<code class="fe mo mp mq mr b">train_test_split</code>是不确定的，数据分割不容易跨语言重现。</p><p id="e635" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，您可能希望将自定义Python模型的性能与使用BigQuery的BQML(使用SQL定义)创建的模型进行比较。从<code class="fe mo mp mq mr b">train_test_split</code> Sklearn中分离出来的内容不容易直接转化成SQL。</p><p id="c266" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">团队使用Python构建模型原型，然后使用另一种语言(如Java)编写生产系统，这种情况也很常见。为了帮助将原型模型翻译成另一种语言的过程，理想情况下，我们应该能够以相同的方式在两种语言中分割数据，以确保可再现性，并帮助调试从原始模型到新模型的任何差异。</p><h1 id="3509" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">解决方案:散列法</h1><h2 id="aab0" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">哈希是什么？</h2><blockquote class="nw nx ny"><p id="7093" class="kd ke nv kf b kg kh ki kj kk kl km kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated"><em class="iq">“哈希函数是可用于将任意大小的数据映射到固定大小的值的任何函数”</em> <a class="ae kc" href="https://en.wikipedia.org/wiki/Hash_function" rel="noopener ugc nofollow" target="_blank"> <em class="iq">维基百科</em> </a></p></blockquote><p id="e536" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多不同的散列算法，但本质上它们允许您可重复地将输入转换成任意值。</p><p id="805e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哈希函数的输出是确定性的——对于相同的输入，它总是相同的。</p><h2 id="8454" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">它是如何可重复地分割数据的？</h2><p id="110b" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在数据分割的上下文中，我们可以使用哈希来可靠地将分割分配给各个数据点。由于这是一个确定性的过程，我们可以确保数据点总是被分配到相同的分割，这有助于再现性。</p><p id="03cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该过程工作如下:</p><ul class=""><li id="7c10" class="oe of iq kf b kg kh kk kl ko og ks oh kw oi la oj ok ol om bi translated">使用数据点的唯一标识符(例如，ID或通过连接多个列)，并使用哈希算法将其转换为任意整数。每个唯一的数据点将具有来自散列函数的唯一输出。</li><li id="ad1c" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated">使用<a class="ae kc" href="https://en.wikipedia.org/wiki/Modulo_operation" rel="noopener ugc nofollow" target="_blank">模运算</a>将数据任意分成“桶”</li><li id="3714" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated">选择存储桶子集中的所有数据点作为训练集，其余的数据点作为测试集</li></ul><h2 id="843c" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">伪码(90:10数据分割)</strong></h2><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="04a3" class="lq lr iq mr b gy na nb l nc nd">row_id = "0001"</span><span id="c258" class="lq lr iq mr b gy oc nb l nc nd"># convert id into a hashed integer value<br/>hash_value = hash(row_id)</span><span id="684f" class="lq lr iq mr b gy oc nb l nc nd"># assign a bucket between 0 and 9<br/>bucket = hash_value % 10</span><span id="2c6f" class="lq lr iq mr b gy oc nb l nc nd"># add id to train set if less than 9 (i.e. approx 90% of the data)<br/>if bucket &lt; 9:<br/>   train_set.append(row_id)<br/>else:<br/>   test_set.append(row_id)</span></pre><h1 id="6353" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">使用哈希的原因</h1><h2 id="4559" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">确定性</strong></h2><p id="a07b" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">与<code class="fe mo mp mq mr b">train_test_split</code>不同，散列对数据中的潜在变化是健壮的。</p><p id="f36e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用这种方法，一个单独的数据点将<em class="nv">总是</em>被分配到同一个存储桶。如果数据被重新排序或添加了新数据，分配的存储桶将不会改变。这是更可取的，因为数据点的训练/测试分割分配现在独立于数据集的其余部分。</p><h2 id="8265" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">提高开发效率，减少人为错误</strong></h2><p id="8525" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">当与同事并行处理模型时，非常容易不小心忘记使用随机种子，甚至使用不同的随机种子。这使您面临人为错误的风险。</p><p id="b070" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用相同的散列算法消除了用随机种子在代码中显式控制可再现性的需要。只要您同意您的团队使用哪种散列算法，您将总是重新创建相同的分割。没有人为错误的风险。</p><h2 id="6eb0" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">原始数据和预处理数据的一致分割</strong></h2><p id="2375" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">在实验过程中，您可能会研究不同的预处理步骤，并将中间数据和预处理数据保存在一个新文件中。然后，您可以在另一个阶段加载这些中间数据，以继续您的分析。</p><p id="aa31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于预处理数据不同于原始数据，当从新文件加载时，使用<code class="fe mo mp mq mr b">train_test_split</code>和随机种子将给原始数据和预处理数据不同的分割。</p><p id="1bd0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">只要用于计算哈希值的列没有改变，哈希将为原始数据和预处理数据提供相同的拆分。</p><h2 id="6485" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">存储和内存高效</strong></h2><p id="2141" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">还有其他策略来对抗再现性(本文稍后讨论)，例如将数据显式保存在“训练”文件和“测试”文件中，或者在数据中添加新列来指示数据点属于哪个训练/测试分割。</p><p id="3b28" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，有时您无法将数据保存到新文件并添加列，例如，如果您没有权限复制或编辑原始数据源，或者数据太大。</p><p id="51b9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哈希是确定性的，需要时可以在内存中“动态”计算数据点分割，而无需显式更改底层数据或保存到新文件中。</p><h1 id="352e" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">Farmhash算法</h1><p id="21ee" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">有许多不同的哈希算法，用于多种用例，如校验和和加密。</p><p id="4f9a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了创建可再现的训练/测试分割，我们需要使用“指纹”散列函数。<a class="ae kc" href="https://devopedia.org/fingerprinting-algorithms" rel="noopener ugc nofollow" target="_blank">指纹散列函数</a>是轻量级的、高效的和确定性的——它们将总是为相同的输入返回相同的值。</p><p id="3d4d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">加密哈希函数，如MD5和SHA1，不适合这种使用情况，因为它们不具有确定性，而且它们的计算开销也很大。</p><p id="91e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://github.com/google/farmhash" rel="noopener ugc nofollow" target="_blank"> Farmhash由Google </a>开发，<a class="ae kc" rel="noopener" target="_blank" href="/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39">推荐给这个用例</a>。它有一个简单的<a class="ae kc" href="https://pypi.org/project/pyfarmhash/" rel="noopener ugc nofollow" target="_blank"> Python库</a>实现，可以跨许多其他语言使用，包括<a class="ae kc" rel="noopener" target="_blank" href="/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39"> BigQuery SQL </a>。</p><blockquote class="nw nx ny"><p id="84a8" class="kd ke nv kf b kg kh ki kj kk kl km kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated"><em class="iq">farm hash的另一种替代方法是使用zlib和crc32校验和算法。本笔记本中显示了一个实施示例，来自</em> <a class="ae kc" href="https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="iq">使用Scikit-Learn、Keras和TensorFlow </em> </a>进行机器实践学习</p></blockquote><p id="a327" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个farmhash的演示，以及我们如何使用它来为我们的数据点分配存储桶。</p><h2 id="b6ff" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">演示</h2><p id="ce0b" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated"><a class="ae kc" href="https://pypi.org/project/pyfarmhash/" rel="noopener ugc nofollow" target="_blank">PyPI上的Python包</a></p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="d3e3" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># install Python library</em><br/><em class="nv"># ! pip install pyfarmhash</em></span></pre><p id="22a4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用数据点的唯一标识符(即ID或列值的连接)来散列数据点。</p><p id="2ef9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从使用farmhash的<code class="fe mo mp mq mr b">fingerprint64</code>函数将单个ID转换成散列整数值开始。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="b60a" class="lq lr iq mr b gy na nb l nc nd"><strong class="mr ir">import</strong> <strong class="mr ir">farmhash</strong></span><span id="8b04" class="lq lr iq mr b gy oc nb l nc nd">example_id = "0001"<br/>hashed_value = farmhash.fingerprint64(example_id)<br/><strong class="mr ir">print</strong>(hashed_value)</span><span id="99ca" class="lq lr iq mr b gy oc nb l nc nd">6241004678967340495</span></pre><p id="0d14" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在可以使用任意函数将这个数据点分配给一个“桶”。</p><p id="d0b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个有用的方法是使用模函数。散列算法的整数输出是随机分布的，因此，例如，使用除数为10的模函数会将数据分成10个随机桶(从0到9)。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="1ff3" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># assign a bucket using the modulo operation</em><br/>bucket = hashed_value % 10<br/><strong class="mr ir">print</strong>(bucket)</span><span id="fe50" class="lq lr iq mr b gy oc nb l nc nd">5</span></pre><p id="48f1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们的数据点ID“0001”将被分配给存储桶5。当我们使用除数10时，我们将有10个不同的桶。因此，例如，我们可以将所有存储桶为“1”的数据点分配给测试集，以使用10%的数据进行测试。</p><h2 id="ebe0" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">使用Farmhash分割数据集</h2><p id="a345" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">现在，让我们将这种分割策略应用到我们的数据集。</p><p id="bd70" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的<code class="fe mo mp mq mr b">hash_train_test_split</code>函数可用于使用指定的散列函数将数据帧分割成训练集和测试集。在此示例中，该函数创建一个新列来存储存储桶分配。这只是出于演示目的，没有必要实际将存储桶值存储在您的数据中，因为存储桶可以从行ID“动态”地重复计算。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="os ot l"/></div></figure><p id="cf37" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和以前一样，我们将使用原始乳腺癌数据集创建训练/测试分割，但使用带有Farmhash的哈希方法，而不是带有随机种子的sklearn的<code class="fe mo mp mq mr b">train_test_split</code>。</p><p id="cc48" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将打乱数据，再次分割数据，并比较测试集id，以确保分割是相同的。</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="0d04" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># create a training and test set from original dataset using hashing method</em><br/>x_train_hash, x_test_hash = hash_train_test_split(<br/>    df,<br/>    split_col="index",<br/>    approx_test_ratio=TEST_RATIO,<br/>)<br/></span><span id="160f" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># create a training and test set from shuffled dataset using hashing method</em><br/>x_train_hash_shuffled, x_test_hash_shuffled = hash_train_test_split(<br/>    df_shuffled,<br/>    split_col="index",<br/>    approx_test_ratio=TEST_RATIO,<br/>)</span><span id="fa4f" class="lq lr iq mr b gy oc nb l nc nd"><em class="nv"># show which bucket each row has been assigned for demo purposes</em><br/>x_train_hash[["index", "bucket"]].head()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/05d6349ec416a44ca8f5016ca8743ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/0*w2bo8T8CBqO4u_T3.png"/></div></figure><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="8bb8" class="lq lr iq mr b gy na nb l nc nd"><em class="nv"># compare the row ids included in each test set</em><br/>set(x_test_hash["index"]) == set(x_test_hash_shuffled["index"])</span><span id="01e7" class="lq lr iq mr b gy oc nb l nc nd">True</span></pre><p id="a62c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问题解决了！即使底层数据帧被打乱，相同的行id仍然出现在测试数据集中。</p><h1 id="39de" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">考虑</h1><p id="db2f" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">哈希方法比常见的Sklearn <code class="fe mo mp mq mr b">train_test_split</code>要复杂一点(虽然不多)。因此，在实现这种方法时，有一些额外的重要事情需要考虑和了解。</p><h2 id="c6f5" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">散列法不会根据您指定的训练/测试比率准确分割您的数据</strong></h2><p id="ea35" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">哈希算法的输出整数是一致的，但仍然是随机的。由于统计上的偶然，您可能会有稍微多一点的输出被分配到一个特定的存储桶，这意味着您可能不会得到<em class="nv">恰好</em> 10%的数据被分配到测试集。可能会多一点或少一点。这就是为什么我将<code class="fe mo mp mq mr b">hash_train_test_split</code>函数中的参数命名为‘approx _ test _ ratio ’,因为结果将仅是该比率的近似值。</p><p id="59c4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们上面的例子中，我们指定比率为0.1，并期望测试集大小为56。然而，我们实际上最终在测试集中只有46条记录(8%)。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ov"><img src="../Images/e0cbb0ac17ae0f50c00db59f6186d5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FDBphrWCmmnZ9Ycn.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="ba46" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集越大，存储桶分配就越均匀，分割就越接近您想要的比例(大数定律)。</p><p id="3be4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一般来说，这应该不是问题。使用90:10的训练/测试分割是任意的。实际上，你的分成比目标比例多一点或少一点都没关系。</p><h2 id="df90" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">应该选择多少个水桶？</strong></h2><p id="efa2" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">也就是说，您应该使用哪个数字作为模数运算的除数。</p><p id="02e2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这实际上取决于期望的测试分割的粒度。如果您想要90:10的分割，您可以使用“10”作为除数将您的数据分割成10个桶。然后选择其中一个桶作为您的测试集，它大约是您的数据点的10%。</p><p id="6787" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您想要15%的数据用于测试，您可以使用<code class="fe mo mp mq mr b">100</code>作为除数将数据分成100个桶。您可以从您的数据中随机选择15个桶，以获取15%的数据进行测试。</p><h2 id="c38c" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated"><strong class="ak">平台交叉兼容性怪癖</strong></h2><p id="86ee" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">尽管如此，哈希方法在不同平台上是一致的。那在某种程度上是真实的。</p><p id="33bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里就不赘述了。在我的博客上的<a class="ae kc" href="https://engineeringfordatascience.com/posts/ml_repeatable_splitting_using_hashing/#considerations" rel="noopener ugc nofollow" target="_blank">原文中可以找到关于在BigQuery和Python中使用散列法分割数据的“陷阱”的更详细的讨论:</a></p><blockquote class="nw nx ny"><p id="183e" class="kd ke nv kf b kg kh ki kj kk kl km kn nz kp kq kr oa kt ku kv ob kx ky kz la ij bi translated">TL；dr:只是要注意不同的语言是如何处理对负数应用模数函数的…</p></blockquote><h1 id="ef38" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">哈希的替代方法</h1><p id="cbad" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">为了完整起见，这里有另外两个常见的更明确的方法来确保一致的训练/测试分割。</p><h2 id="90b4" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">在数据中创建附加列</h2><p id="0baa" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">您可以使用<code class="fe mo mp mq mr b">train_test_split</code>(或另一种随机分割方法)来初始定义分割。然后在数据集中创建一个额外的列，以明确记录该数据点是应该包含在定型还是测试中(或者指定K折叠验证的折叠)。</p><p id="c7f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里是Abhishek Thakur 实现的<a class="ae kc" href="https://github.com/abhishekkrthakur/mlframework/blob/master/src/create_folds.py" rel="noopener ugc nofollow" target="_blank">示例，他用它来定义交叉验证的“折叠”。</a></p><p id="061a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将确保您的分割在训练跑之间被“记住”,因为它们是明确定义的。</p><p id="9a43" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从积极的方面来看，哪些数据点属于每个拆分是非常透明的。但是，缺点是它会增加数据集的总大小，这对于非常大的数据集来说可能是不可持续的。此外，如果您没有对数据集(例如共享数据库表)的完全控制权，您可能无法向原始模式添加列。</p><h2 id="e1ab" class="lq lr iq bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">将培训和测试数据保存到不同的文件中</h2><p id="e7bc" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">另一种常见的方法是在第一次拆分数据后，将您的训练数据和测试数据存储到单独的文件中。例如，转换成名为<code class="fe mo mp mq mr b">train.csv</code>和<code class="fe mo mp mq mr b">test.csv</code>的文件。如果数据对于单个文件来说太大，你也可以将多个文件分别保存到名为<code class="fe mo mp mq mr b">train</code>和<code class="fe mo mp mq mr b">test</code>的文件夹中。</p><p id="66ee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这可能是一种有效的方法。但是，有时将所有数据复制一份并保存到单个文件中并不可行。例如，如果数据集非常大，或者您没有权限从原始源进行复制。</p><p id="1079" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">哈希方法可以在运行中和内存中可重复地计算确定性数据拆分，从而无需将数据复制到单个文件中。</p><h1 id="bd94" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">结论</h1><p id="9463" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">Sklearn的<code class="fe mo mp mq mr b">train_test_split</code>对于入门教程和小型静态数据集来说效果很好，然而，在现实世界中事情会变得更加复杂。</p><p id="257b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">再现性是可持续部署ML模型的关键。Sklearn <code class="fe mo mp mq mr b">train_test_split</code>对底层数据的变化惊人地敏感，可能并不合适，尤其是当您向现有数据中添加新数据时。</p><p id="efd8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">散列法将单个数据点的训练/测试任务与数据集的其余部分分离开来。</strong>这产生了一种更健壮的分割数据的方法。</p><p id="561d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">散列是一个很好的解决方案，但是，它可能会矫枉过正。如果你正在一个小的静态数据集上完成一次性训练，Sklearn的<code class="fe mo mp mq mr b">train_test_split</code>和一个随机种子就足够了。然而，哈希是数据科学家工具箱中的一个重要补充，可以提高重现性并防止模型性能发生意外变化。</p><p id="62c3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编码快乐！</p><pre class="ms mt mu mv gt mw mr mx my aw mz bi"><span id="e2ea" class="lq lr iq mr b gy na nb l nc nd">This article was originally published on my blog, <a class="ae kc" href="https://engineeringfordatascience.com/posts/ml_repeatable_splitting_using_hashing/" rel="noopener ugc nofollow" target="_blank">engineeringfordatascience.com</a></span><span id="1939" class="lq lr iq mr b gy oc nb l nc nd">Code for the article can be found in <a class="ae kc" href="https://github.com/julian-west/e4ds-snippets/tree/master/best-practices/repeatable-splitting" rel="noopener ugc nofollow" target="_blank">this GitHub repository</a></span></pre><h1 id="dcb1" class="ne lr iq bd ls nf ng nh lv ni nj nk ly nl nm nn mb no np nq me nr ns nt mh nu bi translated">参考资料和资源</h1><p id="2256" class="pw-post-body-paragraph kd ke iq kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated"><strong class="kf ir">哈希</strong></p><ul class=""><li id="50fd" class="oe of iq kf b kg kh kk kl ko og ks oh kw oi la oj ok ol om bi translated">ML设计模式:可重复采样(这篇文章的灵感来源)</li><li id="14e2" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated"><a class="ae kc" href="https://www.bi-kring.nl/192-data-science/1340-reusing-data-for-ml-hash-your-data-before-you-create-the-train-test-split" rel="noopener ugc nofollow" target="_blank">在创建训练测试分割之前，散列您的数据</a></li><li id="eb55" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated"><a class="ae kc" href="https://github.com/google/farmhash/blob/master/Understanding_Hash_Functions" rel="noopener ugc nofollow" target="_blank"> Farmhash算法描述</a></li><li id="7469" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated"><a class="ae kc" href="https://pypi.org/project/pyfarmhash/" rel="noopener ugc nofollow" target="_blank"> Python Farmhash库</a></li><li id="f9aa" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated"><a class="ae kc" href="https://www.danli.org/2021/06/06/hands-on-machine-learning/" rel="noopener ugc nofollow" target="_blank">不同于使用Scikit-Learn、Keras和TensorFlow进行动手机器学习的哈希实现</a>另<a class="ae kc" href="https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb" rel="noopener ugc nofollow" target="_blank">参见笔记本</a></li><li id="8a6e" class="oe of iq kf b kg on kk oo ko op ks oq kw or la oj ok ol om bi translated"><a class="ae kc" href="https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/randomization" rel="noopener ugc nofollow" target="_blank">谷歌文档:散列的考虑因素</a></li></ul></div></div>    
</body>
</html>