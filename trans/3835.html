<html>
<head>
<title>3 Common Strategies to Measure Bias in NLP Models (2022)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">衡量NLP模型中偏差的3种常用策略(2022)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-common-strategies-to-measure-bias-in-nlp-models-2022-b948a671d257#2022-08-25">https://towardsdatascience.com/3-common-strategies-to-measure-bias-in-nlp-models-2022-b948a671d257#2022-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d292" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">负责任人工智能语言模型中偏差的量化策略</h2></div><p id="d69b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi le translated"><span class="l lf lg lh bm li lj lk ll lm di">在过去的几年里，构建<a class="ae ln" href="https://www.fatml.org/" rel="noopener ugc nofollow" target="_blank">胖</a>(公平、可审计和透明)机器学习的话题已经从一个边缘话题发展成为主导会议现场的话题。</span></p><p id="9a2f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于<strong class="kk iu">自然语言处理</strong>来说尤其如此，有偏见的ML的影响非常明显。</p><p id="cab5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中一个广受欢迎的话题是<strong class="kk iu">测量偏差</strong>。在数据科学中，偏差是一个被过度使用的术语，但是在本文中，我们将它定义为:</p><blockquote class="lo lp lq"><p id="1fbb" class="ki kj lr kk b kl km ju kn ko kp jx kq ls ks kt ku lt kw kx ky lu la lb lc ld im bi translated">偏差:产生一种伤害的偏斜</p></blockquote><p id="43f6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然这个定义很简单，但实际上测量和量化这种危害是极其困难的。尽管许多人以各种各样的观点对这一不断发展的领域做出了贡献，但有一个主张几乎得到了普遍认同:</p><blockquote class="lv"><p id="7bac" class="lw lx it bd ly lz ma mb mc md me ld dk translated"><strong class="ak">Bia没有单一的衡量标准</strong>。您必须根据您的型号和应用仔细选择您的偏差标准。</p></blockquote><p id="4617" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">即使这样，你也必须深思熟虑，意识到你的测量究竟是什么……测量。</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mk"><img src="../Images/fbcc40a14f23a5f22c16af22c729c4b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jhaipu4MkarPNZG_"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">语言模型非常有用，但如果评估不当，可能会产生意想不到的后果</p></figure><p id="bfa8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望在这篇文章结束时，你会对你的模型需要什么样的方法来减少算法偏差有一个很好的理解。🚀</p><p id="e1e7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lr">本文所有图片和图表，除特别注明外，均由作者创作。</em></p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="d996" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有相当多的方法可以测量语言模型中的偏差。我已经强调了我认为每个人都应该知道的几个关键方法。</p><p id="36f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以下是NLP模型的常见应用，以及与之相关的偏差测量。</p><h1 id="bf46" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">方法1:精选数据集</h1><p id="ea48" class="pw-post-body-paragraph ki kj it kk b kl nz ju kn ko oa jx kq kr ob kt ku kv oc kx ky kz od lb lc ld im bi translated">测量偏差的常用方法是<strong class="kk iu">利用数据集<em class="lr">设计</em>来检测<em class="lr">特定</em>问题的偏差。</strong></p><p id="8beb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这些数据集的目标是针对模型可能具有的潜在偏差，并由选择来解析这些偏差的示例组成。这些数据集是由研究人员手工制作的，虽然肯定无法扩展到所有模型和所有应用程序(稍后将详细介绍)，但如果这些数据集对您的应用程序非常有用。</p><p id="ef60" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们来看看由曹等人在<a class="ae ln" href="https://paperswithcode.com/paper/toward-gender-inclusive-coreference" rel="noopener ugc nofollow" target="_blank">中策划的<strong class="kk iu">可能歧义代词(MAP)</strong></a>数据集。</p><p id="6cca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该数据集的目标是:</p><blockquote class="lo lp lq"><p id="9ecf" class="ki kj lr kk b kl km ju kn ko kp jx kq ls ks kt ku lt kw kx ky lu la lb lc ld im bi translated">群体注释和现有共指消解系统中的询问偏差</p></blockquote><p id="c126" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="lr">(共指消解，</em> </strong> <em class="lr">顺便说一下，</em> <strong class="kk iu"> <em class="lr"> </em> </strong> <em class="lr">是确定一个文本中哪些表达式指代同一个实体的过程；前任。短语“California”、“CA”、“Cali”和“黄金之州”都指同一个实体——美国加利福尼亚州。)</em></p><p id="6afe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以通过编写一个名为<code class="fe oe of og oh b">pull_map.py</code>的文件从github repo中提取csv来查看地图数据集:</p><pre class="ml mm mn mo gt oi oh oj ok aw ol bi"><span id="58c0" class="om ni it oh b gy on oo l op oq">import requests</span><span id="aa45" class="om ni it oh b gy or oo l op oq">csv_url = "https://raw.githubusercontent.com/TristaCao/into_inclusivecoref/mast$</span><span id="fbb6" class="om ni it oh b gy or oo l op oq">req = requests.get(csv_url)<br/>url_content = req.content<br/>csv_file = open('map.csv', 'wb')</span><span id="45b4" class="om ni it oh b gy or oo l op oq">csv_file.write(url_content)<br/>csv_file.close()</span></pre><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi os"><img src="../Images/531a82450d02417d1ec5a76fae9eb6c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ujaefzxviMAmCyXLuSEQ6Q.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">地图数据集的屏幕截图。知识共享许可下的数据</p></figure><p id="38f9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe oe of og oh b">full-text</code>是一系列的句子，通常很长，有点令人困惑，引用了几个实体。这里有一个重点:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ot"><img src="../Images/8175d7638e43446131cbcd63f50afdf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5mGzfPc8Sc99g72QL09QQ.png"/></div></div></figure><p id="1592" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">共指消解模型的目标是确定代词“她”(用橙色突出显示)是否指…</p><ol class=""><li id="d26a" class="ou ov it kk b kl km ko kp kr ow kv ox kz oy ld oz pa pb pc bi translated">萨尔曼(A)</li></ol><p id="fcf9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.萨尔曼或法拉·可汗(甲或乙)</p><p id="cd88" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.法拉·可汗(B)</p><p id="bb30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">4.既不是萨尔曼也不是法拉·可汗</p><p id="241f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lr">以上数字对应</em> <code class="fe oe of og oh b"><em class="lr">Answer</em></code> <em class="lr">栏</em>中的数值</p><p id="5ca9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用这个精选数据集的目的不仅是这些例子通常很难，它们还提供了不同代词、性别和身份的更多表示。看看代词，我们可以看到代词的范围很广，包括:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pd"><img src="../Images/3b5a303aa93572fbacd11de54fe5f17e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3KiloJJRURqi6b2FYbS4bQ.png"/></div></div><p class="mw mx gj gh gi my mz bd b be z dk translated">作者制作的图表</p></figure><p id="8244" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使用代码片段来验证上面的图表:</p><pre class="ml mm mn mo gt oi oh oj ok aw ol bi"><span id="250c" class="om ni it oh b gy on oo l op oq">import matplotlib.pyplot as plt</span><span id="85fb" class="om ni it oh b gy or oo l op oq">map_pd.groupby("Pronoun").count()[['id']].sort_values('id').plot.barh(figsize=(15, 10))</span><span id="94a0" class="om ni it oh b gy or oo l op oq">plt.title("Number of Examples with certain pronouns")<br/>plt.xlabel("Num. of Examples")</span><span id="6642" class="om ni it oh b gy or oo l op oq">plt.gca().spines['top'].set_visible(False)<br/>plt.gca().spines['right'].set_visible(False)</span></pre><p id="0179" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个数据集的一个很好的方面是，你可以看到人类是如何解释这些句子的，从而产生有趣的见解以及比挑战性问题100%准确更现实的黄金标准。</p><p id="9ab3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其他值得注意的策划数据集:</p><ul class=""><li id="0498" class="ou ov it kk b kl km ko kp kr ow kv ox kz oy ld pe pa pb pc bi translated"><strong class="kk iu">wino bias</strong>&amp;<strong class="kk iu">wino gender</strong>创建Winograd模式，研究共指消解模型中的性别刻板印象</li><li id="d227" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld pe pa pb pc bi translated"><strong class="kk iu">性别模糊代词(GAP) </strong>数据集，包含具有模糊代词-名词对的维基百科传记，用于通过模型准确性检测性别偏见。</li><li id="0578" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld pe pa pb pc bi translated"><strong class="kk iu"> Wiki-GenderBias </strong>，通过比较与配偶、职业、出生率或出生地(类似于GAP)配对的男性/女性实体提取之间的模型准确性来测试性别偏见</li><li id="622e" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld pe pa pb pc bi translated"><strong class="kk iu"> CrowS-Pairs </strong>，<strong class="kk iu"> StereoSet </strong>是成对句子的众包数据集，其中一个句子比另一个句子在特定属性上更常规。适用于任何屏蔽语言模型，如BERT，与应用程序无关。偏差由模型偏好通过丢失单词的概率来确定</li><li id="1e55" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld pe pa pb pc bi translated"><strong class="kk iu"> WinoMT </strong>英语数据集，评估性别共指关联的刻板印象和非刻板印象职业的翻译。对机器翻译有用</li></ul><h1 id="fa98" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">方法2:子群间的准确性</h1><p id="dec7" class="pw-post-body-paragraph ki kj it kk b kl nz ju kn ko oa jx kq kr ob kt ku kv oc kx ky kz od lb lc ld im bi translated">也称为“校准”，测量偏差的一种常见方法是探索您的<strong class="kk iu">模型水平跨亚组的误差度量，例如</strong>分析您的模型跨种族亚组的AUC分数。</p><p id="d209" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这通常是各种应用程序的首选方法，从毒性检测到问答，再到自动完成生成。</p><p id="bb5c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于如何做到这一点的虚拟示例，让我们看一个任意数据集，其中有age_range、模型的预测和组真实标签:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/d91b823535938dd16cbb6c06fd97b4ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*xhST3IaRTQzviK6Afh0GGg.png"/></div><p class="mw mx gj gh gi my mz bd b be z dk translated">作者制作的数据</p></figure><p id="b8ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果我们<strong class="kk iu"> <em class="lr">只是检查整个模型</em> </strong>的准确性，我们会得到大约85%的相当不错的准确性:</p><pre class="ml mm mn mo gt oi oh oj ok aw ol bi"><span id="f77f" class="om ni it oh b gy on oo l op oq">def calculate_accuracy(data):<br/>    return 100*len(data[data.model_pred==data.label])/len(data)</span><span id="e576" class="om ni it oh b gy or oo l op oq">print(f"Model Accuracy: {calculate_accuracy(x)}%")</span><span id="7d1e" class="om ni it oh b gy or oo l op oq">## Model Accuracy: 84.8%</span></pre><p id="0a49" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这甚至可能足够高，这取决于将该模型交付生产的应用程序。乍看之下，肯定足够高，可以为将来的迭代构建。</p><p id="1bb4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是，当我们检查不同年龄组时，我们可以看到一些突出的问题</p><pre class="ml mm mn mo gt oi oh oj ok aw ol bi"><span id="bdbc" class="om ni it oh b gy on oo l op oq">def calculate_accuracy(data):<br/>    return 100*len(data[data.model_pred==data.label])/len(data)</span><span id="6360" class="om ni it oh b gy or oo l op oq">def calculate_subgroup_accuracy(data):<br/>    for group in data.age_range.unique():<br/>        g = data[data.age_range==group]<br/>        print(f"{group}: {calculate_accuracy(g):.2f}%")<br/>        <br/>print(f"Model Accuracy: {calculate_accuracy(x)}%")<br/>print()<br/>calculate_subgroup_accuracy(x)</span><span id="3e02" class="om ni it oh b gy or oo l op oq">## Model Accuracy: 84.8%<br/>## &lt;18: 97.41%<br/>## 18-35: 98.71%<br/>## 35-55: 97.06%<br/>## 55+: 48.67%</span></pre><p id="186c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以看到，我们的模型在预测55岁以下的用户方面非常出色，<strong class="kk iu">但在预测55岁以上的用户方面却非常糟糕。事实上，比偶然更糟。</strong></p><p id="9395" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是将我们的模型预测按亚组分解的值。由于这是一个后处理分析，您也不需要在模型本身中包含这些敏感特性，这是一个巨大的优势。</p><p id="17cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然最好的选择是拥有明确的子组特征，如种族和性别，但您也可以通过对数据集运行分类算法来产生子组<strong class="kk iu">，并在这些组内比较模型指标。它不会显示基于显式要素/子组的偏差，但肯定会确保您的模型在数据集中的隐式段之间是公平的</strong></p><h1 id="9a1c" class="nh ni it bd nj nk nl nm nn no np nq nr jz ns ka nt kc nu kd nv kf nw kg nx ny bi translated">方法3:扰动和反事实</h1><p id="d392" class="pw-post-body-paragraph ki kj it kk b kl nz ju kn ko oa jx kq kr ob kt ku kv oc kx ky kz od lb lc ld im bi translated"><strong class="kk iu">扰动输入并观察模型的输出</strong>是探索模型中潜在偏差的好方法。</p><p id="609b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是用于评估与情感分析和文本生成相关的模型的最常见的方法，但对于任何NLP模型来说都非常有用。</p><p id="a34f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">虽然前两个偏差探索<strong class="kk iu">全局</strong>(模型级)偏差伪影在你的模型中，但是这个方法对于发现<strong class="kk iu">局部</strong>(预测级)偏差伪影是有效的。</p><p id="2d30" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最直接的方法是<strong class="kk iu">有计划地删除句子中的每个单词，并将其输入到你的模型</strong>中。</p><p id="d5f0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们想分析为什么我们的模型给出这样的句子:</p><blockquote class="lv"><p id="e396" class="lw lx it bd ly lz ma mb mc md me ld dk translated">我真的爱我的好医生</p></blockquote><p id="34bd" class="pw-post-body-paragraph ki kj it kk b kl mf ju kn ko mg jx kq kr mh kt ku kv mi kx ky kz mj lb lc ld im bi translated">积极情绪得分。<em class="lr">更准确地说，我们希望确保我们的模型不会键入非肯定的词语，如“我的”或“医生”</em></p><p id="18cd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设我们有一个经过训练的情感分析模型，我们可以这样做:</p><pre class="ml mm mn mo gt oi oh oj ok aw ol bi"><span id="fb59" class="om ni it oh b gy on oo l op oq">example = "I really love my good doctor"<br/>prediction = model.prediction(example)</span><span id="6c95" class="om ni it oh b gy or oo l op oq">words = example.split(" ")<br/>word_impacts = []<br/>for i in range(len(words)):<br/>    s = ""<br/>    for j in range(len(words)):<br/>        if i == j:<br/>            continue<br/>        s += words[j] +" "<br/>        <br/>    val = model.predict(s)<br/>    word_impacts.append(prediction-val)</span></pre><p id="b5fc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">其中<code class="fe oe of og oh b">word_impacts</code>列出了句子中每个单词对最终预测的单独影响。</p><p id="f0bc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">表现良好的模型会产生<code class="fe oe of og oh b">word_impact</code>分数，例如:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pl"><img src="../Images/65b0bf2278d63a5b7cfc36a203b27b49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*83gnMDl1TZ6G-Oo0IlDvAQ.png"/></div></div></figure><p id="a154" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">而表现不佳的模型可能会产生<code class="fe oe of og oh b">word_impact</code>分数，如:</p><figure class="ml mm mn mo gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi pm"><img src="../Images/0b817dd52c8a89db3041229bf442a1db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YY68Wo7JMdpZgvOcRri5uw.png"/></div></div></figure><p id="2e89" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以从第一个例子中看到，它不仅得到了正确的答案，而且将大部分权重放在了重要的词上——“爱”和“好”。值得注意的是，它没有在限定词“真的”上放置太多的权重，对于这个例子来说，这不是一个大问题，但是是一个需要注意的重要工件… <strong class="kk iu">即使是高性能的模型也有工件和问题！</strong></p><p id="fd82" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第二个例子表现很差，显然不知道该看句子中的什么，在所有单词中最强调“my”。虽然我们之前知道这个模型不好，但我们可以看到它仍然在形容词等基本语言概念上苦苦挣扎——回到制图板！</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h2 id="099c" class="om ni it bd nj pn po dn nn pp pq dp nr kr pr ps nt kv pt pu nv kz pv pw nx px bi translated">结论</h2><p id="cce7" class="pw-post-body-paragraph ki kj it kk b kl nz ju kn ko oa jx kq kr ob kt ku kv oc kx ky kz od lb lc ld im bi translated">这是三种探索NLP模型偏差的方法，我的团队在部署之前经常使用这三种方法进行探索和迭代。这些方法是:</p><ol class=""><li id="03ba" class="ou ov it kk b kl km ko kp kr ow kv ox kz oy ld oz pa pb pc bi translated"><strong class="kk iu">使用手工制作的数据集</strong>，旨在挑战您的模型和表面潜在偏差。</li><li id="f5cf" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld oz pa pb pc bi translated"><strong class="kk iu">分析子群之间的模型精度</strong>并验证每个子群的精度具有可比性。</li><li id="14fb" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld oz pa pb pc bi translated"><strong class="kk iu">干扰您的输入</strong>查看您的模型使用哪些单词/短语进行预测。</li></ol><p id="8758" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">适合您的方法将完全取决于您的模型类型和应用程序。好消息是，大多数常见的应用程序和模型都可以利用其中的一些方法。</p><p id="9a81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">希望这是一篇有用的信息丰富的文章！🚀</p><p id="2512" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">相关消息来源</p><ul class=""><li id="6cc5" class="ou ov it kk b kl km ko kp kr ow kv ox kz oy ld pe pa pb pc bi translated"><a class="ae ln" href="https://arxiv.org/pdf/2108.03362.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2108.03362.pdf</a></li><li id="76a1" class="ou ov it kk b kl pf ko pg kr ph kv pi kz pj ld pe pa pb pc bi translated"><a class="ae ln" href="https://sethstatistics.files.wordpress.com/2016/08/main.pdf" rel="noopener ugc nofollow" target="_blank">https://sethstatistics.files.wordpress.com/2016/08/main.pdf</a></li></ul></div></div>    
</body>
</html>