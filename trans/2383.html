<html>
<head>
<title>Reinforcement Learning in Minecraft: Create a Bot to Find Diamonds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《我的世界》的强化学习:创造一个寻找钻石的机器人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-a-bot-to-find-diamonds-in-minecraft-d836606a993a#2022-05-25">https://towardsdatascience.com/create-a-bot-to-find-diamonds-in-minecraft-d836606a993a#2022-05-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3b66" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用MineRL实现Python中的强化学习和行为克隆</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1e8c4e3bddd3897fa8df55d0a289cbcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JKGAY7grrGI-UQeaqt9q5w.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者(<a class="ae kv" href="https://account.mojang.com/documents/minecraft_eula" rel="noopener ugc nofollow" target="_blank"> Mojang license </a>)</p></figure><p id="98e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">《我的世界》是人工智能的下一个前沿。</p><p id="8922" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个巨大的游戏，有许多机制和复杂的动作序列。仅仅是教人类如何玩《我的世界》，就需要一个<a class="ae kv" href="https://minecraft.fandom.com/wiki/Minecraft_Wiki" rel="noopener ugc nofollow" target="_blank">超过8000页<strong class="ky ir">的整个维基</strong></a>。那么人工智能能有多好呢？</p><p id="b7ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我们将在本文中回答的问题。我们将设计一个机器人，并尝试完成《我的世界》最困难的挑战之一:从零开始寻找钻石。更糟糕的是，我们将在随机生成的<strong class="ky ir"> </strong>世界中接受这一挑战，因此我们无法学习特定的种子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/ea3a9bbb496ed022d28be27caefdfe2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rkUGZgIo9kKDosfuFhPpNw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">寻找钻石的行动顺序，图片作者(<a class="ae kv" href="https://account.mojang.com/documents/minecraft_eula" rel="noopener ugc nofollow" target="_blank"> Mojang许可证</a>)</p></figure><p id="ab84" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们要谈的不仅限于《我的世界》。可以应用于类似<strong class="ky ir">的复杂环境</strong>。更具体地说，我们将实现两种不同的技术，它们将成为我们智能代理的主干。</p><p id="057b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是在我们训练代理人之前，我们需要了解如何与环境互动。让我们从一个脚本化的机器人开始熟悉语法。我们将使用<a class="ae kv" href="https://minerl.io/" rel="noopener ugc nofollow" target="_blank"> MineRL </a>，一个奇妙的库来在《我的世界》构建人工智能应用程序。</p><p id="2622" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文中使用的代码可以在<a class="ae kv" href="https://colab.research.google.com/drive/1hRxR_UM72JAe32YveLxqoC6eX6Lqd9c2?usp=sharing" rel="noopener ugc nofollow" target="_blank">的Google Colab </a>上找到。它是由<a class="ae kv" href="https://github.com/KarolisRam/MineRL2021-Intro-baselines" rel="noopener ugc nofollow" target="_blank"> MineRL 2021竞赛</a>(麻省理工学院许可)的组织者制作的优秀笔记本的简化和微调版本。</p><h1 id="763b" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">📜一.脚本机器人</h1><p id="f8f6" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">MineRL允许我们用Python启动《我的世界》，并与游戏互动。这是通过流行的<code class="fe mq mr ms mt b">gym</code>库完成的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/4a618205d06a716fd39c522045b4f36b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*7yUvyJkv7_mzfQY92nB60w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1799" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在一棵树前。如你所见，分辨率<strong class="ky ir">相当低</strong>。低分辨率意味着更少的像素，这加快了速度。对我们来说幸运的是，神经网络不需要4K的分辨率来理解屏幕上发生的事情。</p><p id="f11a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们想让<strong class="ky ir">和</strong>在游戏中互动。我们的代理能做什么？以下是<a class="ae kv" href="https://minerl.io/docs/environments/#id14" rel="noopener ugc nofollow" target="_blank">可能采取的行动</a>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/9d32427b7bac4e519f16ac23b968bb87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2sMlc20dxvHaHPIGhcwamg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">动作列表(图片由作者提供)</p></figure><p id="cdc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">找到钻石的第一步是<strong class="ky ir">获取木材</strong>来制作一张工艺桌和一把木制鹤嘴锄。</p><p id="b423" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们试着靠近那棵树。这意味着我们需要按住“前进”按钮不到一秒钟。使用MineRL，每秒处理<strong class="ky ir"> 20个动作</strong>:我们不需要一整秒，所以让我们处理5次，然后再等待40个滴答。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/9b306a8aa256244020e805de44908a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rBsEtxcHRQzTsOHogFvreQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/290a8e93b45bae80fb2d0abcdbc408cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*C-yCC4TUwIHSs3faS73pEA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="16dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">太好了，让我们现在砍树吧。我们总共需要四项行动:</p><ul class=""><li id="1442" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">前进</strong>走在树的前面；</li><li id="8d63" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">攻击</strong>砍树；</li><li id="d365" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">摄像头</strong>向上或向下看；</li><li id="917c" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated"><strong class="ky ir">跳</strong>拿到最后一块木头。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/346afb4a3510affeeb6364bd1d667dfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6uSvnz0pNxwXYNYzLD6rtg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="b546" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">操作相机可能会很麻烦。为了简化语法，我们将使用来自GitHub库<a class="ae kv" href="https://github.com/KarolisRam/MineRL2021-Intro-baselines" rel="noopener ugc nofollow" target="_blank">的<code class="fe mq mr ms mt b">str_to_act</code>函数</a> (MIT许可证)。这是新脚本的样子:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn mv l"/></div></figure><p id="800b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代理人高效的砍下了<strong class="ky ir">整棵树</strong>。这是一个好的开始，但我们希望以更自动化的方式来完成它…</p><h1 id="d5c5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">🧠二世。深度学习</h1><p id="61cd" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我们的bot在固定环境下运行良好，但如果我们改变种子或其起点会发生什么？</p><p id="b020" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一切都是按照<strong class="ky ir">的剧本</strong>进行的，所以代理人可能会试着砍一棵不存在的树。</p><p id="5028" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这种方法对于我们的需求来说太静态了:我们需要能够适应新环境的东西。我们想要一个知道如何砍树的人工智能，而不是编写命令。自然，强化学习是训练这个代理的一个相关框架。更具体地说，deep RL似乎是解决方案，因为我们正在处理图像以选择最佳行动。</p><p id="95c7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两种实现方式:</p><ul class=""><li id="6563" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated"><strong class="ky ir">纯深度RL </strong>:通过与环境的交互，从零开始训练智能体。它每砍一棵树都会得到奖励。</li><li id="2086" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">模仿学习:代理学习如何从数据集中砍树。在这种情况下，它是一个人砍树的一系列动作。</li></ul><p id="b994" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这两种方法具有相同的结果，但它们并不等同。据<a class="ae kv" href="https://github.com/KarolisRam/MineRL2021-Intro-baselines" rel="noopener ugc nofollow" target="_blank"> MineRL 2021竞赛</a>的作者介绍，纯RL解决方案需要<strong class="ky ir"> 8小时</strong>，模仿学习代理需要<strong class="ky ir"> 15分钟</strong>才能达到相同的性能水平。</p><p id="ef13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们没有那么多时间可以花，所以我们选择模仿学习的解决方案。这种技术也叫<strong class="ky ir">行为克隆</strong>，是模仿的最简单形式。</p><p id="f1b6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意模仿学习并不总是比RL更有效率。如果你想了解更多，Kumar等人写了一篇关于这个话题的很棒的<a class="ae kv" href="https://bair.berkeley.edu/blog/2022/04/25/rl-or-bc/" rel="noopener ugc nofollow" target="_blank">博文</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/a3539aca601585245fb6ed032f1c1203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tMStW6YdFORe7WsZwDShew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="e94a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该问题被简化为多类分类任务。我们的数据集由mp4视频组成，因此我们将使用一个<a class="ae kv" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a> (CNN)将这些图像转化为相关的动作。我们的目标也是<strong class="ky ir">限制可以采取的行动</strong>(类别)的数量，这样CNN就有更少的选择，这意味着它将得到更有效的训练。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="2522" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本例中，我们手动定义<strong class="ky ir"> 7个相关动作</strong>:攻击、前进、跳跃、移动摄像机(左、右、上、下)。另一种流行的方法是应用K-means来自动检索人类采取的最相关的动作。在任何情况下，我们的目标都是抛弃最没用的行为来完成我们的目标，比如我们例子中的手工制作。</p><p id="99bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们在<code class="fe mq mr ms mt b">MineRLTreechop-v0</code>数据集上训练我们的CNN。其他数据集可以在<a class="ae kv" href="https://minerl.io/docs/environments/index.html#basic-environments" rel="noopener ugc nofollow" target="_blank">这个地址</a>找到。我们选择0.0001的学习率和6个时期，批量大小为32。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><pre class="kg kh ki kj gt np mt nq nr aw ns bi"><span id="4f52" class="nt lu iq mt b gy nu nv l nw nx">Step  4000 | Training loss = 0.878<br/>Step  8000 | Training loss = 0.826<br/>Step 12000 | Training loss = 0.805<br/>Step 16000 | Training loss = 0.773<br/>Step 20000 | Training loss = 0.789<br/>Step 24000 | Training loss = 0.816<br/>Step 28000 | Training loss = 0.769<br/>Step 32000 | Training loss = 0.777<br/>Step 36000 | Training loss = 0.738<br/>Step 40000 | Training loss = 0.751<br/>Step 44000 | Training loss = 0.764<br/>Step 48000 | Training loss = 0.732<br/>Step 52000 | Training loss = 0.748<br/>Step 56000 | Training loss = 0.765<br/>Step 60000 | Training loss = 0.735<br/>Step 64000 | Training loss = 0.716<br/>Step 68000 | Training loss = 0.710<br/>Step 72000 | Training loss = 0.693<br/>Step 76000 | Training loss = 0.695</span></pre><p id="1c24" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型是经过训练的。我们现在可以实例化一个环境，看看它的行为。如果训练成功，它应该疯狂地<strong class="ky ir">砍掉视线内的所有树木</strong>。</p><p id="6e56" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这一次，我们将使用<code class="fe mq mr ms mt b">ActionShaping</code>包装器将通过<code class="fe mq mr ms mt b">dataset_action_batch_to_actions</code>创建的数字数组映射到MineRL中的离散动作。</p><p id="7d81" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型需要正确格式的<strong class="ky ir">视点观察</strong>并输出逻辑。这些逻辑可以通过<code class="fe mq mr ms mt b">softmax</code>函数转化为一组7个动作的概率分布。然后我们根据概率随机选择一个行动。多亏了<code class="fe mq mr ms mt b">env.step(action)</code>，选定的动作在MineRL中被执行。</p><p id="ee72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个过程可以重复很多次。让我们做1000次，看看结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn mv l"/></div></figure><p id="4902" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的代理人相当混乱，但它设法在这个新的、看不见的环境中砍树。现在，如何找到钻石？</p><h1 id="8317" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">⛏️三世。脚本+模仿学习</h1><p id="3793" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">一个简单而强大的方法是将的脚本动作和人工智能结合起来。学习枯燥的东西，将知识编写成脚本。</p><p id="5304" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个范例中，我们将使用CNN来获取适量的木材(3000步)。然后，我们可以<strong class="ky ir">编写一个序列</strong>来制作木板、棍子、手工桌、木镐，并开始开采石头(它应该在我们的脚下)。这种石头可以用来制作一个可以开采铁矿石的石镐。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/e849cae289d5aa49b1565043a0d4c308.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4goOdaVMh1TRy0E8SPRxQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CNN +脚本方式，图片由作者(<a class="ae kv" href="https://account.mojang.com/documents/minecraft_eula" rel="noopener ugc nofollow" target="_blank"> Mojang license </a>)</p></figure><p id="2e47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是事情变得复杂的时候:铁矿石非常稀有，所以我们需要运行一段时间来寻找矿藏。然后，我们将不得不制造一个熔炉，熔化它来得到铁镐。最后，我们必须进入更深的地方，更加幸运地在不掉进岩浆的情况下获得钻石。</p><p id="9baa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如你所见，这是可行的，但结果是随机的。我们可以训练另一个代理人去<a class="ae kv" href="https://minerl.readthedocs.io/en/latest/environments/index.html#minerlobtaindiamond-v0" rel="noopener ugc nofollow" target="_blank">寻找钻石</a>，甚至训练第三个代理人去<a class="ae kv" href="https://minerl.readthedocs.io/en/latest/environments/index.html#minerlobtainironpickaxe-v0" rel="noopener ugc nofollow" target="_blank">制造铁镐</a>。如果你对更复杂的方法感兴趣，你可以阅读Kanervisto等人的<a class="ae kv" href="https://arxiv.org/abs/2202.10583" rel="noopener ugc nofollow" target="_blank">minell Diamond 2021竞赛</a>的结果。它描述了几种使用不同智能技术的解决方案，包括端到端深度学习架构。然而，这是一个复杂的问题，没有一个团队能够持续不断地找到钻石，如果有的话。</p><p id="fa1c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这就是为什么在下面的例子中我们将自己限制在获取一个石镐，但是您可以修改代码来做得更好。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mu mv l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nn mv l"/></div></figure><p id="90b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到我们的代理在最初的3000步中像疯子一样劈柴，然后我们的脚本接管并完成任务。这可能不明显，但是命令<code class="fe mq mr ms mt b">print(obs.inventory)</code>显示了一个石镐。请注意，这是一个精选的例子:大多数运行都没有那么好的结局。</p><p id="1daf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">代理失败的原因有几个:它可以在恶劣的环境中繁殖(水，熔岩等)。)，在没有木头的区域，甚至会摔死。尝试不同的种子会让你很好地理解这个问题的复杂性，并且有希望获得构建更好的事件代理的想法。</p><h1 id="7ffc" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="59cd" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">我希望你喜欢这个《我的世界》强化学习的小指南。除了其明显的受欢迎程度，《我的世界》还是一个尝试和测试RL代理的有趣环境。像<a class="ae kv" href="https://nethackchallenge.com/" rel="noopener ugc nofollow" target="_blank"> NetHack </a>一样，它需要<strong class="ky ir">对其机制有透彻的了解</strong>才能在程序生成的世界中计划精确的行动顺序。在这篇文章中，</p><ul class=""><li id="f7e6" class="mz na iq ky b kz la lc ld lf nb lj nc ln nd lr ne nf ng nh bi translated">我们学会了如何使用<strong class="ky ir">密涅尔</strong>；</li><li id="763e" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">我们看到了<strong class="ky ir">两种方法</strong>(脚本和行为克隆)以及如何组合它们；</li><li id="24da" class="mz na iq ky b kz ni lc nj lf nk lj nl ln nm lr ne nf ng nh bi translated">我们<strong class="ky ir">用短视频把代理的动作可视化</strong>。</li></ul><p id="0fd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该环境的主要缺点是它的<strong class="ky ir">处理时间</strong>慢。《我的世界》不是像NetHack或Pong那样的轻量级游戏，这就是为什么代理需要很长时间来训练。如果这对你来说是个问题，我会推荐像<a class="ae kv" href="https://openai.com/blog/gym-retro/" rel="noopener ugc nofollow" target="_blank">健身房复古</a>这样的轻松环境。</p><p id="532b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢您的关注！如果你对应用于电子游戏的人工智能感兴趣，请在Twitter上关注我。</p></div></div>    
</body>
</html>