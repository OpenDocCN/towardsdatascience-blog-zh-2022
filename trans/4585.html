<html>
<head>
<title>How to Prune Neural Networks with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用PyTorch修剪神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-prune-neural-networks-with-pytorch-ebef60316b91#2022-10-12">https://towardsdatascience.com/how-to-prune-neural-networks-with-pytorch-ebef60316b91#2022-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a66d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">流行的框架内置了对这一伟大技术的支持，这一技术提高了泛化能力、准确性和推理速度</h2></div><p id="39c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我一直认为修剪需要单独的模块，但是我最近发现PyTorch内置了对它的支持。文档有点缺乏，所以我决定写这篇文章，向你展示一些技巧和窍门！</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/6eb6a43d1c16a92a757c0a9b8ac43106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ho-R1C9J2c4gHvpSAcGT7w.jpeg"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">Wikimedia Commons上的图片由<a class="ae lr" href="https://commons.wikimedia.org/wiki/File:Two-layer_feedforward_artificial_neural_network.png" rel="noopener ugc nofollow" target="_blank"> Akritasa </a>提供。作者修改。根据CC-BY-SA-4.0获得许可。</p></figure><h1 id="937e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">什么是修剪？</h1><p id="e68d" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">修剪是一种从神经网络中移除权重或偏差(参数)的技术。如果做得好，这将减少模型的内存占用，提高泛化能力，加快推理速度，并允许用更少的样本进行训练/微调。当然，您不能只是从您的网络中随机删除参数并期望它执行得更好，但是您可以确定哪些参数对您的目标是不必要的并删除它们。不用说，你还应该注意你移除了多少参数:如果你移除了太多，你的网络将会表现得更差，或者如果你阻塞了梯度流(例如，通过从连接层修剪所有参数)，你的网络可能会完全失效。</p><p id="bb1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，在训练之后进行修剪是很常见的，一般来说，也可以在训练之前或期间进行修剪。</p><h1 id="f69a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我应该删除哪些参数？</h1><p id="6eef" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在前一段中，我有意使用“不必要的”一词来指代可修改的参数。但是是什么使得参数变得不必要呢？这是一个相当复杂的问题，至今仍是一个研究领域。寻找可修剪权重(修剪标准)的最流行的方法有:</p><ol class=""><li id="0ca5" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la mu mv mw mx bi translated"><strong class="kh ir"> Random*: </strong>简单剪枝随机参数。</li><li id="4eaa" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir"> Magnitude*: </strong>修剪具有最小权重的参数(例如它们的L2范数)。</li><li id="1949" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">梯度:</strong>根据累积的梯度修剪参数(需要一个反向过程，因此需要数据)。</li><li id="507c" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">信息:</strong>利用高阶曲率信息等其他信息进行剪枝。</li><li id="5c82" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la mu mv mw mx bi translated"><strong class="kh ir">学会了:</strong>当然，我们也可以训练我们的网络自我修剪(很贵，需要训练)！</li></ol><p id="95b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">*PyTorch内置了对随机、基于幅度的修剪的支持。这两种方法都出奇地有效，因为它们很容易计算，而且可以在没有任何数据的情况下计算。</p><h1 id="0d09" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">修剪的类型</h1><h2 id="c188" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">非结构化修剪</h2><p id="ab5d" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">非结构化普宁是指修剪参数的单个原子。例如，线性层中的单个权重、卷积层中的单个过滤器像素、自定义层中的一些缩放浮动等。要点是您在没有各自结构的情况下修剪参数，因此命名为非结构化修剪。</p><h2 id="b388" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">结构化剪枝</h2><p id="9acb" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">作为非结构化修剪的替代方法，结构化修剪会删除整个参数结构。这并不意味着它必须是一个完整的参数，但你可以超越删除单个原子，例如，在线性权重中，你可以删除整个行或列，或者，在卷积层中，可以删除整个滤波器(我将感兴趣的读者指向[1]，其中我们已经表明，许多公开可用的模型包含一组退化的滤波器，这些滤波器应该是可删除的)。</p><p id="b39d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在实践中，您可以通过非结构化修剪实现更高的修剪率，但这可能不会加速您的模型，因为您仍然需要进行所有的计算。例如，结构化修剪可以修剪整个卷积通道，从而显著降低所需的矩阵乘法次数。目前，有一种趋势是在软件和硬件中支持稀疏张量，因此在未来非结构化修剪可能变得非常重要。</p><h2 id="dc52" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated"><strong class="ak">局部与全局修剪</strong></h2><p id="0120" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">修剪可以发生在每层(<strong class="kh ir">局部</strong>)或所有多层/所有层(<strong class="kh ir">全局</strong>)。</p><h1 id="9cd3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">PyTorch中的修剪</h1><h2 id="24e5" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">PyTorch中的修剪是如何工作的？</h2><p id="c9d7" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">修剪在<code class="fe np nq nr ns b">torch.nn.utils.prune</code>中实现。</p><p id="15ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有趣的是，PyTorch不仅仅是简单地将修剪后的参数设置为零。PyTorch将参数<code class="fe np nq nr ns b">&lt;param&gt;</code>复制到一个名为<code class="fe np nq nr ns b">&lt;param&gt;_original</code>的参数中，并创建一个存储修剪掩码<code class="fe np nq nr ns b">&lt;param&gt;_mask</code>的缓冲区。它还创建了一个模块级的<code class="fe np nq nr ns b">forward_pre_hook</code>(一个在向前传递之前调用的回调函数)，将修剪掩码应用于原始权重。</p><p id="3371" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这具有以下结果:打印<code class="fe np nq nr ns b">&lt;param&gt;</code>将打印带有应用掩码的参数，但是通过<code class="fe np nq nr ns b">&lt;module&gt;.parameters()</code>或<code class="fe np nq nr ns b">&lt;module&gt;.named_parameters()</code>列出它将显示原始的、未修剪的参数。</p><p id="e544" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这具有以下优点:有可能确定模块是否已经被修剪，并且原始参数是可访问的，这允许对各种修剪技术进行实验。然而，这是以一些内存开销为代价的。</p><h2 id="bc59" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">支持哪些PyTorch版本？</h2><p id="372a" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如果你有1.4.0或更高版本，你是好的。</p><h1 id="c311" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我该如何实施？</h1><p id="bd83" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">支持的选项有点混乱，API也有点不一致，所以我做了这个概述，希望能澄清一些事情:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nt"><img src="../Images/7250a3e20d58a8c83c3234e56a8ece25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l7Nx7TtTSHdqISSzbNrtiA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">py torch 1 . 12 . 1版支持的修剪技术。图片作者。</p></figure><h2 id="871b" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">局部非结构化剪枝</h2><p id="537e" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">以下函数可用于本地非结构化修剪:</p><blockquote class="nu nv nw"><p id="7ee3" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . random _ unstructured(模块，名称，金额)</p><p id="6df7" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . L1 _ unstructured(模块，名称，金额，重要性分数=无)</p></blockquote><p id="a263" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">只需调用上面的函数，将你的层/模块作为<code class="fe np nq nr ns b">module</code>传递，并将参数的名称传递给<code class="fe np nq nr ns b">name</code>。通常这将是<em class="nx">重量</em>或<em class="nx">偏差</em>。<code class="fe np nq nr ns b">amount</code>参数指定要修剪多少。您可以传递一个介于0和1之间的浮点数作为比率，或者传递一个整数来定义参数的绝对数量。请注意，这些命令可以迭代应用，并且<code class="fe np nq nr ns b">amount</code>始终与剩余(即未删减)参数的数量相关。所以，如果你用<code class="fe np nq nr ns b">amount=0.5</code>反复修剪一个有12个条目的参数，第一轮后你会得到6个参数，然后是3个…</p><p id="040c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个修剪40%卷积层权重的示例。请注意4个参数是如何设置为零的。</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="e85b" class="nd lt iq ns b gy of og l oh oi">&gt;&gt;&gt; import torch.nn.utils.prune as prune<br/>&gt;&gt;&gt; conv = torch.nn.Conv2d(1, 1, 3)<br/>&gt;&gt;&gt; prune.random_unstructured(conv, name="weight", amount=4)<br/>&gt;&gt;&gt; conv.weight<br/>tensor([[[[-0.0000,  0.0000,  0.2603],           <br/>          [-0.3278,  0.0000,  0.0280],      <br/>          [-0.0361,  0.1409,  0.0000]]]], grad_fn=&lt;MulBackward0&gt;)</span></pre><p id="5768" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们对原子进行操作，所以不支持L1规范以外的其他规范。</p><h2 id="0196" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">全局非结构化修剪</h2><p id="cf84" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">如果您想要全局非结构化修剪，命令略有不同:</p><blockquote class="nu nv nw"><p id="4a88" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . global _ unstructured(parameters，pruning_method，importance_scores=None，**kwargs)</p></blockquote><p id="293b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我们需要将<code class="fe np nq nr ns b">parameters</code>作为元组列表传递，这些元组包含要修剪的模块及其参数名。<code class="fe np nq nr ns b">pruning_method=prune.L1Unstuctured</code>似乎是唯一支持的选项。这里有一个来自<a class="ae lr" href="https://pytorch.org/tutorials/intermediate/pruning_tutorial.html#pruning-a-module" rel="noopener ugc nofollow" target="_blank"> PyTorch文档</a>的例子:</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="c9f5" class="nd lt iq ns b gy of og l oh oi">model = ...</span><span id="d5c6" class="nd lt iq ns b gy oj og l oh oi">parameters = (<br/>    (model.conv1, "weight"),<br/>    (model.conv2, "weight"),<br/>    (model.fc1, "weight"),<br/>    (model.fc2, "weight"),<br/>    (model.fc3, "weight"),<br/>)</span><span id="60ed" class="nd lt iq ns b gy oj og l oh oi">prune.global_unstructured(<br/>    parameters,<br/>    pruning_method=prune.L1Unstructured,<br/>    amount=0.2,<br/>)</span></pre><p id="bbc9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果要修剪特定层类型(例如卷积层)的所有权重，可以按如下方式自动收集它们:</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="b972" class="nd lt iq ns b gy of og l oh oi">model = ...</span><span id="1780" class="nd lt iq ns b gy oj og l oh oi">parameters_to_prune = [<br/>    (module, "weight") for module in filter(lambda m: type(m) == torch.nn.Conv2d, model.modules())<br/>]</span><span id="b96f" class="nd lt iq ns b gy oj og l oh oi">prune.global_unstructured(<br/>    parameters_to_prune,<br/>    pruning_method=prune.L1Unstructured,<br/>    amount=0.2,<br/>)</span></pre><p id="f670" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，您可以根据需要调整过滤器。</p><h2 id="1541" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">局部结构化剪枝</h2><p id="d5fc" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">PyTorch仅支持<em class="nx">局部</em>结构化修剪:</p><blockquote class="nu nv nw"><p id="dbe0" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . ln _ structured(模块，名称，金额，n，dim，importance _ scores =无)</p><p id="db86" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . random _ structured(模块、名称、金额、维度)</p></blockquote><p id="52a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些命令与本地非结构化命令非常相似，唯一的区别是您必须定义<code class="fe np nq nr ns b">dim</code>参数。这将定义你的结构的轴。以下是相关维度的助手:</p><p id="7afb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于<code class="fe np nq nr ns b">torch.nn.Linear</code></p><ul class=""><li id="75e9" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la ok mv mw mx bi translated">断开一个输入的所有连接:<code class="fe np nq nr ns b">1</code></li><li id="3c6b" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la ok mv mw mx bi translated">断开一个神经元:<code class="fe np nq nr ns b">0</code></li></ul><p id="c6c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于<code class="fe np nq nr ns b">torch.nn.Conv2d</code>:</p><ul class=""><li id="4956" class="mp mq iq kh b ki kj kl km ko mr ks ms kw mt la ok mv mw mx bi translated">通道(输出一个特征图的内核堆栈):<code class="fe np nq nr ns b">0</code></li><li id="d01d" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la ok mv mw mx bi translated">神经元(在不同通道中处理相同输入特征图的内核堆栈):<code class="fe np nq nr ns b">1</code></li><li id="9d21" class="mp mq iq kh b ki my kl mz ko na ks nb kw nc la ok mv mw mx bi translated">过滤内核:<em class="nx">不支持</em>(需要多轴[2，3]或预先整形，这也不容易)</li></ul><p id="2d57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，与非结构化修剪相反，您实际上可以通过<code class="fe np nq nr ns b">n</code>参数定义使用什么范数。可以在这里找到支持的列表:<a class="ae lr" href="https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" rel="noopener ugc nofollow" target="_blank">https://py torch . org/docs/stable/generated/torch . norm . html # torch . norm</a>。</p><p id="768d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是一个基于L2范数修剪整个通道(在我们的例子中对应于2个内核)的例子:</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="c388" class="nd lt iq ns b gy of og l oh oi">&gt;&gt;&gt; conv = torch.nn.Conv2d(2, 3, 3)<br/>&gt;&gt;&gt; prune.ln_structured(conv, name="weight", amount=1, n=2, dim=0)<br/>&gt;&gt;&gt; conv.weight<br/>tensor([[[[ 0.0000,  0.0000,  0.0000],<br/>          [ 0.0000,  0.0000,  0.0000],<br/>          [ 0.0000, -0.0000, -0.0000]],</span><span id="62b0" class="nd lt iq ns b gy oj og l oh oi">         [[ 0.0000, -0.0000,  0.0000],<br/>          [ 0.0000,  0.0000,  0.0000],<br/>          [ 0.0000,  0.0000, -0.0000]]],</span><span id="0504" class="nd lt iq ns b gy oj og l oh oi">        [[[ 0.2284,  0.1574, -0.0215],<br/>          [-0.1096,  0.0952, -0.2251],<br/>          [-0.0805, -0.0173,  0.1648]],</span><span id="8d85" class="nd lt iq ns b gy oj og l oh oi">         [[-0.1104,  0.2012, -0.2088],<br/>          [-0.1687,  0.0815,  0.1644],<br/>          [-0.1963,  0.0762, -0.0722]]],</span><span id="9d36" class="nd lt iq ns b gy oj og l oh oi">        [[[-0.1055, -0.1729,  0.2109],<br/>          [ 0.1997,  0.0158, -0.2311],<br/>          [-0.1218, -0.1244,  0.2313]],</span><span id="1767" class="nd lt iq ns b gy oj og l oh oi">         [[-0.0159, -0.0298,  0.1097],<br/>          [ 0.0617, -0.0955,  0.1564],<br/>          [ 0.2337,  0.1703,  0.0744]]]], grad_fn=&lt;MulBackward0&gt;)</span></pre><p id="18fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，如果我们删除一个神经元，输出会如何变化:</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="671d" class="nd lt iq ns b gy of og l oh oi">&gt;&gt;&gt; conv = torch.nn.Conv2d(2, 3, 3)<br/>&gt;&gt;&gt; prune.ln_structured(conv, name="weight", amount=1, n=2, dim=1)<br/>&gt;&gt;&gt; conv.weight<br/>tensor([[[[ 0.0000, -0.0000, -0.0000],<br/>          [-0.0000, -0.0000,  0.0000],<br/>          [-0.0000,  0.0000,  0.0000]],</span><span id="466a" class="nd lt iq ns b gy oj og l oh oi">         [[-0.1013,  0.1255,  0.0151],<br/>          [-0.1110,  0.2281,  0.0783],<br/>          [-0.0215,  0.1412, -0.1201]]],</span><span id="665f" class="nd lt iq ns b gy oj og l oh oi">        [[[ 0.0000, -0.0000,  0.0000],<br/>          [ 0.0000, -0.0000,  0.0000],<br/>          [ 0.0000, -0.0000,  0.0000]],</span><span id="78e7" class="nd lt iq ns b gy oj og l oh oi">         [[ 0.0878,  0.2104,  0.0414],<br/>          [ 0.0724, -0.1888,  0.1855],<br/>          [ 0.2354,  0.1313, -0.1799]]],</span><span id="9b45" class="nd lt iq ns b gy oj og l oh oi">        [[[-0.0000, -0.0000, -0.0000],<br/>          [-0.0000, -0.0000,  0.0000],<br/>          [ 0.0000, -0.0000,  0.0000]],</span><span id="0be6" class="nd lt iq ns b gy oj og l oh oi">         [[ 0.1891,  0.0992,  0.1736],<br/>          [ 0.0451,  0.0173,  0.0677],<br/>          [ 0.2121,  0.1194, -0.1031]]]], grad_fn=&lt;MulBackward0&gt;)</span></pre><h2 id="ad49" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">自定义基于重要性的修剪</h2><p id="60f4" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">您可能已经注意到，前面的一些函数支持<code class="fe np nq nr ns b">importance_score</code>参数:</p><blockquote class="nu nv nw"><p id="57e7" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . L1 _ unstructured(模块，名称，金额，重要性分数=无)</p><p id="829b" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . ln _ structured(模块，名称，金额，n，dim，importance _ scores =无)</p><p id="0ec6" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . global _ unstructured(parameters，pruning_method，importance_scores=None，**kwargs)</p></blockquote><p id="db78" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以将一个张量(或<code class="fe np nq nr ns b">global_unstructured</code>的张量列表)传递给那些与您的参数形状相同的函数，并带有您自定义的修剪信息条目。这可作为量值的替代，并为您提供用任何自定义评分来替换它的选项。</p><p id="6963" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，让我们实现一种简单的修剪方法，该方法消除了线性层权重张量中的前5个条目:</p><pre class="lc ld le lf gt ob ns oc od aw oe bi"><span id="e109" class="nd lt iq ns b gy of og l oh oi">&gt;&gt;&gt; linear = torch.nn.Linear(3, 3)<br/>&gt;&gt;&gt; prune.l1_unstructured(linear, name="weight", amount=5, importance_scores=torch.arange(9).view(3, 3))<br/>&gt;&gt;&gt; linear.weight<br/>tensor([[-0.0000,  0.0000, -0.0000],<br/>        [ 0.0000, -0.0000, -0.1293],<br/>        [ 0.1886,  0.4086, -0.1588]], grad_fn=&lt;MulBackward0&gt;)</span></pre><h2 id="f71f" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">助手功能</h2><p id="9b06" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">PyTorch还提供了几个助手函数。我想展示的第一个是:</p><blockquote class="nu nv nw"><p id="609a" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch . nn . utils . prune . is _ prune(模块)</p></blockquote><p id="03da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如您可能已经猜到的，这个函数允许您检查模块中的任何参数是否已经被删除。如果模块被删除，则返回True。然而，您<strong class="kh ir">不能</strong>指定要检查哪个参数。</p><p id="54fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想展示的最后一个功能是:</p><blockquote class="nu nv nw"><p id="18da" class="kf kg nx kh b ki kj jr kk kl km ju kn ny kp kq kr nz kt ku kv oa kx ky kz la ij bi translated">torch.nn.utils.prune.remove(模块，名称)</p></blockquote><p id="6071" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能天真地认为这撤销了修剪，但实际情况恰恰相反:它通过删除掩码、原始参数和前向挂钩来应用修剪。最后，将修剪后的张量写入参数。因此，在这样的模块上调用<code class="fe np nq nr ns b">torch.nn.utils.prune.is_pruned(module)</code>将返回False。</p><h2 id="fe78" class="nd lt iq bd lu ne nf dn ly ng nh dp mc ko ni nj me ks nk nl mg kw nm nn mi no bi translated">结论</h2><p id="8a8b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">PyTorch提供了一种内置的方法，可以根据大小或自定义度量对张量随机应用非结构化或结构化修剪。然而，API有点混乱，文档可以改进。</p></div><div class="ab cl ol om hu on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="ij ik il im in"><p id="94ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nx">感谢您阅读本文！如果你喜欢它，请考虑订阅我的更新。如果你有任何问题，欢迎在评论中提出。</em></p></div><div class="ab cl ol om hu on" role="separator"><span class="oo bw bk op oq or"/><span class="oo bw bk op oq or"/><span class="oo bw bk op oq"/></div><div class="ij ik il im in"><p id="5064" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考资料:</p><p id="6ea1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1] P. Gavrikov和J. Keuper，<a class="ae lr" href="https://openaccess.thecvf.com/content/CVPR2022/html/Gavrikov_CNN_Filter_DB_An_Empirical_Investigation_of_Trained_Convolutional_Filters_CVPR_2022_paper.html" rel="noopener ugc nofollow" target="_blank"> CNN滤波器DB:训练卷积滤波器的实证研究</a> (2022)，CVPR 2022 Orals</p><p id="3d37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="nx">这项工作由德国巴登-符腾堡州科学、研究和艺术部资助，基金号为32–7545.20/45/1(Q-AMeLiA)。</em></p></div></div>    
</body>
</html>