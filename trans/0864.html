<html>
<head>
<title>Bayesian Machine Learning and Julia are a match made in heaven</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯机器学习和朱莉娅是天作之合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-machine-learning-and-julia-are-a-match-made-in-heaven-c3c498f2d221#2022-03-08">https://towardsdatascience.com/bayesian-machine-learning-and-julia-are-a-match-made-in-heaven-c3c498f2d221#2022-03-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="04d4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">两个 Julia 库让贝叶斯机器学习变得轻而易举</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9f25aca2cbc031fccbb6bd54d84a6a5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EdK_aduhC-W1AaVp"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@pablozuchero?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Pablo Zuchero </a>在<a class="ae ky" href="https://unsplash.com/s/photos/thumbs-up?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="e8ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我在<a class="ae ky" href="https://sarem-seitz.com/blog/when-is-bayesian-machine-learning-actually-useful/" rel="noopener ugc nofollow" target="_blank">早先的一篇文章</a>中所说，贝叶斯机器学习可能非常强大。然而，用 Python 构建实际的贝叶斯模型有时有点麻烦。你在网上找到的大多数解决方案要么相对复杂，要么需要学习另一种特定领域的语言。当您需要高度定制的解决方案时，后者很容易限制您的表达能力。</p><p id="c963" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，在 Julia 中进行贝叶斯机器学习可以缓解这两个问题。事实上，你只需要几行原始的 Julia 代码来构建，例如，一个用于回归的<a class="ae ky" href="https://arxiv.org/pdf/2007.06823.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯神经网络</a>。朱莉娅的<a class="ae ky" href="https://fluxml.ai/Flux.jl/stable/" rel="noopener ugc nofollow" target="_blank">通量</a>和<a class="ae ky" href="https://turing.ml/stable/" rel="noopener ugc nofollow" target="_blank">图灵</a>软件包将处理引擎盖下的繁重工作。</p><p id="7955" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此今天，我想向你展示如何用不到 30 行 Julia 代码实现和训练贝叶斯神经网络。在向您展示代码之前，让我们简要回顾一下主要的理论方面:</p><h1 id="6aec" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">贝叶斯机器学习的三个步骤</h1><p id="9e7b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">像往常一样，我们希望通过贝叶斯定律找到后验分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/480f4af6b53e2d99c64a76979d6b8786.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/format:webp/1*BXOHTTPWKp_0kZRxyIMIQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="9764" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于分母中的数据项是一个常数，我们可以简化上述公式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/37cb5adba7d640d9f651938aa3db09da.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*wr2a9VjCnYikoCWtI5s0wg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="653e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了避免混淆，让我们使用以下标准措辞:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/55a67dfcaf39b1740b241bb9045b5b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*El1fi8aDH7TeS7no69cKjg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="5685" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于贝叶斯神经网络回归，我们进一步指定似然函数:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/11fb96db5f83ea65d3f088c9a0a9222b.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*BQ1gZRO_BGz9HpC3yt0nZA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="99fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这表示具有由神经网络输出定义的平均值的独立正态分布的乘积。正态分布的方差被选择为常数。</p><p id="73ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相应的先验分布可能如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/31e85b18aca5cfff2ca6427c007b5b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*Ek4Syx5eBaXQHXFmCtmrfg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="ea7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">网络权重的先验分布是独立的标准正态分布。对于方差的平方根(也称为标准偏差)，我们使用标准的<a class="ae ky" href="https://en.wikipedia.org/wiki/Gamma_distribution" rel="noopener ugc nofollow" target="_blank">伽马分布</a>。所以，从理论的角度来看，我们都准备好了。</p><p id="af00" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理想情况下，我们现在希望通过以下步骤实现贝叶斯神经网络:</p><p id="6a7f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在代码中将这三个步骤相互分开，将有助于我们</p><ul class=""><li id="de56" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu nc nd ne nf bi translated"><strong class="lb iu">保持可读性</strong> —除了相应的函数更小之外，潜在的读者也可以更容易地从先验中辨别可能性。</li><li id="4369" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu nc nd ne nf bi translated"><strong class="lb iu">在粒度级别保持代码的可测试性</strong>——可能性和先验分布显然是不同的关注点。因此，我们也应该能够单独测试它们。</li></ul><p id="7e5b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到这一点，让我们开始在 Julia 中构建模型。</p><h1 id="5d01" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">定义似然函数</h1><p id="6534" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated"><code class="fe nl nm nn no b">Flux</code>库提供了我们构建和使用神经网络所需的一切。它有<code class="fe nl nm nn no b">Dense</code>来建立前馈层和<code class="fe nl nm nn no b">Chain</code>来将这些层组合成一个网络。事实上，它们就像我们在本文<a class="ae ky" href="https://sarem-seitz.com/blog/implementing-neural-networks-in-16-lines-of-raw-julia/" rel="noopener ugc nofollow" target="_blank">中定义的<code class="fe nl nm nn no b">Layer</code>和<code class="fe nl nm nn no b">Network</code>结构一样工作。</a></p><p id="4f79" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们的<code class="fe nl nm nn no b">Likelihood</code>结构由神经网络<code class="fe nl nm nn no b">network</code>和标准差<code class="fe nl nm nn no b">sigma</code>组成。在前馈通道中，我们使用网络的输出和<code class="fe nl nm nn no b">sigma</code>来定义高斯似然的条件均值和标准差:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="0946" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nl nm nn no b">Normal.(...)</code>中的点让我们为每个网络输出定义一个正态分布，每个都有标准偏差<code class="fe nl nm nn no b">sigma</code>。我们可以将此与来自<a class="ae ky" href="https://juliastats.org/Distributions.jl/stable/" rel="noopener ugc nofollow" target="_blank">分布</a>库的<code class="fe nl nm nn no b">logpdf(...)</code>相结合，以训练具有最大似然梯度下降的模型。然而，为了执行贝叶斯机器学习，我们需要添加更多的元素。</p><p id="f22a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就引出了本文的中心功能，即<code class="fe nl nm nn no b">Flux.destructure()</code>。从文档中:</p><pre class="kj kk kl km gt nr no ns nt aw nu bi"><span id="7fcd" class="nv lw it no b gy nw nx l ny nz">destructure(m)<br/>Flatten a model's parameters into a single weight vector.</span><span id="fe64" class="nv lw it no b gy oa nx l ny nz">julia&gt; m = Chain(Dense(10, 5, σ), Dense(5, 2), softmax) Chain(Dense(10, 5, σ), Dense(5, 2), softmax) julia&gt; θ, re = destructure(m);</span><span id="23c5" class="nv lw it no b gy oa nx l ny nz">julia&gt; θ <br/>67-element Vector{Float32}:<br/>-0.1407104 <br/>...<br/>The second return value re allows you to reconstruct the original network after making modifications to the weight vector (for example, with a hypernetwork).</span><span id="96e2" class="nv lw it no b gy oa nx l ny nz">julia&gt; re(θ .* 2)<br/>Chain(Dense(10, 5, σ), Dense(5, 2), softmax)</span></pre><p id="8885" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，<code class="fe nl nm nn no b">destructure(...)</code>获取一个实例化的模型结构并返回一个包含两个元素的元组:</p><ol class=""><li id="524f" class="mx my it lb b lc ld lf lg li mz lm na lq nb lu ob nd ne nf bi translated">将<strong class="lb iu">模型参数</strong>串接成一个向量</li><li id="64da" class="mx my it lb b lc ng lf nh li ni lm nj lq nk lu ob nd ne nf bi translated">一个<strong class="lb iu">重建器</strong>函数，它采用一个如<strong class="lb iu"> 1 所示的参数向量。</strong>作为输入，并返回带有这些参数的模型</li></ol><p id="85e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">后者很重要，因为我们可以向重建器提供任意参数向量。只要它的长度有效，它就会返回具有给定参数配置的相应模型。在代码中:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="18e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后一个函数将允许我们分别向重建器提供权重和标准偏差参数。为了让<code class="fe nl nm nn no b">Turing</code>处理贝叶斯推理部分，这是一个必要的步骤。</p><p id="e05f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这里，我们准备转移到先前的分布。</p><h1 id="62e9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">定义先验分布</h1><p id="5ac1" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这部分非常简短，我们只需定义权重向量和标准差标量的先验分布:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="3e2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定义了可能性和先验后，我们可以从<strong class="lb iu">先验预测分布</strong>中抽取样本</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/8cde9a835eb7853852b33f72f1eb1ef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*YRruzoO-5YyeId-bL2oDzw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="6cb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然这可能看起来像一个复杂的公式，但我们基本上只是绘制蒙特卡罗样本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="1610" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先前预测分布本身包括来自<code class="fe nl nm nn no b">sigma</code>的噪声。仅从网络中提取的先验预测，即先验预测平均值，产生了良好且平滑的样本:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/d5b00c73d3811db4fe6a47da317feb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*L2_kfaoAgR9L77xm.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oe">先验预测从均值函数(贝叶斯神经网络的输出；图片作者)</em></p></figure><p id="0bcb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们可以训练这个模型了。</p><h1 id="aea7" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">训练贝叶斯神经网络</h1><p id="f403" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在本例中，我们将使用合成数据，采样自</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/13553a232658a5b3bc10697ccf189602.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*fq_OSrqgeQbfUSqGb2GtXA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="0507" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">后一个因子表示<em class="og"> (-2，2) </em>上的均匀密度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/128d515d3afeb4cbf314289b00841c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*al-m2Clw7PU-Wrr-.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oe">合成数据集——50 个来自正常均匀模拟(图片由作者提供)</em></p></figure><p id="d5bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使用<code class="fe nl nm nn no b">Turing</code>，我们需要定义一个模型，正如他们的文档中所解释的<a class="ae ky" href="https://turing.ml/dev/docs/using-turing/quick-start" rel="noopener ugc nofollow" target="_blank">。应用于我们的示例，我们得到以下结果:</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="d694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们需要为贝叶斯后验推断选择一个算法。由于我们的模型相对较小，<a class="ae ky" href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo" rel="noopener ugc nofollow" target="_blank">哈密顿蒙特卡罗</a> (HMC)是一个合适的选择。事实上，HMC 被普遍认为是贝叶斯机器学习的<em class="og">黄金标准</em>算法。不幸的是，它在高维空间变得非常低效。</p><p id="ca10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管如此，我们现在通过<a class="ae ky" href="https://turing.ml/dev/docs/library/#Turing.Inference.HMC" rel="noopener ugc nofollow" target="_blank">图灵</a>使用 HMC，并收集来自 MCMC 后验的结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="609d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这里，我们可以看到完整的后验预测分布，</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/6f4bf502780de5918d4db25543cf1b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*977kGj4zRj41-iD5S__SDg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="e112" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是以与先前预测分布类似的方式完成的(星形变量表示训练集之外的新输入)。唯一的区别是，我们现在使用来自 MCMC 后验分布的样本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/fbb77706bda11553a9dc8305ed7a4b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*yfuzeOHCfdap0Haa.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oe">90%置信区间的后验预测分布。作为贝叶斯机器学习的典型，认知不确定性在观察数据的范围之外增加(图片由作者提供)</em></p></figure><p id="b74d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用上面的例子，很容易尝试其他以前的发行版。</p><h1 id="5b08" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">即插即用，具有不同的先验分布</h1><p id="3f85" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">作为另一大优势，<code class="fe nl nm nn no b">Turing</code>可以使用来自<code class="fe nl nm nn no b">Distributions</code>库的几乎所有发行版作为先验。这也允许我们尝试一些奇异的权重先验，比如半径为 0.5 的半圆分布。我们所要做的就是替换高斯先验:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="8db0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用与之前相同的设置，我们得到以下后验预测分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/70e0fa43ebe34ee11b7699dc944bf306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*CYUfEUZSK8Rnw7vT.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="oe">独立</em> <code class="fe nl nm nn no b"><em class="oe">Semicircle(0.5)</em></code> <em class="oe">先验权重分布的后验预测分布(图片由作者提供)</em></p></figure><p id="41c2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可能性显然不止于此。另一个卓有成效的调整可能是引入<a class="ae ky" href="https://en.wikipedia.org/wiki/Hyperprior" rel="noopener ugc nofollow" target="_blank">超先验分布</a>，例如权重先验的标准偏差。</p><p id="a312" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用不同于神经网络的模型也很简单。你只需要调整<code class="fe nl nm nn no b">Likelihood</code> struct 和相应的函数。</p><h1 id="1606" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="d634" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本文简要介绍了 Julia 的贝叶斯机器学习。事实上，<a class="ae ky" href="https://julialang.org/benchmarks/" rel="noopener ugc nofollow" target="_blank"> Julia 不仅速度快</a>而且还能让编码变得更加容易和高效。</p><p id="3857" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然 Julia 仍然是一门年轻的语言，在将 Julia 程序部署到产品中时还存在一些问题，但对于研究和原型开发来说，它绝对是一门令人敬畏的语言。尤其是不同库之间的无缝互操作性可以大大缩短学术界内外的迭代周期。</p><p id="6d92" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这一点上，我也非常希望在不久的将来，我们会看到更多的 Julia 被用于工业级的产品代码中。</p></div><div class="ab cl oi oj hx ok" role="separator"><span class="ol bw bk om on oo"/><span class="ol bw bk om on oo"/><span class="ol bw bk om on"/></div><div class="im in io ip iq"><p id="ec24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="og">原载于 2022 年 3 月 8 日</em><a class="ae ky" href="https://sarem-seitz.com/blog/bayesian-machine-learning-and-julia-are-a-match-made-in-heaven/" rel="noopener ugc nofollow" target="_blank"><em class="og">https://sarem-seitz.com</em></a><em class="og">。</em></p></div></div>    
</body>
</html>