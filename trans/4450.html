<html>
<head>
<title>Transfer Learning with a One-Dimensional Signal</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一维信号的迁移学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-with-a-one-dimensional-signal-76a0d543e9aa#2022-10-03">https://towardsdatascience.com/transfer-learning-with-a-one-dimensional-signal-76a0d543e9aa#2022-10-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ffa3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">加上数据洞察力</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f00b5d303ed8e2e474f8ce235c9b5119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1vz3Ks8sDjeVC2vfwoG5Rw.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><h2 id="f386" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">目录</h2><blockquote class="lr ls lt"><p id="1d5b" class="lu lv lw lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">——<a class="ae mr" href="#dfab" rel="noopener ugc nofollow">简介</a><br/>——<a class="ae mr" href="#16cd" rel="noopener ugc nofollow">信号统计</a><br/>——<a class="ae mr" href="#59b9" rel="noopener ugc nofollow">获取双谱图像</a><br/>——<a class="ae mr" href="#cdef" rel="noopener ugc nofollow">载荷图像</a><br/>——<a class="ae mr" href="#9f93" rel="noopener ugc nofollow">创建模型</a><br/>——<a class="ae mr" href="#74bc" rel="noopener ugc nofollow">训练并评估</a><br/>——<a class="ae mr" href="#7e17" rel="noopener ugc nofollow">损耗和精度度量</a><br/>——<a class="ae mr" href="#dc27" rel="noopener ugc nofollow">数据洞察</a><br/>——<a class="ae mr" href="#7814" rel="noopener ugc nofollow">结论</a></p></blockquote><h1 id="dfab" class="ms kw iq bd kx mt mu mv la mw mx my ld jw mz jx lh jz na ka ll kc nb kd lp nc bi translated">介绍</h1><p id="ec1b" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">迁移学习重用为旧任务建立的模型作为新任务的起点。模型参数被冻结—对旧任务的训练已经完成。VGG16就是这样一个训练有素的模型。这是一个卷积神经网络(CNN)对图像进行分类。它赢得了2014年ImageNet挑战赛。</p><p id="629e" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">我们稍微修改VGG16，使其成为新图像的有效分类器。模型重用大大降低了培训时间和成本。这就是迁移学习的神奇之处。</p><p id="863d" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">我们的数据集是从一维信号产生的图像。一维信号是一条侧向弯曲的线。信号幅度随时间上下移动。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/cb75876166d00ce089c44990e276fd54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*BUcSEGkqYgEPSXTc_o63og.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">信号幅度随时间的变化。信号是一维，时间是二维。</p></figure><p id="cd33" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">图像是从振动信号中提取的<a class="ae mr" href="https://medium.com/@mackiej/fourier-and-bispectral-analysis-of-signals-c7a71021b1c8" rel="noopener">双谱</a>图像。每个都是从4，095 (2 -1)个数据点段构建的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c63fc5d4439d8eb45f818d8fe8b577f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*FZ_j97TMnymVb_bn6EdAGw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">显示泵气蚀的双谱图像。</p></figure><p id="014b" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">振动信号是以16，000 Hz采样的泵加速计数据。工程师记录了三种取样条件。通过透明的泵壳[ <a class="ae mr" href="#b35f" rel="noopener ugc nofollow"> 1 </a> ]观察每种情况。</p><p id="0521" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated"><strong class="lx ir">三个信号:</strong></p><ol class=""><li id="5147" class="nk nl iq lx b ly lz mb mc le nm li nn lm no mq np nq nr ns bi translated"><strong class="lx ir">无气蚀</strong> (nc) —泵正常运行</li><li id="8119" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated"><strong class="lx ir">低汽蚀</strong>【LC】<strong class="lx ir"/>—小气泡云</li><li id="dae7" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated"><strong class="lx ir">产生气蚀</strong>(直流)——大团气泡</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/d0b9bf22fe8bb618911222b4ff4ff08a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6oer_8Fzfmo2ar7uDG9VUg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">以16000Hz采样的泵加速计信号。从上到下，条件为无气蚀、低气蚀和发展气蚀。</p></figure><h2 id="16cd" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">信号统计</h2><p id="a3ca" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">每个加速度计信号有800，001个数据点(16，000 Hz时为50秒)。每个的平均振幅为零。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/4465ca5e0070d4f221419ac54c81184c.png" data-original-src="https://miro.medium.com/v2/resize:fit:478/format:webp/1*1cBVtbAZx2CiY9RmzG-KNw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">熊猫统计无/低/发展空化信号。</p></figure><p id="dbe1" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">这三个条件的配对图显示它们之间几乎没有相关性。在这个样本中，发展的空化(dc1)状态看起来是高斯型的。我们稍后再讨论这个问题的重要性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/0328cd33b9dbaa906cd6b3f915bfea1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qk0jVldsdGZ8VqvpXRmCFw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。(<a class="ae mr" href="https://gist.github.com/jkmackie/2a5e455fd8072ccc81daeeee1eb6f18a" rel="noopener ugc nofollow" target="_blank"> GitHub要诀</a>)</p></figure><h2 id="59b9" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">获取双谱图像</h2><p id="c365" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">图像和信号保存在这个<a class="ae mr" href="https://github.com/jkmackie/transfer_learning_VGG16" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中。要自己创建图像，请遵循以下方法:</p><ol class=""><li id="209d" class="nk nl iq lx b ly lz mb mc le nm li nn lm no mq np nq nr ns bi translated">使用<code class="fe ob oc od oe b">joblib.load(‘signals.joblib’)</code>加载每个信号的熊猫数据帧:nc1和dc1。将信号分割成不重叠的4，095个点段。使用这种技术，一个800，000点的信号有195个图像。</li><li id="92b3" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated">作者的双谱代码(下面的双谱2D)从信号段<code class="fe ob oc od oe b">y</code> [ <a class="ae mr" href="#01cb" rel="noopener ugc nofollow"> 2 </a> ]创建双谱图像。在第104行实例化Bispectrum2D。使用<code class="fe ob oc od oe b">freqsample=16,000</code>和<code class="fe ob oc od oe b">window_name=’hanning’</code>。Hanning是用于未知信号的常用窗口。要绘制图像，请使用<code class="fe ob oc od oe b">bs2D.plot_bispec_magnitude()</code>。</li><li id="c6e0" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated">保存每个图像。我强烈建议在每个文件名中保存索引。这使得将来分离测试图像变得容易。<code class="fe ob oc od oe b">plt.savefig(f’./images/{feature_name}_hanning_{start_idx}-{end_idx}.png’)</code></li><li id="3acf" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated"><a class="ae mr" href="https://gist.github.com/jkmackie/70ada8c662e3dd7a2b0da05ca3d05c1f" rel="noopener ugc nofollow" target="_blank">将</a>图像格式化为224x224像素。这是VGG16所需的尺寸。</li><li id="2ea8" class="nk nl iq lx b ly nt mb nu le nv li nw lm nx mq np nq nr ns bi translated">使用VGG16 <strong class="lx ir">预处理_输入</strong>库:</li></ol><p id="210b" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated"><code class="fe ob oc od oe b">from tensorflow.keras.applications.vgg16 import preprocess_input</code></p><p id="ae4e" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">它将图像从RGB转换到BGR。此外，“每个颜色通道相对于ImageNet数据集以零为中心，没有缩放。”</p><blockquote class="lr ls lt"><p id="6b26" class="lu lv lw lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated"><strong class="lx ir">双谱2D Python数据类:</strong></p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从1D信号产生2D双谱图像。作者的Python数据类。(<a class="ae mr" href="https://gist.github.com/jkmackie/388344f86e29c4841077f74a95bad6df" rel="noopener ugc nofollow" target="_blank"> GitHub </a>)</p></figure></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="5e55" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated"><strong class="lx ir"> <em class="lw">关于双谱的旁注2D: </em> </strong> <em class="lw">计算是一个独立的实现——不需要Python类继承接触点，也不需要术语翻译。作者将两个Python类重构为一个dataclass。双谱2D自动从采样频率产生频率范围。</em></p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><h2 id="cdef" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">加载图像</h2><p id="4e1e" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">每个图像类都有一个文件夹。“训练”文件夹已标记了用于训练模型的图像。有效用于培训期间的模型调整和度量。测试(又名维持)是看不见的图像，以验证模型的普遍性。我们将进行以下二进制分类场景:无空化与直接空化[ <a class="ae mr" href="#e63b" rel="noopener ugc nofollow"> 3 </a> ]。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/08ffcf0d8d49611aea1372d5714e4e76.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*vy_VMIcNgxzhuEq9AoLOBA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">文件夹结构:nc =无气蚀；dc =直接空化。由于担心数据泄漏，作者选择将有效文件夹与列车文件夹分开。Tensorflow API可以动态地将训练分成训练和验证数据。</p></figure><p id="dcc8" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">从<a class="ae mr" href="https://github.com/jkmackie/transfer_learning_VGG16" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>下载图像数据集。参见用Python编写的迁移学习Jupyter笔记本。</p><p id="4272" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">我们如何为图像建模？TensorFlow 2是图像模型的软件工具。</p><p id="d856" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">在张量流中创建图像数据集。详情如下。有210幅训练图像和60幅验证图像。每个中的图像都是互斥的。此外，验证图像在时间上在训练图像之后(信号是时间序列)。</p><blockquote class="lr ls lt"><p id="1635" class="lu lv lw lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">用于模型拟合的图像数据集:</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加载VGG16。获取并可视化数据。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/e9adb67671719ac685e7d4ea016613a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d8kIqrHLwCq8zsZl6qzpmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">从RGB到BGR的VGG16特定预处理后的双谱图像。</p></figure><h2 id="9f93" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">创建模型</h2><p id="5c74" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">让我们回顾一下数据集结构。它将如何与VGG16配合使用？</p><p id="5d1d" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">我们一批选择32张图片。这些图像是224 X 224的。3表示红色、绿色和蓝色(RGB)通道。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="1ad9" class="kv kw iq oe b gy ou ov l ow ox">1 train class names: ['dc', 'nc']<br/>2 val class names: ['dc', 'nc']<br/>3 images, xpixels, ypixels, color_channels: (32, 224, 224, 3)<br/>4 labels: (32,)</span></pre><p id="0a6a" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">在下面的第3行，我们初始化VGG16。它有将近1500万个参数。它们被设置为不可训练，因此被冻结。此外，最后几个分类层被排除:include_top = False。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="5a2b" class="kv kw iq oe b gy ou ov l ow ox">Model: "vgg16"<br/>_________________________________________________________________<br/> Layer (type)                Output Shape              Param #   <br/>=================================================================<br/> input_5 (InputLayer)        [(None, 224, 224, 3)]     0         <br/>                                                                 <br/> block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      <br/>                                                                 <br/> block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     <br/>                                                                 <br/> block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         <br/>                                                                 <br/> block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     <br/>                                                                 <br/> block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    <br/>                                                                 <br/> block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         <br/>                                                                 <br/> block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    <br/>                                                                 <br/> block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    <br/>                                                                 <br/> block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    <br/>                                                                 <br/> block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         <br/>                                                                 <br/> block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   <br/>                                                                 <br/> block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   <br/>                                                                 <br/> block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   <br/>                                                                 <br/> block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         <br/>                                                                 <br/> block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   <br/>                                                                 <br/> block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   <br/>                                                                 <br/> block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   <br/>                                                                 <br/> block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         <br/>                                                                 <br/>=================================================================<br/>Total params: 14,714,688<br/>Trainable params: 0<br/>Non-trainable params: 14,714,688<br/>_________________________________________________________________</span></pre><p id="4f2b" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">VGG16就是我们的<code class="fe ob oc od oe b">base_model</code>。现在插入最后几个分类层(下面的第4–7行和第12–15行)。一如既往，选择神经网络层的大小更多的是艺术而不是科学。这可能需要反复试验。好消息是起点是一个令人敬畏的<code class="fe ob oc od oe b">base_model</code>。</p><blockquote class="lr ls lt"><p id="d67e" class="lu lv lw lx b ly lz jr ma mb mc ju md me mf mg mh mi mj mk ml mm mn mo mp mq ij bi translated">带有分类层的模型层:</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div></figure><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="cbce" class="kv kw iq oe b gy ou ov l ow ox">Model: "sequential"<br/>_________________________________________________________________<br/> Layer (type)                Output Shape              Param #   <br/>=================================================================<br/> vgg16 (Functional)          (None, 7, 7, 512)         14714688  <br/>                                                                 <br/> flatten (Flatten)           (None, 25088)             0         <br/>                                                                 <br/> dense (Dense)               (None, 10)                250890    <br/>                                                                 <br/> dropout (Dropout)           (None, 10)                0         <br/>                                                                 <br/> dense_1 (Dense)             (None, 1)                 11        <br/>                                                                 <br/>=================================================================<br/>Total params: 14,965,589<br/>Trainable params: 250,901<br/>Non-trainable params: 14,714,688<br/>_________________________________________________________________</span></pre><p id="ad8b" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">注意，我们在模型中添加了25万个<strong class="lx ir">可训练参数</strong>。因为所有的VGG16参数都被冻结，所以之前为零。</p><h2 id="74bc" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">培训和评估</h2><p id="a69e" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">我们建立了模型。现在设置培训流程。编译模型(下面的第2行)。使用自定义回调记录指标(第8–30行)。模型被拟合(第33行)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div></figure><p id="420c" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">下面的代码加载test_ds —测试数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of og l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">评估测试(也称为保持)数据。</p></figure><p id="3aa3" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">测试图像评估100%准确(<em class="lw">通常——结果是随机的</em>)。只使用了三个时期的训练。这就是迁移学习的神奇之处。</p><h2 id="7e17" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">损失和准确性指标</h2><p id="64a4" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">在左下图的第一个时期之后，训练损失下降到接近零。注意在一个时期后，训练损失比确认损失高得多。是否存在与原始时序信号相关的数据泄漏？</p><p id="9f71" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">每个文件夹都是独立的(是不是<strong class="lx ir">而不是</strong>使用TensorFlow API来拆分验证图像)。此外，训练、验证和测试数据是时间分离的。所以训练数据在时间线上先于验证数据。并且验证数据在测试数据之前。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/d7c9b9137b50f55b71e29e2f9bc14e3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCLTLiZVXGImN2eGh9yICg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者的模型损失和准确性。压差设置为0.3。</p></figure><p id="d27a" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">根据Keras开发人员的说法，辍学可能导致培训损失高于“测试”(验证)损失。完整的解释是<a class="ae mr" href="https://keras.io/getting_started/faq/#why-is-my-training-loss-much-higher-than-my-testing-loss" rel="noopener ugc nofollow" target="_blank">这里</a>。下面，培训和验证之间的差距通过消除辍学而缩小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/72df5bd619ad52fd5369a5962cadce52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f5JW5dzTl6LeAzdbE4hyDA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">鞋底脱落已移除。</p></figure><p id="dbdd" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">尽管有非典型的度量曲线，但模型是一般化的。事实上，不管有没有辍学，测试预测都是100%准确的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/80d7cb9e76ac0d8a1c57b37d2a255a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*WwmrFZSVqmWpTHbSN4eLUg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试数据度量(<code class="fe ob oc od oe b"><a class="ae mr" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">sklearn.metrics</a></code> <a class="ae mr" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">)。分类_报告</a></p></figure><p id="675d" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">这个任务需要这么大的CNN模型吗？大概不会吧！CNN似乎过度参数化了。的确，谷歌大脑研究称，一个简单的带<code class="fe ob oc od oe b"><strong class="lx ir">num_weights = 2 * <em class="lw">n</em>_samples + <em class="lw">d</em>_dimensions</strong></code>的两层神经网络可以表示任何函数[ <a class="ae mr" href="#3645" rel="noopener ugc nofollow"> 4 </a> ]。</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><h2 id="dc27" class="kv kw iq bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">数据洞察</h2><p id="2d6a" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">我们建立了一个有效的二元分类模型，有近1500万个参数。工作做得好吗？我们是否正确地探索和理解了信号数据？</p><p id="4009" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">是时候重新查看<strong class="lx ir">信号统计</strong>部分的800点随机样本直方图了。回想一下产生的空化信号看上去是高斯型的。</p><p id="30fd" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">我们用更多的数据点做直方图吧。下面的<strong class="lx ir"> nc </strong>信号看起来是8000点和80000点样本的双峰。相比之下，<strong class="lx ir"> dc </strong>信号是单峰高斯曲线。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/2e582cdd4ec0a43669d70c31c19c08ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8TJvCNZFoVcyXevRu3vD_g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">信号直方图。顶行—无气穴现象。底排—形成气穴。</p></figure><p id="1016" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">可能二进制分类就是驼峰计数，不需要深度学习！两个峰值表示没有气蚀，一个峰值表示气蚀。</p><p id="78c7" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">为了计算峰值，我们需要(1)平滑信号和(2)计算局部最大值。通过<a class="ae mr" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html" rel="noopener ugc nofollow" target="_blank">核密度估计</a>，波动信号转换为平滑曲线。SciPy有一个<code class="fe ob oc od oe b">find_peaks</code>函数来计算信号的局部最大值。</p><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="1bc2" class="kv kw iq oe b gy ou ov l ow ox">from scipy.signal import find_peaks<br/>peaks_num = len(find_peaks(y_kde, height=0.2)[0])</span></pre><p id="8702" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">通过将信号分段来计算峰值。同样，我们预计无气穴现象有两个峰值，而发展气穴现象有一个峰值。</p><p id="3f32" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">首先测试800个点段峰值。也就是说，每个信号有1000个独立段<code class="fe ob oc od oe b">(800*1,000=800,000)</code>。结果是几百个错误。糟糕的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/2b893a46ec541f7db471c3a167c9ff5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*_cnli2eFsKaarIqwLEHtyA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">峰值计数无气蚀的KDE。指数显示了8000点的区间。100个片段中的单个错误在上面以红色显示。</p></figure><p id="b42b" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">直方图显示了<strong class="lx ir">8000点</strong>段的更清晰的峰值。事实证明，增加数据点可以提高准确性。除一个区段外，所有区段都有正确的峰数，准确率为99.5%。这是一大进步。所有需要的是一个更大的样本和曲线平滑[ <a class="ae mr" href="#9d57" rel="noopener ugc nofollow"> 5 </a> ]。</p><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="c295" class="kv kw iq oe b gy ou ov l ow ox"><strong class="oe ir">8,000 point segments:</strong><br/>* no cavitation - 100 segments<br/>* developed cavitation - 100 segments<br/>* total segments - 200 segments</span><span id="950e" class="kv kw iq oe b gy pd ov l ow ox">accuracy = 99.5%<strong class="oe ir"> =</strong> (200 segments - 1 error) / 200 segments * 100</span></pre><h1 id="7814" class="ms kw iq bd kx mt mu mv la mw mx my ld jw mz jx lh jz na ka ll kc nb kd lp nc bi translated">结论</h1><p id="c80d" class="pw-post-body-paragraph lu lv iq lx b ly nd jr ma mb ne ju md le nf mg mh li ng mk ml lm nh mo mp mq ij bi translated">本项目使用了两种情况下加速度计信号的图像:<em class="lw">无空化</em>和<em class="lw">产生空化</em>。我们使用一个拥有近1500万个参数的卷积神经网络对图像进行分类。其中，25万只受过抓痒训练，大约1400万只被冷冻。</p><p id="7e52" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">CNN对于二元分类是有效的。但是，有一个更简单的选择。没有图像和没有大模型是必需的。数峰就行了。</p></div><div class="ab cl oh oi hu oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="ij ik il im in"><p id="f559" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated"><strong class="lx ir">后记</strong></p><p id="8a25" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">对于寻找更多双谱分析的读者，我写了<a class="ae mr" href="https://medium.com/@mackiej/fourier-and-bispectral-analysis-of-signals-c7a71021b1c8" rel="noopener">信号的傅立叶和双谱分析</a>。</p><p id="3ca0" class="pw-post-body-paragraph lu lv iq lx b ly lz jr ma mb mc ju md le mf mg mh li mj mk ml lm mn mo mp mq ij bi translated">除非另有说明，所有图片均由作者提供。祝你愉快！😎</p><pre class="kg kh ki kj gt oq oe or os aw ot bi"><span id="4a81" class="kv kw iq oe b gy ou ov l ow ox"><strong class="oe ir">REFERENCES</strong></span><span id="b35f" class="kv kw iq oe b gy pd ov l ow ox">[1] Ali Hajnayeb, "<a class="ae mr" href="https://www.researchgate.net/journal/Shock-and-Vibration-1875-9203/publication/356754152_Cavitation_Analysis_in_Centrifugal_Pumps_Based_on_Vibration_Bispectrum_and_Transfer_Learning/links/61aa54b8aade5b1bf5ffe596/Cavitation-Analysis-in-Centrifugal-Pumps-Based-on-Vibration-Bispectrum-and-Transfer-Learning.pdf" rel="noopener ugc nofollow" target="_blank">Cavitation Analysis in Centrifugal Pumps Based on Vibration Bispectrum and Transfer Learning</a>", 2021.  </span><span id="c100" class="kv kw iq oe b gy pd ov l ow ox">Hajnayeb Accelerometer Dataset:  <a class="ae mr" href="https://www.researchgate.net/publication/308415702_No_Cavitation1" rel="noopener ugc nofollow" target="_blank">nc</a>, <a class="ae mr" href="https://www.researchgate.net/publication/308415892_Limited_Cavitation1" rel="noopener ugc nofollow" target="_blank">lc</a>, <a class="ae mr" href="https://www.researchgate.net/publication/308415784_Developed_Cavitation1" rel="noopener ugc nofollow" target="_blank">dc</a></span><span id="01cb" class="kv kw iq oe b gy pd ov l ow ox">[2] Matteo Bachetti, et al., stingray v1.0 code, <a class="ae mr" href="https://docs.stingray.science/" rel="noopener ugc nofollow" target="_blank">https://docs.stingray.science</a>, 2022.</span><span id="e63b" class="kv kw iq oe b gy pd ov l ow ox">[3] Multi-class classification is successful with bispectrum images as per [1].  The neuron count in the final layer increases--one per class.  The author chose binary classification to highlight a classification alternative.</span><span id="3645" class="kv kw iq oe b gy pd ov l ow ox">[4] Chiyuan Zhang, et al., <a class="ae mr" href="https://arxiv.org/pdf/1611.03530.pdf" rel="noopener ugc nofollow" target="_blank">Understanding Deep Learning Requires Rethinking Generalization</a>, 2017.</span><span id="9d57" class="kv kw iq oe b gy pd ov l ow ox">[5] Test overlapping time segments to get more confident peak counting works.  Increase the number of segments per signal from 100 to 800. Slide the segment window in 1,000 point steps rather 8,000 point steps. The result is two errors total (for both nc and dc).  See nc1 indices 199000-207000 and 200000-208000.  1598 correct out of 1600 is 99.875% accuracy, i.e.  (1600-2)/1600*100.  This is better accuracy than the fewer segments per signal scenario.</span><span id="df1b" class="kv kw iq oe b gy pd ov l ow ox"> <br/>                         <a class="ae mr" href="#f386" rel="noopener ugc nofollow">GO TO TABLE OF CONTENTS</a></span></pre></div></div>    
</body>
</html>