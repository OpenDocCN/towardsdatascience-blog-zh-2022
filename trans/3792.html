<html>
<head>
<title>Why SQL-Like Interfaces are Sub-optimal for Distributed Computing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么类似SQL的接口对于分布式计算来说是次优的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-sql-like-interfaces-are-sub-optimal-for-distributed-computing-45f62224bab4#2022-08-23">https://towardsdatascience.com/why-sql-like-interfaces-are-sub-optimal-for-distributed-computing-45f62224bab4#2022-08-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="991f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">检查SQL接口的局限性</h2></div><p id="74e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编剧<a class="ae lb" href="https://www.linkedin.com/in/kvnkho/" rel="noopener ugc nofollow" target="_blank">凯文·库</a>和<a class="ae lb" href="https://www.linkedin.com/in/han-wang-97272610/" rel="noopener ugc nofollow" target="_blank">汪涵</a></p><p id="10ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们最近的<a class="ae lb" href="https://databricks.com/dataaisummit/session/fuguesql-enhanced-sql-interface-pandas-and-spark-dataframes" rel="noopener ugc nofollow" target="_blank"> Spark Data + AI Sumit talk </a>的书面版本。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/d8fc4190f6af80491373cb336ec70181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eVrO6e9TS3F4-MggB28Waw.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">柴犬驾驶飞机——作者图片</p></figure><h1 id="f164" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">分布式计算的类SQL框架</h1><p id="3bb9" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">在我们的上一篇文章中，我们讨论了使用Pandas接口进行分布式计算的局限性。有些人很快就认为我们支持SQL，但这也不完全正确。在这里，我们将了解传统SQL以及将其用作大数据工作流语法的难点。对于活跃的SQL用户来说，这些都不会太令人惊讶，但是讨论它们将展示使用SQL与使用Python之间的权衡。</p><p id="9c1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据社区经常在SQL和Python之间两极分化。喜欢Pandas和Spark提供的功能接口的人通常会很快指出SQL为什么不能进行更复杂的转换，或者需要更多的代码行。另一方面，SQL用户发现SQL作为一种语言更具表现力。在本文的最后一节，我们将展示这些工具并不相互排斥，我们可以通过<a class="ae lb" href="https://github.com/fugue-project/fugue/" rel="noopener ugc nofollow" target="_blank">赋格</a>无缝地利用它们。</p><h1 id="1349" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">SQL经常被Python代码夹在中间</h1><p id="96dd" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">当我们在本文中谈论SQL时，我们指的是像<a class="ae lb" href="https://duckdb.org/" rel="noopener ugc nofollow" target="_blank"> DuckDB </a>这样的工具，或者对于大数据，像<a class="ae lb" href="https://spark.apache.org/sql/" rel="noopener ugc nofollow" target="_blank"> SparkSQL </a>和<a class="ae lb" href="https://dask-sql.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> dask-sql </a>这样的工具。最后两个接口允许SQL爱好者用类似SQL的语言表达计算逻辑，然后在各自的分布式计算引擎(Spark或Dask)上运行它。</p><p id="241c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是即使这些SQL接口存在，它们也经常在Python代码之间被调用。以Spark的<a class="ae lb" href="https://spark.apache.org/docs/3.2.0/sql-getting-started.html#inferring-the-schema-using-reflection" rel="noopener ugc nofollow" target="_blank">后续文档</a>(也见下图)为例，Python代码仍然需要执行大量数据帧的转换或加载，以及SQL查询后的后处理。这是因为标准SQL没有表达分布式计算用户执行的许多操作的语法。目前，SQL不足以表达端到端的工作流。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mp"><img src="../Images/4efb81891e4d3bc731ad9e06556bd98e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sBs1hTx6SbXEDa3PiFcQ9A.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">来自<a class="ae lb" href="https://spark.apache.org/docs/3.2.0/sql-getting-started.html#inferring-the-schema-using-reflection" rel="noopener ugc nofollow" target="_blank"> Spark文档的示例</a></p></figure><p id="f883" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于主要想使用SQL的用户来说，有很多Python代码需要理解。SQL通常被归入工作流的有限部分。我们将通过一个具体的例子更仔细地研究SQL的缺点。</p><h1 id="e6f3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">示例数据和查询</h1><p id="0838" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">以下面由多个时间序列组成的数据帧为例，有三列。第一列指的是分组，第二列指的是排序(你可以把它想象成一个datetime)，最后一列指的是关注的值。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/1d52ec6f87824d153f5192ff814b98fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/0*nc0NH-e9aAQtpEwZ"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">基线数据框架—作者提供的图像</p></figure><p id="56d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以如下所示的查询为例。没必要真的深究和理解。如果这已经令人望而生畏，那是因为对于更复杂的操作来说，SQL的表达能力更差，更难阅读。我们将在下一部分对其进行分解。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mr"><img src="../Images/07d415c0143c0f1bded89e89466c73b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xibxV-eWb5sJQqCB"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">对基线数据帧的SQL查询—按作者排序的图像</p></figure><p id="940d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该块中有5条<code class="fe ms mt mu mv b">SELECT</code>语句。按顺序，他们做:</p><ul class=""><li id="214b" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nb nc nd ne bi translated">获得这些值的滚动平均值和滚动标准偏差</li><li id="c986" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">计算滚动z值(有足够预热的记录)并过滤掉空记录</li><li id="d824" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">根据异常值计数获取排名靠前的时间序列</li><li id="66c8" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">用一个<code class="fe ms mt mu mv b">INNER JOIN</code>获得最差时间序列的完整数据到先前的z分数表</li><li id="8729" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">对最差表中的z分值求和</li></ul><p id="ac1d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此操作的设计并不完全合理。更重要的是查询和中间表的结构。我们有一个由两个下游表使用的中间表<code class="fe ms mt mu mv b">z</code>。这就引出了传统SQL的第一个问题。</p><h1 id="3498" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">问题1:传统的SQL缺乏用于分布式计算的语法</h1><p id="035b" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">上面查询的结构如下所示。桌子<code class="fe ms mt mu mv b">z</code>最终被<code class="fe ms mt mu mv b">top</code>和<code class="fe ms mt mu mv b">worst</code>共同使用。因为分布式计算使用惰性计算，所以只在需要时才计算操作。这样做的一个副作用是，当使用Spark或Dask时，<code class="fe ms mt mu mv b">z</code>可能会被重新计算两次，一次用于<code class="fe ms mt mu mv b">top</code>,一次用于<code class="fe ms mt mu mv b">worst</code>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a5c3e7f4ea52ae87a2fcb0f7751af0e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/0*rryYlIFoDGTkZVpA"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">数据帧z使用了两次—图片由作者提供</p></figure><p id="8a2d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过在Spark数据帧上显式调用<code class="fe ms mt mu mv b">.persist()</code>可以避免<code class="fe ms mt mu mv b">z</code>的重新计算。但是我们在使用SparkSQL接口的时候如何持久化呢？没有<code class="fe ms mt mu mv b">PERSIST</code>关键词。我们需要分解SQL查询，并在查询的下游部分之前使用Python调用persist调用。SQL也没有<a class="ae lb" href="https://spark.apache.org/docs/2.4.4/sql-pyspark-pandas-with-arrow.html#grouped-map" rel="noopener ugc nofollow" target="_blank">分组映射语义</a>。</p><p id="6425" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">问题是SQL没有分布式计算操作的关键字，比如持久化或广播。如果没有必要的语法，查询优化对我们来说就是一个黑盒，结果可能不是最佳的(在我们的例子中，差别是21秒对12秒)。这表明<code class="fe ms mt mu mv b">z</code>花了9秒钟来计算，我们可以通过显式使用persist调用来删除重复的计算。</p><p id="4104" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">缺乏表示这些的语法阻止了我们充分利用分布式计算引擎，除非我们将逻辑带回Python。</strong></p><h1 id="fd11" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">问题2: SQL传统上只返回一个表</h1><p id="7527" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">接下来，一个<strong class="kh ir"> SQL查询与一个返回相关联。</strong>它面向单一任务，限制了可能操作的表面积。例如，将一个数据帧分割成两个独立的数据帧通常用于机器学习(训练-测试分割)。如果不将一个查询分解成多个查询，这是不可能的，这会造成一些冗余。</p><p id="7034" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于熟悉Python的人来说，这相当于用一个函数调用返回多个值。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/046dd41f71ced0031c8ac38871368f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/0*iHyKBJiBOLioQNoI"/></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">标准SQL不支持的语义—按作者分类的图像</p></figure><h1 id="a6e6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">问题3: SQL引入了大量样板代码</h1><p id="ce28" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">SQL的另一个缺点是它引入了大量样板代码。上面的查询已经通过使用公共表表达式(cte)写得很好了，它允许从上到下读取。在其他情况下，SQL从业者通常从内向外编写查询，其中内部查询用于外部“下游”查询。SQL从业者经常不得不处理长达数百行的查询。</p><p id="a0c8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更深入地看这个查询，我们甚至不关心上面查询中的中间表，但是我们无论如何都要给它们命名，以便以后引用它们。<strong class="kh ir">大量的样板代码降低了阅读查询所表达的业务逻辑的能力。</strong>这增加了维护的开销，尤其是对于没有编写原始查询的人。</p><h1 id="e502" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">问题4:修改会导致框架锁定</h1><p id="2560" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">SparkSQL支持使用修改后的语法读取parquet文件。注意，第一个<code class="fe ms mt mu mv b">SELECT</code>语句有一个类似于下面的<code class="fe ms mt mu mv b">FROM</code>:</p><pre class="ld le lf lg gt nm mv nn no aw np bi"><span id="80d3" class="nq lt iq mv b gy nr ns l nt nu">FROM parquet.`/tmp/t.parquet`</span></pre><p id="9cab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这实际上是Spark特有的语法，有助于Spark用户，但它造成了框架锁定。SQL的一个优点是它无处不在，被广泛采用，但是如果您想使用另一个SQL引擎，添加特定的语法会降低可移植性。这是创建框架锁定的Spark特定语法的最简单的例子，但是还有很多。</p><h1 id="91a7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">传统的SQL很难在大数据上迭代</h1><p id="5ce0" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">这些问题的结果是大数据上的SQL查询变得难以迭代。痛点被放大了。大数据查询通常需要几个小时，这使得用户必须能够快速、廉价地进行迭代。</p><p id="118d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在处理大数据时，快速迭代有三个主要障碍。</p><ul class=""><li id="bb4d" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nb nc nd ne bi translated"><strong class="kh ir">在迭代查询的下游部分之前，我们如何缓存昂贵的中间步骤的结果？</strong></li><li id="2177" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">我们如何在较小的数据上运行完整的查询来进行测试？然后在准备就绪时将其无缝引入大数据？</li><li id="ce43" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated"><strong class="kh ir">我们如何在SQL语法中保持加载、保存和持久化等操作，以便不需要频繁地将数据提交给Python？</strong></li></ul><p id="9bb4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">列表中的第一个包括在代码的Python和SQL部分之间处理数据帧的技巧，但这仍然是次优的用户体验。像上面这样相对较大的SQL查询需要拆分，并用更多的Python代码包围起来。我们如何避免这种情况，并将大部分代码保留在SQL中？</p><p id="58dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">列表中的最后两个用目前的工具几乎是不可能的。即使SQL代码是标准的SQL并且跨后端兼容，我们的问题也变成了Python代码。同样，SQL不足以单独表达端到端的工作流。我们求助于编写PySpark代码，这是框架锁定的另一个来源。</p><h1 id="9fc0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">FugueSQL —用于计算工作流的增强SQL界面</h1><p id="8349" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><a class="ae lb" href="https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes_sql.html" rel="noopener ugc nofollow" target="_blank"> FugueSQL </a>通过扩展标准SQL来解决这些问题，使其对计算工作流更具可读性、可移植性和表达性。FugueSQL是Fugue的开源接口，使用户能够在分布式计算引擎上编写端到端的查询。我们可以使用FugueSQL将上面的SQL重写为下面的形式。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nv"><img src="../Images/935e8d3d859849a24679b4d2d2c358ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNUjgTVA1JTfCH6IsC_45g.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">使用FugueSQL重写的SQL —图片由作者提供</p></figure><p id="dca9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">FugueSQL遵循对任何后端都不可知的SQL原则；这段代码从任何框架锁定中删除。用户只需指定引擎，就可以在Pandas或Duckdb到Spark或Dask之间切换。上面的代码可以在任何后台的赋格支持上运行。</p><p id="c646" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将检查上面查询中突出显示的更改:</p><ol class=""><li id="84d8" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nw nc nd ne bi translated"><code class="fe ms mt mu mv b">LOAD</code>现在是一个兼容所有后端的通用操作。FugueSQL还附带了一个<code class="fe ms mt mu mv b">SAVE</code>关键字，它允许用户执行完整的提取-转换-加载(ETL)工作流。FugueSQL的附加关键字下推到指定的后端。例如，<code class="fe ms mt mu mv b">LOAD</code>用Spark引擎用parquet会翻译成PySpark的<code class="fe ms mt mu mv b">spark.read.parquet</code>。</li><li id="e94a" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nw nc nd ne bi translated">变量赋值减少了大量样板代码。另一个变化是缺少一个明确的<code class="fe ms mt mu mv b">FROM</code>条款。如果没有<code class="fe ms mt mu mv b">FROM</code>子句，则自动消耗上一步中的数据帧。</li><li id="e3ba" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nw nc nd ne bi translated"><code class="fe ms mt mu mv b">PERSIST</code>关键字下推到后端持久化(本例中是Spark)。这仅仅通过添加一个关键字就明确地消除了z的重新计算。</li></ol><p id="f8ef" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的代码片段是在Jupyter笔记本单元格中编写的。与原始查询相比，该查询可以很容易地分成多个单元格(稍作修改)。我们需要做的就是使用<code class="fe ms mt mu mv b">YIELD</code>关键字来<a class="ae lb" href="https://fugue-tutorials.readthedocs.io/tutorials/fugue_sql/operators.html#yield" rel="noopener ugc nofollow" target="_blank">将数据帧</a>保存在内存中(或者为更大的数据帧归档)。这对于SQL用户来说更加自然，因为他们不需要处理Python代码来管理内存中的数据帧。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nx"><img src="../Images/52a5f60ae4bb28270caab311d5778d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cBAdIIb0f74G8hDorKJulg.png"/></div></div><p class="lo lp gj gh gi lq lr bd b be z dk translated">为迭代更改引擎—按作者排序的图片</p></figure><p id="d579" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这张图片中重要的一点是，在Spark上运行全部内容之前，我们可以使用Pandas或DuckDB引擎迭代采样数据。因为有了<code class="fe ms mt mu mv b">YIELD LOCAL DATAFRAME</code>语句，所以<code class="fe ms mt mu mv b">df</code>作为熊猫数据帧保存在内存中。</p><p id="886a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然本文没有涉及，但FugueSQL也能够与Python代码交互。从FugueSQL调用Python函数将在后面的文章中讨论，但是可以在这里找到一个例子<a class="ae lb" href="https://fugue-tutorials.readthedocs.io/tutorials/fugue_sql/extensions.html#transformer" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="486a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结论</h1><p id="fb5e" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><strong class="kh ir">固守传统的SQL使其无法表达端到端的计算工作流，通常需要补充Python代码。</strong>开发人员的迭代时间很慢，因为对大数据的查询需要一段时间，而运行标准SQL需要重新运行所有中间步骤。<strong class="kh ir"> FugueSQL将SQL提升为一级语法，允许用户使用</strong> <code class="fe ms mt mu mv b"><strong class="kh ir">LOAD, SAVE, PERSIST</strong></code> <strong class="kh ir">等关键字调用与分布式系统相关的Python代码。</strong></p><p id="b8ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">FugueSQL通过以下方式加快大数据迭代速度:</p><ul class=""><li id="d3cf" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nb nc nd ne bi translated">允许本地和分布式后端的无缝交换(DuckDB或Pandas到Spark或Dask)。</li><li id="99e9" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">删除标准SQL引入的样板代码。</li><li id="3560" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">添加调用Python代码的关键字，允许SQL作为与Python相对的主要语言。</li></ul><p id="bc1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些增强允许不太熟悉Python的SQL爱好者和数据从业者用他们喜欢的语法定义他们的代码。SQL的优点是易于阅读，而FugueSQL的目标是在保持标准SQL的直观和表达精神的同时扩展这一点。</p><p id="5f01" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ny">编辑:“厂商锁定”改为“框架锁定”，因为Spark是开源的。来自Giles Middleton的反馈。</em></p><h1 id="0325" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">资源</h1><ol class=""><li id="390d" class="mw mx iq kh b ki mk kl ml ko nz ks oa kw ob la nw nc nd ne bi translated"><a class="ae lb" href="http://slack.fugue.ai" rel="noopener ugc nofollow" target="_blank">赋格懈怠——与我们聊天！</a></li><li id="a3ab" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nw nc nd ne bi translated"><a class="ae lb" href="https://github.com/fugue-project/fugue/" rel="noopener ugc nofollow" target="_blank">赋格Github </a></li><li id="e1a4" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nw nc nd ne bi translated"><a class="ae lb" href="https://fugue-tutorials.readthedocs.io/tutorials/quick_look/ten_minutes_sql.html" rel="noopener ugc nofollow" target="_blank">10分钟后FugueSQL</a></li></ol></div></div>    
</body>
</html>