<html>
<head>
<title>Pandas Is Not Enough? A Comprehensive Guide To Alternative Data Wrangling Solutions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">熊猫还不够？替代数据争论解决方案的全面指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pandas-is-not-enough-a-comprehensive-guide-to-alternative-data-wrangling-solutions-a4730ba8d0e4#2022-03-25">https://towardsdatascience.com/pandas-is-not-enough-a-comprehensive-guide-to-alternative-data-wrangling-solutions-a4730ba8d0e4#2022-03-25</a></blockquote><div><div class="fc ij ik il im in"/><div class="io ip iq ir is"><figure class="iu iv gp gr iw ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi it"><img src="../Images/0c61bd9d120209526a9a6382c9cbe7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IZMi5wQt01RY04IffpkxPg.jpeg"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated">照片由<a class="ae ji" href="https://unsplash.com/@cadop?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">马修·施瓦茨</a>在<a class="ae ji" href="https://unsplash.com/s/photos/data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><div class=""/><div class=""><h2 id="3aa0" class="pw-subtitle-paragraph ki jk jl bd b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dk translated">包括达斯克、摩丁、polars、Vaex、Terality 等 6 人</h2></div><p id="dd43" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我认为<code class="fe lw lx ly lz b">pandas</code>不需要介绍。这是数据科学家使用的一个伟大而通用的工具，并且很可能会继续在日常生活中使用。但是在使用<code class="fe lw lx ly lz b">pandas</code>时，我们可能会面临一些潜在的挑战。</p><p id="d6ca" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">最大的问题与数据量有关，这在大数据时代肯定会成为一个问题。虽然有许多任务不涉及如此大量的数据，但我们迟早会遇到这种情况。在这种情况下，我们可以试几招。首先，我们可以尝试优化存储在数据帧中的变量的数据类型，以使数据适合内存。或者，我们可以一次只加载整个数据的一部分。</p><p id="00a0" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这些解决方案通常会有所帮助，但有时它们仅仅是不够的，我们可能会耗尽内存或操作变得慢得令人无法忍受。在这种情况下，我们可能想要远离<code class="fe lw lx ly lz b">pandas</code>，使用更好的工具来完成工作。</p><p id="5498" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">本文的目标不是提供所有可能方法的性能比较。相反，我想介绍一下<code class="fe lw lx ly lz b">pandas</code>的可能替代方案，并简要介绍它们的潜在用例，以及它们的优缺点。然后，您可以选择哪个解决方案符合您的需求，并且可以更深入地了解实现的本质细节。</p><h1 id="7fdf" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">回顾线程与流程</h1><p id="dee1" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">在整篇文章中，我们将提到使用线程或进程运行并行操作。我认为这需要快速复习一下:</p><ul class=""><li id="7c10" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><em class="ng">进程</em>不共享内存，在单个内核上运行。它们更适合于不需要相互通信的计算密集型任务。</li><li id="651c" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><em class="ng">线程</em>共享内存。在 Python 中，由于全局解释器锁(GIL)，两个线程不能在同一程序中同时运行。因此，只有一些操作可以使用线程并行运行。</li></ul><p id="71cb" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">有关线程与进程的更多信息，请参考本文。</p><h1 id="1b04" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">熊猫替代品列表</h1><p id="043f" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">在本节中，我们将介绍最受欢迎的<code class="fe lw lx ly lz b">pandas</code>替代品(截至 2022 年初)。列表的顺序不是从最好到最差的排序，也不是事实上的任何排序。我只是尝试提出这些方法，并在这样做的同时，当各种解决方案之间存在逻辑桥梁时，介绍一些结构。开始吧！</p><h2 id="bf8c" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">Dask — ~10k GitHub stars</h2><p id="cd4f" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">Dask 是一个用于分布式计算的开源库。换句话说，它有助于在一台机器或许多独立的计算机(集群)上同时运行许多计算。对于前者，Dask 允许我们使用线程或进程并行运行计算。</p><figure class="nz oa ob oc gt ix gh gi paragraph-image"><div role="button" tabindex="0" class="iy iz di ja bf jb"><div class="gh gi ny"><img src="../Images/0ff24e8ad059260ce5e086d787275a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ubd0ryXa3Dzqq3lc.gif"/></div></div><p class="je jf gj gh gi jg jh bd b be z dk translated"><a class="ae ji" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="7b19" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">Dask 依靠的是被称为懒惰评估的原理。这意味着直到我们明确地要求(使用<code class="fe lw lx ly lz b">compute</code>函数)操作才会被执行。通过延迟操作，Dask 创建了一个转换/计算队列，以便它们可以在以后并行执行。</p><p id="e98b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">在幕后，Dask 将一个大型数据处理任务分解成许多较小的任务，然后由<code class="fe lw lx ly lz b">numpy</code>或<code class="fe lw lx ly lz b">pandas</code>处理。之后，该库将结果重新组合成一个连贯的整体。</p><p id="b0da" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于 Dask 的一些要点:</p><ul class=""><li id="b4d7" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">将数据处理工作负载从单台机器扩展到分布式集群(可能扩展到具有 1000 个内核的集群)的良好选择。我们可以很容易地使用完全相同的代码在本地机器上用整个数据集的样本来测试运行一些任务。然后，我们可以在完整数据上重复使用完全相同的代码，并在群集上运行它。</li><li id="e053" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">数据不必放入内存，而是需要放在磁盘上。</li><li id="c614" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它建立在现有的众所周知的对象之上，如<code class="fe lw lx ly lz b">numpy</code>数组和<code class="fe lw lx ly lz b">pandas</code>数据帧——没有必要放弃当前的方法并从头重写</li><li id="c59e" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">API 与<code class="fe lw lx ly lz b">pandas</code>非常相似，除了它有懒惰的行为。</li><li id="272c" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Dask 为更多的定制工作负载和与其他项目的集成提供了任务调度接口。此外，它还提供了大量交互式图表和任务分布的可视化，以便进行深入的分析和诊断。</li><li id="2edb" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Dask 不仅仅是数据处理。Dask-ML(一个独立的库)使用<a class="ae ji" href="https://dask.org/" rel="noopener ugc nofollow" target="_blank"> Dask </a>以及流行的机器学习库，如<code class="fe lw lx ly lz b">scikit-learn</code>、<code class="fe lw lx ly lz b">xgboost</code>、<code class="fe lw lx ly lz b">lightgbm</code>等，提供了 Python 中可扩展的机器学习。它有助于缩放数据大小和模型大小。一个例子是，许多<code class="fe lw lx ly lz b">scikit-learn</code>算法是使用<code class="fe lw lx ly lz b">joblib</code>为并行执行而编写的(它支持众所周知的<code class="fe lw lx ly lz b">n_jobs</code>参数)。Dask 通过提供另一个<code class="fe lw lx ly lz b">joblib</code>后端将这些算法扩展到一个机器集群。</li></ul><p id="faee" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="5270" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/dask/dask" rel="noopener ugc nofollow" target="_blank">https://github.com/dask/dask</a></li><li id="3a07" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">【https://dask.org/】</li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="a37d" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">摩丁——约 7k GitHub 星</h2><p id="4f93" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">Modin 是一个库，旨在通过在系统的所有可用 CPU 内核之间自动分配计算来并行化<code class="fe lw lx ly lz b">pandas</code>数据帧。由于这一点，摩丁声称能够获得接近线性的速度提升到你的系统上的 CPU 核心的数量。</p><p id="8242" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">那么这是怎么发生的呢？Modin 只是将现有的数据帧分成不同的部分，这样每个部分都可以发送到不同的 CPU 内核。更准确地说，Modin 将数据帧划分为行和列，这使得它的并行处理对于任何大小和形状的数据帧都是高度可扩展的。</p><p id="a2cf" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">该库的作者专注于将数据科学家的时间优先于硬件时间。这就是为什么摩丁:</p><ul class=""><li id="cc39" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">具有与<code class="fe lw lx ly lz b">pandas</code>相同的 API，因此不会增加数据科学家的学习成本。与大多数其他库不同，它的目标是全面覆盖<code class="fe lw lx ly lz b">pandas</code> API。在撰写本文时，它提供了<code class="fe lw lx ly lz b">pd.DataFrame</code>90%的&gt;功能和<code class="fe lw lx ly lz b">pd.Series</code>88%的&gt;功能。如果某个功能/方法没有实现，Modin 默认为<code class="fe lw lx ly lz b">pandas</code>，所以最终所有命令都被执行。</li><li id="7639" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">运行非常简单，可作为<code class="fe lw lx ly lz b">pandas</code>的替代产品。其实我们只需要把一个导入行改成<code class="fe lw lx ly lz b">import modin.pandas as pd</code>。</li><li id="5f68" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">提供与 Python 生态系统的流畅集成。</li><li id="737a" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">不仅可以在本地机器上运行，还可以在 Ray/Dask 集群上运行。我们之前已经介绍过 Dask，所以提到 Ray 是有意义的。Ray 是一个高性能的分布式执行框架。完全相同的代码可以运行在一台机器上(高效的多处理)和一个专用集群上进行大规模计算。</li><li id="7703" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">支持核外模式，在这种模式下，Modin 使用磁盘作为内存的溢出存储。这样，我们可以处理比内存大得多的数据集。</li></ul><p id="0d2b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">那么摩丁和达斯克有什么不同呢？有一些差异值得一提:</p><ul class=""><li id="8214" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">与 Dask 相反，Modin 提供了完全的兼容性。为了可伸缩性，Dask 数据帧提供基于行的存储。这就是为什么他们不能完全支持所有的<code class="fe lw lx ly lz b">pandas</code>功能。相比之下，Modin 被设计成一个灵活的列存储。</li><li id="cfdf" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Dask 数据帧需要使用<code class="fe lw lx ly lz b">compute</code>方法显式计算(因为它们处于惰性模式)。在 Modin 中，对用户查询的所有优化都是在幕后执行的，不需要用户的任何输入。</li><li id="76d9" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">必须明确说明 Dask 中的分区数量。</li><li id="7fff" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Modin 可以在 Dask 上运行，但它最初是为了与 Ray 一起工作而构建的。</li></ul><p id="f289" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">有关这些差异的更多信息，请参见下面的链接。</p><p id="3b7e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用的参考资料:</strong></p><ul class=""><li id="f5f0" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/modin-project/modin" rel="noopener ugc nofollow" target="_blank">https://github.com/modin-project/modin</a></li><li id="6d03" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">使用 Modin 透明地扩展交互式数据科学:<a class="ae ji" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-191.pdf" rel="noopener ugc nofollow" target="_blank">https://www2 . eecs . Berkeley . edu/Pubs/techr pts/2018/EECS-2018-191 . pdf</a></li><li id="f680" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://rise.cs.berkeley.edu/blog/pandas-on-ray-early-lessons/" rel="noopener ugc nofollow" target="_blank">https://rise . cs . Berkeley . edu/blog/pandas-on-ray-early-lessons/</a></li><li id="49a9" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">描述 Dask 和 Modin 区别的帖子:<a class="ae ji" href="https://github.com/modin-project/modin/issues/515#issuecomment-477722019" rel="noopener ugc nofollow" target="_blank">https://github . com/Modin-project/Modin/issues/515 # issue comment-477722019</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="038d" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">更快—约 2k 颗 GitHub 星</h2><p id="0d64" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated"><code class="fe lw lx ly lz b">swifter</code>是一个开源库，它试图以最快的方式将任何函数有效地应用到<code class="fe lw lx ly lz b">pandas</code>数据帧或系列中。<code class="fe lw lx ly lz b">apply</code>是一个非常有用的函数，因为它允许我们轻松地将任何函数应用于<code class="fe lw lx ly lz b">pandas</code>对象。然而，这是有代价的——该函数充当 for 循环，导致速度很慢。</p><p id="d1e4" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">除了首先对函数进行矢量化之外，本文中已经提到了相当多的并行替代方法。那么<code class="fe lw lx ly lz b">swifter</code>在这一切中扮演什么角色呢？</p><p id="efab" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">我们已经提到，它试图以最快的方式应用该功能。首先，如果可能的话，<code class="fe lw lx ly lz b">swifter</code>对函数进行矢量化。如果这是不可能的，它估计什么更快:使用 Dask/Modin 或简单的<code class="fe lw lx ly lz b">pandas</code>应用并行处理。</p><p id="7158" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><code class="fe lw lx ly lz b">swifter</code>的主要特点:</p><ul class=""><li id="fb7e" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">低学习曲线——这是在<code class="fe lw lx ly lz b">apply</code>方法链中添加<code class="fe lw lx ly lz b">swifter</code>的问题。例如:</li></ul><pre class="nz oa ob oc gt ok lz ol om aw on bi"><span id="01a7" class="nm mb jl lz b gy oo op l oq or">df["col_out"] = df["col_in"].swifter.apply(some_function)</span></pre><ul class=""><li id="1499" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">截至目前，<code class="fe lw lx ly lz b">swifter</code>支持以下加速方式:<code class="fe lw lx ly lz b">apply</code>、<code class="fe lw lx ly lz b">applymap</code>、<code class="fe lw lx ly lz b">rolling().apply()</code>和<code class="fe lw lx ly lz b">resample().apply()</code></li><li id="f802" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它受益于 Dask/Modin 等库的潜力</li><li id="9f1f" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">我们不应该盲目地把任何功能扔在<code class="fe lw lx ly lz b">swifter</code>上，抱最好的希望。这就是为什么当我们写 UDF 时，我们应该考虑到函数的矢量化。一个例子是使用<code class="fe lw lx ly lz b">np.where</code>代替 if-else 条件流。</li></ul><p id="5a26" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="d579" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/jmcarpenter2/swifter" rel="noopener ugc nofollow" target="_blank">https://github.com/jmcarpenter2/swifter</a></li><li id="73e2" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://medium.com/@jmcarpenter2/swifter-1-0-0-automatically-efficient-pandas-and-modin-dataframe-applies-cfbd9555e7c8" rel="noopener">https://medium . com/@ jmcarpenter 2/swifter-1-0-0-自动-高效-pandas-and-modin-data frame-applies-cfbd 9555 e7c 8</a></li><li id="a1cc" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/jmcarpenter2/swifter/blob/master/examples/swifter_apply_examples.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/jmcarpenter 2/swifter/blob/master/examples/swifter _ apply _ examples . ipynb</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="1a77" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">vaex — 7k GitHub stars</h2><p id="422a" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">Vaex 是另一个开源的数据帧库，专门研究懒惰的核外数据帧。</p><p id="08de" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">该库最大的亮点可能是 Vaex 只需要很少的 RAM 来检查和与任意大小的数据集交互。这是可能的，因为结合了惰性评估和内存映射。后者是一种技术，你告诉操作系统你想要一块内存与磁盘上的内容同步。当一段时间内没有修改或使用某块内存时，它将被丢弃，以便可以重用 RAM。</p><p id="a046" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">实际上，当我们用 Vaex 打开一个文件时，实际上并没有读取任何数据。相反，Vaex 只读取文件的元数据:数据在磁盘上的位置、数据的结构(行数/列数、列名和类型)、文件描述等。</p><p id="79d4" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这就是为什么受益于 Vaex 的要求之一是以内存可映射文件格式存储数据，例如 Apache Arrow、Apache Parquet 或 HDF5。如果我们满足这个要求，Vaex 将立即打开这样一个文件，不管它有多大，也不管我们有多少 RAM。</p><p id="d744" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">Vaex 的主要特点:</p><ul class=""><li id="e04c" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">类似于<code class="fe lw lx ly lz b">pandas</code>的 API。</li><li id="f4a7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">易于处理非常大的数据集—通过结合内存映射和惰性评估，Vaex 只受我们可用硬盘空间的限制。</li><li id="984b" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Dask 等库侧重于让我们将代码从本地机器扩展到集群，而 Vaex 侧重于使在单台机器上处理大型数据集变得更容易。</li><li id="77da" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 不会创建内存副本，因为过滤后的数据帧只是原始数据的浅层副本。这意味着过滤只需要很少的内存。假设我们有一个 50GB 的文件。许多工具需要 50GB 来读取文件，过滤后的数据帧也需要大约 50GB。</li><li id="610f" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">虚拟列是在我们转换 Vaex 数据帧的现有列时创建的。它们的行为就像普通的一样，主要区别是它们根本不使用内存。这是因为 Vaex 只记住它们的定义，并不实际计算这些值。虚拟列仅在必要时才进行延迟评估。</li><li id="8b1d" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 非常快，因为虚拟列的计算是完全并行的，并且使用一些流行的列方法(<code class="fe lw lx ly lz b">value_counts</code>、<code class="fe lw lx ly lz b">groupby</code>等)的 C++实现。).此外，所有这些都在核外工作，这意味着我们可以在使用所有可用内核的同时，处理比 RAM 中所能容纳的更多的数据。</li><li id="aad3" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">速度还来自于智能优化，它允许我们只通过一次数据就可以为多个选择计算一些统计数据(无需每次创建新的参考数据帧)。更好的是，我们可以将这些与<code class="fe lw lx ly lz b">groupby</code>聚合结合起来，同时仍然只传递一次数据。</li><li id="e6e0" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 可以通过 Numba、Pythran 或 CUDA(需要支持 CUDA 的 NVIDIA 显卡)使用即时编译来进一步加速函数的评估。</li><li id="027e" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 坚持只在必要时检查整个数据集的策略，然后尽可能少地检查数据。例如，当显示 Vaex 数据帧或列时，Vaex 仅从磁盘中读取前 5 行和后 5 行。</li><li id="6b0b" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 还提供了非常快速且节省内存的字符串操作(几乎支持所有的<code class="fe lw lx ly lz b">pandas</code>操作)。</li><li id="5a57" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">还有一个<code class="fe lw lx ly lz b">vaex.ml</code>库，它实现了一些常见的数据转换，例如 PCA、分类编码器和数字定标器。它们具有熟悉的 API、并行化和核外执行的优势。该库还提供了几个流行的机器学习库的接口，如<code class="fe lw lx ly lz b">scikit-learn</code>或<code class="fe lw lx ly lz b">xgboost</code>。通过使用它，我们在处理数据争论部分(清理、特征工程和预处理)时不会浪费任何内存。这使我们能够最大限度地利用可用内存来训练模型。</li></ul><p id="63d7" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">这是相当多的信息。我们还将简要介绍 Vaex 和前面提到的方法之间的一些差异。</p><ul class=""><li id="7827" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">虽然 Dask 与<code class="fe lw lx ly lz b">pandas</code>并不完全兼容，但摩丁的目标是兼容，因此，这些库带有一些<code class="fe lw lx ly lz b">pandas</code>固有的包袱。通过更多地偏离源(但仍然非常相似)，Vaex 在功能方面受到的限制更少(内存映射的查询方式等)。)</li><li id="4933" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Dask 和 Modin 扩展到集群，而 Vaex 试图通过内存映射文件和使用本地机器的所有可用核心来帮助用户避免对集群的需求。</li><li id="c1cf" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Vaex 的作者将 Vaex 和 Dask 之间的关系描述为正交。Dask(和 Modin)主要关注数据处理和争论，而 Vaex 也提供了在 N 维网格上快速计算统计数据的能力，并具有一些易于可视化和绘制大型数据集的功能。</li></ul><p id="c1eb" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于 Vaex 和 Dask 更深入的对比，请看<a class="ae ji" rel="noopener" target="_blank" href="/dask-vs-vaex-a-qualitative-comparison-32e700e5f08b">这篇文章</a>。</p><p id="142a" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="9c44" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/vaexio/vaex" rel="noopener ugc nofollow" target="_blank">https://github.com/vaexio/vaex</a></li><li id="8b31" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://vaex.io/" rel="noopener ugc nofollow" target="_blank">https://vaex.io/</a></li><li id="1386" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" rel="noopener" target="_blank" href="/dask-vs-vaex-a-qualitative-comparison-32e700e5f08b">https://towards data science . com/dask-vs-vaex-a-qualitative-comparison-32e 700 e 5 f 08 b</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="3e81" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">数据表— 1.5k GitHub stars</h2><p id="b47d" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated"><code class="fe lw lx ly lz b">datatable</code>是一个用于操作二维表格数据的 Python 库。它是由<a class="ae ji" href="https://www.h2o.ai/" rel="noopener ugc nofollow" target="_blank"> H2O.ai </a>开发的，它的第一个用户是<a class="ae ji" href="https://www.h2o.ai/driverless-ai/" rel="noopener ugc nofollow" target="_blank">无人驾驶. ai </a>。在许多方面，它类似于<code class="fe lw lx ly lz b">pandas</code>，特别强调速度和单节点机器上的大数据(高达 100GB)支持。</p><p id="05e4" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">如果您使用过 R，您可能已经熟悉了相关的包<code class="fe lw lx ly lz b">data.table</code>，这是 R 用户在快速聚合大数据时的首选包。Python 的实现试图模仿其核心算法和 API。</p><p id="c64b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">说到 API，其实就是<code class="fe lw lx ly lz b">datatable</code>和<code class="fe lw lx ly lz b">pandas</code>(以及 R 的<code class="fe lw lx ly lz b">data.frame</code>)的“爱它还是恨它”的区别。在<code class="fe lw lx ly lz b">datatable</code>中，执行所有操作的主要方式是方括号符号，这是受传统矩阵索引的启发。一个例子是:</p><p id="f9a6" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><code class="fe lw lx ly lz b">DT[i, j, ...]</code></p><p id="48d2" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">其中<code class="fe lw lx ly lz b">i</code>是行选择器，<code class="fe lw lx ly lz b">j</code>是列选择器，<code class="fe lw lx ly lz b">...</code>表示可能添加的附加修饰符。虽然这已经很熟悉了，因为它与在 R/ <code class="fe lw lx ly lz b">pandas</code> / <code class="fe lw lx ly lz b">numpy</code>中索引矩阵或对象时遇到的符号完全相同，但还是有一些不同。</p><p id="3359" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">其中之一是<code class="fe lw lx ly lz b">i</code>可以是任何可以被解释为行选择器的东西:一个整数、一个切片、一个范围、一个整数列表、一个切片列表、一个表达式、一个布尔值/整数值框架、一个生成器等等。但这仍然是熟悉的，不应该是一个大问题。</p><p id="18f9" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">当我们想要执行更高级的操作时，棘手的部分就来了，因为<code class="fe lw lx ly lz b">datatable</code>的语法与我们大多数人习惯的语法相差甚远。例如:</p><pre class="nz oa ob oc gt ok lz ol om aw on bi"><span id="dd6f" class="nm mb jl lz b gy oo op l oq or">DT[:, sum(f.quantity), by(f.product_id)]</span></pre><p id="65df" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">该代码片段计算产品数量的总和。而不熟悉的<code class="fe lw lx ly lz b">f</code>是必须从<code class="fe lw lx ly lz b">datatable</code>模块导入的特殊变量。它提供了引用给定框架中任何列的快捷方式。</p><p id="9ebb" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于<code class="fe lw lx ly lz b">datatable</code>的要点:</p><ul class=""><li id="8ca1" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">datatable</code>中的数据帧被称为帧，和<code class="fe lw lx ly lz b">pandas</code>中的数据帧一样，它们是柱状数据结构。</li><li id="4de2" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">与<code class="fe lw lx ly lz b">pandas</code>相反，该库为所有数据类型提供了 native-C 实现，包括字符串。<code class="fe lw lx ly lz b">pandas</code>仅对数值类型有效。</li><li id="5bf7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它提供了从 CSV 和其他文件格式快速读取数据。</li><li id="0683" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">使用<code class="fe lw lx ly lz b">datatable</code>时，我们应该将数据以与内存相同的格式存储在磁盘上。得益于此，我们可以使用磁盘上数据的内存映射，并处理内存不足的数据集。这样，我们就避免了为每个特定的操作加载过多的数据到内存中。</li><li id="4833" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">datatable</code>使用多线程数据处理来实现最高效率。</li><li id="8185" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">该库最大限度地减少了数据复制量。</li><li id="7d3e" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">很容易将<code class="fe lw lx ly lz b">datatable</code>的帧转换成<code class="fe lw lx ly lz b">pandas</code> / <code class="fe lw lx ly lz b">numpy</code>的对象。</li></ul><p id="11ea" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="05dc" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/h2oai/datatable" rel="noopener ugc nofollow" target="_blank">https://github.com/h2oai/datatable</a></li><li id="b4ff" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://datatable.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://datatable.readthedocs.io/en/latest/</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="1e32" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">cuDF —约 4.5k GitHub stars</h2><p id="5462" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated"><code class="fe lw lx ly lz b"><a class="ae ji" href="https://github.com/rapidsai/cudf" rel="noopener ugc nofollow" target="_blank">cuDF</a></code>是一个 GPU 数据框架库，是 NVIDIA 的 RAPIDS 的一部分，这是一个跨多个开源库并利用 GPU 功能的数据科学生态系统。cuDF 提供了一个类似于 pandas 的 API，允许我们从性能提升中获益，而无需深入 CUDA 编程的细节。</p><p id="25fc" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于<code class="fe lw lx ly lz b">cuDF</code>的要点:</p><ul class=""><li id="72fd" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">pandas</code>-像 API 一样——在很多情况下，我们只需要修改一行代码就可以开始受益于 GPU 的强大功能。</li><li id="1ef7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">使用 Apache Arrow 列内存格式构建。</li><li id="2a50" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">cuDF</code>是单 GPU 库。然而，它可以利用多 GPU 设置结合 Dask 和专用的<code class="fe lw lx ly lz b">dask-cudf</code>库。有了它，我们能够在一台机器上的多个 GPU 之间扩展<code class="fe lw lx ly lz b">cuDF</code>，或者在一个集群中的许多机器之间扩展多个 GPU。</li><li id="abdf" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">使用<code class="fe lw lx ly lz b">cuDF</code>需要一个兼容的 NVIDIA GPU 和一些额外的设置(更新驱动程序，安装 CUDA 等)。)</li><li id="7174" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">我们应该记住，只要数据合理地适合 GPU 内存，就可以获得最佳性能。</li></ul><p id="9ffc" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="01d6" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/rapidsai/cudf" rel="noopener ugc nofollow" target="_blank">https://github.com/rapidsai/cudf</a></li><li id="040e" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">【https://docs.rapids.ai/api/cudf/stable/】</li><li id="fe27" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://docs.rapids.ai/api/cudf/stable/user_guide/10min-cudf-cupy.html" rel="noopener ugc nofollow" target="_blank">https://docs . rapids . ai/API/cudf/stable/user _ guide/10min-cudf-cupy . html</a></li><li id="9110" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://docs.rapids.ai/api/cudf/stable/user_guide/10min.html" rel="noopener ugc nofollow" target="_blank">https://docs . rapids . ai/API/cudf/stable/user _ guide/10min . html</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="9a9e" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">pyspark</h2><p id="adee" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">与之前的库相比，我们实际上首先需要后退一步，描述 Spark 是什么。</p><p id="2c12" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">Apache Spark 是一个用于大规模数据处理的统一分析引擎，用 Scala 编写。它基本上是为数据科学处理大型数据集(比如 100GB 以上)的<em class="ng">和</em>库。其受欢迎有多种原因，包括以下原因:</p><ul class=""><li id="1378" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">它比 Hadoop 快 100 倍，</li><li id="338c" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它实现了静态、批处理和流式数据的高性能，</li><li id="d7af" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它使用最先进的 DAG ( <a class="ae ji" href="https://en.wikipedia.org/wiki/Directed_acyclic_graph" rel="noopener ugc nofollow" target="_blank">有向无环图</a>)调度器、查询优化器和物理执行引擎。</li></ul><p id="6480" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">Spark 采用主从架构工作，其中主设备实际上被称为“驱动器”，从设备被称为“工人”。运行 Spark 应用程序时，Spark driver 会创建一个上下文，作为应用程序的入口点。然后，所有操作都在工作节点上执行，而资源由集群管理器管理。</p><p id="040d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">Spark 自带数据帧风格。虽然它们具有类似于<code class="fe lw lx ly lz b">pandas</code>数据帧的功能，但主要区别在于它们是分布式的，它们具有惰性评估并且是不可变的(不允许覆盖数据)。</p><p id="500b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">对 Spark 的介绍已经足够了，让我们把重点放在与本文最相关的部分，即缩放数据帧。为此，我们可以使用 PySpark，这是一个用于 Spark 的 Python API。</p><p id="6625" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于 PySpark 需要了解的关键事项:</p><ul class=""><li id="3533" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">PySpark 是一个通用的、内存中的分布式处理引擎，用于以分布式方式进行高效的数据处理。</li><li id="1284" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">速度大幅提升——在 PySpark 上运行计算比使用传统系统快 100 倍。</li><li id="eafe" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它有一个不同于<code class="fe lw lx ly lz b">pandas</code>的 API，并且它不能很好地与其他库集成(例如用于绘图的<code class="fe lw lx ly lz b">matplotlib</code>等)。).一般来说，它的学习曲线比<code class="fe lw lx ly lz b">pandas</code>更陡。</li><li id="7c6b" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">当使用<em class="ng">宽转换</em>(查看所有节点的全部数据，例如，排序或使用<code class="fe lw lx ly lz b">groupby</code>)时，我们应该小心，因为它们比<em class="ng">窄转换</em>(查看每个节点中的单个数据)计算量更大。</li><li id="85f3" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">要使用 PySpark，我们需要克服一些开销——设置一个 Spark(本地或集群),在我们的计算机上有一个 JVM (Java 虚拟机),等等。当我们的组织中还没有运行时，这可能是一个阻碍，并且对于一些较小的实验来说，设置它将是一个大材小用。或者，我们可以使用托管云解决方案，如<a class="ae ji" href="https://databricks.com/" rel="noopener ugc nofollow" target="_blank"> Databricks </a>。</li><li id="4ceb" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">使用 PySpark，我们可以轻松处理来自 Hadoop HDFS、AWS S3 和许多其他文件系统的数据。这也包括使用流媒体和 Kafka 处理实时数据。</li><li id="47df" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">是 PySpark 的包装器，基本上是 Spark 的机器学习库。由<code class="fe lw lx ly lz b">MLlib</code>库提供的 API 非常容易使用，并且支持许多分类、回归、聚类、维度减少等算法。</li><li id="5de2" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Spark 允许我们用 SQL <strong class="lc jm"> </strong>和<strong class="lc jm"> </strong> Python 查询数据帧。这很方便，因为有时用 SQL 编写一些逻辑比记住确切的 PySpark API 更容易。因为工作可以互换，你可以使用任何你喜欢的。</li><li id="a2a0" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">由于 Spark 运行在几乎无限的计算机集群上，它可以处理的数据集大小实际上没有限制。</li></ul><p id="af84" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="ebe9" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://www.youtube.com/watch?v=XrpSRCwISdk" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=XrpSRCwISdk</a></li><li id="70c7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" rel="noopener" target="_blank" href="/the-most-complete-guide-to-pyspark-dataframes-2702c343b2e8">https://towards data science . com/the-most-complete-guide-to-py spark-data frames-2702 c 343 B2 E8</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="e098" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">考拉——约 3k GitHub 星</h2><p id="499a" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">我们提到过 PySpark 最大的痛点是语法，它不同于<code class="fe lw lx ly lz b">pandas</code>，并且有一个相当陡峭的学习曲线。这正是 Databricks 想用考拉解决的问题。该库的目标是通过在 Spark 上实现<code class="fe lw lx ly lz b">pandas</code> API，让数据科学家在与大数据交互时更有效率。</p><p id="7b30" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于考拉要知道的一些事情:</p><ul class=""><li id="80dc" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">你可以拥有一个既能与<code class="fe lw lx ly lz b">pandas</code>(较小的数据集)又能与 Spark(分布式数据集)一起工作的单一代码库。你只需要把导入语句从<code class="fe lw lx ly lz b">pandas</code>替换到<code class="fe lw lx ly lz b">koalas</code>。</li><li id="dea3" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">考拉支持 Spark ≤ 3.1，在 Spark 3.2 中正式被 PySpark 收录为<code class="fe lw lx ly lz b">pyspark.pandas</code></li><li id="483c" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">空值的处理方式可能稍有不同。<code class="fe lw lx ly lz b">pandas</code>使用 NaNs(特殊常量)来表示缺失值，而 Spark 在每个值上都有一个特殊的标志来表示是否有值缺失。</li><li id="a929" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">惰性求值——由于 Spark 本质上是惰性的，一些操作(例如创建新列)只有在 Spark 需要打印或写入数据帧时才会执行。</li><li id="fbc7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">很容易将考拉数据帧转换成<code class="fe lw lx ly lz b">pandas</code> /PySpark 数据帧。</li><li id="06c7" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">考拉还支持带有<code class="fe lw lx ly lz b">ks.sql()</code>的标准 SQL 语法，允许执行 Spark SQL 查询，并以数据帧的形式返回结果。</li><li id="4bfc" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">考拉和 PySpark 的性能结果非常相似，因为它们都在幕后使用 Spark。但是，与纯 PySpark 相比，性能会略有下降。大多数情况下，它与构建默认索引的开销有关，或者与一些<code class="fe lw lx ly lz b">pandas</code>和 PySpark APIs 共享相同的名称，但具有不同的语义(例如，<code class="fe lw lx ly lz b">count</code>方法)的事实有关。</li><li id="795c" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">树袋熊数据帧与 PySpark 数据帧在外观上略有不同。为了实现需要隐式排序的<code class="fe lw lx ly lz b">pandas</code>数据帧结构及其丰富的 API，考拉数据帧具有表示类似<code class="fe lw lx ly lz b">pandas</code>的索引的内部元数据和映射到 PySpark 数据帧列的列标签。另一方面，PySpark 对应物往往更符合关系数据库中的关系/表。因此，它们没有唯一的行标识符。</li><li id="9ba1" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">在内部，考拉数据帧建立在 PySpark 数据帧之上。考拉将<code class="fe lw lx ly lz b">pandas</code>API 翻译成 Spark SQL 的逻辑计划。然后 Spark SQL 引擎优化并执行该计划。</li></ul><p id="f1d2" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用的参考资料:</strong></p><ul class=""><li id="c4d2" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/databricks/koalas" rel="noopener ugc nofollow" target="_blank">https://github.com/databricks/koalas</a></li><li id="6b85" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://koalas.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://koalas.readthedocs.io/en/latest/</a></li><li id="91eb" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://koalas.readthedocs.io/en/latest/getting_started/10min.html" rel="noopener ugc nofollow" target="_blank">https://koalas . readthe docs . io/en/latest/getting _ started/10min . html</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="408d" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">极地星——约 5k GitHub 星</h2><p id="22cc" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated"><code class="fe lw lx ly lz b">polars</code>是一个强调速度的开源数据框架库。为了实现这一点，它在 Rust 中以 Apache Arrow 作为内存模型来实现。直到最近，作为<code class="fe lw lx ly lz b">polars</code>的 Python 包装器的库被称为<code class="fe lw lx ly lz b">pypolars</code>，然而，为了简单起见，现在它也被称为<code class="fe lw lx ly lz b">polars</code>。</p><p id="c533" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><code class="fe lw lx ly lz b">polars</code>的一些关键特性:</p><ul class=""><li id="7e86" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">API 类似于<code class="fe lw lx ly lz b">pandas</code>，然而，它实际上更接近 R 的<code class="fe lw lx ly lz b">dplyr</code>。</li><li id="07f2" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">有两个 API——渴望和懒惰。前者与<code class="fe lw lx ly lz b">pandas</code>非常相似，因为结果是在执行完成后立即产生的。另一方面，lazy API 更类似于 Spark，在 Spark 中，计划是在执行查询时形成的。但是当我们调用<code class="fe lw lx ly lz b">collect</code>方法时，该计划直到在 CPU 的所有核心上并行执行时才真正看到数据。</li><li id="e9c8" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">绘图很容易生成并与最流行的可视化工具集成。</li><li id="d165" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">polars</code>是目前最快的(如果不是最快的)数据帧库之一(根据这个<a class="ae ji" href="https://h2oai.github.io/db-benchmark/" rel="noopener ugc nofollow" target="_blank">基准</a>)，并且支持对于<code class="fe lw lx ly lz b">pandas</code>来说可能太大的数据帧。</li><li id="2937" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">polars</code>的速度来自于利用你机器所有可用的内核。它与其他解决方案的区别在于，<code class="fe lw lx ly lz b">polars</code>是从底层开始编写的，并考虑到了数据帧查询的并行化，而 Dask 等工具则并行化了现有的单线程库(如<code class="fe lw lx ly lz b">numpy</code>和<code class="fe lw lx ly lz b">pandas</code>)。</li></ul><p id="467b" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="f9b2" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://github.com/pola-rs/polars" rel="noopener ugc nofollow" target="_blank">https://github.com/pola-rs/polars</a></li><li id="e453" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://pola-rs.github.io/polars-book/user-guide/introduction.html" rel="noopener ugc nofollow" target="_blank">https://pola-RS . github . io/polars-book/user-guide/introduction . html</a></li><li id="7660" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://www.ritchievink.com/blog/2021/02/28/i-wrote-one-of-the-fastest-dataframe-libraries/" rel="noopener ugc nofollow" target="_blank">https://www . ritchievink . com/blog/2021/02/28/I-written-one-of-the-fast-data frame-libraries/</a></li></ul></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="0f12" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">潘达平行星——约 2k 颗 GitHub 星</h2><p id="2a4c" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated"><code class="fe lw lx ly lz b">pandarallel</code>(承认吧，这个听起来有点像神奇宝贝)是一个开源库，可以在所有可用的 CPU 上并行化<code class="fe lw lx ly lz b">pandas</code>操作。</p><p id="db16" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">当我们使用<code class="fe lw lx ly lz b">pandarallel</code>调用并行化函数时，下面的步骤会在幕后发生:</p><ul class=""><li id="1c14" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">该库初始化 PyArrow 等离子体共享存储器，</li><li id="7280" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它为每个 CPU 创建一个子进程，然后要求它们处理原始数据帧的一部分，</li><li id="26ee" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它合并了父流程中的所有结果。</li></ul><p id="379e" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于<code class="fe lw lx ly lz b">pandarallel</code>的一些要点:</p><ul class=""><li id="be03" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated">该库允许您并行化下面的<code class="fe lw lx ly lz b">pandas</code>方法:<code class="fe lw lx ly lz b">apply</code>、<code class="fe lw lx ly lz b">applymap</code>、<code class="fe lw lx ly lz b">groupby</code>、<code class="fe lw lx ly lz b">map</code>和<code class="fe lw lx ly lz b">rolling</code>。</li><li id="7ed1" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">如果您的 CPU 使用超线程(例如，8 个核心和 16 个线程)，则只会使用 8 个核心。</li><li id="258d" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">pandarallel</code>需要两倍于标准<code class="fe lw lx ly lz b">pandas</code>操作使用的内存。不言而喻，如果数据最初不适合使用<code class="fe lw lx ly lz b">pandas</code>的内存，则不应使用该库。</li></ul><p id="b0ec" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><p id="9414" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><a class="ae ji" href="https://github.com/nalepae/pandarallel" rel="noopener ugc nofollow" target="_blank">https://github.com/nalepae/pandarallel</a></p></div><div class="ab cl od oe hz of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="io ip iq ir is"><h2 id="36eb" class="nm mb jl bd mc nn no dn mg np nq dp mk lj nr ns mm ln nt nu mo lr nv nw mq nx bi translated">Terality</h2><p id="5d04" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">在谈到<code class="fe lw lx ly lz b">pandas</code>替代品时，Terality 是一个新手。它是一个无服务器的数据处理引擎，使<code class="fe lw lx ly lz b">pandas</code>像 Apache Spark 一样可扩展和快速(比<code class="fe lw lx ly lz b">pandas</code>快 100 倍，能够处理 100 多 GB 的数据)，既没有基础设施要求，也不涉及任何代码更改。听起来已经很棒了！有什么条件？</p><p id="cb22" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">与其他库/方法的最大区别是 Terality 不是开源软件。有不同类型的订阅(包括一个免费的游戏！)但总的来说，你是按处理的数据量收费的。有关定价的更多信息，请参见<a class="ae ji" href="https://www.terality.com/pricing" rel="noopener ugc nofollow" target="_blank">本页</a>。</p><p id="0daf" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">关于 Terality 需要知道的一些事情:</p><ul class=""><li id="e6ab" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><code class="fe lw lx ly lz b">pandas</code> API 的 100%覆盖率。</li><li id="4c1a" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Terality 在现有的<code class="fe lw lx ly lz b">pandas</code>功能的基础上提供了两个新方法:<code class="fe lw lx ly lz b">to_csv_folder</code>和<code class="fe lw lx ly lz b">to_parquet_folder</code>。它们允许我们轻松地将原始数据集分割成多个更小的数据集。当将数据分割成块，然后分别分析每个块时，这个特性特别有用。</li><li id="bd55" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">由于该项目不是开源的，我们不能对其快速性能背后的底层架构说太多。我们所知道的是，Terality 团队开发了一个专有的数据处理引擎，因此它不是 Spark 或 Dask 的分支/风格。</li><li id="b042" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">由于是托管的，所以不需要管理基础设施，内存实际上是无限的。</li><li id="22ba" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">它消除了<code class="fe lw lx ly lz b">pandas</code>的可扩展性问题，Spark 的复杂性(设置+不同的语法)，以及 Dask/Modin 的局限性。</li><li id="f899" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">截至 2022 年 2 月，您可以将 Terality 与 Google Colab 结合使用。</li><li id="fc7d" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Terality 是可自动扩展的——无论数据大小如何，我们的操作都会以极高的速度自动处理。不需要手动调整处理能力来匹配数据集的大小。所有的基础设施都是在 Terality 这边管理的，包括在你完成你的处理后关闭东西。</li><li id="4160" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">Terality 与针对您的数据的云存储解决方案(亚马逊 S3、Azure Data Lake 等)结合使用时效果最佳。).这是因为另一种选择是加载一个本地文件，这可能需要相当长的时间(取决于你的网速)。</li><li id="d4e1" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">自然，在使用具有潜在敏感数据的第三方解决方案时，会有约束/限制，尤其是在涉及公司数据时。就安全性而言，Terality 提供了安全隔离，我们的数据在传输和计算过程中都得到了充分保护。更多安全信息请参考<a class="ae ji" href="https://www.terality.com/security" rel="noopener ugc nofollow" target="_blank">本网站</a>。</li><li id="b835" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated">不久前，Terality 可以部署在您自己的 AWS 帐户中。由于这种自托管部署，您的数据永远不会离开您的 AWS 帐户。这种功能可以帮助您遵守数据保护要求，并消除对数据安全性的任何疑虑。</li></ul><p id="928d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated"><strong class="lc jm">有用参考:</strong></p><ul class=""><li id="1d06" class="mx my jl lc b ld le lg lh lj mz ln na lr nb lv nc nd ne nf bi translated"><a class="ae ji" href="https://www.terality.com/" rel="noopener ugc nofollow" target="_blank">https://www.terality.com/</a></li><li id="186d" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://docs.terality.com/" rel="noopener ugc nofollow" target="_blank">https://docs.terality.com/</a></li><li id="3ce3" class="mx my jl lc b ld nh lg ni lj nj ln nk lr nl lv nc nd ne nf bi translated"><a class="ae ji" href="https://www.terality.com/post/terality-beats-spark-and-dask-h2o-benchmark" rel="noopener ugc nofollow" target="_blank">https://www . terality . com/post/terality-beats-spark-and-dask-H2O-benchmark</a></li></ul><h1 id="6764" class="ma mb jl bd mc md me mf mg mh mi mj mk kr ml ks mm ku mn kv mo kx mp ky mq mr bi translated">结论</h1><p id="debc" class="pw-post-body-paragraph la lb jl lc b ld ms km lf lg mt kp li lj mu ll lm ln mv lp lq lr mw lt lu lv io bi translated">不要误解我，<code class="fe lw lx ly lz b">pandas</code>是一个很棒的工具，我每天都在使用并将继续使用。然而，对于某些特定的用例来说，这可能是不够的。这就是为什么在这篇文章中，我提供了最流行的<code class="fe lw lx ly lz b">pandas</code>选择的概述。</p><p id="f96d" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">让我先回答一个你可能会想到的问题:哪个解决方案是最好的？你可能已经猜到了，答案是:视情况而定。如果你想简单地在本地机器上加速你的<code class="fe lw lx ly lz b">pandas</code>代码，也许 Modin 是一个很好的起点。如果已经有 Spark 集群在运行，可以试试 py Spark/考拉。对于计算一些统计数据或可视化大规模数据集，Vaex 可能是一个很好的起点。或者，如果您想使用最大速度，而不必担心设置任何基础设施，那么 Terality 可能是一个不错的选择。</p><p id="5bac" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">最后但同样重要的是，如果没有某种基准测试的参考，这样的文章是不完整的。说到纯速度，H2O.ai 为大部分用于数据处理的 Python 库准备了这样的<a class="ae ji" href="https://h2oai.github.io/db-benchmark/" rel="noopener ugc nofollow" target="_blank">一个基准测试</a>。为了评估这些库，他们对 2 个数据集进行了数据聚合和连接。对于这些任务，他们使用了不同大小的数据集:0.2 GB、5 GB 和 50 GB。</p><p id="5daf" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">你对文章中提到的图书馆有经验吗？还是我错过了一个你知道的图书馆？我很想听听你的经历！你可以在<a class="ae ji" href="https://twitter.com/erykml1?source=post_page---------------------------" rel="noopener ugc nofollow" target="_blank">推特</a>或评论中联系我。</p><p id="48fe" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">喜欢这篇文章吗？成为一个媒介成员，通过无限制的阅读继续学习。如果你使用<a class="ae ji" href="https://eryk-lewinson.medium.com/membership" rel="noopener">这个链接</a>成为会员，你将支持我，而不需要额外的费用。提前感谢，再见！</p><p id="ccf6" class="pw-post-body-paragraph la lb jl lc b ld le km lf lg lh kp li lj lk ll lm ln lo lp lq lr ls lt lu lv io bi translated">您可能还会对以下内容感兴趣:</p><div class="iu iv gp gr iw os"><a rel="noopener follow" target="_blank" href="/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jm gy z fp ox fr fs oy fu fw jk bi translated">使处理大型数据帧变得更容易，至少对您的内存来说是这样</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">将数据帧的大小减少多达 90%！</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pc l pd pe pf pb pg jc os"/></div></div></a></div><div class="iu iv gp gr iw os"><a rel="noopener follow" target="_blank" href="/8-more-useful-pandas-functionalities-for-your-analyses-ef87dcfe5d74"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jm gy z fp ox fr fs oy fu fw jk bi translated">用于分析的 8 个更有用的熊猫功能</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">它们可以让你的日常工作更轻松、更快捷</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="ph l pd pe pf pb pg jc os"/></div></div></a></div><div class="iu iv gp gr iw os"><a rel="noopener follow" target="_blank" href="/9-useful-pandas-methods-you-probably-have-not-heard-about-28ff6c0bceee"><div class="ot ab fo"><div class="ou ab ov cl cj ow"><h2 class="bd jm gy z fp ox fr fs oy fu fw jk bi translated">你可能没听说过的 9 种有用的熊猫方法</h2><div class="oz l"><h3 class="bd b gy z fp ox fr fs oy fu fw dk translated">它们可以让你的日常工作更容易、更快捷。</h3></div><div class="pa l"><p class="bd b dl z fp ox fr fs oy fu fw dk translated">towardsdatascience.com</p></div></div><div class="pb l"><div class="pi l pd pe pf pb pg jc os"/></div></div></a></div></div></div>    
</body>
</html>