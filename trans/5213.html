<html>
<head>
<title>Does Your Laptop Matter for Data Science? Old ThinkPad vs. New MacBook Pro Compared</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">您的笔记本电脑对数据科学重要吗？旧 ThinkPad 与新 MacBook Pro 对比</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/does-laptop-matter-for-data-science-old-thinkpad-vs-new-macbook-pro-compared-67e3fa0f9e09#2022-11-22">https://towardsdatascience.com/does-laptop-matter-for-data-science-old-thinkpad-vs-new-macbook-pro-compared-67e3fa0f9e09#2022-11-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="95f6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">英特尔 i3–6100 u 上的 Pandas 和 TensorFlow 性能指标评测与 M1 Pro MacBook Pro 相比，速度慢了 50 倍？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d6574d8154c83b1ca64a6c65b4f2d0fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lfvOpI0njCv6l8XqQRg9Hw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">文章缩略图— ThinkPad L470(左)和 M1 Pro MacBook(右)(图片由作者提供)</p></figure><p id="1fa0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自发布以来，16 英寸的 M1 Pro MacBook 一直是我的首选。它在超高级的表面下提供了令人难以置信的性能，同时可以持续一整天，并拥有可能是业界最好的屏幕。</p><p id="d0da" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">但是一台旧的双核联想 ThinkPad 呢？第六代英特尔处理器能接近现代的发电站吗？</em>继续阅读寻找答案。</p><p id="24b6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在今天的文章中，我们将在一系列基准测试中比较旧的 ThinkPad L470 和现代的 M1 Pro MacBook Pro，从合成产品到熊猫和 TensorFlow。基准测试的范围是有限的，所以一切都可以在十分钟内完成。</p><p id="50ba" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在继续之前，让我们比较一下硬件规格:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lv"><img src="../Images/a516d445df18998c0136b8f3d6441582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e3RFCaQFBVLCK_D8UZ157Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 1 —硬件规格对比(图片由作者提供)</p></figure><p id="578f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这不是真正的苹果之间的比较。Mac 起价 2499 美元，我买的 ThinkPad 不到 200 美元。这要便宜 12 倍以上，所以 Mac 有理由这么做。</p><p id="e3fe" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">不想看书？请观看我的视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lw lx l"/></div></figure></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="f658" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">英特尔酷睿 i3–6100 u 性能指标评测——现在还不太好</h1><p id="b3c6" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">6100U 早在 2015 年就发布了，所以我们真的不能指望它能与更现代、更强大的芯片相媲美。此外，综合基准只能带我们走这么远，但它们是一个很好的起点。</p><p id="8709" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是 i3–6100 u 与单核部门的 M1 Pro 芯片的比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/69e7696a1e6cd988bd3fe6501f568031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yo-dRWCoqK01sBPJx3E_kg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 2 — Geekbench 单核性能(图片由作者提供)</p></figure><p id="d471" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">M1 专业版大约快 3.5 倍，这是意料之中的。即使在今天，大多数 Windows 笔记本电脑也无法与之媲美，所以这真的不足为奇。</p><p id="8fd6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">多核是有趣的地方。i3 只有两个内核，而 M1 Pro 有 8 个性能内核和 2 个效率内核。结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/924864f4711e1b19a82fbf1b8f50026e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20fmqF2Y8SNraJ407pD4Sw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 3 — Geekbench 多核性能(图片由作者提供)</p></figure><p id="168e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，Mac 在这个测试中快了 12 倍。这是一个巨大的差异，你肯定会在日常使用中注意到这一点。此外，macOS 需要更少的资源来顺利运行，所以这是你必须考虑的另一个问题。</p><p id="bdf6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们进入实际的数据科学基准，从熊猫开始。</p><h1 id="5e04" class="mf mg it bd mh mi ne mk ml mm nf mo mp jz ng ka mr kc nh kd mt kf ni kg mv mw bi translated">Pandas 基准测试—典型数据工作流程时间对比</h1><p id="aa3c" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">在一篇文章中，我只能比较这么多，所以让我们继续讨论基础知识。我们将比较创建、保存、读取和转换熊猫数据帧所需的时间。</p><h2 id="a31f" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">创建一个熊猫数据框架</h2><p id="2096" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">让我们创建两个数据集——第一个有 100 万行，第二个大约有 5 行。这些应该足以将 ThinkPad 推向极限。</p><p id="c67b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面的代码片段导入了本节需要的所有库，还声明了一个函数<code class="fe nv nw nx ny b">create_dataset()</code>，它创建了数据集。</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="9a66" class="od mg it ny b be oe of l og oh">import random<br/>import string<br/>import numpy as np<br/>import pandas as pd<br/>from datetime import datetime<br/>np.random.seed = 42<br/><br/><br/>def create_dataset(start: datetime, end: datetime, freq: str) -&gt; pd.DataFrame:<br/>    def gen_random_string(length: int = 32) -&gt; str:<br/>        return ''.join(random.choices(<br/>            string.ascii_uppercase + string.digits, k=length)<br/>        )<br/><br/>    dt = pd.date_range(<br/>        start=start,<br/>        end=end,<br/>        freq=freq,  # Increase if you run out of RAM<br/>        closed='left'<br/>    )<br/><br/>    df_size = len(dt)<br/>    df = pd.DataFrame({<br/>        'date': dt,<br/>        'a': np.random.rand(df_size),<br/>        'b': np.random.rand(df_size),<br/>        'c': np.random.rand(df_size),<br/>        'd': np.random.rand(df_size),<br/>        'e': np.random.rand(df_size),<br/>        'str1': [gen_random_string() for x in range(df_size)],<br/>        'str2': [gen_random_string() for x in range(df_size)]<br/>    })<br/>    <br/>    return df</span></pre><p id="ce5f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们使用它来创建 1M 和 5M 数据集:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="cccf" class="od mg it ny b be oe of l og oh">########## 1M Dataset ##########<br/><br/>df_1m = create_dataset(<br/>    start=datetime(2010, 1, 1),<br/>    end=datetime(2020, 1, 1),<br/>    freq='300s'<br/>)<br/><br/>########## 5M Dataset ##########<br/><br/>df_5m = create_dataset(<br/>    start=datetime(2010, 1, 1),<br/>    end=datetime(2020, 1, 1),<br/>    freq='60s'<br/>)</span></pre><p id="595a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是笔记本电脑和数据集的时间:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/6b36f80f92ae70d93314adff4637f774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBAyqJ_6hQejjKR0OBV7uA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片 4-创建数据集所需的时间(图片由作者提供)</p></figure><p id="a7f7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">从各方面考虑，这并不是一个很大的差别。对于 1M 数据集，Mac 大约快 7 倍，对于 5M 数据集，大约快 5 倍。ThinkPad 上没有发生任何崩溃或冻结，只是需要更多的时间。</p><h2 id="1d56" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">将数据集保存到 CSV 文件</h2><p id="ca0d" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">在整个项目过程中，您可能会将数据保存在不同的状态中，因此将花费在这里的时间减到最少会很好。下面的代码片段将两只熊猫的数据帧转储到一个 CSV 文件:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="239a" class="od mg it ny b be oe of l og oh">########## 1M Dataset ##########<br/><br/>df_1m.to_csv("/Users/dradecic/Desktop/1Mdf.csv", index=False)<br/><br/>########## 5M Dataset ##########<br/><br/>df_5m.to_csv("/Users/dradecic/Desktop/5Mdf.csv", index=False)</span></pre><p id="e8ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/17e551bcb8b5e1258614b7e644ab02cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*70rAGpuWvT-Gleob8ikB6w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 5-将数据集保存为 CSV 文件所需的时间(图片由作者提供)</p></figure><p id="d4b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">和我们之前的故事相似。将熊猫数据保存到 CSV 文件时，Mac 的速度大约快了 5 倍。</p><h2 id="3ba0" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">从磁盘读取 CSV 文件</h2><p id="3d1b" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">但是反过来呢？在 Mac 上读取 CSV 文件也会快 5 倍吗？代码如下:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="57aa" class="od mg it ny b be oe of l og oh">########## 1M Dataset ##########<br/><br/>df_1m = pd.read_csv("/Users/dradecic/Desktop/1MDF.csv")<br/><br/>########## 5M Dataset ##########<br/><br/>df_5m = pd.read_csv("/Users/dradecic/Desktop/5MDF.csv")</span></pre><p id="5b07" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/c2805c82d0755f95546e3021b9d6d492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hkCbHKm9CAtRhyxwEwiGCQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 6 —读取 CSV 文件所需的时间(图片由作者提供)</p></figure><p id="785e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">到目前为止，5X 时差似乎是普遍存在的。</p><h2 id="6dae" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">将函数应用于列</h2><p id="81d5" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">通过调用 DataFrame 列上的<code class="fe nv nw nx ny b">apply()</code>方法，可以在 data frame 列上应用自定义函数。下面的代码片段颠倒了最初包含 32 个字符的随机字符串的<code class="fe nv nw nx ny b">str1</code>列:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="0d33" class="od mg it ny b be oe of l og oh">def reverse_str(x) -&gt; str:<br/>    return x[::-1]<br/>    <br/>    <br/>########## 1M Dataset ##########<br/><br/>df_1m['str1_rev'] = df_1m['str1'].apply(reverse_str)<br/><br/>########## 5M Dataset ##########<br/><br/>df_5m['str1_rev'] = df_5m['str1'].apply(reverse_str)</span></pre><p id="07f3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们来看看结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/8f3e88b959c894a403f18a4381b537dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EMo64lTJiHzNhA1iO3ENpg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 7 —反转一列字符串所需的时间(图片由作者提供)</p></figure><p id="14a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">又一次，5X 时差对 Mac 电脑有利。</p><p id="9105" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">总结一下</strong>——M1 Pro MacBook 一直比 ThinkPad L470 快 5 倍左右。这并不令人惊讶，但让我们看看 TensorFlow 是否能让这种差异变得更大。</p><h1 id="f979" class="mf mg it bd mh mi ne mk ml mm nf mo mp jz ng ka mr kc nh kd mt kf ni kg mv mw bi translated">TensorFlow 基准测试—自定义模型和迁移学习</h1><p id="b27d" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">只是为了解决房间里的大象——可以在 i3–6100 u 或任何其他低端芯片上安装甚至运行 TensorFlow。它可以工作，但是很慢，因为处理器不是很强大，也没有 GPU 的支持。</p><p id="8f64" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于 TensorFlow 基准测试，我使用了来自 Kaggle 的<a class="ae ol" href="https://www.kaggle.com/pybear/cats-vs-dogs?select=PetImages" rel="noopener ugc nofollow" target="_blank">狗与猫数据集</a>，该数据集是在知识共享许可下授权的。长话短说，你可以免费使用。至于数据集准备，如果您想复制结果，请参考本文中的<a class="ae ol" href="https://betterdatascience.com/top-3-prerequisites-for-deep-learning-projects/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="9d70" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们开始第一项测试。</p><h2 id="0e58" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">自定义张量流模型</h2><p id="1367" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">第一个 TensorFlow 基准测试使用数据扩充，并将<a class="ae ol" href="https://betterdatascience.com/train-image-classifier-with-convolutional-neural-networks/" rel="noopener ugc nofollow" target="_blank">两块卷积模型</a>应用于图像数据集。它没有什么特别的，只是一个你在学习 TensorFlow 时可能会偶然发现的模型架构:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="5033" class="od mg it ny b be oe of l og oh">import os<br/>import warnings<br/>from datetime import datetime<br/>os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'<br/>warnings.filterwarnings('ignore')<br/><br/>import numpy as np<br/>import tensorflow as tf<br/>tf.random.set_seed(42)<br/><br/><br/>####################<br/># 1. Data loading<br/>####################<br/>train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0,<br/>    rotation_range=20,<br/>    width_shift_range=0.2,<br/>    height_shift_range=0.2,<br/>    shear_range=0.2,<br/>    zoom_range=0.2,<br/>    horizontal_flip=True,<br/>    fill_mode='nearest'<br/>)<br/>valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0<br/>)<br/><br/>train_data = train_datagen.flow_from_directory(<br/>    directory='/Users/dradecic/Desktop/data/train/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)<br/>valid_data = valid_datagen.flow_from_directory(<br/>    directory='/Users/dradecic/Desktop/data/validation/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)<br/><br/>####################<br/># 2. Model<br/>####################<br/>model = tf.keras.Sequential([<br/>    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), input_shape=(224, 224, 3), activation='relu'),<br/>    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),<br/>    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),<br/>    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),<br/>    tf.keras.layers.Flatten(),<br/>    tf.keras.layers.Dense(128, activation='relu'),<br/>    tf.keras.layers.Dense(2, activation='softmax')<br/>])<br/>model.compile(<br/>    loss=tf.keras.losses.categorical_crossentropy,<br/>    optimizer=tf.keras.optimizers.Adam(),<br/>    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]<br/>)<br/><br/>####################<br/># 3. Training<br/>####################<br/>model.fit(<br/>    train_data,<br/>    validation_data=valid_data,<br/>    epochs=5<br/>)</span></pre><p id="6fed" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型在每台机器上训练了 5 个历元，下图比较了平均历元时间:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/a1e4d88772730711fdbe5d756639327d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brBdf3J2Hcy4e3hsFeedpQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 8-自定义模型上每个历元的张量流平均时间(图片由作者提供)</p></figure><p id="cc13" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，TensorFlow 可以在一台旧笔记本电脑上运行，但与 Mac 相比慢了大约 8 倍。如果你刚刚开始，这不是一个交易破坏者。</p><h2 id="a432" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">张量流迁移学习模型</h2><p id="f2b2" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">下面的代码片段或多或少与上一个相同，但有一个重要的区别——它现在使用一个<a class="ae ol" href="https://betterdatascience.com/tensorflow-transfer-learning/" rel="noopener ugc nofollow" target="_blank">预训练的 VGG-16 网络</a>来分类图像:</p><pre class="kj kk kl km gt nz ny oa bn ob oc bi"><span id="86a0" class="od mg it ny b be oe of l og oh">####################<br/># 1. Data loading<br/>####################<br/>train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0,<br/>    rotation_range=20,<br/>    width_shift_range=0.2,<br/>    height_shift_range=0.2,<br/>    shear_range=0.2,<br/>    zoom_range=0.2,<br/>    horizontal_flip=True,<br/>    fill_mode='nearest'<br/>)<br/>valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(<br/>    rescale=1/255.0<br/>)<br/><br/>train_data = train_datagen.flow_from_directory(<br/>    directory='/Users/dradecic/Desktop/data/train/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)<br/>valid_data = valid_datagen.flow_from_directory(<br/>    directory='/Users/dradecic/Desktop/data/validation/',<br/>    target_size=(224, 224),<br/>    class_mode='categorical',<br/>    batch_size=64,<br/>    seed=42<br/>)<br/><br/>####################<br/># 2. Base model<br/>####################<br/>vgg_base_model = tf.keras.applications.vgg16.VGG16(<br/>    include_top=False, <br/>    input_shape=(224, 224, 3), <br/>    weights='imagenet'<br/>)<br/>for layer in vgg_base_model.layers:<br/>    layer.trainable = False<br/>    <br/>####################<br/># 3. Custom layers<br/>####################<br/>x = tf.keras.layers.Flatten()(vgg_base_model.layers[-1].output)<br/>x = tf.keras.layers.Dense(128, activation='relu')(x)<br/>out = tf.keras.layers.Dense(2, activation='softmax')(x)<br/><br/>vgg_model = tf.keras.models.Model(<br/>    inputs=vgg_base_model.inputs,<br/>    outputs=out<br/>)<br/>vgg_model.compile(<br/>    loss=tf.keras.losses.categorical_crossentropy,<br/>    optimizer=tf.keras.optimizers.Adam(),<br/>    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]<br/>)<br/><br/>####################<br/># 4. Training<br/>####################<br/>vgg_model.fit(<br/>    train_data,<br/>    validation_data=valid_data,<br/>    epochs=5<br/>)</span></pre><p id="4c13" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这次的结果大不相同:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/f3f919091e9ffaad7cf7d873c7e0c856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCwF4gqUHfYvB-YQfW0Fvw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图 9 —迁移学习模型中每个时期的张量流平均时间(图片由作者提供)</p></figure><p id="07e3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，在 Mac 上，每个时期的平均训练时间几乎没有增加，但在 ThinkPad 上却飞速增长。在 i3–6100 u 上等待迁移学习模型完成培训花费了一天中的大部分时间，因为与 Mac 相比，它几乎慢了 54 倍。</p><p id="0d30" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么，<strong class="la iu">我们从这些基准测试中学到了什么？</strong>接下来让我们回顾一些见解。</p><h1 id="32eb" class="mf mg it bd mh mi ne mk ml mm nf mo mp jz ng ka mr kc nh kd mt kf ni kg mv mw bi translated">旧笔记本电脑上的数据科学—需要考虑的事项</h1><p id="d156" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">在旧笔记本电脑上进行数据争论或数据科学工作并不是不可能的，尤其是如果你刚刚起步的话。有几件事你应该记住，所以让我们复习一下。</p><h2 id="e3c7" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">旧笔记本电脑+深度学习=谷歌 Colab</h2><p id="719c" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">没有理由仅仅因为你刚开始深度学习就让一台旧笔记本电脑经历磨难。<a class="ae ol" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjGlsvlyL77AhVW8rsIHUIHALwQFnoECBgQAQ&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Fgoogle-colab-how-does-it-compare-to-a-gpu-enabled-laptop-851c1e0a2ca9&amp;usg=AOvVaw003PyYjAysWQ4y-H0WHXA-" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>是一个令人惊叹的预配置笔记本电脑环境，不需要任何成本，并且包含 GPU 支持。如果你需要更多的功能和更长的运行时间，可以考虑 Colab Pro。</p><h2 id="0b3d" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">港口的缺乏</h2><p id="7446" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">说 Mac 有更好的端口选择很奇怪，但在这种情况下确实如此。ThinkPad L470 已经 5+岁了，所以它没有 USB-C，甚至没有 HDMI 端口。连接外接显示器就没那么容易了。</p><p id="61cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有一个 VGA 端口可用，但这需要一个适配器，如果你有一个现代的外部显示器，图像质量会有所下降。不是交易破坏者，只是需要考虑的事情。</p><p id="f046" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有了 Mac，我可以用一根 USB-C 电缆连接 4K 外部显示器、监视器灯、手机充电器、麦克风和耳机。</p><h2 id="6021" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">可怕的屏幕</h2><p id="3684" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">我从来没有对 ThinkPad 的显示器印象深刻，但 L470 将这种糟糕带到了一个完全不同的水平。显示屏为 14 英寸，对于笔记本电脑来说非常出色，但分辨率不是 1366x768。所有的东西都很大，你不能在屏幕上放超过一两个窗口。色彩准确度也非常糟糕。</p><p id="d1bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果连接全分辨率的外部显示器更容易，这就不是问题了。</p><p id="7730" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">另一方面，Mac 上的迷你 LED 屏幕跨度为 16 英寸，分辨率为 3456x2234。至少可以说，这是白天和黑夜的差别。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h1 id="1be1" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">结论</h1><p id="8e1c" class="pw-post-body-paragraph ky kz it la b lb mx ju ld le my jx lg lh mz lj lk ll na ln lo lp nb lr ls lt im bi translated">英特尔的 i3–6100 u 可以相当好地处理熊猫，它也可以用 TensorFlow 训练深度学习模型，尽管速度很慢。你绝对可以在使用它的同时进入数据科学，甚至在行业内从事专业工作。如今大部分工作都在云端完成，所以笔记本电脑归根结底是被美化了的键盘。</p><p id="4256" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">与新事物相比，廉价的旧笔记本电脑的最大问题不是原始性能，而是其他方面的妥协。每天看着可怕的屏幕 8 个多小时，处理劣质电池和一大堆电缆并不好玩。</p><p id="c89e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但另一方面，如果你想进入数据科学领域，并有 200 美元的闲钱，一台旧笔记本电脑就足够了。</p><p id="821f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你对新旧笔记本电脑的对比有什么看法？您目前使用的笔记本电脑曾经风光过吗？如果是，你每天都在与什么问题作斗争？请在下面的评论区告诉我。</p></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><p id="21ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">喜欢这篇文章吗？成为</em> <a class="ae ol" href="/@radecicdario/membership" rel="noopener ugc nofollow" target="_blank"> <em class="lu">中等会员</em> </a> <em class="lu">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="oo op gp gr oq or"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">通过我的推荐链接加入 Medium-Dario rade ci</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">阅读达里奥·拉德契奇(以及媒体上数以千计的其他作家)的每一个故事。您的会员费直接支持…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">medium.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf ks or"/></div></div></a></div></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><h2 id="25b4" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">更多基准</h2><ul class=""><li id="ef59" class="pg ph it la b lb mx le my lh pi ll pj lp pk lt pl pm pn po bi translated"><a class="ae ol" href="https://betterdatascience.com/macbook-m1-vs-m1-pro-for-data-science/" rel="noopener ugc nofollow" target="_blank">MacBook M1 vs M1 Pro</a></li><li id="7b73" class="pg ph it la b lb pp le pq lh pr ll ps lp pt lt pl pm pn po bi translated"><a class="ae ol" href="https://betterdatascience.com/macbook-m1-vs-google-colab/" rel="noopener ugc nofollow" target="_blank">MacBook M1 vs . Google Colab</a></li><li id="ae03" class="pg ph it la b lb pp le pq lh pr ll ps lp pt lt pl pm pn po bi translated"><a class="ae ol" href="https://betterdatascience.com/macbook-m1-pro-vs-google-colab/" rel="noopener ugc nofollow" target="_blank"> MacBook M1 Pro vs 谷歌 Colab </a></li><li id="bed9" class="pg ph it la b lb pp le pq lh pr ll ps lp pt lt pl pm pn po bi translated"><a class="ae ol" href="https://betterdatascience.com/macbook-m1-vs-rtx3060ti/" rel="noopener ugc nofollow" target="_blank">MacBook M1 vs RTX 3060 ti</a></li></ul><h2 id="63e4" class="nj mg it bd mh nk nl dn ml nm nn dp mp lh no np mr ll nq nr mt lp ns nt mv nu bi translated">保持联系</h2><ul class=""><li id="7bb9" class="pg ph it la b lb mx le my lh pi ll pj lp pk lt pl pm pn po bi translated">雇用我作为一名<a class="ae ol" href="https://betterdatascience.com/contact/" rel="noopener ugc nofollow" target="_blank">技术作家</a></li><li id="5c2f" class="pg ph it la b lb pp le pq lh pr ll ps lp pt lt pl pm pn po bi translated">在 YouTube<a class="ae ol" href="https://www.youtube.com/c/BetterDataScience" rel="noopener ugc nofollow" target="_blank">上订阅</a></li><li id="6d75" class="pg ph it la b lb pp le pq lh pr ll ps lp pt lt pl pm pn po bi translated">在<a class="ae ol" href="https://www.linkedin.com/in/darioradecic/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上连接</li></ul></div><div class="ab cl ly lz hx ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="im in io ip iq"><p id="2f2d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu">原载于 2022 年 11 月 22 日 https://betterdatascience.com</em><a class="ae ol" href="https://betterdatascience.com/data-science-old-laptop/" rel="noopener ugc nofollow" target="_blank"><em class="lu"/></a><em class="lu">。</em></p></div></div>    
</body>
</html>