<html>
<head>
<title>How to Ingest and Consume Data from Azure Data Lake</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从Azure数据湖获取和使用数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-ingest-and-consume-data-from-azure-data-lake-e66b56406b08#2022-10-30">https://towardsdatascience.com/how-to-ingest-and-consume-data-from-azure-data-lake-e66b56406b08#2022-10-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d1c7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">摄入/消费模式分析，包括三角洲湖PoC</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0d0deafa66652375929e065c690f856a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*snjVcZckiAh8A2JEPp9LdQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://unsplash.com/@clintadair?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">克林特·王茂林</a>在<a class="ae ky" href="https://unsplash.com/s/photos/data-patterns?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="d14c" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">1.介绍</h1><p id="b834" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">许多公司考虑建立一个企业数据湖。这个想法是将数据存储在一个集中的存储库中。数据湖的主要利益相关者是以下两个实体:</p><ul class=""><li id="2c98" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated"><strong class="lt iu">数据生产者:</strong>接收数据到数据湖的实体。这通常是指不直接从数据湖中获利的实体，他们更喜欢一种无需太多开销的简单数据获取方式(类似于“一劳永逸”)</li><li id="e682" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated"><strong class="lt iu">数据消费者:</strong>使用数据创造商业价值的实体。这通常是从数据湖中获益最多的实体，并且更喜欢无需太多返工就可以轻松使用数据(数据被正确分区，而不是许多小文件，等等)</li></ul><p id="6799" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">在这篇博文中，第2章讨论了四种不同的数据摄取模式。随后，第三章阐述了两种消费模式。在第4章中，使用ADF和delta lake讨论了使用git repo <code class="fe ng nh ni nj b"><a class="ae ky" href="https://github.com/rebremer/adf-deltalake-ingestion-consumption" rel="noopener ugc nofollow" target="_blank">adf-deltalake-ingestion-consumption</a></code>的概念验证，另请参见下图。最后，在第五章得出结论。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/29737baf197d3798bf280e7e872e6ad6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWFbL73U5gNaomEmEssxaw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">1.建筑概念验证—作者图片</p></figure><h1 id="71db" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">2.数据生产者:摄取模式</h1><p id="9391" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本章中，使用以下两个维度来区分四种类型的摄取模式:</p><ul class=""><li id="a701" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">原始数据与日终聚合:如果使用原始数据，所有源数据都将被接收到目标中。如果使用日终，源数据将以有意义的完整形式聚合到目标</li><li id="282a" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">快照与增量:在使用快照的情况下，所有源数据每天都被接收到目标中。在使用增量情况下，只有变异的源数据被接收到目标中。</li></ul><p id="c172" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">在本章的剩余部分，我们将讨论这四种模式，它们是上述两个维度的组合。为了进一步阐明，使用了一个示例数据集，其中在第一天生产卡1和2，然后在第二天在卡1上完成两个卡交易，见下文。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/60d324cfd6744faf3bdc31c818ddb85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d8J5e3e_IvYWIIdlZKoOZg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2.0.示例数据集</p></figure><p id="d676" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">在接下来的段落中，我们将从正反两方面讨论这些模式。</p><h2 id="d6a3" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">2.1模式P1:原始数据-快照</h2><p id="1076" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在快照模式中，每天都发送完整的原始数据集。对于上面的数据集，这意味着第1天和第2天的数据如下。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/bb55f785f3c5347fc3c34e3be0f6cd12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZY5GgqywdRm5NML-p_e3_g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2.1 .模式P1:原始数据—快照</p></figure><p id="6b9b" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">利弊分析如下:</p><ul class=""><li id="b0e1" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">(pro)数据生产者最容易采用的模式；只需要进行数据转储，而不需要跟踪更改</li><li id="19a0" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(不)对大型数据集不可行；每天发送数据集的成本很高。大型数据集也会影响性能(复制时间)。备份也是如此。</li><li id="a0d8" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(缺点)数据消费者需要跟踪变化。由于数据消费者对数据的了解通常比数据生产者少，这很容易出错。当数据被复制到消费者自己的环境中时，这尤其具有挑战性(如果不进行复制，而是使用数据虚拟化，delta lake可以提供帮助)</li></ul><h2 id="6370" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">2.2模式P2:原始数据—delta</h2><p id="3ca7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在增量模式中，插入新数据并更新现有数据。对于不可变的数据集，总是会插入新数据，因为不会发生更新。如果数据集是可变的，那么可以进行更新。在这种情况下，关键是源和目标中都有一个唯一的ID，以便可以匹配数据。对于示例数据集，模式2可以如下应用(仅插入):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/5642375dbbe9efdfa8d7ac7f1a8d0e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0dJMi-gOFTRTNp0Y2C_mXg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2.2.模式P2:原始数据-增量</p></figure><p id="b8fd" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">利弊分析如下:</p><ul class=""><li id="9b51" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">(亲)更高效的模式。发送大型数据集没有成本，性能可能会更好，复制大型数据集时出错/超时的可能性更小。</li><li id="1b6b" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(缺点)数据消费者必须能够使用所有以前的数据增量。如果缺少一个增量，数据集就会损坏。</li><li id="4159" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(专业)数据消费者可以在自己的环境中轻松识别变更并进行更新。三角洲也可以通过ADF数据流和三角洲湖泊轻松处理。</li></ul><h2 id="ca4f" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">2.3模式P3:一天结束—快照</h2><p id="64f4" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在一天结束时的快照模式中，目标不是同步原始数据源和数据接收器。相反，会在一天结束时创建并发送一个聚合。这可能是因为以下原因:</p><ul class=""><li id="47e7" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">消费者只对最终结果感兴趣(而对导致这个最终结果的N个突变不感兴趣)</li></ul><p id="4137" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">对于示例数据集，消费者可能只对卡的total_amount感兴趣，见下文。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/1a9163cf008feb918f743591d5ab5c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2nYXPLBrsKlLwxhG2jkPKw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2.3.模式P3:一天结束-快照</p></figure><p id="e605" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">利弊分析如下:</p><ul class=""><li id="3b44" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">(不利)由于消费者只能获得汇总数据，因此会发生数据丢失。</li><li id="1253" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(pro)数据模式可能更有效，例如，如果数据消费者只对最终结果感兴趣，而对导致最终结果的N个突变不感兴趣。</li></ul><h2 id="4b3d" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">2.4模式P4:一天结束— delta</h2><p id="dd7a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">模式4:一天结束—增量几乎类似于2a一天结束—快照，但只发送突变的数据。对于示例数据集，这意味着:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/900c49e4b9753985bd69cb6141996370.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i_02X79juJTN6FU5bVhPmw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">2.4.模式P4:一天结束-快照</p></figure><p id="9c47" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">模式3和模式4的利弊分析基本相同。唯一的区别是，在聚合仍然很大的情况下，增量可能更有效。</p><h2 id="9e4d" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">2.5结论</h2><p id="43f7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这四种模式各有利弊。然而，对于企业数据湖的标准化来说，使用<strong class="lt iu">模式P2:原始数据—增量</strong>作为缺省值可能是个好主意。原因如下:</p><ul class=""><li id="4ee1" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">当所有原始数据从源发送到目标时，不会发生数据丢失。生产者很难预测消费者需要什么样的聚合。相反，消费者可以自己决定他们需要什么样的聚合。数据湖中的多个区域也有所帮助，其中一个着陆区域用于接收所有原始数据，一个瓶装区域用于创建多个聚合以供使用</li><li id="3df3" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">增量是一种更具成本效益的模式，因为需要拷贝的数据较少。对于大型数据集，增量甚至可能是唯一可行的解决方案。</li></ul><h1 id="4a9d" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">3.数据消费者:消费模式</h1><p id="7c1b" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本章中，两种不同的消费模式讨论如下:</p><ul class=""><li id="cba4" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">复制数据:消费者将数据从数据湖复制到他们自己的环境中</li><li id="740c" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">虚拟化数据:消费者直接使用数据湖中的数据</li></ul><p id="9298" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">在接下来的两段中，我们将讨论每种消费模式的利弊。</p><h2 id="22bd" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">3.2模式C1:虚拟化数据</h2><p id="4cce" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在数据虚拟化模式中，消费者直接在数据湖上查询，数据不会复制到他们自己的环境中。</p><ul class=""><li id="5ad2" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">(亲)单一来源的事实，没有重复的数据创建</li><li id="1585" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(亲)消费者容易介入的模式。如果消费者没有太多的技术知识，只想创建一些(Power BI)报告，这一点尤其如此</li><li id="cc75" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(支持)Delta lake可用于简化使用SQL对存储帐户的查询</li><li id="8ea3" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(不利)对于有强烈性能需求(SLA)的团队不可行</li><li id="67b5" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(缺点)将企业数据湖数据与不属于数据湖的数据(例如，位于消费者自己的SQL环境中的数据)连接起来可能很困难</li></ul><h2 id="d9f6" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">3.2模式C2:复制数据</h2><p id="a301" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在复制数据模式中，消费者将数据从企业数据湖卸载到自己的环境中。</p><ul class=""><li id="0ea2" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">(赞成)消费者完全控制数据。如果客户有严格的性能要求(为24x7网站提供服务)或严格的SLA(为数据湖提供服务的团队可能无法在凌晨03:00回答问题)，这一点尤为重要</li><li id="4e67" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(缺点)复制可能需要很长时间，尤其是当大型数据集必须复制到消费者自己的环境中时</li><li id="71be" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">(缺点)消费者需要具备技术知识来设置自己的环境(ADF、数据库、网络等)。</li></ul><h2 id="017c" class="nm la it bd lb nn no dn lf np nq dp lj ma nr ns ll me nt nu ln mi nv nw lp nx bi translated">3.3结论</h2><p id="9aaa" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这两种模式各有利弊。然而，对于企业数据湖的标准化，使用<strong class="lt iu">模式C1:默认虚拟化数据</strong>可能是个好主意。这可以解释如下:</p><ul class=""><li id="0547" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">防止了数据不必要的复制，并且是最具成本效益的。</li><li id="7da8" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">还可以利用Delta lake来简化数据消耗，这将在下一章中详述。</li><li id="2373" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">如果使用了delta lake，而消费者仍然希望将数据复制到自己的环境中，则可以使用ADF从delta lake复制数据</li></ul><h1 id="3b58" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">4.ADF、Delta Lake和Spark:概念验证</h1><p id="86c3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本章中，使用以下体系结构构建概念验证:</p><ul class=""><li id="3fa1" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated"><strong class="lt iu">数据生产者:</strong>来自SQLDB的数据使用流向delta lake的ADF数据流获取。使用上面讨论的四种模式(原始数据与聚合数据、完整快照与增量增量)获取数据</li><li id="5760" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated"><strong class="lt iu">数据消费者:</strong>一旦数据被接收到delta lake，消费者就可以使用Databricks和Synapse笔记本使用Spark查询数据。如果消费者想要将数据复制到自己的环境中，则创建两条ADF管道，可以将快照或最新增量复制到自己的环境中</li></ul><p id="e6ce" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">另请参见下图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/29737baf197d3798bf280e7e872e6ad6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jWFbL73U5gNaomEmEssxaw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">4.建筑概念验证—作者图片</p></figure><p id="a160" class="pw-post-body-paragraph lr ls it lt b lu mp ju lw lx mq jx lz ma nd mc md me ne mg mh mi nf mk ml mm im bi translated">项目可以在git repo <code class="fe ng nh ni nj b"><a class="ae ky" href="https://github.com/rebremer/adf-deltalake-ingestion-consumption" rel="noopener ugc nofollow" target="_blank">adf-deltalake-ingestion-consumption</a></code>中找到。为运行PoC执行以下步骤:</p><ol class=""><li id="6da7" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm ny mv mw mx bi translated">替换变量并运行<code class="fe ng nh ni nj b"><a class="ae ky" href="https://github.com/rebremer/adf-deltalake-ingestion-consumption/blob/main/scripts/deploy_resources.sh" rel="noopener ugc nofollow" target="_blank">scripts/deploy_resources.sh</a></code>来部署ADF和deltalake。</li><li id="fb36" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm ny mv mw mx bi translated">运行不同的生产者管道将数据接收到三角洲湖</li><li id="4ee7" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm ny mv mw mx bi translated">消费者类型1:创建一个Databricks工作区或Synapse工作区，并运行<code class="fe ng nh ni nj b"><a class="ae ky" href="https://github.com/rebremer/adf-deltalake-ingestion-consumption/tree/main/notebooks" rel="noopener ugc nofollow" target="_blank">notebooks</a></code>来查询delta lake上的数据</li><li id="82a3" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm ny mv mw mx bi translated">消费者类型2:运行消费者管道，将数据消费到自己的存储帐户</li></ol><h1 id="3360" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">5.结论</h1><p id="60c8" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">许多公司考虑建立一个企业数据湖。数据湖的主要利益相关者是数据生产者和数据消费者。数据生产者通常在寻找一种轻松获取数据的方式，而数据生产者是从数据中创造商业价值的实体。在这篇博文中，作者提出了以下观点:</p><ul class=""><li id="e30b" class="mn mo it lt b lu mp lx mq ma mr me ms mi mt mm mu mv mw mx bi translated">生产者应该将原始数据<strong class="lt iu">存储到数据湖中，并在<strong class="lt iu">增量</strong>中完成此操作。基本原理是原始数据可防止数据丢失，增量数据具有成本效益且可扩展</strong></li><li id="7307" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated">消费者应<strong class="lt iu">直接从数据湖中</strong>查询数据，并在那里建立数据产品。基本原理是这样可以防止数据重复，并且具有成本效益。可能的例外是，当消费者需要更高的性能/更高的SLA时(例如，为24x7网站提供服务)，可以将数据复制到自己的环境中</li><li id="f4da" class="mn mo it lt b lu my lx mz ma na me nb mi nc mm mu mv mw mx bi translated"><strong class="lt iu"> Delta lake </strong>可以帮助消费者轻松查询数据，而Data Factory支持delta as sink，可以帮助生产者以Delta lake格式自动添加数据。这在这次<strong class="lt iu"> git回购</strong> : <code class="fe ng nh ni nj b"><a class="ae ky" href="https://github.com/rebremer/adf-deltalake-ingestion-consumption" rel="noopener ugc nofollow" target="_blank">adf-deltalake-ingestion-consumption</a></code>中得到了实践</li></ul></div></div>    
</body>
</html>