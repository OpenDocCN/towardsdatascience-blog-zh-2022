<html>
<head>
<title>Understanding Neural Network Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解神经网络嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-neural-network-embeddings-851e94bc53d2#2022-04-30">https://towardsdatascience.com/understanding-neural-network-embeddings-851e94bc53d2#2022-04-30</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4688" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深入探究神经网络嵌入</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7ced7f1cb9f7b2b727038e8f40cd623f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*24TCkG1Yr4x4UZgS"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">尼克·希利尔在<a class="ae ky" href="https://unsplash.com" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2773" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在之前关于<a class="ae ky" href="https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases" rel="noopener ugc nofollow" target="_blank">向量数据库</a>和<a class="ae ky" href="https://frankzliu.com/blog/making-machine-learning-more-accessible-for-application-developers" rel="noopener ugc nofollow" target="_blank"> ML应用开发</a>的博客文章中已经提到了嵌入/嵌入向量的主题，但是还没有深入研究嵌入和嵌入模型如何工作背后的一些理论。因此，本文将致力于更深入地研究嵌入/嵌入向量，以及它们在现代ML算法和流水线中的应用。</p><p id="da21" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">快速注意——这篇文章需要深度学习和神经网络的中级知识。如果你还不太了解，我建议你先看看谷歌的ML速成班。课程内容对于理解CV和NLP的神经网络基础很有帮助。</p><h1 id="99dc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">快速回顾一下</h1><p id="cfba" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">通过嵌入对数据进行矢量化，本质上是一种<em class="ms">降维的方法</em>。传统的降维方法— <a class="ae ky" rel="noopener" target="_blank" href="/the-most-gentle-introduction-to-principal-component-analysis-9ffae371e93b"> PCA </a>、<a class="ae ky" href="https://www.mygreatlearning.com/blog/understanding-latent-dirichlet-allocation/" rel="noopener ugc nofollow" target="_blank"> LDA </a>等。—结合使用线性代数、内核技巧和其他统计方法来“压缩”数据。另一方面，现代深度学习模型通过将输入数据映射到<em class="ms">潜在空间</em>中来执行维度缩减，潜在空间即输入数据的表示，其中附近的点对应于语义上相似的数据点。例如，过去代表单个单词或短语的热点向量现在可以表示为维度显著降低的密集向量。我们可以通过<a class="ae ky" href="https://github.com/towhee-io/towhee" rel="noopener ugc nofollow" target="_blank"> Towhee库</a>看到这一点:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="eabb" class="my lw it mu b gy mz na l nb nc">% pip install towhee  # pip3<br/>% python              # python3</span><span id="5d7e" class="my lw it mu b gy nd na l nb nc">&gt;&gt;&gt; import towhee <br/>&gt;&gt;&gt; text_embedding = towhee.dc(['Hello, world!']) \ <br/>...     .text_embedding.transformers(model_name='distilbert-base-cased') \ <br/>...     .to_list()[0]<br/>...<br/>&gt;&gt;&gt; embedding # includes punctuation and start &amp; end tokens</span><span id="3d5e" class="my lw it mu b gy nd na l nb nc">array([[ 0.30296388,  0.19200979,  0.10141158, ..., -0.07752968, 0.28487974, -0.06456392],<br/>       [ 0.03644813,  0.03014304,  0.33564508, ...,  0.11048479, 0.51030815, -0.05664057],<br/>       [ 0.29160976,  0.43050566,  0.46974635, ...,  0.22705288, -0.0923526, -0.04366254],<br/>       [ 0.14108554, -0.00599108,  0.34098792, ...,  0.16725197, 0.10088076, -0.06183652],<br/>       [ 0.35695776,  0.30499873,  0.400652  , ...,  0.20334958, 0.37474275, -0.19292705],<br/>       [ 0.6206475 ,  0.50192136,  0.602711  , ..., -0.03119299, 1.1860386 , -0.6167787 ]], dtype=float32)</span></pre><p id="a133" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于深度神经网络的嵌入算法几乎被普遍认为比传统的降维方法更强。这些嵌入在行业中的各种应用中使用得越来越频繁，例如内容推荐、问答、聊天机器人等。正如我们将在后面看到的，在神经网络中使用嵌入来表示图像和文本<em class="ms">近年来也变得越来越流行。</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ne"><img src="../Images/08e1eed26127233ceaa680b008c82d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksmh34uetPpsijNvO58Frg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由<a class="ae ky" href="https://towhee.io/text-embedding/transformers" rel="noopener ugc nofollow" target="_blank"> DistilBERT </a>制作的可视化文本嵌入。请注意，尽管“football”和“football”这两个词都很常见，但“football”和“soccer”的关系却比“football”更近。</p></figure><h1 id="c674" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">监督嵌入</h1><p id="d311" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">到目前为止，我以前的文章使用了来自使用<em class="ms">监督学习</em>训练的模型的嵌入，即来自标记/注释数据集训练的神经网络模型。例如，<a class="ae ky" href="https://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集包含一组精选的图像到类别的映射，而问答数据集如<a class="ae ky" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank"> SQuAD </a>提供不同语言的1:1句子映射。</p><p id="bc0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多通过标记数据训练的著名模型使用交叉熵损失或均方误差。由于监督训练的最终目标是或多或少地复制输入数据和注释之间的1:1映射(例如，在给定输入图像的情况下输出类别令牌概率)，因此从监督模型生成的嵌入很少使用输出层。例如，在ImageNet-1k上训练的标准ResNet50模型输出1000维向量，该向量对应于输入图像是第<em class="ms"> N </em>个类标签的实例的概率。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6d821e1dad35e561984702e667f52955.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*j9VNLuBV_B-1mHRJ3QI1PQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LeNet-5，已知最早的计算机视觉神经网络架构之一。图片by <a class="ae ky" href="https://d2l.ai/" rel="noopener ugc nofollow" target="_blank"> D2L.ai </a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>。</p></figure><p id="0932" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，大多数现代应用程序使用倒数第二层激活作为嵌入。在上图(LeNet-5)中，这对应于标记为<code class="fe ng nh ni mu b">FC (10)</code> (10维输出层)和<code class="fe ng nh ni mu b">FC (84)</code>的层之间的激活。这一层离输出足够近，可以准确地表示输入数据的语义，同时也是一个相当低的维度。我也见过计算机视觉应用程序使用模型中更早层的池激活。这些激活捕获输入图像的低级特征(角、边、博客等...)，这可以提高徽标识别等任务的性能。</p><h1 id="8cc0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">编码器和自我监督</h1><p id="98b4" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">使用带注释的数据集的一个主要缺点是它们需要注释(这听起来有点愚蠢，但是请原谅我)。为一组特定的输入数据创建高质量的注释需要一个或许多人花费数百甚至数千个小时的时间。例如，完整的ImageNet数据集包含大约22k个类别，需要25000人来管理。让事情更加复杂的是，许多带标签的数据集经常包含意想不到的不准确、明显的错误，或者精选结果中的<a class="ae ky" href="https://github.com/vinayprabhu/Dataset_audits/blob/master/Notebooks/ImageNet_2_NSFW_analysis.ipynb" rel="noopener ugc nofollow" target="_blank"> NSFW内容</a>。随着这种实例数量的增加，由监督学习训练的嵌入模型生成的嵌入质量显著下降。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/ccb57576be58b1f1d94408fdb3e82128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OzKXius16rEAXH6K"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自<a class="ae ky" href="https://unsplash.com/data" rel="noopener ugc nofollow" target="_blank"> Unsplash数据集</a>的标记为“希望”的图像。对于人类来说，这是一个非常明智的描述，但它可能会导致模型在训练过程中学习错误的特征类型。由<a class="ae ky" href="https://unsplash.com/photos/jSjgQmaQtVQ" rel="noopener ugc nofollow" target="_blank"> Lukas L </a>拍摄。</p></figure><p id="da2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一方面，以无人监督的方式训练的模特不需要标签。鉴于每天生成的文本、图像、音频和视频数量惊人，使用这种方法训练的模型基本上可以访问无限量的训练数据。这里的诀窍是开发正确类型的模型和培训方法来利用这些数据。一种令人难以置信的强大且日益流行的方式是通过<em class="ms">自动编码器</em>(或一般的<em class="ms">编码器/解码器</em>架构)。</p><p id="d411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms">自动编码器</em>通常有两个主要组件。第一个组件是编码器:它将一些数据作为输入，并将其转换为固定长度的向量。第二个组件是解码器:它将向量映射回原始数据。这就是所谓的编码器-解码器架构:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/66e44393bba8644ac7de23b3d8a02de9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hotg4SRV3jQAgA-zlmzYMQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">编码器-解码器架构示意图。图片由<a class="ae ky" href="https://d2l.ai/" rel="noopener ugc nofollow" target="_blank"> D2L.ai </a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>。</p></figure><p id="0127" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对应于<code class="fe ng nh ni mu b">Encoder</code>和<code class="fe ng nh ni mu b">Decoder</code>的蓝框都是前馈神经网络，而<code class="fe ng nh ni mu b">State</code>是期望的嵌入。这两种网络都没有什么特别之处——许多图像自动编码器将标准的ResNet50或ViT用于编码器网络，将类似的大型网络用于解码器网络。</p><p id="4805" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于自动编码器被训练为将输入映射到潜在状态，然后再映射回原始数据，因此无监督或自监督嵌入直接来自编码器的输出层，这与在完全监督下训练的模型的中间层相反。因此，自动编码器嵌入仅用于<em class="ms">重建</em>。换句话说，它们可以用来表示输入数据，但通常不足以表示语义，例如区分猫的照片和狗的照片。</p><p id="d5e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">近年来，除了传统的自动编码器之外，自我监督也有了许多改进。对于NLP，具有<em class="ms">上下文</em>的预训练模型，即单词或字符在同一个句子或短语中相对于其他单词或字符出现的位置，是常见的，现在被认为是训练最先进的文本嵌入模型的事实上的技术。自我监督的计算机视觉嵌入模型也正在蓬勃发展；依赖于数据扩充的对比训练技术在应用于一般的计算机视觉任务时已经显示出很好的效果。<a class="ae ky" href="https://arxiv.org/abs/2002.05709" rel="noopener ugc nofollow" target="_blank"> SimCLR </a>和<a class="ae ky" href="https://arxiv.org/abs/2202.03555" rel="noopener ugc nofollow" target="_blank"> data2vec </a>是神经网络的两个例子，它们利用掩蔽和/或其他增强进行自我监督训练。</p><h1 id="f3d9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">嵌入作为其他模型的输入</h1><p id="daaf" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">嵌入模型是非常独特的；它们不仅对一般的应用程序开发有价值，而且它们的输出经常用于其他机器学习模型。视觉变形金刚是一个很好的例子。得益于传统卷积神经网络所不具备的强大性能和巨大感受域，它们的受欢迎程度在过去两年里出现了爆炸式增长。视觉转换器的核心前提是将图像分成正方形小块，为每个小块生成嵌入，并将嵌入作为标准转换器的输入。令人惊讶的是，这对于图像识别非常有效。</p><p id="18a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个很好的例子是OpenAI的<a class="ae ky" href="https://github.com/openai/CLIP" rel="noopener ugc nofollow" target="_blank">剪辑</a>，这是一个大型神经网络模型，经过训练可以将图像与自然语言进行匹配。CLIP的训练对象是来自互联网的大量数据，例如Flickr照片和相应的照片标题。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/997d4362be271998dbdb28ae6f08fe03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Yk5E6A24OOe4JT5O.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">编码器及其相应的嵌入在OpenAI的剪辑模型中发挥了巨大的作用。图片由<a class="ae ky" href="https://github.com/openai" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>。</p></figure><p id="260b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CLIP背后的方法实际上相当简单。首先，CLIP将图像和文本映射成一种潜在状态(即一种嵌入)；这些潜在状态然后被训练以映射到<em class="ms">相同的空间</em>，即如果文本能够准确地描述图像，则文本嵌入和图像嵌入应该彼此非常接近。当涉及到ML时，困难在于细节，如果没有相当大的数据集和一些超参数调整，CLIP实际上很难实现。</p><p id="d745" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CLIP被用作DALLE(和DALLE-2)中的核心组件，DALLE-2是OpenAI的文本到图像生成引擎。最近有很多关于DALLE-2的传言，但如果没有CLIP的代表性，这些都是不可能的。虽然CLIP和DALLE的结果令人印象深刻，但图像嵌入仍有很大的发展空间。某些高级语义，如对象计数和数学运算，仍然难以在图像嵌入中表示。</p><h1 id="4d00" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">生成您自己的嵌入</h1><p id="9a48" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">我已经指出了<a class="ae ky" href="https://github.com/towhee-io/towhee" rel="noopener ugc nofollow" target="_blank"> Towhee </a>开源项目几次，展示了如何使用它来生成嵌入以及开发需要嵌入的应用程序。Towhee包装了来自各种来源(，<code class="fe ng nh ni mu b"><a class="ae ky" href="https://github.com/pytorch/vision" rel="noopener ugc nofollow" target="_blank">torchvision</a></code>等)的数百个图像嵌入和分类模型...)并接受各种不同技术的训练。Towhee也有许多NLP模型，感谢🤗s <a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变压器</a>库。</p><p id="aabf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们后退一步，看看Towhee是如何在幕后生成这些嵌入的。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1f3d" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; from towhee import pipeline<br/>&gt;&gt;&gt; p = pipeline('image-embedding')<br/>&gt;&gt;&gt; embedding = p('towhee.jpg')</span></pre><p id="ceed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<a class="ae ky" href="https://github.com/towhee-io/towhee" rel="noopener ugc nofollow" target="_blank">到</a>，从监督模型生成嵌入的默认方法是简单地移除最终分类或回归层。对于PyTorch模型，我们可以使用下面的示例代码片段来实现:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="5ad9" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; import torch.nn as nn<br/>&gt;&gt;&gt; import torchvision<br/>&gt;&gt;&gt; resnet50 = torchvision.models.resnet50(pretrained=True)<br/>&gt;&gt;&gt; resnet50_emb = nn.Sequential(*(list(resnet50.children())[:-1]))</span></pre><p id="45ce" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面代码片段中的最后一行重新创建了一个前馈网络(<code class="fe ng nh ni mu b">nn.Sequential</code>)，它由<code class="fe ng nh ni mu b">resnet50</code> ( <code class="fe ng nh ni mu b">resnet50.children()</code>)中除最后一层(<code class="fe ng nh ni mu b">[:-1]</code>)之外的所有层组成。也可以使用相同的层移除方法来生成中间嵌入。对于用对比/三重损失训练的模型或作为自动编码器，该步骤是不必要的。</p><p id="71b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于(对于CV)和<code class="fe ng nh ni mu b"><a class="ae ky" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">transformers</a></code>(对于NLP)的模型也保持了它们自己的方法，使得特征提取变得容易:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="de3a" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; import numpy as np<br/>&gt;&gt;&gt; from PIL import Image<br/>&gt;&gt;&gt; import timm<br/>&gt;&gt;&gt; image = numpy.array(Image.open('towhee.jpg'))<br/>&gt;&gt;&gt; model = timm.models.resnet50(pretrained=True)<br/>&gt;&gt;&gt; embedding = model.forward_features(img)</span><span id="0762" class="my lw it mu b gy nd na l nb nc">&gt;&gt;&gt; from transformers import AutoTokenizer, AutoModel<br/>&gt;&gt;&gt; tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')<br/>&gt;&gt;&gt; model = AutoModel.from_pretrained('bert-base-uncased')<br/>&gt;&gt;&gt; inputs = tokenizer('Hello, world!', return_tensors='pt')<br/>&gt;&gt;&gt; outputs = model(**inputs)<br/>&gt;&gt;&gt; embedding = outputs.last_hidden_state()</span></pre><p id="3108" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Towhee为<code class="fe ng nh ni mu b">timm</code>和<code class="fe ng nh ni mu b">transformers</code>维护包装器:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="9e86" class="my lw it mu b gy mz na l nb nc">&gt;&gt;&gt; import towhee<br/>&gt;&gt;&gt; text_embedding = towhee.dc(['Hello, world!']) \<br/>...     .text_embedding.transformers(model_name='distilbert-base-cased') \<br/>...     .to_list()[0] # same as intro example<br/>...<br/>&gt;&gt;&gt; img_embedding = towhee.glob('towhee.jpg') \<br/>...     .image_decode() \<br/>...     .image_embedding.timm(model_name='resnet50') \<br/>...     .to_list()[0]<br/>...</span></pre><h1 id="e13e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">其他资源</h1><p id="e8c3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">如果您想阅读更多内容或从另一个角度研究这个主题，我整理了一个简短的(非常不完整的)关于嵌入式的其他资源列表:</p><ol class=""><li id="17c0" class="nm nn it lb b lc ld lf lg li no lm np lq nq lu nr ns nt nu bi translated"><a class="ae ky" href="https://milvus.io/docs/v1.1.0/vector.md" rel="noopener ugc nofollow" target="_blank"> Milvus文档</a>提供了嵌入矢量的概述(因为它与存储和矢量数据库相关)。</li><li id="d2bc" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">OpenAI在<a class="ae ky" href="https://beta.openai.com/docs/guides/embeddings" rel="noopener ugc nofollow" target="_blank">文本嵌入</a>上维护页面，您可以查看。</li><li id="ab31" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated"><a class="ae ky" href="https://willkoehrsen.github.io/" rel="noopener ugc nofollow" target="_blank"> Will Koehrsen </a>提供了一个<a class="ae ky" rel="noopener" target="_blank" href="/neural-network-embeddings-explained-4d028e6f0526">嵌入式的伟大概述</a>。它有点过时(2018)，但仍然是一个很好的资源。</li><li id="7de7" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">在<a class="ae ky" href="https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter" rel="noopener ugc nofollow" target="_blank">推特</a>上查看嵌入技术是如何被使用的，以获得推荐。</li><li id="1558" class="nm nn it lb b lc nv lf nw li nx lm ny lq nz lu nr ns nt nu bi translated">反向图像搜索是嵌入向量的许多应用之一。本教程展示了如何在几分钟内建立一个。</li></ol><p id="efc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果这篇文章对你有帮助，请考虑在Twitter上关注我。在接下来的文章中，我将简要介绍相似性搜索和向量索引算法。敬请期待！</p><p id="0edb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ms">原载于2022年4月30日https://frankzliu.com</em><a class="ae ky" href="https://frankzliu.com/blog/understanding-neural-network-embeddings" rel="noopener ugc nofollow" target="_blank"><em class="ms"/></a><em class="ms">。</em></p></div></div>    
</body>
</html>