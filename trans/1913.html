<html>
<head>
<title>The Basics of Neural Networks (Neural Network Series) — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络基础(神经网络系列)——第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-basics-of-neural-networks-neural-network-series-part-1-4419e343b2b#2022-05-03">https://towardsdatascience.com/the-basics-of-neural-networks-neural-network-series-part-1-4419e343b2b#2022-05-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><h1 id="11dd" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">神经网络</h1><p id="a340" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">人工神经网络(ANN)或简称为神经网络(NN)是称为节点的小单元的互连层，这些节点执行数学运算以检测数据中的模式。神经网络算法是以模拟人类神经元工作方式的方式构建的(我们将在文章的最后一节讨论两者之间的联系)。</p><h1 id="90f1" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">定义</h1><p id="147f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">在我们深入探讨之前，下面是我们在讨论神经网络(NNs)时将使用的关键术语。</p><ol class=""><li id="92bb" class="lm ln it kq b kr lo kv lp kz lq ld lr lh ls ll lt lu lv lw bi translated"><strong class="kq iu">神经元</strong> —这是神经网络的基本构建模块。它接受加权值，执行数学计算并产生输出。它也被称为单元、节点或感知器。</li><li id="54a9" class="lm ln it kq b kr lx kv ly kz lz ld ma lh mb ll lt lu lv lw bi translated"><strong class="kq iu">输入</strong> —这是传递给神经元的数据/值。</li><li id="5075" class="lm ln it kq b kr lx kv ly kz lz ld ma lh mb ll lt lu lv lw bi translated"><strong class="kq iu">深度神经网络(DNN) </strong> —这是一个具有许多隐藏层(输入(第一)层和输出(最后)层之间的层)的ANN。</li><li id="cf52" class="lm ln it kq b kr lx kv ly kz lz ld ma lh mb ll lt lu lv lw bi translated"><strong class="kq iu">权重</strong> —这些值解释了任意两个神经元之间连接的强度(重要程度)。</li><li id="e043" class="lm ln it kq b kr lx kv ly kz lz ld ma lh mb ll lt lu lv lw bi translated"><strong class="kq iu">偏差</strong> —是一个常数值，加到输入值和各自权重的乘积之和上。它用于加速或延迟给定节点的激活。</li><li id="b50a" class="lm ln it kq b kr lx kv ly kz lz ld ma lh mb ll lt lu lv lw bi translated"><strong class="kq iu">激活函数</strong> —用于将非线性现象引入神经网络系统。这个特性将允许网络学习更复杂的模式。</li></ol><p id="6377" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated"><strong class="kq iu">注:</strong>权值和偏差是NN中的可训练参数，即网络通过调整这些参数来学习模式，以获得最佳预测。</p><h1 id="13a9" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">人工神经元——一个神经元上的数学运算</h1><p id="96ee" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">人工神经元接受输入值(可以是几个)并为其分配权重。在节点内部，对加权输入进行求和，并应用激活函数来获得结果。该节点的输出被传递到其他节点，或者在网络的最后一层的情况下，该输出是网络的总输出。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mf"><img src="../Images/fda52b506f8c8884b76092cd43fb0da6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qQPpdtR0r1APiEfTqN74aA.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">图1:一个有n个输入值的人工神经元(来源:作者)。</p></figure><p id="efc5" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">如上图所示，单个神经元执行以下数学运算:</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mv"><img src="../Images/291c2bd3dc368b13de306e32a74e9468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hIsDGGwg3dRx9ZlkmMAeDw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">等式1</p></figure><p id="8f2c" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">在这个等式中，发生了四件事情——输入乘以各自的权重并相加，偏差被加到结果中，然后应用激活函数<code class="fe mw mx my mz b">g</code>，使得神经元的输出为<code class="fe mw mx my mz b">g(<strong class="kq iu">w</strong>·<strong class="kq iu">x</strong>+b)</code>。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="25a3" class="jq jr it bd js jt nh jv jw jx ni jz ka kb nj kd ke kf nk kh ki kj nl kl km kn bi translated">神经网络设计</h1><p id="a29f" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">神经网络(NN)是由几个层叠的神经元组成的。对于一个<code class="fe mw mx my mz b">n</code>维输入，第一层(也称为输入层)将有<code class="fe mw mx my mz b">n</code>个节点，而<code class="fe mw mx my mz b">t</code>维最终/输出层将有<code class="fe mw mx my mz b"> t </code>个神经单元。所有中间层都称为隐藏层，网络中的层数决定了模型的深度。下图显示了一个<code class="fe mw mx my mz b">3–4–4–1 </code> NN。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nm"><img src="../Images/d1bfb4f45ad0c87c2b898fa14f4e73cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0n1Qw6VlRwchLKasr6RDMg.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">图2:一个神经网络，有3个输入特征，两个隐藏层，每个层有4个节点和一个值输出。节点是密集连接的——每个节点都连接到上一层的所有神经元。每个连接都具有表示任意两个节点之间的连接强度的权重。除了输入层的节点之外，每个节点都执行等式1中描述的计算(来源:作者)。</p></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><h1 id="994b" class="jq jr it bd js jt nh jv jw jx ni jz ka kb nj kd ke kf nk kh ki kj nl kl km kn bi translated">简化示例</h1><p id="0a7a" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">让我们举一个简单的例子来说明单个神经元是如何工作的。在本例中，我们假设有3个输入值，偏差为0。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/aba5558911c511fd4a77ca6193d8ee4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*lTVm-wYpuIkkwQqL5mN-5A.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">图3:具有3个输入值2、1、-4和权重分别为0.8、0.12和0.3的人工神经网络。在这种情况下，偏置设置为0。</p></figure><p id="5276" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">在这个例子中，我们将考虑一个被称为sigmoid的常用激活函数，它被定义为(我们将在本系列的下一部分中全面讨论激活函数)</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/d97b8e81cd486745dd9f5b342803a9e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*ZRIPXxLoSRvf9gqojz-A0w.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">Sigmoid函数(f(x))及其导数(f'(x))。sigmoid f(x)将任何实数值x推入范围(0，1)。这时不要太在意导数。我们以后再讨论。</p></figure><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/238b22d0935b8c6c068ca375d98abc35.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*6gvU4QFzxP32mpB5dXXC0A.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">这是一个sigmoid图。注意，对于小于-5或大于5的x值，f(x)分别接近0和1。</p></figure><p id="d649" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">如前所述，神经元内部正在发生四件事。首先，通过将输入值乘以相应的权重来对输入值进行加权。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/5ad6e986480daa4e5150969c16fdc263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*rj7DBXGzKPv8W1B3Avylkw.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">第一个操作:输入值被加权。</p></figure><p id="7df5" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">接下来，对加权输入求和，然后加上偏差，</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nr"><img src="../Images/a1559f80482a37f101ad8318b57b561b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dzr54vkIJGd_NSXZ4hkxZw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">第二个操作:加权输入和偏差求和</p></figure><p id="3ea6" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">最后，对上述结果应用sigmoid激活函数</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/a40f8b84f734bc587d19188782f24b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*oyesJX9aotv3V3ynzYrE4Q.png"/></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">第三次手术:应用乙状结肠功能。</p></figure><p id="256d" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">就是这样。神经元的输出是<code class="fe mw mx my mz b">0.627</code>。如果给定的神经元在隐藏层中，则该输出成为下一个神经元的输入。另一方面，如果这个值是最后一层的输出，那么它就可以解释为模型的最终预测(可以看作是给定类的概率)。</p><p id="9dea" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated"><strong class="kq iu">重要提示:</strong>为了简化神经元的数学运算，我们可以使用前两个运算的更紧凑的矩阵形式。在这种情况下，输入值向量和权重向量之间的点积运算将会派上用场。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nt"><img src="../Images/67d22371cae0061fb45ede935b7abecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOWRb0XHUnWNRlrbFe-t7w.png"/></div></div></figure></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="2138" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">如前所述，人工神经元(NN的基本构件)的运行是受人脑工作方式的启发。在下一节中，我们将详细讨论这种关系。</p><h1 id="904f" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">生物神经元与人工神经元的联系</h1><p id="0c23" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">生物大脑中的神经系统由两类细胞组成:神经元和神经胶质细胞。神经胶质细胞为神经系统提供支持功能。具体来说，这些细胞的任务是维持体内平衡，形成隔离神经的髓鞘，并参与信号传递。</p><p id="ad16" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">神经元由细胞体、轴突和树突组成。树突是作为神经元输入的投射。它从其他神经元接收电化学信息，并将它们传播到细胞体。另一方面，轴突是神经元的长延伸，将信息从细胞体传输到其他神经元、腺体和肌肉。轴突以称为轴突小丘的圆锥形投影连接到细胞体。小丘负责将抑制性和兴奋性信号相加，如果总和超过某个阈值，神经元就会发出信号(称为动作电位)。两个神经元在突触处连接。突触位于第一神经元的轴突末梢和第二神经元的树突。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi nu"><img src="../Images/fdd46e2448e1c44dc8ab5d300e37e176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k8EcKHlLMhGM8DGnhqngJw.png"/></div></div><p class="mr ms gj gh gi mt mu bd b be z dk translated">生物神经元(左)和人工神经元(右)。</p></figure><h1 id="f567" class="jq jr it bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">人工神经元</h1><p id="39ad" class="pw-post-body-paragraph ko kp it kq b kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll im bi translated">人工神经元(也称为单元或节点)在结构和功能上模仿生物神经元(从广义上讲，见下一个注释)。人工神经元接受几个输入值(与生物神经元中的树突同义)，并为它们分配权重(类似于突触的作用)。在节点内部，对加权输入进行求和，并应用激活函数来获得结果。这种操作与生物神经元中细胞体和轴突小丘的作用相匹配。该节点的输出被传递到其他单元——这种操作模拟了电化学信息从一个神经元传递到另一个神经元或神经系统的其他部分的过程。</p><p id="dea0" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">注意:在过去的几年里，科学家们开始反对直接描述人工神经网络与生物之间的关系。</p><blockquote class="nv nw nx"><p id="93b5" class="ko kp ny kq b kr lo kt ku kv lp kx ky nz mc lb lc oa md lf lg ob me lj lk ll im bi translated">“事实上，就功能和规模而言，人工神经网络与它们的生物对等物并不相似，然而，它们确实受到BNNs(大脑神经网络)的启发，并且用于描述人工神经网络的几个术语是从神经科学文献中借来的。”——阿格达姆，H.H .和赫拉维，E.J. (2017)。卷积神经网络指南。</p></blockquote></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="9c22" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">我希望这篇文章为神经网络系列的其他部分打下良好的基础。下面是系列文章的下一篇文章。继续读。让我们继续学习<strong class="kq iu">。</strong></p><div class="od oe gp gr of og"><a rel="noopener follow" target="_blank" href="/feed-forward-neural-network-with-example-neural-network-series-part-2-eeca7a081ef5"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd iu gy z fp ol fr fs om fu fw is bi translated">神经网络如何工作—实例(神经网络系列)—第2部分</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">本文将涵盖前馈神经网络(FF-NN)，重点讨论在神经网络内完成的计算</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="oq l or os ot op ou mp og"/></div></div></a></div><p id="d982" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">请<a class="ae oc" href="https://medium.com/@kiprono_65591/membership" rel="noopener">以每月5美元的价格注册成为medium会员</a>，这样就可以在medium上阅读我和其他作者的所有文章。</p><p id="f8d6" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">你也可以<a class="ae oc" href="https://medium.com/subscribe/@kiprono_65591" rel="noopener">订阅，以便在我发表文章的时候把我的文章发到你的邮箱</a>里。</p><p id="9830" class="pw-post-body-paragraph ko kp it kq b kr lo kt ku kv lp kx ky kz mc lb lc ld md lf lg lh me lj lk ll im bi translated">感谢您的阅读！！！</p></div></div>    
</body>
</html>