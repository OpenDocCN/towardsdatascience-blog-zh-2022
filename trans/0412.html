<html>
<head>
<title>Markov Chains: Stationary Distribution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马尔可夫链:平稳分布</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/markov-chains-stationary-distribution-bedd67140112#2022-02-16">https://towardsdatascience.com/markov-chains-stationary-distribution-bedd67140112#2022-02-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c517" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用 Python 模拟解释和推导马尔可夫链的平稳分布</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ac4fca0c8b763debb81f710552315d17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_ZIs1Cwdj7G44Ybe"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·温克勒在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="83b0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="01e3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我以前的文章中，我们开始发展我们对<a class="ae ky" href="https://en.wikipedia.org/wiki/Markov_chain" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">马尔可夫链</strong> </a>的直觉和知识。到目前为止，我们已经讲述了:<a class="ae ky" href="https://en.wikipedia.org/wiki/Markov_property" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">马尔可夫性质、</strong> </a> <strong class="lt iu"> </strong> <a class="ae ky" href="https://en.wikipedia.org/wiki/Stochastic_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">转移矩阵</strong> </a>和<strong class="lt iu">多步转移</strong>利用<a class="ae ky" href="https://en.wikipedia.org/wiki/Chapman%E2%80%93Kolmogorov_equation" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">查普-柯尔莫哥洛夫方程</strong> </a> <strong class="lt iu">。我建议在继续写这篇文章之前通读这些文章:</strong></p><div class="mn mo gp gr mp mq"><a rel="noopener follow" target="_blank" href="/markov-chains-simply-explained-dc77836b47e3"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">马尔可夫链简单地解释了</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">马尔可夫性和马尔可夫链的直观而简单的解释</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">towardsdatascience.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne ks mq"/></div></div></a></div><div class="mn mo gp gr mp mq"><a rel="noopener follow" target="_blank" href="/markov-chains-multi-step-transitions-6772114bcc1d"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">马尔可夫链:多步转移</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">使用 Chapman-Kolmogorov 方程理解马尔可夫链中的多步转移</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">towardsdatascience.com</p></div></div><div class="mz l"><div class="nf l nb nc nd mz ne ks mq"/></div></div></a></div><p id="f365" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">但是，简单总结一下上面的文章:<strong class="lt iu">马尔可夫链是离散时间内有限状态空间中的一系列转移，其中转移的概率只取决于当前状态</strong>。这个系统是完全无记忆的。</p><p id="6179" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated"><strong class="lt iu">转移矩阵</strong>显示状态空间中状态间转移的<strong class="lt iu">概率。<strong class="lt iu">Chapman-Kolmogorov 方程</strong>告诉我们如何计算<strong class="lt iu">多步跃迁概率。</strong></strong></p><p id="fd9a" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">在本文中，我们将讨论当我们采用<strong class="lt iu">大量离散时间步长</strong>时，转移矩阵会发生什么。换句话说，我们将描述马尔可夫链如何随着时间<strong class="lt iu">趋于无穷大而发展。</strong></p><h1 id="eb34" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">马尔可夫链和转移矩阵</h1><p id="cf2a" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，让我们快速回顾一下我以前文章中的内容。下面是一个状态空间为<strong class="lt iu"> <em class="nl"> {A，B，C}的马尔可夫链。</em>T45】</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/726ad42bd4e516d6aea740ec6c276052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vD0UrnDmbbKDghmAXnzM5A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者制作的图像。</p></figure><p id="ed29" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">该马尔可夫链具有以下转移矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0e9eb16404d90703c17c03509d74f796.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*YZX83bGaFLzy9L8NChgWgw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者在 LaTeX 中生成的矩阵。</p></figure><p id="48d8" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">其中每个单元格传达在马尔可夫属性下从状态<strong class="lt iu"> <em class="nl"> i </em> </strong>(行)到状态<strong class="lt iu"><em class="nl"/></strong>(列)<strong class="lt iu"> <em class="nl"> </em> </strong>的转移的概率。然而，该矩阵仅用于单步过渡。如果我们想分两步从<strong class="lt iu"> <em class="nl"> i </em> </strong>到<strong class="lt iu"> <em class="nl"> j </em> </strong>呢？</p><p id="b997" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">这个问题可以通过 Chapman-Kolmogorov 方程来解决，它告诉我们这就是转移矩阵的平方。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/52cb3ee60feec64941e4b760a5c68138.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*2nsv135z7-n79Uq74pmy1g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">由作者在 LaTeX 中生成的矩阵。</p></figure><p id="efdc" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">如果我们想计算三步概率，我们就要对转移矩阵求立方。一般来说对于<strong class="lt iu"> n 步</strong>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/cbed03e628f37ddd323f827858b7ff2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*ptG5IV0ULhe9_E-SVzS5sQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="d2b9" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">现在，随着<strong class="lt iu"> <em class="nl"> n </em> </strong>变大会发生什么？我们接下来会回答这个问题。</p><h1 id="39fc" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">稳定分布</h1><p id="801d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">随着时间的推移，处于某些状态的可能性比其他状态更大。从长远来看，该分布将达到一个<strong class="lt iu">平衡</strong>，并具有处于每个状态的相关概率。这就是所谓的<strong class="lt iu">固定分配</strong>。</p><p id="6b84" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">它是稳定的原因是，如果你将转移矩阵应用于这个给定的分布，结果分布是与之前相同的<strong class="lt iu"/>:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/ea70e27af25b50467d9d691cfde676f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:190/format:webp/1*jbGq6frLhOjKx5l-hI5CcQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="3419" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">其中<strong class="lt iu"> <em class="nl"> π </em> </strong>是某个分布，它是列数等于状态空间中的状态的行向量，而<strong class="lt iu"> <em class="nl"> P </em> </strong>是转移矩阵。</p><h1 id="133a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">特征值分解</h1><p id="c784" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有些人可能会把上面的方程认作是<strong class="lt iu"> <em class="nl"> π </em> </strong>是<strong class="lt iu"> <em class="nl"> P </em> </strong>的一个<strong class="lt iu">特征向量</strong>，其<strong class="lt iu">特征值为 1 </strong>。这确实是真的，所以我们可以用<a class="ae ky" href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">【特征值分解(谱定理)</strong> </a> <strong class="lt iu">来求解。</strong></p><blockquote class="nr ns nt"><p id="9eef" class="lr ls nl lt b lu ng ju lw lx nh jx lz nu ni mc md nv nj mg mh nw nk mk ml mm im bi translated">注意:在这篇文章中，我假设读者已经理解了矩阵的特征值以及如何找到它们。如果没有，我建议阅读一些基础教程来获得一些直觉。</p></blockquote><p id="5dff" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">让我们看看上面的例子马尔可夫链，它有一个<strong class="lt iu"> 3x3 </strong>转移矩阵。根据上面的转换矩阵，我们想要求解下面的等式:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/732f7a8c050a82d7b3bea5de2b528628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*kG3TEfEidBGjffy7pYotcQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="a002" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">其中<strong class="lt iu"> λ </strong>为特征向量对应的<strong class="lt iu">特征值。</strong>利用<a class="ae ky" href="https://en.wikipedia.org/wiki/Rule_of_Sarrus" rel="noopener ugc nofollow" target="_blank"> <strong class="lt iu">三角形法则</strong> </a>，这等于:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/eec77206a6ada77a05a5d8f6ca1f4a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*JzHCxEsHOr4qV3qMKM0ocw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="43a8" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">所以我们的<strong class="lt iu">特征值是 0，-0.5 和 1 </strong>。我们知道我们的解<strong class="lt iu">只在特征值等于 1 </strong>的情况下有效，所以我们现在将使用它来找到我们相应的特征向量，这将是我们的平稳分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/6ad705649f3766769209b4846731d2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WNTnCsJ6d0eZMPFBfcusQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="5bbd" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">这里，<strong class="lt iu">下标指的是当我们有一个稳定分布时，处于相应状态</strong>的概率。上述方程可以通过<strong class="lt iu">高斯消去</strong>求解得到如下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/427817996dffecc7b4d14f986bd1b008.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*bhDdKlfOsIQUsgzKUxBEiQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="2370" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">将上述向量归一化，我们的平稳分布为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ced650d9fe25060d0634c7c7660dbcfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*skvutF0EzSVgcAC0ibKwtw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者在 LaTeX 中生成的方程。</p></figure><p id="b222" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">这意味着从长远来看，我们在这三个州中的任何一个州都有同等的可能性！</p><blockquote class="nr ns nt"><p id="580e" class="lr ls nl lt b lu ng ju lw lx nh jx lz nu ni mc md nv nj mg mh nw nk mk ml mm im bi translated">注意:这不是平稳分布的密集深度推导，因为我不想把它变成教科书！不过网上有很多关于<a class="ae ky" href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix" rel="noopener ugc nofollow" target="_blank">特征值分解的深入例子。</a></p></blockquote><h1 id="46f9" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">Python 模拟</h1><p id="f9a7" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们刚刚展示了理论上的稳定分布，现在我们将使用 Python 中的模拟来根据经验计算它<strong class="lt iu">。</strong></p><p id="91e5" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">下面的代码模拟了开始分布为{1，0，0}的 50 步后处于每个状态的<strong class="lt iu">概率:</strong></p><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="f215" class="oh la it od b gy oi oj l ok ol"># import packages<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="17ba" class="oh la it od b gy om oj l ok ol"># set transition matrix<br/>transition_matrix =  np.array([[0, 0.4, 0.6],<br/>                               [0.5, 0.3, 0.2],<br/>                               [0.5, 0.3, 0.2]])</span><span id="9974" class="oh la it od b gy om oj l ok ol"># set initial distribution<br/>initial_dist = np.array([1,0,0])</span><span id="80a5" class="oh la it od b gy om oj l ok ol"># simulate 50 time steps<br/>for _ in range(50):<br/>    update = initial_dist @ transition_matrix<br/>    initial_dist = update<br/>    <br/>print(initial_dist)</span></pre><p id="6e55" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">输出:</p><pre class="kj kk kl km gt oc od oe of aw og bi"><span id="f55b" class="oh la it od b gy oi oj l ok ol">[0.33333333 0.33333333 0.33333333]</span></pre><p id="cf81" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">这与我们上面推导的平稳分布完全相同！</p><p id="9ed8" class="pw-post-body-paragraph lr ls it lt b lu ng ju lw lx nh jx lz ma ni mc md me nj mg mh mi nk mk ml mm im bi translated">完整代码可以在我的 GitHub 上找到:</p><div class="mn mo gp gr mp mq"><a href="https://github.com/egorhowell/Medium-Articles/blob/main/Statistics/markov_stationary.py" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd iu gy z fp mv fr fs mw fu fw is bi translated">Medium-Articles/Markov _ stationary . py at main egorhowell/Medium-Articles</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">github.com</p></div></div><div class="mz l"><div class="on l nb nc nd mz ne ks mq"/></div></div></a></div><h1 id="637a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">摘要</h1><p id="07ee" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这篇文章中，我们描述了什么是平稳分布，以及如何为马尔可夫链推导出平稳分布。在我的下一篇文章中，我们将讨论马尔可夫链的不同性质。</p><h1 id="e296" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">和我联系！</h1><ul class=""><li id="ca40" class="oo op it lt b lu lv lx ly ma oq me or mi os mm ot ou ov ow bi translated">要在媒体上阅读无限的故事，请务必在这里注册！  <em class="nl"> </em>💜</li><li id="9786" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated"><a class="ae ky" href="/subscribe/@egorhowell" rel="noopener ugc nofollow" target="_blank">T35<em class="nl">T37】😀</em></a></li><li id="b8dc" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated"><a class="ae ky" href="https://www.linkedin.com/in/egor-howell-092a721b3/" rel="noopener ugc nofollow" target="_blank"> <em class="nl">【领英】</em> </a> <em class="nl"> </em>👔</li><li id="a7a0" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated"><a class="ae ky" href="https://twitter.com/EgorHowell" rel="noopener ugc nofollow" target="_blank"> <em class="nl">碎碎念</em> </a> <em class="nl"> </em> 🖊</li><li id="fb18" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated"><a class="ae ky" href="https://github.com/egorhowell" rel="noopener ugc nofollow" target="_blank"><em class="nl">github</em></a><em class="nl"/>🖥</li><li id="87b0" class="oo op it lt b lu ox lx oy ma oz me pa mi pb mm ot ou ov ow bi translated"><a class="ae ky" href="https://www.kaggle.com/egorphysics" rel="noopener ugc nofollow" target="_blank"><em class="nl"/></a><em class="nl"/>🏅</li></ul><blockquote class="nr ns nt"><p id="72f1" class="lr ls nl lt b lu ng ju lw lx nh jx lz nu ni mc md nv nj mg mh nw nk mk ml mm im bi translated">(所有表情符号都是由<a class="ae ky" href="https://openmoji.org/" rel="noopener ugc nofollow" target="_blank"> OpenMoji </a>设计的——开源的表情符号和图标项目。许可证:<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0/#" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a></p></blockquote></div></div>    
</body>
</html>