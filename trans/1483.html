<html>
<head>
<title>Beginner’s Guide to Machine Learning with Big Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据机器学习入门指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beginners-guide-to-machine-learning-with-big-data-d6dbb155673c#2022-04-12">https://towardsdatascience.com/beginners-guide-to-machine-learning-with-big-data-d6dbb155673c#2022-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dcc9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Google Cloud和Spark ML处理大型数据集的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/37b4ba4253fadd37be10cffc27e83bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aUgtqC5Y_-uyD1nZ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">约书亚·索蒂诺在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4ae4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/NateDiR/celestial_body_size_predictor/blob/main/pyspark_model_script.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="ls"> GitHub代码</em> </a></p><p id="885b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">学习数据科学和在专业环境中实践数据科学的最大区别之一是我们正在处理的数据的规模和复杂性。</p><p id="bb32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们第一次开始学习时，我们构建第一个项目所用的数据可能是适度的、干净的、易于理解的。在本地机器上使用第一个数据集很容易，用Pandas进行计算，或者用Matplotlib进行可视化，几乎都是瞬间完成的。</p><p id="d239" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不幸的是，这是一个田园诗般的乌托邦，很少(如果有的话)存在于专业界。随着计算能力(<a class="ae kv" href="https://en.wikipedia.org/wiki/Moore%27s_law" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">)摩尔定律</strong> </a>)和存储容量(<a class="ae kv" href="https://www.techtarget.com/searchstorage/definition/Kryders-Law#:~:text=Kryder's%20Law%20is%20the%20assumption,improves%2C%20storage%20will%20become%20cheaper." rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">克莱德定律</strong> </a>)的效率提高和价格下降，企业能够存储、分析和利用的数据比以往任何时候都多。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/ba643c8b0934e5811fc956fbebdd4803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g0VrVEO7iD3bTYVYCSBulA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">摩尔定律图。1970–2020.图片来自维基百科。</p></figure><p id="8564" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为一名新晋的数据科学家，与我们所学的规模适中的数据集相比，处理不太适合本地机器的数据是一个巨大的变化。我们每个人都曾在某个时候试图将一个巨大的数据集加载到熊猫中，并耐心等待，只为内核在抗议中死去。幸运的是，当这种情况发生时，我们有选择！</p><p id="0d37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，我们将讨论两种用于处理海量数据集的常用工具— <a class="ae kv" href="https://cloud.google.com/storage" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">谷歌云存储</strong> </a>和<a class="ae kv" href="https://databricks.com/spark/about" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">Apache Spark</strong></a><strong class="ky ir">。</strong>一旦我们为这些解决方案建立了一个概念基线，我们将通过一个例子来使用存储在Google Cloud中的大型数据集和SparkML的建模功能创建一个基本的回归模型。让我们实现它吧！</p><h1 id="1af7" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">什么是“大”数据？</h1><p id="1723" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在深入了解Spark和GCS之前，让我们先了解一下“大数据”到底是什么。我能想到的最一致的大数据定义如下:<strong class="ky ir">无意义的行话</strong>。</p><p id="3734" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大数据的<em class="ls">概念</em>是一个移动的目标。正如我之前提到摩尔定律和克莱德定律时提到的那样，对更高数量的计算和存储容量的相对可访问性正以大约每两年2倍的速度增长。这意味着2年前的“大数据”按照目前的标准可能还不算大，10年前的“大数据”对于现代机器来说可能微不足道。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/30d1b333957ee9f3f0370bffeb7a5b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e9voIDI1JlFqBSig"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@tama66?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">彼得·赫尔曼</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="f5ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">“大数据”也完全特定于个体数据从业者。判断某样东西是否是大数据的一个简单的经验法则是，它是否适合你的<strong class="ky ir">电脑，而如今电脑有各种不同的配置——我的MacBook有16 GB的内存，8核英特尔处理器和1 TB的磁盘存储。我的Windows桌面有64 GB内存，16核英特尔处理器，12 TB磁盘存储(加上一个GPU下次再说)。可以理解的是，这些机器可以处理不同数量的数据。</strong></p><p id="18b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为个人电脑有如此多不同的风格，我们需要在单个项目中使用大数据技术的情况将取决于我们所拥有的能力。</p><p id="e28f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但一般来说，有企业级数据需求的公司也买得起企业级机器。有时，公司的需求超过了任何一台机器能够提供的能力，无论是计算能力还是磁盘存储。当这种情况发生时，像<strong class="ky ir">谷歌云存储</strong>和<strong class="ky ir"> Spark </strong>这样的解决方案开始发挥作用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/538f50f2c58f643367a8b036cfd98b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sRjMOJljW7-GA3Tc"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Jakub Skafiriak 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="c1cf" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">火花</h1><p id="7948" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">最基本的，Spark是一个开源项目，旨在帮助跨<strong class="ky ir">集群并行处理大量数据。</strong>什么是集群？想想你的电脑。现在想一想你的两台电脑。我们可以将这些计算机连接起来，将磁盘空间、计算能力和内存容量集中到一台“计算机”中，用它来做事情。这是一个(非常基本的)集群。</p><p id="12d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark帮助我们跨集群执行数据处理任务。为了做到这一点，Spark创建了一个<strong class="ky ir">有向无环图</strong> (DAG)，作为数据如何转换的“行动计划”。Spark不是存储这个行动计划的结果，而是将行动计划本身存储在内存中，并且直到它被明确告知要持久化它时才存储结果。这是与熊猫等工具的主要区别之一。</p><p id="b70d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark和传统工具的另一个主要区别是Spark使用<strong class="ky ir">分布</strong>和<strong class="ky ir">并行的方式。</strong>正如我前面提到的，Spark的主要功能是帮助我们跨集群执行数据处理任务。Spark在这项任务上比传统工具更高效的部分原因是它使用了分布式存储和并行计算。</p><p id="b4a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Pandas、NumPy和其他核心Python库针对单核计算进行了优化，而Spark则利用它创建的Dag来寻找完成给定任务的最佳计算路线。</p><p id="6ed3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">回想一下，集群是我们的两台笔记本电脑相互连接，作为一台“计算机”使用。当我们利用Spark处理数据时，Spark将获取“大块”数据(默认为128 MB)，并将它们存储在集群的多个位置。将你的数据分成更小的片段并存储在集群中的过程被称为<strong class="ky ir">数据分片</strong>。我们对数据进行分片，并将每个分片存储在集群的多个位置，以实现冗余性和弹性。值得一提的是，Spark的分布式存储方法是<strong class="ky ir"> Hadoop分布式文件系统(HDFS)的一个分支，</strong>了解Hadoop和HDFS是什么是值得的，但我们不会在这里深入讨论。</p><p id="54db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与Spark分布数据存储的方式非常相似，它也分布您想要在数据上运行的计算，并并行执行它们。正如我上面提到的，像Pandas和NumPy这样的Python库默认使用单个CPU内核运行。另一方面，Spark使用机器上的所有内核。在集群环境中，这意味着Spark会将您的数据分解成更小的碎片，然后在每个碎片上并行执行计算，如果您使用传统的数据操作工具，这将大大减少获得结果所需的时间。</p><p id="ba62" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后值得一提的是，Spark可以部署在单台机器上(比如您的笔记本电脑)。这样做的好处是，它可以更有效地利用您的RAM，并在可能的情况下跨所有CPU内核并行化计算。如果您的数据集特别大，Spark也会将它从RAM溢出到磁盘，尽管这会影响性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/bedf482d6b34df5522c0735b23c62105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rJR-fh0Xi0fvXUBD"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae kv" href="https://unsplash.com/@dannyeve?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Daoudi Aissa </a>拍摄的照片</p></figure><h1 id="ba15" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">谷歌云存储</h1><p id="b969" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">现在我们已经了解了如何用Spark处理数据，下一个问题是我们将在哪里存储数据。处理存储在本地的大型数据集会很快耗尽你的磁盘空间，像GitHub或Google Drive这样的选项不适合处理超过几百MB的文件。进入谷歌云存储。</p><p id="09ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谷歌云存储是一个基于云的<strong class="ky ir">对象存储服务</strong>。在不涉及太多技术细节的情况下，对象存储意味着将非结构化对象存储在一个易于访问的地方。对象通常包括数据本身、关于对象的一些元数据以及使其区别于其他对象的唯一标识符。例如，将对象存储与数据库进行对比。对象存储对于需要经常更改的事务性数据来说并不理想。但它在这里会工作得很好。</p><p id="ccb2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有主要的云提供商都提供对象存储<strong class="ky ir"/>——亚马逊S3、Azure Blob存储、谷歌云存储..都一样。一般来说，云的好处在于它的可伸缩性和高正常运行时间。这是什么意思？当您的硬盘空间已满时，您需要删除一些项目来添加更多内容，或者购买额外的驱动器。当使用云服务时，你基本上是租用你的提供商的计算能力和磁盘存储。如果您需要的比您目前拥有的更多，您的提供商会自动调整您的资源。从这个意义上说，云服务是无限可扩展的(实际上来说)。</p><p id="d750" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样，云服务也极具弹性。凭借这些公司的全球基础设施足迹，您可以放心，您的数据不会在云中丢失(除非发生一些灾难性事件，但您可能会遇到更大的问题)。如果您的本地机器死机，您的数据可能无法恢复。如果云提供商的一部分基础设施出现故障，有许多级别的冗余和故障转移功能来保持您的数据随时可用。</p><p id="627e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我没有提到云服务是要花钱的，那我就失职了。每个主要的提供商都有一个免费层，并提供一些积分让你开始使用一个新帐户，但当使用云服务时，很容易积累大量的账单。<strong class="ky ir">如果您正在使用云服务，请始终关注您的计费中心报告并设置预算限制</strong>！</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="e298" class="lu lv iq bd lw lx nb lz ma mb nc md me jw nd jx mg jz ne ka mi kc nf kd mk ml bi translated">设置</h1><p id="4f19" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">现在我们对Spark和Google云存储有了一个概念性的了解，让我们在一个简单的演示中让它们为我们工作。下面，我将介绍清理存储在谷歌云存储中的大型数据集的过程，并使用Spark建立梯度增强回归模型。但是在我开始之前，让我们先看一下在开始编码之前需要完成的先决步骤。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/a2f6ac295175981d6397bffe47b5e6e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_QZqqAsICi22WL76"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">维克多·塔拉舒克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h2 id="d21c" class="nh lv iq bd lw ni nj dn ma nk nl dp me lf nm nn mg lj no np mi ln nq nr mk ns bi translated">数据</h2><p id="211e" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">对于这个例子，我使用的数据来自加州理工学院美国宇航局喷气推进实验室。他们维护着<a class="ae kv" href="https://ssd.jpl.nasa.gov/tools/sbdb_query.html" rel="noopener ugc nofollow" target="_blank">小天体数据库</a>，这是一个包含超过120万个太阳系已知小行星观测数据的数据集。每一次观测都包含30多个特征，我们将使用这些数据来尝试使用SparkML预测小行星的直径。该数据集是免费供公众使用的，对于一个适度的“大数据”项目来说是一个很好的选择，所以去看看吧。</p><h2 id="7e25" class="nh lv iq bd lw ni nj dn ma nk nl dp me lf nm nn mg lj no np mi ln nq nr mk ns bi translated">Google云设置</h2><p id="d419" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">如果我们要使用云存储，我们需要设置一个谷歌云账户。</p><ol class=""><li id="915e" class="nt nu iq ky b kz la lc ld lf nv lj nw ln nx lr ny nz oa ob bi translated">导航到谷歌云<a class="ae kv" href="https://cloud.google.com/free" rel="noopener ugc nofollow" target="_blank">注册页面</a>，使用你的谷歌账户创建一个GCP账户。公平的警告:创建帐户时，您需要提供一张信用卡。前90天你还可以获得300美元的积分，所以你不应该马上被收费。</li><li id="e224" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">创建GCP账户后，导航至<a class="ae kv" href="http://console.cloud.google.com" rel="noopener ugc nofollow" target="_blank">谷歌云控制台</a>。它应该是这样的:</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/7a87dc0f879976176b96318b6959a42a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_8YsYMCJy3hrMI30yyfhGw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">谷歌云控制台。图片作者。</p></figure><p id="23c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">3.从Google Cloud主页，进入左侧边栏的<strong class="ky ir">云存储</strong>选项:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/a01575e3f21f5d2acbcad7d0b0f764d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*BxBhHChRE-h1tDHhKmMMNw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="6ccd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">4.在谷歌云存储上，点击<strong class="ky ir">‘创建一个存储桶’</strong>。这将带您进入如下页面:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/cab635c67e14eb95bb9a12b3f2a11743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WrhFiAlc-HdaYcfa-J1MA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="3959" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">命名您的存储桶，选择您所在的地区，并决定您要为您的数据使用哪种存储类别。访问管理是保持公司云实例安全的一个非常重要的方面，但是对于初次尝试使用个人云实例的人来说，粒度IAM就不太需要了。统一访问和Google管理的密钥是访问和保护的良好选择。</p><p id="8efb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在此页面的右侧，您应该会看到以GB/月为基础的存储桶价格估算。这一点值得注意，因为一旦你的信用用完或90天试用期结束，这将是保持水桶运行的成本。</p><p id="b483" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">5.一旦您创建了您的bucket，我们就需要获得一个访问键来在我们的代码中使用，以便我们能够访问我们的云实例上的数据。打开左上角的<strong class="ky ir">导航菜单</strong>(三个横条)，点击出现的侧边栏中的<strong class="ky ir"> IAM &amp; Admin </strong>，然后点击<strong class="ky ir">服务账户</strong>。你应该在这样的页面上:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/e2021d8a7edd063bf5da19294dcf0e08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9kMS5rvmmsM1ZlzVUTGl5g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="2567" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创建一个服务帐户，并给它起一个合适的名字。在第2步中，我们希望授予该服务帐户对我们的存储对象的访问权限，因此使用下拉菜单授予它该级别的权限。找到<strong class="ky ir">云存储</strong>选项，然后<strong class="ky ir">存储对象管理</strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/fb0b639baa1bfb4da0988f4e62199a24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MRQ7wsDapI5UotREIY7nUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="5cd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成服务帐户创建过程，应该会返回到包含新创建的服务帐户的表。点击<strong class="ky ir">账户ID </strong>访问详细信息，然后点击顶部的<strong class="ky ir">【密钥】</strong>选项卡。应该是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/7d774828d76dd9dd056d8e20ebce5567.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s0K6EE-WAtc0Eh0FBQylRg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="8587" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">点击<strong class="ky ir">‘添加密钥’&gt;‘创建新密钥’&gt;JSON。</strong>这会自动将密钥下载到您的本地机器。保持这个安全！非常注意你的密匙最终在哪里，例如，永远不要在GitHub repo上公开发布它。我们将介绍如何将它们隐藏在下面。</p><h2 id="70ad" class="nh lv iq bd lw ni nj dn ma nk nl dp me lf nm nn mg lj no np mi ln nq nr mk ns bi translated">加载数据</h2><p id="7c79" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">下载完密钥后，返回云存储页面并创建一个存储桶。恰当地命名。在那里，创建一个文件夹，并将您的数据添加到该文件夹中。我下载了。csv格式的小行星数据来自JPL网站，创建了一个桶，一个名为小行星的文件夹，并上传了。csv到文件夹中，然后从我的本地机器上删除它。这是一个简单的过程，与Google Drive上传没有什么不同，所以应该不会有任何问题。</p><h2 id="94b5" class="nh lv iq bd lw ni nj dn ma nk nl dp me lf nm nn mg lj no np mi ln nq nr mk ns bi translated">火花设置</h2><p id="aab9" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">现在我们已经设置好了Google云存储，是时候在我们的机器上安装Spark了。在Mac上安装Spark需要自制。如果你还没有安装家酿软件，请按照这里的<a class="ae kv" href="https://brew.sh/" rel="noopener ugc nofollow" target="_blank">指示进行安装。</a></p><p id="a6ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦安装了homebrew，我们将使用它来安装Spark及其依赖项。在命令行提示符下输入以下内容:</p><pre class="kg kh ki kj gt oj ok ol om aw on bi"><span id="be89" class="nh lv iq ok b gy oo op l oq or">brew install java scala apache-spark</span></pre><p id="58d1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们需要为Spark安装Python包装器，<strong class="ky ir"> PySpark。</strong>根据您使用的是本地级别的Python还是conda环境，您可以执行以下任一操作:</p><pre class="kg kh ki kj gt oj ok ol om aw on bi"><span id="b77c" class="nh lv iq ok b gy oo op l oq or">pip install pyspark</span><span id="afda" class="nh lv iq ok b gy os op l oq or">conda install -c conda-forge pyspark</span></pre><p id="cf10" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">打开一个新的终端窗口。如果一切正常，输入命令“pyspark”应该会启动一个spark实例(注意:如果您使用的是conda，请在测试pyspark之前激活conda环境)。</p><p id="9795" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果在命令行中一切正常，请尝试在iPython环境或jupyter笔记本中激活Spark:</p><pre class="kg kh ki kj gt oj ok ol om aw on bi"><span id="62c5" class="nh lv iq ok b gy oo op l oq or">import pyspark  <br/>spark = pyspark.sql.SparkSession.builder.getOrCreate()</span></pre><p id="0d78" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果这也正常工作，您就可以开始工作了。如果没有，请对您的问题发表评论。通常归结为Java安装和/或路径变量的问题。</p></div><div class="ab cl mu mv hu mw" role="separator"><span class="mx bw bk my mz na"/><span class="mx bw bk my mz na"/><span class="mx bw bk my mz"/></div><div class="ij ik il im in"><h1 id="de27" class="lu lv iq bd lw lx nb lz ma mb nc md me jw nd jx mg jz ne ka mi kc nf kd mk ml bi translated">代码走查</h1><p id="dcf1" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">此时，我们已经将我们的小行星数据存储在Google Cloud中，将我们的Google Cloud密匙存储在我们的本地机器上，并且已经安装了Spark/PySpark，可以使用了。我们应该有开始编码所需的一切。让我们看一下我们将要使用的库:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="408e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦导入了我们需要的所有内容，我们需要创建一个配置为与Google Cloud协同工作的Spark会话:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="4ebe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里要注意两件事:首先，你应该设置你的内存配置来匹配你的机器。第二，我们如何指定我们想要对Spark实例使用Google Cloud service帐户密钥文件，并指定secrets.json文件包含相关信息。</p><p id="d9ea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里发生的事情是，我在前面的步骤中从Google Cloud下载了密钥文件，将其添加到GitHub repository文件夹，然后将其添加到。gitignore文件，这样它就不会提交到我的公共存储库中。我还将其重命名为secrets.json，以便在代码中更容易指向它。因为我编写的Jupyter文件在同一个文件夹中，所以我可以参考secrets.json文件来获得我的Google云服务帐户凭证。</p><p id="c46c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我需要阅读。我将GCS中的csv文件存储到Spark中:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="edbb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了再次检查一切是否正常，让我们以熊猫的方式预览一下数据:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="eec6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然Spark在Pandas中很容易查看，但我们不会用典型的Pandas语法进行数据操作。Spark有自己的语法，更符合SQL，并且经常在使用Spar查询大型数据集时，它被用作SQL查询的包装器。让我告诉你我的意思:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="08ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们使用createOrReplaceTempView命令将数据帧注册为关系表，然后使用普通的SQL查询对其进行查询。输出将是Spark数据帧形式的前20个结果。</p><p id="017f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Spark中有许多处理数据的方法，网上有大量的资源可以帮助您理解它们。我最后要提到的是。printSchema()，它生成数据集中存在的列和每一列的数据类型的读数。这很重要，因为我们需要将数据以特定的格式传递给SparkML，所以在整个代码中打印模式来确认进度是很方便的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="a876" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我不想进入特性工程领域，所以我只是删除了包含大量NaN的列，并更改了数据类型，为建模做准备。这些变化使我的数据集从120万行减少到大约12万行:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="c33d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我将“neo”和“pha”列更改为True/False，将它们转换为“boolean”，然后将它们转换为“integers”。这只是二进制编码。这些列中的真/假值现在表示为1和0。</p><p id="75cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一件值得注意的事情是，Spark的首选数据类型是“double ”,有点像长浮点型。SparkML中的许多模型需要“double”数据类型作为输入，所以我们在这段代码中也将floats改为double。</p><p id="60ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦我们所有的其他特性都为建模做好了准备，我们就需要使用Spark的StringIndexer、OneHotEncoder和Pipeline类对分类变量进行编码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="ca1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成后，我们可以删除原来的列，并重新排序我们的数据框架:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="0894" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将我们的数据分成训练集、验证集和测试集(删除name列):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="bb9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还必须将所有特征打包到一个向量中。这是在Spark中创建模型的奇怪之处之一。您需要使用VectorAssembler()类将所有的特性列打包成一个向量，并将其输入Spark模型:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="e40f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后(并非绝对必要)，我们需要扩展我们的功能:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="893a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经为建模做好了准备，让我们用SparkML中几种不同的回归方法进行实例化、拟合和预测:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="2868" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们来评估这三种模型的性能:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="dfbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据结果，梯度推进回归的表现最好，R2得分为0.47，均方根误差约为7.1 km，因此让我们尝试使用网格搜索和交叉验证来优化模型:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="e225" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们需要从交叉验证器中提取我们的最佳模型。通过下面的代码，我们还可以看到我们的模型的特性重要性:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="f019" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，让我们使用优化的GBT模型对我们的测试集进行预测，并看看它与我们的初始模型结果相比如何:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot ou l"/></div></figure><p id="2b90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">应该会产生这样的结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/41127fd4ae18e6207851690d08485445.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*d-i20Jmlmi6itpvvPClKtQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><h1 id="d97f" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">结论</h1><p id="356e" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf mo lh li lj mp ll lm ln mq lp lq lr ij bi translated">在这篇文章中，我开始提供对Spark和Google云存储的概念性理解，以及使用这两者创建机器学习模型的实际例子。</p><p id="176e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如模型的结果所示，可以对数据做一些额外的工作(提示:异常值)，但重点不是创建一个最佳模型，而仅仅是为可能刚开始工作的人展示工作流程。</p><p id="b63d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，我们处理大型数据集的方式与我们从学习到实践的转变可能会用到的方式不同。在我们做出这种改变时，重要的是我们要开始考虑针对您的特定问题的最佳解决方案路径——我们可以通过许多其他方式来完成这项任务，例如对数据进行采样。通常，你所拥有的工具将取决于你工作的公司，所以保持灵活性，并对各种工具有一个工作理解是值得的。如果你有任何关于GCP或使用Spark的问题，请随时给我留言。下次见！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/86b1b2eed4a6bec20c8eb3f712f972e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pZByT5qdcuZbHCIi"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">亨特·哈里特在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure></div></div>    
</body>
</html>