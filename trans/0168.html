<html>
<head>
<title>Building a CycleGAN model with Custom Dataset using Tensorflow 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tensorflow 2构建带有自定义数据集的CycleGAN模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-cyclegan-model-with-custom-dataset-using-tensorflow-2-12d66be16378#2022-02-07">https://towardsdatascience.com/building-a-cyclegan-model-with-custom-dataset-using-tensorflow-2-12d66be16378#2022-02-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="d76f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">展开拥抱脸空间</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/968ba3a30e4984ac47b5d57d691968b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*eg8OE1RDb0pM5aEQfTcv2A.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图片来源:作者</p></figure><p id="2826" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">生成对抗网络是机器学习中的一种生成建模技术。在GAN中，两个不同的神经网络(生成器和鉴别器)相互竞争。生成器的输出虽然是合成的，但可能接近真实。</p><p id="c8c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有许多不同的甘<a class="ae lq" href="https://neptune.ai/blog/6-gan-architectures" rel="noopener ugc nofollow" target="_blank">架构</a>。今天，我们将关注CycleGAN。cycleGAN的有趣之处在于，它是一种不成对的图像到图像翻译技术。</p><p id="1842" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这项工作中，我们将研究一个在自定义数据集上训练和部署cycleGAN模型的端到端示例。你可以在这里找到可用的CycleGAN代码(使用Tensorflow 2) <a class="ae lq" href="https://www.kaggle.com/amyjang/monet-cyclegan-tutorial" rel="noopener ugc nofollow" target="_blank">，所以我不会重复我们已经有的。相反，我想重点关注几个重要的缺失部分，这些部分是你在现实生活的深度学习项目中需要的——使用定制数据。评估GAN模型，使用已经训练好的模型进行预测，最后创建一个有趣的演示！！</a></p><p id="992a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此，这项工作的贡献可以概括为—</p><ul class=""><li id="ec3d" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">使用自定义图像数据创建张量流数据集</li><li id="6ca4" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">计算FID分数以评估GAN模型</li><li id="299c" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">保存和加载模型</li><li id="d525" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">在拥抱面空间展开模型</li></ul><p id="a778" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">玩得开心点。</p><p id="7f79" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">使用自定义图像数据创建张量流数据集:</strong></p><p id="b04a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了在Tensorflow中训练我们的模型，我们需要Tensorflow数据集格式的训练数据集——公开为<code class="fe mf mg mh mi b">tf.data.Datasets</code>。<code class="fe mf mg mh mi b">tf.data.Datasets</code>中的每个元素可以由一个或多个元素组成。例如，图像管道中的单个元素可以是表示图像及其标签的一对张量。在我们的示例中，我们将以TFRecord格式表示图像，这是Tensorflow自己的二进制记录格式。使用TFRecord格式有几个好处</p><ul class=""><li id="11bd" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">这是一种二进制格式，因此占用的磁盘空间和内存的读/写时间更少</li><li id="52fa" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">使用TFRecord，可以将多个数据集组合成一个数据集。例如，在这项工作中，我们将多个图像组合成一个TFRecord。这个组合记录很好地集成到了<code class="fe mf mg mh mi b">tf.data.Datasets</code>的数据加载和预处理功能中。这在加载非常大的数据集时特别有用，数据集库可以只加载TFRecord的必要部分进行处理，而不是将整个数据集加载到内存中。</li><li id="bbd4" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">您可以在TFRecord中存储序列数据，例如单词嵌入或时间序列数据。</li></ul><p id="b3ab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">TFRecord的一个缺点是——创建TFRecord并不简单——至少对我来说是这样:)</p><p id="5eff" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，我们需要定义一个描述TFRecord组件的字典。例如，对于一个图像分类问题(有监督的)，您可能有一个<code class="fe mf mg mh mi b">image</code>和一个<code class="fe mf mg mh mi b">label</code>。因为我们正在研究一个cycleGAN模型，我们不需要一个<code class="fe mf mg mh mi b">label</code>,因为它本质上是无人监管的。</p><pre class="kj kk kl km gt mj mi mk ml aw mm bi"><span id="8a01" class="mn mo it mi b gy mp mq l mr ms">feature = {<br/> ‘image’: _bytes_feature(image),<br/> }</span></pre><p id="81e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这里，<code class="fe mf mg mh mi b">_bytes_feature</code>是一个私有方法，它从一个字符串/字节返回一个字节列表</p><pre class="kj kk kl km gt mj mi mk ml aw mm bi"><span id="9280" class="mn mo it mi b gy mp mq l mr ms">def _bytes_feature(value):<br/> “””Returns a bytes_list from a string / byte.”””<br/> if isinstance(value, type(tf.constant(0))):<br/> value = value.numpy() <br/> return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span></pre><p id="1b0c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦我们有了TFRecord，我们如何知道记录实际上是正确创建的呢？我们可以计算每个TFRecord中的项目数(记住——我们在一个TF record中有多个图像)。我们还可以可视化整个数据集。</p><pre class="kj kk kl km gt mj mi mk ml aw mm bi"><span id="5456" class="mn mo it mi b gy mp mq l mr ms">FILENAMES = tf.io.gfile.glob('cat*.tfrec')<br/>print(f'TFRecords files: {FILENAMES}')<br/>print(f'Created image samples: {count_data_items(FILENAMES)}')</span><span id="27ed" class="mn mo it mi b gy mt mq l mr ms">display_samples(load_dataset(FILENAMES, *IMAGE_SIZE).batch(1), 2, 5)</span></pre><p id="16d5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意<code class="fe mf mg mh mi b">display_samples</code>函数调用中的<code class="fe mf mg mh mi b">2</code>和<code class="fe mf mg mh mi b">5</code>这两个数字。这些数字表示行数和列数。将行数乘以列数得到数据集中图像的总数。因此，它需要与您的数据集大小相匹配。</p><p id="9aaf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于自定义数据集创建的端到端代码，请参见<a class="ae lq" href="https://gist.github.com/nahidalam/38bb8d4677440d17ff020ffb0c2ea009" rel="noopener ugc nofollow" target="_blank">这里的</a></p><p id="a884" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">评估GAN模型</strong></p><p id="47a7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">没有单一的指标来评估GAN模型。根据用例，您可能想要使用定量和定性指标的组合。</p><p id="7c46" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在我们的工作中，我们将使用FID评分。Frechet初始距离(FID)度量生成图像和真实图像的特征之间的距离。FID越低越好。如果FID为0，则表示两幅图像相同</p><p id="0bf1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">那么我们如何计算FID分数呢？tldr</p><ul class=""><li id="56ca" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">使用预训练的Inception V3模型，删除最后一层</li><li id="c93a" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">生成两幅图像(生成的和真实的)的特征向量。向量大小将是2，048</li><li id="0421" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">然后使用<a class="ae lq" href="https://arxiv.org/pdf/1907.08175.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中描述的等式1计算FID分数</li></ul><p id="c632" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">FID的一些<em class="mu">缺点</em>要记住</p><ul class=""><li id="94db" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">FID使用一个预训练的初始模型，它的特征向量可能不能捕获你的用例的必要特征。</li><li id="c48f" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">为了更好地工作，FID需要大的样本量。建议的最小样本量为10，000</li></ul><p id="ed80" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您想了解更多关于如何计算FID分数的信息，请参考<a class="ae lq" href="https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/" rel="noopener ugc nofollow" target="_blank">这里的</a></p><p id="1d76" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">保存并加载模型:</strong></p><p id="5360" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">训练完模型后，我们想要保存它(假设我们对训练/验证损失和评估满意)。在保存模型时，我们希望确保保存了整个模型。</p><p id="f206" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们所说的<em class="mu">整个模型</em>是什么意思？</p><ul class=""><li id="4afb" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">模型的架构/配置、重量</li><li id="f06f" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">模型的优化器状态和</li><li id="308a" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">模型的编译信息(如果。调用了compile()</li></ul><p id="bc05" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们想要保存整个模型，因为—</p><ul class=""><li id="ccd2" class="lr ls it kw b kx ky la lb ld lt lh lu ll lv lp lw lx ly lz bi translated">在推理过程中，您不需要模型架构代码。这样你会有一个干净的推理逻辑，更快的开发周期。</li><li id="0a21" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp lw lx ly lz bi translated">如果您想要转换用于边缘设备(TFLite)的模型，或者想要使用Tensorflow.js在浏览器中运行模型，您需要拥有整个模型</li></ul><p id="f114" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有几种方法可以保存整个模型。对于Tensorflow 2，我更喜欢<em class="mu"> SavedModel </em>格式。可以用Keras的<code class="fe mf mg mh mi b">model.save</code>方法，也可以用Tensorflow的<code class="fe mf mg mh mi b">tf.keras.models.save_model</code>方法。在<code class="fe mf mg mh mi b">model.save()</code>函数中，如果你使用一个字符串作为参数，你的模型将被保存为<code class="fe mf mg mh mi b">SavedModel</code>格式。</p><pre class="kj kk kl km gt mj mi mk ml aw mm bi"><span id="e239" class="mn mo it mi b gy mp mq l mr ms">model.save('art_generator')</span></pre><p id="9c6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">在拥抱面部空间展开:</strong></p><p id="56c6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经保存了模型，我们可以编写推理逻辑并部署它供人们使用。对于这个项目，我已经在拥抱面部空间<a class="ae lq" href="https://huggingface.co/spaces/nahidalam/meow" rel="noopener ugc nofollow" target="_blank">这里</a>部署了模型。如果你访问那个<a class="ae lq" href="https://huggingface.co/spaces/nahidalam/meow" rel="noopener ugc nofollow" target="_blank">链接</a>，你会看到这样的东西——</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/b6f3016c5780beb56810a7ab6e273057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lbs9QZBQpLiwZRHbk6KZPA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">拥抱面部空间的示例应用程序</p></figure><p id="2d97" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在那里，你可以上传你的<code class="fe mf mg mh mi b">cat</code>照片(或任何其他宠物)，按下<code class="fe mf mg mh mi b">submit</code>按钮，等待10秒钟就可以看到猫<code class="fe mf mg mh mi b">art</code>了，如下图所示</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi na"><img src="../Images/1ee88b25034a019776b78abf938b10b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3INP4idV2brMbYuETXvyHA.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">照片到艺术</p></figure><p id="bf1f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可能会意识到，我需要更多的迭代来提高艺术的质量。但尽管如此，这是一个有趣的应用程序玩！</p><p id="dab0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">关于如何在拥抱面部空间部署模型的细节可以在<a class="ae lq" href="https://huggingface.co/docs/hub/spaces" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="2b26" class="mn mo it bd nb nc nd dn ne nf ng dp nh ld ni nj nk lh nl nm nn ll no np nq nr bi translated">参考资料:</h2><ol class=""><li id="26c1" class="lr ls it kw b kx ns la nt ld nu lh nv ll nw lp nx lx ly lz bi translated"><a class="ae lq" href="https://developers.google.com/machine-learning/gan" rel="noopener ugc nofollow" target="_blank">https://developers.google.com/machine-learning/gan</a></li><li id="b027" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">关于TF record<a class="ae lq" href="https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564" rel="noopener">https://medium . com/mosely-ai/tensor flow-records-what-them-and-how-to-use-them-c 46 BC 4 BBB 564</a>的详细信息</li><li id="ec01" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">如何评价甘模式<a class="ae lq" href="https://machinelearningmastery.com/how-to-evaluate-generative-adversarial-networks/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-evaluate-generative-adversarial-networks/</a></li><li id="2b40" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">卡格尔·周期根的例子<a class="ae lq" href="https://www.kaggle.com/amyjang/monet-cyclegan-tutorial" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/amyjang/monet-cyclegan-tutorial</a></li><li id="2130" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">如何计算FID分数<a class="ae lq" href="https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-implementing-the-frechet-inception-distance-FID-from-scratch/</a></li><li id="6835" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">如何保存和加载Tensorflow模型<a class="ae lq" href="https://medium.com/deep-learning-with-keras/save-load-keras-models-with-custom-layers-8f55ba9183d2" rel="noopener">https://medium . com/deep-learning-with-keras/save-load-keras-models-with-custom-layers-8f 55 ba 9183 D2</a></li><li id="c9ba" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">关于评估GAN模型的详细信息<a class="ae lq" href="https://wandb.ai/ayush-thakur/gan-evaluation/reports/How-to-Evaluate-GANs-using-Frechet-Inception-Distance-FID---Vmlldzo0MTAxOTI" rel="noopener ugc nofollow" target="_blank">https://wandb . ai/ayush-tha kur/GAN-evaluation/reports/How-to-evaluation-GANs-using-frech et-Inception-Distance-FID-vmlldzo 0 mtaxoti</a></li><li id="93d8" class="lr ls it kw b kx ma la mb ld mc lh md ll me lp nx lx ly lz bi translated">在拥抱面部空间展开你的模型<a class="ae lq" href="https://huggingface.co/docs/hub/spaces" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/docs/hub/spaces</a></li></ol></div></div>    
</body>
</html>