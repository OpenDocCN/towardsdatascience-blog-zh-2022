<html>
<head>
<title>3 Techniques for Building a Machine Learning Regression Model from a Multivariate Nonlinear Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3从多元非线性数据集构建机器学习回归模型的技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-techniques-for-building-a-machine-learning-regression-model-from-a-multivariate-nonlinear-dataset-88b25fc24ad5#2022-08-24">https://towardsdatascience.com/3-techniques-for-building-a-machine-learning-regression-model-from-a-multivariate-nonlinear-dataset-88b25fc24ad5#2022-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9563" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于数据转换、多项式回归和非线性回归的一切</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/46926c3c0e78851fa3772427d42f4285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*P5TNcCkSYH2WIxrJ"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">刘烨·埃斯塔班在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5200" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当目标变量和预测变量之间的关系为线性时，简单线性回归(SLR)模型易于构建。当因变量和自变量之间存在非线性关系时，事情就变得更复杂了。在本文中，我将向您展示在同一个非线性数据集上构建回归模型的三种不同方法:</p><p id="cef0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">1.多项式回归<br/> 2。数据转换<br/> 3。非线性回归</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="5d8c" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">数据集:</h1><p id="619b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我考虑的数据集取自ka ggle:<a class="ae kv" href="https://www.kaggle.com/datasets/yasserh/student-marks-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/Yasser h/student-marks-dataset</a></p><p id="5069" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据由学生的分数组成，包括他们的学习时间和课程数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/34a9b24f8352cc4956cce094d3352f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*IeozN4MwY-6uydsnnMu6PQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据帧细节(作者图像)</p></figure><p id="1015" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你检查目标变量“标记”与学习时间和课程数量之间的关系，你会发现这种关系是非线性的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/ac2c9806231c38a7526e4885f2541cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yfMJGtEnu79R5BWA4nXt2w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">因变量和自变量之间的非线性关系(作者图片)</p></figure><h1 id="6046" class="lz ma iq bd mb mc my me mf mg mz mi mj jw na jx ml jz nb ka mn kc nc kd mp mq bi translated">挑战此数据集上的简单线性模型</h1><p id="a623" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">我尝试用sklearn LinearRegression()模型建立一个线性回归模型。我定义了一个函数来计算模型的各种度量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="29d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我为我的模型调用这个函数时，我得到了下面的输出。</p><p id="701e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf"> R2平方值:0.94<br/>RSS:1211.696<br/>MSE:12.117<br/>EMSE:3.481</em></p><p id="5e40" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">94%的r2分数还不错，但我们很快就会看到，使用非线性回归模型可以得到更好的结果。问题更多在于线性回归模型背后的假设。</p><p id="b80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">单反假设1:同质性</strong></p><p id="0c64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同方差意味着残差在回归线上具有相等或几乎相等的方差。通过绘制误差项和预测项，我们应该确认误差项中没有模式。然而，在这种情况下，我们可以清楚地看到，误差项具有一定的形状。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/414094707a96c209de8b9b3684f7aabd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGaXyl92tvBn_I_HEvEZ1w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">同质性(作者图像)</p></figure><p id="bb18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">单反假设2:误差项正态分布</strong></p><p id="8c13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">具有正态或接近正态分布的钟形分布对于误差项应该是理想可见的。然而，从下图可以清楚地看出，我们有一个双模型分布。结果，在这种情况下，线性回归的假设被打破了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/0251e7075f209dd1c4256849d62e6053.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyynjfomTcHW1QfyJ6UAVw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">错误术语的分布(作者图片)</p></figure><p id="7d93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">单反假设3:误差项相互独立</strong></p><p id="95de" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，误差项之间的自相关应该不存在。然而，下图显示误差项似乎表现出一定程度的自相关性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/cf87e76b996542484263b69030e6701d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YIIqos2L3ix4ld8tBXjEcQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">错误术语之间的自相关(作者图片)</p></figure><p id="8478" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">到目前为止，我们已经验证了数据是非线性的，但我们仍然建立了一个SLR方程。虽然我们取得了令人尊敬的94%的r2分数，但没有一个单反假设得到满足。因此，对于这种类型的数据，SLR不是一个明智的解决方案。我们现在将研究在同一数据集上改进模型的其他技术。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="93fe" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">1.使用多项式回归模型建模非线性关系</h1><p id="2a05" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">非线性回归是自变量<strong class="ky ir"> <em class="nf"> x </em> </strong>和因变量<strong class="ky ir"> <em class="nf"> y </em> </strong>之间的关系，其产生非线性函数模型化的数据。本质上，任何非线性的关系都可以被称为非线性，并且通常由<strong class="ky ir"> <em class="nf"> k </em> </strong>次的多项式来表示(最大功率为<strong class="ky ir"> <em class="nf"> x </em> </strong>)。</p><p id="ff4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf">y</em><strong class="ky ir"><em class="nf"/></strong>= a<em class="nf">x</em>+b<em class="nf">x</em>+c<em class="nf">x</em>+d</p><p id="d3fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">非线性函数可以包含指数、对数、分数等元素。比如:<em class="nf">y</em>= log(<em class="nf">x</em>)<br/><br/>甚至，更复杂的比如:<br/><em class="nf">y</em>= log(a<em class="nf">x</em>+b<em class="nf">x</em>+c<em class="nf">x</em>+d)</p><p id="c2f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="nf">但是如果我们有不止一个自变量</em>会怎么样呢？</strong></p><p id="6cce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于2个预测值，多项式回归方程变为:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/e18e2fb67dd6bf38a738f3dfb2d69c27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*02rMNXDX8C7Zls4wy2ew-g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">2-预测多项式方程</p></figure><p id="cbd3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中，<br/> - Y为目标，<br/> - <em class="nf"> x </em> 1，<em class="nf"> x </em> 2为预测值或自变量<br/> - 𝜃0为偏差，<br/>-𝜃1、𝜃2、𝜃3、𝜃4和𝜃5为回归方程中的权重</p><p id="ea9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于n个预测值，该方程涵盖了各阶多项式的所有可行组合。这就是所谓的多维多项式回归，众所周知它很难实现。我们将构建不同程度的多项式模型，并评估它们的性能。但是首先，让我们为训练准备数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="7456" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以建立一个管道，并传递我们希望用来生成各种次数的多项式的模型的次数和类别。这是下面的代码为我们做的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="3324" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您希望查看所有系数和截距，请使用以下代码块:请记住，系数的数量将根据多项式的次数而变化:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="5184" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是输出结果:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/b25303179c2b542357e9ab377ac7d3a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vpOP6lkfG-wkc3MXRi72tg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不同次数多项式回归的系数/截距(作者图片)</p></figure><p id="4113" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这并没有给出关于每个模型的性能的太多信息，所以将检查r2分数。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/692b374defef87b720a4813f8310049f.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*1HEj6SgFAMKiac1v0tBasQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">不同程度多项式回归的r2分数(作者图片)</p></figure><p id="7ea3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，我们使用sklearn管道方法构建了高达7次的多项式方程，并发现2次及以上产生了99.9%的准确度(相比之下，SLR的准确度约为94%)。在同一个数据集上，我们现在将看到另一种构建回归模型的技术。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="9bb6" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">2.使用数据转换对非线性关系建模</h1><p id="90f4" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">线性回归框架假设反应变量和预测变量之间的关系是线性的。为了继续利用线性回归框架，我们必须修改数据，以便变量之间的关系变成线性的。</p><p id="dd6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据转换的一些准则:</strong></p><ul class=""><li id="12ca" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">响应变量和预测变量都可以转换</li><li id="2277" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">如果残差图显示数据中存在非线性关系，一个直接的策略是利用预测值的非线性变换。在SLR中，这些转换可以是<em class="nf"> log(x)、sqrt(x)、exp(x)、倒数</em>等等。</li><li id="80c0" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">至关重要的是，每个回归变量与目标变量具有线性关系。因变量的变换是解决非线性问题的一种方法。</li></ul><p id="5adb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">简而言之，通常是</strong>:</p><ul class=""><li id="2868" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">-转换y值有助于处理误差项，并可能有助于非线性。</li><li id="ebe3" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">非线性主要通过变换x值来解决。</li><li id="2937" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">有关数据转换的更多信息，请参见<a class="ae kv" href="https://online.stat.psu.edu/stat462/node/155/" rel="noopener ugc nofollow" target="_blank">https://online.stat.psu.edu/stat462/node/155/</a>。</li></ul><p id="e887" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的数据集中，当我们绘制因变量<em class="nf">【分数】</em>对<em class="nf">学习时间</em>和<em class="nf">课程数量</em>时，我们观察到分数与学习时间呈非线性关系。因此，我们将对特征<strong class="ky ir"> <em class="nf">学习时间</em> </strong>进行转换。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/2149459070469c884092e16eb97810be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uSq_2cJZ0JgxkVTBE65Ew.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">研究时间显示非线性行为与标记(作者图像)</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="6145" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在应用上述转换后，我们可以绘制相对于新功能<em class="nf"> time_study_sqaured </em>的<em class="nf">标记</em>，以查看关系是否已变为线性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/5c4403f6cf497d0cb253a8758308316b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-Cp6iGcbhLLCnFJkckiUw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">新特征表现出线性关系(作者图像)</p></figure><p id="e9cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的数据集现在已经准备好构建单反模型了。在这个转换后的数据集上，我们现在将使用sklearn LinearRegression()方法创建一个简单的线性回归模型。当我们在构建模型后打印指标时，我们会得到以下结果:</p><p id="9cbc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf"> R2平方值:0.9996<br/>RSS:7.083<br/>MSE:0.071<br/>EMSE:0.266</em></p><p id="fc9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与之前在原始数据集上构建的SLR模型相比，这是一个显著的改进(没有任何数据转换)。我们得到的R2平方值是99.9%，而不是94%。现在，我们将验证单反模型的各种假设，看看它是否适合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/4cbdd8abaaa454bd4fa2a2b36a50812b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61t4MA6sBAspf0kPuehrJw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">验证单反模型的所有假设(作者图片)</p></figure><p id="3179" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在这一部分，我们转换了数据本身。知道特征<em class="nf"> time_study </em>与<em class="nf">标记</em>不线性相关，我们创建了一个新的特征<strong class="ky ir"><em class="nf">time _ study _ squared</em></strong>，它与<em class="nf">标记</em>线性相关。然后我们又建立了一个单反模型，验证了一个单反模型的所有假设。我们观察到这个新模型满足了所有的假设。现在，是时候探索我们的下一个和最后一个技术了，在同一个数据集上构建不同的模型。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a1ae" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">3.使用非线性回归模型对非线性关系建模</h1><p id="f99b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">对于非线性回归问题，可以尝试sklearn库中的<em class="nf"> SVR()、KNeighborsRegressor()或DecisionTreeRegression() </em>，比较模型性能。这里，出于演示目的，我们将使用<strong class="ky ir"> sklearn </strong> <strong class="ky ir"> SVR() </strong>技术开发我们的非线性模型。SVR支持多种<a class="ae kv" href="https://dataaspirant.com/svm-kernels/#t-1608054630727" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">内核</strong> </a>。核使得线性SVM模型能够分离非线性可分离的数据点。我们将使用SVR算法测试三个备选内核，并观察它们如何影响模型准确性:</p><ul class=""><li id="f54e" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">rbf(支持向量回归的默认内核)</li><li id="dd7d" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">线性的</li><li id="d8c6" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">聚酯纤维（polyester 的简称）</li></ul><p id="b471" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> i. SVR()使用<em class="nf"> rbf </em>内核</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="c225" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里是模型指标:仍然是一个更好的R2平方比我们的第一个单反模型。</p><p id="7cbc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf"> R2平方值:0.9982<br/>RSS:4053558.081<br/>MSE:0.363<br/>EMSE:0.602</em></p><p id="d80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快速检查一下误差项分布似乎也没问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/c65452df11adf2ae53d8da4a71130194.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jHI4MWpXg5ifcjvZfW585g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有rbf核的SVR模型的误差项分布(作者图片)</p></figure><p id="aec9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">二。SVR()使用<em class="nf">线性</em>内核</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="669d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里是我们使用线性内核时的模型指标:R2平方值再次<strong class="ky ir">下降到大约93% </strong></p><p id="a515" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf"> R2平方值:0.9350<br/>RSS:4063556.3<br/>MSE:13.201<br/>EMSE:3.633</em></p><p id="f40e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">同样在这种情况下，误差项似乎是一条近似正态分布曲线:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/50434887a61fe0ad1a58d2a444e3b345.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_OnhLPtvW7sX97um2qdbCQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">具有线性核的SVR模型的误差项分布(作者图片)</p></figure><p id="0ec6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">三世。SVR()使用<em class="nf"> poly </em>内核</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="ddc8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是支持向量回归多内核的模型指标:R2平方值为97%，高于线性内核，但低于rbf内核。</p><p id="8cc7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf"> R2平方值:0.9798<br/>RSS:4000635.359<br/>MSE:4.087<br/>EMSE:2.022</em></p><p id="5d0b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是误差项分布:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/51cd468af606bb0b3b6496a642e06137.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5uVmMYSOj599xhy1V-gGw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多重核支持向量回归模型的误差项分布(作者图片)</p></figure><p id="06b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在本节中，我们使用具有3个不同内核的sklearn <a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> SVR模型</strong> </a>创建了一个非线性模型。我们用rbf核得到了最好的R2平方值。</p><ul class=""><li id="73f5" class="nm nn iq ky b kz la lc ld lf no lj np ln nq lr nr ns nt nu bi translated">径向基函数核的r2得分= 99.82%</li><li id="8357" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">R2-线性核得分= 93.50 %</li><li id="e2fa" class="nm nn iq ky b kz nv lc nw lf nx lj ny ln nz lr nr ns nt nu bi translated">具有多内核的r2分数= 97.98 %</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="559d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结论:</h1><p id="1e52" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在这篇文章中，我们从一个不依赖于目标变量的线性数据集开始。在我们能够研究在非线性数据集上建立回归模型的替代策略之前，我们构建了一个r2分数为94%的简单线性回归模型。然后，我们研究了三种不同的非线性数据集建模方法:多项式回归、数据转换和非线性回归模型(SVR)。我们发现，多项式次数为2或更高会产生99.9%的r2得分，而具有rbf核的SVR会产生99.82%的r2得分。一般来说，每当我们有一个非线性数据集时，我们应该尝试几种策略，看看哪种效果最好。</p><p id="b362" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">【https://github.com/kg-shambhu/Non-Linear-Regression-Model】在这里找到数据集和代码:<a class="ae kv" href="https://github.com/kg-shambhu/Non-Linear-Regression-Model" rel="noopener ugc nofollow" target="_blank"/></p><p id="b4ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nf">你可以在LinkedIn上联系我:</em><a class="ae kv" href="https://www.linkedin.com/in/shambhukgupta/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/shambhukgupta</a>/</p></div></div>    
</body>
</html>