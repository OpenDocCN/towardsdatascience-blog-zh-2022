<html>
<head>
<title>MovieLens-1M Deep Dive — Part II, Tensorflow Recommenders</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MovieLens-1M深潜—第二部分，Tensorflow推荐工具</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/movielens-1m-deep-dive-part-ii-tensorflow-recommenders-4ca358cc886e#2022-09-12">https://towardsdatascience.com/movielens-1m-deep-dive-part-ii-tensorflow-recommenders-4ca358cc886e#2022-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d6a199d79ba1b22e04020098deac5366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbAFlnuM2VOBZt0tKjf5FA.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">Nathan Engel的照片:<a class="ae kc" href="https://www.pexels.com/photo/time-lapse-photography-of-car-lights-in-front-of-cinema-436413/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/photo/time-lapse-photography-of-car-lights-in-front-of-cinema-436413/</a></p></figure><p id="7f65" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">读者们好，</p><p id="fb51" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于那些没有读过前一部分的人，这里是链接:</p><div class="lb lc gp gr ld le"><a rel="noopener follow" target="_blank" href="/movielens-1m-deep-dive-part-i-8acfeda1ad4"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">movie lens-1米深潜—第一部分</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">使用流行的基准数据集的实践推荐系统之旅</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">towardsdatascience.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls jw le"/></div></div></a></div><p id="300c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在那篇文章中，我展示了MovieLens-1M [1]数据集(一个电影推荐数据集，包含不同用户对电影的100万个评级)以及一些探索性的数据分析，并尝试了一些经典的推荐系统算法。虽然，那篇文章不是先决条件，你不读它也能理解这里的内容。</p><p id="b74b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在MovieLens深潜系列的第二部分中，我们将使用TensorFlow推荐器(TFRS)。TFRS将允许我们抽象出处理推荐系统时涉及的许多血淋淋的细节，如评估指标和模型训练程序。我们的模型将基于双塔架构，我们将在深入研究代码之前对其进行回顾。</p><p id="6ce5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在编码部分，我将稍微扩展一个现有的官方TFRS教程— <a class="ae kc" href="https://www.tensorflow.org/recommenders/examples/deep_recommenders" rel="noopener ugc nofollow" target="_blank">构建深度检索模型</a> [3]。在本教程中，目标是使用项目(电影)和用户的丰富上下文特征来构建一个检索推荐系统。我们将测试添加不同功能的影响，并尝试通过将更智能和更相关的功能引入手头的任务来获得改进。</p><p id="2269" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文章的提纲如下:</p><ol class=""><li id="3606" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la ly lz ma mb bi translated">现代推荐系统方法概述</li><li id="f1f2" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">了解TFRS和检索任务——我们将使用的基本构件</li><li id="af38" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">超越基准——通过使用更多上下文相关的特性，尝试超越最初的TFRS教程模型</li><li id="de42" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">超越基准—结果</li><li id="3ba5" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">结论和未来思考</li></ol><p id="4676" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们开始吧！</p><h1 id="b96c" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">第一部分——现代推荐系统方法概述</h1><p id="202c" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">推荐系统管道通常分为两个阶段——检索和排名。在检索阶段，我们为系统中的项目和用户生成表示(通常以嵌入的形式)，并选择用户可能感兴趣的项目子集。这一阶段可能处理数百万用户/项目，因此计算效率必须很高。在排序阶段，我们获取检索阶段的输出，并对它们进行排序，以选择将被推荐给用户的最后几个项目。该模型可能计算量更大，因为它必须处理的数据要少得多。这个过程的描述如图1所示。</p><figure class="nl nm nn no gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/67c112b577ae9112bdb9b12b27f56ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eDYJDXmV7VKSN5yBUyuHVw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图1:推荐系统过程</p></figure><p id="4cfb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本演练中，我们将重点关注检索阶段，并通过在嵌入生成过程中考虑不同的上下文特征，尝试使其更加高效和准确。</p><p id="e9ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在来看一些术语:</p><ul class=""><li id="e16c" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la np lz ma mb bi translated">项目—这些是我们将向用户推荐的项目。就我们而言——电影。</li><li id="369a" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la np lz ma mb bi translated">查询—这是我们的系统将用来推荐商品的信息。在我们的例子中，这将包括我们推荐的用户的ID和其他特征，例如用户的年龄和性别。我们也将在这里包括它</li></ul><h1 id="96f9" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">第二部分——了解TFRS和检索任务</h1><p id="fb3e" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">进入TFRS，这是一个基于Tensorflow构建的推荐系统库，旨在简化构建、培训和部署推荐系统的过程。</p><p id="18f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在TFRS生产的车型将继承<a class="ae kc" href="https://www.tensorflow.org/recommenders/api_docs/python/tfrs/models/Model" rel="noopener ugc nofollow" target="_blank"> tfrs。模型。型号</a>级。这个类本身是围绕<code class="fe nq nr ns nt b">tf.keras.Model</code>的包装器，为我们省去编写train_step和test_step方法的麻烦。作为用户，我们要做的是编写compute_loss函数，它接收一批输入查询和条目，并计算模型的损失。</p><p id="74a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的教程中，我们将构建一个双塔架构模型。这个模型包含一个用于项目的塔和一个用于查询的塔。如图2所示，双塔架构非常简单。嵌入被创建来表示查询和用户，最后，我们对两个嵌入向量执行余弦相似性操作来预测它们的相似性(查询是这个项目的良好匹配吗？).通过使用嵌入每个项目的余弦相似性对特定查询的结果进行排序，系统可以检索该用户的顶部项目(通常大约1000个)，然后最有可能将这些项目馈送到排序模型中，用于对将呈现给用户的最终项目(通常多达10个项目)进行细粒度控制。</p><figure class="nl nm nn no gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/6dfeb1a0d46edcd7329a300541c3b5ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQ565jpYkqeGbw_vjfl3hw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图2:双塔架构的简单示意图</p></figure><p id="1a2f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的解释中我们不明白的是，模型是如何学习的？当然是通过梯度下降。有正面的例子(在我们的例子中，是某个用户评级的电影)和负面的例子(不是某个用户评级的电影)。我们的算法将把这视为多类分类任务，并试图最大化已评级项目和查询之间的相似性，最小化未评级项目和查询之间的相似性。这个操作是在每个批处理中完成的(每个批处理只包含正例，负例是通过将批处理中的不同查询和项目配对生成的，如图3所示)。</p><figure class="nl nm nn no gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/70ca78e3c6c935f7e24fa7a493a6e949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSEuImpGi8JfgPn4juNyLw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图3:检索任务(FFN =前馈网络)</p></figure><h1 id="915a" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">第三部分——超越基准</h1><p id="ce4c" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">在这一部分中，我将向您展示我的代码，我们将通过使用额外的上下文特性来丰富项目和查询表示，从而尝试改进我们的深度检索模型的性能。</p><p id="f1a7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们回顾一下我们将用于条目和查询的特性。对于每个特性，我将指定它是否在最初的TFRS教程中使用过。</p><p id="097d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">查询功能(用户+上下文信息):</strong></p><ul class=""><li id="35cf" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la np lz ma mb bi translated">user_id [int] —最基本的特性。用于索引到用户嵌入矩阵中。(在原始教程中使用)</li><li id="f52a" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la np lz ma mb bi translated">timestamp [int] —用户执行查询的时间，以UNIX时间戳格式表示。这可以帮助我们捕捉数据中的季节性趋势(例如，在周末，人们可能更喜欢较长的电影)。(在原始教程中使用)</li><li id="9838" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la np lz ma mb bi translated">user_age [int] —一个额外的数字特征，可能暗示用户首选项中的模式。(原始教程中未使用)</li></ul><p id="8e4a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">物品特征(电影信息):</strong></p><ul class=""><li id="bd03" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la np lz ma mb bi translated">movie_title [string] —项目的唯一标识符。用于索引到项目嵌入矩阵中。该特性还将用于创建嵌入电影标题文本的句子(而不是仅仅将其用作简单的标识符)。(在原始教程中使用)</li><li id="3ab1" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la np lz ma mb bi translated">movie _ genders[list<int>]—每部电影都与一个或多个流派相关联，其中每个流派都由一个唯一的整数定义。我们将使用这些整数索引到一个流派嵌入矩阵中。对于每部电影，我们将对其所有类型的嵌入进行平均。(原始教程中未使用)</int></li><li id="d1ad" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la np lz ma mb bi translated">movie_length [int] —电影的长度，以分钟为单位。这些信息是使用<a class="ae kc" href="https://cinemagoer.github.io/" rel="noopener ugc nofollow" target="_blank"> Cinemagoer </a> [2] python包收集的。一些电影长度数据丢失了，对于这些电影，我给出了90分钟的默认长度。</li></ul><p id="f64d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">代码:</strong></p><p id="b700" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在这里展示了一种非常规的探索性数据科学工作方式，那就是通过脚本而不是通过Jupyter笔记本。我认为脚本相对于笔记本的优势在于:</p><p id="c811" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)更清洁的代码。鼓励您使用良好的编程实践，例如将公共过程提取到函数中，而不是在单元格之间复制粘贴。</p><p id="0faf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2)以合理的方式跟踪你的工作的能力，这是最重要的，尤其是在与其他人合作的时候。</p><p id="d817" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">缺点是它可能会引入对缓存机制的需求，正如我在本例中所做的那样(这样您就不必为您希望执行的每个实验运行繁重的数据加载/模型训练过程)。在这个例子中，我保存了每个配置的训练模型，这样我就不必在每次运行脚本时都重新运行训练。此外，我使用<code class="fe nq nr ns nt b">tf.data.Dataset.save</code>和<code class="fe nq nr ns nt b">tf.data.Dataset.load</code>保存和加载数据集，因为数据集创建过程可能需要一段时间。最后，我利用了<a class="ae kc" href="https://pypi.org/project/cachier/" rel="noopener ugc nofollow" target="_blank"> cachier </a> python包，当从<code class="fe nq nr ns nt b">Cinemagoer</code>加载电影长度信息时，它在磁盘上生成函数结果的持久缓存，因为这是一个非常漫长的过程，我们希望避免对每部电影运行这个函数超过一次。</p><figure class="nl nm nn no gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="08b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行这个脚本需要的非标准包如下:<code class="fe nq nr ns nt b">tensorflow, tensorflow_datasets, tensorflow_recommenders, plotly, numpy</code>。注意，该脚本假设您的主目录中有两个子目录，分别名为<code class="fe nq nr ns nt b">datasets</code>和<code class="fe nq nr ns nt b">saved_models</code>。</p><p id="2769" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">培训过程将由<code class="fe nq nr ns nt b">MovieLensTrainer</code>班管理。给定训练设置，如图层大小、嵌入大小和要使用的特征，它将训练模型或从磁盘加载相关模型。在通过命令行参数获得我们定义的所有特征组合的训练模型后，我们将运行函数<code class="fe nq nr ns nt b">plot_training_runs</code>,该函数将返回每次运行的前100个分类准确度的曲线图，并允许我们比较我们使用的不同设置。</p><p id="c4d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从最初的TFRS教程开始，我对模型做了一个重要的改变，那就是能够在<code class="fe nq nr ns nt b">MovieModel</code>(物品塔)中使用额外的功能。在本教程中，这个模型只将<code class="fe nq nr ns nt b">movie_title</code>作为输入。在这个项目中，它可以接受任何额外的特性，最终创建一个所有特性嵌入的连接。这很重要，因为它使我们能够利用额外的电影信息，如类型，电影长度，在IMDB上的平均评级，以及您可能想到的任何其他功能。</p></div><div class="ab cl ny nz hu oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="ij ik il im in"><h2 id="6396" class="of mi iq bd mj og oh dn mn oi oj dp mr ko ok ol mv ks om on mz kw oo op nd oq bi translated">命令行参数+运行示例</h2><p id="1a00" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">我们有几个命令行参数来控制我们的脚本做什么。我将讨论一些不太明显的问题:</p><p id="619a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">layer_sizes (list[int])</code> —为两个塔(查询和项目模型)中的每一个定义嵌入层之后的层的数量和大小。我们添加的层越多，给它们的神经元越多，我们的模型就会变得越复杂(因此也更容易过度拟合)</p><p id="6816" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">additional_feature_sets (list[list[string]])</code> —该参数是一个列表列表，其中每个内部列表是我们希望训练TFRS模型的一组特征。例如，使用这个参数我们可以训练两个模型，其中一个训练使用<code class="fe nq nr ns nt b">movie_genres, timestamp</code>特性，另一个训练使用<code class="fe nq nr ns nt b">movie_title_text, timestamp</code>特性。</p><p id="cd65" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">--retrain (bool)</code> —这是一个二元切换。关闭时，如果我们以前已经训练过(从文件系统加载)，我们将使用选定的设置加载以前训练过的模型。如果启用，我们将总是重新训练并覆盖当前在磁盘上的模型。</p><p id="678c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">--generate_recommendations_for_user (int)</code> —这是一个用户的ID，我们将为其生成我们生成的每个训练模型的推荐。这意味着让我们的模型“脚踏实地”，并看到它为偏好已知的用户生成推荐的真实示例。</p><p id="9cfd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此流程的一组命令行参数示例(本次运行将训练6个不同的模型，每个模型训练300个时期。它将为每个训练模型的ID为1的用户生成推荐):</p><pre class="nl nm nn no gt or nt os ot aw ou bi"><span id="e2fe" class="of mi iq nt b gy ov ow l ox oy">--num_epochs<br/>300<br/>--additional_feature_sets<br/>None<br/>--additional_feature_sets<br/>timestamp<br/>--additional_feature_sets<br/>movie_title_text<br/>--additional_feature_sets<br/>timestamp<br/>movie_title_text<br/>--additional_feature_sets<br/>timestamp<br/>movie_title_text<br/>movie_genres<br/>--additional_feature_sets<br/>timestamp<br/>movie_title_text<br/>movie_genres<br/>movie_length<br/>--embedding_size<br/>32<br/>--layer_sizes<br/>64<br/>32<br/>--generate_recommendations_for_user<br/>1</span></pre><p id="2d0c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看看这次运行的输出(为了清楚起见，删除了警告):</p><p id="7887" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">These are the ratings for user 1:</code></p><figure class="nl nm nn no gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><pre class="nl nm nn no gt or nt os ot aw ou bi"><span id="d444" class="of mi iq nt b gy ov ow l ox oy"><br/><strong class="nt ir">Recommendations for model ('timestamp',), user 1:</strong><br/> [b'Alien (1979)' b'Sense and Sensibility (1995)' b'Sea Wolves, The (1980)'<br/> b'Ninth Gate, The (2000)' b'Beautiful (2000)' b'Sweet Nothing (1995)'<br/> b'Titan A.E. (2000)' b'Saint, The (1997)'<br/> b'Killer: A Journal of Murder (1995)' b'Man of the Year (1995)']<br/>Recommendations for model ('movie_title_text',), user 1:<br/> [b'Angel and the Badman (1947)' b'Alien (1979)' b'Shadows (Cienie) (1988)'<br/> b'Two Moon Juction (1988)' b'Sea Wolves, The (1980)' b'Booty Call (1997)'<br/> b'Apple Dumpling Gang Rides Again, The (1979)'<br/> b'Psycho Beach Party (2000)' b'Local Hero (1983)'<br/> b"Shaft's Big Score! (1972)"]<br/><strong class="nt ir">Recommendations for model ('timestamp', 'movie_title_text'), user 1:</strong><br/> [b'Fried Green Tomatoes (1991)' b'Alien (1979)'<br/> b'Angel and the Badman (1947)' b'Sarafina! (1992)'<br/> b'Color Purple, The (1985)' b'Sea Wolves, The (1980)'<br/> b'Madame Sousatzka (1988)' b'Little Shop of Horrors (1986)'<br/> b"One Flew Over the Cuckoo's Nest (1975)" b'L.A. Story (1991)']<br/><strong class="nt ir">Recommendations for model ('timestamp', 'movie_title_text', 'movie_genres'), user 1:<br/></strong> [b'Being There (1979)' b'Alien (1979)' b'Crimes and Misdemeanors (1989)'<br/> b'Two Moon Juction (1988)' b'Psycho (1998)'<br/> b'Apple Dumpling Gang Rides Again, The (1979)' b'Me Myself I (2000)'<br/> b'Loser (2000)' b'Killer: A Journal of Murder (1995)'<br/> b"Barney's Great Adventure (1998)"]<br/><strong class="nt ir">Recommendations for model ('timestamp', 'movie_title_text', 'movie_genres', 'movie_length'), user 1:<br/></strong> [b'Sid and Nancy (1986)' b'Angel and the Badman (1947)' b'Alien (1979)'<br/> b'Two Moon Juction (1988)' b'Crimes of the Heart (1986)'<br/> b'Sea Wolves, The (1980)' b'One False Move (1991)'<br/> b'Rich and Strange (1932)' b'Storefront Hitchcock (1997)'<br/> b'Celebration, The (Festen) (1998)']<br/><strong class="nt ir">Recommendations for model (), user 1:</strong><br/> [b'Alien (1979)' b'Booty Call (1997)'<br/> b'Day the Earth Stood Still, The (1951)' b'Angel and the Badman (1947)'<br/> b'Sea Wolves, The (1980)' b'Celebration, The (Festen) (1998)'<br/> b'Midnight Cowboy (1969)' b'Desperado (1995)' b'Tingler, The (1959)'<br/> b'Blue Chips (1994)']</span></pre><p id="4707" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这只是个人想法，但是作为用户1，我想我会非常失望。出现在所有推荐中的唯一的儿童电影是“巴尼大冒险(1998)”，尽管用户对这些类型的电影有明显的亲和力。另外，我们甚至可以看到一些不合适的电影(用户1被归类为K-12岁)。在这个系统投入生产之前，还需要更多的建模改进和启发式布局。</p><p id="bdad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们查看一些准确性结果，看看我们是否通过在训练过程中包含更多功能来击败教程基准。</p><h1 id="ba1a" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">第四部分——超越基准——结果</h1><p id="09c9" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">我们将训练具有以下特征组合的模型:</p><ol class=""><li id="0205" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id</code></li><li id="66d7" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id, timestamp</code></li><li id="05f4" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id, movie_title_text</code></li><li id="c5b8" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id, timestamp, movie_title_text <strong class="kf ir">(this setting was used in the official tutorial)</strong></code></li><li id="205b" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id, timestamp, movie_title_text, movie_genres</code></li><li id="822b" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated"><code class="fe nq nr ns nt b">movie_title, user_id, timestamp, movie_title_text, movie_genres, movie_length</code></li></ol><p id="73de" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并使用以下图层大小:</p><p id="586d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe nq nr ns nt b">[64, 32]</code></p><p id="cf3a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总共6个训练好的模型。我们将为每个模型训练300个历元，并对所有嵌入层使用32的嵌入大小。我假设额外的特性将丰富项目/查询嵌入，并帮助生成更准确的表示。我们将用于比较模型的指标是前100名的准确度(越高=越好)。这意味着，对于验证集中的每个项目/查询对，是否为该查询生成了前100对中的配对的相似性？</p><p id="abef" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图4所示(包括静态图像和交互图，因为移动设备上的可见性问题)是每个模型训练的验证前100名准确度(在5个时期间隔内)。</p><figure class="nl nm nn no gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oz"><img src="../Images/ce1d1ef5607e4887524ab4dbeaf36aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*szA0EDkEUgEjgV07NE0glQ.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图4(静态):模型比较结果</p></figure><figure class="nl nm nn no gt jr"><div class="bz fp l di"><div class="pa nx l"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图4(交互式):模型比较结果</p></figure><p id="b0e4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以始终如一地看到，随着我们添加更多的功能，验证的准确性会增加。这是令人鼓舞的，因为这意味着我们的工作产生了积极的影响！请注意，整体准确性似乎很低，这是因为这是一个非常困难的问题(需要从大约6000部电影中猜出正确的电影)。就验证准确性而言，最好的方法是使用所有建议特性的方法，实际上，在300个时期后，它比本教程中的基准高出大约0.015。</p><h1 id="826b" class="mh mi iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">第五部分——结论和展望</h1><p id="ef63" class="pw-post-body-paragraph kd ke iq kf b kg nf ki kj kk ng km kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">在这篇文章中我们已经看到:</p><ol class=""><li id="f45e" class="lt lu iq kf b kg kh kk kl ko lv ks lw kw lx la ly lz ma mb bi translated">如何用tensorflow推荐器搭建推荐系统？</li><li id="0fc8" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">如何将上下文特性添加到项目和查询中以获得更好的性能。</li><li id="f651" class="lt lu iq kf b kg mc kk md ko me ks mf kw mg la ly lz ma mb bi translated">如何通过简单的脚本而不是使用Jupyter笔记本进行研究。</li></ol><p id="6a96" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，查询和项目的额外上下文可以提高我们的推荐性能(即使在相对密集的数据集上，如MovieLens-1M)。当构建你自己的推荐系统时，试着想想你是否可以在你的嵌入中加入更多的上下文，而不仅仅是使用用户和商品标识符:)</p><p id="83bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下次见，</p><p id="1ac4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">埃拉德</p><p id="f55e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考文献:</strong></p><p id="d5cf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[1] <em class="pb">麦克斯韦·哈珀和约瑟夫·a·康斯坦。2015.电影镜头数据集:历史和背景。美国计算机学会交互式智能系统汇刊5，4:19:1–19:19。</em><a class="ae kc" href="https://doi.org/10.1145/2827872" rel="noopener ugc nofollow" target="_blank"><em class="pb">https://doi.org/10.1145/2827872</em></a></p><p id="d64d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] Tensorflow深度检索系统教程—<a class="ae kc" href="https://www.tensorflow.org/recommenders/examples/deep_recommenders" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/re commenders/examples/deep _ re commenders</a></p><p id="a4c7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] Cinemagoer python包—<a class="ae kc" href="https://cinemagoer.github.io/" rel="noopener ugc nofollow" target="_blank">https://cinemagoer.github.io/</a></p></div></div>    
</body>
</html>