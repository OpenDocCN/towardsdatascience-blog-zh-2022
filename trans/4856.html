<html>
<head>
<title>Three Ways to Use AI to Generate Stunning Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用人工智能生成令人惊叹的图像的三种方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/three-ways-to-use-ai-to-generate-stunning-images-44c667c89a28#2022-10-28">https://towardsdatascience.com/three-ways-to-use-ai-to-generate-stunning-images-44c667c89a28#2022-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4e3c218f5cb543a55935ea30479a78d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4t5XV3YeVsPiV0KRUEjxg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">“照片/表现性油画/像素艺术，一名宇航员躺在沙漠中的躺椅上，喝着鸡尾酒。”—用DALL-E2使用各自的提示创建的图像。</p></figure><p id="f6b6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi ld translated">最近，互联网上充斥着人工智能生成的惊人图像。也就是说，用户提供文本提示，AI系统基于所述提示生成图像。有趣的是，它不仅产生了——坦率地说——非凡的图像，而且人们可以将有趣的想法和风格结合起来。这可能意味着你将一名宇航员放在沙漠中，并将其作为照片级真实感图像、富有表现力的油画或像素艺术。在这里，我们将提供三种方法，让你可以用不同的技术专业知识水平探索这些技术:在线版本的<em class="lm"> DALL-E 2 </em>，谷歌Colab，以及本地版本的<em class="lm">稳定扩散。</em></p><h2 id="ccf0" class="ln lo it bd lp lq lr dn ls lt lu dp lv kq lw lx ly ku lz ma mb ky mc md me mf bi translated">背景</h2><p id="0949" class="pw-post-body-paragraph kf kg it kh b ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky mk la lb lc im bi translated">让我们首先简要了解一下不同技术的一些基本信息。<a class="ae ml" href="https://en.wikipedia.org/wiki/DALL-E" rel="noopener ugc nofollow" target="_blank"><em class="lm">DALL-E 2</em></a><em class="lm"/>是一个拥有35亿参数的AI模型，由<a class="ae ml" href="https://openai.com" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>在<a class="ae ml" href="https://en.wikipedia.org/wiki/Generative_Pre-trained_Transformer" rel="noopener ugc nofollow" target="_blank">创成式预训练变压器(GPT) </a>模型的基础上构建而成。针对选定用户的测试阶段于2022年7月开始，并于9月28日由OpenAI向公众推出，源代码尚未公开。</p><p id="e934" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">与此相反，稳定扩散的代码和模型权重对<a class="ae ml" href="https://github.com/CompVis/stable-diffusion" rel="noopener ugc nofollow" target="_blank">公众</a>可用。这是一个潜在的扩散模型，于2022年8月22日由Ludwig Maximilian大学(LMU)的CompVIS集团、<a class="ae ml" href="https://stability.ai" rel="noopener ugc nofollow" target="_blank">stability ai</a>——一家视觉艺术初创公司和<a class="ae ml" href="https://runwayml.com" rel="noopener ugc nofollow" target="_blank"> Runway </a>合作发布。稳定扩散模型是用大规模人工智能开放网络(<a class="ae ml" href="https://en.wikipedia.org/wiki/LAION" rel="noopener ugc nofollow" target="_blank"> LAION </a>)的数据训练的，这是一家德国非营利组织，从网络上搜集图像。模型本身有8.9亿个参数，可以在消费级显卡上运行。</p><p id="2a37" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">除了DALL-E，还有<a class="ae ml" href="https://www.midjourney.com/home/" rel="noopener ugc nofollow" target="_blank"> Midjourney </a>，它也只能通过云服务访问，并于2022年7月12日开始公开测试。</p><p id="1c91" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">从商业角度来看，人工智能生成的艺术似乎非常有前途。StabilityAI刚刚从<a class="ae ml" href="https://techcrunch.com/2022/10/17/stability-ai-the-startup-behind-stable-diffusion-raises-101m/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAF-7nlldrhRUB5FtuJITew7PeyssTHYQit4FjI3wVX49ijDVkbsPjBInzZlrRq7P84d-Q7zT1WOy-PZIpRHspgdvv67qZn0oB7WH7_XaqKzaXZJiUzn0YYCTX5dCDgzwUuWn7Loye0n1BL9yFYF2bTyseLGB6VpapBXReDRu938e" rel="noopener ugc nofollow" target="_blank">筹集了1.01亿美元</a>，Midjourney声称<a class="ae ml" href="https://www.theregister.com/2022/08/01/david_holz_midjourney/" rel="noopener ugc nofollow" target="_blank">已经盈利。</a></p><h2 id="4745" class="ln lo it bd lp lq lr dn ls lt lu dp lv kq lw lx ly ku lz ma mb ky mc md me mf bi translated">达尔-E 2</h2><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mm"><img src="../Images/5208945870292df97f2339cf25dc0ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3dTm4mZzRSM2QslNlE6N_w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">截至2022年10月的DALL-E登录后截图。</p></figure><p id="af9b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">DALL-E 2的用法简单明了:进入OpenAI的DALL-E 2页面<a class="ae ml" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank">注册</a>。他们将需要一个手机号码来注册您的帐户。就是这样。你最终会看到一个类似谷歌的文本提示；输入你的想法，几秒钟内就能生成四幅示例图像。你可以点击单个图像，得到它们的变化。每要求<a class="ae ml" href="https://help.openai.com/en/articles/6399305-how-dall-e-credits-work" rel="noopener ugc nofollow" target="_blank"> <em class="lm">花费</em> </a>你一个信用点；第一个月你将获得50个学分，随后的每个月会增加15个学分。此外，你可以花15美元购买115个积分。</p><h2 id="dbee" class="ln lo it bd lp lq lr dn ls lt lu dp lv kq lw lx ly ku lz ma mb ky mc md me mf bi translated">稳定扩散</h2><p id="0eb3" class="pw-post-body-paragraph kf kg it kh b ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky mk la lb lc im bi translated">如果你更喜欢开源的替代稳定扩散，我们首先需要设置东西。</p><p id="ff6e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">谷歌可乐。</strong>如果你没有合适的硬件，我推荐使用Google Colab，它可以访问适合该任务的GPU。作为起点，我们从这个<a class="ae ml" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>开始。它需要一个<a class="ae ml" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>令牌来访问模型权重。你可以通过创建一个拥抱脸帐户，前往<a class="ae ml" href="https://huggingface.co/CompVis/stable-diffusion-v1-4" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>模型，并接受共享模型的条款来获得令牌。</p><p id="7543" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">要生成图像，请执行所有单元格，直到需要输入令牌，然后继续执行，直到到达可以输入图像生成提示的单元格。这需要几分钟的时间，生成一幅图像需要几秒钟的时间。</p><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mr"><img src="../Images/718295178b708941eedbe0f981c80ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hquXE3CO7gUjf4WX9A36OA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">Google Colab和Stable Diffusion:“一幅富有表现力的油画，描绘了一名宇航员躺在阳光躺椅上，在沙漠中喝着鸡尾酒。”</p></figure><p id="331a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">如果您想将图像保存到您的Google Drive，例如保存在文件夹<em class="lm"> exported-images </em>中，您可以这样做:</p><p id="ad15" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">安装驱动器:</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="b16a" class="ln lo it mt b gy mx my l mz na">from google.colab import drive<br/>drive.mount(‘/content/gdrive’)</span></pre><p id="3b45" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">保存图片(注意主目录是<em class="lm">我的驱动</em>为谷歌驱动)</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="2d6f" class="ln lo it mt b gy mx my l mz na">image.save(f"/content/gdrive/My Drive/exported-images/image.png")</span></pre><p id="2f31" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">Google Colab方法的一个局限性是，如果失去了与内核的连接，您需要重新设置环境。</p><p id="3147" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">本地安装。</strong>如果你有一台为深度学习任务而设置的GPU机器正在运行；您可以在本地安装并运行稳定的扩散。更准确地说，你应该有一个Python环境(比如<a class="ae ml" href="https://anaconda.org/" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>或者<a class="ae ml" href="https://docs.conda.io/en/latest/miniconda.html" rel="noopener ugc nofollow" target="_blank"> Miniconda </a>)，<a class="ae ml" href="https://git-scm.com/" rel="noopener ugc nofollow" target="_blank"> Git </a>，并且正确安装了GPU，也就是CUDA驱动)。实事求是地说，对于一台装有NVIDIA卡的Windows机器，如果你运行</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="4813" class="ln lo it mt b gy mx my l mz na">nvidia-smi</span></pre><p id="72d4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在命令行中，您应该会看到CUDA版本。对于安装，您可以遵循<a class="ae ml" href="https://github.com/CompVis/stable-diffusion" rel="noopener ugc nofollow" target="_blank"> GitHub </a>指令，但是本质上，您通过Git克隆存储库并创建和安装环境。</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="970e" class="ln lo it mt b gy mx my l mz na">conda env create -f environment.yaml<br/>conda activate ldm</span></pre><p id="8410" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">接下来，你需要从稳定扩散的<a class="ae ml" href="https://huggingface.co/CompVis/stable-diffusion-v-1-4-original" rel="noopener ugc nofollow" target="_blank">拥抱脸页面下载重量。我用的是最新的</a><a class="ae ml" href="https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt" rel="noopener ugc nofollow" target="_blank">SD-v1–4 . ckpt</a>。在Linux上，可以像GitHub存储库上描述的那样链接文件；在Windows系统上，您可以下载该文件并将其重命名为model.ckpt，然后将其复制到稳定扩散模型的文件夹中，如下所示:</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="66b6" class="ln lo it mt b gy mx my l mz na">models/ldm/stable-diffusion-v1/model.ckpt</span></pre><p id="4e4d" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然后，您可以(在激活的环境中)通过命令行提示符创建图像(注意，您需要位于GitHub存储库的文件夹中):</p><pre class="mn mo mp mq gt ms mt mu mv aw mw bi"><span id="a548" class="ln lo it mt b gy mx my l mz na">python scripts/txt2img.py --prompt <!-- -->"Expressive oil painting of an astronaut laying in a sun lounger with a cocktail in the desert" <!-- -->--plms</span></pre><figure class="mn mo mp mq gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/8de39913e18aa0e1920721d68b77f157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*JPSRfnGBRsGZ0XNcjG93WQ.png"/></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">“一幅富有表现力的油画，描绘了一名宇航员躺在太阳躺椅上，喝着沙漠中的鸡尾酒”——由稳定扩散的本地装置生成。请注意，我尝试了五种不同的种子，才在照片中找到一名穿着太空服的宇航员。</p></figure><p id="9d4a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">生成的图像将位于outputs/txt2img-samples中。</p><p id="eade" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这里的是一个更详细的安装指南，也展示了如何使用网络界面。</p><p id="b3da" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我用12 GB内存的Titan V进行了测试，确实经常遇到内存问题。在这里，通过传递-H或-W参数或者用-n_samples减少样本数来减小大小是有帮助的。</p><h2 id="fe3c" class="ln lo it bd lp lq lr dn ls lt lu dp lv kq lw lx ly ku lz ma mb ky mc md me mf bi translated">结论</h2><p id="dc30" class="pw-post-body-paragraph kf kg it kh b ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky mk la lb lc im bi translated">今天，生成带有文本提示的AI图像出奇的容易。使用DALL-E 2这样的工具，甚至不需要昂贵的硬件或编码技能。虽然图像质量令人惊叹，但仍可能存在伪像，这些伪像会泄露图像是人造的，例如，当查看来自稳定扩散的本地安装的最后一个示例图像的阴影时。最终，我相信这将彻底改变创意部门，因为它从未如此容易地将想法可视化。</p></div></div>    
</body>
</html>