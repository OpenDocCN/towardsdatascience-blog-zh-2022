<html>
<head>
<title>Top 6 Machine Learning Algorithms for Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于分类的6大机器学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501#2022-02-23">https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501#2022-02-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b8ca" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何用Python构建机器学习模型管道</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/b9a536c18794cccea3ad5ea865cc2f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R6Rbcks-pGO0SkhCINrP0g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用于分类的机器学习算法(原图来自我的<a class="ae ky" href="https://www.visual-design.net/" rel="noopener ugc nofollow" target="_blank">网站</a></p></figure><h2 id="536b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">监督与非监督与强化学习</h2><p id="aec4" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">区分有监督学习和无监督学习最简单的方法就是看数据是否被标注。</p><p id="3e9b" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">监督学习</strong>学习一个函数，根据输入数据对定义的标签进行预测。它可以是将数据分类(分类问题)或预测结果(<a class="ae ky" rel="noopener" target="_blank" href="/top-machine-learning-algorithms-for-regression-c67258a2c0ac">回归算法</a>)。</p><p id="7195" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">无监督学习</strong>揭示数据集中没有明确呈现的潜在模式，它可以发现数据点的相似性(聚类算法)或揭示变量的隐藏关系(关联规则算法)…</p><p id="656c" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">强化学习</strong>是另一种类型的机器学习，其中代理学习根据其与环境的交互采取行动，目的是最大化回报。它非常类似于人类的学习过程，遵循试错法。</p><h2 id="0bcc" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">分类与回归</h2><p id="4cec" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">监督学习可以进一步分为分类和回归算法。<strong class="lx iu">分类模型</strong>识别对象属于哪个类别，而<a class="ae ky" rel="noopener" target="_blank" href="/top-machine-learning-algorithms-for-regression-c67258a2c0ac"> <strong class="lx iu">回归模型</strong> </a>预测连续输出。</p><p id="27c3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="mt">有关回归算法的指南，请参见:</em></p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/top-machine-learning-algorithms-for-regression-c67258a2c0ac"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">机器学习中的四大回归算法</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">全面的实施和比较指南</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="nh l ni nj nk ng nl ks mx"/></div></div></a></div><p id="5e0a" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">有时在分类算法和回归算法之间有一条模糊的线。许多算法既可以用于分类，也可以用于回归，而分类只是应用了阈值的回归模型。当数量高于阈值时，它被分类为真，而低于阈值时，它被分类为假。</p><p id="37aa" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">在本文中，我们将讨论分类问题的6大机器学习算法，包括:l <em class="mt">逻辑回归、决策树、随机森林、支持向量机、k近邻和朴素贝叶斯</em>。我总结了每种方法背后的理论，以及如何使用python实现每种方法。在我的<a class="ae ky" href="https://www.visual-design.net/code-snippets" rel="noopener ugc nofollow" target="_blank">网站</a>上查看模型管道的代码。</p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="71e4" class="nt la it bd lb nu nv nw le nx ny nz lh jz oa ka ll kc ob kd lp kf oc kg lt od bi translated">1.逻辑回归</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/50b8966448a389699977c25f03af24e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*25whI_Jt8LQIHhF6ds-j6Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑回归(图片由作者提供)</p></figure><p id="73f6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">逻辑回归使用上面的sigmoid函数来返回标签的概率。当分类问题是二元的——真或假，赢或输，正或负时，它被广泛使用...</p><p id="e3cc" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">sigmoid函数生成概率输出。通过将该概率与预定义的阈值进行比较，对象被相应地分配给标签。查看我在<a class="ae ky" rel="noopener" target="_blank" href="/simple-logistic-regression-using-python-scikit-learn-86bf984f61f1">逻辑回归</a>上的帖子，获得详细的演示。</p><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/simple-logistic-regression-using-python-scikit-learn-86bf984f61f1"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">Python中的简单逻辑回归</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">从数据预处理到模型评估的逐步指南</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="of l ni nj nk ng nl ks mx"/></div></div></a></div><p id="d431" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">下面是默认逻辑回归和常用超参数的代码片段，看看哪些组合能带来最好的结果。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="4651" class="kz la it oh b gy ol om l on oo">from sklearn.linear_model import LogisticRegression<br/>reg = LogisticRegression()<br/>reg.fit(X_train, y_train)<br/>y_pred = reg.predict(X_test)</span></pre><p id="4c28" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/tuning-the-hyperparameters-of-your-machine-learning-model-using-gridsearchcv-7fc2bb76ff27"> <strong class="lx iu"> logistic回归常用超参数</strong> </a> <strong class="lx iu"> : </strong> penalty，max_iter，C，solver</p><h1 id="4923" class="nt la it bd lb nu op nw le nx oq nz lh jz or ka ll kc os kd lp kf ot kg lt od bi translated">2.决策图表</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/340feb63c7136753d44503373e11cf65.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*fSlQBEta5GKjNgZGsVTVTA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">决策树(图片由作者提供)</p></figure><p id="b0ca" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">决策树以分层的方式构建树分支，每个分支可以被视为一个if-else语句。分支是通过基于最重要的特征将数据集划分为子集来发展的。最终的分类发生在决策树的叶子上。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="dce5" class="kz la it oh b gy ol om l on oo">from sklearn.tree import DecisionTreeClassifier<br/>dtc = DecisionTreeClassifier()<br/>dtc.fit(X_train, y_train)<br/>y_pred = dtc.predict(X_test)</span></pre><p id="dd71" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/how-to-tune-a-decision-tree-f03721801680"> <strong class="lx iu">决策树常用超参数</strong> </a> : criterion，max_depth，min_samples_split，min _ samples _ leaf最大_功能</p><h1 id="1a4d" class="nt la it bd lb nu op nw le nx oq nz lh jz or ka ll kc os kd lp kf ot kg lt od bi translated">3.随机森林</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/ce8d4958b18de7db925586765f625017.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*fsy57DtqUR_UDOTQKtghkw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机森林(图片由作者提供)</p></figure><p id="2106" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">顾名思义，随机森林是决策树的集合。这是一种常见的集合方法，它集合了来自多个预报器的结果。随机森林还利用bagging技术，允许每棵树在原始数据集的随机采样上训练，并从树中获得多数票。与决策树相比，它具有更好的泛化能力，但可解释性较差，因为模型中增加了更多的层。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="3c93" class="kz la it oh b gy ol om l on oo">from sklearn.ensemble import RandomForestClassifier<br/>rfc = RandomForestClassifier()<br/>rfc.fit(X_train, y_train)<br/>y_pred = rfc.predict(X_test)</span></pre><p id="de55" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"> <strong class="lx iu">随机森林常用超参数</strong> </a> : n_estimators，max_features，max_depth，min_samples_split，min_samples_leaf，boostrap</p><h1 id="6082" class="nt la it bd lb nu op nw le nx oq nz lh jz or ka ll kc os kd lp kf ot kg lt od bi translated">4.支持向量机(SVM)</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/87c835bb9bc5b44ae6a7930f95e3ad13.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*WMbKMcC-gfXe4JgzcSxN2Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">支持向量机(图片作者提供)</p></figure><p id="bf77" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">支持向量机根据与正类和负类之间的边界相关的位置找到对数据进行分类的最佳方式。这个边界被称为超平面，它最大化来自不同类的数据点之间的距离。类似于决策树和随机森林，支持向量机可以用于分类和回归，SVC(支持向量分类器)用于分类问题。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="b3e9" class="kz la it oh b gy ol om l on oo">from sklearn.svm import SVC<br/>svc = SVC()<br/>svc.fit(X_train, y_train)<br/>y_pred = svc.predict(X_test)</span></pre><p id="dcb6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" href="https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv/" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">支持向量机常用超参数:</strong> </a> <strong class="lx iu"> </strong> c，内核，伽马</p><h1 id="19d1" class="nt la it bd lb nu op nw le nx oq nz lh jz or ka ll kc os kd lp kf ot kg lt od bi translated">5.k-最近邻(KNN)</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/37df5768284350fc5f2f71804135f4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*-IOhINAS4oEFJnutXGHJDA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">knn(图片由作者提供)</p></figure><p id="e4f8" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">您可以将k最近邻算法视为表示由n个特征定义的n维空间中的每个数据点。它计算一个点到另一个点的距离，然后根据最近的观察数据点的标签分配未观察数据的标签。KNN也可以用来构建推荐系统，如果你对这个话题感兴趣，可以看看我的文章“<a class="ae ky" rel="noopener" target="_blank" href="/a-beginner-friendly-guide-to-recommender-system-3f5fa2a57c02">协同过滤推荐电影</a>”。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="0f49" class="kz la it oh b gy ol om l on oo">from sklearn.neighbors import KNeighborsClassifier<br/>knn = KNeighborsClassifier()<br/>knn.fit(X_train, y_train)<br/>y_pred = knn.predict(X_test)</span></pre><p id="c527" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" href="https://medium.datadriveninvestor.com/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> KNN常用超参数</strong></a><strong class="lx iu">:</strong>n _ neighbors，weights，leaf_size，p</p><h1 id="f9ca" class="nt la it bd lb nu op nw le nx oq nz lh jz or ka ll kc os kd lp kf ot kg lt od bi translated">6.朴素贝叶斯</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/ae4d607675c7f8ef78e2be2b3b23cb96.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*tYTrLRcVBBEsCqSUxFDHHA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">朴素贝叶斯(作者图片)</p></figure><p id="abb2" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">朴素贝叶斯基于<a class="ae ky" href="https://machinelearningmastery.com/bayes-theorem-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>——一种基于先验知识计算条件概率的方法，以及每个特征相互独立的朴素假设。朴素贝叶斯的最大优点是，虽然大多数机器学习算法依赖于大量的训练数据，但即使训练数据量很小，它也能表现得相对较好。高斯朴素贝叶斯是一种遵循正态分布的朴素贝叶斯分类器。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="66a4" class="kz la it oh b gy ol om l on oo">from sklearn.naive_bayes import GaussianNB<br/>gnb = GaussianNB()<br/>gnb.fit(X_train, y_train)<br/>y_pred = gnb.predict(X_test)</span></pre><p id="8256" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><a class="ae ky" href="https://www.analyticsvidhya.com/blog/2021/01/gaussian-naive-bayes-with-hyperpameter-tuning/" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">高斯朴素贝叶斯常用超参数</strong> </a>:先验，var_smoothing</p><p id="c481" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">如果你想知道更多其他机器学习算法，请查看我的列表:</p><div class="mu mv gp gr mw"><div role="button" tabindex="0" class="ab bv gv cb fp oz pa bn pb ks ex"><div class="pc l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw pd pe fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l pd pe fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="ph pi gw l"><h2 class="bd iu vq qq fp vr fr fs nd fu fw is bi translated">机器学习实用指南</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vs au vt vu vv sh vw an eh ei vx vy vz el em eo de bk ep" href="https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wa l fo"><span class="bd b dl z dk">10 stories</span></div></div></div><div class="pu dh pv fp ab pw fo di"><div class="di pm bv pn po"><div class="dh l"><img alt="Principal Component Analysis for ML" class="dh" src="../Images/1edea120a42bd7dc8ab4a4fcdd5b822d.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*swd_PY6vTCyPnsgBYoFZfA.png"/></div></div><div class="di pm bv pp pq pr"><div class="dh l"><img alt="Time Series Analysis" class="dh" src="../Images/fda8795039b423777fc8e9d8c0dc0d07.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*8sSAHftNwd_RNJ3k4VA0pA.png"/></div></div><div class="di bv ps pt pr"><div class="dh l"><img alt="deep learning cheatsheet for beginner" class="dh" src="../Images/b2a4e3806c454a795ddfae0b02828b30.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uNyD4yNMH-DnOel1wzxOOA.png"/></div></div></div></div></div></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="7047" class="nt la it bd lb nu nv nw le nx ny nz lh jz oa ka ll kc ob kd lp kf oc kg lt od bi translated">构建分类模型管道</h1><h2 id="c290" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">1.加载数据集和数据概述</h2><p id="b054" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">我选择了Kaggle上流行的数据集<a class="ae ky" href="https://www.kaggle.com/ronitf/heart-disease-uci" rel="noopener ugc nofollow" target="_blank">心脏病UCI </a>来预测基于几个健康相关因素的心脏病的存在。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qa"><img src="../Images/eda76fc627318073f4fffc63d22d7c4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*JYPGkSAKxdVdRLHyCgqe2w.png"/></div></figure><p id="6fe0" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">使用<code class="fe qb qc qd oh b">df.info()</code>获得数据集的汇总视图，包括<strong class="lx iu">数据类型、缺失数据和记录数。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/a22923770b8a6c4a1983aa64caecf122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*5I9kVmtbK4qZ3lkv3FcC0A.png"/></div></figure><h2 id="163b" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">2.探索性数据分析</h2><p id="c477" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated"><strong class="lx iu">直方图、分组条形图和箱线图</strong>是适合分类机器学习算法的EDA技术。如果你想要更全面的EDA指南，请参见我的帖子“<a class="ae ky" href="https://www.visual-design.net/post/semi-automated-exploratory-data-analysis-process-in-python" rel="noopener ugc nofollow" target="_blank">Python中的半自动探索性数据分析过程</a></p><div class="mu mv gp gr mw mx"><a href="https://www.visual-design.net/post/semi-automated-exploratory-data-analysis-process-in-python" rel="noopener  ugc nofollow" target="_blank"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">Python中的半自动探索性数据分析过程</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">本文介绍了几种使用Python实现EDA过程自动化的技术，包括单变量分析…</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">www.visual-design.net</p></div></div><div class="ng l"><div class="qf l ni nj nk ng nl ks mx"/></div></div></a></div><p id="8d57" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">单因素分析</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qg"><img src="../Images/641700e24777ce532e20ae98474bb465.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V60vNoUhjSlnqot-OgRRBw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">单变量分析(图片由作者提供)</p></figure><p id="cbda" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">直方图用于所有要素，因为所有要素都已编码为数据集中的数值。这为我们节省了通常发生在<a class="ae ky" href="https://www.visual-design.net/post/data-transformation-and-feature-engineering-in-python" rel="noopener ugc nofollow" target="_blank">特征工程</a>阶段的分类编码时间。</p><p id="a1ca" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">分类特征与目标—分组条形图</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qh"><img src="../Images/46b7525309e2873c8b186279bceefc08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eecgt_BiNZRqbVfNVg5Ilw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">分组条形图(作者图片)</p></figure><p id="eaa4" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">为了显示分类值在确定目标值时的权重，分组条形图是一种直观的表示方法。例如，性别= 1和性别= 0具有明显的目标值分布，这表明它可能对目标的预测贡献更大。相反，如果不管分类特征如何，目标分布是相同的，那么它们很可能是不相关的。</p><p id="da2e" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu">数值特征与目标值的对比——箱线图</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qi"><img src="../Images/1d8b775022f9741387e532325dfef4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgio773zeQtk1xCbhvVr9Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">箱线图(图片由作者提供)</p></figure><p id="7260" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">箱线图显示了不同目标群体的数值特征如何变化。例如，我们可以看出，当目标值为0与目标值为1时,“旧峰”具有明显的差异，这表明它是一个重要的预测因子。然而，“trestbps”和“chol”似乎不太突出，因为目标群体之间的箱线图分布相似。</p><h2 id="6982" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">3.将数据集分成训练集和测试集</h2><p id="d6fa" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">分类算法属于监督学习的范畴，因此数据集需要分成一个子集用于训练，一个子集用于测试(有时也是一个验证集)。该模型在训练集上进行训练，然后使用测试集进行检查。</p><pre class="kj kk kl km gt og oh oi oj aw ok bi"><span id="fe3c" class="kz la it oh b gy ol om l on oo">from sklearn.model_selection import train_test_split<br/>from sklearn import preprocessing</span><span id="7e15" class="kz la it oh b gy qj om l on oo">X = df.drop(['target'], axis=1)<br/>y = df["target"]</span><span id="6f57" class="kz la it oh b gy qj om l on oo">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span></pre><h2 id="7714" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">4.机器学习模型流水线</h2><p id="4f5a" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">为了创建一个管道，我将上面提到的所有分类算法的默认状态附加到模型列表中，然后迭代通过它们来训练、测试、预测和评估。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/cbeac6f6560736826aab47ca0f8650c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*Vnzg39JyDj_ee4k2PJ9RXQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型管道(图片由作者提供)</p></figure><h2 id="89c7" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">5.模型评估</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ql"><img src="../Images/26a800b74a248653d01acc07de6619af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rxLdgZhHhin5DQfJgmzyw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型评估(图片由作者提供)</p></figure><p id="2cdd" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">下面是分类模型常用评价方法的抽象解释——<strong class="lx iu">准确率、ROC &amp; AUC和混淆矩阵</strong>。以下每个指标都值得深入研究，请随意访问我关于<a class="ae ky" rel="noopener" target="_blank" href="/simple-logistic-regression-using-python-scikit-learn-86bf984f61f1">逻辑回归</a>的文章，获取更详细的说明。</p><p id="57a9" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 1。精确度</strong></p><p id="5d68" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">精确度是模型性能最直接的指标。它衡量准确预测的百分比:<em class="mt">准确性=(真阳性+真阴性)/(真阳性+假阳性+假阴性+假阳性)</em></p><p id="3c69" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 2。ROC &amp; AUC </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qm"><img src="../Images/253314f7366d4cb21ccc7906d8150c77.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*qAdEHKk-AI9oBrUe8D1zig.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ROC和AUC(图片由作者提供)</p></figure><p id="7c83" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">ROC是在不同分类阈值下<strong class="lx iu">真阳性率对</strong>假阳性率的图。AUC是ROC曲线下的面积，AUC越高表明模型性能越好。</p><p id="2e0f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><strong class="lx iu"> 3。混乱矩阵</strong></p><p id="309a" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">混淆矩阵显示实际值与预测值，并以矩阵形式汇总<strong class="lx iu">真阴性、假阳性、假阴性和真阳性值</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qn"><img src="../Images/2a70aaf8a7fd7bd3ced0b8356911e013.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*JUOYOWkBeIiIWQjngXWbKA.png"/></div></figure><p id="3920" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">然后，我们可以使用seaborn在热图中可视化混淆矩阵。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi qo"><img src="../Images/c03d94fdecfb0ffdd3799775f8b94263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hzTXK3RuhMrUORj4Aqw6uA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">混乱矩阵图(图片由作者提供)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qp"><img src="../Images/c35370226f4d0775dc2fb1e285bd1aa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*b97CYazDRZqEi7RZtEgJIA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">准确性和AUC结果(图片由作者提供)</p></figure><p id="782f" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">基于上述三种评估方法，随机森林和朴素贝叶斯的性能最好，而KNN的表现不佳。然而，这并不意味着随机森林和朴素贝叶斯是优越的算法。我们只能说，它们更适合这种规模相对较小、数据不在同一尺度的数据集。</p><p id="bbe6" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">每种算法都有自己的偏好，需要不同的数据处理和特征工程技术，例如KNN对不同尺度的特征很敏感，多重共线性会影响逻辑回归的结果。了解每种模型的特征使我们能够权衡利弊，并根据数据集选择合适的模型。</p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><p id="612a" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated">感谢您到目前为止，如果您想阅读更多来自Medium的文章并支持我的工作，我真的很感谢您使用这个附属<a class="ae ky" href="https://destingong.medium.com/membership" rel="noopener">链接</a>注册Medium会员。</p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><h1 id="ff68" class="nt la it bd lb nu nv nw le nx ny nz lh jz oa ka ll kc ob kd lp kf oc kg lt od bi translated">带回家的信息</h1><p id="8032" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">本文介绍了以下6种机器学习算法，并指导您构建模型管道来解决分类问题:</p><ol class=""><li id="9781" class="qq qr it lx b ly mo mb mp li qs lm qt lq qu mn qv qw qx qy bi translated">逻辑回归</li><li id="d48a" class="qq qr it lx b ly qz mb ra li rb lm rc lq rd mn qv qw qx qy bi translated">决策图表</li><li id="eb2d" class="qq qr it lx b ly qz mb ra li rb lm rc lq rd mn qv qw qx qy bi translated">随机森林</li><li id="1d5a" class="qq qr it lx b ly qz mb ra li rb lm rc lq rd mn qv qw qx qy bi translated">支持向量机</li><li id="684b" class="qq qr it lx b ly qz mb ra li rb lm rc lq rd mn qv qw qx qy bi translated">KNN</li><li id="e8d0" class="qq qr it lx b ly qz mb ra li rb lm rc lq rd mn qv qw qx qy bi translated">朴素贝叶斯</li></ol><h2 id="d13a" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">更多这样的资源</h2><div class="mu mv gp gr mw"><div role="button" tabindex="0" class="ab bv gv cb fp oz pa bn pb ks ex"><div class="pc l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw pd pe fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l pd pe fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="ph pi gw l"><h2 class="bd iu vq qq fp vr fr fs nd fu fw is bi translated">机器学习实用指南</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vs au vt vu vv sh vw an eh ei vx vy vz el em eo de bk ep" href="https://destingong.medium.com/list/practical-guides-to-machine-learning-a877c2a39884?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wa l fo"><span class="bd b dl z dk">10 stories</span></div></div></div><div class="pu dh pv fp ab pw fo di"><div class="di pm bv pn po"><div class="dh l"><img alt="Principal Component Analysis for ML" class="dh" src="../Images/1edea120a42bd7dc8ab4a4fcdd5b822d.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*swd_PY6vTCyPnsgBYoFZfA.png"/></div></div><div class="di pm bv pp pq pr"><div class="dh l"><img alt="Time Series Analysis" class="dh" src="../Images/fda8795039b423777fc8e9d8c0dc0d07.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*8sSAHftNwd_RNJ3k4VA0pA.png"/></div></div><div class="di bv ps pt pr"><div class="dh l"><img alt="deep learning cheatsheet for beginner" class="dh" src="../Images/b2a4e3806c454a795ddfae0b02828b30.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*uNyD4yNMH-DnOel1wzxOOA.png"/></div></div></div></div></div><div class="mu mv gp gr mw mx"><a rel="noopener follow" target="_blank" href="/how-to-self-learn-data-science-in-2022-a537a76d138e"><div class="my ab fo"><div class="mz ab na cl cj nb"><h2 class="bd iu gy z fp nc fr fs nd fu fw is bi translated">2022年如何自学数据科学</h2><div class="ne l"><h3 class="bd b gy z fp nc fr fs nd fu fw dk translated">基于项目的数据科学入门方法</h3></div><div class="nf l"><p class="bd b dl z fp nc fr fs nd fu fw dk translated">towardsdatascience.com</p></div></div><div class="ng l"><div class="re l ni nj nk ng nl ks mx"/></div></div></a></div><div class="mu mv gp gr mw"><div role="button" tabindex="0" class="ab bv gv cb fp oz pa bn pb ks ex"><div class="pc l"><div class="ab q"><div class="l di"><img alt="Destin Gong" class="l de bw pd pe fe" src="../Images/dcd4375055f8aa7602b1433a60ad5ca3.png" width="20" height="20" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:40:40/1*_qYYfgLTcvZF3zhHO0yVdA@2x.jpeg"/><div class="fb bw l pd pe fc n aw fd"/></div><div class="hh l fo"><p class="bd b dl z fp fq fr fs ft fu fv fw dk translated"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://destingong.medium.com/?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">德斯坦贡</a></p></div></div><div class="ph pi gw l"><h2 class="bd iu vq qq fp vr fr fs nd fu fw is bi translated">开始学习数据科学</h2></div><div class="ab q"><div class="l fo"><a class="bd b be z bi vs au vt vu vv sh vw an eh ei vx vy vz el em eo de bk ep" href="https://destingong.medium.com/list/get-started-in-data-science-8006bb4ba3ad?source=post_page-----2197870ff501--------------------------------" rel="noopener follow" target="_top">View list</a></div><div class="wa l fo"><span class="bd b dl z dk">8 stories</span></div></div></div><div class="pu dh pv fp ab pw fo di"><div class="di pm bv pn po"><div class="dh l"><img alt="" class="dh" src="../Images/d302bbd526df8af0e847419971dc535a.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*__Lp9NvZvtLrZ00KKyoS_A.png"/></div></div><div class="di pm bv pp pq pr"><div class="dh l"><img alt="Statistical Tests in Python" class="dh" src="../Images/2ff8d4b6d8bd95fde596b31de22ef09e.png" width="194" height="194" loading="lazy" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*2hGMrCjLtVKtOKD_QnyuWA.png"/></div></div><div class="di bv ps pt pr"><div class="dh l"><img alt="" class="dh" src="../Images/ae659430af3f4c100a2e11f1f558462c.png" width="194" height="194" loading="lazy" role="presentation" data-original-src="https://miro.medium.com/v2/resize:fill:388:388/1*wCpwHS7BWBe6JnHfIMSWrQ.png"/></div></div></div></div></div></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="rf rg l"/></div></figure><p id="cbe3" class="pw-post-body-paragraph lv lw it lx b ly mo ju ma mb mp jx md li mq mf mg lm mr mi mj lq ms ml mm mn im bi translated"><em class="mt">原载于2022年2月22日https://www.visual-design.net</em><em class="mt">的</em> <a class="ae ky" href="https://www.visual-design.net/post/3-ux-design-principles-for-better-data-visualization" rel="noopener ugc nofollow" target="_blank"> <em class="mt">。</em></a></p></div></div>    
</body>
</html>