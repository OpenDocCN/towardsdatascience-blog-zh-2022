<html>
<head>
<title>Clustering Algorithm Fundamentals and an Implementation in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类算法基础及其Python实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-algorithm-fundamentals-and-an-implementation-in-python-31a482592b04#2022-09-01">https://towardsdatascience.com/clustering-algorithm-fundamentals-and-an-implementation-in-python-31a482592b04#2022-09-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8f50" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">创建包含相似元素的数据组的无监督过程</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/539b54cf6c325fc96e6cc29ae0e51bff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eEi64AE8jGD_p8qmh_4tyA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">伊恩·杜利在<a class="ae ky" href="https://unsplash.com/s/photos/assortment?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><h1 id="ae5a" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">什么是集群？</h1><p id="a2ab" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">聚类是一种可以通过创建有意义的组或簇来帮助机器学习工程师理解未标记数据的方法。这通常会揭示数据中的模式，这可能是机器学习中有用的第一步。由于您正在处理的数据是未标记的，<strong class="lt iu">聚类</strong>是一项无监督的机器学习任务。</p><p id="c151" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">通过一个称为<strong class="lt iu">相似性度量</strong>的度量标准，数据根据彼此的相似性被分类成组，其中<strong class="lt iu"> </strong>用于找出数据集中对象的相似程度。为了计算这种相似性度量，使用数据集中对象的特征数据<strong class="lt iu"/>。为每个集群提供一个<strong class="lt iu">集群ID </strong>，这是一个强大的集群应用。这样可以简化大型数据集，还可以将对象的整个特征集压缩到其分类ID中。</p><p id="50f9" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">这一原则的一个简单现实例子是收集关于家庭规模和家庭收入的数据，以创建用户群，如小家庭高消费群、小家庭低消费群、大家庭高消费群和大家庭低消费群。</p><h1 id="2d6f" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">聚类的用途</h1><p id="dad1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">如今，集群被广泛应用于行业中的各种用例。其中包括搜索结果分组、社交网络分析和市场细分。聚类也用于图像分割、异常检测和医学成像。</p><p id="c861" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">扩展上面提到的集群id的优点，集群可以用于根据不同的特征对对象进行分组。例如，星星可以根据亮度分组，音乐可以根据流派分组。</p><p id="28a2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在像Google这样的组织中，集群用于:</p><ul class=""><li id="06a5" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">概化:当集群中的对象缺少要素数据时，可以从集群中的其他对象推断出它们。</li><li id="d70f" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">数据压缩:特征数据可以完全由集群ID代替。这节省了存储空间并简化了特征空间。这有助于使ML模型训练更简单、更快速。</li><li id="16f9" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">保护隐私:将用户分组并将他们的数据与集群id相关联可以防止将用户数据与特定用户相关联，从而确保用户隐私。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/5ef17101fc76351a03938800a815e5a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*tq87toRdl9g0tz6C8M7JZQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">聚类分析的结果。来源:hellisp，公共领域，via <a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Cluster-2.png" rel="noopener ugc nofollow" target="_blank"> Wikimedia Commons </a></p></figure><h1 id="db61" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">聚类算法</h1><p id="bfc2" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在我们已经了解了聚类的概念，让我们看看一些常见的聚类算法。关于详尽的清单，你可以参考<a class="ae ky" href="https://link.springer.com/article/10.1007/s40745-015-0040-1" rel="noopener ugc nofollow" target="_blank">这篇论文</a>。</p><h2 id="3dde" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">分层聚类</h2><p id="e8af" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这种方法适用于分层数据，它创建了一个聚类树。对于大多数数据集来说，标准算法太慢，因为它的时间复杂度为O(n ),内存需求为ω(n)。然而，运行时间的减少是以内存需求为代价的，尽管内存开销在大多数情况下很难实际使用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/71011234fc43f7118e0fba1992cc49ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8KFd7H2mPl781Je9YK4zag.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Orange_(software)" rel="noopener ugc nofollow" target="_blank"> Orange数据挖掘套件</a>中的层次聚类和交互式树状图可视化。<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Orange-data-mining-hierarchical-clustering.png" rel="noopener ugc nofollow" target="_blank">blazupan(橙色数据挖掘)</a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 4.0 </a>，通过维基共享</p></figure><h2 id="55b2" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">基于分布的聚类</h2><p id="f393" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在这些算法中，假设数据属于不同的分布。然后，集群被定义为那些包含相似分布的对象的集群。一个缺点是基于分布的聚类容易过度拟合。因此，必须对模型的复杂性加以限制。</p><p id="87f3" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下图显示了一个示例，其中数据被聚类为三个高斯分布。较暗的颜色更接近分布的中心，条带显示数据属于某个分类的概率强度。随着到中心的距离增加，数据属于该聚类的可能性将降低。</p><p id="62a6" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您没有关于数据集分布类型的信息，此算法可能不是最好的。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/ce293641951a61d55bf2afdf48a4c63d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bAx9_8PmRZA6tin5AlnxyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基于高斯分布的聚类。由Chire-Own工作，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=17085713" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 3.0 </a>，通过维基共享</p></figure><h2 id="a5d2" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">基于密度的聚类</h2><p id="37f1" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这些算法通过连接包含高密度对象的区域来创建聚类。它要求密集区域是可连接的，并且根据设计，离群值不会被分配给聚类。一个缺点是基于密度的聚类算法在处理更高维度以及具有不同密度的数据时面临困难。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/be7ebae131dda7528950b398f55be1b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WqPXKK37rZtIR7LJ78pnVA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用<a class="ae ky" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank"> DBSCAN </a>算法对基于密度的数据集进行聚类分析。<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:DBSCAN-density-data.svg" rel="noopener ugc nofollow" target="_blank"> Chire </a>，<a class="ae ky" href="https://creativecommons.org/licenses/by-sa/3.0" rel="noopener ugc nofollow" target="_blank"> CC BY-SA 3.0 </a>，通过维基共享</p></figure><h2 id="9fd7" class="nh la it bd lb ni nj dn lf nk nl dp lj ma nm nn ll me no np ln mi nq nr lp ns bi translated">基于质心的聚类</h2><p id="3f3e" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这种形式的聚类将数据分组到非分层分区中。虽然这些类型的算法是有效的，但它们对初始条件和异常值很敏感。最常用的基于质心的算法称为k-means，其中k是定义聚类数量的超参数。</p><p id="1ada" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">K-means提供了一些优势，例如扩展到大型数据集的能力、易于实现以及适应新数据。另一方面，<em class="nw"> k </em>值必须费些力气手动找到，并且质心会被离群值拖动。考虑在聚类之前移除离群值是有益的。</p><p id="7c92" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">给定一组n个数据点，k-means算法的目标是将它们分成k个组，其中每个组包含相似的数据点。为了做到这一点，我们首先需要选择一个数字k，然后我们开始随机分配每个点到它最近的聚类中心。接下来，计算每个数据点与其指定中心之间的距离。然后，我们重复上述步骤，直到没有进一步的变化发生。一旦我们完成了距离和中心的计算，我们返回到步骤1并重新计算聚类。这种情况一直持续到集群没有变化。此时，我们知道我们的集群是稳定的。</p><h1 id="b8ea" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">k均值算法的实现</h1><p id="ed24" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">现在，让我们实现上面讨论的算法之一，并可视化产生的集群。为此，我们将使用k-means算法和scikit-learn。该代码受<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py" rel="noopener ugc nofollow" target="_blank"> scikit-learn examples </a>提供的手写数字数据K-Means聚类演示的启发，并包含其中的代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">实现k均值。包含来自<a class="ae ky" href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py" rel="noopener ugc nofollow" target="_blank"> scikit-learn示例</a> ( <a class="ae ky" href="https://github.com/scikit-learn/scikit-learn/blob/main/COPYING" rel="noopener ugc nofollow" target="_blank"> BSD许可证</a>)的代码</p></figure><p id="5363" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">输出如下图所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/6d9d656e2818048844ad2268e44f96c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*u62bMka-HpRlDOGOBchO_Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">结果图是从上面的代码中产生的。</p></figure><p id="1f60" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">除了k-means算法之外，scikit-learn库还提供了其他几种算法，可以根据您所拥有的数据来使用。这些算法包括:</p><ul class=""><li id="fced" class="ms mt it lt b lu mn lx mo ma mu me mv mi mw mm mx my mz na bi translated">亲和传播</li><li id="e0e3" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">凝聚聚类</li><li id="fbc3" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">桦树</li><li id="8523" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">基于密度的噪声应用空间聚类</li><li id="1961" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">k均值</li><li id="383c" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">小批量K均值</li><li id="04bd" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">光学</li><li id="4355" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">谱聚类</li><li id="ebb2" class="ms mt it lt b lu nb lx nc ma nd me ne mi nf mm mx my mz na bi translated">高斯混合</li></ul><p id="e0dd" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">请记住，没有固定的算法可以提供最好的结果。您必须运行受控实验，以确定最适合您正在处理的数据集的算法。</p><p id="ddfa" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">如果您想更深入地研究所提供的算法，scikit-learn集群API 是一个很好的起点。</p><h1 id="df2e" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="2b77" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我们研究了集群、其用途以及一些常用的集群算法类型。我们还研究了它们的优缺点，以及一些算法与其他算法相比的闪光点。最后，我们看了一个如何进行k均值聚类的编码示例。我希望这些信息对你有用。请在下面的评论区告诉我你的想法和问题。</p></div></div>    
</body>
</html>