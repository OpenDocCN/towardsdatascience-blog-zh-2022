<html>
<head>
<title>Rise of Spark for Big Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据科学火花的升起</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/rise-of-spark-for-big-data-analytics-e794ca75855d#2022-06-18">https://towardsdatascience.com/rise-of-spark-for-big-data-analytics-e794ca75855d#2022-06-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f722" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Apache Spark已经成为处理大数据的首选解决方案。让我们来看看Spark受欢迎背后的三个原因。</h2></div><p id="e01f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着可用于处理和分析的数据量增加，我们看到了向分布式系统的缓慢但明确的转变(查看我关于分布式系统崛起的文章，特别是Hadoop <a class="ae lb" href="https://medium.com/codex/journey-to-hadoop-e2dbc30acc" rel="noopener">这里</a>)。然而，在21世纪初，数据科学和“大数据”的机器学习仍然具有挑战性。当时的尖端解决方案(如Hadoop)依赖于Map Reduce，这在一些关键方面存在不足</p><ul class=""><li id="9d1e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">在数据科学过程中，大部分时间花在探索性数据分析、特征工程和选择上。这需要对数据进行复杂的多步转换，很难仅使用Hadoop中的Map和Reduce函数来表示，这将花费大量开发时间并产生复杂的代码库。因此，需要一种支持复杂数据转换的解决方案。</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/c22a4f63e848b88811329b39fceeeb7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chkIcmwnjpvHMGiCaBBt0w.jpeg"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">使用MapReduce分析数据可以…..令人沮丧(照片由<a class="ae lb" href="https://unsplash.com/@siora18?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Siora摄影</a>在<a class="ae lb" href="https://unsplash.com/s/photos/frustrated?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄)</p></figure><ul class=""><li id="f52f" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">数据科学是一个迭代过程，Hadoop中典型的Map-Reduce操作需要每次从磁盘读取数据，这使得每次迭代都非常耗时且成本高昂。因此，需要一种解决方案来减少数据科学过程每次迭代的时间。</li><li id="303e" class="lc ld iq kh b ki mb kl mc ko md ks me kw mf la lh li lj lk bi translated">模型需要生产、部署和维护。因此，我们需要一个框架，不仅允许我们分析数据，还允许我们在生产中开发和部署模型。Hadoop不支持前面提到的迭代分析，R/Python等框架也不能很好地扩展到大型数据集。因此，需要一种解决方案<strong class="kh ir"> </strong>来支持大数据的迭代分析，并生产生成的ML模型。</li></ul><p id="7314" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进入阿帕奇火花。</p><p id="8526" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它在2014年首次发布时就考虑到了上述需求。Spark保留了Hadoop的可伸缩性和容错性(查看我的<a class="ae lb" href="https://medium.com/codex/journey-to-hadoop-e2dbc30acc" rel="noopener"> Hadoop </a>文章了解更多细节),并在此基础上构建了以下特性</p><ul class=""><li id="47a0" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">包括<a class="ae lb" href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#transformations" rel="noopener ugc nofollow" target="_blank">广泛的操作列表</a>(除了map和reduce之外),允许仅用几行代码构建复杂的数据处理/分析系统。此外，为Spark开发的MLlib库有助于像使用Scikit learn一样直观地构建ML模型。这减少了开发人员/科学家的时间，并使代码库更易于维护。</li><li id="f6b4" class="lc ld iq kh b ki mb kl mc ko md ks me kw mf la lh li lj lk bi translated">Spark利用一个<a class="ae lb" href="https://data-flair.training/blogs/dag-in-apache-spark/#:~:text=What%20is%20DAG%20in%20Apache%20Spark?,to%20later%20in%20the%20sequence." rel="noopener ugc nofollow" target="_blank">有向无环图</a>或‘DAG’(把它想象成一个流程图)来跟踪你想要对你的数据执行的操作。因此，与Hadoop不同的是，在Hadoop中，您会将一系列Map Reduce作业串在一起，每个作业都需要从磁盘读取和写入，而Spark DAG可以帮助您将操作串在一起，而不必写出中间结果。这意味着多步数据处理/分析作业将运行得更快。Spark还能够在内存中缓存中间结果。这在机器学习中特别有用，在机器学习中，您可以执行预处理并缓存结果训练数据，以便在优化期间可以从内存中重复访问它(因为梯度下降等优化算法将多次迭代训练数据)。在Hadoop Map-Reduce中，必须从磁盘访问列车数据，这使得该过程非常耗时。</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi mg"><img src="../Images/03b4bffeaf3b26790995d7cad0fea0eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j2WEoA9QxWxMQM5P7mGu6A.jpeg"/></div></div><p class="lx ly gj gh gi lz ma bd b be z dk translated">使用Map Reduce优化逻辑回归？可能要等很久了……(图片由<a class="ae lb" href="https://unsplash.com/s/photos/waiting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae lb" href="https://unsplash.com/@13on?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">13拍摄)</a></p></figure><ul class=""><li id="6453" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">Spark不仅可以以迭代和交互的方式分析数据(可以与jupyter笔记本集成)，还可以构建生产级数据处理和机器学习管道。</li></ul><p id="b815" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些特性使Apache Spark在过去十年中成为分布式数据科学和机器学习的首选框架，现在几乎可以在所有处理真正大数据的组织中找到。</p><p id="585b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本系列的下一篇文章将介绍如何使用Apache Spark，从Scala的基础知识开始，Scala是编写Spark程序的理想语言。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="22aa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参考文献。</p><p id="f1eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Sandy Ryza等人在《Spark高级分析:大规模数据学习模式》一书中指出了Spark在大数据分析方面的优势。</p></div></div>    
</body>
</html>