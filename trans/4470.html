<html>
<head>
<title>An Intro to Discretization Techniques for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的离散化技术介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intro-to-discretization-techniques-for-machine-learning-93dce1198e68#2022-10-04">https://towardsdatascience.com/an-intro-to-discretization-techniques-for-machine-learning-93dce1198e68#2022-10-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="012b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">概述和Python实现</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2316804c3b5500b75cb8a34a19df1d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5H-4coVRx_Bm9iyLzSnPQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由Vladislav Vasnetsov拍摄:<a class="ae ky" href="https://www.pexels.com/photo/assorted-color-plastic-trash-bins-2682683/" rel="noopener ugc nofollow" target="_blank">https://www . pexels . com/photo/mished-color-plastic-trash-bins-2682683/</a></p></figure><p id="1822" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多机器学习算法在用离散变量训练时表现更好。因此，特征工程程序通常会包含离散化。你可能会发现，机器学习竞赛中的许多获奖作品都利用了这一技术。</p><p id="e64c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不要被5音节词吓倒。离散化只需要将连续值转换成离散的类别。这是统计学中的一个常见概念，通常被称为“宁滨”或“木桶理论”。</p><p id="7654" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">离散化在机器学习中有许多优点，并且在Python中易于执行，这将详细解释。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="cd5f" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">利益</h2><p id="4add" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">乍一看，将连续变量转换成离散变量的概念似乎是不必要的，但将这一步骤包括在特征工程过程中有许多好处。</p><ol class=""><li id="6d0a" class="na nb it lb b lc ld lf lg li nc lm nd lq ne lu nf ng nh ni bi translated"><strong class="lb iu">降低噪音</strong></li></ol><p id="81ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">连续变量倾向于存储具有微小波动的信息，这对感兴趣的机器学习任务没有提供附加值。处理这样的值将导致模型产生大量噪声，这不可避免地会影响性能。</p><p id="9990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">离散化解决了这一问题，使用户能够通过创建包含更少唯一值的分布来限制这种噪声。</p><p id="19e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。提供直观的功能</strong></p><p id="f986" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据不同的用例，离散变量可能比连续变量更直观。</p><p id="2aa5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果要建立一个比较年轻人和老年人的因果模型，可能值得将年龄记录为离散变量(例如，“儿童”、“成人”和“老年人”)，而不是连续变量。</p><p id="3f73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将使模型的结果更容易解释，因为特性是为应用程序定制的。</p><p id="bafc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。最小化异常影响</strong></p><p id="c206" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，离散化减轻了离群值的影响。无论异常值对值分布的倾斜程度如何，在转换后，它都将被转换为较高或较低的组。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="ccc6" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">缺点</h2><p id="2cd0" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">尽管有很多好处，离散化有一个明显的缺点:信息丢失。</p><p id="0e22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，这是特征工程中许多转换的特征。像归一化和主成分分析(PCA)这样的技术自然会导致一些信息损失。</p><p id="96af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，离散化中的信息损失不一定很大，但是在考虑转换后应该有多少个离散值时，值得记住。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="a9b0" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">离散化的类型</h2><p id="1017" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">有许多方法可以在Python中实现离散化。</p><p id="c000" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以促进这种转换的两个最突出的Python包是:<a class="ae ky" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>和<a class="ae ky" href="https://feature-engine.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> feature_engine </a>。</p><p id="f73d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了展示这些包提供的一些转换器，让我们使用下面的虚构数据，这些数据由预测特征“年龄”和目标标签“糖尿病”组成。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/48f3776a799dfdba4e597e594a831067.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*cveSJvpznrj-4kLzOvv4ew.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="51d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目标是使用各种可用的离散化方法将年龄特征中的值转换成5个离散组。</p><p id="c9ad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用以下函数来可视化转换，并突出显示每种方法的特性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="1324" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。等频离散化</strong></p><p id="ea29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">等频率离散化需要将连续数据转换成箱，每个箱具有相同(或相似)数量的记录。</p><p id="1f16" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了在Python中实现这个方法，我们可以使用scikit-learn包的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html" rel="noopener ugc nofollow" target="_blank"> KBinsDiscretizer </a>，其中的<code class="fe nm nn no np b">strategy</code>超参数被设置为“分位数”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/dd222cfdc1f6f729891151c049d05cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*BWgnU05gTAc9jkvSL0KDiA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="821b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就观察数量而言，这5个箱相对接近。然而，为了获得这种均匀性，每个箱的宽度必须是不均匀的。</p><p id="86ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以用feature_engine包中的<a class="ae ky" href="https://feature-engine.readthedocs.io/en/0.6.x_a/discretisers/EqualFrequencyDiscretiser.html" rel="noopener ugc nofollow" target="_blank">equalfrequencydiscreditser</a>来执行这个转换。</p><p id="cdad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。等宽离散化</strong></p><p id="1f72" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顾名思义，等宽离散化将数据转换为具有相同宽度的条块。与等频率离散化非常相似，我们可以将这种技术与sci-kit learn包的KBinsDiscretizer一起使用。但是，<code class="fe nm nn no np b">strategy</code>超参数应设置为“统一”。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/4959af530745117b74a11fd12d08f6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*D2t54HXwJwAcjhQyMG6FQA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="d849" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如输出所示，所有创建的条块的宽度为15.4。</p><p id="2e8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们也可以通过使用feature_engine包的<a class="ae ky" href="https://feature-engine.readthedocs.io/en/0.6.x_a/discretisers/EqualWidthDiscretiser.html" rel="noopener ugc nofollow" target="_blank"> EqualWidthDiscretiser </a>来执行这个转换。</p><p id="211e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。k-均值离散化</strong></p><p id="7aab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">k-均值离散化需要使用k-均值聚类算法将数据点分配给箱。</p><p id="5a57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也可以用scikit-learn包的KBinsDiscretizer来执行，其中的<code class="fe nm nn no np b">strategy</code>超参数被设置为‘k means’。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/db04e7f0c0998401c1f4c9299a205f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*U4Rupsw4V5ZcLRCCf_e2SA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="ab0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4。决策树离散化</strong></p><p id="b8d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">决策树离散化与之前的方法不同，它是一种<em class="nt">监督的</em>学习技术，这意味着它需要使用目标标签来转换连续变量。</p><p id="08a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顾名思义，它使用决策树算法寻找理想的分割点来分割观察值。</p><p id="91d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用feature_engine包中的<a class="ae ky" href="https://feature-engine.readthedocs.io/en/1.0.x/discretisation/DecisionTreeDiscretiser.html" rel="noopener ugc nofollow" target="_blank">decision tree discrete ser</a>来实现这一技术。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/3f7e3bf188e0bb74081f3824b7268602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*Nb7I2JIb3r-PzOIkE8VPBw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><p id="2a51" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 5。自定义离散化</strong></p><p id="14c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，用户可以选择根据自定义规则将其连续变量转换为离散值。具有一定领域知识的用户可以受益于创建具有预定义宽度的箱子。</p><p id="220f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们的示例中，假设我们希望将年龄特征转换为预定义的组，包括年龄组“1–12”、“13–18”、“19–30”、“31–60”和“60–80”。</p><p id="2777" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用Python中的feature_engine包的<a class="ae ky" href="https://feature-engine.readthedocs.io/en/1.2.x/user_guide/discretisation/ArbitraryDiscretiser.html" rel="noopener ugc nofollow" target="_blank">arbitrary discretizer</a>来实现这一点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/ed29f3a29fa3cf4dd295605af5a9194d.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*C3lJ8ZPsBe3FhQT_r8A94w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码输出(由作者创建)</p></figure><h2 id="7467" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">关于feature_engine包的说明</h2><p id="33c9" class="pw-post-body-paragraph kz la it lb b lc mv ju le lf mw jx lh li mx lk ll lm my lo lp lq mz ls lt lu im bi translated">值得注意的是，feature_engine转换器与scikit-learn工具兼容，这意味着它们可以与其他转换器一起用于无缝的特征工程过程。</p><p id="81ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了展示这一点，我们可以将feature_engine包的EqualWidthDiscretiser合并到sci-kit学习管道中，以生成预测作为示例。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h2 id="f462" class="mc md it bd me mf mg dn mh mi mj dp mk li ml mm mn lm mo mp mq lq mr ms mt mu bi translated">结论</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/5299cbbe24dd8422d55c501712e4b3b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5gLKxsI3kdog-vyF"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@prateekkatyal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Prateek Katyal </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="d970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有时候，最简单的转换比最复杂的机器学习算法能获得更多的好处。</p><p id="0a88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像噪声和极值这样的因素在数据集中普遍存在，很难通过增加模型的复杂性来克服。</p><p id="64f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">长期以来，离散化被证明是一种将数据转换为更易于管理的有效方法，从而改善了任何后续建模的结果。这就是为什么这种技术通常包含在机器学习竞赛的获奖作品中。</p><p id="0b5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我祝你在数据科学的努力中好运！</p></div></div>    
</body>
</html>