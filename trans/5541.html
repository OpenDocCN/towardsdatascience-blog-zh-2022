<html>
<head>
<title>How to Perform Speech-to-Text and Translate Any Speech to English With OpenAI’s Whisper</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 OpenAI 的 Whisper 执行语音到文本转换并将任何语音翻译成英语</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-perform-speech-to-text-and-translate-any-speech-to-english-with-openais-whisper-50e3a366cbca#2022-12-14">https://towardsdatascience.com/how-to-perform-speech-to-text-and-translate-any-speech-to-english-with-openais-whisper-50e3a366cbca#2022-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f26" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用前沿的 NLP 模型进行音频转录到文本和机器翻译。</h2></div><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><h1 id="4f91" class="kp kq it bd kr ks kt ku kv kw kx ky kz jz la ka lb kc lc kd ld kf le kg lf lg bi translated">介绍</h1><p id="99d2" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">OpenAI 是人工智能领域的纯粹玩家，并向社区提供了许多人工智能模型，包括<a class="ae md" href="https://arxiv.org/abs/2005.14165" rel="noopener ugc nofollow" target="_blank"/>、<a class="ae md" href="https://www.pinecone.io/learn/clip-image-search/" rel="noopener ugc nofollow" target="_blank"> CLIP </a>等。</p><p id="e6b3" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">由 OpenAI 开源的 Whisper 模型被认为在英语语音识别中已经接近人类水平的鲁棒性和准确性。</p><p id="1909" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">本文将尝试向您介绍使用<strong class="lj iu"> HugginFaces Transformers </strong>框架，通过 OpenAI 的 Whisper 将长段音频转换成文本信息的所有步骤。</p><p id="68dc" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">在这篇文章的结尾，你将能够把英语和非英语的音频翻译成文本。</p><h1 id="7a49" class="kp kq it bd kr ks kt ku kv kw kx ky kz jz la ka lb kc lc kd ld kf le kg lf lg bi translated">OpenAI 的耳语— Kézako？</h1><p id="6977" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">已经开发了耳语模型来研究用于语音识别和翻译任务的语音处理系统的能力。他们有能力将语音音频转录成文本。</p><p id="5232" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">根据 680，000 小时的标记音频数据进行训练，作者<a class="ae md" href="https://cdn.openai.com/papers/whisper.pdf" rel="noopener ugc nofollow" target="_blank">报告称这是监督语音识别领域有史以来最大的一次训练。此外，通过对一系列中等大小的模型进行训练来评估模型的性能，这些模型基于对应于完整数据集大小的 0.5%、1%、2%、4%和 8%的二次抽样版本的数据，如下所示。</a></p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/fd51462f45583f2da3cd62226b9b7188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*6fDQTKIf6z3ZMq7FOHcKrg.png"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">原始训练数据的 5 个不同的二次抽样版本(图片由作者提供)</p></figure><h1 id="a0ac" class="kp kq it bd kr ks kt ku kv kw kx ky kz jz la ka lb kc lc kd ld kf le kg lf lg bi translated">逐步实施</h1><p id="0154" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本节涵盖了从安装和导入相关模块到实施音频转录和翻译案例的所有步骤。</p><h2 id="0ae0" class="mq kq it bd kr mr ms dn kv mt mu dp kz lq mv mw lb lu mx my ld ly mz na lf nb bi translated">安装和初始化</h2><p id="968e" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">首先，您需要在计算机上安装<a class="ae md" href="https://www.python.org/downloads/" rel="noopener ugc nofollow" target="_blank"> Python </a>和 Whisper 库，最新的稳定版本可以使用 Python 包管理器<code class="fe nc nd ne nf b">pip</code>安装，如下所示:</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="6446" class="nk kq it nf b be nl nm l nn no">!pip install git+https://github.com/openai/whisper.git </span></pre><p id="b02f" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">现在，我们需要安装并导入用于音频和视频处理的<code class="fe nc nd ne nf b">ffmpeg</code>模块。根据您的操作系统，安装过程可能有所不同。</p><p id="fe6a" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">由于我用的是 MAC，下面是相应的流程:</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="d6ca" class="nk kq it nf b be nl nm l nn no"># Installation for MAC<br/>brew install ffmpeg</span></pre><p id="cb0f" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">请参考适合您情况的正确代码片段</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="af42" class="nk kq it nf b be nl nm l nn no"># on Ubuntu or Debian<br/>sudo apt update &amp;&amp; sudo apt install ffmpeg<br/><br/># on Windows using Chocolatey (https://chocolatey.org/)<br/>choco install ffmpeg<br/><br/># on Windows using Scoop (https://scoop.sh/)<br/>scoop install ffmpeg</span></pre><blockquote class="np nq nr"><p id="ff53" class="lh li ns lj b lk me ju lm ln mf jx lp nt mg ls lt nu mh lw lx nv mi ma mb mc im bi translated">如果您不想为所有这些配置费心，该怎么办呢？</p></blockquote><p id="ca22" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">→在这种情况下，Google collab 可以拯救你的生命，它还提供了一个免费的 GPU，你可以按如下方式访问:</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi nw"><img src="../Images/2814ffcd88d7f5dea1744032995c828d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLvAj2YpB-5iopu3mVBkgQ.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">在 Google Colab 上使用 GPU 的运行时配置(图片来自作者)</p></figure><p id="f209" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">使用<code class="fe nc nd ne nf b">nvidia-smi</code>我们可以有关于分配给你的 GPU 的信息，这是我的。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="7e61" class="nk kq it nf b be nl nm l nn no">!nvidia-smi</span></pre><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ob"><img src="../Images/f373b48a053e7de479d3b5b60304f891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G-JhH5G9zlzRu4MkKJsxRg.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">我的 Google Colab 上的 GPU 信息(图片由作者提供)</p></figure><p id="7e78" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">一旦您安装了所有的东西，您就可以导入模块并加载模型了。在我们的例子中，我们将使用具有 1550M 参数的大型模型，并且需要大约 10g 字节的 VRAM 存储器。无论您使用的是 CPU 还是 GPU，处理时间都可能会更长或更快。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="1877" class="nk kq it nf b be nl nm l nn no"># Import the libraries <br/>import whisper<br/>import torch<br/>import os<br/><br/># Initialize the device<br/>device = "cuda" if torch.cuda.is_available() else "cpu"<br/><br/># Load the model <br/>whisper_model = whisper.load_model("large", device=device)</span></pre><ul class=""><li id="ede1" class="oc od it lj b lk me ln mf lq oe lu of ly og mc oh oi oj ok bi translated">在<code class="fe nc nd ne nf b">load_model()</code>函数中，我们使用了之前行中初始化的<code class="fe nc nd ne nf b">device</code>。默认情况下，如果没有另外指定，新创建的张量是在 CPU 上创建的。</li></ul><p id="b56c" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">现在是开始提取音频文件的时候了…</p><h2 id="1ed0" class="mq kq it bd kr mr ms dn kv mt mu dp kz lq mv mw lb lu mx my ld ly mz na lf nb bi translated">音频转录</h2><p id="5c92" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">本节说明了 Whisper 在录制不同语言的音频方面的优势。</p><p id="47ec" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">这一部分的一般工作流程如下。</p><figure class="ki kj kk kl gt km gh gi paragraph-image"><div role="button" tabindex="0" class="nx ny di nz bf oa"><div class="gh gi ol"><img src="../Images/68c1406b8b962cb705844b3e347ca301.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*flkrKEOZHWceGJXDzoAnOA.png"/></div></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">文章的语音转文本工作流(图片由作者提供)</p></figure><p id="0530" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">前两步是用下面的助手函数执行的。但在此之前，我们需要使用下面的<code class="fe nc nd ne nf b">pip</code>语句安装<code class="fe nc nd ne nf b"><a class="ae md" href="https://pytube.io/en/latest/" rel="noopener ugc nofollow" target="_blank">pytube</a></code>库，以便从 YouTube 下载音频。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="54ac" class="nk kq it nf b be nl nm l nn no"># Install the module<br/>!pip install pytube<br/><br/># Import the module<br/>from pytube import YouTube</span></pre><p id="a1b8" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">然后，我们可以如下实现助手函数:</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="9402" class="nk kq it nf b be nl nm l nn no">def video_to_audio(video_URL, destination, final_filename):<br/><br/>  # Get the video<br/>  video = YouTube(video_URL)<br/><br/>  # Convert video to Audio<br/>  audio = video.streams.filter(only_audio=True).first()<br/><br/>  # Save to destination<br/>  output = audio.download(output_path = destination)<br/><br/>  _, ext = os.path.splitext(output)<br/>  new_file = final_filename + '.mp3'<br/><br/>  # Change the name of the file<br/>  os.rename(output, new_file)</span></pre><p id="9618" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">该函数有三个参数:</p><ul class=""><li id="ddbd" class="oc od it lj b lk me ln mf lq oe lu of ly og mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">video_URL</code>YouTube 视频的完整网址。</li><li id="2d43" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">destination</code>保存最终音频的位置。</li><li id="f39f" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">final_filename</code>最终音频的名称。</li></ul><p id="c2c4" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">最后，我们可以使用功能下载视频并将其转换为音频。</p><h2 id="8823" class="mq kq it bd kr mr ms dn kv mt mu dp kz lq mv mw lb lu mx my ld ly mz na lf nb bi translated">英语转录</h2><p id="b73a" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">这里使用的视频是来自激励 Quickie 的<a class="ae md" href="https://www.youtube.com/watch?v=E9lAeMz1DaM" rel="noopener ugc nofollow" target="_blank"> YouTube 上的 30 秒激励演讲。只有前 17 秒对应于真实的语音，而语音的其余部分是噪声。</a></p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="ecc8" class="nk kq it nf b be nl nm l nn no"># Video to Audio<br/>video_URL = 'https://www.youtube.com/watch?v=E9lAeMz1DaM'<br/>destination = "."<br/>final_filename = "motivational_speech"<br/>video_to_audio(video_URL, destination, final_filename)<br/><br/># Audio to text<br/>audio_file = "motivational_speech.mp3"<br/>result = whisper_model.transcribe(audio_file)<br/><br/># Print the final result<br/>print(result["text"])</span></pre><ul class=""><li id="40b9" class="oc od it lj b lk me ln mf lq oe lu of ly og mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">videoURL</code>是励志演讲的链接。</li><li id="283e" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">destination</code>是我当前文件夹对应的`<code class="fe nc nd ne nf b">.</code>`吗</li><li id="c2b4" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">motivational_speech</code>将是音频的最终名称。</li><li id="12ce" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">whisper_model.transcribe(audio_file)</code>将模型应用于音频文件以生成转录。</li><li id="657c" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">transcribe()</code>功能通过滑动 30 秒窗口对音频进行预处理，并执行<a class="ae md" href="https://arxiv.org/abs/1909.07063" rel="noopener ugc nofollow" target="_blank">自回归序列到序列</a>方法对每个窗口进行预测。</li><li id="8f9a" class="oc od it lj b lk om ln on lq oo lu op ly oq mc oh oi oj ok bi translated">最后，<code class="fe nc nd ne nf b">print()</code>语句生成以下结果。</li></ul><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="11c6" class="nk kq it nf b be nl nm l nn no">I don't know what that dream is that you have. <br/>I don't care how disappointing it might have been as you've <br/>been working toward that dream. <br/>But that dream that you're holding in your mind that it's possible.</span></pre><p id="5e3d" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">下面是相应的视频，你可以播放来检查之前的输出。</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div></figure><h2 id="efdb" class="mq kq it bd kr mr ms dn kv mt mu dp kz lq mv mw lb lu mx my ld ly mz na lf nb bi translated">非英语转录</h2><p id="7972" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">除了英语，Whisper 还可以处理非英语语言。让我们来看看 YouTube 上对阿拉萨内·德拉马纳·瓦塔拉的采访。</p><p id="018e" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">与前面的方法类似，我们获取视频，将其转换为音频并获取内容。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="21a5" class="nk kq it nf b be nl nm l nn no">URL = "https://www.youtube.com/watch?v=D8ztTzHHqiE"<br/>destination = "."<br/>final_filename = "discours_ADO"<br/>video_to_audio(URL, destination, final_filename)<br/><br/># Run the test<br/>audio_file = "discours_ADO.mp3"<br/>result_ADO = whisper_model.transcribe(audio_file)<br/><br/># Show the result<br/>print(result_ADO["text"])</span></pre><p id="3ca8" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated"><strong class="lj iu"> →视频讨论:</strong></p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="kn ko l"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">阿拉萨内总统在 YouTube 上关于法郎 CFA <a class="ae md" href="https://www.youtube.com/watch?v=D8ztTzHHqiE" rel="noopener ugc nofollow" target="_blank">的讨论</a></p></figure><p id="1b3c" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">→来自<code class="fe nc nd ne nf b">print()</code>语句的模型结果。</p><p id="0a93" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">下面是最终的结果，结果是令人兴奋的🤯。唯一被拼错的信息是“法郎 CFA ”,而模型将其识别为“前线 CFA”😀。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="421b" class="nk kq it nf b be nl nm l nn no">Le Front CFA, vous l'avez toujours défendu, bec et ongle, est-ce que vous <br/>continuez à le faire ou est-ce que vous pensez qu'il faut peut-être changer <br/>les choses sans rentrer trop dans les tailles techniques? Monsieur Perelman, <br/>je vous dirais tout simplement qu'il y a vraiment du n'importe quoi dans ce <br/>débat. Moi, je ne veux pas manquer de modestie, mais j'ai été directeur des <br/>études de la Banque Centrale, j'ai été vice-gouverneur, j'ai été gouverneur <br/>de la Banque Centrale, donc je peux vous dire que je sais de quoi je parle. <br/>Le Front CFA, c'est notre monnaie, c'est la monnaie des pays membres et nous <br/>l'avons acceptée et nous l'avons développée, nous l'avons modifiée. J'étais <br/>là quand la reforme a eu lieu dans les années 1973-1974, alors tout ce débat <br/>est un nonsense. Maintenant, c'est notre monnaie. J'ai quand même eu à <br/>superviser la gestion monétaire et financière de plus de 120 pays dans le <br/>monde quand j'étais au Fonds Monétaire International. Mais je suis bien placé <br/>pour dire que si cette monnaie nous pose problème, écoutez, avec les autres <br/>chefs d'État, nous prendrons les décisions, mais cette monnaie est solide, <br/>elle est appropriée. Les taux de croissance sont parmi les plus élevés sur le <br/>continent africain et même dans le monde. Le Côte d'Ivoire est parmi les dix <br/>pays où le taux de croissance est le plus élevé. Donc c'est un nonsense, <br/>tout simplement, de la démagogie et je ne souhaite même pas continuer ce débat <br/>sur le Front CFA. C'est la monnaie des pays africains qui ont librement <br/>consenti et accepté de se mettre ensemble. Bien sûr, chacun de nous aurait pu <br/>avoir sa monnaie, mais quel serait l'intérêt? Pourquoi les Européens ont <br/>décidé d'avoir une monnaie commune et que nous les Africains ne serons pas en <br/>mesure de le faire? Nous sommes très fiers de cette monnaie, elle marche bien, <br/>s'il y a des adaptations à faire, nous le ferons de manière souveraine.</span></pre><h2 id="5584" class="mq kq it bd kr mr ms dn kv mt mu dp kz lq mv mw lb lu mx my ld ly mz na lf nb bi translated">非英语翻译成英语</h2><p id="1fd7" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">除了语音识别、口语识别和语音活动识别之外，<code class="fe nc nd ne nf b">Whisper</code>还能够执行从任何语言到英语的语音翻译。</p><p id="a853" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">在这最后一部分，我们将生成以下喜剧法语视频的英语转录。</p><figure class="ki kj kk kl gt km"><div class="bz fp l di"><div class="or ko l"/></div><p class="mm mn gj gh gi mo mp bd b be z dk translated">来自<a class="ae md" href="https://www.youtube.com/watch?v=hz5xWgjSUlk" rel="noopener ugc nofollow" target="_blank"> YouTube </a>的漫画视频</p></figure><p id="5b9f" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">这个过程与我们上面看到的没有太大的变化。主要变化是在<code class="fe nc nd ne nf b">transcribe()</code>功能中使用了<code class="fe nc nd ne nf b">task</code>参数。</p><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="3db9" class="nk kq it nf b be nl nm l nn no">URL = "https://www.youtube.com/watch?v=hz5xWgjSUlk"<br/>final_filename = "comic"<br/>video_to_audio(URL, destination, final_filename)<br/><br/># Run the test<br/>audio_file = "comic.mp3"<br/>french_to_english = whisper_model.transcribe(audio_file, task = 'translate')<br/><br/># Show the result<br/>print(french_to_english["text"])</span></pre><ul class=""><li id="6fe5" class="oc od it lj b lk me ln mf lq oe lu of ly og mc oh oi oj ok bi translated"><code class="fe nc nd ne nf b">task=’translate’</code>意味着我们正在执行一项翻译任务。下面是最终结果。</li></ul><pre class="ki kj kk kl gt ng nf nh bn ni nj bi"><span id="1db3" class="nk kq it nf b be nl nm l nn no">I was asked to make a speech. I'm going to tell you right away, <br/>ladies and gentlemen, that I'm going to speak without saying anything. <br/>I know, you think that if he has nothing to say, he would better shut up. <br/>It's too easy. It's too easy. Would you like me to do it like all those who <br/>have nothing to say and who keep it for themselves? Well, no, ladies and <br/>gentlemen, when I have nothing to say, I want people to know. I want to make <br/>others enjoy it, and if you, ladies and gentlemen, have nothing to say, well, <br/>we'll talk about it. We'll talk about it, I'm not an enemy of the colloquium. <br/>But tell me, if we talk about nothing, what are we going to talk about? Well, <br/>about nothing. Because nothing is not nothing, the proof is that we can <br/>subtract it. Nothing minus nothing equals less than nothing. So if we can find <br/>less than nothing, it means that nothing is already something. We can buy <br/>something with nothing by multiplying it. Well, once nothing, it's nothing. <br/>Twice nothing, it's not much. But three times nothing, for three times nothing,<br/>we can already buy something. And for cheap! Now, if you multiply three times <br/>nothing by three times nothing, nothing multiplied by nothing equals nothing, <br/>three multiplied by three equals nine, it's nothing new. Well, let's talk <br/>about something else, let's talk about the situation, let's talk about the <br/>situation without specifying which one. If you allow me, I'll briefly go over <br/>the history of the situation, whatever it is. A few months ago, remember, <br/>the situation, not to be worse than today's, was not better either. Already, <br/>we were heading towards the catastrophe and we knew it. We were aware of it, <br/>because we should not believe that the person in charge of yesterday was more <br/>ignorant of the situation than those of today. Besides, they are the same. <br/>Yes, the catastrophe where the pension was for tomorrow, that is to say that <br/>in fact it should be for today, by the way. If my calculations are right, <br/>but what do we see today? That it is still for tomorrow. So I ask you the <br/>question, ladies and gentlemen, is it by always putting the catastrophe that <br/>we could do the day after tomorrow, that we will avoid it? I would like to <br/>point out that if the current government is not capable of taking on the <br/>catastrophe, it is possible that the opposition will take it.</span></pre><h1 id="2fc8" class="kp kq it bd kr ks kt ku kv kw kx ky kz jz la ka lb kc lc kd ld kf le kg lf lg bi translated">结论</h1><p id="f089" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated">恭喜🎉！您刚刚学习了如何执行语音到文本转换，并且已经应用了机器翻译！从这个模型中可以解决很多用例。</p><p id="deef" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">如果你喜欢阅读我的故事，并希望支持我的写作，考虑<a class="ae md" href="https://zoumanakeita.medium.com/membership" rel="noopener">成为一个媒体成员</a>。每月支付 5 美元，你就可以无限制地阅读媒体上的故事。</p><p id="9669" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated">欢迎在<a class="ae md" href="https://zoumanakeita.medium.com/" rel="noopener"> Medium </a>、<a class="ae md" href="https://twitter.com/zoumana_keita_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae md" href="https://www.youtube.com/channel/UC9xKdy8cz6ZuJU5FTNtM_pQ" rel="noopener ugc nofollow" target="_blank"> YouTube </a>上关注我，或者在<a class="ae md" href="https://www.linkedin.com/in/zoumana-keita/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上跟我打招呼。讨论人工智能、人工智能、数据科学、自然语言处理和人工智能是一种乐趣！</p><h1 id="a859" class="kp kq it bd kr ks kt ku kv kw kx ky kz jz la ka lb kc lc kd ld kf le kg lf lg bi translated">附加材料</h1><p id="e21c" class="pw-post-body-paragraph lh li it lj b lk ll ju lm ln lo jx lp lq lr ls lt lu lv lw lx ly lz ma mb mc im bi translated"><a class="ae md" href="https://github.com/openai/whisper" rel="noopener ugc nofollow" target="_blank"> GitHub 之私语</a></p><p id="1cfa" class="pw-post-body-paragraph lh li it lj b lk me ju lm ln mf jx lp lq mg ls lt lu mh lw lx ly mi ma mb mc im bi translated"><a class="ae md" href="https://cdn.openai.com/papers/whisper.pdf" rel="noopener ugc nofollow" target="_blank">通过大规模弱监督的鲁棒语音识别</a></p></div></div>    
</body>
</html>