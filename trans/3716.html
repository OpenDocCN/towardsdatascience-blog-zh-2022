<html>
<head>
<title>The Annotated ResNet-50</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带注释的ResNet-50</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758#2022-08-18">https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758#2022-08-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6ad8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">解释ResNet-50的工作原理以及它如此受欢迎的原因</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3f6b87121a1268ecb33e5353dbfa677e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tH9evuOFqk8F41FG.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://commons.wikimedia.org/wiki/File:ResNet50.png" rel="noopener ugc nofollow" target="_blank"> Resnet-5 </a> 0模型架构</p></figure><h1 id="7411" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="3c73" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">ResNet架构被认为是最流行的卷积神经网络架构之一。剩余网络(ResNet)是微软研究院在2015年提出的，在何的论文<a class="ae kv" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">中首次提出时就打破了多项记录。et。艾尔</a>。</p><h1 id="8108" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">为什么是ResNet？</h1><p id="ccde" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对像ResNet这样的模型的需求是由于当时现代网络中的许多缺陷而产生的。</p><ol class=""><li id="60cd" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj mr ms mt mu bi translated"><strong class="lq ir">深度神经网络训练难度:</strong>随着模型层数的增加，模型中的参数数量呈指数增长。对于每个卷积层，总共有((<em class="mv">高度(内核</em> )⋅ <em class="mv">宽度(内核)</em> ⋅ <em class="mv">滤波器(输入)</em> )+1)⋅ <em class="mv">滤波器(输出)</em>被添加到账单中。具体来说，从<em class="mv"> 3 </em>通道到<em class="mv"> 32 </em>通道的一个简单的<em class="mv"> 7x7 </em>内核卷积层添加了<em class="mv"> 4736 </em>参数。为了进行实验而增加层数会导致训练模型的复杂度同样增加。然后训练需要更大的计算能力和记忆。</li><li id="b874" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><strong class="lq ir">更具表现力，差异性更小</strong>:神经网络通常被认为是一个函数逼近器。它能够在给定输入、目标以及函数输出和目标之间的比较的情况下对函数进行建模。向网络中添加多层使其更有能力模拟复杂的功能。但是论文中发表的结果表明，18层平面神经网络的性能比34层平面神经网络好得多，如下图所示。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/a941d474c71db15963b2f4ea2e505ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Pz9FYuVI0UV7qzYj.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">(何等，2015) </a></p></figure><p id="bc16" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">增加层可以看作是功能空间的扩展。例如，多个层加在一起可以看作是一个函数<em class="mv"> F </em>。这个函数<em class="mv"> F </em>可以表示为它可以到达/建模的函数空间<em class="mv"> F </em>的表示。</p><p id="0e06" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">在<em class="mv"> F` </em>中拥有你想要的功能将是一个幸运的机会，但通常情况并非如此。在这里加层可以让我们围绕函数空间<em class="mv"> F` </em>展开变化，可以让我们在由可想象宇宙中所有可能的函数组成的更大的母函数空间中覆盖更大的空间。但是这种方法有一个固有的缺陷。随着函数空间变大，不能保证我们更接近我们的目标函数。事实上，很有可能在实验阶段，你离开了可能有你实际需要的功能的功能空间。</p><p id="4c55" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">行话让你困惑了吗？我们来打个针和干草堆的比方。<br/>让这根针成为神经网络的完美权重，或者如前所述，成为一个函数。让干草堆成为所有可能的功能。</p><p id="8e53" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">一种是从一个单一的搜索区域开始，并试图从那里对准指针。添加图层相当于移动你的搜索区域，让它变大。但这也带来了离开针头实际所在位置的风险，同时也使我们的搜索更加耗时和困难。干草堆越大，就越难找到完美的针。那么，解决办法是什么？</p><p id="ff04" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">实际上，非常简单和优雅。嵌套您的功能空间。</p><p id="ae2e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">这样做有几个简单的原因。最重要的一点是，它允许您确保当模型添加层来增加功能空间的大小时，您不会最终降低模型的质量。这保证了虽然我们的模型可以用更多的层做得更好，但它不会做得更差。</p><p id="6acd" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">回到我们的干草堆类比，这相当于使我们的搜索空间更大，但确保我们不离开我们当前的搜索空间。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/54935f4ad3cc3da99c84178e08505917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*SErommjtR8un15r-.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/abs/2106.11342" rel="noopener ugc nofollow" target="_blank">(张等，2021) </a></p></figure><p id="d492" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">3.<strong class="lq ir">消失/爆炸梯度</strong>:这是困扰大型/深度神经网络训练的最常见问题之一，是网络参数数值稳定性方面疏忽的结果。<br/>在反向传播过程中，当我们不断从深层向浅层移动时，微分的链式法则使我们乘以梯度。通常，这些梯度很小，在10^{-5}10−5量级或更大。</p><p id="89f7" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">根据一些简单的数学，随着这些小数字不断相乘，它们会变得越来越小，对重量的影响几乎可以忽略不计。</p><p id="6711" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">在光谱的另一端，存在梯度达到10⁴或更高的量级的情况。随着这些大梯度彼此相乘，这些值趋向于无穷大。允许如此大范围的值处于权重的数值域中使得收敛难以实现。</p><p id="0336" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">这个问题通常被称为消失/爆炸梯度问题。ResNet由于其架构，根本不允许这些问题发生<em class="mv"/>。为什么跳跃连接(前面描述过)不允许这种情况，因为它们作为梯度高速公路，允许其流动而不被大幅度改变。</p><h1 id="e614" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">什么是跳过连接？</h1><p id="801e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">ResNet论文推广了使用<a class="ae kv" href="https://medium.com/blogging-guide/medium-subscript-text-and-medium-superscript-format-c169a8717ecf" rel="noopener">跳过连接</a>的方法。如果你还记得，解决函数空间问题的方法是嵌套它们。就将它应用到我们的用例而言，它是在输出中引入了一个简单的identity函数。</p><p id="94b7" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">在数学术语中，它意味着<em class="mv">y</em>=<em class="mv">x</em>+<em class="mv">F</em>(<em class="mv">x</em>)，其中y是该层的最终输出。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/32e6a8893d1268ff68fa89fa7b28f303.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/0*6VRgGE_UnEH8Q2Zv.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">(何等，2015) </a></p></figure><p id="e6e6" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">就体系结构而言，如果任何一层最终损害了普通网络中模型的性能，则由于存在跳过连接，该层会被跳过。</p><h1 id="80d9" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">体系结构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/cf988c69f4c981873aa61cf1a52e5e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rPktw9-nz-dy9CFcddMBdQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="http://dx.doi.org/10.11591/ijeecs.v18.i2.pp1015-1027" rel="noopener ugc nofollow" target="_blank"> ResNet-50架构</a></p></figure><p id="45cb" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">ResNet-50架构可以分为6个部分</p><ol class=""><li id="a9b8" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj mr ms mt mu bi translated">输入预处理</li><li id="367a" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><code class="fe ni nj nk nl b">Cfg[0]</code>街区</li><li id="5106" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><code class="fe ni nj nk nl b">Cfg[1]</code>区块</li><li id="058d" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><code class="fe ni nj nk nl b">Cfg[2]</code>街区</li><li id="c511" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><code class="fe ni nj nk nl b">Cfg[3]</code>街区</li><li id="20b6" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated">全连接层</li></ol><p id="bdb5" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">ResNet体系结构的不同版本在不同级别使用不同数量的Cfg块，如上图所示。下面是一份详细的信息清单。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/97f03018a354613093466202245a9e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mQA4WKBXkvE-Atjn.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">(何等，2015) </a></p></figure><h1 id="2ba2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">给我看看代码！</h1><p id="ab5f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">理解这个概念的最好方法是通过一些代码。下面的实现是在Keras中完成的，使用标准的ResNet-50架构(ResNet有几个版本，网络深度不同)。我们将在斯坦福AI 著名的<a class="ae kv" href="http://vision.stanford.edu/aditya86/ImageNetDogs/" rel="noopener ugc nofollow" target="_blank">斯坦福狗数据集上训练模型。</a></p><h1 id="fa58" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">导入标题</h1><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="a958" class="nq kx iq nl b gy nr ns l nt nu">!pip install <strong class="nl ir">-</strong>q tensorflow_datasets<br/>import tensorflow <strong class="nl ir">as</strong> tf<br/>from tensorflow import keras<br/>import tensorflow_datasets <strong class="nl ir">as</strong> tfds<br/>import os<br/>import PIL<br/>import pathlib<br/>import PIL.Image<br/>import warnings<br/>warnings<strong class="nl ir">.</strong>filterwarnings<strong class="nl ir">(</strong>"ignore"<strong class="nl ir">)</strong><br/>from datetime import datetime</span></pre><h1 id="cfed" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">数据集下载和预处理</h1><p id="eefd" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们使用<a class="ae kv" href="https://www.tensorflow.org/datasets/catalog/stanford_dogs" rel="noopener ugc nofollow" target="_blank"> <strong class="lq ir"> Tensorflow数据集(稳定)</strong> </a>下载斯坦福狗数据集，并将其分成训练、验证和测试集。</p><p id="29a2" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">除了图像和标签，我们还获得了一些元数据，为我们提供了关于数据集的更多信息。它存储在<code class="fe ni nj nk nl b">ds_info</code>并以人类可读的方式打印出来。</p><p id="234c" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们还利用<code class="fe ni nj nk nl b">tfds.show_examples()</code>从数据集中打印一些随机的示例图像和标签。</p><p id="3485" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们运行<code class="fe ni nj nk nl b">tfds.benchmark()</code>来对<code class="fe ni nj nk nl b">tf.data.Dataset</code>提供的迭代器进行基准测试</p><p id="fef2" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们在<code class="fe ni nj nk nl b">tf.data.Dataset</code>对象上执行以下最佳实践步骤，以提高其效率:</p><ul class=""><li id="7157" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated"><code class="fe ni nj nk nl b">batch(BATCH_SIZE)</code>:允许我们在数据集内准备小批量。请注意，批处理操作要求所有图像都具有相同的大小和相同的通道数</li><li id="8e11" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated"><code class="fe ni nj nk nl b">map(format_image)</code>:将图像转换为<code class="fe ni nj nk nl b">tf.float32</code>张量，归一化范围[0，1][0，1]中的所有值，使用<code class="fe ni nj nk nl b">lanczos3</code>内核方法将图像从其原始形状调整为模型输入形状(224，224，3)(224，224，3)</li><li id="f6b2" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated"><code class="fe ni nj nk nl b">prefetch(BUFFER_SIZE)</code>:在处理当前批次的同时，预取会将训练期间的下一批数据集带入内存，从而减少I/O时间，但需要更多的GPU内存</li><li id="0728" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated"><code class="fe ni nj nk nl b">cache()</code>:缓存第一批迭代器，以减少加载时间，类似于预取，区别只是缓存将加载文件，而不是推入GPU内存</li></ul><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="5ace" class="nq kx iq nl b gy nr ns l nt nu"><strong class="nl ir">(</strong>train_ds<strong class="nl ir">,</strong> valid_ds<strong class="nl ir">,</strong> test_ds<strong class="nl ir">),</strong> ds_info <strong class="nl ir">=</strong> tfds<strong class="nl ir">.</strong>load<strong class="nl ir">(</strong><br/>    'stanford_dogs'<strong class="nl ir">,</strong> <br/>    split<strong class="nl ir">=[</strong>'train'<strong class="nl ir">,</strong> 'test[0%:10%]'<strong class="nl ir">,</strong> 'test[10%:]'<strong class="nl ir">],</strong> <br/>    shuffle_files<strong class="nl ir">=True,</strong> with_info<strong class="nl ir">=True,</strong><br/>    as_supervised<strong class="nl ir">=True</strong><br/><strong class="nl ir">)</strong></span><span id="d67f" class="nq kx iq nl b gy nw ns l nt nu"><em class="mv">print</em><strong class="nl ir">(</strong>"Dataset info: \n"<strong class="nl ir">)</strong><br/><em class="mv">print</em><strong class="nl ir">(</strong>f'Name: {ds_info<strong class="nl ir">.</strong>name}\n'<strong class="nl ir">)</strong><br/><em class="mv">print</em><strong class="nl ir">(</strong>f'Number of training samples : {ds_info<strong class="nl ir">.</strong>splits<strong class="nl ir">[</strong>"train"<strong class="nl ir">].</strong>num_examples}\n'<strong class="nl ir">)</strong><br/><em class="mv">print</em><strong class="nl ir">(</strong>f'Number of test samples : {ds_info<strong class="nl ir">.</strong>splits<strong class="nl ir">[</strong>"test"<strong class="nl ir">].</strong>num_examples}\n'<strong class="nl ir">)</strong><br/><em class="mv">print</em><strong class="nl ir">(</strong>f'Description : {ds_info<strong class="nl ir">.</strong>description}'<strong class="nl ir">)</strong><br/>tfds<strong class="nl ir">.</strong>show_examples<strong class="nl ir">(</strong>train_ds<strong class="nl ir">,</strong> ds_info<strong class="nl ir">)</strong></span><span id="0fa8" class="nq kx iq nl b gy nw ns l nt nu">CLASS_TYPES <strong class="nl ir">=</strong> ds_info<strong class="nl ir">.</strong>features<strong class="nl ir">[</strong>'label'<strong class="nl ir">].</strong>num_classes<br/>BATCH_SIZE <strong class="nl ir">=</strong> 4</span><span id="2ff9" class="nq kx iq nl b gy nw ns l nt nu"><em class="mv">print</em><strong class="nl ir">(</strong>'Benchmark results'<strong class="nl ir">)</strong><br/>tfds<strong class="nl ir">.</strong>benchmark<strong class="nl ir">(</strong>train_ds<strong class="nl ir">)</strong></span><span id="dc72" class="nq kx iq nl b gy nw ns l nt nu"><strong class="nl ir">def</strong> <strong class="nl ir">format_image(</strong>image<strong class="nl ir">,</strong> label<strong class="nl ir">):</strong></span><span id="9b6d" class="nq kx iq nl b gy nw ns l nt nu">    image <strong class="nl ir">=</strong> tf<strong class="nl ir">.</strong>cast<strong class="nl ir">(</strong>image<strong class="nl ir">,</strong> tf<strong class="nl ir">.</strong>float32<strong class="nl ir">)</strong><br/>    image <strong class="nl ir">=</strong> image <strong class="nl ir">/</strong> 255.0<br/>    image <strong class="nl ir">=</strong> tf<strong class="nl ir">.</strong>image<strong class="nl ir">.</strong>resize_with_pad<strong class="nl ir">(</strong>image<strong class="nl ir">,</strong> 224<strong class="nl ir">,</strong> 224<strong class="nl ir">,</strong> method<strong class="nl ir">=</strong>'lanczos3'<strong class="nl ir">,</strong> antialias<strong class="nl ir">=True)</strong><br/>    <strong class="nl ir">return</strong> image<strong class="nl ir">,</strong> label</span><span id="0752" class="nq kx iq nl b gy nw ns l nt nu"><strong class="nl ir">def</strong> <strong class="nl ir">prepare_ds(</strong>ds<strong class="nl ir">):</strong><br/>    ds <strong class="nl ir">=</strong> ds<strong class="nl ir">.</strong>map<strong class="nl ir">(</strong>format_image<strong class="nl ir">)</strong><br/>    ds <strong class="nl ir">=</strong> ds<strong class="nl ir">.</strong>batch<strong class="nl ir">(</strong>BATCH_SIZE<strong class="nl ir">)</strong><br/>    ds <strong class="nl ir">=</strong> ds<strong class="nl ir">.</strong>prefetch<strong class="nl ir">(</strong>tf<strong class="nl ir">.</strong>data<strong class="nl ir">.</strong>AUTOTUNE<strong class="nl ir">)</strong><br/>    ds <strong class="nl ir">=</strong> ds<strong class="nl ir">.</strong>cache<strong class="nl ir">()</strong><br/>    <strong class="nl ir">return</strong> ds</span><span id="ee31" class="nq kx iq nl b gy nw ns l nt nu">train_ds <strong class="nl ir">=</strong> prepare_ds<strong class="nl ir">(</strong>train_ds<strong class="nl ir">)</strong><br/>valid_ds <strong class="nl ir">=</strong> prepare_ds<strong class="nl ir">(</strong>valid_ds<strong class="nl ir">)</strong><br/>test_ds <strong class="nl ir">=</strong> prepare_ds<strong class="nl ir">(</strong>test_ds<strong class="nl ir">)</strong></span></pre><p id="f523" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">输出:</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="5d0d" class="nq kx iq nl b gy nr ns l nt nu">Downloading and preparing dataset 778.12 MiB (download: 778.12 MiB, generated: Unknown size, total: 778.12 MiB) to /root/tensorflow_datasets/stanford_dogs/0.2.0...<br/>Dataset stanford_dogs downloaded and prepared to /root/tensorflow_datasets/stanford_dogs/0.2.0. Subsequent calls will reuse this data.<br/>Dataset info:</span><span id="fc86" class="nq kx iq nl b gy nw ns l nt nu">Name: stanford_dogs</span><span id="551b" class="nq kx iq nl b gy nw ns l nt nu">Number of training samples : 12000</span><span id="e49d" class="nq kx iq nl b gy nw ns l nt nu">Number of training samples : 8580</span><span id="b610" class="nq kx iq nl b gy nw ns l nt nu">Description : The Stanford Dogs dataset contains images of 120 breeds of dogs from around<br/>the world. This dataset has been built using images and annotation from<br/>ImageNet for the task of fine-grained image categorization. There are<br/>20,580 images, out of which 12,000 are used for training and 8580 for<br/>testing. Class labels and bounding box annotations are provided<br/>for all the 12,000 images.</span><span id="7a02" class="nq kx iq nl b gy nw ns l nt nu">Benchmark results</span><span id="b1a3" class="nq kx iq nl b gy nw ns l nt nu">************ Summary ************</span><span id="40cb" class="nq kx iq nl b gy nw ns l nt nu">Examples/sec (First included) 787.00 ex/sec (total: 12000 ex, 15.25 sec)<br/>Examples/sec (First only) 10.34 ex/sec (total: 1 ex, 0.10 sec)<br/>Examples/sec (First excluded) 791.95 ex/sec (total: 11999 ex, 15.15 sec)</span></pre><h1 id="7833" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">增大</h1><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="4f68" class="nq kx iq nl b gy nr ns l nt nu">imageAug <strong class="nl ir">=</strong> keras<strong class="nl ir">.</strong>Sequential<strong class="nl ir">([</strong><br/>    keras<strong class="nl ir">.</strong>layers<strong class="nl ir">.</strong>RandomFlip<strong class="nl ir">(</strong>"horizontal_and_vertical"<strong class="nl ir">),</strong><br/>    keras<strong class="nl ir">.</strong>layers<strong class="nl ir">.</strong>RandomRotation<strong class="nl ir">(</strong>0.2<strong class="nl ir">),</strong><br/>    keras<strong class="nl ir">.</strong>layers<strong class="nl ir">.</strong>RandomContrast<strong class="nl ir">(</strong>0.2<strong class="nl ir">)</strong><br/><strong class="nl ir">])</strong></span></pre><p id="0d07" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们进行了一些数据扩充，使我们的模型更加稳健。一个<em class="mv">随机翻转</em>、<em class="mv">随机旋转</em>和<em class="mv">随机对比度</em>用于使图像组更加多样。函数的参数是概率，即图像经历所选变换的机会。</p><h1 id="e6d2" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">Cfg0块</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="59bc" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">该区块包含1个Conv层和2个身份层。为了有助于数值稳定性，我们指定了一个核约束，以确保所有的权重以恒定的间隔被归一化。在两个后续层之间，我们还包括一个批处理标准化层。代码以一种明确的方式被有意地写出来，以帮助读者理解在每个阶段做出了什么样的设计选择。</p><ul class=""><li id="27c2" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated">输入形状:(56，56，64)</li><li id="5768" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated">输出形状:(56，56，256)</li></ul><h1 id="2bd6" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">Cfg1模块</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="b0bd" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">该区块包含1个Conv层和2个身份层。这类似于Cfg0块，区别主要在于Conv和身份层中的<code class="fe ni nj nk nl b">out_channels</code>的数量更多。</p><ul class=""><li id="d0f9" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated">输入形状:(56，56，256)</li><li id="bdc9" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated">输出形状:(28，28，512)</li></ul><h1 id="b766" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">Cfg2模块</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="5652" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">该区块包含1个Conv层和5个身份层。对于ResNet来说，这是一个更重要的块，因为模型的大多数版本在这个块空间上都有所不同。</p><ul class=""><li id="82fd" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated">输入形状:(28，28，512)</li><li id="6a8e" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated">输出形状:(14，14，1024)</li></ul><h1 id="f911" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">Cfg3块</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="effe" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">该区块包含1个Conv层和2个身份层。这是网络中最后一组卷积层块。</p><ul class=""><li id="60fc" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated">输入形状:(14，14，1024)</li><li id="ffb6" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated">输出形状:(7，7，2048)</li></ul><h1 id="1c49" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">分类器块</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="b86e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">这个区块包含一个<code class="fe ni nj nk nl b">AveragePooling</code>层、一个<code class="fe ni nj nk nl b">Dropout</code>层和一个<code class="fe ni nj nk nl b">Flatten</code>层。在此块中，要素地图最终被展平并推入完全连接的图层，该图层随后用于生成预测。Softmax激活用于生成逻辑/概率。</p><ul class=""><li id="8e0e" class="mk ml iq lq b lr mm lu mn lx mo mb mp mf mq mj nv ms mt mu bi translated">输入形状:(7，7，2048)</li><li id="88d2" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj nv ms mt mu bi translated">输出形状:(1，CLASS_TYPES)</li></ul><h1 id="99b0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">构建ResNet模型</h1><p id="e4f2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">现在，我们将所有的模块连接在一起，创建最终的ResNet模型。在我们的整个过程中，我们使用了Keras Functional API，这是Tensorflow的最佳实践。</p><p id="04d6" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">我们还执行一些可视化，即<code class="fe ni nj nk nl b">model.summary()</code>打印出模型层的结构，以及<code class="fe ni nj nk nl b">keras.utils.plot_model()</code>绘制模型的可视化有向无环图，Tensorflow将在后端使用该图来简化执行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nx ny l"/></div></figure><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="0294" class="nq kx iq nl b gy nr ns l nt nu">Model: "resnet50"<br/>_________________________________________________________________<br/> Layer (type)                Output Shape              Param #   <br/>=================================================================<br/> input (InputLayer)          [(None, 224, 224, 3)]     0         <br/>                                                                 <br/> sequential (Sequential)     (None, 224, 224, 3)       0         <br/>                                                                 <br/> conv2d_28 (Conv2D)          (None, 112, 112, 64)      9472      <br/>                                                                 <br/> max_pooling2d (MaxPooling2D  (None, 56, 56, 64)       0         <br/> )                                                               <br/>                                                                 <br/> cfg0_block (Functional)     (None, 56, 56, 256)       148480    <br/>                                                                 <br/> cfg1_block (Functional)     (None, 28, 28, 512)       665600    <br/>                                                                 <br/> cfg2_block (Functional)     (None, 14, 14, 1024)      2641920   <br/>                                                                 <br/> cfg3_block (Functional)     (None, 7, 7, 2048)        10526720  <br/>                                                                 <br/> classifier (Functional)     (None, 120)               3932280   <br/>                                                                 <br/>=================================================================<br/>Total params: 17,924,472<br/>Trainable params: 17,893,752<br/>Non-trainable params: 30,720<br/>_________________________________________________________________<br/>None</span></pre><h1 id="5227" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">定义回调</h1><p id="6721" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在<code class="fe ni nj nk nl b">model.fit()</code>中，我们可以为模型定义回调，这些回调在训练期间以预定的间隔被调用。我们定义了一个模型检查点回调，它在每个时期完成时创建模型的快照。</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="cc89" class="nq kx iq nl b gy nr ns l nt nu">callbacks_list <strong class="nl ir">=</strong> <strong class="nl ir">[</strong><br/>    keras<strong class="nl ir">.</strong>callbacks<strong class="nl ir">.</strong>ModelCheckpoint<strong class="nl ir">(</strong><br/>        filepath<strong class="nl ir">=</strong>'resnet50_model/checkpoint_{epoch:02d}.hdf5'<strong class="nl ir">,</strong><br/>        monitor<strong class="nl ir">=</strong>'val_loss'<strong class="nl ir">,</strong><br/>        verbose<strong class="nl ir">=</strong>0<strong class="nl ir">,</strong><br/>        save_best_only<strong class="nl ir">=True,</strong><br/>        mode<strong class="nl ir">=</strong>'auto'<strong class="nl ir">,</strong><br/>        save_freq<strong class="nl ir">=</strong>'epoch'<strong class="nl ir">,</strong><br/>        options<strong class="nl ir">=None,</strong><br/>        initial_value_threshold<strong class="nl ir">=None</strong><br/>    <strong class="nl ir">)</strong><br/><strong class="nl ir">]</strong></span><span id="e086" class="nq kx iq nl b gy nw ns l nt nu">history <strong class="nl ir">=</strong> model<strong class="nl ir">.</strong>fit<strong class="nl ir">(</strong><br/>    x<strong class="nl ir">=</strong>train_ds<strong class="nl ir">,</strong><br/>    validation_data<strong class="nl ir">=</strong>valid_ds<strong class="nl ir">,</strong><br/>    callbacks<strong class="nl ir">=</strong>callbacks_list<strong class="nl ir">,</strong><br/>    epochs<strong class="nl ir">=</strong>20<br/><strong class="nl ir">)</strong></span></pre><p id="0cdd" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">如果我们希望使用先前保存的模型，我们也可以这样做。</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="6433" class="nq kx iq nl b gy nr ns l nt nu"><em class="mv">## If using Google Colaboratory, one can upload checkpoints onto Google Drive and use it directly.</em></span><span id="0dbc" class="nq kx iq nl b gy nw ns l nt nu">from google.colab import drive<br/>drive<strong class="nl ir">.</strong>mount<strong class="nl ir">(</strong>'/content/gdrive'<strong class="nl ir">)</strong><br/>model <strong class="nl ir">=</strong> keras<strong class="nl ir">.</strong>models<strong class="nl ir">.</strong>load_model<strong class="nl ir">(</strong>'/content/gdrive/My Drive/checkpoint_18.hdf5'<strong class="nl ir">)</strong></span><span id="8250" class="nq kx iq nl b gy nw ns l nt nu"><em class="mv">## If using local Jupyter Notebooks, one can use checkpoints from local drives itself.</em></span><span id="7d7c" class="nq kx iq nl b gy nw ns l nt nu">model <strong class="nl ir">= </strong>keras<strong class="nl ir">.</strong>models<strong class="nl ir">.</strong>load_model<strong class="nl ir">(</strong>'./resnet50_model/checkpoint_18.hdf5'<strong class="nl ir">)</strong></span></pre><h1 id="f214" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">获取模型历史</h1><p id="e45d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们打印模型历史以获得关于训练过程的更多信息</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="0d70" class="nq kx iq nl b gy nr ns l nt nu"><em class="mv">print</em><strong class="nl ir">(</strong>history<strong class="nl ir">)</strong></span></pre><h1 id="b163" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">预测结果</h1><p id="a3bf" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们采用经过训练的模型，并使用它对测试集进行预测，以及计算一些指标，如损失和准确性</p><pre class="kg kh ki kj gt nm nl nn no aw np bi"><span id="a826" class="nq kx iq nl b gy nr ns l nt nu">results <strong class="nl ir">=</strong> model<strong class="nl ir">.</strong>evaluate<strong class="nl ir">(</strong>test_ds<strong class="nl ir">)</strong><br/><em class="mv">print</em><strong class="nl ir">(</strong>f"Results : {results}"<strong class="nl ir">)</strong></span></pre><h1 id="cab0" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="c6e3" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">上面，我们已经访问了残差网络架构，浏览了它的显著特征，从头实现了一个ResNet-50模型，并训练它在斯坦福狗数据集上进行推理。</p><p id="b98e" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">作为一个模型，ResNet同时在计算机视觉和深度学习领域带来了一场革命。它还赢得了2015年ImageNet大规模视觉识别挑战赛和COCO比赛。但这只是产生更好结果的许多有趣变化的垫脚石。查看下面有趣的链接部分，找到一些伟大的博客和研究论文。</p><h1 id="0e60" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><ol class=""><li id="d1bf" class="mk ml iq lq b lr ls lu lv lx nz mb oa mf ob mj mr ms mt mu bi translated">何刚，张，徐，任，孙(2015)。<em class="mv">用于图像识别的深度残差学习</em>。</li><li id="cdf2" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated">张，李，张，李，米，斯莫拉，A. J. (2021)。潜入深度学习。<em class="mv"> ArXiv预印本ArXiv:2106.11342 </em>。</li></ol><h1 id="20ba" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">有趣的链接</h1><ol class=""><li id="b316" class="mk ml iq lq b lr ls lu lv lx nz mb oa mf ob mj mr ms mt mu bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/an-overview-of-resnet-and-its-variants-5281e2f56035">resnet及其变体的概述</a></li><li id="ed3d" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><a class="ae kv" href="https://link.springer.com/chapter/10.1007/978-3-030-64340-9_13" rel="noopener ugc nofollow" target="_blank">关于ResNet变体多尺度集合的论文</a></li><li id="2cf3" class="mk ml iq lq b lr mw lu mx lx my mb mz mf na mj mr ms mt mu bi translated"><a class="ae kv" href="https://cloud.google.com/tpu/docs/tutorials/resnet" rel="noopener ugc nofollow" target="_blank">在云TPU上训练ResNet-50</a></li></ol><p id="acba" class="pw-post-body-paragraph lo lp iq lq b lr mm jr lt lu mn ju lw lx nc lz ma mb nd md me mf ne mh mi mj ij bi translated">更多信息，请访问我的博客<a class="ae kv" href="https://suvadityamuk.github.io/portfolio/" rel="noopener ugc nofollow" target="_blank">这里</a>或者通过<a class="ae kv" href="http://suvadityamuk@gmail.com" rel="noopener ugc nofollow" target="_blank">电子邮件</a>或<a class="ae kv" href="https://github.com/suvadityamuk" rel="noopener ugc nofollow" target="_blank"> GitHub </a>联系我！</p></div></div>    
</body>
</html>