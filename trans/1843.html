<html>
<head>
<title>Create Image Classification Models with TensorFlow in 10 Minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow在10分钟内创建图像分类模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-image-classification-models-with-tensorflow-in-10-minutes-d0caef7ca011#2022-04-29">https://towardsdatascience.com/create-image-classification-models-with-tensorflow-in-10-minutes-d0caef7ca011#2022-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a09d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">端到端教程—从数据准备到模型训练和评估</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/566164bf958514c642804703c83c54d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6IJmFaAt-E7BLIhe"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Anton Maksimov 5642.su 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="d7d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习生命周期是一个复杂的过程，涉及许多不同的部分，包括:</p><ul class=""><li id="41f4" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">预处理和数据清洗。</li><li id="2d0b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">寻找和建立正确的模型。</li><li id="263f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">测试和适当的评估。</li></ul><p id="7dd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本文将上述所有技术打包成一个简单的教程:</p><blockquote class="mj mk ml"><p id="aebc" class="kz la mm lb b lc ld ju le lf lg jx lh mn lj lk ll mo ln lo lp mp lr ls lt lu im bi translated">如果我对<strong class="lb iu">深度学习</strong>或<strong class="lb iu"> Tensorflow </strong>一无所知，这就是我希望有人给我看的！</p></blockquote><p id="52a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">先决条件:</strong>你需要Tensorflow 2.0+和几个库——<em class="mm">Numpy</em>、<em class="mm">熊猫</em>、<em class="mm"> Sklearn、</em>和<em class="mm"> Matplotlib </em>。我们将使用Tensorflow中包含的<a class="ae ky" href="https://www.kaggle.com/datasets/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">时尚MNIST[1] </a>数据集。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="935f" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated"><strong class="ak">加载数据</strong></h1><p id="afaa" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">数据集包含训练集中的60，000幅灰度图像和测试集中的10，000幅图像。每张图片代表属于10个类别之一的时尚单品。图1 中给出了一个例子:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="51b6" class="nz my it nv b gy oa ob l oc od">fashion_mnist = tf.keras.datasets.fashion_mnist</span><span id="eb70" class="nz my it nv b gy oe ob l oc od">(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><span id="f165" class="nz my it nv b gy oe ob l oc od">class_names={ 0: 'T-shirt/top',<br/>              1: 'Trouser',<br/>              2: 'Pullover',<br/>              3: 'Dress',<br/>              4: 'Coat',<br/>              5: 'Sandal',<br/>              6: 'Shirt',<br/>              7: 'Sneaker',<br/>              8: 'Bag',<br/>              9: 'Ankle boot' }</span><span id="5420" class="nz my it nv b gy oe ob l oc od">plt.figure(figsize=(10,10))<br/>for i in range(25):<br/>   plt.subplot(5,5,i+1)<br/>   plt.xticks([])<br/>   plt.yticks([])<br/>   plt.imshow(train_images[i], cmap=plt.cm.binary)<br/>   plt.xlabel(class_names[train_labels[i]])<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1a1e280cc445a824b977176c8f2fb9bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*yi8h-0WGU9PKhlZkHNwd5g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图1: </strong>来自数据集的图像样本</p></figure><p id="fa4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的目标是建立一个模型，正确预测每个图像的标签/类别。于是，我们有了一个<strong class="lb iu">多类</strong>，分类问题。</p><h1 id="8f35" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">培训/验证/测试分割</h1><p id="1194" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">我们已经有了<em class="mm">训练</em>和<em class="mm">测试</em>数据集。我们保留5%的训练数据集，我们称之为<strong class="lb iu">验证</strong>数据集。这用于超参数优化。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="8a90" class="nz my it nv b gy oa ob l oc od">train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels, stratify=train_labels, random_state=48, test_size=0.05)</span><span id="8287" class="nz my it nv b gy oe ob l oc od">(test_x, test_y)=(test_images, test_labels)</span></pre><h1 id="fa37" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">像素重新缩放</h1><p id="87d3" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">由于图像是<strong class="lb iu">灰度</strong>，所有值都在<em class="mm">0–255</em>的范围内。我们除以<em class="mm"> 255 </em>，使像素值位于<em class="mm"> 0 </em>和<em class="mm"> 1 </em>之间。这是<strong class="lb iu">常态化</strong>的一种形式，以后会加快我们的训练进程。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="06f1" class="nz my it nv b gy oa ob l oc od"># normalize to range 0-1<br/>train_x = train_x / 255.0<br/>val_x = val_x / 255.0<br/>test_x = test_x / 255.0</span></pre><h1 id="addc" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">目标值的一键编码</h1><p id="1569" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">每个标签属于我们上面看到的10个类别中的一个。因此，目标值(y)取0到9之间的值。比如根据字典<code class="fe om on oo nv b">class_names</code> <em class="mm">，</em>，<strong class="lb iu">，【0】，</strong>就是<strong class="lb iu">，【t恤/上衣】，</strong>的类。</p><p id="669c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看训练集中前5件衣服的目标值:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="ffc3" class="nz my it nv b gy oa ob l oc od">train_y[:5]<br/>-&gt; array([[2],                  (Pullover)<br/>          [8],                  (Bag)<br/>          [6],                  (Shirt)<br/>          [1],                  (Trouser)<br/>          [.3]], dtype=uint8).  (Dress)</span></pre><p id="67ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们对它们进行一次性编码——将每个目标值分配给一个向量。对所有y数据集(训练、验证、测试)进行该过程。我们使用<strong class="lb iu">to _ categorial()</strong>函数:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="cde4" class="nz my it nv b gy oa ob l oc od">train_y = to_categorical(train_y)<br/>val_y = to_categorical(val_y)<br/>test_y = to_categorical(test_y)</span></pre><p id="c1aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，前5件衣服的目标值变为:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="f00c" class="nz my it nv b gy oa ob l oc od">array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],        <br/>       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],        <br/>       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],        <br/>       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],        <br/>       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]], dtype=float32)</span></pre><h1 id="ee9e" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">概述</h1><p id="bfba" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">每个数据集存储为一个<em class="mm"> Numpy </em>数组。让我们检查一下它们的尺寸:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="bc10" class="nz my it nv b gy oa ob l oc od">print(train_x.shape)  #(57000, 28, 28)<br/>print(train_y.shape)  #(57000, 10)<br/>print(val_x.shape)    #(3000, 28, 28)<br/>print(val_y.shape)    #(3000, 10)<br/>print(test_x.shape)   #(10000, 28, 28)<br/>print(test_y.shape)   #(10000, 10)</span></pre><h1 id="fcaa" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">训练分类模型</h1><p id="9a49" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">现在，构建我们的模型的一切都准备好了:我们将使用两种类型的神经网络:经典的<strong class="lb iu">多层感知器</strong> ( <em class="mm"> MLP </em>)和<strong class="lb iu">卷积神经网络</strong> ( <em class="mm"> CNN </em>)。</p><h2 id="4159" class="nz my it bd mz op oq dn nd or os dp nh li ot ou nj lm ov ow nl lq ox oy nn oz bi translated">多层感知器(MLP)</h2><p id="54da" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">标准神经网络架构如图1 中<strong class="lb iu">所示。具有至少一个隐藏层和非线性激活的<em class="mm"> MLP </em>的行为类似于<strong class="lb iu">通用连续函数逼近器</strong>。像所有的神经网络一样，它们基于<strong class="lb iu">斯通-维尔斯特拉斯定理:</strong></strong></p><blockquote class="pa"><p id="508c" class="pb pc it bd pd pe pf pg ph pi pj lu dk translated"><strong class="ak"> E </strong>定义在闭区间上的非常连续函数[ <em class="pk"> a </em>，<em class="pk"> b </em> ]可以用一个多项式函数按所希望的那样一致逼近。</p></blockquote><p id="6b96" class="pw-post-body-paragraph kz la it lb b lc pl ju le lf pm jx lh li pn lk ll lm po lo lp lq pp ls lt lu im bi translated">当然，<strong class="lb iu">神经网络的每一层都将输入的多项式表示投射到不同的空间</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pq"><img src="../Images/b9c299d5ef7e88d82b56d971f5294466.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*iLlC_5ZfIBg6sKZbK3S9TA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图1 </strong>:具有一个隐藏层的多层感知器[2]</p></figure><p id="c6da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，让我们使用来自<strong class="lb iu"> Tensorflow </strong>的<strong class="lb iu"> Keras API </strong>来定义我们的模型。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="f92c" class="nz my it nv b gy oa ob l oc od">model_mlp = Sequential()<br/>model_mlp.add(Flatten(input_shape=(28, 28)))<br/>model_mlp.add(Dense(350, activation='relu'))<br/>model_mlp.add(Dense(10, activation='softmax'))</span><span id="b6ef" class="nz my it nv b gy oe ob l oc od">print(model_mlp.summary())<br/>model_mlp.compile(optimizer="adam",loss='categorical_crossentropy', metrics=['accuracy'])</span></pre><p id="305a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你应该知道的是:</p><ul class=""><li id="102b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">网络结构:</strong>每幅图像是<code class="fe om on oo nv b">28x28</code>个像素。第一层将输入展平成一个<code class="fe om on oo nv b">28*28=784</code>大小的向量。然后，我们添加一个有350个神经元的隐藏层。最后一层有10个神经元，一个用于我们数据集中的类。</li><li id="91ea" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">激活功能:</strong><strong class="lb iu"/>隐藏层使用标准<em class="mm"> RELU </em>激活。最后一层使用<em class="mm"> softmax </em>激活，因为我们有一个多类问题。</li><li id="8d6b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">损失函数:</strong>我们的模型试图最小化的目标。由于我们有一个多类问题，我们使用<code class="fe om on oo nv b">categorical_crossentropy</code>损失。</li><li id="4c16" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">度量:</strong>在<strong class="lb iu"> </strong>训练期间，我们监控准确性:即，我们正确分类的实例的百分比。</li><li id="b53e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">时期:</strong>模型在训练期间遍历整个数据集的次数。</li></ul><p id="eba5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们网络的结构:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="0c6a" class="nz my it nv b gy oa ob l oc od">_________________________________________________________________<br/> Layer (type)                Output Shape              Param #   <br/>=================================================================<br/> flatten (Flatten)           (None, 784)               0         <br/>                                                                 <br/> dense (Dense)               (None, 350)               274750    <br/>                                                                 <br/> dense_1 (Dense)             (None, 10)                3510      <br/>                                                               =================================================================<br/>Total params: 278,260<br/>Trainable params: 278,260<br/>Non-trainable params: 0</span></pre><p id="a7e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管这是一个初学者友好的教程，但是有一个重要的特性你应该知道:</p><p id="6d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">神经网络容易过度拟合:有可能从训练数据中学习得如此之好，以至于它们可能无法对新的(测试)数据进行归纳。</p><p id="e614" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们让网络无限地训练，过拟合最终会发生。由于我们无法确切知道神经网络需要多长时间才能开始过度拟合，我们使用一种称为<strong class="lb iu"> <em class="mm">提前停止的机制。</em>T3】</strong></p><p id="ebf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="mm">提前停止</em> </strong>监控训练期间的确认损失。如果验证损失在指定的时期(称为<em class="mm">耐心</em>)内停止下降，训练立即停止。让我们在实现中使用它:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="f50d" class="nz my it nv b gy oa ob l oc od">early_stop=EarlyStopping(monitor='val_loss', restore_best_weights= True, patience=5, verbose=1)</span><span id="f758" class="nz my it nv b gy oe ob l oc od">callback = [early_stop]</span></pre><p id="d28b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们训练我们的模型:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="375f" class="nz my it nv b gy oa ob l oc od">history_mlp = model_mlp.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(val_x, val_y), callbacks=callback)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/5e029c3520ac54187ed4191e4450d3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mxeFxxFEv0GLrPm4yR_JbQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图2:</strong>MLP模型的训练历史</p></figure><p id="5ce9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个简单的数据集，我们使用了大量的时段(100)来证明<em class="mm">提前停止</em>在时段10被激活，并恢复了最佳权重(具体来说，在时段5)。</p><p id="03cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，这里最重要的指标是<strong class="lb iu"> <em class="mm">损失</em> </strong>和<strong class="lb iu"> <em class="mm">准确性</em> </strong>:让我们把它们形象化在一个图中。我们定义<em class="mm"> plot_history </em>函数:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="c5a4" class="nz my it nv b gy oa ob l oc od"># define the function:<br/>def plot_history(hs, epochs, metric):<br/>    plt.rcParams['font.size'] = 16<br/>    plt.figure(figsize=(10, 8))<br/>    for label in hs:<br/>        plt.plot(hs[label].history[metric], label='{0:s} train {1:s}'.format(label, metric), linewidth=2)<br/>        plt.plot(hs[label].history['val_{0:s}'.format(metric)], label='{0:s} validation {1:s}'.format(label, metric), linewidth=2)<br/>    plt.ylim((0, 1))<br/>    plt.xlabel('Epochs')<br/>    plt.ylabel('Loss' if metric=='loss' else 'Accuracy')<br/>    plt.legend()<br/>    plt.grid()<br/>    plt.show()</span><span id="5fe1" class="nz my it nv b gy oe ob l oc od">plot_history(hs={'MLP': history_mlp}, epochs=15, metric='loss')<br/>plot_history( hs={'MLP': history_mlp}, epochs=15, metric='accuracy')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/7be8e5d45389eaf9ea459a9964204c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*OtOnfAFG3ks5oTkcF627XA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图3:</strong>MLP的培训和验证损失</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/f1012414c1873d892f1d52916a968dcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*o2fcX_RmaYAVqFNcDUtRUA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图4:</strong>MLP的训练和验证精度</p></figure><p id="babd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">两个图都显示了度量标准的改进:损失减少了，而准确性提高了。</p><p id="3b28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果模型被训练了更多的时期，训练损失将继续减少，而验证损失将保持不变(甚至更糟，增加)。这将导致模型过度拟合。</p><p id="0a6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，让我们检查培训、验证和测试集的准确性:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="7397" class="nz my it nv b gy oa ob l oc od">mlp_train_loss, mlp_train_acc = model_mlp.evaluate(train_x,  train_y, verbose=0)<br/>print('\nTrain accuracy:', np.round(mlp_train_acc,3))</span><span id="5cde" class="nz my it nv b gy oe ob l oc od">mlp_val_loss, mlp_val_acc = model_mlp.evaluate(val_x,  val_y, verbose=0)<br/>print('\nValidation accuracy:', np.round(mlp_val_acc,3))</span><span id="5b17" class="nz my it nv b gy oe ob l oc od">mlp_test_loss, mlp_test_acc = model_mlp.evaluate(test_x,  test_y, verbose=0)<br/>print('\nTest accuracy:', np.round(mlp_test_acc,3))</span><span id="bfd5" class="nz my it nv b gy oe ob l oc od"><br/>#Output:</span><span id="9b84" class="nz my it nv b gy oe ob l oc od">#Train accuracy: 0.916<br/>#Validation accuracy: 0.889<br/>#Test accuracy: 0.866</span></pre><p id="5950" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">测试精度约为90%。此外，训练和验证/测试精度之间存在2%的差异。</p><h2 id="3388" class="nz my it bd mz op oq dn nd or os dp nh li ot ou nj lm ov ow nl lq ox oy nn oz bi translated"><strong class="ak">卷积神经网络</strong></h2><p id="681f" class="pw-post-body-paragraph kz la it lb b lc np ju le lf nq jx lh li nr lk ll lm ns lo lp lq nt ls lt lu im bi translated">另一类神经网络是<strong class="lb iu">卷积神经网络</strong>(或<strong class="lb iu"> CNN </strong>)。CNN更适合图像分类。他们使用<strong class="lb iu"> <em class="mm">滤镜</em> </strong>(也称为<strong class="lb iu"> <em class="mm">内核</em> </strong>或<strong class="lb iu"> <em class="mm">特征图</em> </strong>)帮助模型捕捉和学习图像的各种特征。<em class="mm"> CNN </em>的通用架构如图5<strong class="lb iu">所示。</strong></p><p id="677a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些过滤器不是静态的:它们是可训练的，这意味着模型在拟合期间以优化训练目标的方式学习它们。这与传统的计算机视觉相反，传统的计算机视觉使用静态过滤器进行特征提取。</p><p id="e1a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，CNN的深度至关重要。这是因为图像可以被视为一个层次结构，所以几层处理对这个领域有直观的意义。CNN 的第一层专注于提取底层特征(如边缘、角落)。随着深度的增加，特征地图学习更复杂的特征，例如形状和脸。</p><p id="e7ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，在每个步骤中，信息在被传递到下一个过滤层之前经历“<strong class="lb iu">子采样“</strong>”。最后一个组件是一个<strong class="lb iu">全连接层</strong>，它看起来像一个MLP，但是没有隐藏层。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/fff293357945e7f1d58d1fca7db08cbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRLw4lsANPEfGgimG3YVQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图5:</strong>CNN的顶层架构[3]</p></figure><p id="07da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们深入研究一下实现。</p><p id="f73a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，了解每个网络接受什么类型的输入至关重要。对于MLPs，每个图像被展平成一个单独的<code class="fe om on oo nv b">28x28</code>向量。这里，每个图像被表示为一个3d立方体，其尺寸<code class="fe om on oo nv b">28x28x1</code>表示格式(宽度、高度、颜色通道)。如果我们的图像不是灰度的，尺寸将会是<code class="fe om on oo nv b">28x28x3</code>。</p><p id="604b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们仍然会像以前一样使用相同的激活和损失函数。此外，我们只执行一组过滤/特征映射和子采样。在<em class="mm"> Keras API </em>中，这些分别被称为<strong class="lb iu"> <em class="mm"> Conv2D </em> </strong>和<strong class="lb iu"> <em class="mm"> MaxPooling2D </em> </strong>层:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="dc4f" class="nz my it nv b gy oa ob l oc od">model_cnn = Sequential()<br/>model_cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))<br/>model_cnn.add(MaxPooling2D((2, 2)))<br/>model_cnn.add(Flatten())<br/>model_cnn.add(Dense(100, activation='relu'))<br/>model_cnn.add(Dense(10, activation='softmax'))</span><span id="d210" class="nz my it nv b gy oe ob l oc od">model_cnn.compile(optimizer="adam", loss='categorical_crossentropy', metrics=['accuracy'])<br/>print(model_cnn.summary())</span><span id="1be1" class="nz my it nv b gy oe ob l oc od">history_cnn= model_cnn.fit(train_x, train_y, epochs=100, batch_size=32, validation_data=(val_x, val_y), callbacks=callback)</span></pre><p id="86e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">输出是:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="efd8" class="nz my it nv b gy oa ob l oc od">_________________________________________________________________<br/> Layer (type)                Output Shape              Param #   <br/>=================================================================<br/> conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       <br/>                                                                 <br/> max_pooling2d_3 (MaxPooling  (None, 13, 13, 32)       0         <br/> 2D)                                                             <br/>                                                                 <br/> flatten_3 (Flatten)         (None, 5408)              0         <br/>                                                                 <br/> dense_6 (Dense)             (None, 100)               540900    <br/>                                                                 <br/> dense_7 (Dense)             (None, 10)                1010      <br/>                                                                 <br/>=================================================================<br/>Total params: 542,230<br/>Trainable params: 542,230<br/>Non-trainable params: 0<br/>_________________________________________________________________<br/>Epoch 1/100<br/>1782/1782 [==============================] - 19s 5ms/step - loss: 0.4063 - accuracy: 0.8581 - val_loss: 0.3240 - val_accuracy: 0.8913<br/>Epoch 2/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.2781 - accuracy: 0.9001 - val_loss: 0.3096 - val_accuracy: 0.8883<br/>Epoch 3/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.2343 - accuracy: 0.9138 - val_loss: 0.2621 - val_accuracy: 0.9057<br/>Epoch 4/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.2025 - accuracy: 0.9259 - val_loss: 0.2497 - val_accuracy: 0.9080<br/>Epoch 5/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.1763 - accuracy: 0.9349 - val_loss: 0.2252 - val_accuracy: 0.9200<br/>Epoch 6/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.1533 - accuracy: 0.9437 - val_loss: 0.2303 - val_accuracy: 0.9250<br/>Epoch 7/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.1308 - accuracy: 0.9516 - val_loss: 0.2447 - val_accuracy: 0.9140<br/>Epoch 8/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.1152 - accuracy: 0.9573 - val_loss: 0.2504 - val_accuracy: 0.9213<br/>Epoch 9/100<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.0968 - accuracy: 0.9644 - val_loss: 0.2930 - val_accuracy: 0.9133<br/>Epoch 10/100<br/>1779/1782 [============================&gt;.] - ETA: 0s - loss: 0.0849 - accuracy: 0.9686Restoring model weights from the end of the best epoch: 5.<br/>1782/1782 [==============================] - 9s 5ms/step - loss: 0.0849 - accuracy: 0.9686 - val_loss: 0.2866 - val_accuracy: 0.9187<br/>Epoch 10: early stopping</span></pre><p id="1cee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们用100个历元初始化我们的模型。然而，10个纪元足够训练了——直到<em class="mm">提前停止</em>开始。</p><p id="6c39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们画出我们的训练和验证曲线。我们使用与之前相同的<em class="mm"> plot_history </em>函数方法:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="3843" class="nz my it nv b gy oa ob l oc od">plot_history(hs={'CNN': history_cnn},epochs=10,metric='loss')<br/>plot_history(hs={'CNN': history_cnn},epochs=10,metric='accuracy')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/0116437058f1444b972e3e9354023190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*19zhqchjLt8gJyAyIlQdFQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图6:</strong>CNN的训练和验证损失</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/28f9da0d4a99beeba3ad0b4aaebfae1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*Nv5t4y0EgcdePDIh5FEPJA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd og">图7:</strong>CNN的训练和验证精度</p></figure><p id="d164" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">验证曲线遵循与<em class="mm"> MLP </em>车型相同的模式。</p><p id="35cd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们计算训练、验证和测试精度:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="a079" class="nz my it nv b gy oa ob l oc od">cnn_train_loss, cnn_train_acc = model_cnn.evaluate(train_x,  train_y, verbose=2)<br/>print('\nTrain accuracy:', cnn_train_acc)</span><span id="0158" class="nz my it nv b gy oe ob l oc od">cnn_val_loss, cnn_val_acc = model_cnn.evaluate(val_x,  val_y, verbose=2)<br/>print('\nValidation accuracy:', cnn_val_acc)</span><span id="0c25" class="nz my it nv b gy oe ob l oc od">cnn_test_loss, cnn_test_acc = model_cnn.evaluate(test_x,  test_y, verbose=2)<br/>print('\nTest accuracy:', cnn_test_acc)</span><span id="aae9" class="nz my it nv b gy oe ob l oc od">#Output:</span><span id="152f" class="nz my it nv b gy oe ob l oc od">#Train accuracy: 0.938<br/>#Validation accuracy: 0.91<br/>#Test accuracy: 0.908</span></pre><p id="46f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CNN的<em class="mm">模式胜过了MLP的<em class="mm">模式。这是意料之中的，因为CNN</em>更适合图像分类。</em></p><h1 id="5149" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">结束语</h1><ul class=""><li id="369d" class="lv lw it lb b lc np lf nq li pu lm pv lq pw lu ma mb mc md bi translated">神经网络用于训练的优化函数是“<em class="mm">随机</em>”。这意味着，除了别的以外，每次你训练一个模型，你会得到稍微不同的结果。</li><li id="8656" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">数据集很简单。首先，图像是灰度的，这意味着它们只有一个通道。彩色图像有3个通道(RGB)。</li><li id="a427" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">即使我们使用了验证集，我们也没有执行任何超参数调优。在本教程的下一部分，我们将展示如何进一步优化我们的模型。</li></ul><p id="b742" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">完整的例子可以在<a class="ae ky" href="https://jovian.ai/nkafr/create-image-classification-models-with-tensorflow-in-10-minutes" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="c781" class="mx my it bd mz na nb nc nd ne nf ng nh jz ni ka nj kc nk kd nl kf nm kg nn no bi translated">感谢您的阅读！</h1><ul class=""><li id="5327" class="lv lw it lb b lc np lf nq li pu lm pv lq pw lu ma mb mc md bi translated">订阅我的<a class="ae ky" href="https://towardsdatascience.com/subscribe/@nikoskafritsas" rel="noopener" target="_blank">简讯</a>！</li><li id="f4f8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在<a class="ae ky" href="https://www.linkedin.com/in/nikos-kafritsas-b3699180/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上关注我！</li><li id="ee66" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><a class="ae ky" href="https://medium.com/@nikoskafritsas/membership" rel="noopener"> <strong class="lb iu">加入介质</strong> </a> <strong class="lb iu">！</strong>(附属链接)</li></ul><h1 id="993c" class="mx my it bd mz na oh nc nd ne oi ng nh jz oj ka nj kc ok kd nl kf ol kg nn no bi translated">参考</h1><ol class=""><li id="9ee6" class="lv lw it lb b lc np lf nq li pu lm pv lq pw lu px mb mc md bi translated">时尚MNIST数据集由Zalando，<a class="ae ky" href="https://www.kaggle.com/datasets/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/Zalando-research/fashion mnist</a>，麻省理工学院许可(MIT)版权【2017】</li><li id="8a6e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu px mb mc md bi translated">By Glosser.ca —自己的作品，衍生文件:人工神经网络. svg，CC BY-SA 3.0，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=24913461" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=24913461</a></li><li id="d839" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu px mb mc md bi translated">By Aphex34 —自己的作品，CC BY-SA 4.0，<a class="ae ky" href="https://commons.wikimedia.org/w/index.php?curid=45679374" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=45679374</a></li></ol></div></div>    
</body>
</html>