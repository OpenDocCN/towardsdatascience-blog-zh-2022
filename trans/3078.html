<html>
<head>
<title>Correlation Matrix, Demystified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">相关矩阵，非神秘化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/correlation-matrix-demystified-3ae3405c86c1#2022-07-06">https://towardsdatascience.com/correlation-matrix-demystified-3ae3405c86c1#2022-07-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e750" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关联矩阵:什么是关联矩阵，它是如何构建的，它有什么用途</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fd68ed42fccc3bbf569d665a8c58888d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bp99LwDDzmRNrcud"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这看起来像散点图，不是吗？稍后将详细介绍。照片由<a class="ae kv" href="https://www.pexels.com/photo/yellow-bokeh-photo-949587/" rel="noopener ugc nofollow" target="_blank">rovenimages.com</a>:</p></figure><p id="8928" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这个关于统计指数的迷你系列(最初是根据我在<a class="ae kv" href="https://datamasters.it/" rel="noopener ugc nofollow" target="_blank"> Datamasters.it </a>当老师的经验设计的)的上一篇文章中，我们已经研究了<a class="ae kv" href="https://medium.com/@mastrandreagiuseppe/come-non-avere-paura-di-deviazione-standard-varianza-e-covarianza-12425a9dca09" rel="noopener">方差、标准差、协方差</a> e <a class="ae kv" href="https://medium.com/@mastrandreagiuseppe/correlazione-vs-covarianza-%C3%A8-tutto-pi%C3%B9-semplice-di-quel-che-sembra-be16d74d080d" rel="noopener">相关性</a>。在本文中，我们将重点关注上一篇文章中概述的一种数据结构，当我开始学习机器学习时，我简直惊呆了，不是因为这是一个难以理解的概念，而是因为它让我清楚地了解了数据科学和机器学习的力量。</p><h1 id="6056" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我们在哪里停下来的？相互关系</h1><p id="a8c6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我说的数据结构就是强大的<strong class="ky ir">相关矩阵。</strong>像许多其他数据科学概念一样，它是一个易于理解甚至更易于使用的代数概念。让我们快速回顾一下相关性:它是一个指数，显示两个随机变量X和y之间的线性关系。它总是一个介于-1和1之间的数字，其中:</p><ul class=""><li id="d9e6" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">-1意味着这两个变量具有逆线性关系:当X增加时，Y减少</li><li id="4cb9" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">0表示X和Y之间没有线性相关性</li><li id="679c" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">1表示这两个变量具有线性关系:当X增加时，Y也增加。</li></ul><p id="2930" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当心！相关性并不意味着因果关系。当X和Y之间的相关性接近1时，我们不能说X的变化意味着Y的后续变化。例如，考虑两个变量:“一年内每天售出的冰淇淋数量”和“一年内晒伤的数量”。这两个变量可能有很高的相关性，但是两个变量<strong class="ky ir">中一个的变化不会反映另一个</strong>。高相关性，低因果性。现在:回到相关矩阵。</p><h1 id="7f0d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">相关矩阵</h1><p id="e6b5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">相关矩阵是一个<strong class="ky ir">平方</strong>(行数等于列数)<strong class="ky ir">对称</strong>(矩阵等于其转置)，所有主对角元素等于1且<strong class="ky ir">半正定</strong>(其所有特征值均非负)的矩阵。虽然前3个属性很容易理解和可视化，但在最后一个条件上花一些时间是值得的，因为<em class="nd">不是所有主对角线等于1的正方形对称矩阵都是半正定的</em>，因此不是所有满足前3个必要条件的矩阵都是相关矩阵。例如，下面的矩阵:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="8c0d" class="nj lt iq nf b gy nk nl l nm nn">m = [<br/>    [1, 0.6, 0.9],<br/>    [0.6, 1, 0.9],<br/>    [0.9, 0.9, 1]<br/>]</span></pre><p id="6550" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有一个负特征值。你可以用纸和笔找到它，但是当我们可以让其他人做算术的时候，为什么还要麻烦呢？我们可以用Python和numpy得到m的所有特征值:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="44d1" class="nj lt iq nf b gy nk nl l nm nn">m = [<br/>    [1, 0.6, 0.9],<br/>    [0.6, 1, 0.9],<br/>    [0.9, 0.9, 1]<br/>]</span><span id="87a4" class="nj lt iq nf b gy no nl l nm nn">eigenvalues = np.linalg.eig(m)<br/>print(eigenvalues[0])</span><span id="43e4" class="nj lt iq nf b gy no nl l nm nn">Out: [ 2.60766968  0.4        -0.00766968]</span></pre><p id="68da" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html" rel="noopener ugc nofollow" target="_blank"> np.linalg.eig </a>函数将一个矩阵作为输入(在所有编程语言中，它可以表示为一个列表列表、一个数组数组或一个矢量向量),并返回一个包含两个元素的元组:</p><ul class=""><li id="561b" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">第一个是矩阵的<strong class="ky ir">特征值</strong>列表</li><li id="1fc5" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">第二个是包含矩阵的<strong class="ky ir">归一化特征向量</strong>的列表</li></ul><p id="f4b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特征值是返回的元组中索引为<code class="fe np nq nr nf b">[0]</code>的元素。有一些技术可以使一个非半正定矩阵成为半正定矩阵，但是我们不会在这里讨论这个话题。如果你想进一步研究这个话题，你可以查看这个网址。</p><h1 id="4ed2" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">构建相关矩阵</h1><p id="7596" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在让我们试着去理解<strong class="ky ir">一个相关矩阵是如何产生的</strong>，假设它已经有了之前写的所有属性。</p><p id="abaf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从一个数据集开始，也称为“随机变量集”，或者如果你喜欢一组代表单个<strong class="ky ir">观察值</strong>的行和列，其中每行有一定数量的列或<strong class="ky ir">特征</strong>。</p><p id="1188" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我开始阅读<a class="ae kv" href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" rel="noopener ugc nofollow" target="_blank">这本书</a>来研究ML时，第一个完整的预测模型例子(一个简单的线性回归，第二章)在一个由加州地区房屋数据组成的数据集上训练自己。你可以从<a class="ae kv" href="https://www.kaggle.com/datasets/camnugent/california-housing-prices" rel="noopener ugc nofollow" target="_blank">这里</a>下载。当我第一次读到什么是线性回归，当我学习探索性分析部分(相关性和相关性矩阵出现的地方)时，我的感知之门很快就打开了，正如有人所说。是的，没有麦斯卡林。我们，计算机科学家，很少需要去旅行。顺便说一下:数据集的每一行代表不同的加州区；另外，每一行都有以下特性(<em class="nd">特性</em>是一个很酷的名字，可以称之为“随机变量”，或者更好:<em class="nd">变量你可以在</em>上计算一些统计指数):</p><ul class=""><li id="41d6" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">经度</li><li id="0ddc" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">纬度</li><li id="3baf" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">房屋年龄中位数</li><li id="514c" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">房间总数</li><li id="7dae" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">卧室总数</li><li id="eeee" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">人口数量</li><li id="a807" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">家庭</li><li id="fd70" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">中等收入</li><li id="6873" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">房价中位数</li><li id="666f" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">海洋接近度</li></ul><p id="2de9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这本书对于任何想学习机器学习的人来说都是真正的<em class="nd">必读</em>，尽管它不适合完全初学者，如果你有基本的数据科学背景就更好了。所有的代码都可以在这里<a class="ae kv" href="https://github.com/ageron/handson-ml2" rel="noopener ugc nofollow" target="_blank">找到</a>，把它收藏起来。</p><p id="ead6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以说我们的数据集有一个<code class="fe np nq nr nf b">n x 10</code>维度，其中<code class="fe np nq nr nf b">n</code>是行数，即加利福尼亚地区的数量。</p><p id="b439" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们为这个数据集构建相关矩阵。我们要计算相关性的变量是数据集的10个特征。哦，好吧，在这个数据集中，有一个特征的相关性是没有意义的:我们正在谈论的是<code class="fe np nq nr nf b">ocean_proximity</code>特征，一个<strong class="ky ir">分类</strong>变量。“分类”意味着变量的定义域是一组<strong class="ky ir">离散的</strong>值，而不是一组连续的数字。特别是，对于这些特性<strong class="ky ir">，唯一允许的值是</strong>:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="f3df" class="nj lt iq nf b gy nk nl l nm nn">{“1H OCEAN”, “INLAND”, “NEAR OCEAN”, “NEAR BAY”, “ISLAND” }</span></pre><p id="8e6f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以用这个变量计算相关性(计算两个连续随机变量之间线性关系的指标)是没有意义的。我们可以把它从相关矩阵中排除。让我们从头开始:我们的数据集由10个特征组成，但我们忽略了其中的一个，因此我们的相关矩阵最初将是一个空的9x9矩阵:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/66954ddb88d83b5f2533b877da3477ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4EBx4xLVBtKAFSGT"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一个空的9x9矩阵。图片由作者提供。</p></figure><p id="f0fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们用实际的相关性填充矩阵。让我提醒您，矩阵的每个元素都有一个行索引和一个列索引，用于描述它在矩阵中的位置。我们从0开始对行和列进行计数:这意味着(例如)最左边的最低值的位置是<code class="fe np nq nr nf b">8, 0</code>(第8行，第0列)。第四行最右边的元素的位置是<code class="fe np nq nr nf b">3, 8</code>(第3行，第8列)。矩阵的对称性告诉我们一件更有趣的事情:位置为<code class="fe np nq nr nf b">i, j</code>的元素等于位置为<code class="fe np nq nr nf b">j, i</code>的元素(位置为<code class="fe np nq nr nf b">3, 8</code>的元素等于位置为<code class="fe np nq nr nf b">8, 3</code>的元素):为了满足这一性质，我们必须构建矩阵，使得位于某一位置的变量也位于同一列。例如，让我们从<code class="fe np nq nr nf b">longitude</code>特性开始，假设我们想在第0行使用它。对称条件要求我们必须对第0列使用<code class="fe np nq nr nf b">longitude</code>特性。然后我们对<code class="fe np nq nr nf b">latitude</code>做同样的操作:第1行，第1列。<code class="fe np nq nr nf b">housing_median_age</code>？第3行，第3列，依此类推，直到我们使用了所有的数据集特征并得到这个空矩阵:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8a06f3ca02ac3736b355e8401e4a7a25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ErjIF52oTxRkYbvG"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">相关矩阵的标签。图片由作者提供。</p></figure><p id="360a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们试着<em class="nd">读一下</em>这个矩阵:位置为<code class="fe np nq nr nf b">0, 5</code>(第0行，第5列)的元素表示经度与人口的<strong class="ky ir">相关性；对于对称属性，它等于位置为<code class="fe np nq nr nf b">5, 0</code>的元素，表示人口和经度</strong>之间的<strong class="ky ir">相关性。两个变量X和Y之间的相关性等于Y和X之间的相关性。对于位置为<code class="fe np nq nr nf b">6, 7</code>的元素，包含“家庭”和“中位数_收入”之间的相关性的元素以及等于索引为<code class="fe np nq nr nf b">7, 6</code>的元素，<code class="fe np nq nr nf b">median_income</code>和<code class="fe np nq nr nf b">households</code>之间的相关性也是如此。</strong></p><p id="55eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在考虑矩阵主对角线上的一个元素，例如，位置为<code class="fe np nq nr nf b">4, 4</code>的元素:它将表示“总卧室数”<em class="nd">与其自身</em>的相关性。根据定义，变量与其自身的相关性是<strong class="ky ir">总是1 </strong>。当然，所有的主对角线元素都有这个性质:一个相关矩阵的所有主对角线元素都等于1。</p><h1 id="5257" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Python、pandas和seaborn中的相关矩阵</h1><p id="f225" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在:要用实际值填充相关矩阵，我们应该计算每对变量的相关性。<strong class="ky ir">无聊</strong>。<em class="nd">这个证明留给读者做练习</em>。我们可以用“熊猫”来代替:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="02a7" class="nj lt iq nf b gy nk nl l nm nn">import pandas as pd</span><span id="8be0" class="nj lt iq nf b gy no nl l nm nn">housing = pd.read_csv('datasets/housing.csv')</span><span id="8a6e" class="nj lt iq nf b gy no nl l nm nn">rounded_corr_matrix = housing.corr().round(2)</span><span id="e1ee" class="nj lt iq nf b gy no nl l nm nn">print(rounded_corr_matrix[‘median_income’])</span></pre><p id="27ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在命名的(它是<code class="fe np nq nr nf b">as pd</code>部分)导入指令之后，让我们使用pandas方法<code class="fe np nq nr nf b">read_csv</code>读取我们之前下载的CSV文件，该方法将文件的路径作为输入，让我们将读取结果存储在一个名为<code class="fe np nq nr nf b">housing</code>的变量中。<code class="fe np nq nr nf b">read_csv</code>返回的数据类型是一个<code class="fe np nq nr nf b">DataFrame</code>，pandas中定义的最重要的数据类型，代表一组数据(有人说“数据集”了吗？).我们可以在一个数据帧上使用许多方法和函数，其中有<code class="fe np nq nr nf b">corr()</code>方法；顾名思义，我们可以用它从一个数据集中得到一个相关矩阵！我们使用方法<code class="fe np nq nr nf b">round(2)</code>将相关值四舍五入到第二个小数位，只是因为我们想使用可读性更好的<em class="nd">矩阵。在下一条指令中，我们以熊猫<code class="fe np nq nr nf b">Series</code>的形式打印<code class="fe np nq nr nf b">median_income</code>和所有其他特征之间的相关值。它是一种类似于常规数组的数据结构(例如，我们可以使用数字索引来访问它的值)，但是具有超能力。另外，我们可以访问一个指定第二个</em>索引的特定值。例如:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="c967" class="nj lt iq nf b gy nk nl l nm nn">rounded_corr_matrix['median_income']['housing_median_age']</span></pre><p id="be25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将保持<code class="fe np nq nr nf b">median_income</code>和<code class="fe np nq nr nf b">housing_median_age</code>之间的相关性。得心应手，对吧？我们还可以使用以下指令打印按降序排列的<code class="fe np nq nr nf b">median_income</code>特征的所有相关值</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="d187" class="nj lt iq nf b gy nk nl l nm nn">rounded_corr_matrix["median_income"].sort_values(ascending=False)</span></pre><p id="3188" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出将是:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="027b" class="nj lt iq nf b gy nk nl l nm nn">median_income         1.00<br/>median_house_value    0.69<br/>total_rooms           0.20<br/>households            0.01<br/>population            0.00<br/>total_bedrooms       -0.01<br/>longitude            -0.02<br/>latitude             -0.08<br/>housing_median_age   -0.12<br/>Name: median_income, dtype: float64</span></pre><p id="0c7d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，要获得<em class="nd">整个</em>数据集的相关矩阵，需要使用<code class="fe np nq nr nf b">corr()</code>方法。如果我们想<em class="nd">改进</em>可视化相关矩阵的方式，我们可以使用seaborn的<code class="fe np nq nr nf b">heatmap</code>函数。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="2482" class="nj lt iq nf b gy nk nl l nm nn">import seaborn as sns</span><span id="1e66" class="nj lt iq nf b gy no nl l nm nn">heatmap = sns.heatmap(rounded_corr_matrix, annot=True)<br/>heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)</span></pre><p id="556c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">热图是一种数据可视化工具，可以将特定现象映射到色标上。在我们的例子中，较深的颜色用于映射较低的值(黑色映射相关值-1)，而较高的值映射到较浅的颜色(白色映射相关值+1)。Seaborn有一个<code class="fe np nq nr nf b">heatmap</code>方法，它将我们将要创建热图的二维数据结构作为第一个参数:在我们的例子中是相关矩阵。我们向名为<code class="fe np nq nr nf b">annot</code>的<code class="fe np nq nr nf b">heatmap</code>函数传递另一个参数:在热图单元格中写入实际的相关值很有用，可以更精确地了解正在发生的事情。</p><p id="2bb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi">​​</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fc34d880073e7bd1a76abf648dd86b02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dL10RKpRR6l0FxLy"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加州住房数据集的Seaborn热图。图片由作者提供。</p></figure><p id="2204" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如我们所见，热图的有用性依赖于对可视化数据解释的即时性。例如，快速浏览后，很明显“总卧室数”和<code class="fe np nq nr nf b">total_rooms</code> (0.93，<em class="nd">非常接近于1)，<code class="fe np nq nr nf b">total_roomns</code>和<code class="fe np nq nr nf b">population</code>，<code class="fe np nq nr nf b">total_bedrooms</code>和<code class="fe np nq nr nf b">households</code>之间有很高的相关性。很有道理，不是吗？相比之下，我们将为<code class="fe np nq nr nf b">latitude</code>和<code class="fe np nq nr nf b">longitude</code>设置一个较低的相关值(稍等片刻，试着想象一下加利福尼亚州的<em class="nd">形状</em>)。对于0附近的值(例如<code class="fe np nq nr nf b">median_income</code>和<code class="fe np nq nr nf b">population</code>)，我们不能说什么。</em></p><p id="3028" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">多亏了pandas，我们可以获取数据集特征的子集并打印相关的相关矩阵。为了获取我们的相关矩阵特征的子集，我们所要做的就是创建一个带有<em class="nd">特征</em> <em class="nd">名称</em>的列表，并在原始矩阵上使用括号符号:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="e16c" class="nj lt iq nf b gy nk nl l nm nn">features = ["median_house_value", "median_income", "total_rooms",<br/>                  "housing_median_age"]</span><span id="0d51" class="nj lt iq nf b gy no nl l nm nn">subset = rounded_corr_matrix[features].loc[features]<br/>heatmap = sns.heatmap(subset, annot=True)</span></pre><p id="e8f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们注意到，如果我们试图简单地访问<code class="fe np nq nr nf b">rounded_corr_matrix[features]</code>，我们将得到一个9x4的矩阵，其中包含4个所选特征与<em class="nd">所有其他数据集特征的关联。我们使用<code class="fe np nq nr nf b">loc</code> pandas属性，这允许我们使用它们的名称而不是数字索引来访问9x4数据结构的特性子集。这些名字当然是<code class="fe np nq nr nf b">features</code>的名字。我们得到一个4x4的结构，可以在上面使用我们的热图。结果如下:</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/982e62b1ddec713ecdecb6bce26fefaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IN7_MhcLFnC-q-TY"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据集子集的热图。图片由作者提供。</p></figure><h1 id="c0f0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">散点图—基础</h1><p id="d914" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">最后，我们使用pandas函数<code class="fe np nq nr nf b">scatter_matrix</code>，它为我们提供了更加<em class="nd">直观的</em>相关矩阵可视化。顾名思义，该矩阵不是由数字构成的，而是由散点图(2D图，其中每个轴都是一个数据集要素)构成的。</p><p id="27be" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将特征对之间的线性关系可视化是很有用的(与经典相关矩阵的目的相同，但从<em class="nd">视觉</em>的角度来看)。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="02c6" class="nj lt iq nf b gy nk nl l nm nn">from pandas.plotting import scatter_matrix</span><span id="89ec" class="nj lt iq nf b gy no nl l nm nn">features = ["total_rooms", "population", "households", "median_house_value"]<br/>scatter_matrix(housing[features], figsize=(12, 8))</span></pre><p id="b6f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/273e2183a3ad53641a2b176b1e163cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*J5M8nrUwJWTfqMvt"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加州住房数据集子集的散布矩阵。图片由作者提供。</p></figure><p id="1ac4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意一件奇怪的事情:我们在主对角线上有直方图。理论上，我们应该在这些位置找到变量和<em class="nd">本身</em>之间的相关性，但是如果我们画出它们，我们只会得到方程y=x的直线(我们在x轴和y轴上有相同的值，一条直线)。“scatter_matrix”向我们展示了这些变量的<strong class="ky ir">直方图</strong>，而不是可视化的45度线，只是为了快速了解特征的分布。查看其他图，对于某些变量对(es。人口/总房间数，或家庭/人口)有明显的正相关，在某些情况下<em class="nd">非常接近</em>1。相比之下，所有变量都呈现出一个与' median_house_value '(最有趣的特征，我们应该设计一个机器学习预测模型)接近0的相关值，而且这些图非常“稀疏”。</p><h1 id="c971" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">相关矩阵的使用</h1><p id="39c9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">既然我们知道了如何构建关联矩阵，并且在探索了Python中其他形式的数据可视化技术之后，我们可以问自己这种数据结构的实际用途是什么。通常，在机器学习中使用相关矩阵来进行一些探索性和初步的分析，以推测<em class="nd">哪种</em>预测模型可以有效地解决给定的任务。例如，如果我们的模型是一个能够预测房价的回归模型(即我们的模型应该预测一个<em class="nd">连续值</em>),我们可以对最感兴趣的特征使用相关矩阵。在这种情况下，最相关的特征(毫无疑问)将是<code class="fe np nq nr nf b">median_house_value</code>，因此传统的方法是绘制该特征和具有更高相关性的特征之间的相关性的热图或散点图:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="5262" class="nj lt iq nf b gy nk nl l nm nn">features = ["median_house_value", "total_rooms", "median_income"]</span><span id="a94a" class="nj lt iq nf b gy no nl l nm nn">scatter_matrix(housing[features], figsize=(12, 8))</span></pre><p id="983d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们会发现<code class="fe np nq nr nf b">median_income</code>和<code class="fe np nq nr nf b">median_house_value</code>之间有非常明显的相关性(收入中值越高，房屋价值中值越高……一如既往，这是有道理的)。然后我们可以尝试建立、训练和优化一个简单的线性回归模型。我们不会得到一个非常精确的模型，但这仍然是一个起点，不是吗？</p><h1 id="52a5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">奖励赛道—加州，我们来了！</h1><p id="0ed4" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在文章的前面，我们问了<code class="fe np nq nr nf b">latitude</code>和<code class="fe np nq nr nf b">longitude</code>之间非常低的相关值意味着什么。为了科学起见，让我们画一个这两个变量的散点图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/3fea1e9bb8c3597565bdc619954004c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8iw1oxSWHqGutBHS"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">加州，我们来了！作者图片</p></figure><p id="540c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">嘿，它看起来不像真正的加州的<strong class="ky ir">吗？是的，当然！纬度和经度之间的低相关值是由于<strong class="ky ir">地理加州形状</strong>类似于具有负角度系数的直线。这不是很有趣吗？</strong></p><p id="5166" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是生成熊猫散点图的代码:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="9962" class="nj lt iq nf b gy nk nl l nm nn">housing[['longitude', 'latitude']].plot.scatter(x="longitude", y="latitude")</span></pre><p id="c6bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">快乐学习和编码！</p></div></div>    
</body>
</html>