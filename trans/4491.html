<html>
<head>
<title>“You Can’t Predict the Errors of Your Model”… Or Can You?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“你不能预测你的模型的错误”…或者你能吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/you-cant-predict-the-errors-of-your-model-or-can-you-1a2e4a1f38a0#2022-10-05">https://towardsdatascience.com/you-cant-predict-the-errors-of-your-model-or-can-you-1a2e4a1f38a0#2022-10-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d29d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">NannyML已经发布了DLE，这是一种算法，能够在缺乏基本事实的情况下预测回归模型的平均误差和均方误差</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1ce667a5a5e41f4e0852329f5d999b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0HdszcpApJt0FQy-LUCSpg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">[图片由作者提供]</p></figure><p id="5b18" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi lr translated"><span class="l ls lt lu bm lv lw lx ly lz di">在</span> a <a class="ae ma" rel="noopener" target="_blank" href="/predict-your-models-performance-without-waiting-for-the-control-group-3f5c9363a7da">之前的文章</a>中，我们已经看到了如何在地面真相可用之前预测你的分类模型的性能。这在现实世界中非常有用，因为它可以为您提供模型在生产中表现如何的早期反馈。</p><p id="16ac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是由NannyML构想的一种算法实现的，称为“<a class="ae ma" href="https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#confidence-based-performance-estimation-cbpe" rel="noopener ugc nofollow" target="_blank">基于信心的性能估计</a>”(CBPE)，它使用模型预测的概率来获得任何分类指标的可靠估计。一个自然的问题是:</p><blockquote class="mb"><p id="b16b" class="mc md iq bd me mf mg mh mi mj mk lq dk translated">我们能对回归模型也这样做吗？</p></blockquote><p id="69c7" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">根据NannyML的说法，是的，我们可以。他们开发了一种称为“<a class="ae ma" href="https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#direct-loss-estimation-dle" rel="noopener ugc nofollow" target="_blank">直接损失估计</a>”(DLE)的方法，允许在无法获得基本事实的情况下，估计任何回归模型的性能(特别是平均绝对误差和均方误差)。</p><p id="d0c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">他们声称<a class="ae ma" href="https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html" rel="noopener ugc nofollow" target="_blank">在这里</a>作为评估性能的一站式解决方案，DLE优于其他方法，如贝叶斯方法或整合分位数回归。但是除非我们看到，否则我们不会相信，对吗？因此，在本文中，我们将探索DLE，在真实数据集上尝试它，看看它是否真的像NannyML承诺的那样表现良好。</p><h1 id="9e34" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">主要思想</h1><p id="7b1b" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">DLE背后的直觉非常简单。简单到好得难以置信。基本上，<strong class="kx ir">的想法是直接预测模型</strong>产生的误差。</p><p id="8f12" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我知道你在想什么。你可能会持怀疑态度，因为你听说过:</p><blockquote class="mb"><p id="0a94" class="mc md iq bd me mf mg mh mi mj mk lq dk translated">"你不能让一个模型预测另一个模型的误差."</p></blockquote><p id="7d60" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">但这是真的吗？要回答这个问题，需要从后验分布说起。</p><h1 id="788b" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">介绍后验分布</h1><p id="fdd4" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">我们习惯于为每个观察返回单个值的模型，也称为“<strong class="kx ir">点预测</strong>”。但是，我们必须记住，在点预测的背后，总是有一个完整的分布。如果你喜欢花哨的统计术语，你可以称之为“<strong class="kx ir">后验分布</strong>”。</p><p id="a82b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">后验分布是什么意思？</p><blockquote class="mb"><p id="2312" class="mc md iq bd me mf mg mh mi mj mk lq dk translated">后验分布给出了预测不确定性的完整描述。</p></blockquote><p id="e050" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">让我们借助一个例子来理解它。</p><p id="572a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">假设我们训练了一个模型，根据一个人的国家、性别、年龄、婚姻状况和工作来预测她的收入。现在，假设我们有10，000人，他们都具有以下特征:</p><ul class=""><li id="52ba" class="nn no iq kx b ky kz lb lc le np li nq lm nr lq ns nt nu nv bi translated">国家:美国。</li><li id="7438" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">性别:女。</li><li id="abad" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">年龄:27。</li><li id="0383" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">婚姻状况:已婚。</li><li id="438b" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">工作:销售人员。</li></ul><p id="b3c7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当然，即使他们有相同的特征，他们也不会有相同的收入。我们可以把他们收入的分布想象成这种特殊特征组合的后验分布。</p><p id="94b5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们用Python生成一个后验分布:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="026c" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># generate posterior distribution</strong></span><span id="d9cd" class="og mr iq oc b gy ol oi l oj ok">import numpy as np</span><span id="c699" class="og mr iq oc b gy ol oi l oj ok">posterior_distribution = np.random.lognormal(0, .25, 10000) * 50000</span></pre><p id="758f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是分布的直方图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/ad7db364b0f9f0aab778de18a2abe703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-ZZ1R5i4-35FOqEBdLEfA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">个人收入的后验分布。[图片由作者提供]</p></figure><p id="f7e7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">知道后验分布最酷的一点是，我们可以计算任何我们想要的东西:百分位数、平均值、中位数……任何东西。</p><p id="f5a6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，大多数预测模型被设计成获得点预测。的确，<strong class="kx ir">当给定上面的10，000个人时，你的模型将预测他们每个人的收入是相同的</strong>。正如您所猜测的，模型通常被设计用来预测后验分布的平均值。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="8ce2" class="og mr iq oc b gy oh oi l oj ok">np.mean(posterior_distribution)</span></pre><p id="a041" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的例子中，这是50，000美元。这是模型的预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/2e7097a82694605716a2759886f5107c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZ9xCpgVZ_LNaZWOWlk3xA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">点预测对应于后验分布的平均值。[图片由作者提供]</p></figure><h1 id="8f96" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">为什么预测误差没有意义…</h1><p id="2ea4" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">对于我们每一个个体，误差是由点预测和真实值之间的差给出的。例如，如果一个人的收入是65，000美元，模型产生的误差是-15，000美元。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="0932" class="og mr iq oc b gy oh oi l oj ok">error_distribution = point_prediction - posterior_distribution</span></pre><p id="860e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你取平均误差:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="3489" class="og mr iq oc b gy oh oi l oj ok">mean_error = np.mean(error_distribution)</span></pre><p id="192e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">根据定义，这当然是零。</p><p id="961f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">平均误差为零的事实很有意义。这意味着，平均而言，我们的模型做出了正确的预测，因为正误差抵消了负误差。</p><p id="e9b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上，很容易理解为什么<strong class="kx ir">预测误差没有意义。因为这意味着试图预测定义为空的东西</strong>。<strong class="kx ir"> *** </strong></p><p id="6fba" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是我们不是说过DLE正是建立在预测误差的基础上吗？那么，有什么条件呢？</p><blockquote class="on oo op"><p id="8593" class="kv kw oq kx b ky kz jr la lb lc ju ld or lf lg lh os lj lk ll ot ln lo lp lq ij bi translated"><strong class="kx ir"> *** </strong>我们假设模型预测的是后验分布的均值。情况并非总是如此。例如，如果您使用不同于MSE的损失函数，您的误差可能不会以0为中心。然而，在这种情况下，预测带符号的误差仍然是没有意义的:这就像“纠正”您在一开始选择的损失函数一样。</p></blockquote><h1 id="ea03" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">…但是预测绝对误差很有意义。</h1><p id="e011" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">重点是<strong class="kx ir"> DLE不预测符号误差，而是预测绝对误差</strong>！</p><p id="d752" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这似乎是一个很小的区别，但实际上，这是一个完全不同的故事。事实上，与带符号的错误相反:</p><blockquote class="mb"><p id="c98e" class="mc md iq bd me mf mg mh mi mj mk lq dk translated">绝对误差是我们的点预测的不确定性的度量。</p></blockquote><p id="41e5" class="pw-post-body-paragraph kv kw iq kx b ky ml jr la lb mm ju ld le mn lg lh li mo lk ll lm mp lo lp lq ij bi translated">有了后验分布，我们可以计算绝对误差:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="2a1a" class="og mr iq oc b gy oh oi l oj ok">absolute_error_distribution = np.abs(point_prediction - posterior_distribution)</span></pre><p id="e1a0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们取平均值，我们得到平均绝对误差:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="7984" class="og mr iq oc b gy oh oi l oj ok">mean_absolute_error = np.mean(absolute_error_distribution)</span></pre><p id="50ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于我们模拟的分布，平均绝对误差约为10，000美元。这意味着，平均而言，实际收益与我们的模型给出的点预测相差10，000美元。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/ebcdc36ceb708c89ee2cb29225e77bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qXBIYD56Ml-87Fzws7udIg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">点预测和平均绝对误差。[图片由作者提供]</p></figure><p id="3405" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总而言之:</p><ul class=""><li id="d903" class="nn no iq kx b ky kz lb lc le np li nq lm nr lq ns nt nu nv bi translated">试图预测有符号的错误是没有意义的，因为我们试图纠正一个我们认为是最好的模型。</li><li id="c74d" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">试图预测绝对(平方)误差很有意义，因为我们试图量化与预测相关的不确定性。</li></ul><p id="e294" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，我们的模型的最终性能直接与不确定性相关联。很直观。<strong class="kx ir">不确定性越多，表现越差。不确定性越少，性能越好</strong>。</p><h1 id="c5a1" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">描述DLE算法</h1><p id="fc4e" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">在实践中，DLE训练了一个新模型，该模型学习与原始模型的预测相关的不确定性。事实上:</p><ul class=""><li id="a6e2" class="nn no iq kx b ky kz lb lc le np li nq lm nr lq ns nt nu nv bi translated">原始模型进行点预测(一如既往)。</li><li id="678c" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">DLE引入的模型预测主模型产生的绝对(或平方)误差。NannyML称之为“保姆模型”(原因很明显)。</li></ul><p id="e166" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以将整个过程总结为4个步骤。</p><p id="5aa9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">像往常一样，一切都从在训练数据集上训练模型开始。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/0d47a006d01e45669c413f6c07c17a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q-lK6-QlB_3AR5iseqzotA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第一步。该模型在训练数据集上学习。[图片由作者提供]</p></figure><p id="429a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，该模型用于对测试数据集进行预测。一旦我们有了预测，我们也可以计算绝对误差，作为目标和预测之间的绝对差:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/0fbfdf1320434268652b5e156e4b7c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bwwxc95cZAFPsZ48a5IGDg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第二步。该模型对测试数据进行预测，并计算绝对误差。[图片由作者提供]</p></figure><p id="bcba" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此时，第二个模型——称为保姆模型——使用原始特征和第一个模型做出的预测来学习关于绝对误差的模式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/e467f1d4fb666bd45c14a5a9c9279205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qlHpcVAX5iowv-b8nnBMMA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第三步。该模型学习预测测试数据的绝对误差。[图片由作者提供]</p></figure><p id="c9d3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后，当在生产中使用模型进行预测<em class="oq">、</em>时，我们可以使用第一个模型来预测目标变量，使用保姆模型来预测绝对误差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ov"><img src="../Images/77e31221aa2532429530d8e076cb1246.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3QeJdy4Cb38krAwlDMVJNA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第四步。一旦生产数据可用，主模型就对目标进行预测，而保姆模型对绝对误差进行预测。[图片由作者提供]</p></figure><p id="d35e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总而言之，这是整个流程的视图(为了清晰起见，没有区分培训、测试和生产数据集):</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/84c9c5974ae75b73d262aebd9124620d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUI2oXCn9XMxV6lyUvrj3g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">直接损失估算的所有步骤。为了简单起见，这里没有区分训练、测试和生产数据集。[图片由作者提供]</p></figure><h1 id="7126" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">在真实数据集上预测性能</h1><p id="51c3" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">让我们看看DLE是否在真实数据集上工作。</p><p id="1619" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将使用<a class="ae ma" href="https://archive.ics.uci.edu/ml/datasets/superconductivty+data" rel="noopener ugc nofollow" target="_blank">超导体数据集</a>，一个来自UCI的开源数据集。该数据集由21，263种材料组成，记录了关于原子质量、原子半径、密度等的81个特征。目标是预测临界温度。</p><p id="2ee1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将把数据集分为培训数据集、测试数据集和生产数据集。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="1c80" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># load data and split into train, test, prod</strong></span><span id="f170" class="og mr iq oc b gy ol oi l oj ok">import pandas as pd</span><span id="5481" class="og mr iq oc b gy ol oi l oj ok">df = pd.read_csv(‘/kaggle/input/superconductor-dataset/train.csv’).sample(frac=1, random_state=123)</span><span id="6ffc" class="og mr iq oc b gy ol oi l oj ok">df_train = df.iloc[:int(len(df)/5)]<br/>df_test = df.iloc[int(len(df)/5):int(len(df)/5*2)]<br/>df_prod = df.iloc[int(len(df)/5*2):]</span><span id="6d36" class="og mr iq oc b gy ol oi l oj ok">X_train = df_train.drop("critical_temp", axis=1)<br/>X_test = df_test.drop("critical_temp", axis=1)<br/>X_prod = df_prod.drop("critical_temp", axis=1)<br/> <br/>y_train = df_train["critical_temp"]<br/>y_test = df_test["critical_temp"]<br/>y_prod = df_prod["critical_temp"]</span></pre><p id="cf80" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此时，我们已经准备好训练我们的模型:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="5557" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># train model</strong></span><span id="517a" class="og mr iq oc b gy ol oi l oj ok">from lightgbm import LGBMRegressor</span><span id="a4e0" class="og mr iq oc b gy ol oi l oj ok">model = LGBMRegressor().fit(X=X_train,y=y_train)</span></pre><p id="3661" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后，我们使用测试数据集来计算模型产生的误差。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="d7bf" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># compute observed errors made by the model on test data</strong></span><span id="652b" class="og mr iq oc b gy ol oi l oj ok">pred_test = pd.Series(model.predict(X_test),<br/>  index=X_test.index).clip(0)</span><span id="7bc3" class="og mr iq oc b gy ol oi l oj ok">error_test = pred_test — y_test</span></pre><p id="c43d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一旦我们有了错误，我们就可以训练保姆模型。请注意，nanny模型使用所有原始特征加上第一个模型所做的预测作为特征。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="e9e2" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># train model to predict the absolute error</strong></span><span id="770d" class="og mr iq oc b gy ol oi l oj ok">model_abs_error = LGBMRegressor().fit(<br/>  X=pd.concat([X_test, pred_test], axis=1),<br/>  y=error_test.abs()<br/>)</span></pre><p id="2523" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在生产数据集上，我们首先使用主模型来获得预测。然后，我们使用保姆模型来获得预测的绝对误差。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="9216" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># predict the absolute errors on production data</strong></span><span id="bd64" class="og mr iq oc b gy ol oi l oj ok">pred_prod = pd.Series(model.predict(X_prod), index=X_prod.index).clip(0)</span><span id="2abf" class="og mr iq oc b gy ol oi l oj ok">pred_abs_error_prod = pd.Series(model_abs_error.predict(pd.concat([X_prod, pred_prod], axis=1)), index=X_prod.index)</span></pre><p id="20d7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上，我们有了对每一次观察的绝对误差的预测。因此，我们最终可以预测生产数据集的平均绝对误差(MAE ),这是我们最初的目标。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="31ea" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># predict MAE on production set</strong></span><span id="bf78" class="og mr iq oc b gy ol oi l oj ok">pred_mae_prod = np.mean(pred_abs_error_prod)</span></pre><h1 id="cfba" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">针对数据漂移测试DLE</h1><p id="1304" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">DLE的全部目的是在我们没有基本事实时预测我们模型的平均误差(或均方误差)。这在现实场景中非常有用，因为我们想提前知道模型的性能是否有所下降。</p><p id="b50a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了模拟这个场景，我们将把生产集分成十个部分。<strong class="kx ir">为了重现数据漂移，我们不会随机分割褶皱，而是会根据模型</strong>做出的预测进行分割。通过这种方式，我们确保折叠彼此之间有足够的差异，并且跨文件夹的性能有合理的差异。</p><p id="e415" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，让我们将每个文件夹上的实际MAE与作为保姆模型预测的绝对误差的平均值而获得的MAE进行比较。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ox"><img src="../Images/29454ca64298544477e315f54b393d21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K454plsK8Tr-xjLt7UT8ow.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在测试褶皱上观测MAE和预测MAE的比较。[图片由作者提供]</p></figure><p id="b1c1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果令人印象深刻。通过保姆模型预测的MAE实际上与实际的MAE相同。</p><p id="8d77" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们试试MSE:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oy"><img src="../Images/7ba04dda8bd5858da990c77c8640270e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G_Cdel9_iHx1o3Rflh9Wow.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试褶皱上观测MSE和预测MSE的比较。[图片由作者提供]</p></figure><p id="defe" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样在这种情况下，结果是惊人的好。</p><h1 id="dc8a" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">如果我们试图估计误差(而不是绝对误差)，会发生什么？</h1><p id="5335" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">我们已经看到，从理论的角度来看，试图估计符号误差是没有意义的。但是既然数据科学家更喜欢实践而不是理论，我们还是试着去做吧。</p><p id="ad70" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">换句话说，这意味着重复上面的过程，但是不是在测试绝对错误上训练保姆模型，而是在测试符号错误上训练它。</p><p id="01fc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在Python中，这意味着以下内容:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="d0a1" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># train model to predict the error (which makes no sense)</strong></span><span id="c47a" class="og mr iq oc b gy ol oi l oj ok">model_error = LGBMRegressor().fit(<br/>  X=pd.concat([X_test, pred_test], axis=1),<br/>  y=error_test<br/>)</span></pre><p id="1fd3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们能够预测测试集中每个观察值的有符号误差。如果我们取这些预测，取它们的绝对值，然后平均它们，这是对MAE的新估计。</p><p id="bcd0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们看看它在上述相同的测试折叠中表现如何:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oz"><img src="../Images/dbb02e4dc627f01be9b89f1dd6b92f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-V4yIDr-b8sPON3USvBqJg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在测试褶皱上观测MAE和预测MAE的比较。这里预测的MAE是从一个基于符号误差而不是绝对误差训练的保姆模型中获得的。[图片由作者提供]</p></figure><p id="221b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">很明显，使用这种新策略，预测的MAE系统地低估了实际的MAE。</p><p id="f8c6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们尝试为MSE这样做，情况会更糟:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pa"><img src="../Images/ba774f5f7d997ef040c2ac372253d558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ykjCv5_o3Q9ZzRW8jiY-2Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试褶皱上观测MSE和预测MSE的比较。这里预测的MSE是从一个基于符号误差而不是平方误差训练的保姆模型中获得的。[图片由作者提供]</p></figure><p id="69f5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这只是进一步证明，预测绝对误差与预测带符号误差然后取绝对误差完全不同。</p><h1 id="a2b8" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">如果你不想重新发明轮子…</h1><p id="bdc1" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">在本文中，我们从头实现了DLE，以展示它是如何工作的。然而，在现实生活中，使用维护良好的库往往更好。</p><p id="c807" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">所以，您可能想直接使用NannyML，它有几个本机功能，比如为您拟合超参数。</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="92d8" class="og mr iq oc b gy oh oi l oj ok"><strong class="oc ir"># use DLE directly with NannyML</strong></span><span id="2c0c" class="og mr iq oc b gy ol oi l oj ok">import nannyml as nml</span><span id="2d49" class="og mr iq oc b gy ol oi l oj ok">estimator = nml.DLE(<br/>    feature_column_names=features,<br/>    y_pred='y_pred',<br/>    y_true='critical_temp',<br/>    metrics=['mae', 'mse'],<br/>    chunk_number=10,<br/>    tune_hyperparameters=False<br/>)</span><span id="3c5f" class="og mr iq oc b gy ol oi l oj ok">estimator.fit(df_test)<br/>results = estimator.estimate(df_prod_drifted)</span></pre><p id="5214" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">此外，您可以通过一行代码轻松获得关于模型性能的精彩图表:</p><pre class="kg kh ki kj gt ob oc od oe aw of bi"><span id="57ab" class="og mr iq oc b gy oh oi l oj ok">results.plot(metric=’mae’)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pb"><img src="../Images/528c0ba26ebbab0b7e18ffa650834a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8TwTa5ZlZh61aJiOOdG-yw.png"/></div></div></figure><h1 id="d075" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated"><strong class="ak">当它不起作用时</strong></h1><p id="04e8" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">当使用DLE估计性能时，有一些假设你应该注意。事实上，如果这些假设中的一些被违反，DLE估计的性能可能不再可靠。这些是假设:</p><ul class=""><li id="7046" class="nn no iq kx b ky kz lb lc le np li nq lm nr lq ns nt nu nv bi translated">没有<strong class="kx ir">概念漂移</strong>。如果特征和目标变量之间的关系以不可预见的方式改变，你试图预测的误差也会改变，因此保姆模型可能会失败。</li><li id="e003" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated">在输入空间中，没有<strong class="kx ir">协变移动到以前看不见的区域</strong>。主模型和保姆模型都学习原始特性。如果特征漂移到在训练/验证阶段看不到的值，模型可能做出不正确的猜测。</li><li id="2225" class="nn no iq kx b ky nw lb nx le ny li nz lm oa lq ns nt nu nv bi translated"><strong class="kx ir">数据的样本足够大</strong>。当然，训练和验证数据集都需要足够大，以使两个模型都足够健壮。</li></ul><h1 id="526c" class="mq mr iq bd ms mt mu mv mw mx my mz na jw nb jx nc jz nd ka ne kc nf kd ng nh bi translated">总结</h1><p id="a891" class="pw-post-body-paragraph kv kw iq kx b ky ni jr la lb nj ju ld le nk lg lh li nl lk ll lm nm lo lp lq ij bi translated">在本文中，我们已经看到了<strong class="kx ir">当基础事实不可用</strong>时，如何可靠地预测回归模型的预期性能(特别是MAE和MSE)。</p><p id="04ae" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种算法被称为“直接损失估计”(DLE)，由NannyML (一个专注于部署后数据科学的开源库)在本文<a class="ae ma" href="https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html#direct-loss-estimation-dle" rel="noopener ugc nofollow" target="_blank">中提出。</a></p><p id="063f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> DLE基于直接预测每个单次观测的绝对(或平方)误差的直觉</strong>。我们已经在超导体数据集上进行了测试，并获得了出色的结果。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pc"><img src="../Images/39b4665b574becfafa35bd5d0980d34c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RROmBmKuJon0FGjQ.png"/></div></div></figure><p id="3164" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可以在Github资源库中找到本文使用的所有代码。</p><p id="ceff" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="oq">感谢您的阅读！我希望你喜欢这篇文章。如果你愿意，</em> <a class="ae ma" href="https://www.linkedin.com/in/samuelemazzanti/" rel="noopener ugc nofollow" target="_blank"> <em class="oq">在Linkedin上加我</em> </a> <em class="oq">！</em></p></div></div>    
</body>
</html>