<html>
<head>
<title>Why SMOTE is not necessarily the answer to your imbalanced dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么SMOTE不一定是不平衡数据集的答案</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-smote-is-not-necessarily-the-answer-to-your-imbalanced-dataset-ef19881da57a#2022-06-13">https://towardsdatascience.com/why-smote-is-not-necessarily-the-answer-to-your-imbalanced-dataset-ef19881da57a#2022-06-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e16d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">人人都爱SMOTE，但它真的是银弹吗？</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/90885d9907be1b1227d4d9a72d3a8d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7LC88bliOuCiBBo4Sm_3qQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">埃伯哈德·🖐·格罗斯加斯泰格在<a class="ae ky" href="https://unsplash.com/s/photos/smoke?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="0638" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当不平衡分类的话题出现时，许多人称赞SMOTE是首选方法。事实上，流行的算法在社区的进化选择过程中幸存了下来。然而，我们仍然不应该盲目地对我们的问题提出现成的解决方案。为了证明这一点，我们可以构造让SMOTE惨败的实际玩具例子。在此之前，让我们简单回顾一下不平衡问题和算法本身。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="9f71" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">SMOTE打算如何解决不平衡分类的问题</h1><p id="f6b1" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">社区数据科学的大部分对不平衡数据的叙述如下:</p><p id="3a0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果数据集中的一个或多个类严重不足，分类算法在训练后通常无法识别这些类。为了解决这个问题，我们使用一些重采样技术来创建一个新的数据集，其中所有的类大致相等。SMOTE算法是迄今为止经受住时间考验的重采样技术之一。</p><p id="8c54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，SMOTE通过在少数群体的域间隙中随机创建合成观测值来对代表性不足的类进行过采样。考虑一个1D的例子，其中你的少数类实例都位于区间<code class="fe mz na nb nc b">[0,1]</code>中。SMOTE现在通过随机插入两个现有的数据点，在此间隔内创建更多的少数实例。</p><p id="4b43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里不再赘述，但如果想了解更多，推荐阅读<a class="ae ky" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>。值得一提的是，如果输入数据不连续，原始的SMOTE算法将不起作用。考虑一次性编码数据——随机插值步骤将创建非二进制合成数据，这显然是错误的。幸运的是，<a class="ae ky" href="https://imbalanced-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">不平衡学习</a>库包含了一个适合这种情况的<a class="ae ky" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html" rel="noopener ugc nofollow" target="_blank">选择</a>。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="b2f0" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">创建一个简单的例子，事情在SMOTE中上升</h1><p id="652d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">我们可以很容易地构造一个SMOTE有用的反例。考虑以下数据生成过程:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/fcc80d36579537b0f1b258aa3f1512c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*JowOaxgNTORL9OkPzj9-Ow.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><h2 id="a14a" class="ne md it bd me nf ng dn mi nh ni dp mm li nj nk mo lm nl nm mq lq nn no ms np bi translated">原始数据——一切看起来都很好</h2><p id="3d2e" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">逻辑回归模型应该很容易学习条件类分布。由于输入变量<code class="fe mz na nb nc b">X</code>的变化，我们可以预期类别<code class="fe mz na nb nc b">y=0</code>的代表性不足。让我们用Python绘制这个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/decf930743191711fe9f0592dccd50ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*4hyIbJcLSkKCkI93.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">一个简单的例子，其中少数类仅占总数据集的4.5%。由于足够大的训练集，逻辑回归模型可以容易地学习条件类概率。(图片由作者提供)</em></p></figure><p id="83a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们所见，逻辑回归模型能够很好地学习潜在的类别概率。</p><h2 id="f96f" class="ne md it bd me nf ng dn mi nh ni dp mm li nj nk mo lm nl nm mq lq nn no ms np bi translated">过采样让事情变得更糟</h2><p id="058d" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">现在，假设您不能像我们在这个例子中那样很好地检查数据。您可能只看到您的数据集不平衡，并迅速开始实施SMOTE解决方案。</p><p id="a1af" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们为上面的例子绘制这种方法的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/36a6c91b5838cbaee625c325d5f03523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/0*gHqQYDLZLYWEyUYi.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">使用SMOTE后的相同型号。逻辑回归模型预测的类别概率现在比</em>之前差得多。(图片由作者提供)</p></figure><p id="cfb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在应用SMOTE之后，我们的模型的性能显著下降。这很糟糕，因为SMOTE是处理不平衡数据的最佳解决方案。</p><h2 id="51b1" class="ne md it bd me nf ng dn mi nh ni dp mm li nj nk mo lm nl nm mq lq nn no ms np bi translated">哪里出了问题？</h2><p id="68ef" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">上述示例的结构很容易向我们指出潜在的问题:</p><p id="b7e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> SMOTE隐含地假设</strong> <strong class="lb iu">类分布在少数类实例周围的一些邻域中足够均匀。</strong></p><p id="1eeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">简单地说:如果数据生成过程在你的输入域中的类之间频繁地“跳跃”,你会有一段不好的时间。</p><p id="4ffd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以用另一个情节来验证这一说法:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/c3c61bd30c892aa53b4098c2eef6a595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4OpRR3RmogjBjwtO.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">根据数据生成流程，</em>少数民族类出现为<code class="fe mz na nb nc b"><em class="nr">abs(X)&gt;3</em></code>。然而，使用SMOTE破坏了这个简单的模式。(图片由作者提供)</p></figure><p id="900b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这个例子中，在每个“少数面元”中出现少于五个数据点。由于SMOTE(默认设置)在每个少数点的五个最近邻点之间进行插值，因此该算法将合并来自远处聚类的样本。这显然打破了这个玩具例子中的模式。</p><p id="5c71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一旦少数聚类大于knn步中的邻居数量，情况又变得合理了:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/03b33870ad6e295bc4c15cacb93398d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dn2fPGi8X1qJqX4T.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">一旦少数聚类包含足够多的数据点，SMOTE将再次按预期工作。(图片由作者提供)</em></p></figure></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="ca02" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">是不是总的来说注定要失败？</h1><p id="737b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">像往常一样，我们不应该根据一个简单的例子就得出算法有用的结论。与其他方法一样，SMOTE的有用性在很大程度上取决于手头的问题。毕竟原始论文是2002年的，所以算法到目前为止绝对是经得起时间考验的。</p><p id="4814" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，您应该始终记住，每个数据科学问题都是不同的，即使是最受称赞的算法也可能无法完成您的任务。另一方面，<a class="ae ky" href="https://arxiv.org/pdf/2201.08528.pdf" rel="noopener ugc nofollow" target="_blank">这篇文章</a>提供了一些有用的经验法则，告诉你什么时候应该使用SMOTE，什么时候不应该。</p><p id="5a1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">另一个例子，不幸的是，我在这一点上只有经验证据，是硬类边界的可区分分类器。SMOTEed数据似乎“硬化”并改善了另一个玩具分类问题的逻辑回归模型的类别边界:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/48b3a0a6c3f297681edba91e374ce873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KrXZalUAS96UuG3I.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="nr">无(左)和有(右)SMOTE应用的Logistic回归。应用SMOTE会使模型的硬类边界(橙色线，通过舍入类概率获得)非常接近真实的类边界(蓝色线)(图片由作者提供)</em></p></figure><p id="bbcf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这表明SMOTE可能对不平衡图像分类特别有用。对于图像数据，我们通常可以期待低噪声。例如，一个明确的狗的图像实际上是一只猫的可能性相当低。此外，除了一些潜在的边界情况和种族，狗和猫很容易区分他们的外表。如前所述，这意味着相当严格的阶级界限。</p><p id="3cae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于表格数据，我们应该预料到标签噪声会更加普遍。考虑臭名昭著的信用卡欺诈检测问题，欺诈交易通常占少数类别。虽然偏远国家异常高的提款率更有可能是欺诈性的，但仍然有相当高的几率是正常的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="3b1d" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">SMOTE不管用怎么办？</h1><p id="bd6b" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">总结以上几节— SMOTE可以工作，但不能保证。如果SMOTE让您失望，并且您已经验证了您的代码本身是正确的，我会推荐以下步骤:</p><ol class=""><li id="3774" class="nt nu it lb b lc ld lf lg li nv lm nw lq nx lu ny nz oa ob bi translated"><strong class="lb iu">网格搜索尽可能多的SMOTE超参数</strong> —如果你有足够的可用资源和数据，你应该尝试彻底搜索最佳的SMOTE超参数，如果你还没有这样做的话。</li><li id="59e1" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">尝试另一种用于不平衡数据的重采样算法</strong>—Python中的不平衡学习包提供了更多的重采样方法。尝试他们的又一轮超参数优化。</li><li id="0038" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">为你的分类器</strong>调整决策界限——这个有点棘手，只用几句话来解释。我可能会在以后的文章中更详细地解释这一点。现在我推荐<a class="ae ky" href="https://stats.stackexchange.com/questions/405041/philosophical-question-on-logistic-regression-why-isnt-the-optimal-threshold-v/405049#405049" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae ky" href="https://www.fharrell.com/post/classification/" rel="noopener ugc nofollow" target="_blank">这个</a>来解释一下。</li><li id="8f36" class="nt nu it lb b lc oc lf od li oe lm of lq og lu ny nz oa ob bi translated"><strong class="lb iu">深入挖掘不平衡分类的研究</strong> —一个快速的<a class="ae ky" href="https://scholar.google.com/scholar?hl=de&amp;as_sdt=0%2C5&amp;q=imbalanced+classification+resampling&amp;btnG=&amp;oq=im" rel="noopener ugc nofollow" target="_blank">谷歌学术研究</a>给你大约25，000篇关于不平衡分类问题重采样的文章。你很有可能找到适合你手头问题的东西。</li></ol></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="53b6" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">结论</h1><p id="9b8c" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated">希望这篇简短的文章能够说服你不要盲目地跳上数据科学的宣传列车。虽然SMOTE和重采样在工具包中肯定有它们的位置，但它们并不是神奇的银弹。</p><p id="b4a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，“SMOTE”和“re-sampling”甚至是求职面试中不平衡数据的预期标准答案。我个人认为这是很有问题的做法。实际上，这种做法进一步传播了关于SMOTE普遍适用性的错误观念。希望这篇文章能说服你。</p><p id="dc28" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，这也是另一个例子，说明了为什么对算法的深入理解是有用的，并且有助于调试。毕竟，<a class="ae ky" href="https://sarem-seitz.com/blog/you-do-need-math-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">你确实需要(至少一些)机器学习的数学知识</a>🙂</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><h1 id="6fed" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated">参考</h1><p id="71a9" class="pw-post-body-paragraph kz la it lb b lc mu ju le lf mv jx lh li mw lk ll lm mx lo lp lq my ls lt lu im bi translated"><strong class="lb iu">【1】</strong><em class="oh">Chawla，Nitesh V .等SMOTE:合成少数过采样技术。人工智能研究杂志2002年第16期</em>。</p><p id="470e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">【2】</strong><em class="oh">Elor，Yotam哈达尔·阿韦尔布赫-埃洛尔。打，还是不打？。arXiv预印本arXiv:2201.08528，2022。</em></p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="93a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oh">原载于2022年6月13日https://sarem-seitz.com</em><em class="oh">的</em> <a class="ae ky" href="https://sarem-seitz.com/blog/why-smote-is-not-necessarily-the-answer-to-your-imbalanced-dataset/" rel="noopener ugc nofollow" target="_blank"> <em class="oh">。</em></a></p></div></div>    
</body>
</html>