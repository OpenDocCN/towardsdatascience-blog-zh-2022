<html>
<head>
<title>data2vec and the future of multimodal learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">data2vec和多模态学习的未来</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data2vec-and-the-future-of-multimodal-learning-f33f9c781f48#2022-04-27">https://towardsdatascience.com/data2vec-and-the-future-of-multimodal-learning-f33f9c781f48#2022-04-27</a></blockquote><div><div class="fc ig ih ii ij ik"/><div class="il im in io ip"><h2 id="84f8" class="iq ir is bd b dl it iu iv iw ix iy dk iz translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/tds-podcast" rel="noopener" target="_blank">播客</a></h2><div class=""/><div class=""><h2 id="0740" class="pw-subtitle-paragraph jy jb is bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">Alexei Baevski谈适用于文本、图像、语音、视频等的人工智能架构</h2></div><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="kv kw l"/></div><p class="kx ky gj gh gi kz la bd b be z dk translated"><a class="ae lb" href="https://podcasts.apple.com/ca/podcast/towards-data-science/id1470952338?mt=2" rel="noopener ugc nofollow" target="_blank">苹果</a> | <a class="ae lb" href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9hbmNob3IuZm0vcy8zNmI0ODQ0L3BvZGNhc3QvcnNz" rel="noopener ugc nofollow" target="_blank">谷歌</a> | <a class="ae lb" href="https://open.spotify.com/show/63diy2DtpHzQfeNVxAPZgU" rel="noopener ugc nofollow" target="_blank"> SPOTIFY </a> | <a class="ae lb" href="https://anchor.fm/towardsdatascience" rel="noopener ugc nofollow" target="_blank">其他</a></p></figure><p id="a1ba" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated"><em class="ly">编者按:TDS播客由杰雷米·哈里斯主持，他是人工智能安全初创公司墨丘利的联合创始人。每周，Jeremie都会与该领域前沿的研究人员和商业领袖聊天，以解开围绕数据科学、机器学习和人工智能的最紧迫问题。</em></p></div><div class="ab cl lz ma hw mb" role="separator"><span class="mc bw bk md me mf"/><span class="mc bw bk md me mf"/><span class="mc bw bk md me"/></div><div class="il im in io ip"><p id="7060" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">如果data2vec这个名字听起来很熟悉，那可能是因为它在大约两个月前问世时在社交媒体甚至传统媒体上引起了不小的轰动。这是一个重要的条目，现在越来越多的策略专注于创建单独的机器学习架构，处理许多不同的数据类型，如文本、图像和语音。</p><p id="48da" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">大多数自我监督学习技术涉及让模型获取一些输入数据(例如，一幅图像或一段文本)并屏蔽掉这些输入的某些成分(例如，通过遮蔽像素或单词)，以便让模型预测那些被屏蔽掉的成分。</p><p id="0613" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">“填空”任务很难迫使人工智能学习关于其数据的事实，这些事实可以很好地概括，但这也意味着训练模型来执行根据输入数据类型而有很大不同的任务。例如，填充涂黑的像素与填充句子中的空白非常不同。</p><p id="dd74" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">那么，如果有一种方法可以提出一个我们可以用来在任何类型的数据上训练机器学习模型的任务呢？这就是data2vec的用武之地。</p><p id="3d65" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">在这一集的播客中，我和data2vec的创造者之一Meta AI的研究员Alexei Baevski在一起。除了data2vec，Alexei还参与了相当多的文本和语音模型的开创性工作，包括脸书广泛宣传的无监督语音模型<a class="ae lb" href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/" rel="noopener ugc nofollow" target="_blank"> wav2vec </a>。Alexei和我一起讨论了data2vec的工作原理和该研究方向的下一步，以及多模态学习的未来。</p><p id="c794" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">以下是我在对话中最喜欢的一些观点:</p><ul class=""><li id="a7a6" class="mg mh is le b lf lg li lj ll mi lp mj lt mk lx ml mm mn mo bi translated">自回归模型通常被训练来填充部分涂黑的句子或图像。但这种策略有一个固有的限制:因为填充空白对于文本和图像来说是一个非常不同的任务，所以使用这些任务来训练一个可以同时处理文本和图像的单一架构要困难得多。为了解决这个问题，data2vec被训练成不是在图像或句子中填空，而是在一个教师网络生成的图像和文本数据的潜在表示中填空。这创建了一个无论输入数据类型如何都可以使用的通用任务。</li><li id="b177" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">正如Alexei指出的，data2vec仍然使用专门的预处理技术，根据输入数据类型的不同而不同。因此，它不完全是一个通用的架构，它需要特定目的的输入信息。然而，阿列克谢认为这可能会改变:谷歌人工智能最近发表了他们在一个名为感知者的架构上所做的工作，该架构对所有输入数据类型使用单一的预处理技术。通过将感知者的输入不可知预处理与data2vec的输入不可知训练任务相结合，他看到了新一波鲁棒多模态模型的巨大潜力。</li><li id="8a12" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">越来越多的多模态模型带来的挑战之一是互操作性:当深度网络只处理图像数据时，很难理解深度网络如何处理图像数据，但如果处理视觉的同一网络也处理文本和音频数据会怎么样？我们可能需要新一代的可解释性技术来跟上多模态系统的发展。</li><li id="283c" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">阿列克谢和他的团队没有尝试过，但阿列克谢很好奇的一个问题是:data2vec为单词“dog”生成的潜在表征看起来与它为狗图像提出的潜在表征相似或相关吗？天真地说，这似乎会告诉我们一些关于系统学习概念的健壮性的事情。</li><li id="d855" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">人们常说，机器学习——尤其是规模化人工智能——正在成为软件工程。阿列克谢有软件工程背景，虽然他认为这个想法有一些优点，但这并没有转化为软件工程师在人工智能研究中的明显优势。</li></ul><p id="9e7e" class="pw-post-body-paragraph lc ld is le b lf lg kc lh li lj kf lk ll lm ln lo lp lq lr ls lt lu lv lw lx il bi translated">你可以<a class="ae lb" href="https://twitter.com/ZloiAlexei" rel="noopener ugc nofollow" target="_blank">在Twitter上关注阿列克谢</a>，或者<a class="ae lb" href="https://twitter.com/jeremiecharris" rel="noopener ugc nofollow" target="_blank">我在这里</a>。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/202c1f5a4ae47604c746dbd6ac3f798a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pLcGqvGcysJ4S5eoZSpp9w.png"/></div></div></figure><h2 id="fd8b" class="nb nc is bd nd ne nf dn ng nh ni dp nj ll nk nl nm lp nn no np lt nq nr ns iy bi translated">章节:</h2><ul class=""><li id="de3f" class="mg mh is le b lf nt li nu ll nv lp nw lt nx lx ml mm mn mo bi translated">0:00介绍</li><li id="b91f" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">2点阿列克谢的背景</li><li id="80b5" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">10:00软件工程知识</li><li id="2651" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">14:10 data 2 vec在进展中的作用</li><li id="9752" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">30:00学生和教师之间的时间差</li><li id="bcff" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">38:30丧失口译能力</li><li id="4d98" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">41:45更强能力的影响</li><li id="4899" class="mg mh is le b lf mp li mq ll mr lp ms lt mt lx ml mm mn mo bi translated">49:15总结</li></ul></div></div>    
</body>
</html>