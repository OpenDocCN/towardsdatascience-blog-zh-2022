<html>
<head>
<title>Linear Regression (Part-3)— The underlying Assumptions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归(第三部分)——基本假设</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-part-3-the-underlying-assumptions-82a66d5d5dd5#2022-02-22">https://towardsdatascience.com/linear-regression-part-3-the-underlying-assumptions-82a66d5d5dd5#2022-02-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2441" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">理解最流行的数据科学算法所基于的支柱(前提)的来龙去脉</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3e4015dd86d13b14dea73080a9c918f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TbuTIzSob9t-ySXm"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@_staticvoid?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Lucas Santos </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="943a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们知道，当我们试图通过在一组<strong class="lb iu">独立</strong>变量(称为预测器)之间建立线性关系来预测一个变量(称为<strong class="lb iu">因变量</strong>)的值时，需要<strong class="lb iu">线性回归</strong>。在这篇文章中，我想谈谈线性回归模型背后的关键假设。然而，如果你在想<strong class="lb iu">‘为什么要回归？’</strong>或<strong class="lb iu">‘线性回归背后的科学/数学基础是什么？请查看下面的帖子。</strong></p><p id="36fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">请看下面的链接，链接到一篇关于为什么需要回归的早期文章。</em></p><div class="lw lx gp gr ly lz"><a rel="noopener follow" target="_blank" href="/linear-regression-the-basic-building-blocks-part-1-abd605c39f"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">线性回归——基本构件！(第一部分)</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">介绍最广泛使用的数据科学技术之一的需求和基本概念。</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="mj l mk ml mm mi mn ks lz"/></div></div></a></div><p id="10b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="lv">..一个解释线性回归背后的科学/数学。</em></p><div class="lw lx gp gr ly lz"><a rel="noopener follow" target="_blank" href="/linear-regression-the-behind-the-scenes-data-science-part-2-efdb9bf5437c"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd iu gy z fp me fr fs mf fu fw is bi translated">线性回归—幕后数据科学！(第二部分)</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">深入探究最广泛使用的数据科学之一背后的数据科学/数学…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">towardsdatascience.com</p></div></div><div class="mi l"><div class="mo l mk ml mm mi mn ks lz"/></div></div></a></div><p id="002b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">任何模型或任何程序都带有一堆<strong class="lb iu">假设</strong>，这些是<strong class="lb iu">必须为真</strong>的条件，模型才能被视为<strong class="lb iu">成功匹配</strong>。<em class="lv">将这些视为“如果a，b，c为真，则x，y，z成立”一类的陈述，当其为真时，意味着我们可以应用这种统计技术(即拟合我们的线性回归模型)。</em></p><p id="6f2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你读过关于线性回归的书籍/文章，你可能会发现不同数量的假设——这是因为有些假设非常基本，并且通常文本假设你已经按照设计对它们进行了分类。然而，下面我列出了所有的假设。<br/> <em class="lv">请注意，假设1至6是关键假设，然后7–10是隐含假设或衍生假设。</em></p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="0930" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">假设#1 —参数的线性</h1><h2 id="a160" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">什么意思？</em> </strong></h2><p id="a3f0" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">要应用线性模型，观测数据中需要有实际的线性。也就是说，<strong class="lb iu">因变量和自变量必须有一个线性关系</strong> <em class="lv">(相对于像二次关系这样的非线性关系)</em>以便我们在它们之间拟合一个线性模型。</p><blockquote class="og oh oi"><p id="0e1e" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">你知道吗？<br/> </em> </strong> <em class="it"> </em>这并不意味着总是Y和X需要线性相关；可以是Y与X平方相关，然后我们可以在Y和X平方之间(而不是Y和X之间)拟合一个线性模型。</p></blockquote><p id="9963" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">比如下图-1中；在场景-1中，Y和X不是线性相关的，但是存在某种关系。在操作X(通过查看X-cube的相同数据)之后，我们在场景2中看到Y和X-cube是线性相关的。因此，Y和X的变换(在这种情况下是X立方体)是线性相关的。<br/> →我们可以在Y和X-cube之间应用线性回归模型。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/f10ba14386ea5328164f6cd9e5f32431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3vdCbUSjOQeODtsM5qgzcQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片-1 |线性关系(图片由作者提供)</p></figure><blockquote class="og oh oi"><p id="c3df" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><em class="it">这个假设也可以理解为:‘</em><strong class="lb iu"><em class="it">参数的线性度</em></strong><em class="it">‘，</em>即<strong class="lb iu">对于一个解释变量</strong>的一个单位变化，在<strong class="lb iu">因变量</strong>的值中总有<strong class="lb iu">的一个常数变化</strong>。</p></blockquote><h2 id="9dbf" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">这个为什么重要？</em>T29】</strong></h2><p id="d43b" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">如果没有线性关系，那么建模和应用线性模型就没有意义。对！</p><h2 id="e2cf" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><p id="189d" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">我们可以通过<strong class="lb iu">将Y对所有解释变量作图来找出线性关系。</strong> <br/>请注意，如上所述，我们可能有X、X-square、X-cube、log(X)……X的任何变换作为解释变量，我们正在寻找因变量Y和解释变量<em class="lv">之间的线性关系(即模型中使用的X的变换与仅X的变换)。</em></p><h1 id="80de" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">假设# 2——观察的独立性</h1><h2 id="1976" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">什么意思？</em> </strong></h2><p id="b963" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这种假设指的是收集的<strong class="lb iu">数据点或观察值相互独立</strong>的事实，根据这些数据点或观察值创建回归模型。如果数据是以独立的方式收集的，那么在您的数据集中这应该是最常见的情况。</p><blockquote class="og oh oi"><p id="0afc" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">你知道吗？</em> </strong> <br/>为个人收集的购物行为数据通常是独立的，因为一个人的行为不会依赖于其他人。相反，时间序列数据往往会导致观察结果相互依赖，因为一个数据点与基于时间的前一个值相关。</p></blockquote><h2 id="02b3" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">为什么这个<strong class="ak"> <em class="oa">很重要？</em>T49】</strong></h2><p id="37bc" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">不独立通常意味着有一个潜在的模式；即<strong class="lb iu">观察值来自特定来源</strong> <em class="lv">(例如，时间序列数据——同一来源在不同时间点的观察值)。</em></p><p id="dd68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们的数据不独立时，我们看到:<br/> - X的观测值与自身相关<br/> - X和Y相互相关<em class="lv">(这是我们回归的前提)</em> <br/> - <em class="lv">依次暗示，</em> Y的观测值与自身相关</p><p id="11fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">→ <strong class="lb iu">在我们回归的数据中存在这些聚类或类</strong>，这种潜在模式或类间相关性确保<strong class="lb iu">来自相同类的多个观察值不会带来任何附加信息</strong> <em class="lv">(因为它们来自相同的源)</em>和<strong class="lb iu">模型的估计变得不太精确</strong>。<br/> <em class="lv">例如，考虑基于100个数据点估计学校中儿童的身高和体重之间的关系。你会看100个不同的孩子或者20个孩子的身高体重测量5次吗？</em></p><h2 id="a612" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><p id="f309" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这高度依赖于数据收集的方式。如果我们的数据单元彼此不相关，即每个单元的数据点独立于其他单元的数据值，那么可以安全地假设观察值的独立性。</p><h1 id="5c85" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">假设# 3-无多重共线性</h1><h2 id="005f" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">什么是多重共线性？</h2><p id="a69c" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">多重共线性是多重抑制模型中的现象，其中一个或多个独立变量彼此密切相关。也就是说，当<strong class="lb iu">一个或多个解释变量<strong class="lb iu">之间存在高度相关性</strong>时，多重共线性就存在。</strong></p><blockquote class="og oh oi"><p id="0b6d" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated">线性回归假设解释变量之间没有完美或精确的关系。</p></blockquote><h2 id="aaa1" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">为什么这很重要？</h2><p id="559c" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">当两个或多个自变量相关时，它们<strong class="lb iu">不会添加任何额外的信息来解释因变量</strong>，而是添加了噪声，因为太多的变量传达了相同的信息。在回归模型中出现多重共线性的情况下，由于两个预测值之间的高度相关性，模型无法<strong class="lb iu">了解两个变量对因变量的影响程度</strong> <em class="lv">(因为两个预测值传达相同的信息，即以相同的方式影响因变量)</em>。<br/>→这进一步导致<strong class="lb iu">系数估计值和模型给出的p值变得非常不可靠</strong>。随着多重共线性的严重程度增加，这些有问题的影响也会增加。</p><p id="c6ff" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于回归模型的关键目标之一是建立因变量和自变量之间的关系，多重共线性不会让这种情况发生，因为模型描述的<strong class="lb iu">关系(具有多重共线性)变得不可信</strong> <em class="lv">(因为多重共线性变量的β系数和p值不可靠)</em>。</p><blockquote class="og oh oi"><p id="8041" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">你知道吗？</em> </strong> <br/>多重共线性<strong class="lb iu">对模型如何拟合</strong>没有重大影响，即<strong class="lb iu"> R平方和预测因变量</strong>值在很大程度上<strong class="lb iu">不受影响</strong>。然而，自变量和因变量之间的关系显然是。</p></blockquote><h2 id="3d16" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><ul class=""><li id="4d2d" class="os ot it lb b lc ob lf oc li ou lm ov lq ow lu ox oy oz pa bi translated"><strong class="lb iu">相关矩阵:</strong> <br/>为模型中使用的n个预测值准备一个<strong class="lb iu">‘n×n’相关矩阵</strong>，这使我们了解了每个预测值之间的相关性。为了使多重共线性最小化，<strong class="lb iu">相关系数必须具有非常低的值</strong>。</li><li id="6bb6" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated"><strong class="lb iu">容差或方差膨胀因子(VIF): </strong> <br/>另一种了解一个预测因子是否与其他预测因子相关或者是否可以被其他预测因子解释的方法是<strong class="lb iu">通过使用考虑中的这个预测因子作为因变量，其余所有预测因子作为自变量，运行线性回归</strong>。如果模型非常适合，即<strong class="lb iu">高R平方</strong>，那么它意味着考虑中的<strong class="lb iu">预测因子</strong> <strong class="lb iu">可以被其他预测因子</strong>很好地解释。换句话说，考虑中的预测因子与其他预测因子密切相关，并且存在多重共线性。<br/> <em class="lv">下图-2解释了我们如何为每个预测值定义容差和VIF，并得出关于多重共线性存在的结论。</em></li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/8bf14db60f915b0824b227ee876e4890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lbOL8RuASD7ycGJVhQN0uQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片-2 |从公差和VIF解释多重共线性(图片由作者提供)</p></figure><h1 id="32bb" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">关于残差的假设..</h1><p id="662e" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated"><em class="lv">残差定义如下:误差= y _实际值—Y _预测值</em></p><p id="16f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">残差是误差项，我们的模型无法解释它。因为没有一个模型是完美的，所以每个模型中都会有残差。然而，如果我们认真思考一个好的模型必须做什么，我们就会明白，在一个好的模型中，大多数因变量应该由模型来解释(即自变量)，残差项只是数据无法解释的随机位。</p><p id="dbda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从这个角度来看下面关于残差的假设。</p><h1 id="8e6e" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">假设# 4-残差应为独立同分布随机值</h1><h2 id="51cb" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">什么意思？</em>T41】</strong></h2><p id="064f" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这意味着剩余的残差是<strong class="lb iu">独立且同分布的随机</strong>值。让我们一个一个地思考这个问题。</p><ul class=""><li id="de3f" class="os ot it lb b lc ld lf lg li ph lm pi lq pj lu ox oy oz pa bi translated"><strong class="lb iu">残差是随机值:</strong> <br/>回想一下，我们将在训练数据上拟合一个回归模型，它将始终是总体人口数据的子集<em class="lv">(因为我们几乎不可能拥有整个人口数据)</em>。如果我们选择不同的训练数据，模型拟合将会不同<em class="lv">(即使略有不同)</em>，因此，残差将会不同。<br/> →由于使用的<strong class="lb iu">训练数据是随机的</strong>，因此模型产生的<strong class="lb iu">残差也是随机的。</strong></li><li id="46b9" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated"><strong class="lb iu">残差同分布:</strong> <br/>这意味着对应于每个数据行的每个预测的残差具有相同的概率分布。</li><li id="8065" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated"><strong class="lb iu">残差是独立的:</strong> <br/>这有两个部分，都很重要:</li></ul><p id="0033" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。残差与自身无关- </strong>一次观测的残差不应该影响下一次观测的残差。这就是所谓的自相关。</p><blockquote class="og oh oi"><p id="1672" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu">自相关</strong>是一个变量与自身相关的现象，即值依赖于先前的值。</p></blockquote><p id="d1a2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。残差与解释变量无关- </strong>残差是随机值<em class="lv">(如上所述)</em>和<strong class="lb iu">不得与模型中使用的解释变量(X) </strong>相关。因为如果它们是，那么它意味着有一些信息，驻留在剩余项中，我们的模型不能捕捉到。因此，我们的模型并不适合。</p><p id="4b6d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">→如果残差可以预测，无论是通过残差本身还是通过解释变量，该信息都应该进入模型。否则，该模型不是很适合，因为它没有捕获这些信息。</p><h2 id="81d5" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">为什么这很重要？</h2><p id="bb5d" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">如果剩余项不是独立且同分布的随机值，这可能意味着下列情况之一为真:</p><ul class=""><li id="5a69" class="os ot it lb b lc ld lf lg li ph lm pi lq pj lu ox oy oz pa bi translated">线性回归模型<strong class="lb iu">未能捕捉到</strong>所有重要的独立变量。</li><li id="52bc" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated">线性回归模型<strong class="lb iu">未正确指定</strong>；也就是说，因变量和自变量之间没有内在的线性关系。</li><li id="a52d" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated">在数据中<strong class="lb iu">存在多重共线性，这导致模型系数不稳定，进而导致残差项相互依赖。<br/> <br/> →因此，为了使我们的模型被认为是一个合适的可概括模型，<strong class="lb iu">上述所有情况都必须不存在</strong>。</strong></li></ul><h2 id="a049" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><p id="b7fd" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">检查自相关:</em> </strong> <em class="lv"> </em> <br/>自相关的存在意味着残差项与上一个或下一个残差项相关。简单地说，当数据的行中存在<strong class="lb iu">模式时，就会发生<strong class="lb iu">自相关</strong>。<br/>我们可以看看剩余项与其滞后值的<strong class="lb iu">相关性(Lag(1)，Lag(2)，..滞后(x)值)并绘制成图</strong>。<br/>请参见下面的图片-3。X轴对应于残差的滞后，以1为步长增加。第一行(左侧)显示残差与其自身的相关性(Lag0)，因此，它将始终等于1。如果残差<strong class="lb iu">不是自相关的</strong>，<strong class="lb iu">，从紧邻的下一行开始的相关性(Y轴)将下降到虚线(显著性水平)以下的接近零值</strong>。如果残差是自相关的，那么我们会看到残差项与其滞后值的高度相关性远远超出了可接受的界限。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pk"><img src="../Images/17fe99f7442575216df0f1f06f585d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5lHzmugeWdPi5k1BsrsZQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3 |绘制残差与多个滞后残差值的相关性(虚拟数据)(图片由作者提供)</p></figure><blockquote class="og oh oi"><p id="c633" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu">永盒</strong>和<strong class="lb iu">杜宾-沃森测试</strong>也可用于检查<strong class="lb iu">自相关</strong>。(我将在以后的文章中详细介绍这些内容)</p></blockquote><p id="8909" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">检查与解释变量无关系:</em> <br/> </strong>这可以通过查看残差与所有X变量的相关系数来检查。我们期望看到<strong class="lb iu">残差项与解释变量的相关系数的低值，</strong>表明它们之间的关系很弱。<br/>我们可以前进一步，对观察到的相关系数进行<strong class="lb iu">显著性检验</strong>，看它们是否与零显著不同。显然，如果样本量较大，观察到的相关系数可能在统计上是有效的。</p><blockquote class="og oh oi"><p id="6c5e" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu">皮尔逊相关、肯德尔等级相关、斯皮尔曼相关和点双列相关</strong>是根据变量类型检测两个变量之间相关性的一些常用方法。(我会在以后的文章中详细介绍这些内容)</p></blockquote><h1 id="31e9" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">假设# 5-残差正态分布，平均值为0</h1><h2 id="c573" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">什么意思？</em>T41】</strong></h2><p id="f1d0" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">它有两个组成部分，两者齐头并进:<br/> (1)残差为<strong class="lb iu">正态分布</strong>和<br/> (2)残差的<strong class="lb iu">均值为0 </strong>。</p><p id="4c5f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果回归模型是好的，这意味着<strong class="lb iu">自变量在预测因变量</strong>方面做得很好，并且大多数预测非常接近因变量的实际值。</p><ul class=""><li id="043d" class="os ot it lb b lc ld lf lg li ph lm pi lq pj lu ox oy oz pa bi translated">换句话说，<strong class="lb iu">你的模型的大部分预测误差接近于零</strong>而<strong class="lb iu">大误差比小误差少得多。</strong> <br/> <em class="lv"> →这就是正态分布的样子。</em></li><li id="7f14" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated">另外，<strong class="lb iu">残差的整体影响必须抵消</strong>，即残差对因变量的正面和负面影响必须相互抵消。<br/> <em class="lv"> →这意味着残差的平均影响(或均值)接近0。</em></li></ul><p id="e7d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">→ <strong class="lb iu">残差~ N (0，σ平方)</strong>；即残差正态分布，平均值为零。</p><h2 id="a618" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">为什么这个<strong class="ak"> <em class="oa">很重要？</em>T19】</strong></h2><p id="0aec" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">甚至不严格要求残差<strong class="lb iu">的正态性。</strong>如果残差不是正态分布的，你的回归模型不会出什么大问题。常态只是一个可取的性质。然而，如果<strong class="lb iu">模型是好的，</strong>残差必须相互抵消，并且必须以0 为中心<strong class="lb iu">。</strong></p><blockquote class="og oh oi"><p id="b2be" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">你知道吗？<br/> </em> </strong>线性回归模型要求<strong class="lb iu">解释变量和响应变量呈正态分布</strong>，这是一个常见的误解<strong class="lb iu"/>。</p></blockquote><h2 id="5887" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><p id="fc7c" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">检查残差的正态性:</em> </strong> <em class="lv"> </em> <br/>我们可以将<strong class="lb iu">残差项绘制在直方图</strong>上，检查它们是否正态分布。请看下图-4(a)描绘了一个正常的情节。<br/>另一种方法是创建一个<strong class="lb iu">分位数-分位数图</strong> (QQ图)，绘制观察到的<strong class="lb iu">残差分布与理论正态分布</strong>。绘制的数据点是分位数，如果残差分布与理论正态分布对齐，我们将看到大多数点位于45度参考线上。请参见下图-4(b)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/0a20717bb2c4b84a29c0e4e85eea8eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f_9MSfiI6a_2KlZg3uHD2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片-4 |检查残差(虚拟数据)的正态性(图片由作者提供)</p></figure><p id="f05f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住中心极限定理，它说随着样本量的增加，分布趋于正态。可能会偏向分布的末端。在现实生活的数据中很难得到完美的曲线和分布。</p><blockquote class="og oh oi"><p id="0369" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated">Kolmogorov-Smirnov、Shapiro-维尔克和Anderson-Darling检验是检查变量正态性的一些常见检验。<br/>(我将在以后的文章中详细讨论这些问题)</p></blockquote><p id="427c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">检查残差的均值是否以0为中心:</em> </strong> <em class="lv"> </em> <br/>寻找残差的分布，应该在0附近，实际均值应该每接近0。</p><h1 id="04a5" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">假设# 6——残差中的同方差</h1><h2 id="65d3" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated"><strong class="ak"> <em class="oa">什么意思？</em>T13】</strong></h2><p id="5315" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated"><em class="lv">同方差—Homo =相等，同方差=分散</em> <br/>我们在上面已经了解到，残差是独立同分布的随机值，服从均值为0的正态分布。这里，我们施加了一个额外的约束，并且说<strong class="lb iu">残差的变化不应该是因变量(y)的函数，并且通过扩展，不应该是解释变量(X)的函数</strong></p><p id="e676" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">异方差</strong>是指<strong class="lb iu">残差对于X </strong> <em class="lv">的所有值都不具有恒定方差的现象(与同方差相反，这意味着残差对于所有X都具有恒定方差)</em>。</p><p id="4658" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们试着理解更多，异方差意味着残差有更大的变化，这个变化依赖于x。</p><ul class=""><li id="f830" class="os ot it lb b lc ld lf lg li ph lm pi lq pj lu ox oy oz pa bi translated">这意味着<strong class="lb iu">实际残差是独立变量的函数。</strong></li><li id="1935" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu ox oy oz pa bi translated">这也意味着，<strong class="lb iu">残差包含一些独立变量没有捕捉到的信息</strong>。</li></ul><h2 id="b78b" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">为什么这个<strong class="ak"> <em class="oa">很重要？</em> </strong></h2><p id="b3f1" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">根据异方差的定义，剩余值随X的变化更大；这意味着<strong class="lb iu">预测随着X值</strong>的增加或减少而变得更差，即<strong class="lb iu">模型在X的范围内并不同样可靠或同样拟合</strong>。<em class="lv">(注意，当残差显示出更大的变化时，模型更不可靠)</em> <br/>此外，它通常会导致相关变量的系数估计值的方差增加，但回归模型并没有考虑到这一点。<br/> — <strong class="lb iu"> <em class="lv">模型更有可能将系数报告为显著；事实上可能不是。</em>T44】</strong></p><p id="bccb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，<em class="lv">异方差导致</em><strong class="lb iu">模型不利于总体的泛化</strong>。<br/> <em class="lv"> →我们必须在模型中有同方差。</em></p><blockquote class="og oh oi"><p id="6ef9" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> <em class="it">你知道吗？<br/> </em> </strong>观察数据中异方差的常见原因有:<br/> - <strong class="lb iu">从你的模型中缺失重要变量</strong>。<br/> - <strong class="lb iu">存在影响模型拟合的异常值</strong>。<br/> - <strong class="lb iu">模型的函数形式</strong>不正确(即在没有线性关系的情况下模拟线性关系)</p></blockquote><h2 id="f2ca" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">怎么找？</h2><p id="2315" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated"><strong class="lb iu">残差和回归预测值</strong>之间的<strong class="lb iu">散点图</strong>是检查数据是否同方差<strong class="lb iu">(意味着残差在回归线上平均分布)</strong>的好方法。见下图-5左侧，残差的分布或方差随着回归预测值的增加而保持一致。反之；在右边，我们看到残差的分布(或方差)随着我们在预测回归值(X轴)上从左向右移动而增加。<br/> <em class="lv">请注意，在少数情况下，可能会绘制残差和回归预测值的标准化值，以了解分布情况</em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/fbf7bfeb31bd377a1c741780de5bdf36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RX1Pwl609nyz0aGeDkh4og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片-5 |检查同质性:残差与拟合值散点图(虚拟数据)(图片由作者提供)</p></figure><blockquote class="og oh oi"><p id="3664" class="kz la lv lb b lc ld ju le lf lg jx lh oj lj lk ll ok ln lo lp ol lr ls lt lu im bi translated"><strong class="lb iu"> Goldfeld Quandt </strong>和<strong class="lb iu"> Breusch-Pagan测试</strong>也可用于检查<strong class="lb iu">同异方差</strong>。(我将在以后的文章中详细介绍这些内容)</p></blockquote><h1 id="127e" class="mw mx it bd my mz on nb nc nd oo nf ng jz op ka ni kc oq kd nk kf or kg nm nn bi translated">隐含假设..</h1><h2 id="ec1b" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">假设# 7-回归方程被正确指定。</h2><p id="0f37" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这直接来自线性假设，即如果Y与X平方有实际的线性关系，使用X平方(而不是X)作为解释变量是有意义的。</p><h2 id="63db" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">假设# 8——X的可变性是正的</h2><p id="384a" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这直接来自于观察值彼此独立的事实，即彼此不相关。也就是说，所有观测值的解释变量的值并不相同。x有可变性。</p><h2 id="64db" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">假设#9 —剩余项与X无关</h2><p id="d242" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">这直接来源于这样一个事实，即剩余项是独立且同分布的随机值。“独立性”意味着，它们与X变量完全无关。</p><h2 id="2c8b" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">假设#10—观察值的数量多于预测值的数量</h2><p id="2bb4" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">我们必须有大量的观察数据来构建我们的模型，而且这些数据应该远远多于所使用的解释变量的数量。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="3f29" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">摘要</h1><p id="c5ca" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">为了让任何模型或数学/统计框架成立，底层数据需要遵循某些准则或原则。在线性回归模型的情况下，这些被称为“假设”，对于应用于任何数据的线性回归框架，这些假设必须成立。下面是一个线性回归模型的所有假设的详细清单。请注意，1-6是关键，7-10是派生的或更隐含的。</p><ol class=""><li id="1d3f" class="os ot it lb b lc ld lf lg li ph lm pi lq pj lu pn oy oz pa bi translated"><strong class="lb iu">参数</strong>中的<strong class="lb iu">线性度</strong>。</li><li id="220c" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated"><strong class="lb iu">观察值</strong>以<strong class="lb iu">独立的方式</strong>收集。</li><li id="ed20" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated"><strong class="lb iu">解释变量之间无多重共线性或多重共线性极小</strong>。</li><li id="d4d7" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">剩余项是<strong class="lb iu">独立同分布的随机变量</strong>。</li><li id="fc2e" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">残差项为<strong class="lb iu">正态分布</strong> <em class="lv">(非必选)</em><strong class="lb iu">均值以0 </strong>为中心。</li><li id="af7f" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">模型中剩余的项之间不存在<strong class="lb iu">异方差。</strong></li><li id="f940" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">正确指定了回归模型。</li><li id="7702" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">X的可变性是正的。</li><li id="de31" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">剩余项和X(解释)变量之间没有关系。</li><li id="4a1a" class="os ot it lb b lc pb lf pc li pd lm pe lq pf lu pn oy oz pa bi translated">观察值的数量大于变量的数量。</li></ol></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h2 id="974f" class="no mx it bd my np nq dn nc nr ns dp ng li nt nu ni lm nv nw nk lq nx ny nm nz bi translated">保持联系..</h2><p id="0471" class="pw-post-body-paragraph kz la it lb b lc ob ju le lf oc jx lh li od lk ll lm oe lo lp lq of ls lt lu im bi translated">如果你喜欢这篇文章并且对类似的文章感兴趣<a class="ae ky" href="https://medium.com/@deepakchopra2911" rel="noopener"> <strong class="lb iu"> <em class="lv">在Medium上关注我</em></strong></a><a class="ae ky" href="https://medium.com/subscribe/@deepakchopra2911" rel="noopener"><strong class="lb iu"><em class="lv">加入我的邮件列表</em> </strong> </a> <strong class="lb iu"> </strong>和<em class="lv">(..如果你已经不是了..)</em>跳上成为<a class="ae ky" href="https://medium.com/@deepakchopra2911/membership" rel="noopener"> <strong class="lb iu"> <em class="lv">中型家族的一员</em></strong></a><strong class="lb iu"><em class="lv"/></strong>获取数以千计的有用文章。<strong class="lb iu"> <em class="lv"> <br/> </em> </strong> <em class="lv">(如果你使用以上链接，我将获得你约50%的会员费)</em></p><p id="a58e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="lv">..不断学习，不断成长！</em>T56】</strong></p></div></div>    
</body>
</html>