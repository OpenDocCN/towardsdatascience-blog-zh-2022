<html>
<head>
<title>Tune Deep Neural Networks using Bayesian Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用贝叶斯优化调整深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tune-deep-neural-networks-using-bayesian-optimization-c9f6503a049f#2022-06-08">https://towardsdatascience.com/tune-deep-neural-networks-using-bayesian-optimization-c9f6503a049f#2022-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3738" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用贝叶斯理论提高你的绩效</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/83b9addc2338a7b81d9cebfd33b6d3f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*94Pwx0VtVeMGOOo1"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Syarafina Yusof 在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="92ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" rel="noopener" target="_blank" href="/create-image-classification-models-with-tensorflow-in-10-minutes-d0caef7ca011">之前的一篇帖子</a>中，我们展示了一个关于使用Tensorflow和深度学习方法进行图像分类的案例研究。</p><p id="16fd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">虽然案例研究很少，但它展示了机器学习项目的每个阶段:清理、预处理、模型构建、训练和评估。<strong class="lb iu">但是我们跳过了调优</strong>。</p><p id="3af2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我们将更深入地研究超参数优化。同样，我们将使用Tensorflow中包含的<a class="ae ky" href="https://www.kaggle.com/datasets/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">时尚MNIST[1] </a>数据集。</p><p id="9d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">提醒一下，数据集在训练集中包含60，000幅灰度图像，在测试集中包含10，000幅图像。每个图像代表属于10个类别之一的时尚项目(<em class="lv"> T恤/上衣</em>’、<em class="lv">裤子</em>’、<em class="lv">套头衫</em>等等)。因此，我们有一个多类分类问题。</p><h1 id="29d7" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">设置</h1><p id="bff5" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">我将简要回顾一下准备数据集的步骤。有关更多信息，请查看上一篇文章的<a class="ae ky" rel="noopener" target="_blank" href="/create-image-classification-models-with-tensorflow-in-10-minutes-d0caef7ca011">第一部分:简而言之，步骤如下:</a></p><ol class=""><li id="fac5" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated">加载数据。</li><li id="91a5" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">分为<em class="lv">训练</em>、<em class="lv">验证</em>和<em class="lv">测试</em>套。</li><li id="52a1" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">将0–255到0–1范围内的像素值标准化。</li><li id="3c42" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">对目标变量进行一次性编码。</li></ol><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="ec23" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">概括地说，所有训练集、验证集和测试集的形状是:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><h1 id="f5cd" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">超参数调谐</h1><p id="50fe" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">现在，我们将使用<strong class="lb iu"> Keras Tuner </strong>库[2]:它将帮助我们轻松地调整神经网络的超参数。要安装它，请执行:</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="cc7f" class="no lx it nk b gy np nq l nr ns">pip install keras-tuner</span></pre><p id="9543" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong> <em class="lv"> Keras Tuner需要Python 3.6+和TensorFlow 2.0+ </em></p><p id="6efc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">快速提醒一下，超参数调整是机器学习项目的基本部分。有两种超参数:</p><ol class=""><li id="3b39" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu">结构超参数</strong>:定义模型整体架构的参数(如<em class="lv">隐藏单元</em>的数量、<em class="lv">层数</em></li><li id="f3ec" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu">优化器超参数:</strong>影响训练速度和质量的参数(如<em class="lv">学习率</em>和<em class="lv">优化器类型</em>、<em class="lv">批量</em>、<em class="lv">周期数</em>)</li></ol><h2 id="0805" class="no lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">为什么调优很棘手？</h2><p id="93f9" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">为什么需要超参数调节库？难道我们不能尝试每一种可能的组合，看看在验证集上什么是最好的？</p><p id="f0fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，没有:</p><ul class=""><li id="5598" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu oe mz na nb bi translated">深度神经网络需要大量的时间来训练，甚至几天。</li><li id="efcf" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated">如果你在云上训练大型模型(比如亚马逊Sagemaker)，记住每个实验都是要花钱的。</li></ul><p id="e923" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，限制超参数搜索空间的剪枝策略是必要的。</p><h2 id="9a40" class="no lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">贝叶斯优化</h2><p id="c77b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">幸运的是，<strong class="lb iu"> Keras tuner </strong>提供了一个<strong class="lb iu">贝叶斯优化<em class="lv"> </em> tuner </strong>。贝叶斯优化调谐器不是搜索每一个可能的组合，而是遵循一个迭代过程，在这个过程中，它随机选择前几个组合。然后，基于这些超参数的性能，贝叶斯调谐器选择下一个最好的可能。</p><p id="d8ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，超参数的每个选择取决于先前的尝试。基于历史选择下一组超参数<em class="lv">和评估性能</em>的迭代次数继续，直到调谐器找到最佳组合或用尽最大数量的<strong class="lb iu">试验</strong>。我们可以用参数'<em class="lv"> max_trials </em>'进行配置。</p><p id="0fe4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了贝叶斯优化调谐器之外，<strong class="lb iu"> Keras调谐器</strong>还提供了两个调谐器:<strong class="lb iu"> RandomSearch </strong>和<strong class="lb iu"> Hyperband。我们将在本文的最后讨论它们。</strong></p><h1 id="9978" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">回到我们的例子</strong></h1><p id="6a83" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">接下来，我们将对网络应用超参数调整。在上一篇文章中，我们实验了两种网络架构，标准的<strong class="lb iu">多层感知器</strong> ( <em class="lv"> MLP </em>)和<strong class="lb iu">卷积神经网络</strong> ( <em class="lv"> CNN </em>)。</p><h2 id="7a15" class="no lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">多层感知器(MLP)</h2><p id="1ead" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">但是首先，让我们记住我们的基线MLP模型是什么:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="f2ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调整过程需要两种主要方法:</p><ol class=""><li id="68c9" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu"> hp。Int(): </strong>设置超参数的范围，其值为整数-例如，<em class="lv">密集层</em>中隐藏单元的数量:</li></ol><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="84f1" class="no lx it nk b gy np nq l nr ns">model.add(Dense(units = hp.Int('dense-bot', min_value=50, max_value=350, step=50))</span></pre><p id="c612" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.<strong class="lb iu">惠普。Choice(): </strong>为超参数提供一组值—例如，<em class="lv"> Adam </em>或<em class="lv"> SGD </em>作为最佳优化器？</p><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="ed5d" class="no lx it nk b gy np nq l nr ns">hp_optimizer=hp.Choice('Optimizer', values=['Adam', 'SGD'])</span></pre><p id="6c97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，在我们最初的MLP示例<strong class="lb iu">、</strong>上使用<strong class="lb iu">贝叶斯优化<em class="lv">、</em>调谐器</strong>，我们测试了以下超参数:</p><ul class=""><li id="5e18" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu oe mz na nb bi translated"><strong class="lb iu">隐藏层数</strong>:1-3</li><li id="b79f" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">第一密层尺寸</strong>:50–350</li><li id="79ef" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">第二和第三致密层尺寸</strong>:50–350</li><li id="2a41" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">辍学率</strong> : 0，0.1，0.2</li><li id="03f7" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">优化器</strong> : <em class="lv"> SGD </em>(内斯特洛夫=真，动量=0.9)或者<em class="lv">亚当</em></li><li id="860b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">学习率</strong> : 0.1，0.01，0.001</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="5d5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意第5行的for循环:<strong class="lb iu">我们让模型决定我们网络的深度！</strong></p><p id="b824" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们启动调谐器。注意我们之前提到的<em class="lv"> max_trials </em>参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="0e3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将打印:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/60812bfa38e8d97dfa28dbaf1c941d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*YuMkvG0BiInO2WeDt6NxhQ.png"/></div></figure><p id="0b09" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该过程耗尽了迭代次数，用了大约1个小时才完成。我们还可以使用以下命令打印模型的最佳超参数:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/0b75ae157f5d735b1ae9f8b1441aaa44.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*3oavQYnoT6qhEcyHBuhMRg.png"/></div></figure><p id="fd37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就是这样！现在，我们可以使用最佳超参数重新训练我们的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="b2d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">或者，我们可以用更少的冗长来重新训练我们的模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="0def" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们现在要做的就是检查测试的准确性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="e501" class="no lx it nk b gy np nq l nr ns"># Test accuracy: 0.8823</span></pre><p id="e6e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与基线的模型测试精度相比:</p><p id="88ed" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">基线MLP模式:</strong> 86.6 % <br/> <strong class="lb iu">最佳MLP模式:</strong> 88.2 %</p><p id="8a56" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，我们观察到测试准确度有大约3%的差异！</p></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><h2 id="d154" class="no lx it bd ly nt nu dn mc nv nw dp mg li nx ny mi lm nz oa mk lq ob oc mm od bi translated">卷积神经网络</h2><p id="cd9b" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">同样，我们将遵循相同的程序。有了CNN，我们可以测试更多的参数。</p><p id="9a45" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，这是我们的基线模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="c325" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基线模型仅包含单组<strong class="lb iu">过滤</strong>和<strong class="lb iu">汇集</strong>层。对于我们的调优，我们将测试以下内容:</p><ul class=""><li id="6f7a" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu oe mz na nb bi translated"><strong class="lb iu">卷积层、最大池层和漏失层的“块”数量</strong></li><li id="30cb" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">各区块Conv层的滤波尺寸</strong> : 32，64</li><li id="47ae" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">conv层上有效或相同的填充</strong></li><li id="477c" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">最终附加层的隐藏层大小:</strong>25–150，乘25</li><li id="2b21" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">优化器</strong> : <em class="lv"> SGD </em>(内斯特洛夫=真，动量=0.9)或<em class="lv">亚当</em></li><li id="0fab" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated"><strong class="lb iu">学习率:</strong> 0.01，0.001</li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="4f2a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像以前一样，我们让网络决定它的深度。</p><p id="b255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们准备调用贝叶斯调谐器。最大迭代次数设置为100:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="fe4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这将打印:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/3d23ea87ff92e9b18a1d6a407bff9f6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*e2bohTdwtgSOjbVlP5ZdKw.png"/></div></figure><p id="0529" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最好的超参数是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/26bc7fe39d3885f7c7294bec3be2c7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/1*kbW8MnvhVn2dv80poNaijA.png"/></div></figure><p id="8e84" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们使用最佳超参数训练我们的CNN模型:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="462b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并检查测试集的准确性:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><pre class="kj kk kl km gt nj nk nl nm aw nn bi"><span id="41ba" class="no lx it nk b gy np nq l nr ns"># Test accuracy: 0.92</span></pre><p id="70d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与基线的CNN模型测试准确性相比(来自我们的前一篇文章):</p><p id="0bad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">基线CNN模型:</strong> 90.8 % <br/> <strong class="lb iu">最佳CNN模型:</strong> 92%</p><p id="842f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们看到了优化模型的性能提升！</p><p id="0dbc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除了准确性之外，我们可以确认调音师做得很好，原因如下:</p><ul class=""><li id="e51d" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu oe mz na nb bi translated">调谐器在任何情况下都选择非零的<em class="lv">压差</em>值，即使我们提供的调谐器也是零压差。这是意料之中的，<strong class="lb iu">因为<em class="lv">压差</em>是一种减少过拟合的宝贵机制。</strong></li><li id="913a" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated">有趣的是，最好的CNN架构是标准管道，其中每层的过滤器数量逐渐增加。这是意料之中的，因为随着计算在后续层中向前推进，模式变得更加复杂。因此，有更多的模式组合需要更多的过滤器来捕捉。</li></ul><h1 id="87e3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated"><strong class="ak">闭幕词</strong></h1><p id="41de" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">毫无疑问，<strong class="lb iu"> Keras Tuner </strong>是一款用Tensorflow优化深度神经网络的万能工具。</p><p id="e874" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最明显的选择是<strong class="lb iu">贝叶斯优化<em class="lv"> </em> </strong>调谐器。然而，还有另外两种选择可供人们使用:</p><ol class=""><li id="ff98" class="mt mu it lb b lc ld lf lg li mv lm mw lq mx lu my mz na nb bi translated"><strong class="lb iu"> RandomSearch: </strong>这种类型的调优器通过随机选择几个超参数来避免探索超参数的整个搜索空间。但是，它不能保证这个调谐器会找到最佳的。</li><li id="57a1" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated"><strong class="lb iu"> Hyperband: </strong>这个调谐器选择一些超参数的随机组合，并使用它们来训练仅几个时期的模型。然后，调优器使用这些超参数来训练模型，直到所有历元都用完，并从中选择最佳的。</li></ol><h1 id="83c3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">感谢您的阅读！</h1><ul class=""><li id="41a0" class="mt mu it lb b lc mo lf mp li op lm oq lq or lu oe mz na nb bi translated">订阅我的<a class="ae ky" href="https://medium.com/subscribe/@nikoskafritsas" rel="noopener">简讯</a>！</li><li id="687b" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu oe mz na nb bi translated">在Linkedin上关注我！</li></ul></div><div class="ab cl oh oi hx oj" role="separator"><span class="ok bw bk ol om on"/><span class="ok bw bk ol om on"/><span class="ok bw bk ol om"/></div><div class="im in io ip iq"><h1 id="8f22" class="lw lx it bd ly lz os mb mc md ot mf mg jz ou ka mi kc ov kd mk kf ow kg mm mn bi translated">参考</h1><ol class=""><li id="a9fc" class="mt mu it lb b lc mo lf mp li op lm oq lq or lu my mz na nb bi translated">时尚MNIST数据集由Zalando，<a class="ae ky" href="https://www.kaggle.com/datasets/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/Zalando-research/fashion mnist</a>，麻省理工学院许可(MIT)版权【2017】</li><li id="2bce" class="mt mu it lb b lc nc lf nd li ne lm nf lq ng lu my mz na nb bi translated">喀拉斯调谐器，<a class="ae ky" href="https://keras.io/keras_tuner/" rel="noopener ugc nofollow" target="_blank">https://keras.io/keras_tuner/</a></li></ol></div></div>    
</body>
</html>