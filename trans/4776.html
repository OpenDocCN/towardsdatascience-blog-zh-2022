<html>
<head>
<title>The Most Fundamental Layer of MLOps — Required Infrastructure</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MLOps的最基础层—所需的基础架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-most-fundamental-layer-of-mlops-required-infrastructure-bafd111db4c3#2022-10-24">https://towardsdatascience.com/the-most-fundamental-layer-of-mlops-required-infrastructure-bafd111db4c3#2022-10-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cbd9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">拥有实施MLOps解决方案的合适基础架构</h2></div><p id="ede2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我之前的帖子中，我讨论了构建端到端MLOps解决方案的三个关键组件，即数据和功能工程管道、ML模型培训和再培训管道ML模型服务管道。你可以在这里找到文章:<a class="ae lb" rel="noopener" target="_blank" href="/learn-the-core-of-mlops-building-machine-learning-ml-pipelines-7242b77520b7?source=friends_link&amp;sk=0a3006eed886f1071082ac1b5a485785">学习MLOPS的核心——构建ML管道。</a>在我上一篇文章的最后，我简要地谈到了一个事实，即MLOps解决方案的复杂性可能会因ML项目的性质而有很大的不同，更重要的是，取决于所需的底层基础设施的变化。</p><p id="65eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，在今天的帖子中，我将解释不同级别的基础架构是如何要求的，如何确定MLOps解决方案的复杂性，以及如何将MLOPS解决方案分为不同的级别。</p><p id="da84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更重要的是，在我看来，将mlop分为不同的级别可以使任何规模的组织更容易采用mlop。原因是，并不是每个层次的MLOps都需要Kubernetes这样的大规模在线推理基础设施，Apache Spark这样的并行和分布式数据处理框架，以及结构化流和Apache Flink这样的低延迟和流数据管道解决方案。因此，拥有小规模数据集和批量推理ML项目的组织不需要招聘具有这些专业技能的人员，也不需要设置复杂的底层存储和计算基础架构，但仍然可以利用现有的技能组合和大大简化的基础架构来正确执行MLOps。</p><p id="9a21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于每个级别，我将在以后的博客中分享一些参考架构和实现指南。如果你想在这些新博客发表时得到通知，请随时关注我。</p><p id="2fe4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们讨论一下运行端到端MLOps解决方案所需的基础架构，包括3个关键组件:</p><ul class=""><li id="8ffc" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">数据和特征工程管道；</li><li id="665f" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">ML模型培训管道；</li><li id="6cb3" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">ML模型推理管道；</li></ul><p id="879a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将介绍每个组件可能需要的所有基础设施。然后，我将根据所需的基础设施将它们分为不同的级别。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/9bbd792021ab53e5324f41be497f406d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*yAodosBYSPGcJ_gP"/></div></div><p class="mc md gj gh gi me mf bd b be z dk translated">由<a class="ae lb" href="https://unsplash.com/@ryanquintal?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">瑞安·昆塔尔</a>在<a class="ae lb" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="32f8" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">数据和特征工程管道所需的基础设施</h2><p id="b5fd" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">根据数据量和数据延迟，运行数据和特征工程管道所需的基础设施如下:</p><ul class=""><li id="828e" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">第1级—当数据量可以由单台机器处理，并且数据延迟为批量频率时，所需的基础架构可以像本地笔记本电脑或公共云上的虚拟机一样简单。此外，您可以利用云平台即服务(PaaS)产品，如AWS Batch、AWS Lambda或Azure功能，进一步简化基础架构管理；</li><li id="90cb" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">第2级—当数据量无法由单台机器处理且需要并行和分布式数据处理，但数据延迟仍可保持批处理频率时，所需的基础架构将需要超越单台机器成为计算集群，以便安装和管理Apache Spark等分布式计算框架。Apache Spark是一个开源解决方案。组织可以运行自己的计算集群，并使用开源Spark来管理他们的数据和功能工程管道。但是，大多数企业仍然选择托管服务(如Databricks)作为大规模数据和功能工程工作负载的底层数据基础架构。公共云提供商也为Spark提供服务，如AWS EMR和GCP数据处理。</li><li id="884b" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">级别3 <strong class="kh ir"> </strong> —在前两个场景中，数据延迟保持在批处理级别。然而，当数据延迟需要非常低时，就需要完全不同的基础设施集合。至少需要一个事件驱动的消息队列和一个流引擎。为了实现更低的延迟，通常需要消息队列服务来动态捕获流数据，而不是将数据保存到存储系统中。对于消息队列服务，有开源的解决方案，比如Apache Kafka还有商业托管服务，比如Azure Event Hub、AWS Kinesis数据流和Confluent。除了消息队列服务之外，为了实现下游数据消耗的低频率，健壮的流引擎也是非常必要的。开源流媒体引擎包括Apache Spark结构化流媒体和Apache Flink以及Apache Beam。当然，也有针对流媒体引擎的商业产品，如Databricks、AWS Kinesis数据分析以及GCP数据流。</li></ul><p id="6e17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所见，根据数据量和数据延迟要求，运行数据和功能工程管道的基础设施可能会有很大差异。实际上，这对于ML模型训练管道和ML模型推理管道都是相同的。这就是为什么在基础设施级别进行澄清是至关重要的，以避免MLOPS的印象(或误解)是<strong class="kh ir"> <em class="nl">总是</em> </strong>令人生畏且复杂。对于某些级别，MLOps也可以非常简单，我将在这篇博客的后面解释。现在让我们继续解释运行ML模型训练管道所需的基础设施。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="0275" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">ML模型培训管道所需的基础设施</h2><p id="a000" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">根据训练数据的大小和将训练好的模型用于生产环境所需的时间(SLA ),模型训练的基础结构可以划分如下:</p><ul class=""><li id="52ca" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">级别1 —当训练数据大小适合单台计算机的内存，并且总训练时间不超过生产环境所需的SLA时，使用单台计算机进行模型训练就足够了。根据训练数据的格式，可能需要一台GPU机器。比如你的训练数据是结构化的，数值型的，一般一个CPU机器就够了。然而，如果您的训练数据是非结构化的，如图像，首选的训练基础设施将是GPU机器。</li><li id="9437" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">第2级<strong class="kh ir"> </strong> —当训练数据太大而无法容纳在单台机器的内存中，或者即使训练数据大小可以容纳在单台机器的内存中，但完成一项训练工作所需的时间长于所需的SLA时，这是公司需要启动训练集群以跨多个节点进行并行和分布式ML模型训练的时候。然而，在多个节点上运行分布式ML模型训练引入了许多新的复杂性，例如跨多台机器调度任务、高效地传输数据以及从机器故障中恢复。幸运的是，已经有一些开源库来处理多节点训练带来的这些额外的复杂性，并使数据科学家的训练工作相对简单，即使他们需要分发这些工作。这些开源库包括用于扩展Python ML工作负载的Ray，用于TensorFlow、Keras、PyTorch和Apache MXNet的分布式深度学习培训框架的Horovod，以及用于扩展Python库(包括Python ML库)的Dask。</li></ul><p id="8aa7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将单独发表一篇关于分布式培训的博客。如果您想在发布博客时得到通知，请随时关注我。</p><p id="6a34" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">众所周知，ML是一个极其动态的领域。要运行一个模型训练工作，数据科学家需要安装相当多的开源库，包括Pandas、Numpy、Matplotlib、Seaborn、Plotly、Scikit Learn、Tensorflow、Keras、Pytorch、mlflow等等。因此，大多数公共云供应商或特定的数据+人工智能供应商(如Databricks)提供预配置的ML运行时，包括所有这些流行的ML库，以节省数据科学家安装和维护这些库的大量时间。因此，大多数组织通过利用云服务来构建他们的ML培训基础设施。云上流行的ML服务有AWS Sagemaker、Azure机器学习工作空间、GCP Vertex AI以及Databricks机器学习运行时。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="e856" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">ML模型推理管道所需的基础设施</h2><p id="2660" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">根据模型推理频率和推理请求量，运行ML模型推理管道所需的基础设施如下:</p><ul class=""><li id="719a" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">级别1-当模型推理频率是批量的，并且用于模型推理的数据量能够由一台单独的机器处理时，通过对数据调用预测函数，可以将训练的模型加载到用于批量预测的单独的机器中，该数据通常存储为Pandas数据帧；</li><li id="0738" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">第2级<strong class="kh ir"> </strong> —当模型推理频率为批处理，但数据量无法在单台机器内管理时，需要建立一个集群来利用分布式计算框架，如Apache Spark。例如，经过训练的ML模型可以作为Spark用户定义函数(UDF)加载，并且可以将UDF应用于Spark数据帧以进行并行模型预测。</li><li id="3d58" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">级别3 —当模型推理频率是低延迟的，并且数据量相当大时，流推理就变得必要了。与第2级类似，也需要一个计算集群。此外，还需要使用流引擎进行模型预测，以满足低延迟要求。在这种情况下，使用的流行流媒体引擎是Apache Spark和Apache Flink的结构化流媒体。</li><li id="470c" class="lc ld iq kh b ki ll kl lm ko ln ks lo kw lp la lh li lj lk bi translated">第4级—当模型推理在线时，这意味着模型通常被打包为REST API端点，但API请求量很小，可以由单台机器处理，所需的基础架构通常是云上的单节点CPU虚拟机。公共云提供商和数据/人工智能供应商都有针对此类模型服务的托管服务。例如，Databricks有无服务器端点，客户不必担心设置服务基础设施，他们需要做的只是实例化一个模型端点。其他公司也有类似的产品。</li></ul><p id="a94a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们进入第5级之前，需要注意一点——在线推理不同于流式推理，在流式推理中，经过训练的ML模型仍然作为Python函数加载，而不是作为REST端点。它们都有低延迟，但是在线推理应该是实时的。</p><ul class=""><li id="f446" class="lc ld iq kh b ki kj kl km ko le ks lf kw lg la lh li lj lk bi translated">级别5 —当模型推理是在线的，并且API请求量是大规模的(意味着每秒查询数(QPS)对于单个端点来说是非常大的)时，就需要设置一个像Kubernetes这样的集群基础设施来进行分布式推理。通常使用的流行方法是，将训练好的模型打包成容器映像，并在容器注册表中注册，如AWS弹性容器注册表、Azure容器注册表或GCP容器注册表。然后，这些经过训练的模型的注册图像将被拉入并部署到Kubernetes中，用于大规模和分布式模型推理。每个公共云都有自己的托管Kubernetes服务。</li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="95e8" class="mn mo iq bd mp mq mr dn ms mt mu dp mv ko mw mx my ks mz na nb kw nc nd ne nf bi translated">结论</h2><p id="881f" class="pw-post-body-paragraph kf kg iq kh b ki ng jr kk kl nh ju kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">到目前为止，我们已经涵盖了完整的端到端MLOps解决方案的3个关键管道中的每一个所需的不同级别的基础设施。很明显，不同级别的基础架构的复杂性有很大不同。</p><p id="8b84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下一篇博客中，我将根据基础设施的复杂性和实现模式将MLOps分为不同的级别，对于每个级别，我还将分享一些参考架构和代码示例，其中将包括MLOps解决方案的其他部分，如编排、模型版本控制、数据版本控制、漂移检测、数据质量检查和监控。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="5ed7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望你喜欢阅读这篇博客。如果你想在有新博客发表时得到通知，请随时关注我。</p><p id="2e9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果想看到更多围绕现代高效数据+AI栈的指南、深度潜水、见解，请订阅我的免费简讯— <a class="ae lb" href="https://yunnawei.substack.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> <em class="nl">高效数据+AI栈</em> </strong> </a>，谢谢！</p><p id="d4cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注:以防万一你还没有成为媒体会员，并希望获得无限制的媒体访问，你可以使用我的<a class="ae lb" href="https://medium.com/@weiyunna91/membership" rel="noopener">推荐链接</a>注册！我可以免费给你一点佣金。非常感谢你的支持！</p></div></div>    
</body>
</html>