<html>
<head>
<title>Making pictures with words</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用文字制作图片</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/making-pictures-with-words-9aac0b97b356#2022-09-07">https://towardsdatascience.com/making-pictures-with-words-9aac0b97b356#2022-09-07</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3673" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">人工智能文本到图像生成器的崛起</h2></div><p id="3ccd" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">当我第一次听这首歌的时候，我还很年轻。我觉得这是一首有趣又朗朗上口的歌，就像一首顺口溜，尽管我不知道这首歌是关于什么的。但这没什么，我只是一个小男孩，听着收音机，看着录像机上的录像。我真的没有太注意标题或歌词。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj lg"><img src="../Images/82aaf17a638ecaf210ff8164f5d7d5f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JXKH4hdFRKL2IN7MumrhA.png"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated">Dall-E 2使用文本提示创建的图像“视频杀死了电台明星，在用迷幻灯光演唱80年代流行歌曲风格的乐队中演奏”</p></figure><p id="fa06" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">很久以后，我才意识到歌词的真正含义。</p><blockquote class="lw lx ly"><p id="68c8" class="kj kk lf kl b km kn jv ko kp kq jy kr lz kt ku kv ma kx ky kz mb lb lc ld le in bi translated">视频杀了电台明星<br/>视频杀了电台明星</p><p id="3605" class="kj kk lf kl b km kn jv ko kp kq jy kr lz kt ku kv ma kx ky kz mb lb lc ld le in bi translated">在我的脑海里，在我的车里<br/>我们不能倒带，我们已经走得太远<br/>画面传来，伤透了你的心<br/>归咎于录像机</p><p id="b576" class="kj kk lf kl b km kn jv ko kp kq jy kr lz kt ku kv ma kx ky kz mb lb lc ld le in bi translated"><em class="iu">视频杀了电台明星(道恩斯/伍利/霍恩)</em></p></blockquote><p id="4ba8" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">这首歌是塑料时代专辑的一部分，该专辑的主题是怀旧和对现代技术影响的焦虑。虽然这张专辑发行于40多年前(1980年)，但这些主题仍然真实而清晰。</p><h1 id="a8af" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">生成图像</h1><p id="889b" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">当<a class="ae mz" href="https://techcrunch.com/2022/08/15/tiktok-in-app-text-to-image-ai-generator/" rel="noopener ugc nofollow" target="_blank">抖音开始在他们的应用程序中推出</a>时，你就知道一项技术已经进入了大联盟。仅在本周，我就阅读了几份人工智能文本到图像生成器的前10名名单。这项技术炙手可热，模型和创业公司一夜之间如雨后春笋般涌现。每隔一周或一个月，整个思维方式都会被推翻，昨天令人兴奋的技术已经是旧闻了。</p><p id="5cce" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">最知名的文本到图像AI模型当然是2021年1月发布的<a class="ae mz" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> OpenAI的Dall-E </a>。OpenAI在2021年12月发布了另一款机型GLIDE(没事，后面我再说首字母缩写)而之后没多久，<a class="ae mz" href="https://openai.com/dall-e-2/" rel="noopener ugc nofollow" target="_blank"> Dall-E 2 </a>在2022年4月公布。至少可以说，发布的速度非常快。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj lg"><img src="../Images/9802fae55827c4734b582a526e1d7771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ob7WhbGuRW_ZavdXkkYWfg.jpeg"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated">图片由Dall-E 2创建，使用文本提示“一名宇航员以逼真的风格租用一匹马”</p></figure><p id="cd2c" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">谷歌备受期待的<a class="ae mz" href="https://imagen.research.google" rel="noopener ugc nofollow" target="_blank"> Imagen </a>于2022年6月发布，尽管它尚未发布，但大量媒体报道已经开始称赞它如何完全超越了王者Dall-E 2 。</p><p id="085b" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">在这股浪潮中，<a class="ae mz" href="https://hypebeast.com/2022/7/meta-make-a-scene-ai-artwork-tool" rel="noopener ugc nofollow" target="_blank"> Meta(脸书)于2022年7月发布了他们的文本到图像工具，Make-A-Scene </a>。Make-a-Scene与中的其他场景稍有不同，因为它允许用户根据自己的选择用一个简单的草图来补充文本提示。</p><p id="b15f" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">就连微软也赶了上来，宣布推出<a class="ae mz" href="https://nuwa-infinity.microsoft.com/#/" rel="noopener ugc nofollow" target="_blank">女娲-Infinity </a>，这是一种人工智能模型，可以从任何给定的文本、图像或视频输入中生成高质量的图像和视频。</p><p id="61db" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">是的，视频。</p><p id="c3c6" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">然而，大公司并没有垄断文本到图像的淘金热。在同一个领域有很多小型创业公司。<a class="ae mz" href="https://www.midjourney.com/home/" rel="noopener ugc nofollow" target="_blank"> Midjourney </a>是一家小型创业/研究实验室(不到10人)，拥有一批使用其工具创作艺术作品的用户。它于2022年7月公开测试。</p><p id="4b7f" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">睡前咖啡是另一个流行的工具，来自澳大利亚。该公司于2019年11月作为<a class="ae mz" href="https://en.wikipedia.org/wiki/Neural_style_transfer" rel="noopener ugc nofollow" target="_blank">神经风格转移</a>应用程序成立，但当较新的人工智能模型在2021年年中登场时，他们很快转向图像生成。如今，它自称已经在其平台上创作了超过500万件艺术品。</p><p id="4c6a" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">小型人工智能文本到图像初创公司的新宠必须是<a class="ae mz" href="https://stability.ai" rel="noopener ugc nofollow" target="_blank">稳定性人工智能</a>。所以<a class="ae mz" href="https://www.nasdaq.com/articles/stability.ai-debuted-most-provocative-open-source-text-to-image-model-ark-says" rel="noopener ugc nofollow" target="_blank">滔滔不绝的报道</a>已经写在上面，他们炒作泛滥。资金也越来越多——一家投资公司表达了对一项交易的初步兴趣，该交易对总部位于伦敦的初创公司Stability AI的估值为5亿美元。Stability AI的首席执行官兼创始人艾玛德·莫斯塔克表示:“我们已经谈成了大规模交易，因此与大多数亏损的大公司相比，我们在门口就能盈利。”</p><p id="18af" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">它于2022年8月进行了公开测试，并与它赞助的由慕尼黑路德维希·马克西米利安大学开发的新的强大的稳定扩散文本到图像人工智能模型密切相关。Stability AI也比其他小型创业公司更进了一步，不仅拥有自己强大的人工智能模型，还迈出了大胆的一步，将该模型作为开源软件发布。</p><p id="cb86" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">新的稳定扩散模型也不是唯一的开源模型。</p><p id="df90" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">6月6日，<a class="ae mz" href="https://huggingface.co" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>，一家托管开源人工智能项目和应用的公司，突然看到其托管的人工智能文本到图像应用<a class="ae mz" href="https://huggingface.co/spaces/dalle-mini/dalle-mini" rel="noopener ugc nofollow" target="_blank"> Dall-E mini </a>的流量激增。顾名思义，Dall-E mini是对Dall-E模型的一种改进。</p><p id="6f33" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">这个应用程序很简单——它只是用文本提示创建了9张图片。它之所以广受欢迎，是因为它是可用的，而且是免费的，不像它最初的同名游戏Dall-E，需要一个等待名单才能加入测试版。Dall-E mini很快就达到了每天50，000张图片，最终迫使创作者将该应用程序从拥抱脸中移除。当OpenAI开始注意到并对Dall-E这个名字的使用感到不舒服时，它甚至不得不改变它的名字(改为<a class="ae mz" href="https://www.craiyon.com" rel="noopener ugc nofollow" target="_blank"> Craiyon </a>)。</p><p id="f8d0" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">另一个流行的开源文本到图像是<a class="ae mz" href="https://colab.research.google.com/github/justinjohn0306/VQGAN-CLIP/blob/main/VQGAN%2BCLIP(Updated).ipynb" rel="noopener ugc nofollow" target="_blank"> VQGAN+CLIP </a>，这样命名是因为它结合了两种不同的人工智能模型(VQGAN和CLIP)来创建一个强大的文本到图像模型。大约在2021年4月，瑞安·默多克将剪辑与一个名为比根的图像生成技术结合起来。后来，凯瑟琳·克劳森和其他一些人用VQGAN取代了BigGAN，并把它放在了一个Google Colab笔记本上。剩下的就是开源历史了。</p><p id="0fd6" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">截至今天，在<a class="ae mz" href="https://replicate.com" rel="noopener ugc nofollow" target="_blank"> Replicate </a>中，一家AI模型托管公司(拥有出色的API)拥有32个开源文本到图像模型，包括稳定扩散、各种GAN+CLIP模型，当然还有Dall-E mini。</p><p id="9720" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">有很多模型。</p><h1 id="29ac" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">它是如何工作的</h1><p id="0a5a" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">人工智能行业充满了令人惊讶的难以破译的首字母缩写词和行话，而tex-to-image子行业也一样模糊，如果不是更模糊的话。如果你涉水通过技术，你会在不同的时间听到甘斯，剪辑，变压器和扩散模型。技术术语可能令人难以置信(自然，它们毕竟是重大研究成果)，但我会尽可能简单地解释它。让我们从技术组件开始，然后从那里继续。我不会试图解释神经网络，因为这是已知的。如果你不确定它们是什么，想要一本<a class="ae mz" rel="noopener" target="_blank" href="/how-to-build-a-simple-artificial-neural-network-with-go-ac2e8c49ae37">快速入门</a>，我不久前写了一篇关于它的文章。</p><h2 id="7e1a" class="na md iu bd me nb nc dn mi nd ne dp mm ks nf ng mo kw nh ni mq la nj nk ms nl bi translated">变压器</h2><p id="c9ef" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">变压器是一个神经网络。斯坦福大学的研究人员在2021年8月的一篇论文<a class="ae mz" href="https://arxiv.org/pdf/2108.07258.pdf" rel="noopener ugc nofollow" target="_blank">中将变形金刚<em class="lf">基金会模型</em>称为</a>，因为他们看到它们正在推动人工智能的范式转变。</p><p id="263e" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">神经网络已经被用于分析复杂的数据类型，如图像、视频、音频和文本，并且不同类型的神经网络被设计用于不同类型的数据。例如，CNN(卷积神经网络)经常用于图像数据。</p><p id="e89f" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">不幸的是，还没有一个真正好的用于语言和文本的神经网络，尽管rnn(递归神经网络)也经常被使用(在transformers之前),尽管它们很难训练并且在处理长段落时有问题。</p><p id="ac12" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">transformer神经网络是由谷歌和多伦多大学的研究人员在2017年开发的，最初是为语言任务设计的。Transformers易于训练，因为它可以有效地并行化，并且它有效地取代了RNNs，成为最终用于许多事情的主要神经网络。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj nm"><img src="../Images/a3c5b9fcac494b7578eb4a9399da1329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oaafLNojDhFeqYcIMOQrnw.jpeg"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated">多伦多大学(<a class="ae mz" href="https://commons.wikimedia.org/wiki/File:University_of_Toronto.jpg" rel="noopener ugc nofollow" target="_blank">维基媒体</a>中的知识共享)</p></figure><p id="98bf" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">今天最著名的变形金刚之一是OpenAI的GPT-3，它是一个巨大的模型，在45 TB的文本数据上进行训练，几乎包括整个公共网络。</p><p id="5e0c" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">虽然它最初是为自然语言处理(即语言和文本)而设计的，但它已经用于许多其他事情，包括文本到图像生成器。如你所见，变形金刚无处不在。事实上，这里的其他技术要么完全是变压器，要么将变压器作为模型的一部分。</p><h2 id="13fa" class="na md iu bd me nb nc dn mi nd ne dp mm ks nf ng mo kw nh ni mq la nj nk ms nl bi translated">夹子</h2><p id="fd9b" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated"><a class="ae mz" href="https://openai.com/blog/clip/" rel="noopener ugc nofollow" target="_blank"> CLIP(对比语言-图像预训练)</a>是一个神经网络，它识别图片中的对象，并提供文本片段来描述它们。这听起来像你的老式图像分类器，但它比那更强大。如果对标记数据进行训练，您习惯的图像分类器可以识别图片中的对象，如果对象不符合任何类别，则不会被识别。</p><p id="b111" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">另一方面，CLIP不是使用带标签的图像数据集训练的，而是来自互联网上的4亿张图像及其文本描述。因此，它不按类别识别，而是从单词列表中提供图像的文本片段。</p><p id="63ee" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">CLIP还创建了一种图像-文本字典，允许图像和文本之间的翻译，这对于文本到图像的人工智能模型非常有帮助。CLIP本身使用两种不同的转换器作为编码器——图像编码器是视觉转换器，而文本转换器是GPT-2。</p><h2 id="60a6" class="na md iu bd me nb nc dn mi nd ne dp mm ks nf ng mo kw nh ni mq la nj nk ms nl bi translated">VQGAN</h2><p id="3e71" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">VQGAN(矢量量化生成对抗网络)是另一种类型的神经网络，由海德堡大学的研究人员在2020年首次开发。它由一个获取一组图像来学习特征的<a class="ae mz" href="https://wiki.pathmind.com/generative-adversarial-network-gan" rel="noopener ugc nofollow" target="_blank"> GAN(生成对抗网络)</a>和一个获取序列来学习远程交互的转换器组成。</p><p id="a387" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">GANs是一种有趣的机器学习技术，它让两个神经网络相互竞争，这是一场永无止境的争霸赛。其中一个神经网络称为生成器，另一个称为鉴别器。生成器生成模拟真实数据的数据，而鉴别器尝试从生成的数据中识别真实数据。本质上，GANs创建它们自己的训练数据，生成器和鉴别器之间的反馈回路产生越来越好的结果。</p><h2 id="0e0f" class="na md iu bd me nb nc dn mi nd ne dp mm ks nf ng mo kw nh ni mq la nj nk ms nl bi translated">巴特</h2><p id="7c56" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated"><a class="ae mz" href="https://arxiv.org/abs/1910.13461" rel="noopener ugc nofollow" target="_blank"> BART(双向自回归变压器)</a>是由脸书人工智能研究人员创建的神经网络，结合了谷歌的BERT和开放人工智能的GPT技术。</p><p id="c35b" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">BERT(变压器的双向编码器表示)的定向方法适用于下游任务，如需要整个序列信息的分类，但不适用于生成数据仅依赖于先前生成的数据的生成任务。GPT的单向自动回归方法对文本生成很好，但对需要整个序列信息的任务就不太好了。</p><p id="50e9" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">巴特把伯特的编码器和GPT的解码器结合在一起，结合了两者的优点。这对于文本生成和文本理解都非常有用。</p><h2 id="ce48" class="na md iu bd me nb nc dn mi nd ne dp mm ks nf ng mo kw nh ni mq la nj nk ms nl bi translated">传播</h2><p id="87eb" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated"><a class="ae mz" href="https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/" rel="noopener ugc nofollow" target="_blank">扩散</a>是一种生成式机器学习技术，这意味着他们创建的数据看起来像他们接受训练的数据。例如，稳定扩散使用3个神经网络、自动编码器和U-Net以及CLIP。</p><p id="494d" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">该模型的主要思想是，它获取一幅图像，并对其进行随机置乱，直到它变成纯粹的噪声。然后，它训练一个神经网络，一步一步地将其改变回类似原始图像的东西。这有效地从随机性中生成图像，当给定随机样本时，它甚至可以生成新的图像！</p><h1 id="4922" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">模型</h1><p id="4cba" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">在几个段落中塞进了大量的缩写词和技术！希望对这些技术的作用有一个更清晰的了解，让我们看看如何使用这些技术将模型放在一起。先从OpenAI的机型说起吧。</p><p id="73af" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">Dall-E基本上是GPT-3的120亿参数版本，一个变形金刚模型，用文本-图像对的数据集训练。</p><p id="ae08" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">GLIDE(用于生成和编辑的引导语言到图像扩散)是具有35亿个参数的剪辑引导扩散模型。</p><p id="496a" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">Dall-E 2与Dall-E截然不同，更类似于GLIDE。和GLIDE一样，比Dall-E小，只有35亿个参数。它还使用了一个扩散模型，由剪辑模型指导，然后用6.5亿个文本图像对进行优化、精炼和训练。它将从Dall-E、CLIP和GLIDE中学到的概念整合在一起。</p><p id="5bc1" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">VQGANs擅长生成看起来彼此相似的图像，而CLIP则决定提示与图像的匹配程度。艺术家兼数学家凯瑟琳·克劳森(Katherine Crowson)受瑞安·默多克(Ryan Murdoch)的启发，将这两个模型结合在一起，这一想法首次出现在谷歌的Colab笔记本上。本质上，VQGAN生成候选图像，并对它们进行剪辑排序，直到生成可接受的候选图像。这变得非常流行，有几个模型使用这种方法，并有自己的调整。例如，NightCafe使用VQGAN+CLIP作为其人工智能文本到图像生成器的基础。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div class="gi gj nn"><img src="../Images/9162b5cfacd86fbc4574e1843d9255c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*hf_BQTrS6I8m4NE7qy-Cng.jpeg"/></div><p class="ls lt gk gi gj lu lv bd b be z dk translated">由NightCafe使用VQGAN+剪辑创建，带有文本提示“新加坡滨海湾金沙日落油画，作者詹姆斯·格尼”</p></figure><p id="0558" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">另一个使用VQGAN+CLIP的型号是我前面提到的Dall-E mini。它基本上是VQGAN + CLIP，但是使用BART对VQGAN的文本提示进行编码。</p><p id="6bcf" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">稳定扩散，顾名思义用的是扩散模型。事实上，扩散模型越来越多地被许多公司用作其人工智能模型的基础。例如，Midjourney也使用扩散模型。稳定扩散是潜在扩散模型(LDM)的开源实现，在256x256图像上进行预训练，然后在512x512图像上进行微调，所有这些都来自<a class="ae mz" href="https://laion.ai/blog/laion-5b/" rel="noopener ugc nofollow" target="_blank"> LAION-5B </a>数据库的子集。</p><p id="ba6d" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">这是当前技术和模型的快速浏览。</p><h1 id="2e3a" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">未来如此光明？</h1><p id="88bd" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">所有这些技术都很吸引人，但它们也会对现实世界产生影响。</p><p id="5064" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">2022年8月，Jason Allen凭借一件名为<em class="lf">Thétre D ' opéra Spatial</em>的作品赢得了<a class="ae mz" href="https://coloradostatefair.com/wp-content/uploads/2022/08/2022-Fine-Arts-First-Second-Third.pdf" rel="noopener ugc nofollow" target="_blank">科罗拉多州博览会的数字艺术竞赛</a>。然而，杰森·艾伦不是艺术家。这张图片是使用Midjourney创建的——它接受了艾伦的文本提示，并创建了一个令人惊叹的作品，为他赢得了第一个价格。</p><p id="f192" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">不出所料，它引发了对作弊、人工智能产生艺术的伦理的指责，并声称这本质上是一种高科技形式的抄袭。</p><p id="121b" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">最后是可以理解的。我自己也走了一半路程，在几分钟内完成了这件作品。如果你熟悉亨利·马蒂斯的作品，这应该会让你想起它。我只用了几分钟就想出了这个。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj no"><img src="../Images/81fe9c508592b383b10fe1be20c78055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zbMQAHio4qBlFRNpkAbd5w.png"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated">中途创作——“马蒂斯绘画风格的新加坡滨海湾金沙日落”</p></figure><p id="8875" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">当然，新的艺术制作技术总是有争议的。当时的许多画家和艺术家都对照相机的发明感到愤怒。法国诗人兼艺术评论家夏尔·波德莱尔这样评价摄影:“T2入侵了艺术的领地，成为了艺术最大的敌人”。然而今天，摄影是一种完全不同的艺术形式。</p><p id="3b77" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">就在几个月前，有人在MakeUseOf杂志上写了一篇关于人工智能文本到图像生成器的文章，他用这句话结束了这篇文章。</p><blockquote class="lw lx ly"><p id="b633" class="kj kk lf kl b km kn jv ko kp kq jy kr lz kt ku kv ma kx ky kz mb lb lc ld le in bi translated">就像人工智能写作工具一样，虽然最终产品看起来足够“真实”，就像是由人类制作的一样，但它仍然错过了一些东西。艺术家可以添加创意、情感和自我定义的风格，使艺术作品个性化和原创。也许几年后，人工智能也可以进化成那样，但艺术家的工作目前是安全的。</p><p id="6260" class="kj kk lf kl b km kn jv ko kp kq jy kr lz kt ku kv ma kx ky kz mb lb lc ld le in bi translated">【https://www.makeuseof.com/ai-text-to-art-generators/<em class="iu"/><em class="iu">(2022年6月11日出版)</em></p></blockquote><p id="befb" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">现在看来有点过时了。毕竟，如果一个人工智能模型能想出上面这些图片，艺术家和插画师的工作有多安全？就像艾伦在接受《纽约时报》采访时说的那样:“艺术已经死了，伙计。结束了。人工智能赢了。人类输了。”</p><h1 id="b9d2" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">冰的故事</h1><p id="abe9" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">在我职业生涯的早期，我听过盖伊·川崎的一次演讲，他是苹果公司的传奇人物和传道者。他讲述了采冰行业的故事(克里斯托弗在迪士尼电影《冰雪奇缘》开始时所做的事情)，并谈到技术变革通常不是进化性的，而是革命性的。</p><p id="f9c0" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">在19世纪和20世纪早期，斯堪的纳维亚国家和北美有一个大型的采冰工业。大块的冰块从湖泊和河流中切割下来，储存在冰库中，然后运送到温暖国家或夏季的家庭和企业。在19世纪90年代的巅峰时期，美国冰贸易雇佣了大约90，000人，并将冰出口到远至香港、东南亚、菲律宾和波斯湾。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj np"><img src="../Images/ff513559e677e3ca7c6f97cfe917b5a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JCet7W5IBBLDVM5vce9jFQ.jpeg"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated"><a class="ae mz" href="https://en.wikipedia.org/wiki/Ice_cutting#/media/File:Cutting_Ice_on_the_river.jpg" rel="noopener ugc nofollow" target="_blank">19世纪90年代，加拿大安大略省多伦多市的切冰工人(公共领域)</a></p></figure><p id="23ae" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">然而，在20世纪早期，事情发生了迅速的变化。生产人造冰的冰工厂开始取代天然冰贸易，加上暖冬期间天然冰的稀缺、对天然冰污染的担忧以及来自冰工厂的低成本竞争，促使其最终消亡。在第一次世界大战后的几年里，整个冰贸易崩溃了，随之而来的还有工业和采冰工作。</p><p id="80ad" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">第二个变化发生在制冰厂开始接管天然冰贸易的时候。1913年，第一台家用电冰箱DOMELRE(家用电冰箱)发明并出售。它是革命性的，也是成功的，甚至包括自动温度控制和引入冰块冷冻托盘等创新。到1944年，85%的美国家庭拥有冰箱。正如制冰厂取代了冰贸易一样，家用冰箱取代了家庭从制冰厂购买冰的需求。</p><figure class="lh li lj lk gu ll gi gj paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><div class="gi gj nq"><img src="../Images/d3fa7c2bd1396107d2d0174e273740e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I596l0y-8WB4DdFfr0tt2A.jpeg"/></div></div><p class="ls lt gk gi gj lu lv bd b be z dk translated"><a class="ae mz" href="https://www.sutori.com/en/item/1901-the-ice-factory-produces-about-305-tonnes-of-ice-per-day-equivalent-to" rel="noopener ugc nofollow" target="_blank">格里姆斯比冰厂的冰厂工人</a></p></figure><p id="bc41" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">不幸的是，没有一家冰贸易公司从收获和销售冰转向经营冰厂，同样，也没有一家冰厂公司转向制造冰箱。冰收割机没有成为冰厂工人，冰厂工人没有成为冰箱厂工人。</p><p id="455d" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">正如摄影改变了绘画行业，照片编辑改变了艺术和摄影行业，人工智能文本到图像生成器形式的生成艺术也将改变艺术和插图行业。没有人真正知道当前的艺术家和插画师有多擅长曲线跳跃。</p><h1 id="c093" class="mc md iu bd me mf mg mh mi mj mk ml mm ka mn kb mo kd mp ke mq kg mr kh ms mt bi translated">下一跳？</h1><p id="77ba" class="pw-post-body-paragraph kj kk iu kl b km mu jv ko kp mv jy kr ks mw ku kv kw mx ky kz la my lc ld le in bi translated">transformer模型是为了解决2017年的一个自然语言处理问题而创建的。2020年，OpenAI发布了非常受欢迎的GPT-3模型，使用了变形金刚模型。这在2021年发展成用于软件代码生成的Codex(现在用于Github Copilot)，也发展成用于文本到图像生成的Dall-E (2021)和Dall-E 2 (2022)模型。</p><p id="adb6" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">文本到图像似乎不太可能是最后的领域。有视频、音频和<a class="ae mz" href="https://www.discovermagazine.com/technology/the-ai-popstar-learning-to-sing-like-a-human" rel="noopener ugc nofollow" target="_blank">音乐(有人想唱歌吗？)</a>前方还有更多。我们正处于激动人心的时代，但也有一些可怕的时代。</p><p id="feb2" class="pw-post-body-paragraph kj kk iu kl b km kn jv ko kp kq jy kr ks kt ku kv kw kx ky kz la lb lc ld le in bi translated">视频杀死了电台明星，也许人工智能正在杀死艺术家和插画师。下一个是谁？</p></div></div>    
</body>
</html>