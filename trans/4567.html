<html>
<head>
<title>Efficient memory management when training a deep learning model in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中训练深度学习模型时的高效内存管理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/efficient-memory-management-when-training-a-deep-learning-model-in-python-fde9065782b7#2022-10-11">https://towardsdatascience.com/efficient-memory-management-when-training-a-deep-learning-model-in-python-fde9065782b7#2022-10-11</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="59df" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用Tensorflow、Python和迭代器在小型计算机上使用大数据</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/43f5631a5a02b905b7fae0561eed241b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jgAEQpB6iy9_OQglcdYqWw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">西西弗斯的作品；由维基共享许可授权<a class="ae ky" href="https://commons.wikimedia.org/wiki/File:Friedrich_John_nach_Matth%C3%A4us_Loder_Sisyphus_ubs_G_0825_II.jpg" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/Wiki/File:Friedrich _ John _ nach _ Matth % C3 % A4us _ Loder _ Sisyphus _ UBS _ G _ 0825 _ ii . jpg</a></p></figure><p id="db67" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当前商业世界中的数据量每天都在增加。有新的数据源要合并，有更多的行要追加，有新的列要连接。</p><p id="7cd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，对于典型的数据科学家或机器学习工程师来说，购买新笔记本电脑或计算机或扩展云服务的速度通常赶不上新数据进入的速度。一个人的硬件可能感觉像西西弗斯:试图保持岩石不压碎他(计算机中的内存不会填满)，同时仍然保持他的工作(训练深度学习模型)。</p><p id="cee9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将提出一个关于如何考虑将大量数据放入少量RAM的逻辑。</p><p id="a1f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有的代码和例子都可以在我的回购中找到:</p><div class="lv lw gp gr lx ly"><a href="https://github.com/Eligijus112/big-data-ml" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">GitHub - Eligijus112/big-data-ml:展示如何使用TF数据生成器的项目</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">展示如何使用TF数据生成器和Keras在大数据上拟合模型的项目。下载一大块…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">github.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="6535" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将尝试解决的目标是创建一个模型，使用以下功能预测纽约市出租车司机的车费金额</p><ul class=""><li id="f5cc" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">拾取日期时间</li><li id="1aba" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">出租车里的人数</li><li id="cb0f" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">上车点和目的地之间的距离</li></ul><p id="03f3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据已在Kaggle竞赛中提供，包含约5500万行。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/188a8f41ba75a447d6859154f6edb87b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtKq00_6FKPu6hxzmMfItA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据片段；作者照片</p></figure><p id="0c90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用以下函数对此数据集进行一些特征工程:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提货日期转换；作者代码</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">距离计算；作者代码</p></figure><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">虚拟变量创建；作者代码</p></figure><p id="616f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">将这些函数应用于数据框后，我们将使用以下公式对票价金额进行建模:</p><ul class=""><li id="e016" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><strong class="lb iu">乘客数量</strong></li><li id="96ef" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">每周提货日的虚拟变量</strong></li><li id="36ab" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">行驶距离</strong></li><li id="ab9c" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">拾取时一天中某小时的Sin和Cos循环转换</strong></li><li id="d037" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu">拾取时一年中某一天的Sin和Cos循环转换</strong></li></ul><p id="ce80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要了解更多关于周期性特征的信息，请访问以下资源:</p><div class="lv lw gp gr lx ly"><a href="https://feature-engine.readthedocs.io/en/1.3.x/user_guide/creation/CyclicalFeatures.html" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">周期性特征- 1.3.0</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">从数字变量中创建2个新特征，更好地捕捉原始变量的循环性质…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">feature-engine.readthedocs.io</p></div></div><div class="mh l"><div class="nl l mj mk ml mh mm ks ly"/></div></div></a></div><p id="8062" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">模型中共有<strong class="lb iu"> 18 </strong>个特征。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="1828" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便说一句，要更好地理解数据并向伟大的数据科学家社区致敬，请访问本笔记本:</p><div class="lv lw gp gr lx ly"><a href="https://www.kaggle.com/code/breemen/nyc-taxi-fare-data-exploration" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">纽约市出租车费用-数据探索</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自纽约市出租车费用预测的数据</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.kaggle.com</p></div></div><div class="mh l"><div class="nm l mj mk ml mh mm ks ly"/></div></div></a></div></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="2a25" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章的标题中，有一个术语叫做<em class="nn">内存管理</em>。当谈到内存和深度学习时，人们要么指图形处理单元的内存(<strong class="lb iu"> GPU) </strong>，要么指随机存取存储器(<strong class="lb iu"> RAM) </strong>。我将探索RAM部分，以及如何使用大数据不堵塞计算机内存。</p><p id="6559" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在使用Tensorflow的典型深度学习模型训练中，记忆方面的训练可以表示为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/cd7c5fcc16bff3b6d3e4b5e9642cde61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y1NJygOsOfN-HWXKGjWDNQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">记忆和深度学习；作者照片</p></figure><p id="5efc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们启动一个Python脚本并使用TensorFlow定义一个模型时，我们会立即占用RAM中的一些空间。这是我们不能走捷径的部分，因为为了让训练程序工作，整个模型对象需要存在于内存中，并且可以被Python的运行进程快速访问。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">纽约市数据的深度学习模型；作者代码</p></figure><p id="6153" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用内存分析器，我们可以运行上面的脚本:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="783e" class="nu nv it nq b gy nw nx l ny nz">python -m model</span></pre><p id="bf8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">并得到如下细分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/5302290fe6c4387aaa4a42359b8091ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_e8viMgQECGiPUCJQ3NfyQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">内存使用细分；作者照片</p></figure><p id="f443" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">甚至在调用函数之前，Python已经通过加载函数<strong class="lb iu"> <em class="nn"> (Keras，TensorFlow，memory_profiler)上面定义的包在我们的系统中预留了391 MB的RAM。</em>T9】</strong></p><p id="e9e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第38行，当模型启动时，RAM使用量增加了大约600 MB。即使是这个简单的一个隐藏层模型也要占用超过半个GB的内存。</p><p id="9b8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，即使在训练开始之前，没有数据被加载到存储器中，也需要至少1 GB的RAM来进行任何类型的训练。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="2f58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们运行下面的代码，它将数据集的所需行加载到内存中，训练一个模型并返回它。运行包含100k行的脚本的命令是:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="06e9" class="nu nv it nq b gy nw nx l ny nz">python -m train_whole_data --rows 100000</span></pre><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">以直截了当的方式进行培训；作者代码</p></figure><p id="1841" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">内存分析器返回以下结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/3e64aed9df5f86c1539033967ea00359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PFd3blgeKZYgkjJLprtufw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">100k行的内存使用情况；作者图片</p></figure><p id="9190" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们从第71行看到的，数据占用了大约33 MB的RAM。模型训练需要额外的74 MB。所有其他RAM的使用都是由于加载了额外的包。让我们看看一百万行会发生什么:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="0445" class="nu nv it nq b gy nw nx l ny nz">python -m train_whole_data --rows 1000000</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/602e659a41680f6468784bff2917fd37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tQvITaLln9R8WE9XdiWLaQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用1000 000行的内存使用量；作者照片；</p></figure><p id="dd3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">增加10倍的行数会使整体RAM使用量增加1.5倍。让我们分析一下下面的情节:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/ed227322bab52b2b6be6ba3417f65707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N9-DCpZYuL3pEd-E6rQcMw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">RAM使用与行数的关系；作者照片</p></figure><p id="31c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当行数增加时，内存使用量呈线性增长。试图用所有数据(大约5400万行)来拟合一个模型会导致代码使用超过12GB的RAM！</p><p id="f396" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">到目前为止，我们所做的过程可以总结在下图中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/d2042d8afd3df49ecf19e933d3be35a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5LON0Px8PMkCOG4M8fXk8w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">填满羊肉饼；作者照片</p></figure><p id="69dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RAM空间是有限的，取决于机器的规格。当行数增加时，加载到RAM的数据和用于模型定型的RAM使用量(<strong class="lb iu"> X </strong>和<strong class="lb iu"> Y </strong>变大)都会增加。</p><p id="3b52" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">把所有东西都存储在RAM里最大的好处就是训练的整体速度快。这是因为运行数据加载和训练模型的Python进程获得了它自己的专用RAM空间，并且从那里向训练加载数据只需要几分之一秒的时间。</p><p id="8f01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可以看到，我们最终将达到一个阈值，在该阈值处，训练脚本将被终止，因为我们将使用系统中的每一位RAM。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="3da7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了用几乎<strong class="lb iu">任何</strong>数量的数据训练一个模型，我们将使用<strong class="lb iu">一个数据生成器序列(从这里开始，我将数据生成器序列简单地称为数据迭代器)</strong>。</p><p id="e543" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">形式上，编程中的迭代器是一个有两种方法的对象:</p><ul class=""><li id="8caa" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><strong class="lb iu"> hasNext() </strong> —返回一个布尔值，判断当前活动迭代项旁边是否有元素。<em class="nn">假</em>表示迭代应该停止。</li><li id="5ccf" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> next() </strong> —返回迭代中使用的下一项。</li></ul><p id="400d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在为TensorFlow定义数据生成器时，我们需要使用以下类:</p><div class="lv lw gp gr lx ly"><a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence" rel="noopener  ugc nofollow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">TF . keras . utils . sequence | tensor flow v 2 . 10 . 0</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">适合数据序列(如数据集)的基本对象。</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">www.tensorflow.org</p></div></div></div></a></div><p id="2b4b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要在类中定义的方法有:</p><ul class=""><li id="b676" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated"><strong class="lb iu"> __init__() </strong> —对象构造函数。</li><li id="9bc6" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> __len__() </strong> —我们迭代器中的总项数。</li><li id="17f8" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated"><strong class="lb iu"> __getitem__() </strong> —获取迭代中的下一项。</li></ul><p id="a796" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">__ <strong class="lb iu"> getitem__() </strong>方法等价于形式定义中的<strong class="lb iu"> next() </strong>方法。</p><p id="f622" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每次迭代结束时调用__ <strong class="lb iu"> len__() </strong>方法，一个单独的规则或者停止迭代器或者继续它。这模仿了<strong class="lb iu"> hasNext() </strong>方法背后的逻辑。</p><p id="65bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是这个项目中使用的数据迭代器:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">纽约市数据的数据生成器；作者代码</p></figure><p id="d598" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">构造函数中的第一个参数是使用Pandas库中的<strong class="lb iu">read _ CSV(iterator = True)</strong>方法获得的。这是一种内部Pandas数据框方法，可以在读取具有分区的数据时使用。在读取到计算机内存时，CSV文件可以被拆分为单独的行，而无需将整个数据集加载到RAM中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/ed87494142096866e91ed1010c4a00de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gI6pFnsqLjpv5GmqRcBMSg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">对块的引用保存在内存中；按作者分类的图表</p></figure><p id="b349" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每次调用<strong class="lb iu"> __getitem__() </strong>方法时，都会从csv_generator对象中调用一个块到内存中。然后对块进行预处理，并从中创建用于深度学习的<strong class="lb iu"> x </strong>和<strong class="lb iu"> y </strong>矩阵。</p><p id="f0d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">x和y矩阵被馈送到TensorFlow模型，并且在用它们完成所有训练之后，它们被从存储器中删除。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/382506f354ae655543e119f6f0a57ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nIoYis2tzSl1DZtKcwV_YQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用迭代器模式训练；按作者分类的图表</p></figure><p id="b9a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当数据迭代器停止时，训练完成。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="c191" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用迭代器训练模型的完整python代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nj nk l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用迭代器的完整管道；作者代码</p></figure><p id="5a97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们试着运行有一百万行的代码:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="3bad" class="nu nv it nq b gy nw nx l ny nz">python -m train_iterator --rows 1000000</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/716c98c4f230bd4afd6a22a2c9a887ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMWCobJQeI_neIq56GS-Rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用迭代器1百万行；作者图片</p></figure><p id="28a4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如我们从第126行看到的，创建一个CSV生成器来遍历整个数据集只需要6.4 MB的RAM。回想一下，将整个数据集加载到内存需要大约<strong class="lb iu"> 12000 MB </strong>的内存。内存的总使用量大约为2100 MB。</p><p id="03a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用整个数据集运行脚本:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="71d0" class="nu nv it nq b gy nw nx l ny nz">python -m train_iterator </span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/2c0cc929a27a759e7d3034105ae139c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mtJaLUW4YsU6PqIGadcYNw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用迭代器对完整数据集进行训练；作者照片</p></figure><p id="41b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">令人惊讶的是，即使添加了54倍的数据，整体RAM消耗几乎保持不变(从2191MB到2373MB)！这可以用图表来解释:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/c841233f34a8ce57fd369d961caf721a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qurL-j5nIq1sMxuTQQh6ng.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">有效的语块训练；按作者分类的图表</p></figure><p id="af0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SSD(或数据库或任何其他存储)中的数据需要分成分区(块)。有效的训练算法可以总结如下:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="c3ea" class="nu nv it nq b gy nw nx l ny nz">* Split the data into<strong class="nq iu"> M</strong> chunks. </span><span id="b74e" class="nu nv it nq b gy ok nx l ny nz">* Initiate an empty model in memory. </span><span id="7c2e" class="nu nv it nq b gy ok nx l ny nz">* For <strong class="nq iu">m</strong> in <strong class="nq iu">M</strong> chunks do:</span><span id="92f8" class="nu nv it nq b gy ok nx l ny nz">  1) Load the data of chunk <strong class="nq iu">m</strong> to memory </span><span id="ca70" class="nu nv it nq b gy ok nx l ny nz">  2) Train the model using that chunk</span><span id="61d5" class="nu nv it nq b gy ok nx l ny nz">  3) The model weights are saved and the chunk <strong class="nq iu">m</strong> is removed from memory. </span></pre><p id="c10f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的算法让我们在相对低内存的设备上使用非常大的数据文件来训练模型。</p><p id="d2e1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种方法的缺点是将数据块从本地存储转换到RAM会产生瓶颈，从而减慢整个训练过程。</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="aa9c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，在训练神经网络的速度和将大量数据放入计算机内存的能力之间存在权衡:</p><ul class=""><li id="6f5a" class="mu mv it lb b lc ld lf lg li mw lm mx lq my lu mz na nb nc bi translated">RAM中的数据越多，训练速度越快。</li><li id="40a9" class="mu mv it lb b lc nd lf ne li nf lm ng lq nh lu mz na nb nc bi translated">RAM中的数据越少，训练模型所需的资源就越少。</li></ul><p id="6a01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我展示了如何使用这两种方法，介绍了TensorFlow提供的数据迭代器的概念，并展示了所有代码示例。</p><p id="1367" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">编码快乐！</p></div><div class="ab cl mn mo hx mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="im in io ip iq"><p id="64a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]纽约市出租车费用预测；<br/>网址:<a class="ae ky" href="https://www.kaggle.com/competitions/new-york-city-taxi-fare-prediction/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/harlfoxem/housesales prediction？资源=下载</a></p><p id="64c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">执照:<a class="ae ky" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/publicdomain/zero/1.0/</a></p></div></div>    
</body>
</html>