<html>
<head>
<title>Unlock the Latest Transformer Models with Amazon SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用亚马逊 SageMaker 解锁最新的变压器型号</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/unlock-the-latest-transformer-models-with-amazon-sagemaker-7fe65130d993#2022-12-06">https://towardsdatascience.com/unlock-the-latest-transformer-models-with-amazon-sagemaker-7fe65130d993#2022-12-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ba9b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">关于扩展和定制 AWS 深度学习容器的快速教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b476512c85fb2d73724075f3bd4567b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a2GMGvxtO_jbJtSeA4BJeQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者使用 Midjourney 制作</p></figure><h1 id="24a9" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">这是怎么回事？</h1><p id="a319" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">由于方便易用，AWS 深度学习容器(DLC)已经成为亚马逊 SageMaker (SM)上训练和部署自然语言处理(NLP)模型的热门选择。然而，有时预构建的 DLC 中没有最新版本的 Transformers 库。在这篇博文中，我们将扩展这些 DLC，在 AWS 上训练和部署最新的拥抱脸模型。无论你是 DLCs 新手还是有经验的用户，这篇文章都将为在 AWS 上运行拥抱人脸模型提供有价值的见解和技术。</p><p id="b81a" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">本教程的代码可以在这个<a class="ae mo" href="https://github.com/marshmellow77/sm-extend-container" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中获得。</p><h1 id="5a73" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">为什么这很重要？</h1><p id="fcfa" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">亚马逊 SageMaker 是一个运行 AI 模型的流行平台，但运行最新的变形金刚模型(例如<a class="ae mo" href="https://huggingface.co/openai/whisper-base" rel="noopener ugc nofollow" target="_blank">耳语</a>、<a class="ae mo" href="https://huggingface.co/bigscience/bloom" rel="noopener ugc nofollow" target="_blank">布鲁姆</a>)需要最新版本的<a class="ae mo" href="https://github.com/huggingface/transformers" rel="noopener ugc nofollow" target="_blank">变形金刚库</a>。然而，AWS 上最新的可用 DLC 仅支持版本 4.17，而在撰写本文时，最新版本是 4.25.1。当试图将最新的 DLC 用于不受支持的型号时，用户会遇到一条错误消息，例如，参见拥抱脸(HF)论坛上的这个<a class="ae mo" href="https://discuss.huggingface.co/t/deploying-open-ais-whisper-on-sagemaker/24761/1" rel="noopener ugc nofollow" target="_blank">主题</a></p><p id="6ccc" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这个问题的一个解决方法是将 requirements.txt 文件注入到模型中，但是这可能是一个缓慢而乏味的过程。它需要下载模型，添加 requirements.txt 文件，打包模型，并上传到 S3，对于大型模型来说，这可能需要几个小时。在这篇博文中，我们将利用 AWS 的预建 DLC 可以扩展这一事实，从而为用户节省这一变通办法，并因此在他们想要培训或部署新模型时节省许多时间。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="cb1c" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">如何在 SageMaker 上部署 Transformer 模型</h1><p id="9368" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在 SM 上部署 Transformer 模型通常是一件轻而易举的事情，尤其是如果您想使用预先构建的模型而无需进一步培训的话。在这种情况下，我们可以将模型直接从 HF 模型中心部署到 SM:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="4362" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">以下是运行这段代码时在后台发生的情况:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/247e3534e0f5812c277750317ed4b481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eT4-MoiGdoAyZRrGEB8_mA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bb3f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">一旦执行了 deploy()命令，SM 就会启动一个 EC2 实例，并从指定的 DLC 中获取映像，这是由 transformers 和 pytorch 库的版本号决定的。我们可以在这里找到可用 DLC <a class="ae mo" href="https://huggingface.co/docs/sagemaker/reference#inference-dlc-overview" rel="noopener ugc nofollow" target="_blank">的列表——这些是从一个特定的</a><a class="ae mo" href="https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-inference-containers" rel="noopener ugc nofollow" target="_blank"> AWS 账户</a>中获取的，并且是公开可用的，参见<a class="ae mo" href="https://github.com/aws/deep-learning-containers/tree/master/huggingface/pytorch/inference/docker/1.10/py3" rel="noopener ugc nofollow" target="_blank">这个例子</a>。</p><p id="08bc" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">正如我们在这个<a class="ae mo" href="https://huggingface.co/docs/sagemaker/reference#inference-dlc-overview" rel="noopener ugc nofollow" target="_blank">列表</a>中看到的，DLCs 中最新可用的变形金刚版本是 4.17，但许多型号将需要比这更高的版本。</p><h1 id="f3ad" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">最新型号变压器的问题是</h1><p id="e665" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">当我们试图使用最新的 DLC 运行需要高于 4.17 版本的模型时，我们可以看到这一点。部署将会成功，但是当我们尝试使用该模型时，我们会收到以下错误消息:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/2473cd07f967530844fb18c3901cbbf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q5ll6lWjWLRvhggKpM89Dg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="2999" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在 Cloudwatch 日志中，我们可以看到更多信息:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/9b54739266a807e538d242b62d611e54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*xHCvwzsttbgVrqPGlj7J0w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="66f5" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这意味着我们试图通过最新的 DLC 部署的模型(在这种情况下是 BLOOM)是不可能的。</p><h1 id="6ee4" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">解决方法—注入一个 requirements.txt 文件</h1><p id="9461" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">如上所述，有一个解决方法——<a class="ae mo" href="https://github.com/aws/sagemaker-huggingface-inference-toolkit#-user-defined-codemodules" rel="noopener ugc nofollow" target="_blank">HF SM 推理工具包</a>允许定制推理代码，以及通过 requirements.txt 文件指定所需的附加库的可能性。我们可以通过将最新的 transformers 版本添加到 requirements.txt 文件来使用这种机制，如下所示:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="d522" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">然而，要将这个 requirements.txt 文件注入到模型中，需要一些额外的步骤:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/f5ea36273ecca0f40ec193da90165e42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wWKyDhGk5txel6nhCzGFHw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="c2d1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">在这种情况下，我们首先需要从 HF 模型中心手动下载模型。然后，我们将 requirements.txt 文件添加到模型目录中，并将其打包。然后，模型需要上传到 S3 桶。然后，最后，我们可以部署模型，将端点指向模型的 S3 位置。当启动端点的 EC2 实例时，将读取 requirements.txt 文件并安装最新的 transformers 版本。</p><p id="bf5d" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">如果这是一个相对较小的模型，这是繁琐的，但不会花费太长时间。然而，如果这是盛开的模式，整个过程可能需要 12 个小时(相信我，我试过了😕)</p><h1 id="03f5" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">解决方案—扩展预构建的数据链路连接器</h1><p id="c31f" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">相反，我们希望直接从 HF 模型中心进行部署，特别是在不需要定制代码或者需要任何模型微调的情况下。在这种情况下，我们可以编写一个 Docker 文件，首先从公共 AWS ECR 中提取最新的 DLC，然后添加我们自己的要求，在这种情况下，只需一个“pip install”命令即可更新到最新的 transformers 版本:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="6696" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">然后，我们可以运行<a class="ae mo" href="https://docs.aws.amazon.com/sagemaker/latest/dg/prebuilt-containers-extend.html" rel="noopener ugc nofollow" target="_blank">官方 AWS 教程</a>来扩展 DLCs，我们只需要确保我们调整了命名，并且我们运行该脚本的角色拥有读取和写入 ECR 服务的权限:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="b02f" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">几分钟后这个脚本完成后，我们应该会在 ECR 中看到新的 DLC。</p><h1 id="6b88" class="kv kw iq bd kx ky kz la lb lc ld le lf jw lg jx lh jz li ka lj kc lk kd ll lm bi translated">测试新的数据链路连接器</h1><p id="f077" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">现在新的 DLC 已经准备好了，我们可以再次测试之前的部署，但是这次使用我们的扩展 DLC:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nb nc l"/></div></figure><p id="7b36" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">现在，当我们运行一个推理请求时，我们得到一个正确的响应:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/e9031f8ac61d39c67633c9108ae5659e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PWEJURjDsYoiCHBDyrpF-Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7968" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">这是现在在后台发生的事情:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/ad1ed6e53feb1b00a758fefa56b847fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08nG5cBHgfGgPIZ3flvzAg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="85a1" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">我们曾经努力扩展 DLC，但是现在，每当我们想要从 HF Model Hub 部署需要最新版本的 transformers 库的模型时，我们可以重用我们的 DLC，而不是 AWS 的官方 DLC🤗</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h1 id="33c2" class="kv kw iq bd kx ky mw la lb lc mx le lf jw my jx lh jz mz ka lj kc na kd ll lm bi translated">结论</h1><p id="a3a8" class="pw-post-body-paragraph ln lo iq lp b lq lr jr ls lt lu ju lv lw lx ly lz ma mb mc md me mf mg mh mi ij bi translated">在本教程中，我们扩展了 AWS 的官方 HF DLCs，将变压器库更新到许多新变压器型号所需的更高版本。通过这样做，我们创建了自己的可重用 DLC，使我们能够直接从 HF 模型中心进行部署，从而节省了我们数小时的繁琐工作。</p><p id="ef83" class="pw-post-body-paragraph ln lo iq lp b lq mj jr ls lt mk ju lv lw ml ly lz ma mm mc md me mn mg mh mi ij bi translated">注意，这篇博文主要关注的是扩展推理 DLC，然而，同样的想法也可以用于<a class="ae mo" href="https://huggingface.co/docs/sagemaker/reference#training-dlc-overview" rel="noopener ugc nofollow" target="_blank">训练 DLC</a>。</p></div></div>    
</body>
</html>