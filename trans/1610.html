<html>
<head>
<title>How to use XLNET from the Hugging Face transformer library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用来自拥抱脸变压器库的XLNET</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-xlnet-from-the-hugging-face-transformer-library-ddd0b7c8d0b9#2022-04-18">https://towardsdatascience.com/how-to-use-xlnet-from-the-hugging-face-transformer-library-ddd0b7c8d0b9#2022-04-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ccc2" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用XLNET从拥抱脸变压器库的三个重要任务</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/972e842f48116d5dac765f8b1a144df1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mFpPcPPyFmoMauUo"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@ahmed_rizkhaan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Ahmed Rizkhaan </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="1e17" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本文中，我将演示如何使用XLNET通过拥抱脸变压器库完成三项重要任务。我还将展示如何配置XLNET，这样，除了它被设计用来解决的标准任务之外，您还可以将它用于您想要的任何任务。</p><p id="ef5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，本文写于2022年4月，因此拥抱脸库的早期/未来版本可能会有所不同，本文中的代码可能无法工作。</p><h2 id="ed6c" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">XLNet快速回顾</h2><p id="cf06" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">XLNET是一个通用的自回归模型，它使用置换语言建模来创建单词的双向上下文化表示。值得注意的是，它建立在BERT transformer的弱点之上，并在许多任务上优于BERT，如问题回答、情感分析等。虽然BERT是一个非常强大和通用的转换器，但它的架构固有地具有两个弱点。首先，因为它使用屏蔽语言建模来生成单词的上下文化表示，所以它扭曲了输入，所以BERT真正使用屏蔽单词的方式是未知的。第二，当BERT屏蔽一个句子中的多个标记时，它不能捕获两个被屏蔽的标记之间的依赖关系，这两个标记可能拥有彼此的重要信息。XLNET相对于BERT的另一个主要的、强大的优势是，与具有512个令牌输入限制的BERT不同，XLNET是少数几个没有序列长度限制的模型之一。</p><p id="4f91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XLNET通过置换语言建模捕获单词周围的双向上下文来克服这些问题。在不屏蔽任何单词或改变输入的情况下，置换语言建模通过对句子中所有可能的单词置换训练自回归模型来捕获上下文。它最大化了一个句子所有排列的对数似然，因此，文本中的每个标记都学会了利用句子中所有其他标记的上下文信息，从而创建了强大、丰富的单词表示。</p><p id="6623" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">XLNet可以解决许多任务，但是我将在本文中讨论的是多项选择问题回答、抽取问题回答和语言建模。我还将演示如何配置XLNET来完成除上述任务和拥抱脸提供的任务之外的任何任务。</p><p id="9025" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，对于我在本文中展示的所有代码/模型，我都是直接从Hugging Face transformer库中获取的，没有任何微调/培训。与许多其他多功能变压器一样，XLNET在核心自回归模型的基础上增加了一个线性层，以针对特定任务进行自我微调。虽然拥抱脸确实为核心模型提供了预训练的权重，但它不为顶部的线性层提供权重。为了实现每个特定任务的最佳性能，必须针对正在解决的任务训练该线性层，因此本文中代码的结果可能不会很好。</p><h2 id="49bc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">多项选择问题回答</h2><p id="ffb2" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">选择题答题简单来说就是顾名思义。我没有把这个题目叫做“问题回答”的唯一原因是因为问题回答的另一个版本:摘录问题回答。在抽取式问题回答中，该模型试图在上下文段落/文本中找到答案，而不是像选择题一样在几个答案选项中进行选择。</p><p id="1f68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在运行下面的代码之前，您必须确保运行该代码，以导入代码编译所需的库。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="82d7" class="lv lw it mu b gy my mz l na nb">pip install transformers <br/>pip install sentencepiece<br/>pip install torch<br/>## All of these lines can vary depending on what version of <br/>## each library you use</span></pre><p id="d779" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是我做选择题回答的代码:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="1e1f" class="lv lw it mu b gy my mz l na nb">from transformers import XLNetTokenizer, XLNetForMultipleChoice<br/>from torch.nn import functional as F<br/>import torch<br/>tokenizer = XLNetTokenizer.from_pretrained("xlnet-base-cased")<br/>model = XLNetForMultipleChoice.from_pretrained("xlnet-base-cased", return_dict = True)<br/>prompt = "What is the capital of France?"<br/>answers = ["Paris", "London", "Lyon", "Berlin"]<br/>encoding = tokenizer([prompt, prompt, prompt, prompt], answers, return_tensors="pt", padding = True)<br/>outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()}) <br/>logits = outputs.logits<br/>softmax = F.softmax(logits, dim = -1)<br/>index = torch.argmax(softmax, dim = -1)<br/>print("The correct answer is", answers[index])</span></pre><p id="7f57" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">拥抱脸是这样设置的，对于它有预训练模型的任务，你必须下载/导入那个特定的模型。在这种情况下，我们必须下载用于多项选择问题回答模型的XLNET，而标记器对于所有不同的XLNET模型都是相同的。</p><p id="5c9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先对问题和4个答案选项进行编码。多项选择的工作方式非常简单:该模型计算每个答案选项的得分，对这些得分进行软最大化以获得概率分布，并只取最高值(张量中最高值的索引使用torch.argmax找到)。在softmax函数应用于XLNET的输出之前，logits是XLNET模型的输出。通过将softmax应用于输出逻辑，我们可以获得每个答案选项的概率分布:具有较高概率的答案选项意味着它们是问题的更好/最佳答案。我们可以使用torch.argmax检索具有最高概率值的答案的索引。如果您想知道每个答案选项的每个概率值是多少(即模型如何对每个选项进行评级)，您可以简单地打印出softmax值的张量。在我的例子中，这是它打印的内容(记住，这个模型顶部的线性层没有经过训练，所以值不好)。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="b273" class="lv lw it mu b gy my mz l na nb">tensor([[0.2661, 0.2346, 0.2468, 0.2525]])</span></pre><p id="4c4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，模型正确地预测答案是巴黎。但是，您可以看到softmax值非常接近。HuggingFace提供了能够处理问题和答案的基础、预训练的架构，以及顶部的未训练的线性分类器来创建适当的输出。从这些值来看，很明显模型需要训练才能达到好的结果。</p><h2 id="28f6" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">抽取式问题回答</h2><p id="7ace" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">抽取式问题回答是在给定一些上下文文本的情况下，通过输出答案在上下文中所处位置的开始和结束索引来回答问题的任务。以下是我使用XLNET回答问题的代码:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="f0a5" class="lv lw it mu b gy my mz l na nb">from transformers import XLNetTokenizer <br/>from transformers import XLNetForQuestionAnsweringSimple<br/>from torch.nn import functional as F<br/>import torch<br/>tokenizer = XLNetTokenizer.from_pretrained("xlnet-base-cased")<br/>model = XLNetForQuestionAnsweringSimple.from_pretrained("xlnet-base-cased",return_dict = True)<br/>question = "How many continents are there in the world?"<br/>text = "There are 7 continents in the world."<br/>inputs = tokenizer.encode_plus(question, text, return_tensors='pt')<br/>output = model(**inputs)<br/>start_max = torch.argmax(F.softmax(output.start_logits, dim = -1))<br/>end_max = torch.argmax(F.softmax(output.end_logits, dim=-1)) + 1 <br/>## add one because of python list indexing<br/>answer = tokenizer.decode(inputs["input_ids"][0][start_max : end_max])<br/>print(answer)</span></pre><p id="03b8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">像多项选择问题回答一样，我们首先下载用于问题回答的特定XLNET模型，并标记我们的两个输入:问题和上下文。HuggingFace提供了两个XLNET模型用于抽取式问题回答:用于简单问题回答的XLNET和用于问题回答的普通XLNET。你可以在官方的HuggingFace transformer库页面上了解更多关于这两者的信息。提取性问题回答的过程与多项选择略有不同。抽取式问题回答的工作方式是通过计算答案在上下文中所处位置的最佳开始和结束索引。该模型返回上下文/输入中所有单词的分数，该分数对应于它们对于给定问题的起始值和结束值有多好；换句话说，输入中的每个单词接收表示它们是答案的好的开始单词还是答案的好的结束单词的开始和结束索引分数/值。然后，我们计算这些分数的softmax以找到值的概率分布，使用torch.argmax()检索开始和结束张量的最高值，并在输入中找到对应于这个start : end范围的实际标记，解码它们并打印出来。</p><h2 id="289f" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">语言建模</h2><p id="d6cb" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">语言建模的任务是在给定句子中所有单词的情况下，预测跟随/继续句子的最佳单词。</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="80cd" class="lv lw it mu b gy my mz l na nb">from transformers import XLNetTokenizer, XLNetLMHeadModel<br/>from torch.nn import functional as F<br/>import torch<br/>tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')<br/>model = XLNetLMHeadModel.from_pretrained('xlnet-base-cased', return_dict = True)<br/>text = "The sky is very clear at " + tokenizer.mask_token<br/>input = tokenizer.encode_plus(text, return_tensors = "pt")<br/>output = model(**input).logits[:, -1, :]<br/>softmax = F.softmax(output, dim = -1)<br/>index = torch.argmax(softmax, dim = -1)<br/>x = tokenizer.decode(index)<br/>print(x)<br/>new_sentence = text.replace(tokenizer.mask_token, x)<br/>print(new_sentence)</span></pre><p id="7243" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们首先下载用于语言建模的特定XLNET模型，并标记我们的输入:不完整的句子(该句子必须像我上面所做的那样将掩码标记连接到句子的末尾)。代码相对简单:我们必须检索模型的逻辑，使用-1索引取最后一个隐藏状态的逻辑(因为这对应于句子中的最后一个单词)，计算这些逻辑的softmax(在这种情况下，softmax创建XLNET词汇表中所有单词的概率分布；具有较高概率值的单词将是掩码标记的更好的候选替换单词)，找到词汇表中的最大概率值，并解码和打印该标记。在上面的代码中，我正在检索具有最高概率值的单词(即最佳候选单词)，但是如果您想知道前10个候选单词是什么(可以是前10个或您喜欢的任何数字)，那么您可以这样做。通过使用torch.topk()函数而不是torch.argmax()，可以检索给定张量中的前k个值，并且该函数返回包含这些前k个值的张量。在此之后，过程与之前相同:迭代张量，解码每个候选单词，并用候选单词替换句子中的掩码标记。下面是执行此操作的代码:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="3fe3" class="lv lw it mu b gy my mz l na nb">from transformers import XLNetTokenizer, XLNetLMHeadModel<br/>from torch.nn import functional as F<br/>import torch<br/>tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')<br/>model = XLNetLMHeadModel.from_pretrained('xlnet-base-cased', return_dict = True)<br/>text = "The sky is very clear at " + tokenizer.mask_token<br/>mask_index = torch.where(input["input_ids"][0] == tokenizer.mask_token_id)<br/>input = tokenizer.encode_plus(text, return_tensors = "pt")<br/>output = model(**input).logits<br/>softmax = F.softmax(output, dim = -1)<br/>mask_word = softmax[0, mask_index, :]<br/>top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]<br/>for token in top_10:<br/>  word = tokenizer.decode([token])<br/>  new_sentence = text.replace(tokenizer.mask_token, word)<br/>  print(new_sentence)</span></pre><h2 id="803e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">使用XLNET完成任何任务</h2><p id="8e87" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">尽管问题回答、语言建模和XLNET可以解决的其他任务在NLP中非常重要，但人们通常希望使用XLNET这样的转换器来完成其他独特的任务，尤其是在研究中。他们这样做的方式是通过采用核心，基础XLNET模型，然后将他们自己的特定神经网络附加到它(通常是线性层)。然后，他们针对特定的任务，在特定的数据集上对这种架构进行微调。在Pytorch中，最好将其设置为Pytorch深度学习模型，如下所示:</p><pre class="kj kk kl km gt mt mu mv mw aw mx bi"><span id="801f" class="lv lw it mu b gy my mz l na nb">from transformers import XLNetModel<br/>import torch.nn as nn<br/>class XLNet_Model(nn.Module):<br/>  def __init__(self, classes):<br/>    super(XLNet_Model, self).__init__()<br/>    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')<br/>    self.out = nn.Linear(self.xlnet.config.hidden_size, classes)<br/>  def forward(self, input):<br/>    outputs = self.xlnet(**input)<br/>    out = self.out(outputs.last_hidden_state)<br/>    return out</span></pre><p id="1481" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我没有下载已经为特定任务(如问答)设计的特定XLNET模型，而是下载了基本的、预训练的XLNET模型，并为其添加了一个线性层。要获取XLNET模型的原始核心输出，请使用xlnet.config.hidden_size(实际值为768)并将其附加到您希望线性图层输出的类的数量。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="49ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望您觉得这些内容很容易理解。如果你认为我需要进一步阐述或澄清什么，请在下面留言。</p><h1 id="6afe" class="nj lw it bd lx nk nl nm ma nn no np md jz nq ka mg kc nr kd mj kf ns kg mm nt bi translated">参考</h1><p id="9d84" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://huggingface.co/transformers/index.html" rel="noopener ugc nofollow" target="_blank">拥抱变脸库</a></p></div></div>    
</body>
</html>