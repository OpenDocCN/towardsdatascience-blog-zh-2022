<html>
<head>
<title>Achieving state-of-the-art for offensive tweet prediction using transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用变形金刚实现最先进的攻击性推文预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/achieving-state-of-the-art-for-offensive-tweet-prediction-using-transformers-8245e571c769#2022-05-02">https://towardsdatascience.com/achieving-state-of-the-art-for-offensive-tweet-prediction-using-transformers-8245e571c769#2022-05-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f6dc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">利用蒸馏和微调进行文本分类</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/ee058e054d1f6ab6c136b6d50062c717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*drwU7RWyXfeO0DVK"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">克劳迪奥·施瓦茨在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4d72" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然人们很容易理所当然地认为像拥抱脸这样的工具可以很容易地应用复杂的模型，并将学习转移到我们喜欢的任何问题上，但我认为展示这些工具可以在一个下午内实际实现最先进的(SOTA)结果是有益的。否则，努力又有什么意义呢？</p><p id="b58d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的任务是预测一条推文是否无害。为此，我们将使用论文<a class="ae kv" href="https://paperswithcode.com/paper/tweeteval-unified-benchmark-and-comparative" rel="noopener ugc nofollow" target="_blank"><em class="ls">TweetEval:Tweet分类的统一基准和比较评估</em> </a>中的Tweet eval数据集。我们将只使用这个数据集的子集<code class="fe lt lu lv lw b">offensive</code>，但是你可以查看其他子集，这些子集标记了诸如情绪和对气候变化的立场。我们正在执行一种文本分类，并将使用一个更小、更快的版本的BERT transformer模型，名为<a class="ae kv" href="https://arxiv.org/abs/1910.01108" rel="noopener ugc nofollow" target="_blank"> DistilBERT </a>。</p><h1 id="d181" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">资料组</h1><p id="2eb2" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">TweetEval数据集的<code class="fe lt lu lv lw b">offensive</code>配置在Hugging Face中有一个模型卡，它被描述为包含:</p><ul class=""><li id="3027" class="mu mv iq ky b kz la lc ld lf mw lj mx ln my lr mz na nb nc bi translated"><code class="fe lt lu lv lw b">text</code>:包含推文的<code class="fe lt lu lv lw b">string</code>功能。</li><li id="e177" class="mu mv iq ky b kz nd lc ne lf nf lj ng ln nh lr mz na nb nc bi translated"><code class="fe lt lu lv lw b">label</code>:一个<code class="fe lt lu lv lw b">int</code>分类标签，映射如下:<code class="fe lt lu lv lw b">0</code>:非攻击性，<code class="fe lt lu lv lw b">1</code>:攻击性</li></ul><h2 id="03ba" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">拥抱人脸数据集</h2><p id="5bae" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">让我们用<code class="fe lt lu lv lw b">load_dataset()</code>函数加载适当的数据集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="fa1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe lt lu lv lw b">offensive</code>对象类似于Python字典，其键是数据集分割(训练、验证和测试)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="1156" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用传统的Python字典语法允许我们访问这些单独的数据集。这些数据集将作为一个<code class="fe lt lu lv lw b">Dataset</code>类返回，这是拥抱脸数据集中的一个关键结构。把一个<code class="fe lt lu lv lw b">Dataset</code>看作一个特殊类型的数组，意味着我们可以索引它并得到它的长度。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="7085" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里需要理解的关键是，数据集中的单个项目(将此视为训练的一行)是一个字典，由关键字<code class="fe lt lu lv lw b">text</code>和<code class="fe lt lu lv lw b">label</code>组成，这些关键字中的值是推文本身，以及攻击性状态。</p><h2 id="3533" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">从数据集到数据框架</h2><p id="eea9" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">虽然用Python管理字典是可行的，但使用Pandas DataFrames更容易，特别是因为大多数数据科学家都非常熟悉它。拥抱脸允许我们在标准的<code class="fe lt lu lv lw b">Datasets</code>物体和熊猫<code class="fe lt lu lv lw b">DataFrame</code>之间转换。我们可以使用<code class="fe lt lu lv lw b">set_format()</code>来做到这一点:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/07d1fcfd2802e997cf78fbff208bc3e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l6tPiVTKJbupQWPipYwLKw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="f15a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">万一我们忘记0或1是攻击性标签，我们可以在标签整数和名称之间转换。为此，我们访问数据集的特征，然后使用索引访问标签，最后使用<code class="fe lt lu lv lw b">int2str</code>函数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/4e15c139936844dd424434eea9f8072a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrzEJe7EFFuwzHy0w6JF4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><h2 id="0311" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">不平衡数据集-类的频率</h2><p id="fafe" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">有许多不同的策略来处理不平衡的数据，其中一些标签比其他标签出现得更频繁。通过简单的直方图，很容易看出我们的数据集是不平衡的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/6c37e761734e3a38a9043f190a5d149b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kS0VNOFYOWMiqb2mhAEyoQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的两个类在数据集中的出现频率(图片由作者提供)。</p></figure><p id="0ee8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然我不一定要在这里深入探讨我们如何解决这个问题，但我要指出的是，这一点很重要。这里有一个<a class="ae kv" href="https://neptune.ai/blog/how-to-deal-with-imbalanced-classification-and-regression-data" rel="noopener ugc nofollow" target="_blank">处理分类问题中不平衡数据的好资源</a>。</p><h2 id="ac6a" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">推文长度和最大模型上下文</h2><p id="c121" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">不同的模型采用不同数量的上下文，其中上下文是用作输入序列的标记的数量。最大输入序列长度称为最大上下文大小。虽然上下文取决于标记的长度和我们如何标记，但我们可以通过检查每条推文的字数来估计我们的大多数输入(即推文)是否会超过最大上下文大小:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/53e8b26520b9913526b7cc01adb35cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8K78Kxp0oqS7_C9pHudQw.png"/></div></div></figure><p id="7bd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用DistilBERT模型，它的最大上下文大小为512个令牌。每条推文的上限是70个词，这意味着我们应该没问题。</p><h1 id="8824" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">符号化</h1><p id="c53e" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">当我们使用一个拥抱脸模型，特别是一个预训练的模型时，我们需要确保我们使用的是模型训练时使用的同一个标记器。如果您不确定这是为什么，可以考虑在加密每个令牌时使用不同的令牌化器。因此，以前表示“球”的标记现在有了不同的标记，这给模型增加了解密这个附加层的额外工作。</p><p id="8a33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">DistilBERT(我们将要使用的模型)使用了<code class="fe lt lu lv lw b">WordPiece</code>标记器。我们不需要做任何花哨的事情来实例化它— <code class="fe lt lu lv lw b">AutoTokenizer</code>是一个HF类，它使用<code class="fe lt lu lv lw b">from_pretrained()</code>方法为我们提供了一个预训练模型的相关标记器:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="db45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们想要标记整个数据集(包括它的子集)，所以我们使用内置的<code class="fe lt lu lv lw b">map()</code>函数，它对数据集中的每一行应用一个处理函数。我们使用<code class="fe lt lu lv lw b">padding=True</code>,所以示例都是批中最长项目的长度，其余的用0填充。<code class="fe lt lu lv lw b">truncation=True</code>简单地确保每个示例小于最大上下文大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="472e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">还要注意，除了返回编码后的tweets作为<code class="fe lt lu lv lw b">input_ids</code>之外，tokeniser还返回一个<code class="fe lt lu lv lw b">attention_mask</code>数组列表。这是因为我们不希望模型被额外的填充标记弄糊涂:注意掩码允许模型忽略输入的填充部分。</p><p id="96e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们最后使用<code class="fe lt lu lv lw b">map</code>在所有数据集上应用记号化。<code class="fe lt lu lv lw b">batched=True</code>意味着我们通过分批编码来加速这个过程，而<code class="fe lt lu lv lw b">batch_size=None</code>意味着我们的分批将只是实际的数据集(例如，训练、验证)。这确保了输入具有相同的长度(即张量和注意力屏蔽)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="9f7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，该映射向数据集中添加了新的列。</p><h1 id="4d31" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">微调变压器</h1><p id="377b" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">不幸的是，DistilBERT只在预测序列中的屏蔽词方面受过训练。虽然大多数模型(身体<em class="ls">对英语有深刻的理解，但最后几层(头部<em class="ls">和头部</em>)经过专门训练，可以预测这些被屏蔽的单词。这和我们的任务不一样。我们只想输出一个序列属于某一类的概率。因为只有两个类，所以我们只输出两个概率。</em></p><p id="0bde" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着我们必须在最后一层训练隐藏状态，要求模型头是可微分的。与我们通常用Pytorch编写自己的训练循环不同，我们将遵循fastai方法，并使用HF Transformers API进行训练循环。</p><h2 id="b76c" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">加载预训练的蒸馏模型</h2><p id="d319" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">为了能够训练模型的最后几层，我们首先需要具有预训练权重的实际模型。拥抱脸通常会让我们使用方法<code class="fe lt lu lv lw b">.from_pretrained()</code>抓取任何带有<code class="fe lt lu lv lw b">AutoModel</code>类的模型。因为我们需要一个分类头，我们使用<code class="fe lt lu lv lw b">AutoModelForSequenceClassification</code>,它只是在预训练权重的基础上，为分类选取合适的架构。唯一需要说明的是要预测的类的数量(在我们的例子中是两个):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="2990" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">定义绩效指标</h2><p id="8a31" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">训练器API需要的一个不太直观的东西是一个<code class="fe lt lu lv lw b">compute_metrics()</code>函数，它接受一个<code class="fe lt lu lv lw b">EvalPrediction </code>对象(一个由<code class="fe lt lu lv lw b">predictions</code>和<code class="fe lt lu lv lw b">label_ids</code>属性组成的命名元组)并返回一个度量:值对的字典。由于我们正在进行二元分类，我们将使用准确度和F1分数作为我们的衡量标准:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="fde7" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">训练跑步</h2><p id="abc3" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">如果我们想上传我们的模型运行并保存我们的性能，我们需要登录到HF Hub。这将允许我们与其他用户共享我们的模型。你需要一个<code class="fe lt lu lv lw b">write</code> API访问令牌，你可以在<a class="ae kv" href="https://huggingface.co/docs/hub/security" rel="noopener ugc nofollow" target="_blank">文档</a>中读到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/f3b327fabdaf486ce31211b4d10dd77e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bpekeZOvmJbJtXXpINoPaA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="0e25" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">训练器API还需要训练参数(包括我们的超参数)。我们使用来自高频变压器的<code class="fe lt lu lv lw b">TrainingArguments</code>类来做到这一点。重要的是，我们在<code class="fe lt lu lv lw b">output_dir</code>中指定了所有训练结果的存储位置。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="a80d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们还设置了批量大小、学习速率、时期数和其他重要参数。最后，我们使用训练器API实例化模型，并调用<code class="fe lt lu lv lw b">.train()</code>进行微调。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/7def975e61d75c3ea1f0d145015ed91c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x4oReSjysHq5qBT14vauAQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="4855" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以再坚持训练几个纪元，看能不能挤出更多的汁液。为了检查这个结果是否合适，我们可以在scikit-learn中实现一个虚拟分类器，它只预测最常见的类，并看看它能获得什么样的精度。在这里，预测每条推文无害的准确率为65%。要使用它，你需要定义<code class="fe lt lu lv lw b">X_train, y_train</code>等等。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c967" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以我们的模型肯定比基线要好。然而，为了更好地了解我们的性能，我们应该与该数据集上的可用基线进行比较。</p><p id="2c3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，我们可以通过在验证数据集上使用训练器的<code class="fe lt lu lv lw b">predict</code>方法，然后调用该对象的<code class="fe lt lu lv lw b">metrics</code>特性来获得一个指标字典:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="eca2" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">结果比较</h1><p id="1767" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">将模型上传到HF Hub的一个好处是，它们会在一个名为<a class="ae kv" href="https://paperswithcode.com/" rel="noopener ugc nofollow" target="_blank"> Papers的网站上自动评分，代码为</a>。这些人将论文、数据集和社区模型汇集在一起，记录整个ML中数千个不同任务的所有评估指标。</p><p id="2080" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们要做的第一件事是在我们的浏览器中登录到拥抱脸，然后单击特定的模型(它将在您命名的任何名称下)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/fa551e83947278fd3fc663f3e1b62ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QTU1QDeQ6HMkEx_5mQaVig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="6cd5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个页面列出了模型的性能，还提供了一个推理API，这样您就可以自己尝试这个模型了。此外，它还会记录一段时间内的超参数和训练表现:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/acea0473fb854c56392d4d34eb001315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jxfzm0ZtSNoiy0ivjVOYkw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="0cdf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果我们向下到右下角，我们可以转到带代码的论文，以查看该数据集和该任务的排行榜。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/eb7520bd8ab75acc414c98747f43193b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5F8xfv7-S293pyQnk5Bfxw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片作者。</p></figure><p id="67cb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">令人印象深刻的是，我们在微调预训练模型方面做得相当好。在这个特定的数据集上，我们现在是世界第一，无论是准确性还是F1分数。</p><div class="kg kh ki kj gt ab cb"><figure class="of kk og oh oi oj ok paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/b0f23dd4a28e454f9235451413992289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*ww6XswC9MEernJTf-0TtXw.png"/></div></figure><figure class="of kk ol oh oi oj ok paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/e45778c4e4c507736e35d45444e20027.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*hJ4j56VqObwTUl239nzRLQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk om di on oo translated">F1得分与之前的基线相比。注意，我们在这个数据集上实现了SOTA(图片由作者提供)。</p></figure></div><p id="eb43" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们甚至在<a class="ae kv" href="https://paperswithcode.com/dataset/tweeteval" rel="noopener ugc nofollow" target="_blank">的论文中得到认可，将数据集</a>的代码页作为最先进的基准:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/de1418331d5e946c4a76c7adb948c935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d101PmFNO6PBlv8D39OkYw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">我们的模型<strong class="bd oq"><em class="or">distil Bert-base-un cased-fine tuned-tweet _ eval-offensive</em></strong>现在以Code网站作为这个数据集的基准(图片由作者提供)列在论文上。</p></figure><h1 id="64ac" class="lx ly iq bd lz ma mb mc md me mf mg mh jw mi jx mj jz mk ka ml kc mm kd mn mo bi translated">结论</h1><p id="d044" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">这次排练真实地展示了杰瑞米·霍华德常说的一句话:不需要数学博士或昂贵的图形处理器就能在一个下午内完成一项任务。像拥抱脸和fastai这样的工具可以让我们快速训练模型，并在模型上迭代。使用越来越容易获得的预训练模型的迁移学习更多地利用了这些工具。</p><p id="087c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对快速探索变形金刚拥抱脸的能力感兴趣，看看我在这里做的这个演示。</p><h2 id="d7eb" class="ni ly iq bd lz nj nk dn md nl nm dp mh lf nn no mj lj np nq ml ln nr ns mn nt bi translated">参考</h2><p id="70a0" class="pw-post-body-paragraph kw kx iq ky b kz mp jr lb lc mq ju le lf mr lh li lj ms ll lm ln mt lp lq lr ij bi translated">[1] L. Tunstall、L. Werra和T. Wolf，<a class="ae kv" href="https://learning.oreilly.com/library/view/natural-language-processing/9781098103231/copyright-page01.html" rel="noopener ugc nofollow" target="_blank">用转换器进行自然语言处理</a> s (2022)，奥赖利媒体</p><p id="0614" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sanh%2C+V" rel="noopener ugc nofollow" target="_blank">维克多·桑</a>、<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Debut%2C+L" rel="noopener ugc nofollow" target="_blank">弗拉达利出道</a>、<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaumond%2C+J" rel="noopener ugc nofollow" target="_blank">朱利安·肖蒙德</a>、<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wolf%2C+T" rel="noopener ugc nofollow" target="_blank">托马斯·沃尔夫</a>、<em class="ls">蒸馏版伯特:更小更快更便宜更轻</em> (2019)、arxiv</p><p id="bd9c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] F .巴比耶里，j .卡马乔-科拉多斯，L .内维斯，路易斯·埃斯皮诺萨-安克，<em class="ls">Tweet eval:Tweet分类的统一基准和比较评估</em> (2020)，arxiv</p><p id="b90a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[4] J. Howard和S. Ruder，<a class="ae kv" href="https://arxiv.org/pdf/1801.06146.pdf" rel="noopener ugc nofollow" target="_blank">面向文本分类的通用语言模型微调</a> (2018)，arxiv</p><p id="817f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[5] <a class="ae kv" href="https://huggingface.co/docs/datasets/index" rel="noopener ugc nofollow" target="_blank">拥抱脸部数据集文档</a> (2022)</p></div></div>    
</body>
</html>