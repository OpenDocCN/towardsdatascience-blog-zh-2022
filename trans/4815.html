<html>
<head>
<title>Generate a 3D Mesh from an Image with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python从图像生成三维网格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-a-3d-mesh-from-an-image-with-python-12210c73e5cc#2022-10-26">https://towardsdatascience.com/generate-a-3d-mesh-from-an-image-with-python-12210c73e5cc#2022-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7abd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">将深度学习与3D数据处理相结合以生成网格</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5f6977760230a527bb12a55edba24f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9JNMzxwnHu3d2bSVx0Ja1Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">阿尔瓦罗·皮诺在<a class="ae ky" href="https://unsplash.com/s/photos/abstract-triangles?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="f677" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated">几年前，从一张2D图片生成一个3D网格似乎是一项非常困难的任务。如今，由于深度学习的进步，已经开发了多个单目深度估计模型，它们可以从任何图像提供精确的深度图。通过这个贴图，可以通过执行表面重建来生成网格。</p><h1 id="1216" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">介绍</h1><p id="0df4" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">单目深度估计是在给定单个RGB图像的情况下，估计每个像素的深度值(相对于相机的距离)的任务。单目深度估计模型的输出是一个<strong class="lb iu">深度图</strong>，它基本上是一个矩阵，其中每个元素对应于输入图像中相关像素的预测深度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/01d8872104a60ba67ba39f3f2073e2df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*0LzJ59fYI9tPfuwCy6XWNQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">深度图。图片由作者提供。</p></figure><p id="14a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深度图中的点可以被视为具有3轴坐标的点的集合。由于映射是一个矩阵，每个元素都有<em class="nc"> x </em>和<em class="nc"> y </em>组件(它的列和行)。而<em class="nc"> z </em>分量是其存储值，是点<em class="nc"> (x，y) </em>的预测深度。在3D数据处理领域，一列<em class="nc"> (x，y，z) </em>点被称为<strong class="lb iu">点云</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/076d61f409520fae7b4a8b0c68df14ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZhgvUrtFC1zhSXLlGpCqKg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个点云。原始文件由<a class="ae ky" href="https://github.com/isl-org/Open3D" rel="noopener ugc nofollow" target="_blank"> Open3D </a>制作。</p></figure><p id="9635" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从非结构化的点云开始，可以获得一个<strong class="lb iu">网格</strong>。网格是由顶点和多边形集合组成的3D对象表示<strong class="lb iu">。</strong>最常见的网格类型<strong class="lb iu"> </strong>是<strong class="lb iu">三角形网格</strong>，它由一组通过公共边或顶点连接的三维三角形组成。在文献中，有几种方法可以从点云中获得三角形网格，最流行的是Alpha shape、Ball pivoting和Poisson曲面重建。这些方法被称为<strong class="lb iu">表面重建算法</strong>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nd"><img src="../Images/f81e84312ed5b2eb609438a16da78178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mGdgZShjQ0uDMyt4EwUj5w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">三角形网格。原始文件由<a class="ae ky" href="https://github.com/isl-org/Open3D" rel="noopener ugc nofollow" target="_blank"> Open3D </a>生成。</p></figure><p id="0481" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">本指南中使用的从图像生成网格的过程由三个阶段组成:</p><ol class=""><li id="6ab2" class="ne nf it lb b lc ld lf lg li ng lm nh lq ni lu nj nk nl nm bi translated"><strong class="lb iu">深度估计</strong> —使用单目深度估计模型生成输入图像的深度图。</li><li id="ff06" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated"><strong class="lb iu">点云构建</strong> —深度图转换成点云。</li><li id="d913" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu nj nk nl nm bi translated"><strong class="lb iu">网格生成</strong>—从点云中，使用表面重建算法生成一个网格。</li></ol><p id="7d8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要遵循指南中说明的不同步骤，您需要一个图像。如果你手边没有，你可以下载这个:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/616d8d1a69ed36b09a4a090c7fecc09f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*tnps7xatwoB76d0qqVr00A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一间卧室。图片来自<a class="ae ky" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2 </a>。</p></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="4c84" class="me mf it bd mg mh nz mj mk ml oa mn mo jz ob ka mq kc oc kd ms kf od kg mu mv bi translated">1.深度估计</h1><p id="d772" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">本指南选择的单目深度估计模型是GLPN⁴.在<a class="ae ky" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">抱脸模型轮毂</a>上有。可以通过使用拥抱脸库<a class="ae ky" href="https://huggingface.co/docs/transformers/index" rel="noopener ugc nofollow" target="_blank">变形金刚</a>从这个中枢检索模型。</p><p id="d371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要安装PyPI最新版本的变压器，请使用:</p><pre class="kj kk kl km gt oe of og bn oh oi bi"><span id="f9ef" class="oj mf it of b be ok ol l om on">pip install transformers</span></pre><p id="4e80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码用于估计输入图像的深度:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="5e5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使用GLPN，Transformers库提供了两个类:<code class="fe oq or os of b">GLPNFeatureExtractor</code>，用于预处理每个输入和<code class="fe oq or os of b">GLPNForDepthEstimation</code>，即模型类。</p><p id="7ca4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于其架构，模型输出大小为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi gj"><img src="../Images/72af7ad38950d19dc3a065da781c3edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ncuky2cP4u1QEH1F-N2u4Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输出大小。使用<a class="ae ky" href="https://www.codecogs.com/latex/eqneditor.php" rel="noopener ugc nofollow" target="_blank"> CodeCogs </a>生成的图像。</p></figure><p id="6e90" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，<code class="fe oq or os of b">image</code>的大小被调整为32的高度和宽度的倍数。否则，模型的输出将小于输入。这是必需的，因为点云将使用图像像素绘制，为此，输入图像和输出深度图必须具有相同的大小。</p><p id="662a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于单目深度估计模型难以在边界附近获得高质量的预测，<code class="fe oq or os of b">output</code>被中心裁剪(第33行)。为了保持输入和输出之间的相同尺寸，还将<code class="fe oq or os of b">image</code>居中裁剪(第34行)。</p><p id="853b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下是一些预测:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/04a9092c2ff48b46338e68e1bae796dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WZy3R_cy0-S5VoOhlIJ_Sw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">卧室的深度预测。来自<a class="ae ky" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2 </a>的输入图像。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/84093ce4e3fd074c6346ef31e499f40b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Les4rWB_2PG9OG-9-Tsz1w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">游戏室的深度预测。来自<a class="ae ky" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2 </a>的输入图像。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/f39ed396dc0ee63698a3931e4b14df96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DXCel6CwRLXFbP8wGdWZw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">办公室的深度预测。来自<a class="ae ky" href="https://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html" rel="noopener ugc nofollow" target="_blank"> NYU深度V2 </a>的输入图像。</p></figure></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="e1b5" class="me mf it bd mg mh nz mj mk ml oa mn mo jz ob ka mq kc oc kd ms kf od kg mu mv bi translated">2.点云构建</h1><p id="0aa3" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">对于本指南的3D处理部分，将使用Open3D⁵。对于这种任务，它可能是最好的Python库。</p><p id="410b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要从PyPI安装最新版本的Open3D，请使用:</p><pre class="kj kk kl km gt oe of og bn oh oi bi"><span id="915c" class="oj mf it of b be ok ol l om on">pip install open3d</span></pre><p id="a009" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">以下代码将估计的深度贴图转换为Open3D点云对象:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="3ab6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个<strong class="lb iu"> RGBD图像</strong>仅仅是一个RGB图像和它对应的深度图像的组合。PinholeCameraIntrinsic类存储所谓的内在相机矩阵。通过这个矩阵，Open3D可以从RGBD图像创建一个点云，点之间的间距正确。保持固有参数不变。有关更多详细信息，请参见指南末尾的附加资源。</p><p id="f051" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要可视化点云，请使用:</p><pre class="kj kk kl km gt oe of og bn oh oi bi"><span id="6581" class="oj mf it of b be ok ol l om on">o3d.visualization.draw_geometries([pcd])</span></pre></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="8730" class="me mf it bd mg mh nz mj mk ml oa mn mo jz ob ka mq kc oc kd ms kf od kg mu mv bi translated">3.网格生成</h1><p id="e936" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">在文献中可用于此任务的各种方法中，该指南使用泊松表面重建算法。选择这种方法是因为它通常能提供更好、更平滑的结果。</p><p id="b780" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此代码使用泊松算法从上一步中获得的点云生成网格:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><p id="c298" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，代码从点云中删除离群值。由于各种原因，点云可能包含噪声和伪像。在这种情况下，模型可能预测了一些深度，如果与其邻居相比，这些深度变化太大。</p><p id="f191" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下一步是正常的估计。法线是垂直于表面或对象的向量(因此具有大小和方向),为了处理泊松算法，必须对其进行估计。有关这些向量的更多详细信息，请参见本指南末尾的附加资源。</p><p id="feda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，执行算法。<code class="fe oq or os of b">depth</code>值定义了网格的详细程度。除了增加网格质量之外，更高的深度值也会增加输出尺寸。</p><p id="8670" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你更喜欢使用程序来可视化网格，我建议下载<a class="ae ky" href="https://www.meshlab.net/" rel="noopener ugc nofollow" target="_blank"> MeshLab </a>，因为有一些3D可视化程序不能渲染颜色。</p><p id="555f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是最后的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/575f3ae522f48c0b8012df5d448a5882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29TI7e_ANNhmMQKlFCoGXQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成的网格。图片由作者提供。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ou"><img src="../Images/f471541852f7818868ba8b21d1bd1ffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bZQdIsIaIKG5b_m5BiAphQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">生成的网格(从另一个角度)。图片由作者提供。</p></figure><p id="30b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于最终结果根据<code class="fe oq or os of b">depth</code>值而变化，这是不同结果之间的比较:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/80009ee9ba04f17c9214c9c4c966a089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uHwkeIAvt0BiX67wytliLQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同深度值之间的比较。图片由作者提供。</p></figure><p id="e14b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<code class="fe oq or os of b">depth=5</code>的算法得到375 KB网格，<code class="fe oq or os of b">depth=6</code>到1.2 MB，<code class="fe oq or os of b">depth=7</code>到5 MB，<code class="fe oq or os of b">depth=8</code>到19 MB，<code class="fe oq or os of b">depth=9</code>到70MB，而使用<code class="fe oq or os of b">depth=10</code>到86 MB。</p><h1 id="dd48" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">结论</h1><p id="a1a6" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">尽管只使用了一张图片，效果还是很不错的。借助一些3D编辑，你可以达到更好的效果。由于本指南不能完全涵盖3D数据处理的所有细节，我建议您阅读下面的其他资源，以更好地理解所涉及的所有方面。</p><h2 id="6b48" class="ow mf it bd mg ox oy dn mk oz pa dp mo li pb pc mq lm pd pe ms lq pf pg mu ph bi translated"><strong class="ak">附加资源</strong></h2><ul class=""><li id="76b9" class="ne nf it lb b lc mw lf mx li pi lm pj lq pk lu pl nk nl nm bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Pinhole_camera_model" rel="noopener ugc nofollow" target="_blank">针孔摄像机型号</a></li><li id="940e" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu pl nk nl nm bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Camera_resectioning" rel="noopener ugc nofollow" target="_blank">内在和外在矩阵</a></li><li id="4cee" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu pl nk nl nm bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Normal_(geometry)" rel="noopener ugc nofollow" target="_blank">法线</a></li><li id="c3bd" class="ne nf it lb b lc nn lf no li np lm nq lq nr lu pl nk nl nm bi translated"><a class="ae ky" href="http://www.open3d.org/docs/release/" rel="noopener ugc nofollow" target="_blank"> Open3D官方文档</a></li></ul><p id="d022" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个项目的演示可在<a class="ae ky" href="https://huggingface.co/spaces/mattiagatti/image2mesh" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="c222" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢阅读，我希望你发现这是有用的。</p></div><div class="ab cl ns nt hx nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="im in io ip iq"><h1 id="a982" class="me mf it bd mg mh nz mj mk ml oa mn mo jz ob ka mq kc oc kd ms kf od kg mu mv bi translated">参考</h1><p id="9512" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">[1] H. Edelsbrunner和E. P. Mücke，<a class="ae ky" href="https://arxiv.org/abs/math/9410208" rel="noopener ugc nofollow" target="_blank">三维阿尔法形状</a> (1994年)</p><p id="58ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] F. Bernardini，J. Mittleman，H. Rushmeier，C. Silva和G. Taubin，<a class="ae ky" href="http://The ball-pivoting algorithm for surface reconstruction" rel="noopener ugc nofollow" target="_blank">用于表面重建的球旋转算法</a> (1999)</p><p id="8eda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[3] M. Kazhdan，M. Bolitho和H. Hoppe，<a class="ae ky" href="https://www.cs.jhu.edu/~misha/MyPapers/SGP06.pdf" rel="noopener ugc nofollow" target="_blank">泊松表面重建</a> (2006)</p><p id="fcad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[4] D. Kim，W. Ga，P. Ahn，D. Joo，S. Chun和J. Kim，<a class="ae ky" href="https://arxiv.org/abs/2201.07436" rel="noopener ugc nofollow" target="_blank">利用垂直切割深度进行单目深度估计的全局-局部路径网络</a> (2022)</p><p id="c496" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[5] Q. Zhou，J. Park和V. Koltun，<a class="ae ky" href="https://arxiv.org/abs/1801.09847" rel="noopener ugc nofollow" target="_blank"> Open3D:用于3D数据处理的现代图书馆</a> (2018)</p><p id="07a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[6] N. Silberman，D. Hoiem，P. Kohli和Rob Fergus，<a class="ae ky" href="https://cs.nyu.edu/~silberman/papers/indoor_seg_support.pdf" rel="noopener ugc nofollow" target="_blank">室内分割和支持从RGBD图像推断</a> (2012)</p></div></div>    
</body>
</html>