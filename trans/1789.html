<html>
<head>
<title>Apache Spark for Data Science: User-Defined Functions (UDF), Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark for Data Science:用户定义函数(UDF)，已解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-for-data-science-user-defined-functions-udf-explained-6c9d913839bb#2022-04-26">https://towardsdatascience.com/apache-spark-for-data-science-user-defined-functions-udf-explained-6c9d913839bb#2022-04-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="11e7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">你觉得Python比SQL简单？PySpark中的用户自定义函数可能就是您正在寻找的</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4cd4c6360b7b91cfe136c6827605dcfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*A1pfWCjCzmq80JQJ"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@spacex?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> SpaceX </a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="7322" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">数据科学家不一定是最好的SQL用户。也许你精通Python，但是你不知道如何将这些知识转化成SQL。这不应该阻止你利用Spark和PySpark所提供的一切。</p><p id="3ba3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用用户定义函数(UDF)，您可以用Python编写函数，并在编写Spark SQL查询时使用它们。今天，我将向您展示如何声明和注册5个Python函数，并使用它们来清理和重新格式化众所周知的Titanic数据集。在文章的最后，您还将学习如何在使用UDF之后过滤掉记录。</p><p id="ddf1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不想看书？请观看我的视频:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lv lw l"/></div></figure></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="6ef1" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">使用的数据集和Spark会话初始化</h1><p id="e1b0" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">为了使事情更加简单，我们将使用泰坦尼克号数据集，在<a class="ae ky" href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=40945&amp;status=active" rel="noopener ugc nofollow" target="_blank">知识共享许可</a>下许可。从<a class="ae ky" href="https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv" rel="noopener ugc nofollow" target="_blank">这个网址</a>下载并保存在你记得的地方:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/13395491bc59dbb2e41a9403690ad74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XxmoHA1qyexunWHox3AmFA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片1 —泰坦尼克号数据集(图片由作者提供)</p></figure><p id="1894" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该数据集比Iris数据集包含更多的功能。这些以后会派上用场的。但首先，让我们看看如何加载它的火花。</p><p id="3738" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您在笔记本环境中使用PySpark，请始终使用此代码片段以获得更好的输出格式。否则，如果一次在屏幕上看到的列太多，数据帧可能会溢出:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="c8bd" class="nh mf it nd b gy ni nj l nk nl">from IPython.core.display import HTML<br/>display(HTML("&lt;style&gt;pre { white-space: pre !important; }&lt;/style&gt;"))</span></pre><p id="7468" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">解决了这个问题后，我们可以初始化一个新的Spark会话:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="f6f3" class="nh mf it nd b gy ni nj l nk nl">from pyspark.sql import SparkSession<br/></span><span id="99e6" class="nh mf it nd b gy nm nj l nk nl">spark = SparkSession.builder.appName("spark-sql").getOrCreate()</span></pre><p id="a098" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要读取CSV文件，只需指定<code class="fe nn no np nd b">read</code>模块的<code class="fe nn no np nd b">csv()</code>函数的路径。每当读取CSV文件时，<code class="fe nn no np nd b">inferSchema</code>和<code class="fe nn no np nd b">header</code>参数是强制性的。如果没有它们，Spark会将所有数据类型转换为string，并将标题行视为实际数据:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="fbe3" class="nh mf it nd b gy ni nj l nk nl">titanic = spark.read.csv(<br/>    path="file://&lt;dataset-path&gt;", <br/>    inferSchema=True, <br/>    header=True<br/>)<br/>titanic.show(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nq"><img src="../Images/2bf2c3586436d7b34178cb379bb8e387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H0pFLR8hzj1hUmMT5ha5RQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片2 —泰坦尼克号数据集的前10行(图片由作者提供)</p></figure><p id="25d6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们来声明我们的第一个用户定义函数。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="d745" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">如何在Spark和Python中声明用户定义函数(UDF)</h1><p id="c373" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">您可以像声明任何其他Python函数一样声明用户定义的函数。当你用Spark注册一个Python函数时，技巧就来了，但是稍后会详细介绍。</p><p id="e214" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的第一个函数将从乘客姓名中提取标题。所有名字的标题从第一个逗号后开始，并在其后包含一个单词。通过链接两个<code class="fe nn no np nd b">split()</code>函数很容易提取它:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="975c" class="nh mf it nd b gy ni nj l nk nl">def extract_title(name):<br/>    return name.split(', ')[-1].split()[0]</span><span id="1bbe" class="nh mf it nd b gy nm nj l nk nl">extract_title("Braund, Mr. Owen Harris")</span><span id="12fb" class="nh mf it nd b gy nm nj l nk nl">&gt;&gt;&gt; 'Mr.'</span></pre><p id="dda1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">光是标题就不是机器学习友好的属性。我们需要一个新的二进制属性，如果这个人的头衔很常见(小姐、先生、夫人和主人)，则该属性的值为1，否则为0:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="3a99" class="nh mf it nd b gy ni nj l nk nl">def is_common_title(title):<br/>    return 1 if title in ["Miss.", "Mr.", "Mrs.", "Master."] else 0</span><span id="66e7" class="nh mf it nd b gy nm nj l nk nl">is_common_title("Dr.")</span><span id="cbd2" class="nh mf it nd b gy nm nj l nk nl">&gt;&gt;&gt; 0</span></pre><p id="960f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nn no np nd b">Sex</code>列是另一个需要转换的属性。如果<code class="fe nn no np nd b">Sex</code>为“阳性”，则<code class="fe nn no np nd b">remap_gender()</code>函数返回1，否则返回0:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="0745" class="nh mf it nd b gy ni nj l nk nl">def remap_gender(gender):<br/>    return 1 if gender == "male" else 0</span><span id="0c6c" class="nh mf it nd b gy nm nj l nk nl">remap_gender("female")</span><span id="c174" class="nh mf it nd b gy nm nj l nk nl">&gt;&gt;&gt; 0</span></pre><p id="3b70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">泰坦尼克号数据集充满了缺失值，属性<code class="fe nn no np nd b">Cabin</code>也不例外。问题是，不是所有的乘客都有专用的客舱，或者他们的客舱号码不知道。我们将声明一个函数，如果乘客有客舱则返回1，否则返回0:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="77f9" class="nh mf it nd b gy ni nj l nk nl">def has_cabin(cabin):<br/>    return 1 if cabin else 0</span><span id="2302" class="nh mf it nd b gy nm nj l nk nl">has_cabin("")</span><span id="0d47" class="nh mf it nd b gy nm nj l nk nl">&gt;&gt;&gt; 0</span></pre><p id="30bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，我们将编写一个输入乘客年龄的函数。与前面的函数不同，这个函数接受两个参数:</p><ul class=""><li id="80a8" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><code class="fe nn no np nd b">age</code> -来自数据集的传入值，可以是数字或Null。</li><li id="dec4" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><code class="fe nn no np nd b">value</code> -我们将把<code class="fe nn no np nd b">age</code>替换为。</li></ul><p id="6586" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">逻辑很简单——如果<code class="fe nn no np nd b">age</code>缺失，返回<code class="fe nn no np nd b">value</code>，否则返回<code class="fe nn no np nd b">age</code>:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="6e15" class="nh mf it nd b gy ni nj l nk nl">def replace_missing_age(age, value):<br/>    return age if age else value</span><span id="ee94" class="nh mf it nd b gy nm nj l nk nl">replace_missing_age(15, -1)</span><span id="f0dc" class="nh mf it nd b gy nm nj l nk nl">&gt;&gt;&gt; 15</span></pre><p id="5b58" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这些都是从函数声明端开始的，现在是时候在Spark中使用它们了。为此，您必须首先通过<code class="fe nn no np nd b">spark.udf.register()</code>功能注册它们。它接受两个参数:</p><ul class=""><li id="0dd7" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu nw nx ny nz bi translated"><code class="fe nn no np nd b">name</code> -一个字符串，您将在SQL查询中使用的函数名。</li><li id="9408" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><code class="fe nn no np nd b">f</code> -包含编程逻辑的Python函数。</li></ul><p id="55d4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为两个参数赋予相同的值是一种常见的做法，只是为了避免以后混淆:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="5427" class="nh mf it nd b gy ni nj l nk nl">spark.udf.register("extract_title", extract_title)<br/>spark.udf.register("is_common_title", is_common_title)<br/>spark.udf.register("remap_gender", remap_gender)<br/>spark.udf.register("has_cabin", has_cabin)<br/>spark.udf.register("replace_missing_age", replace_missing_age)</span></pre><p id="1851" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就这样——您现在可以在Spark SQL中使用这些Python用户声明的函数了！</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="3ccc" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">如何在Spark SQL中使用用户自定义函数</h1><p id="bda4" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">如果您已经阅读了我在Spark文章中的<a class="ae ky" href="https://betterdatascience.com/apache-spark-sql/" rel="noopener ugc nofollow" target="_blank">对SQL的介绍，您应该知道您首先必须在数据帧上创建一个临时视图。这是通过调用<code class="fe nn no np nd b">createOrReplaceTempView()</code>函数并传入一个视图名(任意一个)来完成的:</a></p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="cfe3" class="nh mf it nd b gy ni nj l nk nl">titanic.createOrReplaceTempView("titanic")</span></pre><p id="1eb6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">创建后，在对<code class="fe nn no np nd b">spark.sql()</code>的调用中传递任何SQL语句。下面的例子使用了我们所有的五个用户定义函数:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="8f34" class="nh mf it nd b gy ni nj l nk nl">spark.sql("""<br/>    SELECT<br/>        Survived,<br/>        Pclass,<br/>        extract_title(Name) AS Title,<br/>        is_common_title(extract_title(Name)) AS IsCommonTitle,<br/>        remap_gender(Sex) as IsMale,<br/>        replace_missing_age(Age, -1) as Age,<br/>        SibSp,<br/>        Parch,<br/>        Fare,<br/>        has_cabin(Cabin) as HasCabin,<br/>        Embarked<br/>    FROM titanic<br/>""").show(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/a61ecdb4af19f7300ea747b5707f6e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GmDT3tQ5wYMH8-v6Qq1u5Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3 —在PySpark中使用用户定义的函数(图片由作者提供)</p></figure><p id="14f7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，我们的函数非常好用！我已经将<code class="fe nn no np nd b">replace_missing_gender()</code>设置为用-1替换任何丢失的值，但是您可以随意更改。你也可以将函数链接在一起，如<code class="fe nn no np nd b">is_common_title(extract_title(Name))</code> call所示。</p><p id="9ced" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">但你知道问题是什么吗？</strong>在幕后，Spark为UDF结果的列任意命名，即使我们已经明确指定了别名。这是一个问题，因为你不能使用<code class="fe nn no np nd b">WHERE</code>关键字根据条件过滤掉记录。</p><p id="805b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，您可以将整个查询包装在另一个查询(子查询)中，然后随心所欲地使用SQL:</p><pre class="kj kk kl km gt nc nd ne nf aw ng bi"><span id="7c2a" class="nh mf it nd b gy ni nj l nk nl">spark.sql("""<br/>    SELECT * FROM (<br/>        SELECT<br/>            Survived,<br/>            Pclass,<br/>            extract_title(Name) AS Title,<br/>            is_common_title(extract_title(Name)) AS IsCommonTitle,<br/>            remap_gender(Sex) as IsMale,<br/>            replace_missing_age(Age, -1) as Age,<br/>            SibSp,<br/>            Parch,<br/>            Fare,<br/>            has_cabin(Cabin) as HasCabin,<br/>            Embarked<br/>        FROM titanic<br/>    ) WHERE IsCommonTitle = 0<br/>""").show(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/69c2214013359d66a82026c6894bb1f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VM5zgQePzqbqR7ZdnXiMUg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4 —带有附加过滤器的用户定义函数(图片由作者提供)</p></figure><p id="a145" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在你可以看到，只有不常见的乘客标题记录显示。大部分是年长的男性，这是意料之中的。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h1 id="599e" class="me mf it bd mg mh mi mj mk ml mm mn mo jz mp ka mq kc mr kd ms kf mt kg mu mv bi translated">PySpark中用户定义函数的总结</h1><p id="1bcf" class="pw-post-body-paragraph kz la it lb b lc mw ju le lf mx jx lh li my lk ll lm mz lo lp lq na ls lt lu im bi translated">今天你已经学习了如何在Python和Spark中使用用户定义的函数(UDF)。如果您每天都在使用Python，并且不是SQL的狂热爱好者，这将是一个巨大的里程碑。当然，这些不能代替足够的SQL知识，但是没有人能阻止你使用它们。</p><p id="0ccd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有些事情在Python中更容易完成，当时间非常重要时，UDF确保您不会浪费时间去计算SQL命令。只需记住使用UDF所需的步骤:</p><ol class=""><li id="dc1a" class="nr ns it lb b lc ld lf lg li nt lm nu lq nv lu oh nx ny nz bi translated">声明一个Python函数</li><li id="f0bc" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu oh nx ny nz bi translated">向Spark注册Python函数</li><li id="a18c" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu oh nx ny nz bi translated">使用Spark SQL语句中的函数</li></ol><p id="12d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">就这么简单！接下来，您将学习如何将机器学习算法应用于该数据集，敬请关注。</p></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="408f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oi">喜欢这篇文章吗？成为</em> <a class="ae ky" href="https://medium.com/@radecicdario/membership" rel="noopener"> <em class="oi">中等会员</em> </a> <em class="oi">继续无限制学习。如果你使用下面的链接，我会收到你的一部分会员费，不需要你额外付费。</em></p><div class="oj ok gp gr ol om"><a href="https://medium.com/@radecicdario/membership" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">通过我的推荐链接加入Medium-Dario rade ci</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">medium.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><h2 id="e448" class="nh mf it bd mg pb pc dn mk pd pe dp mo li pf pg mq lm ph pi ms lq pj pk mu pl bi translated">推荐阅读</h2><ul class=""><li id="2bb1" class="nr ns it lb b lc mw lf mx li pm lm pn lq po lu nw nx ny nz bi translated"><a class="ae ky" href="https://betterdatascience.com/best-data-science-prerequisite-books/" rel="noopener ugc nofollow" target="_blank">学习数据科学先决条件(数学、统计和编程)的5本最佳书籍</a></li><li id="e87c" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><a class="ae ky" href="https://betterdatascience.com/top-books-to-learn-data-science/" rel="noopener ugc nofollow" target="_blank">2022年学习数据科学的前5本书</a></li><li id="9a94" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated"><a class="ae ky" href="https://betterdatascience.com/python-list-print/" rel="noopener ugc nofollow" target="_blank">用Python打印列表的7种方法</a></li></ul><h2 id="a9ee" class="nh mf it bd mg pb pc dn mk pd pe dp mo li pf pg mq lm ph pi ms lq pj pk mu pl bi translated">保持联系</h2><ul class=""><li id="217b" class="nr ns it lb b lc mw lf mx li pm lm pn lq po lu nw nx ny nz bi translated">雇用我作为一名技术作家</li><li id="a16e" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">在<a class="ae ky" href="https://www.youtube.com/c/BetterDataScience" rel="noopener ugc nofollow" target="_blank"> YouTube </a>上订阅</li><li id="6d76" class="nr ns it lb b lc oa lf ob li oc lm od lq oe lu nw nx ny nz bi translated">在<a class="ae ky" href="https://www.linkedin.com/in/darioradecic/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上连接</li></ul></div><div class="ab cl lx ly hx lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="im in io ip iq"><p id="6dbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="oi">原载于2022年4月26日https://betterdatascience.com</em><a class="ae ky" href="https://betterdatascience.com/spark-user-defined-functions/" rel="noopener ugc nofollow" target="_blank"><em class="oi"/></a><em class="oi">。</em></p></div></div>    
</body>
</html>