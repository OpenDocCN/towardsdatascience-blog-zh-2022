<html>
<head>
<title>Survival Analysis: Optimize the Partial Likelihood of the Cox Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生存分析:优化 Cox 模型的部分可能性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/survival-analysis-optimize-the-partial-likelihood-of-the-cox-model-b56b8f112401#2022-12-09">https://towardsdatascience.com/survival-analysis-optimize-the-partial-likelihood-of-the-cox-model-b56b8f112401#2022-12-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="031e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在 Python 中寻找最大化对数部分似然的系数</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/512c36355de182c1de8f863d189cec3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xRKLo6Q-Y9FogZ5wwIhpaA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">局部最优 Cox 模型的负对数部分似然。图片作者。</p></figure><h1 id="6834" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">目录</h1><ol class=""><li id="171f" class="lq lr it ls b lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated"><a class="ae mi" href="#1304" rel="noopener ugc nofollow">简介</a></li><li id="c271" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#53f9" rel="noopener ugc nofollow">考克斯比例风险模型</a></li><li id="bd6f" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#5627" rel="noopener ugc nofollow">优化问题</a></li><li id="a249" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#d192" rel="noopener ugc nofollow">实施</a></li><li id="80f1" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#0e6a" rel="noopener ugc nofollow">结论</a></li><li id="465d" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md me mf mg mh bi translated"><a class="ae mi" href="#99e3" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="1304" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">1.介绍</h1><p id="0968" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">生存分析包括描述事件时间数据的统计方法的集合。</p><p id="5d27" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在这篇文章中，我们介绍一个流行的生存分析算法，Cox 比例风险模型。然后，我们定义了它的对数部分似然和梯度，并通过一个实际的 Python 例子对它进行优化以找到最佳的模型参数集。</p><h1 id="53f9" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">2.考克斯比例风险模型</h1><p id="1b81" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">我们将<em class="ng">存活率</em>定义为一段时间后未经历不良事件(如死亡)的患者百分比。</p><p id="88af" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">Cox 比例风险模型可以评估变量和生存率之间的关系。给定一组协变量<code class="fe nh ni nj nk b">x</code>，它将风险函数定义为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/19b7df93def5372c9b1ef80a1e7d321c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*UF5E-dF53b768S1rld4zZw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="959c" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">从公式中，我们观察到风险函数<code class="fe nh ni nj nk b">h(t|x)</code>与基线风险函数<code class="fe nh ni nj nk b">h₀(t)</code>和相对风险<code class="fe nh ni nj nk b">exp(βx)</code>成比例。</p><p id="5125" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">潜在的风险函数<code class="fe nh ni nj nk b">h₀(t)</code>不依赖于协变量。由于<code class="fe nh ni nj nk b">h₀(.)</code>的形式未指定，该模型为半参数模型。</p><p id="e707" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">让我们通过一个只有一个协变量的简化场景来解释模型系数的含义。让我们考虑一个危险因素<code class="fe nh ni nj nk b">xᵢ</code>，例如吸烟，作为二元变量(0:不吸烟者<em class="ng">对</em> 1:吸烟者)。Cox 模型可表示为<code class="fe nh ni nj nk b">h(t|xᵢ)= h₀(t)exp(βxᵢ)</code>，其中<code class="fe nh ni nj nk b">exp(β)</code>表示吸烟与不吸烟相比，不良事件的<strong class="ls iu">相对风险:</strong></p><ul class=""><li id="d11b" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated">吸烟带来的风险:<br/> <code class="fe nh ni nj nk b">(xᵢ=1): h₀(t)exp(β⋅xᵢ) = h₀(t)exp(β⋅1) = h₀(t)exp(β)</code></li><li id="2ea4" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated">不吸烟带来的风险:<br/> <code class="fe nh ni nj nk b">(xᵢ=0): h₀(t)exp(β⋅xᵢ) = h₀(t)exp(β⋅0) = h₀(t)</code></li><li id="9122" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated">相对风险=吸烟带来的风险/不吸烟带来的风险:<br/> <code class="fe nh ni nj nk b">h₀(t)exp(β) / h₀(t) = exp(β)</code></li></ul><p id="fab4" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">相对风险<code class="fe nh ni nj nk b">exp(β)</code>——也称为<strong class="ls iu">风险比</strong>——是恒定的，不依赖于时间。</p><h1 id="5627" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">3.优化问题</h1><p id="ac16" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">在数据科学中，将模型“拟合”到数据集的任务表示搜索优化某个目标函数的模型参数集。一些常见的例子是损失函数的最小化或对数似然的最大化。</p><p id="dabe" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在我们的例子中，我们需要在不知道<code class="fe nh ni nj nk b">h₀(.)</code>的情况下估计<code class="fe nh ni nj nk b">β</code>。为此，Cox 提出了最大化部分可能性:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/dc66f15cf435a168ec77c7684e96ea03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*j2Lzv65-wFKWtxzfZTBjyQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="ce70" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在上一个等式中:</p><ul class=""><li id="a591" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated"><code class="fe nh ni nj nk b">K</code>是按时间顺序排列的事件(死亡)时间的集合:<code class="fe nh ni nj nk b">t₁ &lt; t₂ &lt; ... &lt;tₖ</code>。</li><li id="b883" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated"><code class="fe nh ni nj nk b">R(tⱼ)</code>识别在时间<code class="fe nh ni nj nk b">tⱼ</code>处于危险中的一组受试者。</li></ul><p id="0c4b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">直觉上，部分可能性是在一组观察到的事件时间内看到不良事件的条件概率的产物，给定在这些时间处于危险中的一组患者，并假设成比例的危险。</p><p id="df3b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们可以观察到:</p><ul class=""><li id="7327" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated"><code class="fe nh ni nj nk b">L(β)</code>独立于<code class="fe nh ni nj nk b">ho(t)</code>，可以不指定。</li><li id="99b2" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated"><code class="fe nh ni nj nk b">L(β)</code>不考虑实际的事件次数，而只考虑它们的<strong class="ls iu">顺序</strong>。</li></ul><p id="2025" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们可以将<strong class="ls iu">对数部分似然</strong>推导为:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/293160ecc0a71e4bd7e39047d3c0ca3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fgt9IUF9pesClco1TYGDSA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="0ded" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">在上一个等式中:</p><ul class=""><li id="d74e" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated"><code class="fe nh ni nj nk b">N</code>是被试人数。</li><li id="7d02" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated"><code class="fe nh ni nj nk b">θ = exp(βx)</code>。</li><li id="812a" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated"><code class="fe nh ni nj nk b">δⱼ</code>表示事件(1:死亡，0:其他)。</li></ul><p id="513b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">为了拟合 Cox 模型，需要找到使负对数部分似然最小化的<code class="fe nh ni nj nk b">β</code>系数。</p><p id="9a70" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们记得，在大多数情况下，负偏似然是一个严格凸函数。因此，它有一个唯一的全局极小值。</p><h1 id="d192" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">4.履行</h1><p id="a623" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">让我们导入所需的库:</p><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="aee8" class="nw kz it nk b be nx ny l nz oa">import numpy as np<br/>import matplotlib.pyplot as plt<br/>from scipy.optimize import minimize<br/>from sksurv.datasets import load_whas500</span></pre><p id="54a2" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们加载了在<code class="fe nh ni nj nk b">scikit-survival</code> ⁵包中可用的<em class="ng">伍斯特心脏病发作研究数据集</em> ⁴。特别是:</p><ul class=""><li id="262e" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated">我们重点关注两个协变量:<br/> - <code class="fe nh ni nj nk b">afb</code>:房颤(0:否，1:是)<br/> - <code class="fe nh ni nj nk b">mitype</code> : MI 型(0:非 Q 波，1: Q 波)</li><li id="ee23" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated">我们调整数据以说明<strong class="ls iu">关系</strong>，即同时出现不良事件的患者。由于连续风险的假设，考克斯模型不承认联系。为了简单起见，我们在每个事件日期中添加少量随机噪声来消除它们。</li><li id="c575" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated">我们按日期对数据集进行排序，因为部分可能性要求<strong class="ls iu">排序的</strong>事件时间。</li></ul><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="d47b" class="nw kz it nk b be nx ny l nz oa"># load the whas500 dataset<br/>X, target = load_whas500()<br/><br/># let us consider two covariates<br/>cols = ["afb", "mitype"]<br/><br/>df = X[cols].\<br/>        rename(columns={cols[0]: "v1", <br/>                        cols[1]: "v2"}).\<br/>        astype(float)<br/><br/># extract events and respective times<br/>df["event"], df["time"] = [list(i) for i in zip(*target)]<br/><br/># add random noise to the event time to avoid ties<br/>df.time = df.time.apply(lambda x : x + np.random.normal(2, 1))<br/><br/># sort observations by descending event time<br/>df = df.sort_values("time", ascending=False).reset_index(drop=True)<br/><br/># inspect first rows<br/>df.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/5c1576c66af1e4f6a1902510628c63c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*-J4JRfnH_pPimILZNC66Og.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">开始数据集。<strong class="bd oc"> v1，v2 </strong>:协变量；<strong class="bd oc">事件</strong>:真/假(死亡/无事件)；<strong class="bd oc">时间</strong>:事件发生的时间。图片作者。</p></figure><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="0254" class="nw kz it nk b be nx ny l nz oa">v = df[["v1", "v2"]].to_numpy()<br/>time, event = df.time.to_numpy(), df.event.to_numpy().astype(int)</span></pre><p id="95cf" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">现在，我们需要定义优化任务的目标函数，即<strong class="ls iu">负</strong>对数部分似然，我们将最小化它:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/18a0a31c3de2a4710e47ebffea5447d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDFwLW5cac9v3r1sfr6DRA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">负对数-部分可能性。图片作者。</p></figure><p id="627e" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><strong class="ls iu"> <em class="ng">注</em> </strong>:在标准机器学习问题中，<code class="fe nh ni nj nk b">X</code>一般描述输入特征。相反，在我们的例子中，未知变量是<code class="fe nh ni nj nk b">β</code>，我们试图找到它的最佳值。</p><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="4f09" class="nw kz it nk b be nx ny l nz oa">def get_theta(x):<br/>    '''<br/>    Return theta as per negative log-partial likelihood<br/>    of the Cox model and its gradient.<br/>    It assumes input features v to be ordered by event time.<br/>    <br/>    Args:<br/>        - x: beta coefficients <br/>    <br/>    Output:<br/>        - theta_l: cumulative theta &lt;numpy.ndarray&gt;<br/>        - theta_l_v: cumulative theta by features &lt;numpy.ndarray&gt;<br/>    '''<br/>    theta = np.exp(np.dot(v, x))<br/>    theta_l = np.cumsum(theta)<br/>    theta_l_v = np.cumsum(v * theta.reshape(-1,1), axis=0)<br/>    return theta_l, theta_l_v<br/><br/><br/>def objective_function(x):<br/>    '''<br/>    Return the negative log-partial likelihood <br/>    of the Cox model<br/>    <br/>    Args:<br/>        - x: beta coefficients &lt;numpy.ndarray&gt;<br/>    Output:<br/>        - Negative log-partial likelihood of the Cox model<br/>    '''<br/>    theta_l, _ = get_theta(x)<br/>    return -np.sum(event * (np.dot(v, x) - np.log(theta_l)))</span></pre><p id="07f7" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们导出目标函数的<strong class="ls iu">梯度</strong>，即其相对于<code class="fe nh ni nj nk b">β</code>的导数，如下所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/c7dfae4a2e8e78aabd446a7d68d1c146.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzfHv3HA25t1n4oSNa3UWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">负对数部分似然的梯度。图片作者。</p></figure><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="2caa" class="nw kz it nk b be nx ny l nz oa">def gradient(x):<br/>    '''<br/>    Return the gradient of the negative log-partial<br/>    likelihood of the Cox model<br/>    <br/>    Args:<br/>        - x: beta coefficients &lt;numpy.ndarray&gt;<br/>    Output:<br/>        - Gradient of the objective function<br/>    '''<br/>    theta_l, theta_l_v = get_theta(x)<br/>    return -np.sum(event.reshape(-1,1) * (v-(theta_l_v/theta_l.reshape(-1,1))), axis=0)</span></pre><p id="2d79" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们现在可以初始化<code class="fe nh ni nj nk b">β</code>并执行最小化任务。我们使用<em class="ng">牛顿-CG </em> ⁶算法和<code class="fe nh ni nj nk b">scipy</code>软件包:</p><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="da35" class="nw kz it nk b be nx ny l nz oa"># starting values for beta<br/>beta = np.array([1, 1])<br/><br/>opt_result = minimize(<br/>    objective_function,<br/>    beta, <br/>    method = "Newton-CG",<br/>    jac = gradient<br/>)<br/><br/>opt_result</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/6ea1892a86d6a3e23641debf0a87624e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*91EV7yU-dHntYkK2ydx1zw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">优化任务的输出。作者的<code class="fe nh ni nj nk b">β coefficients are stored in x.</code>图片。</p></figure><p id="4a45" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">结果是:</p><ul class=""><li id="2caf" class="lq lr it ls b lt nb lv nc lx nm lz nn mb no md np mf mg mh bi translated"><code class="fe nh ni nj nk b">β₁</code> = 0.5293</li><li id="4369" class="lq lr it ls b lt mj lv mk lx ml lz mm mb mn md np mf mg mh bi translated"><code class="fe nh ni nj nk b">β₂</code> = -0.6541</li></ul><p id="fd6d" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">我们可以使用库将 Cox 模型拟合到相同的输入数据上，并验证我们将为<code class="fe nh ni nj nk b">β</code>获得相同的一组值:</p><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="3cac" class="nw kz it nk b be nx ny l nz oa">from sksurv.linear_model import CoxPHSurvivalAnalysis<br/><br/>model = CoxPHSurvivalAnalysis()<br/>model_fit = model.fit(<br/>    df[["v1", "v2"]], <br/>    np.array(list(zip(df.event, df.time)), dtype=np.dtype("bool, float")))<br/><br/>model_fit.coef_</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/2efe9b001c13b7a4348cfde872be6e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*CWWYLcwiy74bVTjV0MCEJw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="6ab1" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">事实上，<code class="fe nh ni nj nk b">β</code>系数几乎相同，小数点后第七位略有差异。</p><p id="8474" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">让我们画出估计的最优值和目标函数:</p><pre class="kj kk kl km gt ns nk nt bn nu nv bi"><span id="25cd" class="nw kz it nk b be nx ny l nz oa">def objective_function_in_x(x0, x1):<br/>    '''<br/>    Return the negative log-partial likelihood <br/>    of the Cox model evaluated in the given beta<br/>    <br/>    Args:<br/>        - x0: input beta_0 &lt;numpy.ndarray&gt;<br/>        - x1: input beta_1 &lt;numpy.ndarray&gt;<br/>    Output:<br/>        - objective function in beta_0, beta_1 &lt;numpy.ndarray&gt;<br/>    '''<br/>    v0, v1, l = v[:,0], v[:,1], v.shape[0]<br/>    theta = np.exp(x0*v0 + x1*v1)<br/>    return -np.sum(event * ((x0*v0 + x1*v1) - np.log(np.cumsum(theta).reshape(-1, l))))<br/><br/>def get_plot_data(inf=-5, sup=5, size=10):<br/>    '''<br/>    Return a three-dim square box with the evaluation<br/>    of the negative log-partial likelihood of the Cox model<br/>    <br/>    Args:<br/>      - inf: min value of the box, default: -5 &lt;int&gt;<br/>      - sup: min value of the box, default: 5 &lt;int&gt;<br/>      - size: size of the output coordinates arrays, default: 10 &lt;int&gt;<br/>    Output:<br/>      - x0: input beta_0 &lt;numpy.ndarray&gt;<br/>      - x1: input beta_1 &lt;numpy.ndarray&gt;<br/>      - z: objective function in beta_0, beta_1 &lt;numpy.ndarray&gt;<br/>    '''<br/>    x0, x1 = np.linspace(inf, sup, size), np.linspace(inf, sup, size)<br/>    x0, x1 = np.meshgrid(x0, x1)<br/>    z = np.zeros((size, size))<br/>    for i in range(0, x0.shape[0]):<br/>        for j in range(0, x0.shape[1]):<br/>            z[i][j] = objective_function_in_x(x0[i][j], x1[i][j])<br/>    return x0, x1, z<br/><br/>def get_min_obj_function(model):<br/>    '''<br/>    Return coordinates of local optimum found with optimization<br/>    <br/>    Args:<br/>      - model: instance of &lt;scipy.optimize._optimize.OptimizeResult&gt;<br/>    Output:<br/>      - x0: optimum for beta_0 &lt;numpy.ndarray&gt;<br/>      - x1: optimum for beta_1 &lt;numpy.ndarray&gt;<br/>      - z: objective function in the optimum &lt;numpy.ndarray&gt;<br/>    '''<br/>    x0, x1 = np.array(model.x[0]), np.array(model.x[1])<br/>    z = objective_function_in_x(x0, x1)<br/>    return x0, x1, z<br/><br/># generate data<br/>x0, x1, z = get_plot_data(-5, 5, 10)<br/>x0_min, x1_min, z_min = get_min_obj_function(opt_result)<br/><br/># plot the objective function and the local optimum<br/>fig = plt.figure(figsize=plt.figaspect(0.4))<br/><br/># left subplot<br/>ax = fig.add_subplot(1, 2, 1, projection="3d")<br/>ax.contour3D(x0, x1, z, 100, cmap="viridis")<br/>ax.scatter(x0_min, x1_min, z_min, marker="o", color="red", linewidth=50000)<br/>ax.set_xlabel("$β_1$")<br/>ax.set_ylabel("$β_2$")<br/>ax.set_zlabel("- Log-Partial Likelihood")<br/><br/># right subplot<br/>ax = fig.add_subplot(1, 2, 2, projection="3d")<br/>ax.contour3D(x0, x1, z, 100, cmap="viridis")<br/>ax.scatter(x0_min, x1_min, z_min, marker="o", color="red", linewidth=50000)<br/>ax.set_xlabel("$β_1$")<br/>ax.set_ylabel("$β_2$")<br/>ax.set_zlabel("- Log-Partial Likelihood")<br/>ax.view_init(10, 30)<br/>fig.suptitle("Negative log-partial likelihood of the Cox model with local optimum", fontsize=10);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/88d5eec6f33ad03b908839ef65729006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q4vE1kzWnv0V-iQnbvtALg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片作者。</p></figure><p id="b94a" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><em class="ng">注</em>:先前定义的函数的优化问题可以用任意数量的输入变量<code class="fe nh ni nj nk b">v</code>来解决。然而，三维图只需要考虑两个。事实上，一个三维绘图只能为每个轴显示一个<code class="fe nh ni nj nk b">β</code>系数。</p><p id="474a" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">从图中可以看出，负对数部分似然是一个凸损失函数。</p><h1 id="0e6a" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">5.结论</h1><p id="51f0" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">在生存分析的背景下，我们引入了 Cox 比例风险模型，并对输入数据进行拟合。特别是，我们用 Python 写了负对数部分似然及其梯度。然后，我们将其最小化，以找到最佳的模型参数集。</p><h1 id="99e3" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">6.参考</h1><p id="b0c9" class="pw-post-body-paragraph mo mp it ls b lt lu ju mq lv lw jx mr lx ms mt mu lz mv mw mx mb my mz na md im bi translated">[1] D. R. Cox，<em class="ng">回归模型和生命表</em>，皇家统计学会杂志。B 系列(方法学)，第 34 卷，第 2 期。，第 187-220 页，1972 年。</p><p id="1d1b" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[2]<a class="ae mi" href="https://en.wikipedia.org/wiki/Likelihood_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Likelihood_function</a></p><p id="ed69" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[3] C. M. Winson 等，<em class="ng">Cox 部分似然的 Fenchel 对偶及其在生存核学习中的应用</em>，医学中的人工智能，<br/> vol. 116，102077，2021。</p><p id="0e0e" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[4]s . pl sterl，<em class="ng"> scikit-survival:一个建立在 scikit-learn </em>之上的时间-事件分析库，机器学习研究杂志，第 21 卷，第 212 期，第 1–6 页，2020 ( <a class="ae mi" href="https://scikit-survival.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">包网站</a>)。</p><p id="071e" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[5]<a class="ae mi" href="https://scikit-survival.readthedocs.io/en/stable/api/generated/sksurv.datasets.load_whas500.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-survival . readthedocs . io/en/stable/API/generated/sk surv . datasets . load _ whas 500 . html</a></p><p id="0f02" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated">[6]<a class="ae mi" href="https://docs.scipy.org/doc/scipy/reference/optimize.minimize-newtoncg.html#optimize-minimize-newtoncg" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/scipy/reference/optimize . minimize-newtoncg . html # optimize-minimize-newtoncg</a></p><p id="62c4" class="pw-post-body-paragraph mo mp it ls b lt nb ju mq lv nc jx mr lx nd mt mu lz ne mw mx mb nf mz na md im bi translated"><em class="ng">注意</em>:数据集<code class="fe nh ni nj nk b">whas500</code>是<code class="fe nh ni nj nk b">scikit-survival</code>包中的<a class="ae mi" href="https://github.com/sebp/scikit-survival/tree/master/sksurv/datasets/data" rel="noopener ugc nofollow" target="_blank">免费提供</a>使用。<code class="fe nh ni nj nk b">scikit-survival</code>软件包是在<a class="ae mi" href="https://github.com/sebp/scikit-survival/blob/master/COPYING" rel="noopener ugc nofollow" target="_blank"> GPL v3 </a>下授权的。</p></div></div>    
</body>
</html>