<html>
<head>
<title>Shortening model deployment with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow缩短模型部署</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/shortening-model-deployment-with-tensorflow-d5a11044d0d#2022-09-28">https://towardsdatascience.com/shortening-model-deployment-with-tensorflow-d5a11044d0d#2022-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c1f4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用TensorFlow简化ML模型部署和服务</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/38efa4aba21f88752c9ff59895515f0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*ULjsHtYba4KCXRuCZsDgmg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated"><a class="ae kr" href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="noopener ugc nofollow" target="_blank">稳定扩散</a>生成的图像来自提示“酷炫的机器学习和AI stuff”。</p></figure><p id="3716" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi lo translated"><span class="l lp lq lr bm ls lt lu lv lw di"> U </span>通常，对于现实生活中的机器学习应用程序，最终目标是在生产中部署模型以供客户使用。但对于一个由机器学习应用程序驱动的系统来说，不仅仅是模型预测，还有另外两个主要步骤是预处理和后处理。</p><p id="0b59" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">预处理</strong>与实际预测之前的所有步骤相关。对于图像分类，它可以是归一化，通常，视觉模型要求输入像素在0和1之间。在文本模型的情况下，预处理可以是文本标记化或删除空格和标点符号。预处理可以采取多种形式，但归根结底是处理输入，以便模型可以做出可靠的预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/df1560cc2b09d2257bb491bebd84f6df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*z820aI4Y_4qQYKU0JMZD4A.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">NLP任务的预处理管道</p></figure><p id="a1ee" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">另一方面，后处理</strong>负责处理模型输出所需的所有步骤，以使其呈现理想的形式。在分类任务的情况下，通常，模型输出每个类别的概率，但是终端用户通常不关心这些，所以我们需要处理这些输出，以便它们可以采用标签的形式，在文本情感分析中，这些标签通常是“正面”和“负面”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/d0eb13d19544666a683f1ab45b5ac942.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*zRuplNVjJDft7ximELTTbw.jpeg"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">后处理管道</p></figure><p id="96bd" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi lo translated">当预处理和后处理成为一个复杂系统的一部分时，挑战就开始了，这个复杂系统可能已经在使用中，并且需要维护。</p><p id="5ddf" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">想象以下场景—您是一家提供医疗保健ML产品的公司的成员，该产品包括一个API，客户可以使用该API发送图像并预测x射线是否有健康问题。最初，工程师们使用<a class="ae kr" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>模型创建了一个具有良好结果的基线，因此该公司开始使用它，但经过几周的研究，科学家们提出了一个使用<a class="ae kr" href="https://arxiv.org/abs/1801.04381" rel="noopener ugc nofollow" target="_blank"> MobileNetV2 </a>的改进版本，因此团队更换了模型，几周后，他们再次提出了一个使用<a class="ae kr" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank"> EfficientNetB3 </a>的更好的模型。太好了！在一个月内，您的结果提高了3倍，您的客户也更高兴了，但这里的挑战是什么？</p><p id="895b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在那一个月里，你必须调整你的系统来处理三种不同的模型，每一种模型都有不同的输入。举例来说，让我们假设团队使用基于TensorFlow的模型，并使用<a class="ae kr" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank"> Keras应用模块</a>加载它们，在那里您可以看到预训练的<a class="ae kr" href="https://keras.io/api/applications/resnet/#resnet50-function" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir"> ResNet-50 </strong> </a>期望输入具有224 x 224 x 3(宽度x高度x通道)的大小，通道是BGR的格式，并且每个颜色通道相对于ImageNet数据集以零为中心。<a class="ae kr" href="https://keras.io/api/applications/mobilenet/#mobilenetv2-function" rel="noopener ugc nofollow" target="_blank"> <strong class="ku ir"> MobileNetV2 </strong> </a>也期望图像大小为224 x 224 x 3，但期望像素在-1和1范围内。最后，<a class="ae kr" href="https://keras.io/api/applications/efficientnet/#efficientnetb3-function" rel="noopener ugc nofollow" target="_blank"><strong class="ku ir">efficient net B3</strong></a>期望图像的大小为384 x 384 x 3，并且已经将图像缩放作为模型的一部分。<br/>在这个场景中，您有一个带有特定预处理例程的初始管道，然后必须更改它以支持第二个模型，然后再次更改它以支持第三个模型，现在想象一下，如果您需要一周多次交换模型，并行服务多个模型，回滚到以前的模型，对照新模型评估旧模型，很容易混淆不同的预处理例程，丢失代码，或者忘记重要的细节。 特别是因为该公司很可能为不同的客户提供多种服务，这只是为了展示事情有多容易失控。</p><p id="f97b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi lo translated"><span class="l lp lq lr bm ls lt lu lv lw di">那么</span>我们能做什么？虽然管理这样一个系统确实是一项复杂的任务，但是我们可以通过将模型的预处理和后处理逻辑融合或嵌入其中来使事情变得容易得多。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lz"><img src="../Images/6498dad56ad36f11417f78b7227e68db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55aZBvZVg96dyThSKjMNaA.jpeg"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">常规流水线与嵌入处理逻辑的流水线</p></figure><p id="fd22" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们通过一个实际的例子来展示这个概念。<br/>在这里，我将使用TensorFlow和“<a class="ae kr" href="https://archive.ics.uci.edu/ml/datasets/heart+Disease" rel="noopener ugc nofollow" target="_blank">克里夫兰心脏病诊所基金会</a>”数据集构建一个简单的系统，目标是对患者是否患有心脏病进行分类。这个例子是基于Keras代码的例子“<a class="ae kr" href="https://keras.io/examples/structured_data/structured_data_classification_from_scratch/" rel="noopener ugc nofollow" target="_blank">结构化数据分类从零开始</a>”。<br/>你可以按照这个例子用<a class="ae kr" href="https://colab.research.google.com/drive/1NXJL1c2kNzYJxbHZNwlkhsGclj8BGc4V?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>来写完整的代码。</p><p id="e316" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了简化起见，我们将只使用这些功能的一个子集，以下是关于它们的一些信息:</p><blockquote class="me mf mg"><p id="bb19" class="ks kt mh ku b kv kw jr kx ky kz ju la mi lc ld le mj lg lh li mk lk ll lm ln ij bi translated"><strong class="ku ir">年龄:</strong>年龄以年为单位“数值”<br/> <strong class="ku ir">性别:</strong> (1 =男性；0 =女性)<br/> <strong class="ku ir"> CP: </strong>胸痛类型(0，1，2，3，4)<br/><strong class="ku ir">Thal:</strong>3 =正常；6 =修复缺陷；<br/><strong class="ku ir">7 =可逆性缺损【目标:】</strong>诊断心脏病(1 =真；0 =假)“目标(二进制)”</p></blockquote><p id="94cf" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我特别选择了这些特性，因为它们有不同的数据类型和不同的预处理要求。</p><h1 id="41a7" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">张量流预处理层</h1><p id="fab2" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">TensorFlow有一种内置的方式来处理不同的数据类型，即<a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/" rel="noopener ugc nofollow" target="_blank">预处理层</a>，与常规预处理步骤相比，它们的一大优势是您可以将这些层与模型或TensorFlow数据集结合起来，以优化端到端的管道，同时使部署变得更加容易。</p><p id="545b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">对于常规用例，需要对这些层进行调整以了解如何处理数据,“调整”步骤类似于我们在标准化数据之前需要了解某个特征的均值和标准差，这就是我们在第一种情况下要做的事情。</p><h2 id="1675" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">标准化(年龄特征)</h2><p id="10f4" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">对于数字特征“年龄”,我们将应用特征归一化，换句话说，我们将移动和缩放输入到以0为中心的分布中，标准差为1，这正是<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/numerical/normalization/" rel="noopener ugc nofollow" target="_blank">normalization</a></code>层所做的。首先，我们创建一个TensorFlow数据集，该数据集只加载来自pandas数据框的数据和原始要素和标注格式的地图</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="d627" class="ni mm iq nx b gy oc od l oe of">raw_data = tf.data.Dataset.from_tensor_slices(<br/>            (dict(data[[“age”, “sex”, “cp”, “thal”]]), data.target))</span></pre><p id="673a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">之后，我们可以创建预处理层，通过使用<code class="fe nu nv nw nx b">adapt</code>方法来学习如何使用该数据集对要素进行预处理。</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="a5af" class="ni mm iq nx b gy oc od l oe of">age_preprocessing = L.Normalization()<br/>age_preprocessing.adapt(raw_data.map(lambda x, y: x["age"])<br/>                              .map(lambda x: tf.expand_dims(x, -1)))<br/>print(f"Age mean: {age_preprocessing.mean.numpy()[0]:.2f}")<br/>print(f"Age variance: {age_preprocessing.variance.numpy()[0]:.2f}")<br/>---------- Outputs ----------<br/>Age mean: 54.27<br/>Age variance: 81.74</span></pre><p id="5518" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里发生的事情是，我正在获取<code class="fe nu nv nw nx b">raw_data</code>数据集，并通过映射lambda操作仅提取<code class="fe nu nv nw nx b">age</code>特征，然后我扩展维度以适应预处理层的预期格式。<br/>适应数据后，<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/numerical/normalization/" rel="noopener ugc nofollow" target="_blank">Normalization</a></code>层学习到“年龄”特征的均值为54.27，方差为81.74。现在在此基础上，它可以正常化该特征的新数据。</p><h2 id="0f02" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">IntegerLookup(性特征)</h2><p id="2d60" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">接下来，我们可以学习预处理“性别”特征，这是一个分类数字特征，这意味着每个值实际上意味着不同的类别，这里它们是(1 =男性；0 =女性)。对于这种特定情况，我们还希望该层能够处理未知或错误的值，在正常情况下，如果输入不同于1或0，该层将抛出错误，并且不会给出输出，但这里这些值将被预处理为“-1”，模型将返回预测，这种行为取决于每个上下文。</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="04c0" class="ni mm iq nx b gy oc od l oe of">sex_preprocessing = L.IntegerLookup(output_mode="int")<br/>sex_preprocessing.adapt(raw_data.map(lambda x, y: x["sex"]))<br/>sex_vocab = sex_preprocessing.get_vocabulary()<br/>print(f"Vocab size: {len(sex_vocab)}")<br/>print(f"Vocab sample: {sex_vocab}")<br/>---------- Outputs ----------<br/>Vocab size: 3<br/>Vocab sample: [-1, 1, 0]</span></pre><p id="4a29" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里的<code class="fe nu nv nw nx b">output_mode=”int”</code>表示这一层的输出是一个<code class="fe nu nv nw nx b">Integer</code>。<br/>在适应数据之后，<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup/" rel="noopener ugc nofollow" target="_blank">IntegerLookup</a></code>层了解到“性别”特征具有大小为3(包括OOV)的词汇表，并分配<code class="fe nu nv nw nx b">[-1, 1, 0] </code>作为输入的可能值。请注意，这一层的主要好处是处理未知值，因为输出等于输入。</p><h2 id="4c76" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">整数查找(cp功能)</h2><p id="1be0" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">对于另一个分类数字特征“cp”特征，我们也将使用类似于“sex”特征的<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup/" rel="noopener ugc nofollow" target="_blank">IntegerLookup</a></code>层，但是我们将改变输出格式。</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="dd59" class="ni mm iq nx b gy oc od l oe of">cp_preprocessing = L.IntegerLookup(output_mode="one_hot")<br/>cp_preprocessing.adapt(raw_data.map(lambda x, y: x["cp"]))<br/>cp_vocab = cp_preprocessing.get_vocabulary()<br/>print(f"Vocab size: {len(cp_vocab)}")<br/>print(f"Vocab sample: {cp_vocab}")<br/>---------- Outputs ----------<br/>Vocab size: 6<br/>Vocab sample: [-1, 4, 3, 2, 1, 0]</span></pre><p id="9ab1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这里的<code class="fe nu nv nw nx b">output_mode=”one_hot”</code>表示该层的输出具有<a class="ae kr" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank">一键编码</a>格式，在这种情况下，每个输出都具有类似于“[0，0，0，0，1，0]”的格式，这种格式可用于为模型提供更多关于特征的信息，尤其是如果特征不具有<a class="ae kr" href="https://en.wikipedia.org/wiki/Boolean_data_type" rel="noopener ugc nofollow" target="_blank">布尔</a>或<a class="ae kr" href="https://en.wikipedia.org/wiki/Ordinal_data" rel="noopener ugc nofollow" target="_blank">序数</a>性质。<br/>在适应数据之后，<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/categorical/integer_lookup/" rel="noopener ugc nofollow" target="_blank">IntegerLookup</a></code>层了解到“cp”特征具有大小为6(包括OOV)的词汇表，并分配<code class="fe nu nv nw nx b">[-1, 4, 3, 2, 1, 0]</code>作为输入的可能值，进一步处理为独热编码格式。</p><h2 id="98ff" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">字符串查找(thal特征)</h2><p id="21ad" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">最后，对于“thal”特性，我们将使用<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup/" rel="noopener ugc nofollow" target="_blank">StringLookup</a></code>层，对于该特性，我们有可以作为文本或数字出现的字符串值。</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="a8e6" class="ni mm iq nx b gy oc od l oe of">thal_preprocessing = L.StringLookup(output_mode="one_hot")<br/>thal_preprocessing.adapt(raw_data.map(lambda x, y: x["thal"]))<br/>thal_vocab = thal_preprocessing.get_vocabulary()<br/>print(f"Vocab size: {len(thal_vocab)}")<br/>print(f"Vocab sample: {thal_vocab}")<br/>---------- Outputs ----------<br/>Vocab size: 6<br/>Vocab sample: ['[UNK]', 'normal', 'reversible', 'fixed', '2', '1']</span></pre><p id="e599" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">与“cp”功能类似，我们也有<code class="fe nu nv nw nx b">output_mode=”one_hot”</code>，这意味着该功能的输出也将有<a class="ae kr" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank">一键编码</a>格式，因为词汇表很小，这个选项应该很好。<br/>在适应数据之后，<code class="fe nu nv nw nx b"><a class="ae kr" href="https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup/" rel="noopener ugc nofollow" target="_blank">StringLookup</a></code>层了解到“thal”特征具有大小为6(包括OOV)的词汇表，并且将<code class="fe nu nv nw nx b">[‘[UNK]’, ‘normal’, ‘reversible’, ‘fixed’, ‘2’, ‘1’]</code>分配为输入的可能值，这里<code class="fe nu nv nw nx b">[UNK]</code>被分配为未知值(OOV)，并且这些值被进一步处理为独热编码格式。</p><h2 id="e351" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">合并图层和数据集</h2><p id="11ff" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">现在我们已经有了适合我们数据的所有预处理层，我们可以让它们成为我们数据集管道的一部分。这样做的动机是<a class="ae kr" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank"> tf.data pipeline </a>可以利用预处理层来使数据摄取更快、更有效。另一种选择是将这些层用作模型的一部分，并以这种方式对其进行训练，本文的“<a class="ae kr" href="https://keras.io/guides/preprocessing_layers/" rel="noopener ugc nofollow" target="_blank">在模型之前或模型内部预处理数据”一节中讨论了这种权衡。</a></p><p id="20b6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">由于这不在本文的讨论范围之内，我就不详细介绍这一部分了，但是你可以在“数据集”部分看看相关的<a class="ae kr" href="https://colab.research.google.com/drive/1NXJL1c2kNzYJxbHZNwlkhsGclj8BGc4V?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>。</p><h2 id="f7a3" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">建模</h2><p id="2a5f" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">在常规设置中，对数据进行预处理后，您将得到如下所示的模型:</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="61c3" class="ni mm iq nx b gy oc od l oe of">age_input = L.Input(shape=(1,), dtype=tf.float32)<br/>sex_input = L.Input(shape=(1,), dtype=tf.float32)<br/>cp_input = L.Input(shape=(len(cp_vocab),), dtype=tf.float32)<br/>thal_input = L.Input(shape=(len(thal_vocab),), dtype=tf.float32)</span><span id="6a7f" class="ni mm iq nx b gy og od l oe of">concat_inputs = L.Concatenate()([age_input, sex_input, <br/>                                 cp_input, thal_input])<br/>x = L.Dense(32, activation="relu")(concat_inputs)<br/>x = L.Dropout(0.5)(x)<br/>output = L.Dense(1, activation="sigmoid")(x)<br/>  <br/>model = tf.keras.models.Model(inputs=[age_input, sex_input, <br/>                                      cp_input, thal_input], <br/>                              outputs=output)<br/>model.summary()<br/>---------- Outputs ----------____________________________________________________________________<br/>Layer (type)              Output Shape Param # Connected to                      ====================================================================<br/>age (InputLayer)          [(None, 1)]  0       []                                                                                                                                    sex (InputLayer)          [(None, 1)]  0       []                                                                                                                                    cp (InputLayer)           [(None, 6)]  0       []                                                                                                                                    thal (InputLayer)         [(None, 6)]  0       []                                                                                                                                    concatenate (Concatenate) (None, 14)   0       ['age[0][0]', <br/>                                                'sex[0][0]',<br/>                                                'cp[0][0]', <br/>                                                'thal[0][0]']                                                                                                                        dense (Dense)             (None, 32)   480     ['concatenate[0][0]']                                                                                                         dropout (Dropout)         (None, 32)   0       ['dense[0][0]']                                                                                                                   dense_1 (Dense)           (None, 1)    33      ['dropout[0][0]']                                                                                                                    ====================================================================<br/>Total params: 513<br/>Trainable params: 513<br/>Non-trainable params: 0<br/>____________________________________________________________________</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi oh"><img src="../Images/f709abe45be83a8dc5311d5b282bd0f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQMyt--KvthN104g4L1Lfw.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">常规型号的图表</p></figure><p id="99b4" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这个模型会有我们在开始时讨论的所有问题，对于部署，我们需要跟踪在训练期间使用的准确的预处理参数，这将需要维护人员的大量工作。幸运的是，TensorFlow允许我们将模型预处理逻辑嵌入到模型中。</p><h2 id="ffd6" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">结合模型和预处理</h2><p id="1227" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">将预处理层与我们的模型结合起来是相当简单的，事实上，我们基本上可以将任何可以转化为张量流图的张量流操作结合起来，让我们看看新模型是什么样子的:</p><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="f926" class="ni mm iq nx b gy oc od l oe of">age_input = L.Input(shape=(1,), dtype=tf.int64)<br/>sex_input = L.Input(shape=(1,), dtype=tf.int64)<br/>cp_input = L.Input(shape=(1,), dtype=tf.int64)<br/>thal_input = L.Input(shape=(1,), dtype=tf.string)</span><span id="173d" class="ni mm iq nx b gy og od l oe of"># Preprocessing<br/>age_processed = age_preprocessing(age_input)<br/>sex_processed = tf.cast(sex_preprocessing(sex_input), <br/>                        dtype=tf.float32)<br/>cp_processed = cp_preprocessing(cp_input)<br/>thal_processed = thal_preprocessing(thal_input)</span><span id="6388" class="ni mm iq nx b gy og od l oe of"># Model prediction<br/>output = model({"age": age_processed, <br/>                "sex": sex_processed, <br/>                "cp": cp_processed, <br/>                "thal": thal_processed})</span><span id="5603" class="ni mm iq nx b gy og od l oe of"># Postprocessing<br/>label_postprocess = label_postprocessing(output)<br/>model = tf.keras.models.Model(inputs=[age_input, sex_input, <br/>                                      cp_input, thal_input], <br/>                              outputs=label_postprocess)<br/>model.summary()<br/>---------- Outputs ---------- ____________________________________________________________________<br/>Layer (type)          Output Shape Param # Connected to                      ====================================================================<br/>sex (InputLayer)      [(None, 1)]  0    []                                                                                                                                    age (InputLayer)      [(None, 1)]  0    []                                                                                                                                    cp (InputLayer)       [(None, 1)]  0    []                                                                                                                                    sex_preprocessing     (None, 1)    0    ['sex[0][0]']      <br/>thal (InputLayer)     [(None, 1)]  0    []                                                                                                                                    age_preprocessing     (None, 1)    3    ['age[0][0]'] cp_preprocessing      (None, 6)    0    ['cp[0][0]'] <br/>tf.cast (TFOpLambda)  (None, 1)    0    ['sex_preprocessing[0] [0]']                                                                                                           thal_preprocessing    (None, 6)    0    ['thal[0][0]'] <br/>model (Functional)    (None, 1)    513  ['age_preprocessing[0][0]', <br/>                                         'cp_preprocessing[0][0]', <br/>                                         'tf.cast[0][0]', <br/>                                         'thal_preprocessing[0][0]']                                                                                                          label_postprocessing  (None, 1)    0    ['model[0][0]']  ====================================================================<br/>Total params: 516<br/>Trainable params: 513<br/>Non-trainable params: 3 ____________________________________________________________________</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi oi"><img src="../Images/0605f9d6d8725714dda41832101cb5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lfnauoo_i1VsT4GosmdjIg.png"/></div></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">组合模型的图表</p></figure><p id="edf1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">请注意，我还包括了一个“后处理”层，该层负责将模型输出(0或1)映射到实际标签，我省略了创建它的代码，因为它与我们之前所做的类似，但它也包括在<a class="ae kr" href="https://colab.research.google.com/drive/1NXJL1c2kNzYJxbHZNwlkhsGclj8BGc4V?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a>中。<br/>您可以看到模型本质上是相同的，但是第二个模型将所有预处理逻辑嵌入到模型图中，这种方法的优点是您可以保存和加载该模型，并且它将拥有运行推理所需的一切。让我们看看它们有什么不同:</p><h2 id="1750" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">第一个模型的推论</h2><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="ebbd" class="ni mm iq nx b gy oc od l oe of">sample = {"age": 60, "sex": 1, "cp": 1, "thal": "fixed"}</span><span id="1a3a" class="ni mm iq nx b gy og od l oe of">sample = {"age": age_preprocessing(sample["age"]),<br/>          "sex": sex_preprocessing(sample["sex"]), <br/>          "cp": cp_preprocessing(sample["cp"]),<br/>          "thal": thal_preprocessing(sample["thal"])}</span><span id="d149" class="ni mm iq nx b gy og od l oe of">print(model.predict(sample))<br/>---------- Outputs ----------<br/>0</span></pre><h2 id="297f" class="ni mm iq bd mn nj nk dn mr nl nm dp mv lb nn no mx lf np nq mz lj nr ns nb nt bi translated">第二个模型的推论</h2><pre class="kg kh ki kj gt ny nx nz oa aw ob bi"><span id="516a" class="ni mm iq nx b gy oc od l oe of">sample = {"age": 60, "sex": 1, "cp": 1, "thal": "fixed"}</span><span id="e142" class="ni mm iq nx b gy og od l oe of">print(model.predict(sample))<br/>---------- Outputs ----------<br/>"Have heart disease"</span></pre><p id="f064" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">如您所见，使用第二种方法，您的推理服务需要做的就是加载模型并使用它。</p><h1 id="4dda" class="ml mm iq bd mn mo mp mq mr ms mt mu mv jw mw jx mx jz my ka mz kc na kd nb nc bi translated">结论</h1><p id="e2a8" class="pw-post-body-paragraph ks kt iq ku b kv nd jr kx ky ne ju la lb nf ld le lf ng lh li lj nh ll lm ln ij bi translated">在本文中，我们讨论了我们在模型部署过程中面临的与模型的预处理和后处理相关的一些挑战，我们还研究了一种显著减少认知负载和维护工作以部署和服务模型的方法，即使用TensorFlow将所有逻辑嵌入模型本身。</p><p id="e90a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir">注:“除特别注明外，所有图片均为作者所有。”</strong></p></div></div>    
</body>
</html>