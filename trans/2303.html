<html>
<head>
<title>LDA Topic Model Instability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LDA主题模型不稳定性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lda-topic-model-instability-c2fedb77d249#2022-05-20">https://towardsdatascience.com/lda-topic-model-instability-c2fedb77d249#2022-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4ccb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">没有两个LDA主题模型是相同的。主题建模者应该做什么？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c4de10a1a16b966827e4594da58996f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*cGkmjQCprjMQBJs1"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@possessedphotography?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">附身摄影</a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><p id="3d04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi ls translated"><span class="l lt lu lv bm lw lx ly lz ma di">答</span>在花费数小时调整LDA模型后，没有什么比意识到他们的模型运行与下一次有多么不同更能破坏主题建模者的一天了。LDA算法是随机的，用相同的参数对相同的数据生成的模型会产生不同的结果。这是一个特征，而不是算法的错误(试着向你的老板解释一下)。这篇文章对LDA模型的不稳定性提供了一个实用的、深入的观察，并展示了对抗其不良影响的方法。</p><p id="5e9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">之前的两篇文章<a class="ae kv" rel="noopener" target="_blank" href="/use-metrics-to-determine-lda-topic-model-size-1a1feaa1ff3c">此处</a>和<a class="ae kv" rel="noopener" target="_blank" href="/determining-the-right-lda-topic-model-size-part-ii-ff4312e9fd9">此处</a>详细介绍了确定指定LDA模型的最佳主题数量的步骤。本系列使用的语料库是一个更大的公开许可数据集<a class="ae kv" href="https://www.kaggle.com/harishcscode/all-news-articles-from-home-page-media-house" rel="noopener ugc nofollow" target="_blank">新闻文章</a>的<a class="ae kv" href="https://www.kaggle.com/datasets/danrobinson707/newsdf" rel="noopener ugc nofollow" target="_blank"> 30，000篇文章子集</a>。前面文章中概述的分析导致了将主题模型大小设置为20的决定。本文着眼于使用LDA创建的模型有多不稳定，并通过调整指标和转向LDA的一种变体— <a class="ae kv" href="https://radimrehurek.com/gensim/models/ensemblelda.html" rel="noopener ugc nofollow" target="_blank"> <em class="mb">集成LDA </em> </a> <em class="mb">来解决这种不稳定性。</em></p><p id="c056" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">(注:有关数据集、模型参数、技术细节和代码片段的更多信息，请参见附录。)</p><p id="4bcf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">不幸的是，每次从具有相同参数的相同语料库中生成LDA模型时，结果模型将是不同的。这种差异在下面的图表中得到了说明，该图表将文档类别与两种模型进行了比较，我们希望这两种模型即使不相同，至少也是相似的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">相同的参数，相同的数据，不同的结果。图片作者。</p></figure><p id="e8a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每一列代表为模型A中的每个主题分类的所有文档。这显示了模型A中的每个主题分布在模型b中的每个主题上。最清晰的相关性由模型A的主题13和模型b的主题15之间的红色单元格表示。96%的模型A的主题13文档包含在模型b的单个主题中。但是，相关性从那里迅速下降。尽管其他一切都是平等的，但这两个模型显然是不一样的。而且问题不仅仅在两个模型之间，进一步的检查暗示着模型内部是相当嘈杂的。以下是A的主题列表:</p><pre class="kg kh ki kj gt me mf mg mh aw mi bi"><span id="b327" class="mj mk iq mf b gy ml mm l mn mo">0 government president people law country obama vote republican call right<br/>1 people government kill attack official force cnn group report security<br/>2 police court old charge home family case woman death leave<br/>3 claim people london jackson muslim group last british child family<br/>4 police car people officer road fire city family report man<br/>5 french world first murray france last open set iran tennis<br/>6 win right race goal free_kick leave second first minute real_madrid<br/>7 bbc party labour last people pay uk vote election first<br/>8 facebook user apple company google gun people phone device internet<br/>9 team game win first sport play world last coach world_cup<br/>10 people study high research cent patient researcher company increase risk<br/>11 health virus patient people country ebola disease china case world<br/>12 water hospital people home die area family care river boat<br/>13 game player club season play team first last win goal<br/>14 school police student university teacher report home church investigation officer<br/>15 know life woman people think love want come family first<br/>16 russia military country russian president force official government leader united_state<br/>17 child school parent people health need report education service age<br/>18 right police miss dog leave city free_kick attempt officer foot_shot<br/>19 see first world animal people old know picture even come</span></pre><p id="c1e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">总的来说，主题本身是合理的连贯和可理解的。然而，有很多重叠——单词出现在多个主题中，这无疑增加了分类问题。通过将每个模型的主题词与其他主题中的主题词进行比较，可以明显看出主题表示有多嘈杂:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型主题词的重叠。图片作者。</p></figure><p id="b846" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果每个主题词分组与模型中的其他分组有最小的重叠就好了。如果每个主题由一组独特的单词组成，那么整个图表将由被红色对角线整齐分开的深蓝色单元格组成。然而在这个图表中，我们可以看到有很多很多重复的单词。从主题9和13可以清楚地看出这个问题:</p><pre class="kg kh ki kj gt me mf mg mh aw mi bi"><span id="0e86" class="mj mk iq mf b gy ml mm l mn mo">9 team game win first sport play world last coach world_cup<br/>13 game player club season play team first last win goal</span></pre><p id="0c4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">术语重叠的程度可以通过计算每列中匹配单词的平均值来表示，对于该模型，该平均值为26.7，而如果每个主题集是唯一的，则该值为10。</p><p id="1201" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了调整这个模型，我们可以增加<em class="mb">遍数</em>，在Gensim文档中描述为“在训练期间通过语料库的次数”，从而提供额外的回归来微调模型。碰撞<em class="mb">通过</em>从默认值1到10，当分析所有主题的单词分布时，我们看到一个显著的差异:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">碰撞通过后减少了主题词重叠。图片作者。</p></figure><p id="8997" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单个模型中的共享单词数量急剧减少。单程模型的平均值为26.7，而该模型的平均值为16.4。类似地，当比较跨两个模型的文档/主题分布时，模型相似性的改进是明显的:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">跨两个模型的文档分布。图片作者。</p></figure><p id="82d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">向下阅读各列，很明显，与第一个例子相比，总噪声已经显著降低。不幸的是，除了<em class="mb">通道，</em>之外，在LDA基本算法中没有其他参数可以调整，我们可以在这种情况下使用这些参数来实现模型间的内聚性。然而，我们可以采用一种变体算法:<em class="mb"> </em>集成LDA。这种混合LDA实现直接解决了不稳定性问题。</p><p id="211f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mb"> Ensemble LDA </em>允许合并多个模型以创建单个混合模型。上面例子中的模型都是二十个主题模型。这是使用基于PMI的指标和试探法可以最好地确定的值(见以前的文章)。然而，除了合并多个LDA运行之外，集成LDA也不同于LDA算法，因为它在其处理期间确定最佳主题模型大小。在这种情况下，它选择代表十二个主题的语料库。对新生成的词汇表中重叠部分的分析产生:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">集成模型中的主题词重叠。图片作者。</p></figure><p id="2969" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个版本的平均14.92比之前的16.4有所提高，很明显，但没有<em class="mb">通过</em>干预那么引人注目。但是，当比较文档分布时，有一个显著的差异:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">集成模型中两个模型之间的文档分布。图片作者。</p></figure><p id="3811" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们看到了一个更有益的结果，在两个模型中的所有12个主题上都有广泛的一致。不仅大多数主题在每个模型中都有很好的表现，而且从一个主题到下一个主题几乎没有流血。八个主题从一个模型到下一个模型有90%的镜像。三个在80%以上，一个在82%。</p><p id="82f1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文已经展示了LDA主题模型在不同的运行中可能会很不一致。它进一步检查了增加<em class="mb">通道</em>数量的影响，这提高了模型到模型的稳定性。然而，通过使用系综LDA可以看到显著的提升，它通过基本上消除重叠和噪声而显著地改善了最终输出。除了处理不稳定性问题，集成LDA还引入了为模型选择最佳主题大小的能力。有趣的是，12个主题的选择，与使用指标表示的20个主题的大小明显不同，引入了关于基于PMI的指标和整体LDA过程的输出之间的差异的问题，但这是未来文章的素材。</p><h2 id="8700" class="mj mk iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">附录:技术细节</h2><p id="d9f2" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">这篇文章基于三种不同模型配置的三次迭代。为了测试LDA模型的每次运行是不同的，但是这些不一致性在每次运行中大致相等的前提，创建并比较了三个模型。文章中只显示了A / B的比较，但B / C和A / C实际上是相似的。</p><p id="e14d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个模型都是从三万个文档语料库中创建的，这里的<a class="ae kv" rel="noopener" target="_blank" href="/use-metrics-to-determine-lda-topic-model-size-1a1feaa1ff3c"/>和这里的<a class="ae kv" rel="noopener" target="_blank" href="/determining-the-right-lda-topic-model-size-part-ii-ff4312e9fd9"/>进行了更详细的讨论。语料库是小写的，去掉了停用词、数字和标点符号。进一步的修剪去除了所有不是名词、动词、副词或形容词的词类。一个定制的十几个单词的列表也被删除了:</p><pre class="kg kh ki kj gt me mf mg mh aw mi bi"><span id="4deb" class="mj mk iq mf b gy ml mm l mn mo">say, year, make, find, use, get, mr, work, state, time, also, take, new, look. show, day, go, tell</span></pre><p id="081a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，由此产生的超过100，000个单词的字典减少到20，000个。</p><p id="dfa8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成系综模型时<em class="mb">道次</em>被设置为15，<em class="mb">主题号</em>为20，<em class="mb">模型</em>为16。这些不能与基本的LDA算法直接比较。</p><p id="7f47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Gensim <a class="ae kv" href="https://radimrehurek.com/gensim/models/ldamulticore.html" rel="noopener ugc nofollow" target="_blank"> ldamulticore </a>实现用于生成LDA模型。Gensim的<a class="ae kv" href="https://radimrehurek.com/gensim/models/ensemblelda.html" rel="noopener ugc nofollow" target="_blank"> ensemblelda </a>实现用于集合运行。在每次运行中，使用0.05的<em class="mb">α值和0.5的<em class="mb">β值。Thes值是通过测试得出的。</em></em></p><p id="51fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在第一次运行中，在调整<em class="mb">通道</em>参数之前，主题被设置为二十。在第二轮测试中，<em class="mb">通行证</em>从默认的一个增加到十个。整体LDA支持<em class="mb">通道、</em>通道，这与LDA模型中的效果相似。然而，集合其模型大小参数与基本LDA实现有意义地不同，并且它引入了<em class="mb"> num_models </em>参数。对于第三组模型，通道设置为15，主题设置为20，模型设置为16。需要注意的是，这并不意味着生成了二十个主题。相反，生成16个模型，每个模型有20个主题，然后分析全部320个主题，这导致模型为最终模型选择12个主题的混合。上述分析中不包括设置为12个主题和240个通道的三个基本LDA模型。选择高数量的通道来近似集合的多个模型的累积效果，以及测试减少主题数量可能影响模型稳定性的假设。也不是这种情况，并且结果非常类似于讨论中包括的十遍基本LDA运行。</p><p id="e035" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在启用了GPU的Colab+环境中，生成单遍模型大约需要1分钟，十遍模型需要10分钟，而整体模型大约需要3小时45分钟。240次pass base LDA运行每次大约需要三个小时。</p><p id="c016" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管事实上超过前五个单词的额外单词对文档分类的影响迅速减小，但还是选择了十个单词的词汇表用于示例和测试。比较五个单词和十个单词的统计差异可以忽略不计，增加的单词是为了使描述更容易理解。</p><p id="e310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">词汇矩阵比较是使用以下代码生成的:</p><pre class="kg kh ki kj gt me mf mg mh aw mi bi"><span id="0317" class="mj mk iq mf b gy ml mm l mn mo">def CompareVocabs(model1, model2) :<br/>  compareMatrix = pd.DataFrame()<br/>  for x in range(len(model1)) :<br/>    compRow = []<br/>    for y in range(len(model2)) :<br/>      compRow.append(len(set(model1[x]) &amp; set(model2[y])))<br/>    compareMatrix[x] = compRow<br/>  return compareMatrix</span></pre><p id="cc2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其中<em class="mb">模型1 </em>和<em class="mb">模型2 </em>是主题的词汇列表。</p><p id="ba74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">生成矩阵的代码比较了一个模型和另一个模型中文档的主题分布，代码如下:</p><pre class="kg kh ki kj gt me mf mg mh aw mi bi"><span id="702b" class="mj mk iq mf b gy ml mm l mn mo">def getPercentDif(dfA, topicA, dfB, topicB) :<br/>  aDF = dfA[dfA[0]==topicA]<br/>  bDF = dfB[dfB[0]==topicB]<br/>  if aDF.shape[0] == 0 :<br/>    return 0<br/>  else :<br/>    return aDF[aDF.index.isin(bDF.index)].shape[0] / aDF.shape[0]</span><span id="0954" class="mj mk iq mf b gy nl mm l mn mo">resultDF = pd.DataFrame()<br/>for y in range(aDF.shape[1]) :<br/>  vals = []<br/>  for x in range(bDF.shape[1]) :<br/>    vals.append(getPercentDif(aDF, y, bDF, x))<br/>  resultDF[y] = vals</span><span id="c8db" class="mj mk iq mf b gy nl mm l mn mo"># See note below regarding aDF and bDF</span></pre><p id="6002" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="mb"> aDF </em>和<em class="mb"> bDF </em>是从LDA输出中计算出的矩阵，这些矩阵产生主导主题(对于给定文档具有最高可能性的主题)。生成这些矩阵的代码太长了，无法在这里发布，但可以在由<em class="mb"> ModelMonster生成的<a class="ae kv" href="https://github.com/drob-xx/TopicModelTuning/blob/main/TopicModelTuning.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>的<em class="mb"> ModelMonster </em>类中找到。_ GenerateMatricies()。</em>矩阵可以通过<em class="mb">ModelMonster . topiciddfs</em>字典从实例化的model monster类中访问。</p><h2 id="cc9f" class="mj mk iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">文献学</h2><p id="59c5" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">布莱博士，Ng，A. Y .，&amp;乔丹，M. I. (2003年)。潜在狄利克雷分配。<em class="mb">机器学习研究杂志:JMLR </em>。<a class="ae kv" href="https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com" rel="noopener ugc nofollow" target="_blank">https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf?ref=https://githubhelp.com </a></p><p id="835a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">布里格尔，托拜厄斯(2019)。使用系综潜在狄利克雷分配提取可靠主题[学士论文]。英戈尔施塔特技术学校。慕尼黑:数据回复有限公司。<a class="ae kv" href="https://www.sezanzeb.de/machine_learning/ensemble_LDA/" rel="noopener ugc nofollow" target="_blank">https://www.sezanzeb.de/machine_learning/ensemble_LDA/</a></p><p id="1a3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">丹尼尔·罗宾逊(2022)。潜在狄利克雷分配的主题建模:潜在狄利克雷分配的自然语言处理技术及其在主题建模任务中的应用的实践探索。<a class="ae kv" href="https://medium.com/towards-data-science" rel="noopener"> <em class="mb">走向数据科学</em> </a> <em class="mb">。</em><a class="ae kv" rel="noopener" target="_blank" href="/use-metrics-to-determine-lda-topic-model-size-1a1feaa1ff3c">https://towards data science . com/use-metrics-to-determine-LDA-topic-model-size-1a 1 feaa 1 ff 3c</a></p><p id="9fb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">丹尼尔·罗宾逊(2022)。确定正确的LDA主题模型大小，第二部分。<a class="ae kv" href="https://medium.com/towards-data-science" rel="noopener"> <em class="mb">走向数据科学</em> </a> <em class="mb">。</em><a class="ae kv" rel="noopener" target="_blank" href="/determining-the-right-lda-topic-model-size-part-ii-ff4312e9fd9">https://towards data science . com/determining-the-right-LDA-topic-model-size-part-ii-ff 4312 e 9 FD 9</a></p><h2 id="569e" class="mj mk iq bd mp mq mr dn ms mt mu dp mv lf mw mx my lj mz na nb ln nc nd ne nf bi translated">附加参考</h2><p id="c488" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf ni lh li lj nj ll lm ln nk lp lq lr ij bi translated">对于我经常用来指导分析的LDA模型参数的详细信息，我推荐Haaya Naushan的优秀的<a class="ae kv" rel="noopener" target="_blank" href="/topic-modeling-with-latent-dirichlet-allocation-e7ff75290f8"> <em class="mb">主题建模和潜在的狄利克雷分配</em> </a> <em class="mb">。</em></p></div></div>    
</body>
</html>