<html>
<head>
<title>Training a Neural Network by Hand</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手动训练神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-a-neural-network-by-hand-1bcac4d82a6e#2022-06-24">https://towardsdatascience.com/training-a-neural-network-by-hand-1bcac4d82a6e#2022-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8239" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">神经网络背后的数学导论</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/eccb1719f22583bddeffb8f357d527f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9pv86ms0aetZW8Y0FijQ6g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">网络图片——作者<a class="ae kv" href="https://unsplash.com/@clintadair" rel="noopener ugc nofollow" target="_blank">克林特·王茂林</a></p></figure><h2 id="a300" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="6339" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本文中，我们将讨论训练一个解决回归问题的简单神经网络背后的数学原理。我们将使用输入变量x来预测输出变量y。我们将手动训练两个模型，然后使用Python训练最终模型。</p><p id="8820" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在开始之前，最好了解一点多元微积分、线性代数和线性回归，以便完全理解本文中解释的数学过程。如果没有，我会考虑探索<a class="ae kv" href="https://www.khanacademy.org/" rel="noopener ugc nofollow" target="_blank">可汗学院</a>，因为他们在这些主题上有一些很棒的课程。</p><p id="6911" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">让我们首先定义一些数据点来训练模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><h1 id="ec8e" class="ms kx iq bd ky mt mu mv lb mw mx my le jw mz jx li jz na ka lm kc nb kd lq nc bi translated">1.超级简单神经网络</h1><p id="7850" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">第一个神经网络将具有带有单个节点的输入层和带有单个节点的输出层。输出层将具有线性激活函数。这是你能得到的最简单的神经网络，但是从这个模型开始会使数学变得非常直观。我们将从初始化模型开始，权重为0.5，偏差为0。</p><p id="5aae" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">初始化模型参数最简单的方法是用0到1之间的值随机化权重，并用0初始化偏差值。设置起始参数的其他方法包括He初始化和Xavier初始化，旨在减轻爆炸/消失梯度并加速收敛，但这些超出了本文的范围。</p><h2 id="d9fb" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">前进传球</h2><p id="4f3a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">第一步是通过模型传递我们的输入变量来衡量它的表现。这叫做向前传球。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/7c7605ffd042b6141962f41014987189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PeULtrsWaVUdRUyQESsvcA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单神经网络初始参数—作者</p></figure><p id="f683" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在上图中，a(x)是该节点输入的线性组合，h(x)是转换a(x)的激活函数。当我们使用线性激活函数时，输入的线性组合不会改变。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/e6ab611103afd3ff5aa46939bacab05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GT38IA9kA08U7JMvQDdQCA.png"/></div></div></figure><p id="39c7" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">整个正向传递由以下函数表示。这可能看起来很熟悉，因为这是一条直线的方程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/5cac5700a1c78ddf7d660bc51e5ddf5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5wa9cUZMalI1ep1XZsZDiw.png"/></div></div></figure><p id="fd14" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">因此，通过插入每个数据点，我们可以求解方程来获得我们的初始模型预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/5fd9f22fe816d69c5618d7e7b9102524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eYTwRt3QGz6oSMkvwDonkQ.png"/></div></div></figure><p id="da67" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然后，我们使用一个误差函数来确定我们的预测有多好。在这种情况下，我们将使用1/2 * MSE(均方误差)。我们乘以因子1/2的原因是，它减少了我们在反向传播期间计算的链式偏导数中的系数数量。如果这没有意义，不要担心，我将在文章的后面解释它。1/2 * MSE的公式和计算如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/966de5d993756007f8512785923ba119.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ullBESQiTl0B2shFK65CGg.png"/></div></div></figure><p id="db17" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然后，我们可以使用matplotlib可视化初始预测。在下图中，蓝色点是真实标注，橙色点是预测标注。蓝线显示了神经网络如何对0-1之间的其他x值进行分类。重要的是要注意，这条线有一个恒定的斜率，这是预期的，因为模型方程正是直线方程。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f9b03e5c393fe560a93a02bbe64acf56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*XHz19wbeJEu-S5QL5UMikQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单神经网络初始预测-作者</p></figure><h2 id="5e50" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">反向传播</h2><p id="acaa" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">看着上面的图表，你可能会想，你可以选择一个y轴截距和斜率来进行更好的预测。你可能是对的。在这一节中，我们将使用反向传播向正确的方向迈出一步。</p><p id="da06" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在反向传播期间，我们对模型中的每个权重和偏差取误差函数的偏导数。误差函数在其方程中不包含任何权重或偏差，因此我们使用链式法则来实现。这样做的结果是每个参数应该被调整的方向和幅度，以最小化误差函数。这个概念叫做梯度下降。</p><h2 id="c47d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">重量的链式导数</h2><p id="aad2" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们从计算误差相对于重量值的偏导数开始。我喜欢大声读出链式偏导数，因为它使过程更容易理解。例如，在下面的链式导数中，我们取“误差函数相对于激活函数h11的偏导数，然后我们取激活函数h11相对于线性组合a11的偏导数，然后我们取线性组合a11相对于权重w11的偏导数。”</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/c33b25e93fb5d5740d25ae4afa8ce171.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VcNaP3V8Mr-DOma0JHiS8g.png"/></div></div></figure><p id="b564" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们将计算的第一偏导数是误差函数相对于激活函数h11的偏导数。这就是我们看到使用1/2 * MSE的好处的地方。通过乘以因子1/2，我们在所得的偏导数中消除了所有系数(除了1)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/da694b26acdb5d1086c2d6da4e76b20c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wxABy--X7gD92PFcZGRE9g.png"/></div></div></figure><p id="43ea" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">接下来，我们取激活函数h11相对于线性组合a11的偏导数。由于激活是线性的，这实质上是一个函数对自身的偏导数，也就是1。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/f729f89bd1584f855c4fbfe03fef2bd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n3qNjDGGIVq071D0icnlAg.png"/></div></div></figure><p id="61c8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">最后，我们求线性组合a11相对于权重w11的偏导数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/90c4ec5ea8763371236927a154615e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZbWOuRd-T2exvegxPHR5XA.png"/></div></div></figure><p id="d680" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">把所有这些放在一起，我们得到下面的等式。我们可以通过这个等式传递所有点，并取平均值来确定我们应该如何改变w11参数以最小化误差函数。这被称为批量梯度下降。如果我们使用数据点的子集，这将被称为小批量梯度下降。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/ea90b3421799e1c2020a8046ab01d200.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XuXvSQS2p3MRxJaiErFLfQ.png"/></div></div></figure><h2 id="61bd" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">偏差的链式导数</h2><p id="61d0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们还没做完偏导数呢！我们还必须调整偏差值。除了链中的最终导数之外，该参数以与重量非常相似的方式更新。谢天谢地，在上一节中，我们已经计算了除一个导数以外的所有导数。</p><p id="d83c" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">偏差项的链式导数如下所示。注意它和重量的链式导数是多么的相似。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/c192059d4b7c2bc7c78ce809b21b1bb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAzGvWuHhnLo1pE8Z7rlFQ.png"/></div></div></figure><p id="2957" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们需要计算的唯一偏导数是线性组合a11相对于偏差b11的偏导数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/e8fe0f7c3952f723857e17c7fda393b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORDwbHyZ7rE27TQw32nskg.png"/></div></div></figure><p id="06d6" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">将所有这些放在一起，我们可以求解每个数据点的方程，并获得我们应该对b11做出的平均变化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/a2d9741395b7f3e89e1264ddbea0ee21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktk2cwxA0mtpVWMf8UG4Ug.png"/></div></div></figure><h2 id="c2fa" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">更新重量</h2><p id="77e0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经计算了重量的偏导数，我们可以更新它的值。权重变化的幅度取决于一个称为学习率的参数。如果学习率太低，达到最佳模型参数将需要大量的历元。如果学习率太高，我们会不断超调最佳参数组合。在本文中，我们将使用学习率1。学习率通常在0-1的范围内。</p><p id="ecb9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">更新每个权重的公式如下。注意，学习率由α表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/6ea8c24a589e1e9704ee1e9b9e646be7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3XZVZvHIt_LjGPhXyE7cNQ.png"/></div></div></figure><h2 id="1bf9" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">更新偏差</strong></h2><p id="7499" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">然后我们可以对偏差做同样的处理。用于更新它的公式本质上与用于权重的公式相同，变化的幅度也取决于学习速率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/46a83f880eb6a257d59908e87dea602e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTmr1IYmvW3-cxNFMF3YhA.png"/></div></div></figure><h2 id="7724" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">又一次向前传球</h2><p id="df1c" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经更新了网络的权重和偏差，它应该可以做出更好的预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/941b40bc45ea550038cdc40ac7c4be04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MRcfIzwylWUHCrY2H5sAZw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单神经网络更新参数—按作者</p></figure><p id="b4e5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">让我们执行另一个向前传递来确认这种情况。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/c8a7116fafae2a9538b02bb43b4afe5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TLIZVfdUycKVUmlGtRSmjA.png"/></div></div></figure><p id="c289" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然后我们用1/2 * MSE来评估预测有多好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/ce97068ba39a4c4fd7dfc2904a8eed97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxadY3KMkEitOi6eWzN5UA.png"/></div></div></figure><p id="ba40" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">哇！我们能够在一个时期内将误差函数从大约0.08改善到大约0.02。理论上，我们会不断更新权重和偏差，直到我们停止改进误差函数。在现实世界中还有其他需要考虑的事情，例如过度拟合训练数据和使用验证集，但我们现在将跳过这一点。让我们想象1个纪元后的预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/22af8551183c10a21c3b67ae117713b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*oOKToF-aiybHD1Sujdw4vw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单神经网络更新预测-作者</p></figure><p id="e781" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我之前简单提到过这个模型是一个简单的线性回归模型。这是因为我们使用了线性激活函数、单输入和单输出节点。如果我们将输入节点的数量增加到x的递增幂，我们可以建立任何程度的线性回归模型。这很酷，如果你已经理解了线性回归模型，这是一个过渡到神经网络的好方法。</p><h1 id="42ac" class="ms kx iq bd ky mt mu mv lb mw mx my le jw mz jx li jz na ka lm kc nb kd lq nc bi translated">2.稍微复杂一点的神经网络</h1><p id="e9fb" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本节中，我们将拟合一个具有两个输入节点(x和x)和一个输出节点的神经网络。虽然仍然是一个简单的网络，这个模型将显示如何使用神经网络创建一个二阶线性回归模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/84cd186a04eaf0cf84579385721bcc15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*roO0ptzZU1tOog_Fl6nM7w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SMC神经网络初始参数—作者</p></figure><h2 id="d1c0" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">前进传球</h2><p id="9c6e" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在这个网络中，向前传球的公式比前一个模型稍微复杂一些。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/5b2f7a1fa215574027be592dcf4f11e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L30xHEQJIJobWqOcZm2fgg.png"/></div></div></figure><p id="db81" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">使用我们的训练数据，我们可以解决每个数据点的方程。x1就是x，x2是x的平方。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/fd3ccf4768c10cadf7073239510c38c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*38P6uRLpuD2yo2g9M6B1ag.png"/></div></div></figure><p id="9d39" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然后，正如我们对之前的模型所做的那样，我们用误差函数(1/2 * MSE)评估预测。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/2ce66223ca23b83c9d50083c85612379.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ViKV-dVD6SvHXmRY3j59Ag.png"/></div></div></figure><p id="669f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">在下图中，我们可以看到，由于我们添加了第二个输入参数，这条线(向上的曲线)有一点凸起。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/58a092aa4b3e0db41a1c3351f28fd97a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*Yl1H6QKm2xuF4xi1T_YRew.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SMC神经网络初始预测—作者</p></figure><h2 id="304e" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">反向传播</h2><p id="5000" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经做出了初步的预测，我们可以反推计算我们应该如何改变权重和偏差。我们需要计算的三个偏导数链如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/b19c6978031fa35a50c80591ac9dc4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PBROeSWGKETQk5a0B6R9JA.png"/></div></div></figure><p id="6505" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">上面三个方程的前两个偏导数与我们用之前的模型计算的完全相同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/3c62fa05fd91ae32c16e42a42ab75b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fVASAiafZ8mzc69oWt-eQ.png"/></div></div></figure><p id="81b1" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">每条链的最终偏导数如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/ca6e1ca4a44ceb5366dc9f2e41cc7c73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksK7sceg76p1Wjo-_s_SXQ.png"/></div></div></figure><p id="aaa5" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">然后我们就可以把每个导数链放在一起，对每个数据点求解，对每个链取平均值！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/d1f3093f7c1d9d3d9db249a1777eaa2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LuXF6o9cwkrDUiIYyYIqmA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/85cbaa9bb04452548d6b70b9e04f9375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K3LiKMvSg63EIg0ltfSSnw.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/f987baa2e5dfca5faaba061dfaa75306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*km-s5rTFfbTf5tarQdHWEQ.png"/></div></div></figure><p id="3a77" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">接下来，我们使用与之前相同的公式更新权重和偏差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/dd83c5dc02010525a722ed58c39995b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRyRNRLvJlxLOU2RV00bEQ.png"/></div></div></figure><p id="2504" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们将再次使用学习率1。这触发了参数的大跳跃，并且有利于在1个时期之后可视化模型中的变化。通常，您会设置一个较低的学习速率，并执行多个时期。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/6b33761ff97d498c43f4b92a8e8041df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0go31ZrRaUzo12wF9tHA_Q.png"/></div></div></figure><h2 id="f215" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">又一次向前传球</h2><p id="99df" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">最后，我们可以执行另一个向前传递，看看模型改进了多少！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/b0d7e7bac1b4cca9fa8d805bfa381fc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9R5LxSI-pMle5_7hDZo0kw.png"/></div></div></figure><p id="6970" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">厉害！我们将误差函数从大约0.06降低到大约0.01。在下面的单元格中，我们看到了这种改进。我们对模型训练得越多，我们就应该越接近精确拟合数据点。蓝线是更新的模型，灰线是初始模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/2ddc44490057ebb6e9aac02074919e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*3IjHoamjyIaVohPN8PMjJg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">SMC神经网络更新预测-作者</p></figure><h2 id="acc6" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">3.用代码训练神经网络</h2><p id="16c0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在我们已经完成了所有的数学，我想向你展示如何使用Python训练一个模型。我们上面所做的计算可以由计算机每秒钟完成数千次。下面的代码块为模型定义了一个神经网络类。我鼓励你浏览类函数和代码注释来确认这一点。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="e7e8" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">首先，我们实例化该类并传入x和y值。然后，我们可以迭代地执行前向传递和后向传播来更新模型参数。在下面的例子中，我们为3000个时期训练模型，并且每500个时期记录模型预测。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/958f48c9fa12e3ddac6333f693a690c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3O7Z7_BKOxOT-u-Mkm-EfA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">带代码的SMC NN按作者</p></figure><p id="f95f" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">正如我们所见，该模型不断改进其预测，经过2500个时代后，我们得到了一个高度准确的模型。由于该模型反映了二阶线性回归模型，因此它仅限于凸函数，其缩放和变换取决于模型参数。训练数据点并不完全是凸函数，因此我们需要增加输入节点的数量来完美地拟合数据。</p><h1 id="910d" class="ms kx iq bd ky mt mu mv lb mw mx my le jw mz jx li jz na ka lm kc nb kd lq nc bi translated">最后的想法</h1><p id="e9f6" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我认为神经网络背后的数学非常棒。希望本文中的几个例子和一些样本数据有助于展示这一点。从线性回归模式的神经网络开始是一个很好的起点，但当您添加多个层和非线性激活函数时，神经网络的真正预测能力就会释放出来。</p><p id="bb27" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">这篇文章的代码可以在这里找到。</p><p id="3980" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">资源</strong></p><ol class=""><li id="a5d8" class="ob oc iq lu b lv ml ly mm lf od lj oe ln of mk og oh oi oj bi translated"><a class="ae kv" href="https://www.jeremyjordan.me/neural-networks-training/" rel="noopener ugc nofollow" target="_blank">训练神经网络——杰瑞米·乔登</a></li><li id="6d6c" class="ob oc iq lu b lv ok ly ol lf om lj on ln oo mk og oh oi oj bi translated"><a class="ae kv" href="https://www.analyticsvidhya.com/blog/2021/04/activation-functions-and-their-derivatives-a-quick-complete-guide/" rel="noopener ugc nofollow" target="_blank">激活函数及其导数——Lakshmi Panneerselvam</a></li><li id="3f9b" class="ob oc iq lu b lv ok ly ol lf om lj on ln oo mk og oh oi oj bi translated"><a class="ae kv" href="https://datascience.stackexchange.com/questions/19272/deep-neural-network-backpropogation-with-relu" rel="noopener ugc nofollow" target="_blank">与RELU的反向传播—堆叠交换讨论</a></li><li id="54c0" class="ob oc iq lu b lv ok ly ol lf om lj on ln oo mk og oh oi oj bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/weight-initialization-techniques-in-neural-networks-26c649eb3b78">权重初始化技术— Saurabh Yadav </a></li><li id="7e5c" class="ob oc iq lu b lv ok ly ol lf om lj on ln oo mk og oh oi oj bi translated"><a class="ae kv" href="https://www.baeldung.com/cs/deep-learning-bias-backpropagation" rel="noopener ugc nofollow" target="_blank">深度学习偏差反向传播——Enes Zvornicanin</a></li><li id="b835" class="ob oc iq lu b lv ok ly ol lf om lj on ln oo mk og oh oi oj bi translated"><a class="ae kv" href="https://hmkcode.com/ai/backpropagation-step-by-step/" rel="noopener ugc nofollow" target="_blank">逐步反向传播—哈尼族M. K. </a></li></ol></div></div>    
</body>
</html>