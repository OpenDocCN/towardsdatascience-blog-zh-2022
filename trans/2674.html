<html>
<head>
<title>Decision Tree Hyperparameter Tuning in R using mlr</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用mlr在R中调整决策树超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-tree-hyperparameter-tuning-in-r-using-mlr-3248bfd2d88c#2022-06-09">https://towardsdatascience.com/decision-tree-hyperparameter-tuning-in-r-using-mlr-3248bfd2d88c#2022-06-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a49a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用mlr在R中执行超参数网格搜索</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9b4910e81fe389e7321b3bacdd78a6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h8pzmu2UqmubLQMt"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@alexisbaydoun" rel="noopener ugc nofollow" target="_blank">Alexis bay doun</a>@ unsplash . com拍摄</p></figure><p id="10f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">许多人通过研究和应用决策树算法进入数据科学之旅。这并不奇怪，因为这种算法可能是最容易解释的一种，它很好地模仿了人类的决策。</p><p id="f00f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">理解决策树还有另一个巨大的优势:它们是最著名的boosting(极端梯度Boosting)和bagging(随机森林)算法的基础，这些算法在世界各地发起了Kaggle竞赛，解决了无数的商业问题。</p><p id="7426" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在您掌握了<a class="ae ky" rel="noopener" target="_blank" href="/classification-decision-trees-easily-explained-f1064dde175e">决策树如何构建</a>以及它如何选择用于在数据中执行关键拆分的特征的细节后，您会立即明白，当我们开始让决策树适合解决问题时，有许多决策要做，即:</p><ul class=""><li id="59b8" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">树应该有多深？</li><li id="9085" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">应该考虑多少个相关的<em class="me">示例</em>来拆分一个节点？</li><li id="8107" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">我们要考虑多少个<em class="me">例子</em>才能做出决定？</li><li id="d98f" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">考虑新拆分的最小基尼/熵增阈值是多少？</li></ul><p id="5728" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些问题似乎都有点武断。但是，您可能会注意到，它们都与决策树的一个关键特性相关联— <em class="me">超参数:</em>不是由模型学习而是由用户参数化的一组值。</p><p id="c06b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调整这些超参数对于实现所有机器学习算法的最终目标——泛化能力——至关重要。而且，在决策树中，可以说它们甚至更重要，因为基于树的算法对<em class="me">超参数</em>空间中的微小变化极其敏感。</p><p id="8ddf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">训练<em class="me">超参数</em>是全世界数据科学家和机器学习工程师的一项基本任务。而且，了解这些<em class="me">参数</em>中的每一个参数的个体影响会让你更信任并更好地解释你的表现。</p><p id="59b7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将使用R和<code class="fe mk ml mm mn b">mlr</code>库来优化决策树<em class="me">超参数</em>。我还想向您展示如何可视化和评估每个<em class="me">参数</em>对我们算法性能的影响。对于我们的例子，我们将使用神话般的泰坦尼克号数据集，可在<a class="ae ky" href="https://www.kaggle.com/c/titanic/data?select=train.csv" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>中获得。</p><p id="6541" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">开始吧！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="566e" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">加载数据</h1><p id="5138" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">在加载数据之前，让我们调用代码的所有依赖项:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="40fc" class="nw mw it mn b gy nx ny l nz oa">library(dplyr)<br/>library(rpart)<br/>library(rpart.plot)<br/>library(Metrics)<br/>library(mlr)<br/>library(ggplot2)<br/>library(plotly)</span></pre><p id="e4fe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">描述我们的依赖关系:</p><ul class=""><li id="7162" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">dplyr</code>执行一些数据角力任务。</li><li id="b57f" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">rpart</code>无需调整即可拟合决策树。</li><li id="0e32" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">rpart.plot</code>绘制我们的决策树。</li><li id="34a1" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">Metrics</code>评估我们模型的性能；</li><li id="8b85" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">mlr</code>训练我们模型的<em class="me">超参数</em>。</li><li id="7fa8" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">ggplot2</code>对于一般的剧情我们都会做。</li><li id="ce6b" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><code class="fe mk ml mm mn b">plotly</code>用于三维绘图。</li></ul><p id="0db0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Titanic数据集是一个csv文件，我们可以使用<code class="fe mk ml mm mn b">read.csv</code>函数加载它。该数据集包含有关泰坦尼克号乘客的信息，包括以下各列:</p><ul class=""><li id="7542" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">幸存</strong> —表示乘客是否在泰坦尼克号失事中幸存的标志。</li><li id="b3b6" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu"> pclass </strong> —乘客的机票等级。</li><li id="7596" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">性别</strong>—乘客的性别。</li><li id="11b1" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">年龄</strong>——以年为单位的年龄。</li><li id="a54a" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">泰坦尼克号上兄弟姐妹/配偶的数量。</li><li id="89dd" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">泰坦尼克号上父母/孩子的数量。</li><li id="4bde" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">车票</strong>—车票号码。</li><li id="6e47" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">票价</strong> —客运票价。</li><li id="9bc5" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">客舱</strong> —乘客的客舱号。</li><li id="47bc" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated"><strong class="lb iu">登船</strong> —乘客登船的港口。</li></ul><p id="f511" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我已经用以下方式加载了它:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="4b81" class="nw mw it mn b gy nx ny l nz oa">titanic &lt;- read.csv(‘train.csv’)</span></pre><p id="ae3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了简化，我将只使用来自<code class="fe mk ml mm mn b">titanic</code>数据框架的原始列的子集——让我使用<code class="fe mk ml mm mn b">dplyr</code>来选择它们:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="b0a6" class="nw mw it mn b gy nx ny l nz oa">titanic &lt;- titanic %&gt;%<br/>  select(Fare, Age, Sex, Pclass, Survived, SibSp, Parch)</span></pre><p id="5f54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们也将数据分成训练测试—留下20%的数据作为维持组:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="0975" class="nw mw it mn b gy nx ny l nz oa"># Splitting data into Train and Test<br/>titanic['row_id'] = rownames(titanic)</span><span id="d6df" class="nw mw it mn b gy ob ny l nz oa">set.seed(123)<br/>train_data &lt;- titanic %&gt;%<br/>  sample_frac(0.8)</span><span id="2a5d" class="nw mw it mn b gy ob ny l nz oa">test_data &lt;- titanic %&gt;%<br/>  anti_join(train_data, by='row_id')</span><span id="8ce0" class="nw mw it mn b gy ob ny l nz oa"># Drop row_id from both dataframes<br/>train_data[,'row_id'] &lt;- NULL<br/>test_data[,'row_id'] &lt;- NULL</span></pre><p id="497a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">尽管我们将在<em class="me">超参数</em>调整中使用交叉验证(稍后我会提到这一点)，但测试集将用于确保我们不会过度拟合我们的训练集或交叉验证集。对于决策树来说，这是非常重要的，因为它们非常容易出现高方差。</p><p id="e1dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们继续之前，让我们先预览一下我们的数据:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/9fe841d988826f7f12c3bc5fdbe54ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*GakexomcQ6I1V0-tLepQmw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们泰坦尼克号数据的前9行——作者图片</p></figure><p id="cc1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很好，我们已经有了数据，让我们来拟合第一个决策树吧！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="5a94" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">拟合第一决策树</h1><p id="e3b7" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">对于决策树的第一个<em class="me">普通</em>版本，我们将使用带有默认<em class="me">超参数</em>的<code class="fe mk ml mm mn b">rpart</code>包。</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="6f76" class="nw mw it mn b gy nx ny l nz oa">d.tree = rpart(Survived ~ ., <br/>               data=train_data, <br/>               method = 'class')</span></pre><p id="68d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于我们没有指定<em class="me">超参数</em>，我们使用<a class="ae ky" href="https://www.rdocumentation.org/packages/rpart/versions/4.1.16/topics/rpart" rel="noopener ugc nofollow" target="_blank"> rpart的</a>默认值:</p><ul class=""><li id="d177" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我们的树可以下降到30级—<code class="fe mk ml mm mn b">maxdepth = 30</code>；</li><li id="708a" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">一个节点中执行拆分的最小实例数为20—<code class="fe mk ml mm mn b">minsplit = 20</code>；</li><li id="a54d" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">终端节点中的最小实例数是7—<code class="fe mk ml mm mn b">minbucket = 7</code>；</li><li id="d289" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">分割必须增加树的“性能”(虽然不是那么直接，我们可以认为“性能”是<code class="fe mk ml mm mn b">cp</code>的代理)至少0.01—<code class="fe mk ml mm mn b">cp = 0.01</code>；</li></ul><p id="e95d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们如何知道这些是我们数据的最佳超参数？这些都是随机选择，使用默认选项是一个冒险的赌注。</p><p id="bcb1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">也许我们可以把节点分离得更远一点。或者，我们可能使用低样本来根据低<code class="fe mk ml mm mn b">minsplit</code>和<code class="fe mk ml mm mn b">minbucket</code>做出决策。在继续之前，这是我们树:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/eb3bbdc60b6d83b3259c052f70eaadc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*_I4f9nFvyTUigcVehFYtZg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">普通决策树—作者图片</p></figure><p id="38cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们看到这是一个相对较浅的树，有4个层次。让我们检查一下测试集的准确性:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="4ffc" class="nw mw it mn b gy nx ny l nz oa"># Predict Values<br/>predicted_values &lt;- predict(d.tree, test_data, type = 'class')</span><span id="b33c" class="nw mw it mn b gy ob ny l nz oa"># Getting Accuracy<br/>accuracy(test_data$Survived, predicted_values)</span></pre><p id="d7f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的准确率约为79.21%。我们还能提高这个值吗？也许吧！调整<em class="me">超参数</em>是我们可以探索的第一个想法！</p><p id="71c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们首先手动设置它们——我们可以使用<code class="fe mk ml mm mn b">rpart</code>函数中的<code class="fe mk ml mm mn b">rpart.control</code>来覆盖默认的<em class="me">超参数</em>:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="bfb4" class="nw mw it mn b gy nx ny l nz oa">d.tree.custom = rpart(Survived~ ., <br/>               data=train_data, <br/>               method = 'class',<br/>               control = c(maxdepth = 5, cp=0.001))</span></pre><p id="227c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这棵树上，我将<code class="fe mk ml mm mn b">maxdepth</code>设置为5，强制我的树比我们上面看到的更深一点。此外，我还调整了<code class="fe mk ml mm mn b">cp</code>——让我们看看结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/da6cf0deaf760ab45aa30067f75c25ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*mlxx2SnKcZmAmb6qlQKZIQ.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有调整的超参数的决策树—作者图片</p></figure><p id="18bc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">新的树更深一点，包含更多的规则——在性能方面，它的准确率约为79.78%，比我们的普通版本好一点！</p><p id="c4b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">随着我们的准确度提高了几个百分点，我们的指标也在变化。</strong>从<strong class="lb iu"> </strong>我们可以调优的<em class="me">超参数</em>的整体情况来看，其中肯定有一些在测试集上产生了<em class="me">最佳</em>性能——对吗？我们必须手动尝试这些参数吗？</p><p id="d73d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">幸好没有！</strong>虽然<code class="fe mk ml mm mn b">rpart</code>不能让我们自动进行搜索，但是我们有一个名为<code class="fe mk ml mm mn b">mlr</code>的库可以帮助我们！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="3435" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">使用MLR的超参数调整—调整一个参数</h1><p id="a993" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">一件很酷的事情是，我们将在这里学到的东西可以扩展到其他模型。<code class="fe mk ml mm mn b">mlr</code>库使用完全相同的方法，我们将学习调整<em class="me">随机森林、xgboosts、SVM等的参数。</em></p><p id="f4a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过去你可能听说过<code class="fe mk ml mm mn b">caret</code>，一个著名的R数据科学库。虽然<code class="fe mk ml mm mn b">caret</code>也有一些内置的<em class="me">超参数</em>搜索，<code class="fe mk ml mm mn b">mlr</code>使我们能够更好地查看那些<em class="me">超参数的影响，</em>不那么“黑箱化”——这是我在这篇文章中使用<code class="fe mk ml mm mn b">mlr</code>的主要原因。</p><p id="da74" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以，<code class="fe mk ml mm mn b">mlr</code> <a class="ae ky" href="https://mlr.mlr-org.com/" rel="noopener ugc nofollow" target="_blank">，R库中的机器学习</a>是R中一个很酷的人工智能包，它给了我们训练几个不同模型并执行调优的工具。正如我们已经讨论过的，其中一个优点是它让我们可以查看每个<em class="me">超参数</em>对模型性能的影响。</p><p id="7acf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mk ml mm mn b">mlr</code>中一个方便的函数是<code class="fe mk ml mm mn b">getParamSet</code>,它返回特定模型的所有可调整参数——对于<code class="fe mk ml mm mn b">classification rpart</code>,我们可以调用<code class="fe mk ml mm mn b">getParamSet("classif.rpart")</code>,得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/7892824d1e6f51eebddecf0aa988b3ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*J7-wSOVnbrzWv0PT29FANQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用于分类决策树的可调超参数—作者图片</p></figure><p id="454e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所有这些参数都可以使用<code class="fe mk ml mm mn b">mlr</code>进行调整。让我们重点关注其中的三种——仅从<code class="fe mk ml mm mn b">maxdepth</code>开始。</p><p id="08d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在列<code class="fe mk ml mm mn b">constr</code>上，我们可以看到我们可以调整的值的范围——对于<code class="fe mk ml mm mn b">maxdepth</code>,我们可以从1到30进行深度调整。</p><p id="cfdb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有一种简单的方法来拟合这30种不同版本的决策树，并评估这些模型的准确性，岂不是很有趣？这就是<code class="fe mk ml mm mn b">mlr</code>的作用！</p><p id="bbf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mk ml mm mn b">mlr</code>需要比普通<code class="fe mk ml mm mn b">rpart</code>甚至<code class="fe mk ml mm mn b">caret</code>多一点的代码。首先，我们需要定义一个任务——在本例中，我用<code class="fe mk ml mm mn b">train_data</code>和<code class="fe mk ml mm mn b">target = 'Survived</code>定义一个分类任务:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="295a" class="nw mw it mn b gy nx ny l nz oa">d.tree.params &lt;- makeClassifTask(<br/> data=train_data, <br/> target=”fraud”<br/> )</span></pre><p id="b329" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们需要创建要迭代的参数网格——就像我们讨论的那样，让我们从单个参数开始。我们需要<code class="fe mk ml mm mn b">makeParamSet</code>并使用<code class="fe mk ml mm mn b">makeDiscreteParam</code>:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="1957" class="nw mw it mn b gy nx ny l nz oa">param_grid &lt;- makeParamSet( <br/> makeDiscreteParam(“maxdepth”, values=1:30))</span></pre><p id="e36b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在上面的代码中声明的是，我的树将迭代30个不同的<code class="fe mk ml mm mn b">maxdepth</code>值，这是一个向量(<code class="fe mk ml mm mn b">1:30</code>)，它包含1，2，3 …，30作为输入到<em class="me">超参数</em>的值。</p><p id="adb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们需要做三件事——初始化控制网格实验，选择交叉验证方法，并选择一种用于评估我们结果的方法:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="37bf" class="nw mw it mn b gy nx ny l nz oa"># Define Grid<br/>control_grid = makeTuneControlGrid()</span><span id="4f39" class="nw mw it mn b gy ob ny l nz oa"># Define Cross Validation<br/>resample = makeResampleDesc("CV", iters = 3L)</span><span id="cfe8" class="nw mw it mn b gy ob ny l nz oa"># Define Measure<br/>measure = acc</span></pre><p id="a1a0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/deeply-explained-cross-validation-in-ml-ai-2e846a83f6ed" rel="noopener">交叉验证是改善决策树结果的一种方式</a>。在我们的例子中，我们将使用三重交叉验证。对于测量，我们将使用精确度(<code class="fe mk ml mm mn b">acc</code>)。</p><p id="5a1f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一切就绪！是时候将一切输入到神奇的<code class="fe mk ml mm mn b">tuneParams</code>函数中了，这将启动我们的<em class="me">超参数</em>调谐！</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="38fb" class="nw mw it mn b gy nx ny l nz oa">set.seed(123)<br/>dt_tuneparam &lt;- tuneParams(learner=’classif.rpart’, <br/> task=d.tree.params, <br/> resampling = resample,<br/> measures = measure,<br/> par.set=param_grid, <br/> control=control_grid, <br/> show.info = TRUE)</span></pre><p id="350c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当您运行上面的代码时，我们的超参数搜索将开始执行！<code class="fe mk ml mm mn b">show.info = TRUE</code>将输出执行的反馈:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="3f3b" class="nw mw it mn b gy nx ny l nz oa">[Tune-x] 1: maxdepth=1<br/>[Tune-y] 1: acc.test.mean=0.7895909; time: 0.0 min<br/>[Tune-x] 2: maxdepth=2<br/>[Tune-y] 2: acc.test.mean=0.7881845; time: 0.0 min<br/>[Tune-x] 3: maxdepth=3<br/>[Tune-y] 3: acc.test.mean=0.8008132; time: 0.0 min<br/>...</span></pre><p id="fade" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个<code class="fe mk ml mm mn b">maxdepth</code>生成一个acc.test.mean，交叉验证中使用的几个数据集的<code class="fe mk ml mm mn b">acc</code>的平均值。<code class="fe mk ml mm mn b">mlr</code>也让我们用<code class="fe mk ml mm mn b">generateHyperParsEffectData</code>来评估结果:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="8065" class="nw mw it mn b gy nx ny l nz oa">result_hyperparam &lt;- generateHyperParsEffectData(dt_tuneparam, partial.dep = TRUE)</span></pre><p id="f3cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用<code class="fe mk ml mm mn b">ggplot</code>绘制精度的变化图:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="ff72" class="nw mw it mn b gy nx ny l nz oa">ggplot(<br/>  data = result_hyperparam$data,<br/>  aes(x = maxdepth, y=acc.test.mean)<br/>) + geom_line(color = 'darkblue')</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi od"><img src="../Images/bb7437f5f313b5853fe143ee4bcd4e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*t4KmNjVoRgQ11RiWk5bkzg.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每最大深度精度的演变——作者提供的图片</p></figure><p id="4ed8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">查看我们的图，我们知道在深度为5之后，对精确度的影响是微不足道的，差异极小。让我们确认一下<code class="fe mk ml mm mn b">tuneParams</code>函数选择的最佳模型——我们可以通过直接调用<code class="fe mk ml mm mn b">dt_tuneparam</code>对象来检查:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="02d4" class="nw mw it mn b gy nx ny l nz oa">Tune result:<br/>Op. pars: maxdepth=11<br/>f1.test.mean=0.9985403</span></pre><p id="8278" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">调整结果选择19 <code class="fe mk ml mm mn b">maxdepth</code>作为最佳参数，只是因为微小的差异——不过，让我们使用对象<code class="fe mk ml mm mn b">dt_tuneparam$x</code>来拟合我们的最佳参数，以拾取保存的<em class="me">超参数</em>并使用<code class="fe mk ml mm mn b">setHyperPars</code>来存储它们:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="43c3" class="nw mw it mn b gy nx ny l nz oa">best_parameters = setHyperPars(<br/> makeLearner(“classif.rpart”), <br/> par.vals = dt_tuneparam$x<br/> )</span><span id="a6e1" class="nw mw it mn b gy ob ny l nz oa">best_model = train(best_parameters, dt_task)</span></pre><p id="2bab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mk ml mm mn b">train</code>将用保存在<code class="fe mk ml mm mn b">best_parameters</code>对象中的<em class="me">超参数</em>来拟合决策树。</p><p id="b21a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行上面的代码后，我们得到了一个拟合树，其中包含从<code class="fe mk ml mm mn b">best_model</code>上的网格搜索中返回的最佳<em class="me">超参数</em>。为了在我们的测试集上评估这个模型，我们需要创建一个指向测试数据的新的<code class="fe mk ml mm mn b">makeClassifTask</code>:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="514a" class="nw mw it mn b gy nx ny l nz oa">d.tree.mlr.test &lt;- makeClassifTask(<br/> data=test_data, <br/> target=”Survived”<br/>)</span></pre><p id="c065" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<code class="fe mk ml mm mn b">test_data</code>上预测和检查准确性:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="b72a" class="nw mw it mn b gy nx ny l nz oa">results &lt;- predict(best_model, task = d.tree.mlr.test)$data<br/>accuracy(results$truth, results$response)</span></pre><p id="5e13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们的准确率约为79.21%，与我们的普通版本相同。所以…很可能，我们对<code class="fe mk ml mm mn b">cp</code>参数的调整是为了提高我们的模型性能。</p><p id="a0a5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">问题是..在本例中，我们保持其他参数不变，这是否意味着我们只能逐个调整<em class="me">超参数</em><em class="me">？</em>T32】不对！</p><p id="2074" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了<code class="fe mk ml mm mn b">mlr</code>，我们可以同时调整整个参数范围，只需在代码中做一点小小的调整！就这么办吧。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="d6db" class="mv mw it bd mx my mz na nb nc nd ne nf jz ng ka nh kc ni kd nj kf nk kg nl nm bi translated">调整多个参数</h1><p id="4dcf" class="pw-post-body-paragraph kz la it lb b lc nn ju le lf no jx lh li np lk ll lm nq lo lp lq nr ls lt lu im bi translated">调整多个<em class="me">超参数</em>很容易！还记得我们为网格搜索创建的<code class="fe mk ml mm mn b">param_grid</code>对象吗？让我们回忆一下:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="1c30" class="nw mw it mn b gy nx ny l nz oa">param_grid &lt;- makeParamSet( <br/> makeDiscreteParam(“maxdepth”, values=1:30))</span></pre><p id="43e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我在<code class="fe mk ml mm mn b">makeParamSet</code>函数中添加新的参数，我将会添加新的参数，这些参数将会在搜索中进行组合——例如，让我们将<code class="fe mk ml mm mn b">cp</code>和<code class="fe mk ml mm mn b">minsplit</code>添加到我们的场景中:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="42a6" class="nw mw it mn b gy nx ny l nz oa">param_grid_multi &lt;- makeParamSet( <br/> makeDiscreteParam(“maxdepth”, values=1:30),<br/> makeNumericParam(“cp”, lower = 0.001, upper = 0.01),<br/> makeDiscreteParam(“minsplit”, values=1:30)<br/> )</span></pre><p id="7f8b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe mk ml mm mn b">makeNumericParam</code>创建<code class="fe mk ml mm mn b">numeric</code>参数(例如包含小数位的<code class="fe mk ml mm mn b">cp</code>)—我们可以在<code class="fe mk ml mm mn b">getParamSet</code>函数中检查哪些<em class="me">超参数</em>是离散的还是数字的(记住<code class="fe mk ml mm mn b">integers</code>可以用<code class="fe mk ml mm mn b">makeDiscreteParam</code>调用)。</p><p id="3dba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">又该如何训练这种多参数搜索呢？通过将我们的<code class="fe mk ml mm mn b">param_grid_multi</code>输入到<code class="fe mk ml mm mn b">tuneParams</code>函数中！</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="ae7c" class="nw mw it mn b gy nx ny l nz oa">dt_tuneparam_multi &lt;- tuneParams(learner=’classif.rpart’, <br/> task=d.tree.mlr, <br/> resampling = resample,<br/> measures = measure,<br/> par.set=param_grid_multi, <br/> control=control_grid, <br/> show.info = TRUE)</span></pre><p id="f7a8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">当我们训练更多数量的超参数时，存在计算成本。</strong>你会注意到<code class="fe mk ml mm mn b">dt_tuneparam_multi</code>将比<code class="fe mk ml mm mn b">dt_tuneparam</code>搜索花费更多的时间，因为我们将在3000(！)树到我们的数据。</p><p id="71ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在搜索结束时，您可能会得到如下输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi of"><img src="../Images/003713f3607b1497255a7add5a40be11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*vhx43qU8VmC_3zNAqTPrfA.png"/></div></figure><p id="091a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<code class="fe mk ml mm mn b">[Tune]</code>输出中，我们有搜索的最佳参数:</p><ul class=""><li id="4a20" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">15的一个<code class="fe mk ml mm mn b">maxdepth</code>。</li><li id="2267" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">0.003的一个<code class="fe mk ml mm mn b">cp</code>。</li><li id="3b89" class="lv lw it lb b lc mf lf mg li mh lm mi lq mj lu ma mb mc md bi translated">5的一个<code class="fe mk ml mm mn b">minsplit</code>。</li></ul><p id="2f1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个<em class="me">超参数</em>的组合在交叉验证中产生了大约82%的准确率，不错！</p><p id="8f2f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们提取最佳参数，用它们训练一个新的树，并在我们的测试集上查看结果:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="0b51" class="nw mw it mn b gy nx ny l nz oa"># Extracting best Parameters from Multi Search<br/>best_parameters_multi = setHyperPars(<br/> makeLearner(“classif.rpart”, predict.type = “prob”), <br/> par.vals = dt_tuneparam_multi$x<br/>)</span><span id="20e1" class="nw mw it mn b gy ob ny l nz oa">best_model_multi = train(best_parameters_multi, d.tree.mlr)</span><span id="44a3" class="nw mw it mn b gy ob ny l nz oa"># Predicting the best Model<br/>results &lt;- predict(best_model_multi, task = d.tree.mlr.test)$data</span><span id="5451" class="nw mw it mn b gy ob ny l nz oa">accuracy(results$truth, results$response)</span></pre><p id="11da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">我们在</strong> <code class="fe mk ml mm mn b">test_set</code> <strong class="lb iu">的准确率是81.46%！</strong>仅仅通过调整这些参数，我们就能够将基线精度提高2个百分点，这是一个非常好的结果！</p><p id="112c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，为了帮助您直观地了解我们所做的工作，让我们绘制一个网格搜索结果样本的准确性结果:</p><pre class="kj kk kl km gt ns mn nt nu aw nv bi"><span id="a64e" class="nw mw it mn b gy nx ny l nz oa"># Extracting results from multigrid<br/>result_hyperparam.multi &lt;- generateHyperParsEffectData(dt_tuneparam_multi, partial.dep = TRUE)</span><span id="1d58" class="nw mw it mn b gy ob ny l nz oa"># Sampling just for visualization<br/>result_sample &lt;- result_hyperparam.multi$data %&gt;%<br/> sample_n(300)</span><span id="9942" class="nw mw it mn b gy ob ny l nz oa">hyperparam.plot &lt;- plot_ly(result_sample, <br/> x = ~cp, <br/> y = ~maxdepth, <br/> z = ~minsplit,<br/> marker = list(color = ~acc.test.mean, colorscale = list(c(0, 1), c(“darkred”, “darkgreen”)), showscale = TRUE))<br/>hyperparam.plot &lt;- hyperparam.plot %&gt;% add_markers()<br/>hyperparam.plot</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi og"><img src="../Images/45926056c139cc0e458072d4253ba39d.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*IHDlam5h_wZWdAPpPWZfpQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超参数搜索景观-作者图片</p></figure><p id="dd12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在y轴上我们有<code class="fe mk ml mm mn b">minsplit</code>。x轴上有<code class="fe mk ml mm mn b">maxdepth</code>，z轴上有<code class="fe mk ml mm mn b">cp</code>。</p><p id="e583" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个点都是一个实验(由<em class="me">超参数</em>组合而成)，颜色与该实验的精度结果相关。红点表示准确度较低。绿点意味着更好的性能。</p><p id="6457" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在三维图中有一个明显的红色区域，我们看到来自<code class="fe mk ml mm mn b">cp</code>的结果不是很好——让我旋转它以获得更好的视图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/45311a0ae6f96d70dd0635faec61444f.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*9jst7hrj035KID47Ahhn1Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">超参数搜索景观-作者图片</p></figure><p id="739d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">请注意，真正低的</strong> <code class="fe mk ml mm mn b">cp</code> <strong class="lb iu">会产生更差的性能，尤其是与低的</strong> <code class="fe mk ml mm mn b">minsplit</code> <strong class="lb iu">结合使用时！</strong></p><p id="9edb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">可视化我们的<em class="me">超参数</em>搜索结果‘让我们可以鸟瞰我们的训练过程是如何进行的。</p><p id="0f86" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想查看以上剧情的互动版本，请点击<a class="ae ky" href="https://rpubs.com/ivopbernardo/hyperparam_mlr" rel="noopener ugc nofollow" target="_blank">链接</a>！</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><p id="905b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">感谢你花时间阅读这篇文章！我希望你已经欣赏了它，现在你可以理解如何使用r训练<em class="me">超参数</em>。</p><p id="253e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">超参数</em>可以建立或破坏一个模型，作为数据科学家，我们需要知道如何用几行代码有效地调整它们。如果使用R，<code class="fe mk ml mm mn b">mlr</code>可能是做这个常见机器学习任务的绝佳选择！</p><p id="8375" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="me">我在Udemy上建立了一个</em></strong><a class="ae ky" href="https://www.udemy.com/course/r-for-absolute-beginners/?referralCode=F839A741D06F0200F312" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="me">R简介</em> </strong> </a> <strong class="lb iu"> <em class="me">和一个</em> </strong> <a class="ae ky" href="https://www.udemy.com/course/r-for-data-science-first-step-data-scientist/?referralCode=6D1757B5E619B89FA064" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> <em class="me">学习数据科学的训练营</em> </strong> </a> <strong class="lb iu"> <em class="me">。这两个课程都是为初学者量身定做的，我希望你能在我身边！</em> </strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/210dd6b4b8f5a19d02097c5a5ede14f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/0*QG2MGbr9WcX4-bH6.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.udemy.com/course/r-for-data-science-first-step-data-scientist/?referralCode=6D1757B5E619B89FA064" rel="noopener ugc nofollow" target="_blank">数据科学训练营:你成为数据科学家的第一步</a> —图片由作者提供</p></figure><div class="oj ok gp gr ol om"><a href="https://ivopbernardo.medium.com/membership" rel="noopener follow" target="_blank"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">通过我的推荐链接加入Medium-Ivo Bernardo</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">ivopbernardo.medium.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa ks om"/></div></div></a></div><p id="11d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面是这篇文章中代码的一个小要点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="4583" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me">数据集许可:本文中使用的数据集在</em><a class="ae ky" href="https://www.openml.org/d/40945" rel="noopener ugc nofollow" target="_blank">https://www.openml.org/d/40945</a>公开提供使用</p></div></div>    
</body>
</html>