<html>
<head>
<title>Discontinuity in CNN Training Time with Increase Batch Size</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随着批量增加，CNN训练时间不连续</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/discontinuity-in-cnn-training-time-with-increase-batch-size-bd2849129283#2022-06-08">https://towardsdatascience.com/discontinuity-in-cnn-training-time-with-increase-batch-size-bd2849129283#2022-06-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ca47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">致谢:<a class="ae kl" href="https://www.linkedin.com/in/xin-zhang-99246817a/" rel="noopener ugc nofollow" target="_blank"/>&amp;<a class="ae kl" href="https://www.linkedin.com/in/yuqiliofficial/" rel="noopener ugc nofollow" target="_blank">【禺期】李</a> @ <a class="ae kl" href="https://www.linkedin.com/company/aipaca" rel="noopener ugc nofollow" target="_blank">艾帕卡公司</a></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/c08dafeeae88b1af65ce4370f1542a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rm0OwH1G1y3BBdET"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">照片由<a class="ae kl" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">艾米丽·莫特</a>在<a class="ae kl" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="81e6" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">背景</h1><p id="da83" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">随着新的机器学习模型的规模越来越大，模型训练时间分析是当今的重要课题之一。除了像GPTs这样的超级巨型模型，计算机视觉模型对于像数据科学家和研究人员这样的普通最终用户来说训练起来很慢。根据任务和数据，计算机视觉模型的训练时间可能从几个小时到几周不等。</p><p id="bf53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们讨论了我们对模型训练时间的研究中的一个有趣的发现。为了明确我们所说的训练时间的含义，我们想知道一个GPU配置为一批数据训练一个模型需要多长时间。显然，它取决于许多变量，如模型结构、优化器、批量大小等。然而，给定关于配置和模型设置的足够知识，并且如果一批的训练时间是已知的，我们能够计算一个时期的训练时间，因此也能够计算给定时期数目的总训练时间。</p><p id="b9bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们获得CNN模型的训练时间数据时，我们固定了模型结构、输入和输出大小、优化器和损失函数，但是没有固定批量大小。换句话说，我们想知道在其他条件不变的情况下，增加批量是如何影响训练时间的。</p><p id="c259" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们这样做之前，我们确定的是批量大小和批量训练时间之间存在正相关。我们不确定的是，这是线性关系还是非线性关系？如果是线性的，斜率是多少？如果是非线性的，是二次还是三次关系？带着这些问题，我们做了实验，观察到了一些我们没有想到的东西。</p><h1 id="7578" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">实验</h1><p id="faf6" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">我们在特斯拉T4云实例上运行TensorFlow <a class="ae kl" href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16" rel="noopener ugc nofollow" target="_blank"> VGG16 </a>，使用默认输入形状(224，224，3)、优化器和损失函数的CategoricalCrossentropy。我们将批量从1增加到70。实验结果如下所示，x轴是批量大小，y轴显示相应的批量训练时间。有趣的是，我们的预期是部分正确的，我们确实观察到批量大小和批量训练时间之间的正线性关系。然而，在批量大小等于16、32、48和64时，我们观察到批量训练时间的“跳跃”。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mf"><img src="../Images/55b41bdf495a959787e2d1e81aff03a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Llz_w90FJKMoP2BL"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者制作的图像</p></figure><p id="1b15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是特斯拉T4上VGG16的批量大小对批量时间的图，我们观察到关系的总体斜率几乎没有变化，这意味着很可能证实了线性关系。然而，在特定的批量，特别是16、32、48和64，线性关系破裂，并且在这些位置发生不连续。</p><p id="95ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以肯定地说，值16、32、48和64不会随机出现，它们是16的倍数，恰好与GPU的PCIe链接最大宽度16x的值相同。PCIe是PCI Express的缩写，引自wiki“PCI Express电气接口是通过同时通道的数量来衡量的。(通道是数据的单个发送/接收行。这个比喻就是一条双向交通的高速公路。)".简而言之，PCIe越宽，同时传输的数据流量就越多。</p><p id="0508" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对培训过程的假设如下。在VGG16的训练周期中，对于每个批量训练步骤，批量中的每个数据点被分配使用一个PCIe通道，如果批量小于或等于16，则不需要额外的轮次，来自每个PCIe通道的结果被组合，因此我们具有线性关系。当批大小大于16但小于32时，需要另一轮来计算整个批，这由于新一轮的分配而导致训练时间的“跳跃”(我们假设新一轮需要一些额外的时间来导致曲线的移动或“跳跃”)。</p><h1 id="55e4" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">不同GPU上的轨迹</h1><p id="65f8" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">为了验证我们对上述实验的观察，我们进行了相同的实验，但在不同的GPU设置上，下图显示了特斯拉K80、特斯拉P100和特斯拉V100的结果。</p><p id="9500" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从图中我们可以看出，第一，V100的速度&gt; P100 &gt; T4 &gt; K80，因为对于相同的批量，V100的批量时间&lt; P100 &lt; T4 &lt; K80。其次，他们在16岁、32岁、48岁和64岁都有“跳跃”。对于所有四个GPU，它们都具有16倍的PCIe链接最大宽度。(我们想要比较PCIe链接最大宽度不是16倍的GPU的结果，但是，我们在谷歌上可以找到的所有GPU云实例都是PCIe链接最大宽度16倍的)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mg"><img src="../Images/d35ad8f2ab005a30674471ce5e332540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uyfhkDjsu3eRtDAB"/></div></div></figure><h1 id="da13" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">不同模型结构的试验</h1><p id="5535" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">为了测试我们在不同模型上的发现，我们在V100上对VGG19 MobileNet和ResNet50运行了相同的实验。</p><p id="5a34" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果很有趣。对于VGG19，我们仍然可以找到与VGG16完全相同的模式，但是预期的训练时间稍长。然而，对于MobileNet和ResNet50，我们不再观察到这种模式。事实上，与VGGs相比，MobileNet和ResNet50的训练时间波动更大。</p><p id="5095" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于这种现象，我们还没有一个好的解释。我们现在可以说的是，对于类似于VGGs的常规CNN结构，这种“跳跃”行为是成立的。对于其他不同的CNN结构，我们不再观察。进一步的调查和研究正在进行中。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mg"><img src="../Images/3d42c9c61a7745107f881fdb9528a27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-4DfX2AUvD83CkAd"/></div></div><p class="ky kz gj gh gi la lb bd b be z dk translated">作者制作的图像</p></figure><h1 id="ff93" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结束语</h1><p id="6fb0" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><em class="mh">这项研究来自一个名为</em> <a class="ae kl" href="https://github.com/aipaca-mlops/ML-training-cost-calculator" rel="noopener ugc nofollow" target="_blank"> <em class="mh">培训成本计算器</em> </a> <em class="mh"> (TCC)的开源研究项目。项目目标是通过产生一个巨大的ML实验数据库来理解影响机器学习训练时间(TT)的因素。基于数据库，TCC能够预测不同云服务器上培训作业的TT，从而为您的特定ML模型匹配最佳服务器。如果你对这个领域感兴趣，请加入我们成为贡献者。</em></p><p id="ff60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我们展示了类似VGG的CNN模型的“跳跃”现象。我们的解释是PCIe车道分配导致了这一点。</p><p id="17c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但我们目前的解释仍然存在问题:为什么我们没有从我们的解释中看到双倍的训练时间，因为如果批量大小为32，GPU需要进行两轮相同的计算。以及为什么这种情况只发生在VGG16和VGG19上，而没有发生在MobileNet和ResNets上。这些问题需要进一步的调查和研究。</p><p id="6481" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/aipaca-mlops/ML-training-cost-calculator/blob/create_readme_xin/experiments/ClassicModels.ipyn" rel="noopener ugc nofollow" target="_blank">代码</a>复制实验</p></div></div>    
</body>
</html>