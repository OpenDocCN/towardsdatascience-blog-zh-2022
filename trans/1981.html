<html>
<head>
<title>Getting Started with NLTK in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的NLTK入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-nltk-eb4ed6eb7a37#2022-05-05">https://towardsdatascience.com/getting-started-with-nltk-eb4ed6eb7a37#2022-05-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0034" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索一些我们可以用来开发基本NLP管道的最常见的函数和技术。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/443a185f48b8f16a34de07faa9b6fbb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lfV8E5_ZCjPLaDZC"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@aaronburden" rel="noopener ugc nofollow" target="_blank">亚伦·伯顿</a> @unsplash.com拍摄</p></figure><p id="4127" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> N </span> LTK ( <em class="me">自然语言工具包</em>)是自然语言处理技术在Python中的首批实现之一。尽管它可能看起来有点过时，并且面临来自其他库的竞争(例如，<a class="ae ky" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> <em class="me"> spaCy </em> </a>)，但我仍然认为<em class="me"> NLTK </em>是对Python中文本方法的一个非常温和的介绍。</p><p id="0c4c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">起初，使用<em class="me"> NLTK </em>可能看起来有点奇怪，因为它有很多方法，特别是对于Python初学者来说。但实际上，它是从简单的NLP任务开始更方便的库之一，因为它有简单的单行方法，人们可以调用这些方法来执行一些很酷的文本转换。</p><p id="ccd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，你不应该指望使用<em class="me"> NLTK来训练最先进的模型。</em>然而<em class="me">，</em>这个库给了你很多工具，用于小的宠物项目和开发小规模的NLP项目。此外，它也是第一次接触NLP技术的最好的库之一。</p><p id="296c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章会给你一些简短的解释和例子，你可以马上用在NLTK中。我们将做一些<em class="me"> NLTK </em>函数的代码示例，并讨论一些我们可以使用的替代方法。</p><p id="f6a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了使这段代码易于复制，我们将使用来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Python_(programming_language)" rel="noopener ugc nofollow" target="_blank"> Python的维基百科页面</a>的前几段:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="a68c" class="mk ml it mg b gy mm mn l mo mp">python_wiki = '''<br/>Python is a high-level, interpreted, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.<br/>Python is dynamically-typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a “batteries included” language due to its comprehensive standard library.<br/>Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0.[33] Python 2.0 was released in 2000 and introduced new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 3.0, released in 2008, was a major revision that is not completely backward-compatible with earlier versions. Python 2 was discontinued with version 2.7.18 in 2020.<br/>Python consistently ranks as one of the most popular programming languages.<br/>'''</span></pre></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="046c" class="mx ml it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">单词分词器</h1><p id="37c6" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">自然，如果没有某种类型的转换，计算机无法真正理解大量的文本。在处理NLP管道时，标记化是第一个想到的转换。</p><p id="b0c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">“<em class="me">令牌</em>”是NLP行业中一个非常常见的表达。令牌是某个特定文本的子集或整个文本的分解。例如，孤立的单词！</p><p id="9d36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于有多种方法可以将单词从文本中分离出来，<code class="fe nt nu nv mg b">nltk</code>有一些关于记号赋予器的很酷的不同实现，即:</p><ul class=""><li id="e45d" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><em class="me">空白符号化器</em></li><li id="e8cb" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Treebank" rel="noopener ugc nofollow" target="_blank"><em class="me">tree bank</em></a><em class="me"/>分词器</li></ul><p id="1d68" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记号赋予者把我们的句子分割成记号。然后，这些标记可以被送入多种单词表示算法，如<em class="me"> tf-idf </em>，二进制或计数矢量器。让我们从最简单的开始，<em class="me"> whitespace </em> tokenizer，它根据单词之间的空格分割文本:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="b78d" class="mk ml it mg b gy mm mn l mo mp">from nltk import tokenize</span><span id="6baa" class="mk ml it mg b gy ok mn l mo mp">ws_tok = tokenize.WhitespaceTokenizer()<br/>token_list = ws_tok.tokenize(python_wiki)<br/>print(token_list[0:10])</span></pre><p id="c665" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分解上面的代码:</p><ul class=""><li id="9f69" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">from nltk import tokenize</code> —我们从导入通用的<code class="fe nt nu nv mg b">tokenize</code>模块开始，该模块包含标记化器的不同实现。</li><li id="21fd" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我们在<code class="fe nt nu nv mg b">ws_tok</code>中定义了一个<code class="fe nt nu nv mg b">WhitespaceTokenizer</code>的实例。</li><li id="4189" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我们使用<code class="fe nt nu nv mg b">ws_tok</code>实例来标记我们的<code class="fe nt nu nv mg b">python_wiki</code>文本。</li></ul><p id="64f4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nt nu nv mg b">print</code>语句产生以下结果:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="adc8" class="mk ml it mg b gy mm mn l mo mp">['Python', 'is', 'a', 'high-level,', 'interpreted,', 'general-purpose', 'programming', 'language.', 'Its', 'design']</span></pre><p id="8cfb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><code class="fe nt nu nv mg b">WhitespaceTokenizer</code>的一个主要问题是，它最终通过每个空格分割文本，形成一些由单词和标点组成的记号。</p><p id="1f1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，“<code class="fe nt nu nv mg b">interpreted,</code>”被认为是一个单独的标记，注意这个单词上的逗号。如果你有另一个没有逗号的<code class="fe nt nu nv mg b">interpreted</code>，这个单词会被认为是一个完全不同的单词。这是一个重大的挫折，因为如果单词在逗号、句号或其他标点符号旁边，它们的意思不会真正改变。</p><p id="b644" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，我们有其他可用的记号赋予器，比如<a class="ae ky" href="https://www.nltk.org/_modules/nltk/tokenize/treebank.html" rel="noopener ugc nofollow" target="_blank"> TreeBank </a>记号赋予器。这个记号赋予器的一些特性是(摘自官方文档):</p><blockquote class="ol om on"><p id="871c" class="kz la me lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">该记号赋予器执行以下步骤:</p><p id="cc9b" class="kz la me lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">-拆分标准缩写，例如:“不要”、“不要”和“他们会”、“他们会”</p><p id="a46c" class="kz la me lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">-将大多数标点符号视为单独的符号-当逗号和单引号后跟空格时，将其分开</p><p id="3bee" class="kz la me lb b lc ld ju le lf lg jx lh oo lj lk ll op ln lo lp oq lr ls lt lu im bi translated">-在行尾出现单独的句点</p></blockquote><p id="1ca0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用我们的<code class="fe nt nu nv mg b">python_wiki</code>文本做同样的测试:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="3f2c" class="mk ml it mg b gy mm mn l mo mp">tb_tokenizer = tokenize.treebank.TreebankWordTokenizer()<br/>token_list = tb_tokenizer.tokenize(python_wiki)<br/>print(token_list[0:10])</span></pre><p id="0d1b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们检查一下印刷品:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="5741" class="mk ml it mg b gy mm mn l mo mp">['Python', 'is', 'a', 'high-level', ',', 'interpreted', ',', 'general-purpose', 'programming', 'language.']</span></pre><p id="6297" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">酷！一些问题已经解决。注意<code class="fe nt nu nv mg b">language.</code>还是一个单词和标点结合的令牌。幸运的是，这个问题用默认的混合了<code class="fe nt nu nv mg b">TreebankWordTokenizer</code>和<code class="fe nt nu nv mg b">PunkSentenceTokenizer</code>的<code class="fe nt nu nv mg b">word_tokenize</code>函数解决了(我们没有测试的一个记号赋予器)。</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="edce" class="mk ml it mg b gy mm mn l mo mp">from nltk import word_tokenize<br/>token_list = word_tokenize(python_wiki)<br/>print(token_list[0:10])</span></pre><p id="2c3b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看我们的前十个令牌:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="e8db" class="mk ml it mg b gy mm mn l mo mp">['Python', 'is', 'a', 'high-level', ',', 'interpreted', ',', 'general-purpose', 'programming', 'language']</span></pre><p id="a4aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">酷！NLTK的默认<code class="fe nt nu nv mg b">word_tokenize</code>似乎很好地隔离了句子中的标记，因为它没有在单个标记中附加任何标点符号。</p><p id="e532" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总的来说，这些记号化器是将我们的文本分割成记号的好方法，然后将它们输入到其他应用程序中，如简单的情感分析或单词向量。我们的实验有助于你理解不存在单一的“记号赋予者”。虽然有人可能会说<code class="fe nt nu nv mg b">word_tokenize</code>产生了最好的结果，但是在<code class="fe nt nu nv mg b">nltk</code>中可以尝试其他的选择和实现。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="ba06" class="mx ml it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">堵塞物</h1><p id="187d" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">减少文本的变化可能是您在处理文本数据时首先要做的实验之一。</p><p id="daee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本数据本质上是高维的——英语中有成千上万的单词，其维数与其他语言相似。</p><p id="a859" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">词干可能是减小文本大小的一个好选择——词干的作用是从单词中去掉一些后缀。词干是一种有点“蛮力”的技术，在从文本中剪切字符时被认为是相当激进的。像<code class="fe nt nu nv mg b">tokenizers</code>一样，词干分析器有不同的风格——让我们看看NLTK中的一些实现，从<code class="fe nt nu nv mg b">PorterStemmer</code>开始:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="c639" class="mk ml it mg b gy mm mn l mo mp">from nltk.stem import PorterStemmer<br/>porter = PorterStemmer()<br/>porter_tokens = [porter.stem(token) for token in token_list]</span></pre><p id="4836" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">分解我们代码的每个指令:</p><ul class=""><li id="6d5c" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">我们从从<code class="fe nt nu nv mg b">nltk.stem</code>模块导入<code class="fe nt nu nv mg b">PorterStemmer</code>开始。</li><li id="09d3" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我们在<code class="fe nt nu nv mg b">porter</code>变量中定义了一个<code class="fe nt nu nv mg b">PorterStemmer</code>的实例。</li><li id="a692" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我们使用列表理解并在<code class="fe nt nu nv mg b">porter.stem</code>函数中传递每个<code class="fe nt nu nv mg b">token</code>来阻止每个标记。</li></ul><p id="7694" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们打印我们的第一个10个词干标记:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="61b5" class="mk ml it mg b gy mm mn l mo mp">['python', 'is', 'a', 'high-level', ',', 'interpret', ',', 'general-purpos', 'program', 'languag']</span></pre><p id="a176" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在某些情况下，我们的词干与我们的原始单词不同——例如，原始单词<code class="fe nt nu nv mg b">interpreted</code>变成了<code class="fe nt nu nv mg b">interpret</code>。词干意味着首字母相同的单词将被认为是相同的，例如:</p><ul class=""><li id="1b68" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">interpretation</code>变为<code class="fe nt nu nv mg b">interpret</code></li><li id="2d9e" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">interpreted</code>变为<code class="fe nt nu nv mg b">interpret</code></li><li id="8dc4" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">interpret</code>停留<code class="fe nt nu nv mg b">interpret</code></li></ul><p id="bb30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据定义，有些单词没有词干。当我们通过词干算法时,<code class="fe nt nu nv mg b">python</code>保持<code class="fe nt nu nv mg b">python</code>。</p><p id="0e24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更具侵略性的斯特梅尔是T20——我们也可以用它来表达</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="f469" class="mk ml it mg b gy mm mn l mo mp">from nltk.stem import LancasterStemmer<br/>lanc = LancasterStemmer()<br/>lanc_tokens = [lanc.stem(token) for token in token_list]</span></pre><p id="a6a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">检查我们的<code class="fe nt nu nv mg b">lanc_tokens</code>:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="f223" class="mk ml it mg b gy mm mn l mo mp">['python', 'is', 'a', 'high-level', ',', 'interpret', ',', 'general-purpose', 'program', 'langu']</span></pre><p id="c9d8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般来说，<code class="fe nt nu nv mg b">LancasterStemmer</code>会比<code class="fe nt nu nv mg b">PorterStemmer</code>从文本中删除更多的字符，但这并不意味着，在某些情况下，与<code class="fe nt nu nv mg b">Lancaster</code>相比，<code class="fe nt nu nv mg b">Porter</code>可以进一步阻止单词。从上面的例子来看:</p><ul class=""><li id="617a" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">language</code>在<code class="fe nt nu nv mg b">Lancaster</code>中变成<code class="fe nt nu nv mg b">langu</code>，在<code class="fe nt nu nv mg b">Porter</code>中变成<code class="fe nt nu nv mg b">languag</code>。</li><li id="ff9b" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">反过来，<code class="fe nt nu nv mg b">general-purpose</code>在<code class="fe nt nu nv mg b">Porter</code>中有词干，但在<code class="fe nt nu nv mg b">Lancaster</code>中没有。</li></ul><p id="371e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你检查全文，你会发现<code class="fe nt nu nv mg b">Lancaster</code>减少了更多的文本，进一步规范化。</p><p id="c731" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本规范化是一项很酷的技术，可以减少输入的差异，并规范化可能(或可能不)表达相同意思的相似单词。然而，要注意的是，每次你应用<code class="fe nt nu nv mg b">Stemmer</code>，你都在减少来自<em class="me">语料库</em>的信息。</p><p id="7e7b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">目前，人们正在讨论<code class="fe nt nu nv mg b">Stemmers</code>或<code class="fe nt nu nv mg b">Lemmatizers</code>(接下来将详细介绍)是否应该成为大多数数据管道的一部分，尤其是在新的神经网络技术应用于文本的情况下。有人可能会说，它们将来可能会过时，但是，在下列情况下，它们仍然有效:</p><ul class=""><li id="5a8b" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">你缺乏训练大量参数的计算能力；</li><li id="053e" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">由于可解释性或其他潜在原因，您需要应用更简单的模型。</li></ul><p id="dfcd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解更多关于<code class="fe nt nu nv mg b">Stemmers</code>的事情，你可以在这里查看我关于此事的博文<a class="ae ky" rel="noopener" target="_blank" href="/stemming-corpus-with-nltk-7a6a6d02d3e5">！</a></p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="47b3" class="mx ml it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">词汇化</h1><p id="dac0" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">与词干化类似，词汇化是另一种标准化技术，目的是减少文本的变化。</p><p id="2db0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">主要区别在于，它不是将单词切割成后缀，而是试图找到单词的词根，通常称为<em class="me"> lemma。</em></p><p id="d98b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">NLTK还包含一个现成的WordNet Lemmatizer实现，这是一个非常著名的词汇数据库，包含关于单词关系的数据。让我们检查一下<code class="fe nt nu nv mg b">WordNetLemmatizer</code>模块:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="853e" class="mk ml it mg b gy mm mn l mo mp">['Python', 'is', 'a', 'high-level', ',', 'interpreted', ',', 'general-purpose', 'programming', 'language']</span></pre><p id="8221" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">那很有趣..看来我们的令牌和我们的句子完全一样！解释很简单——我们需要给<code class="fe nt nu nv mg b">lemmatizer</code>输入我们想要减少的单词的词性标签。让我们从我们的代币中选择单词<code class="fe nt nu nv mg b">programming</code>:</p><ul class=""><li id="76f4" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">lemmatizer.lemmatize('programming')</code>产量<code class="fe nt nu nv mg b">programming</code></li><li id="7381" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">lemmatizer.lemmatize('programming', pos = 'v')</code>产量<code class="fe nt nu nv mg b">program</code></li></ul><p id="7271" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当我们给出论点<code class="fe nt nu nv mg b">pos</code>时，引理者能够理解单词programming是一个与词根“program”相关的动词<em class="me">。<em class="me">NLTK</em>wordnet<em class="me">lemmatizer</em>接收5个<code class="fe nt nu nv mg b">pos</code>标签:</em></p><ul class=""><li id="8005" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">名词的“n”——这是默认值。实际上，如果我们只是调用我们的<code class="fe nt nu nv mg b">lemmatizer.lemmatize</code>而没有<code class="fe nt nu nv mg b">pos</code>参数，我们将把所有的单词都看作名词；</li><li id="dcd0" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">动词用“v ”;</li><li id="e25e" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">形容词用“a ”;</li><li id="0fcb" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">r代表副词；</li><li id="373c" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">s代表卫星形容词——不常使用；</li></ul><p id="1f85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当然，手动输入这些<code class="fe nt nu nv mg b">pos</code>标签是非常低效的。幸运的是，<code class="fe nt nu nv mg b">nltk</code>有一个超级酷的实现来自动检索POS标签！</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="44b9" class="mx ml it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">词性标注</h1><p id="5650" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">正如我们在词汇化一节中看到的，词性标注包括根据单词在句子中的功能对其进行分类。</p><p id="98f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一个特定的词在一个句子中有一定的功能(通常称为<em class="me">词性</em>)——例如，句子“<code class="fe nt nu nv mg b">I like learning Python</code>”包含4个词和下面的<em class="me">词性</em>:</p><ul class=""><li id="35b1" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">代词<code class="fe nt nu nv mg b">I</code></li><li id="9e6a" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">动词<code class="fe nt nu nv mg b">like</code>和<code class="fe nt nu nv mg b">learning</code></li><li id="6ba8" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">名词<code class="fe nt nu nv mg b">Python</code></li></ul><p id="8494" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">棘手的是，某些单词在句法上可能是相同的，但在不同的句子中有不同的“功能”:</p><ul class=""><li id="489c" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">我正在洗<em class="me">水槽</em>。</li><li id="96ea" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我要把<em class="me">沉入水中</em></li></ul><p id="f678" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词<code class="fe nt nu nv mg b">sink</code>的写法完全相同，但有不同的词性标签。在第一句中，<code class="fe nt nu nv mg b">sink</code>是名词。第二个，是一个<code class="fe nt nu nv mg b">verb</code>。</p><p id="f6bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<code class="fe nt nu nv mg b">NLTK</code>中，我们有现成的POS tagger可供使用，幸运的是，它避免了这些问题:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="5e7b" class="mk ml it mg b gy mm mn l mo mp">import nltk<br/>pos_tags = nltk.pos_tag(token_list)<br/>print(pos_tags[0:10])</span></pre><p id="b7f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第10期<code class="fe nt nu nv mg b">pos_tags</code>:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="3955" class="mk ml it mg b gy mm mn l mo mp">[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), (',', ','), ('interpreted', 'JJ'), (',', ','), ('general-purpose', 'JJ'), ('programming', 'NN'), ('language', 'NN')]</span></pre><p id="2cb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与上面的一些例子相反，<code class="fe nt nu nv mg b">nltk.pos_tag</code>返回一个元组列表。每个元组包含单词及其对应的<code class="fe nt nu nv mg b">pos_tag</code>。让我们看几个例子:</p><ul class=""><li id="f0d1" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">Python</code>被归类为<code class="fe nt nu nv mg b">NNP</code>——专有单数名词；</li><li id="a49d" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated"><code class="fe nt nu nv mg b">is</code>是一个<code class="fe nt nu nv mg b">VBZ</code>——现在时态的动词。</li></ul><p id="61aa" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从预告中，我们看到很多标签！我们必须记住他们吗？当然不是！我们有两种方法来理解每个标签的含义:</p><ul class=""><li id="daf1" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">查找<a class="ae ky" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" rel="noopener ugc nofollow" target="_blank"> Penn Treebank POS表</a>。</li><li id="7dc5" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">使用您想要检查的标签运行<code class="fe nt nu nv mg b">nltk.help.upenn_tagset()</code>。例如，<code class="fe nt nu nv mg b">nltk.help.upenn_tagset('NN')</code>返回标签<code class="fe nt nu nv mg b">NN</code>的完整wiki。</li></ul><p id="5330" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从第一句话开始，看看这位经过预先训练的pos标记员是否能够处理我们的“下沉”问题:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="d70b" class="mk ml it mg b gy mm mn l mo mp">print(nltk.pos_tag(['I','am','washing','the','sink']))</span></pre><p id="82db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这会产生:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="2f56" class="mk ml it mg b gy mm mn l mo mp">[('I', 'PRP'), ('am', 'VBP'), ('washing', 'VBG'), ('the', 'DT'), ('sink', 'NN')]</span></pre><p id="d1e4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">爽，这里沉的是一只<code class="fe nt nu nv mg b">NN</code>！让我们看看另一句话:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="b0a8" class="mk ml it mg b gy mm mn l mo mp">print(nltk.pos_tag([‘I’,’am’,’going’,’to’,’sink’,’in’,’the’,’water’]))</span></pre><p id="49ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这会产生:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="9a7b" class="mk ml it mg b gy mm mn l mo mp">[('I', 'PRP'), ('am', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('sink', 'VB'), ('in', 'IN'), ('the', 'DT'), ('water', 'NN')]</span></pre><p id="cb99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">厉害！<code class="fe nt nu nv mg b">sink</code>是<code class="fe nt nu nv mg b">vb</code> —一个动词！</p><p id="2757" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是因为这个预先训练的词性标注器考虑了单词的上下文。由于<code class="fe nt nu nv mg b">sink</code>紧挨着<code class="fe nt nu nv mg b">to</code>，标记者立即意识到它应该标记为动词，因为没有其他场景中这些单词一起出现，而<code class="fe nt nu nv mg b">sink</code>是名词。</p><p id="c911" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你也可以在我在Udemy 上的<a class="ae ky" href="https://www.udemy.com/course/nlp_natural_language_processing_python_beginners/?referralCode=MEDIUMREADERS" rel="noopener ugc nofollow" target="_blank"> NLP基础课程中了解更多关于训练你自己的pos标签员的信息。</a></p><p id="fb78" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi">…</p><p id="8001" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，等等..这些标签与我们必须输入到词汇化过程中的标签不匹配！这是怎么回事？</p><p id="4b63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">幸运的是，我们可以用下面的函数很容易地转换它们:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="d51c" class="mk ml it mg b gy mm mn l mo mp">def get_lemma_tag(pos_tag):<br/>    if pos_tag.startswith('J'):<br/>        return 'a'<br/>    elif pos_tag.startswith('V'):<br/>        return 'v'<br/>    elif pos_tag.startswith('N'):<br/>        return 'n'<br/>    elif pos_tag.startswith('R'):<br/>        return 'r'<br/>    else:<br/>        return ''</span></pre><p id="ef0e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您只需检查<code class="fe nt nu nv mg b">pos_tag</code>函数的起始字母是什么，并将其转换为输入到lemmatizer的单字母版本——让我们测试一下:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="3538" class="mk ml it mg b gy mm mn l mo mp">lemmatizer.lemmatize(‘programming’, pos = get_lemma_tag(‘VBZ’))</span></pre><p id="fcea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这输出<code class="fe nt nu nv mg b">program</code>。成功了！</p><p id="0e54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了简单起见，我们在函数中忽略了“附属形容词”——它们不常使用，需要更复杂的规则。</p><p id="f16e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">POS标签是NLP中一个非常重要的概念。你可能最终会使用你自己训练过的标签或者更高级的标签，比如spacy的实现。尽管如此，<em class="me"> NLTK的</em>版本仍然被广泛使用，并且可以实现很好的性能，足以完成一些NLP任务。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><h1 id="1c0a" class="mx ml it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">N-Grams</h1><p id="b416" class="pw-post-body-paragraph kz la it lb b lc no ju le lf np jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">到目前为止，我们只把我们的<em class="me">记号</em>看作孤立的单词。在许多NLP应用程序中，将单词耦合在一起作为单个“令牌”来考虑是很重要的。</p><p id="474d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，否定是解释的基本要素。Bi-grams是“两个连续单词”的自然语言处理方式。让我们来考虑这个句子:</p><ul class=""><li id="92cb" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">我不喜欢剧院。</li></ul><p id="0ec4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在典型的<em class="me">单字符</em>方式中，我们的令牌是:</p><ul class=""><li id="c1e4" class="nw nx it lb b lc ld lf lg li ny lm nz lq oa lu ob oc od oe bi translated">我没有去剧院</li></ul><p id="941f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，将“<strong class="lb iu">不像</strong>”视为一个单独的标记是有意义的。想象一个情感分析应用程序，它将检查相关的标记来理解我们文本的整体“情感”。在这种情况下，它显然是一个否定的句子，因为“代理人”不喜欢剧院。</p><p id="a156" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于这个用例，了解我们的文本包含多少“不喜欢”的表达是有用的。如果我们只考虑一个孤立的单词“like”，我们的算法将很难拾取这种“负面情绪”，因为单词“<em class="me">而不是</em>”也将是孤立的。此外，一个孤立的“<em class="me"> not </em>”本身并不一定代表一种负面情绪——例如在句子“<em class="me">我不认为这个剧院不好。</em></p><p id="26c7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在更高级的模型中，如神经网络，算法能够自己挑选这些<em class="me">二元模型</em>、<em class="me">三元模型</em>(三个令牌)——这实际上是它们的优势之一。但是，对于更简单的模型(朴素贝叶斯、回归、基于树的模型),必须显式地给出<em class="me"> n-grams </em>作为特征。</p><p id="afb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="me"> NLTK </em>有一个我们可以获取的<em class="me">二元模型</em>和<em class="me">三元模型</em>的快速实现:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="e705" class="mk ml it mg b gy mm mn l mo mp">print(list(nltk.bigrams(token_list)))</span></pre><p id="2a89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超级容易！我们只是把我们原来的<code class="fe nt nu nv mg b">token_list</code>喂给<code class="fe nt nu nv mg b">nltk.bigrams</code>然后…</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="757b" class="mk ml it mg b gy mm mn l mo mp">[('Python', 'is'),<br/> ('is', 'a'),<br/> ('a', 'high-level'),<br/> ('high-level', ','),<br/> (',', 'interpreted'),<br/> ('interpreted', ','),<br/> (',', 'general-purpose'),<br/> ('general-purpose', 'programming'),<br/> ('programming', 'language'),<br/> ('language', '.'),<br/> ('.', 'Its'),</span></pre><p id="557a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是我们课文的前10个双字母组合的预览。我们现在有了一个元组列表，每个元组包含来自<code class="fe nt nu nv mg b">python_wiki</code>文本的两个单词。</p><p id="3c7e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们想要三个词呢？使用<code class="fe nt nu nv mg b">nltk</code>很简单:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="cd5a" class="mk ml it mg b gy mm mn l mo mp">list(nltk.trigrams(token_list))</span></pre><p id="3dc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有一个功能叫做<code class="fe nt nu nv mg b">trigrams</code>！让我们看看前10个:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="66a4" class="mk ml it mg b gy mm mn l mo mp">[('Python', 'is', 'a'),<br/> ('is', 'a', 'high-level'),<br/> ('a', 'high-level', ','),<br/> ('high-level', ',', 'interpreted'),<br/> (',', 'interpreted', ','),<br/> ('interpreted', ',', 'general-purpose'),<br/> (',', 'general-purpose', 'programming'),<br/> ('general-purpose', 'programming', 'language'),<br/> ('programming', 'language', '.'),<br/> ('language', '.', 'Its'),</span></pre><p id="5a01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">酷！现在我们有了一个元组列表，其中每个元组包含文本中三个连续单词的每一对。我们能有更多的三字母组合吗？没错。使用带额外参数的通用<code class="fe nt nu nv mg b">ngrams</code>函数:</p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="9e1d" class="mk ml it mg b gy mm mn l mo mp">list(nltk.ngrams(token_list, 4))</span></pre><p id="2b39" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这产生了<em class="me">四个字母:</em></p><pre class="kj kk kl km gt mf mg mh mi aw mj bi"><span id="f7ac" class="mk ml it mg b gy mm mn l mo mp">[('Python', 'is', 'a', 'high-level'),<br/> ('is', 'a', 'high-level', ','),<br/> ('a', 'high-level', ',', 'interpreted'),<br/> ('high-level', ',', 'interpreted', ','),<br/> (',', 'interpreted', ',', 'general-purpose'),<br/> ('interpreted', ',', 'general-purpose', 'programming'),<br/> (',', 'general-purpose', 'programming', 'language'),<br/> ('general-purpose', 'programming', 'language', '.'),<br/> ('programming', 'language', '.', 'Its'),<br/> ('language', '.', 'Its', 'design'),</span></pre><p id="f98a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于你的<em class="me"> NLP </em>管道来说，N-grams 是一个非常重要的概念，尤其是当你处理可能需要一些聪明的特征工程的更简单的模型的时候。</p></div><div class="ab cl mq mr hx ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="im in io ip iq"><p id="8a1e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们完事了。如果你想开始使用自然语言处理管道，NLTK 是一个非常酷的库。虽然你不应该期望使用<em class="me"> NLTK来构建<em class="me">最先进的</em>模型，但是</em>熟悉这个库将是向你介绍很酷的<em class="me"> NLP </em>概念<em class="me">的一个极好的方式。</em></p><p id="c622" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> <em class="me">我在</em></strong><a class="ae ky" href="https://www.udemy.com/course/nlp_natural_language_processing_python_beginners/?referralCode=MEDIUMREADERS" rel="noopener ugc nofollow" target="_blank"><strong class="lb iu"><em class="me">Udemy</em></strong></a><strong class="lb iu"><em class="me">上开设了一门学习自然语言处理基础知识的课程，在这里我向学生们介绍nltk、词向量和神经网络！这门课程是为初学者量身定做的，我希望你能在我身边。</em>T13】</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/4ec776de69b299a0232f4eba0a3ee546.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*YXX4NqEHI2QAEs7h-EE6QQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.udemy.com/course/nlp_natural_language_processing_python_beginners/?referralCode=MEDIUMREADERS" rel="noopener ugc nofollow" target="_blank">Python中的自然语言处理基础</a> —图片作者</p></figure><div class="os ot gp gr ou ov"><a href="https://ivopbernardo.medium.com/membership" rel="noopener follow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd iu gy z fp pa fr fs pb fu fw is bi translated">通过我的推荐链接加入Medium-Ivo Bernardo</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">ivopbernardo.medium.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj ks ov"/></div></div></a></div><p id="e677" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这篇文章的代码有一个小要点:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pk pl l"/></div></figure></div></div>    
</body>
</html>