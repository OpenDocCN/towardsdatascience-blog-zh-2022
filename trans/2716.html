<html>
<head>
<title>Using PCA to Reduce Number of Parameters in a Neural Network by 30x Times</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PCA将神经网络中的参数数量减少30倍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-pca-to-reduce-number-of-parameters-in-a-neural-network-by-30x-times-fcc737159282#2022-06-12">https://towardsdatascience.com/using-pca-to-reduce-number-of-parameters-in-a-neural-network-by-30x-times-fcc737159282#2022-06-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="cc75" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">同时还能获得更好的性能！—神经网络和深度学习课程:第17部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5596d57ad9b8b8dbe404b9f8452e8901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*46u8MFAXp2BmU9hstEkPPw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae ky" href="https://unsplash.com/es/@magicpattern?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> MagicPattern </a>原图，作者编辑</p></figure><p id="fc65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<a class="ae ky" rel="noopener" target="_blank" href="/creating-a-multilayer-perceptron-mlp-classifier-model-to-identify-handwritten-digits-9bac1b16fe10">之前的文章</a>中，我们创建了一个多层感知器(MLP)分类器模型来识别手写数字。</p><p id="fb50" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们为网络架构使用了两个具有256个神经元的隐藏层。即使是这样一个小网络，我们总共得到了269，322个参数(权重和偏差项)。获得如此大量的网络参数的主要原因是输入层的大尺寸。</p><p id="62ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因为MLP的输入图层采用1D张量，所以我们需要将二维MNIST影像数据重塑为一维数据。这个过程在技术上叫做<strong class="lb iu"> <em class="lv">展平</em> </strong>图像。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/20842bd6e2225f9e96442c4341228516.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Bo7BUfrDLrwZqRpyCff9PA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供，用draw.io制作)</p></figure><p id="1599" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像中的每个像素代表一个输入。如果图像中有784个像素，我们在MLP的输入层需要784个神经元。当输入层的大小增加时，我们得到网络中大量的总参数。这就是为什么MLP不是参数有效的。当我们使用高像素值图像数据(例如500 x 500 px图像)时，输入层的大小会显著增加。</p><p id="b2e5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">获得网络中大量总参数的问题是，我们需要大量计算资源来训练神经网络，并且这也是耗时的。</p><p id="9b2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MLP不适用于图像数据。还有一种更好的神经网络架构，称为<strong class="lb iu">卷积神经网络(CNN或ConvNets) </strong>，用于处理图像数据。它的输入层可以获取高维数据，因此我们不需要展平图像。</p><p id="c527" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有一种方法可以减少图像中的像素数量，而不会损失太多的图像质量，我们仍然可以有效地将MLPs用于图像数据。如果我们能做到这一点，输入层的大小将会非常小，MLP模型将是参数有效的。</p><p id="313c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将<strong class="lb iu">主成分分析(PCA) </strong>应用到展平的图像中，以显著减少像素数量，同时仍然获得几乎相同的图像质量，但现在像素更少了！</p><p id="8048" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一般的工作流程是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lx"><img src="../Images/e899495970f45790ecf99330847f576f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tLuhEcDi7OqHhR4pAf1UJQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供，用draw.io制作)</p></figure><p id="6d87" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将PCA应用于MNIST数字数据，并在保持91.4%图像质量的同时将维数(像素数)减少了7.48倍！然后，我们建立我们在<a class="ae ky" rel="noopener" target="_blank" href="/creating-a-multilayer-perceptron-mlp-classifier-model-to-identify-handwritten-digits-9bac1b16fe10">第16部分</a>中建立的相同的MLP模型。现在，输入的形状是(100，)，而不是(784，)。这将显著减少网络中总参数的数量。此外，我们有机会减少隐藏层中的神经元数量，因为现在输入大小很小。这也将有助于显著减少网络中的总参数数量。</p><h1 id="20ce" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">将主成分分析应用于MNIST数据</h1><p id="0a92" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">如果您<a class="ae ky" href="https://rukshanpramoditha.medium.com/acquire-understand-and-prepare-the-mnist-dataset-3d71a84e07e7#9d79" rel="noopener">通过Keras API </a>获取MNSIT数据，您将为训练集获得60，000幅手写数字灰度图像，为测试集获得10，000幅手写数字灰度图像。每个灰度图像都是二维的，宽28像素，高28像素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/344fc38e21522953e6f1c55b2039fddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*Sb3VSJtq8fCOZsEUhRBsVw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="ba10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们需要在应用PCA之前展平这些图像。展平后，我们得到:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/a744a4a926d5c5f90d2142e449f5c9c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*5y8BFZZD1MVSWPxxYqaXrg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="eb2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以将这个新的训练集图像数组视为一个简单的数据集，它有60，000行(图像数)和784列(图像中的像素数)。现在，我们可以像往常一样应用PCA。注意，我们将PCA分别应用于训练集和测试集。</p><p id="5941" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当考虑单个展平的图像时，像素的数量代表它的维度。当我们降低维度时，我们减少了图像中的像素数量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">对MNSIT数据进行主成分分析，选择最佳主成分数</strong>(作者代码)</p></figure><p id="9831" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">运行上述代码后，我们得到以下输出。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/1304ccadb9938a75739c0fd5c37b083f.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*tRZVPzCXha0tlUNsd2om9g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd na">选择最佳主成分数</strong>(图片作者提供)</p></figure><p id="c295" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以看到，前100个分量捕获了原始图像数据中大约90%的可变性。这足以保持原始图像的质量。因此，我们选择了前100个组件，并对所选组件的数量再次应用PCA。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="ak">用所选组件再次应用PCA</strong>(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/0845c718456b3138fcb179ef39fa6ba7.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*-w7c_kMUaH0lI93Y8giB6A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="81a7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将原始图像数据的维数减少了7.84倍(784/100)，同时保持了原始数据中91.43%的可变性。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/6e275d08287bdb4168dcd9e44e66581f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NVZtjOiRALzDiZaLXS3JUQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd na">图像样本:应用PCA前后</strong>(图片由作者提供)</p></figure><p id="c2ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">压缩后的图像依然清晰可辨！</p><p id="80ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>这里不打算多解释PCA过程。敬请参考下面的文章系列(我写的)，了解PCA和降维的一切。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/pca-and-dimensionality-reduction-special-collection-146045a5acb5"><div class="gh gi nc"><img src="../Images/1f1eeaa5bc9819a3b152644754499b1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*O7Xn8QtcMSXQWL7p6Ih8Dg.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd na">点击此图进入我的PCA与降维特辑</strong>(作者截图)</p></figure><h1 id="9a01" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">使用压缩(缩减)的图像数据构建MLP分类器</h1><p id="df2e" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li ms lk ll lm mt lo lp lq mu ls lt lu im bi translated">现在，我们建立与在<a class="ae ky" rel="noopener" target="_blank" href="/creating-a-multilayer-perceptron-mlp-classifier-model-to-identify-handwritten-digits-9bac1b16fe10">第16部分</a>中相同的MLP分类器模型，但是使用压缩的图像数据(更少的维度和更少的像素)！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/33aee7ced93607857e193e1e7c5d4e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*epFn3pY-cM5zcxmXVKVj4A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="5024" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这次我们得到了0.9745的准确度分数。之前(即在应用PCA之前)，我们得到了0.9804的准确度分数。我们只损失了很少的准确度分数。也就是0.0059。</p><p id="f012" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们现在检查总参数的数量，我们会得到:</p><pre class="kj kk kl km gt ne nf ng nh aw ni bi"><span id="c42e" class="nj lz it nf b gy nk nl l nm nn">MLP.summary()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/fe7a026d52caceee1bbe08d0add56e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*gtax8p1oeTmmA08CsUXRhg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd na">应用PCA后的可训练参数数量</strong>(图片由作者提供)</p></figure><p id="969e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">先前(即，在应用PCA之前)，我们总共获得了269，322个参数。这次我们总共只得到8874个参数。因此，在应用PCA后，我们将总参数数量减少了30倍(269，322 / 8，874 )!我们只损失了0.0059的模型精度。</p><p id="9b5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过应用主成分分析得到更好的结果。这次我说的是过度拟合的问题。</p><p id="c994" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我在培训期间测量了模型的性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mx my l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(作者代码)</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/03a8d13124d58af4cd366d51592b23e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*0PXwLrclqzxD7yZqJcvjFw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="5371" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这可以与相应的前一种情况相比较:在应用五氯苯甲醚之前。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c1c5ccc95f8dd2f61e47c25086917776.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*ngFo_eE2A4e0brNNdgu2mw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">(图片由作者提供)</p></figure><p id="6a36" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很明显，<strong class="lb iu"> <em class="lv">模型在应用PCA </em> </strong>后过拟合更少。该模型对新的未见过的数据(测试数据)进行了很好的概括。原因是:</p><blockquote class="nq nr ns"><p id="a733" class="kz la lv lb b lc ld ju le lf lg jx lh nt lj lk ll nu ln lo lp nv lr ls lt lu im bi translated">PCA去除数据中的噪声，只保留数据集中最重要的特征。这将减轻数据的过度拟合，并提高模型对未知数据的性能。除此之外，当数据中有许多要素时，模型会变得更加复杂。复杂的模型往往会过度拟合数据。PCA通过减少数据中的特征数量(维度)来处理模型的复杂性—来源:<a class="ae ky" rel="noopener" target="_blank" href="/how-to-mitigate-overfitting-with-dimensionality-reduction-555b755b3d66"> <strong class="lb iu">如何通过维度减少来缓解过度拟合</strong> </a> <strong class="lb iu"> </strong>(我自己的文章)</p></blockquote><h1 id="80bf" class="ly lz it bd ma mb mc md me mf mg mh mi jz mj ka mk kc ml kd mm kf mn kg mo mp bi translated">摘要</h1><ul class=""><li id="fe2f" class="nw nx it lb b lc mq lf mr li ny lm nz lq oa lu ob oc od oe bi translated">我们将PCA应用于MNIST数据，并成功地将原始图像数据的维数降低了7.84倍。因此，我们可以显著减小MLP输入层的大小。我们在原始数据中保留了91.43%的可变性。所以，图像还是可以识别的。</li><li id="2602" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">在应用PCA之后，我们仅损失了非常少量的准确性。</li><li id="8f9a" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">我们可以将MLP模型中的总参数数量减少30倍！这是因为我们大大减少了MLP输入层的大小和隐藏层中神经元的数量。因为现在输入量很小，我们有机会减少隐藏层中神经元的数量。通过增加隐藏层中神经元的数量，您不会获得太多的性能改善。不过，最好还是通过设置不同的值来做一些实验，然后测量性能。</li><li id="7cfe" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">应用主成分分析后，模型的过拟合程度降低。我解释了原因。另外，请注意，该模型仍然过拟合，因为我们还没有对该模型应用任何正则化技术。</li><li id="622e" class="nw nx it lb b lc of lf og li oh lm oi lq oj lu ob oc od oe bi translated">对MNIST图像数据应用PCA是容易的，因为图像是灰度的，其被表示为二维(2D)张量。PCA过程对于表示为三维(3D)的RGB图像来说是复杂的。阅读<a class="ae ky" rel="noopener" target="_blank" href="/rgb-color-image-compression-using-principal-component-analysis-fce3f48dfdd0">这篇文章</a>了解如何将PCA应用于RGB图像。要了解RGB和灰度图像的区别，请阅读<a class="ae ky" rel="noopener" target="_blank" href="/exploring-the-mnist-digits-dataset-7ff62631766a">这篇文章</a>。</li></ul></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="1aad" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的帖子到此结束。</p><p id="b508" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">如果您有任何问题或反馈，请告诉我。</strong></p><p id="07f1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢阅读这篇文章。如果你愿意支持我成为一名作家，请考虑 <a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="lv">注册会员</em> </strong> </a> <em class="lv">以获得无限制的媒体访问权限。它只需要每月5美元，我会收到你的会员费的一部分。</em></p><div class="or os gp gr ot ou"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="ov ab fo"><div class="ow ab ox cl cj oy"><h2 class="bd iu gy z fp oz fr fs pa fu fw is bi translated">通过我的推荐链接加入Medium</h2><div class="pb l"><h3 class="bd b gy z fp oz fr fs pa fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pc l"><p class="bd b dl z fp oz fr fs pa fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="pd l"><div class="pe l pf pg ph pd pi ks ou"/></div></div></a></div><p id="bfbe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你一直以来的支持！下一篇文章再见。祝大家学习愉快！</p></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><h2 id="2d28" class="nj lz it bd ma pj pk dn me pl pm dp mi li pn po mk lm pp pq mm lq pr ps mo pt bi translated">加入我的神经网络和深度学习课程</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75"><div class="gh gi pu"><img src="../Images/bedd5a46ddb147b7ace687395e4ae98c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*LPXNySfy0qXFOYx_fylxxQ.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd na">点击此图片进入我的神经网络和深度学习课程</strong>(作者截图)</p></figure></div><div class="ab cl ok ol hx om" role="separator"><span class="on bw bk oo op oq"/><span class="on bw bk oo op oq"/><span class="on bw bk oo op"/></div><div class="im in io ip iq"><p id="4471" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="pv pw ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----fcc737159282--------------------------------" rel="noopener" target="_blank">鲁克山·普拉莫迪塔</a><br/><strong class="lb iu">2022–06–12</strong></p></div></div>    
</body>
</html>