<html>
<head>
<title>Optical Character Recognition with KNN Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 KNN 分类器的光学字符识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optical-character-recognition-with-knn-classifier-10fd220ed797#2022-03-31">https://towardsdatascience.com/optical-character-recognition-with-knn-classifier-10fd220ed797#2022-03-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="962d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过流行的 K 近邻算法编码并解释光学字符识别的工作原理</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/6552a8ba9879f670c8095b132dcf0667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*tq541X21Qlz84RQSIO-0DQ.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">来自<a class="ae kr" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集</a>的手写数字</p></figure><p id="8bb8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">光学字符识别(<a class="ae kr" href="https://en.wikipedia.org/wiki/Optical_character_recognition" rel="noopener ugc nofollow" target="_blank"> OCR </a>)比我们想象的更经常地出现在我们的日常生活中。当我们使用<a class="ae kr" href="https://translate.google.com/" rel="noopener ugc nofollow" target="_blank">谷歌翻译</a>从图片翻译文本时，我们使用的是光学字符识别。当我们发送一封信并且它到达目的地时，OCR 正在为我们工作。当一个有视觉障碍的人扫描一份文件，一台机器为他们阅读时，OCR 又一次获得了荣誉。这些只是我们日常工作中 OCR 出现的几个例子，但是，到今天为止，还有更多的例子存在，并且在不久的将来，它们的数量还会进一步增加。</p><p id="7929" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">本文旨在说明什么是光学字符识别，并提供一个循序渐进的应用程序来熟悉它。我将使用<a class="ae kr" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集</a>来训练一个机器学习模型，它将能够从图片中识别手写数字。在微调算法后，我将评估它的准确性。</p><h1 id="ff3d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">什么是光学字符识别？</h1><p id="2eac" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">光学字符识别(<a class="ae kr" href="https://en.wikipedia.org/wiki/Optical_character_recognition" rel="noopener ugc nofollow" target="_blank"> OCR </a>)，也称为文本识别，是一种能够将印刷或手写字符转换为机器可读文本的技术。OCR 利用硬件和软件工具。硬件通常由光学扫描仪或照相机组成，而软件(本文的重点)由机器学习算法组成，如 KNN 分类器、SVM 分类器或神经网络。</p><p id="7e0f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">当前 OCR 的应用是无止境的。仅举其中一些例子:</p><ul class=""><li id="6e12" class="ml mm iq ku b kv kw ky kz lb mn lf mo lj mp ln mq mr ms mt bi translated">旧书籍或文件的电子版本(软版本)的生成(参见<a class="ae kr" href="https://books.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Books </a></li><li id="db8c" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">扫描路标<a class="ae kr" href="https://en.wikipedia.org/wiki/Self-driving_car" rel="noopener ugc nofollow" target="_blank">自动驾驶</a></li><li id="8022" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">创造工具使盲人和视障人士能够阅读(见<a class="ae kr" href="https://www.afb.org/node/16207/optical-character-recognition-systems#:~:text=Optical%20character%20recognition%20(OCR)%20systems,%2C%20recognition%2C%20and%20reading%20text." rel="noopener ugc nofollow" target="_blank"> AFB </a>)</li><li id="2e64" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">手写文本的实时转换</li><li id="2602" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">从护照或保险文件中自动提取信息</li></ul><h1 id="4656" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">型号选择</h1><p id="b361" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">光学字符识别是一个分类问题，这意味着它是一个机器学习问题，其中输出是分类的(即，它属于有限的一组值)。当然，输出类是不同的字符。在这个应用中，我们负责手写数字识别。输出类的数量为 10，由 0 到 9 的整数组成:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/aa48461c89f4e1ba48b671410b0a2be5.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/1*gC7pgoSmK6BWgKlkAEd6ZA.gif"/></div></figure><p id="2896" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">有许多现成的分类算法，所以我们需要选择一个非常适合这个目的的算法。算法选择的主要约束是它必须适合于<em class="na">多类分类</em>。事实上，由于类别多于 2，这不能被认为是一个<em class="na">二元分类</em>问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/03a75ffbf11d8a0cc70173bf8add37ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*KU-HW3LjsKX8LB3zTztEgA.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">多类分类</p></figure><p id="b79a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">一些算法天生能够处理多类分类问题(例如随机梯度下降、随机森林或朴素贝叶斯分类器)。其他算法(如支持向量机或逻辑回归分类器)本身就是二元分类器。即使存在使用二元分类器(<a class="ae kr" rel="noopener" target="_blank" href="/multi-class-classification-one-vs-all-one-vs-one-94daed32a87b"> <em class="na">一对一</em>或<em class="na">一对一</em> </a>策略)执行多类分类的技术，对于本文的范围，我将坚持使用原生多类分类器。</p><h2 id="e0ae" class="nc lp iq bd lq nd ne dn lu nf ng dp ly lb nh ni ma lf nj nk mc lj nl nm me nn bi translated">k 近邻分类器</h2><p id="8abb" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">由于没有公认的理论来确定每种问题类型的最佳学习算法，我的选择落在了<strong class="ku ir">k-最近邻分类器</strong> ( <strong class="ku ir"> KNN </strong> ) <strong class="ku ir"> </strong>上，主要是因为它简单:它需要调整的超参数很少(要考虑的邻居数量<em class="na"> k </em>，距离函数，通常对应于欧几里德距离或曼哈顿距离)，而且它是非参数的(这意味着它不需要关于数据分布的假设)。一个缺点是，由于其固有的性质，KNN 对大型数据集的伸缩性很差:每当需要对新的例子进行分类时，它都必须扫描整个数据集。出于这个原因，探索额外的学习算法是有意义的，比如决策树或随机森林。</p><p id="8bff" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">KNN 背后的思想是，一个实例<em class="na"> i </em>有很高的概率属于某个特定的类，姑且称之为<em class="na"> m </em>，如果<em class="na"> m </em>也是特征空间中<em class="na"> k </em>最近实例的最流行类。更正式地说，KNN 学习算法遵循以下步骤:</p><ol class=""><li id="6915" class="ml mm iq ku b kv kw ky kz lb mn lf mo lj mp ln no mr ms mt bi translated">给定一个未知示例，测量它与数据集中所有已标记示例的距离</li><li id="50b4" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln no mr ms mt bi translated">以最接近未标记的示例的标记示例为例</li><li id="bdef" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln no mr ms mt bi translated">基于<em class="na"> k </em>个最近邻的类别，预测未标记示例的类别</li><li id="2d32" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln no mr ms mt bi translated">对所有未标记的示例重复步骤 1-3。</li></ol><p id="5983" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这个操作之后，特征空间可以被可视化为分成与类一样多的区域。根据一个新例子的位置，它将被预测为属于一个特定的类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/babe89039cac87140ea255f78034bd65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*mqRILg7L9KkJjiKc9TwGVg.png"/></div><p class="kn ko gj gh gi kp kq bd b be z dk translated">特征空间的分类(图像来源:<a class="ae kr" href="https://en.wikipedia.org/wiki/File:Map1NN.png" rel="noopener ugc nofollow" target="_blank">Wikipedia.org</a></p></figure><p id="9f31" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了将 KNN 应用于分类问题，我们需要说明:</p><ul class=""><li id="9777" class="ml mm iq ku b kv kw ky kz lb mn lf mo lj mp ln mq mr ms mt bi translated">一个距离度量<em class="na"> p </em>。最常用的是欧几里德距离，它是<a class="ae kr" href="https://en.wikipedia.org/wiki/Minkowski_distance" rel="noopener ugc nofollow" target="_blank">闵可夫斯基距离</a>的一个特例，这里设置<em class="na"> p=2。</em>给定相同尺寸的 2 个点<em class="na"> X </em>和<em class="na"> Y </em>，闵可夫斯基距离<em class="na"> D(X，Y) </em>计算如下:</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/58f36ce7ac9cb918c1e614fdd517e6cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/1*GepZdJxqQ_5LSViS2sj81Q.gif"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/c6899cf73f0ed184153d545db6e5f2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/1*-yXK5Jf997mR0LRjNbxEpQ.gif"/></div></figure><ul class=""><li id="170d" class="ml mm iq ku b kv kw ky kz lb mn lf mo lj mp ln mq mr ms mt bi translated">要考虑的邻居数量 k。这可能是 KNN 最关键的超参数，因为:<br/> -对于<em class="na"> k </em>来说太小的值可能导致过度拟合<br/> -对于<em class="na"> k </em>来说太大的值可能导致拟合不足<br/>强烈建议使用<a class="ae kr" href="https://scikit-learn.org/stable/modules/cross_validation.html" rel="noopener ugc nofollow" target="_blank">交叉验证</a>集来优化<em class="na"> k </em>。</li><li id="1f6a" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">可选加权函数。它经常被忽略，但是在某些应用中，通过设置一个奖励最近邻类的加权函数可以获得更好的结果。</li><li id="9e76" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln mq mr ms mt bi translated">聚合方法。通常选择简单多数票。</li></ul><p id="1d6e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在这里我提供了 KNN 算法的一个简明的快照，有关其功能的更详细的信息请查看本文。</p><h1 id="c144" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">MNIST 数据集</h1><p id="f18a" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">为了训练我们的模型，我将使用<a class="ae kr" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集</a>，这是一个手写数字的大型数据库。该数据集包含 70，000 个小图像(28 x 28 像素)，每个图像都被标记。</p><p id="4b27" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">首先，我们必须导入数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="72ef" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">为了了解数据集，我定义了一个函数来打印 70，000 幅图像中的一幅:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="59c6" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">输出将是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/08f9e7d2ad57dec66eb197884e68355d.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*0_-4Abq8L80eAuEQV5nP2A.png"/></div></figure><p id="9a3b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">数据集由 70，000 个示例组成，每个示例都有 784 个要素(28 x 28 像素)。每个特征代表灰度色图上给定像素的强度，特征值范围从 0 到 255。<br/>0 值对应白色像素，而 255 值对应黑色像素。</p><h1 id="f5f2" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">模特培训</h1><p id="59e6" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">按照惯例，我们将数据集分为训练集和测试集。我选择将 25%的例子分配给测试集。测试集将被放在一边，直到最后都不会被触及。其唯一目的是提供模型的一般评估。将使用交叉验证集执行超参数调整。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="7a5b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">让我们首先尝试用默认参数来拟合分类器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="295b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这应该输出大约 96.8%的准确率，考虑到构建模型的工作量很小，这还不算太差。</p><h2 id="9e4d" class="nc lp iq bd lq nd ne dn lu nf ng dp ly lb nh ni ma lf nj nk mc lj nl nm me nn bi translated">超参数调谐</h2><p id="8ec4" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">为了获得更好的结果，我将尝试使用<a class="ae kr" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" rel="noopener ugc nofollow" target="_blank">网格搜索</a>方法来调整模型超参数。网格搜索是一种穷举搜索方法。这就是我在交叉验证中降低折叠数的原因，也就是说，为了计算的原因。我通过考虑以下组合来探索超参数空间:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="d9ea" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">换句话说，网格搜索将探索最近邻<em class="na"> k </em>的 3 个不同值的组合和聚合邻居类的 2 种方式(统一权重或距离加权)。有了 6 个可能的超参数组合，我将交叉验证折叠数设为 3，总共 18 个训练步骤。</p><p id="9222" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">另一个值得研究的可能的超参数是距离度量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="35a7" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在网格搜索和交叉验证过程之后，我们可以通过在拟合的网格搜索对象上调用<code class="fe nv nw nx ny b">best_estimator_</code>方法来访问最佳估计量。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="3f4e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在我的例子中，最好的估计器是具有<em class="na"> k=4 </em>并使用距离加权聚合的那个。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/7f0a2d6487197718b47ce6ddf27f4822.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*XPUQ2eS5-_lpIaDlUFJIdA.png"/></div></figure><p id="db0c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">我现在将在测试集上评估优化后的模型。这里的步骤如下:</p><ol class=""><li id="1231" class="ml mm iq ku b kv kw ky kz lb mn lf mo lj mp ln no mr ms mt bi translated">使用训练好的模型来预测测试集中每个示例的标签</li><li id="ee19" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln no mr ms mt bi translated">将预测标签与实际标签进行比较</li><li id="7a9a" class="ml mm iq ku b kv mu ky mv lb mw lf mx lj my ln no mr ms mt bi translated">计算准确度分数</li></ol><p id="b5a5" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">Scikit-learn 允许用一行代码执行所有这些操作:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="1b64" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">通过简单地应用网格搜索来寻找更好的超参数，模型的准确度增加到 97.3%。</p><h1 id="0b31" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">后续步骤</h1><p id="c7da" class="pw-post-body-paragraph ks kt iq ku b kv mg jr kx ky mh ju la lb mi ld le lf mj lh li lj mk ll lm ln ij bi translated">为了进一步改进 OCR 模型，我们可以尝试不同的方法，如运行其他学习算法，扩展超参数搜索空间，以及通过综合修改原始数据(添加噪声，移动或旋转图像)来增加训练集的大小。接下来，将会有一篇文章用合成生成的样本训练一个新模型。</p><p id="d609" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">感谢您的阅读，希望您喜欢！</p></div></div>    
</body>
</html>