<html>
<head>
<title>Convolutional Neural Network (CNN) Architecture Explained in Plain English Using Simple Diagrams</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络(CNN)架构用简单的图表用简单的英语解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-cnn-architecture-explained-in-plain-english-using-simple-diagrams-e5de17eacc8f#2022-06-20">https://towardsdatascience.com/convolutional-neural-network-cnn-architecture-explained-in-plain-english-using-simple-diagrams-e5de17eacc8f#2022-06-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="076e" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">神经网络和深度学习课程:第23部分</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a8736af13a54aa5d5c702ea42135589a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_x133taVqLpW4zWJdLsu6Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始图片由<a class="ae ky" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7255440" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a>从<a class="ae ky" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=7255440" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>获得，由作者编辑</p></figure><p id="dd82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们已经讨论了一种神经网络架构——多层感知器(MLP)。MLP不适用于图像数据，因为即使对于小图像，网络中也涉及大量参数。</p><p id="f72f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积神经网络(CNN)是专门为处理图像而设计的。它们广泛应用于计算机视觉领域。</p><h1 id="933e" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">CNN的动机</h1><p id="00e9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">以下是在处理图像数据时使用CNN而不是MLPs的两个主要原因。这些原因会激励你更多地了解CNN。</p><ul class=""><li id="059a" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated">要对图像使用MLPs，我们需要使图像变平。如果我们这样做，空间信息(相邻像素之间的关系)将会丢失。所以，准确度会大大降低。CNN可以保留空间信息，因为它们以原始格式拍摄图像。</li><li id="8f1a" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">CNN可以显著减少网络中的参数数量。因此，CNN是参数有效的。</li></ul><h2 id="76f5" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">灰度与RGB图像(先决条件)</h2><p id="f6b9" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">CNN处理灰度和RGB图像。在我们继续之前，你需要了解灰度和RGB图像之间的区别</p><p id="3ea8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图像由像素组成。在深度学习中，图像被表示为像素值的数组。</p><p id="6891" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">灰度图像中只有一个颜色通道。因此，灰度图像被表示为<code class="fe ns nt nu nv b">(height, width, 1)</code>或简称为<code class="fe ns nt nu nv b">(height, width)</code>。我们可以忽略第三维度，因为它是一维的。因此，灰度图像通常表示为2D阵列(张量)。</p><p id="7868" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">RGB图像中有三个颜色通道(<strong class="lb iu"> R </strong> ed、<strong class="lb iu"> G </strong> reen和<strong class="lb iu"> B </strong> lue)。因此，一个RGB图像被表示为<code class="fe ns nt nu nv b">(height, width, 3)</code>。第三维表示图像中颜色通道的数量。RGB图像被表示为3D阵列(张量)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/87e2d607542edc1e2070bf5ecc1f6903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MWiWZw5yUFGV80Ox2KEnZQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">灰度与RGB图像表示</strong>(图片由作者提供，使用draw.io制作)</p></figure><p id="65bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>这里有更多的资源来了解更多关于灰度和RGB图像的信息。</p><ul class=""><li id="86da" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/exploring-the-mnist-digits-dataset-7ff62631766a">RGB和灰度图像如何在NumPy阵列中表示</a></li><li id="c5a4" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><a class="ae ky" href="https://rukshanpramoditha.medium.com/real-world-examples-of-0d-1d-2d-3d-4d-and-5d-tensors-100b0837ced4" rel="noopener">0D、1D、2D、3D、4D和5D张量的真实世界示例</a></li></ul><h1 id="be98" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">CNN架构</h1><p id="6654" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">与MLP架构相比，CNN架构比较复杂。在CNN架构中有不同类型的附加层和操作。</p><p id="9a13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CNN以原始格式拍摄图像。我们不需要像在MLPs中那样将图像展平以用于CNN。</p><h2 id="abde" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">CNN中的层</h2><p id="5068" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">CNN中主要有三种类型的层:<strong class="lb iu">卷积层</strong>、<strong class="lb iu">汇聚层</strong>和<strong class="lb iu">全连接(密集)层</strong>。除此之外，在每个卷积层和全连接层之后添加激活层。</p><h2 id="0dc6" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">CNN中的操作</h2><p id="28ec" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">CNN中有四种主要类型的运算:<strong class="lb iu">卷积运算</strong>、<strong class="lb iu">汇集运算</strong>、<strong class="lb iu">展平运算</strong>和<strong class="lb iu">分类</strong>(或其他相关)<strong class="lb iu">运算</strong>。</p><p id="b2b0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">别糊涂了！我将逐一讨论这些内容，并最终将它们结合起来，形成一个CNN架构的全貌。</p><h1 id="0fd2" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">卷积层和卷积运算</h1><p id="ca50" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">CNN的第一层是卷积层。CNN中可以有多个卷积层。第一个卷积层将图像作为输入并开始处理。</p><h2 id="ff1a" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">目标:</h2><ul class=""><li id="5598" class="ms mt it lb b lc mn lf mo li ny lm nz lq oa lu mx my mz na bi translated">从图像中提取一组特征，同时保持邻近像素之间的关系。</li></ul><p id="cf02" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积层有三个元素:<strong class="lb iu">输入图像</strong>、<strong class="lb iu">滤波器</strong>和<strong class="lb iu">特征图</strong>。<strong class="lb iu"> <em class="ob">卷积运算</em> </strong>发生在每个卷积层中。</p><p id="8451" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">卷积运算只不过是图像部分和滤波器之间的<strong class="lb iu"> <em class="ob">元素乘和</em> </strong>运算。现在，参考下图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/dd1f3f33128867c850da449fb086b9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1SVH2rBxGvJx3L4aB59Cg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">卷积运算</strong>(图片由作者提供，用draw.io制作)</p></figure><blockquote class="oc od oe"><p id="5f40" class="kz la ob lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated">卷积操作发生在图像的一部分和过滤器之间。它输出特征图(缩小图像)。</p></blockquote><p id="4bc6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">滤镜:</strong>这也叫<strong class="lb iu"> <em class="ob">内核</em> </strong>或者<strong class="lb iu"> <em class="ob">特征检测器</em> </strong>。这是一个小矩阵。在单个卷积层中可以有多个滤波器。在卷积层中使用相同大小的滤波器。每个过滤器都有特定的功能。使用多个过滤器来识别图像中不同的一组特征。滤波器的大小和滤波器的数量应该由用户指定为超参数。该尺寸应小于输入图像的尺寸。过滤器内的元素定义了<strong class="lb iu"> <em class="ob">过滤器配置</em> </strong>。这些元素是CNN中的一种参数，在训练期间学习。</p><p id="568e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">图像部分:</strong>图像部分的大小应该等于我们选择的滤镜的大小。我们可以在输入图像上垂直和水平移动过滤器，以创建不同的图像部分。图像部分的数量取决于我们使用的<strong class="lb iu"> <em class="ob">步幅</em> </strong>(稍后将详细介绍)。</p><p id="0ae8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特征图:</strong>特征图存储不同图像部分和滤波器之间的不同卷积运算的输出。这将是下一个池层的输入。特征图中元素的数量等于我们通过移动图像上的过滤器获得的不同图像部分的数量。</p><h2 id="cd16" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">卷积计算</h2><p id="0ca5" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">上图显示了图像部分和单个滤镜之间的卷积运算。您可以得到按行或按列的元素乘法，然后求和。</p><pre class="kj kk kl km gt oi nv oj ok aw ol bi"><span id="7fe0" class="ng lw it nv b gy om on l oo op"># Row-wise<br/><strong class="nv iu">(0*0 + 3*1 + 0*1) + (2*0 + 0*1 + 1*0) + (0*1 + 1*0 + 3*0) = 3</strong></span></pre><p id="9bd2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该计算的结果被放置在特征图中的相应区域中。</p><p id="0d4a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们通过将图像上的过滤器向右水平移动一步来进行另一个计算。我们在输入图像上移动滤波器的步数(像素)称为<strong class="lb iu">步距</strong>。移动可以水平和垂直进行。这里，我们用<code class="fe ns nt nu nv b">Stride=1</code>。步幅也是一个应该由用户指定的超参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/862200c5a649da4c78de350d96f5bb2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2HRB1prEkhog_9cON6ZqSQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">另一个步长=1的卷积运算</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="7784" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我们也可以得到按行或按列的元素乘法，然后求和。</p><pre class="kj kk kl km gt oi nv oj ok aw ol bi"><span id="93ce" class="ng lw it nv b gy om on l oo op"># Row-wise<br/><strong class="nv iu">(3*0 + 0*1 + 1*1) + (0*0 + 1*1 + 0*0) + (1*1 + 3*0 + 2*0) = 3</strong></span></pre><p id="6f3c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该计算的结果被放置在特征图中的相应区域中。</p><p id="08a6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">同样，我们可以通过在图像上水平和垂直移动一步(用<code class="fe ns nt nu nv b">Stride=1</code>)来进行类似的计算。</p><p id="5a96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">特征图的尺寸小于输入图像的尺寸。特征图的大小也取决于步幅。如果我们用<code class="fe ns nt nu nv b">Stride=2</code>，尺寸会进一步缩小。如果CNN中有几个卷积层，那么最后特征图的大小会进一步减小，这样我们就不能在特征图上做其他操作了。为了避免这一点，我们使用应用<strong class="lb iu">填充</strong>到输入图像。填充是一个超参数，我们需要在卷积层进行配置。它会在图像的每一侧添加额外的零值像素。这有助于获得与输入相同大小的特征地图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/3a54bffa733e0a1c9f267e2ac4a86240.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*yg435b2AQvJic6mxZ4KR7w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">应用于输入图像</strong>的填充(图片由作者制作，用draw.io制作)</p></figure><p id="9e4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">应用填充后，输入图像的新大小为(8，8)。如果我们现在用<code class="fe ns nt nu nv b">Stride=1</code>做卷积运算，我们得到一个大小为(6x6)的特征图，它等于应用填充之前原始图像的大小。</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="1c99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图显示了灰度图像和单个滤镜的卷积运算。当图像是RGB并且在处理过程中涉及多个滤镜时，您还应该对卷积运算有所了解。</p><h2 id="7655" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">多滤波器卷积运算</h2><p id="8365" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这里，我只改变了过滤器的数量。输入图像类型仍然是灰度。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/56ab6624c2559039467e8839ca9ab2b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORPa-lYc4ebfzIqCt5jmdw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">多重滤镜的卷积运算</strong><strong class="bd nx"/>(图片由作者提供，用draw.io制作)</p></figure><p id="1ce7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">唯一的区别是在特征图上增加了另一个维度。第三维度表示过滤器的数量。</p><h2 id="be0c" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">RGB图像上的卷积运算</h2><p id="e647" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这里，我对RGB图像应用卷积运算。这里使用单个过滤器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/56b7b4270b9204672d33648085b91d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LMzZZQ4Tk2RuvJzILnAi3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">用单个滤镜对RGB图像进行卷积运算</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="3448" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当图像是RGB时，滤镜应该有3个通道。这是因为RGB图像有3个颜色通道，需要3通道过滤器来进行计算。</p><p id="05d1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，如前所述，计算发生在图像部分和滤波器之间的每个对应通道上。通过将每个通道的所有计算输出相加，获得最终结果。这就是为什么特征地图没有第三维。</p><h2 id="c86a" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">用多个滤波器对RGB图像进行卷积运算</h2><p id="38f3" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这是最复杂的版本，也是真实世界的场景。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/58ceac617088a9648770fb6208c94aa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQaEbmmWJakXBsuGHDPs9w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">用多重滤镜对RGB图像进行卷积运算</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="ba26" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，另一个维度也被添加到特征映射中。第三维度表示过滤器的数量。</p><h1 id="d604" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">汇集层和汇集操作</h1><p id="aff2" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">池层是CNN中使用的第二种类型的层。在一个CNN中可以有多个池层。每个卷积层之后是一个汇集层。因此，卷积层和池层成对使用。</p><h2 id="5d99" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">目标:</h2><ul class=""><li id="0153" class="ms mt it lb b lc mn lf mo li ny lm nz lq oa lu mx my mz na bi translated">通过获取最大数量或平均数量来提取最重要(相关)的特征。</li><li id="bb5b" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">减少从先前卷积层返回的输出的维数(像素数)。</li><li id="b518" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">减少网络中的参数数量。</li><li id="6ed5" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">去除由先前卷积层提取的特征中存在的任何噪声。</li><li id="b45b" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated">增加CNN的准确性。</li></ul><p id="966d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">池层有三个元素:<strong class="lb iu">特征图</strong>、<strong class="lb iu">滤镜</strong>和<strong class="lb iu">池特征图</strong>。<strong class="lb iu"> <em class="ob">汇集操作</em> </strong>发生在每个汇集层中。</p><blockquote class="oc od oe"><p id="9a64" class="kz la ob lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated">汇集操作发生在特征地图的一部分和过滤器之间。它输出汇集的要素地图。</p></blockquote><p id="a5ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有两种类型的池操作。</p><ul class=""><li id="6f9d" class="ms mt it lb b lc ld lf lg li mu lm mv lq mw lu mx my mz na bi translated"><strong class="lb iu">最大池化:</strong>获取应用过滤器的区域的最大值。</li><li id="0cd4" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">平均池:</strong>获取应用过滤器的区域中值的平均值。</li></ul><p id="419e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了应用于从之前的卷积运算中获得的要素图上的最大池化运算。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/f817fe20e1c3c54565d5ae2b55b95397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*A1jv5vy8wLHOVRSUXdRfJQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">最大池</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="5012" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">过滤器:</strong>这一次，过滤器只是一个窗口，因为里面没有元素。因此，在池层中没有需要学习的参数。过滤器仅用于指定特征图中的一个部分。滤波器的大小应由用户指定为超参数。该大小应小于功能图的大小。如果特征图有多个通道，我们应该使用具有相同数量通道的过滤器。池操作将在每个通道上独立完成。</p><p id="41e7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">特征映射部分:</strong>特征映射部分的大小应该等于我们选择的滤镜的大小。我们可以在特征图上垂直和水平移动过滤器来创建不同的部分。区段的数量取决于我们使用的步幅。</p><p id="ee24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">汇集特征图:</strong>汇集特征图存储不同特征图部分和过滤器之间不同汇集操作的输出。这将是下一个卷积层(如果有)或展平操作的输入。</p><h2 id="f572" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">合并操作中的步长和填充</h2><ul class=""><li id="cc25" class="ms mt it lb b lc mn lf mo li ny lm nz lq oa lu mx my mz na bi translated"><strong class="lb iu">步幅:</strong>这里的步幅通常等于滤镜的大小。如果过滤器尺寸是(2x2)，我们使用<code class="fe ns nt nu nv b">Stride=2</code>。</li><li id="8463" class="ms mt it lb b lc nb lf nc li nd lm ne lq nf lu mx my mz na bi translated"><strong class="lb iu">填充:</strong>将填充应用于特征图，以调整汇集的特征图的大小。</li></ul><p id="a474" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">步幅和填充都是我们需要在池层中指定的超参数。</p><p id="4ef7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意:</strong>对特征图应用池化后，通道数不变。这意味着我们在特征图和汇集的特征图中具有相同数量的通道。如果特征图有多个通道，我们应该使用具有相同数量通道的过滤器。池操作将在每个通道上独立完成。</p><h1 id="2247" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">展平操作</h1><p id="f04c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在CNN中，从最终汇集层返回的输出(即最终汇集的特征图)被馈送到多层感知器(MLP ),该感知器可以将最终汇集的特征图分类到类别标签中。</p><p id="7b24" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MLP只接受一维数据。因此，我们需要将最终的池化要素地图展平到保存MLP输入数据的单个列中。</p><p id="937b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">与拼合原始图像不同，拼合合并贴图时会保留重要的像素相关性。</p><p id="b5ac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了如何展平仅包含一个通道的池化要素地图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/0d34729e724136fe732d08773f2055a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*B0Yfdv6TkC9mLqKVoy4CwA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">展平单通道汇集特征图</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="089d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下图显示了如何展平包含多个通道的池化要素地图。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/6a84d9055f4ed97f0395005c3215dc79.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*N74xher1f5gJSHY-_o_rQQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">展平多通道汇集特征图</strong>(图片由作者提供，用draw.io制作)</p></figure><h1 id="93cf" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">完全连接的(密集)层</h1><p id="c78c" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">这些是CNN的最后几层。输入是前一个展平的层。可以有多个完全连接的层。最后一层执行分类(或其他相关)任务。在每个完全连接的层中使用激活函数。</p><h2 id="e525" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">目标:</h2><ul class=""><li id="7d53" class="ms mt it lb b lc mn lf mo li ny lm nz lq oa lu mx my mz na bi translated">将图像中检测到的特征分类到类别标签中。</li></ul><h1 id="e962" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">CNN中的层排列</h1><p id="1d79" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">在这里，我将讨论如何添加每一层来构建整个CNN架构。在典型的CNN中，各层按以下顺序排列。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/9e22c65212e7ba3b538314e8ff3174b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2cOInQFLg83hceu4BW-6g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx"> CNN整体架构</strong>(图片由作者提供，用draw.io制作)</p></figure><p id="11f9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">CNN输入照原样获取图像。输入图像经过一系列的层和操作。</p><p id="5a29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">需要卷积层和汇集层来从图像中提取特征，同时保持重要的像素相关性。它们还减少了原始图像的维数(像素数量)。这些层成对一起使用。</p><p id="6173" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ReLU激活用于每个卷积层。</p><p id="a2d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">滤波器的数量在每个卷积层中增加。例如，如果我们在第一个卷积层使用16个滤波器，我们通常在下一个卷积层使用32个滤波器，以此类推。</p><p id="c98f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前几层关注图像数据中不太重要的图案(如边缘)。末端层发现更复杂的图案(例如，脸部图像中的鼻子、眼睛)。最后一层完成分类任务。</p><p id="9c6a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">ReLU激活用于每个完全连接的层，除了最后一层，其中我们使用Softmax激活用于多类分类。</p><blockquote class="oc od oe"><p id="5fbe" class="kz la ob lb b lc ld ju le lf lg jx lh of lj lk ll og ln lo lp oh lr ls lt lu im bi translated">通过上图，我们可以把CNN想象成MLP的一个改良版。绿色框中的图层对图像进行了一些修改。橙色的盒子里装着MLP。在绿色方框和橙色方框之间有一个展平层。</p></blockquote><p id="5107" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注:</strong>CNN中图层排列的编码部分将用Keras在<a class="ae ky" rel="noopener" target="_blank" href="/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875">单独的文章</a>中完成。</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="470c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天的帖子到此结束。</p><p id="e5ec" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">如果您有任何问题或反馈，请告诉我。</strong></p><p id="c9bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢阅读这篇文章。如果你愿意支持我成为一名作家，请考虑 <a class="ae ky" href="https://rukshanpramoditha.medium.com/membership" rel="noopener"> <strong class="lb iu"> <em class="ob">注册会员</em> </strong> </a> <em class="ob">以获得无限制的媒体访问权限。它只需要每月5美元，我会收到你的会员费的一部分。</em></p><div class="pg ph gp gr pi pj"><a href="https://rukshanpramoditha.medium.com/membership" rel="noopener follow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">通过我的推荐链接加入Medium</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">rukshanpramoditha.medium.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px ks pj"/></div></div></a></div><p id="7222" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">非常感谢你一直以来的支持！下一篇文章再见。祝大家学习愉快！</p></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><h2 id="2fac" class="ng lw it bd lx nh ni dn mb nj nk dp mf li nl nm mh lm nn no mj lq np nq ml nr bi translated">加入我的神经网络和深度学习课程</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><a href="https://rukshanpramoditha.medium.com/list/neural-networks-and-deep-learning-course-a2779b9c3f75"><div class="gh gi py"><img src="../Images/dec81e64f13e6b3357076e543fd9cd3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*Dv7yX69yV8G9gnUmYuiXZg.png"/></div></a><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nx">点击此图片进入我的神经网络和深度学习课程</strong>(作者截图)</p></figure></div><div class="ab cl os ot hx ou" role="separator"><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox oy"/><span class="ov bw bk ow ox"/></div><div class="im in io ip iq"><p id="0282" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="pz qa ep" href="https://medium.com/u/f90a3bb1d400?source=post_page-----e5de17eacc8f--------------------------------" rel="noopener" target="_blank">鲁克山·普拉莫迪塔</a><br/><strong class="lb iu">2022–06–20</strong></p></div></div>    
</body>
</html>