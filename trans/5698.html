<html>
<head>
<title>How to Build Machine Learning Models on Snowflake</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在雪花上建立机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-on-snowflake-ea6c559af2d#2022-12-26">https://towardsdatascience.com/machine-learning-on-snowflake-ea6c559af2d#2022-12-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="753f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">雪花是领先的数据平台之一。在本文中，我们将探索它的 snowpark Python 库的功能</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5ac97a5c8696730e262dcebc242a1eec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ceNRNk7_QSHaS2ol"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/@aaronburden?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aaron Burden </a>在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="b831" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，您将学习如何使用，</p><ol class=""><li id="693a" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">用于原始数据预处理的 snowpark-python 功能</li><li id="83b1" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在雪花中训练和部署机器学习模型</li><li id="a51d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">以 pythonic 方式定义 UDF，并在雪花中部署它们</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/fd39264f9a2bb48e86bf4d41ef294c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zOTKNeFOfEDF48XAIwR4YA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">本文涵盖的主题|作者图片</p></figure><p id="3462" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你愿意跟随教程，你应该有一个<a class="ae kv" href="https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda" rel="noopener ugc nofollow" target="_blank">支持 Anaconda 集成的雪花账户</a>。否则，你必须注册一个免费的<a class="ae kv" href="https://signup.snowflake.com/" rel="noopener ugc nofollow" target="_blank">雪花试用账户</a>，并按照这里<a class="ae kv" href="https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda" rel="noopener ugc nofollow" target="_blank">的描述</a>进行配置。</p><p id="0dff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">乍一看，snowpark 是一个机器学习和数据科学框架，它在 Python 的灵活性中提供了 SQL 的强大功能。有时，这类似于 Apache spark 框架。然而，这为我们的机器学习和数据科学项目提供了一个普遍的框架。在尝试本文中的任何内容之前，您应该在 python 和雪花之间建立一个连接。代码示例可以参考<a class="ae kv" href="https://github.com/Ransaka/ML-on-Snowflake" rel="noopener ugc nofollow" target="_blank">我的代码报告</a>。让我们创建一个数据库连接。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="4f48" class="mm mn iq mi b be mo mp l mq mr">from snowflake.snowpark.session import Session<br/><br/>accountname = "********" # your accountname<br/>username = "**********" #your snowflake username<br/>password = "*************" #snowflake password<br/><br/>connection_parameters = {<br/>    "account": accountname,<br/>    "user": username,<br/>    "password": password,<br/>    "role": "ACCOUNTADMIN"<br/>}<br/><br/>def snowflake_connector():<br/>    try:<br/>        session = Session.builder.configs(connection_parameters).create()<br/>        print("connection successful!")<br/>    except:<br/>        raise ValueError("error while connecting with db")<br/>    return session<br/><br/>#define a session<br/>session = snowflake_connector()</span></pre><p id="6041" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以开始主要的数据预处理部分。我将在 snowpark 端做这件事，而不是用 Pandas DataFrame 进行预处理。这里我将使用<a class="ae kv" href="https://www.kaggle.com/datasets/meirnizri/covid19-dataset" rel="noopener ugc nofollow" target="_blank">新冠肺炎</a>数据集，它可以在<a class="ae kv" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank"> CC0: Public Domain </a>下的 Kaggle 中找到。我已经将该数据集作为雪花表加载。由于这不是本文的主要目标，我将跳过这一部分。您可以按照本文的 GitHub repo 中的描述加载数据集。让我们读一下表格。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="644d" class="mm mn iq mi b be mo mp l mq mr">snowpark_df = session.table("COVID19_RECORDS")<br/><br/>print(type(snowpark_df) # snowflake.snowpark.table.Table<br/>print(f"Size of the table object: {(sys.getsizeof(snowpark_df)/1e6)} MB")<br/>#'Size of the table object: 4.8e-05 MB'</span></pre><p id="9345" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">上面的<code class="fe ms mt mu mi b">snowpark_df</code>是一个惰性评估表；因此，它不会像熊猫数据帧那样消耗太多内存。但是我们可以应用任何转换聚合，就像我们对熊猫所做的那样。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="0d5b" class="mm mn iq mi b be mo mp l mq mr">snowpark_df.schema.fields<br/><br/># [StructField('USMER', LongType(), nullable=True),<br/>#  StructField('MEDICAL_UNIT', LongType(), nullable=True),<br/>#  StructField('SEX', LongType(), nullable=True),<br/>#  StructField('PATIENT_TYPE', LongType(), nullable=True),<br/>#  StructField('DATE_DIED', StringType(), nullable=True),<br/>#  StructField('INTUBED', LongType(), nullable=True),<br/>#  StructField('PNEUMONIA', LongType(), nullable=True),<br/>#  StructField('AGE', LongType(), nullable=True),<br/>#  StructField('PREGNANT', LongType(), nullable=True),<br/>#  StructField('DIABETES', LongType(), nullable=True),<br/>#  StructField('COPD', LongType(), nullable=True),<br/>#  StructField('ASTHMA', LongType(), nullable=True),<br/>#  StructField('INMSUPR', LongType(), nullable=True),<br/>#  StructField('HIPERTENSION', LongType(), nullable=True),<br/>#  StructField('OTHER_DISEASE', LongType(), nullable=True),<br/>#  StructField('CARDIOVASCULAR', LongType(), nullable=True),<br/>#  StructField('OBESITY', LongType(), nullable=True),<br/>#  StructField('RENAL_CHRONIC', LongType(), nullable=True),<br/>#  StructField('TOBACCO', LongType(), nullable=True),<br/>#  StructField('CLASIFFICATION_FINAL', LongType(), nullable=True),<br/>#  StructField('ICU', LongType(), nullable=True)]</span></pre><p id="1436" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集中有 1，048，575 条唯一记录和 21 列。我们来做一些基本面分析。首先，让我们如下定义目标变量。根据数据集的描述，<code class="fe ms mt mu mi b">CLASSIFICATION_FINAL</code>列中的 1、2、3 值代表正例，其余代表负例。让我们应用上面的逻辑定义一个名为<code class="fe ms mt mu mi b">TARGET</code>的新列。等效的 SQL 逻辑将是，</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="25d1" class="mm mn iq mi b be mo mp l mq mr">SELECT<br/>    "USMER",<br/>    "MEDICAL_UNIT",<br/>    "SEX",<br/>    "PATIENT_TYPE",<br/>    "DATE_DIED",<br/>    "INTUBED",<br/>    "PNEUMONIA",<br/>    "AGE",<br/>    "PREGNANT",<br/>    "DIABETES",<br/>    "COPD",<br/>    "ASTHMA",<br/>    "INMSUPR",<br/>    "HIPERTENSION",<br/>    "OTHER_DISEASE",<br/>    "CARDIOVASCULAR",<br/>    "OBESITY",<br/>    "RENAL_CHRONIC",<br/>    "TOBACCO",<br/>    "CLASIFFICATION_FINAL",<br/>    "ICU",<br/>    CASE<br/>        WHEN ("CLASIFFICATION_FINAL" &lt; 4 :: INT) THEN 1 :: INT<br/>        ELSE 0 :: INT<br/>    END AS "TARGET"<br/>FROM<br/>    COVID19_RECORDS</span></pre><p id="5345" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为我们正在使用 snowpark API，所以让我们用 snowpark 来创建它。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="8504" class="mm mn iq mi b be mo mp l mq mr">import snowflake.snowpark.functions as F<br/><br/>snowpark_df.with_column('TARGET', F.when(F.col('CLASIFFICATION_FINAL')<br/>                        &lt; 4, 1).otherwise(0))</span></pre><p id="7653" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看看我们的目标分布。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="ec4e" class="mm mn iq mi b be mo mp l mq mr">snowpark_df\<br/>.group_by("TARGET").count().to_pandas().set_index("TARGET")\<br/>.plot.bar()<br/><br/>plt.title("Target distribution",fontweight='semibold')<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/3c4c90119c046a1b5f1486fbf0afa13b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*soGMsladnT8HxaSLFCgIrA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">目标分布|作者图片</p></figure><p id="96b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们再创造一个情节。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="c415" class="mm mn iq mi b be mo mp l mq mr">snowpark_df\<br/>.select('AGE').to_pandas()\<br/>.plot.hist(bins=100,alpha=0.5)<br/><br/>plt.title("Age distribution",fontweight='semibold')<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/838d828a73a100de2a8eedfac7105034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*zEq0762fLVascp54cE0rmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">年龄分布|作者图片</p></figure><p id="880f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们找出年龄变量和目标变量之间的关系。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="b197" class="mm mn iq mi b be mo mp l mq mr">snowpark_df = snowpark_df.with_column(<br/>    "AGE_BKT",<br/>    F.when(F.col("AGE") &lt; 21, "YOUNG").otherwise(<br/>        F.when(F.col("AGE") &lt; 49, "ADULT").otherwise("OLD ADULT")<br/>    ),<br/>)<br/><br/><br/>age_bkt_df = snowpark_df.select(<br/>    F.col("AGE_BKT"),<br/>    F.when((F.col("AGE_BKT")=='YOUNG') &amp; (F.col("TARGET")==1),1).otherwise(0).as_("YOUNG_"),<br/>    F.when((F.col("AGE_BKT")=='ADULT') &amp; (F.col("TARGET")==1),1).otherwise(0).as_("ADULT_"),<br/>    F.when((F.col("AGE_BKT")=='OLD ADULT') &amp; (F.col("TARGET")==1),1).otherwise(0).as_("OLD_ADULT_")<br/>)<br/><br/>age_bkt_df.group_by(F.col("AGE_BKT")).count().show()<br/><br/># -----------------------<br/># |"AGE_BKT"  |"COUNT"  |<br/># -----------------------<br/># |OLD ADULT  |342413   |<br/># |ADULT      |628554   |<br/># |YOUNG      |77608    |<br/># -----------------------<br/><br/>age_bkt_df.select(<br/>    ((F.sum("YOUNG_") * 100 ) / F.count("YOUNG_")).as_("YOUNG % OF CASES"),<br/>    ((F.sum("ADULT_") * 100) / F.count("ADULT_")).as_("ADULT % OF CASES"),<br/>    ((F.sum("OLD_ADULT_") * 100) / F.count("OLD_ADULT_")).as_("OLD_ADULT % OF CASES")<br/>).show()<br/><br/># --------------------------------------------------------------------<br/># |"YOUNG % OF CASES"  |"ADULT % OF CASES"  |"OLD_ADULT % OF CASES"  |<br/># --------------------------------------------------------------------<br/># |1.534463            |20.877858           |14.969745               |<br/># --------------------------------------------------------------------</span></pre><p id="93f3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">完成分析后，我们可以使用以下方法将转换后的数据集保存为新的雪花表。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="7e4b" class="mm mn iq mi b be mo mp l mq mr">snowpark_df.write.save_as_table(<br/>    table_name='COVID19_RECORDS_PROCESSED',<br/>    mode='overwrite'<br/>)</span></pre><p id="91a7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，现在我们有了预处理过的数据集。让我们开始模型训练阶段。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="4d41" class="mm mn iq mi b be mo mp l mq mr"># read the table <br/>train_data = session.table("COVID19_RECORDS_PROCESSED")<br/><br/>#create the stage for storing the ML models<br/>session.sql('CREATE OR REPLACE STAGE ML_MODELS').show()</span></pre><p id="baa1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用两种不同的方法在雪花中训练和部署模型。</p><ol class=""><li id="6400" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">我们可以在本地训练模型，将其上传到一个阶段，并在调用 UDF 时从该阶段加载它。</li><li id="4e19" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">我们可以定义 SPROC，它可以训练模型，并在调用 SPROC 时将训练好的模型保存到雪花阶段。这里我们需要一个独立的 UDF 用于推理部分。</li></ol><p id="44f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将探讨上述两种方法。</p><h2 id="3216" class="mx mn iq bd my mz na dn nb nc nd dp ne lf nf ng nh lj ni nj nk ln nl nm nn no bi translated">在本地训练模型，将其上载到舞台，并从舞台加载它</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e5d2caa5d045869a527d7fb7554af881.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*swC4aXf4M_hgkUT7Fe7r2Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d107" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们必须定义局部训练模型的函数。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="68b6" class="mm mn iq mi b be mo mp l mq mr">def train_model_locally(train:snowflake.snowpark.table.Table):<br/>    from sklearn.tree import DecisionTreeClassifier<br/>    <br/>    #convert into pd dataframes<br/>    <br/>    train = train.to_pandas()<br/>    <br/>    xtrain,ytrain = train.drop('TARGET',axis=1),train['TARGET']<br/>    <br/>    model = DecisionTreeClassifier()<br/>    model.fit(xtrain,ytrain)<br/>    <br/>    return model<br/><br/>#let's train the DT model<br/>model = train_model_locally(train_data_sf)<br/><br/>#save the model<br/>import joblib<br/>joblib.dump(model, 'predict_risk_score.joblib')<br/><br/>#upload into the ML_MODELS SNowfla<br/>session.file.put(<br/>    "predict_risk_score.joblib", "@ML_MODELS", auto_compress=False, overwrite=True<br/>)</span></pre><p id="14b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与其他机器学习管道类似，我们需要定义库依赖关系。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="e759" class="mm mn iq mi b be mo mp l mq mr">session.clear_imports()<br/>session.clear_packages()<br/><br/>#Register above uploded model as import of UDF<br/>session.add_import("@ML_MODELS/predict_risk_score.joblib")<br/><br/>#map packege dependancies<br/>session.add_packages("joblib==1.1.0", "scikit-learn==1.1.1", "pandas==1.3.2")</span></pre><p id="9939" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们来定义 UDF。在 UDF 内部，它应该从舞台加载模型，然后使用它进行推理。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="8ca5" class="mm mn iq mi b be mo mp l mq mr">from snowflake.snowpark.types import PandasSeries, PandasDataFrame<br/><br/><br/>def read_file(filename):<br/>    import joblib<br/>    import sys<br/>    import os<br/>    <br/>    #where all imports located at<br/>    import_dir = sys._xoptions.get("snowflake_import_directory")<br/><br/>    if import_dir:<br/>        with open(os.path.join(import_dir, filename), 'rb') as file:<br/>            m = joblib.load(file)<br/>            return m<br/><br/>#register UDF<br/>@F.udf(name = 'predict_risk_score', is_permanent = True, replace = True, stage_location = '@ML_MODELS')<br/>def predict_risk_score(ds: PandasSeries[dict]) -&gt; PandasSeries[float]:<br/>    <br/>    # later we will input train data as JSON object<br/>    # hance, we have to convert JSON object as pandas DF<br/>    df = pd.io.json.json_normalize(ds)[feature_cols]<br/>    pipeline = read_file('predict_risk_score.joblib')<br/>    return pipeline.predict_proba(df)[:,1]</span></pre><p id="481a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们已经成功地在雪花注册了我们的 UDF。您可以使用以下方式验证它。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="55f9" class="mm mn iq mi b be mo mp l mq mr">session.sql("DESC FUNCTION PREDICT_RISK_SCORE()").show()<br/><br/># ------------------------------------------------------------------------<br/># |"property"       |"value"                                             |<br/># ------------------------------------------------------------------------<br/># |signature        |()                                                  |<br/># |returns          |FLOAT                                               |<br/># |language         |PYTHON                                              |<br/># |null handling    |CALLED ON NULL INPUT                                |<br/># |volatility       |VOLATILE                                            |<br/># |body             |                                                    |<br/># |                 |import pickle                                       |<br/># |                 |                                                    |<br/># |                 |func = pickle.loads(bytes.fromhex('800595050400...  |<br/># |                 |# The following comment contains the UDF source...  |<br/># |                 |# import pandas as pd                               |<br/># |                 |# def read_file(filename):                          |<br/># |                 |#     import joblib                                 |<br/># |                 |#     import sys                                    |<br/># |                 |#     import os                                     |<br/># |                 |#                                                   |<br/># |                 |#     import_dir = sys._xoptions.get("snowflake...  |<br/># |                 |#     if import_dir:                                |<br/># |                 |#         with open(os.path.join(import_dir, fi...  |<br/># |                 |#             m = joblib.load(file)                 |<br/># |                 |#             return m                              |<br/># |                 |# @F.udf(name = 'predict_risk_score', is_perman...  |<br/># |                 |# def predict_risk_score(*args) -&gt; PandasSeries...  |<br/># |                 |#     df = pd.DataFrame([args])                     |<br/># |                 |#     pipeline = read_file('predict_risk_score....  |<br/># |                 |#     return pipeline.predict_proba(df)[:,1]        |<br/># |                 |#                                                   |<br/># |                 |# func = predict_risk_score                         |<br/># |                 |#                                                   |<br/># |                 | *********RESULTS TRUNCATED**************           |<br/># ------------------------------------------------------------------------</span></pre><p id="688a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们用 UDF 进行推理。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="0a0c" class="mm mn iq mi b be mo mp l mq mr"># `test_data_sf` is a fraction of `train_data`<br/>test_data_sf.with_column(<br/>    'PREDICTION', <br/>    predict_risk_score(F.object_construct('*')))\<br/>.select("TARGET","PREDICTION").show(20)<br/><br/># ---------------------------------<br/># |"TARGET"  |"PREDICTION"        |<br/># ---------------------------------<br/># |1         |0.8333333333333334  |<br/># |1         |0.0                 |<br/># |1         |1.0                 |<br/># |1         |1.0                 |<br/># |1         |0.3333333333333333  |<br/># |0         |0.0                 |<br/># |1         |0.4                 |<br/># |0         |0.5                 |<br/># |1         |0.421875            |<br/># ---------------------------------<br/><br/>#similary, you can use below SQL as well.<br/><br/>select<br/>    target,<br/>    predict_risk_score(object_construct(*)) as predictions<br/>from<br/>    COVID19_RECORDS_PROCESSED<br/>limit<br/>    100;</span></pre><h2 id="1749" class="mx mn iq bd my mz na dn nb nc nd dp ne lf nf ng nh lj ni nj nk ln nl nm nn no bi translated">定义培训和推理过程/自定义项</h2><p id="ed90" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">此方法将创建用于定型模型的存储过程和用于推理模型的 UDF。你可以参考下面的图表获得更多的见解。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/e42e380a3391c0bd0a7a99f3e2853e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIEhq0KvXT8wBjOcdI6zQQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="74b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们定义存储过程。首先，我们将实现 Python 函数，我们可以在后面的步骤中将其转换为雪花存储过程。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="150e" class="mm mn iq mi b be mo mp l mq mr">def train_dt_procedure(<br/>    session: Session,<br/>    training_table: str,<br/>    feature_cols: list,<br/>    target_col: str,<br/>    model_name: str,<br/>) -&gt; T.Variant:<br/>    <br/>    """<br/>    This will be our training procedure. Later we will register this as snowflake procedure.<br/>    <br/>    training_table: snowflake table name to be used for training task<br/>    feature_cols: list of columns to be used in training<br/>    target_col: target column to be used<br/>    model_name: model name to used for model saving purpose<br/>    <br/>    """<br/><br/>    #convert as pandas DF, rest of the steps similar to the local model training and saving.<br/>    local_training_data = session.table(training_table).to_pandas()<br/><br/>    from sklearn.tree import DecisionTreeClassifier<br/><br/>    X = local_training_data[feature_cols]<br/>    y = local_training_data[target_col]<br/><br/>    model = DecisionTreeClassifier()<br/>    model.fit(X, y)<br/>    <br/>    #do what ever you want to do with model, even the hyperparameter tuning..<br/>    # here I'll get feature importance<br/>    feat_importance = pd.DataFrame(<br/>        model.feature_importances_, feature_cols, columns=["FeatImportance"]<br/>    ).to_dict()<br/><br/>    from joblib import dump<br/><br/>    dump(model, "/tmp/" + model_name)<br/>    session.file.put(<br/>        "/tmp/" + model_name, "@ML_MODELS", auto_compress=False, overwrite=True<br/>    )<br/>    return feat_importance</span></pre><p id="0eef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们将上面的 Python 函数注册为一个存储过程。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="3b3a" class="mm mn iq mi b be mo mp l mq mr">sproc_train_dt_model = session.sproc.register(<br/>                    func=train_dt_procedure, <br/>                    name='sproc_train_dt_model', <br/>                    is_permanent=True, <br/>                    replace=True, <br/>                    stage_location='@ML_MODELS', <br/>                    packages=[<br/>                        'snowflake-snowpark-python',<br/>                        'scikit-learn',<br/>                        'joblib']<br/>)</span></pre><p id="9476" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在我们可以如下使用程序<code class="fe ms mt mu mi b">SPROC_TRAIN_DT_MODEL()</code>。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="97f3" class="mm mn iq mi b be mo mp l mq mr">train_data = session.table("COVID19_RECORDS_PROCESSED")<br/><br/>#create train and test dataframes<br/>train_data_pd,test_data_pd = train_test_split(<br/>                                        train_data_pd,<br/>                                        stratify=train_data_pd['TARGET'],<br/>                                        test_size=0.1<br/>)<br/><br/># writing as tempoary tables for mode training and inferencing part<br/>session.write_pandas(<br/>    train_data_pd,<br/>    table_name="TRAIN_DATA_TMP",<br/>    auto_create_table=True,<br/>    table_type="temporary",<br/>)<br/>session.write_pandas(<br/>    test_data_pd,<br/>    table_name="TEST_DATA_TMP",<br/>    auto_create_table=True,<br/>    table_type="temporary",<br/>)<br/><br/>train_data_pd = train_data.to_pandas()<br/><br/>feature_cols = train_data.columns<br/>feature_cols.remove('TARGET')<br/>target_col = 'TARGET'<br/>model_name = 'decisiontree.model' # How model should be saved in stage<br/><br/>model_response = sproc_train_dt_model('TRAIN_DATA_TMP', <br/>                                            feature_cols, <br/>                                            target_col,<br/>                                            model_name, <br/>                                            session=session<br/>                                           )<br/><br/>print(model_response)<br/><br/># {<br/>#   "FeatImportance": {<br/>#     "AGE": 0.4543249401305732,<br/>#     "ASTHMA": 0.029003830541684678,<br/>#     "CARDIOVASCULAR": 0.025649097586968667,<br/>#     "COPD": 0.019300936592021863,<br/>#     "DIABETES": 0.059273293874405074,<br/>#     "HIPERTENSION": 0.05885196748765571,<br/>#     "INMSUPR": 0.0232534703448427,<br/>#     "INTUBED": 0.026365011429648998,<br/>#     "MEDICAL_UNIT": 0.08804779552309593,<br/>#     "OBESITY": 0.02991724846285235,<br/>#     "OTHER_DISEASE": 0.026840169399286344,<br/>#     "PATIENT_TYPE": 0,<br/>#     "PNEUMONIA": 0.04225497414608237,<br/>#     "PREGNANT": 0.012929499812685114,<br/>#     "RENAL_CHRONIC": 0.015894267526361774,<br/>#     "SEX": 0,<br/>#     "TOBACCO": 0.028563364646896985,<br/>#     "USMER": 0.059530132494938236<br/>#   }<br/># }<br/><br/>#plot feature importance<br/>feature_coefficients = pd.DataFrame(eval(model_response))<br/><br/>feature_coefficients\<br/>.sort_values(by='FeatImportance',ascending=False)\<br/>.plot\<br/>.bar(y='FeatImportance', figsize=(12,5))<br/>plt.show()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/2df34c92af41d761ca892f92e0b7e84a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sJY5i5mVl2inFLRwxE6XHg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">功能重要性|按作者分类的图片</p></figure><p id="a65a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以把 UDF 定义如下。这个函数类似于上一个函数。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="7e74" class="mm mn iq mi b be mo mp l mq mr">def udf_predict_risk_score(*args) -&gt; float:<br/>    import os<br/>    import sys<br/>    from joblib import load<br/>    <br/>    IMPORT_DIRECTORY_NAME = "snowflake_import_directory"<br/>    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]<br/>    model_name = 'decisiontree.model'<br/>    model = load(import_dir+model_name)<br/>    <br/>    #unlike previous JSON object, this will be a array, hence no need to<br/>    # decode the input<br/>    scored_data = model.predict(pd.DataFrame([args]))[0]<br/><br/>    return scored_data</span></pre><p id="aa6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，注册 UDF。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="e923" class="mm mn iq mi b be mo mp l mq mr">udf_risk_score_model = session.udf.register(<br/>                            func=udf_predict_risk_score, <br/>                            name="udf_risk_score_model", <br/>                            stage_location='@ML_MODELS',<br/>                            input_types=[T.FloatType()]*len(feature_cols),<br/>                            return_type = T.FloatType(),<br/>                            replace=True, <br/>                            is_permanent=True, <br/>                            imports=['@ML_MODELS/decisiontree.model'],<br/>                            packages=['scikit-learn==1.1.1','pandas','joblib'], <br/>                            session=session<br/>)</span></pre><p id="d15c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">好了，是时候为我们的验证数据集进行预测了。在这里，我用雪花编辑器做它。</p><pre class="kg kh ki kj gt mh mi mj bn mk ml bi"><span id="fc6b" class="mm mn iq mi b be mo mp l mq mr">SELECT<br/>    "TARGET",<br/>    udf_risk_score_model(<br/>        "USMER",<br/>        "MEDICAL_UNIT",<br/>        "SEX",<br/>        "PATIENT_TYPE",<br/>        "INTUBED",<br/>        "PNEUMONIA",<br/>        "AGE",<br/>        "PREGNANT",<br/>        "DIABETES",<br/>        "COPD",<br/>        "ASTHMA",<br/>        "INMSUPR",<br/>        "HIPERTENSION",<br/>        "OTHER_DISEASE",<br/>        "CARDIOVASCULAR",<br/>        "OBESITY",<br/>        "RENAL_CHRONIC",<br/>        "TOBACCO"<br/>    ) AS "PREDICTION"<br/>FROM<br/>    COVID19_RECORDS_PROCESSED limit 100;</span></pre><h2 id="2c1b" class="mx mn iq bd my mz na dn nb nc nd dp ne lf nf ng nh lj ni nj nk ln nl nm nn no bi translated">结论</h2><p id="ae83" class="pw-post-body-paragraph kw kx iq ky b kz nq jr lb lc nr ju le lf ns lh li lj nt ll lm ln nu lp lq lr ij bi translated">虽然 snowpark 为我们的机器学习任务提供了一个全面的平台，但在撰写本文时，它还有一些问题。作为一个例子，PyTorch 仍然需要一个雪地公园的支持。此外，康达仅提供精选套餐；如果我们想使用其他包，比如 catboost，我们必须手动将它们导入到我们的环境中，如这里的<a class="ae kv" href="https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html#reading-files-from-a-udf" rel="noopener ugc nofollow" target="_blank">所述</a>。</p><p id="e399" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！在<a class="ae kv" href="https://www.linkedin.com/in/ransaka/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系。</p></div></div>    
</body>
</html>