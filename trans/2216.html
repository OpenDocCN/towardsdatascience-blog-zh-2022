<html>
<head>
<title>Data Quality Comparison on AWS Glue and Great Expectations/Updated with V3 API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS Glue和Great Expectations上的数据质量比较/用V3 API更新</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-quality-comparison-on-aws-glue-and-great-expectations-70af5bdfe39c#2022-05-17">https://towardsdatascience.com/data-quality-comparison-on-aws-glue-and-great-expectations-70af5bdfe39c#2022-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b52bb8673c66965c90fc326f2f4b1414.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdF-S4LkJoTX8H4Sqz_45A.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">图片来自<a class="ae kc" href="https://www.freepik.com/" rel="noopener ugc nofollow" target="_blank"> freepik </a>的<a class="ae kc" href="https://www.freepik.com/anustudio" rel="noopener ugc nofollow" target="_blank"> anustudio </a></p></figure><p id="14f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">在</span>我以前的文章(<a class="ae kc" rel="noopener" target="_blank" href="/monitoring-data-quality-in-a-data-lake-using-great-expectations-and-allure-built-serverless-47fa1791af6a">贴一</a>和<a class="ae kc" rel="noopener" target="_blank" href="/fast-data-quality-framework-on-great-expectations-8921331a08c2">贴二</a>)中，我描述了如何处理存储为中等大小(~500 MB)的Apache Parquet文件的同构数据源。但是如果需要处理大数据呢？如何在AWS上用《远大前程》来测试？如何比较两个非同质数据集？在本文中，我将探索一种方法来做到这一点。</p></div><div class="ab cl lk ll hu lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ij ik il im in"><h1 id="4e1d" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">挑战</h1><p id="fd70" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">Provectus数据工程团队正在开发由Pandas引擎支持的数据管道。最初，Pandas已经足够了，但是随着数据量的增长，该团队面临着Pandas在处理大数据方面的局限性。他们的解决方案是使用阿帕奇火花，而不是熊猫。虽然这是合理的，但他们还需要确保新算法不会出现数据问题。他们正在寻找一种方法来比较他们在Pandas上的小型黄金数据集和Apache Spark上的大型数据集。有了这些信息，我们开始设计解决方案。</p><h1 id="0134" class="lr ls iq bd lt lu mu lw lx ly mv ma mb mc mw me mf mg mx mi mj mk my mm mn mo bi translated">AWS胶水</h1><p id="78cc" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">首先，我们需要一个可以读取大数据帧的工具。我们排除了对我们的基本解决方案做太多改变的可能性，因为Pandas Profiling只适用于Pandas，而且我们还没有尝试对Apache Spark使用Great Expectations。所以，我们开始了探索过程。</p><p id="6ab4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的第一个选择是用黄昏代替熊猫。然而，在对AWS Lambda进行测试后，很明显它没有改变任何东西——机器无法将如此大量的数据上传到RAM，以有效地读取df。</p><p id="79b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的第二个选择是使用AWS Glue Python，因为它可以处理开箱即用的熊猫。在这个实例中安装必要的库是一个相当大的挑战，结果是不可接受的——我们再次收到OutMemoryError。</p><p id="7d2d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们最后的选择是尝试使用Apache Spark。这里我们有两种可能的变体:AWS Glue Spark和Amazon EMR。我们选择尝试AWS Glue Spark，因为这只是一个实验，我们不打算推出基础设施或任何其他组件。最重要的是，AWS Glue是无服务器的，这满足了使用无服务器服务的需求。</p><p id="c649" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这一步中，我们需要完成两个基本操作:概要分析和数据测试。我们通常使用Panda Profiling作为分析工具，但是它没有Spark实现。相反，我们决定使用<a class="ae kc" href="https://github.com/julioasotodv/spark-df-profiling" rel="noopener ugc nofollow" target="_blank"> spark_df_profiling </a>，它基于Pandas Profiling，但支持spark。Great Expectations也支持Spark，所以数据测试部分很容易。</p><p id="cd59" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最大的挑战是发布带有必要库的AWS Glue Spark:<br/>1。使用带有亚马逊S3适配器的预配置great_expectations.yaml将您的初始Great Expectations文件夹上传到亚马逊S3</p><p id="b9a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> V3 API通用电气:</strong></p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="5e86" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.使用作业参数创建AWS Glue Spark作业来安装库:</p><pre class="mz na nb nc gt nf ng nh ni aw nj bi"><span id="03ae" class="nk ls iq ng b gy nl nm l nn no"><em class="np">— additional-python-modules </em><strong class="ng ir"><em class="np">awswrangler, great_expectations, </em></strong><a class="ae kc" href="https://github.com/julioasotodv/spark-df-profiling/archive/master.zip," rel="noopener ugc nofollow" target="_blank"><strong class="ng ir"><em class="np">https://github.com/julioasotodv/spark-df-profiling/archive/master.zip,</em></strong></a><strong class="ng ir"><em class="np"> pyyaml, datacompy</em></strong></span></pre><p id="e878" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.照常初始化库</p><p id="48d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">V2:</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="6694" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">V3:</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="195a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">4.把ge.yaml和df读成Spark</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="1df4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">5.使用spark_df_profiling进行配置，并动态更改Great Expectations配置</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="f007" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">6.初始化远大的期望并开始运行测试</p><p id="8174" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">V2:</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="140f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">V3:</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="cb6e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">7.读取Pandas数据集并运行DataComPy</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="38ee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">之后，你会收到预期的结果。</p><p id="e1b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">稍微介绍一下<a class="ae kc" href="https://github.com/capitalone/datacompy" rel="noopener ugc nofollow" target="_blank"> DataComPy </a>:它是一个可以显示统计数据和模式变化的库。它使我们能够从测试角度获得更多的数据可见性，并为我们提供关于数据集的附加信息。</p><pre class="mz na nb nc gt nf ng nh ni aw nj bi"><span id="27e5" class="nk ls iq ng b gy nl nm l nn no">DataComPy Comparison</span><span id="9126" class="nk ls iq ng b gy nq nm l nn no">--------------------</span><span id="8102" class="nk ls iq ng b gy nq nm l nn no">DataFrame Summary</span><span id="8aa2" class="nk ls iq ng b gy nq nm l nn no">-----------------</span><span id="3dd0" class="nk ls iq ng b gy nq nm l nn no">DataFrame  Columns  Rows</span><span id="760e" class="nk ls iq ng b gy nq nm l nn no">0  original        5     6</span><span id="aee4" class="nk ls iq ng b gy nq nm l nn no">1       new        4     5</span><span id="dc8b" class="nk ls iq ng b gy nq nm l nn no">Column Summary</span><span id="ed46" class="nk ls iq ng b gy nq nm l nn no">--------------</span><span id="05b3" class="nk ls iq ng b gy nq nm l nn no">Number of columns in common: 4</span><span id="a84c" class="nk ls iq ng b gy nq nm l nn no">Number of columns in original but not in new: 1</span><span id="c88e" class="nk ls iq ng b gy nq nm l nn no">Number of columns in new but not in original: 0</span><span id="cc21" class="nk ls iq ng b gy nq nm l nn no">Row Summary</span><span id="26e7" class="nk ls iq ng b gy nq nm l nn no">-----------</span><span id="6bc6" class="nk ls iq ng b gy nq nm l nn no">Matched on: acct_id</span><span id="3676" class="nk ls iq ng b gy nq nm l nn no">Any duplicates on match values: Yes</span><span id="f690" class="nk ls iq ng b gy nq nm l nn no">Absolute Tolerance: 0.0001</span><span id="c46e" class="nk ls iq ng b gy nq nm l nn no">Relative Tolerance: 0</span><span id="1647" class="nk ls iq ng b gy nq nm l nn no">Number of rows in common: 5</span><span id="6e89" class="nk ls iq ng b gy nq nm l nn no">Number of rows in original but not in new: 1</span><span id="ef47" class="nk ls iq ng b gy nq nm l nn no">Number of rows in new but not in original: 0</span><span id="67cc" class="nk ls iq ng b gy nq nm l nn no">Number of rows with some compared columns unequal: 5</span><span id="b979" class="nk ls iq ng b gy nq nm l nn no">Number of rows with all compared columns equal: 0</span><span id="0433" class="nk ls iq ng b gy nq nm l nn no">Column Comparison</span><span id="3b6e" class="nk ls iq ng b gy nq nm l nn no">-----------------</span><span id="967f" class="nk ls iq ng b gy nq nm l nn no">Number of columns compared with some values unequal: 3</span><span id="024b" class="nk ls iq ng b gy nq nm l nn no">Number of columns compared with all values equal: 1</span><span id="9ea2" class="nk ls iq ng b gy nq nm l nn no">Total number of values which compare unequal: 7</span><span id="8b1b" class="nk ls iq ng b gy nq nm l nn no">Columns with Unequal Values or Types</span><span id="9324" class="nk ls iq ng b gy nq nm l nn no">------------------------------------</span><span id="f1b1" class="nk ls iq ng b gy nq nm l nn no">Column original dtype new dtype  # Unequal  Max Diff  # Null Diff</span><span id="eb01" class="nk ls iq ng b gy nq nm l nn no">0  dollar_amt        float64   float64          1    0.0500            0</span><span id="e945" class="nk ls iq ng b gy nq nm l nn no">1   float_fld        float64   float64          4    0.0005            3</span><span id="d7c6" class="nk ls iq ng b gy nq nm l nn no">2        name         object    object          2    0.0000            0</span><span id="3893" class="nk ls iq ng b gy nq nm l nn no">Sample Rows with Unequal Values</span><span id="c84c" class="nk ls iq ng b gy nq nm l nn no">-------------------------------</span><span id="9884" class="nk ls iq ng b gy nq nm l nn no">acct_id  dollar_amt (original)  dollar_amt (new)</span><span id="fdbd" class="nk ls iq ng b gy nq nm l nn no">0  10000001234                 123.45             123.4</span><span id="f7f5" class="nk ls iq ng b gy nq nm l nn no">acct_id  float_fld (original)  float_fld (new)</span><span id="8d92" class="nk ls iq ng b gy nq nm l nn no">0  10000001234            14530.1555        14530.155</span><span id="623c" class="nk ls iq ng b gy nq nm l nn no">5  10000001238                   NaN          111.000</span><span id="4a11" class="nk ls iq ng b gy nq nm l nn no">2  10000001236                   NaN            1.000</span><span id="c9ac" class="nk ls iq ng b gy nq nm l nn no">1  10000001235                1.0000              NaN</span><span id="97d7" class="nk ls iq ng b gy nq nm l nn no">acct_id name (original)            name (new)</span><span id="5faa" class="nk ls iq ng b gy nq nm l nn no">0  10000001234  George Maharis  George Michael Bluth</span><span id="972d" class="nk ls iq ng b gy nq nm l nn no">3  10000001237      Bob Loblaw         Robert Loblaw</span><span id="a021" class="nk ls iq ng b gy nq nm l nn no">Sample Rows Only in original (First 10 Columns)</span><span id="5b2c" class="nk ls iq ng b gy nq nm l nn no">-----------------------------------------------</span><span id="72cb" class="nk ls iq ng b gy nq nm l nn no">acct_id  dollar_amt           name  float_fld    date_fld</span><span id="725d" class="nk ls iq ng b gy nq nm l nn no">4  10000001238        1.05  Lucille Bluth        NaN  2017-01-01</span></pre><h1 id="f8d7" class="lr ls iq bd lt lu mu lw lx ly mv ma mb mc mw me mf mg mx mi mj mk my mm mn mo bi translated">生产者和消费者的概念</h1><p id="3732" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">我们已经学习了如何使用Apache Spark的必要工具集。让我们回到第一步，更深入地研究比较概念。主要思想很简单:您需要一个黄金数据集(生产者)并基于它生成测试，然后对它运行，并对目标数据集(消费者)运行这些测试，以比较质量。要访问所有报告，您需要实现一个元数据存储和一个BI仪表板。</p><p id="ca9c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，您可以看到参考架构:</p><figure class="mz na nb nc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/dc8a058790234a1b37476a6ab9548dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pLMStILbEs6vajJ4"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><h1 id="0955" class="lr ls iq bd lt lu mu lw lx ly mv ma mb mc mw me mf mg mx mi mj mk my mm mn mo bi translated">管道</h1><p id="8ea3" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">为了实现参考架构，让我们重新使用我们的基本解决方案和AWS Step函数和AWS Lambda。(查看<a class="ae kc" rel="noopener" target="_blank" href="/monitoring-data-quality-in-a-data-lake-using-great-expectations-and-allure-built-serverless-47fa1791af6a">这篇文章</a>了解技术细节。)您需要:</p><ol class=""><li id="26ba" class="ns nt iq kf b kg kh kk kl ko nu ks nv kw nw la nx ny nz oa bi translated">对pandas_df运行分析</li><li id="0d94" class="ns nt iq kf b kg ob kk oc ko od ks oe kw of la nx ny nz oa bi translated">动态生成测试</li><li id="458d" class="ns nt iq kf b kg ob kk oc ko od ks oe kw of la nx ny nz oa bi translated">针对spark_df运行分析</li><li id="9813" class="ns nt iq kf b kg ob kk oc ko od ks oe kw of la nx ny nz oa bi translated">针对spark_df运行准备好的测试</li><li id="d408" class="ns nt iq kf b kg ob kk oc ko od ks oe kw of la nx ny nz oa bi translated">运行DataComPy</li></ol><figure class="mz na nb nc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/e2d20d59fb7ae7ed9b9e19118ded35d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Yl5JsnxKo5LaTHBO"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><p id="06ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里只需要一个技术说明:在生产者步骤中，我们将项目推送到元数据存储，并保存到有效负载id；在消费者步骤中，我们需要更新这个项目。</p><figure class="mz na nb nc gt jr"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="3032" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从ETL的角度来看，这看起来很简单:</p><figure class="mz na nb nc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/150ec6c484d3832bbb46704077bfdd95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kmTzuADn5CGh5AM0"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><h1 id="e8fa" class="lr ls iq bd lt lu mu lw lx ly mv ma mb mc mw me mf mg mx mi mj mk my mm mn mo bi translated">实施理念</h1><p id="9a1d" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">上述经验帮助我们为我们的一个客户<a class="ae kc" href="https://lanehealth.com/" rel="noopener ugc nofollow" target="_blank"> Lane Health </a>实施了一个数据QA解决方案。挑战在于车道健康数据是不均匀的，并且获取和读取数据的方式有很大不同。创建一个用于处理高负载的通用管道并不容易。我们将其构建为一个两步解决方案:</p><ol class=""><li id="6d1c" class="ns nt iq kf b kg kh kk kl ko nu ks nv kw nw la nx ny nz oa bi translated">从PostgreSQL CDC迁移到亚马逊S3</li><li id="5dac" class="ns nt iq kf b kg ob kk oc ko od ks oe kw of la nx ny nz oa bi translated">Apache胡迪上的数据转换</li></ol><figure class="mz na nb nc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/b5851455c26f0d77bd31d98e2f6784c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*GHHZK6275wOoZNYz"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure><figure class="mz na nb nc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/3f9a5d801ebdfdca01aed2a86970c96b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-8Kk_-MDujZQUhSX"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">作者图片</p></figure></div><div class="ab cl lk ll hu lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ij ik il im in"><h1 id="3eae" class="lr ls iq bd lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo bi translated">结论</h1><p id="349c" class="pw-post-body-paragraph kd ke iq kf b kg mp ki kj kk mq km kn ko mr kq kr ks ms ku kv kw mt ky kz la ij bi translated">本文探索了使用带有AWS Glue (Apache Spark ETL)的Great Expectations来比较两个数据集的质量的方法，而不需要行比较、字节大小等。我们为我们的一个商业客户演示了这种<a class="ae kc" href="https://provectus.com/data-quality-assurance/" rel="noopener ugc nofollow" target="_blank">数据质量方法</a>的实现。</p><p id="207d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您有任何问题或建议，欢迎在下面的评论中联系我，或者直接联系<a class="ae kc" href="https://www.linkedin.com/in/bogdan-volodarskiy-652498108/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>！</p></div></div>    
</body>
</html>