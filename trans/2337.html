<html>
<head>
<title>BERTScore: Evaluating Text Generation with BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BERTScore:用BERT评估文本生成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bertscore-evaluating-text-generation-with-bert-beb7b3431300#2022-05-23">https://towardsdatascience.com/bertscore-evaluating-text-generation-with-bert-beb7b3431300#2022-05-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="94ad" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">机器学习研究论文摘要</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1bc483894fa9095a3f00f9d5eed11197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyPAGG93uuiUNOZBXZU4mw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="00ce" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">BERTScore是一种自动评估标准，用于测试文本生成系统的优劣。与计算标记级句法相似性的现有流行方法不同，BERTScore侧重于计算参考标记和假设标记之间的语义相似性。这篇论文的作者在机器翻译和图像字幕任务上测试了它，发现它与人类的判断更相关。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lu lv l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae lw" href="https://www.youtube.com/c/TechVizTheDataScienceGuy" rel="noopener ugc nofollow" target="_blank">更多这样的视频</a></p></figure><p id="cae4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们以总结系统为例，任务是通过GPT2模型对给定的书进行总结，假设模型说“这是我如何总结的”，但事实是“这应该是如何总结的”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi lx"><img src="../Images/5ef75c89b5cb1704f9eed065e5987f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GW6yodvGUgSqWbbV7n9DzQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="7ad5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了评估系统已经生成的摘要的质量，可以使用现有的系统，例如<a class="ae lw" href="https://en.wikipedia.org/wiki/ROUGE_(metric)" rel="noopener ugc nofollow" target="_blank"> ROUGE </a>和<a class="ae lw" href="https://en.wikipedia.org/wiki/BLEU" rel="noopener ugc nofollow" target="_blank"> BLEU </a>度量，这些度量依赖于假设和参考之间的句法重叠，通过考虑单字、双字等。但是考虑到它们的局限性，即在假设和参考中存在确切的词，并且不能解码语义，引入了BERTScore，其中的<em class="ly">思想是理解你已经生成的和应该生成的</em>的含义，然后进行比较。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ab1ec82b0b8617b27c7f7f3ca1e81e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EEVR8WZHAjXkt7WrlsGtYQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="2287" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如上图所示，我们采用参考(基本事实)和候选(生成的)，并通过预训练的BERT模型，在输出端为每个单词生成上下文嵌入。一旦我们有了这些单词中每个单词的最终嵌入，我们就通过计算每个单词与候选单词中每个单词的参考相似度来进行n平方计算。我们从参考中找到并挑选与候选词最相似的词，并计算<a class="ae lw" rel="noopener" target="_blank" href="/accuracy-precision-recall-or-f1-331fb37c5cb9">精确度、召回率和f值</a>(精确度和召回率的调和平均值)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d2d8b9e978ef4da40229ca53652baa90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEJ0bsLyTtoLRAppmEhBwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="f4ac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文作者还引入了权重的概念，用于计算每个单词的相似度。他们坚持基于大量离线文本数据得出的<a class="ae lw" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> IDF </a>权重。因此，如果一个单词具有非常高的IDF权重，那么这不是一个在多个文档中使用的非常常见的单词，所以在进行相似性计算时，它可能值得您进行比较，不像具有低IDF的单词<em class="ly">(主要代表常见单词)</em></p><p id="e5b0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以，是的，这就是我的博客。我鼓励你也通读这篇论文，其细节将在下面提及—</p><p id="9e62" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ly">⏩</em> <strong class="la iu"> <em class="ly">论文标题</em> </strong> <em class="ly"> : BERTScore:用BERT评估文本生成</em></p><p id="8920" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ly">⏩</em> <strong class="la iu"> <em class="ly">论文</em></strong><em class="ly">:</em><a class="ae lw" href="https://arxiv.org/abs/1904.09675" rel="noopener ugc nofollow" target="_blank">【https://arxiv.org/abs/1904.09675】T21</a></p><p id="c1d0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ly">⏩</em> <strong class="la iu"> <em class="ly">作者</em> </strong> <em class="ly">:张天翼、瓦莎·基肖尔、菲利克斯·吴、基连·q·温伯格、约夫·阿奇</em></p><p id="4b84" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="ly">⏩</em> <strong class="la iu"> <em class="ly">组织机构</em></strong><em class="ly">:ASAPP康乃尔大学公司</em></p><p id="5a86" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我希望你喜欢读这篇文章。如果你愿意支持我成为一名作家，可以考虑注册<a class="ae lw" href="https://prakhar-mishra.medium.com/membership" rel="noopener">成为</a>中的一员。每月只需5美元，你就可以无限制地使用Medium。</p></div></div>    
</body>
</html>