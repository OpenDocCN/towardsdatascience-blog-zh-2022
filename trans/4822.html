<html>
<head>
<title>Hands-On Tutorial for Applying Grad-CAMs for Explaining Image Classifiers Using Keras and TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras和TensorFlow讲解图像分类器的Grad-cam应用实践教程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-tutorial-for-applying-grad-cams-for-explaining-image-classifiers-using-keras-and-cbdcef68bb89#2022-10-26">https://towardsdatascience.com/hands-on-tutorial-for-applying-grad-cams-for-explaining-image-classifiers-using-keras-and-cbdcef68bb89#2022-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5bde" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解如何使用Keras和TensorFlow应用Grad-CAM来解释基于深度学习的图像分类器</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/308d55937800d1ed51b183063e021fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*2azI5VmVB0ylxqfD0EqpVw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">解释图像分类器的Grad-CAM方法的输出(作者图片，基本图片来源:<a class="ae ku" href="https://unsplash.com/photos/DJ4vjcD0s0I?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="b33d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当应用于图像和文本等非结构化数据时，经典的机器学习(ML)算法与深度学习(DL)算法相比效率不高。由于与经典ML中的手动特征工程相比，DL中的自动特征提取的好处，DL算法在模型精度方面更有效，因此更受欢迎。然而，这些模型比经典的ML模型更复杂，更难解释。因此，对于像图像这样的非结构化数据的DL模型来说，可解释性总是一个问题。<strong class="kx iu">逐层相关性传播</strong> ( <strong class="kx iu"> LRP </strong>)是一种可解释方法，它突出图像的相关区域来解释模型预测。</p><p id="179e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你不太熟悉可解释的人工智能(XAI)概念，我强烈建议观看我过去在2021年APAC人工智能加速器节上发表的关于XAI的演讲:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lr ls l"/></div></figure><p id="ef12" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">你也可以浏览我的书<a class="ae ku" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu">应用机器学习可解释技术</strong> </a> <strong class="kx iu"> </strong>并看看<a class="ae ku" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/" rel="noopener ugc nofollow" target="_blank">代码库</a>以获得对其他XAI方法的实际接触。</p><div class="lt lu gp gr lv lw"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">www.amazon.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ko lw"/></div></div></a></div><p id="9b4d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如果你想得到关于这本书的详细反馈，这个视频可能对你有用:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="lr ls l"/></div></figure><p id="6545" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这篇文章中，我将提到一种叫做<strong class="kx iu"> Grad-CAM </strong>的流行LRP技术的实际应用，用于解释图像分类器。我还将介绍使用Keras和TensorFlow应用Grad-CAMs的一步一步的代码教程。</p><p id="308e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，让我们开始吧！</p><h1 id="8e8d" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">LRP简介</h1><p id="ee86" class="pw-post-body-paragraph kv kw it kx b ky nd ju la lb ne jx ld le nf lg lh li ng lk ll lm nh lo lp lq im bi translated">为了解释DL模型，LRP是最突出的方法之一。直观地说，这种方法利用网络中的权重和前向传递神经激活，通过网络中的各个层将输出传播回输入层。因此，在网络权重的帮助下，我们可以将对最终模型输出贡献最大的数据元素(图像中的像素和文本数据中的单词)可视化。这些数据元素的贡献是通过网络层传播的相关性的定性度量。此外，对于具有多层的深度神经网络，当通过层间梯度流动过程的信息流保持一致时，学习就发生了。因此，为了解释任何深度学习模型，LRP方法允许我们可视化网络不同层中的<em class="ni">激活的</em>或最有影响力的数据元素，并定性地检查算法的功能。</p><div class="lt lu gp gr lv lw"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">www.amazon.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ko lw"/></div></div></a></div><h1 id="538a" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">什么是Grad-CAM？</h1><p id="dd1f" class="pw-post-body-paragraph kv kw it kx b ky nd ju la lb ne jx ld le nf lg lh li ng lk ll lm nh lo lp lq im bi translated"><strong class="kx iu">类激活图(CAMs) </strong>是用于解释深度学习模型的可视化方法。在这种方法中，模型预测的类别分数被追溯到最后的卷积层，以突出图像中的有区别的感兴趣区域，这些区域是特定于类别的，甚至不是其他计算机视觉或图像处理算法所通用的。<strong class="kx iu"> Gradient CAM </strong>或俗称<strong class="kx iu"> Grad-CAMs </strong>结合了导向反向传播和CAM的效果，在不突出颗粒像素重要性的情况下，突出类别区分感兴趣区域。但是Grad-CAM可以应用于任何CNN架构，不像CAM可以应用于在预测层之前对来自卷积层的输出特征图执行全局平均汇集的架构。为了更详细地了解Grad-CAM过程，您可以看看这篇研究论文<em class="ni"> Grad-CAM:通过基于梯度的定位从深度网络进行可视化解释，Ramprasaath等人。艾尔—</em><a class="ae ku" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1610.02391</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="nk nl di nm bf nn"><div class="gh gi nj"><img src="../Images/88ff2f84b111584e9224662f7402a012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DfNo5uL_RSUI82_7.jpg"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">引导Grad-CAM的架构图(来源:<em class="no"> Grad-CAM:通过基于梯度的定位，来自深度网络的视觉解释，Ramprasaath等人。艾尔—</em><a class="ae ku" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1610.02391</a></p></figure><h1 id="87b1" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">使用Keras和TensorFlow应用Grad-cam</h1><p id="2af6" class="pw-post-body-paragraph kv kw it kx b ky nd ju la lb ne jx ld le nf lg lh li ng lk ll lm nh lo lp lq im bi translated">现在来看这篇文章有趣的部分:学习如何应用Grad-CAMs！我们将使用Keras和TensorFlow来应用Grad-cam来解释预训练的图像分类器。您将需要以下Python框架来应用Grad-CAMs，这些框架可以使用Python pip安装程序进行安装:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="6d9a" class="nu mm it nq b gy nv nw l nx ny"><strong class="nq iu">!</strong>pip install --upgrade numpy matplotlib tensorflow</span></pre><p id="2019" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们从用Python加载所需的模块开始。我会推荐使用本地Jupyter笔记本或Google colab来运行这个代码教程。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="b232" class="nu mm it nq b gy nv nw l nx ny"><strong class="nq iu">import</strong> numpy <strong class="nq iu">as</strong> np<br/><strong class="nq iu">import</strong> matplotlib.pyplot <strong class="nq iu">as</strong> plt<br/><strong class="nq iu">import</strong> matplotlib.cm <strong class="nq iu">as</strong> c_map<br/><strong class="nq iu">from</strong> IPython.display <strong class="nq iu">import</strong> Image, display<br/><strong class="nq iu">import</strong> tensorflow <strong class="nq iu">as</strong> tf<br/><strong class="nq iu">from</strong> tensorflow <strong class="nq iu">import</strong> keras<br/><strong class="nq iu">from</strong> tensorflow.keras.applications.xception <strong class="nq iu">import</strong> Xception, preprocess_input, decode_predictions<br/><strong class="nq iu">from</strong> tensorflow.keras.preprocessing <strong class="nq iu">import</strong> image<br/><strong class="nq iu">import</strong> os</span></pre><p id="9b55" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们将使用TensorFlow和Keras框架在<strong class="kx iu"> ImageNet </strong>数据集上获得一个预训练的网络，并在从来源:<a class="ae ku" href="https://images.unsplash.com/photo-1615963244664-5b845b2025ee?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=464&amp;q=80" rel="noopener ugc nofollow" target="_blank">https://images . unsplash . com/photo-1615963244664-5b 845 b 2025 ee？IX lib = r b-4 . 0 . 3&amp;ixid = mnwxmja 3 fdb 8 mhxwag 90 by 1 wywdlfhx 8 fgvufdb 8 fhx 8&amp;auto = format&amp;fit = crop&amp;w = 464&amp;q = 80</a>。更多使用Keras和TensorFlow的例子请访问:【https://keras.io/examples/】T4。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="5628" class="nu mm it nq b gy nv nw l nx ny">model_builder <strong class="nq iu">=</strong> Xception<br/>preprocess_input <strong class="nq iu">=</strong> preprocess_input<br/>decode_predictions <strong class="nq iu">=</strong> decode_predictions<br/>IMG_SIZE <strong class="nq iu">=</strong> (299, 299)<br/>last_conv_layer <strong class="nq iu">=</strong> "block14_sepconv2_act"</span><span id="1fa8" class="nu mm it nq b gy nz nw l nx ny"><em class="ni"># The local path to our target image</em><br/>image_path <strong class="nq iu">=</strong> keras<strong class="nq iu">.</strong>utils<strong class="nq iu">.</strong>get_file(<br/>    "tiger.jpg", "<a class="ae ku" href="https://images.unsplash.com/photo-1615963244664-5b845b2025ee?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=464&amp;q=80" rel="noopener ugc nofollow" target="_blank">https://images.unsplash.com/photo-1615963244664-5b845b2025ee?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=464&amp;q=80</a>"<br/>)<br/><br/>display(Image(image_path))</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/f84bd3ee116125f2a90069a9d9ca6f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/0*xXw92dS6O-ypgpmh"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来源推断图像(来源:<a class="ae ku" href="https://unsplash.com/photos/DJ4vjcD0s0I?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="c80a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">加载图像后，您需要应用预处理层。由于我们将使用来自Keras和TensorFlow的预训练<strong class="kx iu">异常</strong>模型，我们将需要应用相同的预处理。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="9776" class="nu mm it nq b gy nv nw l nx ny"><strong class="nq iu">def</strong> vectorize_image(img_path, size):<br/>    '''<br/>    Vectorize the given image to get a numpy array<br/>    '''<br/>    img <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>load_img(img_path, target_size<strong class="nq iu">=</strong>size)<br/>    array <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>img_to_array(img)<br/>    array <strong class="nq iu">=</strong> np<strong class="nq iu">.</strong>expand_dims(array, axis<strong class="nq iu">=</strong>0) <em class="ni"># Adding dimension to convert array into a batch of size (1,299,299,3)</em><br/>    <strong class="nq iu">return</strong> array</span></pre><p id="e9c9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">现在，让我们将预训练的模型应用于我们预处理的图像，并查看预测。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="1780" class="nu mm it nq b gy nv nw l nx ny">vectorized_image <strong class="nq iu">=</strong> preprocess_input(vectorize_image(image_path, size<strong class="nq iu">=</strong>IMG_SIZE))<br/>model <strong class="nq iu">=</strong> model_builder(weights<strong class="nq iu">=</strong>"imagenet")<br/>model<strong class="nq iu">.</strong>layers[<strong class="nq iu">-</strong>1]<strong class="nq iu">.</strong>activation <strong class="nq iu">=</strong> <strong class="nq iu">None</strong> <em class="ni"># Removing the last layer as it is the softmax layer used for classification</em><br/><br/>model_prediction <strong class="nq iu">=</strong> model<strong class="nq iu">.</strong>predict(vectorized_image)<br/>print(f"The predicted class is : {decode_predictions(model_prediction, top<strong class="nq iu">=</strong>1)[0][0][1]}")</span></pre><p id="55c4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这是我们得到的输出:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="4b57" class="nu mm it nq b gy nv nw l nx ny">The predicted class is : tiger</span></pre><p id="c78c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">因此，我们的模型正确地预测了我们的推断图像为老虎。现在，让我们来理解使用Grad-cam进行预测背后的基本原理。</p><h1 id="1597" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">建筑Grad-CAM热图</h1><p id="50d1" class="pw-post-body-paragraph kv kw it kx b ky nd ju la lb ne jx ld le nf lg lh li ng lk ll lm nh lo lp lq im bi translated">我们将构建一个Grad-CAM热图可视化工具来突出显示模型中有影响力的超像素。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="bb5d" class="nu mm it nq b gy nv nw l nx ny"><strong class="nq iu">def</strong> get_heatmap(vectorized_image, model, last_conv_layer, pred_index<strong class="nq iu">=None</strong>):<br/>    '''<br/>    Function to visualize grad-cam heatmaps<br/>    '''<br/>    gradient_model <strong class="nq iu">=</strong> tf<strong class="nq iu">.</strong>keras<strong class="nq iu">.</strong>models<strong class="nq iu">.</strong>Model(<br/>        [model<strong class="nq iu">.</strong>inputs], [model<strong class="nq iu">.</strong>get_layer(last_conv_layer)<strong class="nq iu">.</strong>output, model<strong class="nq iu">.</strong>output]<br/>    )<br/><br/>    <em class="ni"># Gradient Computations</em><br/>    <strong class="nq iu">with</strong> tf<strong class="nq iu">.</strong>GradientTape() <strong class="nq iu">as</strong> tape:<br/>        last_conv_layer_output, preds <strong class="nq iu">=</strong> gradient_model(vectorized_image)<br/>        <strong class="nq iu">if</strong> pred_index <strong class="nq iu">is</strong> <strong class="nq iu">None</strong>:<br/>            pred_index <strong class="nq iu">=</strong> tf<strong class="nq iu">.</strong>argmax(preds[0])<br/>        class_channel <strong class="nq iu">=</strong> preds[:, pred_index]<br/><br/>    grads <strong class="nq iu">=</strong> tape<strong class="nq iu">.</strong>gradient(class_channel, last_conv_layer_output)<br/>    pooled_grads <strong class="nq iu">=</strong> tf<strong class="nq iu">.</strong>reduce_mean(grads, axis<strong class="nq iu">=</strong>(0, 1, 2))<br/>    last_conv_layer_output <strong class="nq iu">=</strong> last_conv_layer_output[0]<br/>    heatmap <strong class="nq iu">=</strong> last_conv_layer_output <strong class="nq iu">@</strong> pooled_grads[<strong class="nq iu">...</strong>, tf<strong class="nq iu">.</strong>newaxis]<br/>    heatmap <strong class="nq iu">=</strong> tf<strong class="nq iu">.</strong>squeeze(heatmap)<br/>    heatmap <strong class="nq iu">=</strong> tf<strong class="nq iu">.</strong>maximum(heatmap, 0) <strong class="nq iu">/</strong> tf<strong class="nq iu">.</strong>math<strong class="nq iu">.</strong>reduce_max(heatmap) <em class="ni"># Normalize the heatmap</em><br/>    <strong class="nq iu">return</strong> heatmap<strong class="nq iu">.</strong>numpy()<br/><br/>plt<strong class="nq iu">.</strong>matshow(get_heatmap(vectorized_image, model, last_conv_layer))<br/>plt<strong class="nq iu">.</strong>show()</span></pre><p id="339f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当我们将热图应用于预训练模型的第四卷积层时，我们得到的输出热图图像如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/b5c81643e415a8dc18eec0260a3904a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*NWVx8nCv4BTJ6D_E_wUbZw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">Grad-CAM热图来自推理老虎图片(来源:作者)</p></figure><p id="456b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">但是这并不能告诉我们什么，除非我们把这个图像叠加到我们的推理图像上。因此，让我们使用下面的代码片段来看看如何做到这一点:</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="0bf3" class="nu mm it nq b gy nv nw l nx ny"><strong class="nq iu">def</strong> superimpose_gradcam(img_path, heatmap, output_path<strong class="nq iu">=</strong>"grad_cam_image.jpg", alpha<strong class="nq iu">=</strong>0.4):<br/>    '''<br/>    Superimpose Grad-CAM Heatmap on image<br/>    '''<br/>    img <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>load_img(img_path)<br/>    img <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>img_to_array(img)<br/><br/>    heatmap <strong class="nq iu">=</strong> np<strong class="nq iu">.</strong>uint8(255 <strong class="nq iu">*</strong> heatmap) <em class="ni"># Back scaling to 0-255 from 0 - 1</em><br/>    jet <strong class="nq iu">=</strong> c_map<strong class="nq iu">.</strong>get_cmap("jet") <em class="ni"># Colorizing heatmap</em><br/>    jet_colors <strong class="nq iu">=</strong> jet(np<strong class="nq iu">.</strong>arange(256))[:, :3] <em class="ni"># Using RGB values</em><br/>    jet_heatmap <strong class="nq iu">=</strong> jet_colors[heatmap]<br/>    jet_heatmap <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>array_to_img(jet_heatmap)<br/>    jet_heatmap <strong class="nq iu">=</strong> jet_heatmap<strong class="nq iu">.</strong>resize((img<strong class="nq iu">.</strong>shape[1], img<strong class="nq iu">.</strong>shape[0]))<br/>    jet_heatmap <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>img_to_array(jet_heatmap)<br/><br/>    <br/>    superimposed_img <strong class="nq iu">=</strong> jet_heatmap <strong class="nq iu">*</strong> alpha <strong class="nq iu">+</strong> img <em class="ni"># Superimposing the heatmap on original image</em><br/>    superimposed_img <strong class="nq iu">=</strong> image<strong class="nq iu">.</strong>array_to_img(superimposed_img)<br/><br/>    superimposed_img<strong class="nq iu">.</strong>save(output_path) <em class="ni"># Saving the superimposed image</em><br/>    display(Image(output_path)) <em class="ni"># Displaying Grad-CAM Superimposed Image</em><br/>    <br/>superimpose_gradcam(image_path, get_heatmap(vectorized_image, model, last_conv_layer))</span></pre><p id="189c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">瞧啊。我们得到了参考图像的以下叠加热图图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/308d55937800d1ed51b183063e021fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*2azI5VmVB0ylxqfD0EqpVw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">用于解释图像分类器的Grad-CAM方法的输出(图片由作者提供，基本图片来源:<a class="ae ku" href="https://unsplash.com/photos/DJ4vjcD0s0I?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><p id="bfbd" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">使用Grad-CAMs是不是太难了？绝对不行！Keras和TensorFlow使得将这种可解释的技术应用于图像分类器变得更加容易！这是一种非常强大的技术，用于解释复杂的深度学习算法对图像等非结构化数据的工作。虽然这种方法对于初学者来说很难理解。然而，一旦你掌握了它，这是一个非常强大的方法，对模型的可解释性非常有帮助。</p><p id="6ca0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">希望你喜欢这篇文章！完整的教程笔记本可在:<a class="ae ku" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/blob/main/Chapter02/Layerwise%20Propagation.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/packt publishing/Applied-Machine-Learning-explability-Techniques/blob/main/chapter 02/layer wise % 20 propagation . ipynb</a>获得。我推荐阅读这本书:<a class="ae ku" href="https://amzn.to/3cY4c2h" rel="noopener ugc nofollow" target="_blank"> <strong class="kx iu">【应用机器学习可解释技术】</strong> </a> <strong class="kx iu"> </strong>并探索<a class="ae ku" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>以获得更多实际操作的代码示例。</p><p id="c01b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在<a class="ae ku" href="https://adib0073.medium.com/membership" rel="noopener"> Medium </a>和<a class="ae ku" href="https://www.linkedin.com/in/aditya-bhattacharya-b59155b6/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我，了解更多可解释的AI和机器学习。</p><div class="lt lu gp gr lv lw"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">www.amazon.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ko lw"/></div></div></a></div><h1 id="c57b" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">作者关于TDS的其他XAI相关文章:</h1><ol class=""><li id="c6c8" class="oc od it kx b ky nd lb ne le oe li of lm og lq oh oi oj ok bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/explainable-machine-learning-for-models-trained-on-text-data-combining-shap-with-transformer-5095ea7f3a8">用于在文本数据上训练的模型的可解释机器学习:将SHAP与变压器模型相结合</a></li><li id="ead0" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/euca-an-effective-xai-framework-to-bring-artificial-intelligence-closer-to-end-users-74bb0136ffb1">EUCA——一个有效的XAI框架，让人工智能更贴近终端用户</a></li><li id="3960" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/understand-the-working-of-shap-based-on-shapley-values-used-in-xai-in-the-most-simple-way-d61e4947aa4e">理解可解释人工智能中使用的SHAP和沙普利值的工作原理</a></li><li id="b25a" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/how-to-explain-image-classifiers-using-lime-e364097335b4">如何用石灰解释图像分类器</a></li></ol><div class="lt lu gp gr lv lw"><a href="https://www.amazon.com/Applied-Machine-Learning-Explainability-Techniques/dp/1803246154?_encoding=UTF8&amp;pd_rd_w=Wr6SJ&amp;content-id=amzn1.sym.716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_p=716a1ed9-074f-4780-9325-0019fece3c64&amp;pf_rd_r=6P2PM599T97MRG7NZD9J&amp;pd_rd_wg=m4qUW&amp;pd_rd_r=6e349d93-5ba0-4bfe-9055-905c0153fe58&amp;linkCode=li3&amp;tag=adib0073-20&amp;linkId=35506e1847de5c011fc57aa66c2b1d8e&amp;language=en_US&amp;ref_=as_li_ss_il" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab fo"><div class="ly ab lz cl cj ma"><h2 class="bd iu gy z fp mb fr fs mc fu fw is bi translated">应用机器学习可解释技术:使ML模型可解释和可信…</h2><div class="md l"><h3 class="bd b gy z fp mb fr fs mc fu fw dk translated">应用机器学习可解释技术:使ML模型可解释和可信赖的实践…</h3></div><div class="me l"><p class="bd b dl z fp mb fr fs mc fu fw dk translated">www.amazon.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ko lw"/></div></div></a></div><h1 id="5985" class="ml mm it bd mn mo mp mq mr ms mt mu mv jz mw ka mx kc my kd mz kf na kg nb nc bi translated">参考</h1><ol class=""><li id="81e2" class="oc od it kx b ky nd lb ne le oe li of lm og lq oh oi oj ok bi translated">Keras Tensorflow教程示例—<a class="ae ku" href="https://keras.io/examples/" rel="noopener ugc nofollow" target="_blank">https://keras.io/examples/</a></li><li id="d1e5" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated">Grad-CAM:通过基于梯度的定位来自深度网络的视觉解释。艾尔<em class="ni">—</em><a class="ae ku" href="https://arxiv.org/abs/1610.02391" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1610.02391</a>。</li><li id="c9f1" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated">应用机器学习解释技术</li><li id="40b0" class="oc od it kx b ky ol lb om le on li oo lm op lq oh oi oj ok bi translated">GitHub repo自《应用机器学习可解释技术》——<a class="ae ku" href="https://github.com/PacktPublishing/Applied-Machine-Learning-Explainability-Techniques/" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/packt publishing/Applied-Machine-Learning-explability-Techniques/</a></li></ol></div></div>    
</body>
</html>