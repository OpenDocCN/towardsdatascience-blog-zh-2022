<html>
<head>
<title>LSTM Recurrent Neural Networks — How to Teach a Network to Remember the Past</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LSTM 递归神经网络——如何教网络记住过去</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lstm-recurrent-neural-networks-how-to-teach-a-network-to-remember-the-past-55e54c2ff22e#2022-02-06">https://towardsdatascience.com/lstm-recurrent-neural-networks-how-to-teach-a-network-to-remember-the-past-55e54c2ff22e#2022-02-06</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="ba17" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">神经网络</h2><div class=""/><div class=""><h2 id="b420" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">以双向 LSTM 解决“多对多”序列问题为例直观解释长时短时记忆</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/c1a12ce30fb14ef0e5eda2c0942a6d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7cMfenu76BZCzdKWCfBABA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">长短期记忆(LSTM)神经网络。图片作者。</p></figure><h1 id="5b81" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated">介绍</h1><p id="4fd3" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">标准递归神经网络(RNNs)由于在处理较长的数据序列时出现的消失梯度问题而遭受短期记忆。</p><p id="666e" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">幸运的是，我们有更先进的 RNNs 版本，可以保存序列早期的重要信息，并将其发扬光大。两个最著名的版本是<strong class="mc je">长短期记忆(LSTM) </strong>和<a class="ae nb" rel="noopener" target="_blank" href="/gru-recurrent-neural-networks-a-smart-way-to-predict-sequences-in-python-80864e4fe9f6"> <strong class="mc je">门控循环单位(GRU) </strong> </a>。</p><p id="cb5b" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">在本文中，我将重点关注<strong class="mc je"> LSTM </strong>的结构，并为您提供一个详细的 Python 示例供您使用。</p><h1 id="f226" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated">内容</h1><ul class=""><li id="397c" class="nc nd iu mc b md me mg mh mj ne mn nf mr ng mv nh ni nj nk bi translated">LSTM 在机器学习领域处于什么位置？</li><li id="ce02" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">LSTM 与标准 RNNs 有何不同，LSTM 是如何工作的？</li><li id="b409" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">一个完整的 Python 示例，向您展示了如何构建和训练您自己的 LSTM 模型</li></ul><h1 id="0868" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated">LSTM 在机器学习领域处于什么位置？</h1><p id="179e" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">下面的图表是我对最常见的机器学习算法进行分类的尝试。</p><p id="6ca7" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">虽然我们经常以监督的方式使用带有标签的训练数据的神经网络，但我觉得它们独特的机器学习方法值得单独归类。</p><p id="b029" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">因此，我的图表显示了从机器学习宇宙的核心分支出来的神经网络。递归神经网络占据 NNs 的一个子分支，并且包含诸如标准 RNNs、LSTMs 和 GRUs 的算法。</p><p id="70b5" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">下图是<strong class="mc je">交互式的，</strong>所以请点击不同的类别来<strong class="mc je">放大并展示更多的</strong>👇。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nq nr l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">机器学习算法分类。由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>创建的互动图表。</p></figure><p id="5fba" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated"><strong class="mc je"> <em class="ns">如果你喜欢数据科学和机器学习</em> </strong> <em class="ns">，请</em> <a class="ae nb" href="https://solclover.com/subscribe" rel="noopener ugc nofollow" target="_blank"> <em class="ns">订阅</em> </a> <em class="ns">获取我的新文章的电子邮件。</em></p><h1 id="51a3" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated">LSTM 与标准 RNNs 有何不同，LSTM 是如何工作的？</h1><p id="f49c" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">让我们先快速回顾一下简单的 RNN 结构。RNN 由类似于前馈神经网络的多层组成:输入层、隐藏层和输出层。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj nt"><img src="../Images/52219d7e4585900c9695f3205af6e827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88v6lf17GqXSIPnQNA5ktQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">标准递归神经网络结构。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="43e4" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">然而，RNN 在其隐藏层中包含了<strong class="mc je">个递归单元</strong>，这允许算法处理<strong class="mc je">个序列数据</strong>。它通过循环传递来自前一个<strong class="mc je">时间步长</strong>的隐藏状态并将其与当前时间步长的输入相结合来实现。</p><blockquote class="nu"><p id="d40f" class="nv nw iu bd nx ny nz oa ob oc od mv dk translated">时间步长—通过递归单元对输入进行的单一处理。时间步长的数量等于序列的长度。</p></blockquote><p id="b50e" class="pw-post-body-paragraph ma mb iu mc b md oe ke mf mg of kh mi mj og ml mm mn oh mp mq mr oi mt mu mv in bi translated">如果需要，你可以在我的<a class="ae nb" rel="noopener" target="_blank" href="/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92">前一篇文章</a>中找到标准 rnn 的详细解释。</p><h2 id="bdb2" class="oj lj iu bd lk ok ol dn lo om on dp ls mj oo op lu mn oq or lw mr os ot ly ja bi translated">LSTM 和标准的 RNN 有什么不同？</h2><p id="eab8" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">我们知道 RNNs 利用<strong class="mc je">循环单元</strong>从序列数据中学习。LSTMs 也是。然而，在这两者之间，循环单元内部发生的事情是非常不同的。</p><p id="cf81" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">查看标准 RNN 的简化递归单位图(未显示权重和偏差)，我们注意到只有两个主要操作:将先前的隐藏状态与新的输入相结合，并将其传递给激活函数:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ou"><img src="../Images/688260265c0d236a22509c739e0c68c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yo6sBAs6NUtNI0a16ZqZKQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">标准 RNN 循环单位。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="4332" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">在时间步长 t 计算隐藏状态后，它被<strong class="mc je">传回递归单元</strong>并与时间步长 t+1 的输入组合，以计算时间步长 t+1 的新隐藏状态。对 t+2、t+3、…、t+n 重复该过程，直到达到预定数量(n)的时间步长。</p><p id="e2b5" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">与此同时，LSTM 利用各种关口来决定保留或丢弃哪些信息。还有，它增加了一个<strong class="mc je">细胞状态</strong>，就像是 LSTM 的长期记忆。所以让我们仔细看看。</p><h2 id="5916" class="oj lj iu bd lk ok ol dn lo om on dp ls mj oo op lu mn oq or lw mr os ot ly ja bi translated">LSTM 是如何工作的？</h2><p id="1250" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">LSTM 递归单元比 RNN 复杂得多，提高了学习，但需要更多的计算资源。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ov"><img src="../Images/cdd2e87a5ca31f302d68277b6ec17492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zrht4QBK5_hAxif17ED4ew.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">LSTM 循环股。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="cf34" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">让我们通过简图(未显示权重和偏差)来了解 LSTM 循环单位是如何处理信息的。</p><ol class=""><li id="eaf7" class="nc nd iu mc b md mw mg mx mj ow mn ox mr oy mv oz ni nj nk bi translated"><strong class="mc je">隐藏状态&amp;新输入</strong> —来自前一时间步(h_t-1)的隐藏状态和当前时间步(x_t)的输入在通过各种门传递其副本之前被组合。</li><li id="6897" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv oz ni nj nk bi translated"><strong class="mc je">遗忘之门</strong> —这个门控制着什么信息应该被遗忘。因为 sigmoid 函数的范围在 0 和 1 之间，所以它设置单元状态中的哪些值应该被丢弃(乘以 0)、记住(乘以 1)或部分记住(乘以 0 和 1 之间的某个值)。</li><li id="6513" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv oz ni nj nk bi translated"><strong class="mc je">输入门</strong>有助于识别需要添加到单元状态的重要元素。注意，输入门的结果乘以单元状态候选，只有输入门认为重要的信息被添加到单元状态。</li><li id="52f2" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv oz ni nj nk bi translated"><strong class="mc je">更新单元状态</strong>—首先，前一个单元状态(c_t-1)乘以遗忘门的结果。然后我们从[输入门×单元状态候选]中加入新的信息，得到最新的单元状态(c_t)。</li><li id="4b41" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv oz ni nj nk bi translated"><strong class="mc je">更新隐藏状态</strong> —最后一部分是更新隐藏状态。最新的单元状态(c_t)通过 tanh 激活函数，并乘以输出门的结果。</li></ol><p id="7743" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">最后，最新的单元状态(c_t)和隐藏状态(h_t)回到递归单元，并且在时间步长 t+1 重复<strong class="mc je">过程。循环继续，直到我们到达序列的末尾。</strong></p><div class="kt ku kv kw gu ab cb"><figure class="pa kx pb pc pd pe pf paragraph-image"><a href="https://solclover.com/membership"><img src="../Images/63320331b74bd98eea6402472b4209ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qkXay39OnVc2IosW6rkxtw.png"/></a></figure><figure class="pa kx pb pc pd pe pf paragraph-image"><a href="https://www.linkedin.com/in/saulius-dobilas/"><img src="../Images/60fb21d1cb2701bfb6b71f61c99403e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vabxOXtQ4T034N_mscHSmQ.png"/></a></figure></div><h1 id="fbb5" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated"><strong class="ak">一个完整的 Python 例子，展示了如何构建和训练你自己的 LSTM 模型</strong></h1><p id="f7e8" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">我们可以以四种不同的方式使用 LSTMs:</p><ul class=""><li id="6d61" class="nc nd iu mc b md mw mg mx mj ow mn ox mr oy mv nh ni nj nk bi translated"><strong class="mc je">一对一</strong> —理论上是可能的，但是如果一个项目不是一个序列，你就不会得到 LSTMs 提供的任何好处。因此，在这种情况下，最好使用<a class="ae nb" rel="noopener" target="_blank" href="/feed-forward-neural-networks-how-to-successfully-build-them-in-python-74503409d99a">前馈神经网络</a>。</li><li id="9696" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><strong class="mc je">多对一</strong> —使用一系列值来预测下一个值。你可以在我的<a class="ae nb" rel="noopener" target="_blank" href="/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92"> RNN 文章</a>中找到这种设置的 Python 例子。</li><li id="f735" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><strong class="mc je">一对多</strong> —使用一个值预测一系列值。</li><li id="cb33" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><strong class="mc je">多对多</strong> —使用一个值序列来预测下一个值序列。我们现在将构建一个多对多的 LSTM。</li></ul><h2 id="e1e5" class="oj lj iu bd lk ok ol dn lo om on dp ls mj oo op lu mn oq or lw mr os ot ly ja bi translated">设置</h2><p id="ad18" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">获取以下数据和库:</p><ul class=""><li id="a014" class="nc nd iu mc b md mw mg mx mj ow mn ox mr oy mv nh ni nj nk bi translated"><a class="ae nb" href="https://www.kaggle.com/jsphyg/weather-dataset-rattle-package" rel="noopener ugc nofollow" target="_blank">澳大利亚天气数据来自 Kaggle </a>(许可:<a class="ae nb" href="http://www.bom.gov.au/other/copyright.shtml?ref=ftr" rel="noopener ugc nofollow" target="_blank"> Creative Commons </a>，数据原始来源:<a class="ae nb" href="http://www.bom.gov.au/climate/data/" rel="noopener ugc nofollow" target="_blank">澳大利亚联邦，气象局</a>)。</li><li id="2992" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><a class="ae nb" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank">熊猫</a>和<a class="ae nb" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> Numpy </a>用于数据操作</li><li id="b5ed" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><a class="ae nb" href="https://plotly.com/python/" rel="noopener ugc nofollow" target="_blank"> Plotly </a>用于数据可视化</li><li id="5489" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><a class="ae nb" href="https://www.tensorflow.org/api_docs/python/tf" rel="noopener ugc nofollow" target="_blank">用于 LSTM 神经网络的 Tensorflow/Keras </a></li><li id="8c25" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated"><a class="ae nb" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">Scikit-学习库</a>用于数据缩放(<a class="ae nb" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html" rel="noopener ugc nofollow" target="_blank"> MinMaxScaler </a> ) — <em class="ns">可选</em></li></ul><p id="c2c1" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">让我们导入所有库:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><p id="2662" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">上面的代码打印了我在这个例子中使用的包版本:</p><pre class="kt ku kv kw gu ph pi pj pk aw pl bi"><span id="4d47" class="oj lj iu pi b gz pm pn l po pp">Tensorflow/Keras: 2.7.0<br/>pandas: 1.3.4<br/>numpy: 1.21.4<br/>sklearn: 1.0.1<br/>plotly: 5.4.0</span></pre><p id="b75a" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">接下来，下载并摄取澳大利亚的天气数据(来源:<a class="ae nb" href="https://www.kaggle.com/jsphyg/weather-dataset-rattle-package" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>)。我们只接收列的子集，因为我们的模型不需要整个数据集。</p><p id="5c72" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">此外，我们执行一些简单的数据操作，并得出几个新的变量:年月和中值温度。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pq"><img src="../Images/51553fff5c401cb5d25a40a9451b0c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J3SjpNjBXB7NLLcuXl2ekw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">一小段<a class="ae nb" href="https://www.kaggle.com/jsphyg/weather-dataset-rattle-package" rel="noopener ugc nofollow" target="_blank"> Kaggle 的澳大利亚天气数据</a>做了一些修改。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="2aea" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">目前，我们对每个地点和日期都有一个中值温度记录。然而，每天的温度波动很大，使得预测更加困难。因此，让我们计算月平均值，并将数据转置为以地点为行，以年月为列。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pr"><img src="../Images/a68debe4b9ff65df3fe6ae7c453cc47b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wSGmRfPhVwvsA9Rlg7cU8g.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">按地点和月份划分的月平均温度。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="8d5e" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">由于我们使用的是现实生活中的数据，我们注意到三个月(2011 年 4 月、2012 年 12 月和 2013 年 2 月)完全从数据框架中消失了。因此，我们通过取前一个月和后一个月的平均值来估算缺失月份的值。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><p id="daf7" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">最后，我们可以在图表上绘制数据。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ps"><img src="../Images/b27bd52260fb777295b9f9a82b483904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6BL8vdXvILNCwYidkWHICA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">月平均气温。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="3d1b" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">该图最初显示了所有地点，但我选择了其中的四个(堪培拉、达尔文、黄金海岸和吉尼火山)显示在上图中。</p><p id="a456" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">请注意不同地点的平均温度以及温度变化是如何不同的。我们可以训练一个特定位置的模型以获得更高的精度，也可以训练一个通用模型来预测每个地区的温度。</p><p id="bdd4" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">在这个例子中，我将在一个地点(坎培拉)训练我们的 LSTM 模型。如果你对一个通用模型感兴趣，你可以看看我关于<a class="ae nb" rel="noopener" target="_blank" href="/gru-recurrent-neural-networks-a-smart-way-to-predict-sequences-in-python-80864e4fe9f6">门控循环单元(GRU) </a>的后续文章。</p><h2 id="bea3" class="oj lj iu bd lk ok ol dn lo om on dp ls mj oo op lu mn oq or lw mr os ot ly ja bi translated">训练和评估 LSTM 模型</h2><p id="2079" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">在我们开始之前，这里有一些需要强调的事情。</p><ul class=""><li id="1ede" class="nc nd iu mc b md mw mg mx mj ow mn ox mr oy mv nh ni nj nk bi translated">我们将使用 18 个月的序列来预测未来 18 个月的平均气温。您可以根据自己的喜好进行调整，但要注意，对于长度超过 23 个月的序列，将没有足够的数据。</li><li id="7cda" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">我们将把数据分成两个独立的数据帧——一个用于训练，另一个用于验证(<strong class="mc je">超时</strong>验证)。</li><li id="e803" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">由于我们正在创建一个<strong class="mc je">多对多</strong>预测模型，我们需要使用一个稍微复杂一点的<strong class="mc je">编码器-解码器</strong>配置。编码器和解码器都是隐藏的 LSTM 层，信息通过<strong class="mc je">重复向量</strong>层从一个层传递到另一个层。</li><li id="6bf0" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">当我们想要有不同长度的序列时，例如，一个 18 个月的序列来预测接下来的 12 个月，一个<strong class="mc je">重复向量</strong>是必要的。它确保我们为解码器层提供正确的形状。然而，如果您的输入和输出序列的长度与我的示例中的长度相同，那么您也可以选择在编码器层中设置<em class="ns"> return_sequences=True </em>并移除重复向量。</li><li id="ebe2" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">注意，我们给 LSTM 层添加了一个双向<strong class="mc je">包装器。它允许我们在两个方向上训练模型，这有时会产生更好的结果。但是，它的用途是<strong class="mc je">可选的<em class="ns">。</em>T19】</strong></strong></li><li id="3487" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">此外，我们需要在输出层使用一个<strong class="mc je">时间分布</strong>包装器来单独预测每个时间步长的输出。</li><li id="a77d" class="nc nd iu mc b md nl mg nm mj nn mn no mr np mv nh ni nj nk bi translated">最后，请注意，我在这个示例中使用了未缩放的数据，因为它比使用缩放数据(MinMaxScaler)训练的模型产生了更好的结果。你可以在我的 GitHub 库<em class="ns">(文章末尾有链接)</em>的 Jupyter 笔记本中找到缩放和未缩放的版本。</li></ul><p id="719f" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">首先，让我们定义一个 helper 函数，将数据整形为 LSTMs 所需的 3D 数组。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><p id="caa9" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">接下来，我们训练 LSTM 神经网络超过 1，000 个时期，并显示带有评估指标的模型摘要。您可以按照我在代码中的注释来理解每一步。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><p id="ab42" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">上述代码为我们的 LSTM 神经网络打印了以下摘要和评估指标(注意，由于神经网络训练的随机性，您的结果可能会有所不同):</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pt"><img src="../Images/2ee2916fbd5c4939315f5e2e8996d6b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5KN30bwZPKgbJnjeJiae1g.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">LSTM 神经网络性能。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="b993" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">现在让我们将结果绘制在图表上，以比较实际值和预测值。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="pg nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pu"><img src="../Images/cf9aa0a37e65b13fd752d3287d296c1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cau7vUfLC1CAAX-r5lsPLA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">LSTM 神经网络预测与实际。图片由<a class="ae nb" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="5f90" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">看起来我们在预测堪培拉月平均气温的探索中已经相对成功了。看看你是否能为一个不同的澳大利亚城市得到更好的结果！</p><h1 id="273e" class="li lj iu bd lk ll lm ln lo lp lq lr ls kj lt kk lu km lv kn lw kp lx kq ly lz bi translated">结束语</h1><p id="57e4" class="pw-post-body-paragraph ma mb iu mc b md me ke mf mg mh kh mi mj mk ml mm mn mo mp mq mr ms mt mu mv in bi translated">我真诚地希望你喜欢阅读这篇文章，并获得一些新的知识。</p><p id="1fff" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">你可以在我的<a class="ae nb" href="https://github.com/SolClover/Art044_NN_LSTM" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到完整的 Jupyter 笔记本代码。请随意使用它来构建您自己的 LSTM 神经网络，如果您有任何问题或建议，请不要犹豫与我们联系。</p><p id="cb16" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">干杯！👏<br/>T5【索尔多比拉斯】T6】</p></div><div class="ab cl pv pw hy px" role="separator"><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa qb"/><span class="py bw bk pz qa"/></div><div class="in io ip iq ir"><p id="1bc2" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated"><strong class="mc je"> <em class="ns">如果你已经花光了这个月的学习预算，下次请记得我。</em> </strong> <em class="ns">我的个性化链接加入媒介:</em></p><div class="qc qd gq gs qe qf"><a href="https://solclover.com/membership" rel="noopener  ugc nofollow" target="_blank"><div class="qg ab fp"><div class="qh ab qi cl cj qj"><h2 class="bd je gz z fq qk fs ft ql fv fx jd bi translated">通过我的推荐链接加入 Medium 索尔·多比拉斯</h2><div class="qm l"><h3 class="bd b gz z fq qk fs ft ql fv fx dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qn l"><p class="bd b dl z fq qk fs ft ql fv fx dk translated">solclover.com</p></div></div><div class="qo l"><div class="qp l qq qr qs qo qt lc qf"/></div></div></a></div><p id="9f4a" class="pw-post-body-paragraph ma mb iu mc b md mw ke mf mg mx kh mi mj my ml mm mn mz mp mq mr na mt mu mv in bi translated">您可能感兴趣的其他文章:</p><div class="qc qd gq gs qe qf"><a rel="noopener follow" target="_blank" href="/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92"><div class="qg ab fp"><div class="qh ab qi cl cj qj"><h2 class="bd je gz z fq qk fs ft ql fv fx jd bi translated">RNN:递归神经网络——如何在 Python 中成功地对序列数据建模</h2><div class="qm l"><h3 class="bd b gz z fq qk fs ft ql fv fx dk translated">rnn 的可视化解释和使用 Keras 和 Tensorflow Python 库构建它们的逐步指南</h3></div><div class="qn l"><p class="bd b dl z fq qk fs ft ql fv fx dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qu l qq qr qs qo qt lc qf"/></div></div></a></div><div class="qc qd gq gs qe qf"><a rel="noopener follow" target="_blank" href="/feed-forward-neural-networks-how-to-successfully-build-them-in-python-74503409d99a"><div class="qg ab fp"><div class="qh ab qi cl cj qj"><h2 class="bd je gz z fq qk fs ft ql fv fx jd bi translated">前馈神经网络——如何在 Python 中成功构建它们</h2><div class="qm l"><h3 class="bd b gz z fq qk fs ft ql fv fx dk translated">使用真实数据的 Python 示例对神经网络进行了详细的图形说明</h3></div><div class="qn l"><p class="bd b dl z fq qk fs ft ql fv fx dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qv l qq qr qs qo qt lc qf"/></div></div></a></div><div class="qc qd gq gs qe qf"><a rel="noopener follow" target="_blank" href="/deep-feed-forward-neural-networks-and-the-advantage-of-relu-activation-function-ff881e58a635"><div class="qg ab fp"><div class="qh ab qi cl cj qj"><h2 class="bd je gz z fq qk fs ft ql fv fx jd bi translated">深度前馈神经网络及其再激活函数的优势</h2><div class="qm l"><h3 class="bd b gz z fq qk fs ft ql fv fx dk translated">如何使用 Tensorflow Keras API 在 Python 中构建深度前馈(DFF)神经网络，以及如何在…</h3></div><div class="qn l"><p class="bd b dl z fq qk fs ft ql fv fx dk translated">towardsdatascience.com</p></div></div><div class="qo l"><div class="qw l qq qr qs qo qt lc qf"/></div></div></a></div></div></div>    
</body>
</html>