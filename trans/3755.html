<html>
<head>
<title>Training from Cloud Storage with S5cmd</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用S5cmd从云存储进行培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-from-cloud-storage-with-s5cmd-5c8fb5c06056#2022-08-21">https://towardsdatascience.com/training-from-cloud-storage-with-s5cmd-5c8fb5c06056#2022-08-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="88e6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用数百万个小的、单一的样本文件进行训练</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e7c28e858baa051a732998004d4d61a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*km3cSD1wBV8VtiH9"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">鲁本·米什丘克在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="51d2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在典型的深度学习训练管道中，数据样本从存储位置迭代加载，并馈入机器学习模型。模型<em class="ls">从这些样本中学习</em>，并相应地更新其参数。因此，每个训练步骤的速度以及建模收敛的总时间直接受到从存储中加载数据样本的速度的影响。数据加载速度又会受到多种因素的影响，包括:</p><ol class=""><li id="64f6" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated"><strong class="ky ir">数据位置</strong>:数据的位置及其与训练机器的距离会影响数据加载的延迟。</li><li id="5502" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">带宽</strong>:存储位置和训练机器之间的通信信道的带宽将决定数据可以被拉取的最大速度。</li><li id="cccd" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">样本大小</strong>:每个数据样本的大小会影响需要传输的总字节数。</li><li id="dc41" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">压缩</strong>:注意，虽然压缩您的数据会减少样本数据的大小，但它也会在训练实例上添加一个解压缩步骤。</li><li id="e690" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">数据格式</strong>:样本存储的格式会直接影响数据加载的开销。</li><li id="e645" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">文件大小</strong>:组成数据集的文件大小会影响从数据存储中提取的数量。大小可以由分组到文件中的样本数量来控制。</li><li id="96cb" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><strong class="ky ir">软件堆栈</strong>:从存储器中提取数据时，软件实用程序表现出不同的性能行为。除其他因素外，这些行为还取决于系统资源的利用效率。</li></ol><p id="b229" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">您选择存储数据的方式会对您的训练</strong>工作量的运行时性能产生有意义的影响，因此应该进行相应的设计。</p><p id="2935" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们以前的几篇文章已经致力于存储训练数据的不同选项(例如这里的<a class="ae kv" rel="noopener" target="_blank" href="/data-formats-for-training-in-tensorflow-parquet-petastorm-feather-and-more-e55179eeeb72"/>)和将它流式传输到训练会话中(例如这里的<a class="ae kv" rel="noopener" target="_blank" href="/training-in-pytorch-from-amazon-s3-6156d5342d1"/>、这里的<a class="ae kv" href="https://julsimon.medium.com/deep-dive-on-tensorflow-training-with-amazon-sagemaker-and-amazon-s3-12038828075c" rel="noopener"/>和这里的<a class="ae kv" rel="noopener" target="_blank" href="/amazon-sagemaker-fast-file-mode-d12829479c39"/>)。像以前一样，我们将假设我们的数据集如此之大，以至于将其全部下载到训练实例上是不切实际的，甚至是不可能的。</p><p id="cd59" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们之前的帖子中，我们遵循了将样本分组到大约100兆字节大小的文件中的传统智慧，作为优化从云存储中提取数据的一种方法。我们在这篇文章中的意图是评估消除这一限制的成本。具体来说，我们将探索在将数据保存在小的单个样本对象文件中而不是将它们组合在一起时可以实现的运行时性能。</p><p id="7428" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然我们将进行的实验将使用AWS提供的云服务(<a class="ae kv" href="https://aws.amazon.com/s3/" rel="noopener ugc nofollow" target="_blank">亚马逊S3 </a>、<a class="ae kv" href="https://aws.amazon.com/ec2/" rel="noopener ugc nofollow" target="_blank">亚马逊EC2 </a>和<a class="ae kv" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker </a>)，并将使用PyTorch(版本1.12)进行编程，但我们将得出的结论也适用于其他云环境和其他培训框架。我们将演示几个将单个样本文件从亚马逊S3流式传输到培训会话的选项。我们提到的这种或那种方法不应被解释为认可。其他方法可能表现出更好的性能，我们提到的方法的性能可能会随着API的增强和优化而改变。此外，请记住，运行时性能可能会因项目细节而有很大差异，我们将分享的比较结果可能不会应用到您自己的项目中。简而言之——对我们写的所有东西都要有所保留，并确保在做出任何设计决定之前进行自己的全面评估。</p><p id="f3c3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">特别感谢<a class="ae kv" href="https://www.linkedin.com/in/nadav-shaag-a77a8b104/?originalSubdomain=il" rel="noopener ugc nofollow" target="_blank"> Nadav Shaag </a>对本帖的贡献。</p><h1 id="ce0d" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">动机——为什么要存储单独的训练样本？</h1><p id="635d" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">您可能希望以单个样本的形式维护数据，而不是将它们分组到大文件中，原因有很多。</p><h2 id="8fda" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated">原始数据格式</h2><p id="d0fd" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">让我们面对现实吧——采用一种能够满足所有数据消费者需求和愿望的文件格式确实令人头疼。单独存储数据样本使您能够以原始格式维护它们。以下是坚持原始格式的一些优势:</p><ul class=""><li id="8627" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr nq lz ma mb bi translated">数据格式转换通常意味着数据丢失。例如，如果出于训练目的转换数据，您可以选择忽略每个样本的某些属性，只保留训练任务所需的属性，但随后会发现不同的任务需要其中一个被忽略的属性。通过以原始格式维护您的数据，您可以确保数据的完整性并保持最大的灵活性。</li><li id="a3b8" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nq lz ma mb bi translated">作为开发过程中的一个额外步骤，数据格式转换的过程会增加代码的复杂性和出错的可能性。此外，无论何时选择添加或更新数据样本，都需要重新运行格式转换步骤，然后才能使用新数据。去除格式转换步骤可以<strong class="ky ir">简化你的开发流程</strong>并减少延迟。</li><li id="aa25" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr nq lz ma mb bi translated">有时，您可能会发现自己需要维护多种重叠的数据格式，以满足多个数据消费者的需求。除了这种冗余带来的麻烦之外，它还会显著增加您的存储成本。以原始格式维护数据的单一副本可以<strong class="ky ir">简化数据管理并降低成本</strong>。</li></ul><h2 id="d1a1" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated">随机存取</h2><p id="5d49" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">当您的数据样本单独存储时，很容易随机访问它们中的任何一个。相比之下，当样本被分组到文件中时，随机访问其中的任何一个都是困难的。您选择的文件格式可能不支持这种随机访问，即使支持，也可能需要您仔细记录您的样本是如何分组的。此外，从大文件中提取单个记录会产生开销，可能会对运行时性能产生负面影响。在深度学习训练工作负载中，对数据进行随机访问的需求是常见的，尽管有一些方法可以解决在将样本分组到更大的文件中时缺乏这种需求的问题(参见此处的<a class="ae kv" href="https://julsimon.medium.com/making-amazon-sagemaker-and-tensorflow-work-for-you-893365184233" rel="noopener"/>)，但这些方法并不完美。</p><h2 id="366e" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated">减少数据重复</h2><p id="bb53" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">我们已经提到了以一种或多种格式维护数据的多个重叠副本所导致的数据重复。当每个训练样本(即输入到模型中的每个样本)由多个原始样本组成时，就会出现另一个潜在的重复源。例如，如果您正在处理一个计算机视觉模型，该模型正在被训练以根据视频中的帧序列进行预测(例如，光流或运动结构)，任何给定的帧(原始样本)都可能出现在序列中不同位置的多个<em class="ls">训练样本</em>(帧序列)中。如果你的序列长度是<em class="ls"> N </em>，你可能会发现你的训练数据的大小是你的原始数据总大小的<em class="ls"> N </em>倍。相比之下，如果您的数据存储为单个样本(帧)文件，您的存储成本将降低<em class="ls"> N </em>倍。在这种情况下，组成<em class="ls"> N </em>序列的各个帧将在训练期间被加载并分组在一起。</p><p id="672c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当然，将数据保存为单独的文件也有其缺点。根据单个样本的大小，存储中的文件数量可能会急剧增加。如果<a class="ae kv" href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/optimizing-performance.html" rel="noopener ugc nofollow" target="_blank">管理不当</a>，这可能导致节流问题、运行列表查询的延迟(例如<em class="ls"> aws s3 ls </em>)等。如果您之前在每个文件中分组了<em class="ls"> N </em>个样本，您将需要在培训期间下载<em class="ls"> N </em>倍数量的文件。这增加的潜在开销可能会降低数据加载管道的速度，并在您的培训中引入瓶颈。在接下来的几节中，我们将探索从单样本文件进行训练的几种选择，并将它们的性能与推荐的将样本分组到大约100兆字节的文件中的方法进行比较。</p><h1 id="1cbd" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">方法</h1><p id="e705" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">我们在这篇文章中探讨的选项包括将数据直接从云存储传输到训练循环中。其他选项超出了本文的范围，可能需要建立一个由一个或多个服务器组成的集群，专门管理对您的数据存储的访问(例如<a class="ae kv" href="https://github.com/NVIDIA/aistore" rel="noopener ugc nofollow" target="_blank"> AIStore </a>)，或者使用额外的专用数据检索服务来增强您的云架构(例如<a class="ae kv" href="https://aws.amazon.com/fsx/" rel="noopener ugc nofollow" target="_blank"> Amazon FSx </a>)。虽然这种选择可能导致更快的培训吞吐量，但是它们也需要更高的成本，并且需要更大的努力来设置、配置和维护。</p><h2 id="3227" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated"><strong class="ak"> Boto3 </strong></h2><p id="dda4" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">将文件从亚马逊S3流式传输到您的训练循环中最直接的方法是使用<a class="ae kv" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Boto3 </a> Python库。下面的代码块演示了如何将文件数据的内容提取到本地内存的字节流中。假设样本是成对的图像和标签文件。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="12ba" class="ne mi iq ns b gy nw nx l ny nz">from torch.utils.data import Dataset<br/>import boto3, io, re, os<br/>class BotoSingleSampleDataset(Dataset):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.base_path = &lt;path to data in S3&gt;<br/>        self.client = boto3.client("s3")</span><span id="7d58" class="ne mi iq ns b gy oa nx l ny nz">    def __len__(self):<br/>        return 100000<br/><br/>    def get_bytes_io(self, path):<br/>        byte_io = io.BytesIO()<br/>        _, bucket, key, _ = re.split("s3://(.*?)/(.*)$", path)<br/>        self.client.download_fileobj(bucket, key, byte_io)<br/>        byte_io.seek(0)<br/>        return byte_io<br/><br/>    def __getitem__(self, index: int):<br/>        image_path = f'{self.base_path}/{index}.image'<br/>        label_path = f'{self.base_path}/{index}.label'<br/>        image = self.get_bytes_io(image_path).read()<br/>        label = self.get_bytes_io(label_path).read()<br/>        return {"image": image, "label": label}</span><span id="4262" class="ne mi iq ns b gy oa nx l ny nz">def get_dataset_and_sampler():<br/>    ds = BotoSingleSampleDataset()<br/>    return ds, None</span></pre><h2 id="15be" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated"><strong class="ak">亚马逊SageMaker快速文件模式</strong></h2><p id="fe0d" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><a class="ae kv" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">亚马逊SageMaker </strong> </a> <strong class="ky ir"> </strong>提供了一个基于<a class="ae kv" href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace" rel="noopener ugc nofollow" target="_blank"> FUSE </a>的解决方案，用于访问S3的文件，称为<em class="ls">快速文件模式</em> (FFM)。当您对SageMaker作业进行编程以使用快速文件输入模式时，S3路径会挂载到预定义的本地文件路径上。在最近的一篇文章中，我们扩展了这个输入模式选项，演示了它的用法，并讨论了它的优缺点。下面的代码块演示了如何基于使用Amazon SageMaker快速文件模式访问的单个数据样本创建PyTorch数据集:</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="8587" class="ne mi iq ns b gy nw nx l ny nz">from torch.utils.data import Dataset<br/>import os<br/>class FFMSingleSampleDataset(Dataset):<br/>    def __init__(self):<br/>        super().__init__()<br/>        self.base_path = os.environ['SM_CHANNEL_TRAINING']<br/><br/>    def __len__(self):<br/>        return 100000<br/><br/>    def get_from_files(self, image_path, label_path):<br/>        image_file = open(image_path, 'rb')<br/>        label_file = open(label_path, 'rb')<br/>        image = image_file.read()<br/>        label = label_file.read()<br/>        image_file.close()<br/>        label_file.close()<br/>        return {"image": image, "label": label}<br/><br/>    def __getitem__(self, index: int):<br/>        index = index%10000<br/>        image_path = os.path.join(self.base_path, f'{index}.image')<br/>        label_path = os.path.join(self.base_path, f'{index}.label')<br/>        return self.get_from_files(image_path, label_path)</span><span id="b3ca" class="ne mi iq ns b gy oa nx l ny nz">def get_dataset_and_sampler():<br/>    ds = FFMSingleSampleDataset()<br/>    return ds, None</span></pre><h2 id="fe55" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated"><strong class="ak"> S5cmd </strong></h2><p id="43f8" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/peak/s5cmd" rel="noopener ugc nofollow" target="_blank"> S5cmd </a>是一个命令行工具，用于从亚马逊S3获取对象。用<a class="ae kv" href="https://go.dev/" rel="noopener ugc nofollow" target="_blank"> Go编程语言</a>编写的S5cmd非常依赖多线程和多个TCP连接的使用来加速来自S3的数据传输。查看这个信息丰富的博客了解更多关于s5cmd如何工作及其性能优势的细节。</p><p id="a464" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下面的代码块中，我们定义了一个自定义PyTorch采样器，它运行一个后台进程，一次对1000个样本异步调用s5cmd。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="9e81" class="ne mi iq ns b gy nw nx l ny nz">from torch.utils.data import Dataset<br/>from torch.utils.data import SequentialSampler<br/>import os, threading, shlex, time<br/>from subprocess import Popen</span><span id="147f" class="ne mi iq ns b gy oa nx l ny nz"><strong class="ns ir">samples_per_call = 1000<br/></strong>rank = 0 # in case of multi-gpu, get the local rank<strong class="ns ir"><br/></strong>local_path = f'/tmp/{rank}' # local path to download files to<br/>base_path = &lt;path to files in S3&gt;<br/><br/>class S5cmdSampler(SequentialSampler):<br/>    def __init__(self, data_source, shuffle=False):<br/>        super().__init__(data_source)<br/>        self.shuffle = shuffle</span><span id="b2ce" class="ne mi iq ns b gy oa nx l ny nz">    def load_sample_files(self, handle, indices):<br/>        all_files = []<br/>        for i in indices:<br/>            all_files.append(f'{local_path}/{i}.image')<br/>            all_files.append(f'{local_path}/{i}.label')<br/>        cmd_txt = os.path.join(local_path, f'{handle}.txt')<br/>        with open(cmd_txt, "w") as f:<br/>            for fp in all_files:<br/>                c = f'cp {fp} {fp.replace(base_path,local_path)}\n')<br/>                f.write(c) # add command to list of commands<br/>        s5cmd = f's5cmd --log error run {cmd_txt}'<br/>        p = Popen(shlex.split(s5cmd))<br/>        return p<br/><br/>    def __iter__(self):<br/>        n = len(self.data_source)<br/>        if self.shuffle:<br/>            import torch<br/>            r = torch.empty((), dtype=torch.int64).random_()               <br/>            seed=int(r.item())<br/>            generator = torch.Generator()<br/>            generator.manual_seed(seed)<br/>            slist = torch.randperm(n, generator=generator)<br/>            slist = slist.tolist()<br/>        else:<br/>            slist = list(range(n))<br/>        procs = [None, None]<br/>        sublists = [None, None]<br/>        proc_index = 0<br/>        list_index = 0<br/>        end_index = min(list_index + <strong class="ns ir">samples_per_call</strong>, n)<br/>        sublists[proc_index] = slist[list_index:end_index]<br/>        procs[proc_index] = self.load_sample_files(<br/>                                 handle=proc_index, <br/>                                 indices=sublists[proc_index])<br/>        while list_index &lt; n:<br/>            list_index = end_index<br/>            if list_index &lt; n:<br/>                <em class="ls"># extract next batch<br/>                </em>end_index = min(list_index + <strong class="ns ir">samples_per_call</strong>, n)<br/>                sublists[1-proc_index] = slist[list_index:end_index]<br/>                procs[1-proc_index] = self.load_sample_files(<br/>                                handle=1-proc_index,<br/>                                indices=sublists[1-proc_index])<br/>            counter = 0<br/>            while procs[proc_index].poll() is None:<br/>                counter = counter + 1<br/>                time.sleep(0.1)<br/>                if counter == 10:<br/>                    print('data starvation')<br/>            sublist = sublists[proc_index]<br/>            proc_index = 1 - proc_index<br/>            yield from sublist</span><span id="830a" class="ne mi iq ns b gy oa nx l ny nz">def release_files(file_list):<br/>    def delete_files(files):<br/>        for file in files:<br/>            if os.path.exists(file):<br/>                os.remove(file)<br/>    threading.Thread(target=lambda: delete_files(file_list)).start()</span><span id="d7cb" class="ne mi iq ns b gy oa nx l ny nz">class S5cmdDataset(Dataset):<br/>    def __init__(self):<br/>        super().__init__()</span><span id="b887" class="ne mi iq ns b gy oa nx l ny nz">    def __len__(self):<br/>        return 100000</span><span id="2607" class="ne mi iq ns b gy oa nx l ny nz">    def get_from_files(self, image_path, label_path):<br/>        image_file = open(image_path, 'rb')<br/>        label_file = open(label_path, 'rb')<br/>        image = image_file.read()<br/>        label = label_file.read()<br/>        image_file.close()<br/>        label_file.close()<br/>        return {"image": image, "label": label}</span><span id="7038" class="ne mi iq ns b gy oa nx l ny nz">    def __getitem__(self, index: int):<br/>        index = index % 10000<br/>        image_path = os.path.join(local_path, f'{index}.image')<br/>        label_path = os.path.join(local_path, f'{index}.label')<br/>        ret = self.get_from_files(image_path,label_path)<br/>        release_files([image_path, label_path])<br/>        return ret</span><span id="ede6" class="ne mi iq ns b gy oa nx l ny nz">def get_dataset_and_sampler():<br/>    ds = S5cmdDataset()<br/>    sampler = S5cmdSampler(ds)<br/>    return ds, sampler</span></pre><p id="7712" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在上面的例子中，我们将每个s5cmd调用的样本数设置为1000，并依赖于s5cmd的默认设置。很可能可以通过调整一些控制设置来进一步优化代码，特别是<a class="ae kv" href="https://github.com/peak/s5cmd#numworkers" rel="noopener ugc nofollow" target="_blank"><em class="ls">num workers</em></a><em class="ls"/>(控制并行S3命令的数量)和<a class="ae kv" href="https://github.com/peak/s5cmd#concurrency" rel="noopener ugc nofollow" target="_blank"> <em class="ls">并发</em> </a> <em class="ls"> </em>设置(控制如何分解单个文件的上传/下载)。</p><p id="c264" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们分享的示例中，我们选择将文件下载到本地磁盘(/tmp)，然后从同一位置加载它们。可以想象，您可以通过将文件对象直接放入内存来减少读写磁盘的开销。一种方法是使用<a class="ae kv" href="https://medium.com/p/5c8fb5c06056/edit" rel="noopener"> tmpfs </a>(例如/dev/shm)。</p><p id="a858" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，s5cmd所采用的高度并行处理可以用其他方式实现(包括Python)。然而，达到与s5cmd相同的性能水平可能并不那么简单。</p><h1 id="7af8" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">实验</h1><p id="d5e0" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">在本节中，我们使用一个<a class="ae kv" href="https://aws.amazon.com/ec2/instance-types/c5/" rel="noopener ugc nofollow" target="_blank"> Amazon EC2 c5.4xlarge </a>实例(有16个vCPUs)对一个玩具示例进行了一些实验。</p><p id="7b4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了只关注数据流的性能，我们将测量空训练步骤情况下的吞吐量，如下面的代码块所示。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="d587" class="ne mi iq ns b gy nw nx l ny nz">import torch, time<br/>from statistics import mean, variance</span><span id="cc92" class="ne mi iq ns b gy oa nx l ny nz">dataset, sampler = get_dataset_and_sampler()<br/>dl = torch.utils.data.DataLoader(dataset, sampler=sampler, <br/>                                 batch_size=4, num_workers=16)<br/>stats_lst = []<br/>t0 = time.perf_counter()<br/>for batch_idx, batch in enumerate(dl, start=1):<br/>    if batch_idx % 100 == 0:<br/>        t = time.perf_counter() - t0<br/>        print(f'Iteration {batch_idx} Time {t}')<br/>        stats_lst.append(t)<br/>        t0 = time.perf_counter()<br/>mean_calc = mean(stats_lst[1:])<br/>var_calc = variance(stats_lst[1:])<br/>print(f'mean {mean_calc} variance {var_calc}')</span></pre><p id="1b46" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请记住，虽然这种比较测量可能会让我们很好地了解每种方法可以支持的最大吞吐量，但它可能无法很好地预测您选择的方法将如何影响实际的培训吞吐量:</p><ol class=""><li id="3359" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">您选择的方法可能不会影响您的整体训练步骤时间。例如，如果您的培训步骤是计算密集型的，那么从S3提取一批样本需要1秒钟还是10秒钟可能没有区别。</li><li id="b82f" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">一个典型的培训步骤将包括许多额外的操作，这些操作可能会影响您的实际培训量。特别是，一些操作可能会争用从S3传输数据的相同资源。</li></ol><p id="6c7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">作为比较的基准，我们将使用我们在<a class="ae kv" rel="noopener" target="_blank" href="/training-in-pytorch-from-amazon-s3-6156d5342d1">这篇文章</a>中描述的相同的WebDataset示例。我们还使用相同的代码块来生成一个玩具图像数据集和相关的每像素标签。</p><pre class="kg kh ki kj gt nr ns nt nu aw nv bi"><span id="11a8" class="ne mi iq ns b gy nw nx l ny nz">import webdataset as wds<br/>import numpy as np<br/>from PIL import Image<br/>import ioout_tar = 'wds.tar'<br/>sink = wds.TarWriter(out_tar)<br/>im_width = 1024<br/>im_height = 1024<br/>num_classes = 256<br/>for i in range(100):<br/>    image = Image.fromarray(np.random.randint(0, high=256,<br/>                  size=(im_height,im_width,3), dtype=np.uint8))<br/>    label = Image.fromarray(np.random.randint(0, high=num_classes,<br/>                  size=(im_height,im_width), dtype=np.uint8))<br/>    image_bytes = io.BytesIO()<br/>    label_bytes = io.BytesIO()<br/>    image.save(image_bytes, format='PNG')<br/>    label.save(label_bytes, format='PNG')<br/>    sample = {"__key__": str(i),<br/>              f'image': image_bytes.getvalue(),<br/>              f'label': label_bytes.getvalue()}<br/>    sink.write(sample)</span></pre><h2 id="e7e7" class="ne mi iq bd mj nf ng dn mn nh ni dp mr lf nj nk mt lj nl nm mv ln nn no mx np bi translated">结果</h2><p id="1c55" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">这些结果旨在让您对可能看到的比较结果有所了解。请记住，根据许多项目细节，包括样本大小、批量大小等，结果会有很大差异。该表包括平均报告的步骤时间以及平均CPU利用率。CPU利用率给出了在真实(非空)训练循环的情况下选择的方法将引入CPU资源争用的可能性的一些指示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/f3c7333a8e25c8da4c0585ce9fbb1be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G67pT2igrw4jAcSxwKmS9A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">比较速度和CPU利用率(按作者)</p></figure><p id="f9f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">毫不奇怪，基于单个样本数据集的解决方案无法与基于WebDataset (WDS)的最佳结果(超过FFM)相媲美。根据您的模型的细节，这可能意味着较低的训练吞吐量。与此同时，s5cmd的价值非常明显，相比其他单个样品选项，其通量性能提高了约58%。使用tmpfs代替本地磁盘并没有带来任何额外的好处。使用s5cmd可以节省大约58%的培训成本。另一方面，在真实的训练循环中，CPU利用率增加2.6倍(与FFM相比)可能会减少整体节省。</p><h1 id="948c" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">摘要</h1><p id="3f7e" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">虽然单独存储数据样本比将数据样本分组到文件中有很多优点，但是您的训练吞吐量可能会因此而下降。它是否下降，以及下降的程度，可能取决于您用于将单个样本流式传输到您的训练实例的<strong class="ky ir">方法</strong>。如本文所示，s5cmd是一个强大的命令行实用程序，用于从S3提取数据，相对于评估的其他方法，它可以产生显著更高的吞吐量。</p><p id="7682" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如需更正、评论或问题，请随时联系我们。</p></div></div>    
</body>
</html>