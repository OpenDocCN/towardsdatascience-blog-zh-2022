<html>
<head>
<title>Avoid This Pitfall When Using LASSO and Ridge Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用套索和脊回归时避免这个陷阱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/avoid-this-pitfall-when-using-lasso-and-ridge-regression-f4f4948bfe70#2022-07-07">https://towardsdatascience.com/avoid-this-pitfall-when-using-lasso-and-ridge-regression-f4f4948bfe70#2022-07-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="df2f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">您的监管处罚可能针对错误的变量</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a4b562c8ad9a66013ad24dcd6b780faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*q1AS_Wlqd1n7PB7z"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">马库斯·斯皮斯克在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="cc6d" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在线性回归中，套索和岭正则化通常用于克服过度拟合并生成更健壮的模型。然而，当应用于不正确缩放的变量时，结果可能是灾难性的。</p><h1 id="0ec5" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">基本线性模型</strong></h1><p id="e322" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">假设我们有一个非常简单的线性模型，我们根据婚姻状况<code class="fe mz na nb nc b"> x_1 ∈ {0,1}</code> (1表示已婚)和年薪<code class="fe mz na nb nc b">x_2 ∈ R^+</code>(实数非负数)来预测预期寿命y。该模型如下所示:</p><p id="5eee" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><code class="fe mz na nb nc b">y=β_0+β_1x_1+β_2x_2+ϵ</code></p><blockquote class="nd ne nf"><p id="1e97" class="lg lh ng li b lj lk ju ll lm ln jx lo nh lq lr ls ni lu lv lw nj ly lz ma mb im bi translated">如果不熟悉术语:<code class="fe mz na nb nc b">y</code>为结果/自变量，<code class="fe mz na nb nc b">β_0</code>为常数，<code class="fe mz na nb nc b"><em class="it">β_i x_i</em></code> <strong class="li iu"> <em class="it"> </em> </strong>代表加权解释/因变量，<code class="fe mz na nb nc b">ϵ</code>为误差项/随机噪声。</p></blockquote><p id="feae" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">我们如何表达工资<code class="fe mz na nb nc b">x_2</code>？如果我们愿意，我们可以用美元($)，数千美元($k)，甚至美分($c)来表示。这里没有固有的对错。</p><p id="c841" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">虽然因变量的单位是用户确定的，但它对结果并不重要。如果我们决定将<code class="fe mz na nb nc b">x_2</code>从$改为$k，我们只需将<code class="fe mz na nb nc b">β_2 </code>乘以1000以保持相同的结果<code class="fe mz na nb nc b">y</code>。类似地，如果我们使用美分，我们将<code class="fe mz na nb nc b">β_2</code>除以100以保留结果。</p><p id="0fe0" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">目前为止路上没有颠簸，但让我们继续前进。</p><h1 id="7346" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">引入套索和脊</strong></h1><p id="7894" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">线性回归有许多问题，例如过度拟合。过度拟合意味着模型在训练集上表现良好，但在样本外数据上表现不佳。过度拟合的模型倾向于<strong class="li iu">使变量适应噪声</strong>，而不是识别真实的数据模式。</p><p id="395e" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">更准确地说，我们处理一个<strong class="li iu">偏差-方差权衡</strong>，高偏差意味着我们没有捕捉到相关的模式，高方差意味着我们适合不存在的模式。所谓的<strong class="li iu">规则化技术</strong>有助于平衡偏差和方差，套索和脊调节是最常用的技术。</p><p id="fea6" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">有关<strong class="li iu">套索和脊正规化</strong>的更深入讨论，请查看以下文章:</p><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/regulate-your-regression-model-with-ridge-lasso-and-elasticnet-92735e192e34"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">用脊线、套索和橡皮筋来调整你的回归模型</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">什么是正则化技术，我们为什么要使用它们？提供了一个Python sklearn示例。</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="nx l ny nz oa nw ob ks nn"/></div></div></a></div><p id="ae68" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">来对抗过度拟合。LASSO将以下惩罚(用红色标记)添加到基本回归程序中:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/25768d68757e27476547e0112530484c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MYSLq5QvMwLvzQYs6I3iFQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">套索正则化对绝对<code class="fe mz na nb nc b">β</code>值施加惩罚，导致许多权重被设置为0。</p></figure><p id="5a4a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由于绝对值<code class="fe mz na nb nc b">β</code>被罚，LASSO倾向于<strong class="li iu">将许多权重设置为0 </strong>。这个过程剔除了不太相关的变量，只保留了最显著的变量。</p><p id="ed76" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">岭正则化对<code class="fe mz na nb nc b">β</code>应用平方惩罚:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oc"><img src="../Images/a4a100ff76cbb6c11acb2f37469224bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67uwngWONojcyiExLK84hw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">岭正则化对平方的<code class="fe mz na nb nc b">β</code>值进行惩罚，从而产生相对较小(但非零)的权重。</p></figure><p id="cb04" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">由于平方a <code class="fe mz na nb nc b">β&lt;1</code>会降低其值(即0.0⁵ =0.0023)，岭回归倾向于在<code class="fe mz na nb nc b">β</code>值中更均匀地分配权重，而不是将它们完全设置为0。这将导致更可靠的预测。</p><h1 id="5a05" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">问题</strong></h1><p id="dc04" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">LASSO和ridge看起来是明智的技术，但它们只考虑了<code class="fe mz na nb nc b">β</code>的值，而忽略了相应的变量<code class="fe mz na nb nc b">x</code>。如果我们有以美分为单位的工资，LASSO可能会认为相应的贝塔系数很小，无足轻重，而以美元为单位的工资会产生一个大100，000倍的<code class="fe mz na nb nc b">β</code>！显然，<strong class="li iu">选择的单位对行为有巨大的影响</strong>。在一种情况下，变量似乎高度相关，在另一种情况下，它似乎可以忽略不计，尽管<code class="fe mz na nb nc b">β_i⋅x_i</code>在两种情况下产生相同的结果。</p><p id="114a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">当应用套索或山脊时，我们惩罚大的<code class="fe mz na nb nc b">β</code>值。由于数值变量的单位通常是任意的，因此<strong class="li iu">正则化的影响可能很大</strong>。因此，如果没有适当的变换，套索和山脊就不应该被应用。</p><h1 id="7b21" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">解决方案</strong></h1><p id="bf44" class="pw-post-body-paragraph lg lh it li b lj mu ju ll lm mv jx lo lp mw lr ls lt mx lv lw lx my lz ma mb im bi translated">那么，发现问题后，我们能做些什么来解决它呢？通常情况下，没有放之四海而皆准的解决方案，但是有相当标准的解决方案。</p><p id="84df" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">机器学习中的一个常见解决方案是将输入重新调整到[0，1]范围。为此，我们可以简单地将所有数据除以数据集中的最大值。如果数据分布合理，这种方法会非常有效。</p><p id="ab8a" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">然而，假设数据集中的一个幸运儿每年赚2000万美元。作为最高值，该条目将被设置为等于1($ 2000万/$ 2000万)。对于其他人，我们可能得到非常低的<code class="fe mz na nb nc b">x</code>值，例如，60$k/$20m=0.003。一个孤立点就能完全破坏这种规模。</p><p id="093f" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">在处理这种分布时，通常会执行对数转换。在这种情况下，我们将得到log(20m)=7.30103和log(60k)=4.30103。仍然有很大的差别，但远不如以前那么大。变量现在将分别缩放到1和0.59，与<code class="fe mz na nb nc b">β</code>相乘具有更全面的影响。</p><p id="752b" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">可以说，最合理的解决方案是转换变量，使所有<code class="fe mz na nb nc b">x_i </code>的期望值等于1(或其他常数)。请注意，这也意味着我们将重新调整虚拟变量(其平均值为<code class="fe mz na nb nc b">0 ≤ E(x_i) ≤ 1</code>)。如有必要，可以将围绕相同平均值的中心值与对数变换相结合。</p><p id="8688" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated">一旦每个变量都有相同的均值，我们就有了直接可比的<code class="fe mz na nb nc b">β</code>值。经过这种转换后，LASSO和Ridge将针对正确的变量，不再受到美分和美元的任意设置的阻碍。</p><h1 id="3b0b" class="mc md it bd me mf mg mh mi mj mk ml mm jz mn ka mo kc mp kd mq kf mr kg ms mt bi translated"><strong class="ak">外卖</strong></h1><ul class=""><li id="6fb2" class="od oe it li b lj mu lm mv lp of lt og lx oh mb oi oj ok ol bi translated">在回归模型中，<strong class="li iu">变量单位</strong>决定了相应<code class="fe mz na nb nc b">β</code>值的大小。为了保持因变量<code class="fe mz na nb nc b">x</code>和自变量<code class="fe mz na nb nc b">y</code>之间的关系不变，<code class="fe mz na nb nc b">β</code>的值随着<code class="fe mz na nb nc b">x</code>单位的增大而减小，反之亦然。</li><li id="6897" class="od oe it li b lj om lm on lp oo lt op lx oq mb oi oj ok ol bi translated">在线性回归中，<strong class="li iu">选择的变量单位</strong>通常影响有限，因为<code class="fe mz na nb nc b">β</code>的大小抵消了选择的单位。术语<code class="fe mz na nb nc b">β⋅ x</code>的结果保持不变，对输出<code class="fe mz na nb nc b">y</code>的贡献相等。</li><li id="d737" class="od oe it li b lj om lm on lp oo lt op lx oq mb oi oj ok ol bi translated">线性回归模型往往容易<strong class="li iu">过拟合</strong>。正则化技术如LASSO和Ridge引入了减轻这个问题的惩罚。</li><li id="7709" class="od oe it li b lj om lm on lp oo lt op lx oq mb oi oj ok ol bi translated">由于<strong class="li iu">套索和脊</strong>惩罚<code class="fe mz na nb nc b">β</code>值，变量<code class="fe mz na nb nc b">x</code>的选择单位高度相关。大<code class="fe mz na nb nc b">x</code>收益小<code class="fe mz na nb nc b">β</code>收益小，反之亦然，因此单位直接影响惩罚机制。影响可能相当大。</li><li id="95a4" class="od oe it li b lj om lm on lp oo lt op lx oq mb oi oj ok ol bi translated">最合适的解决方案是将所有的<code class="fe mz na nb nc b">x</code>变量换算成<strong class="li iu">相同的预期平均值</strong>(如果在对数变换后需要的话)，这样所有的<code class="fe mz na nb nc b">β</code>都是相同的量级，可以直接比较。在这种情况下，套索和山脊惩罚适当。</li></ul></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><p id="2c44" class="pw-post-body-paragraph lg lh it li b lj lk ju ll lm ln jx lo lp lq lr ls lt lu lv lw lx ly lz ma mb im bi translated"><em class="ng">对更高级的回归技术感兴趣？你可能也会喜欢这篇关于多项式回归的文章:</em></p><div class="nk nl gp gr nm nn"><a rel="noopener follow" target="_blank" href="/polynomial-regression-an-alternative-for-neural-networks-c4bd30fa6cf6"><div class="no ab fo"><div class="np ab nq cl cj nr"><h2 class="bd iu gy z fp ns fr fs nt fu fw is bi translated">多项式回归——神经网络的替代方案？</h2><div class="nu l"><h3 class="bd b gy z fp ns fr fs nt fu fw dk translated">讨论多项式和神经网络，理论上都能够近似连续函数…</h3></div><div class="nv l"><p class="bd b dl z fp ns fr fs nt fu fw dk translated">towardsdatascience.com</p></div></div><div class="nw l"><div class="or l ny nz oa nw ob ks nn"/></div></div></a></div></div></div>    
</body>
</html>