<html>
<head>
<title>A New, Better Version of the K-Nearest Neighbors Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">K-最近邻算法的一个新的更好的版本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-better-version-of-the-k-nearest-neighbors-algorithm-12af81391682#2022-04-05">https://towardsdatascience.com/a-new-better-version-of-the-k-nearest-neighbors-algorithm-12af81391682#2022-04-05</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/978956dc48416e2e2575442c1228c839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h2Prb351YVL99UVV"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">妮娜·斯特雷尔在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><div class=""/><div class=""><h2 id="00e7" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">通过使用正则化来改善KNN的结果</h2></div><h1 id="173e" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">介绍</h1><p id="4457" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">前几天，当我写<a class="ae jg" rel="noopener" target="_blank" href="/k-nearest-neighbors-theory-and-practice-7f6f6ee48e56">这篇关于KNN算法的文章</a>时，我注意到一件事:在计算观察值之间的距离时，没有考虑每个特征对整个任务的重要性。</p><p id="13f0" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">即使您过滤掉不相关的特征，剩余的特征对于预测某个目标变量仍然具有不同程度的重要性，并且在我们识别最近邻时不考虑这一点。</p><p id="6702" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后，我试图寻找KNN的实现或文章，但什么都没有出现(我发现<a class="ae jg" href="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e26ff79b-911c-4349-bdcb-38d59882abb3/The_impact_of_distance_feature_weighting_and_selection_for_KNN_in_credit_default_prediction.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220404%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20220404T130106Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=ad652ce74d8eb6936056697edec606e8839ac408ba12ce23a04888010c0acea6&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22The%2520impact%2520of%2520distance%252C%2520feature%2520weighting%2520and%2520selection%2520for%2520KNN%2520in%2520credit%2520default%2520prediction.pdf%22&amp;x-id=GetObject" rel="noopener ugc nofollow" target="_blank">这篇文章</a>似乎做了类似的事情，但它不是很清楚如何加权，也没有任何实现)。最后，我决定自己做，测试它是否能提高结果，然后把它放在那里，以便其他人可以改进它。</p><p id="9bf5" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后，本文将介绍KNN“正则化”方法背后的理论、实现它的Python代码、玩具数据集上的结果以及进一步改进的建议。</p><h1 id="63f6" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">KNN</h1><p id="900e" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">设x是我们想要估计目标变量y的值的新观测值，KNN算法工作如下:<br/> 1。计算x和所有其他已知y值的数据点之间的距离。按照递增顺序排列距离<br/> 3。给定一个正整数k，从排列列表中选择k-first距离<br/> 4。选择对应于这些距离的k点<br/> 5。如果这是一个分类任务，用k个观察值中的多数类来标记x。如果这是一个回归任务，使用k次观察的y的平均值来估计y。</p><p id="0910" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">步骤1中使用的距离度量可以根据手头的任务和数据类型而变化，但最常用的包括欧几里德距离、曼哈顿距离、闵可夫斯基距离和马哈拉诺比斯距离。</p><p id="ac1c" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">直观地说，这意味着当我们想要预测一个新的观察值时，我们会找到具有该信息的类似观察值，并根据这些已知值进行预测。</p><h1 id="fe86" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">正则化版本</h1><p id="ea14" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在KNN算法中，当计算x和其他点之间的距离度量时，可以在步骤1中进行正则化。为了考虑到每个变量和目标之间的关系，我们有几个备选方案。在本文中，我们将使用皮尔逊相关系数的绝对值作为每个要素的权重，并通过正则化参数进行调整:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ae342bb5157aded1d1293c23a2fa684f.png" data-original-src="https://miro.medium.com/v2/resize:fit:198/1*qK3r62PDAd6c-tvT_vTLKg.gif"/></div></figure><p id="9628" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">其中j表示所讨论特征的等级，λ表示正则化参数。正则化参数越大，对与目标变量不相关的要素的惩罚就越大，它们在距离计算中的权重就越小。</p><p id="ce73" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这具有非负面和易于解释的优点。不利的一面是，它不能恰当地考虑非线性关系。</p><p id="fd2f" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然后可以从每个特征的权重形成权重向量w，然后将其应用于闵可夫斯基距离:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/59478e9a6371a5ce832eeb782068ef86.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/1*nu3XVZX08rfQR2xj6DUvIw.gif"/></div></figure><p id="8614" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">或Mahalanobis距离:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/42f15a49fe10060f0264d33cfa8958ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/1*IfSbbAxUp_B448HoJnk9vA.gif"/></div></figure><h1 id="438a" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">履行</h1><p id="0b5f" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">为了评估规则化KNN预测能力，遵循以下步骤:<br/> 1。对于每个距离度量(Manhattan、Euclidean和Minkowsky)，使用KNN的非正则化版本并针对MSE(均方误差)<br/> 2进行优化，在某个任意搜索空间内计算k的局部最优值。相同的k被应用于正则化版本，使用λ <br/> 3的不同值。然后比较两种算法获得的MSE分数，以确定最佳解决方案</p><h1 id="5203" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">结果</h1><p id="b9db" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">为了测试其预测能力，正则化版本已经在<em class="my"> sklearn </em>上包含的糖尿病数据集上进行了测试。</p><p id="a8ac" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">该数据集包含关于健康指标和糖尿病的信息，有442个实例和10个属性，其中一个是我们回归任务的目标变量:基线后一年疾病进展的定量测量。所有其他变量都是数字或二进制的，包括年龄、身体质量指数和血糖水平等信息。</p><p id="4720" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">正则化KNN算法为所有三个距离度量产生了更好的结果，并且最好的总体MSE (3314)是用正则化版本的Mahalanobis距离获得的:</p><figure class="ms mt mu mv gt iv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/12d48de33518ff7315ed3deb814e3969.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*zwNh0QhH9z5xjdOXDmaegw.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">不同λ值的MSE(均方误差),使用马氏距离</p></figure><p id="20cb" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">正如我们所见，结果可能会因用于λ(正则化参数)的值而有很大差异，但这仍然表明正则化KNN算法可以带来改进。</p><h1 id="d54a" class="ky kz jj bd la lb lc ld le lf lg lh li kp lj kq lk ks ll kt lm kv ln kw lo lp bi translated">结论和进一步研究</h1><p id="b3db" class="pw-post-body-paragraph lq lr jj ls b lt lu kk lv lw lx kn ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">进一步改进的潜在领域是用另一种考虑非线性关系的度量来代替皮尔逊相关系数。如果你有什么建议，请在下面评论！</p><p id="077d" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">用于测试的完整代码和关于这个主题的更详细的论文可以在<a class="ae jg" href="https://github.com/arthurmello/regularized-knn" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><p id="ff64" class="pw-post-body-paragraph lq lr jj ls b lt mm kk lv lw mn kn ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">如果你喜欢这篇文章，你可能也会喜欢这些:</p><div class="is it gp gr iu nh"><a href="https://medium.com/@arthurmello_/support-vector-machine-theory-and-practice-69394a31df6a" rel="noopener follow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">支持向量机:理论与实践</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">了解SVM，最强大的最大似然算法之一</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ja nh"/></div></div></a></div><div class="is it gp gr iu nh"><a href="https://medium.datadriveninvestor.com/how-to-correct-sampling-bias-988181c73f5d" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">如何校正采样偏差</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">有没有不代表总体的样本？这里有一个处理方法！</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">medium.datadriveninvestor.com</p></div></div><div class="nq l"><div class="nw l ns nt nu nq nv ja nh"/></div></div></a></div><div class="is it gp gr iu nh"><a rel="noopener follow" target="_blank" href="/k-nearest-neighbors-theory-and-practice-7f6f6ee48e56"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd jk gy z fp nm fr fs nn fu fw ji bi translated">k近邻:理论与实践</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">了解如何使用KNN，这是最直观的分类和回归算法之一</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">towardsdatascience.com</p></div></div><div class="nq l"><div class="nx l ns nt nu nq nv ja nh"/></div></div></a></div></div><div class="ab cl na nb hx nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="im in io ip iq"><blockquote class="ny nz oa"><p id="1190" class="lq lr my ls b lt mm kk lv lw mn kn ly ob mo mb mc oc mp mf mg od mq mj mk ml im bi translated">如果你想进一步讨论，请随时在<a class="ae jg" href="https://www.linkedin.com/in/melloarthur/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我，这将是我的荣幸(老实说)。</p></blockquote></div></div>    
</body>
</html>