<html>
<head>
<title>Deep Equilibrium Models via Neural ODEs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于神经微分方程的深度平衡模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-equilibrium-models-via-neural-odes-c25a3ac8d004#2022-10-25">https://towardsdatascience.com/deep-equilibrium-models-via-neural-odes-c25a3ac8d004#2022-10-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8666" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">结合神经网络、不动点和常微分方程的艺术</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/19c60db5ace40d856ccb06abdd89c78c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fy5RJSFgoTbrXdsVJ1Yjog.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae ky" href="https://pixabay.com/photos/sea-waves-nature-light-ripples-7484743/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/photos/sea-waves-nature-light-ripples-7484743/</a></p></figure><h1 id="bf87" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="1a90" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">最近，聪明的研究人员已经意识到，我们可以将看似无关的想法结合起来，重新解释神经网络如何工作以及我们如何训练它们。首先，如果我们将神经网络的隐藏层数增加到无穷大，我们可以将神经网络的输出视为一个<strong class="lt iu">不动点问题</strong>。第二，神经网络和<strong class="lt iu">常微分方程</strong> (ODEs)之间有很深的联系。我们可以用微分方程求解器来训练神经网络。那么，如果我们把这两个想法结合在一起呢？也就是说，我们通过找到ODE的稳态来训练一个<strong class="lt iu">神经网络。</strong>事实证明，这种方法非常有效，这也是这篇博文的目的。</p><p id="46ea" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><strong class="lt iu">演职员表:</strong>本帖基于这篇优秀的<a class="ae ky" href="https://julialang.org/blog/2021/10/DEQ/" rel="noopener ugc nofollow" target="_blank">博文</a>，第一次看的时候完全炸了我的心。</p><h1 id="3ed6" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">不动点</h1><p id="2dc0" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">假设我们有一个由关系式x'=f(x)定义的动力系统。当左侧等于左侧时，达到系统的固定点:x*=f(x*)。为了找到一个固定点，可以从随机猜测开始，然后应用函数f和一定次数。</p><p id="7050" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">下面用固定点cos(x)=x来说明这个过程。我从最初的猜测x0 = -1开始。然后，我使用规则x1 = cos(x0)更新我的猜测。然后我重复这个过程。经过几次迭代，xn真的接近红线(45°线)，这表明</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/1a005f8e924259b82fd5fb88da43573a.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*oC7QwQ1qVXo7nWy9KnNQLg.png"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/fedf217eaa928cbb2e8531aed0a776fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*81Fm04TZFQ17J9alYsekMw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">计算定点cos(x)=x .来源:作者的计算。</p></figure><p id="f4ad" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated"><em class="mu">细心的读者请注意:</em>这里一切正常的原因是因为函数x- &gt; cos(x)是感兴趣区间上的收缩映射。参见:<a class="ae ky" href="https://en.wikipedia.org/wiki/Banach_fixed-point_theorem" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Banach_fixed-point_theorem</a></p><p id="ef49" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">跟神经网络有什么关系？好吧，让我们考虑一个单层x'=NN(x)的神经网络。现在，假设我们添加另一层，使用相同的架构:x'' = NN(NN(x))。我们再做一遍那个运算:x''' = NN(NN(NN(x)))。等等…这个过程和我们上面做的真的很像，简单的不动点问题cos(x)=x。</p><h1 id="92c0" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">常微分方程</h1><p id="cdbb" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">到目前为止，一切顺利。现在，让我们假设我们正在考虑一个物理系统(一个球，一个火箭，等等。)与位置x，我们假设f给我们系统的速度:f(x) = dx/dt。现在dx ≈ x_{n+1}-x_{n}，所以</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/90cf7b004fe264a207022b90fbed6d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*2K-FKlk-cXtS_Q7YYI6EXQ.png"/></div></div></figure><p id="7a45" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">速度为零时物理系统不动:f(x) = 0。物理系统在g(x)=x时也不动，其中<strong class="lt iu"> </strong>就是上述类型的不动点问题。<strong class="lt iu">重点是不动点问题和寻找颂歌的稳态之间存在联系。</strong></p><h1 id="9d08" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">定点+ ODE +神经网络</h1><p id="42dc" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">有时，我们可以找到常微分方程的精确解。大多数时候，我们不能，所以我们必须找到数字近似值。一个(绝妙的)想法是使用神经网络来近似求解。更具体地说，对于上面的函数g，我们使用神经网络。</p><p id="a152" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">对于给定的g，我们可以使用一个ODE求解器，它给出了ODE的固定点。<strong class="lt iu">更进一步，我们可以训练神经网络，这样对于给定的输入，ODE的固定点就是我们想要预测的量</strong>。简而言之，这就是<strong class="lt iu">深度均衡模型</strong> (DEM)的全部内容。</p><h1 id="1fa5" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">应用1:学习y=2x</h1><p id="1383" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">首先，我们可以检查这种方法是否适用于一个非常简单的案例。这里，给定x，我们希望DEM预测值2x。下面的代码使用了Julia，它被描述为“快速Python”:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="cb14" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">它应该输出类似于下图的图形:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/3f32f5bba2b209a7dae007fcb0672259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*TW-98zIfrFqS8ar4lq5eDw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者基于上述代码的计算。基于<a class="ae ky" href="https://julialang.org/blog/2021/10/DEQ/" rel="noopener ugc nofollow" target="_blank">https://julialang.org/blog/2021/10/DEQ/</a>的代码</p></figure><p id="9422" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">事情按预期运行。然而，使用DEM学习函数y=2x感觉就像用火箭筒打死一只苍蝇。在下一个应用程序中，我们要处理一个稍微有点雄心勃勃的目标:MNIST数据集和从图像中预测数字。</p><h1 id="8bed" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">应用2: MNIST</h1><p id="8fba" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">代码有点复杂，但主要思想保持不变。对于给定的输入，输出是ODE的固定点，其中ODE依赖于神经网络。</p><p id="c4f2" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">在这里，我们必须做更多的工作，因为我们首先要把图像转换成矢量。然后，我们使用softmax层将ODE的稳态转换为数字预测(已经包含在损失函数<code class="fe my mz na nb b">logitcrossentropy).</code>中)。还要注意，ODE层夹在另外两层之间。请随意尝试其他架构。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mw mx l"/></div></figure><p id="1e81" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">训练之后，您应该会看到类似这样的内容</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/61d3f1379095c4518e4cd7fbd2dcc31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*-oE9vHp1QUgI4fnelH848Q.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:作者基于上述代码的计算。基于<a class="ae ky" href="https://julialang.org/blog/2021/10/DEQ/" rel="noopener ugc nofollow" target="_blank">https://julialang.org/blog/2021/10/DEQ/</a>的代码</p></figure><pre class="kj kk kl km gt nd nb ne nf aw ng bi"><span id="26be" class="nh la it nb b gy ni nj l nk nl">DEM prediction: 2<br/>True digit: 2</span></pre><h1 id="ce70" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">结论</h1><p id="231c" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">这篇博客文章概述了什么是深度均衡模型。我们可以创建一个结合了神经网络、ode和固定点的预测机器，这看起来几乎是不可思议的。读完这篇博客后，我希望你能多理解一点这个魔术背后的机制。</p><h1 id="578b" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">参考</h1><p id="3c6d" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">白，，科尔特和弗拉德连科尔顿。“深度平衡模型。”<em class="mu">神经信息处理系统进展</em> 32 (2019)。</p><p id="5cb8" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">陈，李瑞奇，等。神经常微分方程。<em class="mu">神经信息处理系统进展</em> 31 (2018)。</p><p id="bb73" class="pw-post-body-paragraph lr ls it lt b lu mn ju lw lx mo jx lz ma mp mc md me mq mg mh mi mr mk ml mm im bi translated">Julia中的可组合性:通过神经微分方程实现深度平衡模型。网址:【https://julialang.org/blog/2021/10/DEQ/ T4】</p></div></div>    
</body>
</html>