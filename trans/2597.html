<html>
<head>
<title>Coalescing Vs. Dynamic Coalescing in Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark中的合并与动态合并</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/coalescing-vs-dynamic-coalescing-in-apache-spark-1d7824c8dbcb#2022-06-06">https://towardsdatascience.com/coalescing-vs-dynamic-coalescing-in-apache-spark-1d7824c8dbcb#2022-06-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9b13ab3969ca32d61069679b7cd83d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrGs6VNvwuF-QrmZXKLjCQ.jpeg"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">参考:Pixabay</p></figure><div class=""/><div class=""><h2 id="4ff3" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">随着Spark 3.0中默认启用“动态合并”，Spark应用程序中合并的使用将会增加。现在，您不再需要手动调整分区来进行洗牌，也不会感觉受到“spark.sql.shuffle.partitions”值的限制。阅读这个故事来了解更多..</h2></div><p id="c2c6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">分区的重要性</strong>:对于Spark应用程序的最佳执行来说，正确的分区集就像一个圣杯。当Spark应用程序的每个组成阶段都以最佳方式执行时，它将实现最佳效率。这反过来意味着每个阶段都应该在最佳数量的分区上运行，这些分区的数量可能因阶段而异。最佳分区数量的差异是因为输入数据量和计算性质通常随阶段不同而不同。</p><p id="12ae" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">太多的小分区会增加簿记和调度的开销，而大分区会导致所需并行性的损失。类似地，繁重和内存密集型计算更喜欢小尺寸的分区，而大尺寸的分区自然适合于轻型计算。如果你想了解更多关于火花分割方面的内容，可以参考<a class="ae lq" href="https://www.amazon.com/Guide-Spark-Partitioning-Explained-Depth-ebook/dp/B08KJCT3XN" rel="noopener ugc nofollow" target="_blank">《火花分割指南》</a>。</p><p id="2564" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">洗牌产生阶段</strong>:Spark作业中的大多数阶段是由于Spark执行引擎插入了洗牌交换操作符而产生的。此外，每个混洗交换操作符使用配置参数"<em class="lr">spark . SQL . shuffle . partitions</em>"来决定混洗分区的数量。因此，所有混洗产生的阶段(进行混洗读取的阶段)在相似数量的分区上运行。但是，类似数量的已配置混洗分区对于所有混洗产生的级来说可能不是最优的，导致受影响的级非最优地运行。这反过来降低了Spark作业的整体效率。(你可以参考<a class="ae lq" href="https://medium.com/swlh/revealing-apache-spark-shuffling-magic-b2c304306142" rel="noopener">揭示阿帕奇火花洗牌魔术</a>来了解更多关于火花洗牌的过程)</p><p id="2a1a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">下面是一个代码片段，用于模拟当未启用动态合并时，所有shuffle born阶段都以分区号等于"<em class="lr">spark . SQL . shuffle . partitions</em>"的方式运行。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ls"><img src="../Images/6db873c286d03d3fcf2eb08da7a8879d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEwp06MK7gWAMshvcke82Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图1:模拟多个洗牌诞生阶段的代码片段</p></figure><p id="4219" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">以下是在Spark集群上执行图1 中<em class="lr">所示逻辑时的阶段执行快照:</em></p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lx"><img src="../Images/07529f5e96c965acdcb34c7df9c46bb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4i3FOzRKEbqTd6Ov9yeqSA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><em class="ly">图5 </em>:图1 的<em class="ly">逻辑产生的分级快照，无动态合并</em></p></figure><p id="ffe7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">从<em class="lr">图2 </em>中可以看出，阶段3、5和6都是混洗产生的阶段，并且每个阶段都运行在默认值“<em class="lr">spark . SQL . shuffle . partitions</em>上，该值设置为200。</p><blockquote class="lz ma mb"><p id="1462" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated">为了克服“<em class="jf">spark . SQL . shuffle . partitions</em>带来的限制，Spark开发人员通常使用“<em class="jf">re partition”</em>或“<em class="jf"> coalesce </em>”转换来手动和间接调整shuffle分区。调整是围绕需要数据混洗的转换进行的，例如“分组”和“连接<em class="jf">”</em>。</p></blockquote><p id="8979" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">重新分区和合并</strong> : ' <em class="lr">重新分区'</em>与数据集中的原始分区数量相比，转换允许用户将数据集重新分区为更多或更少的分区。这通常是通过指定从记录的一个或多个属性派生的重新分区键来完成的。如果在<em class="lr"> groupby </em>转换前使用“r<em class="lr">e partition】</em>，则重新分区键与分组键相同；如果在<em class="lr"> Join </em>转换前使用“r<em class="lr">e partition】</em>，则重新分区键与Join键相同。</p><blockquote class="lz ma mb"><p id="434d" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated">当开发人员想要手动增加shuffle分区的数量超过“spark.sql.shuffle.partitions”指定的数量时，他们通常会在shuffle导致转换之前求助于' r <em class="jf"> epartition' </em>。</p></blockquote><p id="0d1e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">Coalesce’</em>转换允许用户将数据集重新划分为与数据集中的原始分区数量相比数量更少的分区。在这里，没有必要指定任何键。</p><blockquote class="lz ma mb"><p id="24b6" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated">与“spark.sql.shuffle.partitions”指定的分区相比，当开发人员想要手动减少洗牌分区的数量时，他们通常会在洗牌后求助于'<em class="jf"> Coalesce' </em>'。</p></blockquote><p id="b191" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">虽然可以通过'<em class="lr">重新分区</em>或'<em class="lr">合并</em>'手动调整混洗的阶段分区，但这是一个反复而繁琐的过程，需要对Spark的执行引擎有很好的理解。为了解决这个问题，Spark支持将'<em class="lr">动态合并</em>'作为一个更大的运行时优化模块的特性之一，Spark 1.6中首次引入了'<em class="lr">高级查询执行(AQE) </em>'。</p><blockquote class="lz ma mb"><p id="2571" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated"><em class="jf">除了</em>‘动态合并’，<em class="jf"/>AQE<em class="jf">的其他特性包括’</em>将连接策略切换到广播连接’和‘优化偏斜连接’。在Spark 3.0之前，AQE被默认禁用，因为它仍在不断成熟，但在Spark 3.0中，AQE被默认启用，以在运行时自动优化Spark作业。</p></blockquote><p id="fa34" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">要使用“动态合并”，必须将以下配置设置为“<em class="lr">真</em>”。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/88aaf266066928f0228bcd46bab71ace.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*gBXp-LVhcKGt1TAH2Nbdbw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图3。用于启用动态合并的配置参数。</p></figure><p id="01cc" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">了解“动态合并”:</strong>众所周知，洗牌由两个连续的阶段组成。第一个是写入混洗块的映射阶段(对应于配置的混洗分区号)。映射阶段之后是归约阶段，该归约阶段读取相关混洗块，根据它们的混洗分区号来组合它们，然后对每个组合的数据块运行归约逻辑。</p><p id="a2c1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">“动态聚结”在洗牌映射和简化阶段之间起作用。实际上，在映射阶段之后，在混洗完成之前(在写入所有混洗数据块之后)，它向spark执行引擎报告大量的统计数据，例如记录的数量和每个混洗分区的大小，关于产生的混洗分区(如配置"<em class="lr">Spark . SQL . shuffle . partitions</em>")的规定。</p><blockquote class="lz ma mb"><p id="db5d" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated">当混洗分区被合并到较低的数目时，这些报告的统计信息提示执行引擎咨询“动态合并”模块来检查潜在的优化机会。</p></blockquote><p id="93f3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">“动态合并”参考由洗牌的映射端产生的统计数据和一些其他可配置的参数(以提供行为的灵活性),以便计算合并分区的最佳目标大小。基于所计算的目标大小，对合并的混洗分区的数量进行估计。如果估计的数量低于由“<em class="lr">spark . SQL . shuffle . partitions</em>”指示的数量，则在运行时，“<em class="lr">动态合并</em>”模块动态地插入后续的<em class="lr">合并</em>转换，该转换具有作为合并的混洗分区的估计数量的输入参数。</p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/a2b96c9913665586cd7b61ffa3339e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*HLffrgq_D5k6Os8L6-AuzQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图4:动态合并的图示</p></figure><p id="889a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><em class="lr">图4 </em>提供了“<em class="lr">动态合并</em>”的图示。如图所示，'<em class="lr">spark . SQL . shuffle . partitions</em>'设置为4。因此，混洗的映射阶段中的两个映射任务(对应于2个分区)写入对应于所配置的混洗分区的4个混洗块。然而，在火花执行引擎已经使用了'<em class="lr">动态合并</em>'之后，第二和第三混洗分区被合并，因此混洗分区的总数在混洗之后的缩减器阶段(混洗产生阶段)变为3而不是4。</p><p id="dee3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">配置“动态合并”:</strong>影响“<em class="lr">动态合并</em>的决策过程的各种可配置参数如下:</p><p id="91aa" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">在Spark 3.0之前:</strong> <em class="lr"> </em>在Spark 3.0之前，这样的参数只有一个:</p><p id="9162" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">"<em class="lr">spark . SQL . adaptive . shuffle . targetpostshuffleinputsize</em>":控制合并后的目标大小。合并后的分区大小将接近但不会大于该目标大小。(默认值:64MB)</p><p id="2360" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="lr"> Spark 3.0及以上</em></strong>:Spark 3.0引入了多个参数来微调“<em class="lr">动态合并</em>的行为，以保持所需并行度和合并洗牌分区的最大大小之间的平衡。所有这些参数解释如下:</p><p id="90a6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">"<em class="lr">spark . SQL . adaptive . advorypartitionsizeinbytes</em>":控制合并后的目标大小。合并后的分区大小将接近但不会大于该目标大小。(默认值:64MB)</p><p id="935c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">"<em class="lr">spark . SQL . adaptive . coalesce partitions . minpartitionnum</em>":控制合并后的最小分区数。如果未设置，则默认为等于'<em class="lr">spark . default . parallelism</em>'。</p><p id="88bc" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">"<em class="lr">Spark . SQL . adaptive . coalesce partitions . minpartitionsize</em>":这是Spark 3.2中新引入的参数。它控制合并后分区的最小大小。合并的分区大小不会小于该大小。(默认值:1MB)</p><blockquote class="lz ma mb"><p id="8dcc" class="ku kv lr kw b kx ky kg kz la lb kj lc mc le lf lg md li lj lk me lm ln lo lp ij bi translated">因此可以看出，在Spark 3.2之前，只使用“Spark . SQL . adaptive . shuffle . targetpostshuffleinputsize”为合并分区大小指定了一个固定的上限。但是，在Spark 3.2中，可以分别基于“Spark . SQL . adaptive . shuffle . targetpostshuffleinputsize”和“Spark . SQL . adaptive . coalesce partitions . minpartitionsize”的值为合并的分区大小指定固定的上限和下限。</p></blockquote><p id="92f3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">以下是再次执行图1 中的<em class="lr">逻辑时Spark产生的阶段快照，但“动态合并”已打开:</em></p><figure class="lt lu lv lw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mh"><img src="../Images/ea6ae8b5ecb8da211c322e91e99ced2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WH9e-50lh7-9GG5NQP6gZw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><em class="ly">图5 </em>:图1逻辑产生的带有动态合并的阶段快照</p></figure><p id="25af" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">从<em class="lr">图5 </em>中可以看出，在启用了<em class="lr">动态合并</em>的情况下，在<em class="lr">图1 </em>中的<em class="lr"> 4 </em>和<em class="lr"> 6 </em>分别对应的<em class="lr"> 5 </em>和<em class="lr"> 14 </em>中，洗牌分区的数量减少为1，而对应于<em class="lr">阶段的<em class="lr"> 9 </em>的分区数量保持为200(<em class="lr">注意，启用AQE后，由于引入了多个跳过的阶段</em>，阶段编号有所改变)</em></p><p id="4d35" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我希望上面的故事已经让你对Coalesce操作有了一个很好的了解，以及“动态合并”特性背后的原因。在这种背景下，我鼓励大家通过使用手动合并操作或启用动态合并功能来探索现有Spark作业的优化机会。</p><p id="d12b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">关于使用“动态合并”的指导原则，我将在下一部分介绍，在此之前，如果有任何疑问、反馈或建议，你可以通过LinkedIn联系我@<a class="ae lq" href="https://www.linkedin.com/in/ajaywlan/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/ajaywlan/</a>。</p></div></div>    
</body>
</html>