<html>
<head>
<title>Natural Language Process for Judicial Sentences with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Python 实现司法判决的自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-process-for-judicial-sentences-with-python-e6a01e30a675#2022-12-16">https://towardsdatascience.com/natural-language-process-for-judicial-sentences-with-python-e6a01e30a675#2022-12-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="ir is gp gr it iu gh gi paragraph-image"><div class="ab gu cl iv"><img src="../Images/f07ee96bb38bd710e1e7005c8e7cfdb3.png" data-original-src="https://miro.medium.com/v2/format:webp/0*9g0o_RccyFazT8qI.jpg"/></div><p class="iy iz gj gh gi ja jb bd b be z dk translated"><a class="ae jc" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">https://pixabay.com/</a></p></figure><div class=""/><div class=""><h2 id="c009" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">第 9 部分:无监督情感分析</h2></div><p id="e8d1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">情感分析是一种自然语言处理技术，涉及使用机器学习算法从文本数据中识别和提取主观信息。它通常用于确定一篇文章的整体情绪，无论是积极的、消极的还是中性的。这对于各种应用程序都很有用，例如分析客户反馈、检测社交媒体帖子的情绪或识别电影评论的情绪。情感分析算法通常使用自然语言处理技术和机器学习算法的组合来处理和分析文本数据，并且可以被训练来识别各种类型的情感。</p><h2 id="1c86" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">所用模型的介绍</h2><p id="fd86" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">在我们的场景中，我想分析文章的情感是否取决于它们的类别。由于文章没有与其情感对应的标签，我将使用一个名为 VADER 的预训练模型进行无监督分析，该模型可从<a class="ae jc" href="https://www.nltk.org/api/nltk.sentiment.vader.html" rel="noopener ugc nofollow" target="_blank"> NLTK </a> Python 库中获得。第一个单元格可能需要一段时间，所以您可以直接跳到突出显示的 markdown 开始运行代码并可视化结果。</p><p id="50c3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">VADER 属于一种依赖于情感相关词汇的情感分析。因此，该模型是在具有相关分数(取决于它是正/+ve、中性还是负/-ve)的词典语料库上训练的。</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="6476" class="mx lr jf mt b be my mz l na nb">import nltk<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer<br/>nltk.download('vader_lexicon')<br/>sia = SentimentIntensityAnalyzer()</span></pre><p id="0f26" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi">[….]</p><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/35c2f2bb600166106cd6fef63dfab6af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*PB0PQr1rG7sBqZUbXuPfTA.png"/></div></figure><p id="0175" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi">[….]</p><p id="3b68" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">一旦输入一个完整的句子，该模型使用函数“polarity_score”返回 4 个分数:前三个，+ve，neutral 和-ve，表示属于这些分类的内容的范围。第四个是复合分数，在-1 和 1 之间归一化的词汇等级的总量。</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="b6f5" class="mx lr jf mt b be my mz l na nb">raw_text = "this cake looks delicious, I would love to eat it"<br/>sia.polarity_scores(raw_text)</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nd"><img src="../Images/2eb280244807d638e3cfb15125533c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VFV8JZb5dW5NpEHz8ImLIw.png"/></div></div></figure><h2 id="c5be" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">司法判决的情感分析</h2><p id="59e1" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">现在让我们将 VADER 模式用于我们的司法判决:</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="311a" class="mx lr jf mt b be my mz l na nb"><br/>import nltk<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer <br/>df_sentiment=df.copy()<br/><br/>sia = SentimentIntensityAnalyzer()<br/>sentiment=[]<br/>for i in range(len(df)):<br/>     ss = sia.polarity_scores(df.Lemmas[i])<br/>     sentiment.append(ss)<br/>    <br/>    <br/>import pickle<br/>pickle.dump(sentiment, open("data/sentiment.pkl", 'wb'))</span></pre><p id="1b99" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们用复合分数向数据集添加一列:</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="b072" class="mx lr jf mt b be my mz l na nb">#now we can add a column to our dataset to establish whether the release was positive, neutral or negative.<br/>compound=[sentiment[i]['compound'] for i in range(len(sentiment))]<br/>df_sentiment['compound']=compound<br/>df_sentiment.head()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ni"><img src="../Images/d9f09dadbc6ecb1f066c2e487ff63b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrFKDGbgaQve1neETcFyVw.png"/></div></div></figure><p id="c145" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我在联想:</p><ul class=""><li id="11f5" class="nj nk jf kw b kx ky la lb ld nl lh nm ll nn lp no np nq nr bi translated">化合物大于 0.05 的任何句子的正标签</li><li id="1fc7" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated">任何复合值低于-0.05 的句子的否定标记</li><li id="f267" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated">任何含有-0.05 到 0.05 之间的复合词的句子的中性标签</li></ul><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="8fda" class="mx lr jf mt b be my mz l na nb">#let's attribute a label <br/>sent=[]<br/>for i in compound:<br/>    if i&lt;-0.05:<br/>        sent.append('negative')<br/>    elif i&gt;0.05:<br/>        sent.append('positive')<br/>    else:<br/>        sent.append('neutral')<br/>        <br/>df_sentiment['sentiment']=sent<br/><br/>#storing results<br/>df_sentiment.to_pickle('data/df_sentiment.pkl')<br/>df_sentiment.head()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ni"><img src="../Images/0830dc4f2f02a7b907a37cdde5fc9598.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gYtIC9VTrMnytWNZA0N7ug.png"/></div></div></figure><h2 id="ed20" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">可视化结果</h2><p id="84e8" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">由于我想在一个低维空间中可视化标记的句子，我将从<a class="ae jc" rel="noopener" target="_blank" href="/natural-language-process-for-judicial-sentences-with-python-102064f24372"> TF-IDF 矩阵</a>开始应用<a class="ae jc" href="https://medium.com/towards-data-science/natural-language-process-for-judicial-sentences-with-python-a0ec2792b70" rel="noopener">奇异值分解</a>(您可以在本系列的前几部分中了解关于 SVD 和 TF-IDF 的更多信息):</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="9c67" class="mx lr jf mt b be my mz l na nb">#Now let's visualize it via Singular Value Decomposition<br/><br/>documents = df_sentiment.Lemmas.apply(str).tolist()<br/>tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words='english', analyzer='word', min_df=0.001, max_df=0.5, sublinear_tf=True, use_idf=True)<br/>X = tfidf_vectorizer.fit_transform(documents)<br/>print(X.shape)<br/><br/><br/>k = 2<br/>svd = TruncatedSVD(n_components=k)<br/>U = svd.fit_transform(X)<br/>S = svd.singular_values_<br/>V = svd.components_<br/><br/>print(U.shape, S.shape, V.shape)</span></pre><pre class="nx ms mt mu bn mv mw bi"><span id="fa10" class="mx lr jf mt b be my mz l na nb">(13087, 28314)<br/>(13087, 2) (2,) (2, 28314)</span></pre><p id="80a4" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们导入可视化库并初始化一个绘图函数:</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="35e6" class="mx lr jf mt b be my mz l na nb">import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from matplotlib import colors<br/>def show_topics(A, vocabulary, topn = 5):<br/>    """<br/>    find the top N words for each of the latent dimensions (=rows) in a<br/>    """<br/>    topic_words = ([[vocabulary[i] for i in np.argsort(t)[:-topn-1:-1]]<br/>                    for t in A])<br/>    return [', '.join(t) for t in topic_words]<br/><br/><br/><br/>def plot_vectors(vectors, title = 'VIZ', labels = None, dimensions = 3, low_dim = None):<br/>    sns.set_context('poster')<br/>    """<br/>    plot the vectors in 2 or 3 dimensions. If supplied, color them according to the labels<br/>    """<br/>    # set up graph<br/>    fig = plt.figure(figsize = (12, 12))<br/><br/>    # create data frame<br/>    df = pd.DataFrame(data = {'x': vectors[:, 0], 'y': vectors[:, 1]})<br/>    # add labels, if supplied<br/>    if labels is not None:<br/>        df['label'] = labels<br/>    else:<br/>        df['label'] = [''] * len(df)<br/><br/>    # assign colors to labels<br/>    cm = plt.get_cmap('tab20b') # choose the color palette<br/>    n_labels = len(df.label.unique())<br/>    label_colors = [cm(1. * i/n_labels) for i in range(n_labels)]<br/>    cMap = colors.ListedColormap(label_colors)<br/>        <br/>    # plot in 3 dimensions<br/>    if dimensions == 3:<br/>        sns.set_style("white")<br/>        # add z-axis information<br/>        df['z'] = vectors[:,2]<br/>        # define plot<br/>        ax = fig.add_subplot(111, projection='3d')<br/>        frame1 = plt.gca() <br/>        # remove axis ticks<br/>        frame1.axes.xaxis.set_ticklabels([])<br/>        frame1.axes.yaxis.set_ticklabels([])<br/>        frame1.axes.zaxis.set_ticklabels([])<br/>        <br/>        if low_dim != None:<br/>            labels = sorted(show_topics(low_dim_svd.components_, tfidf_vectorizer.get_feature_names()))<br/>            frame1.axes.set_xlabel(labels[0])<br/>            frame1.axes.set_ylabel(labels[1])<br/>            frame1.axes.set_zlabel(labels[2])<br/><br/>        # plot each label as scatter plot in its own color<br/>        for l, label in enumerate(df.label.unique()):<br/>            df2 = df[df.label == label]<br/>            ax.scatter(df2['x'], df2['y'], df2['z'], c = label_colors[l], cmap = cMap, edgecolor = None, label = label, alpha = 0.5, s = 100)<br/>      <br/>    # plot in 2 dimensions<br/>    elif dimensions == 2:<br/>        sns.set()<br/>        ax = fig.add_subplot(111)<br/>        frame1 = plt.gca() <br/>        frame1.axes.xaxis.set_ticklabels([])<br/>        frame1.axes.yaxis.set_ticklabels([])<br/>        <br/>        if low_dim != None:<br/>            labels = sorted(show_topics(low_dim_svd.components_, tfidf_vectorizer.get_feature_names()))<br/>            frame1.axes.set_xlabel(labels[0])<br/>            frame1.axes.set_ylabel(labels[1])<br/><br/>        for l, label in enumerate(df.label.unique()):<br/>            df2 = df[df.label == label]<br/>            ax.scatter(df2['x'], df2['y'], c = label_colors[l], cmap = cMap, edgecolor = None, label = label, alpha = 0.5, s = 100)<br/><br/>    else:<br/>        raise NotImplementedError()<br/>    <br/>    plt.legend(ncol = 5, loc = "upper left", frameon = True, fancybox = True)<br/>    ax.legend(frameon = True, ncol = 2, fancybox = True, title_fontsize = 15,<br/>          loc = 'center left', bbox_to_anchor = (1, 0.5), labelspacing = 2.5, borderpad = 2);<br/>    plt.title(title)<br/>    plt.show()</span></pre><p id="8b70" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们画出结果:</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="9980" class="mx lr jf mt b be my mz l na nb">low_dim_svd = TruncatedSVD(n_components = 3)<br/>categories = df_sentiment.sentiment<br/><br/>low_dim_U = low_dim_svd.fit_transform(X)<br/><br/><br/>plot_vectors(low_dim_U, title = "SVD", labels = categories, dimensions = 3, low_dim = low_dim_svd)</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ny"><img src="../Images/c512c3ba27c2f9fb4e8302e3abb93ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oIrX7MNUMIu1eSjr9gm-QA.png"/></div></div></figure><p id="f46e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在让我们想象一下，对于每个类别，它的文章的总体情绪是什么。</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="2c22" class="mx lr jf mt b be my mz l na nb">categories = list(set([i for  l in df_sentiment['category'].to_list() for i in l]))<br/>categories_list=[]<br/>for k in range(len(categories)):<br/>    counter=0<br/>    categories_list.append(categories[k])<br/><br/>l = [[] for i in range(len(categories_list))]<br/><br/>for category in range(len(categories_list)):<br/>    for i in range(len(df_sentiment)):<br/>        if categories_list[category] in df_sentiment.category[i]:<br/>            l[category].append(df_sentiment['compound'][i])<br/><br/>comp_df=pd.DataFrame(list(zip(categories_list, l)), columns=['category', 'compounds'])<br/><br/>pos=[]<br/>neg=[]<br/>for i in range(len(comp_df)):<br/>    pos_c=0<br/>    neg_c=0<br/>    for j in comp_df.compounds[i]:<br/>        if j&gt;=0:<br/>            pos_c+=1<br/>        else:<br/>            neg_c+=1<br/>    pos.append(pos_c)<br/>    neg.append(neg_c)<br/>    <br/>comp_df['positive_count']=pos<br/>comp_df['negative_count']=neg<br/>comp_df.head()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/43d7910cf413ff5fa71f07878b644a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*_ZXaLzZ7aMcIpg6ZjwFPsw.png"/></div></figure><p id="87f1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们画出结果:</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="6873" class="mx lr jf mt b be my mz l na nb">fig = plt.figure(figsize=(20,15))<br/>ax = plt.subplot(111)<br/>ax.bar(comp_df.category, [-i for i in neg], width=1, color='r')<br/>ax.bar(comp_df.category, pos, width=1, color='g')<br/>plt.xticks(rotation='vertical')<br/>plt.show()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oa"><img src="../Images/32626d418f19fa3828bb475594a2bb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uf6LhXOpH7aw7qsTJYjBCw.png"/></div></div></figure><p id="a65f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">显然，税收似乎是最消极的话题。但是，长的负棒线主要是因为税收是最常见的类别。我们感兴趣的是给定类别的负面程度的相对度量。</p><p id="e732" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">带着这个目的，让我们计算并绘制负对正的比值比。</p><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="fb10" class="mx lr jf mt b be my mz l na nb">odds = []<br/>for i in range(len(comp_df)):<br/>    odds.append(comp_df['negative_count'][i]/comp_df['positive_count'][i])<br/>    <br/>comp_df['odds'] = odds<br/>comp_df.head()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/5a9b8de9e5f9a28d303d184115d79940.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*wEzf507Yj67CUx3S3qVOEg.png"/></div></figure><pre class="mo mp mq mr gt ms mt mu bn mv mw bi"><span id="d0b7" class="mx lr jf mt b be my mz l na nb">colors = []<br/>for i in odds:<br/>    if i&gt;1:<br/>        colors.append('b')<br/>    else:<br/>        colors.append('gray')<br/>fig = plt.figure(figsize=(20,15))<br/>ax = plt.subplot(111)<br/>ax.bar(comp_df.category, odds, width=1, color=colors)<br/>ax.axhline(1, color="red", ls = '--')<br/>plt.xticks(rotation='vertical')<br/>plt.show()</span></pre><figure class="mo mp mq mr gt iu gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oc"><img src="../Images/61e436526e683590978b6303cabf6920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPR5Iiu4ze2eEnWNtb3RBA.png"/></div></div></figure><h2 id="2c02" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">结论</h2><p id="6c6d" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp im bi translated">由于比值比，我们可以看到负面文章是正面文章次数最多的类别是身份盗窃。相反，与上面猜测的不同，税收类别显示出较低的优势比，这意味着这两种情绪没有那么不平衡。</p><p id="6b28" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">总体而言，司法新闻稿的总体情绪似乎是负面的，只有少数类别的优势比低于 1(由红色虚线表示)，这意味着正面文章多于负面文章。</p><h2 id="55b6" class="lq lr jf bd ls lt lu dn lv lw lx dp ly ld lz ma mb lh mc md me ll mf mg mh mi bi translated">参考</h2><ul class=""><li id="cb7d" class="nj nk jf kw b kx mj la mk ld od lh oe ll of lp no np nq nr bi translated">自然语言工具包</li><li id="aea8" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">Python 中的 spaCy 工业级自然语言处理</a></li><li id="8579" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://www.justice.gov/news" rel="noopener ugc nofollow" target="_blank">司法新闻| DOJ |司法部</a></li><li id="1ac4" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://www.kaggle.com/datasets/jbencina/department-of-justice-20092018-press-releases" rel="noopener ugc nofollow" target="_blank">司法部 2009-2018 年新闻发布| Kaggle </a></li><li id="4d3e" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://spacy.io/usage/linguistic-features#named-entities" rel="noopener ugc nofollow" target="_blank">https://spacy.io/usage/linguistic-features#named-entities</a></li><li id="1fab" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://medium.com/p/d81bdfa14d97/edit" rel="noopener">https://medium.com/p/d81bdfa14d97/edit</a></li><li id="2a71" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated"><a class="ae jc" href="https://www.nltk.org/api/nltk.sentiment.vader.html" rel="noopener ugc nofollow" target="_blank">https://www.nltk.org/api/nltk.sentiment.vader.html</a></li><li id="bf20" class="nj nk jf kw b kx ns la nt ld nu lh nv ll nw lp no np nq nr bi translated">休顿，C.J .和吉尔伯特，E.E. (2014 年)。VADER:基于规则的社交媒体文本情感分析的简约模型。第八届网络日志和社交媒体国际会议。密歇根州安阿伯，2014 年 6 月。</li></ul></div></div>    
</body>
</html>