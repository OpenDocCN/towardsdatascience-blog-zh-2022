<html>
<head>
<title>Nearest Neighbors is the foundation for KNN, Optics, DBSCAN, HDBSCAN &amp; SMOTE</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最近邻是KNN、光学、DBSCAN、HDBSCAN和SMOTE的基础</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nearest-neighbors-is-the-foundation-for-knn-optics-dbscan-hdbscan-smote-eeb10ea956e9#2022-04-22">https://towardsdatascience.com/nearest-neighbors-is-the-foundation-for-knn-optics-dbscan-hdbscan-smote-eeb10ea956e9#2022-04-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="4d14" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">最近邻之旅及其衍生算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/84037ea3b6b7caf2b561d9a0f27a5c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6MzSxmmYL8-RC1pa.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Frogly Neighbors，(蛙趣屋居民)，Alexas_Fotos，<a class="ae ky" href="https://pixabay.com/photos/frogs-fun-house-residents-1382827/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>。</p></figure><p id="2c54" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有各种算法是建立在其他算法的基础上的。下面的文章关注最近邻(NN ),其他模型在其概念或代码的基础上利用和创新了它。</p><h2 id="c93a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">无监督的最近邻居</h2><p id="f47a" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">让我们从基础模型开始，即在Scikit中实现的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html" rel="noopener ugc nofollow" target="_blank">无监督最近邻</a>。此算法用于判断训练数据中的实例是否与您要测量的点k最近。它是用于计算神经网络的不同算法的接口，如BallTree、KDTree。如下图所示，它继承了KNeighborsMixin、RadiusNeighborsMixin、NeighborsBase。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mt"><img src="../Images/5bac0339ccb76e3f0c97bc2c92dad6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrv0bdHxtM-tDIp7y_1L0w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">邻居分类器类实现。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mu"><img src="../Images/2e87e67f8ca3f42e1d8c032fe11ea3dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLlreZ_mO-06bcwn7JPyrA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最近邻的“算法”参数。</p></figure><h2 id="c248" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">k-最近邻</h2><p id="4bce" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">继续使用每个数据科学家都会遇到的用于分类的<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank"> K个最近邻</a>，并使用上述方法，根据其K个近邻来确定一个未见过的样本是否属于某个类别。</p><p id="a372" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如下面的<a class="ae ky" href="https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/neighbors/_classification.py" rel="noopener ugc nofollow" target="_blank">代码</a>所示，KNN继承了相同的基类“KNeighborsMixin，&amp;radiusboresmixin”，但是顺序不同；在文档中，它在内部使用了fit()的NeighborsMixin和predict()的neighborsmixin实现。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mv"><img src="../Images/a41d7916bbdd6e849ae84d43890f3074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-g_ghDsjUQ8uJ_FL2j4-nw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNeighborsClassifier类的实现，KNN，Scikit-learn。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mw"><img src="../Images/6cb56b39a58b6b446a628f5afeefe346.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Jp2Xr6EXZY8VK8Rr6vaFw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KNN的“算法”参数。</p></figure><h2 id="a73e" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">基于密度的噪声应用空间聚类</h2><p id="9473" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">继续讨论<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html" rel="noopener ugc nofollow" target="_blank"> DBSCAN </a>，这是一种基于密度的聚类算法。简单来说，DBSCAN寻找高密度样本的集群。我们可以在这里找到DBSCAN的代码<a class="ae ky" href="https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/cluster/_dbscan.py#L164" rel="noopener ugc nofollow" target="_blank">，在文档中已经可以看到DBSCAN的内部算法指向了NN模块。</a></p><p id="48dc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深入挖掘，我们看到DBSCAN的<a class="ae ky" href="https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/cluster/_dbscan.py#L364" rel="noopener ugc nofollow" target="_blank">代码</a>在内部使用了‘nearest neighbors’模块，如下面快照中的DBSCAN的fit()函数代码和文档所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/8d013399b674a4f1c3cd57658ffa0ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A5EwK73-G9QZaHTPHAuauw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最近邻用法，DBSCAN，Scikit-learn。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/a0590d84b63d461746dfa67dc1c9ce03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBhhNIHLegHUTXvdbfJ0-w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">DBSCAN的“算法”参数。</p></figure><h2 id="0ce1" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">光学</h2><p id="93ef" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html" rel="noopener ugc nofollow" target="_blank"> Optics </a>与DBSCAN密切相关，同样，它发现高密度区域并从中扩展集群，但是，它使用基于半径的集群层次结构，Scikit建议在更大的数据集上使用它。这种光学实现在所有点上使用k-最近邻搜索</p><p id="b266" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在报告内部，我们看到Optics的代码在内部依赖于“最近邻居”模块及其算法，如Optics compute_optics_graph()函数<a class="ae ky" href="https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/cluster/_optics.py#L516" rel="noopener ugc nofollow" target="_blank">代码</a>和下面的文档快照所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/a0cb9be9205c0e8934b83df2a906506f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7F-Dj4VwRdYn1uYMiFWHmg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">最近邻用法，compute_optics_graph()，optics，Scikit-learn。</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/dc34466ac1862be64c5b9e347377e1de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oF8OU3kD4OyZ5Hm-ch0-Eg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">光学“算法”参数。</p></figure><h2 id="3235" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">HDBSCAN</h2><p id="1296" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated"><a class="ae ky" href="https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html" rel="noopener ugc nofollow" target="_blank"> HDBSCAN </a>通过将DBSCAN转换为层次聚类算法来扩展它，然后在其上使用平面聚类提取。</p><p id="dfd1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以在<a class="ae ky" href="https://hdbscan.readthedocs.io/en/latest/api.html" rel="noopener ugc nofollow" target="_blank"> API引用</a>和<a class="ae ky" href="https://github.com/scikit-learn-contrib/hdbscan/blob/18f116995e38aae2ca26b0fef8c27cff5ed66a78/hdbscan/robust_single_linkage_.py#L70" rel="noopener ugc nofollow" target="_blank">代码</a>中看到一些指向KNN的线索</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/4314fc2f6461714d859ca639e0a028d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ILr5YwBDeRE4Spbl_f0hRA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><strong class="bd nc"> <em class="nd">类中的K参数</em> </strong> <code class="fe ne nf ng nh b"><strong class="bd nc">hdbscan.robust_single_linkage_.RobustSingleLinkage()</strong></code></p></figure><p id="84ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">深入到代码中我们可以看到，在下面的代码中，函数_rsl_prims_balltree实际上是基于balltree的，而_rsl_prims_kdtree是基于kdtree的，它们是Scikit-learn中用来计算NN的算法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ni"><img src="../Images/dff3852960959fcbbbd1346485911e94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f9rA_62oLH2uosbOIN_qxg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">KDTree，prims_balltree，HDBSCAN</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/44b9f01142583f0d5327500ad50809b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xXAcirTx6W_kkaOSXDCGkw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">BallTree，prims_balltree，HDBSCAN</p></figure><h2 id="f4f3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">重击</h2><p id="0615" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">合成少数过采样算法(SMOTE)的不平衡学习<a class="ae ky" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank">实现</a>，它不直接使用Scikit-learn NN类实现，但使用NN概念。我们可以浏览一下代码和文档，立即发现generate_samples() <a class="ae ky" href="https://github.com/scikit-learn-contrib/imbalanced-learn/blob/ef4edde/imblearn/over_sampling/_smote/base.py#L56" rel="noopener ugc nofollow" target="_blank">函数</a>中的k_neighbors参数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/dce7f94c7d14175026eec1db21265ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*89artLDOze3EGU2n4Wkpww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">k_neighbors参数，SMOTE，不平衡-学习。</p></figure><h2 id="d200" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">摘要</h2><p id="a89f" class="pw-post-body-paragraph kz la it lb b lc mo ju le lf mp jx lh li mq lk ll lm mr lo lp lq ms ls lt lu im bi translated">最近邻算法，由<a class="ae ky" href="https://en.wikipedia.org/wiki/Evelyn_Fix" rel="noopener ugc nofollow" target="_blank"> Evelyn Fix </a>，<a class="ae ky" href="https://en.wikipedia.org/wiki/Joseph_Lawson_Hodges_Jr." rel="noopener ugc nofollow" target="_blank"> Joseph Hodges </a> et开发。艾尔。在1951年，后来由Thomas Cover在1967年扩展，对上述所有实现都至关重要。我们还可以看到，Scikit-learn的各种算法实现从头到尾都在重用这些代码，而且其他各种包也使用了NN算法，以便为我们带来更高级的模型。</p><p id="3bd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我真诚地希望这篇综述能让你理解所有这些算法之间的联系和关系，希望能帮助你用众多的算法方法解决更多的问题。</p><p id="c967" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[1]修复，伊芙琳；约瑟夫·霍奇斯(1951)。<a class="ae ky" href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a800276.pdf" rel="noopener ugc nofollow" target="_blank">歧视性分析。非参数判别:一致性性质</a> (PDF)(报告)。德克萨斯州伦道夫机场美国空军航空医学院。</p><p id="eea9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">[2] <a class="ae ky" href="https://en.wikipedia.org/wiki/Thomas_M._Cover" rel="noopener ugc nofollow" target="_blank">盖，托马斯·m .</a>；彼得·哈特(1967)。<a class="ae ky" href="http://ssg.mit.edu/cal/abs/2000_spring/np_dens/classification/cover67.pdf" rel="noopener ugc nofollow" target="_blank">“最近邻模式分类”</a> (PDF)。<em class="nl"> IEEE汇刊于</em></p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><p id="834a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">Ori Cohen博士拥有计算机科学博士学位，主要研究机器学习。他是<a class="ae ky" href="https://book.mlcompendium.com/" rel="noopener ugc nofollow" target="_blank"> ML &amp; DL纲要</a>和<a class="ae ky" href="http://www.stateofmlops.com" rel="noopener ugc nofollow" target="_blank">StateOfMLOps.com</a>的作者，对AIOps &amp; MLOps领域很感兴趣。他是Justt.ai的数据科学高级总监。</p></div></div>    
</body>
</html>