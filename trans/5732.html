<html>
<head>
<title>Torch and Torchvision C++ installation and debugging on Linux</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Torch 和 Torchvision C++在 Linux 上的安装和调试</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/torch-and-torchvision-c-installation-and-debugging-on-linux-263676c38fa2#2022-12-30">https://towardsdatascience.com/torch-and-torchvision-c-installation-and-debugging-on-linux-263676c38fa2#2022-12-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="80ca" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Torchvision 中的 RoIAlign 调试示例</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8704d5e22e4235f43a03a59f32d804d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_q2w004TSWdJ8Y1u"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/@udayawal" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/@udayawal</a></p></figure><h2 id="766d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">介绍</h2><p id="e817" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本教程中，我们将在 Linux 机器上安装<em class="ml"> Torch </em>和<em class="ml"> Torchvision </em> C++库来调试一个不是用 Python 而是用 C++编写的函数。因为我们感兴趣的函数是用 C++编写的，而不是用<em class="ml"> Pytorch </em>编写的，所以我们不能从 Python API 到<em class="ml"> Torchvision </em>调试它，因此我们需要深入研究 C++代码。如果你想知道更多关于 Python 和 C++如何链接以及如何从 Python 中调用 C++代码的信息，你可以参考我之前的文章<a class="ae kv" href="https://medium.com/towards-data-science/calling-c-code-from-python-with-ctypes-module-58404b9b3929" rel="noopener">这里</a>。</p><h2 id="9e47" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">火炬安装</h2><p id="b78f" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">首先我们需要下载<em class="ml"> Torchlib </em> C++库，它提供了使用 Torch 所需的所有头文件和库的二进制发行版。这可以从 PyTorch 官方网站<a class="ae kv" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">这里</a>完成。我选择了以下下载配置:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/fcbfbd1c18030676e8c591f8876a6574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sdG0loJNkXjq83kB6_BAVg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片—图 1</p></figure><p id="82a3" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">然后，我们为项目创建一个新文件夹，将。我们刚刚下载的 zip 文件夹，并在那里解压缩。</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="1613" class="mx kx iq mt b be my mz l na nb">mkdir torchinstall<br/>unzip libtorch-cxx11-abi-shared-with-deps-1.13.1+cpu.zip</span></pre><p id="4f24" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">从这里我们将参考 Torch 的<a class="ae kv" href="https://pytorch.org/cppdocs/installing.html" rel="noopener ugc nofollow" target="_blank">官方文档</a>来编译和构建依赖于<em class="ml"> Torch </em>库的文件。首先让我们创建两个文件:</p><ul class=""><li id="f600" class="nc nd iq lu b lv mn ly mo lf ne lj nf ln ng mk nh ni nj nk bi translated"><em class="ml"> main.cpp </em> — C++文件，我们将在其中编写一些代码，以确保我们可以使用安装火炬库，并且它在我们的机器上工作</li><li id="d17e" class="nc nd iq lu b lv nl ly nm lf nn lj no ln np mk nh ni nj nk bi translated"><em class="ml"> CMakeLists.txt </em> —包含 CMake 工具生成和构建文件的指令的文本文件</li></ul><p id="eccf" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">以及一个构建文件夹，我们编译的<em class="ml"> main.cpp </em>文件将存储在其中</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="e4b0" class="mx kx iq mt b be my mz l na nb">touch main.cpp<br/>touch CMakeLists.txt<br/><br/>#################################################################<br/>touch main.cpp file will contain the following code:<br/><br/>// import libraries <br/>#include &lt;iostream&gt;<br/>#include &lt;torch/torch.h&gt;<br/><br/>int main(){<br/>  torch::manual_seed(0); // set manual seed<br/>  torch::Tensor x = torch::randn({2,3}); // create torch random tensor<br/>  std::cout &lt;&lt; x;} // print tensor<br/><br/>#################################################################<br/>touch CMakeLists.txt file will contain the following:<br/><br/>cmake_minimum_required(VERSION 3.0)<br/># project name<br/>project(debugfunc)<br/><br/># define path to the libtorch extracted folder<br/>set(CMAKE_PREFIX_PATH /home/alexey/Desktop/torchinstall/libtorch)<br/><br/># find torch library and all necessary files<br/>find_package(Torch REQUIRED)<br/>set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}")<br/><br/># executable to add that we want to compile and run<br/>add_executable(debugfunc main.cpp)<br/># link torch libraries to our executable<br/>target_link_libraries(debugfunc "${TORCH_LIBRARIES}")<br/>set_property(TARGET debugfunc PROPERTY CXX_STANDARD 14)<br/>#################################################################<br/><br/># create build folder<br/>mkdir build</span></pre><p id="cd7b" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">现在我们已经准备好编译、构建和运行我们的<em class="ml"> main.cpp </em>文件。</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="0dcc" class="mx kx iq mt b be my mz l na nb"># go into the build folder<br/>cd build<br/># compile main.cpp file<br/>cmake ..<br/># build it<br/>make<br/># run the built file<br/>./debugfunc</span></pre><p id="8a15" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">如果一切正常，您应该会看到以下输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/6975331dd4cebbaa205741618a8a35a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qnrAOBwokb4_-lcVfM5oug.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片—图 2</p></figure><p id="3c27" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">恭喜你，你现在可以构建和运行使用<em class="ml"> torch </em> C++库的文件了！下一步是安装<em class="ml"> torchvision </em> C++库。</p><h2 id="d893" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">火炬视觉装置</h2><p id="93e6" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">让我们回到我们的<em class="ml">桌面</em>目录，创建另一个名为<em class="ml">火炬视觉</em>的文件夹。首先从<a class="ae kv" href="https://github.com/pytorch/vision" rel="noopener ugc nofollow" target="_blank">这里</a>下载 zip <em class="ml"> torchvision </em> C++库，放入 out <em class="ml"> torchvision </em>目录并解压。之后我们进入解压后的文件夹<em class="ml"> vision-main </em>，创建一个<em class="ml"> build </em>目录，打开<em class="ml"> vision-main </em>中的<em class="ml"> CMakeLists.txt </em>文件进行修改和添加一些东西。</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="cb81" class="mx kx iq mt b be my mz l na nb">mkdir torchvision<br/>unzip vision-main.zip<br/>cd vision-main<br/><br/>mkdir build</span></pre><p id="d03b" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">对我来说，<em class="ml"> CMakeLists.txt </em>文件的最终版本如下所示。我添加了<em class="ml"> CMAKE_PREFIX_PATH </em>，关闭了所有选项像<em class="ml"> WITH_CUDA </em>、<em class="ml"> WITH_PNG </em>、<em class="ml"> WITH_JPEG </em>、<em class="ml"> USE_PYTHON </em>。</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="858e" class="mx kx iq mt b be my mz l na nb">cmake_minimum_required(VERSION 3.12)<br/>project(torchvision)<br/>set(CMAKE_CXX_STANDARD 14)<br/>file(STRINGS version.txt TORCHVISION_VERSION)<br/><br/># added CMAKE_PREFIX_PATH<br/>set(CMAKE_PREFIX_PATH /home/alexey/Desktop/torchinstall/libtorch;)<br/><br/># turned off all the options<br/>option(WITH_CUDA "Enable CUDA support" OFF)<br/>option(WITH_PNG "Enable features requiring LibPNG." OFF)<br/>option(WITH_JPEG "Enable features requiring LibJPEG." OFF)<br/>option(USE_PYTHON "Link to Python when building" OFF)<br/><br/>if(WITH_CUDA)<br/>  enable_language(CUDA)<br/>  add_definitions(-D__CUDA_NO_HALF_OPERATORS__)<br/>  add_definitions(-DWITH_CUDA)<br/>  set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} --expt-relaxed-constexpr")<br/>  # CUDA-11.x can not be compiled using C++14 standard on Windows<br/>  string(REGEX MATCH "^[0-9]+" CUDA_MAJOR ${CMAKE_CUDA_COMPILER_VERSION})<br/>  if(${CUDA_MAJOR} GREATER 10 AND MSVC)<br/>    set(CMAKE_CXX_STANDARD 17)<br/>  endif()<br/>endif()<br/><br/>find_package(Torch REQUIRED)<br/><br/>if (WITH_PNG)<br/>    add_definitions(-DPNG_FOUND)w<br/>    find_package(PNG REQUIRED)<br/>endif()<br/><br/>if (WITH_JPEG)<br/>    add_definitions(-DJPEG_FOUND)<br/>    find_package(JPEG REQUIRED)<br/>endif()<br/><br/>if (USE_PYTHON)<br/>  add_definitions(-DUSE_PYTHON)<br/>  find_package(Python3 REQUIRED COMPONENTS Development)<br/>endif()<br/><br/>function(CUDA_CONVERT_FLAGS EXISTING_TARGET)<br/>    get_property(old_flags TARGET ${EXISTING_TARGET} PROPERTY INTERFACE_COMPILE_OPTIONS)<br/>    if(NOT "${old_flags}" STREQUAL "")<br/>        string(REPLACE ";" "," CUDA_flags "${old_flags}")<br/>        set_property(TARGET ${EXISTING_TARGET} PROPERTY INTERFACE_COMPILE_OPTIONS<br/>            "$&lt;$&lt;BUILD_INTERFACE:$&lt;COMPILE_LANGUAGE:CXX&gt;&gt;:${old_flags}&gt;$&lt;$&lt;BUILD_INTERFACE:$&lt;COMPILE_LANGUAGE:CUDA&gt;&gt;:-Xcompiler=${CUDA_flags}&gt;"<br/>            )<br/>    endif()<br/>endfunction()<br/><br/>if(MSVC)<br/>  set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /wd4819")<br/>  if(WITH_CUDA)<br/>    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -Xcompiler=/wd4819")<br/>    foreach(diag cc_clobber_ignored integer_sign_change useless_using_declaration<br/>      set_but_not_used field_without_dll_interface<br/>      base_class_has_different_dll_interface<br/>      dll_interface_conflict_none_assumed<br/>      dll_interface_conflict_dllexport_assumed<br/>      implicit_return_from_non_void_function<br/>      unsigned_compare_with_zero<br/>      declared_but_not_referenced<br/>      bad_friend_decl)<br/>      string(APPEND CMAKE_CUDA_FLAGS " -Xcudafe --diag_suppress=${diag}")<br/>    endforeach()<br/>    CUDA_CONVERT_FLAGS(torch_cpu)<br/>    if(TARGET torch_cuda)<br/>      CUDA_CONVERT_FLAGS(torch_cuda)<br/>    endif()<br/>    if(TARGET torch_cuda_cu)<br/>      CUDA_CONVERT_FLAGS(torch_cuda_cu)<br/>    endif()<br/>    if(TARGET torch_cuda_cpp)<br/>      CUDA_CONVERT_FLAGS(torch_cuda_cpp)<br/>    endif()<br/>  endif()<br/>endif()<br/><br/>include(GNUInstallDirs)<br/>include(CMakePackageConfigHelpers)<br/><br/>set(TVCPP torchvision/csrc)<br/>list(APPEND ALLOW_LISTED ${TVCPP} ${TVCPP}/io/image ${TVCPP}/io/image/cpu ${TVCPP}/models ${TVCPP}/ops<br/>  ${TVCPP}/ops/autograd ${TVCPP}/ops/cpu ${TVCPP}/io/image/cuda)<br/>if(WITH_CUDA)<br/>    list(APPEND ALLOW_LISTED ${TVCPP}/ops/cuda ${TVCPP}/ops/autocast)<br/>endif()<br/><br/>FOREACH(DIR ${ALLOW_LISTED})<br/>    file(GLOB ALL_SOURCES ${ALL_SOURCES} ${DIR}/*.*)<br/>ENDFOREACH()<br/><br/>add_library(${PROJECT_NAME} SHARED ${ALL_SOURCES})<br/>target_link_libraries(${PROJECT_NAME} PRIVATE ${TORCH_LIBRARIES})<br/><br/>if (WITH_PNG)<br/>    target_link_libraries(${PROJECT_NAME} PRIVATE ${PNG_LIBRARY})<br/>endif()<br/><br/>if (WITH_JPEG)<br/>    target_link_libraries(${PROJECT_NAME} PRIVATE ${JPEG_LIBRARIES})<br/>endif()<br/><br/>if (USE_PYTHON)<br/>  target_link_libraries(${PROJECT_NAME} PRIVATE Python3::Python)<br/>endif()<br/><br/>set_target_properties(${PROJECT_NAME} PROPERTIES<br/>  EXPORT_NAME TorchVision<br/>  INSTALL_RPATH ${TORCH_INSTALL_PREFIX}/lib)<br/><br/>include_directories(torchvision/csrc)<br/><br/>if (WITH_PNG)<br/>    include_directories(${PNG_INCLUDE_DIRS})<br/>endif()<br/><br/>if (WITH_JPEG)<br/>    include_directories(${JPEG_INCLUDE_DIRS})<br/>endif()<br/><br/>set(TORCHVISION_CMAKECONFIG_INSTALL_DIR "share/cmake/TorchVision" CACHE STRING "install path for TorchVisionConfig.cmake")<br/><br/>configure_package_config_file(cmake/TorchVisionConfig.cmake.in<br/>  "${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfig.cmake"<br/>  INSTALL_DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})<br/><br/>write_basic_package_version_file(${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfigVersion.cmake<br/>  VERSION ${TORCHVISION_VERSION}<br/>  COMPATIBILITY AnyNewerVersion)<br/><br/>install(FILES ${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfig.cmake<br/>  ${CMAKE_CURRENT_BINARY_DIR}/TorchVisionConfigVersion.cmake<br/>  DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})<br/><br/>install(TARGETS ${PROJECT_NAME}<br/>  EXPORT TorchVisionTargets<br/>  LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}<br/>  )<br/><br/>install(EXPORT TorchVisionTargets<br/>  NAMESPACE TorchVision::<br/>  DESTINATION ${TORCHVISION_CMAKECONFIG_INSTALL_DIR})<br/><br/>FOREACH(INPUT_DIR ${ALLOW_LISTED})<br/>    string(REPLACE "${TVCPP}" "${CMAKE_INSTALL_INCLUDEDIR}/${PROJECT_NAME}" OUTPUT_DIR ${INPUT_DIR})<br/>    file(GLOB INPUT_FILES ${INPUT_DIR}/*.*)<br/>    install(FILES ${INPUT_FILES} DESTINATION ${OUTPUT_DIR})<br/>ENDFOREACH()</span></pre><p id="9281" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">之后，我们进入<em class="ml">构建</em>文件夹，编译、构建并安装库。</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="a390" class="mx kx iq mt b be my mz l na nb">cd build<br/>cmake ..<br/>make<br/>sudo make install</span></pre><p id="a511" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">如果您没有看到任何错误(警告不是错误！)那么一切应该都没问题。现在让我们测试一下我们可以在项目中导入<em class="ml"> torchvision </em>库。回到<em class="ml"> torchinstall </em>文件夹，进入<em class="ml"> main.cpp </em>和<em class="ml"> CMakeLists.txt </em>文件，修改如下:</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="5839" class="mx kx iq mt b be my mz l na nb">// main.cpp we import torchvision library<br/><br/>#include &lt;iostream&gt;<br/>#include &lt;torch/torch.h&gt;<br/>#include &lt;torchvision/vision.h&gt;<br/><br/>int main(){<br/>  torch::manual_seed(0);<br/>  torch::Tensor x = torch::randn({2,3});<br/>  std::cout &lt;&lt; x;<br/>}</span></pre><pre class="nr ms mt mu bn mv mw bi"><span id="2147" class="mx kx iq mt b be my mz l na nb">cmake_minimum_required(VERSION 3.0)<br/>project(debugfunc)<br/><br/>set(CMAKE_PREFIX_PATH /home/alexey/Desktop/torchinstall/libtorch)<br/><br/>find_package(Torch REQUIRED)<br/>find_package(TorchVision REQUIRED)<br/><br/>set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}")<br/><br/>add_executable(${PROJECT_NAME} main.cpp)<br/>target_compile_features(${PROJECT_NAME} PUBLIC cxx_range_for)<br/>target_link_libraries(${PROJECT_NAME} TorchVision::TorchVision)<br/>set_property(TARGET ${PROJECT_NAME} PROPERTY CXX_STANDARD 14)</span></pre><p id="e916" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">现在像以前一样编译、构建和运行:</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="cd8f" class="mx kx iq mt b be my mz l na nb"># compile main.cpp file<br/>cmake ..<br/># build it<br/>make<br/># run the built file<br/>./debugfunc</span></pre><p id="4d6e" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">您应该看不到错误，并再次看到相同的张量输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/b96b58df69f7c8c7fda205f730075aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XzhmmCAUf3jGGk6r8Kceqg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片—图 3</p></figure><p id="1bbf" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">酷，我们现在已经安装了<em class="ml">火炬视觉</em>库！</p><h2 id="8626" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">调试功能</h2><p id="6029" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">现在，假设我们想从 C++的<em class="ml"> torchvision </em>库中调试<em class="ml"> roi_align </em>函数。我使用可视代码进行调试，因为我们使用 CMake，所以您需要在可视代码中安装一些依赖项，以便能够在其中进行调试。我发现<a class="ae kv" href="https://www.youtube.com/watch?v=Rfj40xW9q6w&amp;t=541s" rel="noopener ugc nofollow" target="_blank">这个视频</a>上手挺有用的。</p><p id="72a4" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">为了调试<em class="ml"> roi_align </em>函数，我必须从这个路径复制粘贴一些位:<em class="ml">torch vision/CSRC/ops/CPU</em>以下面的<em class="ml"> main.cpp </em>文件结束</p><pre class="kg kh ki kj gt ms mt mu bn mv mw bi"><span id="591e" class="mx kx iq mt b be my mz l na nb">#include &lt;iostream&gt;<br/>#include &lt;torch/torch.h&gt;<br/>#include &lt;torchvision/vision.h&gt;<br/>#include &lt;torchvision/ops/nms.h&gt;<br/>#include &lt;torch/script.h&gt;<br/><br/>#include &lt;ATen/core/dispatch/Dispatcher.h&gt;<br/>#include &lt;torch/library.h&gt;<br/>#include &lt;torch/types.h&gt;<br/><br/>#include &lt;ATen/ATen.h&gt;<br/>#include &lt;torchvision/ops/cpu/roi_align_common.h&gt;<br/><br/>namespace vision {<br/>namespace ops {<br/><br/>namespace {<br/><br/>template &lt;typename T&gt;<br/>void roi_align_forward_kernel_impl(<br/>    int n_rois,<br/>    const T* input,<br/>    const T&amp; spatial_scale,<br/>    int channels,<br/>    int height,<br/>    int width,<br/>    int pooled_height,<br/>    int pooled_width,<br/>    int sampling_ratio,<br/>    bool aligned,<br/>    const T* rois,<br/>    T* output) {a<br/>  // (n, c, ph, pw) is an element in the pooled output<br/>  // can be parallelized using omp<br/>  // #pragma omp parallel for num_threads(32)<br/>  for (int n = 0; n &lt; n_rois; n++) {<br/>    int index_n = n * channels * pooled_width * pooled_height;<br/><br/>    const T* offset_rois = rois + n * 5;<br/>    int roi_batch_ind = offset_rois[0];<br/><br/>    // Do not using rounding; this implementation detail is critical<br/>    T offset = aligned ? (T)0.5 : (T)0.0;<br/>    T roi_start_w = offset_rois[1] * spatial_scale - offset;<br/>    T roi_start_h = offset_rois[2] * spatial_scale - offset;<br/>    T roi_end_w = offset_rois[3] * spatial_scale - offset;<br/>    T roi_end_h = offset_rois[4] * spatial_scale - offset;<br/><br/>    T roi_width = roi_end_w - roi_start_w;<br/>    T roi_height = roi_end_h - roi_start_h;<br/>    if (!aligned) {<br/>      // Force malformed ROIs to be 1x1<br/>      roi_width = std::max(roi_width, (T)1.);<br/>      roi_height = std::max(roi_height, (T)1.);<br/>    }<br/><br/>    T bin_size_h = static_cast&lt;T&gt;(roi_height) / static_cast&lt;T&gt;(pooled_height);<br/>    T bin_size_w = static_cast&lt;T&gt;(roi_width) / static_cast&lt;T&gt;(pooled_width);<br/><br/>    // We use roi_bin_grid to sample the grid and mimic integral<br/>    int roi_bin_grid_h = (sampling_ratio &gt; 0)<br/>        ? sampling_ratio<br/>        : ceil(roi_height / pooled_height); // e.g., = 2<br/>    int roi_bin_grid_w =<br/>        (sampling_ratio &gt; 0) ? sampling_ratio : ceil(roi_width / pooled_width);<br/><br/>    // We do average (integral) pooling inside a bin<br/>    // When the grid is empty, output zeros.<br/>    const T count = std::max(roi_bin_grid_h * roi_bin_grid_w, 1); // e.g. = 4<br/><br/>    // we want to precalculate indices and weights shared by all chanels,<br/>    // this is the key point of optimization<br/>    std::vector&lt;detail::PreCalc&lt;T&gt;&gt; pre_calc(<br/>        roi_bin_grid_h * roi_bin_grid_w * pooled_width * pooled_height);<br/>    detail::pre_calc_for_bilinear_interpolate(<br/>        height,<br/>        width,<br/>        pooled_height,<br/>        pooled_width,<br/>        roi_start_h,<br/>        roi_start_w,<br/>        bin_size_h,<br/>        bin_size_w,<br/>        roi_bin_grid_h,<br/>        roi_bin_grid_w,<br/>        pre_calc);<br/><br/>    for (int c = 0; c &lt; channels; c++) {<br/>      int index_n_c = index_n + c * pooled_width * pooled_height;<br/>      const T* offset_input =<br/>          input + (roi_batch_ind * channels + c) * height * width;<br/>      int pre_calc_index = 0;<br/><br/>      for (int ph = 0; ph &lt; pooled_height; ph++) {<br/>        for (int pw = 0; pw &lt; pooled_width; pw++) {<br/>          int index = index_n_c + ph * pooled_width + pw;<br/><br/>          T output_val = 0.;<br/>          for (int iy = 0; iy &lt; roi_bin_grid_h; iy++) {<br/>            for (int ix = 0; ix &lt; roi_bin_grid_w; ix++) {<br/>              detail::PreCalc&lt;T&gt; pc = pre_calc[pre_calc_index];<br/>              output_val += pc.w1 * offset_input[pc.pos1] +<br/>                  pc.w2 * offset_input[pc.pos2] +<br/>                  pc.w3 * offset_input[pc.pos3] + pc.w4 * offset_input[pc.pos4];<br/><br/>              pre_calc_index += 1;<br/>            }<br/>          }<br/>          output_val /= count; // Average pooling<br/><br/>          output[index] = output_val;<br/>        } // for pw<br/>      } // for ph<br/>    } // for c<br/>  } // for n<br/>}<br/><br/><br/>template &lt;class T&gt;<br/>inline void add(T* address, const T&amp; val) {<br/>  *address += val;<br/>}<br/><br/><br/>at::Tensor roi_align_forward_kernel(<br/>    const at::Tensor&amp; input,<br/>    const at::Tensor&amp; rois,<br/>    double spatial_scale,<br/>    int64_t pooled_height,<br/>    int64_t pooled_width,<br/>    int64_t sampling_ratio,<br/>    bool aligned) {<br/>  TORCH_CHECK(input.device().is_cpu(), "input must be a CPU tensor");<br/>  TORCH_CHECK(rois.device().is_cpu(), "rois must be a CPU tensor");<br/>  TORCH_CHECK(rois.size(1) == 5, "rois must have shape as Tensor[K, 5]");<br/><br/>  at::TensorArg input_t{input, "input", 1}, rois_t{rois, "rois", 2};<br/><br/>  at::CheckedFrom c = "roi_align_forward_kernel";<br/>  at::checkAllSameType(c, {input_t, rois_t});<br/><br/>  auto num_rois = rois.size(0);<br/>  auto channels = input.size(1);<br/>  auto height = input.size(2);<br/>  auto width = input.size(3);<br/><br/>  at::Tensor output = at::zeros(<br/>      {num_rois, channels, pooled_height, pooled_width}, input.options());<br/><br/>  if (output.numel() == 0)<br/>    return output;<br/><br/>  auto input_ = input.contiguous(), rois_ = rois.contiguous();<br/>  AT_DISPATCH_FLOATING_TYPES_AND_HALF(<br/>      input.scalar_type(), "roi_align_forward_kernel", [&amp;] {<br/>        roi_align_forward_kernel_impl&lt;scalar_t&gt;(<br/>            num_rois,<br/>            input_.data_ptr&lt;scalar_t&gt;(),<br/>            spatial_scale,<br/>            channels,<br/>            height,<br/>            width,<br/>            pooled_height,<br/>            pooled_width,<br/>            sampling_ratio,<br/>            aligned,<br/>            rois_.data_ptr&lt;scalar_t&gt;(),<br/>            output.data_ptr&lt;scalar_t&gt;());<br/>      });<br/>  return output;<br/>}<br/><br/>} // namespace<br/><br/><br/>} // namespace ops<br/>} // namespace vision<br/><br/>int main(){<br/>  torch::manual_seed(0);<br/>  <br/>  // load tensors saved from Python <br/>  torch::jit::script::Module tensors = torch::jit::load("/media/sf_Linux_shared_folder/roialign/tensors.pth");<br/>  c10::IValue feats = tensors.attr("cr_features");<br/>  torch::Tensor feat_ts = feats.toTensor();<br/>  <br/>  c10::IValue boxes = tensors.attr("cr_proposal");<br/>  torch::Tensor boxes_ts = boxes.toTensor();<br/>  <br/>  std::cout &lt;&lt; boxes_ts &lt;&lt; std::endl;<br/><br/>  double spatial_scale = 1.0;<br/>  int64_t pooled_height = 2, pooled_width = 2, sampling_ratio = -1;<br/>  bool aligned = false;<br/>  <br/>  at::Tensor out = vision::ops::roi_align_forward_kernel(feat_ts, boxes_ts, spatial_scale, pooled_height, pooled_width, sampling_ratio, aligned);<br/>  <br/>  std::cout &lt;&lt; out;<br/><br/>}</span></pre><p id="43e0" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">你会注意到我加载了<em class="ml">特性</em>和<em class="ml">建议</em>张量，我在<a class="ae kv" href="https://medium.com/p/d30f6843da3a" rel="noopener">这篇文章</a>中使用了这些张量用于<em class="ml"> roi_align。现在你可以在任何你想调试代码的地方放置断点，然后一行一行地查看发生了什么。</em></p><h2 id="e90d" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结论</h2><p id="1a22" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">在本文中，我们看到了如何在 Linux 机器上安装<em class="ml"> torch </em>和<em class="ml"> torchvision </em> C++库，并调试我们无法在 Pytorch Python API 中直接调试的函数。如果你知道如何不用复制粘贴就能调试函数的简单方法，请在评论中告诉我。</p></div></div>    
</body>
</html>