<html>
<head>
<title>5-Minute Paper Explanations: Food AI Part IV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5分钟的书面解释:食品人工智能第四部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-minute-paper-explanations-food-ai-part-iv-902e5131fd8d#2022-09-07">https://towardsdatascience.com/5-minute-paper-explanations-food-ai-part-iv-902e5131fd8d#2022-09-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0e8d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">im2recipe相关论文“用于跨模式食品检索的多模式正则化变压器解码器”的直观深入探讨</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/72efa19def8f19f92dcea89e4fa561f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FcL1qGEatUCXFy60"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">奥拉因卡·巴巴罗拉在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="e802" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">问题简介</h1><p id="4e64" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">欢迎来到食品人工智能系列论文的第四部分，也是最后一部分！</p><p id="d18f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/5-minute-paper-explanations-food-ai-part-i-9276b61873c1">第一部分</a>:“学习烹饪食谱和食物图像的跨模态嵌入”</p><p id="e66d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/5-minute-paper-explanations-food-ai-part-ii-c085b2789bd1">第二部分</a>:“分而治之的跨模态配方检索:从最近邻基线到SoTA”</p><p id="4bd5" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><a class="ae kv" href="https://medium.com/towards-data-science/5-minute-paper-explanations-food-ai-part-iii-bd7256473c4d" rel="noopener">第三部分</a>:“跨通道检索和合成(X-MRS):缩小共享表征学习中的通道差距”</p><p id="139d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">正如在以前的文章中提到的，这些解释旨在绘制机器学习的特定领域的研究进展。因此，今天，我们将关注2022年发表的名为“用于跨模态食品检索的多模态正则化变压器解码器”的论文<a class="ae kv" href="https://arxiv.org/abs/2204.09730" rel="noopener ugc nofollow" target="_blank">。本文进一步研究了此处</a><a class="ae kv" href="http://pic2recipe.csail.mit.edu/im2recipe.pdf" rel="noopener ugc nofollow" target="_blank">介绍的</a>和本系列第一部分解释的<a class="ae kv" rel="noopener" target="_blank" href="/5-minute-paper-explanations-food-ai-part-i-9276b61873c1">中的im2recipe问题，主要是1) <strong class="lq ir">使用跨模态普通变压器和注意力</strong>，即注意力集中在<em class="mp">图像和文本编码</em>上，而不是像第三部分那样只关注<em class="mp">文本</em>；2)使用非常强大的<strong class="lq ir">视觉和语言预训练(VLP)模型剪辑</strong>；3) <strong class="lq ir">使用模拟课程训练的动态三重损失</strong>；4) <strong class="lq ir">使用多模态正则化技术</strong>，而不是通过第一部分中的分类任务和第三部分中的生成来正则化。</a></p><p id="6aff" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里有一个题外话:VLP的目标是从一个庞大的图像-文本对数据集学习多模态表示。在对Recipe1M数据集进行微调后，这个预训练的模型可以用于下游视觉语言任务，如本例。VLP模型采用CNN-Transformer架构，用CNN嵌入图像，然后用Transformer对齐图像和文本。此处对VLP车型进行了很好的概述<a class="ae kv" href="https://theaisummer.com/vision-language-models/" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="f76e" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">相关工作和改进</h1><p id="522d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><strong class="lq ir">一:</strong>在以前的论文中，我们看到文本编码可以为每个组件(成分、说明、标题)单独编码，也可以一起编码。本文所做的改进是对文本编码进行独立和共同的编码。作者首先使用分层转换器模块对组件进行单独编码，并使用这些输出来获得最终的文本编码。</p><p id="0fe4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">第二:</strong>图像编码器不再仅仅是一个卷积神经网络，而是一个经过VLP任务预训练的视觉转换器。这确保了在学习图像编码的同时充分利用transformer的能力，而不仅仅是像以前那样学习文本编码。</p><p id="f35c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">三:</strong>以前，我们有一个单独的正则化模块，要么通过分类(合并Food-101或其他分类数据集信息)，要么通过图像生成(使生成的图像分布与实际图像分布相似)。这里，我们又有一个正则化子，但这个更复杂。它使用普通的变形器和图像和文本编码之间的交叉注意，使它们尽可能地相似，用于相同的食谱。更重要的是，这个模块只在训练时使用，在测试和推理时移除。</p><p id="71cc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">四:</strong>引入动态三重损失，其作用类似于课程训练</p><h1 id="4a7c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">建筑:食物</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/520ee7589da40e47f6e57f68959880f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hfq4TbHp1ksa0R_jkrUZ_g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">整体架构(来自论文，作者)</p></figure><p id="6aa9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">整体架构可以在上面看到，与我们到目前为止看到的所有其他架构非常相似。我们有一个图像和一个图像编码器，相应的文本和文本编码器。然后，编码被投影到共享空间。应用一些损失，同时这些编码也被传递到“MMR”模块。该模块既作为对齐模块又作为正则化模块，从而分别通过分类来补充三元组丢失和替换GANs /语义正则化。</p><p id="54c0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">图像编码器:</strong>如前所述，图像编码器是一个视觉转换器(特别是微调剪辑ViT B/16)，确保我们也能获得图像编码转换器的好处。和以前一样，对于变形金刚，我们使用[CLS]令牌的输出作为图像的编码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/381837c9c72ea81d3269a37450549a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSKA-z0dpnAfZHV8oSk3WA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">详细的文本编码器(来自论文，作者)</p></figure><p id="39a4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">文本编码器:</strong>文本编码器是分层的。和第二部分一样，我们有单独的变形金刚<strong class="lq ir"> <em class="mp"> T </em> </strong>编码标题、指令和成分。在这里，说明书和配料一次编码一种配料或说明书。接下来，我们有单独的变压器<strong class="lq ir"> <em class="mp"> HT </em> </strong>对指令序列和成分编码进行编码。现在，显然单独编码每个组件会导致模型不知道它们是如何相互关联的。所以，作者使用变压器解码器<strong class="lq ir"> <em class="mp">、HTD </em> </strong>来实现这一点。</p><p id="3d66" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这些解码器的工作方式是针对每个解码器，查询Q是相应<strong class="lq ir"> <em class="mp"> HT </em> </strong>的输出，而密钥K和值V是另外两个<strong class="lq ir"> <em class="mp"> HT的输出的串联。</em> </strong>例如，对于成分解码器来说，查询是成分，而键和值是标题和指令的串联。这意味着我们交叉关注标题和说明上的成分。这基本上实现了不同数据格式如何编码的完全独立性，同时还能够学习它们之间的关系。</p><p id="e25e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">注意，对于文本，我们处理转换器的整个输出，而不仅仅是[CLS]令牌。通过对<strong class="lq ir"><em class="mp"/></strong>HTD的所有输出令牌的值进行平均，将所有<strong class="lq ir"><em class="mp"/></strong>的平均输出连接起来，并投影到共享空间，从而获得最终的配方编码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/f12ab4e13d4c4faf01e1262c0db92270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tLlwvJB18xwY2MAiIet-cQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">多模态正则化+对齐模块(来自论文，作者)</p></figure><p id="187f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">多模态正则化:</strong>请注意，该模块仅在训练期间使用，它取代了之前为对齐文本和图像编码而进行的在共享空间上的简单投影以及随后的对比(三元组)损失。相反，我们有一个使用交叉注意的变换器解码器，其中查询Q来自一个模态，而键和值K、V(它们是相同的)来自另一个模态。</p><p id="4ca4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在本模块中，我们有两个子模块。图像标记增强模块(ITEM)是一个“将图像标记作为查询，将文本标记作为键和值的转换器解码器”。这“通过关注文本元素来丰富图像表征”。多模态转换器解码器(MTD)是实际上对配方令牌和增强图像令牌应用交叉关注的子模块。测量图像和文本标记之间对齐程度的匹配分数如下图所示获得。匹配分数不是以前论文中的余弦相似度，而是解码器直接输出的[0，1]范围内的分数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/3de36e0b1d0651ae85e5b3f170fff6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgxh6adJDhK-ISD_3Hbapw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">MTD匹配分数方程(图片由作者提供，来自论文)</p></figure><p id="b91e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">因此，总的来说，我们有一个用于编码图像的VLP预训练视觉转换器，一个用于编码文本的分层转换器模块(首先用于单个组件，然后通过这些组件之间的交叉注意)。然后，图像和文本编码都被投影到一个共享空间，其中:1)图像编码通过处理文本元素的编码增强器项传递；2)增强的图像编码和文本编码通过用于计算匹配或对准分数的多模态变换器解码器。</p><h1 id="1f69" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">损失函数</h1><p id="45dc" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated"><strong class="lq ir">图像-文本匹配损失:</strong> ITM是BCE损失，它跟踪图像-文本对是否匹配。计算这一损失所遵循的取样过程是硬负采矿法。我们在下面看到，这个等式与实际的BCE损失函数非常相似。<em class="mp"> y </em>对于匹配的图文对是1，否则是0，<em class="mp"> s </em>是解码器输出的分数。然后计算这两者之间的交叉熵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/60d37a95946d1f26ec642f673712c975.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*SD7yIqGqpMfCZTJlLRdvXA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">ITM损失(图片由作者提供，来自论文)</p></figure><p id="e236" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">三重损失/增加余量损失:</strong>建议的三重损失是具有自适应余量的正常三重损失。裕度保持在可接受的范围内，当开始时裕度较小(因此更容易优化),并且逐渐变大。</p><p id="1098" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在，作者还通过对三元组使用自适应加权策略来适应动态三元组损失(称为IncMargin ),如在<a class="ae kv" href="https://arxiv.org/abs/1804.11146" rel="noopener ugc nofollow" target="_blank"> Adamine论文</a>中所述。通常，三重态损失的工作原理是，通过平均小批量中每个三重态的梯度来获得每个小批量的更新。问题是在许多代之后，一些三元组已经收敛，并且损失的梯度为零。使用一些数学魔法(这里不打算详述)，自适应加权策略设法给尚未收敛的三元组更多的权重。</p><p id="e5da" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">语义损失:</strong>作者还使用另一种三元组类型损失，其捕获给定查询图像和与查询相似的食谱图像的语义。例如，任何两个比萨饼应该比一个比萨饼和任何其他类别的另一个项目(如沙拉)更接近潜在空间。这种优化与其他优化一起直接在潜在空间中完成。这与第一部分中使用单独的分类正则化模块形成对比</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/9da31013b33d589791394edb2f4629eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*0mfY1LRQJWVI7NzcSTJhYA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">语义三元组类型丢失(图片由作者提供，来自Adamine论文)</p></figure><p id="50bf" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这里，<em class="mp"> xq </em>是查询，<em class="mp"> xₚ </em>属于与查询相同的语义类，<em class="mp"> xₙ </em>属于与查询不同的语义类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/aecd434e0d9d9a6a5c496f4b6fc08dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*JVxIpDiROWHTBM7oL7z06Q.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">全损(图片由作者提供，来自论文)</p></figure><h1 id="d07c" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">实验和结果</h1><p id="653d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">实验中使用的不同型号:作为图像编码器的ViT-B/16和CLIP-ViT-B/16；对于配方编码器，变压器编码器有2层4头，用于分级变压器<strong class="lq ir"><em class="mp"/></strong>和<strong class="lq ir"> <em class="mp"> HT </em> </strong>。<strong class="lq ir"> <em class="mp"> HTD </em> </strong>使用2层4头变压器解码器(无屏蔽)。隐藏层维度被保存512在配方编码器中。利用输出维度1024的不同线性层来获得图像和配方嵌入。然后，在进入<strong class="lq ir"> <em class="mp"> MMR </em> </strong>模块之前，使用1024的相同输出尺寸的不同线性层来投影图像和配方标记。<strong class="lq ir"> <em class="mp">项</em> </strong>模块由一个只有1层的4头隐藏尺寸为1024的变压器解码器组成。<strong class="lq ir"> <em class="mp"> MTD </em> </strong>由一个4层4头隐维1024的变压器解码器组成。</p><p id="ccc4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">撇开实际数字不谈，我们可以从论文中的结果看出，使用从剪辑权重初始化的CLIP-ViT在这种架构中工作得最好。另一个值得注意的观察是，随着测试样本大小从10k开始增加，TFood与其他产品之间的性能差异也在增加，这意味着TFood更具可伸缩性。</p><p id="1f5a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">从消融研究中，验证了以下几点:1) <strong class="lq ir"> <em class="mp"> HTD </em> </strong>导致更好的对准，因此证明配方成分是纠缠的，并且不应该单独编码；2) <strong class="lq ir"> <em class="mp"> MTD </em> </strong>带来了额外的改进，表明多模态变压器是解决此类问题的好模块。此外，自适应三重态损耗和ViT也带来了显著的额外改进。</p><h1 id="0759" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">个人想法</h1><p id="713f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这篇论文看起来很难理解，但实际上非常简单，因为它只使用了变压器。我认为，视觉变形金刚的发现让它受益匪浅。到处使用变压器的想法似乎也奏效了。这篇论文也更令人满意，因为作者已经能够使用transformer解码器来分离每个编码的学习，以及这些编码之间的关系。然而，本文方法的一个问题是计算和所需资源方面的复杂性。</p></div><div class="ab cl mx my hu mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="ij ik il im in"><p id="d40d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是我在直觉论文解释系列中开始的食品人工智能系列的最后一部分。我正在挑选行业中的一个子域，并浏览该域中的论文。我要写的下一个系列将是关于VLP模特的。如果你喜欢我写的东西，可以考虑订阅或者关注我<a class="ae kv" href="https://www.medium.com/@kunjmehta10" rel="noopener">这里</a>或者在<a class="ae kv" href="http://www.linkedin.com/in/kunjmehta" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>或者<a class="ae kv" href="https://www.twitter.com/@kunjmehta10" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上与我联系！有关我以前的媒体文章的代码，请访问我的<a class="ae kv" href="https://github.com/kunjmehta/Medium-Article-Codes" rel="noopener ugc nofollow" target="_blank"> GitHub </a>。</p><p id="feed" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">论文引用</strong></p><p id="7f5d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">[1] Shukor，Mustafa和Couairon，Guillaume和Grechka，Asya和Cord，Matthieu，“用于跨模式食品检索的具有多模式调整的变压器解码器”。2022</p></div></div>    
</body>
</html>