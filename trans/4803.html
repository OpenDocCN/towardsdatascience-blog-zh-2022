<html>
<head>
<title>Ace your Machine Learning Interview — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">赢得机器学习面试——第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ace-your-machine-learning-interview-part-2-c58526b5faba#2022-10-25">https://towardsdatascience.com/ace-your-machine-learning-interview-part-2-c58526b5faba#2022-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/02b1e0735376d11e3a28b80a8db2a56f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ncter0AQ2FL_gRqs"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated"><a class="ae jd" href="https://unsplash.com/@kobuagency?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> KOBU机构</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><div class=""/><div class=""><h2 id="fab0" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">使用Python研究分类问题的逻辑回归</h2></div><h2 id="dfdd" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">介绍</h2><p id="d334" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">在以前的文章中，我们已经看到了<strong class="lt jh">线性回归</strong>算法的理论和实现:</p><ol class=""><li id="6cd9" class="mk ml jg lt b lu mm lx mn le mo li mp lm mq mj mr ms mt mu bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/ace-your-machine-learning-interview-part-1-e6a5897e6844"> <em class="mv"> Ace your Machine Learning面试—第一部分</em> </a></li><li id="3da3" class="mk ml jg lt b lu mw lx mx le my li mz lm na mj mr ms mt mu bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/linear-regression-and-gradient-descent-using-only-numpy-53104a834f75"> <em class="mv">仅使用Numpy的线性回归和梯度下降</em> </a></li></ol><p id="0cab" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">现在让我们看看如何使用线性回归的变体来解决分类问题。</p><h2 id="216a" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">逻辑回归</strong></h2><p id="b263" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">我们要做的是建立一个模型，输出给定输入属于某个类的概率。</p><p id="1819" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">假设我们的输入数据由矢量<em class="mv"> x </em>表示，我们直线的参数由<em class="mv">矢量θ </em>表示。我们可以通过下面的方式简单地计算通常称为<strong class="lt jh"> <em class="mv"> logit </em> </strong>的第一个分数。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/1040421cccb2236c91048bea5c19be26.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*edOno5Ewu-QDNu8XUD8lpw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Logit(图片由作者提供)</p></figure><p id="0351" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">一旦我们得到这个分数，我们仍然没有能力说我们的<em class="mv"> x </em>是否属于一个概率为<em class="mv"> p </em>的类。我们如何得到这个概率？</p><p id="4254" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">假设我们处于一个<strong class="lt jh"> <em class="mv">二进制分类问题</em> </strong>，那么<em class="mv">一个数据项只能属于0类或者1类</em>。</p><p id="2cdc" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">你要做的是使用一个<strong class="lt jh"> <em class="mv"> sigmoid函数</em> </strong>来估计概率。所以我们的logit将是这个函数的输入。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/f8334cd72f74176244876dc5eecf8d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*lhlxeb8-yleQChTi5SV0og.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">乙状结肠(图片由作者提供)</p></figure><p id="ed0a" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">现在让我们想象一下sigmoid函数在图上的表现。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/6062f8634124f71d923b1aa4ac2f3973.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*a2e-ozEcNCm_s0trFzf-DA.jpeg"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Sigmoid函数(图片由作者提供)</p></figure><p id="840f" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">你可以看到在y轴点<em class="mv"> 0.5 </em>处，函数不知何故分成了两半。然后我们可以说<strong class="lt jh">如果我们得到的分数小于0.5，我们将把我们的<em class="mv"> x </em>归类为<em class="mv"> 0 </em>否则归类为<em class="mv"> 1 </em> </strong>。更正式地说:</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/dd61e5ae1e43e11313a290f92b2d251f.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*ikHEhzeTKUx4nJwhxDP89g.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">决策阈值(图片由作者提供)</p></figure><p id="c1b8" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">我们的目标是找到θ的最佳值，这样我们就能够(几乎)正确地对每个实例进行分类。因此，正如我在线性回归案例中展示的，我邀请你重读这里的<a class="ae jd" rel="noopener" target="_blank" href="/linear-regression-and-gradient-descent-using-only-numpy-53104a834f75"><em class="mv"/></a>，我们再次需要一个<strong class="lt jh"> <em class="mv">成本函数</em></strong><strong class="lt jh">为我们量化模型</strong>产生的误差。单个实例的成本函数如下。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/632711c6fc73fd4865e2c3eb2e032077.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*JmzTalgCaRGTVsXxfloqtw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">单个实例的成本(图片由作者提供)</p></figure><p id="1243" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">我邀请你思考一下为什么上面的成本函数是有意义的。如果将对数的图形可视化，就更容易理解为什么这个成本函数是有意义的。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/6439d92143a3c6570a2587f01bdfecde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9iJplflLrLEzMY3YLnrgbQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">-log(x)和log(x)(图片由作者提供)</p></figure><ul class=""><li id="4ed0" class="mk ml jg lt b lu mm lx mn le mo li mp lm mq mj no ms mt mu bi translated"><strong class="lt jh">当<em class="mv"> x </em>接近<em class="mv"> 0 </em>时，log(x) </strong>变得非常大，因此如果模型估计正实例(实例1)的概率接近0，则<strong class="lt jh">的成本会很高。</strong></li><li id="6ecd" class="mk ml jg lt b lu mw lx mx le my li mz lm na mj no ms mt mu bi translated">对称地，<strong class="lt jh">如果模型估计一个负实例</strong>(实例0)的概率接近1，那么成本将非常高。</li></ul><p id="562a" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">我上面显示的成本是单个实例的成本，如果我们想要整个数据集的成本，我们只需平均所有单个实例的成本。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi np"><img src="../Images/d6dd83988331287cc5d4b62ae8731d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eN7XvHOuG5mECrAdv9ABhQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">总成本函数(图片由作者提供)</p></figure><p id="aeca" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">请注意，所有的父母都有一个女儿，名叫萨拉·阿蒂瓦。一部分是左边的，另一部分是右边的。车安·阿瑟的第一首节奏很快，给人一种非常复杂的感觉。</p><h2 id="04dc" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">多项式逻辑回归</h2><p id="630d" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">逻辑回归可以推广到多个类别。当给定一个输入<em class="mv"> x </em>时，该模型首先计算每个类别<em class="mv"> k </em>的得分<em class="mv"> s_k(x) </em>(类似于logit)，然后使用Softmax函数(也称为<strong class="lt jh">归一化指数</strong>)估计该特定类别的<strong class="lt jh">概率。</strong></p><p id="b332" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">所以首先让我们计算每门课的分数。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/18e310566cb31077ca6754d42cbc9f9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*-1oyPU7ef5SjkAkJaBWLbQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">每堂课的分数(图片由Auhtor提供)</p></figure><p id="f259" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">和以前一样，根据分数，我们可以使用softmax函数计算每个类的概率<strong class="lt jh">。</strong></p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nr"><img src="../Images/99acde4fa8c1a20200bba14071a6e9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LoNYzXzE8vy7mhohpf7Tgw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Softmax函数(图片由作者提供)</p></figure><p id="2438" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">给定每个类的概率，我们选择哪个类？当然<strong class="lt jh">最有可能是</strong>，所以形式上<strong class="lt jh"> argmax超过所有职业</strong>。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/8b2a540d82d2a63b2ea2fb96d297b751.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*3mhgXzWf7k5bBUiRNqb0Pw.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">Argmax over k(图片由作者提供)</p></figure><p id="ca30" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">但是在多项逻辑回归中应该使用哪个<strong class="lt jh">成本函数</strong>？嗯，<strong class="lt jh">交叉熵</strong>。</p><figure class="nf ng nh ni gt is gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/72e36aeb54aef1a4782868018d14a943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*4tDBnqmJvdElSEcVSrhoMA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">交叉熵(作者图片)</p></figure><h2 id="586f" class="kv kw jg bd kx ky kz dn la lb lc dp ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">我们来编码吧！</h2><p id="fdb1" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">现在让我们看看如何使用sklearn实现一个简单的逻辑回归！我想指出的是，我们将简要地看一下sklearn在这个实现中的基本功能，而不涉及数据集分割、预处理等。我们将为这个脚本使用众所周知的<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>。</p><p id="258b" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">首先，我们导入必要的库。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="5ce7" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">我们现在导入数据集，并用熊猫形象化它。数据集由4个数字特征组成，而目标是指示花的类型的多类数。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nu nv l"/></div></figure><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="97f9" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">我们将特征值分配给变量<em class="mv"> x </em>，将目标值分配给<em class="mv"> y </em>。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="4456" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated">现在我们可以使用sklearn函数来预测每个类的概率，或者直接使用predict()(基于argmax)函数来预测类本身。</p><figure class="nf ng nh ni gt is"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h1 id="73ff" class="nw kw jg bd kx nx ny nz la oa ob oc ld km od kn lh kp oe kq ll ks of kt lp og bi translated">最后的想法</h1><p id="d86f" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated">当一个人开始研究分类问题的机器学习时，逻辑回归可能是最重要的算法。这是一个实现起来非常简单的算法，并且在线性可分经典上表现得非常好。我们已经看到，它既可以用于二元分类，也可以用于多元分类。</p><h1 id="c7d6" class="nw kw jg bd kx nx ny nz la oa ob oc ld km od kn lh kp oe kq ll ks of kt lp og bi translated">结束了</h1><p id="f84f" class="pw-post-body-paragraph lr ls jg lt b lu lv kh lw lx ly kk lz le ma mb mc li md me mf lm mg mh mi mj ij bi translated"><em class="mv">马赛洛·波利蒂</em></p><p id="1e75" class="pw-post-body-paragraph lr ls jg lt b lu mm kh lw lx mn kk lz le nb mb mc li nc me mf lm nd mh mi mj ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/marcello-politi/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>，<a class="ae jd" href="https://twitter.com/_March08_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>，<a class="ae jd" href="https://march-08.github.io/digital-cv/" rel="noopener ugc nofollow" target="_blank"> CV </a></p></div></div>    
</body>
</html>