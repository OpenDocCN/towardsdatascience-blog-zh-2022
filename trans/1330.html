<html>
<head>
<title>Denoising Autoencoders (DAE) — How To Use Neural Networks to Clean Up Your Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">去噪自动编码器(DAE)——如何使用神经网络清理数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/denoising-autoencoders-dae-how-to-use-neural-networks-to-clean-up-your-data-cd9c19bc6915#2022-04-04">https://towardsdatascience.com/denoising-autoencoders-dae-how-to-use-neural-networks-to-clean-up-your-data-cd9c19bc6915#2022-04-04</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><h2 id="4161" class="is it iu bd b dl iv iw ix iy iz ja dk jb translated" aria-label="kicker paragraph">神经网络</h2><div class=""/><div class=""><h2 id="858c" class="pw-subtitle-paragraph ka jd iu bd b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr dk translated">使用Tensorflow / Keras库在Python中构建DAE的指南</h2></div><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ks"><img src="../Images/157653f7b6e6b2f6efe76295c484cdfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iXCORmu7vWolNrcqCTMB0A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">去噪自动编码器(DAE)。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h1 id="57e1" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">介绍</h1><p id="a2f8" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">自动编码器提供了一种有效的方法来学习数据的表示，这有助于完成降维或特征提取等任务。你甚至可以训练一个自动编码器来<strong class="md je">识别并去除你数据中的噪音</strong>。</p><p id="15ec" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">本文将快速回顾自动编码器(AE ),并深入探讨一种称为<strong class="md je">去噪自动编码器(DAE)的特定类型。</strong></p><p id="ddf7" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">如果你在找AE降维、特征提取的例子，可以参考我之前的文章:<a class="ae li" rel="noopener" target="_blank" href="/autoencoders-ae-a-smart-way-to-process-your-data-using-unsupervised-neural-networks-9661f93a8509">under complete Autodencoders</a>。</p><h1 id="51da" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">内容</h1><ul class=""><li id="afae" class="nc nd iu md b me mf mh mi mk ne mo nf ms ng mw nh ni nj nk bi translated">机器学习领域中的去噪自动编码器(DAE)</li><li id="a4d7" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">DAE的结构</li><li id="a30f" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">如何使用Keras/Tensorflow在Python中构建DAE</li></ul><h1 id="b3d8" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">机器学习领域中的去噪自动编码器(DAE)</h1><p id="1350" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">自动编码器不同于其他流行类型的神经网络(<a class="ae li" rel="noopener" target="_blank" href="/feed-forward-neural-networks-how-to-successfully-build-them-in-python-74503409d99a">前馈</a>、<a class="ae li" rel="noopener" target="_blank" href="/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92">递归</a>和<a class="ae li" rel="noopener" target="_blank" href="/convolutional-neural-networks-explained-how-to-successfully-classify-images-in-python-df829d4ba761#b32e-f8a4ab5107c5">卷积</a>)，因为它们不需要标记数据来训练它们。因此，我们可以称它们为<strong class="md je">无监督的</strong>，或者，如果我们想要非常精确的话，称它们为<strong class="md je">自监督的</strong>神经网络。</p><p id="5258" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">鉴于神经网络的多样性和它们对机器学习的独特方法，我觉得它们应该被单独归类。</p><p id="f0a3" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">通过<strong class="md je">点击</strong>打开并<strong class="md je">探索</strong>下面的<strong class="md je">交互式旭日图</strong>，看看你是否能找到去噪自动编码器(DAE)👇。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="nq nr l"/></div><p class="le lf gk gi gj lg lh bd b be z dk translated">机器学习算法分类。由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>创建的互动图表。</p></figure><p id="9ac1" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><strong class="md je"> <em class="ns">如果你喜欢数据科学和机器学习</em> </strong> <em class="ns">，请</em> <a class="ae li" href="https://bit.ly/3sItbfx" rel="noopener ugc nofollow" target="_blank"> <em class="ns">订阅</em> </a> <em class="ns">获取我的新文章的邮件。如果你不是中等会员，可以在这里</em>  <em class="ns">加入</em> <a class="ae li" href="https://bit.ly/36Mozgu" rel="noopener ugc nofollow" target="_blank"> <em class="ns">。</em></a></p><h1 id="635d" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">DAE的结构</h1><p id="7176" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">首先，让我们快速回顾一下自动编码器的高级结构。自动编码器的关键组件包括:</p><ul class=""><li id="5cea" class="nc nd iu md b me mx mh my mk nt mo nu ms nv mw nh ni nj nk bi translated"><strong class="md je">输入层</strong> —将输入数据传入网络</li><li id="546b" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><strong class="md je">隐藏层</strong>由<strong class="md je">编码器</strong>和<strong class="md je">解码器— </strong>组成，通过应用权重、偏置和激活函数来处理信息</li><li id="bdf8" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><strong class="md je">输出层</strong> —通常匹配输入神经元</li></ul><p id="1e8a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">以下是对上述总结的说明:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj nw"><img src="../Images/c5488f2bcf2c771d36973da30e3efbee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JwnlfIm4MmlFcPH5QaUIg.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">自动编码器神经网络中各层的高级图示。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="c000" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">最常见的自动编码器类型是<a class="ae li" rel="noopener" target="_blank" href="/autoencoders-ae-a-smart-way-to-process-your-data-using-unsupervised-neural-networks-9661f93a8509">欠完整自动编码器</a>，它将数据压缩(编码)到更少的神经元(更低的维度)中，同时删除“不重要”的信息。它通过同时训练编码器和解码器来实现这一点，因此输出神经元尽可能地匹配输入。</p><p id="5973" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">以下是欠完整自动编码器的网络图示例:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj nx"><img src="../Images/428b76af88b44684555933545be22523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgMGbqdPXCpDjfbQWzyAzQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">欠完全自动编码器神经网络。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供，使用<a class="ae li" href="http://alexlenail.me/NN-SVG/index.html" rel="noopener ugc nofollow" target="_blank"> AlexNail的NN-SVG工具</a>创建。</p></figure><h2 id="50e0" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated"><strong class="ak">去噪自动编码器(DAE) </strong></h2><p id="88c8" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">DAE的目的是消除噪音。你也可以把它想象成一个为你的数据定制的去噪算法。</p><p id="2d5b" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">注意对单词<strong class="md je">定制</strong>的强调。假设我们在一组特定的数据上训练DAE，它将被优化以消除相似数据中的噪声。例如，如果我们训练它从一组图像中去除噪声，它将在相似的图像上工作得很好，但不适合清理文本数据。</p><p id="9f4a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">与不完全AE不同，我们可以在隐藏层中使用相同或更多数量的神经元，使DAE <strong class="md je">过度完全</strong>。</p><p id="b1d9" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">第二个区别来自于没有使用相同的输入和输出。相反，输出是原始数据(例如，图像)，而输入包含带有一些添加噪声的数据。</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj oj"><img src="../Images/97d23e9867c94ab0ea0ec2e2783d432e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtzVl3JcRkn-y-gd-pGv9A.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">去噪自动编码器架构。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="eeff" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">上面的例子是一个DAE设置去噪MNIST手写数字。在下一节中，我将向您展示如何设置和训练这样的DAE。</p><div class="kt ku kv kw gu ab cb"><figure class="ok kx ol om on oo op paragraph-image"><a href="https://solclover.com/membership"><img src="../Images/63320331b74bd98eea6402472b4209ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qkXay39OnVc2IosW6rkxtw.png"/></a></figure><figure class="ok kx ol om on oo op paragraph-image"><a href="https://www.linkedin.com/in/saulius-dobilas/"><img src="../Images/60fb21d1cb2701bfb6b71f61c99403e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vabxOXtQ4T034N_mscHSmQ.png"/></a></figure></div><h1 id="a6a1" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated"><strong class="ak">如何使用Keras/Tensorflow在Python中构建DAE？</strong></h1><h2 id="1274" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated">设置</h2><p id="739f" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">我们需要以下数据和库:</p><ul class=""><li id="1cb2" class="nc nd iu md b me mx mh my mk nt mo nu ms nv mw nh ni nj nk bi translated"><a class="ae li" href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data" rel="noopener ugc nofollow" target="_blank"> MNIST手写数字数据</a>(版权由Yann LeCun和Corinna Cortes根据<a class="ae li" href="https://creativecommons.org/licenses/by-sa/3.0/" rel="noopener ugc nofollow" target="_blank">知识共享署名-分享3.0许可</a>持有；数据的原始来源:<a class="ae li" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">MNIST数据库</a></li><li id="ee98" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae li" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> Numpy </a>用于数据操作</li><li id="9e63" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">用于一些基本可视化的<a class="ae li" href="https://matplotlib.org/stable/api/index.html" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>和<a class="ae li" href="https://graphviz.org/" rel="noopener ugc nofollow" target="_blank"> Graphviz </a></li><li id="390e" class="nc nd iu md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated"><a class="ae li" href="https://www.tensorflow.org/api_docs/python/tf" rel="noopener ugc nofollow" target="_blank">神经网络的Tensorflow/Keras </a></li></ul><p id="a985" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">让我们导入所有的库:</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><p id="586f" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">上面的代码打印了本例中使用的包版本:</p><pre class="kt ku kv kw gu or os ot ou aw ov bi"><span id="d8ea" class="ny lk iu os b gz ow ox l oy oz">Tensorflow/Keras: 2.7.0<br/>numpy: 1.21.4<br/>matplotlib: 3.5.1<br/>graphviz: 0.19.1</span></pre><p id="eca7" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">接下来，我们加载MNIST手写数字数据并显示前十位数字。请注意，我们可以去掉标签，因为我们在模型中不使用它们，但我保留了它们，所以我们知道更难阅读的数字是什么。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><p id="26ee" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">这是我们运行上述代码得到的结果:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pa"><img src="../Images/4ce41cd8af15772c81a2c50a4102e2ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WIMtOpzRY1p0Z9DL4bh-yw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">MNIST数据集的前十位数字。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="9e5a" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">如您所见，我们在训练集中有60，000张图像，在测试集中有10，000张图像。请注意，它们的尺寸是28 x 28像素。</p><p id="f47c" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">现在是时候给我们的图像添加一些噪声了。使用下面的代码，您可以指定噪声的级别，这当然会影响最终的模型。我们添加的噪声越多，模型就越难清理。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><p id="4dcc" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">这就是我们嘈杂的图像的样子:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pb"><img src="../Images/63b11864c619bc1d649f7aea8f21b0bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GxUgC0G4a1BmEbKvrxtTVA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">有附加噪声的MNIST数字。图片来自<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>。</p></figure><p id="fc79" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">在大多数情况下，这些数字仍然是可读的，但是很难说出它是什么数字。</p><p id="b2c4" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">构建DAE之前的最后一步是重塑我们的输入。展平我们的映像的原因是，在本例中，我们将制作一个标准DAE，而不是卷积DAE。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><p id="3475" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">以下是我们的MNIST图像数据的新形状:</p><pre class="kt ku kv kw gu or os ot ou aw ov bi"><span id="e4fd" class="ny lk iu os b gz ow ox l oy oz">New shape of X_train:  (60000, 784)<br/>New shape of X_test:  (10000, 784)<br/>New shape of X_train_noisy:  (60000, 784)<br/>New shape of X_test_noisy:  (10000, 784)</span></pre><h2 id="3026" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated">构建去噪自动编码器</h2><p id="6fd2" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">现在，我们将组装和训练我们的DAE神经网络。我们可以使用Keras顺序模型或Keras Functional API来实现。在下面的例子中，我选择了后者。</p><p id="d534" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">请注意，我在每一层都保留了相同数量的神经元(784)，并在中间层添加了L1正则化以控制过度拟合。然而，这个模型决不是最佳的，所以您应该仅将它作为试验不同结构和超参数的起点。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><p id="5777" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">上面的代码打印了两项内容。第一个是模型总结:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pc"><img src="../Images/4a543e346f6abebb31334b8ec5e9914f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T0ErOtd6dXtza3VIji50zw.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">去噪自动编码器模型概述。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="52ac" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">第二部分是看待模型结构的一种略微不同的方式，有些人更喜欢这种方式:</p><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pd"><img src="../Images/8052c4c2452c35d05c38e32efc1e1c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8B9_sV3PpKJDpWZfiVckeA.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">去噪自动编码器模型图。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="a171" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">组装好模型后，让我们对其进行20个时期的训练，并绘制损失图。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pe"><img src="../Images/e56cae3257a3423267446618fe59d33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZpnHycujyhXwmu-YP0WxuQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">通过历元去噪自动编码器模型损失。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="9095" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">最后，是时候对我们的模型进行可视化评估了。我们将使用<strong class="md je">测试数据集</strong>并显示来自<strong class="md je">原始</strong>、<strong class="md je">噪声</strong>和<strong class="md je">去噪</strong>集的十幅图像进行比较。</p><h2 id="bde9" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated"><strong class="ak">原文</strong></h2><p id="46d1" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">请注意，我们必须将尺寸调整回28 x 28。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pf"><img src="../Images/04aa9769ae01e88c6af478cc60bd2050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*98SZU_nLr9ZdYoVNSdWlwQ.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">来自测试数据集的十幅原始图像。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><h2 id="7eea" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated"><strong class="ak">嘈杂</strong></h2><p id="7d0b" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">现在我们来看看添加了噪声的图像。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj pg"><img src="../Images/6669725dbd1e7bf0b8e1a180703fa564.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jv3-CQeDk5H4S_D2v60tew.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">来自测试数据集的10个噪声图像。图片来自<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>。</p></figure><h2 id="9894" class="ny lk iu bd ll nz oa dn lp ob oc dp lt mk od oe lv mo of og lx ms oh oi lz ja bi translated"><strong class="ak">去噪</strong></h2><p id="cc4f" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated">最后，让我们使用DAE来处理有噪声的图像并显示输出。</p><figure class="kt ku kv kw gu kx"><div class="bz fq l di"><div class="oq nr l"/></div></figure><figure class="kt ku kv kw gu kx gi gj paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gi gj ph"><img src="../Images/e4ae2246d57cd9d4dd8b78529bee4f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiIoPYdGq4pVnW2VZb5tww.png"/></div></div><p class="le lf gk gi gj lg lh bd b be z dk translated">应用DAE神经网络模型后，来自测试数据集的10个图像。图片由<a class="ae li" href="https://solclover.com/" rel="noopener ugc nofollow" target="_blank">作者</a>提供。</p></figure><p id="1976" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">尽管我们没有试验不同的网络设置和超参数调整，但结果令人印象深刻。我相信您可以创建一个性能更好的DAE。试一试，让我知道结果如何！</p><h1 id="e840" class="lj lk iu bd ll lm ln lo lp lq lr ls lt kj lu kk lv km lw kn lx kp ly kq lz ma bi translated">结束语</h1><p id="0228" class="pw-post-body-paragraph mb mc iu md b me mf ke mg mh mi kh mj mk ml mm mn mo mp mq mr ms mt mu mv mw in bi translated"><strong class="md je">去噪自动编码器是神经网络的一个迷人应用，有现实生活中的用例</strong>。除了对图像去噪之外，还可以使用它们在模型管线中预处理数据。让我知道你如何在你的数据科学项目中使用它们！</p><p id="2905" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">为了您的方便，我在我的<a class="ae li" href="https://github.com/SolClover/Art048_NN_DAE" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中保存了一个Jupyter笔记本，其中包含了上述所有代码。在构建自己的去噪自动编码器时，可以随意使用它作为指南。</p><p id="367b" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated">干杯！🤓<br/>T3【索尔·多比拉斯】T4</p></div><div class="ab cl pi pj hy pk" role="separator"><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn po"/><span class="pl bw bk pm pn"/></div><div class="in io ip iq ir"><p id="2efc" class="pw-post-body-paragraph mb mc iu md b me mx ke mg mh my kh mj mk mz mm mn mo na mq mr ms nb mu mv mw in bi translated"><strong class="md je"> <em class="ns">通过以下我的个性化链接加入Medium，继续您的数据科学之旅</em></strong><em class="ns">:</em></p><div class="pp pq gq gs pr ps"><a href="https://bit.ly/3J6StZI" rel="noopener  ugc nofollow" target="_blank"><div class="pt ab fp"><div class="pu ab pv cl cj pw"><h2 class="bd je gz z fq px fs ft py fv fx jd bi translated">通过我的推荐链接加入Medium索尔·多比拉斯</h2><div class="pz l"><h3 class="bd b gz z fq px fs ft py fv fx dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="qa l"><p class="bd b dl z fq px fs ft py fv fx dk translated">solclover.com</p></div></div><div class="qb l"><div class="qc l qd qe qf qb qg lc ps"/></div></div></a></div></div></div>    
</body>
</html>