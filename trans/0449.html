<html>
<head>
<title>Run a SageMaker TensorFlow object detection model in batch mode</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以批处理模式运行 SageMaker TensorFlow 对象检测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/run-a-sagemaker-tensorflow-object-detection-model-in-batch-mode-66989346390b#2022-02-17">https://towardsdatascience.com/run-a-sagemaker-tensorflow-object-detection-model-in-batch-mode-66989346390b#2022-02-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6a92" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用 Sagemaker 批量转换作业处理大型图像</h2></div><p id="3e73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于一个计算机视觉项目，我需要在一大组图像上应用对象检测模型。这篇博文描述了如何在 Amazon SageMaker 中通过 TensorFlow 对象检测模型 API 使用批量转换作业来实现这一点。</p><p id="e108" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，基于一个 AWS 示例笔记本，我将解释如何使用 SageMaker 端点在单个图像上运行模型。对于小图像，这种方法是可行的，但是对于大图像，我们会遇到问题。为了解决这些问题，我改用批量转换作业。最后，我最后说几句话。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/46d5bf76ed1f627f0d2fb676e28bc5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9JC-wMTlb-EflvuxeDApNA.png"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">用于检测徽标的对象检测。图片由作者提供。</p></figure><h1 id="448d" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">起点:使用 SageMaker TensorFLow 对象检测 API 进行模型推断</h1><p id="a831" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">AWS 在 GitHub 上提供了一些<a class="ae mo" href="https://github.com/aws-samples/" rel="noopener ugc nofollow" target="_blank">如何使用 SageMaker 进行物体检测的好例子。我用这个例子通过一个使用 TensorFlow 对象检测 API 的对象检测模型进行预测:</a><a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS-samples/Amazon-sage maker-tensor flow-object-detection-API</a>。</p><p id="4bbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当模型被部署为端点时，您可以通过调用端点，一次一个图像地使用模型进行推理。这段代码摘自示例笔记本，展示了如何定义 TensorFlowModel 并将其部署为模型端点:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api/blob/main/3_predict/deploy_endpoint.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS-samples/Amazon-sage maker-tensor flow-object-detection-API/blob/main/3 _ predict/deploy _ endpoint . ipynb</a>。</p></figure><p id="3562" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，将图像作为 NumPy 数组加载，并作为列表进行解析，以便将其传递给端点:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api/blob/main/3_predict/deploy_endpoint.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS-samples/Amazon-sage maker-tensor flow-object-detection-API/blob/main/3 _ predict/deploy _ endpoint . ipynb</a>。</p></figure><p id="1db1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，调用端点:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api/blob/main/3_predict/deploy_endpoint.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS-samples/Amazon-sage maker-tensor flow-object-detection-API/blob/main/3 _ predict/deploy _ endpoint . ipynb</a>。</p></figure><p id="e901" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，完整的笔记本可以在<a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api/blob/main/3_predict/deploy_endpoint.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="5138" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">问题:端点请求负载太大</h1><p id="6470" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">这在使用小图像时非常好，因为 API 调用的请求负载足够小。但是，当使用较大的图片时，API 会返回 413 错误。这意味着有效负载超过了<a class="ae mo" href="https://docs.aws.amazon.com/general/latest/gr/sagemaker.html#limits_sagemaker" rel="noopener ugc nofollow" target="_blank">允许的大小</a>，即 6 MB。</p><p id="fe4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，我们可以在调用端点之前调整图像的大小，但是我想使用<a class="ae mo" href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#run-a-batch-transform-job" rel="noopener ugc nofollow" target="_blank">批处理转换作业</a>。</p><h1 id="9d5f" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">解决方案:改用批处理转换作业</h1><p id="903c" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">使用 SageMaker 批处理转换作业，您可以定义自己的最大有效负载大小，这样我们就不会遇到 413 错误。除此之外，这些作业可以用来一次性处理全套图像。</p><p id="708e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些图像需要存储在 S3 桶上。所有图像都以批处理模式处理(顾名思义),预测也存储在 S3 上。为了使用批处理转换作业，我们再次定义了一个 TensorFlowModel，但是这次我们还定义了一个<code class="fe mr ms mt mu b">entry_point</code>和一个<code class="fe mr ms mt mu b">source_dir</code>:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mo" href="https://github.com/aws-samples/amazon-sagemaker-tensorflow-object-detection-api/blob/main/3_predict/deploy_endpoint.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/AWS-samples/Amazon-sage maker-tensor flow-object-detection-API/blob/main/3 _ predict/deploy _ endpoint . ipynb</a>并由作者改编。</p></figure><p id="4e2c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe mr ms mt mu b">inference.py</code>代码转换模型的输入和输出数据，如<a class="ae mo" href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#how-to-implement-the-pre-and-or-post-processing-handler-s" rel="noopener ugc nofollow" target="_blank">文档</a>中所述。这段代码需要将请求负载(图像)更改为 NumPy 数组，解析为 list 对象。从这个例子开始，我修改了代码，让它加载图像并将其转换成 NumPy 数组。<code class="fe mr ms mt mu b">inference.py</code>中<code class="fe mr ms mt mu b">input_handler</code>功能的内容变更如下:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">来源:<a class="ae mo" href="https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/using_tf.html#how-to-implement-the-pre-and-or-post-processing-handler-s" rel="noopener ugc nofollow" target="_blank">https://sage maker . readthe docs . io/en/stable/frameworks/tensor flow/using _ TF . html # how-to-implementation-the-pre-and-or-post-processing-handler-s</a>并由作者改编。</p></figure><p id="2890" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，我在上面的代码中排除了<code class="fe mr ms mt mu b">output_handler</code>函数。确保在您的代码中也包含该函数(取自文档)。</p><p id="dd21" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该函数需要 Python 包 NumPy 和 Pillow，它们没有安装在运行批处理推理作业的映像上。我们可以创建自己的图像并使用那个图像(在初始化 TensorFlowModel 对象时使用<code class="fe mr ms mt mu b">image_uri</code>关键字)，或者我们可以提供一个<code class="fe mr ms mt mu b">requirements.txt</code>并将它存储在与您的笔记本相同的文件夹中(称为<code class="fe mr ms mt mu b">source_dir='.’</code>)。该文件在映像启动过程中使用，以便使用 pip 安装所需的软件包；内容是:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">内容由作者提供。</p></figure><p id="cbf3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我想使用 OpenCV(就像端点示例中一样)，但是这个包不太容易安装。</p><p id="f09b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在使用模型来创建一个 transformer 对象，而不是将模型部署为模型端点:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者代码。</p></figure><p id="bfd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，使用输入路径调用转换器:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="mp mq l"/></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">作者代码。</p></figure><p id="9b8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">瞧！图像由模型处理，结果将作为 JSON 文件保存在<code class="fe mr ms mt mu b">output_path</code>桶中。命名等同于输入文件名，后跟一个<code class="fe mr ms mt mu b">.out</code>扩展名。顺便说一下，您还可以调整和优化实例类型、最大负载等。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mv"><img src="../Images/580bd425b036eb3e6ce8d4b28030946b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tPcjEe1PAr_eHEw0"/></div></div><p class="ln lo gj gh gi lp lq bd b be z dk translated">布鲁斯·马尔斯在<a class="ae mo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><h1 id="7714" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">最后的想法</h1><p id="3f57" class="pw-post-body-paragraph kf kg iq kh b ki mj jr kk kl mk ju kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">这很可能不是最划算的方法，因为我们将图像作为 NumPy 数组传递给转换器。从<a class="ae mo" href="https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_batch_transform/tensorflow_open-images_jpg/tensorflow-serving-jpg-python-sdk.ipynb" rel="noopener ugc nofollow" target="_blank">的另一个示例笔记本</a>中，我发现建议您的 SavedModel 应该接受二进制数据的 base-64 编码字符串，因为二进制数据的 JSON 表示可能很大。</p><p id="f112" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我们可以调整<code class="fe mr ms mt mu b">inference.py</code>中的<code class="fe mr ms mt mu b">output_handler</code>函数来压缩返回并存储在 S3 上的 JSON，或者只返回相关的检测。</p></div></div>    
</body>
</html>