<html>
<head>
<title>The Bayesian Bootstrap</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯自助</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-bayesian-bootstrap-6ca4a1d45148#2022-08-08">https://towardsdatascience.com/the-bayesian-bootstrap-6ca4a1d45148#2022-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="d8e6" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/causal-data-science" rel="noopener" target="_blank">因果数据科学</a></h2><div class=""/><div class=""><h2 id="b60c" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated"><em class="ko">简单而强大的bootstrap扩展的简短指南</em></h2></div><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/f97412551e919ce6038e76ff5775272f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WEgBbUfwhc2Od1oBNGCYzA.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">封面图片，由作者使用<a class="ae lf" href="https://creator.nightcafe.studio/" rel="noopener ugc nofollow" target="_blank">nightcafe</a>生成</p></figure><p id="54c6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在因果推断中，我们不仅仅想要计算治疗效果，我们还想要进行<strong class="li ja">推断</strong>。理解围绕点估计的不确定性通常比点本身更有信息和价值。在某些情况下，由于<a class="ae lf" href="https://en.wikipedia.org/wiki/Central_limit_theorem" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja">中心极限定理</strong> </a>，计算估计量的(渐近)分布非常容易。例如，在计算AB试验或随机对照试验中的平均治疗效果时就是这种情况。然而，在其他情况下，推断更加复杂<strong class="li ja"/>，要么是因为很难获得方差的分析估计量，要么是因为它需要难以估计的对象(例如分位数回归中的全密度)。那我们能做什么？</p><p id="2caa" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja"> bootstrap </strong>是数据科学的标准答案。这是一个非常强大的程序来估计一个估计量的分布，不需要任何数据生成过程的知识。实现起来也非常<strong class="li ja">直观和简单</strong>:只需通过多次替换对数据进行重新采样，然后计算样本间的估计值。</p><p id="1703" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们能做得更好吗？答案是肯定的！贝叶斯自举<strong class="li ja">是一个强大的程序，在很多设置中比自举执行<strong class="li ja">更好</strong>。特别是，它通常更快，可以给出更紧的置信区间，并避免了许多极限情况。在本文中，我们将更详细地探讨这个简单但功能强大的过程。</strong></p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="827f" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">自举</h1><p id="664b" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">bootstrap是一种通过随机<strong class="li ja">重新采样并替换数据</strong>来计算估计器属性的程序。它首先由Efron (1979) 提出，现在是数据科学中的标准推理过程。程序非常简单，由以下<strong class="li ja">步骤</strong>组成。</p><p id="260b" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">假设你有一个i.i.d .样本{ <em class="ng"> X </em> ᵢ}ᵢⁿ，你想使用估计量<em class="ng">θ̂(x】</em>计算一个统计量<em class="ng"> θ </em>。你可以用下面的公式来近似θ̂的分布。</p><ol class=""><li id="6f08" class="nh ni iq li b lj lk lm ln lp nj lt nk lx nl mb nm nn no np bi translated">样本<em class="ng"> n </em>观察值与替换样本{<em class="ng">x̃</em>ᵢ}ᵢⁿ{<em class="ng">x</em>ᵢ}ᵢⁿ.</li><li id="f1f7" class="nh ni iq li b lj nq lm nr lp ns lt nt lx nu mb nm nn no np bi translated">计算估计量<em class="ng"> θ̂-bootstrap </em> ( <em class="ng"> X̃ </em>)。</li><li id="f287" class="nh ni iq li b lj nq lm nr lp ns lt nt lx nu mb nm nn no np bi translated">多次重复步骤1和2。</li></ol><p id="3016" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="ng"> θ̂-bootstrap </em>的分布与<em class="ng"> θ̂ </em>的分布非常接近。</p><p id="5dab" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">自举为什么这么厉害？</strong></p><p id="cca8" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先是<strong class="li ja">容易实现</strong>。除了已经在做的事情之外，它不需要你做任何事情:估计<em class="ng"> θ </em>。你只需要做很多次<em class="ng"/>。事实上，bootstrap的主要缺点是它的计算成本。如果你的估算过程很慢，自举就变得禁止了。</p><p id="54db" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">第二，bootstrap使得<strong class="li ja">没有分布假设</strong>。它只假设你的样本是总体的代表，观测值是相互独立的。当观察结果彼此紧密相连时，例如在研究社会网络或市场互动时，这一假设可能会被违反。</p><p id="be4e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><strong class="li ja">bootstrap只是加权吗？</strong></p><p id="781e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">最后，当我们重新采样时，我们所做的是给我们的观察值分配整数权重，这样它们的总和就等于样本大小。这样的分布就是<a class="ae lf" href="https://en.wikipedia.org/wiki/Multinomial_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja">多项式分布</strong> </a>。</p><p id="9721" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们通过抽取一个大小为10.000的样本来看看多项分布是什么样的。我从<code class="fe nv nw nx ny b"><a class="ae lf" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py" rel="noopener ugc nofollow" target="_blank">src.utils</a></code>导入了一组标准库和函数。为了不仅包括代码，还包括像数据和表格这样的输出，我使用了<a class="ae lf" href="https://deepnote.com/" rel="noopener ugc nofollow" target="_blank"> Deepnote </a>，一个类似Jupyter的基于网络的协作笔记本环境。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="dc42" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，我们检查权重的总和是否为1000，或者说，我们生成了相同大小的数据的重新样本。</p><p id="9489" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们现在可以绘制<strong class="li ja">权重分布</strong>。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ob oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oc"><img src="../Images/8e430e6c2809eb0230110a3a9172c6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1GjQeQGCjNEhymY7sQYBKg.png"/></div></div></figure><p id="344a" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">如我们所见，大约3600个观察值的权重为零，而几个观察值的权重为6。或者相当于，大约3600个观察值没有被重新采样，而几个观察值被采样了多达6次。</p><p id="9dda" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">现在你可能会有一个自然而然的问题:为什么不使用<strong class="li ja">连续砝码</strong>来代替离散砝码？</p><p id="3ecf" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">非常好的问题！<strong class="li ja">贝叶斯自举</strong>就是答案。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="9b11" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">贝叶斯自助</h1><p id="600d" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">贝叶斯自助法是由<a class="ae lf" href="https://www.jstor.org/stable/2240875" rel="noopener ugc nofollow" target="_blank"> Rubin (1981) </a>提出的，它基于一个非常简单的<strong class="li ja">想法</strong>:为什么不画一个更平滑的权重分布呢？多项式分布的连续等价物是<a class="ae lf" href="https://en.wikipedia.org/wiki/Dirichlet_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja">狄利克雷分布</strong> </a>。下面我绘制了单次观察的多项式和狄利克雷权重的概率分布(它们分别是泊松分布和伽玛分布)。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi od"><img src="../Images/45320ab30bedd99f2a6bee7c7ec0203b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FU_qUPgbuV6aLpJayyv-yg.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">比较权重分布，按作者分类的图像</p></figure><p id="fc49" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">贝叶斯自举有很多优点。</p><ul class=""><li id="7ad1" class="nh ni iq li b lj lk lm ln lp nj lt nk lx nl mb oe nn no np bi translated">第一个也是最直观的一个是，由于它的连续加权方案，它提供的估计比正常的bootstrap更加平滑。</li><li id="e466" class="nh ni iq li b lj nq lm nr lp ns lt nt lx nu mb oe nn no np bi translated">此外，连续加权方案<strong class="li ja">防止了拐角情况</strong>的出现，因为任何观测都不会得到零权重。例如，在线性回归中，如果原始样本中没有共线性问题，则不会出现共线性问题。</li><li id="7674" class="nh ni iq li b lj nq lm nr lp ns lt nt lx nu mb oe nn no np bi translated">最后，作为贝叶斯方法，我们得到<strong class="li ja">解释</strong>:估计量的估计分布可以解释为<a class="ae lf" href="https://en.wikipedia.org/wiki/Posterior_probability" rel="noopener ugc nofollow" target="_blank">后验分布</a>和<a class="ae lf" href="https://en.wikipedia.org/wiki/Prior_probability" rel="noopener ugc nofollow" target="_blank">无信息先验</a>。</li></ul><p id="255e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们现在画一组狄利克雷权重。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="of oa l"/></div></figure><p id="a686" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">权重自然总和(大约)为1，所以我们必须用因子n对它们进行缩放。</p><p id="a06c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">和以前一样，我们可以绘制重量分布图，不同的是现在我们有连续的重量，所以我们必须近似分布。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ob oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oc"><img src="../Images/edbaf2e49a00e0eb5e8aa57135316292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YiHNtQZHGtQnKSsHL8ZGwA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">狄利克雷权重示例，图片由作者提供</p></figure><p id="45f2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">您可能已经注意到，狄利克雷分布有一个<strong class="li ja">参数<em class="ng"> α </em> </strong>，我们已经将它设置为所有观测值的1。它是做什么的？</p><p id="75ee" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="ng"> α </em>参数本质上决定了被采样的绝对和相对概率。增加所有观察值的<em class="ng"> α </em>使得分布不那么偏斜，从而所有观察值具有更相似的权重。对于<em class="ng"> α→∞ </em>，所有的观测值得到相同的权重，我们回到原始样本。</p><p id="6522" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们应该如何<strong class="li ja">选择<em class="ng">α</em>T35】的值？<a class="ae lf" href="https://link.springer.com/book/10.1007/978-1-4612-0795-5" rel="noopener ugc nofollow" target="_blank">邵和涂(1995) </a>建议如下。</strong></p><blockquote class="og oh oi"><p id="ae62" class="lg lh ng li b lj lk ka ll lm ln kd lo oj lq lr ls ok lu lv lw ol ly lz ma mb ij bi translated">随机权重向量的分布不必局限于Diri(l，…，1)。后来的研究发现，具有比例Diri(4，…，4)分布的权重给出了更好的近似(涂和郑，1987)</p></blockquote><p id="f8e3" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们来看看，对于所有观测值来说，<em class="ng"> α=4 </em>的狄利克雷分布与之前对于所有观测值来说，<em class="ng"> α=1 </em>的分布相比如何。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="om oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi oc"><img src="../Images/8b68444d62cff531d1b9eed00bbc52d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n5d3UoHFsKJR3vbEv6CrTA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">不同<em class="ko"> α的狄利克雷权重样本，图片作者</em></p></figure><p id="ed3c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">新的分布更少偏斜，更集中在平均值1附近。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="77c2" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">例子</h1><p id="9345" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">让我们看几个例子，比较两种推理过程。</p><h2 id="652c" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">偏态分布的平均值</h2><p id="4fcc" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">首先，让我们来看看最简单也是最常见的估计量之一:<strong class="li ja">样本均值</strong>。首先，让我们从一个<a class="ae lf" href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noopener ugc nofollow" target="_blank">帕累托分布</a>中抽取100个观察值。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="oy oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="ab gu cl oz"><img src="../Images/e0b9e772963e9883f4c0b1b3a54fd8c3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1SlRGXyNuJNjWEl5t_pW_Q.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">来自帕累托分布的样本，图片由作者提供</p></figure><p id="05d2" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这种分布非常<strong class="li ja">偏斜</strong>，一些观察值比平均值高得多。</p><p id="052d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">首先，让我们计算一个再抽样的经典bootstrap估计量。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="om oa l"/></div></figure><p id="1cbf" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">然后，让我们写一组随机权重的贝叶斯自举。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa oa l"/></div></figure><p id="2f27" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们现在可以实现任何引导程序。我使用<code class="fe nv nw nx ny b"><a class="ae lf" href="https://joblib.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">joblib</a></code>库来并行化计算。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pa oa l"/></div></figure><p id="9f0f" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">最后，让我们编写一个比较结果的函数。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pb oa l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ob oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pc"><img src="../Images/06e5410ab8a7526afa0dd917be77a29a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-4cIFrMP4xn1Nnry27HF1A.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">样本均值的Bootstrap分布，按作者分类的图像</p></figure><p id="5c3d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这个设置中，两个程序给出了非常相似的答案。这两个分布非常接近，而且估计量的估计均值和标准差几乎相同，与bootstrap过程无关。</p><p id="e083" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">哪个引导程序<strong class="li ja">更快</strong>？</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pd oa l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pe oa l"/></div></figure><p id="a73c" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在97.8%的模拟中，贝叶斯bootstrap比经典bootstrap快，并且快了令人印象深刻的66.5%！</p><h2 id="622b" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">不加权？没问题</h2><p id="0136" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">如果我们有一个不接受权重的估计量，比如中位数，会怎么样？我们可以做<strong class="li ja">两级抽样</strong>:首先我们对权重进行抽样，然后根据权重对观测值进行抽样。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pf oa l"/></div></figure><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="oy oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pg"><img src="../Images/e92656a7f74523d50e0136e4303ec15c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7gVU_vn1We0ZrdALvEADBA.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">样本中位数的Bootstrap分布，按作者分类的图像</p></figure><p id="f133" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这种情况下，贝叶斯Bootstrap也比经典Bootstrap<strong class="li ja">更精确</strong>，因为<em class="ng"> α=4时的权重分布更密集。</em></p><h2 id="8feb" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">结果罕见的逻辑回归</h2><p id="747a" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">现在让我们探索经典自举可能陷入<strong class="li ja">困境</strong>的两种设置中的第一种。假设我们观察到一个特征<em class="ng"> x </em>，正态分布，以及一个二元结果<em class="ng"> y </em>。我们对这两个变量之间的关系感兴趣。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ph oa l"/></div></figure><p id="84d6" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这个样本中，我们只在100次观察中的10次观察到阳性结果。</p><p id="b948" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">由于结果是二元的，我们拟合一个<a class="ae lf" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="li ja">逻辑回归</strong> </a>模型。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pi oa l"/></div></figure><p id="b513" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们得到的点估计值为<em class="ng"> -23 </em>，置信区间非常小。</p><p id="ff94" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">我们能自助估计量的分布吗？让我们尝试计算1000个bootstrap样本的逻辑回归系数。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pj oa l"/></div></figure><p id="8a2e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">对于1000个样本中的5个，我们<strong class="li ja">无法</strong>计算估计值。使用贝叶斯自举不会发生这种情况。</p><p id="2491" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">在这种情况下，这似乎是一个无关紧要的问题:我们可以忽略这些观察。让我们以一个更危险的例子来结束。</p><h2 id="df1f" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">用很少的处理单元回归</h2><p id="da99" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">假设我们观察到一个二元特征<em class="ng"> x </em>和一个连续结果<em class="ng"> y </em>。我们再次对这两个变量之间的关系感兴趣。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="ph oa l"/></div></figure><p id="07cb" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">让我们比较一下<em class="ng"> x </em>上<em class="ng"> y </em>回归系数的两个bootstrap估计量。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pk oa l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi pg"><img src="../Images/0df6cbe9fa57f7ae89386fcf904a2607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNBZAKNGOYHLe3aSRxo86Q.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者自举分布图</p></figure><p id="304e" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">经典的bootstrap程序估计的方差比我们的估计量大50%。为什么？如果我们更仔细地观察，我们会发现在近20个重新样本中，我们得到了一个非常不寻常的零估计值！为什么？</p><p id="8f02" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">问题是，在某些样本中，我们可能没有任何观察值<strong class="li ja">x = 1。因此，在这些重新采样中，估计系数为零。贝叶斯自助不会发生这种情况，因为它不会丢弃任何观察值(所有观察值总是得到正权重)。</strong></p><p id="f633" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这里有问题的部分是我们没有得到任何错误消息或警告。这种偏见非常狡猾，很容易被忽视！</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="a3eb" class="mj mk iq bd ml mm mn mo mp mq mr ms mt kf mu kg mv ki mw kj mx kl my km mz na bi translated">结论</h1><p id="d0aa" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">在本文中，我们看到了bootstrap的一个强大扩展:贝叶斯bootstrap。关键思想是，只要我们的估计量可以表示为加权估计量，bootstrap就相当于带有多项式权重的随机加权。贝叶斯自助相当于用狄利克雷权重加权，即多项式分布的连续等价。具有连续的权重避免了极限情况，并且可以生成估计量的更平滑的分布。</p><p id="ea77" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">这篇文章的灵感来自布朗大学教授<a class="ae lf" href="https://sites.google.com/site/aboutpeterhull/home" rel="noopener ugc nofollow" target="_blank">彼得·赫尔</a>的以下推文。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="pl oa l"/></div></figure><p id="1acc" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">事实上，除了是一个简单和直观的程序，贝叶斯Bootstrap并不是经济学研究生院标准计量经济学课程的一部分。</p><h2 id="5dae" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">参考</h2><p id="86d2" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">[1] B. Efron <a class="ae lf" href="https://www.jstor.org/stable/2958830" rel="noopener ugc nofollow" target="_blank"> Bootstrap方法:再看刀切</a>(1979)<em class="ng">《统计年鉴》</em>。</p><p id="0977" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[2] D .鲁宾，<a class="ae lf" href="https://www.jstor.org/stable/2240875" rel="noopener ugc nofollow" target="_blank">《贝叶斯自助法》</a> (1981)，<em class="ng">《统计年鉴》</em>。</p><p id="cf35" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[3] A. Lo，<a class="ae lf" href="https://www.jstor.org/stable/2241087" rel="noopener ugc nofollow" target="_blank">贝叶斯自助法的大样本研究</a> (1987)，<em class="ng">《统计年鉴》</em>。</p><p id="3e13" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated">[4] J .邵，d .涂，<a class="ae lf" href="https://link.springer.com/book/10.1007/978-1-4612-0795-5" rel="noopener ugc nofollow" target="_blank">杰克尼菲与自举</a> (1995)，<em class="ng">斯普林格</em>。</p><h2 id="1e7a" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">密码</h2><p id="d8d7" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated">你可以在这里找到Jupyter的原始笔记本:</p><div class="pm pn gp gr po pp"><a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/bayes_boot.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pq ab fo"><div class="pr ab ps cl cj pt"><h2 class="bd ja gy z fp pu fr fs pv fu fw iz bi translated">Blog-Posts/Bayes _ boot . ipynb at main matter courthoud/Blog-Posts</h2><div class="pw l"><h3 class="bd b gy z fp pu fr fs pv fu fw dk translated">我的中型博客文章的代码和笔记本。为matteocourthoud/Blog-Posts的发展作出贡献</h3></div><div class="px l"><p class="bd b dl z fp pu fr fs pv fu fw dk translated">github.com</p></div></div><div class="py l"><div class="pz l qa qb qc py qd kz pp"/></div></div></a></div></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="ab21" class="on mk iq bd ml oo op dn mp oq or dp mt lp os ot mv lt ou ov mx lx ow ox mz iw bi translated">感谢您的阅读！</h2><p id="1a92" class="pw-post-body-paragraph lg lh iq li b lj nb ka ll lm nc kd lo lp nd lr ls lt ne lv lw lx nf lz ma mb ij bi translated"><em class="ng">真的很感谢！</em>🤗<em class="ng">如果你喜欢这个帖子并且想看更多，可以考虑</em> <a class="ae lf" href="https://medium.com/@matteo.courthoud" rel="noopener"> <strong class="li ja"> <em class="ng">关注我</em> </strong> </a> <em class="ng">。我每周发布一次与因果推断和数据分析相关的主题。我尽量让我的帖子简单而精确，总是提供代码、例子和模拟。</em></p><p id="8e0d" class="pw-post-body-paragraph lg lh iq li b lj lk ka ll lm ln kd lo lp lq lr ls lt lu lv lw lx ly lz ma mb ij bi translated"><em class="ng">还有，一个小小的</em> <strong class="li ja"> <em class="ng">免责声明</em> </strong> <em class="ng">:我写作是为了学习所以错误是家常便饭，尽管我尽了最大努力。当你发现他们的时候，请告诉我。也很欣赏新话题的建议！</em></p></div></div>    
</body>
</html>