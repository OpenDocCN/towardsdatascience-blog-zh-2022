<html>
<head>
<title>Developing Web-Based Real-Time Video/Audio Processing Apps Quickly with Streamlit</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Streamlit快速开发基于Web的实时视频/音频处理应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/developing-web-based-real-time-video-audio-processing-apps-quickly-with-streamlit-7c7bcd0bc5a8#2022-02-02">https://towardsdatascience.com/developing-web-based-real-time-video-audio-processing-apps-quickly-with-streamlit-7c7bcd0bc5a8#2022-02-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8c07" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在本文中，我们将了解如何使用Streamlit创建浏览器就绪的实时视频/音频处理应用。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/96852765fa347d7d4f4bacbc18005833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eGozi0vrtOKChteXMCEM6g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="a2db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">Streamlit是一个Python框架，开发人员可以使用它快速构建web应用程序，而无需前端编码。在此基础上，开发人员可以开发实时视频/音频处理应用程序，从用户的媒体设备接收视频/音频流，在最简单的例子中，只需大约10行代码。</p><p id="833a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于这类应用程序是基于网络的，它们可以被部署到云上，与用户轻松共享，并拥有现代化和用户友好的用户界面。</p><p id="998f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个技术堆栈对于创建视频/音频应用程序的演示和原型设计非常有用，例如人体或物体检测、风格转换、图像过滤器、语音识别、视频聊天应用程序等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/9b477292b0c40a80db4dea865bd63680.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*nwr9_9Ee0TSE_vBJ.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一个简单的基于网络的物体检测应用程序。用户可以在执行过程中交互更改阈值。 <a class="ae lt" href="https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py" rel="noopener ugc nofollow" target="_blank"> <em class="ls">在线试玩🎈</em> </a></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/6c4ae17b66035408acb74101330a81f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*1Wuc0VtaduShJnPF.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="ls">一个基于web的风格转移应用程序示例。用户可以在执行过程中交互更改模型类型和模型参数。</em> <a class="ae lt" href="https://share.streamlit.io/whitphx/style-transfer-web-app/main/app.py" rel="noopener ugc nofollow" target="_blank"> <em class="ls">在线演示🎈</em>T11】</a></p></figure><p id="88a5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可以在下面的<em class="lv">示例</em>部分看到更多示例。</p><p id="5ed7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">注</strong>:这些样本应用托管在公共云上(<a class="ae lt" href="https://streamlit.io/cloud" rel="noopener ugc nofollow" target="_blank"> Streamlit Cloud </a>)，视频和音频流传输到云服务器上进行处理。虽然这些数据只在内存中处理，不会保存到任何存储中，但是，如果您担心，请不要使用它们。至于本文中的以下内容，我们可以在本地全部执行。此外，您可以按照下面的<em class="lv">示例</em>部分的说明，在本地尝试上述示例。</p><p id="63a9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">注:</strong>我在<a class="ae lt" href="https://ep2022.europython.eu/" rel="noopener ugc nofollow" target="_blank">europhon 2022</a>上做了一个关于这个主题的演讲，题目是<a class="ae lt" href="https://ep2022.europython.eu/session/real-time-browser-ready-computer-vision-apps-with-streamlit" rel="noopener ugc nofollow" target="_blank">“使用Streamlit的实时浏览器计算机视觉应用”</a>演讲视频如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lw lx l"/></div></figure><p id="1a4d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">更新:</strong>本文已于2022/09/02更新，使用的是从<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc/blob/main/CHANGELOG.md#0400---2022-06-07" rel="noopener ugc nofollow" target="_blank"> v0.40.0 </a>开始可用的<code class="fe ly lz ma mb b">streamlit-webrtc</code>新引入的API。</p><h1 id="af1e" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">基于网络的应用程序的优势</h1><p id="b907" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">我们通常使用OpenCV来构建图像或视频处理的实时演示应用。你们中的一些人(尤其是这类领域的开发人员或研究人员)可能已经多次看到下面的代码或类似的代码。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="8d78" class="nd md iq mb b gy ne nf l ng nh">import cv2<br/><br/>cap = cv2.VideoCapture(0)<br/><br/>while True:<br/>    ret, frame = cap.read()<br/><br/>    img = cv2.Canny(frame, 100, 200)  # Some image processing<br/><br/>    cv2.imshow('frame', img)<br/>    if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>        break<br/><br/>cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="9c82" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">与上面使用运行在本地环境的<code class="fe ly lz ma mb b">cv2.VideoCapture</code>和<code class="fe ly lz ma mb b">cv2.imshow</code>的GUI应用程序相比，基于网络的应用程序有如下优势。</p><p id="0192" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">易于共享和运行:</p><ul class=""><li id="3b72" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">如果我们在云上部署应用程序，我们可以通过发送URL与用户分享应用程序。</li><li id="ccee" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">用户只有通过网络浏览器才能使用这些应用程序。它不需要任何设置或外部依赖。</li></ul><p id="079e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可在智能手机上使用:</p><ul class=""><li id="8d03" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">因为用户只需要网络浏览器，所以他们可以在智能手机上使用这些应用。如果我们能在这样的便携设备上展示演示，那就太方便了。</li></ul><p id="feae" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用户友好的用户界面:</p><ul class=""><li id="0218" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">开发人员可以使用文本输入、滑块或其他基于web的组件来接受用户输入或显示数据。近来，这种基于网络的用户界面比桌面图形用户界面对用户更友好。</li></ul><h1 id="f786" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">辅导的</h1><p id="5269" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">我们将创建一个简单的基于web的实时视频处理应用程序，其LoC约为10或20。请在有网络摄像头和麦克风的环境中尝试本教程。</p><p id="f266" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可以在<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc-article-tutorial-sample" rel="noopener ugc nofollow" target="_blank">这个资源库</a>里查看这个教程的最终结果。此处是部署的在线演示<a class="ae lt" href="https://share.streamlit.io/whitphx/streamlit-webrtc-article-tutorial-sample/main/app.py" rel="noopener ugc nofollow" target="_blank">🎈</a></p><p id="2d76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本教程中，我们将在<code class="fe ly lz ma mb b">app.py</code>中编写代码。请先创建一个空的<code class="fe ly lz ma mb b">app.py</code>。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="09f9" class="nd md iq mb b gy ne nf l ng nh">$ touch app.py</span></pre><h2 id="0471" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">安装必要的软件包</h2><p id="95ce" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">接下来，我们必须安装本教程所需的软件包。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="8b32" class="nd md iq mb b gy ne nf l ng nh">$ pip install -U streamlit streamlit-webrtc opencv-python-headless</span></pre><ul class=""><li id="7bcf" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated"><code class="fe ly lz ma mb b">streamlit</code>:Streamlit主包。</li><li id="d1a0" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated"><code class="fe ly lz ma mb b">streamlit-webrtc</code>:Streamlit的定制组件，处理实时视频和音频流。</li><li id="8556" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated"><code class="fe ly lz ma mb b">opencv-python-headless</code> : OpenCV。我们在这里选择headless版本，因为我们将使用Streamlit构建UI。</li></ul><h2 id="4bfa" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">第一次接触Streamlit</h2><p id="99d4" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">注意:如果您有使用Streamlit的经验，请跳过这一部分。</p><p id="4a9c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，用下面的命令启动Streamlit。请运行与<code class="fe ly lz ma mb b">app.py</code>相同目录下的命令。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="5298" class="nd md iq mb b gy ne nf l ng nh">$ streamlit run app.py</span></pre><p id="40fe" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">过一会儿，Streamlit服务器进程将启动。然后访问<a class="ae lt" href="http://localhost:8501" rel="noopener ugc nofollow" target="_blank"> http://localhost:8501 </a>看到如下图的页面(或者默认会在浏览器中自动打开)。这里的截图是在黑暗模式下，如果你使用的是光明模式，看起来会有所不同。</p><p id="09ce" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这时，网页上没有内容，因为<code class="fe ly lz ma mb b">app.py</code>是空的。我们将在Streamlit应用程序的<code class="fe ly lz ma mb b">app.py</code>中添加代码行。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/392f0c11386891cfd2ac55085c31d7cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*PRka72fPP0_cpkI6.png"/></div></figure><p id="14c4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">用你的编辑器打开<code class="fe ly lz ma mb b">app.py</code>，写下下面的代码。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="a2ad" class="nd md iq mb b gy ne nf l ng nh">import streamlit as st<br/><br/>st.title("My first Streamlit app")<br/>st.write("Hello, world")</span></pre><p id="8d97" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当您保存文件时，Streamlit将检测文件更改，并在屏幕右上角显示“重新运行”和“总是重新运行”按钮。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e29abdb82c92585c8a2206226902b217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*DWESA0QTNPUllxPB.png"/></div></figure><p id="51f4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">单击“重新运行”按钮。然后网页被重新加载，页面内容如下所示。网页内容基于<code class="fe ly lz ma mb b">app.py</code>代码生成。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/53c662461f1fcb7785b781b86571c9e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*Bml-NxT9SGupZ91a.png"/></div></figure><p id="ae05" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你点击了“总是重新运行”按钮，每次文件改变时，页面会自动重新加载。</p><p id="d0ed" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，在更新<code class="fe ly lz ma mb b">app.py</code>时，您必须按照下面的说明重新加载页面。</p><p id="f161" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们已经了解了Streamlit应用的基本开发流程。你用像<code class="fe ly lz ma mb b">st.title()</code>和<code class="fe ly lz ma mb b">st.write()</code>这样的Streamlit组件编写Python代码并传递给<code class="fe ly lz ma mb b">streamlit run</code>命令，然后Streamlit在网页上生成相应的前端内容。</p><p id="84ad" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在下一节中，我们将看到如何在Streamlit之上开发一个实时视频处理应用程序。除此之外，Streamlit本身涵盖了更多的用例，如机器学习、数据科学或更通用的用途。此类用例请参见<a class="ae lt" href="https://docs.streamlit.io/library/get-started/create-an-app" rel="noopener ugc nofollow" target="_blank">官方Streamlit教程</a>举例。</p><h2 id="68cd" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">引入实时视频/音频流组件</h2><p id="ba17" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">如下更新<code class="fe ly lz ma mb b">app.py</code>。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="49f4" class="nd md iq mb b gy ne nf l ng nh">import streamlit as st<br/>from streamlit_webrtc import webrtc_streamer<br/><br/>st.title("My first Streamlit app")<br/>st.write("Hello, world")<br/><br/>webrtc_streamer(key="example")</span></pre><p id="ac84" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们用<code class="fe ly lz ma mb b">webrtc_streamer()</code>添加了一行。web应用程序将类似于下面的屏幕截图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/319fef5272686e11cbc7078fe440ecca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*m5IsS5LrYnDnnP-X.png"/></div></figure><p id="c4ac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在第一次试用时，可能需要一些时间来编译软件包，以便在单击“重新运行”按钮后，页面在一段时间内保持显示“正在运行”的消息。在这种情况下，请等待该过程完成。</p><p id="256c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">单击“开始”按钮开始视频和音频流。第一次试用时，可能会要求您允许使用网络摄像头和麦克风。在这种情况下，请给予许可。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/c0271db1e519111e3e6ee45868df628f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*iCOeOTSsJrCA451j.gif"/></div></figure><p id="1966" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">上面的<code class="fe ly lz ma mb b">webrtc_streamer(key="example")</code>是一个Streamlit组件，它通过web浏览器处理视频和音频实时I/O。<code class="fe ly lz ma mb b">key</code>参数是脚本中标识组件实例的唯一ID。我们在这里将其设置为<code class="fe ly lz ma mb b">"example"</code>，但是您可以使用任何字符串。该示例中的组件仅接收来自客户端网络摄像头和麦克风的视频和音频，并输出原始流。这是组件的最基本版本。我们将通过在以下部分添加其他选项来增强它的功能。</p><h2 id="ac0e" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">实时视频处理应用程序的开发</h2><p id="5d5d" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">如下更新<code class="fe ly lz ma mb b">app.py</code>。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="c055" class="nd md iq mb b gy ne nf l ng nh">import streamlit as st<br/>from streamlit_webrtc import webrtc_streamer<br/>import av<br/>import cv2<br/><br/>st.title("My first Streamlit app")<br/>st.write("Hello, world")<br/><br/><br/>def callback(frame):<br/>    img = frame.to_ndarray(format="bgr24")<br/><br/>    img = cv2.cvtColor(cv2.Canny(img, 100, 200), cv2.COLOR_GRAY2BGR)<br/><br/>    return av.VideoFrame.from_ndarray(img, format="bgr24")<br/><br/><br/>webrtc_streamer(key="example", video_frame_callback=callback)</span></pre><p id="7c72" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">像上一节一样，通过单击“开始”按钮来尝试一下。在这个新示例中，您可以发现图像过滤器被应用于视频流。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/872700793793ea611a2e4cd2a5d57783.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*_mC81QA0GhPLTES4.gif"/></div></figure><p id="b82b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们已经定义了一个接收输入帧并返回输出帧的回调。我们还将图像处理(本例中是边缘检测)代码放在回调函数中。于是，我们通过回调把图像处理代码注入到实时视频app中。</p><p id="f9c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于代码的详细解释如下。</p><ul class=""><li id="f68a" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated"><code class="fe ly lz ma mb b">webrtc_streamer()</code>可以通过<code class="fe ly lz ma mb b">video_frame_callback</code>自变量取一个函数对象作为回调。</li><li id="3044" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">回调接收并返回输入和输出图像帧。这些是来自<code class="fe ly lz ma mb b"><a class="ae lt" href="https://github.com/PyAV-Org/PyAV" rel="noopener ugc nofollow" target="_blank">PyAV</a></code>的<code class="fe ly lz ma mb b"><a class="ae lt" href="https://pyav.org/docs/develop/api/video.html#av.video.frame.VideoFrame" rel="noopener ugc nofollow" target="_blank">VideoFrame</a></code>类的实例。<code class="fe ly lz ma mb b">PyAV</code>库是<code class="fe ly lz ma mb b">ffmpeg</code>的Python绑定，提供视频和音频功能。它作为<code class="fe ly lz ma mb b">streamlit-webrtc</code>的依赖项安装。</li><li id="3e49" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">回调的参数是来自网络摄像头的输入视频流中的图像帧。可以用<code class="fe ly lz ma mb b">frame.to_ndarray()</code>转换成NumPy数组。</li><li id="e3ca" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">回调的返回值显示在屏幕上。在上面的示例中，要返回的新的<code class="fe ly lz ma mb b">VideoFrame</code>对象是从一个NumPy数组中生成的，带有<code class="fe ly lz ma mb b">av.VideoFrame.from_ndarray(img, format="bgr24")</code>。</li><li id="aef8" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">任何代码都可以放在回调函数中。在上面的例子中，我们使用了边缘检测滤波器<code class="fe ly lz ma mb b">cv2.Canny(img, 100, 200)</code>(和灰度转换器<code class="fe ly lz ma mb b">cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)</code>)作为例子。</li></ul><p id="eb96" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，我们已经创建了一个浏览器就绪的实时视频处理应用程序！在这个例子中，我们使用了一个简单的Canny边缘检测器，您可以在您的原始应用程序中用任何图像处理代码替换它。</p><p id="90b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们对该部分使用对象检测或样式转换，该应用程序将类似于本文开头的截图。</p><h2 id="9159" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">接收用户输入</h2><p id="d79b" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">如下更新<code class="fe ly lz ma mb b">app.py</code>。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="fd67" class="nd md iq mb b gy ne nf l ng nh">import streamlit as st<br/>from streamlit_webrtc import webrtc_streamer<br/>import av<br/>import cv2<br/><br/>st.title("My first Streamlit app")<br/>st.write("Hello, world")<br/><br/>threshold1 = st.slider("Threshold1", min_value=0, max_value=1000, step=1, value=100)<br/>threshold2 = st.slider("Threshold2", min_value=0, max_value=1000, step=1, value=200)<br/><br/><br/>def callback(frame):<br/>    img = frame.to_ndarray(format="bgr24")<br/><br/>    img = cv2.cvtColor(cv2.Canny(img, threshold1, threshold2), cv2.COLOR_GRAY2BGR)<br/><br/>    return av.VideoFrame.from_ndarray(img, format="bgr24")<br/><br/><br/>webrtc_streamer(key="example", video_frame_callback=callback)</span></pre><p id="03cd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后点击“开始”按钮。你会发现在这个例子中有2个滑块。您可以通过滑块修改<code class="fe ly lz ma mb b">cv2.Canny()</code>的参数，即使是在实时执行期间。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/0576edb28edc3bbf21d5f4c6b7fda47e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*BZbFekJtJtfG2MFNbZAZGA.gif"/></div></figure><p id="c08e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有了这次更新，</p><ul class=""><li id="3a9e" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">我们添加了<code class="fe ly lz ma mb b">threshold1</code>和<code class="fe ly lz ma mb b">threshold2</code>变量。</li><li id="422c" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">我们添加了两个带有<code class="fe ly lz ma mb b">st.slider()</code>的滑块组件，并将它们的值赋给这些变量。<code class="fe ly lz ma mb b">st.slider()</code>是Streamlit的内置组件。它的官方API参考是<a class="ae lt" href="https://docs.streamlit.io/library/api-reference/widgets/st.slider" rel="noopener ugc nofollow" target="_blank">https://docs . streamlit . io/library/API-reference/widgets/ST . slider</a>。</li><li id="c107" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">然后我们将这些变量作为参数传递给回调函数中的<code class="fe ly lz ma mb b">cv2.Canny()</code>。</li></ul><p id="7b2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们有交互式输入来控制实时视频过滤器！</p><h2 id="b3f9" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">回调的执行模式和重要注意事项</h2><p id="2174" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">与OpenCV不同，<code class="fe ly lz ma mb b">streamlit-webrtc</code>需要回调来处理图像和音频帧。这种基于回调的设计是OpenCV GUI和<code class="fe ly lz ma mb b">streamlit-webrtc</code>之间的一个主要区别，关于它有一些事情你必须知道。</p><p id="6108" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，回调是在一个分叉线程中执行的，该线程不同于运行Streamlit应用程序代码的主线程。它做了如下一些限制。</p><ul class=""><li id="8051" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated"><code class="fe ly lz ma mb b">global</code>关键字在回调中没有像预期的那样工作。</li><li id="be22" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">诸如<code class="fe ly lz ma mb b">st.write()</code>之类的Streamlit方法不能在回调中使用。</li><li id="cb24" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">回调内部和外部之间的通信必须是线程安全的。</li></ul><h1 id="664e" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">将应用部署到云</h1><p id="bf57" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">我们将把web应用程序部署到云中，让每个人都可以使用它。</p><h2 id="1cec" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">配置WebRTC</h2><p id="0ef1" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">要将应用程序部署到云中，我们必须将<code class="fe ly lz ma mb b">rtc_configuration</code>参数添加到<code class="fe ly lz ma mb b">webrtc_streamer()</code>中。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="385f" class="nd md iq mb b gy ne nf l ng nh">webrtc_streamer(<br/>    key="example",<br/>    video_frame_callback=callback,<br/>    rtc_configuration={  # Add this line<br/>        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]<br/>    }<br/>)</span></pre><p id="732f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">当服务器在远程主机上时，此配置是建立媒体流连接所必需的。</p><p id="f2a3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe ly lz ma mb b">streamlit_webrtc</code>使用WebRTC进行视频和音频流传输。它必须访问全局网络中的“STUN服务器”,以便远程对等点(确切地说，是NAT上的对等点)建立WebRTC连接。虽然我们在本文中没有看到关于STUN服务器的细节，但是如果感兴趣的话，请使用关键字如STUN、TURN或NAT traversal来搜索它。</p><p id="76c1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在上面的例子中，我们将代码配置为使用Google提供的免费STUN服务器。您也可以使用任何其他可用的STUN服务器。</p><p id="f1ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">参数<code class="fe ly lz ma mb b">rtc_configuration</code>的值将被传递给前端的<code class="fe ly lz ma mb b"><a class="ae lt" href="https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/RTCPeerConnection" rel="noopener ugc nofollow" target="_blank">RTCPeerConnection</a></code>构造函数。</p><h2 id="3151" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">HTTPS</h2><p id="9fda" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">我们必须通过HTTPS在远程主机上提供网络应用程序，以使用网络摄像头或麦克风。</p><p id="013d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">不仅我们在这里使用的<code class="fe ly lz ma mb b">webrtc_streamer()</code>组件，而且任何访问客户端网络摄像头或麦克风的前端应用程序都使用<code class="fe ly lz ma mb b"><a class="ae lt" href="https://developer.mozilla.org/ja/docs/Web/API/MediaDevices/getUserMedia" rel="noopener ugc nofollow" target="_blank">MediaDevices.getUserMedia()</a></code> API。这个API不能在“不安全的上下文”中工作</p><p id="2473" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">文件<a class="ae lt" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia#privacy_and_security" rel="noopener ugc nofollow" target="_blank">说</a></p><blockquote class="oi oj ok"><p id="930a" class="kv kw lv kx b ky kz jr la lb lc ju ld ol lf lg lh om lj lk ll on ln lo lp lq ij bi translated"><em class="iq">简而言之，安全上下文是使用HTTPS或</em> <code class="fe ly lz ma mb b"><em class="iq">file:///</em></code> <em class="iq"> URL方案加载的页面，或者从</em> <code class="fe ly lz ma mb b"><em class="iq">localhost</em></code> <em class="iq">加载的页面。</em></p><p id="9b54" class="kv kw lv kx b ky kz jr la lb lc ju ld ol lf lg lh om lj lk ll on ln lo lp lq ij bi translated"><a class="ae lt" href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia#privacy_and_security" rel="noopener ugc nofollow" target="_blank"><em class="iq">media devices . getuser media()-隐私和安全</em> </a></p></blockquote><p id="9df5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们需要HTTPS在访问客户端网络摄像头或麦克风的远程主机上提供网络应用。</p><h2 id="1a85" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">流线云</h2><p id="7ce4" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">我推荐使用<a class="ae lt" href="https://streamlit.io/cloud" rel="noopener ugc nofollow" target="_blank"> Streamlit Cloud </a>托管Streamlit应用。只需点击几下鼠标，你就可以从GitHub库部署应用程序，它会通过HTTPS自动提供应用程序。而且Streamlit Cloud似乎提供了比Heroku free-tier更好的运行时，而Streamlit Cloud免费提供了大部署容量。</p><p id="ec1e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其用法请参考<a class="ae lt" href="https://docs.streamlit.io/streamlit-cloud" rel="noopener ugc nofollow" target="_blank">公文</a>。</p><p id="1e4d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我在Streamlit Cloud上实际部署了我们在本文中看到的app:<a class="ae lt" href="https://share.streamlit.io/whitphx/streamlit-webrtc-article-tutorial-sample/main/app.py" rel="noopener ugc nofollow" target="_blank">https://share . Streamlit . io/whit phx/Streamlit-webrtc-article-tutorial-sample/main/app . py</a>。</p><p id="12ab" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它的GitHub资源库是<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc-article-tutorial-sample" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/whit phx/streamlit-webrtc-article-tutorial-sample</a>。</p><p id="f2c7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意添加了<code class="fe ly lz ma mb b">requirements.txt</code>来在Streamlit云环境中安装必要的依赖项(<code class="fe ly lz ma mb b">streamlit-webrtc</code>和<code class="fe ly lz ma mb b">opencv-python-headless</code>):<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc-article-tutorial-sample/blob/main/requirements.txt" rel="noopener ugc nofollow" target="_blank">https://github . com/whit phx/Streamlit-webrtc-article-tutorial-sample/blob/main/requirements . txt</a></p><h1 id="9f56" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">通知；注意</h1><p id="5712" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">如上所述，源自客户端设备的视频和音频流被传输到服务器并在服务器处被处理。</p><p id="8b63" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，这个库是不可扩展的，并且依赖于网络连接。您可能认为它主要用于原型制作或演示目的。</p><p id="2bae" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果担心将媒体传输到远程云服务器，你还必须考虑将应用托管在本地网络中。</p><h1 id="f796" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">例子</h1><p id="eefe" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">本部分是在<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc" rel="noopener ugc nofollow" target="_blank">https://github.com/whitphx/streamlit-webrtc</a>的样品清单的副本。</p><h2 id="c40e" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">展示包括以下例子和更多</h2><p id="7522" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated"><a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc-example" rel="noopener ugc nofollow" target="_blank"> ⚡️Repository </a>，<a class="ae lt" href="https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py" rel="noopener ugc nofollow" target="_blank">🎈在线演示</a></p><ul class=""><li id="e642" class="ni nj iq kx b ky kz lb lc le nk li nl lm nm lq nn no np nq bi translated">对象检测(这是本文开头的样例应用程序的截图)</li><li id="d839" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">OpenCV过滤器</li><li id="7250" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">单向视频流</li><li id="112e" class="ni nj iq kx b ky nr lb ns le nt li nu lm nv lq nn no np nq bi translated">音频处理</li></ul><p id="0104" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">您可以在您的本地env上使用以下命令来试用这个示例应用程序。</p><pre class="kg kh ki kj gt mz mb na nb aw nc bi"><span id="ab34" class="nd md iq mb b gy ne nf l ng nh">$ pip install streamlit-webrtc opencv-python-headless matplotlib pydub<br/>$ streamlit run https://raw.githubusercontent.com/whitphx/streamlit-webrtc-example/main/app.py</span></pre><h2 id="7cd4" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">实时语音转文本</h2><p id="a332" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated"><a class="ae lt" href="https://github.com/whitphx/streamlit-stt-app" rel="noopener ugc nofollow" target="_blank"> ⚡️Repository </a>，<a class="ae lt" href="https://share.streamlit.io/whitphx/streamlit-stt-app/main/app_deepspeech.py" rel="noopener ugc nofollow" target="_blank">🎈在线演示</a></p><p id="3c3e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它能实时将你的声音转换成文本。这个app是自带的；它不依赖于任何外部API。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/50acf2699c656c05304ff2d15c922b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*YfONkyW8hE0xn-Mh8R_WFA.gif"/></div></figure><h2 id="1e95" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">实时视频风格传输</h2><p id="f7ce" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated"><a class="ae lt" href="https://github.com/whitphx/style-transfer-web-app" rel="noopener ugc nofollow" target="_blank"> ⚡️Repository </a>，<a class="ae lt" href="https://share.streamlit.io/whitphx/style-transfer-web-app/main/app.py" rel="noopener ugc nofollow" target="_blank">🎈在线演示</a></p><p id="db77" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它将各种各样的风格转换过滤器应用于实时视频流。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/6c4ae17b66035408acb74101330a81f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*1Wuc0VtaduShJnPF.gif"/></div></figure><h2 id="aa15" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">视频聊天</h2><p id="ab53" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated"><a class="ae lt" href="https://github.com/whitphx/streamlit-video-chat-example" rel="noopener ugc nofollow" target="_blank"> ⚡️Repository </a>(不提供在线演示)</p><p id="7bfd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可以用大约100行Python代码创建视频聊天应用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/bd19233f7dfee3be77a1c282ec572729.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U4YKnPDvPSCR2hVXKKpf4A.jpeg"/></div></div></figure><h2 id="7f29" class="nd md iq bd me nw nx dn mi ny nz dp mm le oa ob mo li oc od mq lm oe of ms og bi translated">东京2020象形图</h2><p id="8edd" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated"><a class="ae lt" href="https://github.com/whitphx/Tokyo2020-Pictogram-using-MediaPipe" rel="noopener ugc nofollow" target="_blank"> ⚡️Repository </a> : <a class="ae lt" href="https://share.streamlit.io/whitphx/tokyo2020-pictogram-using-mediapipe/streamlit-app" rel="noopener ugc nofollow" target="_blank">🎈在线演示</a></p><p id="acfe" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><a class="ae lt" href="https://google.github.io/mediapipe/" rel="noopener ugc nofollow" target="_blank"> MediaPipe </a>用于姿态估计。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oq lx l"/></div></figure><h1 id="5c73" class="mc md iq bd me mf mg mh mi mj mk ml mm jw mn jx mo jz mp ka mq kc mr kd ms mt bi translated">音频呢？</h1><p id="b30e" class="pw-post-body-paragraph kv kw iq kx b ky mu jr la lb mv ju ld le mw lg lh li mx lk ll lm my lo lp lq ij bi translated">您可以像处理视频一样处理音频流。如果您定义了一个回调函数并将其传递给<code class="fe ly lz ma mb b">audio_frame_callback</code>参数，那么回调将会在音频帧中执行。在音频的情况下，回调的输入参数和返回值是<a class="ae lt" href="https://pyav.org/docs/develop/api/audio.html#module-av.audio.frame" rel="noopener ugc nofollow" target="_blank"/><code class="fe ly lz ma mb b"><a class="ae lt" href="https://pyav.org/docs/develop/api/audio.html#module-av.audio.frame" rel="noopener ugc nofollow" target="_blank">AudioFrame</a></code><a class="ae lt" href="https://pyav.org/docs/develop/api/audio.html#module-av.audio.frame" rel="noopener ugc nofollow" target="_blank">类</a>的实例。</p><p id="64f8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请参见上面示例中的<a class="ae lt" href="https://github.com/whitphx/streamlit-webrtc/blob/c172483efd4566b18d3500e914285079117b5b35/pages/audio_filter.py" rel="noopener ugc nofollow" target="_blank">更改音频增益的示例应用程序</a>或语音转文本应用程序的源代码。</p></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><p id="a1c9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lv">原载于</em><a class="ae lt" href="https://www.whitphx.info/posts/20211231-streamlit-webrtc-video-app-tutorial/" rel="noopener ugc nofollow" target="_blank"><em class="lv">https://www . whit phx . info</em></a><em class="lv">。</em></p></div></div>    
</body>
</html>