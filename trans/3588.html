<html>
<head>
<title>Optimizing the Random Seed</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">优化随机种子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/optimizing-the-random-seed-99a90bd272e#2022-08-09">https://towardsdatascience.com/optimizing-the-random-seed-99a90bd272e#2022-08-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="dbec" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">做那件事有意义吗？</h2></div><p id="5d57" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">乍一看，答案似乎显而易见。但是在深入挖掘之前，我们先不要急着下结论。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/085497f16906950e9790832ae9571453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*83MCgD6_QqblnLpT"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">马库斯·斯皮斯克在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="76b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我先讲一个小故事来创造背景。</p><h2 id="1b74" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">实践中的随机种子优化</h2><p id="fe2b" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">大约7年前，我开始学习数据科学，大约在同一时间，我也开始在Kaggle平台上参加机器学习比赛。我只知道一点点理论，但没有多少建立真实模型的经验。作为一名机器学习的初学者，当时我做了与Kaggle上许多初学者完全相同的事情——我拿了一些高分的公共示例脚本，并试图修改该脚本中的模型参数，希望改善结果。</p><p id="4af5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一个XGBoost模型，有大约10个参数。那时候。我对每个参数的含义没有太多的了解，所以我只是开始在两个方向上改变它们——增加和减少原始参数值。每次更改后，我都会重新训练模型并提交新的结果，将分数与之前的进行比较。根据结果，我将参数值进一步更改为最佳方向，每次迭代都会略微提高分数。</p><p id="4fbd" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型的参数之一是随机种子。很明显，通过改变随机种子，CV值就改变了。它可以变得稍微低一点，或者稍微高一点——取决于运气。或者更准确地说，是随机的。这给了我们优化随机种子的可能性。我们可以找到种子值，对于这个值，CV值是最好的。这正是我在那次比赛中所做的，发现对我来说最好的随机种子是51。</p><p id="26de" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是现在，整篇文章的主要问题来了。</p><h2 id="cd63" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">有意义吗？</h2><p id="bfaa" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">优化随机种子有意义吗？或者，换句话说，一个种子具有更好的CV值是否意味着该模型总体上比用另一个随机种子训练的具有更低CV值的相同模型更好？</p><p id="834b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们试着找到这个问题的答案。</p><p id="13d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">正如我已经提到的，乍一看，答案似乎是显而易见的。通过改变随机种子，我们简单地得到CV分数的随机变化。因此，我们可以假设这些CV变化并不意味着什么，纯粹基于不同随机种子的CV分数更好的模型并不比用原始种子训练的相同模型更好。</p><p id="19da" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果还没有被说服，有更多的论据证明随机种子优化不会有帮助。取任意一个模型，找到CV值最好的随机种子值。然后对模型做一些细微的改变，比如添加一个新的特性，改变一些其他的超参数，甚至只是简单地调整一下训练行。然后再次检查先前找到的最佳随机种子值是否仍然给出最佳CV分数。几乎可以肯定，不会。这意味着没有单一的最佳随机种子。</p><p id="bf70" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么，我们完事了吗？优化随机种子没有任何意义？</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi mt"><img src="../Images/5ac8726c728ec22e9aedc6230b867d0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*NXkruG24LStWHA1y"/></div></div><p class="lq lr gj gh gi ls lt bd b be z dk translated">纳丁·沙巴纳在<a class="ae lu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5a0b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不完全是。让我们再深入一点。</p><h2 id="c968" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">深入挖掘</h2><p id="8516" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">首先，让我们了解一下，随机种子到底是干什么的。它被机器学习模型用于各种任务——在所有需要随机性的地方。对于基于树的模型，随机性是需要的，以确保所有的树不是相同的，有不同的分裂。基于树的模型中的树越多样化，结果应该越好。</p><p id="9138" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们可以使用各种技术使树木更加多样化。例如，我们可以通过删除一些行或一些特征(列)来使用子采样。在每次迭代中，删除一些行或列的子集。随机性确保了每次这个子集都是不同的。这反过来确保了模型将在每次迭代中创建不同的树。</p><p id="f5e8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，随机种子(以随机的方式)影响将被创建的树。现在的问题是——一棵树能比另一棵树更好吗？</p><p id="9a6a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">是的，可以。例如，假设我们有两个特征。其中一个包含真实信号，但另一个主要包含噪声。可能发生的情况是，在一棵树中，真实特征被子采样移除，使得在考虑最佳可能分割时该特征对于模型不可用。因此，模型将首先根据噪声特征创建分割。但是在其他一些树中，噪声特征将被移除——这意味着第一次分割将由强特征完成。在这种情况下，基于真正强特征的第二棵树通常会更好。</p><p id="8ce2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，如果一颗随机的种子幸运地比其他种子长出更强壮的树会怎么样呢？在这种情况下，用第一个种子训练的模型将确实比用另一个种子训练的模型更好，具有更多在噪声特征上分裂的较弱的树。</p><h2 id="12be" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">把结论放在一起</h2><p id="47c8" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">所以，再一次，优化随机种子有意义吗？看情况。在大多数情况下，它不会。但是在某些情况下，在某些特殊的情况下，这可能会有所不同。例如，如果满足以下两个条件:</p><p id="23ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">1)很少有特征具有显著不同的预测能力。</p><p id="4d21" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2)子采样或类似技术用于在每次迭代中随机丢弃特征的子集。</p><p id="1f16" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在满足这两个条件的数据集上(<a class="ae lu" href="https://www.kaggle.com/datasets/alijs1/artificial-data-leaks" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/alijs 1/artificial-data-leaks</a>)，我设法得到了仅在随机种子上有所不同，但在性能上表现出明显差异的模型。一个种子被选为针对验证集优化的最佳种子，而另一个种子被选为最差种子。并且所选的两个种子的最终性能是在不同的数据上测量的，而不是在优化种子的相同验证集上测量的。这个过程用不同的验证集重复了100次，以获得一些统计上显著的结果。</p><p id="c91e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一个额外的观察是特征重要性分数。根据特定随机种子的幸运程度，具有真实信号的要素在要素重要性列表中的位置会略微靠前或靠后。</p><p id="676e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为结论——存在随机种子优化可以产生更好的模型的情况(即使这个特殊的例子是人为创建的)。</p><h2 id="fb7f" class="lv lw it bd lx ly lz dn ma mb mc dp md kr me mf mg kv mh mi mj kz mk ml mm mn bi translated">一些最后的话</h2><p id="92b9" class="pw-post-body-paragraph ki kj it kk b kl mo ju kn ko mp jx kq kr mq kt ku kv mr kx ky kz ms lb lc ld im bi translated">在现实世界的问题中，我从来没有优化过随机种子。就好像你有两个用不同种子训练的模型，最好的方法不是拿走其中一个，而是把两个融合在一起。在大多数情况下，混合(平均)结果对每个单独的结果都更好。</p><p id="c5c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">但是——如果出于某种原因，我只能从两个模型中选择一个，只是在使用的随机种子上有所不同，我会选择验证分数更高的那个。以防万一。</p><p id="d350" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读！希望你能有所启发。</p><p id="d75e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以后如果有兴趣看更多数据科学和机器学习相关的文章，别忘了关注我。</p></div></div>    
</body>
</html>