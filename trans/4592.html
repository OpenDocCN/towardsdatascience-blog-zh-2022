<html>
<head>
<title>Test Driving Delta Lake 2.0 on AWS EMR — 7 Key Learnings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在AWS EMR上试驾Delta Lake 2.0项重要经验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/test-driving-delta-lake-2-0-on-aws-emr-7-key-learnings-821aa515d247#2022-10-12">https://towardsdatascience.com/test-driving-delta-lake-2-0-on-aws-emr-7-key-learnings-821aa515d247#2022-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9156" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在AWS EMR上使用Delta Lake 2.0后，我学到了什么，以及安装步骤和性能基准</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/5d890a39c3f03ea31682bc8a630cf451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rgi7ytzbwitJ7sA_"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">路易斯·索萨在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="95ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你读过我以前的一篇关于<a class="ae ky" rel="noopener" target="_blank" href="/getting-started-with-delta-lake-spark-in-aws-the-easy-way-9215f2970c58">在AWS </a>中开始使用Delta Lake的文章，你就会了解Delta Lake等产品为什么越来越受欢迎以及它们解决了什么类型的用例的基本背景和基本原理。本文介绍了在AWS EC2上开始使用Delta Lake的简单步骤，尽管您可以使用该方法来处理一些简单的用例，但在可伸缩性和编目方面仍然有一些限制。因此，如果您想要在相对复杂的用例上工作，保证以下几点:</p><ul class=""><li id="ff96" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用可扩展的基础设施，即由多个虚拟机组成，在Spark上对大数据集进行分布式计算，增加了灵活性，即能够根据需要轻松扩展或缩减</li><li id="9089" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用AWS Glue作为目录(即，将其配置为Apache Spark的Hive metastore)</li></ul><p id="8c96" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您不想自己进行上述配置，那么有几个选择:</p><ul class=""><li id="0358" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">考虑提供三角洲湖解决方案的商业供应商，例如Databricks</li><li id="df23" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在AWS中使用Amazon Elastic MapReduce (EMR ),它提供托管Hadoop框架并在其上配置Delta Lake</li></ul><p id="95ab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果出于某种原因，第一个选项不太适合您，而您希望使用AWS原生服务，那么在这种情况下，EMR可以是一种方法。然而，一个主要的问题是EMR本身并不支持Delta Lake(像Databricks那样)。因此，在EMR上配置Delta Lake需要一些配置。</p><p id="1f7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我最近处理了一个用例，在这个用例中，我在EMR上原型化了Delta Lake，并希望利用这篇文章作为一个机会来分享从经验中获得的关键知识，以及性能基准和如何设置它的说明。</p><h1 id="6fd6" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">EMR上的三角洲湖—配置步骤概述</h1><p id="ca40" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">首先，让我们谈谈如何在EMR上配置Delta Lake。我特别想使用Delta Lake 2.0，因为它提供了一些我想使用的命题，例如z排序。你可以阅读更多关于三角洲湖2.0和如果提供什么<a class="ae ky" href="https://delta.io/blog/2022-08-02-delta-2-0-the-foundation-of-your-data-lake-is-open/" rel="noopener ugc nofollow" target="_blank">在这里</a>。</p><p id="95e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在EMR上配置Delta Lake 2.0的核心步骤如下(或者至少我是这么做的):</p><ul class=""><li id="9dd5" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">使用以下服务启动EMR:Spark、Hadoop</li><li id="95cc" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在<strong class="lb iu"> AWS胶数据目录设置</strong>下，选择<strong class="lb iu">用于星火表元数据</strong>。</li><li id="4457" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">确保EMR使用的是最新版本的Python，例如我使用的是Python 3.9(稍后会详细介绍)</li><li id="b77b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">确保您的EMR主节点可以连接到互联网，例如通过NAT网关或HTTP/HTTPS代理，因为设置需要从Maven仓库下载Delta Lake 2.0依赖项。</li><li id="dfad" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu"> PySpark shell — </strong>通过SSH访问EMR主节点，并运行此命令，以便在正确配置Delta Lake 2.0依赖项的情况下运行PySpark shell:</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="cea5" class="nl mk it nh b gy nm nn l no np">pyspark --packages io.delta:delta-core_2.12:2.0.0 --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog" --conf "spark.driver.extraJavaOptions=-Duser.timezone=UTC</span></pre><ul class=""><li id="97c9" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu"> Spark提交作业— </strong>用于运行Spark提交作业。在EMR集群中运行以下py脚本:</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="a3e0" class="nl mk it nh b gy nm nn l no np">spark-submit --packages io.delta:delta-core_2.12:2.0.0 --conf "spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension" --conf "spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog" --conf "spark.driver.extraJavaOptions=-Duser.timezone=UTC helloworld.py</span></pre><p id="5d1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">而helloworld.py看起来像这样:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="7405" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在脚本中:</p><ul class=""><li id="d2ec" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">我们从pyspark.sql模块导入sparkSession，因为它将在下一步中用于构建Spark对象。</li><li id="c2aa" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们创建Spark对象并指定其配置。具体来说，我们在这一步配置Spark使用Delta Lake(第5行，第6行)</li><li id="95b6" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们确保AWS Glue在Spark提交作业期间被用作Hive Metastore(第10行，第11行)。您可能已经注意到，在运行PySpark shell时，我们不需要设置这个配置，但是在运行spark-submit时，这是必需的。否则，Spark将不能与Glue Catalog集成，也不能使用那里定义的数据库和表。</li><li id="4274" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">我们读取Spark数据帧中的Delta Lake表(第15行)，在其上创建一个临时视图(第16行)，然后使用Spark SQL打印它的行数(第17行)；只是为了证实这个系统以它的基本形式运行。</li></ul><p id="a6e2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以使用它作为编写Spark应用程序的基本模板，并在EMR中通过spark-submit运行。</p><ul class=""><li id="d8c7" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">提示:如果您在需要HTTP/HTTPS代理进行internet访问的子网中部署了EMR，则还应包括以下属性:</li></ul><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="0a3c" class="nl mk it nh b gy nm nn l no np">-Dhttp.proxyHost=&lt;proxy_hostname&gt; -Dhttp.proxyPort=&lt;proxy_port&gt; -Dhttps.proxyHost=&lt;proxy_hostname&gt; -Dhttps.proxyPort=&lt;proxy_port&gt;"</span></pre><p id="7158" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们来谈谈一些重要的经验:</p><h1 id="ba9f" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">EMR上的三角洲湖—主要经验</h1><h2 id="354f" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#1 —有效！</h2><p id="764a" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">有了上面突出显示的设置，很高兴看到EMR上的Delta Lake 2.0起作用了！我能够毫无问题地使用核心的Delta Lake特性，比如在S3的Delta表上进行更新/删除。此外，在增加或减少EMR中核心节点的数量时，我可以看到用于Spark作业的资源发生了相应的变化，从而提高了整体性能。</p><h2 id="8005" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated"># 2——AWS胶水三角洲湖表</h2><p id="dc6c" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">当您在EMR中使用Spark SQL创建一个增量表(使用Glue作为metastore)时，它可以工作，并且在AWS Glue Catalog中创建表。如果你在AWS Glue中找到表的定义并访问它的高级属性，它会显示<em class="od">spark . SQL . sources . provider</em>是<em class="od"> delta </em></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/803b02916c2ae50f012312416f5ab969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DiQPGF01PGeqBRhxpI8Dyw.png"/></div></div></figure><p id="dbbf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是，与其他表类型(例如Parquet、CSV)不同，它显示的表模式如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/95e136814de6eb75073494a94b04e5a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08WP4p0hLA6RHo-QYEPSyQ.png"/></div></div></figure><p id="bba5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">其中它只是将列显示为数组类型，即使您在表DDL中使用int和varchar等类型正确定义了它们。从管理控制台的可读性角度来看，这不是最好的表示。但是，如果您在Spark SQL中查询该表，它会很好地工作，并以正确的类型显示各个列。</p><h2 id="c522" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#3 — Python版本难题</h2><p id="c908" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在撰写本文时，我使用的是emr-6.7.0发布标签，其中包含Spark 3.2.1版本。有趣的是，在这个版本中，EMR预装了Python 3.7。当我试图在Python 3.7上正确配置Delta Lake 2.0时，遇到了许多挑战。因此，我必须遵循以下步骤:</p><ul class=""><li id="6ca2" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">创建一个安装了最新版本Python(在我的例子中是Python 3.9)的AMI。</li><li id="2cae" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用自定义AMI启动EMR</li></ul><p id="1ed5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，当我使用自定义AMI启动EMR时，它仍然将Python 3.7作为PySpark的默认版本。为了解决这个问题，我必须提交一个配置请求，将默认版本更改为Python 3.9。你可以跟着<a class="ae ky" href="https://aws.amazon.com/premiumsupport/knowledge-center/emr-pyspark-python-3x/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>了解一下是怎么做的。</p><h2 id="3639" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#4 — Z排序失败</h2><p id="65db" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">我想利用Delta Lake 2.0的z排序功能，这是一种多维聚类技术，因为它似乎可以提高性能，因为它大大减少了Spark处理查询所需读取的数据量。下面是如何用Python实现的:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="8fac" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您基本上指定了一个执行z排序的列，例如在查询谓词中使用的时间戳列。</p><p id="bc3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，当尝试在EMR设置上的Delta Lake中使用它时，它继续失败。它启动了z排序过程，并经历了几个阶段，但在完成之前继续失败(出现容器丢失和任务终止等错误)。</p><p id="c9ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对整个表进行z排序是一个非常耗时的过程，尤其是当表很大的时候。如上面代码中的第9行所示，这可以在特定的分区上完成(假设您的增量表是分区的)。我的假设是Z排序至少可以在数据量较少的特定分区上工作，但事实并非如此。我尝试通过添加更多的任务节点来扩展集群，但也无济于事。</p><h2 id="71b8" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#5 —删除或更新语句中不支持子查询</h2><p id="2610" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">如果您打算在增量表上的DELETE或UPDATE语句中使用子查询，例如</p><pre class="kj kk kl km gt ng nh ni nj aw nk bi"><span id="f727" class="nl mk it nh b gy nm nn l no np">DELETE FROM table_name_1 WHERE EXISTS (Select 1 from table_name_2 where table_name_2.key = table_name_1.key)</span></pre><p id="f4dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然不支持。这是一个公开的问题，可以<a class="ae ky" href="https://github.com/delta-io/delta/issues/826" rel="noopener ugc nofollow" target="_blank">在这里跟踪</a></p><p id="c1bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有趣的是，Databricks上的Delta Lake确实支持这种上下文中的子查询。这里可以找到<a class="ae ky" href="https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-delete-from.html" rel="noopener ugc nofollow" target="_blank">的一个例子</a>。</p><h2 id="81af" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#6 —通过分区修剪优化增量表中的上插/合并</h2><p id="b989" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">Delta Lake通过Merge SQL命令支持Upsert。但是，我发现如果您的表是分区的，并且如果您可以在合并期间进行分区修剪，那么它可以显著提高性能。更多信息，请参考本文。</p><h2 id="16ff" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">#7 —三角洲湖2.0安装注意事项</h2><p id="0b67" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">您可能已经注意到，我管理Delta Lake 2.0依赖项的方式是允许从Maven repo下载它。下载后，它们将被本地缓存并重用。这不是管理依赖关系的理想方式，有或者应该有更好的方式来做到这一点，例如让EMR集群可以使用Delta Lake 2.0相关的jar。您可能会在网上找到许多关于不同方法的教程，例如将Delta Lake jar复制到特定文件夹(例如/usr/lib/spark/jars)，在启动EMR集群时使用JSON conf等。对我来说，这些方法都不起作用。对于Delta Lake 1.0，有效的方法是将Delta Lake jars放在一个文件夹中，例如/home/hadoop/extrajars/并更新spark-defaults.conf(位于/etc/spark/conf/spark-defaults . conf)以引用spark driver和executor类路径中的jar路径。</p><p id="ee9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是……对于Delta Lake 2.0来说，这种方法也不起作用，因为我不断地得到类没有找到相关的错误。因此，我求助于我在上面的文章中强调的方法，即让依赖项从Maven下载一次，并在以后重用。</p><h2 id="9de4" class="nl mk it bd ml ns nt dn mp nu nv dp mt li nw nx mv lm ny nz mx lq oa ob mz oc bi translated">性能基准</h2><p id="d344" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">性能一直是这类原型的主要关注点，所以我也想分享一下我的发现。具体设置如下:</p><ul class=""><li id="42ca" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">EMR集群大小:1个主节点(m4.large)，2个任务节点(m5.xlarge)</li><li id="c982" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">原始批次大小:20 MB(gzip，CSV)</li><li id="800c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PK上重复数据删除时的行数:5000左右</li><li id="802b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">增量表大小:600 GB(按年/月派生列分区)</li><li id="5994" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">相关分区大小(基于原始批处理中的数据):5GB(这很重要，因为我在合并时使用了分区修剪逻辑，如上所述)</li><li id="5960" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">运行合并所用的时间:大约5分钟</li></ul><p id="ccc9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">是好是坏？答案与上下文高度相关，取决于许多因素，如成本效益比、潜在的替代方案等，所以我会让您来判断。</p><h1 id="40d4" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">关键要点</h1><p id="0a51" class="pw-post-body-paragraph kz la it lb b lc nb ju le lf nc jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">现在，可以理解的是，这篇文章似乎带有一些负面的含义，例如EMR上的Delta Lake 2.0，但这不是它的初衷。关键的一点是，这个设置是可行的，但是有一些我已经强调过的怪癖。如果我投入更多的时间和精力，我也有可能解决这些问题，或者这些问题将在即将到来的EMR或Delta Lake 2.0版本中得到解决。如果你有兴趣接受这个设置并解决突出的挑战，那就去做吧。或者潜在地考虑提供具有良好支持的这种解决方案的商业供应商。</p></div></div>    
</body>
</html>