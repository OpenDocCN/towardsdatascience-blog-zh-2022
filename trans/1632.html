<html>
<head>
<title>PyFlink - How To Create a Table From A CSV Source</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何从一个CSV源文件创建一个表格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pyflink-how-to-create-a-table-from-a-csv-source-ca4851a71d0c#2022-04-19">https://towardsdatascience.com/pyflink-how-to-create-a-table-from-a-csv-source-ca4851a71d0c#2022-04-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="74d6" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在关于Apache Flink的第一篇教程中，学习如何使用Python Table API将数据从CSV源导入到表中。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/331c7d9d507fb9433476bf4ad48571ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p74Aa7k7TsRDVf235HoLAQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">大卫·塞尔伯特在Pexels.com拍摄的照片</p></figure><h2 id="f521" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">建议的点播课程</h2><p id="4a18" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated"><em class="mo">您是否希望了解更多关于</em><strong class="lx iu"><em class="mo">Apache Flink</em></strong><em class="mo">，</em><strong class="lx iu"><em class="mo">Apache Spark</em></strong><em class="mo">及其他</em> <strong class="lx iu"> <em class="mo">数据流</em> </strong> <em class="mo">技术？以下是一些用Python教授的在线课程，强烈推荐:</em></p><ul class=""><li id="db89" class="mp mq it lx b ly mr mb ms li mt lm mu lq mv mn mw mx my mz bi translated"><a class="ae ky" href="https://click.linksynergy.com/deeplink?id=533LxfDBSaM&amp;mid=47900&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fapache-flink-relational-programming-using-table-api-and-sql%2F%3FranMID%3D39197%26ranEAID%3D533LxfDBSaM%26ranSiteID%3D533LxfDBSaM-C8L7.VkktnuTmHaetMczNw%26utm_source%3Daff-campaign%26utm_medium%3Dudemyads%26LSNPUBID%3D533LxfDBSaM" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> Apache Flink关系编程使用表API和SQL </strong> </a></li><li id="6a12" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><a class="ae ky" href="https://imp.i115008.net/zaX10r" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">阿帕奇卡夫卡&amp;阿帕奇火花纳米级</strong> </a>数据流</li><li id="5504" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><a class="ae ky" href="https://imp.i115008.net/jWWEGv" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu">数据工程纳米学位</strong> </a> <strong class="lx iu"> → </strong> <em class="mo">优质课程+编码项目如果你有更多的时间投入。</em> <strong class="lx iu"> → </strong> <a class="ae ky" href="https://imp.i115008.net/jWWEGv" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> <em class="mo">通过此链接获得七折优惠</em> </strong> </a></li></ul></div><div class="ab cl nf ng hx nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="im in io ip iq"><h1 id="9950" class="nm la it bd lb nn no np le nq nr ns lh jz nt ka ll kc nu kd lp kf nv kg lt nw bi translated">介绍</h1><p id="cef9" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">几年前，当我开始熟悉<a class="ae ky" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark生态系统</a>时，我立即注意到有多少现成的资源可供Python开发人员使用。</p><p id="46c9" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">事实上，考虑到大量的教程、点播课程和技术书籍，我在学习如何使用PySpark的<a class="ae ky" href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html" rel="noopener ugc nofollow" target="_blank"> DataFrame API </a>时几乎没有遇到任何障碍。</p><p id="b4db" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">去年，当我学习成为Apache Spark 3.0认证开发人员时，我的第一印象得到了加强:材料和考试本身以多种语言提供，包括Python。文档是清晰的，并且在涵盖新主题的同时，有许多编码示例可供参考。</p><p id="366c" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">然而，如果你正在处理大数据量(<em class="mo">也许作为一个软件工程师，数据工程师，或数据科学家？你可能也偶然发现了<a class="ae ky" href="https://flink.apache.org/flink-architecture.html" rel="noopener ugc nofollow" target="_blank">阿帕奇·弗林克</a>。由于其高吞吐量和可扩展性，这是市场上最有前途的实时数据处理框架之一。</em></p><blockquote class="oa"><p id="c74f" class="ob oc it bd od oe of og oh oi oj mn dk translated">但是，就目前情况来看，Python开发人员使用Apache Flink有多容易？</p></blockquote><p id="8758" class="pw-post-body-paragraph lv lw it lx b ly ok ju ma mb ol jx md li om mf mg lm on mi mj lq oo ml mm mn im bi translated">根据我的个人经验，事情并没有那么简单:JAVA工程师可以利用的资源很多，但是当涉及到学习<a class="ae ky" href="https://nightlies.apache.org/flink/flink-docs-master/api/python/" rel="noopener ugc nofollow" target="_blank"><strong class="lx iu">PyFlink</strong></a><strong class="lx iu">(</strong><em class="mo">的意思是它的Python等价物</em> <strong class="lx iu"> ) </strong>的选择池就大大推脱了。</p><p id="cd62" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">在这第一篇教程中，我通过展示如何使用 <a class="ae ky" href="https://nightlies.apache.org/flink/flink-docs-master/api/python/pyflink.table.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lx iu"> PyFlink表API </strong> </a>从CSV源导入(有界)数据来填补空白。</p><p id="d0f1" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">但首先，让我们多了解一下PyFlink，以及它可以用来做什么。</p><h1 id="5c70" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">什么是<strong class="ak"> PyFlink？</strong></h1><p id="f997" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated"><a class="ae ky" href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/python/overview/" rel="noopener ugc nofollow" target="_blank">文档</a>指出PyFlink是一个Python API，可以构建可扩展的批处理和流工作负载，例如:</p><ul class=""><li id="e372" class="mp mq it lx b ly mr mb ms li mt lm mu lq mv mn mw mx my mz bi translated"><em class="mo">实时数据处理管道</em>，</li><li id="56a0" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><em class="mo">大规模探索性数据分析</em>，</li><li id="0bcd" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><em class="mo">机器学习管道，</em></li><li id="fe60" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><em class="mo"> ETL流程。</em></li></ul><p id="8b4f" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">在某些方面，它可能被认为是PySpark的等价物，但在Apache Flink中。根据所需的抽象级别，PyFlink提供了两种不同的API:</p><ul class=""><li id="eed5" class="mp mq it lx b ly mr mb ms li mt lm mu lq mv mn mw mx my mz bi translated"><strong class="lx iu"> PyFlink表API: </strong>允许用户编写强大的关系查询，类似于使用SQL或在Python中处理数据帧。因为数据集可以用类似SQL的查询来导入、操作和丰富，这个API甚至为Python知识有限的个人提供了无限的解决方案。</li><li id="265e" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated"><strong class="lx iu"> PyFlink DataStream API: </strong>提供对Flink的核心构建块<strong class="lx iu"/><strong class="lx iu"/>的控制，构建更复杂的流处理用例。</li></ul><h1 id="c923" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">数据集</h1><p id="9698" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在Apache中，Flink数据可以被处理为<strong class="lx iu"> <em class="mo">有界</em> </strong>或<strong class="lx iu"> <em class="mo">无界</em> </strong>流。</p><p id="0022" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">本教程将重点介绍有界的<strong class="lx iu"> <em class="mo"> </em> </strong>流，因为处理有限的数据是开始学习PyFlink最简单的方法。</p><p id="07bc" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">事实上，当一个流是有界的，它有一个定义的开始和结束。这意味着可以在执行任何计算之前获取数据。有界流的处理也称为批处理。</p><p id="c041" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">具体来说，本教程中使用的<code class="fe ou ov ow ox b">fin_trxs</code>数据集以CSV格式存储，其中包含有关一千笔虚假银行交易的信息，可以在此处下载<a class="ae ky" href="https://github.com/anbento0490/code_tutorials/blob/master/fin_trxs.csv" rel="noopener ugc nofollow" target="_blank">。数据集的前10行显示如下:</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/692da563095635231adc6100bd00a3dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-DQCXWJzQhEYnbQa8IC6lQ.png"/></div></div></figure><p id="9cf2" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">数据故意没有标题，但您可以看到下面八列中每一列的定义:</p><pre class="kj kk kl km gt oz ox pa pb aw pc bi"><span id="448f" class="kz la it ox b gy pd pe l pf pg">column_names = [‘trx_id’, ‘trx_date’, ‘src_curr’, ‘amnt_src_curr’,  ‘amnt_gbp’, ‘user_id’, ‘user_type’, ‘user_country’]</span></pre><p id="5c76" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">现在，让我们学习如何用PyFlink从这个CSV文件创建一个表。</p><h1 id="4283" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">从CSV源创建表格</h1><p id="5a8b" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">使用<strong class="lx iu"> PyFlink表API </strong>，至少有两种方法可以将数据从源导入到表中。</p><h2 id="0b09" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">方法1:使用Python语法</h2><p id="4dee" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">第一种方法使用标准的<strong class="lx iu"> PyFlink </strong>语法从CSV文件导入有界数据。完整代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="3b2b" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">如您所见，代码已经被包装到一个<code class="fe ou ov ow ox b">main()</code>函数中，因此它可以作为一个应用程序工作。让我们一步一步地看看函数中发生了什么。</p><p id="3c11" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">在使用表格API时，最初的步骤是创建一个<em class="mo">表格环境</em>，所以我首先想到的是从<code class="fe ou ov ow ox b">pyflink.table</code>模块导入<code class="fe ou ov ow ox b">EnvironmentSettings</code>和<code class="fe ou ov ow ox b">TableEnvironment</code>。请注意，我还导入了即将使用的<code class="fe ou ov ow ox b">DataTypes</code>和<code class="fe ou ov ow ox b">CsvTableSource</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="3abb" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">我已经定义了环境设置(<code class="fe ou ov ow ox b">env_settings</code>)，指定在这个应用程序中数据将被批量处理(<code class="fe ou ov ow ox b">in_batch_mode</code>)，并将这个对象传递给<code class="fe ou ov ow ox b">TableEnvironment.create()</code>方法，以生成我将用来导入数据的<em class="mo">表环境</em>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="bfb3" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">然后，我将<code class="fe ou ov ow ox b">column_names</code>和<code class="fe ou ov ow ox b">column_types</code>(使用<code class="fe ou ov ow ox b">DataTypes</code>定义数据集<em class="mo">模式</em>)存储为列表，并将它们传递给<code class="fe ou ov ow ox b">CsvTableSource()</code>类——连同我的<code class="fe ou ov ow ox b">fin_trxs.csv</code>文件的本地路径——以创建数据<code class="fe ou ov ow ox b">source</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="fabe" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">最后，我在<code class="fe ou ov ow ox b">financial_trxs</code>名称下注册了CSV <code class="fe ou ov ow ox b">source</code>，并通过将源名称传递给<code class="fe ou ov ow ox b">from_path()</code>方法创建了一个实际的表<code class="fe ou ov ow ox b">tbl</code>:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="9573" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">如果您希望在控制台上可视化<code class="fe ou ov ow ox b">tbl</code>中的一些记录，我建议您使用以下命令:</p><pre class="kj kk kl km gt oz ox pa pb aw pc bi"><span id="1322" class="kz la it ox b gy pd pe l pf pg">tbl.limit(10).execute().print()</span></pre><p id="f5cb" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">或者，如果数据集足够小，可以放在内存中，也可以使用方便的<code class="fe ou ov ow ox b">to_pandas()</code>方法，将<code class="fe ou ov ow ox b">tbl</code>对象转换为pandas dataFrame:</p><pre class="kj kk kl km gt oz ox pa pb aw pc bi"><span id="1f69" class="kz la it ox b gy pd pe l pf pg">print(tbl.to_pandas())</span></pre><p id="9cb0" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">这是我通过运行<code class="fe ou ov ow ox b">main()</code>函数得到的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pj"><img src="../Images/ca33e96ddc61936f38f0c95cfeb88a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oYFdCgW5k1dU-nz6scj3pA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">main()函数的输出，使用方法1</p></figure><p id="8c80" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">这个PyFlink应用程序确实从一个CSV源文件中创建了一个1000行8列的表！</p><h2 id="19fb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">方法2:使用SQL语法</h2><p id="3b47" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在前面的方法中描述的一些步骤(<em class="mo">像定义一个模式，创建一个源并注册它</em>)有点乏味。</p><p id="d25e" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">幸运的是，在PyFlink中你还可以通过标准的SQL <em class="mo">数据定义语言</em> (DDL)直接创建一个表。完整代码如下所示:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="1546" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">如您所见，设置<code class="fe ou ov ow ox b">env_settings</code>和<code class="fe ou ov ow ox b">tbl_env</code>的方式与之前完全相同。</p><p id="e963" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">然而，现在实际的<code class="fe ou ov ow ox b">financial_trxs_2</code>表已经由SQL语句定义，在<code class="fe ou ov ow ox b">with()</code>子句中传递CSV <code class="fe ou ov ow ox b">source path</code>。</p><p id="8270" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">为了让表存在，需要执行查询并使用<code class="fe ou ov ow ox b">from_path()</code>方法导入源。</p><pre class="kj kk kl km gt oz ox pa pb aw pc bi"><span id="5318" class="kz la it ox b gy pd pe l pf pg">tbl_env.execute_sql(source_ddl)</span><span id="56fb" class="kz la it ox b gy pk pe l pf pg">tbl = tbl_env.from_path('financial_trxs')</span></pre><p id="6605" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">你猜怎么着？执行这段代码会导致相同的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pl"><img src="../Images/cc711ba061051c7844f02d1c731b4d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8j_WiRjQEuCzdqnDPTrBCg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">main()函数的输出，使用方法2</p></figure><h1 id="8a6f" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">奖励:PySpark中的等效代码</h1><p id="4ec8" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在这个奖金部分，我将回答这个问题:</p><p id="315a" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated"><em class="mo"/><strong class="lx iu"><em class="mo">PyFlink表API </em> </strong> <em class="mo">和</em><strong class="lx iu"><em class="mo">PySpark data frame API</em></strong><em class="mo">创建</em> <strong class="lx iu"> <em class="mo"> </em> </strong> <em class="mo">一个来自CSV源文件的表之间有什么不太冗长的语言？</em></p><p id="a624" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">为了便于比较，下面我分享了PySpark中的等价代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ph pi l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">等效PySpark代码的输出</p></figure><p id="debf" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">有输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pm"><img src="../Images/1191d8e16d4dd8b3938d2162d0ccb996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*it06nLEysoRxHOG55vCSfg.png"/></div></div></figure><p id="eb7c" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">从上面的代码中可以得出三个注意事项:</p><ul class=""><li id="0c5d" class="mp mq it lx b ly mr mb ms li mt lm mu lq mv mn mw mx my mz bi translated">总的来说，<strong class="lx iu"> PySpark DataFrame API </strong>确实减少了输入。特别是，创建一个<code class="fe ou ov ow ox b">SparkSession</code>比创建一个<code class="fe ou ov ow ox b">TableEnvironment</code>要简单得多。</li><li id="ecc4" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated">然而，使用<strong class="lx iu"> PyFlink表API </strong>，用<em class="mo"> method_1 </em>定义表模式更简单，用<em class="mo"> method_2定义更简单。</em></li><li id="b260" class="mp mq it lx b ly na mb nb li nc lm nd lq ne mn mw mx my mz bi translated">当需要从源中读取实际数据时，<strong class="lx iu"> PySpark DataFrame API </strong>提供了一个更加流畅的语法，不涉及任何初步注册或代码执行。</li></ul><h1 id="f86b" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">结论</h1><p id="0d77" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">在本教程中，您学习了如何利用<strong class="lx iu"> PyFlink表格API </strong>从CSV源文件创建表格。</p><p id="f3e5" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">此外，还对PyFlink 和PySpark 进行了比较，以了解处理这项任务最简便的语言是什么。</p><p id="397d" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">在下一篇教程中，您将学习如何通过数据流应用程序从Kafka主题导入PyFlink中的无界数据。敬请期待！</p><h1 id="d3c2" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">给我的读者一个提示</h1><p id="081b" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated"><em class="mo">这篇文章包括附属链接，如果你购买的话，我可以免费给你一点佣金。</em></p><h1 id="9fdb" class="nm la it bd lb nn op np le nq oq ns lh jz or ka ll kc os kd lp kf ot kg lt nw bi translated">来源</h1><p id="c54e" class="pw-post-body-paragraph lv lw it lx b ly lz ju ma mb mc jx md li me mf mg lm mh mi mj lq mk ml mm mn im bi translated">PyFlink官方文件。</p><p id="5a05" class="pw-post-body-paragraph lv lw it lx b ly mr ju ma mb ms jx md li nx mf mg lm ny mi mj lq nz ml mm mn im bi translated">编码示例是作者对在线课程<a class="ae ky" href="https://click.linksynergy.com/deeplink?id=533LxfDBSaM&amp;mid=39197&amp;murl=https%3A%2F%2Fwww.udemy.com%2Fcourse%2Fapache-flink-relational-programming-using-table-api-and-sql%2F" rel="noopener ugc nofollow" target="_blank">Apache Flink Relational Programming Using Table API And SQL</a>中介绍的材料的重新解释。</p></div></div>    
</body>
</html>