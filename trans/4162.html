<html>
<head>
<title>Modeling DNA Sequences with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch建模DNA序列</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/modeling-dna-sequences-with-pytorch-de28b0a05036#2022-09-15">https://towardsdatascience.com/modeling-dna-sequences-with-pytorch-de28b0a05036#2022-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1b39" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">适合初学者的教程</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/051b600027b968ade27557ef55570711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3WpoR72CPkE1RvHX8Tfzg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="b804" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">DNA是一个复杂的数据流。虽然它可以用一串ACTGs来表示，但它充满了复杂的模式和结构上的细微差别，人类很难通过查看原始的核苷酸序列来理解。近年来，利用深度学习对DNA数据建模取得了很大进展。</p><p id="c674" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">研究人员应用了卷积神经网络(CNN)、长短期记忆网络(LSTMs)、甚至变压器等方法，直接从DNA序列预测各种基因组测量值。这些模型特别有用，因为有了足够多的高质量训练数据，它们可以自动拾取与预测任务相关的序列模式(或基序)，而不需要专家事先指定要寻找哪些模式。总的来说，人们越来越热衷于在基因组学中使用深度学习来帮助将DNA序列映射到它们的生物功能！</p><p id="21e3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为一名对使用计算方法解决可持续性和合成生物学挑战感兴趣的研究生，我一直在学习如何使用PyTorch研究DNA序列模式。不缺少关于如何开始使用PyTorch的教程，但是许多教程倾向于关注图像或语言输入数据。对于使用DNA作为输入，有许多伟大的项目已经开发了PyTorch框架来模拟各种生物现象[ <a class="ae lr" href="https://github.com/FunctionLab/selene" rel="noopener ugc nofollow" target="_blank"> 1 </a>、<a class="ae lr" href="https://github.com/davek44/Basset" rel="noopener ugc nofollow" target="_blank"> 2 </a>、<a class="ae lr" href="https://github.com/jerryji1993/DNABERT" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]，但是它们可能非常复杂，对于初学者来说很难钻研。</p><p id="d8d0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我在为PyTorch新手寻找那些<em class="ls">也</em>关注DNA数据的初学者例子时遇到了一些困难，所以我编写了一个快速教程，以防将来的DNA建模者发现它对入门有帮助！</p><p id="8e34" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">教程本身可以作为一个 <a class="ae lr" href="https://github.com/erinhwilson/dna-pytorch-tutorial" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir"> Jupyter笔记本</strong> </a>交互式运行，或者您可以跟随本文剩余部分中的关键概念和Github要点摘要。</p></div><div class="ab cl lt lu hu lv" role="separator"><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly lz"/><span class="lw bw bk lx ly"/></div><div class="ij ik il im in"><h1 id="7ca0" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">建立PyTorch模型来预测DNA序列的得分</h1><p id="6fe7" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">本教程展示了PyTorch框架的一个示例，它可以使用原始DNA序列作为输入，将这些输入到神经网络模型中，并直接从序列中预测定量标记。</p><p id="e5f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">教程概述:</strong></p><ol class=""><li id="d654" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nc nd ne nf bi translated">生成合成DNA数据</li><li id="4b41" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">为PyTorch培训准备数据</li><li id="e9ec" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">定义PyTorch模型</li><li id="e315" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">定义训练循环函数</li><li id="b801" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">运行模型</li><li id="7182" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">在测试集上检查模型预测</li><li id="29a9" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">可视化卷积滤波器</li><li id="da1b" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nc nd ne nf bi translated">结论</li></ol><p id="b6c8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它假设读者已经熟悉ML概念，如:</p><ul class=""><li id="9e29" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">什么是神经网络，包括卷积神经网络(CNN)的基础知识</li><li id="f08d" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">跨时代的模型训练</li><li id="ecce" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">将数据分成训练/值/测试集</li><li id="dfd8" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">损失函数和比较列车与val损失曲线</li></ul><p id="3e65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">它还假设对生物学概念有所了解，如:</p><ul class=""><li id="f4d7" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">DNA核苷酸</li><li id="7a49" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">什么是调控基序？</li><li id="9192" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">可视化DNA基序</li></ul><p id="9113" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> <em class="ls">注意:</em> </strong> <em class="ls">下面的方法不一定是</em> <strong class="kx ir"> <em class="ls">最优</em> </strong> <em class="ls">的方法！我相信还有更好的解决方法，这只是我在学习中的尝试。但是，如果您刚刚开始使用PyTorch，并且也在使用DNA序列作为输入，那么本教程可能是一个有用的例子，说明如何在DNA序列分析的背景下“将一些PyTorch管连接在一起”。</em></p><h1 id="6039" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">1.生成合成DNA数据</h1><p id="80ab" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">通常，科学家可能对预测结合分数、表达强度或转录因子结合事件的分类感兴趣。但在这里，我们将保持简单:本教程的目标是观察深度学习模型是否可以学习检测DNA序列中非常小、简单的模式，并对其进行适当的评分(同样，这只是一个练习任务，以说服我们自己我们实际上已经正确设置了PyTorch片段，以便它可以从看起来像DNA序列的输入中学习)。</p><p id="99ef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，假设给定一个八聚体DNA序列，给它每个字母的分数如下:</p><ul class=""><li id="55bc" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">A = +20分</li><li id="99b5" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">C = +17点</li><li id="0e5e" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">G = +14点</li><li id="7c90" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">T = +11点</li></ul><p id="6cd9" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于每一个8-mer，合计其总点数，然后取平均值。举个例子，</p><p id="ff7f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe nr ns nt nu b">AAAAAAAA</code>会得分<code class="fe nr ns nt nu b">20.0</code></p><blockquote class="nv nw nx"><p id="770d" class="kv kw ls kx b ky kz jr la lb lc ju ld ny lf lg lh nz lj lk ll oa ln lo lp lq ij bi translated"><code class="fe nr ns nt nu b">mean(20 + 20 + 20 + 20 + 20 + 20 + 20 + 20) = 20.0</code></p></blockquote><p id="9c1e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><code class="fe nr ns nt nu b">ACAAAAAA</code>会得分<code class="fe nr ns nt nu b">19.625</code></p><blockquote class="nv nw nx"><p id="599f" class="kv kw ls kx b ky kz jr la lb lc ju ld ny lf lg lh nz lj lk ll oa ln lo lp lq ij bi translated"><code class="fe nr ns nt nu b">mean(20 + 17 + 20 + 20 + 20 + 20 + 20 + 20) = 19.625</code></p></blockquote><p id="186f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些核苷酸的值是任意的——这里没有真正的生物学！这只是为了我们PyTorch练习的目的而给序列分配分数的一种方式。</p><p id="9024" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，由于最近的许多论文使用类似CNN的方法来自动检测“基序”，或DNA中可以激活或抑制生物反应的短模式，让我们在我们的评分系统中再增加一项。为了模拟诸如影响基因表达的基序之类的东西，假设一个给定的序列，如果<code class="fe nr ns nt nu b">TAT</code>出现在八聚体中的任何地方，就会得到一个<code class="fe nr ns nt nu b">+10</code>凸起，如果其中有一个<code class="fe nr ns nt nu b">GCG</code>，就会得到一个<code class="fe nr ns nt nu b">-10</code>凸起。同样，这些图案在现实生活中没有任何意义，它们只是一种模拟简单激活或抑制效果的机制。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/cdf644df27bf0d7f71fe977ad24f62c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQtWgVWmh_r2sb2D9yCEMw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一个简单的八聚体DNA序列评分系统。图片作者。</p></figure><p id="3169" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是这个简单评分系统的实现:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="3b2d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">绘制8聚体序列的分数分布图，我们看到它们分成3组:</p><ul class=""><li id="7a4a" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">带有<code class="fe nr ns nt nu b">GCG</code>的序列(分数= ~5)</li><li id="8f44" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">没有基序的序列(得分= ~15)</li><li id="cc3d" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">带<code class="fe nr ns nt nu b">TAT</code>的序列(分数= ~25)</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/343efb3f18085c996726149697d4be77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_yHcyeISSZ5UDM28mUC5g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">八聚体分数的分布。图片作者。</p></figure><p id="e6de" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们现在的目标是<strong class="kx ir">训练一个模型，通过观察DNA序列来预测这个分数</strong>。</p><h1 id="c3a6" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">2.为PyTorch培训准备数据</h1><p id="7ad5" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">为了让神经网络做出预测，你必须把你的输入作为一个数字矩阵给它。例如，为了根据图像是否包含猫来对图像进行分类，网络将图像“视为”像素值的矩阵，并学习像素的相对排列中的相关模式(例如，对应于猫耳朵或长有胡须的鼻子的模式)。</p><p id="f308" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们同样需要将我们的DNA序列(ACGTs的字符串)转换成一个数字矩阵。那么我们如何假装自己的DNA是猫呢？</p><p id="c712" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一种常见的策略是一次性编码DNA:将每个核苷酸视为长度为4的向量，其中3个位置为0，一个位置为1，具体取决于核苷酸。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/0e2865ced643d310a55e041d80256d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SMJejOb3mUJcpV6bwhjnPw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">这种一次性编码方案有一个很好的特性，它使你的DNA看起来就像计算机看到的猫的照片一样！图片作者。</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="a330" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有了这个一次性编码方案，我们就可以准备好我们的训练集、val集和测试集。这个<code class="fe nr ns nt nu b">quick_split</code>只是在pandas数据帧中随机选择一些指数来分割(sklearn也有一个函数来做这个)。</p><p id="390f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="ls">注意:在真实的/非合成的任务中，根据你的预测任务，你可能需要更聪明地使用分裂策略:通常论文会根据染色体或其他基因组位置特征创建训练/测试分裂。</em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="23ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为PyTorch准备数据的一个重要步骤是使用<a class="ae lr" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html" rel="noopener ugc nofollow" target="_blank"> DataLoader和Dataset </a>对象。我花了很多时间在谷歌上搜索来找出一些东西，但这是我能够通过大量梳理文档和堆栈溢出帖子来炮制的解决方案！</p><p id="8b1e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">简而言之，数据集将数据包装在一个对象中，该对象可以顺利地将正确格式化的X示例和Y标签提供给正在训练的模型。DataLoader接受数据集和其他一些有关如何根据数据形成批次的详细信息，并使迭代训练步骤变得更加容易。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="5386" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这些数据加载器现在可以在训练循环中使用了！</p><h1 id="9eea" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">3.定义PyTorch模型</h1><p id="ae86" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">我感兴趣尝试的主要模型是卷积神经网络，因为这些已经被证明对从基因组数据中学习基序是有用的。但是作为比较，我包含了一个简单的线性模型。以下是一些模型定义:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="f448" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">注意:这些不是优化的模型，只是一些开始的东西(同样，我们只是在DNA环境中练习连接PyTorch管)。</p><ul class=""><li id="8cc8" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">线性模型试图通过简单地加权出现在每个位置的核苷酸来预测分数。</li><li id="a001" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">CNN模型使用32个长度为(<code class="fe nr ns nt nu b">kernel_size</code> ) 3的过滤器来扫描8-mer序列以获得信息性的3-mer模式。</li></ul><h1 id="08fe" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">4.定义训练循环功能</h1><p id="358a" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">接下来，我们需要定义训练/体能循环。我承认我在这里并不<em class="ls">超级</em>自信，并且花了很多时间费力地解决矩阵维度不匹配错误——可能有更好的方法来解决这个问题！但也许这样就可以了？- <em class="ls">耸肩</em> -(有反馈就给我发消息🤓)</p><p id="1901" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在任何情况下，我都是这样定义函数堆栈的:</p><pre class="kg kh ki kj gt og nu oh oi aw oj bi"><span id="5f94" class="ok mb iq nu b gy ol om l on oo"><em class="ls"># adds default optimizer and loss function</em><br/>run_model()<br/>    <em class="ls"># loops through epochs</em><br/>    fit()<br/>        <em class="ls"># loop through batches</em><br/>        train_step()<br/>            <em class="ls"># calc train loss for batch</em><br/>            loss_batch()<br/>        val_step()<br/>            <em class="ls"># calc val loss for batch</em><br/>            loss_batch()</span></pre><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><h1 id="2c8d" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">5.运行模型</h1><p id="44d7" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">首先，让我们试着在我们的八聚体序列上运行一个线性模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="c6ba" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在收集了train和val损失之后，让我们在一个快速的图中查看它们:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b056363e19cb5ef5ef48849022fe6d02.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*TKnVtOFfyUPcVyxkc5wuHg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">线性模型训练和验证损失曲线。图片作者。</p></figure><p id="da99" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">乍一看，似乎没有学到多少东西。</p><p id="cf31" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来让我们试试CNN，画出损耗曲线。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/0e630fb1c6f905a4c15fd8c17763eb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*gbvkMlVgTNkczUVLUZFuJQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">CNN和线性模型的损耗曲线。图片作者。</p></figure><p id="a1c6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从损失曲线可以清楚地看出，CNN能够捕捉到数据中的一种模式，而线性模型却不能！我们来抽查几个序列，看看是怎么回事。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="64eb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从上面的例子可以看出，线性模型实际上是低估了含有大量G的序列，而高估了含有大量T的序列。这可能是因为它注意到<code class="fe nr ns nt nu b">GCG</code>制造的序列具有异常低的分数，而<code class="fe nr ns nt nu b">TAT</code>制造的序列具有异常高的分数。然而，由于线性模型没有办法考虑到<code class="fe nr ns nt nu b">GCG</code>与<code class="fe nr ns nt nu b">GAG</code>的不同上下文，它只是预测具有G的序列应该更低。从我们的评分方案中我们知道事实并非如此:不是G一般都是有害的，而是<strong class="kx ir">特别是</strong> <code class="fe nr ns nt nu b">GCG</code>是有害的。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><p id="825d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">CNN更能适应3-mer基序之间的差异！它对有和没有基序的序列都有很好的预测。</p><h1 id="865b" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">6.在测试集上检查模型预测</h1><p id="d739" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">在任何机器学习任务中，一个重要的评估步骤是检查你的模型是否能在测试集上做出好的预测，这是<em class="ls">在训练中从未</em>见过的。这里，我们可以使用奇偶图来可视化实际测试序列分数与模型预测分数之间的差异。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/4cf599721a19390f4a754ac91aba057e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hpkEWXIJnfA9mR9EDFJFbg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">测试集序列的实际分数与预测分数的比较。图片作者。</p></figure><p id="983b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">奇偶图对于可视化模型预测单个序列的效果非常有用:在完美的模型中，它们都落在<code class="fe nr ns nt nu b">y=x</code>线上，这意味着模型预测正是序列的实际值。但如果它偏离了<code class="fe nr ns nt nu b">y=x</code>线，这意味着模型预测过高或过低。</p><p id="fadf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在线性模型中，我们可以看到它可以在一定程度上预测测试集序列的趋势，但确实会被分布的高和低区域中的这些序列桶(具有基序的序列)所混淆。</p><p id="1e06" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而对于CNN来说，它更擅长预测接近实际值的分数！这是意料之中的，因为我们的CNN架构使用3-mer核来扫描序列中有影响的基序。</p><p id="5c27" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是CNN并不完美。我们也许可以训练它更长时间或者调整超参数，但是这里的目标不是完美——相对于实际的监管语法，这是一个非常简单的任务。相反，我认为使用Altair可视化库来交互式地检查模型出错的序列会很有趣:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="os od l"/></div></figure><p id="dc5e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，不在对角线上的序列往往有<em class="ls">多个</em>基序实例！在评分函数中，如果序列至少有一个基序，我们只给它一个+/-凸起，但如果基序出现多次，决定增加多个奖励肯定是合理的。在这个例子中，我任意地只增加了至少1个模体出现的奖励，但是我们可以使用不同的评分函数。</p><p id="060f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">无论如何，我认为这个模型注意到了多次出现并预测它们是重要的，这很酷。我想我们确实愚弄了它一点，虽然0.95的R2是相当可观的:)</p><h1 id="2f40" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">7.可视化卷积滤波器</h1><p id="993f" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">当训练CNN模型时，可视化第一层卷积滤波器以尝试了解更多关于模型正在学习的内容可能是有用的。对于图像数据，第一层卷积滤波器通常会学习边界、颜色或纹理等模式，这些基本的图像元素可以重新组合，以形成更复杂的特征。</p><p id="979c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在DNA中，卷积过滤器可以被认为类似于模体扫描仪。与用于可视化序列标志的位置权重矩阵类似，卷积过滤器就像一个显示特定DNA模式的矩阵，但它不是一个<em class="ls">精确的</em>序列，它可以保留一些关于哪些核苷酸出现在模式的哪个部分的不确定性。一些位置可能是非常确定的(例如，在位置2中总是有一个A；高信息含量),而其他位置可以以大约相等的概率容纳多种核苷酸(高熵；信息量低)。</p><p id="5e65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">发生在神经网络隐藏层中的计算可能会变得非常复杂，并且不是每个卷积滤波器都是明显相关的模式，但是有时滤波器中的模式确实会出现，并且可以提供信息来帮助解释模型的预测。</p><p id="ae65" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面是一些功能，以可视化的第一层卷积滤波器，既作为一个原始的热图，也作为一个主题标志。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/7d2a8db4e2c6b338cfd2ac00baf67544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PWCd4OMUx5URsab7GfkIfA.png"/></div></div></figure><p id="a031" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">好吧，也许这有点帮助，但通常人们喜欢将带有一些不确定性的序列可视化为模体标志:x轴是模体中的位置，y轴是每个核苷酸出现在每个位置的概率。通常，这些概率被转换成比特(也称为信息内容)，以便于可视化。</p><p id="3f57" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了将原始卷积滤波器转换成位置权重矩阵视觉效果，通常收集滤波器激活:沿着一个独热编码序列应用滤波器的权重，并测量滤波器激活(也称为权重与序列的匹配程度)。</p><p id="30e8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对应于与给定序列紧密匹配的过滤权重矩阵将被强烈激活(产生更高的匹配分数)。通过收集产生最高激活分数的DNA子序列，我们可以为每个过滤器创建“高度激活序列”的位置权重矩阵，因此将卷积过滤器可视化为基序标志。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ou"><img src="../Images/44119314ed5f902b5b9a23a5373b37c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bsUjiRfRCL8yDlhyvjUIig.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">对于给定的卷积滤波器，如何收集强激活子序列并将其转换为motif徽标的示意图。图片作者。</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/27cd9db82ef46875ca330077b1174072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drImfBkrQ1Uj3VJDc_h8CQ.png"/></div></div></figure><p id="4329" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从这个特定的CNN训练中，我们可以看到一些过滤器选择了强烈的TAT和GCG主题，但其他过滤器也专注于其他模式。</p><p id="79a7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">关于卷积滤波器可视化与模型可解释性的相关性存在一些争论。在具有多个卷积层的深度模型中，卷积滤波器可以在隐藏层内部以更复杂的方式重新组合，因此第一层滤波器本身可能不会提供足够的信息(<a class="ae lr" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007560" rel="noopener ugc nofollow" target="_blank"> Koo和Eddy，2019 </a>)。这个领域的大部分已经转向注意力机制和其他可解释的方法，但是如果你好奇的把你的过滤器想象成潜在的主题，这些函数可以帮助你开始！</p><h1 id="e215" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">8.结论</h1><p id="af02" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">本教程展示了一些基本的PyTorch结构，用于构建处理DNA序列的CNN模型。本演示中使用的练习任务不能反映真实的生物信号；相反，我们设计了评分方法来模拟非常短的序列中调控基序的存在，这对于我们人类来说很容易检查和验证PyTorch的行为符合预期。从这个小例子中，我们观察到具有滑动过滤器的基本CNN如何能够比仅考虑绝对核苷酸位置(没有局部上下文)的基本线性模型更好地预测我们的评分方案。</p><p id="95f3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">要阅读更多关于CNN应用于野外DNA的信息，请查阅以下基础论文:</p><ul class=""><li id="d7ba" class="mx my iq kx b ky kz lb lc le mz li na lm nb lq nl nd ne nf bi translated">深度绑定:<a class="ae lr" href="https://www.nature.com/articles/nbt.3300" rel="noopener ugc nofollow" target="_blank">阿里帕纳西等人2015 </a></li><li id="fee5" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">深海:<a class="ae lr" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4768299/" rel="noopener ugc nofollow" target="_blank">周与特洛扬斯卡娅2015 </a></li><li id="5ea6" class="mx my iq kx b ky ng lb nh le ni li nj lm nk lq nl nd ne nf bi translated">巴塞特:<a class="ae lr" href="https://pubmed.ncbi.nlm.nih.gov/27197224/" rel="noopener ugc nofollow" target="_blank">凯利等人2016 </a></li></ul><p id="1808" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我希望其他对解决生物学问题感兴趣的新手可以发现这有助于开始使用PyTorch对DNA序列建模:)</p><h1 id="84f8" class="ma mb iq bd mc md nm mf mg mh nn mj mk jw no jx mm jz np ka mo kc nq kd mq mr bi translated">9.脚注</h1><h2 id="30ca" class="ok mb iq bd mc ov ow dn mg ox oy dp mk le oz pa mm li pb pc mo lm pd pe mq pf bi translated">脚注1</h2><p id="e9bb" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">在本教程中，CNN模型定义使用了1D卷积层，因为DNA不是二维图像，Conv1D足以沿着长度维度滑动，而不是上下扫描。(事实上，上下滑动过滤器并不适用于一键编码的DNA矩阵:将<code class="fe nr ns nt nu b">A</code>和<code class="fe nr ns nt nu b">C</code>行与<code class="fe nr ns nt nu b">G</code>和<code class="fe nr ns nt nu b">T</code>行分开是没有意义的——你需要所有4行来精确地表示一个DNA序列。)</p><p id="c77a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，我曾经发现自己需要使用一个用keras构建的分析工具，并找到了一个pytorch2keras转换脚本。转换脚本只知道如何处理Conv2d层，并给出了带有Conv1d层的模型的错误:(</p><p id="0e32" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您遇到这种情况，以下是如何使用Conv2D重新格式化CNN定义的示例，同时确保它仍然像Conv1D一样扫描DNA:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oc od l"/></div></figure><h2 id="e6fc" class="ok mb iq bd mc ov ow dn mg ox oy dp mk le oz pa mm li pb pc mo lm pd pe mq pf bi translated">脚注2</h2><p id="6bc0" class="pw-post-body-paragraph kv kw iq kx b ky ms jr la lb mt ju ld le mu lg lh li mv lk ll lm mw lo lp lq ij bi translated">如果你正在做一个分类任务而不是回归任务，你可能想要使用<code class="fe nr ns nt nu b">CrossEntropyLoss</code>。然而，<code class="fe nr ns nt nu b">CrossEntropyLoss</code>期望的格式与<code class="fe nr ns nt nu b">MSELoss</code>略有不同——试试这个:</p><pre class="kg kh ki kj gt og nu oh oi aw oj bi"><span id="0f7f" class="ok mb iq nu b gy ol om l on oo">loss = loss_func(xb_out, yb.long().squeeze(1))</span></pre></div></div>    
</body>
</html>