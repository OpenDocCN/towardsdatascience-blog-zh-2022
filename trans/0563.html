<html>
<head>
<title>Approaching Your First NLP Project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">接近你的第一个NLP项目</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/approaching-your-first-nlp-project-7f3df530d350#2022-02-22">https://towardsdatascience.com/approaching-your-first-nlp-project-7f3df530d350#2022-02-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="920a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第一次处理文本数据是最难的。您错过了一个“简单”的表格数据集，在这里您可以轻松地过滤和连接表。</p><p id="c199" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章将帮助你完成你的第一个NLP项目，并以良好的结果结束它。我们将处理来自<a class="ae ko" href="https://www.kaggle.com/vstepanenko/disaster-tweets" rel="noopener ugc nofollow" target="_blank">灾难推特数据集</a>的推特数据。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi kp"><img src="../Images/bbe32ba72d2824af379178d2963691bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y0cPj_wLVbd6yu-m7Gvi8A.jpeg"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h1 id="d00e" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">本次挑战的目的</h1><p id="c2de" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我们都知道Twitter是一个重要的沟通渠道。成千上万的人每天使用它来分享东西，从随机的想法、模因、科学线索到关于世界上某个地方实时发生的灾难和紧急情况的消息。</p><p id="6c54" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">能够将这些紧急推文从噪音中分离出来将是我们的主要目标。我们将处理包含7613条标签推文的数据集。(标注为灾难或非灾难)。</p><p id="6a62" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将探索多种机器学习模型和标记化/矢量化策略，以找到表现最好的一种。我们目前最好的方法在测试集上显示了0.80723 的<strong class="js iu"> F1值。</strong></p><h1 id="6d66" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据集描述</h1><p id="4d37" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">训练数据集由7613个带标签的示例组成。和5列:</p><ul class=""><li id="c829" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu"> id: </strong>每条推文的唯一标识符。</li><li id="2329" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">文本:推文的文本。</li><li id="5628" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">位置:</strong>发送推文的位置(可能为空)。</li><li id="ca2b" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">关键词:</strong>来自tweet的特定关键词(可能为空)。</li><li id="e247" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu"> target: </strong>表示一条推文是关于真实的灾难(1)还是不是(0)。</li><li id="3dab" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">在所有的实验中，我们将主要使用文本和关键字列。</li></ul><h1 id="59e6" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">快速查看数据</h1><p id="595e" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在全押并随机将你的训练数据插入sklearn函数之前，让我们看看我们的数据，看看是否有任何需要清理的地方。</p><h1 id="a79b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">标签的分发</h1><p id="a799" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">需要注意的一件重要事情是，目标列不是100%平衡的。正如我们所见，数据集略有不平衡。这是我们在设计验证策略时会考虑的因素。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="05fe" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">检查NaN值</h1><p id="2bc3" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">关键字功能似乎很有用。它包含一些NaN值，但没有那么多要估算的，它仍然可以为模型添加一些值。(我们将实验混合文本和关键字数据的模型)。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="8e3b" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据清理</h1><p id="04ed" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">数据集中包含的推文似乎是原始的。这意味着它们包含可能误导我们的机器学习模型的“杂质”。</p><p id="59eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们的下一步应该是通过以下方式清理数据:</p><ul class=""><li id="a3ca" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated"><strong class="js iu">删除网址:</strong>有些推文有分析不感兴趣的外部链接或图片。</li><li id="ab7c" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">移除标签:</strong>电脑会把单词#danger和danger解释为不同的单词。但是对一个人类来说，意义是一样的。</li><li id="f237" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated"><strong class="js iu">删除多个空格:</strong>有些推文有几个空格。我决定删除这些空白，因为它们不会给文本的含义增加任何有用的信息。</li></ul><h1 id="c0ff" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">预处理</h1><p id="9a88" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在接下来的实验中。我们将探索不同的预处理技术。并将最好的用于最终模型。</p><ul class=""><li id="9ee1" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">标记化:我们将使用<a class="ae ko" href="https://www.nltk.org/api/nltk.tokenize.html" rel="noopener ugc nofollow" target="_blank"> NLTK </a>单词标记化方法将字符串分割成单词列表。</li><li id="d694" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">引理化:在一些实验中，我们会看到使用引理化有助于减少样本空间。这特别有用，因为我们的模型更容易推广。</li><li id="5027" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">TF-IDF和计数向量化:我们将尝试使用TF-IDF和计数向量化技术来构建一个单词包。</li><li id="8144" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">One-hot-encoding:在一些实验中，我们将使用文本和关键字列来训练模型。因此，为了能够使用关键字列，我们必须通过使用一键编码将其转换为“计算机友好的输入”。</li></ul><h1 id="f514" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">方法</h1><p id="2980" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我们将遵循四个一般部分的方法来解决这个问题。</p><ul class=""><li id="4f1e" class="mi mj it js b jt ju jx jy kb mk kf ml kj mm kn mn mo mp mq bi translated">建立强有力的验证策略。</li><li id="bfa5" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">专注于优化一个错误指标(F1分)。</li><li id="cd3f" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">探索不同的预处理技术/模型架构。</li><li id="4064" class="mi mj it js b jt mr jx ms kb mt kf mu kj mv kn mn mo mp mq bi translated">用最好的模型建立了一个集合模型。</li></ul><p id="a88c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">构建健壮的机器学习模型的最重要的部分之一是拥有健壮的验证策略。为此，我们将使用<a class="ae ko" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">分层文件夹</a>将数据分成五组。这将允许我们<strong class="js iu">在每个折叠中保持目标的原始分布</strong>。</p><p id="01a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一个重要的细节是使用相同的折叠来训练和验证所有的实验。这样，实验之间的每个结果都可以相互比较。</p><h1 id="1dfc" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">实验</h1><p id="3f7c" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这是有趣的部分开始。我们将探索7个不同的实验。每个人都试图获得比前一个更好的F1确认分数。</p><p id="d641" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，我们将选出三位表现最好的模特，并进行合奏。</p><h2 id="23d9" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">虚拟基线</h2><p id="6d2c" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">在试验复杂的架构和繁重的前置处理之前，让我们只使用数据集中出现的关键字<strong class="js iu">列(这里没有文本数据)来构建一个基本的机器学习模型。</strong></p><p id="0444" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们必须对关键字列中的值进行一次性编码，然后将它们插入到逻辑回归模型中。</p><p id="19f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本实验的目的是使用简单快速的解决方案建立基线误差度量。因此，所有其他更复杂的算法都应该在这个基准之上执行。</p><p id="ce65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于只使用一个特性的模型，我发现结果相当不错。<strong class="js iu">F1得分为0.667 </strong>，这很好，因为比随机得分要好。这将是下一次实验要超越的新基准。</p><p id="44db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">注:</strong> Medium并不是分享编码教程的最佳平台。这对我来说很难，在这里向你们展示，复制这个分析所需的所有代码。但是下面的代码片段应该让你知道我在每个实验中做了什么。我也在这个<a class="ae ko" href="https://www.kaggle.com/santiviquez/nlp-disasters-tweets-lb-0-80723" rel="noopener ugc nofollow" target="_blank">笔记本</a>里分享了<strong class="js iu">所有的代码</strong>。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/9b584d324af6e7320a1e2c04b3510574.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*rei60BrZpLCzaLWS8YY-Lg.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h2 id="b5be" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">逻辑回归和TD-IDF</h2><p id="74c4" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">对于第二个实验，我们将只使用文本数据。我们将应用单词标记器方法将句子转换成单词列表，然后应用TF-IDF矢量化方法。得到句子中单词相关性的数字表示。在预处理之后，我们将拟合逻辑回归模型。</p><p id="c3b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个实验背后的直觉是，某些单词比其他单词更相关。这些词在句子中的出现可能会告诉我们这条推文是否是关于一场灾难。然后使用逻辑回归模型假设每个单词和最终目标之间存在线性关系。</p><p id="91c5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在运行这个实验之后，我得到了一个不错的结果。平均<strong class="js iu"> F1分0.753 </strong>。更重要的是对我们的虚拟基线模型的改进。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/4bd1a9350793df52fcea049985233fba.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*a21ak4i-76c3s7Gw7jnO2g.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h2 id="d8f3" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">逻辑回归和计数矢量器</h2><p id="ab76" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">CountVectorizer会将文本数据转换成数字特征。推文中的每个单词都将被转换成一个数字。这个数字就是这个词在一条推文中出现的次数。</p><p id="401f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用这个简单的方法，我们假设每条推文中包含的单词是一个很好的指标，表明这条推文是否是关于灾难的。</p><p id="6fe8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在应用L2正则化并使用正则化参数后。我找到了一个新的基准。交叉验证的平均<strong class="js iu"> F1分为0.755 </strong>。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/8d34de49a1332338355aac61cd843067.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*a6cQsp6s7EgJYr9yYX60QQ.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h2 id="8307" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">逻辑回归和预处理</h2><p id="e11b" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">到目前为止，在过去的3个实验中，我们只使用了文本数据。在这个实验中，让我们测试一下向文本数据添加关键字特性和一些词汇化是否会有帮助。</p><p id="c198" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">的确很有帮助！我们找到了新的基准。我们从平均F1: 0.755上升到平均F1分数0.764 </p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f4106a7d103de14da2789e627a6184b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*Y9EpfQC1Z2lyMG1OIkNsCA.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><p id="d718" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将在下面的实验中使用相同的前置管道。唯一的区别是我们将尝试不同的模型架构。</p><h2 id="45bc" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">线性SVC和预处理</h2><p id="be25" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">让我们从逻辑回归开始，尝试使用具有相同预处理管道的线性支持向量分类器。</p><p id="a20f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我的表现没有任何提高。然而，这个模型在我们的最后一个实验中是有用的，当我们开始堆叠分类器的时候。</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/5da90de3ea869ff9b393d08c4ce1dde9.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*cn20cBJE6BD-C6FxCSk03w.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h2 id="1b16" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">XGBoost &amp;预处理</h2><p id="407c" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">这次让我们使用XGBoost分类器。XGBoost在机器学习社区中非常流行和广泛使用。</p><p id="b2c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">但是正如你在下面代码的注释中看到的，逻辑回归仍然表现得更好。尽管如此，我们还是会看到，将XGBoost模型添加到系综中会给我们带来很好的结果。</p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div class="gh gi no"><img src="../Images/36103fccc8e71c4a042bcfdcc81d2c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*uwZ-WvbzP-fkqiTOo37caw.png"/></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure><h2 id="3d3a" class="my lg it bd lh mz na dn ll nb nc dp lp kb nd ne lt kf nf ng lx kj nh ni mb nj bi translated">堆叠分类器</h2><p id="5b38" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">对于最后一个实验，让我们用最后三个模型中的分类器建立一个集成模型。</p><p id="9e84" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法将允许我们通过使用最终估计量(另一个逻辑回归量)的输入来使用每个估计量的强度。</p><p id="73e5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们记住当前的基准是0.764。目标是找到一个比这更好的交叉验证F1分数。我们做到了。使用集成模型，我们能够找到一个稍微好一点的分类器，其<strong class="js iu"> F1分数为0.7653 </strong></p><figure class="kq kr ks kt gt ku"><div class="bz fp l di"><div class="mw mx l"/></div></figure><h1 id="6426" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">最终预测</h1><p id="9958" class="pw-post-body-paragraph jq jr it js b jt md jv jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn im bi translated">我使用上次实验中的堆叠模型对隐藏测试集进行了预测，并发现了很好的结果。测试集上的<strong class="js iu"> F1分数为0.80723 </strong>。甚至比我们在验证折叠上得到的结果还要好。</p><p id="63ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就是拥有一个好的验证策略的好处！代码和最终结果可以在<a class="ae ko" href="https://www.kaggle.com/santiviquez/nlp-disasters-tweets-lb-0-80723" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>中找到</p><figure class="kq kr ks kt gt ku gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi np"><img src="../Images/40d34695dfd1ceaea4ad9d88866b8824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vPTuij79EiJCHAUK4HNo6A.png"/></div></div><p class="lb lc gj gh gi ld le bd b be z dk translated">作者图片</p></figure></div><div class="ab cl nq nr hx ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="im in io ip iq"><p id="c7b7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我经常在推特<a class="ae ko" href="https://twitter.com/santiviquez" rel="noopener ugc nofollow" target="_blank"><strong class="js iu"/></a>上分享关于数据科学和机器学习的东西。想加入我的话就关注我，继续在公共场合学习:)</p></div></div>    
</body>
</html>