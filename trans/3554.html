<html>
<head>
<title>Is Your Model the Best One or the Luckiest One?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的模特是最好的还是最幸运的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/is-your-model-the-best-one-or-the-luckiest-one-7cfd1f43ea6#2022-08-08">https://towardsdatascience.com/is-your-model-the-best-one-or-the-luckiest-one-7cfd1f43ea6#2022-08-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9bbb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何避免在选择最佳模型时被随机性所迷惑</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/63ac4c69802cef7663b364e86b415a32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymAMG-SI7iLAdRewfoSrUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[图片由作者提供]</p></figure><p id="9f79" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi lu translated"><span class="l lv lw lx bm ly lz ma mb mc di">我们</span>已经习惯了Kaggle中的数据科学挑战，ROC分数0.1%的变化就能决定赢得10万美元还是一无所获。</p><p id="1c63" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以<a class="ae md" href="https://www.kaggle.com/competitions/data-science-bowl-2017/overview" rel="noopener ugc nofollow" target="_blank">数据科学碗2017 </a>挑战赛为例。第一名的奖金为50万美元，第二名为20万美元，第三名为10万美元，以此类推。选择的评估标准是对数损失。这是最终的排行榜:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi me"><img src="../Images/b05ad12e94c59459af26a2c15ef22b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*51U-YpMfj-Lano_u2cSKwg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">[截图来自<a class="ae md" href="https://www.kaggle.com/competitions/data-science-bowl-2017/leaderboard" rel="noopener ugc nofollow" target="_blank"> Kaggle </a></p></figure><p id="8e6d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，你认为第一名的模特和第二名的模特有什么不同？</p><p id="2000" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你的回答是:“区别在于第一个模型比第二个模型更好，因为它的对数损失更小”，那么你可能有些操之过急了。事实上，</p><blockquote class="mf"><p id="c14d" class="mg mh it bd mi mj mk ml mm mn mo lt dk translated">我们如何确定测试集上更好的度量意味着更好的模型，而不仅仅是更幸运的模型？</p></blockquote><p id="0dfa" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh mr lj lk ll ms ln lo lp mt lr ls lt im bi translated">我举了一个关于Kaggle的例子，但是同样的推理也适用于任何现实生活中我们需要选择一个模型的情况。</p><p id="0dec" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于数据科学家来说，知道在模型选择中哪个部分是偶然发挥作用的是一项基本技能。在本文中，我们将看到如何量化选择最佳模型过程中的随机性。</p><h1 id="e3f7" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">实际上，“最佳模式”是什么？</h1><p id="0db3" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">首先，我们需要一个关于我们所说的“最佳模式”的明确定义。</p><p id="d979" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们有两个模型，A和B，我们想选择最好的一个。我们都同意最好的模型是在看不见的数据上表现最好的模型。</p><p id="9f60" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们收集了一些测试数据(在训练中没有使用)并在此基础上评估我们的模型。假设模型A的ROC分数为86%，模型B的ROC分数为85%。这是否意味着模型A优于模型B？暂时来说，是的。</p><p id="0770" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">但是想象一下，过了一段时间，您收集了更多的数据，并将其添加到之前的测试集中。现在A型还是86%，B型已经提高到87%。在这一点上，B比a好，怎么可能？</p><p id="1a78" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，唯一明确的定义如下:</p><blockquote class="mf"><p id="2819" class="mg mh it bd mi mj mk ml mm mn mo lt dk translated">对于给定的任务，最佳模型是对所有可能的不可见数据表现最佳的模型。</p></blockquote><p id="678f" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh mr lj lk ll ms ln lo lp mt lr ls lt im bi translated">这个定义的重要部分是“<strong class="la iu">所有可能的</strong>”。事实上，我们总是可以访问有限的数据，所以我们的测试数据集只是所有可能的未知数据的一小部分。这就像说我们永远不会真正知道什么是最好的模型！</p><p id="d30c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了处理这个问题，我们需要一个新的概念。</p><h1 id="fb85" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">介绍宇宙</h1><p id="9c8f" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">从现在开始，我们将把所有可能看不见的数据集称为“宇宙”。在现实世界中，我们永远无法观测到宇宙，只能观测到从宇宙中随机抽取的一个测试数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/a74450239a346389960b5e02162e110d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9r_uJEYG4H7lQGOlcgHA8A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们从来不观察宇宙，我们只观察一个单一的测试数据集，它是一个小的，随机的部分。[图片由作者提供]</p></figure><p id="ee0f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">一个模型真正的表现是它在宇宙上的表现</strong>。在这种情况下，模型的真实ROC得分为80.4%。然而，我们永远无法观察宇宙，因此，我们永远无法观察模型的真实ROC。</p><p id="96c8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们所能观察到的是在测试集上计算的ROC分数。有时候会高一点(81.6%)，有时候会小一点(79.9%和78.5%)，但是我们没有办法知道真实的ROC评分和观测的ROC评分有多远。</p><p id="043f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们所能做的就是尝试评估这个过程中有多少随机性。为了做到这一点，我们需要模拟宇宙，并从中抽取许多随机测试数据集。这样，我们就可以量化观察到的分数的离差。</p><h1 id="44de" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">如何模拟宇宙？</h1><p id="5f26" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">我们的目标是获得一个具有给定ROC分数的观察宇宙。事实证明，有一个非常简单的方法可以做到这一点。</p><p id="992d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先，我们需要设定宇宙中期望的个体数量(通常是一个很大的数字)。然后，我们需要设置流行度，即阳性百分比(我们可以将其保留为50 %，这是默认设置)。第三步是选择我们希望在宇宙中的ROC分数。</p><p id="f98e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们可以计算宇宙中每个个体的预测概率:负数必须均匀分布在0和1之间，而正数必须均匀分布在α和1之间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ns"><img src="../Images/f0e9cec0a8107d32ec5284bbca61c5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TtXC1o5fhFzDo-ZPy-8LaQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">如何获得具有任意ROC分数的数据集？[图片由作者提供]</p></figure><p id="daeb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中，α可通过以下公式从ROC中获得:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/2b590ac54e3494b5b038faa86eb90f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMlCMUYGB42k-QHclfrk0A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">当ROC大于或等于50%时，α和ROC之间的关系。[图片由作者提供]</p></figure><p id="1cc8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ROC为50%时，α为0，表示阴性和阳性的分布是相同的。反之，当ROC为100%时，α为1，意味着所有的阳性都集中在1上:阴性和阳性之间没有重叠。</p><p id="4327" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在Python中，这可以转化为以下函数:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="5bc6" class="nz mv it nv b gy oa ob l oc od">def <strong class="nv iu">get_y_proba</strong>(roc, n=100000, prevalence=.5):<br/>  <strong class="nv iu">'''Get two arrays, y and proba, for a given roc (greater than .5)'''</strong></span><span id="97ee" class="nz mv it nv b gy oe ob l oc od">  n_ones = int(round(n * prevalence))<br/>  n_zeros = n - n_ones</span><span id="70ef" class="nz mv it nv b gy oe ob l oc od">  y = np.array([0] * n_zeros + [1] * n_ones)</span><span id="648d" class="nz mv it nv b gy oe ob l oc od">  alpha = (roc - .5) * 2</span><span id="a542" class="nz mv it nv b gy oe ob l oc od">  proba_zeros = np.linspace(0, 1, n_zeros)<br/>  proba_ones = np.linspace(alpha, 1, n_ones)<br/>  proba = np.concatenate([proba_zeros, proba_ones])</span><span id="6725" class="nz mv it nv b gy oe ob l oc od">  return y, proba</span></pre><h1 id="fd68" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">获取我们的不确定性度量</h1><p id="3251" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">既然我们已经有了创建合成宇宙的方法，让我们用下面的命令来获得我们的宇宙:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="83c4" class="nz mv it nv b gy oa ob l oc od">y_universe, proba_universe = get_y_proba(roc=.8, n=100000, prevalence=.5)</span></pre><p id="23ad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们的宇宙由100，000个观察值组成，其中一半是正面的，ROC得分为80%。</p><p id="0fea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，让我们模拟不同测试集的提取。我们将提取5000个不同的测试集，每个测试集由来自宇宙的1000个观测值组成。这是相应的代码:</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="bb34" class="nz mv it nv b gy oa ob l oc od">rocs_sample = []</span><span id="7ba4" class="nz mv it nv b gy oe ob l oc od">for i in range(5_000):<br/>  index = np.random.choice(range(len(y_universe)), 1_000, replace=True)<br/>  y_sample, proba_sample = y[index], proba[index]<br/>  roc_sample = roc_auc_score(y_sample, proba_sample)<br/>  rocs_sample.append(roc_sample)</span></pre><p id="7df7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是观察到的ROC分数的分布:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/e3d4258cf4fa2d384483f847486a7081.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5HyWUZj-q86q4i_Gm2EcQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在来自ROC分数为80%的宇宙的不同测试集上观察到的ROC分数。[图片由作者提供]</p></figure><p id="89cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如您所看到的，结果非常不同，从不到76%到超过84%不等。</p><p id="74a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在正常应用中，我们想要回答的问题如下。我有两个模型，一个ROC分78%，一个82%。<strong class="la iu">它们拥有相同潜在ROC的可能性有多大，而这种差异只是偶然的结果？</strong></p><p id="f94c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了得到一个概念，我们可以计算模拟中每对观察到的ROC分数之间的距离。Scikit-learn有一个函数<code class="fe og oh oi nv b">pairwise_distances</code>允许这样做。</p><pre class="kj kk kl km gt nu nv nw nx aw ny bi"><span id="b730" class="nz mv it nv b gy oa ob l oc od">import numpy as np<br/>from sklearn.metrics import pairwise_distances<br/><br/>dist = pairwise_distances(np.array(rocs_sample).reshape(-1,1))<br/>dist = dist[np.triu_indices(len(rocs_sample), k=1)]</span></pre><p id="34ea" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们在经验累积分布函数中可视化ROC得分之间的成对距离。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/bcdec8d559a2fb458fc860783a92cf79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rL51jwml9sK4wpYMXR1wmQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ROC评分间成对距离的经验累积分布函数。[图片由作者提供]</p></figure><p id="44b5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">第95百分位(用虚线突出显示)约为4%。这意味着两个模型(具有相同的性能)之间的差异只有5%的时候大于4%。</p><p id="cd44" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，用统计学术语来说，我们会说小于4%的差异不显著！这非常有趣，因为通常我们会认为82%的ROC模型比78%的ROC模型好得多。</p><p id="2ce4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了获得这个概念的另一个可视化，我模拟了三个不同的宇宙，一个ROC得分为75%，另一个为80%，最后一个为81%。这些是他们观察到的ROC分数的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/dc8797b908dd42a8be3cdc44dde9a94f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DP18nYzxMcv0V30syjknww.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在来自不同领域的不同测试集上观察到的ROC分数分别为75%、80%和81%。[图片由作者提供]</p></figure><p id="7398" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">很明显，从这个情节来看，最好的模型往往不会赢！想象一下比较几十个模型，每个模型都有不同的真实ROC分数。</p><blockquote class="mf"><p id="01b4" class="mg mh it bd mi mj mk ml mm mn mo lt dk translated">你实际上不太可能选择最好的模型。很有可能，你会选择最幸运的一个。</p></blockquote><h1 id="5066" class="mu mv it bd mw mx my mz na nb nc nd ne jz ol ka ng kc om kd ni kf on kg nk nl bi translated">我能做些什么吗？</h1><p id="e501" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">所以你是在告诉我，我不可能100%确定一个型号比另一个好？这听起来像一场噩梦。当然:数据科学中没有百分百确定的事情。然而，不要绝望。</p><p id="142c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有理由预计，选择最佳模型的不确定性程度既取决于宇宙的特征，也取决于从宇宙中提取的测试集的特征。特别是，有三个参数决定了不确定性:</p><ul class=""><li id="eb12" class="oo op it la b lb lc le lf lh oq ll or lp os lt ot ou ov ow bi translated">真实ROC:在宇宙上计算的ROC分数。</li><li id="63fa" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本维数:测试集中的观察值数量。</li><li id="2ea4" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本流行率:测试集中阳性的百分比。</li></ul><p id="41e9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了了解这些因素对不确定性的影响，我通过为每个因素尝试不同的值来模拟所发生的情况:</p><ul class=""><li id="2c5b" class="oo op it la b lb lc le lf lh oq ll or lp os lt ot ou ov ow bi translated">真实ROC: 70%，80%，90%。</li><li id="cc51" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本维数:1000、5000和10000个观测值。</li><li id="c110" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本患病率:1%、5%和20%。</li></ul><p id="abcc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们正在为三个参数尝试三个值，这意味着27种可能的组合。</p><p id="350c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于每个组合，我模拟了一个宇宙，然后对1000个不同的测试集进行了采样，并测量了各自的ROC分数。然后，我计算了1000个ROC分数的距离矩阵。最后，我取了距离的第95个百分位数(从现在开始称为“d”)。正如我上面所说的，这是选择模型的不确定性的一种度量。</p><p id="b5d7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，这是27次试验中的前5次。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/a91d71a44cb4770135fee272f2d96d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RZsQ832ZldrWeoPxEDtK-w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">27次试验中的前5次。输入是宇宙中的roc分数(“ROC”)、观察次数(“n”)和测试集的流行度。输出是ROC得分之间距离的第95个百分位数(“d”)。[图片由作者提供]</p></figure><p id="cb97" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们用第95个百分点来衡量不确定性。该数值越高，比较ROC曲线的不确定性越高。</p><p id="da82" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为我们想知道不确定度如何依赖于3个参数，所以测量每个参数和“d”之间的偏相关是很有趣的。这是结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pd"><img src="../Images/a222dab8a82e875b2f68efd4ac3163dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idP2JzaDjfPsYRqdDm-zsA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">每个参数和我们的不确定性测量值之间的部分相关性(观察到的ROC评分之间距离的第95个百分点)。[图片由作者提供]</p></figure><p id="0278" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">称为“r”的列显示了每个参数和不确定性之间的部分相关性。所有相关系数都是负的，表明增加这三个系数中的任何一个都会减少不确定性。特别是，</p><ul class=""><li id="11b0" class="oo op it la b lb lc le lf lh oq ll or lp os lt ot ou ov ow bi translated">真ROC。宇宙中较高的ROC值意味着较少的不确定性。这是有意义的，因为根据定义，ROC越高意味着不确定性程度越小。</li><li id="efbe" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本维度。增加样本维数可以减少不确定性。这是非常明显的，并且在统计中经常发生。</li><li id="311b" class="oo op it la b lb ox le oy lh oz ll pa lp pb lt ot ou ov ow bi translated">样本患病率。流行程度的提高减少了不确定性。患病率越低意味着阳性越少。越少的阳性意味着随机抽样时权重越大。因此，更大的不确定性。</li></ul><p id="9243" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">出于好奇，对于固定的真实ROC(在本例中为80%)，让我们也可视化当改变样本维度和样本流行度时观察到的ROC分数的分布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pe"><img src="../Images/29dc1a4f6501e6000a9604ea986a6e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*332v7k85c4sHLFLs3P_T-Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">样本中ROC评分的分布，针对不同的样本维度和样本患病率。请注意，真实的ROC得分始终为80%。[图片由作者提供]</p></figure><p id="a808" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我觉得这个形象不言自明。以左上图为例。样本规模和患病率都非常小:我们有1000个观察值和1%的阳性，这意味着10个阳性和990个阴性。在这种情况下，不确定性非常高，得到的ROC分数分布几乎是均匀的，从75%到85%。此外，ROC得分之间距离的第95百分位是10%，这意味着观察到的ROC为75%和观察到的ROC为85%之间没有显著差异。</p><p id="342a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然而，随着我们逐步提高样本维度和/或患病率，情况会有所改善，观察到的ROC评分分布越来越集中在真实值附近(在本例中为80%)。例如，通过10，000次观察和20%的患病率，第95百分位变成了更合理的1.2%。</p><h1 id="e2a5" class="mu mv it bd mw mx my mz na nb nc nd ne jz nf ka ng kc nh kd ni kf nj kg nk nl bi translated">这对我有用吗？</h1><p id="e2f7" class="pw-post-body-paragraph ky kz it la b lb nm ju ld le nn jx lg lh no lj lk ll np ln lo lp nq lr ls lt im bi translated">确实是。事实上，即使我们在机会面前都很无助，知道在什么条件下你的结果在统计学上是合理的也是很重要的。</p><p id="2878" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">重复我们在上一段中看到的模拟可以帮助您了解测试集的数量和流行程度是否足以检测模型性能之间的真正差异。</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="c2a4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">你可以在<a class="ae md" href="https://github.com/smazzanti/tds_best_or_luckiest/blob/main/model_selection_best_or_luckiest.ipynb" rel="noopener ugc nofollow" target="_blank">我的Github页面</a>中找到本文使用的所有Python代码。</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="73fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想阅读关于这个主题的彻底讨论，更多的是从假设检验的角度(而不是从模拟的角度)，你可以阅读劳伦·奥克登·雷纳的这篇博客:“<a class="ae md" href="https://laurenoakdenrayner.com/2019/09/19/ai-competitions-dont-produce-useful-models/" rel="noopener ugc nofollow" target="_blank">人工智能竞赛不会产生有用的模型</a>”</p></div><div class="ab cl pf pg hx ph" role="separator"><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk pl"/><span class="pi bw bk pj pk"/></div><div class="im in io ip iq"><p id="8837" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="pm">感谢您的阅读！我希望你喜欢这篇文章。如果你愿意，</em> <a class="ae md" href="https://www.linkedin.com/in/samuelemazzanti/" rel="noopener ugc nofollow" target="_blank"> <em class="pm">在Linkedin上加我</em> </a> <em class="pm">！</em></p></div></div>    
</body>
</html>