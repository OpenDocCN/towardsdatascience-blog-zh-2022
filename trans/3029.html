<html>
<head>
<title>Does your model beat the baseline?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你的模型超过基线了吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/does-your-model-beat-the-baseline-3b9fb31cbe76#2022-07-03">https://towardsdatascience.com/does-your-model-beat-the-baseline-3b9fb31cbe76#2022-07-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="da42" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">让我们将我们的模型与一个普通的基线进行比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7fae093a1a81cfc39d73e8fa4f527f2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gYFVJQRfw_VHduqN.jpg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">图片by Pixabay:</em><a class="ae kz" href="https://www.pexels.com/it-it/foto/lampadina-chiara-355948/" rel="noopener ugc nofollow" target="_blank">T3【https://www.pexels.com/it-it/foto/lampadina-chiara-355948/】T5】</a></p></figure><p id="a0a6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">每次我们训练一个模型时，我们都应该检查它的性能是否超过了某个基线，这是一个没有考虑输入的琐碎模型。将我们的模型与基线模型进行比较，我们实际上可以计算出它实际上是否学习了。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><h1 id="fd01" class="md me it bd mf mg mh mi mj mk ml mm mn jz mo ka mp kc mq kd mr kf ms kg mt mu bi translated">什么是基线模型？</h1><p id="1d99" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">基线模型是一种实际上不使用特征的模型，但对所有预测使用一个平凡的常量值。对于一个回归问题，这样的值通常是训练数据集中目标变量的平均值(10年前，我曾经进行ANOVA测试来比较线性模型和这样一个微不足道的模型，这种模型被称为零模型)。对于分类任务，普通模型只返回训练数据集中最频繁的类。</p><p id="69f1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">因此，这是我们数据集的基线，一个经过适当训练的模型应该能够超越这种算法的性能。事实上，如果一个模型像基线一样执行，它实际上没有考虑特性，所以它不是学习。请记住，基线模型的给定定义根本不使用特性，它们只是以某种方式对目标值进行平均。</p><p id="74da" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在这篇文章中，我们将会看到如何比较一个模型和一个基线模型。</p><h1 id="a22a" class="md me it bd mf mg na mi mj mk nb mm mn jz nc ka mp kc nd kd mr kf ne kg mt mu bi translated">战略</h1><p id="e40f" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">总的想法是用模型和基线模型在测试数据集上计算一些性能指标。然后，使用<a class="ae kz" href="https://www.yourdatateacher.com/2021/04/19/the-bootstrap-the-swiss-army-knife-of-any-data-scientist/" rel="noopener ugc nofollow" target="_blank"> bootstrap </a>，我们计算这种测量的<a class="ae kz" href="https://www.yourdatateacher.com/2021/11/08/how-to-calculate-confidence-intervals-in-python/" rel="noopener ugc nofollow" target="_blank"> 95%置信区间</a>。如果间隔不重叠，则模型不同于基线模型。</p><p id="bd24" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">按照我们选择的性能指标，我们允许模型实际上具有可比性的概率高达5%。不幸的是，只看指标的平均值是不够的。小数据集可能会引入有限大小的效应，使我们的分析变得不可靠。这就是为什么我更喜欢使用bootstrap来计算置信区间，这让我们更好地了解情况，从我们的数据集中提取尽可能多的信息。</p><h1 id="1615" class="md me it bd mf mg na mi mj mk nb mm mn jz nc ka mp kc nd kd mr kf ne kg mt mu bi translated">Python中的一个例子</h1><p id="5f8b" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">在Python中，基线模型由DummyClassifier和DummyRegressor对象表示。前者考虑训练数据集中最频繁的目标类，后者考虑目标变量的平均值。这些设置是可以改变的(例如，通过考虑中间值来代替平均值)，但我通常更喜欢使用默认设置，因为它们非常真实和有用。</p><p id="d07c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">对于回归问题，我们将使用“糖尿病”数据集和随机森林分类器。我们的绩效指标将是r平方分数。</p><p id="6411" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">让我们先导入一些库:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="3b4d" class="nk me it ng b gy nl nm l nn no">import numpy as np<br/>from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.datasets import load_wine, load_diabetes<br/>from sklearn.dummy import DummyClassifier,DummyRegressor<br/>from sklearn.metrics import accuracy_score, r2_score</span></pre><p id="ca80" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后，让我们导入数据集:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="f4d5" class="nk me it ng b gy nl nm l nn no">X,y = load_diabetes(return_X_y = True)</span><span id="b611" class="nk me it ng b gy np nm l nn no">X_train,X_test,y_train,y_test  = train_test_split(X,y,test_size=0.4,random_state=0)</span></pre><p id="2b3c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们现在可以训练随机森林和虚拟回归器。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="366f" class="nk me it ng b gy nl nm l nn no">model = RandomForestRegressor(random_state=0) model.fit(X_train,y_train) </span><span id="3a68" class="nk me it ng b gy np nm l nn no">dummy = DummyRegressor() <br/>dummy.fit(X_train,y_train)</span></pre><p id="16f0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，通过500次迭代的bootstrap，我们可以根据相同的测试数据集计算模型的r平方的置信区间。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="b8a8" class="nk me it ng b gy nl nm l nn no">scores_model = []<br/>scores_dummy = []<br/>for n in range(500):<br/>  random_indices = np.random.choice(range(len(X_test)),size=len(X_test),replace=True)<br/>  X_test_new = X_test[random_indices]<br/>  y_test_new = y_test[random_indices]</span><span id="e445" class="nk me it ng b gy np nm l nn no"> scores_model.append(r2_score(y_test_new,model.predict(X_test_new)))<br/> scores_dummy.append(r2_score(y_test_new,dummy.predict(X_test_new)))</span></pre><p id="c1da" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，这些是模型和虚拟分类器的置信区间:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="233e" class="nk me it ng b gy nl nm l nn no">np.quantile(scores_model,[0.025,0.975]),np.quantile(scores_dummy,[0.025,0.975]) </span><span id="61d4" class="nk me it ng b gy np nm l nn no"># (array([0.20883809, 0.48690673]), array([-3.03842778e-02, -7.59378357e-06]))</span></pre><p id="90b3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">正如我们所看到的，区间是不相交的，并且与模型相关的区间的下限大于与虚拟模型相关的区间的上限。因此，我们可以说我们的模型在95%的置信度下比基线表现得更好。</p><p id="b01e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用分类器可以遵循相同的方法。在本例中，数据集将是“葡萄酒”数据集。评分标准将是准确性得分。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="3b7d" class="nk me it ng b gy nl nm l nn no">X,y = load_wine(return_X_y = True) </span><span id="3ff5" class="nk me it ng b gy np nm l nn no">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=0)</span></pre><p id="1c5d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">以下是模型:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="2fa0" class="nk me it ng b gy nl nm l nn no">model = RandomForestClassifier(random_state=0) <br/>dummy = DummyClassifier() <br/>model.fit(X_train,y_train) <br/>dummy.fit(X_train,y_train)</span></pre><p id="e56a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这是两个模型的准确性得分的自举:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="d2b5" class="nk me it ng b gy nl nm l nn no">scores_model = []<br/>scores_dummy = []<br/>for n in range(500):<br/>  random_indices = np.random.choice(range(len(X_test)),size=len(X_test),replace=True)<br/>  X_test_new = X_test[random_indices]<br/>  y_test_new = y_test[random_indices]</span><span id="e62e" class="nk me it ng b gy np nm l nn no">  scores_model.append(accuracy_score(y_test_new, model.predict(X_test_new)))<br/>  scores_dummy.append(accuracy_score(y_test_new, dummy.predict(X_test_new)))</span></pre><p id="b77a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">最后，这些是置信区间:</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="8f7e" class="nk me it ng b gy nl nm l nn no">np.quantile(scores_model,[0.025,0.975]),np.quantile(scores_dummy,[0.025,0.975]) </span><span id="ba72" class="nk me it ng b gy np nm l nn no"># (array([0.91666667, 1. ]), array([0.31215278, 0.54166667]))</span></pre><p id="fc62" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">同样，该模型以95%的置信度比虚拟模型表现得更好。</p><h1 id="33df" class="md me it bd mf mg na mi mj mk nb mm mn jz nc ka mp kc nd kd mr kf ne kg mt mu bi translated">结论</h1><p id="517a" class="pw-post-body-paragraph la lb it lc b ld mv ju lf lg mw jx li lj mx ll lm ln my lp lq lr mz lt lu lv im bi translated">在本文中，我展示了一种技术来评估一个简单的基线模型的性能。尽管这经常被忽视，但这种比较很容易进行，而且必须经常进行，以便评估我们的模型的稳健性及其泛化能力。</p></div><div class="ab cl lw lx hx ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="im in io ip iq"><p id="9756" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><em class="nq">原载于2022年7月3日</em><a class="ae kz" href="https://www.yourdatateacher.com/2022/07/04/does-your-model-beat-the-baseline/" rel="noopener ugc nofollow" target="_blank"><em class="nq">【https://www.yourdatateacher.com】</em></a><em class="nq">。</em></p></div></div>    
</body>
</html>