<html>
<head>
<title>PeopleSansPeople: Generating Synthetic Data of Virtual Human Beings in Unity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PeopleSansPeople:在 Unity 中生成虚拟人的合成数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/peoplesanspeople-generating-synthetic-data-of-virtual-human-beings-in-unity-a1847a56895c#2022-03-09">https://towardsdatascience.com/peoplesanspeople-generating-synthetic-data-of-virtual-human-beings-in-unity-a1847a56895c#2022-03-09</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ed9d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">为计算机视觉创建人类的 3D 模型从未如此简单</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/fd5e9d36ad341de3770a83d8795fb156.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfLeMWaCFyGElCfYs1bOGw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 PeopleSansPeople 项目创建的超现实合成场景(由作者创建)。</p></figure><h1 id="2d29" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">介绍</h1><p id="3e4f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">获取大量高质量的标注训练数据是很难的。收集高质量的数据、收集足够的数据、招募并培训标注团队、确保标注干净一致、确保其充分代表模型在现实世界中可能遇到的各种情况，等等。需要大量的时间和努力。当这些数据涉及到人类时，事情变得更加棘手。现在，你有责任确保你的数据不侵犯隐私，不包含个人身份信息，你可以与你的标签共享数据，并在年龄，性别，种族，文化等方面保持平衡。你用这些数据训练的任何模型也要尊重这些道德界限。</p><p id="ee2e" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">难怪人们对使用模拟来生成大量合成训练数据的兴趣正在稳步增长。但是计算机渲染的数据能像真实世界一样有效吗？</p><p id="66d5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">通过在虚幻引擎中创建高质量的模拟，<a class="ae mr" href="https://aireverie.com/rareplanes" rel="noopener ugc nofollow" target="_blank"> AI 的研究人员。Reverie </a>展示了他们可以将所需的真实世界训练数据量减少 90%,同时实现几乎相同的性能。也就是说，在真实世界的数据集中，你需要的每十张图片中就有一张[ <a class="ae mr" href="https://arxiv.org/abs/2006.02963" rel="noopener ugc nofollow" target="_blank"> 1 </a> ]。谷歌的研究人员证明，通过在一个具有 ImageNet 权重[<a class="ae mr" href="https://arxiv.org/abs/1710.10710" rel="noopener ugc nofollow" target="_blank">2</a>的模型上使用合成数据进行微调，可以在没有任何标记的训练数据的情况下近似得到相同的结果<em class="ms">。合成数据的使用甚至已经破坏了行业，包括<a class="ae mr" href="https://venturebeat.com/2019/06/05/amazon-go-uses-synthetic-data-to-train-cashierless-store-algorithms/" rel="noopener ugc nofollow" target="_blank">亚马逊 Go </a>商店、<a class="ae mr" href="https://medium.com/toyotaresearch/teaching-home-robots-73f7d5e3601f" rel="noopener">丰田</a>和<a class="ae mr" href="https://openai.com/blog/solving-rubiks-cube/" rel="noopener ugc nofollow" target="_blank"> OpenAI </a>等等。合成数据也被用来补充真实世界的训练数据，以训练谷歌 MediaPipe 框架的一部分<a class="ae mr" href="https://ai.googleblog.com/2020/03/real-time-3d-object-detection-on-mobile.html" rel="noopener ugc nofollow" target="_blank"> Objectron </a>中的 3D 边界框检测模型，从而将其准确性提高了 10%。</em></p><h2 id="14e9" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">为什么是合成数据？</h2><p id="0bb9" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">越来越明显的是，投资合成数据可以大大加快你的 ML 研究。以下是学习创建自己的合成数据对您有所帮助的几个原因:</p><ul class=""><li id="be5c" class="nf ng it ls b lt mm lw mn lz nh md ni mh nj ml nk nl nm nn bi translated">以微不足道的成本生成无限量的训练数据</li><li id="8a3e" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">假设-测试新想法，无需花费时间/金钱来获取和标记数据</li><li id="f46d" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">标签是由一个确定性的过程生成的，该过程确保标签是正确的(即使是广泛使用的 ML 基准数据集<a class="ae mr" href="https://labelerrors.com/about" rel="noopener ugc nofollow" target="_blank">也充满了错误</a></li><li id="bc5d" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">轻松对传感器、环境和姿势等因素进行消融研究(如 Hinterstoisser 等人[ <a class="ae mr" href="https://arxiv.org/abs/1710.10710" rel="noopener ugc nofollow" target="_blank"> 2 </a> ])</li><li id="d110" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">模拟罕见但重大的“黑天鹅”事件(如车祸)</li><li id="8950" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">实现可比的性能，同时大幅减少所需的真实训练数据</li><li id="a4a6" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">通过分布模拟[ <a class="ae mr" href="https://arxiv.org/abs/1812.07252" rel="noopener ugc nofollow" target="_blank"> 3 </a> ]快速加快强化学习的速度</li></ul><p id="f750" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">然而，虽然标记真实世界的数据花费大量的时间和金钱，但是为单个 ML 任务创建模拟也不是一件小事。它需要具备专业技能的工程师和 3D 艺术家的投入，他们了解要解决的问题的复杂性。众所周知，创造虚拟人更加困难(至少是那些避开恐怖谷的人)。有许多公司提供合成数据生成服务，如<a class="ae mr" href="https://aireverie.com/" rel="noopener ugc nofollow" target="_blank"> AI。遐想</a>、<a class="ae mr" href="https://www.datagen.tech/" rel="noopener ugc nofollow" target="_blank">数据生成</a>和<a class="ae mr" href="https://kinetic-vision.com/machine-learning-synthetic-data-generation/" rel="noopener ugc nofollow" target="_blank">动态视觉</a>。我们自己生成合成数据而不必马上参与合作关系，这不是很好吗？</p><h2 id="df43" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">Unity 技术公司</h2><p id="4115" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">Unity 是世界上最受欢迎的跨平台游戏引擎之一的制造商，最近发布了一个名为<a class="ae mr" href="https://github.com/Unity-Technologies/com.unity.perception" rel="noopener ugc nofollow" target="_blank"> Unity Perception </a>的开源工具包，将合成标签放在你自己的手中。Unity Perception toolkit 抽象了标签生成过程，甚至允许 Unity 业余爱好者配置 Unity 场景，该场景可以使用 2D 边界框、3D 边界框、语义分割遮罩、实例分割遮罩、对象计数等生成无数图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">统一计算机视觉:增压你的计算机视觉训练(YouTube)。为了更深入地展示统一感知的可能性，请查看来自<a class="ae mr" href="https://standard.ai/" rel="noopener ugc nofollow" target="_blank">标准认知</a>的<a class="ae mr" href="https://youtu.be/D1In3thbuH4" rel="noopener ugc nofollow" target="_blank">案例研究</a>。</p></figure><p id="9116" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">此外，他们在此基础上再次扩展，创建了<a class="ae mr" href="https://github.com/Unity-Technologies/PeopleSansPeople" rel="noopener ugc nofollow" target="_blank">people sans people</a>[<a class="ae mr" href="https://arxiv.org/pdf/2112.09290.pdf" rel="noopener ugc nofollow" target="_blank">4</a>](PSP)，这是一套建立在感知基础上的额外工具，可以生成 2D 和 3D 边界框，实例和语义分割遮罩，以及用于操纵人类 3D 模型的 COCO 姿势标签。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nt nu l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用 Unity Perception 和 PeopleSansPeople 生成的合成数据的催眠蒙太奇。</p></figure><h2 id="0046" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">SynthDet:合成数据的早期尝试</h2><p id="de8d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">如果你看了上面的视频，你可能会问自己:为什么这些合成图像看起来如此…迷幻？合成训练数据不应该看起来更像真实生活吗？答案在 2019 年的一篇论文中，名为“保存的注释是获得的注释:使用完全合成训练进行对象实例检测”<a class="ae mr" href="https://arxiv.org/pdf/1902.09967.pdf" rel="noopener ugc nofollow" target="_blank"> 5 </a>。简而言之，作者发现，与其试图逼近目标域(由于神经网络强大的记忆技能，不可避免地会出现不足)，不如积极地随机化训练数据更有效。此后不久，Unity 发布了一个名为<a class="ae mr" href="https://github.com/Unity-Technologies/SynthDet" rel="noopener ugc nofollow" target="_blank"> SynthDet </a>的开源项目，该项目使用感知包实现了论文中描述的方法。要深入解释为什么这种通常被称为<em class="ms">域随机化</em>的策略如此有效，请看一下<a class="ae mr" href="https://lilianweng.github.io/posts/2019-05-05-domain-randomization/" rel="noopener ugc nofollow" target="_blank">Lilian Weng</a>的这篇精彩文章。</p><p id="d722" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在本教程中，我们将进一步探索这一技术，利用 Unity Perception、PeopleSansPeople 和第三个名为<a class="ae mr" href="http://www.makehumancommunity.org/" rel="noopener ugc nofollow" target="_blank"> MakeHuman </a>的工具来为机器学习生成合成人类的标记训练数据。本教程面向 ML 从业者，假设没有 3D 艺术或游戏开发经验。请注意，我们将在本教程中假设一个基于 Windows 的系统，但是所有的工具都应该与 Linux 兼容。本教程也不需要任何编码经验，因为不会有任何代码！让我们开始吧。</p><h1 id="7a3d" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">制造人类</h1><p id="c0b7" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">从<a class="ae mr" href="https://www.mixamo.com/" rel="noopener ugc nofollow" target="_blank"> Mixamo </a>到<a class="ae mr" href="https://www.turbosquid.com/" rel="noopener ugc nofollow" target="_blank"> Turbosquid </a>，<a class="ae mr" href="http://sketchfab.com/feed" rel="noopener ugc nofollow" target="_blank"> Sketchfab </a>到<a class="ae mr" href="https://www.cgtrader.com/3d-models/character" rel="noopener ugc nofollow" target="_blank"> CGTrader </a>，现在有很多很多的方法来获取 3D 模型。你可以使用一个低级但功能强大的工具，如 Maya 或 Blender，自己制作它们。甚至还有一些专门用于制造人类的专有工具，如 Reallusion 的<a class="ae mr" href="https://www.reallusion.com/character-creator/" rel="noopener ugc nofollow" target="_blank">角色创造者</a>或 Epic Games 的<a class="ae mr" href="https://www.unrealengine.com/en-US/metahuman-creator" rel="noopener ugc nofollow" target="_blank">超能力者创造者</a>。然而，当你想尝试看看什么是有效的，为什么不保持快速和负担得起的东西呢？</p><p id="da88" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">进入<a class="ae mr" href="http://www.makehumancommunity.org/" rel="noopener ugc nofollow" target="_blank"> MakeHuman </a>，一款免费开源的工具，用于快速创建人类的参数化 3D 模型。这个工具可以追溯到 2000 年，它允许你制作并导出一个<a class="ae mr" href="https://en.wikipedia.org/wiki/Skeletal_animation" rel="noopener ugc nofollow" target="_blank">全套装备的</a>人体模型，带有高级滑块，就像你在视频游戏中创造一个角色一样。还有一个活跃的社区，以防你需要任何具体的帮助。他们的代码是在 GNU AGPL 许可证下提供的，其产生的所有资产都受到 CC0 许可证的保护(更多细节，请参见此处的<a class="ae mr" href="https://github.com/makehumancommunity/makehuman/blob/master/LICENSE.md" rel="noopener ugc nofollow" target="_blank"/>)。</p><h2 id="af73" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">设置 MakeHuman</h2><p id="0319" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">使用 MakeHuman 非常简单。首先通过从<a class="ae mr" href="http://www.makehumancommunity.org/content/makehuman_120.html" rel="noopener ugc nofollow" target="_blank">下载页面</a>下载稳定版进行安装。在 Windows 上，只需解压下载文件并执行附带的<em class="ms">。exe </em>文件。在 Linux 上，有<a class="ae mr" href="https://launchpad.net/~makehuman-official/+archive/ubuntu/makehuman-community" rel="noopener ugc nofollow" target="_blank"> PPA 安装指令</a>。现在启动程序。你应该会看到一个相当橙色的默认人类和一些滑块在左边，如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nv"><img src="../Images/8ab310e32426f8165e2f5f4d0d5b59d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88DvpxJmt9CxkiI2TpwS1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">启动 MakeHuman 时首先看到的是。我继续添加衣服到我的，以保持东西 SFW，但我会得到这一点(由作者创建)。</p></figure><p id="71a5" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">UI 由左右两侧的设置栏和顶部的三个工具栏组成。第一行工具包括常见的新建/保存/打开按钮、撤消/重做，以及一些视图选项，如切换网格或查看网格。第二行是 MakeHuman 中大多数工具的存放位置。创建新模型时，通常会沿着这些选项卡从左向右移动。第三行根据第二行的上下文进行更改。接下来，我们将创建一个非常快速的人类模型进行演示。</p><h2 id="8a45" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">创造一个人类</h2><p id="fd5b" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在“建模”选项卡中，您可以编辑主要属性，如身高和年龄，或者更深入地研究面部、躯干、手臂和腿等。请注意当您选择这些选项卡时，右列中的选项是如何变化的。这些给了你对模型非常精细的控制。还有一个随机选项卡，可以随机修改所有这些属性。正如你所料，结果并不总是很好，但是为了时间和乐趣，我们就这样吧。按“随机化”几次，直到你对结果满意。</p><p id="3ade" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在，直接跳到“几何图形”选项卡。在这里，您可以编辑基础服装，并为各种头发、眼睛、牙齿和更多选项选择基础几何体。股票期权是有限的，但是你可以下载更多的期权或者用各种<a class="ae mr" href="http://www.makehumancommunity.org/content/plugins.html" rel="noopener ugc nofollow" target="_blank">插件</a>比如 Blender MakeClothes 2 插件自己制作。把这些也浏览一遍，挑出你喜欢的。只要确保选择至少一件衣服，因为我将展示我们如何在 Unity 中随机化纹理。</p><p id="78d6" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">接下来，“材料”这些选项会替换皮肤、头发、眼睛等的纹理。再一次，选择你喜欢的，继续前进。在“姿势/动画”选项卡上，我们只想改变一件事。选择“骨骼”选项卡，并将装备预设更改为“游戏引擎”这个装备将使我们能够统一的动画角色。这样我们就可以完成对我们的基本角色的编辑了。10 分钟 0 美元还不算太寒酸！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/8eea0db4a3fc5c7db7d0d454092d5461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KZTx0tT8phaEVQOSNByJxw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">一个来自 MakeHuman 的完全建模、装配和纹理化的模型，名为“Mark”(由作者创建)。</p></figure><h2 id="9903" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">输出你的人类</h2><p id="9eab" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在让我们导出。在“Files”选项卡下，选择“Save”选项卡来保存我们的模型，以防我们以后需要进行更改。给你的人类一个“人类名”和一个文件名。两个字段我都选了“马克”，当然也选自己喜欢的。如果你想做更多，你可能希望使用一个命名约定。现在选择“导出”选项卡。在“网格格式”下，选择“Filmbox (fbx)”，这是 Autodesk 制作的一种常见文件格式。在右栏中，确保选中“地面英尺”并将“比例单位”设置为“米”，因为 Unity 使用默认的米单位。我们还设置了“脚踏实地”，这样 Unity 中的位置坐标将与他们的脚的位置相对应，使得在场景中放置和移动我们的人变得更加容易。现在输出你的<em class="ms">。fbx </em>文件，我们完成了这一步。</p><h1 id="d552" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">人民</h1><p id="cd4b" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">如前所述，PeopleSansPeople 是由 Unity Technologies 创建的一个开源工具，用于创建域随机化的合成人的注释数据。我们可以从 GitHub 下载这个工具。进入<a class="ae mr" href="https://github.com/Unity-Technologies/PeopleSansPeople" rel="noopener ugc nofollow" target="_blank"> GitHub 项目页面</a>和<code class="fe nx ny nz oa b">git clone</code>或将该项目下载到您电脑上合适的位置。回想下一步这个项目在哪里。</p><p id="6b32" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">接下来我们需要安装 Unity，特别是 Unity Hub。如果您已经安装了 Unity Hub，请跳过此部分。</p><h2 id="d7b5" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">安装 Unity 集线器</h2><p id="28f3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">Unity Hub 是一个版本和项目管理程序，可组织您电脑上的所有 Unity 项目和版本。强烈建议第一次使用 Unity 的用户使用。从<a class="ae mr" href="https://unity3d.com/get-unity/download" rel="noopener ugc nofollow" target="_blank"> Unity 下载</a>页面下载 Unity Hub 并启动。您应该看到左边有四个选项卡，包括“项目”，右边有两个按钮，分别是“添加”或“新建”PSP 项目预先配置了 Unity 场景，所以点击“添加”打开之前下载的文件夹，选择子文件夹<code class="fe nx ny nz oa b">peoplesanspeople_unity_env</code>，点击“选择文件夹”这可能需要一个你还没有的 Unity 版本(在撰写本文时是<em class="ms"> 2020.3.20f1 </em>)。Unity Hub 会给你一个安装它的选项。使用默认选项安装，然后打开项目。</p><h2 id="8179" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">PeopleSansPeople 项目</h2><p id="4152" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">第一次加载这个项目可能需要几分钟，但是一旦完成，你应该会看到 Unity 编辑器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/be09f7e9276bec4ff0e0d9dd1dcbbf51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H0-u4AdMJATHidOzwqGYyA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">默认的 Unity 编辑器(由作者创建)。</p></figure><p id="1f8b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">Unity 是一个复杂而强大的程序，可能有点令人望而生畏，但我会尽量保持它的最小化，只是为了让你开始。有很多关于正确使用的很棒的资源，包括<a class="ae mr" href="https://learn.unity.com/" rel="noopener ugc nofollow" target="_blank"> Unity 自己的教程</a>，如果你更倾向于使用它的话。现在，要知道 Unity 项目被分组在所谓的“场景”中这些基本上是定义对象的布局和行为(2D 或 3D)的设置。想象一下电子游戏中不同的“关卡”。场景可以像视频一样播放，这就是顶部的大播放和暂停按钮的作用。默认情况下，你应该看到一个空的场景。让我们打开这个项目的“人类场景”。在底部的文件管理器中，双击名为“场景”的文件夹，然后双击名为“人类场景”的文件</p><p id="16a3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这就是奇迹发生的地方。点击播放按钮来明白我的意思(<strong class="ls iu">光敏警告:场景会以许多不同的颜色快速闪烁</strong>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/dcc96eb3521830511f3e114c7564641f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*2M08DjyBrjSo4Oo72zaAFA.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">播放默认的 PSP 场景(由作者创建)。</p></figure><p id="0abb" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这个超现实的场景将重复播放 100 次，生成 RGB 图像、边界框标签、姿势标签和分段蒙版。要找出在哪里，点击左边层次中的“主摄像机”对象。屏幕右侧的 Inspector 选项卡应该会显示您选择的对象的属性。(在 Unity 中,“检查器”面板中的每一行都称为一个“组件”,本质上是附加到对象的类，用于定义其在场景中的行为。)向下滚动到“感知摄像机”组件。这来自感知包，它定义了如何从场景中捕捉帧，应用哪些注释，以及将它们保存在计算机上的什么位置。如果你打算使用感知，这里有许多重要的领域(特别是“相机贴标机”部分，在那里你定义你希望产生的标签和类别的类型)，但现在我们将掩饰细节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/0cb406f5e21f91c891cacfa1701ee2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bt1c-TG0nOH7LzHHB_PdGw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">感知相机组件，您可以在其中配置感知场景的渲染设置。它位于“主相机”对象上(由作者创建)。</p></figure><p id="6910" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">寻找“最后生成的数据集”字段，然后单击“显示文件夹”或“复制路径”以查看文件资源管理器中的数据。请随意浏览这些文件夹，感受一下这个工具可以产生什么样的数据。</p><h2 id="0dc6" class="mt kz it bd la mu mv dn le mw mx dp li lz my mz lk md na nb lm mh nc nd lo ne bi translated">添加您的人员</h2><p id="4b1a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">当前场景的一个明显问题是你的人不在里面！要添加您创建的 3D 模型，我们需要对其进行一些更改，以使其与 PSP 兼容。首先，让我们输入你的个人信息。再次查看底部的文件浏览器。(如果它显示的是“控制台”，请单击它旁边的标签“项目”如果不知何故“项目”不在那里，点击应用程序工具栏上的“窗口”&gt;“常规”&gt;“项目”。打开文件夹“资产/人/网格”并拖动“.fbx”文件(以及它旁边的“纹理”文件夹)。Unity 会自动导入。</p><p id="bc9c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">单击 Unity 文件浏览器中的人体模型，并在文件浏览器中查找“装备”选项卡。将“动画类型”更改为“人形”，然后单击“应用”(如果你得到一个关于“没有足够的骨骼”的错误，你可能忘了在 MakeHuman 中分配“游戏引擎”装备。)这将转换模型的装备，以兼容 Unity 的<a class="ae mr" href="https://docs.unity3d.com/Manual/AvatarCreationandSetup.html" rel="noopener ugc nofollow" target="_blank">化身系统</a>。简单地说，这允许为一个人形模型设计的动画与另一个无缝地工作，只要它们每个都共享这个化身系统。如果您想验证它是否正常工作，请单击“配置”。在检查器的“肌肉&amp;设置”面板中，你可以调整滑块来测试模型是否可以正常动画。要返回你的场景，点击最左边“层级”中“头像配置”左边的“&lt;”箭头。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/b6785f99a2e6576858847664935c06b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*6NyzKaDBG0bZ5XvLpVRzJw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">“肌肉&amp;设置”面板允许你预览连接到你的模型(由作者创建)的化身。</p></figure><p id="05a0" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在钻机完成了！让我们看看我们的人。将你的人从底部的文件浏览器拖到左边的“层次”中，添加到场景中。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/cab8ead6a5184c01e97d749e57e87f73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I2BwSlfsoZPaEE5MJPCpow.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">首次导入时的人员模型。注意粘土般的纹理和不透明的眼睛和眉毛(由作者创作)。</p></figure><p id="3f2b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">嗯，这看起来不太对。我的人有一个不自然的光泽，眼睛和头发缺乏透明度。我们需要编辑这些材料。材质嵌入在模型中，因此我们必须先提取它们才能编辑它们。在文件检查器(不在层级中)中点击你的人<em class="ms">来选择。又是 fbx 文件。这次在检查器中选择“材料”标签。单击“提取材料…”按钮，选择一个文件夹来保存材料。现在，在按钮下方，您应该看到“重新映射的材质”字段现在有了您可以选择和编辑的材质。</em></p><p id="3116" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">其中一个问题是“金属”滑块完全在我们的材料上。我们实际上希望它们都设置为 0。您可以逐个选择它们，也可以一次选择所有材质以同时编辑它们。我还把“平滑度”值设为 0.1，我觉得看起来更自然一点。我们还注意到，这里的“表面类型”设置为“不透明”,即使是头发和眉毛等使用透明度的材质。对于眉毛、睫毛、眼睛和头发材质，您需要将其更改为“透明”。根据您在 MakeHuman 中的选择，这些材质的名称可能有所不同。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oe"><img src="../Images/5deee83fcc3799308bf9f98a5c13d684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CL0kOzhOgD9hguU4EN8OzQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有调整材料的人物模型(由作者创建)。</p></figure><p id="428b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">这些材料选择现在应该可以了。现在，我们需要将一些组件附加到模型上，使其具有我们在领域随机化场景中想要的行为。感知带有几个随机发生器组件，在模拟场景的每次迭代中随机调整位置、旋转、姿势、纹理等内容。我们希望现在添加以下组件:</p><ul class=""><li id="d76d" class="nf ng it ls b lt mm lw mn lz nh md ni mh nj ml nk nl nm nn bi translated">自定义前景旋转随机发生器标签</li><li id="ebc9" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">customforegroundscalenchanozertag</li><li id="511d" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">标记</li><li id="4b83" class="nf ng it ls b lt no lw np lz nq md nr mh ns ml nk nl nm nn bi translated">动画随机发生器标签</li></ul><p id="7a03" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">在“层次结构”中点击你的人的实例，在检查器中选择“添加组件”按钮来添加每个需要的组件。前两个分别随机调整模型的旋转和缩放。第三个为您的模型提供了一个标签方案。这就是如何为模型的标签配置特定的类。最后一个从几个动画中随机选择一个应用于模型。</p><p id="e4de" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">打开“标签”组件，查看“从现有标签配置”字段。下面的行是已经包含在场景中的标签配置文件。“IdLabelConfig”有一个名为“person”的名称，在这里应该没问题。单击“添加新标签”，将标签名称更改为“个人”这样，你的模型的标签将有“人”的类别附加。</p><p id="8c93" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">还有一件事。打开“动画随机发生器标签”并选择“添加文件夹”选择“Assets/Animations_all”文件夹，将默认动画添加到您的个人中。现在我们差不多可以开始了。</p><p id="33cb" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们现在需要为我们的人创建一个“预制品”。一个预置本质上是一个可重用的统一对象，我们可以创建它的实例(如果需要可以修改)。本质上，预置是 Unity 中的预置实例，就像类是面向对象编程中的对象一样。将 person 实例拖到“资产/人/预置”文件夹中。在这种情况下，选择“预设变体”，因为原始的，未修改的模型在技术上已经是一个预设。现在，您可以从“层次结构”中禁用或删除您的人员实例。</p><p id="70e4" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">我们现在处于最后冲刺阶段！我们只需要让我们的模拟意识到我们的新人预设，然后我们就可以开始生成数据。单击层次结构中的“模拟场景”并查看“固定长度场景”组件。这决定了模拟的设置，例如要运行多少场景迭代，每次迭代有多少帧，以及要使用的随机化器。很快的，简单介绍一下背景。我刚才提到的 SynthDet 项目由对象场景组成，这些对象被分为“背景”对象(也称为干扰对象)和“前景”对象，这是我们希望注释的对象。显然，我们的人应该是一个“前景”对象。</p><p id="6328" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">打开“CustomForegroundObjectPlacementRandomizer”组件。在“预设”下，点击“添加选项”向列表中添加一个空行。如果您愿意，也可以单击“清除选项”来删除其他选项。将您的联系人拖到这个新位置。现在，您应该准备好开始模拟了。再次点按“播放”按钮，验证您的人是否像您预期的那样四处走动。验证标签是否也显示出来。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/19329d43f1f47fc60041f9e2e0cd9be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*BXe6ppkx_JZbPhiUySTw5A.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">带有自定义人物模型的已完成场景(由作者创建)。</p></figure><h1 id="8ff2" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">结论</h1><p id="e12b" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这就结束了！这至少可以让你开始任何你想从事的合成人数据项目。Unity Perception 和 PeopleSansPeople 软件包是大规模生成合成数据的强大而灵活的方法。随意试验不同的动画，不同类型的服装，以及不同的 3D 模型来源。如果你最终广泛使用 MakeHuman，我鼓励你<a class="ae mr" href="https://www.patreon.com/makehuman" rel="noopener ugc nofollow" target="_blank">支持他们在 Patreon </a>上的项目。</p><h1 id="9ed5" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">参考</h1><p id="a57f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1] Jacob Shermeyer，Thomas Hossler，Adam Van Etten，Daniel Hogan，瑞恩·刘易斯，Daeil Kim — <a class="ae mr" href="https://arxiv.org/abs/2006.02963" rel="noopener ugc nofollow" target="_blank">稀有飞机:合成数据飞行</a> (2020)，WACV 2021</p><p id="f69c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[2] Stefan Hinterstoisser，Vincent Lepetit，Paul Wohlhart，Kurt Konolige — <a class="ae mr" href="https://arxiv.org/abs/1710.10710" rel="noopener ugc nofollow" target="_blank">关于深度学习的预训练图像特征和合成图像</a> (2017)，ECCV 2018</p><p id="fe06" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[3] Stephen James，Paul Wohlhart，Mrinal Kalakrishnan，Dmitry Kalashnikov，Alex Irpan，Julian Ibarz，Sergey Levine，Raia Hadsell，Konstantinos Bousmalis — <a class="ae mr" href="https://arxiv.org/abs/1812.07252" rel="noopener ugc nofollow" target="_blank">通过 Sim-to-Sim 实现 Sim-to-Real:通过随机到规范的适应网络实现数据高效的机器人抓取</a> (2018)，CVPR 2019</p><p id="012b" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[4]Salehe Erfanian Ebadi，You-Cyuan Jhang，Alex Zook，Saurav Dhakad，Adam Crespi，Pete 帕里西，Steven Borkman，Jonathan Hogins，su joy Ganguly—<a class="ae mr" href="https://arxiv.org/abs/2112.09290" rel="noopener ugc nofollow" target="_blank">PeopleSansPeople:以人为中心的计算机视觉的合成数据生成器</a> (2021)，预印本</p><p id="bc69" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[5] Stefan Hinterstoisser，Olivier Pauly，Hauke Heibel，Martina Marek，Martin Bokeloh — <a class="ae mr" href="https://arxiv.org/pdf/1902.09967.pdf" rel="noopener ugc nofollow" target="_blank">保存的注释是获得的注释:使用完全合成训练进行对象实例检测</a> (2019)，ICCV 2019</p></div></div>    
</body>
</html>