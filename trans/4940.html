<html>
<head>
<title>Using Unsupervised Learning to Find Outliers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用无监督学习发现异常值</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-unsupervised-learning-to-find-outliers-670e07396599#2022-11-02">https://towardsdatascience.com/using-unsupervised-learning-to-find-outliers-670e07396599#2022-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="668d" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">两种选择:局部异常因子和高斯混合模型</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7b032ee38e423c492d6d1afd44c4febf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f0rRVBSBgWGWSaBYB8t5yA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/es/@tareq_aj?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">塔里克·阿贾利亚金</a>在<a class="ae ky" href="https://unsplash.com/s/photos/points?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure></div><div class="ab cl kz la hx lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="im in io ip iq"><h1 id="39a4" class="lg lh it bd li lj lk ll lm ln lo lp lq jz lr ka ls kc lt kd lu kf lv kg lw lx bi translated">介绍</h1><p id="8d50" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">离群值是许多数据科学论坛和博客中经常讨论的话题。这可能是因为这些数据点会扭曲我们的分析，并影响建模，如果我们使用的算法对这些异常不稳健的话。</p><p id="c526" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">一个数据集，很多时候，会把大部分的观察值放在一定的数值范围内，遵循一些模式，离“群体”不太远。这些是<em class="mz">内联器</em>。但是也有一些观察不适合任何地方，远离数据的标准，不遵循这种模式。那些是异常值，离群值。</p><p id="2c2c" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">受异常值影响很大的算法是传统的线性回归。如果您的观察值过于偏离中心值，将会扭曲回归计算，使模型表现更差。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/6c7268ece5373f06fb974baa35baf3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*rw6NtqGzk2_HgSnApCp5DQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">离群值。图片由作者提供。</p></figure><p id="207f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">让我们学习两种使用无监督学习算法查找异常值的快速方法:带有局部异常值因子的KNN和高斯混合，这两种方法都来自Scikit-Learn。</p><h1 id="6324" class="lg lh it bd li lj nb ll lm ln nc lp lq jz nd ka ls kc ne kd lu kf nf kg lw lx bi translated">本地异常因素[LOF]</h1><p id="70f9" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">这个算法在sklearn.neighbors模块中有，可以用<code class="fe ng nh ni nj b">from sklearn.neighbors import <a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html" rel="noopener ugc nofollow" target="_blank">LocalOutlierFactor</a></code>导入。它依赖于K-最近邻算法，有趣的是，LOF有超参数<code class="fe ng nh ni nj b">contamination</code>来帮助我们确定离群值的阈值。所以，如果你使用<code class="fe ng nh ni nj b">contamination= 0.1</code>，这意味着你想把10%的数据作为异常值。</p><blockquote class="nk"><p id="4b80" class="nl nm it bd nn no np nq nr ns nt mt dk translated">数据集的污染量，即数据集中异常值的比例。(sklearn文档)</p></blockquote><p id="81d3" class="pw-post-body-paragraph ly lz it ma b mb nu ju md me nv jx mg mh nw mj mk ml nx mn mo mp ny mr ms mt im bi translated">接下来是应用该算法的编码。我们将使用Python中seaborn包自带的'<a class="ae ky" href="https://github.com/mwaskom/seaborn-data/blob/master/car_crashes.csv" rel="noopener ugc nofollow" target="_blank"> <em class="mz"> car_crashes </em> </a>'数据集。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="3088" class="od lh it nj b gy oe of l og oh"># Dataset<br/>df = sns.load_dataset('car_crashes')</span></pre><p id="16b6" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我将在这里添加一些奇怪的数据，它们将是我们的异常值。请注意，我希望它非常不同，以确保它是一个异常值，这样我就可以演示异常值检测器的运行。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="8f18" class="od lh it nj b gy oe of l og oh"># Creating very odd observations = OUTLIERS<br/>s1 = pd.DataFrame([30,30,30,30,30,30,30,'AB']).T<br/>s2 = pd.DataFrame([40,40,40,40,40,40,40,'AB']).T<br/>s3 = pd.DataFrame([30,30,30,30,50,50,50,'AB']).T<br/>s4 = pd.DataFrame([99,99,99,39,99,59,59,'AB']).T<br/>s5 = pd.DataFrame([99,99,90,9,99,9,99,'AB']).T<br/>s1.columns = s2.columns = s3.columns = s4.columns = s5.columns= df.columns</span><span id="c54e" class="od lh it nj b gy oi of l og oh"># Adding them to the dataset<br/>df=pd.concat([df,s1, s2, s3, s4, s5], axis=0)</span><span id="efdb" class="od lh it nj b gy oi of l og oh"># X<br/>X = df.drop('abbrev', axis=1)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/15258bc317e211b5e73c7a2a327503cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HmHb7BcTT2VM0nFeNrO-RA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集car_crashes的头。图片由作者提供。</p></figure><p id="0012" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">接下来，我们可以导入<code class="fe ng nh ni nj b">Pipeline</code>、<code class="fe ng nh ni nj b">StandardScaler</code>并创建这个简单的管道来缩放数据，将其放入相同的范围，然后运行LOF算法。请注意，我们使用9%的污染率，因为数据有51个观察值，我们知道有5个异常值(5/51 = 9.8%)。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="d69d" class="od lh it nj b gy oe of l og oh"># Let's create a Pipeline to scale the data and find outliers using KNN Classifier</span><span id="56d8" class="od lh it nj b gy oi of l og oh">steps = [<br/>('scale', StandardScaler()),<br/>('LOF', LocalOutlierFactor(contamination=0.09))<br/>]</span><span id="29ee" class="od lh it nj b gy oi of l og oh"># Fit and predict<br/>outliers = Pipeline(steps).fit_predict(X)</span></pre><p id="19b0" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果您调用输出<code class="fe ng nh ni nj b">outliers</code>，您将会看到这个结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ac9650b6092443b33edf74def3ed5152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*88g4i-1N-YsSs_sBI_YOHA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LOF将异常值标注为-1。图片由作者提供。</p></figure><p id="ae09" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">完成后，我们可以将数据添加到原始数据集并查看它。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="a993" class="od lh it nj b gy oe of l og oh"># Add column<br/>df['outliers'] = outliers</span><span id="0121" class="od lh it nj b gy oi of l og oh"># Look at the top 8<br/>df.sort_values(by='outliers').head(8)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/90ecf2676fbc03429f18b301e4fb4089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qAHBTNkquD0w1vM0qGKyQQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LOF算法检测到的异常值。图片由作者提供。</p></figure><p id="8daf" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">非常好。我们能够找到先前创建的异常值。如果我们使用t-SNE来创建这个数据集的2D图，下面是我们将看到的内容(<em class="mz"/><em class="mz">这个图的代码可以在文章</em>末尾的GitHub链接中找到)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi om"><img src="../Images/8c9e9fe2f62c4f6b1a08b3937faa8d62.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*LDHzGtEIZYhfqkVpyaf5LA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集的2D图。图片由作者提供。</p></figure><p id="82a7" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">回顾刚刚发生的事情:LOF使用KNN，这是一个分类器，它根据数据点之间的距离和相似性来聚类数据点。自然，由于创建的数据不同于其他数据，它们被标记为异常。</p><h1 id="fad7" class="lg lh it bd li lj nb ll lm ln nc lp lq jz nd ka ls kc ne kd lu kf nf kg lw lx bi translated">高斯混合模型</h1><p id="ce38" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">可以找到的另一种算法是高斯混合模型(GMM)。这个将查看数据，并将其分成<em class="mz"> n </em>组。为了将每个观察值添加到一个组中，算法会计算并创建<em class="mz"> n </em>个高斯分布，然后检查数据点在这些高斯分布中的哪个位置更适合(概率更高)。</p><p id="80fa" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">sklearn的GMM根据每个点在该空间中的密度来计算观察值。因此，密度较高的区域中的点不太可能是异常值，反之亦然，因此低密度区域就是异常值所在的位置。</p><p id="c8da" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我们编码吧。首先，导入模块。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="503b" class="od lh it nj b gy oe of l og oh">from sklearn.mixture import GaussianMixture</span></pre><p id="a959" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">接下来，我们可以拟合GMM。我们使用3个分量，这意味着该数据被<em class="mz">分成</em>3个高斯分布。<code class="fe ng nh ni nj b">n_init= 10</code>是GMM运行10次迭代以找到最佳拟合。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="3412" class="od lh it nj b gy oe of l og oh">gm = GaussianMixture(n_components=3, n_init=10)<br/>gm.fit(X)</span></pre><p id="762f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">好了，现在我们必须计算分数。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="d3b7" class="od lh it nj b gy oe of l og oh"># Finding densities<br/>density_scores = gm.score_samples(X)</span></pre><p id="d0f5" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果我们打印它，在这种情况下，我们只会看到负数。所以，我只取它们的绝对值，这样更容易计算百分位数。</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="7f8b" class="od lh it nj b gy oe of l og oh">density_scores= abs(density_scores)</span></pre><p id="1815" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">现在我们可以计算我们想要的百分比作为阈值，或者要查找的离群值的数量。让我们用同样的9%来工作</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="3262" class="od lh it nj b gy oe of l og oh"># Define threshold<br/>threshold = np.percentile(density_scores, 9)</span><span id="6f24" class="od lh it nj b gy oi of l og oh"># Finding outliers<br/>X[density_scores&lt; threshold]</span><span id="ec98" class="od lh it nj b gy oi of l og oh">X['densities'] = density_scores</span></pre><p id="e5ec" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">阈值是<code class="fe ng nh ni nj b">16.36102</code>。我们可以看到，它找到了相同的结果，即低于该数字的所有数据(我们的假异常值)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/b4d2a5efd29e217c4e7cd462c9d22ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCq8zqnVGuywN84xleR8OA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用GMM检测到的异常值是前5行，小于16.36。图片由作者提供。</p></figure><p id="0d50" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">它像预期的那样工作。</p><h1 id="e7d8" class="lg lh it bd li lj nb ll lm ln nc lp lq jz nd ka ls kc ne kd lu kf nf kg lw lx bi translated">在你走之前</h1><p id="6039" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">发现异常值是一项可以通过多种方式执行的任务。还有其他好的算法，比如隔离森林。还有其他的方法，比如Z值法、IQR法……还有很多选择。</p><p id="30f4" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">我想展示这两个，因为我发现它们非常容易应用。</p><p id="4d6a" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">对于LOF，只需使用:</p><p id="b8b5" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated"><code class="fe ng nh ni nj b">LocalOutlierFactor(contamination= n)</code>。</p><p id="8c7d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">对于GMM，请使用:</p><pre class="kj kk kl km gt nz nj oa ob aw oc bi"><span id="6d7c" class="od lh it nj b gy oe of l og oh">scores = gm.score_samples(X)</span><span id="de18" class="od lh it nj b gy oi of l og oh">threshold = np.percentile(scores, 9)<br/>X[scores&lt; threshold]</span></pre><p id="0a66" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">这里是GitHub 中的<a class="ae ky" href="https://github.com/gurezende/Studying/blob/master/Python/sklearn/Outliers.ipynb" rel="noopener ugc nofollow" target="_blank">完整代码。</a></p><p id="631d" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">如果你喜欢这个内容，请关注我的博客。</p><div class="oo op gp gr oq or"><a href="http://gustavorsantos.medium.com/" rel="noopener follow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">古斯塔沃·桑托斯-中等</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">阅读古斯塔夫·桑托斯在媒介上的作品。数据科学家。我从数据中提取见解，以帮助个人和公司…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">gustavorsantos.medium.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf ks or"/></div></div></a></div><p id="204f" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">在LinkedIn 上找到我。如果你正在考虑加入Medium，<a class="ae ky" href="https://medium.com/subscribe/@gustavorsantos" rel="noopener">这里有一个推荐链接</a>。</p><h1 id="56dd" class="lg lh it bd li lj nb ll lm ln nc lp lq jz nd ka ls kc ne kd lu kf nf kg lw lx bi translated">参考</h1><p id="61db" class="pw-post-body-paragraph ly lz it ma b mb mc ju md me mf jx mg mh mi mj mk ml mm mn mo mp mq mr ms mt im bi translated">Aurélien Géron，2019。<a class="ae ky" href="https://tinyurl.com/2s3tsh9x" rel="noopener ugc nofollow" target="_blank"> <em class="mz">用Scikit-Learn动手机器学习，Keras &amp; TensorFlow </em> </a>。第二版，奥赖利。</p><p id="083e" class="pw-post-body-paragraph ly lz it ma b mb mu ju md me mv jx mg mh mw mj mk ml mx mn mo mp my mr ms mt im bi translated">迈克尔·沃克，2022年。<a class="ae ky" href="https://www.amazon.com/Data-Cleaning-Exploration-Machine-Learning/dp/1803241675" rel="noopener ugc nofollow" target="_blank"> <em class="mz">用机器学习进行数据清洗和探索。</em> </a> <em class="mz"> </em> 1ed。Packt出版物。</p><div class="oo op gp gr oq or"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">sk learn . neighbors . localooutlierfactor</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">使用局部异常因子(LOF)的无监督异常检测。每个样本的异常值称为…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">scikit-learn.org</p></div></div><div class="pa l"><div class="pg l pc pd pe pa pf ks or"/></div></div></a></div><div class="oo op gp gr oq or"><a href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">sklearn . mixture . Gaussian mixture</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">高斯混合。高斯混合模型概率分布的表示。这个类允许估计…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">scikit-learn.org</p></div></div><div class="pa l"><div class="ph l pc pd pe pa pf ks or"/></div></div></a></div></div></div>    
</body>
</html>