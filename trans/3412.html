<html>
<head>
<title>Quick start for moving data from AWS RDS to an S3 staging bucket</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将数据从AWS RDS移动到S3暂存区的快速入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quick-start-for-moving-data-from-aws-rds-to-an-s3-staging-bucket-c60267ccf7a3#2022-07-28">https://towardsdatascience.com/quick-start-for-moving-data-from-aws-rds-to-an-s3-staging-bucket-c60267ccf7a3#2022-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="eee7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">利用Python和Boto3作为构建数据湖的第一步</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/4b4caed5772537c287e8cabd4c3c80b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TxSzSQzidwd5NfFy"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">考特尼·摩尔在<a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="4c3a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">数据仓库架构中的一个常见元素是数据湖。数据湖是所有结构化和非结构化数据源的中央存储库。最近，我一直在使用雪花，一个流行的基于云的数据存储解决方案，作为一个数据湖和数据仓库。</p><p id="cd24" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">获取源数据是构建数据湖的第一步。在本文中，我们将建立到AWS RDS Postgres实例的连接，并在将数据复制到Snowflake之前将数据传输到S3分段存储桶。本文利用Python和Boto3库来访问AWS资源。</p><h2 id="5ce6" class="lt lu iq bd lv lw lx dn ly lz ma dp mb lg mc md me lk mf mg mh lo mi mj mk ml bi translated"><strong class="ak">要求</strong></h2><ol class=""><li id="4943" class="mm mn iq kz b la mo ld mp lg mq lk mr lo ms ls mt mu mv mw bi translated">计算机编程语言</li><li id="0c25" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">Boto3库</li><li id="f1ce" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">Psycopg2库</li><li id="83d7" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">IO库</li><li id="07c5" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">AWS帐户访问</li><li id="ebb2" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">AWS帐户访问ID和秘密访问密钥</li><li id="4025" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">RDS Postgres数据库和用户访问/凭证</li><li id="1b87" class="mm mn iq kz b la mx ld my lg mz lk na lo nb ls mt mu mv mw bi translated">S3桶访问</li></ol></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><h1 id="c9aa" class="nj lu iq bd lv nk nl nm ly nn no np mb jw nq jx me jz nr ka mh kc ns kd mk nt bi translated">入门指南</h1><p id="e59b" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nu li lj lk nv lm ln lo nw lq lr ls ij bi translated"><a class="ae kw" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html" rel="noopener ugc nofollow" target="_blank"> Boto3 </a>是Python的AWS SDK。它提供了面向对象的API和对AWS服务的底层访问。为了建立到RDS的连接，我们可以利用<code class="fe nx ny nz oa b">Boto3 Session</code>对象来生成一个<code class="fe nx ny nz oa b">db_authentication_token</code>，我们将在稍后使用<code class="fe nx ny nz oa b">psycopg2</code>连接到Postgres时使用它。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="13c0" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">有了这个令牌(密码)，一旦我们有了连接对象，就可以用<code class="fe nx ny nz oa b">psycopg2</code>连接并查询我们的RDS实例。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="9e34" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">有了这个连接对象，我们可以向RDS数据库发送查询来执行必要的提取。举个例子，</p><pre class="kh ki kj kk gt od oa oe bn of og bi"><span id="99df" class="oh lu iq oa b be oi oj l ok ol">import pandas as pd<br/>sql = f'''<br/>    select table_name<br/>    from information_schema.tables<br/>    where table_schema like 'public'<br/>       and table_type like 'base table'<br/>'''<br/>results = pd.read_sql(sql, conn)<br/>df = pd.DataFrame(results)</span></pre><p id="54b3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用同样的逻辑，我们可以遍历表名的结果，并从每个表中提取行上传到雪花。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><h1 id="93c2" class="nj lu iq bd lv nk nl nm ly nn no np mb jw nq jx me jz nr ka mh kc ns kd mk nt bi translated">S3暂存桶</h1><p id="8f59" class="pw-post-body-paragraph kx ky iq kz b la mo jr lc ld mp ju lf lg nu li lj lk nv lm ln lo nw lq lr ls ij bi translated">一旦我们有了包含源数据的可用数据帧，我们就可以开始设置另一个python会话资源来用于S3分段存储桶。一旦分配了资源，我们就可以利用<code class="fe nx ny nz oa b">io.StringIO</code>库将数据帧作为csv文件上传到S3存储桶。</p><p id="bd7b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><a class="ae kw" href="https://docs.python.org/3/library/io.html?highlight=stringio#io.StringIO" rel="noopener ugc nofollow" target="_blank"> StringIO </a>是一个文本流对象，当我们将csv写入S3存储桶时，它使用内存中的文本缓冲区来保存数据帧的内容。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="3109" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><code class="fe nx ny nz oa b">StringIO</code>的好处是它可以很好地与Apache Airflow这样的orchestrator一起工作，在上传文件之前，我们不需要担心将查询的输出编写为本地csv文件(这是另一种选择)。然而，我们也需要考虑这种选择的局限性。随着表大小的增加，有一个明显的内存限制，这将需要增量提取或多部分上传。这可以很容易地用pandas数据帧批处理来处理，从而减少内存负载。</p><p id="c654" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这些数据现在可以在S3以csv格式获得！将数据放入雪花数据湖的下一步是利用<a class="ae kw" href="https://docs.snowflake.com/en/user-guide/data-load-s3-create-stage.html" rel="noopener ugc nofollow" target="_blank"> S3存储桶作为中转站点</a>，这样数据就可以直接加载到雪花中。期待在我的下一篇文章中更深入地探究这个过程。</p></div><div class="ab cl nc nd hu ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="ij ik il im in"><p id="bbf1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">概括地说，在本文中，我们探索了Boto3库，用Python建立了到AWS资源的会话和连接，并从RDS中提取数据，以<code class="fe nx ny nz oa b">.csv</code>格式上传到S3桶。在我作为数据工程师的工作中，这是一种常见的做法。请伸出手来，与我联系，谈论更多关于这个或任何问题。</p></div></div>    
</body>
</html>