<html>
<head>
<title>A Comprehensive Guide to Image Augmentation using Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pytorch进行图像增强的综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-comprehensive-guide-to-image-augmentation-using-pytorch-fb162f2444be#2022-04-29">https://towardsdatascience.com/a-comprehensive-guide-to-image-augmentation-using-pytorch-fb162f2444be#2022-04-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2129" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">一种增加数据量并使模型更加稳健的方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7f271f7c5b48cdc51147e4e6eb1e608f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kXJRrpkDPfjh6OqK"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@danielcgold" rel="noopener ugc nofollow" target="_blank">丹金</a>在<a class="ae ky" href="https://unsplash.com/photos/mgaS4FlsYxQ" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="e8f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最近，在从事我的研究项目时，我开始理解图像增强技术的重要性。这个项目的目的是训练一个健壮的生成模型，能够重建原始图像。</p><p id="a0cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所解决的问题是异常检测，这是一个非常具有挑战性的问题，因为数据量很小，而且模型不足以单独完成所有工作。常见的情况是使用可用于训练的正常图像来训练双网络模型，并在包含正常和异常图像的测试集上评估其性能。</p><p id="83b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最初的假设是，生成模型应该很好地捕捉正态分布，但同时，它应该不能重构异常样本。怎么可能验证这个假设？我们可以查看重建误差，对于异常图像，该误差应该较高，而对于正常样本，该误差应该较低。</p><p id="6d85" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我将列出增加数据集中图像大小和多样性的最佳数据扩充技术。主要目标是提高模型的性能和通用性。我们将探索简单的变换，如旋转、裁剪和高斯模糊，以及更复杂的技术，如高斯噪声和随机块。</p><h2 id="7833" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">图像分析技术；</h2><h2 id="2539" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">1.简单的转换</h2><ul class=""><li id="1021" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">调整大小</li><li id="67d3" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">灰度</li><li id="2a2a" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">使标准化</li><li id="5918" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">随机旋转</li><li id="9e1b" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">中间作物</li><li id="f156" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">随机作物</li><li id="0360" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">高斯模糊</li></ul><h2 id="f08a" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">2.更先进的技术</h2><ul class=""><li id="4be7" class="mo mp it lb b lc mq lf mr li ms lm mt lq mu lu mv mw mx my bi translated">高斯噪声</li><li id="01c4" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">随机块</li><li id="d8fe" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">中部</li></ul><h1 id="e577" class="ne lw it bd lx nf ng nh ma ni nj nk md jz nl ka mg kc nm kd mj kf nn kg mm no bi translated">1.表面裂纹数据集简介</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi np"><img src="../Images/8c9bb2956dbf177450fe3bab15686c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h6mhVP2rGzE0jNGB0z6GTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">表面裂纹数据集。作者插图。</p></figure><p id="761c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将使用表面裂纹检测数据集。你可以在这里或者在<a class="ae ky" href="https://www.kaggle.com/datasets/arunrk7/surface-crack-detection" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上下载数据集<a class="ae ky" href="https://data.mendeley.com/datasets/5y9wdsg2zt/2" rel="noopener ugc nofollow" target="_blank">。正如您可以从名称中推断的那样，它提供了有裂缝和没有裂缝的表面的图像。因此，它可以用作异常检测任务的数据集，其中异常类由有裂缝的图像表示，而正常类由没有裂缝的表面表示。它包含4000张有缺陷和无缺陷表面的彩色图像。这两个类在训练集和测试集中都可用。此外，每个数据集图像以227×227像素的分辨率采集。</a></p><h1 id="073d" class="ne lw it bd lx nf ng nh ma ni nj nk md jz nl ka mg kc nm kd mj kf nn kg mm no bi translated">2.简单的转换</h1><p id="2fd1" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">本节包括<code class="fe nt nu nv nw b">torchvision.transforms</code>模块中可用的不同转换。在深入之前，我们从训练数据集中导入模块和一个没有缺陷的图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="2b2c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们显示图像的尺寸:</p><pre class="kj kk kl km gt nz nw oa ob aw oc bi"><span id="a054" class="lv lw it nw b gy od oe l of og">np.asarray(orig_img).shape  #(227, 227, 3)</span></pre><p id="9d8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着我们有一个227x227的图像，有3个通道。</p><h2 id="96bc" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">调整大小</h2><p id="7f0a" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">由于图像具有非常高的高度和宽度，因此需要在将其传递给神经网络之前降低维度。例如，我们可以将227x227图像调整为32x32和128x128图像。</p><pre class="kj kk kl km gt nz nw oa ob aw oc bi"><span id="3c71" class="lv lw it nw b gy od oe l of og">resized_imgs <strong class="nw iu">=</strong> [T<strong class="nw iu">.</strong>Resize(size<strong class="nw iu">=</strong>size)(orig_img) <strong class="nw iu">for</strong> size <strong class="nw iu">in</strong> [32,128]]<br/>plot(resized_imgs,col_title<strong class="nw iu">=</strong>["32x32","128x128"])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/5bf9414d66aafcf3b74a1f26b5f3b899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toq7XZboBk_RJh6wSomWxQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">已调整大小的图像。作者插图</p></figure><p id="2bd3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">值得注意的是，当我们获得32x32的图像时，分辨率会降低，而128x128的尺寸似乎可以保持样本的高分辨率。</p><h2 id="e695" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">灰度</h2><p id="082b" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">RGB图像可能很难管理。因此，将图像转换为灰度是很有用的:</p><pre class="kj kk kl km gt nz nw oa ob aw oc bi"><span id="1a2a" class="lv lw it nw b gy od oe l of og">gray_img <strong class="nw iu">=</strong> T<strong class="nw iu">.</strong>Grayscale()(orig_img)<br/>plot([gray_img], cmap<strong class="nw iu">=</strong>'gray', col_title<strong class="nw iu">=</strong>["Gray"])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/24331c60681a0c023fc71d727dca3917.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-w9Y2_hlniohGFr8LracuA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始图像与灰度图像。作者插图</p></figure><h2 id="6713" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">使标准化</h2><p id="fdd3" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">归一化可以构成加速基于神经网络架构的模型中的计算和更快学习的有效方式。标准化图像有两个步骤:</p><ul class=""><li id="49ba" class="mo mp it lb b lc ld lf lg li oj lm ok lq ol lu mv mw mx my bi translated">我们从每个输入通道中减去通道平均值</li><li id="709e" class="mo mp it lb b lc mz lf na li nb lm nc lq nd lu mv mw mx my bi translated">后来，我们用它除以信道标准差。</li></ul><p id="c273" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以显示原始图像及其归一化版本:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/fdd037c9886d64f78329137e75e05525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zV_IGsOlEJUfJTXKPLxYQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">原始图像与标准化图像。作者插图</p></figure><h2 id="c973" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">随机旋转</h2><p id="a38a" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated"><code class="fe nt nu nv nw b">T.RandomRotation</code>方法以随机角度旋转图像。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/7c35aeb1f03ab6c015c7481f378865bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkqqlpJ2RE9zpCBEXizSUw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">不同的旋转图像。作者插图</p></figure><h2 id="93a9" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">中间作物</h2><p id="3337" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我们使用<code class="fe nt nu nv nw b">T.CenterCrop</code>方法裁剪图像的中心部分，这里需要指定裁剪的尺寸。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/9d6459d91662044c862e940cfc654ebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2meWbl68LxxrylUlqHSDg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">中间作物。作者插图</p></figure><p id="6ba5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">当图像的边界中有一个大的背景，而这对于分类任务来说是完全不必要的时，这种变换会很有用。</p><h2 id="4c31" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">随机作物</h2><p id="71eb" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我们没有裁剪图像的中心部分，而是通过<code class="fe nt nu nv nw b">T.RandomCrop</code>方法随机裁剪图像的一部分，该方法将裁剪的输出大小作为参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/4055940eb9509c30c3295eea563622b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*svsrkQNI7QOFhGmA6IJg5A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机作物。作者插图</p></figure><h2 id="54a3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">高斯模糊</h2><p id="ab73" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我们使用高斯核对图像应用高斯模糊变换。这种方法有助于使图像变得不太清晰和明显，然后，将得到的图像输入神经网络，神经网络在学习样本模式时变得更加稳健。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/af6e2a0175255290db25be46e3a09b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FflCMpKGYwUpCv_Z7gxutQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高斯模糊。作者插图</p></figure><h1 id="3587" class="ne lw it bd lx nf ng nh ma ni nj nk md jz nl ka mg kc nm kd mj kf nn kg mm no bi translated">3.更先进的技术</h1><p id="4806" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">前面展示了PyTorch提供的简单转换的例子。现在，我们将重点关注从头实现的更复杂的技术。</p><h2 id="cba0" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">高斯噪声</h2><p id="c5f7" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">高斯噪声是向整个数据集添加噪声的一种常见方式，它迫使模型学习数据中包含的最重要的信息。它包括注入高斯噪声矩阵，该矩阵是从高斯分布中抽取的随机值的矩阵。稍后，我们在0和1之间剪切样本。噪声系数越高，图像的噪声越大。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/04dc366fa1a50d4cbf5c71b039d3a358.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3KYy1s--059Z_QiYHUl4w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高斯噪声。作者插图</p></figure><h2 id="5ab3" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">随机块</h2><p id="eb6c" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">正方形面片作为蒙版随机应用在图像中。这些小块的数量越多，神经网络就会发现解决这个问题越有挑战性。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/3625377393da87fd6e5e9b45bfbd6a9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yNgdDR3rMLYw4Fdo5EZsDQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机块。作者插图。</p></figure><h2 id="5cdf" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">中部</h2><p id="a926" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">这是一个非常简单的技术，可以使模型更加一般化。它包括在图像的中心区域添加一个修补块。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/de8a0707d6655b51037c400ceacf4a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESmb9wYhnB_mjFxCkvSr7w.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">中部地区。作者插图。</p></figure><h1 id="d84d" class="ne lw it bd lx nf ng nh ma ni nj nk md jz nl ka mg kc nm kd mj kf nn kg mm no bi translated">最终想法:</h1><p id="3230" class="pw-post-body-paragraph kz la it lb b lc mq ju le lf mr jx lh li nq lk ll lm nr lo lp lq ns ls lt lu im bi translated">我希望这篇教程对你有用。目的是综述图像增强方法，以解决基于神经网络的模型的泛化问题。如果你知道其他有效的技术，请随时评论。我将在下一篇文章中解释如何利用自动编码器来开发这些技术。代码在<a class="ae ky" href="https://www.kaggle.com/code/eugeniaanello/image-augmentation-using-pytorch-on-crack-images" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上。感谢阅读。祝您愉快！</p><h2 id="5662" class="lv lw it bd lx ly lz dn ma mb mc dp md li me mf mg lm mh mi mj lq mk ml mm mn bi translated">其他相关文章:</h2><div class="ot ou gp gr ov ow"><a href="https://medium.com/mlearning-ai/albumentations-a-python-library-for-advanced-image-augmentation-strategies-752bff3a3da0" rel="noopener follow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">Albumentations:用于高级图像增强策略的Python库</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">用Pytorch的Pokemon数据集的例子对这个快速的开源软件进行了一个温和的概述</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">medium.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk ks ow"/></div></div></a></div><div class="ot ou gp gr ov ow"><a href="https://medium.com/mlearning-ai/how-to-quickly-build-your-own-dataset-of-images-for-deep-learning-1cf79073f1bd" rel="noopener follow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd iu gy z fp pb fr fs pc fu fw is bi translated">如何为深度学习快速构建自己的图像数据集</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">使用Octoparse快速抓取数据，无需编码</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">medium.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk ks ow"/></div></div></a></div><p id="7a0b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="pm">免责声明:该数据集由恰拉尔·弗拉特·兹内尔根据</em> <a class="ae ky" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> <em class="pm">知识共享署名4.0国际</em> </a> <em class="pm"> (CC BY 4.0)授权。</em></p></div><div class="ab cl pn po hx pp" role="separator"><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps pt"/><span class="pq bw bk pr ps"/></div><div class="im in io ip iq"><p id="625e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你喜欢我的文章吗？<a class="ae ky" href="https://eugenia-anello.medium.com/membership" rel="noopener"> <em class="pm">成为会员</em> </a> <em class="pm">每天无限获取数据科学新帖！这是一种间接的支持我的方式，不会给你带来任何额外的费用。如果您已经是会员，</em> <a class="ae ky" href="https://eugenia-anello.medium.com/subscribe" rel="noopener"> <em class="pm">订阅</em> </a> <em class="pm">每当我发布新的数据科学和python指南时，您都会收到电子邮件！</em></p></div></div>    
</body>
</html>