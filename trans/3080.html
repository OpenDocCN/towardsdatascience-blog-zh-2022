<html>
<head>
<title>Backpropagation — Chain Rule and PyTorch in Action</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">反向传播——链式法则和PyTorch在起作用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/backpropagation-chain-rule-and-pytorch-in-action-f3fb9dda3a7d#2022-07-06">https://towardsdatascience.com/backpropagation-chain-rule-and-pytorch-in-action-f3fb9dda3a7d#2022-07-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3c9c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Pytorch中从理论到实现的简单指南。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/639a1e242521b51a1008b123c8bf89be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QrjGnaknTOJXC6Mv.jpg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://pixabay.com/illustrations/quantum-physics-wave-particles-4550602/" rel="noopener ugc nofollow" target="_blank">图片</a>由gerald在Pixabay上拍摄</p></figure></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><p id="f607" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现代企业越来越依赖于人工智能等创新领域的进步，来为客户提供最好的产品和服务。许多生产人工智能系统是基于各种神经网络，通常使用大量数据进行训练。对于开发团队来说，最大的挑战之一是如何在有限的时间内训练他们的模型。有各种技术和算法可以做到这一点，但最流行的是使用某种梯度下降法。</p><p id="c10e" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">基于基于梯度的优化算法的神经网络(NN)的训练分为两个主要步骤:</p><ol class=""><li id="45f2" class="lz ma iq lf b lg lh lj lk lm mb lq mc lu md ly me mf mg mh bi translated"><strong class="lf ir">正向传播</strong> —这里我们<strong class="lf ir">计算NN个给定输入的输出</strong></li><li id="d00c" class="lz ma iq lf b lg mi lj mj lm mk lq ml lu mm ly me mf mg mh bi translated"><strong class="lf ir">反向传播</strong> —这里我们<strong class="lf ir">计算输出相对于输入的梯度</strong>以更新权重</li></ol><p id="cfb6" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">第一步通常很容易理解和计算。第二步背后的总体思路也很清楚——我们需要梯度来知道方向，以便在梯度下降优化算法中进行步骤。如果你不熟悉这种方法，你可以看看我的另一篇文章(<a class="ae kv" rel="noopener" target="_blank" href="/gradient-descent-algorithm-a-deep-dive-cf04e8115f21">梯度下降算法——一个深度探索</a>)。</p><p id="2884" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">虽然反向传播并不是一个新的想法(在20世纪70年代开发)，但回答“如何”计算这些梯度的问题让一些人很难回答。人们必须接触一些微积分，尤其是偏导数和链式法则，才能完全理解反向传播的工作原理。</p><p id="420b" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">最初开发反向传播是为了区分复杂的嵌套函数。然而，由于机器学习社区，它变得非常受欢迎，现在是神经网络的基石。</p><p id="bc37" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在本文中，我们将从根本上手动一步一步地解决一个典型的问题，然后我们将使用PyTorch在python中实现它，最后我们将比较两个结果以确保一切正常。</p></div><div class="ab cl kw kx hu ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ij ik il im in"><ol class=""><li id="039f" class="lz ma iq lf b lg lh lj lk lm mb lq mc lu md ly me mf mg mh bi translated"><strong class="lf ir">计算图形</strong></li></ol><p id="d641" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">让我们假设我们想要执行以下一组操作来获得我们的结果<code class="fe mn mo mp mq b">r</code>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/a9b2447f212939edb929d766dc661595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GfNeP620Im8vPLaq3J5opA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">计算图形表示；作者图片</p></figure><p id="dda5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">如果你把所有单独的节点方程代入最终方程，你会发现我们在解下面的方程。更具体地说，我们想计算它的值和它的偏导数。所以在这个用例中，这是一个纯粹的数学任务。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/911d8525ee47513b24c1f1cb148b6fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/1*R2HwBo4LMcS_s4MzlDD3gA.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">情商。1:待解方程(偏导数)</p></figure><p id="f0c3" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf ir"> 2。向前传球</strong></p><p id="586f" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了使这个概念更具体，让我们用一些数字来计算。例如:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/cb2c169614b545b9b7914097943ca61a.png" data-original-src="https://miro.medium.com/v2/resize:fit:86/0*3K30n3X7_yiTOqr_"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">示例性输入值</p></figure><p id="7786" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这里我们简单地将输入代入方程。各个节点步骤的结果如下所示。最终输出为r=144。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/35e0f43242f1559c72cb38557bf87ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lDTnm2rsYMygLexSKFKdVA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">向前传球；作者图片</p></figure><p id="10fa" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf ir"> 3。向后传球</strong></p><p id="6192" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在是时候进行反向传播了，也有一个更花哨的名字“误差反向传播”，甚至是“自动微分的反向模式”。</p><p id="a5cd" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了计算3个变量中每个变量的梯度，我们必须计算图中每个节点的偏导数(局部梯度)。下面我将向您展示如何完成最后两个节点/步骤(我将把剩下的部分作为练习)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/01bb241f5000cdb63a2709a5ede39fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/0*DaHXId-gWSy05mrI"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">最后两个节点的偏导数</p></figure><p id="cf24" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在完成局部梯度的计算之后，反向传播的计算图如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/72c53bb11318a51e8b153d5f7f44dfb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xi-3jdKHEmWqsuDM7pi36w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">反向通道的局部梯度；作者图片</p></figure><p id="49ef" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，为了计算最终的梯度(在橙色圆圈中),我们必须使用链式法则。实际上，这意味着我们必须将从输出到目标变量的所有偏导数相乘:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7a68662a79432d1ccdceb46ed89b2ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/0*j4zaLrnL2JZRHC8C"/></div></figure><p id="a6b7" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在，我们可以根据自己的需要使用这些梯度——例如，梯度下降优化(SGD、Adam等)。).</p><p id="63c1" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf ir"> 4。PyTorch中的实现</strong></p><p id="9b8b" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在各种语言中有许多神经网络框架，你可以在其中实现这样的计算，并让计算机为你计算梯度。下面，我将演示如何使用python PyTorch库来解决我们的示例性任务。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="1a97" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这段代码的输出是:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/b278b686da1b5ab9149c04ca056f29fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*SdjHr-AAUbpOCUyxvkMnmg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PyTorch报告的结果</p></figure><p id="8a8e" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">PyTorch的结果与我们手工计算的结果一致。</p><p id="6492" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">几个注意事项:</p><ul class=""><li id="f3fd" class="lz ma iq lf b lg lh lj lk lm mb lq mc lu md ly nb mf mg mh bi translated">在PyTorch中，一切都是张量——即使它只包含一个值</li><li id="04fe" class="lz ma iq lf b lg mi lj mj lm mk lq ml lu mm ly nb mf mg mh bi translated">在PyTorch中，当你指定一个基于梯度优化的变量时，你必须指定参数<code class="fe mn mo mp mq b">requires_grad = True</code>。否则，它将被视为固定输入</li><li id="ab83" class="lz ma iq lf b lg mi lj mj lm mk lq ml lu mm ly nb mf mg mh bi translated">通过这种实施方式，所有反向传播计算都可以通过使用方法<code class="fe mn mo mp mq b">r.backward()</code>简单地执行</li></ul><p id="2e8d" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="lf ir"> 5。总结</strong></p><p id="0eb0" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在本文中，我们使用反向传播来解决一个特定的数学问题——计算一个复函数的偏导数。然而，当你定义一个神经网络的架构时，你实际上是在创建一个计算图，这里看到的所有原则仍然适用。</p><p id="cbcf" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在NNs中，最终方程是您选择的损失函数，例如MSE、MAE和节点方程主要是权重/自变量的乘积，后跟各种激活函数(ReLu、tanh、softmax等)。)</p><p id="15fd" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">希望现在你能更有信心回答这个问题:反向传播是如何工作的，为什么我们需要它，以及如何在PyTorch中实现它。</p><p id="e4ac" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">编码快乐！</p></div></div>    
</body>
</html>