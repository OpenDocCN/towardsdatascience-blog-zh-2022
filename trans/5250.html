<html>
<head>
<title>Training an Energy Decision Agent With Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用强化学习训练能量决策智能体</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-an-energy-decision-agent-with-reinforcement-learning-a7567b61d0aa#2022-11-23">https://towardsdatascience.com/training-an-energy-decision-agent-with-reinforcement-learning-a7567b61d0aa#2022-11-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/35d68aba503d9393976a34613e03eafa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ta6yOf5C-qt6wxzJ"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">费德里科·贝卡里在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><div class=""/><div class=""><h2 id="10a2" class="pw-subtitle-paragraph kd jf jg bd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku dk translated">设置、培训过程和结果的高级概述</h2></div><p id="f387" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现实世界的强化学习应用很难找到。本文给出了<strong class="kx jh">构建一个 RL 代理的高层次概述，该代理旨在优化能源使用</strong>。本文分为以下几个部分:</p><ol class=""><li id="3864" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx jh">问题设置</strong> —明确问题和目标。</li><li id="bdd6" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">构建模拟环境</strong> —描述如何构建培训环境，包括代理的观察空间、行动空间和奖励。</li><li id="f47c" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">训练过程</strong> —训练中使用的框架、算法和训练过程的图表。</li><li id="ddf9" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">行动中的代理</strong> —一个训练有素的代理如何做出决策的例子。</li><li id="a69e" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx jh">结论</strong> —最终想法。</li></ol><h1 id="1613" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">问题设置</h1><p id="dc8e" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">我们有一个家庭<strong class="kx jh">用 12 kWp 单元</strong>产生自己的太阳能，并且能够<strong class="kx jh">将这种能量存储在家用电池中(容量为 13 kWh 的特斯拉 Powerwall 2)</strong>，这可以通过 API 来控制。该户的电力合同基于<strong class="kx jh">日前市场价格</strong>，该存储装置也可用于<strong class="kx jh">参与</strong> <a class="ae jd" href="https://www.next-kraftwerke.com/knowledge/afrr" rel="noopener ugc nofollow" target="_blank"> <strong class="kx jh">备用/备用</strong> </a> <strong class="kx jh">市场</strong>。</p><p id="eab6" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的目标是<strong class="kx jh">培训一个代理，通过</strong> <strong class="kx jh">控制电池</strong>考虑能源市场(日前市场、频率市场)、当地条件(例如，家庭的基本负荷)和用户偏好(例如，电池水平不能低于某个阈值)来最小化家庭的能源成本。</p><h1 id="a025" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">构建模拟环境</h1><p id="60cf" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">在强化学习中，主体通过在环境中做出动作、接受对这些动作的奖励/惩罚并相应地修改其动作模式(策略)来学习。</p><p id="16a4" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人们可以使用真实环境(真实的家庭和能源市场)或模拟环境。在这个项目中，建立了一个模拟环境，使用<a class="ae jd" href="https://github.com/openai/gym" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>作为框架。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/c7edfda14fe4e6f04c795db9e47fa22a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4izdbHvWYZJ1m7Y2iC01g.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">模拟环境是真实物理环境的数字表示，用于训练强化学习代理(图片由作者提供)。</p></figure><p id="322c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">开发能源决策代理的模拟环境包括以下步骤:</p><ol class=""><li id="3bd6" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated">用数字表示环境的当前情况(状态)。状态表示需要包含我们的代理培训所需的所有信息。</li><li id="a024" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">用数字表示可能的行为(我们的代理可以用我们的电池做的事情)。表示和更新家用电池的当前状态。</li><li id="8e5a" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated">发展一种逻辑，说明在环境中采取特定行动意味着什么。换句话说，表示当代理执行特定动作时，家庭、电池和能源成本会发生什么。</li></ol><p id="44b7" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总之，我们环境的程序表示包括大约 700 行代码(包括助手函数)。接下来，我将解释环境的一些关键部分。</p><h2 id="f1e2" class="nh mg jg bd mh ni nj dn ml nk nl dp mp le nm nn mr li no np mt lm nq nr mv ns bi translated">代表当前状态/观察</h2><p id="e01e" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">状态/观察是当前情况的数字表示。在我们的项目中，这意味着代表能源市场、家庭和资产的当前状态。</p><h2 id="e1e1" class="nh mg jg bd mh ni nj dn ml nk nl dp mp le nm nn mr li no np mt lm nq nr mv ns bi translated">当前状态的初始表示</h2><p id="b567" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">我们的初始(未修改的)观察空间由以下信息组成:</p><ul class=""><li id="034a" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq nt lx ly lz bi translated">未来一天能源市场价格的 12 小时预测，</li><li id="63c9" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">afrr_up 频率市场价格的 12 小时预测，</li><li id="ad0f" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">家庭消费的 12 小时预测，</li><li id="ff1b" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">当地太阳能生产的 12 小时预报，</li><li id="b89e" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">关于电池的信息(长度为 4 的向量):电池的容量(例如 13k wh)；电池的当前充电水平(例如 2 千瓦时)；最大充电功率(例如 5kw)；允许的最低充电水平(例如 1 千瓦时)。</li></ul><p id="0a4d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下面的代码块代表未修改的观察组件的一个示例:我们有 12 个前一天和后一天市场价格的预测值，相同数量的相应基本负载和 pv 产品值，以及 4 个代表电池信息的值。</p><pre class="nd ne nf ng gt nu nv nw bn nx ny bi"><span id="46e8" class="nz mg jg nv b be oa ob l oc od">'day_ahead': array([ 4, 6, 12, 41, -12, 18, 46, 69, 41, 65, 64, 22], dtype = int32)<br/>'afrr_up': array([ 0, 78, 62, 0, 0, 0, 0, 0, 0, 0, 0, 87], dtype=int32)<br/>'baseload': array([ 2, 10, 10, 4, 4, 3, 5, 4, 4, 4, 4, 9], dtype=int32)<br/>'pv': array([ 0, 1, 2, 4, 10, 4, 12, 6, 10, 5, 9, 0], dtype=int32)<br/>'bat': array([13., 2., 15., 1.], dtype=float32)</span></pre><h2 id="8973" class="nh mg jg bd mh ni nj dn ml nk nl dp mp le nm nn mr li no np mt lm nq nr mv ns bi translated">修改的观察空间</h2><p id="3bae" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">初始观察表示被修改，以便使它更容易被我们的代理用于学习的神经网络处理。每个观察值都经过了<strong class="kx jh">归一化</strong>(在 0 和 1 之间表示)和<strong class="kx jh">平坦化</strong>(作为单个向量而不是五个不同的向量给出)。修改后的观察结果如下所示:</p><pre class="nd ne nf ng gt nu nv nw bn nx ny bi"><span id="b9ef" class="nz mg jg nv b be oa ob l oc od">array([0.159375, 0.175 , 0.10625 , 0.09375 , 0.13125 , 0.084375, 0.096875, <br/>0.121875, 0.078125, 0.103125, 0.09375 , 0.19375 , 0.3 , 0.34375 , 0.0625 , <br/>0.0625 , 0.0625 , 0.0625 , 0.0625 , 0.0625 , 0.0625 , 0.365625, 0.375 , <br/>0.0625 , 0.5625 , 0.625 , 0.125 , 0.125 , 0.0625 , 0.0625 , 0.0625 , <br/>0.125 , 0.0625 , 0.6875 , 0.5625 , 0.375 , 0. , 0.0625 , 0. , 0. , <br/>0. , 0. , 0. , 0. , 0. , 0.125 , 0.0625 , 0.5 , 0.8125 , 0.125 , <br/>0.9375 , 0.0625 ])</span></pre><h2 id="9fc2" class="nh mg jg bd mh ni nj dn ml nk nl dp mp le nm nn mr li no np mt lm nq nr mv ns bi translated">行为空间</h2><p id="ecf5" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">动作空间表示代理可以做出的决策(动作)。我们的能量决策代理具有长度为 6 的离散动作空间。</p><pre class="nd ne nf ng gt nu nv nw bn nx ny bi"><span id="3472" class="nz mg jg nv b be oa ob l oc od">0: 'bat_from_grid' #battery is charged from the grid<br/>1: 'bat_to_grid' #battery sends energy to the grid <br/>2: 'bat_to_home' #battery fulfills household’s energy need <br/>3: 'bat_from_pv' #battery charges from solar panels production<br/>4: 'bat_afrr_up' #battery participates in afrr frequency market <br/>5: 'bat_idle' #battery doesn’t do anything (stays idle)</span></pre><p id="2d0c" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每个值(从 0 到 5)对应于代理可以对电池执行的操作之一。每个动作都会影响电池的充电状态，并具有相应的成本/收益。</p><p id="8abd" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">复杂性:一集是 24 小时，每小时我们有 6 个动作可以选择。我们有<strong class="kx jh"><em class="oe">4 738 381 338 321 616 896</em></strong><em class="oe">(4.7 万亿)种可能的方式在一集里使用这个电池。</em></p><h2 id="6fba" class="nh mg jg bd mh ni nj dn ml nk nl dp mp le nm nn mr li no np mt lm nq nr mv ns bi translated">报酬</h2><p id="2d6a" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">代理人<strong class="kx jh">在每一步</strong>都获得奖励，奖励等于家庭经历的能源成本。例如，如果代理决定行动值为 0:“bat _ from _ grid”，则最大可能数量的能量从电网充入电池，代理收到的奖励等于:<em class="oe">充电成本+家庭基本负载成本+光伏生产收入+ … </em></p><p id="2379" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">代理人的目标是<strong class="kx jh">最大化 24 小时时间跨度</strong>的回报(即:24 小时被定义为一集)。</p><h1 id="7d83" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">培训过程</h1><p id="b38b" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">在培训阶段，代理人在模拟环境中采取行动，并试图找到对家庭最有利的行动计划。在这个项目中，代理由 IMPALA 算法的<a class="ae jd" href="https://github.com/ray-project/ray/blob/master/rllib/algorithms/impala/impala.py" rel="noopener ugc nofollow" target="_blank"> RLLIB 实现来表示。IMPALA 能够同时训练多个 CPU 内核的代理。该项目中的设置包括 4 个核心/工作人员和每个工作人员 3 个环境。</a></p><p id="9c42" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图显示了培训过程中每集的平均奖励(以 100 集的平均值计算)。我们可以看到，代理进化得非常快，但在最初的两百万步训练中，策略(其决策模式)的稳定性相当低。在培训的最后阶段，我们的代理能够持续获得每集 1.5-1.6€的平均报酬。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/65f4f9581effe61f52ba55a81203a808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50LC9iY2ap5Y1LN3rtkcMQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">经纪人培训过程中的平均剧集奖励。平均回报代表家庭 24 小时的能源成本。正回报是指住户通过向电网售电挣钱(图片由作者提供)。</p></figure><h1 id="cacf" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">行动中的代理</h1><p id="f9c1" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">作为最后一步，让我们看看我们的代理为示例 24 小时期间建议的操作(下图)。“前一天”和“后一天”列代表这些小时的市场价格。基本负荷和光伏代表家庭的常规消耗和光伏生产(单位为 kWh)。“行动”栏显示我们的能源决策代理建议的行动/决策,“SoC”栏显示一小时结束时(执行建议的行动后)的电池电量(单位为 kWh)。</p><p id="5a3d" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">表中第一个突出显示的区域显示了我们的代理如何在高价时段(21、22、0 小时)在 afrr-up 市场上分配电池，并在当天价格较低的时段(28 和 4 小时)从电网充电。</p><figure class="nd ne nf ng gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/1f68aa0388a8a151146d4a7003dbac59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wb5pdRgnxUZUAn3skPbcGA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">经过培训的代理人的决策示例——我们可以看到，我们的代理人能够在不同的市场价格之间进行套利(作者列表)。</p></figure><p id="b198" class="pw-post-body-paragraph kv kw jg kx b ky kz kh la lb lc kk ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第二个突出显示的区域表明了我们代理人的纯市场价格套利——在高价时段(第 3 和第 5 小时)放电，在低价时段(第 4 和第 6 小时)充电。</p><h1 id="9fa4" class="mf mg jg bd mh mi mj mk ml mm mn mo mp km mq kn mr kp ms kq mt ks mu kt mv mw bi translated">结论</h1><p id="b6da" class="pw-post-body-paragraph kv kw jg kx b ky mx kh la lb my kk ld le mz lg lh li na lk ll lm nb lo lp lq ij bi translated">最后，我想强调以下几个方面:</p><ul class=""><li id="db53" class="lr ls jg kx b ky kz lb lc le lt li lu lm lv lq nt lx ly lz bi translated">强化学习可以用来训练能量决策智能体。</li><li id="ea24" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">构建强化学习的现实应用的关键在于构建一个与物理世界非常相似的训练环境。</li><li id="8852" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">RL 代理不能保证最优性，并且对环境中的微小变化非常敏感。</li><li id="2d00" class="lr ls jg kx b ky ma lb mb le mc li md lm me lq nt lx ly lz bi translated">好好想想。也许你的问题可以用更简单的方法解决！</li></ul></div></div>    
</body>
</html>