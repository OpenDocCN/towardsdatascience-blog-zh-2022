<html>
<head>
<title>Why Graph-modeling Frameworks are the Future of Unsupervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么图建模框架是无监督学习的未来</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-graph-modeling-frameworks-are-the-future-of-unsupervised-learning-2092b089caff#2022-04-25">https://towardsdatascience.com/why-graph-modeling-frameworks-are-the-future-of-unsupervised-learning-2092b089caff#2022-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9c1c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">用于在无监督学习场景中估计特征重要性的迭代图建模方法</em></h2></div><p id="6a9a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">由拜耳制药公司的机器学习工程师<a class="ae lc" href="https://www.linkedin.com/in/abhishek-singh-8997a215/" rel="noopener ugc nofollow" target="_blank"> Abhishek Singh </a>，前微软、摩根大通&amp;公司、汇丰银行和拜耳制药公司的数字健康数据科学<a class="ae lc" href="https://ch.linkedin.com/in/cristiana-de-azevedo" rel="noopener ugc nofollow" target="_blank">Cristiana de aze vedo von Stosch合著。</a></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/4d3dea3146524826c386e1c8c7e5ed4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/0*421fx5ZOlXTCRGSl.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">在Titanic数据集上迭代有向图方法。图片作者。</p></figure><p id="7cfd" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><em class="lp">并非所有的特征都是相同的</em>。此外，特征确定重要性仍然是机器学习中的一个基本问题。</p><p id="460c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">监督学习中的大多数特征重要性方法依赖于目标特征。然而，如果目标特征不存在，并且仅存在独立特征，则计算特征重要性是一个挑战。</p><p id="20f4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">像图建模这样的新技术已经揭示了在无监督学习应用中发现特征重要性。</p><h1 id="4699" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">图建模框架的案例</strong></h1><p id="9951" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">如果对于样本数量而言，您有太多的特征，或者想要移除共线特征以改进模型，有许多技术可以应用于监督学习设置中，如决策树、随机森林等。</p><p id="0375" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">到目前为止，很少有方法可以识别无监督学习问题中的特征重要性。</p><p id="ad58" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">基于特征重要性确定的特征选择将减少任何建模方法的处理时间。在无监督的学习设置中，特征重要性方法可以被应用于寻找最小的特征子集，该子集最好地从数据中揭示有趣的自然分组。</p><h1 id="2ce1" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">为特征重要性确定创建图建模框架的7个步骤</strong></h1><p id="964f" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">想用这种方法创建自己的图形建模框架吗？按照我们下面的步骤，开始为你的无监督学习排名问题创建解决方案！</p><p id="cb82" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于这个实验，我们应用了这些方法:我们提出的排序方法、随机森林、决策树和使用高尔距离的聚类。</p><p id="7857" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">对于数据，我们使用了来自<a class="ae lc" href="https://archive.ics.uci.edu/ml/datasets.php" rel="noopener ugc nofollow" target="_blank"> UCI ML数据集</a> : <a class="ae lc" href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer?ref=datanews.io" rel="noopener ugc nofollow" target="_blank">乳腺癌</a>，<a class="ae lc" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜</a>，<a class="ae lc" href="https://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset" rel="noopener ugc nofollow" target="_blank">免疫疗法</a>，<a class="ae lc" href="https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume" rel="noopener ugc nofollow" target="_blank">地铁州际交通</a>的4个数据集，以及著名的<a class="ae lc" href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=40945&amp;status=active" rel="noopener ugc nofollow" target="_blank">泰坦尼克号</a>个体乘客生存状态数据集。</p><p id="68de" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这个实验是在Python中运行的，使用随机森林和决策树算法及其默认的内部参数。这个项目的代码是GitHub 上的<a class="ae lc" href="https://github.com/abhisheksinghocp/Python_Graph" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="6cc6" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated">准备数据</h1><p id="4f55" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">我们希望通过开始处理列在数据集中出现的顺序来创建一个有向图。这些柱子将成为我们的节点。有向边允许在任何数字和/或分类数据集上创建图形。</p><p id="48b0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们将把五个数据集的列转换成虚拟列，并包括基本列和属性。在没有分类列的情况下，可以将连续属性放入虚拟列中。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/982d679ab0e6842323baf32fdb101a2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/0*RoaX4Efjz7os7aOx.jpeg"/></div><p class="ll lm gj gh gi ln lo bd b be z dk translated">有向图的基本元素:节点和有向边。图片作者。</p></figure><h1 id="b80d" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">逐步创建您的图表</strong></h1><p id="2693" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">要在无监督学习中利用图表方法创建用于特征选择的节点，请遵循以下方法。</p><ol class=""><li id="ea3f" class="mo mp iq ki b kj kk km kn kp mq kt mr kx ms lb mt mu mv mw bi translated">将所有列和行作为节点和边转换成有向图。将属性顺序设置为未排序(<a class="ae lc" href="https://github.com/abhisheksinghocp/Python_Graph/blob/master/3_Iris_data_Graph_Creation_variable_selection.ipynb" rel="noopener ugc nofollow" target="_blank">单元格#10 </a>)。</li><li id="426d" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">使用Google PageRank计算每个节点的排名，确定排名最高的节点(<a class="ae lc" href="https://github.com/abhisheksinghocp/Python_Graph/blob/master/3_Iris_data_Graph_Creation_variable_selection.ipynb" rel="noopener ugc nofollow" target="_blank"> cell #14 </a>)。</li><li id="38e3" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">将此节点设置为图形中的起始节点。再次构建图表(<a class="ae lc" href="https://github.com/abhisheksinghocp/Python_Graph/blob/master/3_Iris_data_Graph_Creation_variable_selection.ipynb" rel="noopener ugc nofollow" target="_blank">单元格#14 </a>)。</li><li id="0cd3" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">重复这个过程<em class="lp"> n- </em>次。在这种情况下，<em class="lp"> n </em>是独立特征的数量。对于每次迭代，创建一个m*n大小的矩阵(m =节点数，n =迭代次数)。</li><li id="53f8" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">存储所有迭代中每个虚拟特征的最小分数。</li><li id="94d7" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">计算每组假人在每个特征级别的总和。</li><li id="c1c5" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb mt mu mv mw bi translated">按升序对模型的输出(特征)进行排序，并对其进行排名。</li></ol><p id="e8f7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">自己尝试一下，看看你的结果会把你带到哪里！</p><h1 id="41ae" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">评估结果:监督学习与提议的排序方法</strong></h1><p id="555c" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">在下图中，您可以看到在乳腺癌、Titanic和Iris数据集中运行的特征排名结果。我们比较了两种监督方法(随机森林，决策树)和提出的排序方法。在每个表中，显示了由三种算法中的每一种算法识别的前9、6和4个特征。</p><p id="bf4b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">排名结果显示在梯度热图表中。在我们的实验中，我们用深绿色表示最重要的特征，用红色表示最不重要的特征。</p><p id="1fc9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">尽管这三种算法返回的特征排序略有不同，但所提出的排序方法能够在所有实验中识别排名最高的特征。</p><div class="le lf lg lh gt ab cb"><figure class="nc li nd ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/5c35cb4cdf13a6e9cba3b30ca211432b.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*76PMQtvwBOEHhuvjmHnB3A.png"/></div></figure><figure class="nc li nm ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/24ef39910818e8d18742d1ff7b29ae4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*0pGRYgxrNwHplGUf1qA5Ow.png"/></div></figure><figure class="nc li nn ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/64df666d4da8b67ed010f2ba8238381c.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*_dPJ39kJuxqzHhxakELJ-w.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk no di np nq translated">使用乳腺癌、Titanic和Iris数据集的随机森林、决策树和提议的排序方法实验的排序结果。在每个表中，显示了由三种算法中的每一种算法识别的前9、6和4个特征。</p></figure></div><h1 id="59ee" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">聚类排名靠前的数据集</strong></h1><p id="6eb6" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">为了进一步比较从我们提出的排序方法得到的排名靠前的结果与其他金标准方法的“适合度”，我们将使用不同的数据子集运行聚类算法，以比较聚类的可分性。</p><p id="f77c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">引入聚类</strong></p><p id="b60b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">聚类采用整个数据集并识别集合的可分性。然而，聚类方法无法确定重要性的顺序。在群集技术中，数据集中的记录被组织到不同的逻辑分组中。数据分组的方式是同一组内的记录比组外的记录更相似。聚类根据相似性矩阵自动将数据集分成不同的组。</p><p id="97b3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">聚类方法使用逻辑分组。因此，不能提取关于特征重要性的信息。如果没有排名方法，就需要分析所有列的维度和数据项，这非常耗时。</p><p id="63e9" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">类似地，聚类是比较所提出的排序方法和随机森林结果以及评估它们的可分性适合度的有用工具。</p><p id="772e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">不同数据集的聚类</strong></p><p id="4edc" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了进一步分析我们的发现，我们使用三组排名靠前的特征来执行五组聚类实验。在我们的聚类算法中，我们使用高尔距离来计算两个实体之间的距离，这两个实体的属性中都有混合的分类值和数值。</p><p id="2037" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">聚类方法的有效性取决于“距离”的定义。如果这个属性不存在，就必须定义它，这并不容易，尤其是在多维场景中。</p><p id="00a4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">通过参考轮廓宽度，可以显示一个聚类中的点与相邻聚类的接近度。这样做提供了一种可视化评估和分析集群数量的方法。</p><p id="a24f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">例如，该度量的范围为[-1，1]。查看轮廓系数时，有几个关键点需要考虑。</p><ul class=""><li id="4ce6" class="mo mp iq ki b kj kk km kn kp mq kt mr kx ms lb nr mu mv mw bi translated">Near +1:表示样本远离相邻聚类。</li><li id="aa6b" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb nr mu mv mw bi translated">0:表示样本位于或非常接近两个相邻分类之间的判定边界。</li><li id="e493" class="mo mp iq ki b kj mx km my kp mz kt na kx nb lb nr mu mv mw bi translated">Near -1:表示样本可能被分配到了错误的簇。</li></ul><div class="le lf lg lh gt ab cb"><figure class="nc li ns ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/22071de814da64dab48874ca028ffb5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*5zSBvGkhW2CvV--LEOCXSg.png"/></div></figure><figure class="nc li nt ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/efdc3c674afb900a12de16112acff22e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*TBSeJM9RX4yS24QsKQcXKQ.png"/></div></figure><figure class="nc li nt ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/ae53fe0b177f03ca83d3f50fa048026f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BE-p642rBkCNCJFEeRZdTQ.png"/></div></figure></div><div class="ab cb"><figure class="nc li nu ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/4cde62da9e84540adf6819d818ca1d8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*Qlb_55AgyTv8jM7Hz7G_Cg.png"/></div></figure><figure class="nc li nv ne nf ng nh paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><img src="../Images/f642d096d4105a8121a90b85a48655b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*hs8acerqRqTB3LRORQJkdQ.png"/></div><p class="ll lm gj gh gi ln lo bd b be z dk nw di nx nq translated">轮廓宽度图与每个聚类实验中的聚类数，对5个数据集的每个数据集运行不同的特征。使用绿色(o)标绘的所有特征，使用红色(#)标绘的建议分级方法的顶部特征，蓝色(#)标绘的建议分级方法的顶部特征，黄色(x)标绘的随机森林的顶部特征，绿色(x)标绘的随机森林的顶部特征。水平虚线表示轮廓宽度为0.2的基准阈值，这是“好的”可分离性的阈值，用于选择最佳的聚类数目:高于0.2，模型具有好的可分离性，低于差的可分离性。离这个阈值越远，模型的可分性越好。</p></figure></div><p id="3fd0" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">使用上图中的信息，数据显示所提出的分级方法产生了排名靠前的特征片段。当在聚类方法中使用时，而不是来自随机森林示例的排名靠前的特征段，可分性更容易识别。在该练习的所有运行中，使用所提出的排序方法的顶部特征的聚类实验的轮廓宽度系数总是高于使用来自随机森林方法的顶部特征时的轮廓宽度系数。</p><h1 id="c826" class="lq lr iq bd ls lt lu lv lw lx ly lz ma jw mb jx mc jz md ka me kc mf kd mg mh bi translated"><strong class="ak">图形建模概要</strong></h1><p id="94c7" class="pw-post-body-paragraph kg kh iq ki b kj mi jr kl km mj ju ko kp mk kr ks kt ml kv kw kx mm kz la lb ij bi translated">我们提出了一种新的图建模方法，该方法可以在没有目标特征的情况下识别数据集的特征重要性。在本文中，我们提出的排名方法使用数据集运行，目标特征列从其数据集“隐藏”，我们计算它们的特征重要性以及常用的监督方法(不隐藏目标列)。</p><p id="c5d5" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在使用监督方法和提议的排序方法确定最有影响力的特征的排序之后，所有方法在其最高特征重要性顺序中包含大量重叠。</p><p id="187c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们的框架试图用图建模来弥合监督和非监督特征选择方法之间的差距。在无监督的设置中实现我们提出的基于图的排序方法允许识别特征的重要性。与随机森林和决策树相比，这些排名靠前的功能还提供了更好的聚类。</p><p id="1ca3" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">虽然仍有许多研究要做，但基于图论的特征重要性识别可以扩展到半监督学习设置。</p><p id="9f8e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">利益冲突</strong></p><p id="0c37" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这项工作基于个人实验、研究和公开可用的数据集，与现任或前任雇主的数据没有任何联系。如有任何出版或专利目的，请联系作者。</p><p id="9caf" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><strong class="ki ir">作者投稿</strong></p><p id="592c" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated"><a class="ae lc" href="https://ch.linkedin.com/in/cristiana-de-azevedo" rel="noopener ugc nofollow" target="_blank">克里斯蒂安娜·德·阿泽维多·冯·斯托施</a>进行文献综述，撰写手稿，并提供概念指导。Abhishek Singh(<a class="ny nz ep" href="https://medium.com/u/2afe5c904a53?source=post_page-----2092b089caff--------------------------------" rel="noopener" target="_blank">Abhishek Singh</a>)编写代码并运行实验。马修·埃利斯·普里查德编辑了这篇文章。</p></div></div>    
</body>
</html>