<html>
<head>
<title>Breaking it Down: Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分解它:逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/breaking-it-down-logistic-regression-e5c3f1450bd#2022-08-19">https://towardsdatascience.com/breaking-it-down-logistic-regression-e5c3f1450bd#2022-08-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="aa07" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用NumPy、TensorFlow和UCI心脏病数据集探索逻辑回归的基本原理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0410d9680ecaefc0a16a0dbf41008556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7EZfRPFHzY0NJN7YfdEYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">逻辑回归概述。图片作者。</p></figure><pre class="kj kk kl km gt ky kz la lb aw lc bi"><span id="dd49" class="ld le it kz b gy lf lg l lh li"><strong class="kz iu">Outline:<br/></strong>1. <a class="ae lj" href="#6a7a" rel="noopener ugc nofollow">What is Logistic Regression?<br/></a>2. <a class="ae lj" href="#c9d3" rel="noopener ugc nofollow">Breaking Down Logistic Regression</a><br/>   1. <a class="ae lj" href="#9cd1" rel="noopener ugc nofollow">Linear Transformation</a><br/>   2. <a class="ae lj" href="#bd84" rel="noopener ugc nofollow">Sigmoid Activation</a><br/>   3. <a class="ae lj" href="#43d1" rel="noopener ugc nofollow">Cross-Entropy Loss Function</a><br/>   4. <a class="ae lj" href="#cee3" rel="noopener ugc nofollow">Gradient Descent</a><br/>   5. <a class="ae lj" href="#3930" rel="noopener ugc nofollow">Fitting the Model</a><br/>3. <a class="ae lj" href="#6f98" rel="noopener ugc nofollow">Learning by Example with the UCI Heart Disease Dataset</a><br/>4. <a class="ae lj" href="#84da" rel="noopener ugc nofollow">Training and Testing Our Classifier<br/></a>5. <a class="ae lj" href="#e0fa" rel="noopener ugc nofollow">Implementing Logistic Regression with TensorFlow</a><br/>6. Summary<br/>7. <a class="ae lj" href="#df98" rel="noopener ugc nofollow">Notes and Resources</a></span></pre><h1 id="6a7a" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">1.什么是逻辑回归？</h1><p id="8270" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated"><a class="ae lj" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>是一种受监督的机器学习算法，它为输入数据集创建分类标签(<a class="ae lj" href="https://web.stanford.edu/~jurafsky/slp3/5.pdf" rel="noopener ugc nofollow" target="_blank"> 1 </a>、<a class="ae lj" href="https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf" rel="noopener ugc nofollow" target="_blank"> 2 </a>)。逻辑回归(logit)模型在各种环境中使用，包括<a class="ae lj" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7785709/" rel="noopener ugc nofollow" target="_blank">医疗</a>、<a class="ae lj" href="https://www.researchgate.net/publication/263933254_Association_between_light_exposure_at_night_and_insomnia_in_the_general_elderly_population_The_HEIJO-KYO_cohort" rel="noopener ugc nofollow" target="_blank">研究</a>和<a class="ae lj" href="http://www.computerscijournal.org/vol10no1/churn-analysis-in-telecommunication-using-logistic-regression/" rel="noopener ugc nofollow" target="_blank">商业</a>分析。</p><p id="8def" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">理解逻辑回归背后的逻辑可以为深度学习的基础提供强有力的基础见解。</p><p id="5320" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在本文中，我们将分解逻辑回归来获得对这个概念的基本理解。为此，我们将:</p><ol class=""><li id="33db" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated">探索逻辑回归的基本组件，并使用NumPy从头开始构建模型</li><li id="756a" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">在UCI心脏病数据集上训练我们的模型，以根据成人的输入健康数据预测他们是否患有心脏病</li><li id="dede" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">使用TensorFlow构建“正式”logit模型</li></ol><p id="15cb" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">你可以用我的演练<a class="ae lj" href="https://github.com/JacobBumgarner/learning-repo/blob/main/logistic_regression/logistic_regression_walkthrough.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>和我的<a class="ae lj" href="https://github.com/JacobBumgarner/learning-repo" rel="noopener ugc nofollow" target="_blank"> GitHub </a> learning-repo中的<a class="ae lj" href="https://github.com/JacobBumgarner/learning-repo/blob/main/logistic_regression/logistic_regression.py" rel="noopener ugc nofollow" target="_blank"> Python </a>脚本文件来遵循这篇文章中的代码。</p><h1 id="c9d3" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">2.分解逻辑回归</h1><p id="fa5f" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">逻辑回归模型为输入数据集创建概率标签。这些标签通常是二元的(是/否)。</p><p id="6221" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们通过一个例子来突出逻辑回归的主要方面，然后我们将开始我们的深入研究:</p><blockquote class="nq nr ns"><p id="2dee" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated">想象一下，我们有一个logit模型，它被训练来预测某人是否患有糖尿病。模型的输入数据是一个人的<strong class="md iu">年龄</strong>、<strong class="md iu">身高</strong>、<strong class="md iu">体重</strong>和<strong class="md iu">血糖</strong>。为了进行预测，模型将使用<strong class="md iu">逻辑</strong>T10】函数转换这些输入数据。该函数的输出将是在<strong class="md iu"> 0 </strong>和<strong class="md iu"> 1之间的概率标签。</strong>这个标签离<strong class="md iu"> 1 </strong>越近，模型对这个人<strong class="md iu">有糖尿病</strong>的把握就越大，反之亦然。</p><p id="8410" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated">重要的是:为了创建分类标签，我们的糖尿病logit模型首先必须<strong class="md iu">学习</strong>如何衡量每条输入数据的重要性。为了预测糖尿病，很可能某人的血糖<strong class="md iu">比其身高<strong class="md iu">高</strong>。这种学习使用一组标记的测试数据和梯度下降来进行。学习到的信息以逻辑函数中使用的<strong class="md iu">权重<em class="it"> </em> </strong>和<strong class="md iu">偏差<em class="it"> </em> </strong>参数值的形式存储在模型中。</strong></p></blockquote><p id="a984" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这个例子提供了逻辑回归模型做什么以及它们如何工作的卫星视图概要。我们现在准备好进行深潜了。</p><p id="30b6" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了开始我们的深入探讨，让我们来分解逻辑回归的核心部分:逻辑函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="7159" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">我们将使用NumPy从头开始构建自己的logit模型，而不仅仅是从阅读中学习。这将是模型的轮廓:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><p id="2c79" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在第<strong class="md iu"> 2.1节</strong>和第<strong class="md iu"> 2.2节</strong>中，我们将实现线性和sigmoid变换函数。</p><p id="b56a" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">在<strong class="md iu"> 2.3 </strong>中，我们将定义<strong class="md iu">交叉熵成本函数</strong>，以告知模型其预测何时为“好”和“坏”。在第<strong class="md iu"> 2.4节</strong>中，我们将通过梯度下降帮助模型学习其参数。</p><p id="6b0e" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">最后，在第<strong class="md iu"> 2.5节</strong>中，我们将把所有这些功能联系在一起。</p><h2 id="9cd1" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">2.1线性变换</h2><p id="fef3" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">正如我们在上面看到的，逻辑函数首先使用其学习到的参数将<strong class="md iu">线性变换</strong>应用于输入数据:权重<strong class="md iu">和偏差</strong>。</p><p id="799e" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu">权重</strong> ( <strong class="md iu"> <em class="nt"> W </em> </strong>)参数表示每条输入数据对分类的重要性。个体重量越接近<strong class="md iu"> 0 </strong>，相应的数据对分类越不重要。<strong class="md iu">权重</strong>向量和输入数据<strong class="md iu"> X </strong>的点积将数据展平成一个标量，我们可以将它放在一个数轴上。</p><blockquote class="nq nr ns"><p id="813e" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated">例如，如果我们试图根据一个人的身高和醒着的时间来预测他是否疲劳，那么这个人的身高权重将非常接近于零。</p></blockquote><p id="6968" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu">bias</strong>(<strong class="md iu"><em class="nt">b</em></strong>)参数用于沿该行的判定边界(<strong class="md iu"> 0 </strong>)移动该标量。</p><p id="ca23" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu">让我们想象一下逻辑函数的线性分量如何使用其学习到的权重和偏差来转换来自UCI心脏病数据集的输入数据。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="5c71" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">我们现在准备开始填充模型的函数。首先，我们需要用它的<strong class="md iu">权重</strong>和<strong class="md iu">偏差</strong>参数初始化我们的模型。<strong class="md iu">权重</strong>参数将是一个<code class="fe ol om on kz b">(n, 1)</code>形状的数组，其中<code class="fe ol om on kz b">n</code>等于输入数据中的特征数量。<strong class="md iu">偏置</strong>参数是一个标量。两个参数都将被初始化为<strong class="md iu"> <em class="nt"> 0。</em> </strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><p id="158f" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">接下来，我们可以填充函数来计算逻辑函数的线性部分。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><h2 id="bd84" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">2.2乙状结肠激活</h2><p id="a8dc" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">逻辑模型通过将<strong class="md iu"> sigmoid函数</strong>应用于逻辑函数线性变换的输出数据来创建概率标签(<strong class="md iu"> <em class="nt"> ŷ </em> </strong>)。sigmoid函数对于从输入数据创建概率很有用，因为它压缩输入数据以产生介于<strong class="md iu"> <em class="nt"> 0 </em> </strong>和<strong class="md iu"> <em class="nt"> 1 </em> </strong>之间的值。</p><blockquote class="nq nr ns"><p id="6338" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated">sigmoid函数是logit函数的逆函数，因此得名逻辑回归。</p></blockquote><p id="8ab9" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了从sigmoid函数的输出中创建二进制标签，我们将决策边界定义为<strong class="md iu"> <em class="nt"> 0.5 </em> </strong>。这意味着如果<strong class="md iu"> <em class="nt"> ŷ ≥ 0.5 </em> </strong>，我们说标号是<em class="nt">正</em>，当<strong class="md iu"> <em class="nt"> ŷ &lt; 0.5 </em> </strong>时，我们说标号是<em class="nt">负</em>。</p><p id="630a" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu">让我们想象一下sigmoid函数是如何将输入数据从逻辑函数的线性分量转换而来的。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="5b18" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">现在，让我们在模型中实现这个函数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><h2 id="43d1" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">2.3交叉熵成本函数</h2><p id="752b" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">为了教会我们的模型如何优化其<strong class="md iu"> <em class="nt">权重</em> </strong>和<strong class="md iu"> <em class="nt">偏差</em> </strong>参数，我们将输入训练数据。然而，为了让模型<em class="nt">学习</em>最优参数，它必须知道如何判断其参数在生成概率标签方面是“好”还是“坏”。</p><p id="a0ba" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这个“良好”因子，或者概率标签和真实标签之间的差异，被称为单个样本的<em class="nt">损失</em>。我们在操作上说，如果参数在预测标签时表现不佳，损失应该是高的，如果表现良好，损失应该是低的。</p><p id="e500" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">然后对训练数据上的损失进行平均，以产生<em class="nt">成本</em>。</p><p id="1068" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">逻辑回归采用的函数是<strong class="md iu">交叉熵成本函数</strong>。在下面的函数中，<strong class="md iu"> <em class="nt"> Y </em> </strong>是地面真实标签，<strong class="md iu"> <em class="nt"> A </em> </strong>是我们的概率标签。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/0ae43a076826468ff1f6395e7fc575e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7QU_qx5Lir8Baukay1sew@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">交叉熵代价函数</p></figure><p id="0f85" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">注意，该函数根据<strong class="md iu"> <em class="nt"> y </em> </strong>是<strong class="md iu"> <em class="nt"> 1 </em> </strong>还是<strong class="md iu"> <em class="nt"> 0 </em> </strong>而变化。</p><ul class=""><li id="28e3" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw op ni nj nk bi translated">当<strong class="md iu"> <em class="nt"> y = 1 </em> </strong>时，该函数计算标签的<strong class="md iu"> <em class="nt">日志</em> </strong>。如果预测正确，则<em class="nt">损失</em>将为<strong class="md iu"> <em class="nt"> 0 </em> </strong>(即<strong class="md iu"> <em class="nt"> log(1) = 0 </em> </strong>)。如果不正确，随着预测越来越接近<strong class="md iu"> <em class="nt"> 0 </em> </strong>，损失会越来越大。</li><li id="c8cf" class="nc nd it md b me nl mh nm mk nn mo no ms np mw op ni nj nk bi translated">当<strong class="md iu"> <em class="nt"> y = 0 </em> </strong>时，该函数从<strong class="md iu"> <em class="nt"> y </em> </strong>中减去<strong class="md iu"> <em class="nt"> 1 </em> </strong>，然后计算标签的<strong class="md iu"> <em class="nt"> log </em> </strong>。这种减法使正确预测的损耗<em class="nt">保持为低</em>而不正确预测的损耗<em class="nt">保持为高</em>。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/b4cd4c1c53319a75bd652bf26f612dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MS74vmgcqyNm1WE2VaLPmw@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">1和0地面真实标签的交叉熵情况</p></figure><p id="cbec" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">现在让我们填充函数来计算输入数据数组的交叉熵成本。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><h2 id="cee3" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">2.4梯度下降</h2><p id="1bdd" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">既然我们可以计算模型的成本，我们必须使用成本通过梯度下降来“调整”模型的参数。如果你需要梯度下降的复习，看看我的<a class="ae lj" href="https://pub.towardsai.net/breaking-it-down-gradient-descent-b94c124f1dfd" rel="noopener ugc nofollow" target="_blank"> <em class="nt">分解:梯度下降</em> </a>帖子。</p><p id="5564" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们创建一个假的场景:想象我们正在训练一个模型来预测一个成年人是否累了。我们的伪模型只得到两个输入特征:<code class="fe ol om on kz b">height</code>和<code class="fe ol om on kz b">hours spent awake</code>。为了准确预测一个成年人是否累了，该模型可能应该为<code class="fe ol om on kz b">height</code>特征开发一个非常小的权重，而为<code class="fe ol om on kz b">hours spent awake</code>特征开发一个大得多的权重。</p><p id="74da" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">梯度下降将使这些参数<em class="nt">下降</em>它们的梯度，这样它们的新值将产生更小的成本。记住，梯度下降使函数的输出最小化。我们可以想象下面的例子。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi or"><img src="../Images/4938b8da5632a3895d024861d9bbae0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*XADsxfdOrrIWT8_Ql-8gWQ.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">梯度下降示例</p></figure><p id="3d8d" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了计算成本函数w . r . t .<strong class="md iu"><em class="nt">权重</em> </strong>和<strong class="md iu"> <em class="nt">偏差</em> </strong>的梯度，我们必须实现<a class="ae lj" href="https://www.khanacademy.org/math/ap-calculus-ab/ab-differentiation-2-new/ab-3-1a/a/chain-rule-review" rel="noopener ugc nofollow" target="_blank">链式规则</a>。为了找到我们参数的梯度，我们将区分成本函数和sigmoid函数，以找到它们的乘积。然后我们将分别区分线性函数w . r . t .<strong class="md iu"><em class="nt">权重</em> </strong>和<strong class="md iu"> <em class="nt">偏差</em> </strong>函数。</p><p id="f895" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu">让我们探索一下逻辑回归偏微分的直观证明:</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="b72f" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们实现这些简化的等式来计算训练示例中每个参数的平均梯度。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><h1 id="3930" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">2.5拟合模型</h1><p id="9f69" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">最后，我们已经为我们的模型构建了所有必要的组件，所以现在我们需要集成它们。我们将创建一个与<em class="nt">批次</em>和<em class="nt">小型批次</em>梯度下降兼容的函数。</p><ul class=""><li id="6e37" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw op ni nj nk bi translated">在<em class="nt">批量梯度下降</em>中，每个训练样本用于更新模型的参数。</li><li id="f758" class="nc nd it md b me nl mh nm mk nn mo no ms np mw op ni nj nk bi translated">在<em class="nt">小批量梯度下降</em>中，选择训练样本的随机部分来更新参数。小批量选择在这里并不重要，但是当训练数据太大而不适合GPU/RAM时，它非常有用。</li></ul><p id="7601" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">提醒一下，拟合模型是一个三步迭代过程:</p><ol class=""><li id="75f0" class="nc nd it md b me mx mh my mk ne mo nf ms ng mw nh ni nj nk bi translated">用<strong class="md iu"> <em class="nt">权重</em> </strong>和<strong class="md iu"> <em class="nt">偏差</em> </strong>对输入数据应用线性变换</li><li id="6df3" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">应用非线性sigmoid变换来获取概率标签。</li><li id="9837" class="nc nd it md b me nl mh nm mk nn mo no ms np mw nh ni nj nk bi translated">计算成本函数w.r.t <strong class="md iu"> <em class="nt"> W </em> </strong>和<strong class="md iu"> <em class="nt"> b </em> </strong>的梯度，并逐步降低这些参数的梯度。</li></ol><p id="78c3" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们来构建函数！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><h1 id="6f98" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">3.UCI心脏病数据集的实例学习</h1><p id="c63f" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">为了确保我们不只是孤立地创建一个模型，让我们用一个示例人类数据集来训练该模型。在临床健康的背景下，我们将训练的模型可以提高医生对患者健康风险的认识。</p><p id="9428" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们通过<a class="ae lj" href="https://archive.ics.uci.edu/ml/datasets/heart+disease" rel="noopener ugc nofollow" target="_blank"> UCI心脏病数据集</a>的例子来学习。</p><p id="94f6" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">数据集包含关于成年患者心脏和身体健康的<strong class="md iu"> 13 </strong>特征。每个样本还贴有标签，以表明受试者<em class="nt">是否患有</em>或<em class="nt">是否患有</em>心脏病。</p><p id="dd37" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">首先，我们将加载数据集，检查它是否缺少数据，并检查我们的要素列。重要的是，标签在这个数据集中是颠倒的(例如，1 =没有疾病，0 =疾病)，所以我们必须解决这个问题。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><pre class="kj kk kl km gt ky kz la lb aw lc bi"><span id="fb1b" class="ld le it kz b gy lf lg l lh li">Number of subjects: 303<br/>Percentage of subjects diagnosed with heart disease:  45.54%<br/>Number of NaN values in the dataset: 0</span></pre><p id="3944" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">让我们也把特征形象化。我已经创建了自定义人物，但是在这里看到我的<a class="ae lj" href="https://gist.github.com/JacobBumgarner/48cdb6c374d14dac83c5a933baac267f" rel="noopener ugc nofollow" target="_blank">要点</a>用Seaborn创建你自己的人物。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi os"><img src="../Images/502af24f395248838367888f8d7d3d42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5RKs6Q3HUQ5GRyyAaWJXhg.png"/></div></div></figure><p id="ce50" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">根据我们的检查，我们可以得出结论，没有明显的缺失特征。我们还可以看到，在几个特征中存在一些stark组分离，包括年龄(<code class="fe ol om on kz b">age</code>)、运动诱发的心绞痛(<code class="fe ol om on kz b">exang</code>)、胸痛(<code class="fe ol om on kz b">cp</code>)和运动期间的心电图形状(<code class="fe ol om on kz b">oldpeak</code> &amp; <code class="fe ol om on kz b">slope</code>)。这些数据将有助于训练logit模型！</p><p id="9b14" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了结束这一部分，我们将完成数据集的准备。首先，我们将对数据进行75/25分割，以创建<a class="ae lj" rel="noopener" target="_blank" href="/train-test-split-and-cross-validation-in-python-80b61beca4b6">测试和训练集</a>。然后我们将标准化*下面列出的连续特性。</p><p id="ba6e" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><code class="fe ol om on kz b">to_standardize = ["age", "trestbps", "chol", "thalach", "oldpeak"]</code></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><blockquote class="nq nr ns"><p id="359c" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated">*除非您正在运行某种形式的正则化，否则您不必对logit模型的数据进行标准化。我在这里这样做只是作为一种最佳实践。</p></blockquote><h2 id="84da" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">4.训练和测试我们的分类器</h2><p id="2b91" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">现在，我们已经构建了模型并准备好了数据集，让我们训练模型来预测健康标签。</p><p id="b152" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">我们将实例化模型，用我们的<code class="fe ol om on kz b">x_train</code>和<code class="fe ol om on kz b">y_train</code>数据训练它，并用<code class="fe ol om on kz b">x_test</code>和<code class="fe ol om on kz b">y_test</code>数据测试它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><pre class="kj kk kl km gt ky kz la lb aw lc bi"><span id="ef32" class="ld le it kz b gy lf lg l lh li">Final model cost: 0.36<br/>Model test prediction accuracy: 86.84%</span></pre><p id="e288" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">这就是我们得到的结果:测试集的准确率为86.8% 。这比50%的随机几率要好得多，对于这么简单的模型，准确率还是挺高的。</p><p id="895c" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了更仔细地观察事物，让我们在模型的训练过程中可视化模型的特征。在第一行，我们可以看到模型在训练过程中的成本和准确性。然后在最下面一行，我们可以看到<strong class="md iu"> <em class="nt">权重</em> </strong>和<strong class="md iu"> <em class="nt">偏差</em> </strong>参数在训练过程中是如何变化的(我最喜欢的部分！).</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ot ny l"/></div></figure><h2 id="e0fa" class="ld le it bd ll oa ob dn lp oc od dp lt mk oe of lv mo og oh lx ms oi oj lz ok bi translated">5.用TensorFlow实现逻辑回归</h2><p id="cb5d" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">在现实世界中，当您需要使用模型时，最好不要构建自己的模型。相反，我们可以依赖功能强大、设计良好的开源软件包，如TensorFlow、PyTorch或scikit-learn来满足我们的ML/DL需求。</p><p id="eac4" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">下面，我们来看看用TensorFlow建立一个logit模型，并将它的训练/测试结果与我们自己的进行比较是多么简单。我们将准备数据，创建一个具有sigmoid激活的单层单单元模型，并使用二元交叉熵损失函数编译它。最后，我们将拟合和评估模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nz ny l"/></div></figure><pre class="kj kk kl km gt ky kz la lb aw lc bi"><span id="4c21" class="ld le it kz b gy lf lg l lh li">Epoch 5000/5000<br/>1/1 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8634</span><span id="bc1d" class="ld le it kz b gy ou lg l lh li">Test Set Accuracy:<br/>1/1 [==============================] - 0s 191ms/step - loss: 0.3788 - accuracy: 0.8553<br/>[0.3788422644138336, 0.8552631735801697]</span></pre><p id="9150" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">由此我们可以看到，该模型的最终训练成本为0.34(相比于我们的0.36)，测试集准确率为<strong class="md iu"> 85.5% </strong>，与我们上面的结果非常相似。引擎盖下有一些小差异，但模型性能非常相似。</p><p id="7b62" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">重要的是，TensorFlow模型是用不到25行代码构建、训练和测试的，而我们在<code class="fe ol om on kz b">logit_model.py</code>脚本中用了200多行代码。</p><h1 id="249c" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">6.摘要</h1><p id="506e" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">在这篇文章中，我们已经探索了逻辑回归的各个方面。我们用NumPy从头开始构建一个模型。我们首先实现了线性和sigmoid转换，实现了二元交叉熵损失函数，并创建了一个拟合函数来用输入数据训练我们的模型。</p><p id="28b5" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">为了理解逻辑回归的目的，我们然后在UCI心脏病数据集上训练我们的NumPy模型来预测患者的心脏病。我们发现这个简单的模型有86%的预测准确率——非常令人印象深刻。</p><p id="6705" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">最后，在花时间学习和理解这些基础知识之后，我们看到了用TensorFlow构建logit模型是多么容易。</p><p id="88e9" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">总之，逻辑回归是一种有用的预测分析算法。理解这个模型是研究深度学习道路上强有力的第一步。</p></div><div class="ab cl ov ow hx ox" role="separator"><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa pb"/><span class="oy bw bk oz pa"/></div><div class="im in io ip iq"><p id="d2c9" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated">好了，就这样了！如果你已经走了这么远，感谢你的阅读。我希望这篇文章对你了解逻辑回归的基本原理有所帮助。</p><h1 id="df98" class="lk le it bd ll lm ln lo lp lq lr ls lt jz lu ka lv kc lw kd lx kf ly kg lz ma bi translated">7.注释和资源</h1><p id="f525" class="pw-post-body-paragraph mb mc it md b me mf ju mg mh mi jx mj mk ml mm mn mo mp mq mr ms mt mu mv mw im bi translated">以下是我最初学习逻辑回归时的几个问题。也许你也会对它们感兴趣！</p><blockquote class="nq nr ns"><p id="452d" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated"><strong class="md iu"> <em class="it"> Q1: </em> </strong> <em class="it">逻辑回归模型基本上不就是神经网络的单个单元吗？</em></p><p id="ea79" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated"><strong class="md iu"> <em class="it"> A1: </em> </strong> <em class="it">有效，是的。我们可以将逻辑回归模型视为单层、单单元神经网络。</em> <a class="ae lj" href="https://sebastianraschka.com/faq/docs/logisticregr-neuralnet.html" rel="noopener ugc nofollow" target="_blank"> <em class="it">塞巴斯蒂安·拉什卡</em> </a> <em class="it">对为什么会这样提供了一些很好的见解。许多神经网络使用sigmoid激活函数来生成单位输出，就像逻辑回归一样。</em></p><p id="2003" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated"><strong class="md iu"> <em class="it"> Q2: </em> </strong> <em class="it">我们所说的</em>后勤<em class="it">是什么意思？</em></p><p id="56e9" class="mb mc nt md b me mx ju mg mh my jx mj nu mz mm mn nv na mq mr nw nb mu mv mw im bi translated"><strong class="md iu"> <em class="it"> A2: </em> </strong> <em class="it">逻辑回归的“逻辑”来源于模型使用了</em> <a class="ae lj" rel="noopener" target="_blank" href="/understanding-logistic-regression-9b02c2aec102"> logit </a> <em class="it">函数的逆函数，即sigmoid函数。</em></p></blockquote><pre class="kj kk kl km gt ky kz la lb aw lc bi"><span id="8f4c" class="ld le it kz b gy lf lg l lh li">Resources<br/>- <a class="ae lj" href="https://www.google.com/search?client=safari&amp;rls=en&amp;q=uci+heart+disease+dataset&amp;ie=UTF-8&amp;oe=UTF-8" rel="noopener ugc nofollow" target="_blank">UCI Heart Disease Dataset</a><br/>- <a class="ae lj" href="https://web.stanford.edu/~jurafsky/slp3/5.pdf" rel="noopener ugc nofollow" target="_blank">Speech and Language Processing. Daniel Jurafsky &amp; James H. Martin.<br/></a>- <a class="ae lj" href="https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf" rel="noopener ugc nofollow" target="_blank">CS229 Lecture notes, Andrew Ng</a><br/>- <a class="ae lj" href="https://github.com/3b1b/manim" rel="noopener ugc nofollow" target="_blank">Manim, 3Blue1Brown</a></span></pre><p id="9543" class="pw-post-body-paragraph mb mc it md b me mx ju mg mh my jx mj mk mz mm mn mo na mq mr ms nb mu mv mw im bi translated"><strong class="md iu"> <em class="nt">除特别注明外，所有图片均为作者所有。</em> </strong></p></div></div>    
</body>
</html>