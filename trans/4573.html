<html>
<head>
<title>Image Quantization with K-Means</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于K均值的图像量化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-quantization-with-k-means-db7127503bcb#2022-10-11">https://towardsdatascience.com/image-quantization-with-k-means-db7127503bcb#2022-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f6f9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用python、scikit-learn、numpy、PIL和matplotlib通过量化进行图像压缩的简单实践教程</h2></div><p id="a801" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">量子化指的是一种用单个量子值来表示一系列值的技术。对于图像，这意味着我们可以将整个颜色范围压缩成一种特定的颜色。这种技术是有损耗的，也就是说，我们故意丢失信息以支持更低的内存消耗。在本教程中，我将向你展示如何用很少的代码自己实现颜色量化。我们将使用Python和scikit-learn、numpy、PIL和matplotlib。</p><p id="20ba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从下载由<a class="ae lb" href="https://unsplash.com/@pascalvansoest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Pascal van Soest </a>拍摄的“Storr老人”的美丽图像开始，我们将使用它(如果您使用Windows或没有wget访问权限，只需下载图像并将其保存为image.jpeg):</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="84b8" class="ll lm iq lh b gy ln lo l lp lq">wget -O image.jpg <a class="ae lb" href="https://unsplash.com/photos/ZI9X8Kz3ccw/download?ixid=MnwxMjA3fDB8MXxhbGx8MjN8fHx8fHwyfHwxNjY1MzE2ODE1&amp;force=true" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/ZI9X8Kz3ccw/download?ixid=MnwxMjA3fDB8MXxhbGx8MjN8fHx8fHwyfHwxNjY1MzE2ODE1&amp;force=true</a></span></pre><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi lr"><img src="../Images/68d26306dd3a38494557f411ebbfe79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cCUzUs0jFFXL2_mRkTMIvw.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">原始(调整大小)图像。由<a class="ae lb" href="https://unsplash.com/@pascalvansoest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">帕斯卡尔·范·索斯特</a>在<a class="ae lb" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片。</p></figure><p id="548e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们可以加载图像，调整其大小以获得更好的性能，并将其作为numpy-array查看:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="6675" class="ll lm iq lh b gy ln lo l lp lq">from PIL import Image<br/>import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="4c36" class="ll lm iq lh b gy md lo l lp lq">img = Image.open("image.jpg").resize((960, 600))<br/>x = np.asarray(img)</span></pre><p id="3937" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图像编码成<em class="me">宽*高*通道</em>大数组(这里:<em class="me"> 960 * 600 * 3 </em>)。通常，彩色图像存储为RGB，并具有3个颜色通道(红色、绿色和蓝色)。你可以把它想象成一个大的2D数组，每个条目包含3个值。每个值代表0到255 (2**8-1)之间的特定颜色通道的强度。其实这本身已经是8位量化了。</p><p id="6060" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于全局量化，我们丢弃关于每个通道的信息，并简单地将我们阵列中的所有强度作为一个大向量来处理。我们可以使用matplotlib轻松绘制结果直方图:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="b559" class="ll lm iq lh b gy ln lo l lp lq">plt.figure(figsize=(16, 6))<br/>plt.hist(x.ravel(), bins=np.arange(256), density=True, linewidth=0)<br/>plt.xlabel("Value")<br/>plt.ylabel("Density")</span></pre><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mf"><img src="../Images/982daac697343787bc2e9d9c4992322e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BDpDHpMkHfp7LjUVxX_VOw.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">颜色强度的全局分布。</p></figure><p id="0c49" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了量化，我们希望用一个更小的数来代替这256个值，例如8。为了实现这一点，我们可以简单地将空间平均分成8个“箱”,并将其中的所有值映射到该箱的平均值。但我们可以看到，我们的图像中的强度并不是均匀分布的:在略高于零的位置有一个较大的峰值，在160°附近有一个较大的强度累积。如果我们平均划分空间，我们将忽略偏斜的分布，并且低估/高估特定的强度。相反，我们希望在密度高的区域有更窄的面元以获得更高的精度，而在密度较低的区域有更宽的面元，因为我们在那里没有太多的样本。</p><p id="37cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以通过使用K-Means来实现这一点。这是一种无监督聚类算法，常用于在给定数据中寻找<strong class="kh ir"> k </strong>聚类中心(称为<strong class="kh ir">质心</strong>)。你可能已经看到了在多维问题中的应用，但它也适用于1D分布，如我们的问题。我不打算在这里介绍K-Means——有无数的文章解释得比我更好，或者，如果你更喜欢一个视频，我强烈建议你看一下<a class="ae lb" href="https://www.youtube.com/watch?v=4b5d3muPQmA" rel="noopener ugc nofollow" target="_blank"> Josh Starmer的StatQuest </a>。</p><p id="421a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于本文，我们将使用K-Means的一个略有不同的版本，称为MiniBatchKMeans。类似地，对于深度学习中的优化，这里的想法是不在所有样本上计算聚类，而是通过在较小的批次上计算聚类来贪婪地逼近解决方案。这大大加快了收敛速度！</p><p id="7c87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">借助scikit-learn，培训迷你批处理方式变得非常简单:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="49c6" class="ll lm iq lh b gy ln lo l lp lq">from sklearn.cluster import MiniBatchKMeans</span><span id="8d6c" class="ll lm iq lh b gy md lo l lp lq">k_means = MiniBatchKMeans(k, compute_labels=False)<br/>k_means.fit(x.reshape(-1, 1))</span></pre><p id="9f9c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，我们将<code class="fe mg mh mi lh b">x.reshape(-1, 1)</code>传递给MiniBatchKMeans。这将我们的3D矩阵展平为一个向量，并增加了一个大小为1的伪维度，因为估计器只支持2D形状的阵列。此外，我们告诉评估者不要通过<code class="fe mg mh mi lh b">compute_labels=False</code>计算每批标签，否则会显著增加训练时间。训练之后，我们希望将颜色强度映射到最近的质心。估计器没有直接这样做的功能，但是我们可以预测每个样本的质心标签，然后使用这个标签来求解质心的值:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="b78a" class="ll lm iq lh b gy ln lo l lp lq">labels = k_means.predict(x.reshape(-1, 1))<br/>q_x = k_means.cluster_centers_[labels]</span></pre><p id="4713" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在已经有了原始图像的量化表示，但我们需要将数组重新整形为原始图像形状，并将scikit-learn处理的所有浮点数转换回整数:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="1ce3" class="ll lm iq lh b gy ln lo l lp lq">q_img = np.uint8(q_x.reshape(x.shape)</span></pre><p id="83ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们把它们放在一个函数中，这个函数将把量化图像作为numpy数组返回:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="5ed4" class="ll lm iq lh b gy ln lo l lp lq">from sklearn.cluster import MiniBatchKMeans</span><span id="80f6" class="ll lm iq lh b gy md lo l lp lq">def quantize_global(x, k):<br/>  k_means = MiniBatchKMeans(k, compute_labels=False)<br/>  k_means.fit(x.reshape(-1, 1))<br/>  labels = k_means.predict(x.reshape(-1, 1))<br/>  q_x = k_means.cluster_centers_[labels]<br/>  q_img = np.uint8(q_x.reshape(x.shape)<br/>  return q_img</span></pre><p id="69ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看量化k=8后强度分布会发生什么变化:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="8ee8" class="ll lm iq lh b gy ln lo l lp lq">quantized_img  = quantize_global(x, 8)</span><span id="8d24" class="ll lm iq lh b gy md lo l lp lq">plt.figure(figsize=(16, 6))<br/>plt.hist(x.ravel(), bins=np.arange(256), density=True, linewidth=0, label="original")<br/>plt.hist(quantized_img.ravel(), bins=np.arange(256), density=True, linewidth=0, label="quantized")<br/>plt.xlabel("Value")<br/>plt.ylabel("Density")</span></pre><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mf"><img src="../Images/7437b0384e8eb2a168dc989ed3fb1931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wCSPgSZv9J8pIJUmLdlEWA.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">量化前后颜色强度的全局分布(全局，k=8)。</p></figure><p id="3dc6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们所看到的，正如我们所要求的，我们的原始分布已经被8个值所取代。请注意，根据原始分布的密度，质心的间距是不相等的。</p><p id="3b4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，让我们测试一下<em class="me"> k </em>的值，看看这会如何影响我们的结果:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="0f0f" class="ll lm iq lh b gy ln lo l lp lq">Image.fromarray(quantize_global(x, k))</span></pre><div class="lc ld le lf gt ab cb"><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/bdf0c01960bef71ee17745ff1f1133b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*E1ZAWtLFkgQK6UIBk9Bz4w.png"/></div></figure><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/d26b713106534e3cc7b27ce27ec53f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*VmLLi_LAuoAWLMi9P0M1IQ.png"/></div></figure><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/c378a6d7c027d4e579b5e2fb7a292fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*-uYM-rEIrmecAhZv5YwJqQ.png"/></div></figure></div><div class="ab cb"><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/72ed9b31ced4e906066ebd26b057ab15.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*fahvb0Lxx8OeNbe7TBMn8g.png"/></div></figure><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/51a608a331eecf0ae2b8c718e30d366b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*qQdlUFMdU5QSrPmJyvXb1w.png"/></div></figure><figure class="mj ls mk ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/32efe64f83bdcb11c5f4c71d747c6f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*dVWHylHv9ei2HyWcCE16FQ.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk mp di mq mr translated">全局K-表示k=1、2、4、8、16和32(从上到下，从左到右)的量化。</p></figure></div><p id="7b74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于k=1，我们只看到一个灰色的图像。这并不奇怪，因为我们只剩下一种颜色强度，它将位于我们颜色空间的中间(即大约125)。<em class="me"> (125，125，125) </em>在RGB中是灰色。随着我们增加<em class="me"> k </em>，我们看到结果图像更准确地代表了原始图像，因为我们学习了更多的强度来描述我们的图像。现在，注意一下k=8的图像—图像前景看起来非常准确，但背景非常分散。由此有两个重要的收获:1)量化使渐变(比如在灰色的天空中)看起来很糟糕；2)由于我们的KMeans方法，我们更关注前景，其看起来具有更密集的强度分布。</p><p id="e654" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能会惊讶地发现每个图像中不止有<em class="me"> k </em>种颜色(例如，看到k=2的图像)，但解释相当简单:尽管我们只学会用<em class="me"> k </em>的强度来表示我们的图像，但我们仍然有3个通道，这给了我们可以表示的k**3种颜色组合。</p><p id="9243" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是图像大小会怎样呢？如果我们将图像保存到磁盘上，我们已经可以看到图像大小的减小，尽管在保存过程中还做了更多我们不知道的处理。</p><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi gj"><img src="../Images/6e0af3fda3ee1d1bac3b579060a3dade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5r-izc6bxieXX_O_0aeOnQ.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">磁盘上的图像大小(如PNG)随着质心数量(k)的增加而增加。</p></figure><p id="dd74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在科学领域，为你的方法设定基准是很好的实践。所以你可能想知道我们重建原始图像的效果如何。让我们通过使用numpy计算量化图像和原始图像之间的绝对误差和平方误差来进行测试，并将误差绘制成柱状图:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="6455" class="ll lm iq lh b gy ln lo l lp lq">plt.figure(figsize=(8, 5))<br/>plt.bar(range(9), [np.linalg.norm((x - quantize_global(x, 2**i)).ravel(), ord=1) for i in range(9)])<br/>plt.xlabel(r"Number of Centroids ($2^k$)")<br/>plt.ylabel(r"Absolute Error")</span><span id="d3a2" class="ll lm iq lh b gy md lo l lp lq">plt.figure(figsize=(8, 5))<br/>plt.bar(range(9), [np.linalg.norm((x - quantize_global(x, 2**i)).ravel(), ord=2) for i in range(9)])<br/>plt.xlabel(r"Number of Centroids ($2^k$)")<br/>plt.ylabel(r"Squared Error")</span></pre><div class="lc ld le lf gt ab cb"><figure class="mj ls ms ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/39df8c13652fc810483bda1448f8cc99.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*VBbUiiCoSbxhUbydUlsIMA.png"/></div></figure><figure class="mj ls mt ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/79a9b69662cee0f63b48fca6006bc6bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*-H3JJVeI37ZMy5WRJoXPSA.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk mu di mv mr translated">不同k值下量化图像的绝对(左)和平方(右)误差。</p></figure></div><p id="a831" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，绝对误差随着质心数量的增加而减小，最终在k=256时变为零(这时我们没有压缩)。尽管如此，还是存在一些误差，例如，由于我们在没有舍入的情况下对uint8进行了简单的转换，这导致了一些可见的平方误差。有趣的是，平方误差似乎也在增加，直到k=4。请理解，误差是一种从数学上捕捉差异的好方法，但我们的人眼可能对这种差异不太敏感。毕竟，从这个意义上来说，这个错误可能并不意味着什么。问问你自己:我能发现k=32和上面的原始图像之间的错误吗？</p><h2 id="863e" class="ll lm iq bd mw mx my dn mz na nb dp nc ko nd ne nf ks ng nh ni kw nj nk nl nm bi translated">逐通道量化</h2><p id="97e7" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">到目前为止，我们已经将所有强度视为相似的，与通道无关。然而，如果我们绘制每个通道的强度分布，我们可以看到一些差异，特别是在蓝色通道中:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="4246" class="ll lm iq lh b gy ln lo l lp lq">plt.figure(figsize=(16, 6))</span><span id="8398" class="ll lm iq lh b gy md lo l lp lq">plt.hist(x[:, :, 0].ravel(), color="red", bins=np.arange(256), density=True, linewidth=0, alpha=0.5)<br/>plt.hist(x[:, :, 1].ravel(), color="green", bins=np.arange(256), density=True, linewidth=0, alpha=0.5)<br/>plt.hist(x[:, :, 2].ravel(), color="blue", bins=np.arange(256), density=True, linewidth=0, alpha=0.5)</span><span id="1b6e" class="ll lm iq lh b gy md lo l lp lq">plt.xlabel("Value")<br/>plt.ylabel("Density")</span></pre><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mf"><img src="../Images/fbd13cd992cd4c10d5c3dce4157b7607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VSXSxjc3xA4ixxTz4egJvA.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">颜色强度的通道式分布。</p></figure><p id="44d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以轻松调整代码，计算每个通道的量化，而不是全局量化:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="5d97" class="ll lm iq lh b gy ln lo l lp lq">def quantize_channels(x, k):<br/>  quantized_x = x.copy()<br/>  for d in range(3):<br/>    channel = x[:, :, d].copy()<br/>    k_means = MiniBatchKMeans(k, compute_labels=False)<br/>    k_means.fit(channel.reshape(-1, 1))<br/>    labels = k_means.predict(channel.reshape(-1, 1))<br/>    quantized_x[:, :, d] = np.uint8(k_means.cluster_centers_[labels]).reshape(channel.shape)<br/>  return quantized_x</span></pre><p id="326a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后根据全局量化，通过上面的代码对损失进行基准测试:</p><div class="lc ld le lf gt ab cb"><figure class="mj ls ms ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/ad7b4b665cd3687b7a255fd5ed966174.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*ZuKXkuQZohiNl_CBmEDZGw.png"/></div></figure><figure class="mj ls mt ml mm mn mo paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><img src="../Images/3ab3105de47c57deaf043f2423fdae0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*xOKpLFHM-ysxFga7FqOVIg.png"/></div><p class="lz ma gj gh gi mb mc bd b be z dk mu di mv mr translated">采用全局和通道量化时，不同k值下量化图像的绝对(左)和平方(右)误差。</p></figure></div><p id="2c12" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，在最好的情况下，它比全局量化稍好，有时甚至更差。事实上，它需要多达3倍的内存，训练成本也是3倍以上的昂贵，似乎全局量化是一个更好的方法。</p><p id="2c14" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我试图理解为什么通道量化性能如此之差，似乎原因很简单，我们独立处理颜色通道，质心没有太大差异:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="ac7d" class="ll lm iq lh b gy ln lo l lp lq">quantized_img = quantize_channels(x, 8)</span><span id="4d63" class="ll lm iq lh b gy md lo l lp lq">plt.figure(figsize=(16, 6))<br/>plt.hist(quantized_img[:, :, 0].ravel(), bins=np.arange(256), density=True, linewidth=0, label="R", color="red")<br/>plt.hist(quantized_img[:, :, 1].ravel(), bins=np.arange(256), density=True, linewidth=0, label="G", color="green")<br/>plt.hist(quantized_img[:, :, 2].ravel(), bins=np.arange(256), density=True, linewidth=0, label="B", color="blue")<br/>plt.xlabel("Value")<br/>plt.ylabel("Density")</span></pre><figure class="lc ld le lf gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mf"><img src="../Images/9c1547922f20282582cf64e422d84322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*om1uXU9_uRRJW95Ic2KbVg.png"/></div></div><p class="lz ma gj gh gi mb mc bd b be z dk translated">k=8时逐通道量化后的色彩强度分布。</p></figure><p id="343b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更好的方法可能是将每种颜色视为3D RGB向量，并在该空间中应用聚类。但我会让你决定的！根据上面的代码片段，你应该可以很容易地创建它。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="6764" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经成功地应用量化来压缩我们的颜色空间，但是也可以在其他域中应用量化，例如频域，这允许更大的压缩。敬请期待下一部分！</p><p id="b258" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以用Google Colab重现本文所有结果:<a class="ae lb" href="https://colab.research.google.com/drive/1_TouWuP30e23VkPqT4ohWkjY_ddhLQn9?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://Colab . research . Google . com/drive/1 _ touwup 30 e 23 vkpqt 4 ohw kjy _ ddhlqn 9？usp =共享</a></p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="d84f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="me">感谢您阅读这篇文章！如果你喜欢它，请考虑订阅我的更新。如果你有任何问题，欢迎在评论中提出。</em></p></div></div>    
</body>
</html>