<html>
<head>
<title>Generate distractors for MCQs using Word Vectors, Sentence Transformers and MMR algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用单词向量、句子转换器和MMR算法为mcq生成干扰项</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generate-distractors-for-mcqs-using-word-vectors-sentence-transformers-and-mmr-algorithm-e3e5b3a90076#2022-05-02">https://towardsdatascience.com/generate-distractors-for-mcqs-using-word-vectors-sentence-transformers-and-mmr-algorithm-e3e5b3a90076#2022-05-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="2dc7" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用NLP为Edtech中的mcq生成错误答案</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0f42a230474fa52d6d5a77dba7942bed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdvBq1gnN4t4rPCFKroG2Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://pixabay.com/illustrations/quiz-exam-questionnaire-2137664/" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></p></figure><p id="dfda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你是在NLP和Edtech的十字路口工作，你迟早会遇到给定问题和答案产生干扰子(错误答案选择)的问题，自动使用NLP。</p><h1 id="928d" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是干扰物？</h1><p id="a840" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">干扰物是选择题的<strong class="lb iu">错误答案</strong>。</p><p id="2860" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，如果一个给定的选择题的正确答案是<strong class="lb iu">巴拉克奥巴马</strong>，那么我们需要产生错误的选择(干扰物)，比如<strong class="lb iu">乔治布什、比尔克林顿、唐纳德川普、</strong>等等。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3d4085dc16ce91c011fd853238428103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yV_TMOaygc9QKs0K1bgA8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="249b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">给出一个正确的答案，你如何找到干扰物？</p><p id="e736" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基于知识图寻找干扰物的方法有几种，还有像<a class="ae ky" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>、fastText等无监督算法。其中一些可以在我之前的博文<a class="ae ky" rel="noopener" target="_blank" href="/3-ways-to-generate-distractors-wrong-choices-for-mcqs-using-natural-language-processing-d52477a56812">中找到。</a></p><p id="acea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们把重点放在<a class="ae ky" href="https://github.com/explosion/sense2vec" rel="noopener ugc nofollow" target="_blank"> Sense2vec </a>上，它与word2vec在同一行，在word 2 vec中，您使用给定的单词或短语进行查询，并在向量空间中获得相似的单词/短语。</p><p id="37d9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们有一个<strong class="lb iu">问题</strong>和一个<strong class="lb iu">正确答案</strong>。</p><p id="0027" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">谁是美国第44任总统？巴拉克·奥巴马</p><p id="5035" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在的目标是为单词“巴拉克·奥巴马”找到错误的答案选项(干扰物)。那可能是其他总统或总统候选人。</p><p id="0f8c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是有一个问题！如果您使用“巴拉克·奥巴马”查询sense2vec，您将会遇到许多近似重复和拼写错误的单词，如巴拉克·奥巴马、奥巴马总统、奥巴马等，您需要过滤这些单词。你也会遇到其他的复制品，比如乔治·布什，乔治·W·布什等等，你只需要保留一个作为干扰物。</p><p id="e2ca" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">sense2vec算法中与“巴拉克·奥巴马”相似的词:</p><p id="3916" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">巴拉克·奥巴马<br/>奥巴马总统<br/>奥巴马<br/>乔治·布什<br/>小布什<br/>比尔·克林顿<br/>约翰·麦凯恩</p><p id="bd63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们如何处理这个过滤近似重复的问题？我们可以有效地使用句子转换器嵌入和最大边际相关性来实现这一点。我们马上就会看到代码是如何实现的！</p><h1 id="f388" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">该算法</h1><p id="455b" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">本教程完整代码的colab笔记本可以在这里找到<a class="ae ky" href="https://colab.research.google.com/drive/1O_edRdaX-F9kVJrPM-TYM-j8yWtX8yQE?usp=sharing" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a9de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从安装sense2vec库并下载和初始化sense2vec模型开始。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="075d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们用搜索词“巴拉克·奥巴马”来看看sense2vec会输出什么</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5c97" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">输出:</strong></p><p id="3970" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">['巴拉克·奥巴马'，'乔治·W·布什'，'罗纳德·里根'，'乔治·布什'，'约翰·麦凯恩'，'吉米·卡特'，'奥巴马总统'，'比尔·克林顿'，'奥巴马'，'希拉里·克林顿'，'总统'，'莎拉·佩林'，'总统'，'南希·佩洛西']</p><p id="4976" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，为了有效地过滤近似重复，让我们使用<a class="ae ky" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank">句子转换器</a>将原始答案单词以及来自sense2vec中相似单词结果的每个单词转换为向量。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="5266" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在我们已经为每个单词/短语嵌入了一个向量，我们的目标是在嵌入空间中挑选前N个不同的(彼此远离的)单词。</p><p id="b5dd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们选择题案例中的n可能是<strong class="lb iu">四个</strong>。因此，我们反复地想要为我们的搜索关键词(“巴拉克·奥巴马”)挑选三个最多样化的单词/短语。但是我们如何实现这一点呢？</p><p id="a611" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们有最大边际关联(MMR)来拯救我们！KeyBert 库中有<a class="mu mv ep" href="https://medium.com/u/22405c3b2875?source=post_page-----e3e5b3a90076--------------------------------" rel="noopener" target="_blank"> Maarten Grootendorst </a>很棒的<a class="ae ky" href="https://maartengr.github.io/KeyBERT/api/mmr.html" rel="noopener ugc nofollow" target="_blank"> MMR算法实现！</a></p><p id="ad3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">引用上面的MMR算法实现页面-</p><p id="827c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MMR考虑关键字/关键短语与文档的相似性，以及已经选择的关键字和关键短语的相似性。这导致选择相对于文档最大化其多样性的关键词。</p><p id="10d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的文档可以用我们原来的查询关键字(巴拉克·奥巴马)来代替。我们将稍微修改MMR算法，以便选择的第一个单词是我们的原始关键字(巴拉克·奥巴马), MMR算法顺序选择的其余单词应该与原始关键字不同，并且与现有列表中的单词不同。这确保了我们通过根据多样性标准不选择它们来消除近似重复。此外，该算法具有控制多样性的参数。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ms mt l"/></div></figure><p id="3d3d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">你可以看到输出是-</p><p id="2372" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">巴拉克·奥巴马<br/>———<br/>约翰·麦凯恩<br/>乔治·W·布什<br/>莎拉·佩林<br/>比尔·克林顿</p><p id="a110" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以清楚地看到，类似“巴拉克·奥巴马”、“乔治·w·布什”、“乔治·布什”、“奥巴马总统”、“奥巴马”等的近似重复项被过滤掉，不会出现在最终输出中。</p><h1 id="e9fc" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="1381" class="pw-post-body-paragraph kz la it lb b lc mn ju le lf mo jx lh li mp lk ll lm mq lo lp lq mr ls lt lu im bi translated">词向量算法可以被用作一种手段来为给定正确答案的多项选择问题生成干扰项(错误选择)。</p><p id="04ae" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是由于单词向量算法中涉及的训练的非监督性质，许多相似的单词和近似重复的单词被返回。</p><p id="b7f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这些单词有时语义相似，所以在短语中使用单词编辑距离或单词匹配效果不好。因此，我们使用基于转换器的算法<a class="ae ky" href="https://www.sbert.net/" rel="noopener ugc nofollow" target="_blank"> SBERT </a>，将任何短语或单词转换成向量，并过滤那里的邻居。这些算法被训练来将拼写错误的单词以及语义相似的单词放置在嵌入空间的附近。</p><p id="1c73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从给定的一组可能的干扰物中，我们可以使用最大边际关联(MMR)算法有效地选择前四个不同的关键字/短语作为MCQ的干扰物。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="2ee3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">祝NLP探索愉快，如果你喜欢它的内容，请随时在<a class="ae ky" href="https://twitter.com/ramsri_goutham" rel="noopener ugc nofollow" target="_blank">推特上找到我。</a></p><p id="5e04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想学习使用变形金刚的现代自然语言处理，看看我的课程<a class="ae ky" href="https://www.udemy.com/course/question-generation-using-natural-language-processing/?referralCode=C8EA86A28F5398CBF763" rel="noopener ugc nofollow" target="_blank">使用自然语言处理的问题生成</a></p></div></div>    
</body>
</html>