<html>
<head>
<title>Stable Diffusion: Best Open Source Version of DALL·E 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">稳定扩散:DALL E 2的最佳开源版本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stable-diffusion-best-open-source-version-of-dall-e-2-ebcdf1cb64bc#2022-08-30">https://towardsdatascience.com/stable-diffusion-best-open-source-version-of-dall-e-2-ebcdf1cb64bc#2022-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a85e373d2bc4e25a36320bd1565c6121.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fccPSTl6GRJGxEmx.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">图片来自<a class="ae jd" href="https://unsplash.com/photos/-fRAIQHKcc0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><p id="ac9c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由来自<a class="ae jd" href="https://stability.ai/" rel="noopener ugc nofollow" target="_blank"> Stability AI </a>、<a class="ae jd" href="https://github.com/CompVis" rel="noopener ugc nofollow" target="_blank"> CompVis </a>和<a class="ae jd" href="https://laion.ai/" rel="noopener ugc nofollow" target="_blank"> LAION </a>的研究人员和工程师创造的“稳定扩散”宣称来自<a class="ae jd" href="https://www.craiyon.com/" rel="noopener ugc nofollow" target="_blank"> Craiyon </a>的王冠，以前被称为DALL E-Mini，是新的最先进的文本到图像的开源模型。</p><p id="8576" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然从文本中生成图像已经感觉像是古老的技术，但稳定的扩散设法将创新带到桌面上，鉴于这是一个开源项目，这更令人惊讶。</p><p id="b3c8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们深入细节，看看数据科学社区有什么稳定的扩散！</p><h1 id="6769" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">引入稳定扩散</h1><p id="24bf" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">稳定扩散是<a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">潜在扩散</a>架构的开源实现，被训练为在低维潜在空间中对随机高斯噪声进行降噪，以获得感兴趣的样本。</p><p id="da7e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练扩散模型来预测在每一步中对样本进行轻微去噪的方式，并且在几次迭代之后，获得结果。扩散模型已经被应用于各种生成任务，例如图像、语音、3D形状和图形合成。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/279c6a6c6878883fef982e6e33d614af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v12mDJwIKWn-_y8L.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">扩散过程(作者图片)</p></figure><p id="0689" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">扩散模型包括两个步骤:</p><ul class=""><li id="5ab6" class="mj mk jg kf b kg kh kk kl ko ml ks mm kw mn la mo mp mq mr bi translated">正向扩散-通过逐渐扰动输入数据将数据映射到噪声。这在形式上是通过简单的随机过程实现的，该过程从数据样本开始，并使用简单的高斯扩散核迭代地产生噪声样本。这个过程仅在训练中使用，而不是在推理中使用。</li><li id="c49b" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated">参数化反向-撤消正向扩散并执行迭代去噪。该过程代表数据合成，并被训练成通过将随机噪声转换成现实数据来生成数据。</li></ul><p id="f9da" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正向和反向过程需要顺序重复数千个步骤，注入和减少噪声，这使得整个过程缓慢且计算资源繁重。</p><p id="7923" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了能够在有限的资源上进行培训，同时保持其质量和灵活性,《稳定传播》的创建者采用了论文中建议的方法。他们没有使用实际的像素空间，而是在一个低维的潜在空间上应用了扩散过程。</p><blockquote class="mx my mz"><p id="cf07" class="kd ke na kf b kg kh ki kj kk kl km kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">例如，稳定扩散中使用的自动编码器的缩减系数为8。这意味着一个形状为<code class="fe ne nf ng nh b">(3, 512, 512)</code>的图像在潜在空间中变成了<code class="fe ne nf ng nh b">(3, 64, 64)</code>，这需要<code class="fe ne nf ng nh b">8 × 8 = 64</code>倍少的内存。<br/> <a class="ae jd" href="https://huggingface.co/blog/stable_diffusion" rel="noopener ugc nofollow" target="_blank">官方《稳定扩散》发布说明</a></p></blockquote><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/4647163cfc75c306eec0eefb0eb05eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rW_y1kjruoT9BSO0.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">稳定的扩散架构(图片来自<a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><h1 id="f537" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">稳定扩散体系结构</h1><p id="e962" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">稳定扩散架构具有三个主要组件，两个用于将样本减少到较低维度的潜在空间，然后对随机高斯噪声进行去噪，一个用于文本处理。</p><p id="b8e7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)自动编码器:模型的输入是期望输出大小的随机噪声。它首先将样本缩减到一个较低维度的潜在空间。为此，作者使用了由编码器和解码器两部分组成的<a class="ae jd" rel="noopener" target="_blank" href="/understanding-variational-autoencoders-vaes-f70510919f73"> VAE架构</a>。在训练期间使用编码器将样本转换成较低的潜在表示，并将其作为输入传递给下一个块。根据推断，去噪后生成的样本经历反向扩散，并被转换回其原始维度潜在空间。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/cdb502af8e9bf17fa373a1e94392b344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rDygDwLLkTtSr-iS.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">VAE建筑(图片来自<a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">论文</a></p></figure><p id="d263" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2) U-Net:由ResNet组成的U-Net块在较低延迟空间中接收有噪声的样本，对其进行压缩，然后以较少的噪声对其进行解码。来自U-Net输出的估计噪声残差用于构建预期的去噪样本表示。</p><p id="a27c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3)文本编码器:文本编码器负责文本处理，将提示转化为嵌入空间。与谷歌的<a class="ae jd" href="https://arxiv.org/abs/2205.11487" rel="noopener ugc nofollow" target="_blank"> Imagen </a>类似，稳定扩散使用冻结剪辑ViT-L/14文本编码器。</p><h1 id="cb2c" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">技术细节</h1><p id="00cb" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">稳定扩散v1在256x256图像上进行预训练，然后在512x512图像上进行微调，所有这些都来自<a class="ae jd" href="https://laion.ai/blog/laion-5b/" rel="noopener ugc nofollow" target="_blank"> LAION-5B </a>数据库的子集。它对扩散模型使用带有860M UNet和CLIP ViT-L/14文本编码器的8倍下采样自动编码器。稳定扩散相对来说是轻量级的，在10GB VRAM的GPU上运行，当使用float16 precision而不是默认的float32时甚至更少。</p><p id="86bb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该小组目前公布了以下检查点:</p><ul class=""><li id="fc8d" class="mj mk jg kf b kg kh kk kl ko ml ks mm kw mn la mo mp mq mr bi translated"><code class="fe ne nf ng nh b">sd-v1-1.ckpt</code>:在<a class="ae jd" href="https://huggingface.co/datasets/laion/laion2B-en" rel="noopener ugc nofollow" target="_blank"> laion2B-en </a>上分辨率<code class="fe ne nf ng nh b">256x256</code>处237k步。<a class="ae jd" href="https://huggingface.co/datasets/laion/laion-high-resolution" rel="noopener ugc nofollow" target="_blank">LAION-高分辨率</a>上分辨率<code class="fe ne nf ng nh b">512x512</code>的194k步(分辨率<code class="fe ne nf ng nh b">&gt;= 1024x1024</code>的LAION-5B的170M示例)。</li><li id="a8dd" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><code class="fe ne nf ng nh b">sd-v1-2.ckpt</code>:从<code class="fe ne nf ng nh b">sd-v1-1.ckpt</code>开始恢复。在<a class="ae jd" href="https://laion.ai/blog/laion-aesthetics/" rel="noopener ugc nofollow" target="_blank"> laion-aesthetics v2 5+ </a>(具有估计美学分数<code class="fe ne nf ng nh b">&gt; 5.0</code>的laion2B-en的子集，并且另外被过滤成具有原始尺寸<code class="fe ne nf ng nh b">&gt;= 512x512</code>和估计水印概率<code class="fe ne nf ng nh b">&lt; 0.5</code>的图像)上以分辨率<code class="fe ne nf ng nh b">512x512</code>前进515k步。水印估计来自<a class="ae jd" href="https://laion.ai/blog/laion-5b/" rel="noopener ugc nofollow" target="_blank"> LAION-5B </a>元数据，美学分数使用<a class="ae jd" href="https://github.com/christophschuhmann/improved-aesthetic-predictor" rel="noopener ugc nofollow" target="_blank">laon美学预测器V2 </a>来估计。</li><li id="1061" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><code class="fe ne nf ng nh b">sd-v1-3.ckpt</code>:从<code class="fe ne nf ng nh b">sd-v1-2.ckpt</code>恢复。“laion-aesthetics v2 5+”的分辨率<code class="fe ne nf ng nh b">512x512</code>为195k步，文本调节下降10%，以改进<a class="ae jd" href="https://arxiv.org/abs/2207.12598" rel="noopener ugc nofollow" target="_blank">无分类器引导取样</a>。</li><li id="8a6d" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><code class="fe ne nf ng nh b">sd-v1-4.ckpt</code>:从<code class="fe ne nf ng nh b">sd-v1-2.ckpt</code>恢复。“laion-aesthetics v2 5+”的分辨率<code class="fe ne nf ng nh b">512x512</code>为225k步，文本调节下降10%，以改进<a class="ae jd" href="https://arxiv.org/abs/2207.12598" rel="noopener ugc nofollow" target="_blank">无分类器引导取样</a>。</li></ul><p id="55d0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">来自GitHub官方稳定扩散库</strong></p><h1 id="09e3" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">模型性能</h1><p id="e5fe" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">为了评估生成模型创建的图像质量，通常使用<a class="ae jd" href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_inception_distance" rel="noopener ugc nofollow" target="_blank">弗雷歇初始距离(FID) </a>度量。简而言之，FID计算真实图像和生成图像的特征向量之间的距离。在COCO基准测试上，Imagen目前取得了7.27的最佳(最低)零拍FID分数，优于10.39 FID分数的DALL E 2。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/c9083b076d18126a9cd4f1971b289674.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jC597OmwO9y-2Tq4.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">扩散模型的最佳结果(图片来自<a class="ae jd" href="https://paperswithcode.com/sota/text-to-image-generation-on-coco?tag_filter=246" rel="noopener ugc nofollow" target="_blank">论文，代码</a></p></figure><p id="1882" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Stable Diffusion团队还没有发布任何基准分数来与其他模型进行比较。从最初的<a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">潜在扩散</a>论文(见下文)，潜在扩散模型(LDM)已经使用56 × 256大小的MS-COCO数据集达到12.63 FID分数:具有250个DDIM步骤。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/342cacf93d574ac3f7d205216461e8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NNwM0cfPslldA1Yr.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">稳定的扩散结果(图片来自<a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">纸张</a></p></figure><p id="c9f1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文本到图像模型最好的部分是我们可以很容易地定性评估模型的性能。让我们来看看稳定扩散与SOTA闭源模型DALL E 2相比表现如何。</p><h1 id="839a" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">稳定扩散vs DALL E 2</h1><blockquote class="mx my mz"><p id="1a91" class="kd ke na kf b kg kh ki kj kk kl km kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">波士顿梗与美人鱼尾巴，在海底，戏剧性的，数字艺术。</p></blockquote><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/ad5456b329b0f15b8950af002df1a114.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F3jVIlEAyLkMpJFhb4fxKQ.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用稳定扩散和DALL E 2生成的图像(图片由作者提供)</p></figure><blockquote class="mx my mz"><p id="d03c" class="kd ke na kf b kg kh ki kj kk kl km kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">一名波士顿梗绝地手持墨绿色光剑，栩栩如生</p></blockquote><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/7071ed3c57f488a8d816e3f66c5a704b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R_EN0k8q7rwZ_jZkscRhwA.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用稳定扩散和DALL E 2生成的图像(图片由作者提供)</p></figure><p id="b325" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我不禁惊叹于这些模型产生的结果，这绝对是令人兴奋的。未来就在这里！</p><p id="4abc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从结果中可以看出，达尔·E-2设法理解并产生了更适合于提示的图像，而稳定的扩散却在挣扎。例如，狗站在一条鱼上，而不是有尾巴。然而，图像的质量、颜色、灯光和风格都令人印象深刻。</p><h1 id="8e4b" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">稳定扩散对Cray ion(DALL E Mini)</h1><p id="7c0b" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">但是作为优秀的数据科学家，我们喜欢比较苹果和苹果。让我们将稳定扩散与开源项目Craiyon进行比较。</p><blockquote class="mx my mz"><p id="aa76" class="kd ke na kf b kg kh ki kj kk kl km kn nb kp kq kr nc kt ku kv nd kx ky kz la ij bi translated">书呆子气的波士顿梗，戴着眼镜，在电脑后面写代码，动漫风格</p></blockquote><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/3ce068daae5ca2e3d4537525c9603d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zeo660JJmgboQRvO9ho5w.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">使用稳定扩散和Craiyon生成的图像(图片由作者提供)</p></figure><p id="7434" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们可以立即看到的，稳定的扩散产生更真实的图像，而Craiyon努力塑造狗的脸。</p><h1 id="0b5c" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">稳定扩散有争议的一面</h1><p id="ea4f" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">稳定扩散在其存在的短时间内已经产生了许多争论。与DALL E 2不同，稳定扩散对它可以生成的内容几乎没有限制。在发布后，用户测试了它的局限性，生成了人名图像、色情图像以及与不同意使用其材料的艺术家的作品可疑相似的图像。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/4c8e6759bb3406a10bac062217c6f225.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*eoDFeVj7BJWVXZs_.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用DALL E 2的话说就是稍微修改一下文字😉(图片由导演提供)</p></figure><p id="f05d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有这些都在Twitter和T2的Reddit上引发了大量讨论，人们呼吁因安全问题停止该项目。截至这篇博文撰写之时，Twitter决定封锁该项目账户，托管在<a class="ae jd" href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="noopener ugc nofollow" target="_blank"> HugginFace Space </a>上的模型对其可以生成的内容进行了限制，名为“安全分类器”，旨在删除NSFW图像。</p><h1 id="fd62" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="c543" class="pw-post-body-paragraph kd ke jg kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">稳定扩散是最近发布的最令人兴奋的OSDS项目之一。与以前的操作系统文本到图像模型相比，它提供了最先进的结果和各方面的显著改进。迫不及待地想看到这个领域的未来，但又忍不住担心它的影响。</p><h1 id="8889" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">资源</h1><ul class=""><li id="f56c" class="mj mk jg kf b kg lz kk ma ko no ks np kw nq la mo mp mq mr bi translated"><a class="ae jd" href="https://huggingface.co/blog/stable_diffusion" rel="noopener ugc nofollow" target="_blank">稳定扩散发布说明</a></li><li id="01c6" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><a class="ae jd" href="https://github.com/CompVis/stable-diffusion" rel="noopener ugc nofollow" target="_blank">稳定扩散GitHub回购</a></li><li id="c443" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><a class="ae jd" href="https://arxiv.org/abs/2112.10752" rel="noopener ugc nofollow" target="_blank">“使用潜在扩散模型的高分辨率图像合成”论文</a></li><li id="0bb3" class="mj mk jg kf b kg ms kk mt ko mu ks mv kw mw la mo mp mq mr bi translated"><a class="ae jd" href="https://developer.nvidia.com/blog/improving-diffusion-models-as-an-alternative-to-gans-part-1/" rel="noopener ugc nofollow" target="_blank">改进扩散模型，作为gan的替代方案</a></li></ul></div></div>    
</body>
</html>