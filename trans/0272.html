<html>
<head>
<title>Why You Should Not Trust the train_test_split() Function</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么不应该信任 train_test_split()函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-you-should-not-trust-the-train-test-split-function-47cb9d353ad2#2022-02-11">https://towardsdatascience.com/why-you-should-not-trust-the-train-test-split-function-47cb9d353ad2#2022-02-11</a></blockquote><div><div class="fc ik il im in io"/><div class="ip iq ir is it"><h2 id="6c47" class="iu iv iw bd b dl ix iy iz ja jb jc dk jd translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="f955" class="pw-subtitle-paragraph kc jf iw bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">反思如何使用 train_test_split()函数会导致错误的结果，并结合实际演示</h2></div><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gi gj ku"><img src="../Images/37c57eca88d99de0028157bdb5aea185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rXCoXZn4yTS4DRXC"/></div></div><p class="lg lh gk gi gj li lj bd b be z dk translated">在<a class="ae lk" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae lk" href="https://unsplash.com/@photoholgic?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">摄影</a>拍摄的照片</p></figure><p id="eb6c" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">毫无疑问，几乎所有的数据科学家在他们的一生中都至少尝试过一次使用<code class="fe mh mi mj mk b">train_test_split()</code>函数。scikit-learn Python 包提供了<code class="fe mh mi mj mk b">train_test_split()</code>函数。通常，我们不太关心使用这个函数的效果，因为用一行代码我们就可以将数据集分成两部分，训练集和测试集。</p><p id="169a" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><strong class="ln jg">的确，使用该功能可能会有危险。在这篇文章中，我将试着解释为什么。</strong></p><p id="9bb0" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">文章组织如下:</p><ul class=""><li id="4aa1" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated"><code class="fe mh mi mj mk b">train_test_split()</code>功能概述</li><li id="117f" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">潜在风险</li><li id="3c33" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">可能的对策。</li></ul><h1 id="2e67" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">train _ test _ split()函数概述</h1><p id="9570" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated"><code class="fe mh mi mj mk b">train_test_split()</code>函数由 sklearn 包下的 model_selection 子包提供。该函数接收以下参数作为输入:</p><ul class=""><li id="9530" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated"><strong class="ln jg">数组— </strong>要拆分的数据集；</li><li id="5450" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><strong class="ln jg"> test_size — </strong>测试集的大小。它可以是浮点数，也可以是整数。如果它是一个浮点数，它应该是一个介于 0.0 和 1.0 之间的数字，表示要包含在测试集中的数据集的比例。如果它是一个整数，它是包含在测试集中的样本总数。如果未设置 test_size，该值将自动设置为列车大小的补码；</li><li id="672a" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><strong class="ln jg"> train_size </strong> —列车组的大小。它的行为是对 test_size 变量的补充；</li><li id="7b9d" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><strong class="ln jg">random _ state-在应用分割之前，数据集被混洗。random_state 变量是一个整数，它初始化用于洗牌的种子。它用于使实验具有可重复性；</strong></li><li id="e939" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><strong class="ln jg">洗牌</strong> —指定是否在分割前洗牌。默认值为 True</li><li id="81d6" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated"><strong class="ln jg">分层</strong> —如果不是无，它为类别标签指定一个频率数组。这允许拆分阶段保留指定的类别标签的频率。</li></ul><p id="bc8f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">通常，我们从<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn 文档</a>中复制如何使用<code class="fe mh mi mj mk b">train_test_split()</code>的示例，并按如下方式使用:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="5257" class="oa na iw mk b gz ob oc l od oe">from sklearn.model_selection import train_test_split</span><span id="eb36" class="oa na iw mk b gz of oc l od oe">X_train, X_test, y_train, y_test = <strong class="mk jg">train_test_split</strong>(X, y, test_size=0.33, random_state=42)</span></pre><p id="8830" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们不太在意这个特性的效果。我们继续写代码吧。</p><p id="ef0f" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">但是也有潜在的风险，我将在下一节向您展示。</p><h1 id="bc43" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">2 潜在风险</h1><p id="be1f" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">在内部，<code class="fe mh mi mj mk b">train_test_split()</code>函数使用一个种子，允许您将数据随机分成两组:训练集和测试集。</p><p id="bfb2" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">该数字是<strong class="ln jg">伪随机</strong>，因为相同的数据子部分对应相同的种子值。这对于确保实验的<strong class="ln jg">再现性</strong>非常有用。</p><p id="762b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">不幸的是，使用一个种子而不是另一个种子可能会导致完全不同的数据集，甚至会修改接收训练集作为输入的所选机器学习模型的性能。</p><p id="fc24" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">为了理解这个问题，我们举个例子。让我们考虑由 scikit-learn 库提供的经典<strong class="ln jg">糖尿病数据集</strong>。该数据集与 scikit-learn 一起发布，可通过<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes" rel="noopener ugc nofollow" target="_blank">此链接</a>获得。</p><p id="b775" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们生成 100 个不同的训练/测试集对，具有不同的<code class="fe mh mi mj mk b">random_state</code>值(从 0 到 99)，我们通过线性回归模型对每个训练集建模。然后，我们计算每个模型的均方误差(MSE)值。</p><p id="69fd" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">首先，我们加载数据集:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="41db" class="oa na iw mk b gz ob oc l od oe">from sklearn.datasets import <strong class="mk jg">load_diabetes</strong></span><span id="2d20" class="oa na iw mk b gz of oc l od oe">diabetes = load_diabetes()<br/>X = diabetes.data<br/>y = diabetes.target</span></pre><p id="7734" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">然后，我们计算每个模型的 MSE:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="2423" class="oa na iw mk b gz ob oc l od oe">import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LinearRegression<br/>from sklearn.metrics import mean_squared_error</span><span id="4fa1" class="oa na iw mk b gz of oc l od oe">n = 100<br/>mse_list = []<br/>seed_list = np.arange(0, n)</span><span id="d1c3" class="oa na iw mk b gz of oc l od oe">for seed in seed_list:<br/>    X_train, X_test, y_train, y_test = <strong class="mk jg">train_test_split</strong>(X, y, test_size=0.30, random_state=seed)<br/>    model = <strong class="mk jg">LinearRegression()</strong><br/>    model.fit(X_train,y_train)</span><span id="ebbd" class="oa na iw mk b gz of oc l od oe">    y_pred = model.predict(X_test)<br/>    mse_list.append(<strong class="mk jg">mean_squared_error</strong>(y_test,y_pred))</span></pre><p id="fe69" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们将不同种子产生的不同 mse 存储在 mse_list 中。现在我们可以绘制 MSE。我们使用 matplotlib 包:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="4dca" class="oa na iw mk b gz ob oc l od oe">import matplotlib.pyplot as plt</span><span id="6b5e" class="oa na iw mk b gz of oc l od oe">plt.plot(seed_list, mse_list)<br/>plt.title("MSE VS RANDOM STATE")<br/>plt.xlabel('random state')<br/>plt.ylabel('mse')<br/>plt.grid()<br/>plt.savefig('mse vs random state.png')<br/>plt.show()</span></pre><figure class="kv kw kx ky gu kz gi gj paragraph-image"><div class="gi gj oh"><img src="../Images/fafbec6c059bd3223f596ab00a1943a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*V0jhL-raJra3rjGR-P7PRQ.png"/></div><p class="lg lh gk gi gj li lj bd b be z dk translated">作者图片</p></figure><p id="6bc1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">我们注意到 MSE 依赖于随机状态。我们还计算平均值和标准差:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="fa40" class="oa na iw mk b gz ob oc l od oe">import numpy as np</span><span id="a0a6" class="oa na iw mk b gz of oc l od oe">mean = np.mean(mse_list)<br/>std = np.std(mse_list)</span></pre><p id="9df1" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">它给出了以下输出:</p><pre class="kv kw kx ky gu nw mk nx ny aw nz bi"><span id="4fc9" class="oa na iw mk b gz ob oc l od oe">mean = 3029.5400317608987</span><span id="fb73" class="oa na iw mk b gz of oc l od oe">std = 302.5362185895346</span></pre><p id="17f3" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">通过这个实验，我们可以得出结论，<code class="fe mh mi mj mk b">train_test_split()</code>功能并没有看起来那么无害。</p><p id="bd12" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如何减轻<code class="fe mh mi mj mk b">train_test_split()</code>的影响？让我们看看一些可能的解决方案。</p><h1 id="1ef9" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">3 种可能的对策</h1><p id="d1b1" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">至少有两种可能的对策来减少<code class="fe mh mi mj mk b">train_test_split()</code>的影响:</p><ul class=""><li id="aea6" class="ml mm iw ln b lo lp lr ls lu mn ly mo mc mp mg mq mr ms mt bi translated">使用不同的随机状态值多次运行<code class="fe mh mi mj mk b">train_test_split()</code>，如前一节所示。然后我们可以计算我们度量的平均值；</li><li id="9cc4" class="ml mm iw ln b lo mu lr mv lu mw ly mx mc my mg mq mr ms mt bi translated">使用<strong class="ln jg">交叉验证</strong>，作为<code class="fe mh mi mj mk b">train_test_split()</code>的替代方案。交叉验证自动将数据集分成 K 个折叠，并在 k-1 个折叠上执行训练阶段，在剩余的折叠上进行测试。然后，它移动折叠，并在接下来的 k-1 个折叠上重新进行训练阶段，并在剩余的折叠上进行测试。诸如此类。</li></ul><p id="ca21" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated"><a class="oi oj ep" href="https://medium.com/u/d86e20f6e783?source=post_page-----47cb9d353ad2--------------------------------" rel="noopener" target="_blank"> Eijaz Allibhai </a>有一篇非常有趣的文章，题为<a class="ae lk" href="https://medium.com/@eijaz/holdout-vs-cross-validation-in-machine-learning-7637112d3f8f" rel="noopener">机器学习中的保留与交叉验证</a>，解释了 train_test_split()(也称为保留)和交叉验证之间的区别。</p><h1 id="c6d7" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">摘要</h1><p id="ef93" class="pw-post-body-paragraph ll lm iw ln b lo nr kg lq lr ns kj lt lu nt lw lx ly nu ma mb mc nv me mf mg ip bi translated">在本文中，我描述了使用 scikit-learn 包提供的<code class="fe mh mi mj mk b">train_test_split()</code>函数的潜在风险。为了对比它们，一个可能的对策是使用交叉验证。</p><p id="5f4b" class="pw-post-body-paragraph ll lm iw ln b lo lp kg lq lr ls kj lt lu lv lw lx ly lz ma mb mc md me mf mg ip bi translated">如果你读到这里，对我来说，今天已经很多了。谢谢！你可以在<a class="ae lk" href="https://alod83.medium.com/which-topics-would-you-like-to-read-c68314dc6813" rel="noopener">这篇文章</a>里读到更多关于我的内容。</p><h1 id="3db2" class="mz na iw bd nb nc nd ne nf ng nh ni nj kl nk km nl ko nm kp nn kr no ks np nq bi translated">相关文章</h1><div class="ok ol gq gs om on"><a rel="noopener follow" target="_blank" href="/a-complete-data-analysis-workflow-in-python-and-scikit-learn-9a77f7c283d3"><div class="oo ab fp"><div class="op ab oq cl cj or"><h2 class="bd jg gz z fq os fs ft ot fv fx jf bi translated">Python 和 scikit 中的完整数据分析工作流程-学习</h2><div class="ou l"><p class="bd b dl z fq os fs ft ot fv fx dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa le on"/></div></div></a></div><div class="ok ol gq gs om on"><a rel="noopener follow" target="_blank" href="/how-to-spend-your-time-when-you-are-waiting-for-a-data-analysis-output-e71b383f43cb"><div class="oo ab fp"><div class="op ab oq cl cj or"><h2 class="bd jg gz z fq os fs ft ot fv fx jf bi translated">当你在等待数据分析结果时，你该如何打发时间</h2><div class="pb l"><h3 class="bd b gz z fq os fs ft ot fv fx dk translated">当你的计算机正在运行你喜欢的算法，而你正在等待的时候，一些建议不要浪费你的时间…</h3></div><div class="ou l"><p class="bd b dl z fq os fs ft ot fv fx dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pc l ox oy oz ov pa le on"/></div></div></a></div><div class="ok ol gq gs om on"><a rel="noopener follow" target="_blank" href="/have-you-ever-thought-about-using-python-virtualenv-fc419d8b0785"><div class="oo ab fp"><div class="op ab oq cl cj or"><h2 class="bd jg gz z fq os fs ft ot fv fx jf bi translated">有没有想过用 Python virtualenv？</h2><div class="pb l"><h3 class="bd b gz z fq os fs ft ot fv fx dk translated">在终端和 Jupyter 笔记本上安装和使用 Python virtualenv 的实用指南。</h3></div><div class="ou l"><p class="bd b dl z fq os fs ft ot fv fx dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pd l ox oy oz ov pa le on"/></div></div></a></div><div class="ok ol gq gs om on"><a rel="noopener follow" target="_blank" href="/automl-in-python-a-comparison-between-hyperopt-sklearn-and-tpot-8c12aaf7e829"><div class="oo ab fp"><div class="op ab oq cl cj or"><h2 class="bd jg gz z fq os fs ft ot fv fx jf bi translated">Python 中的 AutoML:Hyperopt sk learn 和 TPOT 的比较</h2><div class="pb l"><h3 class="bd b gz z fq os fs ft ot fv fx dk translated">两种流行的 Python AutoML 库的优缺点</h3></div><div class="ou l"><p class="bd b dl z fq os fs ft ot fv fx dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pe l ox oy oz ov pa le on"/></div></div></a></div></div></div>    
</body>
</html>