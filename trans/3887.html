<html>
<head>
<title>A pipeline for benchmarking churn prediction approaches</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">测试流失预测方法的管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-pipeline-for-benchmarking-churn-prediction-approaches-f5b533c53e30#2022-08-29">https://towardsdatascience.com/a-pipeline-for-benchmarking-churn-prediction-approaches-f5b533c53e30#2022-08-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5f16" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">如何使用scikit-learn管道对不同数据集上的多种采样策略和模型进行基准测试</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/1207ae7367b0eb49e040792090f7b91b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OUpmvIyZQIJ5JMif0VPLKw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">彼得·赫尔曼在<a class="ae ky" href="https://unsplash.com/@ringo91/likes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片。</p></figure><p id="d37e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi lv translated"><span class="l lw lx ly bm lz ma mb mc md di"> C </span>客户流失预测是营销中非常常见的数据科学用例。这个想法是<strong class="lb iu">估计</strong>哪些客户<strong class="lb iu">可能会取消订阅</strong>或停止使用你的服务。</p><p id="91c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在过去的几年中，举办了许多比赛，开发了新的方法来更好地预测客户流失。几个月前，我发现了一篇由Geiler et al. (2022) 撰写的伟大论文“<em class="me">关于流失预测的机器学习方法的调查</em>”。本文对常见的客户流失预测方法进行了基准测试和分析。像大多数论文一样，找不到Github库或源代码。</p><p id="74cf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">所以我决定自己建立一个定制的基准测试管道，原因有两个:</p><ol class=""><li id="5142" class="mf mg it lb b lc ld lf lg li mh lm mi lq mj lu mk ml mm mn bi translated">将描述的方法从论文转换成代码是数据科学中的一项关键技能。</li><li id="6a1e" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu mk ml mm mn bi translated">我想知道当使用他们用过的数据集的子集(具有高类别不平衡的数据集)时，我是否会得到类似的结果，因为他们的一些数据集具有高流失率(例如，50%)。</li></ol><h2 id="f5c8" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">您将从本文中学到什么:</h2><ul class=""><li id="d353" class="mf mg it lb b lc nm lf nn li no lm np lq nq lu nr ml mm mn bi translated">如何<strong class="lb iu">创建scikit-learn管道</strong>对不同数据集的不同流失预测方法进行基准测试</li><li id="c81d" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">如何用<strong class="lb iu">kers classifier</strong>包装器实现一个<strong class="lb iu">前馈神经网络</strong>来与我们的管道兼容</li><li id="5517" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">如何在scikit-learn中实现一个神经网络作为<strong class="lb iu">自定义分类器</strong></li></ul><h2 id="d020" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">你在这篇文章中找不到的:</h2><ul class=""><li id="ad58" class="mf mg it lb b lc nm lf nn li no lm np lq nq lu nr ml mm mn bi translated">基准测试结果。他们值得拥有自己的文章。</li><li id="9e4f" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><strong class="lb iu">文章现在可以在这里找到</strong><a class="ae ky" rel="noopener" target="_blank" href="/findings-from-benchmarking-churn-prediction-methods-95940683523d"><strong class="lb iu"/></a><strong class="lb iu">。</strong></li><li id="3fcb" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">对所用模型和管道功能的详细解释。</li></ul><blockquote class="ns nt nu"><p id="5f33" class="kz la me lb b lc ld ju le lf lg jx lh nv lj lk ll nw ln lo lp nx lr ls lt lu im bi translated"><strong class="lb iu">请注意</strong> : <br/> 1。如果您对如何使用scikit-learn创建管道的更详细解释感兴趣，请查看我以前的文章“<a class="ae ky" rel="noopener" target="_blank" href="/advanced-pipelines-with-scikit-learn-4204bb71019b">使用scikit-learn的高级管道</a>”。<br/> 2。为了关注代码的重要部分，下面的代码片段不包含任何导入语句。您可以在本文末尾找到完整代码的链接。</p></blockquote><h1 id="a6eb" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">概观</h1><p id="26cc" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">图1提供了流程中每个基准测试步骤的简要概述。<em class="me">数据加载</em>和<em class="me">预清洗</em>在第0章“预流水线步骤”中总结。基准测试本身包含在第1章到第6章中。最后，第7章“可视化”结束了这篇文章。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/412f1025daab52bad5bb2a7bc3d467fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NPmURKvcfMXUfNZYwF0NXg@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图一。基准测试流程概述(图片由作者提供)。</p></figure></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><h1 id="3a6f" class="ny mu it bd mv nz ou ob my oc ov oe nb jz ow ka ne kc ox kd nh kf oy kg nk oi bi translated">0.管道前步骤</h1><p id="bbed" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">由于每个<strong class="lb iu">数据集的结构</strong>不同(例如，目标变量的不同名称或数据类型)，首先以<strong class="lb iu">一致的格式</strong>提交它们是有意义的。</p><p id="f6c8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，<strong class="lb iu">目标列</strong> <strong class="lb iu">应该始终命名为</strong><strong class="lb iu"><em class="me"/></strong><em class="me"/>，其值为<em class="me"> bool </em>。同样，<strong class="lb iu">不提供任何值</strong>(例如，用户id) <strong class="lb iu">的列也应该被删除</strong>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="9cb8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上面的代码片段显示了加载和操作一个数据集的例子(<em class="me"> ibm hr </em>)。对于您想要用于基准测试的任何其他数据集，可以重复第<code class="fe pb pc pd pe b">7-12</code>行。</p><p id="6bf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">每个数据集格式正确后，可以应用<strong class="lb iu">次要预清洗步骤</strong>(见以下代码)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="27e0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第<code class="fe pb pc pd pe b">4-11</code> <strong class="lb iu">行将列名转换为小写</strong> ( <code class="fe pb pc pd pe b">4</code>)，<strong class="lb iu">删除<strong class="lb iu">缺失值超过20%的列</strong>(<code class="fe pb pc pd pe b">6-7</code>)。</strong></p><p id="1619" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在辅助函数<em class="me"> df_pre_cleaning </em>应用于所有数据集之后，可以使用一个简单的管道(<code class="fe pb pc pd pe b">18-23</code>)来移除<strong class="lb iu">重复列</strong>和具有<strong class="lb iu">常量值的列</strong>。最后，预清理的数据集存储为。csv文件(<code class="fe pb pc pd pe b">31</code>)。</p><h1 id="5d6f" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">1.初始配置和加载数据</h1><p id="eea9" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">在确保数据集被预清理和持久化之后，可以构建实际的基准测试。作为初始步骤，必须设置类似于<strong class="lb iu">抑制警告</strong> ( <code class="fe pb pc pd pe b">2–6</code>)、<strong class="lb iu">启用日志记录</strong> ( <code class="fe pb pc pd pe b">9-16</code>)以及确保我们的<strong class="lb iu">管道何时可视化</strong>(当被调用时)(<code class="fe pb pc pd pe b">23</code>)的配置。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="6514" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在此步骤之后，以<em class="me">_ cleaned . CSV</em>(26–30)结尾的每个数据集被加载到<em class="me">数据集</em>字典中。</p><h1 id="aecc" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">2.定义抽样方法</h1><p id="14a0" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">流失数据集通常遭受<strong class="lb iu">高级不平衡</strong>。这意味着<strong class="lb iu">数量的搅棒</strong>属于<strong class="lb iu">少数</strong>。为了处理这种等级不平衡，不平衡学习包<a class="ae ky" href="https://imbalanced-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"/>带有一组不同采样方法的<strong class="lb iu"/>。在这里，我将重点介绍<a class="ae ky" href="https://link.springer.com/article/10.1007/s41060-022-00312-5#citeas" rel="noopener ugc nofollow" target="_blank"> Geiler等人(2022) </a>也使用过的方法。但是，您可以随意扩展下面的列表。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="84f8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了稍后在管道中使用这些采样方法，必须先将它们引入<strong class="lb iu">右格式</strong>(元组)<strong class="lb iu"/>。使用多个采样方法(<code class="fe pb pc pd pe b">20-31</code>)的<strong class="lb iu">组合的方法，必须被<strong class="lb iu">包装在<em class="me">im pipeline</em>对象中。</strong></strong></p><h1 id="662c" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">3.定义模型</h1><p id="33f8" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">有许多机器学习模型可以预测客户流失。对于这次基准测试，我决定坚持以下几点:</p><ul class=""><li id="f41f" class="mf mg it lb b lc ld lf lg li mh lm mi lq mj lu nr ml mm mn bi translated"><a class="ae ky" href="https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification" rel="noopener ugc nofollow" target="_blank"> GEV-NN </a> (gev_nn)</li><li id="6fa5" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://github.com/naomifridman/Neural-Network-Churn-Prediction/blob/master/FFNN_churn_predict_0_12174.ipynb" rel="noopener ugc nofollow" target="_blank">前馈神经网络</a> (ffnn)</li><li id="976e" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a> (lr)</li><li id="6f5e" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林</a>(射频)</li><li id="6484" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://xgboost.readthedocs.io/en/stable/python/python_api.html" rel="noopener ugc nofollow" target="_blank"> XGB分类器</a> (xgb)</li><li id="2cae" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="noopener ugc nofollow" target="_blank">knighborsclassifier</a>(KNN)</li><li id="edd9" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank"> SVC </a> (svc)</li><li id="311c" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html" rel="noopener ugc nofollow" target="_blank">lgbm分类器</a> (lgb)</li><li id="48c1" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">高斯朴素贝叶斯 (gnb)</li><li id="44d7" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">两个<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html" rel="noopener ugc nofollow" target="_blank">投票分类器</a>(软投票)，由lr、xgb、rf和ffnn组成</li></ul><p id="63b9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前两个<strong class="lb iu">深度学习模型</strong>是来自过去客户流失预测竞赛的(获胜)<strong class="lb iu">解决方案。他们的代码不能在scikit-learn管道中直接使用。因此，我必须首先使他们的解决方案“管道兼容”。其余的模型是scikit-learn的默认实现，或者为它提供一个包装器(lgb)。</strong></p><h2 id="e601" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">3.1 GEV-NN</h2><p id="3080" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">GEV-NN是一个用于不平衡分类的深度学习框架。作者<a class="ae ky" href="https://www.sciencedirect.com/science/article/abs/pii/S095070512030037X?via%3Dihub" rel="noopener ugc nofollow" target="_blank"> Munkhdalai等人(2020) </a>声称，它比最先进的基线算法最多高出约2%。他们的GitHub代码可以在这里找到<a class="ae ky" href="https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="7411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了在我的scikit-learn管道中实现它们的架构，我实现了一个<a class="ae ky" href="https://scikit-learn.org/stable/developers/develop.html" rel="noopener ugc nofollow" target="_blank">定制分类器</a>，并从它们的代码中调用相关函数(MLP_AE)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="965e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">MLP_AE类的代码存储在一个单独的文件中，这个文件与他们在<a class="ae ky" href="https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification/blob/master/Gev_network.py" rel="noopener ugc nofollow" target="_blank"> Gev_network.py </a>中的代码几乎相同。作者在确定批量大小时考虑了给定(训练)集的大小。所以我确保将<em class="me"> batch_size </em>作为fit_param ( <code class="fe pb pc pd pe b">34–36</code>)提供。</p><h2 id="4d25" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">3.2前馈神经网络(FFNN)</h2><p id="99e1" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">与GEV-NN模型类似，FFNN模型也是为一项竞赛开发的(WSDM-KKBox的流失预测挑战)。内奥米·弗里德曼的代码可以在这里找到<a class="ae ky" href="https://github.com/naomifridman/Neural-Network-Churn-Prediction" rel="noopener ugc nofollow" target="_blank">。因为她的代码遵循一种更简单的方法，所以我不必编写自定义的分类器。相反，我可以构建一个</a><a class="ae ky" href="https://www.tensorflow.org/api_docs/python/tf/keras/wrappers/scikit_learn" rel="noopener ugc nofollow" target="_blank"> KerasClassifier </a>，它是一个包装器，用于将Scikit-Learn API与Keras模型一起使用。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="d5b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">包装器(<code class="fe pb pc pd pe b">36–41</code>)需要一个返回编译模型(<code class="fe pb pc pd pe b">5-24</code>)的函数。基于原始代码，我还确保了除了存储模型之外的所有回调函数都得到实现。</p><h2 id="5c48" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">3.3整合一切</h2><p id="c9bb" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">现在，这些定制解决方案与sci-kit learn管道兼容，其他默认scikit-learn模型可以快速定义，并作为元组<strong class="lb iu">存储在列表</strong> ( <code class="fe pb pc pd pe b">48-58</code>)中，以便稍后在基准测试期间逐一调用<strong class="lb iu"/>(参见步骤6)。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="1359" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">4.初始管道</h1><p id="30d5" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">流水线的元素<strong class="lb iu">非常动态</strong>。在每次迭代中，<strong class="lb iu">采样方法</strong>和<strong class="lb iu"> ML </strong>的<strong class="lb iu">组合</strong>在给定数据集上进行<strong class="lb iu">基准测试。然而<strong class="lb iu">管道<strong class="lb iu">的某些部分</strong>保持不变</strong>。这些零件被定义为<strong class="lb iu"> <em class="me">初始管线</em> </strong>(图2，左)。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pf"><img src="../Images/565a11c4ece8750ddb50ca6f9589fa66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k-Il-h12pKrWs8q5Vt1cug@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图二。初始管道(左)和扩展管道示例(右)(图片由作者提供)。</p></figure><p id="b75a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">动态部分</strong>表示在每次迭代中改变的采样方法和ML模型的组合。这个管道“扩展”的例子可以在图2的右边看到。在给定方法的交叉验证<strong class="lb iu">评分完成</strong>后，<strong class="lb iu">管道被设置为其初始状态</strong>(零件2从管道中移除)并且一个<strong class="lb iu">新组合被附加到它</strong>。</p><p id="7981" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">下面的代码显示了这个初始管道的实现。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="c24b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">管道<strong class="lb iu">区分数字</strong> ( <code class="fe pb pc pd pe b">4-8</code>)和<strong class="lb iu">类别特征</strong> ( <code class="fe pb pc pd pe b">9-13</code>)。<strong class="lb iu">数值型</strong>特征中的缺失值被特征的均值 ( <code class="fe pb pc pd pe b">5</code>)代替<strong class="lb iu">，而对于<strong class="lb iu">类别型特征</strong>，则使用<strong class="lb iu">最频繁值</strong>(<code class="fe pb pc pd pe b">10</code>)。在插补步骤之后，一个<strong class="lb iu">最小最大缩放器</strong>被应用于<strong class="lb iu">数字</strong>列(<code class="fe pb pc pd pe b">6</code>)和一个<strong class="lb iu">一个</strong>一个<strong class="lb iu">分类</strong>列(<code class="fe pb pc pd pe b">11</code>)。</strong></p><h1 id="f7c6" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">5.要跟踪的分数和正确的批量</h1><h2 id="1320" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">5.1.得分</h2><p id="d2a7" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">交叉验证期间跟踪的分数如下:</p><ul class=""><li id="7588" class="mf mg it lb b lc ld lf lg li mh lm mi lq mj lu nr ml mm mn bi translated"><a class="ae ky" href="https://rasbt.github.io/mlxtend/user_guide/evaluate/lift_score/" rel="noopener ugc nofollow" target="_blank">提升得分</a>(将模型预测与随机生成的预测进行比较)</li><li id="77e9" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html" rel="noopener ugc nofollow" target="_blank"> ROC AUC </a></li><li id="8175" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank"> F1分数</a>(用于真实类和宏)</li><li id="039b" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html" rel="noopener ugc nofollow" target="_blank"> F2分数</a></li><li id="d591" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html" rel="noopener ugc nofollow" target="_blank">回想一下</a>(在客户流失预测中，我们通常在假阴性上有更高的成本)</li><li id="7838" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html" rel="noopener ugc nofollow" target="_blank">精度</a></li><li id="dfb6" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html" rel="noopener ugc nofollow" target="_blank">平均精度</a> (PR AUC)</li></ul><p id="2fef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现可以在下面找到。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="0d01" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于提升分数不是默认的sci-kit学习分数，我使用了<em class="me"> make_scorer </em>函数(<code class="fe pb pc pd pe b">3</code>)使其兼容。</p><h2 id="c4e9" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">5.2确定正确的批量</h2><p id="37a8" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">在运行基准测试之前，我创建了一个<strong class="lb iu">助手函数</strong>，该函数<strong class="lb iu">根据(训练)数据确定正确的批量大小</strong>。该功能遵循<a class="ae ky" href="https://www.sciencedirect.com/science/article/abs/pii/S095070512030037X?via%3Dihub" rel="noopener ugc nofollow" target="_blank"> Munkhdalai等人(2020) </a> <a class="ae ky" href="https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification/blob/master/evaluation_KEEL.py" rel="noopener ugc nofollow" target="_blank">设置<strong class="lb iu">适当批量值</strong>的方法</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><h1 id="bae4" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">6.基准循环</h1><p id="49fc" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">基准测试(参见下面的代码)由<strong class="lb iu">三个嵌套循环</strong>组成:</p><ul class=""><li id="243d" class="mf mg it lb b lc ld lf lg li mh lm mi lq mj lu nr ml mm mn bi translated">第一级:数据集(<code class="fe pb pc pd pe b">3</code>)</li><li id="038b" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">第二级:模特(<code class="fe pb pc pd pe b">11</code>)</li><li id="0ed8" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">第三级:抽样方法(<code class="fe pb pc pd pe b">14</code></li></ul><p id="a0e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在每次循环之前，创建一个<strong class="lb iu">字典</strong> ( <code class="fe pb pc pd pe b">9,13</code>)来存储各个基准组合的分数。上一步(5.1)中定义的<em class="me"> bnchmrk_results </em>字典的结构应该如下所示:</p><pre class="kj kk kl km gt pg pe ph pi aw pj bi"><span id="cfc2" class="mt mu it pe b gy pk pl l pm pn">{<br/>     '<strong class="pe iu">data set ds</strong>': {<br/>        '<strong class="pe iu">model m</strong>':{<br/>           '<strong class="pe iu">sampling approach sa</strong>': {<br/>              'lift_score':[],<br/>              'roc_auc':[],<br/>              'f1_macro':[],<br/>              'recall':[]<br/>           }, ...<br/>        }, ...<br/>     }, ...<br/>}</span></pre><p id="e792" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第一个循环(数据集)中，<strong class="lb iu"> X和y通过删除/分配目标变量<em class="me"> churn </em>来定义</strong> ( <code class="fe pb pc pd pe b">5-7</code>)。</p><p id="8cf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在内循环(第三级—从<code class="fe pb pc pd pe b">14</code>开始)中，相应的<strong class="lb iu">采样方法被附加到初始管道</strong> ( <code class="fe pb pc pd pe b">21–25</code>)。由于一些采样方法具有<strong class="lb iu">多个步骤</strong>(例如，SMOTE + RND)，因此需要一个<strong class="lb iu">循环来附加每个单独的步骤</strong>。附加采样方法后，最后附加<strong class="lb iu">模型和</strong> ( <code class="fe pb pc pd pe b">28</code>)。</p><p id="c60b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如前所述，创建了一个助手函数来确定正确的批量大小。当当前模型是FFNN或GEV-NN时，调用该函数(<code class="fe pb pc pd pe b">31–39</code>)。然后，其输出通过交叉验证函数中的<em class="me"> fit_params </em>参数提供给相应的深度学习模型。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="3fb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在第<code class="fe pb pc pd pe b">44-53</code>行中，<a class="ae ky" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html" rel="noopener ugc nofollow" target="_blank"> <em class="me"> cross_validate </em> </a>函数被调用，其分割策略为RepeatedStratifiedKFold。结果写入<em class="me"> sampling_results </em>字典(<code class="fe pb pc pd pe b">55</code>)后，【扩展】流水线<strong class="lb iu">被设置回初始状态</strong> ( <code class="fe pb pc pd pe b">59</code>)。</p><p id="b95d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于一些基准运行了相当长的时间，每个数据集的结果被存储为一个pickle文件(<code class="fe pb pc pd pe b">68–69</code>)。</p><h1 id="07bc" class="ny mu it bd mv nz oa ob my oc od oe nb jz of ka ne kc og kd nh kf oh kg nk oi bi translated">7.形象化</h1><p id="b75e" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">可视化不同方法性能的综合方法是使用<strong class="lb iu">箱线图</strong>。对于这种类型的可视化，模型名称<strong class="lb iu">与它们各自的(总体)性能</strong>一起标绘在轴上。这意味着我们的<em class="me"> bnchmrk_results </em>字典(见#6) <strong class="lb iu">中的数据集级别可以被跳过</strong>。</p><p id="30f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">但是首先，下面的脚本加载所有pickle文件，并将它们的内容(每个数据集上的基准)添加到<em class="me">结果</em>字典中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="62b6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如开始时提到的，在这个可视化中将不考虑数据集。因此，必须首先应用一些转换，使数据具有以下形状:</p><pre class="kj kk kl km gt pg pe ph pi aw pj bi"><span id="e954" class="mt mu it pe b gy pk pl l pm pn">{<br/>        '<strong class="pe iu">sampling approach sa</strong>':{<br/>           '<strong class="pe iu">model m</strong>': {<br/>              'lift_score':[],<br/>              'roc_auc':[],<br/>              'f1':[],<br/>              'recall':[]<br/>           }, ...<br/>        }, ...<br/>}</span></pre><p id="e07f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">不幸的是，除了使用下面的代码之外，我没能及时找到更好的方法将数据带入正确的结构:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="f38b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">该代码创建一个新的字典(<code class="fe pb pc pd pe b">12</code>)来存储原始字典中经过整形的数据。辅助函数<em class="me"> metric_merger </em> ( <code class="fe pb pc pd pe b">5–9</code>)连接每个误差度量的值。</p><p id="a816" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，整形后的数据可以被可视化。下面的代码由两部分组成。第一个(lines <code class="fe pb pc pd pe b">1–21</code>)是一个辅助函数，它创建一个单一的方框图。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="4ed3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第二部分(第<code class="fe pb pc pd pe b">24-46</code>行)循环通过每个采样方法，然后绘制各自的箱线图。</p><p id="890a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如引言部分所述，<strong class="lb iu">基准测试结果值得单列一篇文章</strong>。这就是为什么我<strong class="lb iu">将下面的可视化只限于IBM HR数据集</strong>(图3 ),并将结果保留不加注释。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi po"><img src="../Images/69a627b9c6d6ed64be902d7897d9d732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vzPWz7rypPwSbNEtpQm38Q@2x.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3。不同方法的可视化仅限于IBM HR数据集(图片由作者提供)。</p></figure></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><h1 id="1999" class="ny mu it bd mv nz ou ob my oc ov oe nb jz ow ka ne kc ox kd nh kf oy kg nk oi bi translated">结论</h1><p id="69e8" class="pw-post-body-paragraph kz la it lb b lc nm ju le lf nn jx lh li oj lk ll lm ok lo lp lq ol ls lt lu im bi translated">用定制的分类器或包装器创建一个更复杂的管道可能是一个挑战。然而，它也非常有趣，我有一个陡峭的学习曲线。最耗时的部分之一无疑是将定制的深度学习模型(gev_nn，ffnn)集成到scikit-learn管道中。</p><p id="406b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，在几个数据集上评估每种方法的计算时间可能会很紧张。这也可能通过最初的管道步骤得到加强。我使用了，像在<a class="ae ky" href="https://link.springer.com/article/10.1007/s41060-022-00312-5#citeas" rel="noopener ugc nofollow" target="_blank"> Geiler等人(2022) </a>的论文中，一键编码。如果具有大量类别特征的数据集进入管道，就会产生大量新列(维数灾难)。另一种方法是在这里增加一个降维步骤。</p><p id="31cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望这些代码能对您的下一个项目有所帮助:</p><ul class=""><li id="f96e" class="mf mg it lb b lc ld lf lg li mh lm mi lq mj lu nr ml mm mn bi translated"><a class="ae ky" href="https://github.com/darinkist/customer_churn_benchmarking/blob/main/Data_Preparation.ipynb" rel="noopener ugc nofollow" target="_blank">预清洗代码</a></li><li id="c9a0" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://github.com/darinkist/customer_churn_benchmarking/blob/main/Benchmarking_Pipeline.ipynb" rel="noopener ugc nofollow" target="_blank">标杆</a></li><li id="362c" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated"><a class="ae ky" href="https://github.com/darinkist/customer_churn_benchmarking/blob/main/Visualization.ipynb" rel="noopener ugc nofollow" target="_blank">可视化</a></li></ul></div><div class="ab cl on oo hx op" role="separator"><span class="oq bw bk or os ot"/><span class="oq bw bk or os ot"/><span class="oq bw bk or os"/></div><div class="im in io ip iq"><h1 id="7c9e" class="ny mu it bd mv nz ou ob my oc ov oe nb jz ow ka ne kc ox kd nh kf oy kg nk oi bi translated">来源</h1><ul class=""><li id="54bd" class="mf mg it lb b lc nm lf nn li no lm np lq nq lu nr ml mm mn bi translated">盖勒，l .，阿费尔特，s .，纳迪夫，m .，2022。<strong class="lb iu">流失预测的机器学习方法综述</strong>。国际数据科学分析。<a class="ae ky" href="https://doi.org/10.1007/s41060-022-00312-5" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/s41060-022-00312-5</a></li><li id="c1e3" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">蒙赫达莱，l，蒙赫达莱，t，刘，K.H，2020。GEV-NN: <strong class="lb iu">针对二元分类中类别不平衡问题的深度神经网络架构</strong>。基于知识的系统。<a class="ae ky" href="https://doi.org/10.1016/j.knosys.2020.105534" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1016/j.knosys.2020.105534</a></li></ul><h2 id="86a3" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">使用的数据</h2><ul class=""><li id="35f6" class="mf mg it lb b lc nm lf nn li no lm np lq nq lu nr ml mm mn bi translated"><strong class="lb iu"> IBM HR Analytics员工流失&amp;绩效</strong> ( <a class="ae ky" href="https://opendatacommons.org/licenses/dbcl/1-0/" rel="noopener ugc nofollow" target="_blank">数据库内容许可证(DbCL) v1.0 </a>)，<a class="ae ky" href="https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/datasets/pavansubhasht/IBM-HR-Analytics-attraction-dataset</a></li></ul><h2 id="abde" class="mt mu it bd mv mw mx dn my mz na dp nb li nc nd ne lm nf ng nh lq ni nj nk nl bi translated">GitHubs</h2><ul class=""><li id="f801" class="mf mg it lb b lc nm lf nn li no lm np lq nq lu nr ml mm mn bi translated">蒙克达莱湖，2020年。<strong class="lb iu">GEV-NN-A-deep-neural-network-architecture-for-class-unbalancy-problem-in-binary-classification</strong>。<a class="ae ky" href="https://github.com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-imbalance-problem-in-binary-classification" rel="noopener ugc nofollow" target="_blank">https://github . com/lhagiimn/GEV-NN-A-deep-neural-network-architecture-for-class-unbalancy-problem-in-binary-classification</a></li><li id="badc" class="mf mg it lb b lc mo lf mp li mq lm mr lq ms lu nr ml mm mn bi translated">新泽西州弗里德曼，2019年。<strong class="lb iu">神经网络，流失预测</strong>。<a class="ae ky" href="https://github.com/naomifridman/Neural-Network-Churn-Prediction" rel="noopener ugc nofollow" target="_blank">https://github . com/Naomi fridman/Neural-Network-Churn-Prediction</a></li></ul></div></div>    
</body>
</html>