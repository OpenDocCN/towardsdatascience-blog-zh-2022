<html>
<head>
<title>5 Minute Paper Explanations: Food AI Part I</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">5分钟书面解释:食品人工智能第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-minute-paper-explanations-food-ai-part-i-9276b61873c1#2022-08-08">https://towardsdatascience.com/5-minute-paper-explanations-food-ai-part-i-9276b61873c1#2022-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0220" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">im2recipe论文“学习烹饪食谱和食物图像的跨模态嵌入”的直观深入分析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/fa1251466e970e010ebb5b44f0e7b927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZqrtA7Ab65WRZnbq"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">乍得·蒙塔诺在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="5cb5" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">问题简介</h1><p id="6834" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">欢迎来到我的新系列论文讲解！你可能会问那里有什么不同？好吧，我不会涵盖流行或著名的论文，而是选择机器学习研究中的子(子)领域，并通过这些文章绘制他们的研究进展。</p><p id="deef" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">让我们开始吧——今天，我们将了解一下<a class="ae kv" href="https://arxiv.org/abs/1905.01273" rel="noopener ugc nofollow" target="_blank">的论文</a>(发表于2018年)，该论文介绍了用于食品中机器学习研究的庞大数据集，并介绍了<em class="mp"> im2recipe </em>检索问题。</p><p id="166f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">问题陈述:</strong>给定一幅食物的图像(想象一下你最喜欢的食物！)，检索制作该食物的食谱。为了能够做到这一点，使模型学习相应的图像和配方嵌入，将这些嵌入转换到共享的联合嵌入空间，并在给定图像的情况下最小化测量配方检索性能的损失。很简单，对吧？</p><p id="b4f9" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">对于不知道什么是跨通道的人来说:通道是我们输入模型的一种信息源。它可以是视频、图像、文本、音频等。在<em class="mp"> im2recipe </em>中，我们有图像和文本。所以，我们用两种模态工作，从一种到另一种，因此是跨模态的。</p><h1 id="4786" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">领域背景和改进</h1><p id="fa51" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">以前有过将食物与人工智能或机器学习交叉的研究。大型数据集的一个突出例子是Food-101和介绍它的<a class="ae kv" href="https://link.springer.com/chapter/10.1007/978-3-319-10599-4_29" rel="noopener ugc nofollow" target="_blank">论文</a>。这是一个关于食物图像的分类问题。相比之下，<em class="mp"> im2recipe </em>论文介绍了一个<strong class="lq ir">检索问题</strong>和一个更丰富的数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/52e2856d7ede0433a3175694a51d0bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BO5x1Qm9gByZkzdhUjWrhg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Food-101数据集类的一些示例(图片由作者提供)</p></figure><p id="fc77" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果我们看到Food-101数据集中的类，它只包含关于食物名称的信息。在名为<em class="mp"> Recipe1M，</em>的<em class="mp"> im2recipe </em>数据集中，我们不仅有更多的数据点，而且这些数据点包括食物图片、标题(名称)、制作说明和配料。</p><p id="99db" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这种丰富数据的一个优势是，我们现在能够通过它的说明和成分对食谱的状态有一种逐步的信息。我们可以知道一种配料是生的、烤的、炸的等等。并且理论上能够用一个好的模型在这些阶段学习相应的不同图像。</p><h1 id="fd28" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">资料组</h1><p id="a262" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">庞大的<em class="mp"> Recipe1M </em>数据集包含100万份食谱食材和说明，以及那些从烹饪网站上提取和下载的准备好的食谱的80万张相应图像，并组织成JSON格式文件。</p><p id="0d83" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在文本情态中，我们有一个标题、一份配料清单和一系列准备菜肴的说明。在第二种模式中，我们有RGB/JPEG格式的与配方相关联的任何图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/6cff4e441da29fa807f94bbd176f4ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_DEhXgmybNjgoCNoEK2MXA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">配方的文本数据示例。id映射到相应配方的图像(作者的图像)</p></figure><p id="a28c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作者对收集的数据集进行了一些分析:</p><ol class=""><li id="5547" class="ms mt iq lq b lr mk lu ml lx mu mb mv mf mw mj mx my mz na bi translated">数据集中的平均食谱由九种成分组成，它们在十个指令的过程中被转化。</li><li id="6bd1" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">配方图像对的精确副本已被删除</li><li id="f9e3" class="ms mt iq lq b lr nb lu nc lx nd mb ne mf nf mj mx my mz na bi translated">16，000种成分中的4，000种占数据中成分出现次数的95%</li></ol><h1 id="a62d" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">体系结构</h1><p id="88a9" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如前所述，有两种形式和四种类型的数据:标题、成分、说明和图像。我们以不同的方式嵌入它们。</p><p id="3b7b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如下所示，首先使用双向LSTM从数据的成分列表中提取成分，然后编码成word2vec表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/0f6c49ad0a51716c379830e823723f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X77Ki-DPzCWR25kYTVmLPA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习成分嵌入(作者图片)</p></figure><p id="119d" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">使用word2vec中使用的<em class="mp">跳过方法</em>对每个指令元素进行编码，其中每个指令以其之前和之后的指令为目标，并且编码被优化以改善这些相邻指令的预测。这里所做的修改是也引入了开始和结束指令标记。接下来，这些单独的指令编码通过LSTM来产生指令嵌入。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/9fe31e47a7d55057f273027f1fd68a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LJTCDWDjBzurNJWx-GHVKg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习指导嵌入(作者图片)</p></figure><p id="e8ad" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">接下来，这些指令和成分嵌入通过仿射变换(具有学习的权重和偏差的线性变换)连接和变换到共享嵌入空间。对于作为从预训练的ResNet-50 / VGG-16提取的特征的图像嵌入也是如此。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/3cc13d52776e04dc4668e6e1441d4c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UIFBnB8J6kXPdMW8iq0v0w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习共享嵌入(作者图片)</p></figure><p id="6b97" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">语义规则化</strong></p><p id="5952" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">除了上述主要架构之外，作者还通过使联合嵌入模型(具有共享权重)学习将任何食谱图像或文本信息分类到Food-101类之一来执行正则化。直观上，这确保了模型已经粗略地知道了一些嵌入聚类(就这些类而言),并且它不会试图为每个图像-配方对创建一个聚类，因此不会过度拟合。因为权重在两个模态之间共享，所以这也确保了所学习的图像-食谱对嵌入彼此对齐(我们不会得到同一道菜的图像和文本信息的单独聚类)。</p><p id="1a3f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">然而，该论文的作者发现，Food-101类只覆盖了<em class="mp"> Recipe1M </em>数据集的13%，因此，他们用来自<em class="mp"> Recipe1M </em>训练集(清理后)的食谱标题中的946个最常见的二元模型来扩充它。通过这样做，他们实现了50%的覆盖率</p><h1 id="ecb7" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">损失函数</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/f314d551a9d75a888e4585d4fe0ff1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*ejRKksQpkPY2-v80ft8jWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">余弦相似度与利润损失(图片来自论文，作者)</p></figure><p id="dd64" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所使用的损失函数是具有边际损失的余弦相似性。训练是以成对的方式进行的，类似于如何训练三重损失函数——用正和负图像配方对。这种训练方法和上述损失函数确保了正对(<em class="mp"> y=1 </em>)的图像配方嵌入更靠近在一起(差值更接近于0)，而负对被推得更远，其间有固定的余量<strong class="lq ir"> α </strong>。</p><p id="5a7c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated"><strong class="lq ir">增加语义正则化</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/27b20c1a0e3ec3dcc0c9984bf2b07e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*6eRYYPuJgnCP-M_HwTJrUw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">组合余弦和正则化损失(图片来自论文，作者)</p></figure><p id="6bd4" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">通过添加正则化损失以获得组合，我们可以直观地看到学习过程将正对的图像配方嵌入集合在一起，将负对的图像配方嵌入推得更远，同时始终通过共享权重和分类保持图像配方对嵌入彼此对齐。具体地，如果cᵣ和cᵥ(分别用于图像和配方嵌入的分类预测)不同，则正则化损失将增加，否则将减少。</p><h1 id="86f5" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">实验和结果</h1><p id="2751" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">这是报告结果的方式:在从测试集中随机选择的1000个配方图像对的子集上。我们重复实验10次并记录平均结果。我们报告了所有检索实验的中值排序(MedR)和顶部K的召回率(R@K)。</p><p id="438c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果我为每个图像检索100个食谱，那么中值等级就是每个实验中每对正确食谱出现的位置的中值。类似地，im2recipe任务中的R@5表示在前5名中检索到相应配方的所有图像查询的百分比，因此越高越好。</p><p id="be81" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">基线结果是使用CCA的结果。顺便说一下，CCA是一种很像PCA的技术，但是用于多组变量。典型相关分析确定了一组典型变量，即每组内变量的正交线性组合，它们最好地解释了组内和组间的可变性。详细的结果和消融研究可以在论文中看到，并且是不言自明的</p><p id="1797" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我想在这里重点关注的是对嵌入的分析。作者使用向量算法提出，模型学习的嵌入具有语义意义。下面是一个例子。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/a776ca4ffec36670ff02ddb8461620f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1DqZTSlDhQWLFh6RqCwvlQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">word2vec类型向量算法显示了学习嵌入的语义(图片来自论文，作者)</p></figure><p id="7596" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">作者还使用给定神经元的顶部激活图像、成分列表和烹饪说明来提取和可视化局部单元激活，并专注于对这些单元的激活贡献最大的特定图像和文本区域。结果如下</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/c71c1174400adefec61ebd43c5f60686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XswzK-hmR5nj5kFzGgcQeg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">学习特定的单元检测器。单元352学习检测图像和指令文本中的奶油，这也示出了模型跨模态对齐(图像来自论文，由作者)</p></figure></div><div class="ab cl nn no hu np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="ij ik il im in"><p id="9176" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这是我开始的一个新系列的一部分，关于直觉的论文解释。我将在行业中挑选一个子域，并浏览该域中的论文。如果你喜欢我写的东西，可以考虑订阅或者关注我<a class="ae kv" href="https://www.medium.com/@kunjmehta10" rel="noopener">这里</a>或者在<a class="ae kv" href="http://www.linkedin.com/in/kunjmehta" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>或者<a class="ae kv" href="https://www.twitter.com/@kunjmehta10" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上与我联系！关于我之前文章的代码，请访问我的<a class="ae kv" href="https://github.com/kunjmehta/Medium-Article-Codes" rel="noopener ugc nofollow" target="_blank"> GitHub </a></p></div></div>    
</body>
</html>