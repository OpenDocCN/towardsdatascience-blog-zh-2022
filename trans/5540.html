<html>
<head>
<title>Understanding Kolmogorov-Smirnov (KS) Tests for Data Drift on Profiled Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解 Kolmogorov-Smirnov (KS)测试对分析数据的数据漂移</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-kolmogorov-smirnov-ks-tests-for-data-drift-on-profiled-data-5c8317796f78#2022-12-14">https://towardsdatascience.com/understanding-kolmogorov-smirnov-ks-tests-for-data-drift-on-profiled-data-5c8317796f78#2022-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5591" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">数据漂移符合数据剖析</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/03e9bf92c581b535a0a48aaff4cd3955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_wnpvvPgUZB6Bg5PiUj1g.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="41b3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> TLDR: </strong>我们进行了统计测试，特别是 Kolmogorov-Smirnov (KS)测试，应用于完整数据集和数据集概要，并比较了结果。这些结果允许我们讨论 KS 漂移检测的数据分析的局限性以及 KS 算法在不同情况下的优缺点。我们还提供了<a class="ae lr" href="https://github.com/whylabs/whylogs/blob/mainline/python/examples/benchmarks/KS_Profiling.ipynb" rel="noopener ugc nofollow" target="_blank">代码</a>供您自己重现实验。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="9812" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">数据漂移是 ML 应用中众所周知的问题。如果不解决这个问题，它会大大降低你的模型，使你的模型完全不可用。解决这些问题的第一步是能够检测和监控数据漂移。</p><p id="7ad8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有多种方法可以监控生产中的数据漂移。通常使用统计测试来获得漂移检测值，并随着时间的推移对其进行监控。传统的漂移检测算法通常需要完整的原始数据来计算这些值，但对于大规模系统，由于存储或隐私问题，完全访问历史数据可能是不可行的。一种可能的替代方法是预先对数据进行采样，这也有缺点:通过聚合，您可能会丢失重要信息，如罕见事件和异常值，从而损害结果的可靠性。</p><p id="1f41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第三种方法是在应用漂移检测算法之前分析数据。配置文件捕获数据的关键统计属性，例如分布度量、频繁项、缺失值等等。然后，我们可以使用这些统计特性来应用漂移检测技术的修改版本。当然，由于<a class="ae lr" href="https://en.wikipedia.org/wiki/No_free_lunch_theorem" rel="noopener ugc nofollow" target="_blank">没有免费的午餐</a>，这种策略也有其不利之处。profile 是对原始数据的估计，因此，使用它进行漂移检测将会生成实际漂移检测值的近似值，如果使用完整的数据，您将会得到该近似值。</p><p id="a6a4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">但是，剖析过程如何与漂移检测算法一起工作，我们这样做会损失多少呢？</p><blockquote class="lz ma mb"><p id="473c" class="kv kw mc kx b ky kz jr la lb lc ju ld md lf lg lh me lj lk ll mf ln lo lp lq ij bi translated">在这篇博文中，我们将把自己限制在数值单变量分布，并选择一个特定的算法来进行实验:Kolmogorov-Smirnov (KS)测试。我们还将深入了解 KS 测试本身对于不同场景的适用性。</p></blockquote><p id="2900" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">以下是我们将在这篇博文中涉及的内容:</p><ul class=""><li id="23d8" class="mg mh iq kx b ky kz lb lc le mi li mj lm mk lq ml mm mn mo bi translated">什么是 KS 测试？</li><li id="eba1" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated">什么是数据分析？</li><li id="d347" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated">试验设计</li><li id="669f" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated">实验<br/> -实验#1 —数据量<br/> -实验#2 —桶数<br/> -实验#3 —轮廓尺寸</li></ul><p id="e037" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你可以检查这篇博文中使用的代码，甚至可以通过访问<a class="ae lr" href="https://colab.research.google.com/github/whylabs/whylogs/blob/mainline/python/examples/benchmarks/KS_Profiling.ipynb" rel="noopener ugc nofollow" target="_blank">实验的 Google Colab 笔记本</a>自己运行实验。</p><h2 id="f11c" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">科尔莫戈罗夫-斯米尔诺夫试验</h2><p id="dde3" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated"><a class="ae lr" href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test" rel="noopener ugc nofollow" target="_blank"> KS 测试</a>是两个一维概率分布相等的测试。它可用于将一个样本与参考概率分布进行比较，或者比较两个样本。现在，我们对后者感兴趣。在比较两个样本时，我们试图回答以下问题:</p><p id="08bc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">"这两组样本来自同一概率分布的概率是多少？"</p><p id="f86e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">KS 检验是非参数的，这意味着我们不需要依赖数据来自给定分布族的假设。这很好，因为我们通常不知道现实世界中的底层分布。</p><p id="b570" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">统计数据</strong></p><p id="e1e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">KS 统计可以表示为:</p><p id="4a41" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="mc"> D = supₓ|F₁(x) — F₂(x)| </em></p><p id="76c4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中 F1 和 F2 分别是第一和第二样本的两个累积分布函数。</p><p id="1c3d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">换句话说，KS 统计量是两个累积分布之间的最大绝对差<strong class="kx ir">。</strong></p><p id="a443" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下图显示了统计数据的一个示例，用黑色箭头表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c1a98eba4f06175147b8ab9c49d1f3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*dYfmOk-bjU6vsh56CD9eFw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">双样本 KS 统计量。来源:维基百科[1]</p></figure><p id="a1a8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">零假设</strong></p><p id="b861" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本实验中使用的零假设是两个样本来自同一分布。例如，如果定义我们的统计模型的所有假设都为真(包括我们的测试假设)，小的 p 值将表明数据不太可能。换句话说，我们可以将 p 值解释为数据和定义我们的统计模型的基础假设之间的兼容性的度量，0 代表完全不兼容，1 代表完全兼容*[2]。</p><p id="c374" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了计算这个值，KS 统计量和两种分布的样本量都被考虑在内。拒绝零假设的典型阈值是 1%和 5%，这意味着任何小于或等于这些值的 p 值都会导致零假设被拒绝。</p><p id="4929" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">(*)作者的勘误表——<em class="mc">零假设</em>部分的原文是:“<em class="mc">例如，p 值 0.05 意味着两个样本有 5%的概率来自同一分布。</em>“这是一种误解，并不代表 P 值的正确定义，如论文<em class="mc">统计测试、P 值、置信区间和功效:误解指南</em>【2】所述。</p><h2 id="96fe" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">数据剖析</h2><p id="fd27" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">分析数据集意味着收集数据的统计测量值。这使我们能够以可伸缩、轻量级和灵活的方式生成数据的统计指纹或摘要。罕见的事件和离群值相关的指标可以被准确地捕获。</p><p id="a33c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了分析我们的数据，我们将使用开源数据日志库<strong class="kx ir"> whylogs。</strong>使用 whylogs 进行分析是以流的方式完成的，需要一次通过数据，并允许并行化。配置文件也是可合并的，允许您跨多个计算实例、时间段或地理位置检查您的数据。这是由 Apache DataSketches 首创的一种叫做<strong class="kx ir">草图</strong>的技术实现的。</p><p id="900a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">确切地说，对于这个例子，我们将利用概要文件的分布指标。为了计算 KS 统计量，我们需要生成样本累积分布函数的近似值。这是由 Apache DataSketches 首创的一种叫做数据草图的技术实现的。</p><h2 id="0845" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">试验设计</h2><p id="58fc" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">首先，我们需要数据。在本实验中，我们将从以下分布中抽取两个大小相同的样本:</p><ul class=""><li id="4782" class="mg mh iq kx b ky kz lb lc le mi li mj lm mk lq ml mm mn mo bi translated"><strong class="kx ir">正常</strong>:宽类数据。没有弯曲，在中心周围达到顶点</li><li id="bb95" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx ir"> Pareto </strong>:带有长尾/异常值的偏斜数据</li><li id="f0dc" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx ir">均匀</strong>:在其域内均匀采样</li></ul><blockquote class="lz ma mb"><p id="620b" class="kv kw mc kx b ky kz jr la lb lc ju ld md lf lg lh me lj lk ll mf ln lo lp lq ij bi translated">在这篇博文中，我们将只展示正态分布的结果，但是你可以直接在示例笔记本<a class="ae lr" href="https://github.com/whylabs/whylogs/blob/mainline/python/examples/benchmarks/KS_Profiling.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>中找到帕累托分布和均匀分布的相同实验。从正态分布情况得出的总体结论也可以应用于其余的分布。</p></blockquote><p id="c87b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">漂移注入</strong></p><p id="ce21" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来，我们将漂移注入到一个样本中(我们称之为<strong class="kx ir">目标</strong>分布),以将其与未改变的<strong class="kx ir">参考</strong>分布进行比较。</p><p id="0353" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将通过简单地根据一个参数移动数据的平均值来人为地引入漂移。我们选择使用分布的四分位间距的比率。下面是正态分布情况下的情况:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/d06e3d97097e3755d10616806eb7e87e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DtRqm_ev_EmzPINq"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="75bc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这个想法是有四个不同的场景:无漂移、小漂移、中等漂移和大漂移。漂移的幅度分类和理想的检测/报警过程可能非常主观，取决于您特定应用所需的灵敏度。在这种情况下，我们假设小漂移情况足够小，可以安全地忽略。我们还预计，中等漂移和大漂移情况应会导致漂移警报，因为这两种情况都需要进一步检查。</p><p id="2e11" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">应用 KS 测试</strong></p><p id="48e1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">作为基本事实，我们将使用<strong class="kx ir"> scipy 的</strong>实现双样本 KS 测试，其中包含来自两个样本的完整数据。然后，我们将这些结果与测试的概要版本进行比较。为此，我们将使用<strong class="kx ir"> whylogs 的</strong>近似实现相同的测试，该测试仅使用每个样本的统计特征。</p><p id="c2ad" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">配置文件中包含的分布度量是从一个称为草图绘制的过程中获得的，这为它们提供了许多有用的属性，但也给结果增加了一些误差。因此，每次生成配置文件时，KS 测试结果都可能不同。对于每个场景，我们将对数据进行 10 次分析，并将基本事实与统计数据进行比较，例如这些运行的平均值、最大值和最小值。</p><p id="d393" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">实验变量</strong></p><p id="8542" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的主要目标是回答:</p><p id="2fcd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">“whylogs 的 KS 实现与 scipy 的实现相比如何？"</p><p id="897b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然而，这个答案取决于几个不同的变量。我们将运行三个独立的实验来更好地理解每个变量的影响:数据量、存储桶数量和概要文件大小。第一个与每个样本中数据点的数量有关，而最后两个与 whylogs 内部可调参数有关。</p><h2 id="02b5" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">实验#1 —数据量</h2><p id="3647" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">样本中数据点的数量不仅影响总体 KS 测试，还影响剖析过程本身。因此，调查它如何影响结果是合理的。</p><p id="d333" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们比较了不同样本量(目标和参考分布)的两种实现的 p 值:<strong class="kx ir"> 500、1k、5k、10k 和 50k。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/35ba3078bcf1add9b5d5f30cffcb1471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*S0Ukkz3bHxayYe_cj-l1_g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7d9e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你会注意到我们没有误差线来表示地面实况。对于给定的样本大小和漂移幅度，scipy 的结果是确定的，因为我们总是使用完整的数据，而对于 whylogs，误差线代表 10 次运行中找到的最大值和最小值。</p><p id="17ee" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">请注意，对于中等和大漂移情况，两个 y 轴都非常接近 0，因此，即使样本大小为 500，两种实现方式都会导致 p 值实际上为 0，这表明我们的数据与零假设高度不相容。对于无漂移和小漂移场景，我们可以看到，当比较基于草图的实现的平均 p 值时，两种实现产生了非常相似的结果，但对于特定运行，尤其是对于大尺寸样本，存在一些差异。然而，对于几乎所有的案例，基本事实都在剖析案例的范围之间。同样值得注意的是，在 95%的置信区间，两种实现对于所有场景中的所有点都会产生相同的结论。</p><p id="9ed0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">KS 检验真的很敏感，它的灵敏度随着样本量的增加而增加:在小漂移的情况下，对于大于或等于 5k 的样本量，我们拒绝零假设。尽管这在技术上没有错，但我们最初认为这种情况非常小，可以安全地忽略。</p><p id="ffef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一点上，我们应该问问自己，这个测试实际上是否告诉了我们所关心的事情。小于 0.05 的 p 值会导致拒绝零假设，但它并不能告诉我们任何关于效应大小的信息。换句话说，它告诉我们有差别，但不是差别有多大。可能有统计学意义，但没有实际的实际意义。</p><h2 id="3395" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">实验 2——桶的数量</h2><p id="9d65" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">为了获得离散的累积分布，我们首先需要定义桶的数量。基于草图的 KS 测试将使用这些桶来计算统计数据。我们将使用大小为:<strong class="kx ir"> 5、10、50 和 100 的等距箱柜进行实验。</strong>对于 10 次运行中的每一次，我们将计算精确的和基于草图的 whylogs 实施之间的绝对误差，并绘制平均值，以及表示发现的最小和最大误差的误差条。我们将根据样本大小和漂移幅度显示这些误差，就像之前的实验一样。</p><p id="4cb4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">whylogs 的当前版本将 100 作为默认的存储桶数，这也是前面显示的结果中使用的值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/304d34254965dc86745dc484a02019bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jDBIX4XNtqqZh7rGM4aJZQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="846a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因为图中的一些值比其余的值高得多，所以我们在某些情况下断开了 y 轴，以便更好地显示图中的所有条形。即便如此，一些酒吧仍然太小，看不见。中等漂移和大漂移情况下的误差非常接近于 0，这意味着两种实现方式获得了相似的结果。</p><p id="6d77" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">总的来说，当增加桶的数量时，误差的平均值似乎减小了。然而，对于更大的样本量，误差的方差增加，这是由于在剖析过程中估计误差的增加。</p><p id="4f6c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">到目前为止，对于两种实现方式，实验显示了无漂移情况下的一定程度的随机性。由于 KS 测试仅依赖于分布之间的最大绝对差值，因此采样过程中的任何微小变化都会影响无漂移情况。</p><h2 id="9200" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">实验#3 —外形尺寸</h2><p id="3e1a" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">如前所述，在剖面图中，我们有一个数据草图格式的近似分布。数据草图由参数<strong class="kx ir"> K、</strong>配置，该参数规定了轮廓的尺寸及其估计误差【3】。该参数越高，估计误差越低。之前的所有实验都是在 K=1024，的情况下进行的，但现在我们想看看随着 K 值的变化，误差会受到怎样的影响。</p><p id="9345" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这一次，我们将样本大小固定为 100k，桶的数量固定为 100，并将<strong class="kx ir"> K </strong>参数更改为以下值:<strong class="kx ir"> 256、512、1024、2048 和 4096。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/9328d24be09a1eedce33aa149da7731c.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*5lU6RCMnXL52kPH6-cqSjA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="1dc4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们省略了漂移大小为 0.4 和 0.75 的图表，因为误差始终很小，不需要可视化。</p><p id="c6b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">X 轴是根据序列化时概要文件的大小显示的:<strong class="kx ir"> K </strong>值 256、512、1024、2048 和 4096 分别产生大约 6KB、11KB、22KB、43KB 和 83KB 的概要文件大小。</p><p id="34ad" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如前所述，任何漂移的场景都显示了 KS 测试是多么的敏感。中等和大漂移情况下看不到条形，因为它们的值实际上为 0，但在无漂移情况下，我们可以看到误差与剖面尺寸成反比，并延伸到 K 参数。通过增加 K，由于剖析引起的误差减少，接近两种实现的结果。</p><p id="fbef" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还可以验证，对于这种情况，误差非常小。但是如果我们对最小化这些错误感兴趣，我们可以牺牲轮廓空间来获得更好的结果。</p><h2 id="8192" class="mu mv iq bd mw mx my dn mz na nb dp nc le nd ne nf li ng nh ni lm nj nk nl nm bi translated">结论</h2><p id="ac34" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">让我们总结一下这些实验的一些要点:</p><ul class=""><li id="d3d2" class="mg mh iq kx b ky kz lb lc le mi li mj lm mk lq ml mm mn mo bi translated">对数据配置文件执行 KS 测试是可能的，并且结果非常接近标准实现。然而，结果是不确定的。</li><li id="4aaa" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated">KS 测试非常敏感，随着样本量的增加，它会变得更加敏感。当只在零假设下进行测试时，它可能会告诉我们一些关于分布之间的差异，但对差异的大小不敏感。</li><li id="a7a6" class="mg mh iq kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated">我们可以调整内部参数以获得更好的 whylogs 实现结果。特别是，我们可以增加剖面大小，以获得更接近地面真相的结果。</li></ul><p id="1f1e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们希望这有助于建立对 KS 测试如何与数据剖析一起工作的直觉。我们也对 KS 测试的局限性有了更好的理解。受此激励，我们 whylogs 已经在实施额外的相似性度量！例如，Hellinger distance 已经在 whylogs 中实现了，所以请继续关注更多的实验和基准测试！</p><p id="c423" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">感谢您的阅读，如果您有任何问题/建议，请随时联系我们！如果你对探索项目中的 whylogs 感兴趣，考虑加入我们的<a class="ae lr" href="https://communityinviter.com/apps/whylabs-community/rsqrd-ai-community" rel="noopener ugc nofollow" target="_blank"> Slack 社区</a>来获得支持并分享反馈！</p><h1 id="e1c5" class="nx mv iq bd mw ny nz oa mz ob oc od nc jw oe jx nf jz of ka ni kc og kd nl oh bi translated">参考</h1><p id="af9e" class="pw-post-body-paragraph kv kw iq kx b ky nn jr la lb no ju ld le np lg lh li nq lk ll lm nr lo lp lq ij bi translated">[1]—Kolmogorov–Smirnov 检验。(2022 年 10 月 29 日)。在<em class="mc">维基百科</em>里。<a class="ae lr" href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Kolmogorov % E2 % 80% 93s mirnov _ test</a></p><p id="b714" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2] —格陵兰，s .，森，S.J .，罗斯曼，K.J. <em class="mc">等</em>统计检验，<em class="mc"> P </em>值，置信区间和功效:误解指南。<em class="mc">欧洲流行病学杂志</em> <strong class="kx ir"> 31 </strong>，337–350(2016)。</p><p id="04f7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] —卡宁，z .，朗，k .，&amp;利伯蒂，E. (2016)。流中的最佳分位数逼近。<em class="mc"> arXiv </em>。<a class="ae lr" href="https://doi.org/10.48550/arXiv.1603.05346" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.48550/arXiv.1603.05346</a></p></div></div>    
</body>
</html>