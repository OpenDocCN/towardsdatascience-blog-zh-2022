<html>
<head>
<title>HuggingFace Inference Endpoints</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">拥抱面孔推断终点</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/huggingface-inference-endpoints-8984e7d8d8d4#2022-12-23">https://towardsdatascience.com/huggingface-inference-endpoints-8984e7d8d8d4#2022-12-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="c9c0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">变压器模型的快速生产级部署</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/d08f3b7bd2e6649954883507eb7d22ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xMWARFWbDAl2Mbz6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://unsplash.com/photos/5u6bz2tYhX8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>由<a class="ae ky" href="https://unsplash.com/@towfiqu999999" rel="noopener ugc nofollow" target="_blank"> Towfiqu barbhuiya </a></p></figure><p id="de6b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我的文章中一个不变的主题是你的机器学习模型的部署。随着机器学习越来越受欢迎，用户的模型部署选项也越来越多。<a class="ae ky" href="https://huggingface.co/" rel="noopener ugc nofollow" target="_blank">特别是 HuggingFace </a>已经成为机器学习领域的领导者，对于数据科学从业者来说，你很可能在过去使用过<a class="ae ky" href="https://huggingface.co/docs/transformers/index" rel="noopener ugc nofollow" target="_blank">变形金刚模型</a>。</p><p id="914b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">HuggingFace 与 AWS 和 Azure 都有合作关系，并提供了跨云提供商的部署选项。虽然在这些云提供商上部署 Transformers 模型是一个相对容易的过程，但它确实需要一些关于他们的生态系统的知识。HuggingFace 如何为模型托管提供生产级基础设施，同时让用户专注于他们的模型？</p><p id="9ba7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">引入<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/index" rel="noopener ugc nofollow" target="_blank"> HuggingFace 推理端点</a>。这个托管选项仍然集成了两家云提供商提供的基础设施，但抽象出了他们的 ML 服务所需的工作，如<a class="ae ky" href="https://aws.amazon.com/sagemaker/" rel="noopener ugc nofollow" target="_blank"> Amazon SageMaker </a>和 Azure ML 端点。</p><p id="7a82" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这篇文章中，我们将看看如何旋转你的第一个 HuggingFace 推断端点。我们将设置一个示例端点，展示如何调用端点，以及如何监控端点的性能。</p><p id="a0fb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">注意</strong>:对于这篇文章，我们将假设对 HuggingFace/Transformers 和 Python 有基本的了解。对于本文，您还需要创建一个<a class="ae ky" href="https://huggingface.co/welcome" rel="noopener ugc nofollow" target="_blank"> HuggingFace 帐户</a>并添加您的账单信息。确保删除您的终端，以免产生更多费用。</p><h1 id="cca9" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">目录</h1><ol class=""><li id="5793" class="mn mo it lb b lc mp lf mq li mr lm ms lq mt lu mu mv mw mx bi translated">设置/端点创建</li><li id="fa32" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">端点调用/监控</li><li id="a06d" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">其他部署选项</li><li id="e75e" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">其他资源和结论</li></ol><h1 id="e0b4" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">设置/端点创建</h1><p id="d467" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">如前所述，确保创建一个 HuggingFace 帐户，您将需要添加您的账单信息，因为您将创建一个由专用计算基础架构支持的端点。我们可以到推理端点<a class="ae ky" href="https://ui.endpoints.huggingface.co/new" rel="noopener ugc nofollow" target="_blank">主页</a>开始部署模型。</p><p id="aaf3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用推理端点创建，需要考虑三个主要步骤:</p><ol class=""><li id="37d8" class="mn mo it lb b lc ld lf lg li ng lm nh lq ni lu mu mv mw mx bi translated">型号选择</li><li id="edab" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">云提供商/基础设施选择</li><li id="99c3" class="mn mo it lb b lc my lf mz li na lm nb lq nc lu mu mv mw mx bi translated">端点安全级别</li></ol><p id="0fb4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要创建一个端点，您需要从<a class="ae ky" href="https://huggingface.co/docs/hub/index" rel="noopener ugc nofollow" target="_blank">拥抱面部中枢</a>中选择一个模型。对于这个用例，我们将采用一个<a class="ae ky" href="https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment" rel="noopener ugc nofollow" target="_blank"> Roberta 模型</a>，它已经在 Twitter 数据集上进行了调整，用于情感分析。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nj"><img src="../Images/de7c99d5388c07eac271b33112fa2576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_7_m9l3Qgg862LOB8DTsaQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">型号选择(作者截图)</p></figure><p id="cbee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">选择了端点部署模型后，您需要选择一个云提供商。对于这个实例，我们将选择 AWS 作为我们的提供商，然后我们可以看到哪些硬件选项可用于 CPU 和 GPU。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/8d4ab7911a72789ecead2e6a9f6b35b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjxx0z9l48hHm7lcFUaw8g.png"/></div></div></figure><p id="5ee8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">更高级的功能是设置自动缩放配置。您可以设置最小和最大实例数，以便根据流量负载和硬件利用率进行伸缩。</p><p id="b076" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">除此之外，在高级配置中，您还可以控制您的模型的<a class="ae ky" href="https://huggingface.co/tasks" rel="noopener ugc nofollow" target="_blank">任务</a>，源框架，以及一个<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/custom_container" rel="noopener ugc nofollow" target="_blank">定制容器映像</a>。此映像可以包含您可能安装的其他依赖项或您在映像上安装的其他脚本。您可以指向<a class="ae ky" href="https://hub.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker Hub </a>上的图像，也可以指向您的云提供商图像注册表，如<a class="ae ky" rel="noopener" target="_blank" href="/pushing-docker-images-to-amazon-elastic-container-registry-830c301b8971"> AWS ECR。</a></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/bdf81f0aa3b497a2cd36dc9334a84094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*57XzkK9HrctkYTCVlz9n2g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高级配置(作者截图)</p></figure><p id="ba2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，您还可以定义端点背后的安全级别。对于私有端点，您必须使用<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/private_link" rel="noopener ugc nofollow" target="_blank"> AWS PrivateLink </a>，对于端到端指南，请遵循朱利安·西蒙的示例<a class="ae ky" href="https://www.youtube.com/watch?v=ZQPm2-uR9zA" rel="noopener ugc nofollow" target="_blank">此处</a>。为了简单起见，在这个例子中，我们将创建一个公共端点。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/760a876a65a931c2419b82cbd62b5e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ehgZLfTLnqXhUnVXAmHmew.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">端点的安全级别(作者截图)</p></figure><p id="312b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，您可以创建端点了，应该在几分钟内就可以完成配置。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/0be5efd0a66ce14c5c2b5c256f3b87d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AecwSTJBnhN6tHjPJyA3nA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">端点运行(作者截图)</p></figure><h2 id="e501" class="no lw it bd lx np nq dn mb nr ns dp mf li nt nu mh lm nv nw mj lq nx ny ml nz bi translated">端点调用/监控</h2><p id="96db" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">为了调用我们的端点，推理端点 UI 通过提供一个自动化的 curl 命令使之变得简单。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oa"><img src="../Images/a1e8d39192cc469aa1ae9952e23fa0aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U4dDF2aTjW7zKFjN8N6Hrg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">测试终点(作者截图)</p></figure><pre class="kj kk kl km gt ob oc od bn oe of bi"><span id="b6c0" class="og lw it oc b be oh oi l oj ok">curl https://ddciyc4dikwsl6kg.us-east-1.aws.endpoints.huggingface.cloud \<br/>-X POST \<br/>-d '{"inputs": "I like you. I love you"}' \<br/>-H "Authorization: Bearer PYVevWdShZXpmWWixcYZtxsZRzCDNVaLillyyxeclCIlvNxCnyYhDwNQGtfmyQfciOhYpXRxcEFyiRppXAurMLafbPLroPrGUCmLsqAauOVhvMVbukAqJQYtKBrltUix" \<br/>-H "Content-Type: application/json"</span></pre><p id="1cf5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用<a class="ae ky" href="https://curlconverter.com/" rel="noopener ugc nofollow" target="_blank"> curl 命令转换器</a>,我们可以获得等效的 Python 代码来测试本地开发环境中的端点。</p><pre class="kj kk kl km gt ob oc od bn oe of bi"><span id="306b" class="og lw it oc b be oh oi l oj ok">import requests<br/>import time<br/><br/>headers = {<br/>    'Authorization': 'Bearer PYVevWdShZXpmWWixcYZtxsZRzCDNVaLillyyxeclCIlvNxCnyYhDwNQGtfmyQfciOhYpXRxcEFyiRppXAurMLafbPLroPrGUCmLsqAauOVhvMVbukAqJQYtKBrltUix',<br/>    # Already added when you pass json=<br/>    # 'Content-Type': 'application/json',<br/>}<br/><br/>json_data = {<br/>    'inputs': 'I like you. I love you',<br/>}<br/><br/><br/>def invoke_ep(headers, json_data):<br/>    response = requests.post('https://ddciyc4dikwsl6kg.us-east-1.aws.endpoints.huggingface.cloud', headers=headers, json=json_data)<br/>    return response.text</span></pre><p id="a66e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以通过长时间发送请求来进一步对端点进行压力测试。</p><pre class="kj kk kl km gt ob oc od bn oe of bi"><span id="7df7" class="og lw it oc b be oh oi l oj ok">request_duration = 100 #adjust for length of test<br/>end_time = time.time() + request_duration<br/>print(f"test will run for {request_duration} seconds")<br/>while time.time() &lt; end_time:<br/>    invoke_ep(headers, json_data)</span></pre><p id="c755" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以使用<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/metrics" rel="noopener ugc nofollow" target="_blank">推理端点分析</a> UI 来观察这些请求和端点性能。在这里，分析仪表板为我们提供了请求计数和延迟指标，以便我们了解我们的流量和相应的端点性能。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/5c635b0e2a73d76cd425d6ff24c03cfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zUtZgT-dO4DDeTueiB6p8Q.png"/></div></div></figure><p id="b8ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果您需要调试您的端点，您也可以在 UI 上查看<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/logs" rel="noopener ugc nofollow" target="_blank">容器日志</a>。在这里，我们还可以跟踪单个请求的持续时间，您在<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/custom_handler" rel="noopener ugc nofollow" target="_blank">自定义推理处理程序</a>或<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/guides/custom_container" rel="noopener ugc nofollow" target="_blank">自定义容器映像</a>中添加的任何日志记录都会在这里得到反映。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/391436ad461b860ff39c54baa45e5868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RV-fteZ59xhz79FHAKAZg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">容器日志(作者截图)</p></figure><p id="b869" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">要更新或删除端点，请根据需要转到“设置”选项卡来管理您的资源。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/1fdf0ed5f78fd1417670681aa0910554.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XEbTk7ojhlTmsCroXRWSHQ.png"/></div></div></figure><h2 id="bc9d" class="no lw it bd lx np nq dn mb nr ns dp mf li nt nu mh lm nv nw mj lq nx ny ml nz bi translated">其他部署选项</h2><p id="3abf" class="pw-post-body-paragraph kz la it lb b lc mp ju le lf mq jx lh li nd lk ll lm ne lo lp lq nf ls lt lu im bi translated">在 HuggingFace 中，您也可以实现不同的托管选项。有免费的<a class="ae ky" href="https://huggingface.co/docs/api-inference/index" rel="noopener ugc nofollow" target="_blank">托管推理 API </a>，在采用推理端点之前，您可以用它来测试您的模型。此外，还有一个 SageMaker，HuggingFace 与它紧密集成。HuggingFace 支持<a class="ae ky" href="https://huggingface.co/docs/sagemaker/index" rel="noopener ugc nofollow" target="_blank">容器图片</a>，你可以在 Amazon SageMaker 上使用它们进行训练和推理。除此之外，还有<a class="ae ky" href="https://huggingface.co/spaces" rel="noopener ugc nofollow" target="_blank"> HuggingFace Spaces </a>，你可以利用它通过<a class="ae ky" rel="noopener" target="_blank" href="/building-web-applications-with-streamlit-for-nlp-projects-cdc1cf0b38db"> Streamlit </a>和<a class="ae ky" href="https://www.gradio.app/docs/" rel="noopener ugc nofollow" target="_blank"> Gradio </a>框架为你的 ML 模型构建快速 UI。</p><h2 id="7bdf" class="no lw it bd lx np nq dn mb nr ns dp mf li nt nu mh lm nv nw mj lq nx ny ml nz bi translated">其他资源和结论</h2><div class="oo op gp gr oq or"><a href="https://github.com/RamVegiraju/HuggingFace-Examples" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd iu gy z fp ow fr fs ox fu fw is bi translated">GitHub-RamVegiraju/hugging face-Examples:hugging face 示例/特性库/</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">github.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf ks or"/></div></div></a></div><p id="1515" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有关示例的代码，请单击上面的链接。如需进一步了解与 HuggingFace 相关的内容，请点击此处的列表<a class="ae ky" href="https://ram-vegiraju.medium.com/list/huggingface-6c3ba5b216f1" rel="noopener"/>。要开始使用 HuggingFace 推断端点，请遵循<a class="ae ky" href="https://huggingface.co/docs/inference-endpoints/index" rel="noopener ugc nofollow" target="_blank">官方文档</a>。我希望这篇文章对那些开始接触 HuggingFace 推断端点的人来说是一个有用的指南，请继续关注这个领域的更多内容。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="cb3a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="pn">如果你喜欢这篇文章，请在</em><a class="ae ky" href="https://www.linkedin.com/in/ram-vegiraju-81272b162/" rel="noopener ugc nofollow" target="_blank"><em class="pn">LinkedIn</em></a><em class="pn">上联系我，订阅我的媒体</em> <a class="ae ky" href="https://ram-vegiraju.medium.com/subscribe" rel="noopener"> <em class="pn">简讯</em> </a> <em class="pn">。如果你是新手，使用我的</em> <a class="ae ky" href="https://ram-vegiraju.medium.com/membership" rel="noopener"> <em class="pn">会员推荐</em> </a> <em class="pn">报名。</em></p></div></div>    
</body>
</html>