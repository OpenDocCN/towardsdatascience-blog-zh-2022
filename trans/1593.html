<html>
<head>
<title>GPT-4 Is Coming Soon. Here’s What We Know About It</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPT 4号即将发射。以下是我们对它的了解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gpt-4-is-coming-soon-heres-what-we-know-about-it-64db058cfd45#2022-04-17">https://towardsdatascience.com/gpt-4-is-coming-soon-heres-what-we-know-about-it-64db058cfd45#2022-04-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="23e5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">官方信息、当前趋势和预测。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/67ee4afbbc9e62fdccf2cb2c399700ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*umWeEgEpP-_gpCokOca-dg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由Shutterstock上的Pinkeyes拍摄</p></figure><h2 id="1ddb" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">更新:<a class="ae ky" href="https://thealgorithmicbridge.substack.com/p/gpt-4-in-10-keys" rel="noopener ugc nofollow" target="_blank"> GPT-4出局</a>。</h2></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="fc2f" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">GPT 4号的发布日期越来越近了。</p><p id="677e" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">GPT-3于2020年5月宣布，差不多两年前。它是在GPT-2之后一年发布的，后者也是在GPT论文发表一年后发布的。如果这种趋势在各个版本中都保持不变，GPT 4应该已经出现了。事实并非如此，但OpenAI的首席执行官萨姆·奥特曼(Sam Altman)几个月前表示，GPT 4号即将到来。目前的估计预测发布日期在2022年的某个时候，可能在7月-8月左右<a class="ae ky" href="https://www.metaculus.com/questions/7401/when-will-gpt-4-be-announced/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2d8f" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">尽管这是最令人期待的人工智能新闻之一，但关于GPT-4的公开信息很少:它会是什么样子，它的特点，或者它的能力。奥特曼去年进行了一次问答，并就OpenAI对GPT 4号的想法给出了一些提示(他要求参与者对这些信息保密，我一直保持沉默——但七个月是一个合理的时间余量)。他肯定的一点是，GPT-4不会有100T的参数，正如我在之前的一篇文章中假设的<a class="ae ky" rel="noopener" target="_blank" href="/gpt-4-will-have-100-trillion-parameters-500x-the-size-of-gpt-3-582b98d82253">(这么大的型号还得等等)。</a></p><p id="c6a5" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">自从OpenAI透露任何关于GPT 4号的信息已经有一段时间了。然而，在人工智能领域，特别是在自然语言处理领域，一些正在获得巨大牵引力的新趋势可能会给我们提供GPT-4的线索。鉴于这些方法的成功和OpenAI的参与，从Altman的话中做出一些可接受的预测是可能的。当然，这些超越了众所周知的——也是令人厌倦的——让模型变得越来越大的做法。</p><p id="da45" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">根据我们从OpenAI和Sam Altman那里获得的信息，以及当前的趋势和人工智能语言的艺术水平，下面是我对GPT-4的预测。(明确的或者上下文的，我会说清楚哪些是猜测，哪些是确定的。)</p><h1 id="e265" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">模型尺寸:GPT-4不会超级大</h1><p id="a450" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">GPT-4不会是最大的语言模型。奥特曼说它不会比GPT 3号大多少。与前几代神经网络相比，这个模型肯定会很大，但大小不会是它的显著特征。它可能位于GPT-3和<a class="ae ky" rel="noopener" target="_blank" href="/deepmind-is-now-the-undisputed-leader-in-language-ai-with-gopher-280b-79363106011f">地鼠</a> (175B-280B)之间。</p><p id="39f8" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">这个决定是有充分理由的。</p><p id="d894" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">由英伟达和微软去年建造的威震天-图灵NLG ，以530B的参数保持着最大密集神经网络的头衔——已经比GPT-3大3倍——直到最近(<a class="ae ky" href="https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html" rel="noopener ugc nofollow" target="_blank">谷歌的PaLM </a>现在保持着540B的头衔)。但值得注意的是，在MT-NLG之后出现的一些较小的型号达到了更高的性能水平。</p><p id="f5a0" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">越大≠越好。</p><p id="31fe" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">更好的小模型的存在有两层含义。</p><p id="e817" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">首先，公司已经意识到使用模型大小作为提高性能的代理不是唯一的方法——也不是最好的方法。2020年，OpenAI的<a class="ae ky" href="https://arxiv.org/abs/2001.08361" rel="noopener ugc nofollow" target="_blank"> Jared Kaplan和他的同事</a>得出结论，当计算预算的增加主要用于扩展参数数量时，性能提高最多，遵循幂律关系。谷歌、英伟达、微软、OpenAI、DeepMind和其他开发语言模型的公司对这些指导方针信以为真。</p><p id="5f52" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">但是NLG山虽然很大，但在性能方面并不是最好的。事实上，在任何单一类别的基准测试中，它都不是最好的。较小的型号，如Gopher (280B)或<a class="ae ky" rel="noopener" target="_blank" href="/a-new-ai-trend-chinchilla-70b-greatly-outperforms-gpt-3-175b-and-gopher-280b-408b9b4510">Chinchilla(70B)</a>——仅仅是它的一小部分——在任务上比MT-NLG好得多。</p><p id="61da" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">很明显，模型的大小并不是获得更好的语言理解的唯一因素，这让我想到了第二个含义。</p><p id="8f77" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">公司开始拒绝“越大越好”的教条。拥有更多参数只是提高性能的众多因素之一。附带损害(例如碳足迹、计算成本或进入壁垒)使其成为最糟糕的考虑因素之一，尽管实施起来非常简单。当公司能够从一个较小的模型中获得类似的——或者更好的——结果时，他们会在建立一个巨大的模型之前三思。</p><p id="879d" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">奥尔特曼说，他们不再专注于让模型变得非常大，而是专注于让较小的模型发挥最大的作用。OpenAI研究人员是<a class="ae ky" href="https://www.gwern.net/Scaling-hypothesis" rel="noopener ugc nofollow" target="_blank">缩放假说</a>的早期倡导者，但现在可能已经意识到其他未探索的途径可以导致改进的模型。</p><p id="5236" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">GPT 4号不会比GPT 3号大多少，这就是原因。OpenAI将把重点转向其他方面——如数据、算法、参数化或对齐——这可能会更干净地带来重大改进。我们还得等着看100T参数模型的能力。</p><h1 id="7891" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">最佳化:充分利用GPT-4</h1><p id="abd8" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">当谈到优化时，语言模型受到一个严重的限制。这种培训非常昂贵，公司不得不在准确性和成本之间进行权衡。这通常会导致模型明显优化不足。</p><p id="b734" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">GPT-3只训练了一次，尽管有些错误在其他情况下会导致重新训练。由于无法负担的成本，OpenAI决定不这样做，这使得研究人员无法找到该模型的最佳超参数集(例如，学习率、批量大小、序列长度等)。</p><p id="03df" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">高培训成本的另一个后果是对模型行为的分析受到限制。当卡普兰的团队得出模型大小是提高性能的最相关变量的结论时，他们没有考虑训练令牌的数量，即模型输入的数据量。这样做需要大量的计算资源。</p><p id="161e" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">科技公司遵循卡普兰的结论，因为这是他们最好的结论。具有讽刺意味的是，谷歌、微软、脸书和其他公司在越来越大的模型上“浪费”了数百万美元——在这个过程中产生了大量的污染——而这恰恰是受经济限制的驱使。</p><p id="860c" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">现在，以DeepMind和OpenAI为首的公司正在探索其他方法。他们试图找到最佳模型，而不仅仅是更大的模型。</p><h2 id="a7c2" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">最佳参数化</h2><p id="713c" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">上个月，微软和OpenAI证明了<a class="ae ky" rel="noopener" target="_blank" href="/how-microsoft-openai-are-squeezing-the-best-out-of-gpt-3-ad0990a66cbe"> GPT-3可以进一步改进</a>，如果他们用最佳超参数训练模型的话。他们发现，GPT-3的6.7B版本的性能提高了很多，可以与最初的13B GPT-3模型相媲美。超参数调优—对于较大的模型不可行—导致了相当于参数数量翻倍的性能提升。</p><p id="80f9" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">他们发现了一种新的参数化(μP ),其中小模型的最佳超参数也是同一家族中较大模型的最佳参数。μP允许他们优化任意大小的模型，只需很少一部分训练成本。然后，超参数可以几乎无成本地转移到更大的模型中。</p><h2 id="02e1" class="kz la it bd lb lc ld dn le lf lg dp lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">最佳计算模型</h2><p id="edc3" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">几周前，DeepMind重新审视了卡普兰的发现，并意识到，与人们的想法相反，训练令牌的数量与模型大小一样影响性能。他们的结论是，随着更多计算预算可用，应该平均分配给扩展参数和数据。他们通过训练<a class="ae ky" rel="noopener" target="_blank" href="/a-new-ai-trend-chinchilla-70b-greatly-outperforms-gpt-3-175b-and-gopher-280b-408b9b4510">龙猫</a>来证明他们的假设，这是一个70B的模型(比Gopher小4倍，以前的SOTA)，数据量是自GPT 3以来所有大型语言模型的4倍(1.4T令牌——来自典型的300B)。</p><p id="0d09" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">结果是明确的。在许多语言基准测试中，龙猫“一致且显著地”超过了地鼠、GPT-3、NLG山和所有其他语言模型:当前的模型训练不足且过大。</p><p id="861b" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">鉴于GPT-4将略大于GPT-3，它需要达到计算优化的训练令牌数量(根据DeepMind的发现)将约为5万亿——比当前的数据集高出一个数量级。他们训练模型以达到最小训练损失所需的失败次数将比他们在GPT-3中使用的次数多10-20倍左右(使用Gopher的计算预算作为代理)。</p><p id="b7c7" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">当奥特曼在问答中说GPT-4将比GPT-3使用更多的计算时，他可能指的就是这一点。</p><p id="f349" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">OpenAI肯定会在GPT-4中实现优化相关的见解——尽管在多大程度上是不可预测的，因为他们的预算是未知的。可以肯定的是，除了模型尺寸之外，他们将专注于优化其他变量。找到最佳的超参数集以及最佳的计算模型大小和参数数量可以在所有基准测试中带来难以置信的改进。如果将这些方法结合到一个模型中，所有对语言模型的预测都将失败。</p><p id="d3f1" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">奥特曼还说，如果不把模型做大，人们不会相信模型能有多好。他可能是在暗示，扩大规模的努力暂时结束了。</p><h1 id="08d1" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">多模态:GPT 4将是一个纯文本模型</h1><p id="0936" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">深度学习的未来是多模态模型。人类的大脑是多感官的，因为我们生活在一个多模态的世界里。一次以一种模式感知世界极大地限制了人工智能导航或理解世界的能力。</p><p id="694e" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">然而，好的多模态模型比好的纯语言或纯视觉模型更难构建。将视觉和文本信息组合成一个单一的表示是一项艰巨的任务。我们对大脑如何做到这一点的概念非常有限(不是说深度学习社区考虑了认知科学对大脑结构和功能的见解)，所以我们不知道如何在神经网络中实现它。</p><p id="9742" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">奥特曼在问答中说，GPT 4不会是多模态的(像DALL E或MUM)，而是一个纯文本的模型。我猜他们正试图达到语言模型的极限，在跳到下一代多模态人工智能之前，调整模型和数据集大小等因素。</p><h1 id="b0bb" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">稀疏性:GPT-4将是一个密集模型</h1><p id="f0cf" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">稀疏模型利用条件计算，使用模型的不同部分来处理不同类型的输入，最近获得了巨大的成功。这些模型可以轻松扩展到1T参数以上，而不会遭受高计算成本，从而在模型大小和计算预算之间建立了一种看似正交的关系。然而，MoE方法的好处在非常大的模型上逐渐减少。</p><p id="669f" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">鉴于OpenAI专注于密集语言模型的历史，有理由期待GPT-4也将是一个密集模型。鉴于奥特曼说GPT-4不会比GPT-3大多少，我们可以得出结论，稀疏性不是OpenAI的一个选项——至少现在是这样。</p><p id="bcc4" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">稀疏性，类似于多模态，将很可能主导未来几代神经网络，因为我们的大脑——人工智能的灵感——严重依赖稀疏处理。</p><h1 id="d40c" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">对齐:GPT-4将比GPT-3更加对齐</h1><p id="1284" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">OpenAI已经付出了很多努力来解决人工智能对齐问题:如何让语言模型遵循我们的意图并坚持我们的价值观——无论这到底意味着什么。这不仅仅是一个数学上的难题(即我们如何才能让AI准确理解我们想要什么？)，但也是哲学上的(即，没有一种通用的方法可以让人工智能与人类保持一致，因为人类价值观在不同群体之间的差异是巨大的——而且往往是冲突的)。</p><p id="029a" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">然而，他们用InstructGPT进行了第一次尝试，这是一个更新的GPT-3，经过人类反馈的训练，以学习遵循指令(这些指令是否是善意的尚未纳入模型)。</p><p id="dd07" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">InstructGPT的主要突破是，不管它在语言基准上的结果如何，它都被人类评委视为一个更好的模型(人类评委组成了一个非常同质的群体——open ai员工和说英语的人——所以我们应该小心提取结论)。这突出了克服使用基准作为评估人工智能能力的唯一标准的必要性。人类如何看待这些模型同样重要，如果不是更重要的话。</p><p id="7b61" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">鉴于Altman和OpenAI对有益的AGI的承诺，我相信GPT-4将实施——并建立在——他们从InstructGPT获得的发现的基础上。</p><p id="e325" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">他们将改进他们调整模型的方式，因为它仅限于OpenAI员工和讲英语的贴标机。真正的结盟应该包括具有各种起源和性别、种族、国籍、宗教等特征的群体。这是一个巨大的挑战，任何朝着这个目标的步骤都是受欢迎的(尽管我们应该谨慎地称之为调整，因为它并不适合大多数人)。</p><h1 id="85ac" class="mv la it bd lb mw mx my le mz na nb lh jz nc ka ll kc nd kd lp kf ne kg lt nf bi translated">总结…</h1><p id="e81c" class="pw-post-body-paragraph mc md it me b mf ng ju mh mi nh jx mk li ni mm mn lm nj mp mq lq nk ms mt mu im bi translated">型号大小: GPT-4将比GPT-3更大，但与目前最大的型号(MT-NLG 530B和PaLM 540B)相比不会很大。型号大小不会是一个显著的特征。</p><p id="010c" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated"><strong class="me iu">优化:</strong> GPT-4将比GPT-3使用更多计算。它将在参数化(最优超参数)和比例法则(训练令牌的数量与模型大小一样重要)方面实现新的优化见解。</p><p id="132a" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated"><strong class="me iu">多模态:</strong> GPT-4将是纯文本模式(非多模态)。OpenAI希望在完全跳到DALL E这样的多模态模型之前，最大限度地利用语言模型——他们预测这种模型将在未来超过单模态系统。</p><p id="c4a1" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated"><strong class="me iu">稀疏度:</strong> GPT-4将遵循GPT-2和GPT-3的趋势，成为一个密集模型(所有参数将用于处理任何给定的输入)。稀疏性在未来会变得更占优势。</p><p id="6788" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated">结盟:GPT 4号将比GPT 3号更与我们结盟。它将实现InstructGPT的学习，instruct GPT是通过人类反馈训练的。尽管如此，人工智能调整是一个漫长的过程，应该仔细评估这些努力，不应该大肆宣传。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="549e" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated"><em class="nl">订阅</em> <a class="ae ky" href="https://thealgorithmicbridge.substack.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="me iu">算法桥</strong> </a> <em class="nl">。弥合算法和人之间的鸿沟。关于与你生活相关的人工智能的时事通讯。</em></p><p id="a9b3" class="pw-post-body-paragraph mc md it me b mf mg ju mh mi mj jx mk li ml mm mn lm mo mp mq lq mr ms mt mu im bi translated"><em class="nl">您也可以直接支持我在Medium上的工作，并通过使用我的推荐链接</em> <a class="ae ky" href="https://albertoromgar.medium.com/membership" rel="noopener"> <strong class="me iu">这里</strong> </a>成为会员来获得无限制的访问权限！<em class="nl"> :) </em></p></div></div>    
</body>
</html>