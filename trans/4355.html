<html>
<head>
<title>Intro to 3D Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3D深度学习简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/intro-to-3d-deep-learning-e992f7efa6ee#2022-09-27">https://towardsdatascience.com/intro-to-3d-deep-learning-e992f7efa6ee#2022-09-27</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="b5e9" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">3D数据表示、视觉任务和学习资源</h2></div><p id="dafc" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作者:玛格丽特·梅纳德·里德和T2</p><p id="4fb9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3D深度学习是一个有趣的领域，具有广泛的现实应用:艺术和设计，自动驾驶汽车，体育，农业，生物，机器人，虚拟现实和增强现实。这篇博客文章介绍了3D深度学习:3D数据表示，计算机视觉任务和学习资源。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/55e1638812630d360029c1fd7ca5b01a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IzTMS0YtQ3L4wm-nEuxSqQ.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片(玛格丽特)</p></figure><h1 id="4657" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3D数据</h1><p id="3f0c" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">数据对于训练机器学习模型来说超级重要。2D和3D深度学习最大的区别之一是数据表示格式。</p><p id="c58d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">常规图像通常以1D或2D阵列表示。另一方面，3D图像可以有不同的表示格式，这里有一些最流行的格式:多视图、体积、点云、网格和体积显示。让我们来看看用图片说明的每个数据表示。</p><h1 id="6420" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">多视图图像</h1><p id="564f" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">这些可以通过定位从同一物体或场景的不同角度拍摄照片的多个相机来捕捉。这是一把椅子的样子，图片来自<a class="ae le" href="https://shapenet.org/" rel="noopener ugc nofollow" target="_blank"> ShapeNet </a>，这是一个注释丰富的大型形状库，由物体的3D CAD模型表示。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/c0f0aa806744654a7a9a287618824141.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/0*PgdSKSvx4571Z6G8"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">ShapeNet数据集的图像</p></figure><h1 id="a21c" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">点云</h1><p id="382b" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在点云数据集中，每个图像由一组从原始传感器收集的点(x，y，z坐标)表示。点云数据通常由激光雷达传感器捕获或从网格数据转换而来。</p><p id="78a6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是来自<a class="ae le" href="https://modelnet.cs.princeton.edu/" rel="noopener ugc nofollow" target="_blank"> ModelNet10 </a>数据集的<strong class="kk iu">点云</strong>表示中椅子的样子。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c986f084c68fe00f9e8122a84b6c4678.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*RAeFi-caePEJ6Le0biZRHQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">来自ModelNet 10数据集的图像</p></figure><h1 id="b2e3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">网状物</h1><p id="90df" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">网格是使用Blender、Autodesk Maya或Unreal Engine等软件进行3D建模的典型构件。与点云中每个3D对象由<strong class="kk iu">点</strong>组成不同，网格表示由一组点以及这些点(<strong class="kk iu">边</strong>和<strong class="kk iu">面</strong>的关系组成。一种网格是<strong class="kk iu">多边形网格</strong>，其面为三角形或四边形。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mu"><img src="../Images/8e5f8da57efbd90ddd35124918437a52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JPUYAqgMWJtkGTAhZMrp2Q.png"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片(玛格丽特)</p></figure><h1 id="0fd0" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">体积显示</h1><p id="7934" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">在体积表示中，每个图像都是实心的，由体素组成:2D图像中像素的3D等价物。</p><p id="1caf" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">诸如Blender之类的3D建模软件可以用来对3D模型进行体素化，这里是一个体素化兔子的例子:</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/c7197b2c857aa83fa511e5b4bad1bc10.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*qyA7g52fcluFkemHvKL5PQ.png"/></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">作者图片(玛格丽特)</p></figure><p id="efc8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">体积表示可以通过实时扫描获得，或者从3D点云或网格转换而来。这里有一个来自<a class="ae le" href="http://scan-net.org" rel="noopener ugc nofollow" target="_blank">scan-net.org</a>的例子，它用语义体素标签对室内场景进行了RGB-D扫描。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mw"><img src="../Images/44845470038b37beaf939671680f7343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wDSgqZ-xx3YXAaKU"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图片来自scan-net.org/<a class="ae le" href="http://www.scan-net.org/" rel="noopener ugc nofollow" target="_blank"/></p></figure><h1 id="7008" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">3D计算机视觉任务</h1><p id="c6ed" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">就像2D计算机视觉一样，3D任务包括图像分类、分割、姿态估计和使用生成模型的图像合成。下面我们将讨论这些任务的几个例子。由于3D数据有如此多不同的表现形式，请注意，我们下面提到的例子可能只涉及一些3D数据格式。</p><h2 id="641e" class="mx lw it bd lx my mz dn mb na nb dp mf kr nc nd mh kv ne nf mj kz ng nh ml ni bi translated">三维图像分类</h2><p id="580e" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">图像分类在2D和三维计算机视觉中都是一个很好解决的问题。</p><p id="279b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3D数据分类涉及识别场景中存在的单个3D或多个3D对象的任务。它将使我们能够通过捕捉物体的形状、大小、方向等来识别物体。这在处理增强现实(AR)、自动驾驶汽车和机器人等现实应用时至关重要。</p><p id="b112" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该任务类似于2D图像分类，不同之处在于模型架构。<a class="ae le" href="https://www.dimatura.net/publications/voxnet_maturana_scherer_iros15.pdf" rel="noopener ugc nofollow" target="_blank"> VoxNet </a> (2015)是利用3D CNNs进行单个3D对象检测的最初作品之一。它接受3D体积数据或2D帧序列作为输入，并应用3D内核进行卷积运算。3D CNNs是学习体数据表示的强大模型。最近的工作，如<a class="ae le" href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Lang_SampleNet_Differentiable_Point_Cloud_Sampling_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank"> SampleNet </a> (2020)介绍了采样点云的技术，其中包括代表视觉场景的点，从而提高分类性能以及其他任务，如3D重建。</p><p id="75bb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这里有一个Keras.io上学习3D图像分类的很棒的教程:<a class="ae le" href="https://keras.io/examples/vision/pointnet/" rel="noopener ugc nofollow" target="_blank">用PointNet进行点云分类</a>。</p><h2 id="3a41" class="mx lw it bd lx my mz dn mb na nb dp mf kr nc nd mh kv ne nf mj kz ng nh ml ni bi translated">3D对象检测和跟踪</h2><p id="5d6a" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">3D中的对象检测和跟踪类似于2D中的任务，但是具有额外的挑战。3D对象检测任务我们处理体素或点。</p><p id="e7d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3D物体检测和跟踪在自动驾驶汽车中非常有用。我们可以使用RGB图像、点云数据或来自相机和传感器(激光雷达)点云的融合数据输入来训练3D对象检测和跟踪。</p><p id="9492" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对象检测和跟踪也可以用于增强现实，以将虚拟项目叠加到现实世界场景中。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nj"><img src="../Images/bbd9a75863ea08f2f32f4e6fe5b6df74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tXcOWWZYxfH0_8GG"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图片来自论文:单目准密集三维物体跟踪</p></figure><h2 id="1c84" class="mx lw it bd lx my mz dn mb na nb dp mf kr nc nd mh kv ne nf mj kz ng nh ml ni bi translated">三维图像分割</h2><p id="fc22" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">与2D图像分割任务一样，3D图像分割也包括语义、实例和部分分割。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nk"><img src="../Images/366d4e9cee41267f5a43f48eab8d0eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qtG9PIfpEiOJ0PYG"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">图片来自纸张:PID-Net零件分割</p></figure><p id="9586" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">根据3D数据表示，不同的技术被用于分割任务。用于分割的一些流行的3D数据集包括ScanNet、ShapeNet和Semantic3D。</p><p id="9b77" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3D分割的一些应用包括使用无人机进行场景分析、3D地图重建和医疗诊断。有趣的是，语义分割也有助于深度估计。</p><h2 id="5346" class="mx lw it bd lx my mz dn mb na nb dp mf kr nc nd mh kv ne nf mj kz ng nh ml ni bi translated">三维姿态估计</h2><p id="5e86" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">3D姿态估计是涉及从作为输入给出的2D图像预测3D对象的实际空间定位的过程。一旦我们获得2D图像中物体的三维旋转和平移等信息，我们就可以将它转换到三维空间。这个问题在机器人领域非常活跃。一个机器人也许能够用照相机看到各种各样的物体，但是仅仅看到一个物体并不足以真正抓住它。</p><p id="0a99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了解决这个问题，通常为每个对象检测、识别和跟踪许多被称为关键点的重要特征。解决这个问题的早期工作之一是由Shubham Tulsiani等人 (2015)完成的，他们引入了一种基于CNN的方法，用于从2D图像中可靠地预测对象的视点和关键点。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nl"><img src="../Images/5cd6095facbde63413bced56e4f2fcba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*anC0ZbK4rjWAdoot"/></div></div><p class="lr ls gj gh gi lt lu bd b be z dk translated">(左)2D汽车图像(中)使用视点(右)关键点位置表示2D汽车的姿态来自纸张的图像:视点和关键点</p></figure><p id="52b0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3D姿态估计的其他重要应用包括增强现实和时尚虚拟试穿。</p><h2 id="27dd" class="mx lw it bd lx my mz dn mb na nb dp mf kr nc nd mh kv ne nf mj kz ng nh ml ni bi translated">三维图像重建</h2><p id="29c6" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">3D图像重建涉及从关键点、分割、深度图和表示3D模型知识的其他形式的数据中理解图像的3D结构和方向的任务。随着数据的丰富，基于深度学习的技术在解决这个问题方面也很受欢迎。这些作品基于不同的模型，如CNN，RNNs，Transformers，VAEs和GANs。</p><p id="b178" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">多视图重建</strong></p><p id="674b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是一项使用代表场景的2D图像集合来重建物体的3D视图的任务。基于这种技术的深度学习模型从图像中提取有用的信息，并探索不同视图之间的关系。</p><p id="c54e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">单视图重建</strong></p><p id="3a94" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在单视图重建中，使用单个2D图像来完成对象的3D视图。这是一项复杂得多的任务，需要模型仅从表示物体单个视图的图像中推断几何结构和视觉特征，如纹理和阴影。然而，该领域已经有许多研究，例如<a class="ae le" href="https://openreview.net/pdf?id=FGqiDsBUKL0" rel="noopener ugc nofollow" target="_blank"> GAN2Shape </a>、<a class="ae le" href="https://arxiv.org/abs/2204.08906" rel="noopener ugc nofollow" target="_blank"> PHORUM </a>已经证明成功地生成了具有精确颜色、纹理和阴影表示的真实感3D结构。</p><p id="5cf0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">用NeRF进行三维重建</strong></p><p id="f809" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">NeRF使用单个连续的5D坐标作为输入来探索3D重建的任务。坐标表示空间位置和观察方向。它输出给定位置的体积密度和视图相关的RGB颜色。这最小化了在渲染先前用于3d重建任务的多个图像时引入的误差。</p><p id="2c5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个概念是论文引入的:将场景表示为神经辐射场进行视图合成<a class="ae le" href="http://www.matthewtancik.com/nerf" rel="noopener ugc nofollow" target="_blank">【Project】</a><a class="ae le" href="https://arxiv.org/abs/2003.08934" rel="noopener ugc nofollow" target="_blank">【Paper】</a><a class="ae le" href="https://github.com/bmild/nerf" rel="noopener ugc nofollow" target="_blank">【Code】</a>。这里还有一个关于https://keras.io/examples/vision/nerf/的很棒的教程。</p><h1 id="1ffd" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">学习资源</h1><p id="34f0" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">我们想分享一些帮助我们学习3D深度学习的学习资源。</p><p id="1cb0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras.io </a>有几个上面提到的3D深度学习教程。</p><p id="8a0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae le" rel="noopener" target="_blank" href="/how-to-represent-3d-data-66a0f6376afb">如何表现3D数据</a>是一篇关于3D数据表现的很好的帖子，有更多的细节。<a class="ae le" href="https://youtu.be/vfL6uJYFrp4" rel="noopener ugc nofollow" target="_blank">加州大学圣地亚哥分校SU实验室的3D深度学习教程</a>提供了3D深度学习的一个很好的概述。GitHub repo <a class="ae le" href="https://github.com/timzhang642/3D-Machine-Learning#material_synthesis" rel="noopener ugc nofollow" target="_blank"> 3D机器学习</a>收集了3D数据集、模型和论文等。</p><p id="0e65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有两个3D深度学习库:<a class="ae le" href="https://github.com/google-research/google-research/tree/master/tf3d" rel="noopener ugc nofollow" target="_blank"> TensorFlow 3D </a>和<a class="ae le" href="https://pytorch3d.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch3D </a>。这篇博文<a class="ae le" href="http://ai.googleblog.com/2021/02/3d-scene-understanding-with-tensorflow.html" rel="noopener ugc nofollow" target="_blank">用TensorFlow 3D理解3D场景</a>详细介绍了TensorFlow 3D模型。而这些优秀的<a class="ae le" href="https://pytorch3d.org/tutorials/" rel="noopener ugc nofollow" target="_blank"> PyTorch3D教程</a>都有Colab笔记本，你可以亲自动手探索。</p><h1 id="2f98" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">摘要</h1><p id="180d" class="pw-post-body-paragraph ki kj it kk b kl mn ju kn ko mo jx kq kr mp kt ku kv mq kx ky kz mr lb lc ld im bi translated">这篇文章提供了3D深度学习的概述:基本术语，3D数据表示和各种3D计算机视觉任务。我们已经分享了一些学习资源，您可能会发现这些资源对开始3D深度学习有所帮助。</p></div><div class="ab cl nm nn hx no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="im in io ip iq"><p id="6f86" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">关于作者——玛格丽特·梅纳德·里德是一名ML工程师、艺术家和有抱负的3D时装设计师。Nived PA是阿姆里塔大学计算机工程专业的本科生。</p></div></div>    
</body>
</html>