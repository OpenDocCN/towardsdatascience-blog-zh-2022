<html>
<head>
<title>A Comprehensive Guide to training CNNs on TPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNNs培训综合指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-comprehensive-guide-to-training-cnns-on-tpu-1beac4b0eb1c#2022-11-08">https://towardsdatascience.com/a-comprehensive-guide-to-training-cnns-on-tpu-1beac4b0eb1c#2022-11-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a9e5" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph">机器学习</h2><div class=""/><div class=""><h2 id="a080" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">让您的TensorFlow代码可在TPU上训练</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/bc173cb8a85600ecebe32592d57e2ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*CGoKaH4dIpSpsMta"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">Enric Moreu 在<a class="ae le" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="e2d7" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">前故事</h1><p id="25d8" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">我最近在Kaggle上了解到TPU的可用性，我想在TPU上运行我的一个旧笔记本。我原以为这只是一个切换加速器和应用几个微小变化的问题，但结果证明这是一个完整的旅程，在这里我学到了很多。我想分享它来帮助其他人利用TPUs来惊人地加快他们的训练，从而提高重复实验的能力。</p><h1 id="6782" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">观众</h1><p id="9b1d" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">⚠️ <strong class="lz ja">警告！</strong>本文假设您熟悉ML、CNN的基础知识，并使用Tensorflow和Keras对其进行培训，并且刚刚开始使用TPU或有一些疑问。</p><p id="4158" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">📝<strong class="lz ja">注</strong>。实际的示例笔记本是在Kaggle上完成的，但是绝大多数讨论的要点也适用于其他环境。</p><p id="78c5" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我希望这篇文章集中在实际应用上，而不要太长，所以让我们简单地谈谈“理论”。</p><h1 id="2142" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">一些TPUs背景</h1><p id="7a74" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">使用TPUs ( <a class="ae le" href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" rel="noopener ugc nofollow" target="_blank">张量处理单元</a>)——在硬件上实现矩阵乘法的深度学习加速器，可以显著提高神经网络训练速度，因此大大减少了计算时间。</p><p id="2e9f" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">要了解更多的背景知识，我建议浏览谷歌的TPUs简介，也可以参考YouTube的视频</p><h1 id="71ef" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">Kaggle环境</h1><p id="18dc" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">以下是该环境的一些详细信息，供您检查与您自己的环境的相关性:</p><ol class=""><li id="05b5" class="mz na iq lz b ma mt md mu mg nb mk nc mo nd ms ne nf ng nh bi translated">TPU v3–8</li><li id="df80" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms ne nf ng nh bi translated">Tensorflow版本2.4.1(带TPU)</li><li id="77f3" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms ne nf ng nh bi translated">在撰写本文时，Kaggle上每周有20小时的TPUs时间(一次最多9小时)是免费的</li></ol><h1 id="184c" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">完整Jupyter笔记本的链接</h1><ul class=""><li id="0f56" class="mz na iq lz b ma mb md me mg nn mk no mo np ms nq nf ng nh bi translated"><a class="ae le" href="https://www.kaggle.com/code/aaalexlit/from-simple-cnn-to-transfer-learning-on-tpu/notebook" rel="noopener ugc nofollow" target="_blank">卡格尔</a></li><li id="bec2" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">Github </li></ul><h1 id="0e2f" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">大意</h1><p id="c2ee" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">让我们先过一遍要点，然后用一些细节和代码片段来回顾它们。</p><blockquote class="nr"><p id="d126" class="ns nt iq bd nu nv nw nx ny nz oa ms dk translated">TPU是游戏规则的改变者，如果他们可用，你需要使用他们</p></blockquote><p id="f4eb" class="pw-post-body-paragraph lx ly iq lz b ma ob ka mc md oc kd mf mg od mi mj mk oe mm mn mo of mq mr ms ij bi translated">我再怎么强调也不为过，TPU会疯狂地提高你的训练时间(当然前提是这对你手头的任务有用)。下面是一个表格，比较了我所经历的实验的每个时期的时间。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">使用不同硬件的近似运行时间比较</p></figure><p id="77f7" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">但是任何好的东西都是有代价的，为了能够利用TPU的优势，人们需要调整他们的代码和数据管道。有时这意味着数据预处理的完全重写。</p><h2 id="0cbb" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated"><strong class="ak">能够使用TPU</strong></h2><ul class=""><li id="7aa4" class="mz na iq lz b ma mb md me mg nn mk no mo np ms nq nf ng nh bi translated">TPUs专门从Google云存储(GCS)中读取数据<strong class="lz ja">。因此，您需要将您的数据放在那里和/或从GCS中读取它(如果它已经可用的话)(就像Kaggle的情况一样)。</strong></li><li id="45ed" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">需要使用<code class="fe ot ou ov ow b">tf.data.Dataset</code>API<strong class="lz ja"/>作为<code class="fe ot ou ov ow b">model.fit()</code>的输入</li><li id="416b" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">型号<strong class="lz ja">必须在<code class="fe ot ou ov ow b">TPUStrategy</code>范围内定义</strong></li><li id="9ae2" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">数据扩充<strong class="lz ja">必须在数据准备期间</strong>完成(即在CPU上)，它不能成为训练代码的一部分，因为<a class="ae le" href="https://cloud.google.com/tpu/docs/tensorflow-ops" rel="noopener ugc nofollow" target="_blank">TPU</a>不支持某些张量流操作。</li><li id="e8ce" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">不能使用改变输入的宽度和高度的数据增强层(例如，<code class="fe ot ou ov ow b">RandomWidth</code>、<code class="fe ot ou ov ow b">RandomHeight</code>和方形图像，或在非方形图像的情况下翻转高度和宽度的数据增强方法)<strong class="lz ja">。</strong></li><li id="2f51" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">来自TensorFlow Hub <strong class="lz ja">的模型需要读取未压缩的</strong>或<strong class="lz ja">直接加载到TPU </strong>，因为云TPU无法访问TFHub所依赖的本地文件系统</li><li id="63ba" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">等等。</li></ul><h2 id="8821" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated"><strong class="ak">优化TPU的使用</strong></h2><p id="2be7" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">有很多事情可以做，以优化TPU上的训练，下面的列表并不详尽。主要是，由于TPU的速度很快，数据管道很容易成为瓶颈:</p><ul class=""><li id="986c" class="mz na iq lz b ma mt md mu mg nb mk nc mo nd ms nq nf ng nh bi translated">根据可用的硬件调整批量大小，并相应地调整学习速率</li><li id="0d15" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">编译模型时使用<code class="fe ot ou ov ow b">steps_per_execution</code>参数</li><li id="5d83" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">使用数据集缓存、预取和<a class="ae le" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">其他数据加载优化</a>来最大化TPU负载。</li><li id="207f" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">确保您的<a class="ae le" href="https://cloud.google.com/tpu/docs/performance-guide#tensor_dimensions" rel="noopener ugc nofollow" target="_blank">特征尺寸</a>是8或128的倍数(取决于选择的批量大小)</li><li id="956f" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">以某种方式组织你在GCS上的数据</li><li id="392a" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated">等等。</li></ul><h1 id="c27f" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">数据集</h1><p id="dd55" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">本教程中使用的器械包来自Kaggle上的<a class="ae le" href="https://www.kaggle.com/competitions/plant-pathology-2020-fgvc7/overview/cvpr-2020" rel="noopener ugc nofollow" target="_blank">植物病理学2020 </a>竞赛。比赛的目标是将苹果叶子的图片分为4个不同的类别——健康、锈病、黑星病或多种疾病。数据集相对较小，在训练集中有1821幅jpg图像，在测试集中有相同的数量。</p><h1 id="775f" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">好了，该动手了</h1><h2 id="bf0c" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">⚠️重要提示</h2><p id="ea08" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">下面我将主要省略与TPU用法不相关的代码。您可以通过提供的链接在笔记本中看到完整版本。</p><h2 id="2677" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">在网络上找到TPU</h2><p id="2606" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">首先，我们需要在网络上定位TPU，并实例化一个负责分布式计算的<code class="fe ot ou ov ow b">TPUStrategy</code>。在TPU不可用的情况下，代码会退回到GPU或CPU</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h2 id="fcd1" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">数据加载</h2><p id="3b94" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">最佳实践是:</p><blockquote class="ox oy oz"><p id="c1c0" class="lx ly my lz b ma mt ka mc md mu kd mf pa mv mi mj pb mw mm mn pc mx mq mr ms ij bi translated"><em class="iq">📝</em>对于TPU培训，将GCS中的数据组织成合理数量(10到100个)的合理大文件(10到100个MB)。如果文件太少，GCS将没有足够的流来获得最大吞吐量。如果文件太多，访问每个单独的文件会浪费时间。</p></blockquote><p id="595b" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">要实现这一点，需要使用<code class="fe ot ou ov ow b">TFRecord</code>文件格式。我不会在这里这样做，因为数据集很小，我们可以将它缓存在RAM中。但是我建议你按照这个详细的教程去做。</p><p id="9fa5" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">这里我们将从GCS上的文件名中创建一个<code class="fe ot ou ov ow b"><strong class="lz ja">tf.data.Dataset</strong></code> <strong class="lz ja"> </strong>，而不是使用<code class="fe ot ou ov ow b">TFRecord</code>。</p><h2 id="f45b" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">我们为什么要使用这种方法</h2><p id="a7f7" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">在当前的目录结构下(即所有的图片都在一个目录下)，我们本可以使用<code class="fe ot ou ov ow b">ImageDataGenerator.flow_from_dataframe</code>方法<br/>，但是<strong class="lz ja">似乎不支持GCS </strong>给出和错误(不像<code class="fe ot ou ov ow b">pd.read_csv()</code>至少在Kaggle上支持GCS)。</p><p id="78af" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><code class="fe ot ou ov ow b">UserWarning: Found 1821 invalid image filename(s) in x_col=”filename”. These filename(s) will be ignored.</code></p><p id="75a5" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">当使用本地输入的路径调用时，即<code class="fe ot ou ov ow b">../input/plant-pathology-2020-fgvc7/images</code>，它没有任何问题，但是TPUs不能访问本地驱动器。</p><p id="cf95" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">此外，<code class="fe ot ou ov ow b">ImageDataGenerator</code>已被弃用，建议使用<code class="fe ot ou ov ow b">tf.keras.utils.image_dataset_from_directory</code>,这在我们的情况下不方便，因为所有的图像文件都在一个目录中。</p><h2 id="a376" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">要遵循的步骤</h2><p id="b0c0" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated"><strong class="lz ja"> 1。设置和帮助功能<br/>批量大小。</strong>最理想的是批量大小为128* <code class="fe ot ou ov ow b">strategy.num_replicas_in_sync</code>但是由于我们的数据集非常小，我们将使用一个通用的经验法则:<em class="my">一般来说，您的批量大小应该能被8或128整除。</em>使用小批量的另一个好处是我们不需要调整学习率，默认的学习率就可以了(看起来确实如此)。</p><p id="345a" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">每次执行的步骤。</strong>此外，我们将通过使用下面描述的<code class="fe ot ou ov ow b">model.compile()</code>的<code class="fe ot ou ov ow b">steps_per_execution</code>参数来减少小批量:</p><blockquote class="ox oy oz"><p id="8543" class="lx ly my lz b ma mt ka mc md mu kd mf pa mv mi mj pb mw mm mn pc mx mq mr ms ij bi translated"><em class="iq">📝</em> <code class="fe ot ou ov ow b">steps_per_execution</code>指示Keras一次发送多个批次到TPU。有了这个选项，就不再需要为了优化TPU性能而将批量设置得很高。</p></blockquote><p id="9b7f" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">定位训练数据。</strong>此外，我们需要获得Google云存储中当前数据集的路径。注意，下面代码片段中的第二行是特定于Kaggle的。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="4883" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja"> 2。准备分层列车验证分割</strong>结合标签和文件名</p><p id="8647" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja"> 3。对标签</strong>进行一次性编码，以符合竞赛要求的提交格式</p><p id="b1f8" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja"> 4。通过压缩文件名和标签创建训练和验证</strong> <code class="fe ot ou ov ow b"><strong class="lz ja">tf.data.Dataset</strong></code> <strong class="lz ja"> </strong></p><p id="3f45" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja"> 5。映射文件名数据集以获得图像数据集</strong></p><p id="37de" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">6。为训练优化数据集</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="d669" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我使用上面的代码来提高数据输入的性能。我强烈建议您使用tf.data API 来检查<a class="ae le" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank">更好的性能，以使您自己的输入管道高效，从而尽可能减少数据加载瓶颈。</a></p><p id="616a" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">⚠️ <strong class="lz ja">缓存和数据扩充。</strong>值得强调的一个<strong class="lz ja">重要提示</strong><strong class="lz ja">。</strong>确保在数据扩充之前<code class="fe ot ou ov ow b">cache()</code>数据集，否则扩充将不会在每个时期重新应用，并且在扩充步骤中几乎没有意义。这种情况的一个症状是训练与验证的过度拟合，当然过度拟合也可能由于其他原因而发生。</p><p id="f8ff" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">在这一步的最后，我们得到了分层的、高性能的训练和验证数据集。</p><h2 id="30de" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">模型创建</h2><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="8cbf" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">每次执行的步骤。</strong>现在是使用我们之前谈到的<code class="fe ot ou ov ow b">steps_per_execution </code>参数的时候了。在这种情况下，32似乎很管用。</p><p id="9364" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">学习率。</strong>同样，如果你决定使用更大的批量，你很可能需要调整学习率，而不是使用默认的学习率。</p><p id="decf" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">特征尺寸。</strong>在TPU上创建训练模型时，另一个需要注意的重要事项是<strong class="lz ja">特征尺寸。</strong></p><blockquote class="ox oy oz"><p id="cfd1" class="lx ly my lz b ma mt ka mc md mu kd mf pa mv mi mj pb mw mm mn pc mx mq mr ms ij bi translated"><em class="iq">📝</em> <strong class="lz ja">注:</strong> <em class="iq">特征尺寸</em>是指一个全连通层的隐藏尺寸或一个卷积中输出通道的数量。不是所有的层都能符合这个规则，尤其是网络的第一层和最后一层。这很好，大多数模型需要一些填充量。</p></blockquote><p id="7e5e" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">您可以在云TPU性能指南中详细阅读关于<a class="ae le" href="https://cloud.google.com/tpu/docs/performance-guide#tensor_dimensions" rel="noopener ugc nofollow" target="_blank">设置特征尺寸的信息，以确定最适合您的模型和数据的方式。</a></p><p id="d987" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">除此之外，你可以像往常一样使用你喜欢的API创建你的模型(比如顺序的或者功能的)并在<code class="fe ot ou ov ow b">TPUStrategy</code>的范围内实例化它:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在TPUStrategy范围内实例化模型</p></figure><h2 id="c92b" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">模特培训</h2><p id="c29b" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">像往常一样训练你的模型。</p><p id="6ef0" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">如果您在数据准备管道中使用了<code class="fe ot ou ov ow b">ds.repeat()</code>，那么您需要为<code class="fe ot ou ov ow b">model.fit()</code>方法提供<code class="fe ot ou ov ow b">steps_per_epoch</code>和<code class="fe ot ou ov ow b">validation_steps</code>。这适用于任何训练，不仅仅是TPU。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="7fd3" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">第一个模型经过60个历元的训练，准确率约为80%(在TPU上训练大约需要2分钟！！！)但是我们可以注意到一些过度拟合的发生。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/336f3e56c7bccc1bf310e69f741baaa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*WjFFyGseTmuKlR_QM7FUlQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">培训与验证学习曲线</p></figure><p id="7d0a" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">对抗过度拟合的方法之一是使用数据扩充。让我们开始吧。</p><h2 id="1d55" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">数据扩充</h2><p id="f1e9" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">TensorFlow有两种应用数据扩充(以及一般的预处理)的方式(<a class="ae le" href="https://www.tensorflow.org/guide/keras/preprocessing_layers#preprocessing_data_before_the_model_or_inside_the_model" rel="noopener ugc nofollow" target="_blank">更多细节请见</a>):</p><ol class=""><li id="0790" class="mz na iq lz b ma mt md mu mg nb mk nc mo nd ms ne nf ng nh bi translated">将数据增强图层添加到模型中</li><li id="31e2" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms ne nf ng nh bi translated">将数据扩充纳入数据集准备管道</li></ol><blockquote class="ox oy oz"><p id="1ac1" class="lx ly my lz b ma mt ka mc md mu kd mf pa mv mi mj pb mw mm mn pc mx mq mr ms ij bi translated"><em class="iq">当在</em><strong class="lz ja"><em class="iq">GPU</em></strong><em class="iq">上运行时，你会想要使用</em> <strong class="lz ja"> <em class="iq">第一选项</em> </strong> <em class="iq">来从GPU加速中获益。</em> <br/> <em class="iq">当运行在</em><strong class="lz ja"><em class="iq">TPU</em></strong><em class="iq">上时</em> <strong class="lz ja"> <em class="iq">不得不</em> </strong> <em class="iq">使用</em> <strong class="lz ja"> <em class="iq">第二选项</em> </strong> <em class="iq">因为不支持数据增强图层(除了</em> <code class="fe ot ou ov ow b"><em class="iq">Normalization</em></code> <em class="iq">和</em> <code class="fe ot ou ov ow b"><em class="iq">Rescaling</em></code> <em class="iq">)</em></p></blockquote><p id="8443" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">最初我使用了第一个选项，当然它不起作用。不要像我一样:</p><p id="602b" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">💔故障排除。</strong>如果您尝试<code class="fe ot ou ov ow b">.fit()</code>一个在TPU上包含数据扩充层的模型，您将会得到一条<code class="fe ot ou ov ow b">TPU compilation failed</code>消息，显示如下所示的错误:</p><pre class="kp kq kr ks gt pe ow pf pg aw ph bi"><span id="9252" class="oi lg iq ow b gy pi pj l pk pl">NotFoundError: 9 root error(s) found.<br/>  (0) Not found: {{function_node __inference_train_function_183323}} No proto found for key &lt;&lt;NO PROGRAM AS COMPILATION FAILED&gt;&gt;<br/>     [[{{node TPUVariableReshard/reshard/_5957770828868222171/_22}}]]<br/>  (1) Invalid argument: {{function_node __inference_train_function_183323}} Compilation failure: Detected unsupported operations when trying to compile graph while/cluster_while_body_181553_10451082903516086736[] on XLA_TPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_TPU_JIT devices compatible with node {{node while/body/_1/while/sequential_28/sequential_27/random_rotation_8/transform/ImageProjectiveTransformV3}}){{node while/body/_1/while/sequential_28/sequential_27/random_rotation_8/transform/ImageProjectiveTransformV3}}One approach is to outside compile the unsupported ops to run on CPUs by enabling soft placement `tf.config.set_soft_device_placement(True)`. This has a potential performance penalty.<br/>    TPU compilation failed <br/>    etc....</span></pre><p id="4105" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我还试着用<em class="my">在没有任何效果的情况下<code class="fe ot ou ov ow b"><a class="ae le" href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/config/set_soft_device_placement" rel="noopener ugc nofollow" target="_blank">tf.config.set_soft_device_placement(True)</a></code>将增强层保留在主模型中。</em>看起来这个选项只对GPU有效。</p><p id="cbee" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">⚠️出于上述原因，如果你想让你的模型使用数据增强在任何加速器上有效训练，你需要有两个版本。一个用于GPU，另一个用于TPU。</p><h2 id="1be1" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">数据扩充转换</h2><p id="4dcb" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">不应使用改变输出张量重量或高度的数据增强图层(如<code class="fe ot ou ov ow b">RandomWidth</code>、<code class="fe ot ou ov ow b">RandomHeight</code>)</p><p id="cb02" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated"><strong class="lz ja">💔故障排除。</strong>否则，您将再次得到<code class="fe ot ou ov ow b">NotFoundError</code>和<code class="fe ot ou ov ow b">TPU compilation failed</code>消息，并显示类似如下的错误:</p><pre class="kp kq kr ks gt pe ow pf pg aw ph bi"><span id="0a0a" class="oi lg iq ow b gy pi pj l pk pl">(6) Invalid argument: {{function_node __inference_train_function_248407}} Compilation failure: Dynamic Spatial Convolution is not supported: lhs shape is f32[&lt;=8,&lt;=274,&lt;=286,3] <br/>     [[{{node conv2d/Conv2D}}]]<br/>    TPU compilation failed<br/>     [[tpu_compile_succeeded_assert/_3495234026254819081/_5]]<br/>     [[TPUVariableReshard/default_shard_state/_4480269216609879393/_8/_123]]<br/>  (7) Not found: {{function_node __inference_train_function_248407}} No proto found for key &lt;&lt;NO PROGRAM AS COMPILATION FAILED&gt;&gt;<br/>     [[{{node TPUVariableReshard/reshard/_11705470937593059017/_16}}]]<br/>  (8) Invalid argument: {{function_node __inference_train_function_248407}} Compilation failure: Dynamic Spatial Convolution is not supported: lhs shape is f32[&lt;=8,&lt;=274,&lt;=286,3] <br/>     [[{{node conv2d/Conv2D}}]]<br/>    TPU compilation failed<br/>     [[tpu_compile_succeeded_assert/_3495234026254819081/_5]]</span></pre><p id="08d9" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">最后(重要且与任何硬件相关):</p><blockquote class="nr"><p id="1e80" class="ns nt iq bd nu nv nw nx ny nz oa ms dk translated"><em class="pm"> ⚠️ </em> <em class="pm">仅对训练集应用数据扩充</em></p></blockquote><p id="5641" class="pw-post-body-paragraph lx ly iq lz b ma ob ka mc md oc kd mf mg od mi mj mk oe mm mn mo of mq mr ms ij bi translated">将其应用于验证集是没有意义的。除非你打算使用<a class="ae le" rel="noopener" target="_blank" href="/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d">测试时间增强(TTA) </a>集成方法，否则将它应用到测试集是没有意义的(但是那样你会做得不同)。</p><p id="fe04" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">我是这样实现的:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="e480" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">使用具有早期停止的数据扩充(耐心设置为20个时期)导致大约10%的提高的准确性，在大约120个时期内跳跃到大约90%的验证集，而没有任何明显的过度拟合迹象</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/0887bfc76e7a139ce93b26ba941c76f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*5S16rEiScnD5PccY5fkEog.png"/></div></figure><h2 id="b090" class="oi lg iq bd lh oj ok dn ll ol om dp lp mg on oo lr mk op oq lt mo or os lv iw bi translated">迁移学习</h2><p id="e05a" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">使用TensorFlow和Keras进行迁移学习有两种方式:</p><ol class=""><li id="8bb9" class="mz na iq lz b ma mt md mu mg nb mk nc mo nd ms ne nf ng nh bi translated">使用TensorFlow Hub提供的图层。</li><li id="d283" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms ne nf ng nh bi translated">使用<code class="fe ot ou ov ow b">tf.keras.applications</code> API</li></ol><p id="9486" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">就我所知，后者在TPU上训练时可以照常使用。但是有一个警告。TPU自带的Kaggle Tensorflow版本是2.4.1。最新型号(如Efficientnet v2系列)不可用。</p><p id="5db4" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">要使用TensorFlow Hub，需要做一些调整。</p><p id="bd96" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">能够在TPU上训练使用TensorFlow Hub层的模型的最简单方法是<a class="ae le" href="https://github.com/tensorflow/hub/issues/604" rel="noopener ugc nofollow" target="_blank">指示TensorFlow从GCS </a>读取未压缩的模型。默认情况下，TensorFlow Hub会下载压缩模型，并将其缓存到TPU无法访问的本地文件系统中。然后可以创建一个层并照常使用</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="d359" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">另一种方法是使用<code class="fe ot ou ov ow b">tf.saved_model.LoadOptions</code>并将模型直接加载到TPU:</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="og oh l"/></div></figure><h1 id="94e0" class="lf lg iq bd lh li lj lk ll lm ln lo lp kf lq kg lr ki ls kj lt kl lu km lv lw bi translated">结论</h1><p id="dcbb" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">TPUs可以惊人地减少执行一个训练步骤所需的时间。但是，使用它们需要一些设置。此外，需要记住的是，由于TPU非常快，I/O操作很容易成为一个限制因素。因此，在TPU上实现最高性能需要高效的输入管道。本文主要集中在CNN上，但是大部分讨论点也适用于其他类型的深度神经网络。</p><p id="fc3e" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">今天就到这里，希望对你加速训练有所帮助。</p><p id="bea1" class="pw-post-body-paragraph lx ly iq lz b ma mt ka mc md mu kd mf mg mv mi mj mk mw mm mn mo mx mq mr ms ij bi translated">不要犹豫留下评论或提出问题。</p></div><div class="ab cl po pp hu pq" role="separator"><span class="pr bw bk ps pt pu"/><span class="pr bw bk ps pt pu"/><span class="pr bw bk ps pt"/></div><div class="ij ik il im in"><h1 id="344d" class="lf lg iq bd lh li pv lk ll lm pw lo lp kf px kg lr ki py kj lt kl pz km lv lw bi translated">进一步阅读</h1><p id="39c7" class="pw-post-body-paragraph lx ly iq lz b ma mb ka mc md me kd mf mg mh mi mj mk ml mm mn mo mp mq mr ms ij bi translated">显然，我没有涵盖你需要知道的在TPU上成功训练你的ML模型的一切。以下是一些资源列表，它们将帮助您深化知识，并进一步调整和优化您自己的管道和模型。</p><ul class=""><li id="12f7" class="mz na iq lz b ma mt md mu mg nb mk nc mo nd ms nq nf ng nh bi translated"><a class="ae le" href="https://codelabs.developers.google.com/codelabs/keras-flowers-tpu" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja"> Keras and modern convnets，on TPUs</strong></a><strong class="lz ja">codelab by<em class="my">Martin g rner</em></strong><em class="my"/>(我一般会推荐它，不只是在TPU培训的背景下)</li><li id="a824" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated"><a class="ae le" href="https://www.kaggle.com/docs/tpu" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">如何使用ka ggle/张量处理单元(TPUs) </strong> </a> <strong class="lz ja">关于<em class="my"> Kaggle </em> </strong>(一个不错的起点)</li><li id="a242" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated"><a class="ae le" href="https://cloud.google.com/tpu/docs/performance-guide" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">云TPU</strong></a><strong class="lz ja">由<em class="my">谷歌</em> </strong>(在我看来相当简短)</li><li id="f1ae" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated"><a class="ae le" href="https://www.tensorflow.org/guide/data_performance" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">使用tf.data API </strong> </a> <strong class="lz ja"> </strong>可以获得更好的性能(必须阅读性能输入管道)</li><li id="221e" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated"><a class="ae le" href="https://www.tensorflow.org/guide/keras/preprocessing_layers" rel="noopener ugc nofollow" target="_blank"> <strong class="lz ja">在Keras中使用预处理层</strong> </a></li><li id="508e" class="mz na iq lz b ma ni md nj mg nk mk nl mo nm ms nq nf ng nh bi translated"><a class="ae le" href="https://cloud.google.com/tpu/docs/tensorflow-ops" rel="noopener ugc nofollow" target="_blank"/></li></ul></div></div>    
</body>
</html>