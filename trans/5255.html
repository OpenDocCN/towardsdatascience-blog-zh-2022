<html>
<head>
<title>Build a Real-Time Event Streaming Pipeline with Kafka, BigQuery &amp; Looker Studio</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Kafka、BigQuery 和 Looker Studio 构建实时事件流管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-event-streaming-with-kafka-bigquery-69c3baebb51e#2022-11-24">https://towardsdatascience.com/real-time-event-streaming-with-kafka-bigquery-69c3baebb51e#2022-11-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="f4b1" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">一个简单的数据工程项目</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi kj"><img src="../Images/fbd368e682651629c5ad66a5e6f567e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MpkCx_S6E5fO0l8c"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated"><a class="ae kz" href="https://unsplash.com/@fhavlik?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">菲利普</a>在<a class="ae kz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="6822" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi lw translated">实时流媒体应用有时可能会很复杂，当试图了解它们时，决定一个实际的用例对于培养有趣有效的学习体验是很重要的。因此，通过下面的例子，我希望您能够以一种简单的方式掌握构建实时应用程序的基础。</p><h1 id="0fdc" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">方案</h1><p id="0784" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">假设我们在一家<strong class="lc iu">音乐流媒体服务</strong>公司的数据工程部门工作，我们需要创建一个<strong class="lc iu">实时仪表板</strong>，显示某个特定艺术家(比如说<a class="ae kz" href="https://en.wikipedia.org/wiki/Tony_Allen_(musician)" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">【托尼·阿伦】</strong> </a>)一段时间内最受欢迎的歌曲。为此，我们将利用一个流行的<strong class="lc iu">分布式流媒体平台 Kafka </strong>来制作、消费必要的歌曲事件，并将其流式传输到<strong class="lc iu"> BigQuery </strong>中，这样我们就可以在<strong class="lc iu"> Looker Studio </strong>的仪表盘上可视化这些流行歌曲。</p><p id="d441" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们的架构最终会是这样的:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi nc"><img src="../Images/40eccf8879634766cd4063c05e91a58b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2k4w4LltiNGHxJ08OdjyDg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">实时流架构—作者图片</p></figure><h2 id="af45" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">术语和概念</h2><p id="7be8" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">让我们快速定义一些我们将在本文中涉及的术语。</p><ul class=""><li id="15ee" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated"><strong class="lc iu">Kafka</strong>:<a class="ae kz" href="https://www.confluent.io/what-is-apache-kafka/" rel="noopener ugc nofollow" target="_blank">Apache Kafka</a>是一个开源的分布式流媒体平台，支持(除其他外)实时事件驱动应用程序的开发，非常适合我们的用例。</li><li id="a83e" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><strong class="lc iu"> Kafka 集群:</strong>一组服务器(称为代理)，它们协同工作，为实时应用程序提供高可用性、容错和存储。</li><li id="55bc" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">如上所述，代理是在 Kafka 集群中执行实际工作的机器。它托管一些分区集，处理向这些分区写入新事件的传入请求，并允许消费者按主题、分区和偏移量获取消息。</li><li id="cdc1" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><strong class="lc iu">主题</strong>:一个主题仅仅是一个<strong class="lc iu"> <em class="od">事件日志</em> </strong>。来自生成器的每个新事件都被附加到主题的末尾。而话题又分为<a class="ae kz" href="https://developer.confluent.io/learn-kafka/apache-kafka/partitions/#:~:text=Kafka%20Partitioning&amp;text=Partitioning%20takes%20the%20single%20topic,many%20nodes%20in%20the%20cluster." rel="noopener ugc nofollow" target="_blank">分区</a>。</li></ul><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oe"><img src="../Images/f7eb69659fe06b4e98984b5754b00d64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n7gfmWreVgV40AS1lb_vjA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">作者图片</p></figure><ul class=""><li id="af69" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated"><strong class="lc iu"> Producer: </strong>您编写的将数据发布(产生)到 Kafka 集群中的主题的应用程序。</li><li id="d49c" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><strong class="lc iu">消费者:</strong>从 Kafka 集群中实时检索数据的应用程序或最终用户<strong class="lc iu"> </strong>。为了有效地获取实时消息，Kafka 消费者必须订阅集群中存在的各个主题。</li><li id="b4c8" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><strong class="lc iu"> Zookeeper </strong>:跟踪 Kafka 集群节点的状态，它还跟踪 Kafka 主题、分区等等。(<em class="od">注:一个名为</em> <a class="ae kz" href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum" rel="noopener ugc nofollow" target="_blank"> <em class="od">的更新 KIP-500 </em> </a> <em class="od">移除了对 Zookeeper 的需求，但我们在本文中将不会使用那个版本的 Kafka)。</em></li><li id="1c7e" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><strong class="lc iu">Poll</strong>:<code class="fe of og oh oi b">poll()</code>方法是 Kafka 消费者调用的从给定主题中检索记录的函数。</li></ul><p id="8cac" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将在<strong class="lc iu"> 4 个步骤</strong>中设置上述架构。但是在我们开始之前，请确保您具备以下先决条件:</p><h2 id="15ff" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">先决条件</h2><ul class=""><li id="5b3c" class="np nq it lc b ld mx lg my lj oj ln ok lr ol lv nu nv nw nx bi translated">确保你已经安装了<a class="ae kz" href="https://docs.docker.com/engine/install/" rel="noopener ugc nofollow" target="_blank">Docker</a>。</li><li id="dcfd" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">在您的机器上安装<code class="fe of og oh oi b"><a class="ae kz" href="https://pypi.org/project/confluent-kafka/" rel="noopener ugc nofollow" target="_blank">confluent-kafka</a></code> Python 库。</li><li id="b12d" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">启用<a class="ae kz" href="https://cloud.google.com/bigquery/docs/quickstarts/query-public-dataset-console#before-you-begin" rel="noopener ugc nofollow" target="_blank"> BigQuery API </a>。</li><li id="c888" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">在 Google Cloud 中创建一个服务帐户密钥，并提供流 API 工作所需的<a class="ae kz" href="https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery#required_permissions" rel="noopener ugc nofollow" target="_blank">权限。将它保存在您的机器上，因为我们稍后会引用它。</a></li></ul><h1 id="83ef" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">#1.用 Docker 部署 Kafka</h1><p id="376b" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">Kafka 可以通过多种方式部署，但是我们将使用 Docker 来部署它，因为它非常简单。</p><p id="cfe0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们的 Kafka 集群将有两个主要实体；</p><ul class=""><li id="c2ab" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated">1 个代理实例和</li><li id="d41c" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">1 个 Zookeeper 实例。</li></ul><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi om"><img src="../Images/6941fff1a95a578e183b886cb9ed9433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mvohTa4DmmsSWG9ORZGaZQ.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">简单的卡夫卡集群——作者图片</p></figure><p id="0e9d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将使用一个 Docker 组合文件来配置和运行这些容器。您会注意到下面的<code class="fe of og oh oi b">docker-compose.yaml</code>文件中公开的 2 个服务和所需的端口:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="e9bd" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">确保 docker 文件与我们稍后将要编写的 Kafka 生产者和消费者文件位于同一个目录中。</p><p id="4848" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">要构建两个 Docker 容器，运行这个命令，您应该在几分钟内就可以启动并运行这两个容器。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="3f00" class="ot mg it oi b be ou ov l ow ox">docker-compose up -d</span></pre><h1 id="993c" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">#2.构建生成器</h1><p id="6999" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">我们将编写一个模拟音乐流平台上用户活动的应用程序/制作程序。这个应用程序将发送一个名为<code class="fe of og oh oi b">song-completed</code>的事件，当用户完成一首歌曲时就会触发这个事件。这个事件将被发送到一个我们称之为<code class="fe of og oh oi b">tony-allen-plays</code>的卡夫卡主题。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oy"><img src="../Images/48c8f4c5e096ca373d0b6bd53382cb66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BSxTYajeymI8-vxmLzjQhg.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">一个生产者和消费者在 Kafka 集群中与主题互动的架构——作者图片</p></figure><p id="48b0" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们将使用<a class="ae kz" href="https://faker.readthedocs.io/en/master/" rel="noopener ugc nofollow" target="_blank"> Faker 包</a>为我们的应用程序生成假的流数据。我们的假事件有效负载看起来像这样:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="b763" class="ot mg it oi b be ou ov l ow ox">{'user_id':001,<br/>'artist': 'tony-allen',<br/>'song_id': 03, <br/>'song_name':  'lady',<br/>'event_type':'song_completed',<br/>'timestamp': '2022-11-03 07:22:13'}</span></pre><p id="d4d2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">要安装 Faker 包，请在终端窗口中运行:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="e6fa" class="ot mg it oi b be ou ov l ow ox">pip install Faker</span></pre><h2 id="bdd9" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">生成一个假歌曲列表</h2><p id="489a" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">现在，在我们的代码中，我们将启动 Faker 对象，并创建一个硬编码的托尼·阿伦 10 首随机歌曲的歌曲列表，它将成为事件有效负载的一部分。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi oz"><img src="../Images/2752fa19c137347475b7187ca5e49226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vgLNL2Y6k9ve-xB7yVq9Lw.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">我从他在谷歌上的歌曲列表中随机挑选了一些歌曲——作者截图</p></figure><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="7597" class="ot mg it oi b be ou ov l ow ox">from confluent_kafka import Producer<br/>from faker import Faker<br/>import json<br/>import time<br/>import logging<br/><br/>#Create Faker object to generate fake data for Producer<br/>fake=Faker()<br/><br/>#Create Tony Allen song list<br/>songs = ["zombie", "lady", "secret-agent","kindness","soldiers","asiko","the-same-blood","upside-down","african-man","vip"]</span></pre><h2 id="8b30" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">配置日志格式</h2><p id="8348" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">每当一个新事件可用时，日志将被附加到主目录中的一个<code class="fe of og oh oi b">producer.log</code>文件中——我们在下面定义了它。这里，我们正在设置我们希望如何格式化该日志文件的基本配置。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="f364" class="ot mg it oi b be ou ov l ow ox">#Configure logger<br/>logging.basicConfig(format='%(asctime)s %(message)s',<br/>                    datefmt='%Y-%m-%d %H:%M:%S',<br/>                    filename='producer.log',<br/>                    filemode='w')<br/><br/>logger = logging.getLogger()<br/>logger.setLevel(logging.INFO)</span></pre><h2 id="e195" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated"><strong class="ak">发起生产者</strong></h2><p id="d8fb" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">通过指定 Kafka 集群的端口来启动 Kafka producer 对象，如上面的 Docker compose 文件中所定义的:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="7df6" class="ot mg it oi b be ou ov l ow ox">#Create Kafka Producer<br/>p=Producer({'bootstrap.servers':'localhost:9092'})</span></pre><h2 id="58d6" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">配置回拨</h2><p id="9dea" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">定义一个负责确认新消息或错误的回调函数。当有效消息可用时，它被解码为 utf-8 并以首选格式打印。相同的消息也会附加到日志文件中。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="550c" class="ot mg it oi b be ou ov l ow ox">#Callback function<br/>def receipt(err,msg):<br/>    if err is not None:<br/>        print('Failed to deliver message: {}'.format(err))<br/>    else:<br/>        message = 'Produced message on topic {} with value of {}\n'.format(msg.topic(), msg.value().decode('utf-8'))<br/>        logger.info(message)<br/>        print(message)</span></pre><h2 id="03de" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">编写一个生产者循环</h2><p id="d216" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">这是有趣的部分！这里我们只是创建了一个 3 秒延迟的循环，模拟流媒体平台上的实际用户活动。我们为 JSON 事件创建了一个模式，并利用 Faker 来生成实际的数据点。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="b7c2" class="ot mg it oi b be ou ov l ow ox">#Write Producer loop <br/>def main():<br/>    for i in range(20):<br/>        random_song_id = fake.random_int(min=0, max=9)<br/>        data={<br/>           'user_id': fake.random_int(min=20000, max=100000),<br/>           'artist': 'tony-allen',<br/>           'song_id': random_song_id, <br/>           'song_name':  songs[random_song_id],<br/>           'event_type':'song_completed',<br/>           'timestamp': str(fake.date_time_this_month())    <br/>           }<br/>        m=json.dumps(data)<br/>        p.produce('tony-allen-plays', m.encode('utf-8'),callback=receipt)<br/>        p.poll(1) # Polls/checks the producer for events and calls the corresponding callback functions.<br/>        p.flush() #Wait for all messages in the Producer queue to be delivered. Should be called prior to shutting down the producer to ensure all outstanding/queued/in-flight messages are delivered.<br/>        time.sleep(3)</span></pre><p id="d382" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">注意，当我们调用<code class="fe of og oh oi b">p.produce</code>时，我们指定了我们想要发布消息的 Kafka 主题。在这种情况下，称为<code class="fe of og oh oi b">tony-allen-plays</code>。因为这个主题在我们的 Kafka 集群中还不存在，所以它是在这个应用程序第一次运行时自动创建的。</p><p id="d7f2" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><code class="fe of og oh oi b">p.poll</code>很重要，因为它检查事件的生产者并调用我们之前定义的相应回调函数。</p><p id="d9a1" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们完整的<code class="fe of og oh oi b">producer.py</code>脚本应该是这样的:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="on oo l"/></div></figure><p id="fc64" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">要确认生成器按预期工作，请在终端窗口中运行以下命令:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="827e" class="ot mg it oi b be ou ov l ow ox">python producer.py</span></pre><p id="5b79" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">您应该看到下面的输出，它打印出每 3 秒钟发送到 Kafka 主题的事件。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pa"><img src="../Images/c97fd6f84bd0dce4fa28ffa14f076260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8WVR1NhIyS883Oj6gwo4WA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">终端窗口中的生产者输出—按作者分类的图像</p></figure><h1 id="7ade" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">#3.建立消费者</h1><p id="b955" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">消费者会做两件主要的事情:</p><ul class=""><li id="1257" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated">从<code class="fe of og oh oi b">tony-allen-plays</code>主题中轮询和检索事件</li><li id="7c8e" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">使用 BigQuery 流 API 将这些事件作为流发送到 BigQuery</li></ul><h2 id="33b1" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">安装 BigQuery Python 库</h2><p id="abd5" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">首先，使用以下命令安装 BigQuery Python 库。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="1991" class="ot mg it oi b be ou ov l ow ox">pip install google-cloud-bigquery</span></pre><p id="e944" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后我们可以将它导入到<code class="fe of og oh oi b">consumper.py</code>脚本中，并设置 BigQuery 配置。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="9a75" class="ot mg it oi b be ou ov l ow ox">from confluent_kafka import Consumer<br/>from google.cloud import bigquery<br/>import ast<br/>from google.oauth2 import service_account<br/><br/>#Create BQ credentials object<br/>credentials = service_account.Credentials.from_service_account_file('PATH-TO-BQ-SERVICE-ACCOUNT')<br/><br/># Construct a BigQuery client object.<br/>bq_client = bigquery.Client(credentials=credentials)<br/><br/>#Speficy BigQuery table to stream to<br/>table_id = 'PROJECT-ID.DATASET.TABLE-NAME'</span></pre><h2 id="457e" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">启动消费者</h2><p id="144a" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">接下来，我们通过指定端口来启动 Kafka 消费者，然后我们订阅主题<code class="fe of og oh oi b">tony-allen-plays</code>。在初始化消费者时，我们指定消费者 groupid，因为所有 Kafka 消费者必须属于一个消费者组。</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="ad48" class="ot mg it oi b be ou ov l ow ox">c=Consumer({'bootstrap.servers':'localhost:9092','group.id':'tony-allen-consumer','auto.offset.reset':'earliest'})<br/>print('Kafka Consumer has been initiated...')<br/><br/>#Subscribe to topic<br/>c.subscribe(['tony-allen-plays'])</span></pre><p id="3e9d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">您还会注意到有一个属性——<code class="fe of og oh oi b">auto.offset.reset</code>——最早被设置为‘T5’。基本上是从话题划分开始就在告诉消费者消费。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pb"><img src="../Images/afb20db2aa3d98a555fef8b6946ad6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MN8dJO34GmzimcJ9_QoDfA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">卡夫卡<strong class="bd pc"> auto.offset.reset:最早的</strong> —作者图片</p></figure><p id="0194" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">典型的 Kafka 消费应用程序以消费循环为中心。因此，最后一步是编写一个循环，不断地轮询主题中的新消息，如果发现新消息，就将这些消息发送给 BigQuery。</p><p id="9189" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们完整的脚本应该是这样的:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="on oo l"/></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">卡夫卡消费者. py</p></figure><h2 id="4bdf" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">运行 Kafka 管道</h2><p id="f2e3" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">既然已经设置了消费者和生产者，那么打开两个单独的终端窗口并再次运行生产者:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="601f" class="ot mg it oi b be ou ov l ow ox">python producer.py</span></pre><p id="8188" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">然后运行消费者，以便它实时从主题中读取数据:</p><pre class="kk kl km kn gt op oi oq bn or os bi"><span id="5289" class="ot mg it oi b be ou ov l ow ox">python consumer.py</span></pre><p id="ede6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您看到生产者生成的消息开始出现在消费者终端窗口中，那么您的消费者正在正常工作，数据也应该流入 BigQuery:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pd"><img src="../Images/c4ec021e59923c00372a6ad5a08a35e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLimM3yeh-hNfIvQL-u1VA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">Kafka consumer.py 输出—作者图片</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pe"><img src="../Images/71be825b1a56d1f7244994ad8c35fc59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uj2u_PxVYx1Iy3r4sLigbA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">《大查询》中的卡夫卡事件——作者图片</p></figure><h1 id="ee2a" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">#4.可视化数据</h1><p id="4953" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">最后一步是将 BigQuery 表连接到 Looker Studio，并创建一个简单的条形图，以接近实时的方式显示流行歌曲。</p><p id="857c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">前往<a class="ae kz" href="https://datastudio.google.com/u/2/navigation/reporting" rel="noopener ugc nofollow" target="_blank"> Looker Studio </a>，签到并:</p><ul class=""><li id="1182" class="np nq it lc b ld le lg lh lj nr ln ns lr nt lv nu nv nw nx bi translated">选择新的“空白报告”</li><li id="ba70" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">在“连接到数据”下，选择“BigQuery”作为数据源</li><li id="f013" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated">然后选择您的 BigQuery 项目、数据集和表</li></ul><p id="da11" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">现在您应该看到一个类似的视图。确保<em class="od">尺寸</em>和<em class="od">度量</em>字段与下面的屏幕截图匹配，您应该有一个如图所示的简单条形图。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gh gi pf"><img src="../Images/50c934efdc044e208503debf3ae3e9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K8J_u4dYoEcWvApPld0eaA.png"/></div></div><p class="kv kw gj gh gi kx ky bd b be z dk translated">Looker 工作室截图作者。“总播放次数”由“记录计数”更名而来。—作者图片</p></figure><h2 id="8ee1" class="nd mg it bd mh ne nf dn ml ng nh dp mp lj ni nj mr ln nk nl mt lr nm nn mv no bi translated">接近实时的仪表板</h2><p id="167d" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">Looker Studio 有一个<a class="ae kz" href="https://support.google.com/looker-studio/answer/7020039#zippy=%2Cin-this-article" rel="noopener ugc nofollow" target="_blank"> <strong class="lc iu">数据刷新</strong> </a> <strong class="lc iu"> </strong>特性，它指定了仪表板刷新的频率。您可以将其设置为 1 分钟，这是当前可用的最频繁的刷新周期，您的控制面板应该每 1 分钟刷新一次。</p><h1 id="8f41" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">结论</h1><p id="8075" class="pw-post-body-paragraph la lb it lc b ld mx ju lf lg my jx li lj mz ll lm ln na lp lq lr nb lt lu lv im bi translated">我们讲述了如何用 Docker 建立一个最小的 Kafka 集群，将数据加载到一个主题中，然后消费数据并将其传输到 BigQuery。最后，我们创建了一个近乎实时的仪表板，在 Looker Studio 中呈现最终结果。</p><p id="513a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我希望你觉得这很有用，并祝你好运建立你的下一个实时应用程序！欢迎分享您的任何建议或其他使用案例。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><blockquote class="pn"><p id="d586" class="po pp it bd pq pr ps pt pu pv pw lv dk translated">你可以<a class="ae kz" href="https://medium.com/@tobisam/membership" rel="noopener">成为中会员</a>支持我，享受更多这样的故事。</p></blockquote><h2 id="41cf" class="nd mg it bd mh ne px dn ml ng py dp mp lj pz nj mr ln qa nl mt lr qb nn mv no bi translated">参考</h2><ul class=""><li id="588b" class="np nq it lc b ld mx lg my lj oj ln ok lr ol lv nu nv nw nx bi translated"><a class="ae kz" href="https://docs.confluent.io/kafka-clients/python/current/overview.html#ak-python" rel="noopener ugc nofollow" target="_blank">融合的卡夫卡 API </a></li><li id="02ac" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><a class="ae kz" href="https://medium.com/towards-data-science/how-to-build-a-simple-kafka-producer-and-consumer-with-python-a967769c4742" rel="noopener">如何用 Python 构建一个简单的 Kafka 生产者和消费者</a></li><li id="ae0e" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><a class="ae kz" href="https://kafka.apache.org/documentation.html#newconsumerconfigs" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡文档</a></li><li id="25af" class="np nq it lc b ld ny lg nz lj oa ln ob lr oc lv nu nv nw nx bi translated"><a class="ae kz" href="https://medium.com/lydtech-consulting/kafka-consumer-auto-offset-reset-d3962bad2665" rel="noopener">卡夫卡消费抵消</a></li></ul></div></div>    
</body>
</html>