<html>
<head>
<title>Tuning an Artificial Neural Network: Optimizing a Multiclass Text Classifier using KerasTuner and other basic Data Analytics Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">调整人工神经网络:使用KerasTuner和其他基本数据分析技术优化多类文本分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-improved-the-performance-of-a-multiclass-text-classifier-using-kerastune-and-other-basic-data-161a22625009#2022-08-22">https://towardsdatascience.com/how-i-improved-the-performance-of-a-multiclass-text-classifier-using-kerastune-and-other-basic-data-161a22625009#2022-08-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8495" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">探索如何通过将简单数据和/或NLP技术与使用KerasTuner超波段算法的人工神经网络超参数调整相结合来提高基于文本的模型的性能</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9434a0fc16d5708cdd16e75cbf670ffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*M5aWbLmQE8aFtW0A"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@tengyart?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">腾雅特</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="3d91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我之前的一篇关于使用Keras预测情绪的<a class="ae ky" rel="noopener" target="_blank" href="/multiclass-text-classification-using-keras-to-predict-emotions-a-comparison-with-and-without-word-5ef0a5eaa1a0">多类文本分类的文章</a>中，我比较了使用skipgrams为深度文本分类器提供预测情绪的学习单词嵌入的结果，以及另一个从零开始学习嵌入的深度文本分类器的结果。<strong class="lb iu">从零开始学习嵌入的人工神经网络分类器比另一个稍微好一点</strong>，在本文中我将把它作为我的基线。</p><p id="227e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在这里阅读上一篇文章:</strong></p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/multiclass-text-classification-using-keras-to-predict-emotions-a-comparison-with-and-without-word-5ef0a5eaa1a0"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">使用Keras预测情感的多类文本分类:使用和不使用单词的比较…</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">单词嵌入增加了文本分类模型的价值吗？让我们在这个多类预测任务中找出…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="c287" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">在这次重新访问相同的数据集时，</strong>在Kaggle <a class="ae ky" href="https://www.kaggle.com/praveengovi/emotions-dataset-for-nlp" rel="noopener ugc nofollow" target="_blank">这里</a>和拥抱人脸数据集<a class="ae ky" href="https://huggingface.co/datasets/emotion" rel="noopener ugc nofollow" target="_blank">这里</a>，<strong class="lb iu">上公开可用，我将尝试改进模型</strong>，在未见过的数据集上的加权平均召回率为81%。</p><p id="611a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在下图中，报告了模型在测试集上的性能。这里，<em class="mn">模型1 </em>是指经过<strong class="lb iu">训练的带有</strong> word2vec嵌入的模型，<em class="mn">模型2 </em>是指经过<strong class="lb iu">训练的没有</strong> word2vec嵌入的模型。回忆那次回忆😏在这个用例中很重要，因此得出结论，第二个模型表现稍好，因此，<strong class="lb iu">模型2是本文的基线。</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mo"><img src="../Images/6657cf4bad2712c8344c939b085c904c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjHT16ytS3Y_xgn6jZaCWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我上一篇关于测试数据集的文章中的两个模型的性能</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="31c1" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated"><strong class="ak">让我们从列出模型改进的5大推荐技术开始:</strong></h1><ol class=""><li id="9328" class="no np it lb b lc nq lf nr li ns lm nt lq nu lu nv nw nx ny bi translated">追加更多的数据，最终给一个ML模型更多的例子来学习和归纳。</li><li id="6eb5" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">特征工程</strong>用于从给定数据中提取有用的信息，使模型能够轻松有效地找到预测模式……以及<strong class="lb iu">特征选择</strong>用于处理<a class="ae ky" href="https://www.techopedia.com/definition/3801/garbage-in-garbage-out-gigo" rel="noopener ugc nofollow" target="_blank"> GIGO </a>问题。基本上，这允许模型只使用一些有用的特征，去除噪声，并节省计算时间和资源。</li><li id="04b3" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">尝试<strong class="lb iu">多种算法</strong>找到最适合预测的算法。</li><li id="7894" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">使用<strong class="lb iu">交叉验证</strong>获得一个稳健且通用的模型。使用交叉验证，您可以在数据集的多个块上训练和测试模型的性能，获得平均性能，并确定模型是否处于最佳状态。</li><li id="232a" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">调整超参数</strong>以识别适合数据集的最佳组合，因为它们对模型训练过程的结果有着关键的影响。</li></ol></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="960d" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">现在…让我们开始编码吧！😄</h1><p id="e9b2" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">参考我在<a class="ae ky" rel="noopener" target="_blank" href="/multiclass-text-classification-using-keras-to-predict-emotions-a-comparison-with-and-without-word-5ef0a5eaa1a0">上一篇文章</a>中的<a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/EmotionClassifier.ipynb" rel="noopener ugc nofollow" target="_blank">相同的笔记本</a>，我做了一些改动</p><p id="03c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1。修改了数据策略</strong> —在前一个中，我使用了2/3的数据进行训练，并保留了1/3的数据进行验证。在这一次，我使用整个train.txt进行训练，并在模型训练期间使用验证集来验证和改进模型性能。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="11e8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2。文本清理和规范化</strong> —以前，我直接使用文本数据，没有清理和规范化它。在这一次，我删除了停用词，并使用波特斯特梅尔获得了词干。它将vocab的大小降低到10375。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="d255" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3。作为引子，我重新设计了</strong>模型，降低了辍学率，并增加了两个LSTM层的单元数量。此外，由于前一步骤中的清洗，vocab大小从15000变为10000。此外，除了LSTM之外，我还试用了<a class="ae ky" href="https://keras.io/api/layers/recurrent_layers/simple_rnn/" rel="noopener ugc nofollow" target="_blank"> SimpleRNN </a>和<a class="ae ky" href="https://keras.io/api/layers/recurrent_layers/gru/" rel="noopener ugc nofollow" target="_blank">门控循环单元</a>。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="f246" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">…并告诉模型<strong class="lb iu">应该关注哪些指标。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="aaeb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">之前，该模型是使用度量标准'<strong class="lb iu"><em class="mn">'</em></strong>编译的。由于我们正在处理一个不平衡的数据集，准确性不是正确的衡量标准。<strong class="lb iu">精度</strong>和<strong class="lb iu"> / </strong>或<strong class="lb iu">召回</strong>更好。我之前选择了查全率而不是查准率，但是无论如何我都想提高两者，所以我将它们指定为评估模型的度量标准。还要注意的是，F1-score在Keras中不是现成的指标，所以为了简单起见，我在列表中直接使用了precision和recall。</p><h2 id="f739" class="oj mx it bd my ok ol dn nc om on dp ng li oo op ni lm oq or nk lq os ot nm ou bi translated"><strong class="ak">修正模型性能评估:</strong></h2><p id="c3e0" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">当我更新这些配置时，模型性能有了显著的提升。看看下面LSTM模型的性能</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ov"><img src="../Images/123303160c37711a05365ef890bff8dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n8y0eCss-IEzEwyL6jVTCA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用更新的超参数和LSTM|作者图片对训练、验证和测试集的性能进行建模</p></figure><p id="07f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">回想一下我们的加权回忆😉基准模型在测试数据上的准确率为81%,而在相同数据上的准确率提高到89%。测试数据中实例数量最多的三个类的召回率等于或高于90%。</p><p id="2136" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我想尝试简单和GRU以及其他RNN层。GRU在测试数据上的性能与LSTM相似，对测试数据的召回率为90%，而SimpleRNN为81%，相当于基线模型！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ow"><img src="../Images/9c0e8a6c88c792ee58a04bc0e4f0e64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_qxep2fxcJMFN2J5CyCjw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用SimpleRNN和GRU的更新超参数在测试集上建模性能|图片由作者提供</p></figure><p id="c934" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SimpleRNN的性能很差，因为模型明显过拟合。这是模型的训练验证损失曲线-</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/c8a520894c52592e6068c9ef86cde24e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mvXfzpO8I7Xkmg9h8xE4Og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蓝色曲线是训练损失，红色曲线是验证损失|作者图片</p></figure><p id="d332" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意，重叠发生在时段4，并且验证损失在时段7之后继续改善。之后，验证损失开始变得不稳定，时有增减。早期停止算法使用耐心5，并且由于验证损失的这种不稳定性，模型继续训练，最终挑选时段19作为最佳时段。这也是由于我在代码<code class="fe oy oz pa pb b">epochs=20</code>中设置的限制。如果我设置了超过20个时期，模型将会多训练5个时期。显然，这个模型不能对测试集或任何由分类报告显示的看不见的数据进行归纳。</p><p id="2a03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">此外，模型的训练时间如下:</p><ul class=""><li id="e244" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu pf nw nx ny bi translated">LSTM—6分钟</li><li id="91ea" class="no np it lb b lc nz lf oa li ob lm oc lq od lu pf nw nx ny bi translated">简单神经网络—19分钟</li><li id="c3df" class="no np it lb b lc nz lf oa li ob lm oc lq od lu pf nw nx ny bi translated">GRU—8分钟</li></ul><p id="038b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然，简单神经网络的训练时间较长，但LSTM和GRU模型的训练速度较快。</p><p id="1dd5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">最后，这是LSTM模型在测试数据上表现的混淆矩阵:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pg"><img src="../Images/4534c89cc0f56d1f0cfcf9249d8999bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*apxaxf5kU2pSV3L5zZ-AYw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">LSTM模型在测试数据上表现的混淆矩阵|图片由作者提供</p></figure><p id="4710" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这个模型仍然会在愤怒和悲伤、快乐和爱之间，以及在快乐和悲伤之间有点混淆！但是每类错误分类的百分比已经显著降低。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="8b16" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">重温5大推荐技术:</h1><ol class=""><li id="d1cf" class="no np it lb b lc nq lf nr li ns lm nt lq nu lu nv nw nx ny bi translated"><strong class="lb iu">追加更多data✅ </strong> —自从我在训练时使用单独的验证集来验证模型性能以来，训练集现在有了更多数据。</li><li id="9469" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">特征工程和特征选择</strong> ✅— I清理并规范化了文本，并且vocab大小也从15k减少到10k。</li><li id="80fd" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">多种算法和改变的超参数✅ </strong> —我修改了模型的网络配置，并将改进的重点从准确度更新为精确度和召回率。我还测试了SimpleRNN和GRU。</li><li id="a481" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">使用<strong class="lb iu">交叉验证❌ </strong></li><li id="3f65" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">调整超参数❌ </strong></li></ol><p id="a3eb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在测试数据上，这三个变化将模型的性能从81%提高到89% (LSTM)和90% (GRU)。所以，是时候探索交叉验证和超参数调整了，看看会发生什么。</p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="f534" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">介绍Keras-Tuner</h1><p id="781b" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">Keras-tuner是一个为您的神经网络模型找到最佳超参数集(或<em class="mn">调整超参数</em>)的库。</p><p id="7ac3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用以下命令安装Keras Tuner:</p><pre class="kj kk kl km gt ph pb pi pj aw pk bi"><span id="cda8" class="oj mx it pb b gy pl pm l pn po">pip install <strong class="pb iu">-</strong>q <strong class="pb iu">-</strong>U keras<strong class="pb iu">-</strong>tuner</span></pre><p id="8021" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，在将文本数据准备成填充序列之后，使用LSTM进行调谐的模型构建过程如下:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="5654" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">KerasTuner允许我们在构建模型时内联定义超参数。比如我用'<em class="mn"> vector size </em>'作为超参数进行调优，指定它应该是一个<strong class="lb iu">整数</strong> (hp。<strong class="lb iu"> Int </strong>)，其最小值为100，最大值为500。它将在搜索空间中以100的步长递增。</p><p id="b963" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在model_builder函数中，我定义了五个超参数-</p><ol class=""><li id="a0ea" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu nv nw nx ny bi translated">vector _ size-Integer |范围100到500，步长:100</li><li id="e0f7" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">dropout_rate — Float |范围为0.6到0.9，步长为0.1</li><li id="27af" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">lstm_units1 —整数|范围32到512，步长:32</li><li id="b09c" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">lstm_units2 —整数|范围16到512，步长:32</li><li id="a6ce" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">learning _ rate-Choice | 1e-2、1e-3、1e-4</li></ol><p id="9a91" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://keras.io/api/keras_tuner/hyperparameters/" rel="noopener ugc nofollow" target="_blank">超参数类</a>给出了一些设计搜索空间的选择。我们可以指定一个超参数是否是布尔(<em class="mn"> hp。布尔型</em>、整型(<em class="mn">hp.Int |第3、16、21行</em>)、浮点型(<em class="mn"> hp)。Float | line 11 </em>，几个选项中的一个选择(<em class="mn"> hp)。选择|第27行</em>)，或者一个固定值等等。</p><p id="bf0c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们已经定义了超参数搜索空间，这意味着<strong class="lb iu"> <em class="mn">超模型</em> </strong>已经准备好开始调优了。为了找到最佳的超参数，首先我使用下面的代码实例化了调谐器:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="b8c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了实例化Hyperband调谐器，我为超级模型指定了以下参数:</p><ol class=""><li id="aedd" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu nv nw nx ny bi translated">超级模型:model_builder函数</li><li id="1c1b" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">目的:超模型中描述的模型的损失函数。我在这个用例中使用了验证召回。</li><li id="3ed5" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">max_epochs:训练一个模型的最大次数</li><li id="c229" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">factor:一个整数，用于定义每个括号中模型和时期数的缩减系数。一个括号中训练的模型数计算为<code class="fe oy oz pa pb b">rounded to nearest</code> (1 + log <code class="fe oy oz pa pb b"><strong class="lb iu">base</strong>=factor</code> ( <code class="fe oy oz pa pb b">max_epochs</code>))</li><li id="a17b" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">目录/项目:在超参数调整期间记录每个试验的配置、检查点和分数</li></ol><p id="bbb0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在<em class="mn">第11行</em>中，我添加了一个提前停止配置来监控验证召回。因此，在一个时期中实现最佳验证召回之后，该模型继续为接下来的5个时期进行训练，以进行任何进一步的改进。最后我在<em class="mn">第21行</em>开始了最佳超参数搜索。</p><h2 id="6cc5" class="oj mx it bd my ok ol dn nc om on dp ng li oo op ni lm oq or nk lq os ot nm ou bi translated"><strong class="ak">超波段调谐器算法是如何工作的？</strong></h2><p id="067d" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">超波段调谐器是连续减半算法(SHA)的扩展，用于提前停止的自适应资源分配。</p><p id="8f12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">用于自适应资源分配的连续减半算法的工作原理可以概括为:</p><ol class=""><li id="914f" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu nv nw nx ny bi translated">将所有资源统一分配给超参数集，并使用一半的资源/时间对它们进行调优。当运行调谐器时，这种策略就显现出来了。请注意，初始模型训练了大约3或4个时期，这远远低于指定的最大时期数。</li><li id="5596" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">性能最好的上半部分超参数集随后被“推进”到下一阶段，在该阶段，使用分配给它们的更高资源/时间来训练结果模型。在运行调谐器时，接近尾声时，这就是epochs数较高的原因。</li><li id="f778" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated">重复直到只有一个配置。</li></ol><p id="4312" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这种算法被调整了一点，使其更灵活的超波段调谐器。它使用η，η是消除率，其中只有1/ η的超参数集前进到下一个括号用于训练和评估。η由算法的这个Keras实现中的公式<code class="fe oy oz pa pb b">rounded to nearest</code> (1 + log <code class="fe oy oz pa pb b"><strong class="lb iu">base</strong>=factor</code> ( <code class="fe oy oz pa pb b">max_epochs</code>))确定。</p><p id="f10a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在原文<a class="ae ky" href="https://jmlr.org/papers/volume18/16-558/16-558.pdf" rel="noopener ugc nofollow" target="_blank">的</a>中阅读更多相关内容。</p><h2 id="e69a" class="oj mx it bd my ok ol dn nc om on dp ng li oo op ni lm oq or nk lq os ot nm ou bi translated">现在…回到代码上来</h2><p id="2220" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">我用两个因子进行了实验:3和5，这里是最佳超参数值的结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pp"><img src="../Images/b931357dfa214b801274a76c9d8bc873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WXOCarptMgaq75-1CcxITg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用因子3和因子5的优化模型的最佳超参数值|作者图片</p></figure><p id="7a70" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，使用最佳超参数来构建最终模型(<em class="mn"> line 2 </em>)，我再次使用相同的旧ANN回调和训练代码来训练它。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="816a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pq"><img src="../Images/cf4f2d5aaf3338b840caa5e30656c560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V51ZOnLVw3Cx2WoKFNagEQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在训练、验证和测试集上使用因子3和因子5的最佳表现模型的结果|图片由作者提供</p></figure><p id="3f1d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这两个模型的性能相似，但是，在未知数据集上，整体性能比基线模型提高了11%，尽管从最后一个模型来看，只有微小的提高。</p><h2 id="e4fb" class="oj mx it bd my ok ol dn nc om on dp ng li oo op ni lm oq or nk lq os ot nm ou bi translated">和...我还使用GRUs重复了这个过程</h2><p id="b3d0" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">以下是model_builder函数的更新代码:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oh oi l"/></div></figure><p id="9a27" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">超参数和模型对测试数据的性能是:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pr"><img src="../Images/9e2cc270ced7d9acbef2666dc3ab085f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fB8gKKvgxB32mvKJHbjmzQ.png"/></div></div></figure><p id="46f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意，加权平均召回率与调整后的LSTM相同，而宏观平均召回率略有不同。然而，调整后的GRU模型的<strong class="lb iu">向量大小是因子为3的调整后的LSTM的两倍，是因子为5的</strong>的四倍。此外，GRU网络单元比LSTMS的大，这表明如果与两个调整的LSTM模型相比，该模型将占用更多的内存。</p><p id="0e43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">这些模型不会过度拟合吗？</strong></p><p id="9cd8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">过度拟合是指模型从训练数据中学到了太多东西，无法对看不见的数据进行归纳，而欠拟合是指模型没有学到足够的东西，无法从新数据中得出有效的结论。</p><p id="0743" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这是最终模型的训练和验证损失图。在这两个图中，我们可以看到随着时代的增加，训练损失越来越低，模型变得过度拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ps"><img src="../Images/f5a1498b304821290c7b4024e5509722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knd5eAHVc_I8QTPKsUZ6qA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用因子=3调整的模型|图片由作者提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/bb3569db06b4811b115bf53d4e69e181.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*to_vct2xDJzOtCvpAMO4EA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用因子=5调整的模型|图片由作者提供</p></figure><p id="18c6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因子=3的调整模型的验证损失在0.25和0.28之间波动，而另一个模型的验证损失停滞在0.22左右。如图所示，模型的过度拟合确实会影响验证损失。在第一种情况下，在两个损失相同的第4个时期之后，训练损失减少，而验证缓慢增加。然而，该模型被训练到第8个时期，在该时期验证损失最低，即模型的概括能力最高。然而，在第8个时期的模型具有过度拟合的风险，因为验证损失不遵循增加的模式，并且在最佳时期的值是突然下降的(因此基本上它就像一个异常值)。</p><p id="7b8e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">如果我不得不选择… </strong>放弃调整后的GRU模型，因为它对未知数据具有相同的性能，但对计算使用了更多的<em class="mn">内存</em>，我宁愿选择LSTM模型之一，如果我专注于资源和计算方面，最好是因子为5的模型。召回的<em class="mn">宏观和加权平均值在测试集上对于系数为5的LSTM来说是高的</em>，因此我会选择这个。此外，最佳历元处的训练损失和验证损失之间的<em class="mn">差异对于该模型来说更低(…并因此降低过拟合的机会)，为0.05(<em class="mn">0.21-0.16</em>)，而对于另一模型来说为0.09(<em class="mn">0.23-0.14</em>)。此外，对于系数为5的调谐LSTM，交叉点处的训练损失与最佳时期</em>之间的<em class="mn">差异也较低。</em></p><p id="f1ee" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而……在所有的调整、搜索和提炼之后，最好的模型仍然对love❤️和乔伊感到困惑😄如下图所示:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/8ba1cae7584edd4fb9ccb8a8513b7ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWa2Dl0kaQY_M1PNYK22Og.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用因子=3调整的LSTM模型的性能|图片由作者提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/4c171e2f7a4c0e9fe98feca6546ce5bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z42MSG96fUYLJfqVawXaiw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">使用因子=5调整的LSTM模型的性能|图片由作者提供</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/2c02242328c61bd5840ee085cc2f35a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_BR3ASqSDS4LsfxLIe-qw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">调谐GRU模型的性能|图片由作者提供</p></figure><p id="020e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">…但是与我们基线的热图相比，后者看起来肯定更丰富多彩，这表明错误分类率更高:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/dd475db16b8c4d43f57d998996659740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C06YjZ3Xg7taTEdgdjEPxA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">基线模型的性能|作者提供的图片</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="1a51" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated"><strong class="ak">结论:</strong></h1><p id="14a2" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">最后，回顾一下模型改进的前5个最常用的方法，我现在是4.5/5。</p><ol class=""><li id="694f" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu nv nw nx ny bi translated"><strong class="lb iu">追加更多data✅ </strong></li><li id="319d" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">特征工程和特征选择</strong> ✅</li><li id="ea7e" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">多重算法和被改变的Hyperparameters✅ </strong></li><li id="7e40" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">交叉验证❌验证✅ </strong></li><li id="3bbf" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><strong class="lb iu">调整超参数✅ </strong></li></ol><p id="f1d3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果是，在测试数据集上，宏召回率从74%提高到86%，加权召回率从81%提高到90%。</p><p id="655f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">列表中唯一遗漏的是交叉验证，但是，一个验证集已经用于验证模型在训练时的性能。与<a class="ae ky" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank"> Sklearn的超参数调优实现</a>不同，KerasTuner没有实现CV，我在文档中找不到任何关于它的内容。此外，为了执行交叉验证，我可能必须混合训练和验证数据，以使用K-fold交叉验证(CV)技术。KerasTuners中的Sklearn调谐器提供了该选项，但要调谐的型号应该是sklearn型号。希望在另一个博客中探讨这个问题！💡</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi py"><img src="../Images/546295bf854b549a721d32db46b80a54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0BNMVvVydI_fyLfI"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae ky" href="https://unsplash.com/@cmhedger?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Courtney hedge</a>拍摄的照片</p></figure></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="0894" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">资源和代码:</h1><p id="9827" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated"><strong class="lb iu">本博客使用的笔记本:</strong> <em class="mn"> </em> <a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/EmotionClassifier_Model_Improvement.ipynb" rel="noopener ugc nofollow" target="_blank">车型改进笔记本</a> | <a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/EmotionClassifier_KerasTuner_2.ipynb" rel="noopener ugc nofollow" target="_blank">使用Keras调谐器的车型改进</a> (LSTM)| <a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/EmotionClassifier_KerasTuner_GRU.ipynb" rel="noopener ugc nofollow" target="_blank">使用Keras调谐器的车型改进(GRU) </a></p><p id="9a20" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">笔记本参考</strong> <a class="ae ky" rel="noopener" target="_blank" href="/multiclass-text-classification-using-keras-to-predict-emotions-a-comparison-with-and-without-word-5ef0a5eaa1a0"> <strong class="lb iu">往期博客</strong></a><strong class="lb iu">:</strong><em class="mn"/><a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/DataExploration.ipynb" rel="noopener ugc nofollow" target="_blank">数据分析笔记本</a> | <a class="ae ky" href="https://github.com/royn5618/Medium_Blog_Codes/blob/master/Emotion%20Detection/EmotionClassifier.ipynb" rel="noopener ugc nofollow" target="_blank">分类器训练笔记本</a></p><p id="69fc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">使用的参考资料和进一步阅读:</strong></p><ol class=""><li id="c49c" class="no np it lb b lc ld lf lg li pc lm pd lq pe lu nv nw nx ny bi translated"><a class="ae ky" href="https://www.tensorflow.org/tutorials/keras/keras_tuner" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/keras/keras_tuner</a></li><li id="d61f" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="https://keras.io/api/keras_tuner/tuners/hyperband/" rel="noopener ugc nofollow" target="_blank">https://keras.io/api/keras_tuner/tuners/hyperband/</a></li><li id="bdf0" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="https://jmlr.org/papers/volume18/16-558/16-558.pdf" rel="noopener ugc nofollow" target="_blank">https://jmlr.org/papers/volume18/16-558/16-558.pdf</a></li><li id="d2fa" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="https://analyticsindiamag.com/speed-up-hyperparameter-tuning-in-deep-learning-with-keras-hyperband-tuner/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/speed-up-hyperparameter-tuning-in-deep-learning-with-keras-hyperband-tuner/</a></li><li id="3eaa" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="http://www.argmin.net/2016/06/23/hyperband/" rel="noopener ugc nofollow" target="_blank">http://www.argmin.net/2016/06/23/hyperband/</a>⭐</li><li id="8329" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/" rel="noopener ugc nofollow" target="_blank">https://blog . ml . CMU . edu/2018/12/12/massively-parameter-optimization/</a>⭐</li><li id="3e21" class="no np it lb b lc nz lf oa li ob lm oc lq od lu nv nw nx ny bi translated"><a class="ae ky" href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/learning-curves-for-diagnostic-machine-learning-model-performance/</a></li></ol></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><h1 id="4576" class="mw mx it bd my mz na nb nc nd ne nf ng jz nh ka ni kc nj kd nk kf nl kg nm nn bi translated">数据集引用:</h1><p id="a84d" class="pw-post-body-paragraph kz la it lb b lc nq ju le lf nr jx lh li oe lk ll lm of lo lp lq og ls lt lu im bi translated">[1]萨拉维亚，刘，洪春涛，黄，杨海红，吴，陈永胜(2018)。<a class="ae ky" href="http://dx.doi.org/10.18653/v1/D18-1404" rel="noopener ugc nofollow" target="_blank"> Carer:用于情绪识别的情境化情感表征。</a>在<em class="mn">2018自然语言处理经验方法会议论文集</em>(第3687–3697页)</p><p id="3742" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://huggingface.co/datasets/emotion" rel="noopener ugc nofollow" target="_blank"><em class="mn">hugging face上的许可证:未知</em></a><em class="mn">|</em><a class="ae ky" href="https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp/metadata" rel="noopener ugc nofollow" target="_blank"><em class="mn">ka ggle上的许可证:CC BY-SA 4.0 </em> </a></p></div><div class="ab cl mp mq hx mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="im in io ip iq"><p id="f86d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="mn">感谢光临！</em></p><p id="e754" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">我的链接:</strong> <a class="ae ky" href="https://medium.com/@nroy0110" rel="noopener">中型</a>|<a class="ae ky" href="https://www.linkedin.com/in/nabanita-roy/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>|<a class="ae ky" href="https://github.com/royn5618" rel="noopener ugc nofollow" target="_blank">GitHub</a></p></div></div>    
</body>
</html>