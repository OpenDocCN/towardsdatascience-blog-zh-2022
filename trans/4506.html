<html>
<head>
<title>Graph Neural Networks with PyG on Node Classification, Link Prediction, and Anomaly Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于PyG的图神经网络在节点分类、链路预测和异常检测方面的应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275#2022-10-06">https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275#2022-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5b06" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Pytorch几何在主要图问题上的实现</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/697960f2cf5778fcc9aed54036b97735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IyuE7DZYDuL92Og0XIn-3Q.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">照片由<a class="ae kv" href="https://unsplash.com/ja/@deepmind?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> DeepMind </a>在<a class="ae kv" href="https://unsplash.com/s/photos/graph-neural-network?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><p id="12d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图形神经网络是一种机器学习算法，设计用于图形结构数据，如社交图、网络安全中的网络或分子表示。在过去的几年中，它发展迅速，并被用于许多不同的应用中。在这篇博文中，我们将回顾它在主要图问题上的代码实现，以及GNN的所有基础知识，包括它的应用和算法细节。</p><h1 id="9087" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">图形神经网络的应用</h1><p id="639d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">GNN可用于解决各种与图形相关的机器学习问题:</p><ul class=""><li id="8903" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><strong class="ky ir">节点分类</strong> <br/>预测节点的类别或标签。例如，在网络安全中检测网络中的欺诈实体可以是节点分类问题。</li><li id="2276" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">链接预测</strong> <br/>预测节点之间是否存在潜在的链接(边)。例如，社交网络服务基于网络数据建议可能的朋友联系。</li><li id="ef48" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">图形分类</strong> <br/>将图形本身分类成不同的类别。一个例子是通过观察一种化合物的图形结构来确定它是有毒的还是无毒的。</li><li id="67f2" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">社区检测<br/> </strong>将节点划分成簇。一个例子是在社交图中寻找不同的社区。</li><li id="d706" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">异常检测</strong> <br/>以无监督的方式发现图中的离群节点。如果您的目标上没有标签，可以使用这种方法。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/6075f4d4cbd5969259e398dfcab8336c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hWFvu0mjChQanfcs3lTiCA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GNN应用程序(图片由作者提供)</p></figure><p id="8a33" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博文中，我们将回顾节点分类、链接预测和异常检测的代码实现。</p><h1 id="4ceb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">图形卷积——直觉</h1><p id="03ef" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">图形神经网络在过去几年中发展迅速，已经发明了许多变体(更多细节，请参见<a class="ae kv" href="https://arxiv.org/pdf/1901.00596.pdf" rel="noopener ugc nofollow" target="_blank">本调查</a>)。在这些GNN变体中，<a class="ae kv" href="https://tkipf.github.io/graph-convolutional-networks/" rel="noopener ugc nofollow" target="_blank">图卷积网络</a>可能是最流行和最基本的算法。在本节中，我们将回顾其算法的高级介绍。</p><p id="c763" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">图卷积是基于图结构提取/总结节点信息的有效方法。它是卷积神经网络的卷积运算的变体，通常用于图像问题。</p><p id="93f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在图像中，像素在网格中按结构排序，卷积运算中的过滤器(权重矩阵)以预先确定的步长在图像上滑动。像素的相邻像素由过滤器大小决定(在下图中，过滤器大小为3 x 3，蓝色过滤器中的八个灰色像素是相邻像素)，过滤器中的加权像素值聚合为一个值。此卷积运算的输出比输入图像的大小小，但具有更高级别的输入视图，这对于预测图像问题(如图像分类)非常有用。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/9215e0c29fddd795d8991de0e5f95d65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s7OJUKOx9HKvV9i0Ijuk5Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="08c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在图中，节点以非结构化的方式排序，并且节点之间的邻域大小不同。图表卷积采用给定结点(下图中的红色结点)及其相邻结点(蓝色圆圈内的灰色结点)的结点要素的平均值来计算该结点的更新结点制图表达值。通过这种卷积运算，节点表示捕获了局部化的图形信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/dc25c0a6e0ed7f9a4187418a4937ee6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXnWRlyarRMmYOsKpP2JcQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="d750" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了图形卷积操作的更多细节。对邻近结点(蓝色)的结点要素和目标结点(红色)的结点要素进行平均。然后将其乘以权重向量(W ),其输出更新目标节点的节点特征(更新的节点值也称为节点嵌入)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/a51ba9404d1aedad2ac8cdf8345f7397.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gWHyvKqgs3HKXO4-_-NQmg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图形卷积运算(图片由作者提供)</p></figure><p id="f0c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nh">对感兴趣的人来说，利用度矩阵的逆矩阵将节点特征归一化后聚合在</em> <a class="ae kv" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nh">原论文</em> </a> <em class="nh">中，而不是简单的平均(论文中的方程(8))。</em></p><p id="7dea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在此卷积运算中需要注意的一点是，图形卷积的数量决定了将多少步以外的节点要素聚合到每个节点中。在下图中，第一个卷积将蓝色节点的要素聚合到橙色节点中，第二个卷积可以将绿色节点的要素合并到橙色节点中。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/55cbb922e331bf3d8c8b81b15b05ef7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_Q0WPceBBGf9-sQNL3fzQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">卷积的数量决定了节点要素聚合的程度(图片由作者提供)</p></figure><h1 id="b344" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">Cora —图表基准数据集</h1><p id="005f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在接下来的几节中，我们将回顾GCN代码的实现。在我们深入研究它们之前，让我们先熟悉一下我们将要使用的数据集。<a class="ae kv" href="https://paperswithcode.com/dataset/cora" rel="noopener ugc nofollow" target="_blank"> Cora数据集</a>是一个论文引用网络数据，包含2708篇科学出版物。图中的每个节点代表一个出版物，如果一篇论文引用了另一篇论文，则一对节点用一条边连接。</p><p id="88b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过这篇文章，我们使用<a class="ae kv" href="https://www.pyg.org/" rel="noopener ugc nofollow" target="_blank"> PyG (Pytorch Geometric) </a>来实现GCN，这是一个流行的GNN库。Cora数据集也可以使用PyG模块加载:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="7ceb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="nh">来源于Pytorch Geometric的Cora数据集最初来自于“</em> <a class="ae kv" href="https://doi.org/10.1023/A:1009953814988" rel="noopener ugc nofollow" target="_blank"> <em class="nh">用机器学习</em> </a> <em class="nh">”论文。</em></p><p id="9596" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">节点特征和边信息如下所示。节点特征是1433个单词向量，指示每个出版物中单词的不存在(0)或存在(1)。边用邻接表表示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/2bd5f8daa408316944d7eff039829854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oKAnr0QwYLytWJRgULhmzw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">节点特征和边列表(图片由作者提供)</p></figure><p id="6157" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个节点都有七个类中的一个，这将是我们的模型目标/标签。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/85a0186881eccf31cc91b9073689d5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLIbp973WgwrKlsiCiZ1hw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">班级分布(图片由作者提供)</p></figure><p id="7f4c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用<a class="ae kv" href="https://networkx.org/" rel="noopener ugc nofollow" target="_blank"> NetworkX </a>库可以可视化图形数据。节点颜色代表节点类。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/8e8e920c76f8983b51eaf792672739ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9iLMS7lBO5IOPfauL80zQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Cora数据集的可视化(图片由作者提供)</p></figure><h1 id="54f0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">节点分类</h1><p id="84c3" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">对于节点分类问题，我们使用PyG的<code class="fe no np nq nr b">RandomNodeSplit</code>模块将节点分为train、valid和test(我们替换了数据中的原始分割掩码，因为它的train集太小)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="7834" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，数据分割被写入图形对象的<code class="fe no np nq nr b">mask</code>属性(见下图),而不是分割图形本身。这些掩码用于训练损失计算和模型评估，而图卷积使用整个图数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/33237ac2240d4e4bd377fa5b132a9f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XBa0pAu3bvVwoAqZiTM0tQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图形对象具有遮罩属性(按作者分类的图像)</p></figure><h2 id="cd47" class="nt lt iq bd lu nu nv dn ly nw nx dp mc lf ny nz me lj oa ob mg ln oc od mi oe bi translated">节点分类的基线模型(MLP)</h2><p id="dc11" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在我们建立GCN之前，我们只使用节点特征来训练MLP(多层感知器，即前馈神经网络)以设置基线性能。该模型忽略了节点连接(或图结构),并试图仅使用单词向量对节点标签进行分类。模型类如下所示。它有两个隐藏层(<code class="fe no np nq nr b">Linear</code>)，带有ReLU激活，后跟一个输出层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="741d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用普通Pytorch培训/评估设置来定义培训和评估功能。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="87e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型的测试精度为<strong class="ky ir"> 73.2% </strong>。</p><h2 id="7335" class="nt lt iq bd lu nu nv dn ly nw nx dp mc lf ny nz me lj oa ob mg ln oc od mi oe bi translated">GCN论节点分类</h2><p id="fb5b" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">接下来，我们将训练GCN，并将它的表现与MLP进行比较。我们使用一个非常简单的模型，它有两个图形卷积层，并在它们之间重新激活。这种设置与<a class="ae kv" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">原GCN论文</a>(方程式9)相同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/ffcbef80afd9b5799526501631221b13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*muTtylabqtMei2KyGLkgcw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">GCN节点分类模型架构(图片由作者提供)</p></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="a316" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型的测试集精度为<strong class="ky ir"> 88.0% </strong>。我们从MLP获得了大约15%的准确性改进。</p><h1 id="ba07" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">链接预测</h1><p id="9912" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">链接预测比节点分类更棘手，因为我们需要一些调整来使用节点嵌入对边进行预测。预测步骤描述如下:</p><ol class=""><li id="def8" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr og mv mw mx bi translated">编码器通过用两个卷积层处理图形来创建节点嵌入。</li><li id="fd7b" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr og mv mw mx bi translated">我们在原图中随机添加负面链接。这使得模型任务具有来自原始边的正链接和来自添加边的负链接的二元分类。</li><li id="bf61" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr og mv mw mx bi translated">解码器使用节点嵌入对包括负链接的所有边进行链接预测(即二进制分类)。它根据每条边上的一对节点计算节点嵌入的点积。然后，它聚合嵌入维度上的值，并在每条边上创建一个代表边存在概率的值。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/48585f8c9f11f34f7dc1418e7fd84b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WrD_01r2H3hgkmaJe8SVFw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">链接预测模型架构(图片由作者提供)</p></figure><p id="f98d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型结构来自<a class="ae kv" href="https://github.com/tkipf/gae" rel="noopener ugc nofollow" target="_blank">变分图自动编码器</a>中的原始链接预测实现。代码如下所示。这改编自<a class="ae kv" href="https://github.com/pyg-team/pytorch_geometric/blob/master/examples/link_pred.py" rel="noopener ugc nofollow" target="_blank">PyG repo</a>中的代码示例，该示例基于图形自动编码器实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4412" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于此链接预测任务，我们希望将链接/边随机分为训练数据、有效数据和测试数据。我们可以使用PyG的<code class="fe no np nq nr b">RandomLinkSplit</code>模块来实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="ef3a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出数据如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/7f3585e07ef6a7a5695f10014500a1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxcMuU2N_rkJqDMhacFU2A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">随机链接拆分输出(图片由作者提供)</p></figure><p id="15dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于这个输出数据，有几点需要注意。</p><p id="c5ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，在<code class="fe no np nq nr b">edge_index</code>上执行分割，使得训练和验证分割不包括来自验证和测试分割的边(即，仅具有来自训练分割的边)，并且测试分割不包括来自测试分割的边。这是因为编码器使用<code class="fe no np nq nr b">edge_index</code>(和<code class="fe no np nq nr b">x</code>)来创建节点嵌入，这种设置确保了在对验证/测试数据进行预测时，节点嵌入上没有目标泄漏。</p><p id="f523" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第二，两个新属性(<code class="fe no np nq nr b">edge_label</code>和<code class="fe no np nq nr b">edge_label_index</code>)被添加到每个分割数据。它们是对应于每个分割的边标签和边索引。<code class="fe no np nq nr b">edge_label_index</code>将用于解码器进行预测，而<code class="fe no np nq nr b">edge_label</code>将用于模型评估。</p><p id="308f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第三，负链接被添加到<code class="fe no np nq nr b">val_data</code>和<code class="fe no np nq nr b">test_data</code>两者，其数量与正链接(<code class="fe no np nq nr b">neg_sampling_ratio=1.0</code>)相同。它们被添加到<code class="fe no np nq nr b">edge_label</code>和<code class="fe no np nq nr b">edge_label_index</code>属性中，但没有添加到<code class="fe no np nq nr b">edge_index</code>中，因为我们不想在编码器上使用负链接(或节点嵌入创建)。此外，我们不会在此向训练集添加负面链接(通过设置<code class="fe no np nq nr b">add_negative_train_samples=False</code>)，因为我们会在上述<code class="fe no np nq nr b">train_link_predictor</code>的训练循环中添加它们。训练期间的这种随机化被认为是使模型更健壮。</p><p id="498e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图总结了编码器和解码器如何执行边缘分割(每个阶段都使用彩色边缘)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/7e3972c6ebf0bf4a57bf3499720883c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DE-M3cTHQvkMWQgvK6hZ4A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">边缘分割总结(图片由作者提供)</p></figure><p id="1d07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们现在可以用下面的代码来训练和评估这个模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="9f73" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型的检验AUC为92.5%。</p><h1 id="ec6a" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">异常检测</h1><p id="c1f8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们再次使用Cora数据集进行异常检测任务，但它与上一个略有不同:异常值被合成注入。数据集有两种不同类型的异常值(异常值定义来自<a class="ae kv" href="https://arxiv.org/pdf/2206.10071.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>):</p><ul class=""><li id="a0ff" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><strong class="ky ir">结构异常值</strong> <br/>密集连接的节点与稀疏连接的常规节点形成对比</li><li id="3ee0" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><strong class="ky ir">上下文异常值</strong> <br/>属性与其相邻节点显著不同的节点</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/b7f5397e07e4a9de2c55fbfa126a4efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOn5df8tTtNl_OSHA5IsnQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">节点异常类型(来源:【https://arxiv.org/pdf/2206.10071.pdf】T21</p></figure><p id="3c1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个异常检测任务，我们使用的是<a class="ae kv" href="https://docs.pygod.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> PyGOD库</a>，这是一个构建在PyG之上的图形异常检测库。我们可以通过PyGOD模块加载异常值注入的Cora数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="4435" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码显示了异常值类型分布。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="acb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">输出:<code class="fe no np nq nr b">Counter({0: 2570, 1: 68, 2: 68, 3: 2})</code></p><p id="17dc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你对这些异常值是如何注入的感兴趣，你可以看看<a class="ae kv" href="https://docs.pygod.org/en/dev/pygod.generator.html" rel="noopener ugc nofollow" target="_blank">关于异常值生成器模块</a>的PyGOD文档，它解释了操作细节。请注意，标签<code class="fe no np nq nr b">y</code>将仅用于模型评估，而不用于训练标签，因为我们正在训练一个无监督的模型。</p><p id="8e23" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了检测这些异常值，我们正在训练来自本文<a class="ae kv" href="https://www.public.asu.edu/~kding9/pdf/SDM2019_Deep.pdf" rel="noopener ugc nofollow" target="_blank"/>的<code class="fe no np nq nr b">DOMINANT</code>(属性网络上的深度异常检测)模型。这是一个具有图形卷积层的自动编码网络，其重构误差将是节点异常分数。该模型按照以下步骤进行预测。</p><ol class=""><li id="4e30" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr og mv mw mx bi translated"><strong class="ky ir"> <em class="nh">属性化网络编码器</em> </strong>用创建节点嵌入的三个图卷积层处理输入图。</li><li id="05f4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr og mv mw mx bi translated"><strong class="ky ir"> <em class="nh">结构重构解码器</em> </strong>使用学习到的节点嵌入来重构原始图边(即邻接矩阵)。它从每个可能的节点对计算节点嵌入的点积，从而在每个节点对上创建指示边存在的概率分数。</li><li id="211b" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr og mv mw mx bi translated"><strong class="ky ir"> <em class="nh">属性重构解码器</em> </strong>使用获得的节点嵌入重构原始节点属性。它有一个图表卷积层来预测属性值。</li><li id="2033" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr og mv mw mx bi translated">在最后一步中，通过在每个节点上加权平均来组合来自上述两个解码器的重构误差，并且组合的误差将是最终的误差/损失。这些最终误差也是节点的异常分数。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/6ce4a25005dc7f480ecf662e5ca44c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Px0jqEizdvd_3ABhHiP84Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">主导模型架构(来源:<a class="ae kv" href="https://www.public.asu.edu/~kding9/pdf/SDM2019_Deep.pdf" rel="noopener ugc nofollow" target="_blank">属性网络上的深度异常检测</a></p></figure><p id="6e07" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">正如您在下面看到的，使用PyGOD可以很容易地实现<code class="fe no np nq nr b">DOMINANT</code>模型。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="dc8d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该模型的AUC为84.1%，而其平均精度为20.8%。这种差异很可能是由于目标不平衡造成的。由于这是一个无监督的模型，我们可能无法期待一个非常准确的模型，但你可以在原始论文中看到<a class="ae kv" href="https://www.public.asu.edu/~kding9/pdf/SDM2019_Deep.pdf" rel="noopener ugc nofollow" target="_blank">它仍然优于任何其他流行的异常检测算法。</a></p></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><p id="6ff8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章到此为止！</p><p id="de3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你感兴趣，完整的代码可以在下面的Google Colab和GitHub repo中找到。</p><div class="ot ou gp gr ov ow"><a href="https://colab.research.google.com/drive/1Ksca_p4XrZjeN0A6jT5aYN6ARvwFVSbY?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd ir gy z fp pb fr fs pc fu fw ip bi translated">谷歌联合实验室</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">用PyG实现GNN</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">colab.research.google.com</p></div></div><div class="pf l"><div class="pg l ph pi pj pf pk kp ow"/></div></div></a></div><div class="ot ou gp gr ov ow"><a href="https://github.com/tomonori-masui/graph-neural-networks/blob/main/gnn_pyg_implementations.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="ox ab fo"><div class="oy ab oz cl cj pa"><h2 class="bd ir gy z fp pb fr fs pc fu fw ip bi translated">gnn _ pyg _ implementations . ipynb at tomonori-masui/graph-neural-networks</h2><div class="pd l"><h3 class="bd b gy z fp pb fr fs pc fu fw dk translated">用PyG实现GNN</h3></div><div class="pe l"><p class="bd b dl z fp pb fr fs pc fu fw dk translated">github.com</p></div></div><div class="pf l"><div class="pl l ph pi pj pf pk kp ow"/></div></div></a></div><h1 id="358b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ul class=""><li id="2664" class="mp mq iq ky b kz mk lc ml lf pm lj pn ln po lr mu mv mw mx bi translated">Benjamin Sanchez-Lengeling等人，<a class="ae kv" href="https://distill.pub/2021/gnn-intro/" rel="noopener ugc nofollow" target="_blank">图形神经网络简介</a></li><li id="5452" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">Ameya Daigavane等人，<a class="ae kv" href="https://distill.pub/2021/understanding-gnns/" rel="noopener ugc nofollow" target="_blank">理解图上的卷积</a></li><li id="a484" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">弗朗切斯科·卡萨莱格诺，<a class="ae kv" rel="noopener" target="_blank" href="/graph-convolutional-networks-deep-99d7fee5706f">图卷积网络——图上的深度学习</a></li><li id="f84a" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">Thomas N. Kipf，Max Welling，<a class="ae kv" href="https://arxiv.org/pdf/1609.02907.pdf" rel="noopener ugc nofollow" target="_blank">图卷积网络的半监督分类</a> (2017)，ICLR，2017</li><li id="6378" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">Thomas N. Kipf，Max Welling，<a class="ae kv" href="https://arxiv.org/pdf/1611.07308.pdf" rel="noopener ugc nofollow" target="_blank">变分图自动编码器</a> (2016)</li><li id="6111" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">丁等人<strong class="ky ir">。</strong>，<a class="ae kv" href="https://www.public.asu.edu/~kding9/pdf/SDM2019_Deep.pdf" rel="noopener ugc nofollow" target="_blank">属性网络上的深度异常检测</a> (2019)</li><li id="412d" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">Kay Liu等，<a class="ae kv" href="https://arxiv.org/pdf/2206.10071.pdf" rel="noopener ugc nofollow" target="_blank">图的基准节点离群点检测</a> (2022)</li></ul></div></div>    
</body>
</html>