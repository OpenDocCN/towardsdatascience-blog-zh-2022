<html>
<head>
<title>Stop Using SMOTE to Treat Class Imbalance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">停止使用SMOTE来处理阶级不平衡</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stop-using-smote-to-treat-class-imbalance-take-this-intuitive-approach-instead-9cb822b8dc45#2022-04-02">https://towardsdatascience.com/stop-using-smote-to-treat-class-imbalance-take-this-intuitive-approach-instead-9cb822b8dc45#2022-04-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fc98" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">请采用这种直观的方法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6d18ce653746b367119156312f7b6ed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OleQ4OsGWfHCAf7k8mdIKg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">在freepik.com发现的rawpixel图像</p></figure><p id="b2e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在分类问题中，无论是二元分类还是多类分类，都会出现属于每一类的观测值数量不平衡的情况。类别不平衡的一个典型例子是欺诈性交易与非欺诈性交易，在这种情况下，我们整个数据集中的任何随机样本都会有更多的非欺诈性交易观察结果。另一个例子可以是在大公司工作的员工流失的数据集，其中离开公司的员工通常比在给定时间内留在公司的员工多。</p><p id="775d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设你计划建立一个机器学习模型来预测可能离开公司的员工。数据中的不平衡带来了挑战，因为大多数机器学习算法都是在假设每个类别中的观察值数量大致相等的情况下创建的。</p><p id="6ed0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">处理类不平衡的方法有很多，欠采样和SMOTE是最流行的。然而，这两种方法都不能达到高水平的召回，同时给流水线制造了过度的复杂性。</p><blockquote class="lu lv lw"><p id="59d4" class="ky kz lx la b lb lc ju ld le lf jx lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated">SMOTE和欠采样都无法达到高水平的召回率，同时给机器学习管道带来了过度的复杂性</p></blockquote><p id="a59d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文将向您展示一种比欠采样和SMOTE在不平衡数据上具有更好性能的直观方法。它还具有更低的复杂性，并且已经<strong class="la iu">内置到scikit-learn分类模型中</strong>。</p><h1 id="5e77" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">SMOTE复习工具</h1><p id="89b6" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">SMOTE代表2002年推出的“合成少数过采样技术”。顾名思义，它通过创建合成数据点来增加少数类中的观察数量，从而平衡数据。</p><p id="8d90" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">作为第一步，SMOTE使用k-最近邻方法来识别特征空间中彼此接近的数据点。然后，它会在数据点之间投射线条，并沿着这些线条创建虚假的观察。听起来很公平，对吧？让我们看看它对数据做了什么。</p><p id="7e99" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">这是他们告诉你的击打方式:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi my"><img src="../Images/7441a2802615ba0abfaef1710c0c6a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyJIwMvEKFYU65PU2o8ubg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">你在网上订购的东西(图片由作者提供)</p></figure><p id="314f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">这是SMOTE实际做的:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mz"><img src="../Images/b66ef67c32af4ed59163c67e29d1fc1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aK5mGlrUQq6jjEKjMUts1g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">你收到的邮件(图片由作者提供)</p></figure><p id="5fa8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如你所见，SMOTE没有填充红点所占据的区域。它只是在少数阶级中产生了一种不寻常的模式，现在我们的模式必须借鉴。</p><h1 id="5914" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">欠采样刷新程序</h1><p id="3064" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">欠采样背后的想法很简单:从多数类中消除观测值，直到你的类具有相同数量的观测值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi na"><img src="../Images/e085308eb1ca90e752a63a97327ee945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZiT4upPHUG5uQjwIaNJfA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">随机欠采样的工作原理(图片由作者提供)</p></figure><h1 id="e3cd" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">类别权重</h1><p id="51d2" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">scikit-learn和神经网络中的所有分类模型都有一个超参数，称为类权重。这个超参数被设计来控制精确度和召回率之间的权衡，换句话说，这与处理类别不平衡是一样的。</p><p id="75f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其思想是给每个类分配权重，使得所有类的观察值的加权和相等。对于两个类别，其中n是观察次数，w是权重:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nb"><img src="../Images/cc826968163f31ca08685def8610f661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8jOoFo1oYPMBfqGNrADMfw.png"/></div></div></figure><p id="b271" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">自然，少数阶级的权重会高于多数阶级的权重。机器学习模型在训练时，更关注权重较高的观测值。通过这样选择权重，我们将补偿少数群体中较少的观察值。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nc"><img src="../Images/ce907bde94fc80c0f9ce7cf875fb8e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DoyuNYz_5Xpges3BqVGZFg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">类别权重如何工作(图片由作者提供)</p></figure><h1 id="8b44" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">哪种方法比较好？</h1><p id="7def" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">让我们来看看这三者的作用。在案例研究中，我们将回顾一个Kaggle数据集，其中包含可能正在寻找工作变动的个人。我们的目标是利用这些数据，识别那些对新的定向招聘机会持开放态度的人。这是数据和它的许可证信息:<a class="ae nd" href="https://creativecommons.org/publicdomain/zero/1.0/" rel="noopener ugc nofollow" target="_blank">https://creativecommons.org/publicdomain/zero/1.0/</a></p><div class="ne nf gp gr ng nh"><a href="https://www.kaggle.com/datasets/kukuroo3/hr-data-predict-change-jobscompetition-form" rel="noopener  ugc nofollow" target="_blank"><div class="ni ab fo"><div class="nj ab nk cl cj nl"><h2 class="bd iu gy z fp nm fr fs nn fu fw is bi translated">人力资源数据，预测变动工作(竞争表格)</h2><div class="no l"><h3 class="bd b gy z fp nm fr fs nn fu fw dk translated">分类问题</h3></div><div class="np l"><p class="bd b dl z fp nm fr fs nn fu fw dk translated">www.kaggle.com</p></div></div><div class="nq l"><div class="nr l ns nt nu nq nv ks nh"/></div></div></a></div><p id="0ff1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">数据预处理和特征工程步骤不在本文的讨论范围内，所以让我们看一下图表:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/dcc64e3b69f34ce2247f69af664b18f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*ZSnmwaR9j1y76B5eV5xr2w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据中大约1:3的阶级不平衡(图片由作者提供)</p></figure><p id="a063" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们用四种不同的策略来比较。首先，我们训练一个随机森林模型，就好像我们不在乎不平衡一样。</p><p id="bbf0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其次，我们使用SMOTE进行过采样:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="aed5" class="oc mc it ny b gy od oe l of og">sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=7)<br/>X_train_over, y_train_over = sm.fit_resample(X_train, y_train)</span></pre><p id="d877" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后欠采样:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="1c75" class="oc mc it ny b gy od oe l of og">rus = RandomUnderSampler(random_state=1)<br/>X_train_un, y_train_un = rus.fit_resample(X_train, y_train)</span></pre><p id="6c05" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后但同样重要的是，类权重:</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="50f9" class="oc mc it ny b gy od oe l of og">count_class_1 = y_train.value_counts()[0]<br/>count_class_2 = y_train.value_counts()[1]<br/>ratio = count_class_1/count_class_2<br/>rf_estimator = RandomForestClassifier(class_weight={1:ratio, 0:1})</span></pre><p id="a990" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">以下是每种策略的召回指标:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/910f98734ed41d6b8abf38934553d905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fC0jrqucHisZmsunE8Im8Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="41dc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你所看到的，调整类权重导致了最好的回忆。然而，我们知道高召回率可以简单地通过牺牲精确度来实现。因此，让我们绘制精度和F1分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oi"><img src="../Images/fb3e48905eff718afb9ed5efef930cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mwhnDc0rc9uMLThZPoSHTA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">类权重具有最好的f1分数和相似的精度(图片由作者提供)</p></figure><p id="cc8e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如您所观察到的，在类不平衡方面，类权重比其他方法表现得更好。</p><h1 id="ffa6" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">如果失衡更严重呢？</h1><p id="f8c1" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">我相信你们中的许多人都想知道不平衡更严重的情况，我们有80/20或90/10的分裂。为了测试这些策略在不同不平衡水平下的性能，我编写了一个函数，在for循环中随机消除少数类中的一些数据点，并重复建模过程，记录每种方法的性能。</p><pre class="kj kk kl km gt nx ny nz oa aw ob bi"><span id="a481" class="oc mc it ny b gy od oe l of og">for i in range(11):<br/>    to_drop = df[df['target']==1].sample(400).index.values<br/>    df = df.drop(to_drop)<br/>    X = df.drop(["target"], axis=1)<br/>    y = df["target"]<br/>    train_all_strategies(X, y, 'smote', 'undersampling', 'class_weights')</span></pre><p id="6a9e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">还有一个超参数调整步骤，以确保每种方法返回最佳结果。下面我们绘制了每次迭代的回忆分数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/96232e81b2b93c026acf8db151c50042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*stoc7TtUenOuwAehPP91jg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">我们今天看到的最重要的情节(图片由作者提供)</p></figure><p id="4272" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">情节的主要要点:</p><p id="be2c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 1-当使用更新的类别权重处理类别不平衡时，模型的性能始终很高</strong></p><p id="faf3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 2-模型的性能随着平滑和欠采样而逐渐下降</strong></p><p id="8ef9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 3-当整个数据集由一个类别组成时，所有策略的召回率都降至零(非常明显)</strong></p><h1 id="5d2e" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">摘要</h1><p id="6ee7" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">在本文中，我们讨论了SMOTE、随机欠采样和类权重来处理分类的类不平衡。在一个案例研究中，我们展示了仔细选择类权重是如何产生最佳建模性能的。我们还证明了这种方法在从25/75一直到1/99的不同等级的不平衡中保持其优越性。</p><p id="a78b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种方法的另一个优点是简单；同时，SMOTE需要大量的时间来运行，并且类权重不会增加机器学习流水线的时间复杂度。</p><p id="432e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请务必关注更多内容！</p></div></div>    
</body>
</html>