<html>
<head>
<title>An Introduction to Preprocessing Data for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习的数据预处理导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-preprocessing-data-for-machine-learning-8325427f07ab#2022-08-30">https://towardsdatascience.com/an-introduction-to-preprocessing-data-for-machine-learning-8325427f07ab#2022-08-30</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><div class=""><h2 id="3844" class="pw-subtitle-paragraph jr it iu bd b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki dk translated">了解如何以及何时应用常见的预处理技术</h2></div><figure class="kk kl km kn gu ko gi gj paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="gi gj kj"><img src="../Images/7213789c388b2d010dcfb7374b01b5da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aKMdyIgjtThqmeEIE-q4nQ.jpeg"/></div></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">马库斯·克里斯蒂亚在<a class="ae kz" href="https://unsplash.com/s/photos/numbers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="144c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">机器学习算法学习存在于一组特征中的模式，并使用这些模式来预测新的未知数据的给定目标变量。得到的训练模型本质上是一个数学函数，它成功地将X(特征)的值映射到y(目标)的未知值。</p><p id="3837" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">与所有数学计算一样，机器学习算法只能处理用数字表示的数据。此外，由于每个算法都在各种不同的约束和假设下工作，因此以反映算法如何理解数据的方式来表示这些数字非常重要。</p><p id="2aec" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">假设我们有一个用红色、蓝色和灰色来表示汽车颜色的特征。如果我们将每种颜色表示为一个数字，比如红色= 1、蓝色= 2或灰色= 3，机器学习算法在不理解颜色概念的情况下，可能会将红色解释为更重要，因为它由最大的数字表示。</p><p id="5850" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在机器学习术语中，预处理是指将原始特征转换为机器学习算法可以理解和学习的数据。</p><p id="5994" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如图所示，为机器学习预处理数据是一种艺术形式，需要仔细考虑原始数据，以便选择正确的策略和预处理技术。</p><p id="1f36" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在下面的教程中，我将主要使用<a class="ae kz" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>库，用代码示例介绍常见的预处理步骤。本文并不打算详尽地概述所有可用的预处理方法，而是旨在提供最常用策略的良好基础知识。如果您对本文感兴趣的话，我在文章末尾提供了一些链接，以便更深入地研究预处理。</p></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="9eca" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">安装</h1><p id="bfeb" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">出于本教程的目的，我将使用来自<a class="ae kz" href="https://www.openml.org/search?type=data&amp;sort=runs&amp;id=9&amp;status=active" rel="noopener ugc nofollow" target="_blank">openml.org</a>的“汽车”数据集。该数据集由许多与汽车特征相关的特征和代表其相关保险风险的分类目标变量组成。也可以下载数据集，并使用下面的代码将其转换成熊猫数据帧。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="047d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在开始预处理之前，理解每一列的数据类型是很重要的。如果我们运行<code class="fe nc nd ne nf b">df.dtypes</code>，我们可以看到数据集混合了分类和数字数据类型。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj ng"><img src="../Images/f0b1df58a3645a79f6b41c6a6b2f29e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*d3zbSlPQt9dcYQD6VPkr0A.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">汽车数据集的数据类型。作者图片</p></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="354a" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">编码分类特征</h1><p id="5273" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">正如文章开头提到的，机器学习算法需要数字数据。因此，在用于模型训练之前，任何分类特征必须首先被转换成数字特征。</p><p id="81b9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">用于处理分类变量的最常见的技术是一种热编码，有时也称为虚拟编码。该技术为要素中包含的每个唯一值创建一个新列。新列是二进制要素，如果值不存在，则包含0，如果存在，则包含1。</p><p id="621a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Scikit-learn库提供了一种预处理方法，可以执行一次热编码。以下代码将数据集中的分类特征转换为一个热编码列。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="dbdd" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当使用这种方法转换分类列时，必须特别注意特性的基数。</p><p id="1891" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">基数是指给定列中唯一值的数量。例如，如果我们有一个包含50个唯一值的特性。执行一次热编码将导致创建50列。</p><p id="5c29" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">这可能导致两个问题:</p><ol class=""><li id="1648" class="nh ni iu lc b ld le lg lh lj nj ln nk lr nl lv nm nn no np bi translated">非常大的训练集导致训练时间明显变长。</li><li id="ab64" class="nh ni iu lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated">稀疏的训练集会导致过度拟合的问题。</li></ol><p id="047f" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们可以通过运行下面的<code class="fe nc nd ne nf b">df[categorical_cols].nunique()</code>来了解数据集中的特征基数。</p><p id="ef54" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">我们可以看到make列具有相当高的基数。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nv"><img src="../Images/42c5ea1058cecf00cc9aa467f43bc154.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*wXL6OUAkdrsvshkw6RFYUg.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">分类特征的基数。作者图片</p></figure><p id="d10a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">处理高基数类别的一种方法是将不常出现的值聚集到一个新的类别中。<code class="fe nc nd ne nf b">OneHotEncoder</code>方法为此提供了两种选择。</p><p id="74ac" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">第一个选项是将<code class="fe nc nd ne nf b">min_frequency</code>参数设置为一个选定的数字。这将导致频率小于该值的任何值被添加到不频繁类别中。</p><p id="4417" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated"><em class="nw">请注意，该选项目前仅适用于Scikit-learn 1 . 1 . 0及以上版本。</em></p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="5722" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">第二个选项是将<code class="fe nc nd ne nf b">max_categories</code>参数设置为任何大于1的数字。这将生成的列数限制在该数量或更少。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="a388" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">输入缺失值</h1><p id="4116" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">大多数真实世界的数据集都会有一些缺失值。这可能有多种原因。生成数据的系统可能出现错误，导致观察值缺失，或者某个值可能因为与特定样本无关而缺失。</p><p id="b95d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">无论什么原因，大多数机器学习算法都不能解释空值，因此，有必要以某种方式处理这些值。</p><p id="a336" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一种选择是删除包含缺失值的行。但是，这通常是不实际的，因为它会将训练数据集的大小减少太多，或者算法的应用可能需要为所有行生成预测。</p><p id="7e60" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">如果无法删除丢失的值，则有必要用一个合理的值来替换它们。这是一种被称为插补的技术。</p><p id="f56a" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">有许多策略可以用来计算缺失值。从用特征的中值、平均值或最频繁值替换缺失值的非常简单的选项。到使用机器学习算法来确定插补的最佳值的更复杂的情况。</p><p id="7a49" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在选择策略之前，我们首先需要了解我们的数据集是否有任何缺失值。为此，请运行以下命令。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="3ad5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">从结果中我们可以看到，5个特征有缺失值，除了“归一化损失”列，所有特征的缺失值百分比都很低(低于2%)。</p><figure class="kk kl km kn gu ko gi gj paragraph-image"><div class="gi gj nx"><img src="../Images/ae36643bca322afc5dd74c73803bc7a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*ztcGEPmr5lGTpycAdZmSqQ.png"/></div><p class="kv kw gk gi gj kx ky bd b be z dk translated">缺失值的百分比。图片作者。</p></figure><p id="f421" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">通常，我们会对每个特征进行一些探索性分析，以便为插补策略的选择提供信息。然而，出于本教程的目的，我将简单地展示一个使用简单策略和一个更复杂策略的例子。</p><p id="608c" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">下面显示的代码使用了Scikit-learn <a class="ae kz" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">方法</a>，称为<code class="fe nc nd ne nf b">SimpleImputer</code>。由于我们混合了带有缺失值的分类和数字特征，我们将使用两种不同的简单策略来估算它们。对于数字特征，我们将用该列的平均值替换缺失值，对于分类特征，我们将使用最常出现的值。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="48d8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">当数据用于训练时，简单地用简单的统计(如平均值)填充所有缺失值可能不会产生最佳性能。一种更复杂的插补方法是使用机器学习算法来告知要插补的值。</p><p id="8eee" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一种常用的技术是<a class="ae kz" rel="noopener" target="_blank" href="/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761">K-最近邻</a>算法。该模型使用距离度量，如欧几里德距离，来确定一组指定的最近邻，并估算这些邻的平均值。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="8efc" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">特征缩放</h1><p id="8c1d" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">训练集中的数字特征通常具有非常不同的比例。例如，特性“价格”的最小值为5，118。而“压缩比”的最小值仅为7，最大值为23。机器学习模型可能会错误地将“价格”特征中的较大值解释为比“压缩比”特征中的值更重要。</p><p id="9608" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">与缩放相关的另一个预处理步骤是在变换要素的位置居中，以便它们形成正态分布。许多机器学习算法假设特征是正态分布的，除非以这种方式表示特征，否则它们不会如预期那样表现。</p><p id="506d" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Scikit-learn <code class="fe nc nd ne nf b">StandardScaler</code>方法通过移除平均值并将每个特征缩放至单位方差来执行居中和缩放。下面的代码执行这些步骤。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="2902" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">扔掉</h1><p id="63d4" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">宁滨或离散化是一种用于将连续变量转换成相似值的组或桶的技术。当一个变量有大量不经常出现的值时，这种技术特别有用。在这种情况下，离散化可以减少特征中的噪声，并减少训练期间模型过拟合的风险。</p><p id="3721" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在我们的数据集中，价格变量的取值范围非常大。最频繁出现的价格只有2次。这是一个特别受益于宁滨的特征的例子。</p><p id="ceb5" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一旦执行了离散化，该特征就必须被视为分类的，因此必须执行额外的预处理步骤，例如一个热编码。</p><p id="19c0" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Scikit-learn库有一个名为<code class="fe nc nd ne nf b">KBinsDiscretizer</code>的方法，它在一个步骤中执行宁滨和分类编码。以下代码将价格功能转换为6个箱，然后对新的分类变量执行一次热编码。结果是一个稀疏矩阵。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><h1 id="7d4a" class="md me iu bd mf mg mh mi mj mk ml mm mn ka mo kb mp kd mq ke mr kg ms kh mt mu bi translated">把所有的放在一起</h1><p id="5de8" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated">到目前为止，在本教程中，我们已经独立执行了所有预处理步骤。在真正的机器学习应用中，我们总是需要对训练集和任何测试或验证数据集进行预处理，然后在对新数据进行推断的过程中再次应用这些预处理。因此，编写能够一步完成所有这些转换的代码是最有效的。</p><p id="1850" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">Scikit-learn有一个被称为<a class="ae kz" href="https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf" rel="noopener">管道</a>的有用工具。Scikit-learn管道使预处理步骤能够与估计器链接在一起。下面的代码创建了一个管道，该管道执行本教程中概述的所有预处理步骤，并且还适合随机森林分类器。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure><p id="95c8" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">可以重用管道来预处理测试数据集并生成预测，如下所示。</p><figure class="kk kl km kn gu ko"><div class="bz fq l di"><div class="na nb l"/></div></figure></div><div class="ab cl lw lx hy ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="in io ip iq ir"><p id="83e4" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">机器学习算法的学习方式与人类不同。一个算法不可能像你和我一样理解车门数量和汽车之间的关系。为了让机器学习，必须将数据转换为适合算法学习方式的表示形式。</p><p id="1efe" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">在本文中，我们介绍了以下预处理技术。下面是对这些方法的简要总结以及它们有用的原因。</p><ol class=""><li id="78f4" class="nh ni iu lc b ld le lg lh lj nj ln nk lr nl lv nm nn no np bi translated"><strong class="lc iv">编码分类特征:</strong>大多数机器学习算法只能处理数字数据，因此分类变量必须转换为数字表示。</li><li id="6e09" class="nh ni iu lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><strong class="lc iv">输入缺失值:</strong>大多数机器学习算法无法解释空值。输入用合理的替换来替换丢失的值。</li><li id="9a93" class="nh ni iu lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><strong class="lc iv">特征缩放:</strong>机器学习算法只理解数值关系。因此，不同比例的要素可能会被错误地解释。缩放可确保连续要素中的值都在相同的比例上。</li><li id="7bbf" class="nh ni iu lc b ld nq lg nr lj ns ln nt lr nu lv nm nn no np bi translated"><strong class="lc iv">宁滨:</strong>具有许多不经常出现的值的连续变量可能包含大量噪声，这可能导致训练期间的过拟合。宁滨将这些值聚集成桶或相似值的组，从而产生新的分类特征。</li></ol><p id="0c98" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">本教程给出了应用于机器学习数据的最常见预处理技术的介绍性概述。这里描述的方法有许多不同的选项，还有更多可能的预处理步骤。</p><p id="caba" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">一旦你对所描述的技术有了全面的了解，如果你想更深入地研究更多的技术,《用Scikit-learn和Tensorflow进行机器学习》这本书是一个很好的资源。这本书可以通过这个<a class="ae kz" href="https://www.knowledgeisle.com/wp-content/uploads/2019/12/2-Aurélien-Géron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-O’Reilly-Media-2019.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>获得免费阅读的PDF格式。</p><p id="d4f9" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">关于Scikit-learn的更多文章，请参见我之前的帖子。</p><div class="ny nz gq gs oa ob"><a rel="noopener follow" target="_blank" href="/a-beginners-guide-to-scikit-learn-14b7e51d71a4"><div class="oc ab fp"><div class="od ab oe cl cj of"><h2 class="bd iv gz z fq og fs ft oh fv fx it bi translated">Scikit初学者指南-学习</h2><div class="oi l"><h3 class="bd b gz z fq og fs ft oh fv fx dk translated">开始使用排名第一的python机器学习库</h3></div><div class="oj l"><p class="bd b dl z fq og fs ft oh fv fx dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="ol l om on oo ok op kt ob"/></div></div></a></div><div class="ny nz gq gs oa ob"><a rel="noopener follow" target="_blank" href="/10-things-you-didnt-know-about-scikit-learn-cccc94c50e4f"><div class="oc ab fp"><div class="od ab oe cl cj of"><h2 class="bd iv gz z fq og fs ft oh fv fx it bi translated">关于Scikit你不知道的10件事-了解</h2><div class="oi l"><h3 class="bd b gz z fq og fs ft oh fv fx dk translated">…直到现在</h3></div><div class="oj l"><p class="bd b dl z fq og fs ft oh fv fx dk translated">towardsdatascience.com</p></div></div><div class="ok l"><div class="oq l om on oo ok op kt ob"/></div></div></a></div><p id="bc97" class="pw-post-body-paragraph la lb iu lc b ld le jv lf lg lh jy li lj lk ll lm ln lo lp lq lr ls lt lu lv in bi translated">感谢阅读！</p><h2 id="6944" class="or me iu bd mf os ot dn mj ou ov dp mn lj ow ox mp ln oy oz mr lr pa pb mt pc bi translated">引用</h2><p id="a366" class="pw-post-body-paragraph la lb iu lc b ld mv jv lf lg mw jy li lj mx ll lm ln my lp lq lr mz lt lu lv in bi translated"><strong class="lc iv"> <em class="nw"> Autos数据集:</em> </strong> <em class="nw"> Jeffrey，C. Schlimmer。https://archive.ics.uci.edu/ml/datasets/Automobile网络数据仓库[</em><a class="ae kz" href="https://archive.ics.uci.edu/ml/datasets/Automobile" rel="noopener ugc nofollow" target="_blank"><em class="nw"/></a><em class="nw">]。在开放科学许可证下使用。</em></p></div></div>    
</body>
</html>