<html>
<head>
<title>Implementing Deep Convolutional GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实施深度卷积GAN</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-deep-convolutional-gan-f76e9b9af270#2022-08-26">https://towardsdatascience.com/implementing-deep-convolutional-gan-f76e9b9af270#2022-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/3ef05fb40f06940bc4b2617451faaa62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1iU8iKDFc8LlRTDdxpJ9Q.jpeg"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">文森特·梵高的《红色葡萄园》</p></figure><p id="357b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">据<a class="ae kc" href="https://www.nytimes.com/2012/09/23/technology/data-centers-waste-vast-amounts-of-energy-belying-industry-image.html" rel="noopener ugc nofollow" target="_blank">纽约时报</a>报道，数据中心使用的能源有90%被浪费了，这是因为公司收集的大部分数据从来没有以任何形式被分析或使用，这更具体地被称为<strong class="kf ir">黑暗数据。</strong></p><blockquote class="lb lc ld"><p id="49c4" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">暗数据是通过各种计算机网络操作获取的数据，但不以任何方式用于获取见解或制定决策。一个组织收集数据的能力可能会超过其分析数据的能力。在某些情况下，组织可能甚至没有意识到数据正在被收集。IBM估计，大约90%由传感器和模数转换产生的数据从未被使用过。— <strong class="kf ir">维基百科上的黑暗数据定义</strong></p></blockquote><p id="6b2c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从机器学习的角度来看，这些数据对于获得任何见解都没有用的一个关键原因是缺乏标签。这使得无监督学习算法非常有吸引力，可以释放这些数据的潜力。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="9c34" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">生成对抗网络</h1><p id="e1a5" class="pw-post-body-paragraph kd ke iq kf b kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">2014年，Ian Goodfellow等人提出了一种通过对抗过程来估计生成模型的新方法。它涉及同时训练两个独立的模型，一个生成器模型试图对数据分布进行建模，一个鉴别器试图通过生成器将输入分类为训练数据或虚假数据。</p><p id="5138" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇论文在现代机器学习领域树立了一个非常重要的里程碑，为无监督学习开辟了新的途径。深度卷积GAN <a class="ae kc" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">论文</a>(拉德福德等人2015)通过应用卷积网络的原理成功产生2D图像，继续构建这一思想。</p><p id="ea42" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过这篇文章，我试图解释本文中的关键组件，并使用PyTorch实现它们。</p><h2 id="2fd6" class="ms lq iq bd lr mt mu dn lv mv mw dp lz ko mx my md ks mz na mh kw nb nc ml nd bi translated">甘有什么了不起的地方？</h2><p id="f937" class="pw-post-body-paragraph kd ke iq kf b kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">为了理解GAN或DCGAN的重要性，让我们看看是什么让它们如此受欢迎。</p><ol class=""><li id="97ae" class="ne nf iq kf b kg kh kk kl ko ng ks nh kw ni la nj nk nl nm bi translated">由于大部分真实世界的数据是未标记的，GANs的无监督学习特性使它们成为这种用例的理想选择。</li><li id="078d" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">生成器和鉴别器对于具有有限标记数据的用例来说是非常好的特征提取器，或者生成额外的数据来改善次级模型训练，因为它们可以生成假样本而不是使用增强。</li><li id="975e" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">GANs提供了最大似然技术的替代方案。它们的对抗性学习过程和非启发式成本函数使它们对强化学习非常有吸引力。</li><li id="2f79" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">围绕GAN的研究非常有吸引力，其结果也是关于ML/DL影响的广泛辩论的来源。例如，Deepfake是GAN的应用之一，它可以将人的面部覆盖在目标人物上，这在本质上一直是非常有争议的，因为它有可能被用于邪恶的目的。</li><li id="5439" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">最后但也是最重要的一点是，与它一起工作很酷，该领域的所有新研究都令人着迷。</li></ol></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="01ad" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">体系结构</h1><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/f7ac483e6ceb8a6605c1519e28d8b78f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nP-etcj_wYCsjDexaFBaQw.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">深度卷积GAN的架构(图片由作者提供)</p></figure><p id="510e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们之前所讨论的，我们将通过DCGAN来实现GAN的核心思想，用于能够生成逼真图像的卷积网络。</p><p id="1797" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">DCGAN由两个独立的模型组成，一个是生成器(G ),它试图模拟随机噪声向量作为输入，并试图学习数据分布以生成伪样本，另一个是鉴别器(D ),它获取训练数据(真实样本)和生成的数据(伪样本),并试图对它们进行分类，这两个模型之间的斗争就是我们所说的对抗性训练过程，其中一个人的损失是另一个人的利益。</p><h2 id="7173" class="ms lq iq bd lr mt mu dn lv mv mw dp lz ko mx my md ks mz na mh kw nb nc ml nd bi translated">发电机</h2><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/dd39427fc444c0137c1663c62ca3f653.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*RX_YoiZCYm_mloDGhMEwGQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">生成器图(图片由作者提供)</p></figure><p id="7ba1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成器是我们最感兴趣的一个，因为它是一个生成假图像来试图欺骗鉴别器的生成器。</p><p id="a338" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们更详细地看看生成器架构。</p><ol class=""><li id="9153" class="ne nf iq kf b kg kh kk kl ko ng ks nh kw ni la nj nk nl nm bi translated"><strong class="kf ir">线性层:</strong>噪声向量被送入一个全连接层，其输出被整形为4D张量。</li><li id="20c7" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">批量标准化层:</strong>通过将输入标准化为零均值和单位方差来稳定学习，这避免了像消失或爆炸梯度这样的训练问题，并允许梯度在网络中流动。</li><li id="cee6" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">上采样层:</strong>根据我对这篇论文的理解，它提到了使用上采样，然后在其上应用一个简单的卷积层，而不是使用卷积转置层来上采样。但我见过有人用卷积转置，你自己决定吧。</li><li id="3f20" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir"> 2D卷积层:</strong>当我们对矩阵进行上采样时，我们让它通过一个步长为1且填充相同的卷积层，以允许它从上采样数据中学习</li><li id="b7c0" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir"> ReLU Layer: </strong>论文提到使用ReLU代替LeakyReLU用于生成器，因为它允许模型快速饱和并覆盖训练分布的颜色空间。</li><li id="30f0" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir"> TanH激活:</strong>论文建议我们对发电机输出使用TanH激活函数，但没有详细说明原因，如果我们不得不猜测这是因为TanH的性质允许模型更快地收敛。</li></ol><p id="2932" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第2层至第5层构成核心生成器模块，可重复N次以获得所需的输出图像形状。</p><p id="32ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里是我们如何在PyTorch中实现它。</p><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/6c9e72dfce835097ed4b0cc6ff19874e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*dKe3XXxcYDu1IcV4HyEu-A.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">用PyTorch实现的生成器。(作者代码)</p></figure><h2 id="ed8b" class="ms lq iq bd lr mt mu dn lv mv mw dp lz ko mx my md ks mz na mh kw nb nc ml nd bi translated">鉴别器</h2><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/f5bd938118f1097eb8dddc15071c9cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*8cVr2suFmO4sHiszctBJLA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">鉴别器图(图片由作者提供)</p></figure><p id="190f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，鉴别器更像是一个图像分类网络，只做了一些小的调整，例如，它不使用任何池层来进行下采样，而是使用步长卷积层来学习自己的下采样。</p><p id="fab9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们更详细地看看鉴别器架构。</p><ol class=""><li id="6ef8" class="ne nf iq kf b kg kh kk kl ko ng ks nh kw ni la nj nk nl nm bi translated"><strong class="kf ir">串联层:</strong>该层将假图像和真实图像组合在一批中，以馈入鉴别器，但这也可以单独进行，仅用于获取发电机损耗。</li><li id="4b57" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">卷积层:</strong>我们在这里使用步幅卷积，它允许我们对图像进行下采样，并在一次通过中学习过滤器。</li><li id="0b0f" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir"> LeakyReLU: </strong>正如论文提到的，与原始GAN论文的max-out函数相比，它发现LeakyReLU对鉴别器有用，因为它允许更容易的训练。</li><li id="35ec" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">退出:</strong>仅用于训练，有助于避免过度适应。该模型具有记忆真实图像数据的趋势，并且训练可能在该点崩溃，因为鉴别器不能再被生成器愚弄</li><li id="f63f" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">批量规范化:</strong>文中提到在除第一个鉴别器块之外的每个鉴别器块的末尾应用批量规范化。文中提到的原因是在每一层上应用批量归一化会导致样本振荡和模型不稳定。</li><li id="e0bd" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">线性:</strong>一个完全连接的图层，它从应用的2D批处理规范化图层中提取一个整形后的矢量。</li><li id="d7b7" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir"> Sigmoid激活:</strong>当我们处理鉴别器输出的二进制分类时，进行Sigmoid层逻辑选择。</li></ol><p id="c3ff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第2层到第5层构成了核心鉴别器块，它可以重复N次，以使每个训练数据的模型更加复杂。</p><p id="56f8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的是我们如何在PyTorch中实现它。</p><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/280f0a8f60d2855371ce361f51e5cbe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tToFmOaLHLSnBXSSDcDVsA.png"/></div></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">用PyTorch实现的鉴别器(代码由作者编写)</p></figure></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="f26f" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">对抗训练</h1><p id="6aec" class="pw-post-body-paragraph kd ke iq kf b kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">我们训练鉴别器(D)以最大化将正确标签分配给训练样本和来自生成器(G)的样本的概率，这可以通过最小化log(D(x))来完成。我们同时训练G使log(1D(G(z))最小，其中z是噪声矢量。换句话说，D和G用价值函数V (G，D)玩以下两人极大极小游戏:</p><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/040997d6495c02f607b5843e1a05bd25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*JYcjHBTw2nwyyYKCVc8p8g.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">对抗成本函数(<a class="ae kc" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><blockquote class="lb lc ld"><p id="c0d1" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">实际上，上述等式可能无法为G提供足够的梯度来学好。在学习早期，当G很差时，D可以以很高的置信度拒绝样本，因为它们与训练数据明显不同。这种情况下，log(1D(G(z))会饱和。我们可以训练G使logD(G(z))最大化，而不是训练G使log D(G(z))最小化。这个目标函数导致G和D的动态的相同的固定点，但是在学习的早期提供更强的梯度。——<a class="ae kc" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><p id="f7c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们同时训练两个模型，这可能会很棘手，而GANs是出了名的难以训练，我们稍后将讨论的一个已知问题称为模式崩溃。</p><p id="29ac" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">论文建议使用学习率为0.0002的Adam优化器，如此低的学习率表明GANs往往很快发散。它还使用值为0.5和0.999的一阶和二阶动量来进一步加速训练。该模型初始化为具有零均值和0.02标准差的正态权重分布。</p><p id="fb87" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://github.com/akash-agni/ReadThePaper/blob/main/DCGAN/dcgan.py" rel="noopener ugc nofollow" target="_blank">这里</a>是我们如何为此实现一个训练循环。</p><figure class="nt nu nv nw gt jr gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/6d3fe85c75df73e5cb80ce78b6f382c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*pcSnCUAbNK7pxozQ090kGQ.png"/></div><p class="jy jz gj gh gi ka kb bd b be z dk translated">DCGAN的训练循环(由作者编写代码)</p></figure><h2 id="9f1b" class="ms lq iq bd lr mt mu dn lv mv mw dp lz ko mx my md ks mz na mh kw nb nc ml nd bi translated">模式崩溃</h2><p id="b528" class="pw-post-body-paragraph kd ke iq kf b kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">理想情况下，我们希望我们的生成器生成各种各样的输出，例如，如果它生成一张脸，它应该为每个随机输入生成一个新的脸。但是，如果发生器产生一个看似合理的输出，足以骗过鉴别器，它可能会一次又一次地产生相同的输出。</p><p id="0b1a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终，发生器对单个鉴别器过度优化，并在一小组输出之间旋转，这种情况称为模式崩溃。</p><p id="69ea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下方法可用于补救这种情况。</p><ol class=""><li id="524d" class="ne nf iq kf b kg kh kk kl ko ng ks nh kw ni la nj nk nl nm bi translated"><strong class="kf ir"> Wasserstein损失:</strong>wasser stein损失通过让您将鉴别器训练到最佳状态来减轻模式崩溃，而不用担心消失梯度。如果鉴别器没有陷入局部最小值，它会学习拒绝发电机稳定的输出。所以，发电机必须尝试新的东西。</li><li id="7223" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">展开的gan:</strong>展开的gan使用生成器损耗函数，该函数不仅包含当前鉴别器的分类，还包含未来鉴别器版本的输出。因此，生成器不能对单个鉴别器进行过度优化。</li></ol></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="7f47" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">应用</h1><ol class=""><li id="571b" class="ne nf iq kf b kg mn kk mo ko od ks oe kw of la nj nk nl nm bi translated"><strong class="kf ir">风格转移:</strong>面部修饰应用程序现在都是炒作，面部衰老、哭脸和名人脸叠加只是社交媒体上已经广泛流行的一些应用程序。</li><li id="428d" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">视频游戏:3D物体的纹理生成和使用图像的场景生成只是帮助视频游戏行业更快开发更大游戏的一些应用。</li><li id="5da9" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">电影行业:</strong> CGI已经成为模范电影院的一个重要组成部分，凭借甘带来的潜力，电影制作人现在可以比以往任何时候都有更大的梦想。</li><li id="e46a" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">语音生成:</strong>一些公司正在使用GANs来改进文本到语音的应用，通过使用它们来生成更真实的声音。</li><li id="8145" class="ne nf iq kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf ir">图像恢复:</strong>利用GANs对被破坏的图像进行去噪和恢复，对历史图像进行着色，通过产生丢帧来改善旧视频，提高其帧率。</li></ol></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="4c22" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">结论</h1><p id="006a" class="pw-post-body-paragraph kd ke iq kf b kg mn ki kj kk mo km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">GAN和DCGAN是一篇里程碑式的论文，在无监督学习方面开辟了新的途径。对抗性训练方法提供了一种新的训练模型的方法，这种方法可以很好地模拟真实世界的学习过程。观察这一领域的发展将会非常有趣。</p><p id="87a5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你喜欢这篇文章。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><blockquote class="lb lc ld"><p id="a425" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><em class="iq">你可以在我的</em> <a class="ae kc" href="https://github.com/akash-agni/ReadThePaper/tree/main/DCGAN" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到完整实现</p><p id="da95" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><em class="iq">你可以在</em> <a class="ae kc" href="http://www.linkedin.com/in/agni25" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上关注我</p><p id="3205" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated"><em class="iq">你可以阅读我在</em> <a class="ae kc" href="https://agniakash25.medium.com/" rel="noopener">媒体</a>上的其他文章</p></blockquote></div></div>    
</body>
</html>