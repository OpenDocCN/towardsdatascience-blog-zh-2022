<html>
<head>
<title>Create geo image dataset in 20 minutes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在20分钟内创建地理图像数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-geo-image-dataset-in-20-minutes-4c893c60b9e6#2022-08-09">https://towardsdatascience.com/create-geo-image-dataset-in-20-minutes-4c893c60b9e6#2022-08-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="035f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">构建LAION-5B的地理特定子集</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a0e2b0c7fe31aebd7c69bf867a96a6a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*if_O9x0w1yejmhcCQ4XFMQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/@dekubaum?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">丹尼斯·库默</a>在<a class="ae kv" href="https://unsplash.com/s/photos/location-data?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><h2 id="f918" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">LAION-5B简介</h2><p id="2fe0" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">大规模人工智能开放网络(LAION)是一个非营利性组织，旨在向公众提供机器学习资源。最近，LAION发布了一个从互联网收集的58.5亿个图文对的数据集。LAION-5B数据集包含URL、文本以及KNN索引。</p><p id="1abf" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">KNN索引为一个名为<a class="ae kv" href="https://github.com/rom1504/clip-retrieval" rel="noopener ugc nofollow" target="_blank">剪辑检索</a>的搜索引擎提供动力，使用户能够交互式地探索LAION-5B数据集。剪辑检索提供了一个anUI和一个API来查询带有文本、图像或嵌入向量的LAION。剪辑检索使得创建原始LAION-5B图像数据集的特定任务子集变得容易。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/4bd8150b42783ce924d3bb8692ef7c28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s0TxRCZigS7xjwrYUce5xQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn5.laion.ai&amp;index=laion5B&amp;useMclip=false" rel="noopener ugc nofollow" target="_blank">使用剪辑检索UI构建的LAION搜索网络界面</a></p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/c81d1a2007743e2e2c9bb5c62ee46139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJJx4sNmE59wrBTNJJKxrg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><code class="fe ms mt mu mv b"><a class="ae kv" href="https://github.com/rom1504/clip-retrieval/blob/main/notebook/clip-client-query-api.ipynb" rel="noopener ugc nofollow" target="_blank">ClipClient</a> API Example</code></p></figure><h2 id="1c32" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">先前关于介子子集的工作</h2><p id="a133" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">LAION数据集以及剪辑检索为生成特定领域的LAION子集提供了巨大的机会。这些领域特定的子集然后可以用于训练任务特定的模型。其他人已经探索了这种方法来创建以下子集-</p><p id="7eb2" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae kv" href="https://github.com/FacePerceiver/LAION-Face" rel="noopener ugc nofollow" target="_blank"> LAION-Face </a>是<a class="ae kv" href="https://laion.ai/laion-400-open-dataset/" rel="noopener ugc nofollow" target="_blank"> LAION-400M </a>的人脸子集，它由5000万个图文对组成。进行人脸检测是为了找到带有人脸的图像。LAION-Face随后被用作<a class="ae kv" href="https://github.com/FacePerceiver/FaRL" rel="noopener ugc nofollow" target="_blank"> FaRL </a>的训练集，为人脸分析任务提供强大的预训练变压器骨干。</p><p id="f9ba" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae kv" href="https://github.com/LAION-AI/laion-datasets/blob/main/laion-aesthetic.md" rel="noopener ugc nofollow" target="_blank"> LAION Aesthetic </a>是LAION-5B的一个子集，已经通过在被判断为美学的图像的剪辑嵌入顶部训练的模型进行了估计。其预期目标是能够创建图像生成模型。</p><p id="fe69" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><a class="ae kv" href="https://github.com/rom1504/img2dataset/blob/main/dataset_examples/laion-high-resolution.md" rel="noopener ugc nofollow" target="_blank"> LAION高分辨率</a>是LAION-5B的一个&gt; = 1024x1024的子集，它有170M个样本。该数据集的预期用途是训练超分辨率模型。</p><h2 id="9b12" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">里昂地理子集</h2><p id="1570" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">鉴于LAION 5B中存在的规模和多样性，我们希望了解创建geo子集的可行性。地理子集可用于训练地理标记、地标检测等的模型。创建子集的流水线大致包括三个阶段，</p><ul class=""><li id="a6ec" class="mw mx iq lu b lv ml ly mm lf my lj mz ln na mk nb nc nd ne bi translated">生成一组位置关键词</li><li id="2ef9" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated">使用剪辑检索API检索图像</li><li id="a21d" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated">执行探索性分析</li></ul><p id="f003" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">位置关键词数据集:</strong>为了获得高质量的位置关键词，我们利用<a class="ae kv" href="https://www.instagram.com/explore/locations" rel="noopener ugc nofollow" target="_blank"> Instagram的探索位置页面</a>。为了构建概念验证，我们将位置关键字限制在美国&gt;(纽约市)中城东部。然后使用<a class="ae kv" href="https://gist.github.com/aadityaubhat/1b6dba5d8519724a8b3a5307547e9573" rel="noopener ugc nofollow" target="_blank"> JavaScript代码片段</a>下载位置关键字。这给了我们1096个位置关键字的列表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/0b49cbecb4e448572a0bb5e1feaa4135.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ljfH9b2RyFr24IZWb65A0A.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Instagram位置探索页面</p></figure><p id="62c9" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">使用ClipClient检索图像:</strong>使用clip-retrieval，我们可以为每个关键字检索图像。剪辑客户端有以下参数:</p><ul class=""><li id="5aea" class="mw mx iq lu b lv ml ly mm lf my lj mz ln na mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">backend_url</code>:后台的url</li><li id="fc1f" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">indice_name</code>:指定要使用的索引的名称</li><li id="34a1" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">aesthetic_score</code>:由<a class="ae kv" href="https://github.com/rom1504/aesthetic_detector" rel="noopener ugc nofollow" target="_blank">审美检测器</a>评定的审美分数</li><li id="dbca" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">use_mclip</code>:是否使用多语言版本的剪辑，默认为False</li><li id="0fc9" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">aesthetic_weight</code>:审美得分的权重</li><li id="0b18" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">modality</code>:在索引中搜索图像或文本</li><li id="0855" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">num_images</code>:从API返回的图像数量</li><li id="399a" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">deduplicate</code>:是否通过图像嵌入对结果进行去重，默认为真</li><li id="3208" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">use_safety_model</code>:是否删除不安全图像，默认为真</li><li id="688a" class="mw mx iq lu b lv nf ly ng lf nh lj ni ln nj mk nb nc nd ne bi translated"><code class="fe ms mt mu mv b">use_violence_detector</code>:是否删除暴力图片，默认为真</li></ul><p id="d574" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">为了获得最相关的结果，我们对clip客户端使用以下配置:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/679517b39300bbab6a9ec30edd32cac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*fKbiRzz0-5suOYcOKW26RA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">剪辑客户端配置</p></figure><p id="53ab" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">例如，我们通过向关键字添加上下文来创建搜索字符串。从关键字'<strong class="lu ir"> grand central terminal </strong>'中，我们创建搜索字符串'<strong class="lu ir">grand central terminal in midtown east，united states </strong>'。我们遍历搜索字符串列表，为每个关键字检索多达1000张图片。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/45ab6457d691c20816d1a742088be6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*imGMTLRvhvHywdqR-YU-rg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">检索关键字的图像</p></figure><p id="2e71" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated"><strong class="lu ir">执行探索性分析:</strong>从clip客户端检索所有位置关键字的图像后，我们目测检查一些结果，以执行基本的健全性检查。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/c090394a56f02b93fb372e4db935b559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jRxEvxDSpjfCAcOZ3UQbAQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">中央车站的结果</p></figure><p id="1743" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">我们在目视检查一些结果后进行探索性分析。对于<strong class="lu ir"> 1096个</strong>位置关键字，我们总共有<strong class="lu ir"> 484，714个</strong>图像，平均每个位置关键字有<strong class="lu ir"> 513.47个</strong>图像和<strong class="lu ir"> 540.5个</strong>图像的&amp;中值。图片数量最多的前20个地点大多是餐馆。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/b27b090a18acfcab3722238e7fdb5431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*6ooyYexKsTTASyq-32ktyA.png"/></div></div></figure><p id="8d41" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">数据集中的属性域分布高度倾斜。总共有<strong class="lu ir">44992个域</strong>，但是数据集中所有图像的<strong class="lu ir"> 37.88% </strong>仅来自前20个域。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b54d61e5e103eccc0f7ad5838719867d.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/0*1FpaGE-oUJQDxlNc"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">前20个域</p></figure><h2 id="4257" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">结论和未来工作</h2><p id="5b3a" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们构建了LAION-5B的美国中城东(纽约市)子集，并对数据集进行了探索性分析。该数据集可用于训练地理标记、地标检测模型。您可以通过运行<a class="ae kv" href="https://colab.research.google.com/drive/1LIwvoXgTBrAA38FcW9ZAh3DOAf4dl0nu?usp=sharing" rel="noopener ugc nofollow" target="_blank"> colab笔记本</a>中的代码来重现结果。</p><p id="2543" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">未来，我们计划扩展到美国的所有地理位置，通过比较现有地理模型的性能来验证结果，并发布带有验证分数的数据集。</p><p id="4800" class="pw-post-body-paragraph ls lt iq lu b lv ml jr lx ly mm ju ma lf mn mc md lj mo mf mg ln mp mi mj mk ij bi translated">如果你觉得我们的工作有帮助，请考虑引用</p><pre class="kg kh ki kj gt nq mv nr ns aw nt bi"><span id="3ab7" class="kw kx iq mv b gy nu nv l nw nx">@article{LAION-geo,<br/>  title={<!-- -->Create geo image dataset in 20 minutes<!-- -->},<br/>  author={Bhat, Aaditya and Jain, Shrey},<br/>  journal={Towards Data Science},<br/>  year={2022},<br/>  url={<a class="ae kv" rel="noopener" target="_blank" href="/create-geo-image-dataset-in-20-minutes-4c893c60b9e6">https://towardsdatascience.com/create-geo-image-dataset-in-20-minutes-4c893c60b9e6</a>}<br/>}</span></pre></div></div>    
</body>
</html>