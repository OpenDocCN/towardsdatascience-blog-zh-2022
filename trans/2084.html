<html>
<head>
<title>7 Lessons I’ve Learnt From Deploying Machine Learning Models Using ONNX</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我从使用ONNX部署机器学习模型中学到的7个教训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/7-lessons-ive-learnt-from-deploying-machine-learning-models-using-onnx-3e993da4028c#2022-05-10">https://towardsdatascience.com/7-lessons-ive-learnt-from-deploying-machine-learning-models-using-onnx-3e993da4028c#2022-05-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5d6b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一次构建，随处部署的绝佳方式</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/1f851c2464bee26b708f445574d35e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r7GcQP0Ir-fxGUkJImECoQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">奥丽雅·丹尼尔维奇在<a class="ae kv" href="https://www.pexels.com/photo/man-sitting-in-front-of-three-computers-4974915/" rel="noopener ugc nofollow" target="_blank">的照片</a></p></figure><p id="93eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本帖中，我们将概述从一个在AWS Lambda函数中使用ONNX运行时API在sci-kit学习模型上运行推理的真实示例中获得的关键知识。这不是一个教程，而是一个指南，集中在有用的技巧，要考虑的要点，和可能会让你省掉一些挠头的怪癖！</p><h1 id="f236" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">ONNX是什么？</h1><p id="72e1" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><a class="ae kv" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">开放神经网络交换(ONNX) </a>格式有点像把你的薯条蘸上奶昔；它不应该工作，但它就是工作。(嗯，反正对我来说)。</p><p id="30d9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ONNX允许我们使用所有我们知道并喜欢的训练框架(如PyTorch和TensorFlow)来建立模型，并将其打包成许多硬件架构和操作系统支持的格式。ONNX运行时是一个简单的API，它是跨平台的，并提供最佳的性能来在ONNX模型上运行推理，只要你需要:云、移动设备、物联网设备，你能想到的！</p><p id="cea9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们选择的编程语言或运行时决定我们如何构建人工智能的日子已经一去不复返了。</p><p id="b76c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要更深入地了解ONNX，请查看本文:<a class="ae kv" rel="noopener" target="_blank" href="/onnx-made-easy-957e60d16e94"> ONNX —变得简单</a>。</p><h1 id="dbac" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">我们怎么知道它有效？</h1><p id="61f5" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在<a class="ae kv" href="https://www.bazaarvoice.com/" rel="noopener ugc nofollow" target="_blank"> Bazaarvoice </a>，我们通过增强产品的用户生成内容(UGC)来改善数百万人的电子商务体验。其中很大一部分是产品匹配的过程，或者换句话说，确定两种产品在零售商之间是相同的。由于唯一的产品标识符，大部分工作可以自动完成，但是，有数百万种产品缺少这种重要的数据。</p><p id="6915" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了解决这个问题，我们建立了一个机器学习模型，它可以自动化产品匹配过程，并在全球范围内部署它，现在它可以准确匹配世界上一些最大品牌的数百万种产品。</p><h1 id="b2bc" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">先决条件</h1><p id="4979" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">虽然其中一些经验适用于多个工作流，但需要注意的是，它们是基于我的团队对我们使用的技术的经验:</p><ul class=""><li id="bcca" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">机器学习模型是使用<a class="ae kv" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>作为训练框架用Python编写的</li><li id="ba18" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">我们使用<a class="ae kv" href="https://www.npmjs.com/package/onnxruntime-node" rel="noopener ugc nofollow" target="_blank"> onnxruntime-node npm包</a>在Node.js环境中运行ONNX模型</li><li id="f579" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">使用<a class="ae kv" href="https://www.serverless.com/framework/docs/providers/aws/guide/intro" rel="noopener ugc nofollow" target="_blank">无服务器框架将模型部署到AWS Lambda </a></li></ul><h1 id="fb30" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">🌎第1课:一次构建，随处部署</h1><p id="c6cb" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">ONNX的最大卖点之一是它的多功能性和防止框架锁定的能力，所以不要陷入选择语言或部署环境，甚至是操作系统的困境。<strong class="ky ir">选择适合自己和项目的。</strong></p><p id="85b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有许多与ONNX格式兼容的<a class="ae kv" href="https://onnx.ai/supported-tools.html#buildModel" rel="noopener ugc nofollow" target="_blank">培训框架</a>和各种流行的<a class="ae kv" href="https://onnx.ai/supported-tools.html#deployModel" rel="noopener ugc nofollow" target="_blank">部署运行时</a>。你可以在这里找到方便的兼容性指南<a class="ae kv" href="https://onnxruntime.ai/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="9da9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于web应用部署目标的更多信息可以在<a class="ae kv" href="https://onnxruntime.ai/docs/reference/build-web-app.html" rel="noopener ugc nofollow" target="_blank"> ONNX运行时文档</a>中找到。</p><h1 id="b101" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">⚠️第二课:“错误:非张量类型暂时不被支持。”</h1><p id="8e7f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">标题中的错误是我们在试图使用<a class="ae kv" href="https://www.npmjs.com/package/onnxruntime-node" rel="noopener ugc nofollow" target="_blank"> onnxruntime-node </a> npm包在Node.js运行时运行从Python (scikit-learn)导出的ONNX模型时遇到的问题。</p><p id="0ef4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于错误消息，所有线索都暗示问题出在onnxruntime-node包中，但是，<strong class="ky ir">问题的根源在于从scikit-learn到ONNX的转换代码</strong>。</p><p id="c9b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">修复非常简单，使用来自<a class="ae kv" href="http://onnx.ai" rel="noopener ugc nofollow" target="_blank"> onnx.ai </a>网站的<a class="ae kv" href="https://onnx.ai/sklearn-onnx/index.html" rel="noopener ugc nofollow" target="_blank"> sklearn-onnx示例</a>代码示例，<strong class="ky ir">我们需要添加一个</strong> <code class="fe nd ne nf ng b"><strong class="ky ir">options</strong></code> <strong class="ky ir">变量，并将</strong> <code class="fe nd ne nf ng b"><strong class="ky ir">zipmap</strong></code> <strong class="ky ir">设置为false </strong>:</p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="36af" class="nl lt iq ng b gy nm nn l no np"># Convert into ONNX format<br/>from skl2onnx import convert_sklearn<br/>from skl2onnx.common.data_types import FloatTensorType<br/>initial_type = [('float_input', FloatTensorType([None, 4]))]<br/>onx = convert_sklearn(clr, initial_types=initial_type, <strong class="ng ir">options={'zipmap': False})</strong>  # enables getting probabilities in Node<br/>with open("rf_iris.onnx", "wb") as f:<br/>    f.write(onx.SerializeToString())</span></pre><p id="55ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过将<code class="fe nd ne nf ng b">zipmap</code>设置为false，我们现在可以在Node.js运行时接收概率输出。</p><p id="097c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有关导出的更多信息，请参见<a class="ae kv" href="https://github.com/onnx/tutorials#services" rel="noopener ugc nofollow" target="_blank"> ONNX教程GitHub repo </a>。它为使用<a class="ae kv" href="https://github.com/onnx/tutorials#converting-to-onnx-format" rel="noopener ugc nofollow" target="_blank">机器学习框架</a>和<a class="ae kv" href="https://github.com/onnx/tutorials#services" rel="noopener ugc nofollow" target="_blank">云服务</a>开发的模型提供了很好的描述和例子。</p><h1 id="f5f3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">📚第3课:用于数据帧操作的JavaScript库</h1><p id="7bf9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">几个npm库提供了DataFrame风格的数据转换(拆分、连接、分组等)。选择最好的取决于您的用例。我们使用的两个库是<a class="ae kv" href="https://danfo.jsdata.org/" rel="noopener ugc nofollow" target="_blank"> danfo.js </a>和<a class="ae kv" href="https://www.npmjs.com/package/dataframe-js" rel="noopener ugc nofollow" target="_blank"> dataframe-js </a>。</p><p id="ebf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">danfo-js建立在<a class="ae kv" href="https://www.tensorflow.org/js" rel="noopener ugc nofollow" target="_blank"> tensorflow-js </a>之上，将数据处理、机器学习和人工智能工具带到JavaScript开发者的手中。它深受熊猫的启发。这意味着如果你熟悉熊猫API，danfo.js应该是一个平滑的过渡。</p><p id="d389" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">dataframe-js是用更具功能性的编程启发的API构建的，所以如果你更熟悉JavaScript，你可能会觉得使用dataframe-js比danfo-js更舒服。</p><p id="693b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">danfo-js和dataframe-js都非常适合我们的用例，并提供了复杂特征工程所需的所有功能。<strong class="ky ir">danfo-js的主要缺点是包的大小。对于我们的无服务器应用程序来说，它太大了，而“dataframe-js”打包在1Mb以下，这是无服务器应用程序的理想选择。</strong></p><p id="fd28" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">选择库时要考虑的一些其他标准是:</p><ul class=""><li id="af3c" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated">语言支持(NodeJS vs browser JS vs Typescript)</li><li id="1952" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">依赖性(即，如果它使用底层库)</li><li id="2233" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">积极支持(积极的用户基础、积极的资源存储库等)</li><li id="a804" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">JS库的大小/速度</li><li id="9a31" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">表演</li><li id="e07a" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">功能/灵活性</li><li id="354c" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">易于使用</li><li id="cb3e" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated">内置可视化功能</li></ul><p id="bd83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其他数据帧操作库包括:</p><ul class=""><li id="d02f" class="mp mq iq ky b kz la lc ld lf mr lj ms ln mt lr mu mv mw mx bi translated"><a class="ae kv" href="https://github.com/data-forge/data-forge-ts" rel="noopener ugc nofollow" target="_blank">数据伪造</a></li><li id="9fba" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" href="https://www.npmjs.com/package/jsdataframe" rel="noopener ugc nofollow" target="_blank"> jsdataframe </a></li><li id="f7c4" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" href="https://www.npmjs.com/package/dataframe" rel="noopener ugc nofollow" target="_blank">数据框</a></li><li id="f535" class="mp mq iq ky b kz my lc mz lf na lj nb ln nc lr mu mv mw mx bi translated"><a class="ae kv" href="https://sqlframes.com/" rel="noopener ugc nofollow" target="_blank"> SQL框架</a></li></ul><h1 id="581c" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">📦第四课:使用<a class="ae kv" href="https://www.npmjs.com/package/serverless-plugin-optimize" rel="noopener ugc nofollow" target="_blank"> <em class="nq">无服务器-插件-优化</em> </a>插件</h1><p id="2be6" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在进行无服务器部署时，保持项目包较小是非常重要的。下图显示了数据科学家最常用的一些库的Python包大小。我们可以看到他们如何吃掉AWS Lambdas和Google Cloud功能的大量部署规模限制。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/32b32955b9d2bb9c1fa3a1dc723d4dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Abva7VRmrv6qqXZO--wbCQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">流行框架的Python包大小和云部署限制。作者照片</p></figure><p id="690d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，我们可以在这些限制内工作。ONNX将PyTorch、Tensorflow和pandas等创建的模型转换成与相对较小的ONNX运行时包(~13MB)兼容的模型。这适用于某些情况，但是添加一个庞大的<em class="ns"> node_modules </em>文件夹，超出部署限制的情况仍然很常见。</p><p id="0c2b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"/><a class="ae kv" href="https://www.npmjs.com/package/serverless-plugin-optimize" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">无服务器-插件-优化</strong> </a> <strong class="ky ir">插件显著减小了无服务器包的大小</strong>。在我们的例子中，插件允许我们在<a class="ae kv" href="https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html" rel="noopener ugc nofollow" target="_blank"> 50Mb之内轻松地打包我们的模型、依赖项和代码。AWS Lambdas的zip文件部署限制</a>。</p><p id="9a52" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要允许AWS Lambda访问onnxruntime-node包和onnx模型，请将以下几行添加到您的<code class="fe nd ne nf ng b">serverless.yml</code>文件中:</p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="ba87" class="nl lt iq ng b gy nm nn l no np">custom:<br/> optimize:<br/> external: ['onnxruntime-node', 'onnxruntime-common']<br/> includePaths: ['PATH_TO_ONNX_MODEL']</span></pre><h1 id="9539" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">🚀第5课:将<a class="ae kv" href="https://www.npmjs.com/package/onnxruntime-node" rel="noopener ugc nofollow" target="_blank"><em class="nq">onnxruntime-node</em></a>部署到AWS</h1><p id="90fa" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">使用<a class="ae kv" href="https://www.npmjs.com/package/onnxruntime-node" rel="noopener ugc nofollow" target="_blank"> onnxruntime-node </a>时需要注意的重要一点是<strong class="ky ir"> <em class="ns">其中</em> </strong> <em class="ns"> </em>你正在运行的app决定了<strong class="ky ir"> <em class="ns">你应该如何</em> </strong>安装包。如果在部署时没有将它安装到正确的体系结构和/或平台上，您将会看到抛出缺失模块错误，如下所示:</p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="5f74" class="nl lt iq ng b gy nm nn l no np">Runtime.ImportModuleError: Error: Cannot find module '../bin/napi-v3/linux/x64/onnxruntime_binding.node'</span></pre><p id="bdc3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数本地节点模块使用<a class="ae kv" href="https://github.com/mapbox/node-pre-gyp" rel="noopener ugc nofollow" target="_blank"> node-pre-gyp </a>，它使用一个安装脚本来为您的OS、arch和v8 ABI组合搜索预构建的二进制文件，如果没有一个可用的，则回退到本地构建。</p><p id="b44c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着一个简单的<code class="fe nd ne nf ng b">npm install onnxruntime-node</code>在本地运行时可以工作，但是<strong class="ky ir">在云函数中无服务器运行时，我们需要明确地安装到我们的环境中</strong>。</p><p id="3e1f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，我们使用的AWS Lambda具有x64架构，并在Linux机器上运行，因此我们必须在部署 之前运行<strong class="ky ir"> <em class="ns">的npm安装命令是:</em></strong></p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="df04" class="nl lt iq ng b gy nm nn l no np">npm install --arch=x64 --platform=linux onnxruntime-node</span></pre><h1 id="e861" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">📅第6课:日程安排</h1><p id="1c7a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">如果您需要您的模型按计划自动运行，而不想手动运行您的模型——如果您使用AWS，请尝试<a class="ae kv" href="https://www.serverless.com/framework/docs/providers/aws/events/event-bridge" rel="noopener ugc nofollow" target="_blank">将EventBridge添加到您的无服务器配置</a>。使用<a class="ae kv" href="https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html#eb-cron-expressions" rel="noopener ugc nofollow" target="_blank"> cron表达式</a>或<a class="ae kv" href="https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-create-rule-schedule.html#eb-rate-expressions" rel="noopener ugc nofollow" target="_blank">速率表达式</a>设置时间表。</p><p id="6247" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是添加到<code class="fe nd ne nf ng b">serverless.yml</code>文件的配置示例:</p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="9aba" class="nl lt iq ng b gy nm nn l no np">events:<br/> - http:<br/>   path: really-cool-onnx-project<br/>   method: post<br/> - eventBridge:<br/>   enabled: true<br/>   schedule: cron(0/20 6-13 * * ? *) # Runs every 20 minutes between 6am and 2pm (UTC) every day<br/>   input:<br/>    stageParams:<br/>     stage: prod</span></pre><p id="8471" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">需要注意的重要一点是，<strong class="ky ir">如果您的AWS Lambda函数在EventBridge调用期间超时，它将一直调用，直到执行完成</strong>。</p><p id="8a4e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Google Cloud Functions和Azure Functions也都有基于cron-job的调度能力，分别有<a class="ae kv" href="https://cloud.google.com/scheduler" rel="noopener ugc nofollow" target="_blank">云调度器</a>和<a class="ae kv" href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-create-scheduled-function" rel="noopener ugc nofollow" target="_blank">定时器触发器</a>。</p><h1 id="8c2d" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">📈第7课:高效扩展无服务器应用</h1><p id="fae2" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在性能和成本之间找到最佳平衡是大规模运行无服务器应用的一个重要方面。</p><p id="2ddf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的用例中，我们为每次AWS Lambda调用生成10，000个产品的预测。这是需要处理的大量数据。出于这个原因，理解Lambda的两个方面以优化性能是很重要的:执行时间(避免超时)和成本效率。</p><p id="56c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们用六种不同的Lambda内存大小配置测试了我们的无服务器应用程序，并推断了我们在内存大小、执行时间和成本方面可以找到的任何结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nt nu l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">使用六种不同的Lambda内存大小配置测试我们的无服务器应用的结果</p></figure><p id="ddc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如您所见，随着内存大小翻倍，执行时间几乎减半——直到它稳定在4096MB，达到收益递减点。<strong class="ky ir">使用更高的分配内存大小也</strong> <a class="ae kv" href="https://docs.aws.amazon.com/lambda/latest/operatorguide/computing-power.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">增加了Lambda函数</strong>可用的虚拟CPU  </a> <strong class="ky ir">的数量，从而节省了成本，因为它减少了总执行时间。</strong></p><p id="386f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2048MB的内存大小最终成为最便宜的——令人惊讶的是甚至比256MB还便宜，同时还快了大约10倍。因此，对于我们的用例，2048MB是性能和成本之间的最佳平衡。</p><h1 id="7c98" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">结束语</h1><p id="9eae" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">希望这篇帖子在用ONNX和Serverless开发的时候对你有所帮助。在Bazaarvoice，我们通过在全球范围内使用ONNX提供人工智能解决方案来支持这些技术。如果您想了解更多关于我们的ONNX解决方案的信息，请查看由我们的一位机器学习工程师所做的<a class="ae kv" href="https://youtu.be/C_DWbsmrrTk?t=10680" rel="noopener ugc nofollow" target="_blank">本次会议报告</a>。</p><pre class="kg kh ki kj gt nh ng ni nj aw nk bi"><span id="9d0f" class="nl lt iq ng b gy nm nn l no np">💻 If you have any questions, please reach out / <a class="ae kv" href="https://matthewleyburn.com/" rel="noopener ugc nofollow" target="_blank">matthewleyburn.com</a></span></pre></div><div class="ab cl nv nw hu nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="ij ik il im in"><p id="57c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">你用过ONNX吗？在评论里告诉我，说说你们的经历吧！</strong></p></div></div>    
</body>
</html>