<html>
<head>
<title>Mango: A new way to do Bayesian optimization in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Mango:用Python实现贝叶斯优化的新方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mango-a-new-way-to-make-bayesian-optimisation-in-python-a1a09989c6d8#2022-08-23">https://towardsdatascience.com/mango-a-new-way-to-make-bayesian-optimisation-in-python-a1a09989c6d8#2022-08-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0100" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你所需要知道的就是这个库，用于机器学习模型的可扩展超参数调整</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/475e3fb9e2124eda36b2820c89336172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RyCnkfyCNk7eGc7Dbl51FA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">由<a class="ae kv" href="https://unsplash.com/s/photos/servers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae kv" href="https://unsplash.com/@freeche?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Kvistholt摄影</a>拍摄</p></figure><p id="fcb9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">模型超参数(或模型设置)的优化可能是训练机器学习算法中最重要的步骤，因为它导致找到使模型损失函数最小化的最佳参数。这一步对于构建不容易过度拟合的通用模型也是必不可少的。</p><p id="c0ec" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">优化模型超参数的最著名技术是<em class="ls">穷举</em> <em class="ls">网格搜索</em>及其随机对应物:<em class="ls">随机网格搜索</em>。在第一种方法中，搜索空间被定义为跨越每个模型超参数的域的网格。通过在网格的每个点上训练模型来获得最佳超参数。虽然网格搜索很容易实现，但它在计算上变得很昂贵，尤其是当要优化的变量数量很大时。另一方面，andom网格搜索是一种更快的优化方法，可以提供更好的结果。在随机网格搜索中，通过仅在网格空间的随机样本点上训练模型来获得最佳超参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lt"><img src="../Images/3d5c67cb87dfa610c324870cec144ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjJzZZ8OXgRxOeNvIvh3xQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">两种网格搜索的比较。这九个点表示参数的选择。左侧和顶部的曲线表示作为每个搜索维度的函数的模型精度。该图摘自Salgado Pilario等人的《IEEE工业电子学汇刊》, 68，6171–6180(2021年)。</p></figure><p id="12bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">长期以来，数据科学家广泛使用这两种网格搜索算法来寻找最佳模型超参数。然而，这些方法通常发现模型超参数的损失函数远离全局最小值。</p><p id="d623" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">历史在2013年发生了改变，当时James Bergstra和他的合作者发表了一篇论文<a class="ae kv" href="https://proceedings.mlr.press/v28/bergstra13.pdf" rel="noopener ugc nofollow" target="_blank"/>，其中他们探索了一种贝叶斯优化技术，以找到图像分类神经网络的最佳超参数。他们将结果与随机网格搜索得到的结果进行了比较。很明显，贝叶斯方法优于随机网格搜索:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi lu"><img src="../Images/b4caaf54d989b4dfe332a85f957bf817.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Clp1pWcpKBYGsQppACFTbA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">LFW数据集(左)和PubFig83数据集(右)上的验证错误。TPE代表Tree Parzen Estimator，这是一种用于贝叶斯优化的算法。该图摘自Bergstra等人的《机器学习研究进展》，28，115–123(2013)。</p></figure><p id="09a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是为什么贝叶斯优化比任何网格搜索算法都好呢？因为这是<em class="ls">引导的</em>方法之一，它执行模型超参数的智能搜索，而不是通过试错法找到它们。</p><p id="5cd0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这篇博客中，我们将剖析贝叶斯优化方法，并通过一个名为<a class="ae kv" href="https://github.com/ARM-software/mango" rel="noopener ugc nofollow" target="_blank"> <em class="ls">芒果</em> </a>的相对较新的Python包来探索其实现之一。</p><h1 id="a32c" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">简而言之，贝叶斯优化</h1><p id="342f" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">在解释<em class="ls"> Mango </em>做什么之前，我们需要了解贝叶斯优化是如何工作的。如果您对这个算法有很好的理解，您可以安全地跳过这一部分。</p><p id="6831" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">贝叶斯优化有4个组成部分:</p><ul class=""><li id="213c" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated"><strong class="ky ir">目标函数</strong>:这是您想要最小化或最大化的真实函数。例如，它可以是回归问题中的均方根误差(RMSE)或分类中的对数损失。在机器学习模型的优化中，目标函数取决于模型超参数。这就是为什么目标函数也被称为黑盒函数，因为它的形状是未知的。</li><li id="1078" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated"><strong class="ky ir">搜索域或搜索空间</strong>:这对应于每个模型超参数可能具有的值。作为用户，您需要指定您的模型的搜索空间。例如，随机森林回归模型的搜索域可能是:</li></ul><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="2e66" class="nl lw iq nh b gy nm nn l no np">param_space = {<strong class="nh ir">'max_depth'</strong>: range(3, 10),<br/>               <strong class="nh ir">'min_samples_split'</strong>: range(20, 2000),<br/>               <strong class="nh ir">'min_samples_leaf'</strong>: range(2, 20),<br/>               <strong class="nh ir">'max_features'</strong>: [<strong class="nh ir">"sqrt"</strong>, <strong class="nh ir">"log2"</strong>, <strong class="nh ir">"auto"</strong>],<br/>               <strong class="nh ir">'n_estimators'</strong>: range(100, 500)<br/>               }</span></pre><p id="f97a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">贝叶斯优化使用定义的搜索空间来采样在目标函数中评估的点。</p><ul class=""><li id="320d" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated"><strong class="ky ir">代理模型</strong>:评估目标函数是非常昂贵的，所以在实践中，我们只在少数地方知道目标函数的真实值，然而，我们需要知道其他地方的值。这是它进入代理模型的时候，代理模型是一种建模目标函数的工具。替代模型的常见选择是所谓的高斯过程(GP ),因为它能够提供不确定性估计。解释高斯过程超出了这篇博文的范围，但是我鼓励你阅读这篇出色的文章，它有大量的图片来帮助你建立这种概率方法背后的直觉。</li></ul><p id="f47a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在贝叶斯优化的开始，代理模型从先验函数开始，该先验函数沿着搜索空间以均匀的不确定性分布:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/610830d19a23fa3a9bb8b976e72225bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*PrdBPb4g1PSAbwO9_Hug9A.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">代理模型之前。阴影区域是它的不确定性，而黑线是它的平均值。紫色线代表一维目标函数。图片复制自博文<a class="ae kv" href="https://distill.pub/2020/bayesian-optimization/" rel="noopener ugc nofollow" target="_blank">探索贝叶斯优化</a>，Apoorv Agnihotri和Nipun Batra，2020。</p></figure><p id="71a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每次在目标函数中评估来自搜索空间的样本点时，代理模型在该点的不确定性变为零。经过多次迭代后，代理模型将类似于目标函数:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/f5c61c089f1fa4485dd152bd95ecb1f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IV6ijoH8cUrBbYafgyFUOA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">简单一维目标函数的代理模型。作者制作的图像。</p></figure><p id="994e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然而，贝叶斯优化的目标不是对目标函数建模。相反，是在尽可能少的迭代次数中找到最佳模型超参数。为此，有必要使用采集功能。</p><ul class=""><li id="7373" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated"><strong class="ky ir">获取函数</strong>:该函数在贝叶斯优化中引入，用于指导搜索。获取函数用于评估一个点是否期望基于当前代理模型进行评估。一个简单的采集函数是对代理函数的均值最大化的点进行采样。</li></ul><p id="9105" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">贝叶斯优化代码的步骤是:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="e380" class="nl lw iq nh b gy nm nn l no np">Select a surrogate model for modeling the objective function and define its prior</span><span id="ed57" class="nl lw iq nh b gy ns nn l no np">for i = 1, 2,..., number of iterations:<br/>    Given a set of evaluations in the objective, use Bayes <br/>       to obtain the posterior.<br/>    Use an acquisition function (which is a function of the    <br/>       posterior) to decide the next sampling point.<br/>    Add newly sampled data to the set of observations.</span></pre><p id="8a7b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下图显示了简单一维函数的贝叶斯优化:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/af02a8ef305e2218862e5e010b67afe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7vLS8z9lmAVo4ZKWeuOwvg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">一维函数的贝叶斯优化。图片摘自ARM research的博客文章:<a class="ae kv" href="https://community.arm.com/arm-research/b/articles/posts/scalable-hyperparameter-tuning-for-automl" rel="noopener ugc nofollow" target="_blank">AutoML的可扩展超参数调优</a>。</p></figure><p id="f735" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有兴趣阅读更多关于贝叶斯优化的内容，我推荐你阅读这篇伟大的文章:</p><div class="nu nv gp gr nw nx"><a href="https://distill.pub/2020/bayesian-optimization/" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">探索贝叶斯优化</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">许多现代机器学习算法都有大量的超参数。为了有效地使用这些算法，我们…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">蒸馏. pub</p></div></div><div class="og l"><div class="oh l oi oj ok og ol kp nx"/></div></div></a></div><p id="ff9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">几个Python包使用贝叶斯优化来获得机器学习模型的最佳超参数。一些例子有:<a class="ae kv" href="http://hyperopt.github.io/" rel="noopener ugc nofollow" target="_blank">远视</a>；<a class="ae kv" href="https://optuna.org/" rel="noopener ugc nofollow" target="_blank">Optuna</a>；<a class="ae kv" href="https://github.com/fmfn/BayesianOptimization" rel="noopener ugc nofollow" target="_blank">贝叶斯优化</a>；<a class="ae kv" href="https://scikit-optimize.github.io/stable/index.html" rel="noopener ugc nofollow" target="_blank">Scikit-optimize(skopt)</a>；<a class="ae kv" href="https://sheffieldml.github.io/GPyOpt/" rel="noopener ugc nofollow" target="_blank">GPyOpt</a>；<a class="ae kv" href="https://pygpgo.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> pyGPGO </a>和<a class="ae kv" href="https://github.com/ARM-software/mango" rel="noopener ugc nofollow" target="_blank"> <em class="ls">芒果</em> </a>。这个列表很长，我没有提到其他库。对于其他软件包的一个很好的总结，你可以阅读这篇博文:</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/10-hyperparameter-optimization-frameworks-8bc87bc8b7e3"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">10个超参数优化框架。</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">使用开源优化库调整您的机器学习模型</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="om l oi oj ok og ol kp nx"/></div></div></a></div><p id="0ff1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们一起深入<em class="ls">芒果</em>！</p><h1 id="4dad" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">芒果:为什么这么特别？</h1><p id="03a4" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">近年来，数据量大幅增长。这对于需要机器学习管道可扩展的数据科学家来说是一个挑战。分布式计算可能会解决这个问题。</p><p id="7641" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分布式计算是指一组计算机在相互通信的同时执行一个共同的任务。这不同于并行计算，在并行计算中，一个任务被分成多个子任务，这些子任务被分配给同一计算机系统上的不同处理器。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/941acd0135272ac7b2aa061561787ed3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tNANn_dwuA8Z43DgJ3UfrQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">并行计算与分布式计算。作者制作的图像。</p></figure><p id="7ee1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">虽然有相当多的Python库使用贝叶斯优化来调优模型超参数，<strong class="ky ir">但是它们都不支持任何分布式计算框架上的调度。</strong>开发<em class="ls">芒果</em>的作者的动机是创建一个能够在分布式计算环境中工作的优化算法，同时保持贝叶斯优化的能力。</p><p id="3263" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Mango的架构在分布式计算环境中运行良好的秘密是什么？Mango 采用模块化设计，优化器与调度器分离。这种设计可以轻松扩展使用大量数据的机器学习管道。然而，这种架构在优化方法方面带来了挑战，因为传统的贝叶斯优化算法是顺序的，这意味着采集函数仅提供单个下一点来评估搜索。</p><p id="0ff3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls"> Mango </em>使用两种方法并行化贝叶斯优化:一种叫做<em class="ls">的方法批量高斯过程土匪</em>和k-means聚类。在这篇博客中，我们不会解释批量高斯过程。如果你有兴趣了解更多关于这种方法的信息，你可以阅读<a class="ae kv" href="https://jmlr.org/papers/volume15/desautels14a/desautels14a.pdf" rel="noopener ugc nofollow" target="_blank">的这篇论文</a>。</p><p id="e046" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于聚类方法，使用k-means聚类来横向扩展贝叶斯优化过程是由IBM的一组研究人员在2018年提出的(参见<a class="ae kv" href="https://arxiv.org/pdf/1806.01159.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>了解技术细节)。这种方法由从搜索域采样的聚类点组成，这些点在采集函数中产生高值(见下图)。一开始，这些聚类在参数搜索空间中彼此远离。当替代函数中的最佳区域被发现时，参数空间中的距离减小。k-means聚类方法横向扩展优化，因为每个聚类用于作为单独的过程运行贝叶斯优化。这种并行化导致更快地找到最佳模型超参数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/8560a9b8953a219c887bb9b3ce7ee825.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UlSQld1kZ1kp7k8J_ZEZCg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Mango使用聚类方法来扩展贝叶斯优化方法。采集函数上的彩色区域是从搜索空间中具有高采集函数值的采样点构建的聚类。在开始时，聚类被彼此分开，但是它们的距离被缩短，因为代理函数类似于目标。图片来自博文:<a class="ae kv" href="https://community.arm.com/arm-research/b/articles/posts/scalable-hyperparameter-tuning-for-automl" rel="noopener ugc nofollow" target="_blank">ARM research的AutoML </a>可扩展超参数调优。</p></figure><p id="23c6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了在分布式计算框架上工作的能力之外，<em class="ls"> Mango </em>还兼容scikit-learn API。这意味着您可以将超参数搜索空间定义为一个Python字典，其中的关键字是模型的参数名称，每个项目都可以用scipy.stats中实现的70多个发行版中的任何一个来定义。所有这些独特的特征使<em class="ls"> Mango </em>成为想要大规模利用数据驱动解决方案的数据科学家的绝佳选择。</p><p id="b1c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有兴趣了解更多关于<em class="ls"> Mango </em>的内部运作，你可以阅读<a class="ae kv" href="https://arxiv.org/pdf/2005.11394.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>或者访问这个由库的作者写的漂亮的博客:</p><div class="nu nv gp gr nw nx"><a href="https://community.arm.com/arm-research/b/articles/posts/scalable-hyperparameter-tuning-for-automl" rel="noopener  ugc nofollow" target="_blank"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">mango:AutoML的可伸缩超参数调优</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">自动机器学习(AutoML)是将机器学习应用于现实世界问题的自动化过程。一个…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">community.arm.com</p></div></div><div class="og l"><div class="op l oi oj ok og ol kp nx"/></div></div></a></div><h2 id="48c9" class="nl lw iq bd lx oq or dn mb os ot dp mf lf ou ov mh lj ow ox mj ln oy oz ml pa bi translated">简单的例子</h2><p id="865b" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">现在让我们来说明一下<em class="ls"> Mango </em>在优化问题中是如何工作的。你首先需要创建一个Python环境，然后通过下面的命令安装<em class="ls">芒果</em>:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="e54e" class="nl lw iq nh b gy nm nn l no np">pip install arm-mango</span></pre><p id="89e3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于这个例子，我们使用可以直接从Scikit-learn加载的加州住房数据集(<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html" rel="noopener ugc nofollow" target="_blank">更多信息请点击此链接</a>):</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="c429" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该数据集包含20，640个样本。每个样本有8个特征，包括房屋年龄，平均卧室数量等。California housing数据集还包括每个样本的房价，单位为100，000。房价分布如下图所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pd"><img src="../Images/b9a7509f4215d5a4ab0e56e3b8837c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kz3nbxMQW7IJBs0xMh6v8Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">在左侧面板中，加利福尼亚数据集中房价的空间分布。右边是同一变量的直方图。作者制作的图像。</p></figure><p id="2588" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意房价分布有点偏左。这意味着在目标中需要一些预处理。例如，我们可以通过对数或Box-Cox变换将目标的分布转换为正常形状。由于减少了目标的方差，这种预处理可能会提高模型的预测性能。我们将在超参数优化和建模过程中执行此步骤。现在，让我们将数据集分为训练集、验证集和测试集:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="c9ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们准备用<em class="ls">芒果</em>来优化机器学习模型。首先，我们定义搜索空间，Mango<em class="ls">和Mango </em>从中取值。在这个例子中，我们使用一种叫做<a class="ae kv" href="https://link.springer.com/article/10.1007/s10994-006-6226-1" rel="noopener ugc nofollow" target="_blank">极端随机化树</a>的算法，这是一种非常类似于随机森林的集成方法，除了选择最佳分割的方式，这是随机进行的。这种算法通常以略微增加偏差为代价来减少方差。如果你有兴趣了解更多关于极度随机化的树，你可以访问这个<a class="ae kv" href="https://scikit-learn.org/stable/modules/ensemble.html#extremely-randomized-trees" rel="noopener ugc nofollow" target="_blank"> Scikit-learn文档</a>。</p><p id="eb3e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">极端随机化树的搜索空间可以定义如下:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="9177" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一旦定义了参数空间，我们就指定了目标函数。这里我们使用上面创建的训练和验证数据集；但是，如果要运行k重交叉验证策略，就需要在目标函数内部实现。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="ab3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于上述代码的重要说明:</p><p id="8acf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">目标函数旨在找到最小化均方根误差(RMSE)的最佳模型参数。</p><p id="2507" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Scikit-learn中回归问题的极端随机化树的实现称为<em class="ls">extractreesregressor。</em></p><p id="eba9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意<em class="ls"> </em>火车集合中的房价是对数变换的。因此，在验证集上做出的预测被转换回它们的原始规模。</p><p id="ab8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">优化模型的超参数所需的最后一步是实例化类<em class="ls">调谐器</em>，它负责运行<em class="ls">芒果</em>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="5c21" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在配备2.3 Ghz四核英特尔酷睿i7处理器的MacBook Pro上，代码运行时间为4.2分钟。</p><p id="5114" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最佳超参数和最佳RMSE分别为:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="e1cd" class="nl lw iq nh b gy nm nn l no np">best parameters: {‘max_depth’: 9, ‘max_features’: ‘auto’, ‘min_samples_leaf’: 85, ‘min_samples_split’: 729}<br/>best accuracy (RMSE): 0.7418871882901833</span></pre><p id="adc6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当在具有最佳模型参数的训练集上训练模型时，测试集上的RMSE是:</p><pre class="kg kh ki kj gt ng nh ni nj aw nk bi"><span id="1645" class="nl lw iq nh b gy nm nn l no np">rmse on test: 0.7395178741584788</span></pre><p id="8da0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">免责声明:</strong>运行这段代码时，您可能会得到不同的结果。</p><p id="5c6c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们简单回顾一下上面<em class="ls">代码中使用的<em class="ls">调音器</em>类。</em>该类<em class="ls"> </em>有许多配置参数，但在本例中，我们只尝试了其中的两个:</p><ul class=""><li id="7c77" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated"><code class="fe pe pf pg nh b">num_iteration</code>:这些是<em class="ls"> Mango </em>用来寻找最优值的总迭代次数。</li><li id="6b11" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated"><code class="fe pe pf pg nh b">initial_random</code>:该变量设置测试的随机样本数量。重要:<strong class="ky ir"> <em class="ls">芒果</em>将所有随机样本一起返回</strong>。这非常有用，尤其是在优化需要并行运行的情况下。</li></ul><p id="3572" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有关配置<em class="ls">芒果</em>的其他参数的更多信息，您可以访问<a class="ae kv" href="https://github.com/ARM-software/mango#6-optional-configurations" rel="noopener ugc nofollow" target="_blank">此链接</a>。</p><p id="283c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇博客中的例子使用了一个小数据集。然而，在许多实际应用中，您可能会处理需要并行实现<em class="ls"> Mango </em>的大型数据文件。如果你去<a class="ae kv" href="https://github.com/anamabo/medium-blogs/tree/main/mango" rel="noopener ugc nofollow" target="_blank">我的GitHub库</a>，你可以找到这里显示的完整代码以及大数据文件的实现。</p><p id="d6ee" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">芒果</em>很百搭。您可以在广泛的机器和深度学习模型中使用它，这些模型需要并行实现或分布式计算环境来优化它们的超参数。因此，我鼓励你访问芒果的GitHub库。在那里，你会发现许多笔记本展示了在不同的计算环境中使用芒果的情况。</p><h1 id="4ab2" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">带回家的信息</h1><p id="83af" class="pw-post-body-paragraph kw kx iq ky b kz mn jr lb lc mo ju le lf mp lh li lj mq ll lm ln mr lp lq lr ij bi translated">在这篇博客中，我们回顾一下<em class="ls"> Mango </em>:一个大规模进行贝叶斯优化的Python库。该软件包将使您能够:</p><ul class=""><li id="79f4" class="ms mt iq ky b kz la lc ld lf mu lj mv ln mw lr mx my mz na bi translated">扩展您的模型超参数优化，甚至可以在分布式计算框架上运行。</li><li id="10d1" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">轻松地将scikit-learn模型与<em class="ls"> Mango </em>集成，以产生强大的机器学习管道。</li><li id="1d40" class="ms mt iq ky b kz nb lc nc lf nd lj ne ln nf lr mx my mz na bi translated">使用scipy.stats中实现的任何概率分布函数来声明您的搜索空间。</li></ul><p id="a635" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所有这些特性使得<em class="ls"> Mango </em>成为一个独特的Python库，它将拓宽你的数据科学工具包。</p><p id="a480" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我希望你学到了新的东西。再次感谢你的阅读！</p></div></div>    
</body>
</html>