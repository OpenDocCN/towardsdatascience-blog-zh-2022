<html>
<head>
<title>Quantum Deep Learning: A Quick Guide to Quantum Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">量子深度学习:量子卷积神经网络快速指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quantum-deep-learning-a-quick-guide-to-quantum-convolutional-neural-networks-d65284e21fc4#2022-10-04">https://towardsdatascience.com/quantum-deep-learning-a-quick-guide-to-quantum-convolutional-neural-networks-d65284e21fc4#2022-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="60f1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated"><em class="kf">你需要知道的关于量子卷积神经网络(QCNNs)的一切，包括与经典计算方法相比，这些方法的优势和局限性</em></h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/df4ddbf72e7f66f0826968ad8df1c90e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHqdoA2wC7BUapBhC86tJQ.jpeg"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated">芬兰埃斯波的IQM量子计算机<a class="ae kw" href="https://commons.wikimedia.org/wiki/File:IQM_Quantum_Computer_Espoo_Finland.jpg" rel="noopener ugc nofollow" target="_blank"> Ragsxl </a></p></figure><p id="26d4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">近年来<a class="ae kw" href="https://semiengineering.com/progress-in-quantum-computing/" rel="noopener ugc nofollow" target="_blank">对量子计算的投资显著增加</a>，安全和网络通信等领域的量子方法有望颠覆现有的经典计算技术。</p><p id="bf9c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Garg和Ramakrishnan等研究人员认为，量子计算的核心是“通过计算成本更低的技术解决经典难题”。或许不足为奇的是，正如近年来深度学习和量子计算的研究平行增长一样，许多人现在正在研究这两个领域交汇的可能性:量子深度学习。</p><p id="e46f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在本文中，我们将在高层次上讨论量子深度学习的现有研究和应用，重点是混合量子卷积神经网络(QCNNs)。首先，提供了与经典计算相比的量子计算的简要定义。从这里，纠缠被定义，以及纠缠态和它们的应用。</p><p id="a8b6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">接下来，讨论了经典卷积神经网络(CCNNs，或CNN)的概述。最后，讨论了QCNNs及其性能，以及这些方法的优点和局限性。</p><h1 id="bbc3" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">经典计算和量子计算的区别</h1><p id="1707" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">如果你对量子计算完全陌生，一个重要的介绍性概念是经典计算(我们通常用于计算任务)和量子计算之间的区别。在传统的计算机上，当一个程序被执行时，编译器被用来把程序的语句翻译成二进制位上的操作。</p><p id="756a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">不像经典计算机上的比特在任何时候都代表1或0，量子比特能够在这两种状态之间“徘徊”。只有在测量时，量子位才会“坍缩”成它的一种状态。</p><p id="09e7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这种性质被称为叠加，对量子计算任务至关重要(Ganguly，Cambier，2021)。通过叠加，量子计算机可以并行执行任务，不需要完全并行的架构或GPU来处理并行计算任务。这是因为如果每个叠加态对应于不同的值，如果叠加态被作用，那么该作用在所有状态上同时执行。</p><p id="3ec3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">叠加量子态的一个例子如下:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/6ffdc94fcf895cbe9c1f86d145b5bd83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*w03eLPB1jmLEdOvHcY2U8A.png"/></div></figure><p id="927a" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">和<strong class="kz ir"> a </strong>和<strong class="kz ir"> b </strong>指的是概率幅度，其给出了一旦执行测量就投射到一个状态的概率。叠加量子态是通过使用量子逻辑门产生的。如果Bra-ket符号对你来说是新的，那么强烈推荐Perry的量子计算的<em class="mr">圣殿。</em></p><h1 id="e171" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">纠缠的简要介绍</h1><p id="68d1" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">正如叠加是量子物理中的一个重要原理一样，另一个要讨论的关键领域是纠缠。纠缠是指在两个或多个粒子之间产生或导致相互作用的行为，这意味着这些粒子的量子状态不再能够彼此独立地描述，即使当<a class="ae kw" href="https://www.ofcom.org.uk/__data/assets/pdf_file/0013/222601/Executive-Summary.pdf" rel="noopener ugc nofollow" target="_blank">相隔很远</a>时也是如此。当粒子变得纠缠时，如果一个粒子被测量，那么与之纠缠的另一个粒子将测量为相反的状态，瞬间(这些粒子没有局域态)。</p><h1 id="434e" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">纠缠——贝尔态</h1><p id="8e19" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">随着对量子位和纠缠的理解，现在可以讨论贝尔态了。这些是量子比特的最大纠缠态，它们是:</p><p id="b837" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi">|00⟩ → β → 1 √ 2 (|00⟩ + |11⟩) = |β00⟩,</p><p id="1803" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi">|01⟩ → β → 1 √ 2 (|01⟩ + |10⟩) = |β01⟩</p><p id="831f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi">|10⟩ → β → 1 √ 2 (|00⟩ − |11⟩) = |β10⟩</p><p id="6902" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi">|11⟩ → β → 1 √ 2 (|01⟩ − |10⟩) = |β11⟩</p><p id="e36f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">贝尔态是由以下量子电路产生的:</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/199cd088192741cc8343fde143b7d7a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*l6kyAkjsimtlxmvPMAZ9eQ.png"/></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><em class="kf">贝尔态电路来自佩里的量子计算圣殿。</em></p></figure><p id="e907" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这里显示了一个贝尔态电路，它接受量子位输入，并应用哈达玛和CNOT门来创建一个纠缠的贝尔态。</p><p id="f156" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">虽然理解不同的量子门超出了本文的范围，但是考虑到旋转和CNOT门将作为QCNNs部分的一部分来讨论，建议使用指南的<a class="ae kw" href="https://qiskit.org/textbook/ch-states/single-qubit-gates.html.." rel="noopener ugc nofollow" target="_blank">。</a></p><p id="6710" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">贝尔态已经被用来开发一系列的量子计算应用。例如，<a class="ae kw" href="https://arxiv.org/abs/1402.6219" rel="noopener ugc nofollow" target="_blank"> Hegazy、Bahaa-Eldin和Dakroury已经从理论上证明了贝尔态和超密集编码可以用来获得“无条件安全”。</a></p><h1 id="6d53" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">经典深度学习:卷积神经网络</h1><p id="2cff" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">随着对量子计算的介绍，我们现在将讨论深度学习的经典方法，特别是卷积神经网络(CNN)。</p><p id="eb08" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">正如Franç ois Chollet在<em class="mr">用Python进行深度学习</em>中指出的那样，卷积神经网络(CNN)已被证明在图像分类等任务中很受欢迎，因为它们能够建立模式的层次结构，例如首先表示线条，然后表示这些线条的边缘。这允许CNN建立在层之间的信息上，并表示复杂的视觉数据。</p><p id="056e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CNN有卷积层，它由过滤器组成，过滤器“滑过”输入并产生一个<a class="ae kw" href="https://books.google.co.uk/books/about/Practical_Convolutional_Neural_Networks.html?id=v3XyvQEACAAJ&amp;redir_esc=y" rel="noopener ugc nofollow" target="_blank">“特征图”，允许检测输入中的模式</a>。CNN还使用池层来减少特征图的大小，从而减少学习所需的资源。关于这方面的更多信息，<a class="ae kw" href="https://arxiv.org/abs/2009.09423" rel="noopener ugc nofollow" target="_blank">哦，崔和金的2020年CNN指南被强烈推荐</a>。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mt"><img src="../Images/3bdc289a970d1192267358bdff457bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rlPZACzcdDKPFghneQ2-xQ.gif"/></div></div><p class="ks kt gj gh gi ku kv bd b be z dk translated"><a class="ae kw" href="https://commons.wikimedia.org/wiki/File:Convolutional_Neural_Network_NeuralNetworkFeatureLayers.gif" rel="noopener ugc nofollow" target="_blank"> Cecbur </a>所示的卷积神经网络(CNN)</p></figure><h1 id="bfb5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">量子卷积神经网络——一个混合网络例子</h1><p id="126a" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">回到手头的主题，定义了经典CNN，现在可以探索量子CNN如何利用这些传统方法并扩展它们。Garg和Ramakrishnan发现，开发量子神经网络的一种常见方法是开发一种“混合”方法，引入所谓的“量子层，一种基于随机量子电路的变换，作为经典CNN的附加组件”。</p><p id="eb8d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这一节中，我们将讨论由<a class="ae kw" href="https://arxiv.org/abs/2107.03630" rel="noopener ugc nofollow" target="_blank"> Lü等人</a>开发并在MNIST手写数字数据集上测试的混合QCNN。对于他们的混合QCNN，<a class="ae kw" href="https://arxiv.org/abs/2107.03630" rel="noopener ugc nofollow" target="_blank"> Lü等人，</a>在他们2021年的论文中，使用量子电路和纠缠作为经典模型的一部分来获取输入图像，然后生成预测作为输出。</p><p id="31bb" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在这种方法中，量子卷积神经网络(QCNN)将图像数据作为输入，并将其编码为量子态<strong class="kz ir"> |x &gt; </strong>，然后进行转换，并使用量子卷积层和池层提取特征(Lü等人，2021)。</p><p id="c5d3" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最后，使用强纠缠电路的全连接层用于执行分类，并通过测量获得预测(Lü等人，2021)。</p><p id="fba5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">用于减少训练数据标签和由QCNN预测的标签之间的差异的优化由随机梯度下降(SGD)处理。关注量子电路，量子卷积层中使用的门如下所示，结合了旋转和CNOT门运算符。</p><p id="0c6d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">在汇集层，测量量子位的子集，然后得出的结果决定是否对它们的邻居应用单量子位门:</p><p id="3c2c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">全连接层由“通用单量子比特量子门”和产生纠缠态的CNOT门组成。为了将QCNN与其他方法进行比较，Lü等人使用了MNIST数据集和模拟的QCNN。按照典型方法，创建了一个训练/测试数据集，并开发了一个由以下层组成的QCNN:</p><ul class=""><li id="f8f7" class="mu mv iq kz b la lb ld le lg mw lk mx lo my ls mz na nb nc bi translated">2个量子卷积层</li><li id="ac77" class="mu mv iq kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated">2个量子池层</li><li id="13da" class="mu mv iq kz b la nd ld ne lg nf lk ng lo nh ls mz na nb nc bi translated">1量子全连接层</li></ul><p id="1fe7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">该QCNN对数据集的测试集准确率达到了96.65%。相比之下，根据代码为的<a class="ae kw" href="https://paperswithcode.com/sota/image-classification-on-mnist" rel="noopener ugc nofollow" target="_blank">论文，这个数据集的最高准确率为99.91%。然而，值得注意的是，对于这个实验，只有两类MNIST数据集被分类，这意味着与其他MNIST模型性能的全面比较是有限的。</a></p><h1 id="0dc2" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">评估QCNNs的可行性</h1><p id="e091" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">虽然Lü等人的研究人员已经开发了量子CNN的方法，但该领域的一个关键挑战是实现理论模型所需的<a class="ae kw" href="https://arxiv.org/pdf/2005.04316.pdf" rel="noopener ugc nofollow" target="_blank">硬件还不可用</a>。除此之外，还有与混合方法特别相关的挑战，混合方法在经典计算方法的基础上引入了量子层。</p><p id="f15d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果我们认为量子计算的一个关键好处是，它可以通过计算成本更低的技术来解决“经典的棘手问题”，这些解决方案的一个重要方面是“量子加速”:当探索量子机器学习的好处时，Phillipson (2020)提出，与经典实现相比，预计量子算法将<a class="ae kw" href="http://ceur-ws.org/Vol-2561/paper5.pdf" rel="noopener ugc nofollow" target="_blank">具有多项式甚至指数加速时间</a>。然而，Lü等人的方法的局限性在于，对于需要经典数据和测量的一致解码/编码的算法，例如QCNN,“量子加速”增益是有限的。阿伦森和<a class="ae kw" href="https://arxiv.org/abs/1904.04767" rel="noopener ugc nofollow" target="_blank">亨德森等人</a>对此进行了讨论。，在他们各自的论文中。目前，关于如何最好地设计编码/解码和需要最小测量的协议以受益于“量子加速”的信息有限。</p><p id="21c9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">更一般地，纠缠已经被证明是量子机器学习的一个重要属性。Lü等人提出的QCNN利用强纠缠电路，可以产生纠缠态作为其全连接层，允许模型进行预测。纠缠已经在其他地方被用来帮助深度学习模型，例如<a class="ae kw" href="https://www.frontiersin.org/articles/10.3389/fams.2021.716044/full" rel="noopener ugc nofollow" target="_blank">刘等人利用纠缠</a>从图像中提取重要特征。此外，Sharma等人<a class="ae kw" href="https://arxiv.org/abs/2007.04900" rel="noopener ugc nofollow" target="_blank">发现，在数据集中使用纠缠可能意味着模型能够从比之前预期的更小的训练数据集中学习</a>，从而完善了所谓的“没有免费的午餐”定理。</p><h1 id="00c2" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">关于QCNNs的结论</h1><p id="353e" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">在这篇文章中，提供了经典和量子深度学习方法的比较，以及利用量子层(包括强纠缠电路)来生成预测的QCNN的概述。量子深度学习的好处和局限性已经讨论过了，包括纠缠在机器学习中更普遍的应用。</p><p id="a8ef" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">考虑到这一点，现在可以考虑量子深度学习的下一步，特别是QCNNs。Garg和Ramakrishnan发现，除了图像识别，量子方法已经开始用于自然语言处理(NLP)等领域，例如<a class="ae kw" href="https://arxiv.org/abs/1811.03275v1" rel="noopener ugc nofollow" target="_blank"> Galofaro等人检测仇恨言论的工作</a>。</p><p id="3a55" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">与此同时，我们也看到了量子硬件的进步，像<a class="ae kw" href="https://www.forbes.com/sites/moorinsights/2022/09/21/psiquantum-has-a-goal-for-its-million-qubit-photonic-quantum-computer-to-outperform-every-supercomputer-on-the-planet/?sh=16f56ea18db3" rel="noopener ugc nofollow" target="_blank"> PsiQuantum这样的公司致力于开发百万量子位量子处理器</a>。因此，尽管我们已经看到了与应用量子神经网络相关的挑战，但随着研究在深度学习和量子计算的“交界处”继续进行，我们可以期待看到量子深度学习的进一步发展。</p><h1 id="e972" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">相关资源</h1><p id="5015" class="pw-post-body-paragraph kx ky iq kz b la ml jr lc ld mm ju lf lg mn li lj lk mo lm ln lo mp lq lr ls ij bi translated">对于那些感兴趣的人，提供了一个关于相关量子计算和深度学习资源的小型参考书目，以及文章中的链接。</p><p id="1c90" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Aaronson，S. (2015)“阅读小字”，《自然物理学》，11(4)，第291–293页。doi: 10.1038/nphys3272。</p><p id="571b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">比亚蒙特，j .等人..(2017)《量子机器学习》，Nature，549(7671)，第195–202页。doi: 10.1038/nature23474。</p><p id="381c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Chollet，(2021年)。用Python进行深度学习。第二版。庇护岛(纽约，Estados Unidos):曼宁。</p><p id="bb4f" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Ganguly和t . Cambier，2021年。量子计算与Silq编程。打包。</p><p id="b1f6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Garg，s .和Ramakrishnan，G. (2020)量子深度学习的进展:概述，arXiv.org。地点:【https://arxiv.org/abs/2005】T2。</p><p id="2341" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Hegazy，o .，Bahaa-Eldin，a .和Dakroury，Y. (2014年)使用纠缠和超密集编码的量子安全直接通信，arXiv.org。地点:【https://arxiv.org/abs/1402.6219 T4】</p><p id="afc6" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Henderson，m .等人，(2019)量子神经网络:用量子电路为图像识别提供动力，arXiv.org。上市地点:<a class="ae kw" href="https://arxiv.org/abs/1904.04767" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1904.04767</a></p><p id="b1a7" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Karn，U. (2016)卷积神经网络的直观解释— KDnuggets。可从以下网址获得:<a class="ae kw" href="https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2016/11/intuitive-explain-convolutionary-neural-networks . html</a></p><p id="e208" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">刘，杨等，(2021)“基于纠缠的张量网络机器学习特征提取”，应用数学与统计前沿，7。doi: 10.3389/fams.2021.716044。</p><p id="e11e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">吕，y .等人，(2021)用于图像分类的量子卷积神经网络，arXiv.org。可在:<a class="ae kw" href="https://arxiv.org/abs/2107.03630" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2107.03630</a>买到。</p><p id="1078" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">北达科他州梅塔，2020年。量子计算。【S.l .】:实用主义书架。</p><p id="6050" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Ofcom，(2021)量子通信:未来通信的新潜力可从以下网址获得:<a class="ae kw" href="https://www.ofcom.org.uk/__data/assets/pdf_file/0013/222601/Executive-Summary.pdf" rel="noopener ugc nofollow" target="_blank">https://www . ofcom . org . uk/_ _ data/assets/pdf _ file/0013/222601/Executive-summary . pdf</a></p><p id="42e9" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Oh，s .，Choi，j .和Kim，J. (2020)量子卷积神经网络教程(QCNN)，arXiv.org。地点:【https://arxiv.org/abs/2009.09423 T2】</p><p id="888d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">s . pattanayak(2021年)。使用Python的量子机器学习:使用来自Google Research和IBM Qiskit的Cirq。阿普瑞斯。</p><p id="8c1e" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">菲利普森，F (2020)。量子机器学习:好处和实例。地点:【http://ceur-ws.org/Vol-2561/paper5.pdf T4】</p><p id="0fd4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">T. R .佩里(2004年)。量子计算的殿堂:1.1版—2006年4月29日。莱利·t·佩里。</p><p id="5ae8" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Sewak，Karim，Pujari，P .(2018年)。实用卷积神经网络。伯明翰:Packt。</p><p id="7232" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Sharma，k .等人(2022) <em class="mr"> </em>“纠缠数据集的无免费午餐定理的重新表述”，《物理评论快报》，128(7)。doi:10.1103/physrevlett . 128.070501。</p><p id="2206" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">Voorhoede，D. (2022)叠加和纠缠，量子激励。可从以下网址获得:<a class="ae kw" href="https://www.quantum-inspire.com/kbase/superposition-and-entanglement/" rel="noopener ugc nofollow" target="_blank">https://www . quantum-inspire . com/kbase/叠加和纠缠/ </a></p></div></div>    
</body>
</html>