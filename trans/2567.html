<html>
<head>
<title>The Bible under the NLP eye (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NLP眼中的圣经(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-bible-under-the-nlp-eye-part-2-df2559cdae5f#2022-06-03">https://towardsdatascience.com/the-bible-under-the-nlp-eye-part-2-df2559cdae5f#2022-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ced0" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们的NLP探索的第二部分:通过TF-IDF和transfomers的主题建模、单词嵌入和文本相似性</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/a22fe38e65c03f259f85361d864925de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LXVK-Foa1Tigc4E2GYEyFA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">西蒙·伯杰在<a class="ae ky" href="https://unsplash.com/photos/twukN12EN7c" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的图片</p></figure><p id="ffd7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">欢迎回到NLP世界的介绍。如果您错过了NLP介绍的第一部分，请单击此处:</p><div class="lv lw gp gr lx ly"><a rel="noopener follow" target="_blank" href="/the-bible-under-the-nlp-eye-part-1-416dbfd79444"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">NLP眼中的圣经(上)</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">有趣的数据科学项目的第一部分，学习更多关于文本处理、NLP技术和提取…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">towardsdatascience.com</p></div></div><div class="mh l"><div class="mi l mj mk ml mh mm ks ly"/></div></div></a></div><p id="11f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">今天我们将探索新的自然语言处理工具，来分析圣经:</p><ul class=""><li id="c5cd" class="mn mo it lb b lc ld lf lg li mp lm mq lq mr lu ms mt mu mv bi translated">主题建模:从文档(圣经书籍)到主题</li><li id="90a2" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">单词嵌入:如何获得嵌入，我们能从这种方法中得到什么信息？</li><li id="e146" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">文本相似性:福音书之间有多相似？我们可以使用什么技术来检测相似性，文本相似性意味着什么？</li></ul><p id="9cda" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/the-bible-under-the-nlp-eye-part-1-416dbfd79444#8a62">在这里</a>你可以找到每个主题所需的所有软件包——更多软件包将在文章中给出。当<a class="ae ky" rel="noopener" target="_blank" href="/the-bible-under-the-nlp-eye-part-1-416dbfd79444#9c99">在这里</a>时，我已经为原始数据定义了预处理和清理代码</p><h2 id="a274" class="nb nc it bd nd ne nf dn ng nh ni dp nj li nk nl nm lm nn no np lq nq nr ns nt bi translated">主题建模</h2><p id="c136" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">数据科学家通常采用主题建模来从非结构化数据中获得洞察力，检索关键和简明的信息(例如，评论、医疗文档、机器信息、元数据)。在商业中有无数的主题建模的例子，从总结评论到在客户电话中发现商业问题。具体来说，有两个主要的主题建模策略:1)非负矩阵分解(NMF)——<a class="ae ky" rel="noopener" target="_blank" href="/practical-cython-music-retrieval-non-negative-matrix-factorisation-fd4b2ce65457">这是我关于NMF及其实现的文章</a>——以及2)潜在狄利克雷分配(LDA)。</p><p id="23b2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本教程中，我们将使用LDA。LDA的根源在于2003年的一篇论文(是的19年前！)发表在《机器学习研究杂志》上，作者大卫·布雷、吴恩达和迈克尔·乔丹——三位伟大的人工智能/人工智能作者。我将写一篇关于这种技术的文章，因为我喜欢它，但是，我很乐意让你抓住LDA工作的这个基本概念:<em class="nz">可交换性</em>。可交换性是一个简单的数学假设，1985年和1990年的论文。根据意大利Guido De Finetti定理，任何可交换随机变量的集合都可以表示为混合分布。简而言之，我们可以在不考虑文档中单词顺序的情况下建立主题模型。有了这个定理，我们可以通过混合分布捕获重要的文档内统计结构。</p><p id="09c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们从旧约开始，通过像我们在第一个教程中所做的那样清理和分组所有的书<a class="ae ky" href="https://gist.github.com/Steboss89/73e1f3bbf1a62403ccad53f7e63a6581#file-cleaning_2-py" rel="noopener ugc nofollow" target="_blank">，让我们看到所有书的主题。图1显示了对旧约全书执行LDA的工作流。</a></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图1:根据旧约全书搜索LDA的函数和参数。</p></figure><p id="4ccf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，在第60行，我们对每本书执行一个<code class="fe oc od oe of b">gensim.utils.simple_preprocess</code>,它被视为一个唯一的字符串/句子。其次，我们将创建一个字典，其中有一个单词索引映射(例如，单词<code class="fe oc od oe of b">allowed</code>在LDA算法中表示为<code class="fe oc od oe of b">0</code>)。一旦映射<code class="fe oc od oe of b">id2word</code>我们就可以创建一个“单词袋”，字面意思就是装满单词的袋子。<code class="fe oc od oe of b">corpus</code>返回每个文档中每个单词的出现频率。最后，我们用<code class="fe oc od oe of b">gensim </code>到<code class="fe oc od oe of b">gensim.models.ldamodel.LdaModel</code>运行LDA算法</p><p id="30a3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们花一点时间来看看我们是如何运行LDA的。LDA理论清楚地表明，我们需要给出我们期望的主题的输入数量。此外，我们还有一些其他超参数，例如，块大小和每次循环的迭代次数，循环次数。在这个例子中，我试图探索主题的数量和组块的大小，以找到最佳主题。然而，等一下，我们如何衡量一个成功的主题建模？嗯，我们有两个很好的指标可以帮助我们进行主题建模:<code class="fe oc od oe of b">perplexity</code>和<code class="fe oc od oe of b">coherence</code>。</p><p id="f4f2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">前一个度量是预测性度量，并且它与模型交叉熵相关联。<code class="fe oc od oe of b">perplexity</code>在训练集上训练后，评估模型预测测试集主题的良好程度。很难给这个分数一个正确的解释，通常越负面越好，但是已经证明<code class="fe oc od oe of b">perplexity</code>没有一个明确的人类解释。第二个指标，<code class="fe oc od oe of b">coherence</code>，通过测量主题的可解释性来帮助我们——在更人性化的意义上，通过测量主题中的单词与文档中的单词的相似度。作为一个建议，在所有这些中，总是需要一点点人类的解释，所以不要过分地用分数来偏见自己。</p><p id="aa30" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实上，这应该是你能得到的最好结果:</p><pre class="kj kk kl km gt og of oh oi aw oj bi"><span id="0a20" class="nb nc it of b gy ok ol l om on">Num Topic 4 and chunksize 20 Computing LDA with  4 topics, 20 chunksize... <br/>Writing classification onto csv file... <br/>Topic Keywords <br/>['lord, saith, land, god, israel, people, shalt, king, man, day'  'lord, israel, king, god, said, son, house, people, juda, jerusalem'  'god, man, lord, things, heart, good, wisdom, men, fear, soul'  'king, great, jews, us, men, kings, daniel, kingdom, came, day']</span></pre><p id="2fc8" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">正如你所看到的，前两个主题有着或多或少的相同含义，它们指的是应许之地，以色列或犹大家(或多或少在地理上)。第三个需要一点解释，它可能是指上帝的智慧以及人类应该如何敬畏上帝，或者是上帝和人类之间的相似性。最后是混合了<a class="ae ky" href="https://en.wikipedia.org/wiki/Daniel_(biblical_figure)" rel="noopener ugc nofollow" target="_blank">丹尼尔</a>的故事，以及有一天国王会到来的预言。</p><p id="4122" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们对新约也这样做:</p><pre class="kj kk kl km gt og of oh oi aw oj bi"><span id="ea92" class="nb nc it of b gy ok ol l om on">Num Topic 3 and chunksize 20 Computing LDA with 3 topics, 20 chunksize… <br/>Writing classification onto csv file… <br/>Topic Keywords <br/>[‘said, jesus, man, god, things, come, therefore, lord, came, say’ ‘god, christ, also, things, jesus, may, lord, faith, sin, according’ ‘god, earth, great, seven, angel, beast, heaven, voice, throne, come’] </span><span id="db90" class="nb nc it of b gy oo ol l om on">Perplexity -7.394623212885921 Coherence 0.4202057333015461</span><span id="c639" class="nb nc it of b gy oo ol l om on"><br/>Num Topic 4 and chunksize 50 Computing LDA with 4 topics, 50 chunksize… <br/>Writing classification onto csv file… <br/>Topic Keywords <br/>[‘said, jesus, god, man, lord, things, come, came, saying, say’ ‘god, christ, also, things, lord, jesus, man, may, faith, according’ ‘god, earth, great, seven, come, heaven, angel, saying, things, beast’ <br/>‘god, christ, sin, law, faith, jesus, son, also, spirit, things’] </span><span id="f754" class="nb nc it of b gy oo ol l om on">Perplexity -7.347456308975332 Coherence 0.3708218577493271</span><span id="3e02" class="nb nc it of b gy oo ol l om on"><br/>Num Topic 5 and chunksize 50 Computing LDA with 5 topics, 50 chunksize… <br/>Writing classification onto csv file… <br/>Topic Keywords <br/>[‘said, jesus, god, man, lord, things, come, came, saying, also’ ‘god, christ, also, things, lord, jesus, man, may, faith, according’ ‘god, earth, great, seven, come, heaven, angel, saying, things, beast’ <br/>‘god, christ, sin, law, spirit, jesus, faith, also, son, world’ ‘jesus, things, god, christ, may, men, saviour, good, also, lord’] </span><span id="b99c" class="nb nc it of b gy oo ol l om on">Perplexity -7.353096888524062 Coherence 0.3734882570283872</span></pre><p id="7185" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如您所见，许多主题相互重叠。我个人认为3个主题足以区分所有的新约主题。前者<code class="fe oc od oe of b">said, jesus,man, god, things, come, therefore, lord, came say</code>指耶稣的寓言；第二个话题<code class="fe oc od oe of b">god, christ, also, things, Jesus, may, lord, faith, sin, according</code>可能是指对上帝的信仰和耶稣为人类的罪所做的牺牲；最后一个话题指的是天启<code class="fe oc od oe of b">god, earth, great, seven, angel, beast, heaven, voice, throne, come</code></p><p id="a638" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总之，主题建模是理解文档中引入的关键词和主题的一种很好的技术。我们不能用一种简单的方式来衡量主题的正当性，但是我们必须采用<code class="fe oc od oe of b">perplexity</code>和<code class="fe oc od oe of b">coherence</code>，无论如何，如果没有足够的人类解释，这是不够的。从旧约和新约，从应许之地到启示录，衍生出三个主题。我们能做更多来整合主题建模吗？当然，我们可以在单词嵌入上运行主题建模——我会把这个练习留给你来解决:)</p><h2 id="bbf9" class="nb nc it bd nd ne nf dn ng nh ni dp nj li nk nl nm lm nn no np lq nq nr ns nt bi translated">单词嵌入</h2><p id="8fff" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">现在让我们来看一些更复杂的东西:单词嵌入。许多(显然)单词和文章都花在了单词嵌入上。简而言之，单词嵌入允许我们将多维单词、句子和文档简化为人类可解释的含义和计算有效的向量。一个向量可以有大量的维度，但是当所有的单词都投影到向量上时，就有可能将它们聚集在不同的类别中，从而解决并大大简化真正的大规模问题，并找到单词之间的有趣关系。</p><p id="fff5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于单词嵌入，我们需要以下附加包:</p><pre class="kj kk kl km gt og of oh oi aw oj bi"><span id="c633" class="nb nc it of b gy ok ol l om on">from sklearn.manifold import TSNE<br/>from collections import Counter<br/>from six.moves import cPickle<br/>import gensim.models.word2vec as w2v<br/>import numpy as np<br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>import multiprocessing<br/>import os<br/>import sys<br/>import io<br/>import re<br/>import json<br/>import nltk<br/>nltk.download('punkt')</span></pre><p id="7fe3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然后，我们将计算嵌入并创建一个<code class="fe oc od oe of b">w2v</code>文件来保存来自<code class="fe oc od oe of b">gensim.w2v.Word2Vec</code>的二进制单词嵌入</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图2:使用gensim word2vec函数从一系列文档中计算给定文本的单词嵌入表示。在这种情况下，我们正在处理新约全书</p></figure><p id="42a1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们想把这个多维向量形象化。一种常用的方法是使用<em class="nz"> t分布随机邻居嵌入</em>或<em class="nz"> t-sne，</em>这是一种非线性降维技术。下面的代码将给我们一个在2D嵌入向量的单词:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图3: T-SNE函数表示二维的单词嵌入。最初，t-sne是基于单词嵌入表示来计算的。然后检索最频繁的单词并收集最相似/相关的单词。最终的图表显示了一个单词与其他单词的关联程度</p></figure><p id="04b1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">代码很长，所以我们要做的是:</p><ul class=""><li id="0c7c" class="mn mo it lb b lc ld lf lg li mp lm mq lq mr lu ms mt mu mv bi translated">首先，我们通过带有<code class="fe oc od oe of b">calculate_t_sne</code>的t-sne减少二维的单词嵌入，产生<code class="fe oc od oe of b">x_coords, y_coords</code>和<code class="fe oc od oe of b">labels</code>(它们是单词)</li><li id="d81c" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">我们用<code class="fe oc od oe of b">Counter().most_common()</code>计算单词的频率</li><li id="a6bf" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">对于前50个最常用的单词，我们将通过<code class="fe oc od oe of b">most_similar</code>检查这些单词是如何与word2vec词汇表中的其他单词向量相关联的。最终，我们为50个最常用的单词返回一系列列表，并为每个单词返回相关的单词。</li><li id="8ea5" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">在这一步之后，我们将这一系列列表转换为t-sne空间中的x和y坐标，并绘制最终结果。</li></ul><p id="52ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我看来，图4显示了word2vec的全部力量，我们可以清楚地看到摩西之间的正确联系。我们有<code class="fe oc od oe of b">Sinai</code>、<code class="fe oc od oe of b">Commandment</code>、<code class="fe oc od oe of b">Observance</code>(至十诫)、<code class="fe oc od oe of b">Pharaoh</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/825e4ad61ae1e653dbdf5abef44ad92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyHlDpOVeVZT1tRWuf60YQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图4:圣经中单词嵌入的t-sne图。在这种情况下，摩西与他故事的所有元素都有关联</p></figure><p id="eb43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图5显示了单词Death的另一个特殊的单词嵌入。我们可以看到<code class="fe oc od oe of b">Life</code>处于完全相反的位置，而在它们之间有<code class="fe oc od oe of b">revenge</code>、<code class="fe oc od oe of b">crimes</code>、<code class="fe oc od oe of b">sickness</code>、<code class="fe oc od oe of b">danger</code>和<code class="fe oc od oe of b">confusion</code></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/6996563c63778254bc8eabf6d8bff99c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gG4QuE5PFSkDPZiQjMtiwQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图5:圣经中单词嵌入的t-sne图。在这种情况下，死亡与他的故事的所有元素相关联</p></figure><p id="8ccc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图6是我们用word2vec得到的信息的最后一个例子，单词<code class="fe oc od oe of b">evil</code>在相反的方向，我们将得到<code class="fe oc od oe of b">hope</code>，有趣的是看到邪恶在整个圣经中是如何联系在一起的。邪恶是错误的，它与疾病、邪恶和虚荣联系在一起。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/cffe52bbdd0690aa91ba124315c12d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*anAwxmc2aIrLvdWAGlLV7Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图6:圣经中单词嵌入的t-sne图。在这种情况下，邪恶与他的故事的所有元素相关联</p></figure><p id="d408" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">总而言之，单词嵌入可以给你单词间隐藏的联系。在真实的场景中，单词可以是评论、产品、搜集的数据，你可以通过嵌入建立重要的联系。此外，单词嵌入可以而且应该与主题建模一起使用，以进一步利用单词关联来发现更多可解释的主题。</p><h1 id="23ef" class="oq nc it bd nd or os ot ng ou ov ow nj jz ox ka nm kc oy kd np kf oz kg ns pa bi translated">文本相似度</h1><p id="0c06" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated"><a class="ae ky" href="https://en.wikipedia.org/wiki/Synoptic_Gospels#/media/File:Relationship_between_synoptic_gospels-en.svg" rel="noopener ugc nofollow" target="_blank">圣经最受讨论的一个方面是书籍</a>的重叠和相似，尤其是福音书。事实证明，马可福音76%的内容是在马太福音和路加福音中共享的。此外，马太和路加分享了大约50%的内容。稍有不同的是约翰福音，它是在将近100年后写成的，写作风格与天气福音相去甚远。</p><p id="0640" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">您可以尝试的第一种文本相似性方法是运行<em class="nz">术语频率-逆文档频率</em>或TF-IDF。在这种方法中，我们将考虑整个语料库中的词的频率，而不是单个文档(例如，整个圣经而不是单本书)。关键是，在任何地方出现次数多的词，意义会低，而出现次数少的词，可能有意义。TF-IDF的实现用<code class="fe oc od oe of b">scikit-learn</code>很简单，如图7所示</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图7:sci kit-learn中的TF-IDF实现。这里的数据是一个dataframe，其中每一列都有一篇福音书(约翰福音、路加福音、马可福音和马太福音)</p></figure><p id="8e66" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里的<code class="fe oc od oe of b">data</code>是一个熊猫数据框架，每一列都是一个福音。文本通过<code class="fe oc od oe of b">TfidfVectorizer</code>处理，最后通过<code class="fe oc od oe of b">cosine_similarity</code> ig计算相似度。记住，当你想测量向量之间的相似程度时，余弦相似度是最好的方法。图8显示了四个福音的相似性结果。正如你所看到的，这个情节强烈地指向天气福音的相似性有多强，通过一点计算能力，我们已经对4本主要的圣经书籍有了一个很好的看法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/6faad2695b984c8901ee4a57f5540321.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xE1uFxgSHvFfWMxRtK9w8g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图8:用TF-IDF方法分析四个福音的余弦相似性。我们用一种简单的方法复制了最初在圣经研究中发现的东西</p></figure><p id="100f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这很好，但我们可以尝试做得更多，分析每本书的上下文内容。使用句子转换器可以实现更精确的方法。在这里，我们可以引用大量的模型，其中最著名的是BERT和Sentence-BERT (SBERT ),它是由一个暹罗网络组成的，用于导出句子嵌入。这里我们不仅要看文本的相似性，还要看上下文的相似性。图9显示了实现，由于<code class="fe oc od oe of b">sentence_transformers</code>包包含了我们想要的所有相关变压器，所以实现非常简单。我们选择<code class="fe oc od oe of b">stsb-roberta-large</code>作为要使用的转换器，并对我们拥有的输入数据进行编码。最后，正如我们之前所做的，相似性是用余弦相似性来度量的。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oa ob l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图9:通过sentence_transformers包实现roberta transformer，并测量4部福音书的相似性。</p></figure><p id="56d7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">图10显示了用Roberta和wow获得的结果！，在这里我们获得了新的有趣的信息。我们知道，约翰福音和路加福音的基调与马太福音和马可福音相去甚远，这两部福音书是最早写成的。因此，在上下文层面上，这两部福音书可能有更多的相似之处，出现了其他福音书中没有出现的词汇和概念。看到所有其他福音在上下文层面上彼此大相径庭，真的很有趣。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/fe5ee653b4059995f5e70077bb533c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vzu7LEFNh78KUvChS3vpbQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图10:四部福音书中变形金刚的上下文层次分析。有趣的是乔恩和卢克有很高的上下文相似性，这可能与写作风格有关。</p></figure><h1 id="874e" class="oq nc it bd nd or os ot ng ou ov ow nj jz ox ka nm kc oy kd np kf oz kg ns pa bi translated">第二部分的结论</h1><p id="5139" class="pw-post-body-paragraph kz la it lb b lc nu ju le lf nv jx lh li nw lk ll lm nx lo lp lq ny ls lt lu im bi translated">那么，做得好，这是我们的2部分教程的结束。让我们回顾一下今天的内容:</p><ul class=""><li id="acbf" class="mn mo it lb b lc ld lf lg li mp lm mq lq mr lu ms mt mu mv bi translated">我们学习了什么是主题建模，以及LDA建模的关键数学点是什么:可交换性</li><li id="a1f5" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">我们可以做更多的工作来理解单词的含义，并将主题建模中的信息与单词嵌入相结合</li><li id="13c2" class="mn mo it lb b lc mw lf mx li my lm mz lq na lu ms mt mu mv bi translated">我们可以用TF-IDF这样的简单技术来测量文档之间的文本相似性，或者，如果我们想在上下文层次上研究相似性，我们可以使用奇妙的sentence_transformers库并旋转一个transformer来测量文本相似性。</li></ul><p id="7b9d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">从这两个教程中，你肯定学到了很多很多技术，这些技术在你每次开始一个新的NLP/text项目时都会有用。我希望您喜欢这一切，并在下一篇文章中尽快见到您:)</p></div><div class="ab cl pd pe hx pf" role="separator"><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi pj"/><span class="pg bw bk ph pi"/></div><div class="im in io ip iq"><p id="022a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nz">通过我的推荐链接加入Medium来支持我的写作和项目:</em></p><div class="lv lw gp gr lx ly"><a href="https://stefanobosisio1.medium.com/membership" rel="noopener follow" target="_blank"><div class="lz ab fo"><div class="ma ab mb cl cj mc"><h2 class="bd iu gy z fp md fr fs me fu fw is bi translated">通过我的推荐链接加入Medium-Stefano Bosisio</h2><div class="mf l"><h3 class="bd b gy z fp md fr fs me fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="mg l"><p class="bd b dl z fp md fr fs me fu fw dk translated">stefanobosisio1.medium.com</p></div></div><div class="mh l"><div class="pk l mj mk ml mh mm ks ly"/></div></div></a></div><p id="de37" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果有任何问题或意见，请随时给我发电子邮件，地址是:stefanobosisio1@gmail.com，或者直接在Medium这里。</p></div></div>    
</body>
</html>