<html>
<head>
<title>Generating Synthetic Data to Train an OCR Learning Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成合成数据以训练OCR学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-synthetic-data-to-train-an-ocr-learning-algorithm-4889f443fe92#2022-05-16">https://towardsdatascience.com/generating-synthetic-data-to-train-an-ocr-learning-algorithm-4889f443fe92#2022-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ba1a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">编码和解释合成数据生成的过程，以提高OCR学习算法的准确性</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/097323fe4fa5e5011f0ac5c29900bbe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*COg3GcsFit4BdSqyO1PgRA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">数据扩充的效果。来源:作者。</p></figure><p id="ff11" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">提高低偏差学习算法性能的最可靠方法之一是在大量数据上对其进行训练。尽管获取额外数据的过程看起来可能是一项昂贵的努力，但存在一种令人着迷的技术，允许机器学习从业者生成潜在的无限量的人工数据:<a class="ae lr" href="https://en.wikipedia.org/wiki/Synthetic_data" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">人工数据合成</strong> </a>。</p><p id="1922" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我将展示用于生成合成数据的技术，并将它应用于一个众所周知的<a class="ae lr" rel="noopener" target="_blank" href="/optical-character-recognition-with-knn-classifier-10fd220ed797">光学字符识别问题</a>。</p><h2 id="d541" class="ls lt iq bd lu lv lw dn lx ly lz dp ma le mb mc md li me mf mg lm mh mi mj mk bi translated">目录:</h2><ul class=""><li id="f3bd" class="ml mm iq kx b ky mn lb mo le mp li mq lm mr lq ms mt mu mv bi translated">人工数据合成</li><li id="8176" class="ml mm iq kx b ky mw lb mx le my li mz lm na lq ms mt mu mv bi translated">MNIST光学字符识别</li><li id="120c" class="ml mm iq kx b ky mw lb mx le my li mz lm na lq ms mt mu mv bi translated">生成人造图像</li><li id="f0f2" class="ml mm iq kx b ky mw lb mx le my li mz lm na lq ms mt mu mv bi translated">模型选择和培训</li><li id="ce32" class="ml mm iq kx b ky mw lb mx le my li mz lm na lq ms mt mu mv bi translated">评估数据扩充的效果</li></ul><h1 id="faf9" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">人工数据合成</h1><p id="69be" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">人工数据合成是以编程方式生成新数据实例的过程，这些数据实例有效地近似底层真实数据。真实数据可以定义为通过真实生活调查或直接测量收集的数据，而人工数据是作为计算机模拟的结果收集的。基本要求是模拟数据<a class="ae lr" href="https://research.aimultiple.com/synthetic-data-generation/" rel="noopener ugc nofollow" target="_blank">反映原始数据</a>的统计特性。截至目前，人工数据生成并不适合每一个机器学习问题，通常需要一定的创造力和洞察力才能将其应用于特定问题。</p><p id="3954" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这种做法可以分为两种截然不同的变化:</p><ul class=""><li id="63f8" class="ml mm iq kx b ky kz lb lc le np li nq lm nr lq ms mt mu mv bi translated">从头开始生成数据:我们没有任何数据，我们希望创建一个近似真实数据的训练集</li><li id="65d5" class="ml mm iq kx b ky mw lb mx le my li mz lm na lq ms mt mu mv bi translated">从小规模的训练集生成数据:我们已经拥有一些训练数据，但我们希望增加它的规模</li></ul><p id="4ab3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本文中，我将探讨后者，因为我已经可以访问数据集。</p><p id="9a10" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">人工数据合成的基本原理是多样化的。如介绍中所述，一个目标是增加训练规模，作为提高算法性能的手段。另一方面，可以执行相同的技术来<a class="ae lr" href="https://research.aimultiple.com/synthetic-data/" rel="noopener ugc nofollow" target="_blank">保护敏感数据</a>，例如个人身份信息(PII)或个人健康信息(PHI)。最后，合成数据在那些数据稀缺或收集成本高昂的应用中发挥着重要作用。这方面的一个例子是异常检测或欺诈检测:欺诈交易的样本很少，人为伪造它们可能很方便。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/2d4e6baad54ce88bc445ab0318a994d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/0*rG0U4bvDia5oj88W.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马和人的人造图像。来源:<a class="ae lr" href="https://developers.google.com/codelabs/tensorflow-5-compleximages#0" rel="noopener ugc nofollow" target="_blank">谷歌开发者</a></p></figure><p id="c6e5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">合成数据经常被用于开发计算机视觉中的学习模型，因为在一些情况下，用计算机生成的数据训练的算法在现实世界中也是有效的。这方面的一个应用由<a class="ae lr" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Mu_Learning_From_Synthetic_Animals_CVPR_2020_paper.pdf" rel="noopener ugc nofollow" target="_blank">的这篇研究论文</a>来表示，其中使用动物的CAD模型来训练学习模型。在这个谷歌开发者笔记本中提供了一个实际应用，其中一个模型用马和人的人工图像进行训练。</p><p id="a22a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后但同样重要的是，数据扩充在避免过度拟合方面带来了有益的效果。过度拟合模型意味着算法在处理某种类型的数据时变得非常出色，但是，如果我们要求模型处理稍微不同类型的数据，模型的性能将会迅速下降。解决这个问题的一个简单方法是在学习阶段向模型提供更多不同的数据。</p><p id="034a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑这个简单的二进制分类任务:识别狗和猫。如果在训练数据中，所有示例都表示站立或坐着的猫，则模型可能很难正确分类下蛋猫的图像，如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/58bdfd52de7f2032165310041c23f3a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*cyJr9y-yGlDXFOiOhze9vg.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">产卵猫。来源:<a class="ae lr" href="https://unsplash.com/photos/IAX2lziq8aw" rel="noopener ugc nofollow" target="_blank"> Unisplash </a></p></figure><p id="6e0d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个简单的解决方案是将训练集中的图像旋转90 °,使它们看起来像下蛋的猫。以这种方式，学习算法更有可能识别更广泛种类的猫图像的特征。</p><h1 id="f16f" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">MNIST光学字符识别</h1><p id="c87b" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">人工数据在像<a class="ae lr" href="https://en.wikipedia.org/wiki/Optical_character_recognition" rel="noopener ugc nofollow" target="_blank">光学字符识别</a> (OCR)这样的应用中尤其有益，在这些应用中，训练集的大小在模型的广义准确性中起着重要作用。出于这个原因，我想探索合成数据可以做些什么来提高基于<a class="ae lr" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>库的学习模型的性能。</p><p id="0a0c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">光学字符识别是一种能够将印刷或手写字符转换为机器可读文本的技术。许多OCR模型的训练基于MNIST数据集，这是一个手写数字的大型数据库。它包含70，000个28x28像素的灰度色图。</p><p id="9a9a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在<a class="ae lr" rel="noopener" target="_blank" href="/optical-character-recognition-with-knn-classifier-10fd220ed797">这篇文章</a>中，我开发了一个基于KNN分类器算法的简单数字识别学习模型。现在的目标是评估一个更大的训练集如何对模型的准确性有价值。</p><h1 id="6a08" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">生成人造图像</h1><p id="18e0" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">考虑到训练集由非常小的图像组成，它可以通过在4个主要方向(左、右、上、下)上移动每个图像1个像素来扩展。通过这种方式，原始数据集被复制了五份。用于图像数据扩充的其他技术是旋转、剪切、缩放、镜像等等。</p><p id="9dd7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">第一步是导入数据集并检查数据样本的外观。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="2b0f" class="ls lt iq nv b gy nz oa l ob oc"># Import the library<br/>from sklearn.datasets import fetch_openml</span><span id="93db" class="ls lt iq nv b gy od oa l ob oc"># Import the dataset<br/>mnist = fetch_openml('mnist_784', version = 1)<br/>mnist.keys()</span><span id="c51b" class="ls lt iq nv b gy od oa l ob oc"># Fetch the data<br/>X = mnist["data"].values<br/>y = mnist["target"].astype(np.uint8).values</span><span id="e692" class="ls lt iq nv b gy od oa l ob oc"># Define function to print the images<br/>def print_digit(index):<br/>  example = X[index]<br/>  example = example.reshape(28,28)<br/>  plt.imshow(example, cmap='viridis')<br/>  plt.axis('off')</span><span id="8822" class="ls lt iq nv b gy od oa l ob oc"># Give a look at some images<br/>print_digit(26)</span></pre><p id="a904" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">输出应该如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/faee8317c42d035b3f683c2fdbd87d73.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*NsCaOLanF7N5BQ_Vt4DYvw.png"/></div></figure><p id="da2f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在分割了训练集和测试集之后，我定义了数据扩充的函数。它将图像和定义移动方向和幅度的向量作为输入。移动的结果是，图像的一些像素将会是空白的。为了保持图像的原始形状，我们可以定义这些像素的填充方法。默认情况下，它们用0.0的浮点数填充。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="cac0" class="ls lt iq nv b gy nz oa l ob oc">from sklearn.model_selection import train_test_split<br/>from scipy.ndimage import shift</span><span id="9f5a" class="ls lt iq nv b gy od oa l ob oc"># Split train test set<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><span id="e63c" class="ls lt iq nv b gy od oa l ob oc"># Define function to shift an image by a given vector<br/>def shift_digit(img, vector, fill_with=0.0):<br/>  img = img.reshape(28,28)<br/>  img_shifted = shift(img, vector, cval=fill_with)<br/>  # Return unrolled image array<br/>  return img_shifted.flatten()</span></pre><p id="2b4d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们来看看将原图下移5个像素的效果。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="313c" class="ls lt iq nv b gy nz oa l ob oc">shift1 = shift_digit(X[26], (5,0))<br/>plt.imshow(shift1.reshape(28,28), cmap='viridis')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/45b6758df0d879758f6ab24c7b8407a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*wF7iXNgNn1IwIudzs7ltgw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">下移图像的效果。来源:作者。</p></figure><p id="9a87" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">接下来的步骤是获取训练集中的每幅图像，并在4个主要方向上移动1个像素。测试集保持不变。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="01f6" class="ls lt iq nv b gy nz oa l ob oc"># Convert dataset into lists<br/>X_train_augment = list(X_train)<br/>y_train_augment = list(y_train)</span><span id="1e00" class="ls lt iq nv b gy od oa l ob oc"># Loop through training images and shift them<br/>for (dx, dy) in ((1,0), (0,1), (-1,0), (0,-1)):<br/>  for image, label in zip(X_train, y_train):<br/>    row_shifted = shift_digit(image, (dx, dy))<br/>    # Append shifted image and label<br/>    X_train_augment.append(row_shifted)<br/>    y_train_augment.append(label)</span><span id="3e1c" class="ls lt iq nv b gy od oa l ob oc"># Convert back to np.array<br/>X_train_augment= np.array(X_train_augment)<br/>y_train_augment= np.array(y_train_augment)</span></pre><p id="a563" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">原始训练集包含56000个训练样本，扩充后的训练集包含280000个样本。</p><h1 id="eaf6" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">模型选择和培训</h1><p id="97ec" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">为了衡量人工数据合成的好处，我将使用2个随机森林分类器分别在原始集和扩充集上训练它们。然后，我将在相同的测试集上比较它们的准确度分数。</p><p id="be68" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于随机森林分类器的工作原理超出了本文的范围，我建议阅读本<a class="ae lr" rel="noopener" target="_blank" href="/understanding-random-forest-58381e0602d2#:~:text=The%20random%20forest%20is%20a,that%20of%20any%20individual%20tree.">介绍性指南</a>。简而言之，随机森林是决策树的集合。为了确保多样性，通常在训练集的不同随机子集上训练树(<a class="ae lr" href="https://scikit-learn.org/stable/modules/ensemble.html" rel="noopener ugc nofollow" target="_blank">有或没有替换</a>)。在多数投票后，随机森林考虑每个弱分类器的决定，并输出聚合预测。</p><p id="2fc7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于原始训练集和扩充集，我在相同的参数空间上执行交叉验证。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="01e4" class="ls lt iq nv b gy nz oa l ob oc">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import GridSearchCV</span><span id="81df" class="ls lt iq nv b gy od oa l ob oc"># Initialize the classifier<br/>clf = RandomForestClassifier(random_state=42)</span><span id="9d1d" class="ls lt iq nv b gy od oa l ob oc"># Definte the parameter space<br/>param_space = {'n_estimators': [100, 200], 'min_samples_split': range(2,8,2)}</span><span id="1ab1" class="ls lt iq nv b gy od oa l ob oc"># Find best parameters in the parameter space without augmentation<br/>grid_no_augment = GridSearchCV(clf, param_grid=param_space, scoring="accuracy", n_jobs=-1, cv=5, verbose=4)<br/>grid_no_augment.fit(X_train, y_train)</span><span id="24b5" class="ls lt iq nv b gy od oa l ob oc"># Find best parameters in the parameter space with augmentation<br/>grid_augment = GridSearchCV(clf, param_grid=param_space, scoring="accuracy", n_jobs=-1, cv=5, verbose=4)<br/>grid_augment.fit(X_train_augment, y_train_augment)</span></pre><h1 id="b49c" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">评估数据扩充的效果</h1><p id="b011" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">现在这两个模型都训练好了，我可以评估它们的准确性了。</p><pre class="kg kh ki kj gt nu nv nw nx aw ny bi"><span id="a715" class="ls lt iq nv b gy nz oa l ob oc">from sklearn.metrics import accuracy_score</span><span id="967d" class="ls lt iq nv b gy od oa l ob oc"># Get the models<br/>model_no_augment = grid_no_augment.best_estimator_<br/>model_augment = grid_augment.best_estimator_</span><span id="9ca4" class="ls lt iq nv b gy od oa l ob oc"># Evaluate the models accuracies<br/>accuracy_no_augment = accuracy_score(y_test, model_no_augment.predict(X_test))<br/>accuracy_augment = accuracy_score(y_test, model_augment.predict(X_test))</span></pre><p id="4982" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">结果显示，未经增强的准确率为96.8%，而基于增强数据训练的相同模型的准确率为97.8%。仅通过将训练集中的每幅图像移动1个像素，该模型的准确度就提高了整整1%。原因之一是模型变得不太容易过度适应训练集。</p><p id="1fb4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于最后一个分析，我将计算混淆矩阵，以了解哪些是最常见的分类错误。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/1c454fce420892d9af8ca735e1b3a1a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*hA40QfBR90bB8nk5-9jTmw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">混乱矩阵。来源:作者。</p></figure><p id="3983" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">可以看出，最常见的错误分类是9被错误地归类为4，2被归类为3。</p><h1 id="a62f" class="nb lt iq bd lu nc nd ne lx nf ng nh ma jw ni jx md jz nj ka mg kc nk kd mj nl bi translated">结论</h1><p id="bf56" class="pw-post-body-paragraph kv kw iq kx b ky mn jr la lb mo ju ld le nm lg lh li nn lk ll lm no lo lp lq ij bi translated">数据扩充被证明是计算机视觉的一种有效技术，因为它允许廉价而简单地提高模型的性能。</p><p id="0fa4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">尽管如此，重要的是要记住，在某些情况下，数据扩充并不同样有效。一种情况是测试集与原始训练集非常相似。在这种情况下，增加训练集是没有帮助的，因为模型将根据与测试阶段遇到的数据不同的数据进行训练。</p></div></div>    
</body>
</html>