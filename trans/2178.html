<html>
<head>
<title>Understanding the Frisch-Waugh-Lovell Theorem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解弗里希-沃-洛弗尔定理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-fwl-theorem-or-how-to-make-all-regressions-intuitive-59f801eb3299#2022-05-16">https://towardsdatascience.com/the-fwl-theorem-or-how-to-make-all-regressions-intuitive-59f801eb3299#2022-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="a6cd" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/causal-data-science" rel="noopener" target="_blank">因果数据科学</a></h2><div class=""/><div class=""><h2 id="8f66" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">因果推理中最强有力的定理之一的循序渐进指南</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/5b54ce7e045dbac612891fc341a0975b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WCUlBZljEHXTpNlgpEIUaA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="e256" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">弗里希-沃夫-洛厄尔定理是一个简单的<strong class="lg ja"/>然而强大的<strong class="lg ja">定理，它允许我们将多变量回归简化为单变量回归<strong class="lg ja"/>。当我们对两个变量之间的关系感兴趣时，这是非常有用的，但我们仍然需要控制其他因素，正如在<strong class="lg ja">因果推断</strong>中经常出现的情况。</strong></p><p id="a7f4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在这篇博文中，我将介绍弗里希-沃-洛厄尔定理，并举例说明一些有趣的应用。</p><h1 id="2d5a" class="ma mb iq bd mc md me mf mg mh mi mj mk kf ml kg mm ki mn kj mo kl mp km mq mr bi translated">定理</h1><p id="f99f" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">该定理由拉格纳·弗里希和弗雷德里克·沃于1933年首次发表。然而，由于它的证明冗长而繁琐，<a class="ae mx" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10480682" rel="noopener ugc nofollow" target="_blank">迈克尔·洛弗尔在1963年</a>提供了一个简单而直观的证明，他的名字被添加到定理名称中。</p><p id="8d36" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该定理指出，当估计一个模型的形式</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi my"><img src="../Images/2648ef739261c05884e3def8fe968548.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8ynPldJ7FmxmAbHMY8txg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="3bc2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">那么，<em class="mz"> β₁ </em>的以下估计量是等价的:</p><ul class=""><li id="e0be" class="na nb iq lg b lh li lk ll ln nc lr nd lv ne lz nf ng nh ni bi translated">通过对<em class="mz"> x₁ </em>和<em class="mz"> x₂ </em>回归<em class="mz"> y </em>得到的OLS估计量</li><li id="9e79" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">在<em class="mz"> x̃₁ </em>回归<em class="mz"> y </em>得到的OLS估计量，其中<em class="mz"> x̃₁ </em>是<em class="mz"> x₁ </em>在<em class="mz"> x₂ </em>回归的残差</li><li id="4c68" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">通过在<em class="mz"> x̃₁ </em>回归<em class="mz"> ỹ </em>得到的OLS估计量，其中ỹ是在<em class="mz"> x₂ </em>回归<em class="mz"> y </em>的残差</li></ul><h2 id="9069" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">解释</h2><p id="ccb7" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">我们究竟从<strong class="lg ja">中学到了什么</strong>？</p><p id="ef4a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">弗里希-沃-洛厄尔定理</strong>告诉我们有多种方法来估计单个回归系数。一种可能性是照常在<em class="mz"> x </em>上运行<em class="mz"> y </em>的完全回归。</p><p id="8001" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">但是，我们也可以在<em class="mz"> x₂ </em>上回归<em class="mz"> x₁ </em>，取残差，只回归<em class="mz"> y </em>那些残差。这个过程的第一部分有时被称为<em class="mz"> x₁ </em>相对于<em class="mz"> x₂ </em>的<strong class="lg ja">部分化</strong>(或<em class="mz">正交化</em>，或<em class="mz">剩余化</em>)。这个想法是我们正在隔离<em class="mz"> x₁ </em>中的变异，即<em class="mz">正交</em>到<em class="mz"> x₂ </em>。注意<em class="mz"> x₂ </em>也可以是多维的(即包括多个变量而不仅仅是一个)。</p><p id="bd42" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为什么会有人这么做？</p><p id="2f53" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这似乎是一个更加复杂的过程。现在我们需要做两步甚至三步，而不是简单的一步完成回归。一点都不直观。主要的优势来自于这样一个事实，即我们已经将一个多变量回归简化为一个单变量回归，使它更容易处理，更直观。</p><p id="bec5" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们稍后将更详细地探讨三个<strong class="lg ja">应用</strong>:</p><ul class=""><li id="9dc4" class="na nb iq lg b lh li lk ll ln nc lr nd lv ne lz nf ng nh ni bi translated">数据可视化</li><li id="2dc4" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">计算速度</li><li id="720c" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">推理的进一步应用</li></ul><p id="fb70" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，让我们首先用一个例子更详细地探讨这个定理。</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="257b" class="ma mb iq bd mc md og mf mg mh oh mj mk kf oi kg mm ki oj kj mo kl ok km mq mr bi translated">例子</h1><p id="c00a" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">假设我们是一家零售连锁店，在不同的地点拥有许多不同的商店。我们想出了一个增加销售额的绝妙主意:以优惠券的形式发放折扣。我们印了很多优惠券，然后分发出去。</p><p id="e74b" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了了解我们的营销策略是否奏效，我们在每家商店检查平均每日使用量<code class="fe ol om on oo b">sales</code>以及使用量<code class="fe ol om on oo b">coupon</code>的购物者比例。然而，有一个<strong class="lg ja">问题</strong>:我们担心收入较高的人不太可能使用折扣，但通常他们会花更多的钱。为了安全起见，我们还记录了每个商店附近的平均<code class="fe ol om on oo b">income</code>。</p><p id="a4a4" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以用<strong class="lg ja">有向无环图</strong> (DAG)来表示数据生成过程。如果你不熟悉DAGs，我在这里写了一篇关于<a class="ae mx" href="https://medium.com/towards-data-science/controls-b63dc69e3d8c" rel="noopener">有向无环图的简短介绍。</a></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi op"><img src="../Images/4506d95c58eda304fd4a2af7e0704764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37kyGbYstE4oX-GAJOFc0g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="34b9" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们加载并检查<strong class="lg ja">数据</strong>。我从<code class="fe ol om on oo b"><a class="ae mx" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py" rel="noopener ugc nofollow" target="_blank">src.dgp</a></code>导入数据生成过程，从<code class="fe ol om on oo b"><a class="ae mx" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py" rel="noopener ugc nofollow" target="_blank">src.utils</a></code>导入一些绘图函数和库。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="41a2" class="no mb iq oo b gy ou ov l ow ox">from src.utils import *<br/>from src.dgp import dgp_store_coupons<br/><br/>df = dgp_store_coupons().generate_data(N=50)<br/>df.head()</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/a33b628026df2f7054112cc6883194f5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*gKaZVi1pDC6qk1RLnLz6vA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="2c46" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们有关于<strong class="lg ja"> 50家商店</strong>的信息，我们观察使用<code class="fe ol om on oo b">coupons</code>、每日<code class="fe ol om on oo b">sales</code>(以千美元计)、附近平均<code class="fe ol om on oo b">income</code>(以千美元计)和<code class="fe ol om on oo b">day of the week</code>的顾客的百分比。</p><p id="d464" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">假设我们在<code class="fe ol om on oo b">coupon</code>的使用上直接回归<code class="fe ol om on oo b">sales</code>。我们会得到什么？我用<code class="fe ol om on oo b">seaborn</code> <code class="fe ol om on oo b">regplot</code>图形化的表示回归的<strong class="lg ja">结果</strong>。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="8f6c" class="no mb iq oo b gy ou ov l ow ox">import seaborn as sns</span><span id="c310" class="no mb iq oo b gy oz ov l ow ox">sns.regplot(x="coupons", y="sales", data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})<br/>plt.legend()<br/>plt.title(f"Sales and coupon usage");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/42c8e7e400eb2d8bd94cda43522d47e6.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-BRQUPPBGRp7tjJtbeipMg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="4bd1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">看起来优惠券是个坏主意:在优惠券使用较多的商店，我们观察到销售额较低。</p><p id="5977" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">然而，这可能只是高收入的人使用较少的优惠券，同时也花费更多。如果这是真的，它可能会使我们的结果产生偏差。就DAG而言，这意味着我们有一条经过<code class="fe ol om on oo b">income</code>的<strong class="lg ja">后门路径</strong>，生成一个非因果关系。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pa"><img src="../Images/c5ffc8ec77b1ea597fdb3771ff3a4fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Wu0XYGOld7T7wTkAlTQbQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="b00f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了恢复<code class="fe ol om on oo b">coupons</code>对<code class="fe ol om on oo b">sales</code>的因果影响，我们需要<strong class="lg ja">对<code class="fe ol om on oo b">income</code>进行条件</strong>分析。这将<strong class="lg ja">阻塞</strong>通过<code class="fe ol om on oo b">income</code>的非因果路径，只留下从<code class="fe ol om on oo b">coupons</code>到<code class="fe ol om on oo b">sales</code>的直接路径打开，允许我们估计因果效应。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pb"><img src="../Images/c0a999773aa2b3808209156813b0b2b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCgZTv2YAeR15Aac8N-J0w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="6ec0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">让我们通过在回归中包含<code class="fe ol om on oo b">income</code>来实现这一点。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="80f1" class="no mb iq oo b gy ou ov l ow ox">import statsmodels.formula.api as smf</span><span id="11ad" class="no mb iq oo b gy oz ov l ow ox">smf.ols('sales ~ coupons + income', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pc"><img src="../Images/b11003960a5caebdcaf927cc50ebf41a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Rta4dmkJ31-BTKhtB8x3w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="fd3e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在估计<code class="fe ol om on oo b">coupons</code>对<code class="fe ol om on oo b">sales</code>的影响是积极而显著的。毕竟优惠券是个好主意。</p><h2 id="d4e7" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">验证定理</h2><p id="c1be" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">现在让我们来验证弗里希-沃-洛厄尔定理是否成立。特别是，我们想要检查我们是否得到了<strong class="lg ja">相同的系数</strong>，如果不是在<code class="fe ol om on oo b">coupons</code>和<code class="fe ol om on oo b">income</code>上回归<code class="fe ol om on oo b">sales</code>，我们</p><ul class=""><li id="3877" class="na nb iq lg b lh li lk ll ln nc lr nd lv ne lz nf ng nh ni bi translated">在<code class="fe ol om on oo b">income</code>上倒退<code class="fe ol om on oo b">coupons</code></li><li id="d693" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">计算残差<code class="fe ol om on oo b">coupons_tilde</code>，即<code class="fe ol om on oo b">coupons</code>中的变化<strong class="lg ja">不是<code class="fe ol om on oo b">income</code>解释的</strong></li><li id="ad4e" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">在<code class="fe ol om on oo b">coupons_tilde</code>上倒退<code class="fe ol om on oo b">sales</code></li></ul><p id="4392" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">请注意，我在回归公式中添加了“-1”来删除截距。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="b471" class="no mb iq oo b gy ou ov l ow ox">df['coupons_tilde'] = smf.ols('coupons ~ income', df).fit().resid<br/><br/>smf.ols('sales ~ coupons_tilde - 1', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pd"><img src="../Images/bbe434106b1e4e322392986927dc4823.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I9gV7Vef4fOZLAeEiK9Gag.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="d71d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在系数是一样的！然而，<strong class="lg ja">标准误差</strong>已经增加了很多，并且估计的系数不再明显不同于零。</p><p id="d9e8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">更好的方法是增加一个步骤，并对<code class="fe ol om on oo b">sales</code>重复相同的程序:</p><ul class=""><li id="871e" class="na nb iq lg b lh li lk ll ln nc lr nd lv ne lz nf ng nh ni bi translated">在<code class="fe ol om on oo b">income</code>上回归<code class="fe ol om on oo b">sales</code></li><li id="2558" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">计算残差<code class="fe ol om on oo b">sales_tilde</code>，即<code class="fe ol om on oo b">sales</code> <strong class="lg ja">而非</strong>由<code class="fe ol om on oo b">income</code>解释的变化</li><li id="7dfc" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated">最后，在<code class="fe ol om on oo b">coupons_tilde</code>上回归<code class="fe ol om on oo b">sales_tilde</code></li></ul><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="1b68" class="no mb iq oo b gy ou ov l ow ox">df['sales_tilde'] = smf.ols('sales ~ income', df).fit().resid<br/><br/>smf.ols('sales_tilde ~ coupons_tilde - 1', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pe"><img src="../Images/804eaadf3311942f1e31eb38ce0d01a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uk4WQ9rpxpx03A9bog2nyg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="4e5c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">系数仍然完全相同，但现在标准误差也几乎相同。</p><h2 id="9186" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">推断</h2><p id="b8c1" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated"><strong class="lg ja">剔除</strong>(或剩余化，或正交化)实际上在做什么？当我们取<code class="fe ol om on oo b">coupons</code>相对于<code class="fe ol om on oo b">income</code>的残差时会发生什么？</p><p id="1f50" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以把这个过程想象成一个情节。首先，我们来展示一下<code class="fe ol om on oo b">coupons</code>关于收入的<strong class="lg ja">残差</strong>。</p><figure class="kp kq kr ks gt kt"><div class="bz fp l di"><div class="pf pg l"/></div></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/e3670470655a8ccf2c72ea5ea87489b5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zixPWeyffo6K8X5TPuzsGA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="4607" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">残差</strong>是数据和线性拟合之间的垂直虚线，即<code class="fe ol om on oo b">income</code>无法解释的<code class="fe ol om on oo b">coupons</code>中的变化部分。</p><p id="29f1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">通过<strong class="lg ja">去除</strong>，我们从数据中移除线性拟合，仅保留残差。我们可以用一个gif来形象化这个过程。我从<code class="fe ol om on oo b">src.figures</code>文件导入代码，你可以在这里找到<a class="ae mx" href="https://github.com/matteocourthoud/Blog-Posts/blob/main/src/figures.py" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="048e" class="no mb iq oo b gy ou ov l ow ox">from src.figures import gif_projection<br/><br/>gif_projection(x='income', y='coupons', df=df, gifname="gifs/fwl.gif")</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/3ecde9aea4cc4259f48534686fc07992.png" data-original-src="https://miro.medium.com/v2/1*EoqLLU3oXvFB0g9VovkzTQ.gif"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="697f" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">数据的原始分布在<em class="mz">蓝色</em>的左边，被分割的数据在<em class="mz">绿色</em>的右边。如我们所见，部分删除移除了<code class="fe ol om on oo b">coupons</code>中的水平和趋势，这由<code class="fe ol om on oo b">income</code>解释。</p><h2 id="6a23" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">多重控制</h2><p id="2019" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">当我们有多个控制变量时，我们也可以使用弗里希-沃定理。假设我们还想在回归中包含<code class="fe ol om on oo b">day of the week</code>，以提高精度。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="0433" class="no mb iq oo b gy ou ov l ow ox">smf.ols('sales ~ coupons + income + dayofweek', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ph"><img src="../Images/e86501f7c17ba88feca4ff8a1e4d2c13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O4-9Y6E2gNUEFWE1F5AV7g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="34ca" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以执行与之前相同的程序，但是不是<strong class="lg ja">只部分去除</strong>而是现在我们部分去除<code class="fe ol om on oo b">income</code>和<code class="fe ol om on oo b">day of the week</code>。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="b1b7" class="no mb iq oo b gy ou ov l ow ox">df['coupons_tilde'] = smf.ols('coupons ~ income + dayofweek', df).fit().resid<br/>df['sales_tilde'] = smf.ols('sales ~ income + dayofweek', df).fit().resid</span><span id="5bba" class="no mb iq oo b gy oz ov l ow ox">smf.ols('sales_tilde ~ coupons_tilde - 1', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pi"><img src="../Images/7ad5f76189cd02ffed2d6a83006f6614.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p8bf_UQbFbE6D7CN-1ju5g.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="0456" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们仍然得到完全相同的系数！</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="c053" class="ma mb iq bd mc md og mf mg mh oh mj mk kf oi kg mm ki oj kj mo kl ok km mq mr bi translated">应用程序</h1><p id="2e68" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">现在让我们来考察FWL定理的一些应用。</p><h2 id="5229" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">数据可视化</h2><p id="a4eb" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">弗里希-沃夫定理的优势之一是，它允许我们从一个<strong class="lg ja">单变量</strong>回归中估计感兴趣的系数，即使用一个解释变量(或特征)。</p><p id="3ae1" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">因此，我们现在可以用图形来表示利益关系<strong class="lg ja">。让我们绘制残差<code class="fe ol om on oo b">sales</code>对残差<code class="fe ol om on oo b">coupons</code>的曲线。</strong></p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="9a06" class="no mb iq oo b gy ou ov l ow ox">sns.regplot(x="coupons_tilde", y="sales_tilde", data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})<br/>plt.legend()<br/>plt.title(f"Residual sales and residual coupons");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/da2eaaaf4e1ce1b5d40b0af20d36b104.png" data-original-src="https://miro.medium.com/v2/format:webp/1*iqI806bO4tox6RYidoQ6qA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="a002" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在从图中可以明显看出<code class="fe ol om on oo b">sales</code>和<code class="fe ol om on oo b">coupons</code>之间的<strong class="lg ja">条件关系</strong>(以<code class="fe ol om on oo b">income</code>为条件)为正。</p><p id="da1d" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这种方法的一个问题是变量<strong class="lg ja">很难解释</strong>:我们现在对<code class="fe ol om on oo b">sales</code>和<code class="fe ol om on oo b">coupons</code>都有负值。奇怪。</p><p id="900c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">怎么发生的？这是因为当我们分割变量时，我们将<strong class="lg ja">截距</strong>包括在回归中，有效地去除了变量的含义(即标准化它们的值，使它们的平均值为零)。</p><p id="cc8c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我们可以通过<strong class="lg ja">缩放</strong>两个变量，加上它们的平均值来<strong class="lg ja">解决</strong>这个问题。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="2add" class="no mb iq oo b gy ou ov l ow ox">df['coupons_tilde_scaled'] = df['coupons_tilde'] + np.mean(df['coupons'])<br/>df['sales_tilde_scaled'] = df['sales_tilde'] + np.mean(df['sales'])</span></pre><p id="5e69" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">现在这两个变量的大小又可以解释了。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="b284" class="no mb iq oo b gy ou ov l ow ox">sns.regplot(x="coupons_tilde_scaled", y="sales_tilde_scaled", data=df, ci=False, line_kws={'color':'r', 'label':'linear fit'})<br/>plt.legend()<br/>plt.title(f"Residual sales scaled and residual coupons scaled");</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="ab gu cl oy"><img src="../Images/1f517583a12ad8ca5867772501a4848c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*z6eKB00aSnNm9Vnl87G3Ww.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="a745" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这是一个有效的方法还是改变了我们的估计？我们可以通过用按比例划分的变量进行回归来检查它。</p><pre class="kp kq kr ks gt oq oo or os aw ot bi"><span id="1bfc" class="no mb iq oo b gy ou ov l ow ox">smf.ols('sales_tilde_scaled ~ coupons_tilde_scaled', df).fit().summary().tables[1]</span></pre><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi pj"><img src="../Images/369a748ac06298843357bd28f1d67815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vz9IhzIHp4t0_ye0YG5BfQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">作者图片</p></figure><p id="bcf8" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">系数和之前一模一样！</p><h2 id="44a8" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">计算速度</h2><p id="a630" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">弗里希-沃-洛弗尔定理的另一个应用是提高线性估值器的计算速度。例如，它用于在存在高维固定效应的情况下计算有效的线性估计量(在我们的例子中为<code class="fe ol om on oo b">day of the week</code>)。</p><p id="9264" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">一些利用弗里希-沃-洛弗尔定理的软件包包括</p><ul class=""><li id="4f26" class="na nb iq lg b lh li lk ll ln nc lr nd lv ne lz nf ng nh ni bi translated"><a class="ae mx" href="http://scorreia.com/software/reghdfe/" rel="noopener ugc nofollow" target="_blank">Stata中的reghdfe</a></li><li id="125c" class="na nb iq lg b lh nj lk nk ln nl lr nm lv nn lz nf ng nh ni bi translated"><a class="ae mx" href="https://pyhdfe.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">Python中的pyhdfe</a></li></ul><p id="ce9c" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我还想提一下R中的<a class="ae mx" href="https://cran.r-project.org/web/packages/fixest/index.html" rel="noopener ugc nofollow" target="_blank"> fixest </a>包，它在运行具有高维固定效应的回归时也非常有效，但是使用了不同的过程。</p><h2 id="b214" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">推理和机器学习</h2><p id="a7c9" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">FWL定理的另一个重要应用位于<strong class="lg ja">机器学习</strong>和<strong class="lg ja">因果推理</strong>的交叉点。我指的是<a class="ae mx" href="https://academic.oup.com/restud/article-abstract/81/2/608/1523757" rel="noopener ugc nofollow" target="_blank">贝洛尼、切尔诺朱科夫、汉森(2013) </a>关于后双选择的工作，以及<a class="ae mx" href="https://academic.oup.com/ectj/article/21/1/C1/5056401" rel="noopener ugc nofollow" target="_blank">切尔诺朱科夫、切特维里科夫、德米勒、杜弗洛、汉森、纽维、罗宾斯(2018) </a>关于“双机器学习”的后续工作。</p><p id="f061" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我计划在以后的文章中讨论这两个应用程序，但是我想从基础开始。敬请期待！</p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h2 id="3537" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">参考</h2><p id="c1c6" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">[1] R .弗里希和F. V .沃夫，<a class="ae mx" href="https://www.jstor.org/stable/1907330" rel="noopener ugc nofollow" target="_blank">与个体趋势相比的部分时间回归</a> (1933)，<em class="mz">计量经济学</em>。</p><p id="2280" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">[2] M. C. Lowell，<a class="ae mx" href="https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10480682" rel="noopener ugc nofollow" target="_blank">经济时间序列的季节调整与多元回归分析</a> (1963)，<em class="mz">美国统计协会杂志</em>。</p><h2 id="4685" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">密码</h2><p id="6237" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated">你可以在这里找到Jupyter的原版笔记本。</p><div class="pk pl gp gr pm pn"><a href="https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/fwl.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="po ab fo"><div class="pp ab pq cl cj pr"><h2 class="bd ja gy z fp ps fr fs pt fu fw iz bi translated">Blog-Posts/fwl . ipynb at main matter courthoud/Blog-Posts</h2><div class="pu l"><h3 class="bd b gy z fp ps fr fs pt fu fw dk translated">我博客文章的代码和笔记本。通过在…上创建帐户，为matteocourthoud/Blog-Posts的发展做出贡献</h3></div><div class="pv l"><p class="bd b dl z fp ps fr fs pt fu fw dk translated">github.com</p></div></div><div class="pw l"><div class="px l py pz qa pw qb ky pn"/></div></div></a></div></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h2 id="6034" class="no mb iq bd mc np nq dn mg nr ns dp mk ln nt nu mm lr nv nw mo lv nx ny mq iw bi translated">感谢您的阅读！</h2><p id="39be" class="pw-post-body-paragraph le lf iq lg b lh ms ka lj lk mt kd lm ln mu lp lq lr mv lt lu lv mw lx ly lz ij bi translated"><em class="mz">真的很感谢！</em>🤗<em class="mz">如果你喜欢这个帖子并且想看更多，可以考虑</em> <a class="ae mx" href="https://medium.com/@matteo.courthoud" rel="noopener"> <strong class="lg ja"> <em class="mz">关注我</em> </strong> </a> <em class="mz">。我每周发布一次与因果推断和数据分析相关的主题。我尽量让我的帖子简单而精确，总是提供代码、例子和模拟。</em></p><p id="2195" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><em class="mz">还有，一个小小的</em> <strong class="lg ja"> <em class="mz">免责声明</em> </strong> <em class="mz">:我写作是为了学习所以错误是家常便饭，尽管我尽了最大努力。当你发现他们的时候，请告诉我。也很欣赏新话题的建议！</em></p></div></div>    
</body>
</html>